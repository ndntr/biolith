{
  "updated_at": "2025-11-13T23:19:03.655Z",
  "clusters": [
    {
      "id": "cluster_5",
      "coverage": 2,
      "updated_at": "2025-11-13T17:33:28-05:00",
      "title": "Apple TV is getting MLS games at no extra cost",
      "neutral_headline": "Apple TV is getting MLS games at no extra cost",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/820595/apple-tv-mls-games-bundle-no-extra-cost-subscription-season-pass",
          "published_at": "2025-11-13T17:33:28-05:00",
          "title": "Apple TV is getting MLS games at no extra cost",
          "standfirst": "Starting with the 2026 Major League Soccer (MLS) season, “all MLS matches” will be available to Apple TV subscribers “at no additional cost,” Apple and the MLS announced today. Since the 2023 MLS season, streaming MLS games has required an MLS Season Pass subscription, which was available on its own or for a discount for [&#8230;]",
          "content": "Starting with the 2026 Major League Soccer (MLS) season, “all MLS matches” will be available to Apple TV subscribers “at no additional cost,” Apple and the MLS announced today. Since the 2023 MLS season, streaming MLS games has required an MLS Season Pass subscription, which was available on its own or for a discount for Apple TV subscribers. But next year, like with Apple’s upcoming F1 streaming for Apple TV subscribers, MLS games will be bundled right into Apple TV. “Starting next season, fans can watch every regular-season match, the annual Leagues Cup tournament, the MLS All-Star Game, the Campeones Cup, the Audi MLS Cup Playoffs, and more — all included with an Apple TV subscription,” according to Apple’s press release. “The standalone MLS Season Pass subscription on the Apple TV app will conclude at the end of the 2025 season.” The official announcement of the change followed reports from earlier on Thursday that it was in the works.",
          "feed_position": 1
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251113/p45#a251113p45",
          "published_at": "Thu, 13 Nov 2025 14:45:45 -0500",
          "title": "Sources: Apple and Major League Soccer agree to make all MLS games available on Apple TV for no extra charge from 2026, ending the MLS Season Pass subscription (Paul Tenorio/The Athletic)",
          "standfirst": "Paul Tenorio / The Athletic: Sources: Apple and Major League Soccer agree to make all MLS games available on Apple TV for no extra charge from 2026, ending the MLS Season Pass subscription &mdash; PALM BEACH, Fla. &mdash; MLS will no longer be behind a separate paywall on Apple TV beginning in 2026.",
          "content": "Paul Tenorio / The Athletic: Sources: Apple and Major League Soccer agree to make all MLS games available on Apple TV for no extra charge from 2026, ending the MLS Season Pass subscription &mdash; PALM BEACH, Fla. &mdash; MLS will no longer be behind a separate paywall on Apple TV beginning in 2026.",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/251113/i45.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251113/i45.jpg",
      "popularity_score": 2019.2400958333333,
      "ai_summary": [
        "Apple TV subscribers will get MLS games at no extra cost.",
        "This begins with the 2026 Major League Soccer season.",
        "The MLS Season Pass subscription will end in 2026.",
        "All MLS matches will be available on Apple TV.",
        "The change was announced by Apple and MLS."
      ]
    },
    {
      "id": "cluster_12",
      "coverage": 2,
      "updated_at": "Thu, 13 Nov 2025 22:01:27 +0000",
      "title": "Black Friday VPN deals: Get 75 percent off Proton VPN two-year plans",
      "neutral_headline": "Black Friday VPN deals: Get 75 percent off Proton VPN two-year plans",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/black-friday-vpn-deals-get-75-percent-off-proton-vpn-two-year-plans-153737858.html",
          "published_at": "Thu, 13 Nov 2025 22:01:27 +0000",
          "title": "Black Friday VPN deals: Get 75 percent off Proton VPN two-year plans",
          "standfirst": "Now is arguably the best time of year to sign up for a VPN, or gift a subscription to someone. Black Friday VPN deals are already available, with one of the best being on our favorite VPN overall. Proton VPN is offering two years of access to its VPN Plus tier for $59.76, which works out to $2.49 per month. That's a discount of 75 percent compared with the regular price of $10 per month. Overall, you'd save $180. Proton VPN is our pick for the best VPN overall because it checks all of the boxes it needs to. There is a free plan with unlimited data, but with that you can only connect to servers in a few countries and the connection might not be fast enough for you to watch anything from your preferred streaming service's library in that locale. The VPN Plus tier unlocks a lot more options, such as the ability to connect to 15,000 servers across more than 120 countries and simultaneous protection for up to 15 devices. The apps are well-designed — Proton has clients for Windows, Mac, iOS and Android — and it's easy to find a feature or setting you're looking for. In our testing, Proton VPN Plus had a relatively small impact on browsing speeds. Our download speeds dropped by 12 percent and uploads by 4 percent, while the global average ping remained below 300 ms (which is especially impressive if you're connecting to a server on the other side of the planet). Perhaps, most importantly, though, it's Proton's commitment to privacy that helps make its VPN an easy recommendation. There's a no-logs policy, meaning it does not log user activity or any identifiable characteristics of devices that connect to the VPN. Proton's servers use full-disk encryption to bolster privacy as well. Proton VPN is not the only service to offer a Black Friday VPN deal this year, of course. There are plenty of others available on services we like. Here are the best of the bunch if you're looking for an alternative to Proton VPN. Surfshark One (24 months + 3 free months) for $59.13 (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. NordVPN Plus (24 months + 3 free months) for $105.03 (74 percent off): NordVPN has taken 74 percent off its Plus subscription for Black Friday. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. CyberGhost (24 months + 4 free months) for $56.94 (84 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Private Internet Access (36 months + 4 free months) for $79.20 (83 percent off): Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 40 months of PIA for just under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-vpn-deals-get-75-percent-off-proton-vpn-two-year-plans-153737858.html?src=rss",
          "content": "Now is arguably the best time of year to sign up for a VPN, or gift a subscription to someone. Black Friday VPN deals are already available, with one of the best being on our favorite VPN overall. Proton VPN is offering two years of access to its VPN Plus tier for $59.76, which works out to $2.49 per month. That's a discount of 75 percent compared with the regular price of $10 per month. Overall, you'd save $180. Proton VPN is our pick for the best VPN overall because it checks all of the boxes it needs to. There is a free plan with unlimited data, but with that you can only connect to servers in a few countries and the connection might not be fast enough for you to watch anything from your preferred streaming service's library in that locale. The VPN Plus tier unlocks a lot more options, such as the ability to connect to 15,000 servers across more than 120 countries and simultaneous protection for up to 15 devices. The apps are well-designed — Proton has clients for Windows, Mac, iOS and Android — and it's easy to find a feature or setting you're looking for. In our testing, Proton VPN Plus had a relatively small impact on browsing speeds. Our download speeds dropped by 12 percent and uploads by 4 percent, while the global average ping remained below 300 ms (which is especially impressive if you're connecting to a server on the other side of the planet). Perhaps, most importantly, though, it's Proton's commitment to privacy that helps make its VPN an easy recommendation. There's a no-logs policy, meaning it does not log user activity or any identifiable characteristics of devices that connect to the VPN. Proton's servers use full-disk encryption to bolster privacy as well. Proton VPN is not the only service to offer a Black Friday VPN deal this year, of course. There are plenty of others available on services we like. Here are the best of the bunch if you're looking for an alternative to Proton VPN. Surfshark One (24 months + 3 free months) for $59.13 (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. NordVPN Plus (24 months + 3 free months) for $105.03 (74 percent off): NordVPN has taken 74 percent off its Plus subscription for Black Friday. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. CyberGhost (24 months + 4 free months) for $56.94 (84 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Private Internet Access (36 months + 4 free months) for $79.20 (83 percent off): Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 40 months of PIA for just under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-vpn-deals-get-75-percent-off-proton-vpn-two-year-plans-153737858.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-black-friday-deals-i-hope-to-see-in-2025-100014091.html",
          "published_at": "Thu, 13 Nov 2025 21:05:01 +0000",
          "title": "The 8 Black Friday deals I hope to see in 2025",
          "standfirst": "Black Friday (which is now basically all of November) is one of the best times of the year to pick up things for yourself and for other people. But to say money is tight is an understatement this year. If Amazon’s Prime Big Deal Days was any indicator, folks are spending more on essentials than anything else during these big sales. That, combined with the rising trend of holding on to big tech purchases for longer means that you may not have gadgets at the top of your to-buy list this year. Even if that’s the case, I’d recommend not overlooking tech entirely this Black Friday. After all, all of us have essential tech that we use every day, and more often than not, you can avoid paying full price for most of those gadgets (and all of the rest of the best tech of the year) if you're looking to add to your repertoire or you need a replacement. Personally, I'm not eyeing a new smartphone or laptop this holiday shopping season, but there are a few tech purchases I’d like to make if the prices are right. This is the tech I’m hoping to save on this year during Black Friday. This article originally appeared on Engadget at https://www.engadget.com/deals/the-black-friday-deals-i-hope-to-see-in-2025-100014091.html?src=rss",
          "content": "Black Friday (which is now basically all of November) is one of the best times of the year to pick up things for yourself and for other people. But to say money is tight is an understatement this year. If Amazon’s Prime Big Deal Days was any indicator, folks are spending more on essentials than anything else during these big sales. That, combined with the rising trend of holding on to big tech purchases for longer means that you may not have gadgets at the top of your to-buy list this year. Even if that’s the case, I’d recommend not overlooking tech entirely this Black Friday. After all, all of us have essential tech that we use every day, and more often than not, you can avoid paying full price for most of those gadgets (and all of the rest of the best tech of the year) if you're looking to add to your repertoire or you need a replacement. Personally, I'm not eyeing a new smartphone or laptop this holiday shopping season, but there are a few tech purchases I’d like to make if the prices are right. This is the tech I’m hoping to save on this year during Black Friday. This article originally appeared on Engadget at https://www.engadget.com/deals/the-black-friday-deals-i-hope-to-see-in-2025-100014091.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/baidu-unveils-proprietary-ernie-5-beating-gpt-5-performance-on-charts",
          "published_at": "Thu, 13 Nov 2025 20:23:00 GMT",
          "title": "Baidu unveils proprietary ERNIE 5 beating GPT-5 performance on charts, document understanding and more",
          "standfirst": "Mere hours after OpenAI updated its flagship foundation model GPT-5 to GPT-5.1, promising reduced token usage overall and a more pleasant personality with more preset options, Chinese search giant Baidu unveiled its next-generation foundation model, ERNIE 5.0, alongside a suite of AI product upgrades and strategic international expansions.The goal: to position as a global contender in the increasingly competitive enterprise AI market.Announced at the company&#x27;s Baidu World 2025 event, ERNIE 5.0 is a proprietary, natively omni-modal model designed to jointly process and generate content across text, images, audio, and video. Unlike Baidu’s recently released ERNIE-4.5-VL-28B-A3B-Thinking, which is open source under an enterprise-friendly and permissive Apache 2.0 license, ERNIE 5.0 is a proprietary model and is available only via Baidu’s ERNIE Bot website (I needed to select it manuallyu from the model picker dropdown) and the Qianfan cloud platform application programming interface (API) for enterprise customers. Alongside the model launch, Baidu introduced major updates to its digital human platform, no-code tools, and general-purpose AI agents — all targeted at expanding its AI footprint beyond China.The company also introduced ERNIE 5.0 Preview 1022, a variant optimized for text-intensive tasks, alongside the general preview model that balances across modalities.Baidu emphasized that ERNIE 5.0 represents a shift in how intelligence is deployed at scale, with CEO Robin Li stating: “When you internalize AI, it becomes a native capability and transforms intelligence from a cost into a source of productivity.”Where ERNIE 5.0 outshines GPT-5 and Gemini 2.5 ProERNIE 5.0’s benchmark results suggest that Baidu has achieved parity—or near-parity—with the top Western foundation models across a wide spectrum of tasks. In public benchmark slides shared during the Baidu World 2025 event, ERNIE 5.0 Preview outperformed or matched OpenAI’s GPT-5-High and Google’s Gemini 2.5 Pro in multimodal reasoning, document understanding, and image-based QA, while also demonstrating strong language modeling and code execution abilities. The company emphasized its ability to handle joint inputs and outputs across modalities, rather than relying on post-hoc modality fusion, which it framed as a technical differentiator.On visual tasks, ERNIE 5.0 achieved leading scores on OCRBench, DocVQA, and ChartQA, three benchmarks that test document recognition, comprehension, and structured data reasoning. Baidu claims the model beat both GPT-5-High and Gemini 2.5 Pro on these document and chart-based benchmarks, areas it describes as core to enterprise applications like automated document processing and financial analysis. In image generation, ERNIE 5.0 tied or exceeded Google’s Veo3 across categories including semantic alignment and image quality, according to Baidu’s internal GenEval-based evaluation. Baidu claimed that the model’s multimodal integration allows it to generate and interpret visual content with greater contextual awareness than models relying on modality-specific encoders.For audio and speech tasks, ERNIE 5.0 demonstrated competitive results on MM-AU and TUT2017 audio understanding benchmarks, as well as question answering from spoken language inputs. Its audio performance, while not as heavily emphasized as vision or text, suggests a broad capability footprint intended to support full-spectrum multimodal applications.In language tasks, the model showed strong results on instruction following, factual question answering, and mathematical reasoning—core areas that define the enterprise utility of large language models. The Preview 1022 variant of ERNIE 5.0, tailored for textual performance, showed even stronger language-specific results in early developer access. While Baidu does not claim broad superiority in general language reasoning, its internal evaluations suggest that ERNIE 5.0 Preview 1022 closes the gap with top-tier English-language models and outperforms them in Chinese-language performance.While Baidu did not release full benchmark details or raw scores publicly, its performance positioning suggests a deliberate attempt to frame ERNIE 5.0 not as a niche multimodal system but as a flagship model competitive with the largest closed models in general-purpose reasoning. Where Baidu claims a clear lead is in structured document understanding, visual chart reasoning, and integration of multiple modalities into a single, native modeling architecture. Independent verification of these results remains pending, but the breadth of claimed capabilities positions ERNIE 5.0 as a serious alternative in the multimodal foundation model landscape.Enterprise Pricing StrategyERNIE 5.0 is positioned at the premium end of Baidu’s model pricing structure. The company has released specific pricing for API usage on its Qianfan platform, aligning the cost with other top-tier offerings from Chinese competitors like Alibaba.ModelInput Cost (per 1K tokens)Output Cost (per 1K tokens)SourceERNIE 5.0$0.00085 (¥0.006)$0.0034 (¥0.024)QianfanERNIE 4.5 Turbo (ex.)$0.00011 (¥0.0008)$0.00045 (¥0.0032)QianfanQwen3 (Coder ex.)$0.00085 (¥0.006)$0.0034 (¥0.024)QianfanThe contrast in cost between ERNIE 5.0 and earlier models such as ERNIE 4.5 Turbo underscores Baidu’s strategy to differentiate between high-volume, low-cost models and high-capability models designed for complex tasks and multimodal reasoning.Compared to other U.S. alternatives, it remains mid-range in pricing:ModelInput (/1 M tokens)Output (/1 M tokens)SourceGPT-5.1$1.25$10.00OpenAIERNIE 5.0$0.85$3.40QianfanERNIE 4.5 Turbo (ex.)$0.11$0.45QianfanClaude Opus 4.1$15.00$75.00Anthropic Gemini 2.5 Pro$1.25 (≤200k) / $2.50 (>200k)$10.00 (≤200k) / $15.00 (>200k)Google Vertex AI PricingGrok 4 (grok-4-0709)$3.00$15.00 xAI APIGlobal Expansion: Products and PlatformsIn tandem with the model release, Baidu is expanding internationally:GenFlow 3.0, now with 20M+ users, is the company’s largest general-purpose AI agent and features enhanced memory and multimodal task handling.Famou, a self-evolving agent capable of dynamically solving complex problems, is now commercially available via invite.MeDo, the international version of Baidu’s no-code builder Miaoda, is live globally via medo.dev.Oreate, a productivity workspace with document, slide, image, video, and podcast support, has reached over 1.2M users worldwide.Baidu’s digital human platform, already rolled out in Brazil, is also part of the global push. According to company data, 83% of livestreamers during this year’s “Double 11” shopping event in China used Baidu’s digital human tech, contributing to a 91% increase in GMV.Meanwhile, Baidu’s autonomous ride-hailing service Apollo Go has surpassed 17 million rides, operating driverless fleets in 22 cities and claiming the title of the world’s largest robotaxi network.Open-Source Vision-Language Model Garners Industry AttentionTwo days before the flagship ERNIE 5.0 event, Baidu also released an open-source multimodal model under the Apache 2.0 license: ERNIE-4.5-VL-28B-A3B-Thinking. As reported by my colleague Michael Nuñez at VentureBeat, the model activates just 3 billion parameters while maintaining a total of 28 billion, using a Mixture-of-Experts (MoE) architecture for efficient inference.Key technical innovations include:“Thinking with Images”, which enables dynamic zoom-based visual analysisSupport for chart interpretation, document understanding, visual grounding, and temporal awareness in videoRuntime on a single 80GB GPU, making it accessible to mid-sized organizationsFull compatibility with Transformers, vLLM, and Baidu’s FastDeploy toolkitsThis release adds pressure on closed-source competitors. With Apache 2.0 licensing, ERNIE-4.5-VL-28B-A3B-Thinking becomes a viable foundation model for commercial applications without licensing restrictions — something few high-performing models in this class offer.Community Feedback and Baidu’s ResponseFollowing the launch of ERNIE 5.0, developer and AI evaluator Lisan al Gaib (@scaling01) posted a mixed review on X. While initially impressed by the model’s benchmark performance, they reported a persistent issue where ERNIE 5.0 would repeatedly invoke tools — even when explicitly instructed not to — during SVG generation tasks.“ERNIE 5.0 benchmarks looked insane until I tested it… unfortunately it’s RL braindamaged or they have a serious issue with their chat platform / system prompt,” Lisan wrote.In a matter of hours, Baidu’s developer-focused support account, @ErnieforDevs, responded:“Thanks for the feedback! It’s a known bug — certain syntax can consistently trigger it. We’re working on a fix. You can try rephrasing or changing the prompt to avoid it for now.”The quick turnaround reflects Baidu’s increasing emphasis on developer communication, especially as it courts international users through both proprietary and open-source offerings.Outlook for Baidu and its ERNIE foundational LLM familyBaidu’s ERNIE 5.0 marks a strategic escalation in the global foundation model race. With performance claims that put it on par with the most advanced systems from OpenAI and Google, and a mix of premium pricing and open-access alternatives, Baidu is signaling its ambition to become not just a domestic AI leader, but a credible global infrastructure provider.At a time when enterprise AI users are increasingly demanding multimodal performance, flexible licensing, and deployment efficiency, Baidu’s two-track approach—premium hosted APIs and open-source releases—may broaden its appeal across both corporate and developer communities.Whether the company’s performance claims hold up under third-party testing remains to be seen. But in a landscape shaped by rising costs, model complexity, and compute bottlenecks, ERNIE 5.0 and its supporting ecosystem give Baidu a competitive position in the next wave of AI deployment.",
          "content": "Mere hours after OpenAI updated its flagship foundation model GPT-5 to GPT-5.1, promising reduced token usage overall and a more pleasant personality with more preset options, Chinese search giant Baidu unveiled its next-generation foundation model, ERNIE 5.0, alongside a suite of AI product upgrades and strategic international expansions.The goal: to position as a global contender in the increasingly competitive enterprise AI market.Announced at the company&#x27;s Baidu World 2025 event, ERNIE 5.0 is a proprietary, natively omni-modal model designed to jointly process and generate content across text, images, audio, and video. Unlike Baidu’s recently released ERNIE-4.5-VL-28B-A3B-Thinking, which is open source under an enterprise-friendly and permissive Apache 2.0 license, ERNIE 5.0 is a proprietary model and is available only via Baidu’s ERNIE Bot website (I needed to select it manuallyu from the model picker dropdown) and the Qianfan cloud platform application programming interface (API) for enterprise customers. Alongside the model launch, Baidu introduced major updates to its digital human platform, no-code tools, and general-purpose AI agents — all targeted at expanding its AI footprint beyond China.The company also introduced ERNIE 5.0 Preview 1022, a variant optimized for text-intensive tasks, alongside the general preview model that balances across modalities.Baidu emphasized that ERNIE 5.0 represents a shift in how intelligence is deployed at scale, with CEO Robin Li stating: “When you internalize AI, it becomes a native capability and transforms intelligence from a cost into a source of productivity.”Where ERNIE 5.0 outshines GPT-5 and Gemini 2.5 ProERNIE 5.0’s benchmark results suggest that Baidu has achieved parity—or near-parity—with the top Western foundation models across a wide spectrum of tasks. In public benchmark slides shared during the Baidu World 2025 event, ERNIE 5.0 Preview outperformed or matched OpenAI’s GPT-5-High and Google’s Gemini 2.5 Pro in multimodal reasoning, document understanding, and image-based QA, while also demonstrating strong language modeling and code execution abilities. The company emphasized its ability to handle joint inputs and outputs across modalities, rather than relying on post-hoc modality fusion, which it framed as a technical differentiator.On visual tasks, ERNIE 5.0 achieved leading scores on OCRBench, DocVQA, and ChartQA, three benchmarks that test document recognition, comprehension, and structured data reasoning. Baidu claims the model beat both GPT-5-High and Gemini 2.5 Pro on these document and chart-based benchmarks, areas it describes as core to enterprise applications like automated document processing and financial analysis. In image generation, ERNIE 5.0 tied or exceeded Google’s Veo3 across categories including semantic alignment and image quality, according to Baidu’s internal GenEval-based evaluation. Baidu claimed that the model’s multimodal integration allows it to generate and interpret visual content with greater contextual awareness than models relying on modality-specific encoders.For audio and speech tasks, ERNIE 5.0 demonstrated competitive results on MM-AU and TUT2017 audio understanding benchmarks, as well as question answering from spoken language inputs. Its audio performance, while not as heavily emphasized as vision or text, suggests a broad capability footprint intended to support full-spectrum multimodal applications.In language tasks, the model showed strong results on instruction following, factual question answering, and mathematical reasoning—core areas that define the enterprise utility of large language models. The Preview 1022 variant of ERNIE 5.0, tailored for textual performance, showed even stronger language-specific results in early developer access. While Baidu does not claim broad superiority in general language reasoning, its internal evaluations suggest that ERNIE 5.0 Preview 1022 closes the gap with top-tier English-language models and outperforms them in Chinese-language performance.While Baidu did not release full benchmark details or raw scores publicly, its performance positioning suggests a deliberate attempt to frame ERNIE 5.0 not as a niche multimodal system but as a flagship model competitive with the largest closed models in general-purpose reasoning. Where Baidu claims a clear lead is in structured document understanding, visual chart reasoning, and integration of multiple modalities into a single, native modeling architecture. Independent verification of these results remains pending, but the breadth of claimed capabilities positions ERNIE 5.0 as a serious alternative in the multimodal foundation model landscape.Enterprise Pricing StrategyERNIE 5.0 is positioned at the premium end of Baidu’s model pricing structure. The company has released specific pricing for API usage on its Qianfan platform, aligning the cost with other top-tier offerings from Chinese competitors like Alibaba.ModelInput Cost (per 1K tokens)Output Cost (per 1K tokens)SourceERNIE 5.0$0.00085 (¥0.006)$0.0034 (¥0.024)QianfanERNIE 4.5 Turbo (ex.)$0.00011 (¥0.0008)$0.00045 (¥0.0032)QianfanQwen3 (Coder ex.)$0.00085 (¥0.006)$0.0034 (¥0.024)QianfanThe contrast in cost between ERNIE 5.0 and earlier models such as ERNIE 4.5 Turbo underscores Baidu’s strategy to differentiate between high-volume, low-cost models and high-capability models designed for complex tasks and multimodal reasoning.Compared to other U.S. alternatives, it remains mid-range in pricing:ModelInput (/1 M tokens)Output (/1 M tokens)SourceGPT-5.1$1.25$10.00OpenAIERNIE 5.0$0.85$3.40QianfanERNIE 4.5 Turbo (ex.)$0.11$0.45QianfanClaude Opus 4.1$15.00$75.00Anthropic Gemini 2.5 Pro$1.25 (≤200k) / $2.50 (>200k)$10.00 (≤200k) / $15.00 (>200k)Google Vertex AI PricingGrok 4 (grok-4-0709)$3.00$15.00 xAI APIGlobal Expansion: Products and PlatformsIn tandem with the model release, Baidu is expanding internationally:GenFlow 3.0, now with 20M+ users, is the company’s largest general-purpose AI agent and features enhanced memory and multimodal task handling.Famou, a self-evolving agent capable of dynamically solving complex problems, is now commercially available via invite.MeDo, the international version of Baidu’s no-code builder Miaoda, is live globally via medo.dev.Oreate, a productivity workspace with document, slide, image, video, and podcast support, has reached over 1.2M users worldwide.Baidu’s digital human platform, already rolled out in Brazil, is also part of the global push. According to company data, 83% of livestreamers during this year’s “Double 11” shopping event in China used Baidu’s digital human tech, contributing to a 91% increase in GMV.Meanwhile, Baidu’s autonomous ride-hailing service Apollo Go has surpassed 17 million rides, operating driverless fleets in 22 cities and claiming the title of the world’s largest robotaxi network.Open-Source Vision-Language Model Garners Industry AttentionTwo days before the flagship ERNIE 5.0 event, Baidu also released an open-source multimodal model under the Apache 2.0 license: ERNIE-4.5-VL-28B-A3B-Thinking. As reported by my colleague Michael Nuñez at VentureBeat, the model activates just 3 billion parameters while maintaining a total of 28 billion, using a Mixture-of-Experts (MoE) architecture for efficient inference.Key technical innovations include:“Thinking with Images”, which enables dynamic zoom-based visual analysisSupport for chart interpretation, document understanding, visual grounding, and temporal awareness in videoRuntime on a single 80GB GPU, making it accessible to mid-sized organizationsFull compatibility with Transformers, vLLM, and Baidu’s FastDeploy toolkitsThis release adds pressure on closed-source competitors. With Apache 2.0 licensing, ERNIE-4.5-VL-28B-A3B-Thinking becomes a viable foundation model for commercial applications without licensing restrictions — something few high-performing models in this class offer.Community Feedback and Baidu’s ResponseFollowing the launch of ERNIE 5.0, developer and AI evaluator Lisan al Gaib (@scaling01) posted a mixed review on X. While initially impressed by the model’s benchmark performance, they reported a persistent issue where ERNIE 5.0 would repeatedly invoke tools — even when explicitly instructed not to — during SVG generation tasks.“ERNIE 5.0 benchmarks looked insane until I tested it… unfortunately it’s RL braindamaged or they have a serious issue with their chat platform / system prompt,” Lisan wrote.In a matter of hours, Baidu’s developer-focused support account, @ErnieforDevs, responded:“Thanks for the feedback! It’s a known bug — certain syntax can consistently trigger it. We’re working on a fix. You can try rephrasing or changing the prompt to avoid it for now.”The quick turnaround reflects Baidu’s increasing emphasis on developer communication, especially as it courts international users through both proprietary and open-source offerings.Outlook for Baidu and its ERNIE foundational LLM familyBaidu’s ERNIE 5.0 marks a strategic escalation in the global foundation model race. With performance claims that put it on par with the most advanced systems from OpenAI and Google, and a mix of premium pricing and open-access alternatives, Baidu is signaling its ambition to become not just a domestic AI leader, but a credible global infrastructure provider.At a time when enterprise AI users are increasingly demanding multimodal performance, flexible licensing, and deployment efficiency, Baidu’s two-track approach—premium hosted APIs and open-source releases—may broaden its appeal across both corporate and developer communities.Whether the company’s performance claims hold up under third-party testing remains to be seen. But in a landscape shaped by rising costs, model complexity, and compute bottlenecks, ERNIE 5.0 and its supporting ecosystem give Baidu a competitive position in the next wave of AI deployment.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7tpZTCavJ5IcG1LDI66Xae/5066d5c70ead90c2f63e0ef888b9a9ef/YPf93J54wCLeSJI7yvPQK.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/black-friday-audible-deal-get-three-months-for-only-3-140010540.html",
          "published_at": "Thu, 13 Nov 2025 20:01:28 +0000",
          "title": "Black Friday Audible deal: Get three months for only $3",
          "standfirst": "Black Friday is a great time to take a look at what subscriptions you may be able to save on. From video streaming services to budgeting apps, many services will have some Black Friday promotion you may be able to take advantage of. One of the best we're tracking is for Audible. You can sign up and get your first three months for just $3 in total, plus get a $20 Audible credit on top of that. This breaks down to $1 per month for the first three months, which is a boon for audiobook fans. Just make sure to cancel before the 90 days are up, as the subscription will auto-renew at $15 per month. That's not the worst deal in the world, given the vast number of titles available on the platform, but still. Audible has a diverse catalog that goes beyond audiobooks. It also hosts podcasts and Audible Originals. Subscribers get to choose one audiobook each month to keep in their collection for free, including best-sellers or new releases. Users also get unlimited access to the Plus Catalog, which houses thousands of audiobooks. Finally, active members get discounts on many audiobooks when looking to purchase. Winter is coming and this is a good way to make sure you have plenty to listen to throughout the next three months. This deal does have a time limit. It expires on December 16.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-audible-deal-get-three-months-for-only-3-140010540.html?src=rss",
          "content": "Black Friday is a great time to take a look at what subscriptions you may be able to save on. From video streaming services to budgeting apps, many services will have some Black Friday promotion you may be able to take advantage of. One of the best we're tracking is for Audible. You can sign up and get your first three months for just $3 in total, plus get a $20 Audible credit on top of that. This breaks down to $1 per month for the first three months, which is a boon for audiobook fans. Just make sure to cancel before the 90 days are up, as the subscription will auto-renew at $15 per month. That's not the worst deal in the world, given the vast number of titles available on the platform, but still. Audible has a diverse catalog that goes beyond audiobooks. It also hosts podcasts and Audible Originals. Subscribers get to choose one audiobook each month to keep in their collection for free, including best-sellers or new releases. Users also get unlimited access to the Plus Catalog, which houses thousands of audiobooks. Finally, active members get discounts on many audiobooks when looking to purchase. Winter is coming and this is a good way to make sure you have plenty to listen to throughout the next three months. This deal does have a time limit. It expires on December 16.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-audible-deal-get-three-months-for-only-3-140010540.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/this-roomba-robot-vacuum-is-on-sale-for-only-150-for-black-friday-191506560.html",
          "published_at": "Thu, 13 Nov 2025 19:15:06 +0000",
          "title": "This Roomba robot vacuum is on sale for only $150 for Black Friday",
          "standfirst": "You can already get a solid deal on a Roomba robot vacuum a couple of weeks before Black Friday kicks off in earnest. iRobot's entry-level Roomba 104 Vac robot vacuum is available for 40 percent off right now, taking its normal $250 price to a record low of $150. In iRobot's lineup of robot vacuums, the Roomba 104 sits on the low end, adept at vacuuming up dust and hair, but without the mopping ability of its more expensive Max, Plus or Combo counterparts. The Roomba 104 Vac makes for a great first robot vacuum all the same, though, because of its four levels of powerful suction, and easy-to-use app. Like iRobot's other vacuums, the Roomba 104 maps and navigates your home with LiDAR, which helps it avoid obstacles. And using the Roomba Home app, you can schedule it to clean specific rooms, and even spot-clean particularly dirty spots. An earlier version of the Roomba Vac is Engadget's favorite budget robot vacuum, and you'll get the same great performance out of the newer Roomba 104 Vac. That includes a specialized brush for cleaning the hard-to-reach corners of your home, and also a charging dock that the vacuum can automatically return to once it's down charging. This sale on Roomba vacuums comes at an admittedly difficult time for iRobot at large, with the company dealing with a serious financial shortfall as of its last earning statement. Regardless of what happens to iRobot, though, the Roomba 104 Vac's offline mode should mean that it can clean your home and charge itself without the need of an app or an internet connection. This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/this-roomba-robot-vacuum-is-on-sale-for-only-150-for-black-friday-191506560.html?src=rss",
          "content": "You can already get a solid deal on a Roomba robot vacuum a couple of weeks before Black Friday kicks off in earnest. iRobot's entry-level Roomba 104 Vac robot vacuum is available for 40 percent off right now, taking its normal $250 price to a record low of $150. In iRobot's lineup of robot vacuums, the Roomba 104 sits on the low end, adept at vacuuming up dust and hair, but without the mopping ability of its more expensive Max, Plus or Combo counterparts. The Roomba 104 Vac makes for a great first robot vacuum all the same, though, because of its four levels of powerful suction, and easy-to-use app. Like iRobot's other vacuums, the Roomba 104 maps and navigates your home with LiDAR, which helps it avoid obstacles. And using the Roomba Home app, you can schedule it to clean specific rooms, and even spot-clean particularly dirty spots. An earlier version of the Roomba Vac is Engadget's favorite budget robot vacuum, and you'll get the same great performance out of the newer Roomba 104 Vac. That includes a specialized brush for cleaning the hard-to-reach corners of your home, and also a charging dock that the vacuum can automatically return to once it's down charging. This sale on Roomba vacuums comes at an admittedly difficult time for iRobot at large, with the company dealing with a serious financial shortfall as of its last earning statement. Regardless of what happens to iRobot, though, the Roomba 104 Vac's offline mode should mean that it can clean your home and charge itself without the need of an app or an internet connection. This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/this-roomba-robot-vacuum-is-on-sale-for-only-150-for-black-friday-191506560.html?src=rss",
          "feed_position": 13
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/vampire-survivors-vr-asks-what-if-the-bullet-hell-was-on-your-face-190749256.html",
          "published_at": "Thu, 13 Nov 2025 19:07:49 +0000",
          "title": "Vampire Survivors VR asks what if the bullet hell was on your face?",
          "standfirst": "During my many hours playing Vampire Survivors I often wondered what it would feel like to have the absolutely insane bullet hell action extremely close to my eyeballs. Now my dream is being fulfilled, as there's a VR port for Meta Quest headsets. The appropriately-named Vampire Survivors VR costs $10 and is available for the Meta Quest 2, 3, 3S and Pro. This isn't a game that puts you in the middle of the action, as you won't have to duck and weave around the living room to avoid incoming hordes. Rather, it gives you a top-down view of the stage and you use a controller to navigate as you would on any other platform. This kind of tactic has worked in the past with VR titles like Demeo. It can be played seated or standing, which isn't true of all VR games. Also, this is a standalone version and there's no cross-buy with other platforms. That means that save files don't carry over. That's a bummer, but I guess it makes sense given the uniqueness of VR. Developer Poncle has not revealed if this version will feature online co-op, which was recently announced as coming soon to the PC and console builds. As for DLC, Vampire Survivors VR includes the base game and the Legacy of the Moonspell and Tides of the Foscari expansions. We don't have any information regarding the status of other expansions like the cool Castlevania one or the utterly bizarre Balatro tie-in. Vampire Survivors VR is available right now, for those willing to risk a massive headache and perhaps a spot of nausea. Poncle currently has no plans to develop it for other VR platforms, like Steam VR or Pico.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/vampire-survivors-vr-asks-what-if-the-bullet-hell-was-on-your-face-190749256.html?src=rss",
          "content": "During my many hours playing Vampire Survivors I often wondered what it would feel like to have the absolutely insane bullet hell action extremely close to my eyeballs. Now my dream is being fulfilled, as there's a VR port for Meta Quest headsets. The appropriately-named Vampire Survivors VR costs $10 and is available for the Meta Quest 2, 3, 3S and Pro. This isn't a game that puts you in the middle of the action, as you won't have to duck and weave around the living room to avoid incoming hordes. Rather, it gives you a top-down view of the stage and you use a controller to navigate as you would on any other platform. This kind of tactic has worked in the past with VR titles like Demeo. It can be played seated or standing, which isn't true of all VR games. Also, this is a standalone version and there's no cross-buy with other platforms. That means that save files don't carry over. That's a bummer, but I guess it makes sense given the uniqueness of VR. Developer Poncle has not revealed if this version will feature online co-op, which was recently announced as coming soon to the PC and console builds. As for DLC, Vampire Survivors VR includes the base game and the Legacy of the Moonspell and Tides of the Foscari expansions. We don't have any information regarding the status of other expansions like the cool Castlevania one or the utterly bizarre Balatro tie-in. Vampire Survivors VR is available right now, for those willing to risk a massive headache and perhaps a spot of nausea. Poncle currently has no plans to develop it for other VR platforms, like Steam VR or Pico.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/vampire-survivors-vr-asks-what-if-the-bullet-hell-was-on-your-face-190749256.html?src=rss",
          "feed_position": 15
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/walmart-subscriptions-are-only-49-for-black-friday-and-it-includes-access-to-peacock-192739301.html",
          "published_at": "Thu, 13 Nov 2025 18:38:34 +0000",
          "title": "Walmart+ subscriptions are only $49 for Black Friday, and it includes access to Peacock",
          "standfirst": "Walmart is offering its Walmart+ subscription at half off for new sign-ups, and it includes a choice of either Peacock Premium or Paramount+ Essential. The deal for new subscribers is just $49 for the first year, marked down from $98. The real value is in selecting Peacock Premium, which would normally run you $110 per year on its own. With the current discount on a Walmart+ subscription you are essentially getting half off on your streaming subscription for that year. Just about every major streaming service has raised its prices in the last year, including HBO Max, Disney+, Netflix, Apple TV and YouTube TV, so saving some money on one of them just might be worth the effort. Cord cutting is not nearly as affordable as it used to be, so finding a deal like this is pretty helpful. Walmart+ itself offers myriad additional benefits like early access to Black Friday deals, free shipping on orders over $35, discounts on gas, free online veterinary care and more. Earlier this year, Walmart+ subscribers got first dibs on the Nintendo Switch 2 at the retailer. You can also use that free shipping to take advantage of Walmart's drone delivery program in a handful of select cities.This article originally appeared on Engadget at https://www.engadget.com/deals/walmart-subscriptions-are-only-49-for-black-friday-and-it-includes-access-to-peacock-192739301.html?src=rss",
          "content": "Walmart is offering its Walmart+ subscription at half off for new sign-ups, and it includes a choice of either Peacock Premium or Paramount+ Essential. The deal for new subscribers is just $49 for the first year, marked down from $98. The real value is in selecting Peacock Premium, which would normally run you $110 per year on its own. With the current discount on a Walmart+ subscription you are essentially getting half off on your streaming subscription for that year. Just about every major streaming service has raised its prices in the last year, including HBO Max, Disney+, Netflix, Apple TV and YouTube TV, so saving some money on one of them just might be worth the effort. Cord cutting is not nearly as affordable as it used to be, so finding a deal like this is pretty helpful. Walmart+ itself offers myriad additional benefits like early access to Black Friday deals, free shipping on orders over $35, discounts on gas, free online veterinary care and more. Earlier this year, Walmart+ subscribers got first dibs on the Nintendo Switch 2 at the retailer. You can also use that free shipping to take advantage of Walmart's drone delivery program in a handful of select cities.This article originally appeared on Engadget at https://www.engadget.com/deals/walmart-subscriptions-are-only-49-for-black-friday-and-it-includes-access-to-peacock-192739301.html?src=rss",
          "feed_position": 18
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/upwork-study-shows-ai-agents-excel-with-human-partners-but-fail",
          "published_at": "Thu, 13 Nov 2025 18:30:00 GMT",
          "title": "Upwork study shows AI agents excel with human partners but fail independently",
          "standfirst": "Artificial intelligence agents powered by the world&#x27;s most advanced language models routinely fail to complete even straightforward professional tasks on their own, according to groundbreaking research released Thursday by Upwork, the largest online work marketplace.But the same study reveals a more promising path forward: When AI agents collaborate with human experts, project completion rates surge by up to 70%, suggesting the future of work may not pit humans against machines but rather pair them together in powerful new ways.The findings, drawn from more than 300 real client projects posted to Upwork&#x27;s platform, marking the first systematic evaluation of how human expertise amplifies AI agent performance in actual professional work — not synthetic tests or academic simulations. The research challenges both the hype around fully autonomous AI agents and fears that such technology will imminently replace knowledge workers.\"AI agents aren&#x27;t that agentic, meaning they aren&#x27;t that good,\" Andrew Rabinovich, Upwork&#x27;s chief technology officer and head of AI and machine learning, said in an exclusive interview with VentureBeat. \"However, when paired with expert human professionals, project completion rates improve dramatically, supporting our firm belief that the future of work will be defined by humans and AI collaborating to get more work done, with human intuition and domain expertise playing a critical role.\"How AI agents performed on 300+ real freelance jobs—and why they struggledUpwork&#x27;s Human+Agent Productivity Index (HAPI) evaluated how three leading AI systems — Gemini 2.5 Pro, OpenAI&#x27;s GPT-5, and Claude Sonnet 4 — performed on actual jobs posted by paying clients across categories including writing, data science, web development, engineering, sales, and translation.Critically, Upwork deliberately selected simple, well-defined projects where AI agents stood a reasonable chance of success. These jobs, priced under $500, represent less than 6% of Upwork&#x27;s total gross services volume — a tiny fraction of the platform&#x27;s overall business and an acknowledgment of current AI limitations.\"The reality is that although we study AI, and I&#x27;ve been doing this for 25 years, and we see significant breakthroughs, the reality is that these agents aren&#x27;t that agentic,\" Rabinovich told VentureBeat. \"So if we go up the value chain, the problems become so much more difficult, then we don&#x27;t think they can solve them at all, even to scratch the surface. So we specifically chose simpler tasks that would give an agent some kind of traction.\"Even on these deliberately simplified tasks, AI agents working independently struggled. But when expert freelancers provided feedback — spending an average of just 20 minutes per review cycle — the agents&#x27; performance improved substantially with each iteration.20 minutes of human feedback boosted AI completion rates up to 70%The research reveals stark differences in how AI agents perform with and without human guidance across different types of work. For data science and analytics projects, Claude Sonnet 4 achieved a 64% completion rate working alone but jumped to 93% after receiving feedback from a human expert. In sales and marketing work, Gemini 2.5 Pro&#x27;s completion rate rose from 17% independently to 31% with human input. OpenAI&#x27;s GPT-5 showed similarly dramatic improvements in engineering and architecture tasks, climbing from 30% to 50% completion.The pattern held across virtually all categories, with agents responding particularly well to human feedback on qualitative, creative work requiring editorial judgment — areas like writing, translation, and marketing — where completion rates increased by up to 17 percentage points per feedback cycle.The finding challenges a fundamental assumption in the AI industry: that agent benchmarks conducted in isolation accurately predict real-world performance.\"While we show that in the tasks that we have selected for agents to perform in isolation, they perform similarly to the previous results that we&#x27;ve seen published openly, what we&#x27;ve shown is that in collaboration with humans, the performance of these agents improves surprisingly well,\" Rabinovich said. \"It&#x27;s not just a one-turn back and forth, but the more feedback the human provides, the better the agent gets at performing.\"Why ChatGPT can ace the SAT but can&#x27;t count the R&#x27;s in &#x27;strawberry&#x27;The research arrives as the AI industry grapples with a measurement crisis. Traditional benchmarks — standardized tests that AI models can master, sometimes scoring perfectly on SAT exams or mathematics olympiads — have proven poor predictors of real-world capability.\"With advances of large language models, what we&#x27;re now seeing is that these static, academic datasets are completely saturated,\" Rabinovich said. \"So you could get a perfect score in the SAT test or LSAT or any of the math olympiads, and then you would ask ChatGPT how many R&#x27;s there are in the word strawberry, and it would get it wrong.\"This phenomenon — where AI systems ace formal tests but stumble on trivial real-world questions — has led to growing skepticism about AI capabilities, even as companies race to deploy autonomous agents. Several recent benchmarks from other firms have tested AI agents on Upwork jobs, but those evaluations measured only isolated performance, not the collaborative potential that Upwork&#x27;s research reveals.\"We wanted to evaluate the quality of these agents on actual real work with economic value associated with it, and not only see how well these agents do, but also see how these agents do in collaboration with humans, because we sort of knew already that in isolation, they&#x27;re not that advanced,\" Rabinovich explained.For Upwork, which connects roughly 800,000 active clients posting more than 3 million jobs annually to a global pool of freelancers, the research serves a strategic business purpose: establishing quality standards for AI agents before allowing them to compete or collaborate with human workers on its platform.The economics of human-AI teamwork: Why paying for expert feedback still saves moneyDespite requiring multiple rounds of human feedback — each lasting about 20 minutes — the time investment remains \"orders of magnitude different between a human doing the work alone, versus a human doing the work with an AI agent,\" Rabinovich said. Where a project might take a freelancer days to complete independently, the agent-plus-human approach can deliver results in hours through iterative cycles of automated work and expert refinement.The economic implications extend beyond simple time savings. Upwork recently reported that gross services volume from AI-related work grew 53% year-over-year in the third quarter of 2025, one of the strongest growth drivers for the company. But executives have been careful to frame AI not as a replacement for freelancers but as an enhancement to their capabilities.\"AI was a huge overhang for our valuation,\" Erica Gessert, Upwork&#x27;s CFO, told CFO Brew in October. \"There was this belief that all work was going to go away. AI was going to take it, and especially work that&#x27;s done by people like freelancers, because they are impermanent. Actually, the opposite is true.\"The company&#x27;s strategy centers on enabling freelancers to handle more complex, higher-value work by offloading routine tasks to AI. \"Freelancers actually prefer to have tools that automate the manual labor and repetitive part of their work, and really focus on the creative and conceptual part of the process,\" Rabinovich said.Rather than replacing jobs, he argues, AI will transform them: \"Simpler tasks will be automated by agents, but the jobs will become much more complex in the number of tasks, so the amount of work and therefore earnings for freelancers will actually only go up.\"AI coding agents excel, but creative writing and translation still need humansThe research reveals a clear pattern in agent capabilities. AI systems perform best on \"deterministic and verifiable\" tasks with objectively correct answers, like solving math problems or writing basic code. \"Most coding tasks are very similar to each other,\" Rabinovich noted. \"That&#x27;s why coding agents are becoming so good.\"In Upwork&#x27;s tests, web development, mobile app development, and data science projects — especially those involving structured, computational work — saw the highest standalone agent completion rates. Claude Sonnet 4 completed 68% of web development jobs and 64% of data science projects without human help, while Gemini 2.5 Pro achieved 74% on certain technical tasks.But qualitative work proved far more challenging. When asked to create website layouts, write marketing copy, or translate content with appropriate cultural nuance, agents floundered without expert guidance. \"When you ask it to write you a poem, the quality of the poem is extremely subjective,\" Rabinovich said. \"Since the rubrics for evaluation were provided by humans, there&#x27;s some level of variability in representation.\"Writing, translation, and sales and marketing projects showed the most dramatic improvements from human feedback. For writing work, completion rates increased by up to 17 percentage points after expert review. Engineering and architecture projects requiring creative problem-solving — like civil engineering or architectural design — improved by as much as 23 percentage points with human oversight.This pattern suggests AI agents excel at pattern matching and replication but struggle with creativity, judgment, and context — precisely the skills that define higher-value professional work.Inside the research: How Upwork tested AI agents with peer-reviewed scientific methodsUpwork partnered with elite freelancers on its platform to evaluate every deliverable produced by AI agents, both independently and after each cycle of human feedback. These evaluators created detailed rubrics defining whether projects met core requirements specified in job descriptions, then scored outputs across multiple iterations.Importantly, evaluators focused only on objective completion criteria, excluding subjective factors like stylistic preferences or quality judgments that might emerge in actual client relationships. \"Rubric-based completion rates should not be viewed as a measure of whether an agent would be paid in a real marketplace setting,\" the research notes, \"but as an indicator of its ability to fulfill explicitly defined requests.\"This distinction matters: An AI agent might technically complete all specified requirements yet still produce work a client rejects as inadequate. Conversely, subjective client satisfaction — the true measure of marketplace success — remains beyond current measurement capabilities.The research underwent double-blind peer review and was accepted to NeurIPS, the premier academic conference for AI research, where Upwork will present full results in early December. The company plans to publish a complete methodology and make the benchmark available to the research community, updating the task pool regularly to prevent overfitting as agents improve.\"The idea is for this benchmark to be a living and breathing platform where agents can come in and evaluate themselves on all categories of work, and the tasks that will be offered on the platform will always update, so that these agents don&#x27;t overfit and basically memorize the tasks at hand,\" Rabinovich said.Upwork&#x27;s AI strategy: Building Uma, a &#x27;meta-agent&#x27; that manages human and AI workersThe research directly informs Upwork&#x27;s product roadmap as the company positions itself for what executives call \"the age of AI and beyond.\" Rather than building its own AI agents to complete specific tasks, Upwork is developing Uma, a \"meta orchestration agent\" that coordinates between human workers, AI systems, and clients.\"Today, Upwork is a marketplace where clients look for freelancers to get work done, and then talent comes to Upwork to find work,\" Rabinovich explained. \"This is getting expanded into a domain where clients come to Upwork, communicate with Uma, this meta-orchestration agent, and then Uma identifies the necessary talent to get the job done, gets the tasks outcomes completed, and then delivers that to the client.\"In this vision, clients would interact primarily with Uma rather than directly hiring freelancers. The AI system would analyze project requirements, determine which tasks require human expertise versus AI execution, coordinate the workflow, and ensure quality — acting as an intelligent project manager rather than a replacement worker.\"We don&#x27;t want to build agents that actually complete the tasks, but we are building this meta orchestration agent that figures out what human and agent talent is necessary in order to complete the tasks,\" Rabinovich said. \"Uma evaluates the work to be delivered to the client, orchestrates the interaction between humans and agents, and is able to learn from all the interactions that happen on the platform how to break jobs into tasks so that they get completed in a timely and effective manner.\"The company recently announced plans to open its first international office in Lisbon, Portugal, by the fourth quarter of 2026, with a focus on AI infrastructure development and technical hiring. The expansion follows Upwork&#x27;s record-breaking third quarter, driven partly by AI-powered product innovation and strong demand for workers with AI skills.OpenAI, Anthropic, and Google race to build autonomous agents—but reality lags hypeUpwork&#x27;s findings arrive amid escalating competition in the AI agent space. OpenAI, Anthropic, Google, and numerous startups are racing to develop autonomous agents capable of complex multi-step tasks, from booking travel to analyzing financial data to writing software.But recent high-profile stumbles have tempered initial enthusiasm. AI agents frequently misunderstand instructions, make logical errors, or produce confidently wrong results — a phenomenon researchers call \"hallucination.\" The gap between controlled demonstration videos and reliable real-world performance remains vast.\"There have been some evaluations that came from OpenAI and other platforms where real Upwork tasks were considered for completion by agents, and across the board, the reported results were not very optimistic, in the sense that they showed that agents—even the best ones, meaning powered by most advanced LLMs — can&#x27;t really compete with humans that well, because the completion rates are pretty low,\" Rabinovich said.Rather than waiting for AI to fully mature — a timeline that remains uncertain—Upwork is betting on a hybrid approach that leverages AI&#x27;s strengths (speed, scalability, pattern recognition) while retaining human strengths (judgment, creativity, contextual understanding).This philosophy extends to learning and improvement. Current AI models train primarily on static datasets scraped from the internet, supplemented by human preference feedback. But most professional work is qualitative, making it difficult for AI systems to know whether their outputs are actually good without expert evaluation.\"Unless you have this collaboration between the human and the machine, where the human is kind of the teacher and the machine is the student trying to discover new solutions, none of this will be possible,\" Rabinovich said. \"Upwork is very uniquely positioned to create such an environment because if you try to do this with, say, self-driving cars, and you tell Waymo cars to explore new ways of getting to the airport, like avoiding traffic signs, then a bunch of bad things will happen. In doing work on Upwork, if it creates a wrong website, it doesn&#x27;t cost very much, and there&#x27;s no negative side effects. But the opportunity to learn is absolutely tremendous.\"Will AI take your job? The evidence suggests a more complicated answerWhile much public discourse around AI focuses on job displacement, Rabinovich argues the historical pattern suggests otherwise — though the transition may prove disruptive.\"The narrative in the public is that AI is eliminating jobs, whether it&#x27;s writing, translation, coding or other digital work, but no one really talks about the exponential amount of new types of work that it will create,\" he said. \"When we invented electricity and steam engines and things like that, they certainly replaced certain jobs, but the amount of new jobs that were introduced is exponentially more, and we think the same is going to happen here.\"The research identifies emerging job categories focused on AI oversight: designing effective human-machine workflows, providing high-quality feedback to improve agent performance, and verifying that AI-generated work meets quality standards. These skills—prompt engineering, agent supervision, output verification—barely existed two years ago but now command premium rates on platforms like Upwork.\"New types of skills from humans are becoming necessary in the form of how to design the interaction between humans and machines, how to guide agents to make them better, and ultimately, how to verify that whatever agentic proposals are being made are actually correct, because that&#x27;s what&#x27;s necessary in order to advance the state of AI,\" Rabinovich said.The question remains whether this transition— from doing tasks to overseeing them — will create opportunities as quickly as it disrupts existing roles. For freelancers on Upwork, the answer may already be emerging in their bank accounts: The platform saw AI-related work grow 53% year-over-year, even as fears of AI-driven unemployment dominated headlines.",
          "content": "Artificial intelligence agents powered by the world&#x27;s most advanced language models routinely fail to complete even straightforward professional tasks on their own, according to groundbreaking research released Thursday by Upwork, the largest online work marketplace.But the same study reveals a more promising path forward: When AI agents collaborate with human experts, project completion rates surge by up to 70%, suggesting the future of work may not pit humans against machines but rather pair them together in powerful new ways.The findings, drawn from more than 300 real client projects posted to Upwork&#x27;s platform, marking the first systematic evaluation of how human expertise amplifies AI agent performance in actual professional work — not synthetic tests or academic simulations. The research challenges both the hype around fully autonomous AI agents and fears that such technology will imminently replace knowledge workers.\"AI agents aren&#x27;t that agentic, meaning they aren&#x27;t that good,\" Andrew Rabinovich, Upwork&#x27;s chief technology officer and head of AI and machine learning, said in an exclusive interview with VentureBeat. \"However, when paired with expert human professionals, project completion rates improve dramatically, supporting our firm belief that the future of work will be defined by humans and AI collaborating to get more work done, with human intuition and domain expertise playing a critical role.\"How AI agents performed on 300+ real freelance jobs—and why they struggledUpwork&#x27;s Human+Agent Productivity Index (HAPI) evaluated how three leading AI systems — Gemini 2.5 Pro, OpenAI&#x27;s GPT-5, and Claude Sonnet 4 — performed on actual jobs posted by paying clients across categories including writing, data science, web development, engineering, sales, and translation.Critically, Upwork deliberately selected simple, well-defined projects where AI agents stood a reasonable chance of success. These jobs, priced under $500, represent less than 6% of Upwork&#x27;s total gross services volume — a tiny fraction of the platform&#x27;s overall business and an acknowledgment of current AI limitations.\"The reality is that although we study AI, and I&#x27;ve been doing this for 25 years, and we see significant breakthroughs, the reality is that these agents aren&#x27;t that agentic,\" Rabinovich told VentureBeat. \"So if we go up the value chain, the problems become so much more difficult, then we don&#x27;t think they can solve them at all, even to scratch the surface. So we specifically chose simpler tasks that would give an agent some kind of traction.\"Even on these deliberately simplified tasks, AI agents working independently struggled. But when expert freelancers provided feedback — spending an average of just 20 minutes per review cycle — the agents&#x27; performance improved substantially with each iteration.20 minutes of human feedback boosted AI completion rates up to 70%The research reveals stark differences in how AI agents perform with and without human guidance across different types of work. For data science and analytics projects, Claude Sonnet 4 achieved a 64% completion rate working alone but jumped to 93% after receiving feedback from a human expert. In sales and marketing work, Gemini 2.5 Pro&#x27;s completion rate rose from 17% independently to 31% with human input. OpenAI&#x27;s GPT-5 showed similarly dramatic improvements in engineering and architecture tasks, climbing from 30% to 50% completion.The pattern held across virtually all categories, with agents responding particularly well to human feedback on qualitative, creative work requiring editorial judgment — areas like writing, translation, and marketing — where completion rates increased by up to 17 percentage points per feedback cycle.The finding challenges a fundamental assumption in the AI industry: that agent benchmarks conducted in isolation accurately predict real-world performance.\"While we show that in the tasks that we have selected for agents to perform in isolation, they perform similarly to the previous results that we&#x27;ve seen published openly, what we&#x27;ve shown is that in collaboration with humans, the performance of these agents improves surprisingly well,\" Rabinovich said. \"It&#x27;s not just a one-turn back and forth, but the more feedback the human provides, the better the agent gets at performing.\"Why ChatGPT can ace the SAT but can&#x27;t count the R&#x27;s in &#x27;strawberry&#x27;The research arrives as the AI industry grapples with a measurement crisis. Traditional benchmarks — standardized tests that AI models can master, sometimes scoring perfectly on SAT exams or mathematics olympiads — have proven poor predictors of real-world capability.\"With advances of large language models, what we&#x27;re now seeing is that these static, academic datasets are completely saturated,\" Rabinovich said. \"So you could get a perfect score in the SAT test or LSAT or any of the math olympiads, and then you would ask ChatGPT how many R&#x27;s there are in the word strawberry, and it would get it wrong.\"This phenomenon — where AI systems ace formal tests but stumble on trivial real-world questions — has led to growing skepticism about AI capabilities, even as companies race to deploy autonomous agents. Several recent benchmarks from other firms have tested AI agents on Upwork jobs, but those evaluations measured only isolated performance, not the collaborative potential that Upwork&#x27;s research reveals.\"We wanted to evaluate the quality of these agents on actual real work with economic value associated with it, and not only see how well these agents do, but also see how these agents do in collaboration with humans, because we sort of knew already that in isolation, they&#x27;re not that advanced,\" Rabinovich explained.For Upwork, which connects roughly 800,000 active clients posting more than 3 million jobs annually to a global pool of freelancers, the research serves a strategic business purpose: establishing quality standards for AI agents before allowing them to compete or collaborate with human workers on its platform.The economics of human-AI teamwork: Why paying for expert feedback still saves moneyDespite requiring multiple rounds of human feedback — each lasting about 20 minutes — the time investment remains \"orders of magnitude different between a human doing the work alone, versus a human doing the work with an AI agent,\" Rabinovich said. Where a project might take a freelancer days to complete independently, the agent-plus-human approach can deliver results in hours through iterative cycles of automated work and expert refinement.The economic implications extend beyond simple time savings. Upwork recently reported that gross services volume from AI-related work grew 53% year-over-year in the third quarter of 2025, one of the strongest growth drivers for the company. But executives have been careful to frame AI not as a replacement for freelancers but as an enhancement to their capabilities.\"AI was a huge overhang for our valuation,\" Erica Gessert, Upwork&#x27;s CFO, told CFO Brew in October. \"There was this belief that all work was going to go away. AI was going to take it, and especially work that&#x27;s done by people like freelancers, because they are impermanent. Actually, the opposite is true.\"The company&#x27;s strategy centers on enabling freelancers to handle more complex, higher-value work by offloading routine tasks to AI. \"Freelancers actually prefer to have tools that automate the manual labor and repetitive part of their work, and really focus on the creative and conceptual part of the process,\" Rabinovich said.Rather than replacing jobs, he argues, AI will transform them: \"Simpler tasks will be automated by agents, but the jobs will become much more complex in the number of tasks, so the amount of work and therefore earnings for freelancers will actually only go up.\"AI coding agents excel, but creative writing and translation still need humansThe research reveals a clear pattern in agent capabilities. AI systems perform best on \"deterministic and verifiable\" tasks with objectively correct answers, like solving math problems or writing basic code. \"Most coding tasks are very similar to each other,\" Rabinovich noted. \"That&#x27;s why coding agents are becoming so good.\"In Upwork&#x27;s tests, web development, mobile app development, and data science projects — especially those involving structured, computational work — saw the highest standalone agent completion rates. Claude Sonnet 4 completed 68% of web development jobs and 64% of data science projects without human help, while Gemini 2.5 Pro achieved 74% on certain technical tasks.But qualitative work proved far more challenging. When asked to create website layouts, write marketing copy, or translate content with appropriate cultural nuance, agents floundered without expert guidance. \"When you ask it to write you a poem, the quality of the poem is extremely subjective,\" Rabinovich said. \"Since the rubrics for evaluation were provided by humans, there&#x27;s some level of variability in representation.\"Writing, translation, and sales and marketing projects showed the most dramatic improvements from human feedback. For writing work, completion rates increased by up to 17 percentage points after expert review. Engineering and architecture projects requiring creative problem-solving — like civil engineering or architectural design — improved by as much as 23 percentage points with human oversight.This pattern suggests AI agents excel at pattern matching and replication but struggle with creativity, judgment, and context — precisely the skills that define higher-value professional work.Inside the research: How Upwork tested AI agents with peer-reviewed scientific methodsUpwork partnered with elite freelancers on its platform to evaluate every deliverable produced by AI agents, both independently and after each cycle of human feedback. These evaluators created detailed rubrics defining whether projects met core requirements specified in job descriptions, then scored outputs across multiple iterations.Importantly, evaluators focused only on objective completion criteria, excluding subjective factors like stylistic preferences or quality judgments that might emerge in actual client relationships. \"Rubric-based completion rates should not be viewed as a measure of whether an agent would be paid in a real marketplace setting,\" the research notes, \"but as an indicator of its ability to fulfill explicitly defined requests.\"This distinction matters: An AI agent might technically complete all specified requirements yet still produce work a client rejects as inadequate. Conversely, subjective client satisfaction — the true measure of marketplace success — remains beyond current measurement capabilities.The research underwent double-blind peer review and was accepted to NeurIPS, the premier academic conference for AI research, where Upwork will present full results in early December. The company plans to publish a complete methodology and make the benchmark available to the research community, updating the task pool regularly to prevent overfitting as agents improve.\"The idea is for this benchmark to be a living and breathing platform where agents can come in and evaluate themselves on all categories of work, and the tasks that will be offered on the platform will always update, so that these agents don&#x27;t overfit and basically memorize the tasks at hand,\" Rabinovich said.Upwork&#x27;s AI strategy: Building Uma, a &#x27;meta-agent&#x27; that manages human and AI workersThe research directly informs Upwork&#x27;s product roadmap as the company positions itself for what executives call \"the age of AI and beyond.\" Rather than building its own AI agents to complete specific tasks, Upwork is developing Uma, a \"meta orchestration agent\" that coordinates between human workers, AI systems, and clients.\"Today, Upwork is a marketplace where clients look for freelancers to get work done, and then talent comes to Upwork to find work,\" Rabinovich explained. \"This is getting expanded into a domain where clients come to Upwork, communicate with Uma, this meta-orchestration agent, and then Uma identifies the necessary talent to get the job done, gets the tasks outcomes completed, and then delivers that to the client.\"In this vision, clients would interact primarily with Uma rather than directly hiring freelancers. The AI system would analyze project requirements, determine which tasks require human expertise versus AI execution, coordinate the workflow, and ensure quality — acting as an intelligent project manager rather than a replacement worker.\"We don&#x27;t want to build agents that actually complete the tasks, but we are building this meta orchestration agent that figures out what human and agent talent is necessary in order to complete the tasks,\" Rabinovich said. \"Uma evaluates the work to be delivered to the client, orchestrates the interaction between humans and agents, and is able to learn from all the interactions that happen on the platform how to break jobs into tasks so that they get completed in a timely and effective manner.\"The company recently announced plans to open its first international office in Lisbon, Portugal, by the fourth quarter of 2026, with a focus on AI infrastructure development and technical hiring. The expansion follows Upwork&#x27;s record-breaking third quarter, driven partly by AI-powered product innovation and strong demand for workers with AI skills.OpenAI, Anthropic, and Google race to build autonomous agents—but reality lags hypeUpwork&#x27;s findings arrive amid escalating competition in the AI agent space. OpenAI, Anthropic, Google, and numerous startups are racing to develop autonomous agents capable of complex multi-step tasks, from booking travel to analyzing financial data to writing software.But recent high-profile stumbles have tempered initial enthusiasm. AI agents frequently misunderstand instructions, make logical errors, or produce confidently wrong results — a phenomenon researchers call \"hallucination.\" The gap between controlled demonstration videos and reliable real-world performance remains vast.\"There have been some evaluations that came from OpenAI and other platforms where real Upwork tasks were considered for completion by agents, and across the board, the reported results were not very optimistic, in the sense that they showed that agents—even the best ones, meaning powered by most advanced LLMs — can&#x27;t really compete with humans that well, because the completion rates are pretty low,\" Rabinovich said.Rather than waiting for AI to fully mature — a timeline that remains uncertain—Upwork is betting on a hybrid approach that leverages AI&#x27;s strengths (speed, scalability, pattern recognition) while retaining human strengths (judgment, creativity, contextual understanding).This philosophy extends to learning and improvement. Current AI models train primarily on static datasets scraped from the internet, supplemented by human preference feedback. But most professional work is qualitative, making it difficult for AI systems to know whether their outputs are actually good without expert evaluation.\"Unless you have this collaboration between the human and the machine, where the human is kind of the teacher and the machine is the student trying to discover new solutions, none of this will be possible,\" Rabinovich said. \"Upwork is very uniquely positioned to create such an environment because if you try to do this with, say, self-driving cars, and you tell Waymo cars to explore new ways of getting to the airport, like avoiding traffic signs, then a bunch of bad things will happen. In doing work on Upwork, if it creates a wrong website, it doesn&#x27;t cost very much, and there&#x27;s no negative side effects. But the opportunity to learn is absolutely tremendous.\"Will AI take your job? The evidence suggests a more complicated answerWhile much public discourse around AI focuses on job displacement, Rabinovich argues the historical pattern suggests otherwise — though the transition may prove disruptive.\"The narrative in the public is that AI is eliminating jobs, whether it&#x27;s writing, translation, coding or other digital work, but no one really talks about the exponential amount of new types of work that it will create,\" he said. \"When we invented electricity and steam engines and things like that, they certainly replaced certain jobs, but the amount of new jobs that were introduced is exponentially more, and we think the same is going to happen here.\"The research identifies emerging job categories focused on AI oversight: designing effective human-machine workflows, providing high-quality feedback to improve agent performance, and verifying that AI-generated work meets quality standards. These skills—prompt engineering, agent supervision, output verification—barely existed two years ago but now command premium rates on platforms like Upwork.\"New types of skills from humans are becoming necessary in the form of how to design the interaction between humans and machines, how to guide agents to make them better, and ultimately, how to verify that whatever agentic proposals are being made are actually correct, because that&#x27;s what&#x27;s necessary in order to advance the state of AI,\" Rabinovich said.The question remains whether this transition— from doing tasks to overseeing them — will create opportunities as quickly as it disrupts existing roles. For freelancers on Upwork, the answer may already be emerging in their bank accounts: The platform saw AI-related work grow 53% year-over-year, even as fears of AI-driven unemployment dominated headlines.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1v1ddqAyA62qgnuh9O3ek5/6c2c87800376ecfd23a29d2c01c593e4/nuneybits_Robot_and_human_working_side_by_side_in_a_modern_offi_8b67c654-4d49-42c2-a291-5a9bb86c99db.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/quicken-simplifi-subscriptions-are-half-off-for-black-friday-160025840.html",
          "published_at": "Thu, 13 Nov 2025 18:01:27 +0000",
          "title": "Quicken Simplifi subscriptions are half off for Black Friday",
          "standfirst": "Budgeting can be a stressful, challenging and uncomfortable experience. While it's completely possible to do it on your own, we've become fans of a few great budgeting apps. Take our favorite budgeting app Quicken, which is having a 50 percent off sale for Black Friday. The Quicken Simplifi app is down to $3 monthly from $6 monthly, adding up to $36 for the year. Quicken Classic, the company's \"original desktop software\" for \"experienced investors\" is also half off at $6 monthly, down from $12 monthly. The sale starts today and is available until Wednesday, December 3. One of the many things that sets Quicken Simplifi apart from its competitors is its sleek, easy to use interface. The setup is pretty straightforward and it allows for your spouse or financial advisor to act as co-manager of the account. It also clearly shows figures like net worth, recent spending, upcoming recurring payments and more. Plus, there's an option to say if you're expecting a refund. Quicken Simplifi unfortunately doesn't offer a free trial so testing it out with a discount means less money invested if it's not for you. This article originally appeared on Engadget at https://www.engadget.com/deals/quicken-simplifi-subscriptions-are-half-off-for-black-friday-160025840.html?src=rss",
          "content": "Budgeting can be a stressful, challenging and uncomfortable experience. While it's completely possible to do it on your own, we've become fans of a few great budgeting apps. Take our favorite budgeting app Quicken, which is having a 50 percent off sale for Black Friday. The Quicken Simplifi app is down to $3 monthly from $6 monthly, adding up to $36 for the year. Quicken Classic, the company's \"original desktop software\" for \"experienced investors\" is also half off at $6 monthly, down from $12 monthly. The sale starts today and is available until Wednesday, December 3. One of the many things that sets Quicken Simplifi apart from its competitors is its sleek, easy to use interface. The setup is pretty straightforward and it allows for your spouse or financial advisor to act as co-manager of the account. It also clearly shows figures like net worth, recent spending, upcoming recurring payments and more. Plus, there's an option to say if you're expecting a refund. Quicken Simplifi unfortunately doesn't offer a free trial so testing it out with a discount means less money invested if it's not for you. This article originally appeared on Engadget at https://www.engadget.com/deals/quicken-simplifi-subscriptions-are-half-off-for-black-friday-160025840.html?src=rss",
          "feed_position": 20
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/lego-black-friday-deals-on-star-wars-and-disney-sets-are-up-to-37-percent-off-ahead-of-the-big-sale-155007410.html",
          "published_at": "Thu, 13 Nov 2025 17:47:35 +0000",
          "title": "Lego Black Friday deals on Star Wars and Disney sets are up to 37 percent off ahead of the big sale",
          "standfirst": "Lego is cutting prices for Black Friday and Cyber Monday. I'm a lifelong Lego lover, and my younger self would have squealed at some of the deals I'm seeing — as I'm betting is true for many of you. With so many to choose from, you'll be able to find one that makes a great gift for anyone who you know loves these little building bricks. Throughout the month, I'll be checking all the biggest online shopping centers in search of the biggest discounts on the best Lego sets available. We've already seen low prices on Disney and Harry Potter advent calendars your kids will love this December, plus beautiful botanicals and art pieces for yourself or the adults on your list. It's only likely to get better, so keep checking regularly. In general, we always recommend using a price tracker when determining if a Lego deal is in fact a good one. You'll find Lego deals across the board this holiday season at retailers like Amazon and Walmart, but don't overlook Lego's own site. If you join the free Lego Insiders program, you'll build up points with each purchase that you can redeem in the future, get special discounts and sometimes get exclusive gifts when you buy. While not a deal, arguably the hottest Lego for Black Friday will be the brand new Star Trek USS Enterprise set, which was announced recently. It has a whopping 3,600 pieces and will be a must-have for any Star Trek fans. The set will be available starting November 28 for $400. Best Lego Black Friday deals LEGO Disney Frozen Advent Calendar 2025 43273 for $31 (32 percent off) Lego Harry Potter Advent Calendar 2025 76456 for $37 (17 percent off) LEGO Star Wars Brick-Built Star Wars Logo 75407 for $48 (19 percent off) LEGO Star Wars Grogu with Hover Pram Building Toy Set 75403 for $50 (50 percent off) LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable Model 75375 for $68 (20 percent off) LEGO Star Wars R2-D2 Building Toy Set 75379 for $80 (20 percent off) LEGO Harry Potter Hogwarts Castle and Grounds 76419 for $136 (20 percent off) LEGO Creator 3 in 1 Magical Unicorn Toy 31140 for $7 (32 percent off) LEGO City Donut Truck Toy 60452 for $16 (20 percent off) LEGO Speed Champions 2 Fast 2 Furious Nissan Skyline GT-R (R34) Race Car 76917 for $18 (28 percent off) LEGO Botanicals Happy Plants Building Toys 10349 for $20 (13 percent off) LEGO Botanicals Mini Orchid Building Set 10343 for $24 (20 percent off) LEGO Art Hokusai The Great Wave Framed Japanese Wall Art Building Set 31208 for $85 (15 percent off) LEGO Ideas Tuxedo Cat 21349 for $80 (20 percent off) LEGO Icons Fountain Garden Building Set 10359 for $70 (30 percent off) LEGO Dreamzzz Izzie's Dream Animals Toys 71481 for $32 (20 percent off) LEGO NINJAGO Dragon Stone Shrine 71819 for $79 (34 percent off) LEGO Harry Potter Mandrake Figure & Pot Plant Toy 76433 for $49 (30 percent off) This article originally appeared on Engadget at https://www.engadget.com/deals/lego-black-friday-deals-on-star-wars-and-disney-sets-are-up-to-37-percent-off-ahead-of-the-big-sale-155007410.html?src=rss",
          "content": "Lego is cutting prices for Black Friday and Cyber Monday. I'm a lifelong Lego lover, and my younger self would have squealed at some of the deals I'm seeing — as I'm betting is true for many of you. With so many to choose from, you'll be able to find one that makes a great gift for anyone who you know loves these little building bricks. Throughout the month, I'll be checking all the biggest online shopping centers in search of the biggest discounts on the best Lego sets available. We've already seen low prices on Disney and Harry Potter advent calendars your kids will love this December, plus beautiful botanicals and art pieces for yourself or the adults on your list. It's only likely to get better, so keep checking regularly. In general, we always recommend using a price tracker when determining if a Lego deal is in fact a good one. You'll find Lego deals across the board this holiday season at retailers like Amazon and Walmart, but don't overlook Lego's own site. If you join the free Lego Insiders program, you'll build up points with each purchase that you can redeem in the future, get special discounts and sometimes get exclusive gifts when you buy. While not a deal, arguably the hottest Lego for Black Friday will be the brand new Star Trek USS Enterprise set, which was announced recently. It has a whopping 3,600 pieces and will be a must-have for any Star Trek fans. The set will be available starting November 28 for $400. Best Lego Black Friday deals LEGO Disney Frozen Advent Calendar 2025 43273 for $31 (32 percent off) Lego Harry Potter Advent Calendar 2025 76456 for $37 (17 percent off) LEGO Star Wars Brick-Built Star Wars Logo 75407 for $48 (19 percent off) LEGO Star Wars Grogu with Hover Pram Building Toy Set 75403 for $50 (50 percent off) LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable Model 75375 for $68 (20 percent off) LEGO Star Wars R2-D2 Building Toy Set 75379 for $80 (20 percent off) LEGO Harry Potter Hogwarts Castle and Grounds 76419 for $136 (20 percent off) LEGO Creator 3 in 1 Magical Unicorn Toy 31140 for $7 (32 percent off) LEGO City Donut Truck Toy 60452 for $16 (20 percent off) LEGO Speed Champions 2 Fast 2 Furious Nissan Skyline GT-R (R34) Race Car 76917 for $18 (28 percent off) LEGO Botanicals Happy Plants Building Toys 10349 for $20 (13 percent off) LEGO Botanicals Mini Orchid Building Set 10343 for $24 (20 percent off) LEGO Art Hokusai The Great Wave Framed Japanese Wall Art Building Set 31208 for $85 (15 percent off) LEGO Ideas Tuxedo Cat 21349 for $80 (20 percent off) LEGO Icons Fountain Garden Building Set 10359 for $70 (30 percent off) LEGO Dreamzzz Izzie's Dream Animals Toys 71481 for $32 (20 percent off) LEGO NINJAGO Dragon Stone Shrine 71819 for $79 (34 percent off) LEGO Harry Potter Mandrake Figure & Pot Plant Toy 76433 for $49 (30 percent off) This article originally appeared on Engadget at https://www.engadget.com/deals/lego-black-friday-deals-on-star-wars-and-disney-sets-are-up-to-37-percent-off-ahead-of-the-big-sale-155007410.html?src=rss",
          "feed_position": 21
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/dyson-black-friday-deals-on-cordless-and-robot-vacuums-already-get-you-up-to-500-off-173533407.html",
          "published_at": "Thu, 13 Nov 2025 17:05:38 +0000",
          "title": "Dyson Black Friday deals on cordless and robot vacuums already get you up to $500 off",
          "standfirst": "Early Black Friday deals are starting to pop up across the web, and a great one to check out is at Dyson. While we still think you have the best shot to get the steepest discounts the closer to Black Friday we get, some of the discounts on Dyson's site right now are some of the best we've seen. One of those is 50 percent off the Dyson 360 Vis Nav robot vacuum, which is down to $500. Dyson was pretty late to the robot-vacuum party, but its entry was (and remains) one of the strongest in the category. It doesn't have a lot of bells and whistles like a self-emptying base or mopping capabilities, but it makes up for that by having probably the best suction power of any robovac we've tested. All kinds of debris will fall in its path: dirt, dust, food crumbs, pet hair and more. It also has excellent obstacle avoidance, so you'll rarely — if ever — have to dislodge it from getting stuck on the edge of a carpet or wedged in between furniture. Dyson's mobile app is easy to use as well, so if you're looking for a robot vacuum that does its main job incredibly well and you don't mind skipping on some extras, the 360 Vis Nav is a great option. Cordless vacuums are also a part of the sale. Take the Dyson V9 Motorbar cordless vacuum on sale for just $270 at both Dyson and Amazon, which is a discount of $330. That's more than half off. Dyson devices are all over our list of the best cordless vacuums, and for good reason. The company makes effective products. The V9 Motorbar has been designed to clean all floor types, in addition to upholstery. It's also been engineered to squeeze into tight spots, which is great for hitting those oft-neglected parts of the home. The suction power is on point and the battery lasts for 40 minutes before requiring a charge. That's just enough time to vacuum a standard-sized home if you don't stop for too many breaks. The V9 is getting a bit long-in-the-tooth. If you want a newer model, the V11 Extra is on sale for $400, which is a discount of $260. This one boosts the suction power and increases the battery life to 60 minutes. This article originally appeared on Engadget at https://www.engadget.com/deals/dyson-black-friday-deals-on-cordless-and-robot-vacuums-already-get-you-up-to-500-off-173533407.html?src=rss",
          "content": "Early Black Friday deals are starting to pop up across the web, and a great one to check out is at Dyson. While we still think you have the best shot to get the steepest discounts the closer to Black Friday we get, some of the discounts on Dyson's site right now are some of the best we've seen. One of those is 50 percent off the Dyson 360 Vis Nav robot vacuum, which is down to $500. Dyson was pretty late to the robot-vacuum party, but its entry was (and remains) one of the strongest in the category. It doesn't have a lot of bells and whistles like a self-emptying base or mopping capabilities, but it makes up for that by having probably the best suction power of any robovac we've tested. All kinds of debris will fall in its path: dirt, dust, food crumbs, pet hair and more. It also has excellent obstacle avoidance, so you'll rarely — if ever — have to dislodge it from getting stuck on the edge of a carpet or wedged in between furniture. Dyson's mobile app is easy to use as well, so if you're looking for a robot vacuum that does its main job incredibly well and you don't mind skipping on some extras, the 360 Vis Nav is a great option. Cordless vacuums are also a part of the sale. Take the Dyson V9 Motorbar cordless vacuum on sale for just $270 at both Dyson and Amazon, which is a discount of $330. That's more than half off. Dyson devices are all over our list of the best cordless vacuums, and for good reason. The company makes effective products. The V9 Motorbar has been designed to clean all floor types, in addition to upholstery. It's also been engineered to squeeze into tight spots, which is great for hitting those oft-neglected parts of the home. The suction power is on point and the battery lasts for 40 minutes before requiring a charge. That's just enough time to vacuum a standard-sized home if you don't stop for too many breaks. The V9 is getting a bit long-in-the-tooth. If you want a newer model, the V11 Extra is on sale for $400, which is a discount of $260. This one boosts the suction power and increases the battery life to 60 minutes. This article originally appeared on Engadget at https://www.engadget.com/deals/dyson-black-friday-deals-on-cordless-and-robot-vacuums-already-get-you-up-to-500-off-173533407.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/best-drone-120046775.html",
          "published_at": "Thu, 13 Nov 2025 17:00:36 +0000",
          "title": "The best drone for 2025",
          "standfirst": "Drones have evolved from hobbyist gadgets into everyday tools for creators and explorers. They’re smaller, easier to fly and packed with smart features that make aerial photography more accessible than ever. Whether you want to film sweeping landscapes or just learn to pilot your first quadcopter, there’s a drone built to match your needs.Beginner models now include GPS, collision sensors and automated flight modes that simplify controls. Move up a tier and you’ll find foldable designs that fit easily in a backpack while capturing stable 4K footage that rivals handheld cameras. For experienced flyers, the best camera drones combine larger sensors with precise stabilization and automated tracking for professional-quality results.We’ve tested drones across price ranges and categories to help you find one that fits how you want to fly, whether that means filming cinematic shots, traveling light or discovering a new perspective from above. Table of contents Best drones for 2025 What to look for in a drone Best drone FAQs Best drones for 2025 What to look for in a drone Camera features For this guide, we're looking only at drones that are basically flying cameras, so you want the best video and photo features possible. Bigger devices like DJI’s Mavic 3 Pro or Air 3S carry relatively large sensors, offering superior camera quality for nighttime cityscapes or other low-light scenes. Smaller models like the Mini 4 Pro and HoverAir X1 Max use smaller camera sensors, so they aren’t as good in dim light. Field of view and minimum aperture are also important, with most drones typically having a wide-angle focal length, though a few others like the HoverAir X1 Max carry an ultrawide lens. Some models have multiple cameras including a wide and a zoom. As for aperture, lower numbers are better and allow for shooting in dim light. Most DJI models are solid in this regard, while the HoverAir models don’t perform as well. Video resolution and slow-mo are also essential camera capabilities. Most drones these days can shoot at 4K with a frame rate of at least 30 fps, though some offer 6K or even 8K at up to 30 fps. Higher-end models can shoot 4K at up to 120 fps, allowing you to slow down the action dramatically to create a cinematic look. Other noteworthy features include log or HDR video that supports higher dynamic range, particularly in bright and sunny conditions. Finally, the camera’s gimbal and stabilization are important factors to keep your footage looking as smooth as possible. Some drones have gimbals that can rotate the camera 90 degrees to give social media creators the maximum resolution for vertical formats. Drone features: Speed, range, safety, battery life and obstacle detection By and large, there are two types of camera drones to consider. The first are standard drones (usually with open propellers but not always) designed to fly outside and take scenic shots. Often there’s nothing to stop the props from striking skin or objects, so they can’t really be used indoors or around people. Some models like the DJI Neo and Flip have prop guards that better protect bystanders and property, as well as the drone itself. Then there's first-person-view (FPV) camera drones, which often have propeller guards and are meant to be used both indoors or outside to capture exciting footage. Standard models don’t need to go particularly fast as they’re mainly used to shoot fun videos for social media, but FPV drones need to move at high speeds to create excitement. Because of that speed, they’re also better in breezy conditions thanks to stronger wind resistance, and they can fight gusts and return home more quickly. Acrobatic abilities (often promoted by the manufacturer in ads or packaging) are also important for FPV drones, as it allows the user to perform tricks and zip around obstacles. Battery life is another important factor. The best drones boast a battery endurance of up to 45 minutes, while FPV drones like the Avata 2 can only fly for about half that time as they tend to be heavier and carry smaller batteries to reduce weight. As a general rule, a single battery isn’t enough for any serious shooting so you’d do well to buy your drone in a kit with a few batteries and a charger. As for range, DJI tends to dominate in this area, with its latest models able to maintain a video signal at a distance up to 20km (12.4 miles). HoverAir’s models are weaker with the top-end X1 Max model limited to just 1km (0.6 miles) when using the optional beacon system. DJI also offers multiple ways to control its drones including headsets, joystick-type controllers, motion detection controllers and smartphones. The best drones have sensors to detect obstacles in all directions. Others are limited to only avoiding obstructions coming at them from the front and some only rely on the main camera to prevent crashes. Finally, if you want to have your drone follow you around automatically, you’ll need it to be able to track you around when you’re vlogging, riding a bike or skiing, while also avoiding obstacles. Smooth takeoff and return-to-home features are especially valuable here for both beginners and experienced drone pilots as well. Best drone FAQs What are the rules for owning a drone? Anyone can buy any drone, but once purchased, all drones between 250g and 25 kg must be registered with the FAA and marked with the FAA registration number. Recreational pilots with drones over 249g must pass the recreational UAS safety \"TRUST\" exam and carry proof of TRUST completion when flying a drone. Commercial pilots must obtain a Remote Pilot Certificate from the FAA. You must be aware of and avoid any areas with airspace restrictions, particularly around airports. Are drones safe to fly in the city? In general, it is not legal to fly a drone within city limits over populations, as a crash from a high altitude could injure or kill someone. However, they can be flown over adjacent, non-populated areas in many cases. Here is a guide to where: https://uavcoach.com/where-to-fly-drone/ What is the average flight time of a drone? Most drones can fly for around 20-30 minutes, though some advanced models like DJI's Mavic 4 can fly up to 40 minutes or more.This article originally appeared on Engadget at https://www.engadget.com/cameras/best-drone-120046775.html?src=rss",
          "content": "Drones have evolved from hobbyist gadgets into everyday tools for creators and explorers. They’re smaller, easier to fly and packed with smart features that make aerial photography more accessible than ever. Whether you want to film sweeping landscapes or just learn to pilot your first quadcopter, there’s a drone built to match your needs.Beginner models now include GPS, collision sensors and automated flight modes that simplify controls. Move up a tier and you’ll find foldable designs that fit easily in a backpack while capturing stable 4K footage that rivals handheld cameras. For experienced flyers, the best camera drones combine larger sensors with precise stabilization and automated tracking for professional-quality results.We’ve tested drones across price ranges and categories to help you find one that fits how you want to fly, whether that means filming cinematic shots, traveling light or discovering a new perspective from above. Table of contents Best drones for 2025 What to look for in a drone Best drone FAQs Best drones for 2025 What to look for in a drone Camera features For this guide, we're looking only at drones that are basically flying cameras, so you want the best video and photo features possible. Bigger devices like DJI’s Mavic 3 Pro or Air 3S carry relatively large sensors, offering superior camera quality for nighttime cityscapes or other low-light scenes. Smaller models like the Mini 4 Pro and HoverAir X1 Max use smaller camera sensors, so they aren’t as good in dim light. Field of view and minimum aperture are also important, with most drones typically having a wide-angle focal length, though a few others like the HoverAir X1 Max carry an ultrawide lens. Some models have multiple cameras including a wide and a zoom. As for aperture, lower numbers are better and allow for shooting in dim light. Most DJI models are solid in this regard, while the HoverAir models don’t perform as well. Video resolution and slow-mo are also essential camera capabilities. Most drones these days can shoot at 4K with a frame rate of at least 30 fps, though some offer 6K or even 8K at up to 30 fps. Higher-end models can shoot 4K at up to 120 fps, allowing you to slow down the action dramatically to create a cinematic look. Other noteworthy features include log or HDR video that supports higher dynamic range, particularly in bright and sunny conditions. Finally, the camera’s gimbal and stabilization are important factors to keep your footage looking as smooth as possible. Some drones have gimbals that can rotate the camera 90 degrees to give social media creators the maximum resolution for vertical formats. Drone features: Speed, range, safety, battery life and obstacle detection By and large, there are two types of camera drones to consider. The first are standard drones (usually with open propellers but not always) designed to fly outside and take scenic shots. Often there’s nothing to stop the props from striking skin or objects, so they can’t really be used indoors or around people. Some models like the DJI Neo and Flip have prop guards that better protect bystanders and property, as well as the drone itself. Then there's first-person-view (FPV) camera drones, which often have propeller guards and are meant to be used both indoors or outside to capture exciting footage. Standard models don’t need to go particularly fast as they’re mainly used to shoot fun videos for social media, but FPV drones need to move at high speeds to create excitement. Because of that speed, they’re also better in breezy conditions thanks to stronger wind resistance, and they can fight gusts and return home more quickly. Acrobatic abilities (often promoted by the manufacturer in ads or packaging) are also important for FPV drones, as it allows the user to perform tricks and zip around obstacles. Battery life is another important factor. The best drones boast a battery endurance of up to 45 minutes, while FPV drones like the Avata 2 can only fly for about half that time as they tend to be heavier and carry smaller batteries to reduce weight. As a general rule, a single battery isn’t enough for any serious shooting so you’d do well to buy your drone in a kit with a few batteries and a charger. As for range, DJI tends to dominate in this area, with its latest models able to maintain a video signal at a distance up to 20km (12.4 miles). HoverAir’s models are weaker with the top-end X1 Max model limited to just 1km (0.6 miles) when using the optional beacon system. DJI also offers multiple ways to control its drones including headsets, joystick-type controllers, motion detection controllers and smartphones. The best drones have sensors to detect obstacles in all directions. Others are limited to only avoiding obstructions coming at them from the front and some only rely on the main camera to prevent crashes. Finally, if you want to have your drone follow you around automatically, you’ll need it to be able to track you around when you’re vlogging, riding a bike or skiing, while also avoiding obstacles. Smooth takeoff and return-to-home features are especially valuable here for both beginners and experienced drone pilots as well. Best drone FAQs What are the rules for owning a drone? Anyone can buy any drone, but once purchased, all drones between 250g and 25 kg must be registered with the FAA and marked with the FAA registration number. Recreational pilots with drones over 249g must pass the recreational UAS safety \"TRUST\" exam and carry proof of TRUST completion when flying a drone. Commercial pilots must obtain a Remote Pilot Certificate from the FAA. You must be aware of and avoid any areas with airspace restrictions, particularly around airports. Are drones safe to fly in the city? In general, it is not legal to fly a drone within city limits over populations, as a crash from a high altitude could injure or kill someone. However, they can be flown over adjacent, non-populated areas in many cases. Here is a guide to where: https://uavcoach.com/where-to-fly-drone/ What is the average flight time of a drone? Most drones can fly for around 20-30 minutes, though some advanced models like DJI's Mavic 4 can fly up to 40 minutes or more.This article originally appeared on Engadget at https://www.engadget.com/cameras/best-drone-120046775.html?src=rss",
          "feed_position": 24
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/valves-trio-of-hardware-announcements-revived-my-half-life-3-fever-dream-170000561.html",
          "published_at": "Thu, 13 Nov 2025 17:00:00 +0000",
          "title": "Valve's trio of hardware announcements revived my Half-Life 3 fever dream",
          "standfirst": "Yesterday, Valve announced three (3) hardware products: a Steam Machine console, an accompanying Steam Controller and the long-rumored Steam Frame VR headset. This hardware, along with the excellent Steam Deck, gives Valve a pretty comprehensive way to get people playing games wherever they want, on any sort of screen. And, of course, the games are what this is all about. Steam’s catalog is impossibly vast, encompassing every genre you can imagine — but there’s still one crucial title missing from the thousands of games available.I am, of course, talking about Half-Life 3.I swore back in 2017 that I’d stop beating this dead horse, but Valve sucked me back in with the utterly unexpected, excellent, VR-only Half-Life: Alyx prequel. At the very least, it was a sign that the Half-Life universe wasn’t dead and buried in Valve’s mind, despite the fact that it had lain dormant with an unresolved cliffhanger for more than a dozen years.At the time, Valve indicated it was interested in moving forward with more games in the series, though I wouldn’t have been surprised if the company just dropped things again. But, a big push into hardware that is significantly more powerful than the Steam Deck feels like another perfect opportunity to make Half-Life 3 happen.And there have actually been a few more concrete bread crumbs to follow over the last year or so indicating Valve might finally be returning to the Half-Life story. It started with the 20th anniversary of Half-Life 2, when Valve dropped a major update for the game. “Every map in Half-Life 2 has been looked over by Valve level designers to fix longstanding bugs, restore content and features lost to time, and improve the quality of a few things like lightmap resolution and fog,” the developer wrote. Along with some developer commentary, a documentary and the inclusion of the two episodic follow-up games, this was a pretty substantial update for such an old game.At the end of last year, YouTuber Gabe Follower dropped some details on a potential Half-Life 3 coming soon. Follower had previously called the release of Counter-Strike 2, lending some credibility to his findings. To make a long story short, Follower claimed a Valve project internally titled “HLX” had reached the play-testing stage. That didn’t necessarily mean a launch was imminent, but at the very least the game was advancing in development.Another less consequential but fun tidbit dropped around the same time: actor Michael Shapiro (who voiced the infamous G-Man in the Half-Life series) posted a New Years’ message where he spoke in the G-Man’s strange accent and said he’d see viewers in the year to come. Not coincidentally, he also did this in 2020 prior to the Half-Life: Alyx launch. The game had already been announced when he posted that message, but it’s still an intriguing tease. The timing couldn’t be better, either. The Game Awards are less than a month away, and that extravaganza is about the biggest platform you could ask for if you’re announcing a big new title. Not that Valve really needs the stage — they could just drop a trailer on YouTube and the gaming world would take care of the rest.But as a companion piece to the company’s renewed hardware ambitions? The synergy would be too good to pass up. After all, the Valve Index VR headset launched just a short time before Half-Life: Alyx was announced, and anyone who had purchased it got the game for free. A theoretical Half-Life 3 isn’t quite the same, as there’s no chance the game will require the official Steam Machine. But it would still make a heck of a launch title to help drive interest in the company’s new devices. As for me, I’m not letting myself get too excited here. I remember in 2013, when Valve introduced the first Steam Machines initiative and its first attempt at a controller, I assumed it would be a perfect time to announce Half-Life 3. That clearly did not happen. But I’d be lying if I said I wasn’t a little bit hopeful this time around. There’s enough smoke to make me think that the fire is real; it’s hopefully time to wake up and smell the ashes. This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/valves-trio-of-hardware-announcements-revived-my-half-life-3-fever-dream-170000561.html?src=rss",
          "content": "Yesterday, Valve announced three (3) hardware products: a Steam Machine console, an accompanying Steam Controller and the long-rumored Steam Frame VR headset. This hardware, along with the excellent Steam Deck, gives Valve a pretty comprehensive way to get people playing games wherever they want, on any sort of screen. And, of course, the games are what this is all about. Steam’s catalog is impossibly vast, encompassing every genre you can imagine — but there’s still one crucial title missing from the thousands of games available.I am, of course, talking about Half-Life 3.I swore back in 2017 that I’d stop beating this dead horse, but Valve sucked me back in with the utterly unexpected, excellent, VR-only Half-Life: Alyx prequel. At the very least, it was a sign that the Half-Life universe wasn’t dead and buried in Valve’s mind, despite the fact that it had lain dormant with an unresolved cliffhanger for more than a dozen years.At the time, Valve indicated it was interested in moving forward with more games in the series, though I wouldn’t have been surprised if the company just dropped things again. But, a big push into hardware that is significantly more powerful than the Steam Deck feels like another perfect opportunity to make Half-Life 3 happen.And there have actually been a few more concrete bread crumbs to follow over the last year or so indicating Valve might finally be returning to the Half-Life story. It started with the 20th anniversary of Half-Life 2, when Valve dropped a major update for the game. “Every map in Half-Life 2 has been looked over by Valve level designers to fix longstanding bugs, restore content and features lost to time, and improve the quality of a few things like lightmap resolution and fog,” the developer wrote. Along with some developer commentary, a documentary and the inclusion of the two episodic follow-up games, this was a pretty substantial update for such an old game.At the end of last year, YouTuber Gabe Follower dropped some details on a potential Half-Life 3 coming soon. Follower had previously called the release of Counter-Strike 2, lending some credibility to his findings. To make a long story short, Follower claimed a Valve project internally titled “HLX” had reached the play-testing stage. That didn’t necessarily mean a launch was imminent, but at the very least the game was advancing in development.Another less consequential but fun tidbit dropped around the same time: actor Michael Shapiro (who voiced the infamous G-Man in the Half-Life series) posted a New Years’ message where he spoke in the G-Man’s strange accent and said he’d see viewers in the year to come. Not coincidentally, he also did this in 2020 prior to the Half-Life: Alyx launch. The game had already been announced when he posted that message, but it’s still an intriguing tease. The timing couldn’t be better, either. The Game Awards are less than a month away, and that extravaganza is about the biggest platform you could ask for if you’re announcing a big new title. Not that Valve really needs the stage — they could just drop a trailer on YouTube and the gaming world would take care of the rest.But as a companion piece to the company’s renewed hardware ambitions? The synergy would be too good to pass up. After all, the Valve Index VR headset launched just a short time before Half-Life: Alyx was announced, and anyone who had purchased it got the game for free. A theoretical Half-Life 3 isn’t quite the same, as there’s no chance the game will require the official Steam Machine. But it would still make a heck of a launch title to help drive interest in the company’s new devices. As for me, I’m not letting myself get too excited here. I remember in 2013, when Valve introduced the first Steam Machines initiative and its first attempt at a controller, I assumed it would be a perfect time to announce Half-Life 3. That clearly did not happen. But I’d be lying if I said I wasn’t a little bit hopeful this time around. There’s enough smoke to make me think that the fire is real; it’s hopefully time to wake up and smell the ashes. This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/valves-trio-of-hardware-announcements-revived-my-half-life-3-fever-dream-170000561.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/black-friday-deals-for-2025-have-arrived-the-best-tech-sales-from-amazon-apple-lego-anker-and-others-so-far-100052657.html",
          "published_at": "Thu, 13 Nov 2025 16:36:23 +0000",
          "title": "Black Friday deals for 2025 have arrived: The best tech sales from Amazon, Apple, Lego, Anker and others so far",
          "standfirst": "Black Friday has become the time to buy the hottest tech of the year. Whether you're shopping for yourself or stocking up on gifts for the holidays, Black Friday deals are sure to bring the best prices of the year to things like headphones, game consoles, robot vacuums, phone accessories and everything in between. You don't even have to wait until Black Friday proper to save a ton of money. Over the past few years, we've seen Black Friday tech deals start earlier and earlier — to the point where the entire month of November is packed with discounts.If you're on the hunt for solid tech deals, Engadget has you covered. We've collected the best Black Friday deals on tech you can get right now, and we'll continue to update this post as we get closer to the big day at the end of November. Note that you probably have the best chance of snagging record-low prices when we get to about one week before Thanksgiving, but these deals available now are worth considering. Black Friday deals to shop now Apple AirTags (four pack) for $65 (34 percent off): iPhone users who frequently misplace things should invest in a few AirTags. Slip them into your wallet, bag, jacket and other belongings to keep track of their locations in the Find My app. Just make sure that, if you're going to attach one to your keys, you also pick up an AirTag holder to go along with it. Amazon Fire TV Stick 4K Max for $35 (42 percent off): One of our favorite streaming devices, the 4K Max dongle supports Dolby Vision, Dolby Atmos, 4K and HDR10+ and it has Wi-Fi 6E for a speedier, more stable internet connection. It also supports the Fire TV Ambient Experience, which can display art on your TV when you're not actively using it. Ninja Dual-Zone air fryer (10-quart) for $180 (22 percent off): If you cook for large crowds on Thanksgiving and other occasions, this is the air fryer to get. Not only is it a large, 10-quart capacity model, but it also has two separate cooking areas. You can crisp up potatoes on one side and brussel sprouts on the other with no issues. Use the Smart Finish feature to cook two separate foods in different ways and have them both be done at the same time, or Match Cook to copy the cooking method in both chambers. LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable 75375 for $68 (20 percent off): This is a set that any Star Wars fan will love to build and then love to display once it's complete. The 921-piece set features a fully-detailed Millennium Falcone, buildable stand and nameplate. It's one of many Lego Black Friday deals you can get right now. Nintendo Switch 2 + Mario Kart World bundle for $499: Black Friday Nintendo sales were announced recently and, unsurprisingly, there won't be many true deals out there this year. There are no straight discounts on the Switch 2 console, so your best bet is to pick up a bundle that saves you some cash on a Switch 2 game. One of the best is the Mario Kart Wold bundle, but Pokémon fans should consider the Pokémon Legends: Z-A bundle, too. Apple MacBook Air (13-inch, M4) for $749 ($250 off): Our top pick for the best laptop you can get, the M4 MacBook Air will be plenty of power for most people in a convenient, premium package. It's thin and light as ever, with an excellent keyboard and trackpad, plus enough battery life to get you through a whole day of work, video calls and more. Apple Watch SE 3 for $200 ($50 off): The SE has been our top pick for the best Apple Watch for those on a budget, and the latest model only solidifies that further. It has the same chipset found in the latest flagship Apple Watches, fast-charging capabilities, an always-on display and most of the same activity-tracking features you'll find in more expensive model. Apple Mac Mini M4 for $499 ($100 off): Desktop users looking for an upgrade should consider the latest Mac Mini, which runs on the M4 chip and 16GB of RAM as standard in the base configuration. This version has a smaller design that takes up less space, front-facing USB-C ports and a headphone jack, plus Thunderbolt 5 support. Jisulife Life 7 handheld fan for $25 (14 percent off): This handy little fan is a must-have if you life in a warm climate or have a tropical vacation planned anytime soon. It can be used as a table or handheld fan and even be worn around the neck so you don't have to hold it at all. Its 5,000 mAh battery allows it to last hours on a single charge, and the small display in the middle of the fan's blades show its remaining battery level. Leebin 2025 electric spin scrubber for $40 (43 percent off, Prime exclusive): This weird little scrubber makes cleaning my bathroom and shower much less of a pain. Just choose the brush head you need for your job and the rotating head takes care of most of the hard work. I love the adjustable handle, which extends from 12 to 50 inches so you can get into hard-to-reach places without breaking a sweat. Monarch Money budgeting app (one year) for $50 (50 percent off with code MONARCHVIP): One of our favorite budgeting apps, Monarch Money gives you a lot of control over the organization of your funds. There's a helpful goals feature for when you're planning out big purchases or financial milestones you want to hit, and we found the month-in-review recap it provides to be more thorough than other budgeting apps we tried. There's even Zillow integration for folks looking to buy a home. SanDisk microSD Express card (256GB) for $60 (12 percent off): If you have a Switch 2, no regular microSD card will do if you want to expand the console's storage. You need a newer microSD Express card, and currently there are only a handful on the market. We did some testing to find the best microSD Express card for the Switch 2 and found that performance was, in general, very similar amongst all the readily available cards. We recommend getting whichever fits within your budget at the capacity you want. Google TV Streamer 4K for $75 ($25 off): Our top pick for the best streaming device right now, the latest version of Google's streamer supports 4K video and an excellent, easy-to-use interface that will feel familiar to anyone who's seen a set with the Google TV technology built in. It provides access to all of the major streaming services including Netflix, Disney+, HBO Max, YouTube and more, plus it has a handy on-screen pop up that lets you control all compatible smart home devices right from your TV. Also available at Walmart. Dyson 360 Vis Nav robot vacuum for $400 ($600 off): This is one of the best robot vacuums you can get, period. It doesn't have a self-emptying base, but its superior suction power almost makes up for that. It's one of the strongest robot vacuums I've ever tested, and it has excellent obstacle avoidance. The latter means you will rarely, if ever, have to attend to it getting caught on the edge of a carpet or getting stuck under a piece of furniture. If a cordless stick vacuum is what you're looking for, don't forget to check out all of the other Dyson Black Friday deals. EcoFlow Black Friday deals — get up to 80 percent off: Portable power stations are an investment, but they can be crucial pieces of tech during emergencies. The top pick from our friends at Yahoo Tech has been heavily discounted in this early Black Friday sale. You can pick up the EcoFlow Delta Pro 3 for $1,400 off, down to $2,299, or the power station with an extra battery bundled in for $2,699 off, down to $3,599. Black Friday FAQs When is Black Friday 2025? Black Friday 2025 lands on November 28. Which stores have Black Friday deals? Many physical retail stores have Black Friday deals including Walmart, Target, Best Buy and others. Even more retailers have online Black Friday deals, including Amazon, GameStop, Costco and others. When do Black Friday sales start? Gone are the times when Black Friday sales were one-day-only affairs. Now, Black Friday deals are often available starting on Thanksgiving, or even earlier. Last year, we saw Black Friday deals online begin the week before Black Friday proper. When do Black Friday sales end? Black Friday and Cyber Monday have blended a lot over the past few years. Now, you can expect to see a good portion of Black Friday deals extend through the weekend and into Cyber Monday. It's not uncommon for Black Friday deals to expire at the end of Cyber Monday. Which retailers have the best Black Friday tech deals? The best Black Friday tech deals are typically available online at retailers like Amazon, Walmart, Best Buy and Target. It's also a good idea to check the store websites of the companies that make the products you want — for example, if you're looking for a Sonos speaker, check the Sonos website on Black Friday. Most of the time, you'll find the best Black Friday tech deals are matched at multiple retailers. Does Apple have Black Friday sales? No, you will usually not find Black Friday sales at Apple stores or on Apple's website. However, you can find Black Friday deals on Apple devices elsewhere; we recommend checking Amazon, Best Buy and other big retailers for discounts on iPads, Apple Watches and more on Black Friday. Does Amazon have Black Friday sales? Yes, Amazon has Black Friday sales. The online retailer's site will look similar to Prime Day on Black Friday, with discounts on all sorts of items from household essentials to fashion to tech.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-deals-for-2025-have-arrived-the-best-tech-sales-from-amazon-apple-lego-anker-and-others-so-far-100052657.html?src=rss",
          "content": "Black Friday has become the time to buy the hottest tech of the year. Whether you're shopping for yourself or stocking up on gifts for the holidays, Black Friday deals are sure to bring the best prices of the year to things like headphones, game consoles, robot vacuums, phone accessories and everything in between. You don't even have to wait until Black Friday proper to save a ton of money. Over the past few years, we've seen Black Friday tech deals start earlier and earlier — to the point where the entire month of November is packed with discounts.If you're on the hunt for solid tech deals, Engadget has you covered. We've collected the best Black Friday deals on tech you can get right now, and we'll continue to update this post as we get closer to the big day at the end of November. Note that you probably have the best chance of snagging record-low prices when we get to about one week before Thanksgiving, but these deals available now are worth considering. Black Friday deals to shop now Apple AirTags (four pack) for $65 (34 percent off): iPhone users who frequently misplace things should invest in a few AirTags. Slip them into your wallet, bag, jacket and other belongings to keep track of their locations in the Find My app. Just make sure that, if you're going to attach one to your keys, you also pick up an AirTag holder to go along with it. Amazon Fire TV Stick 4K Max for $35 (42 percent off): One of our favorite streaming devices, the 4K Max dongle supports Dolby Vision, Dolby Atmos, 4K and HDR10+ and it has Wi-Fi 6E for a speedier, more stable internet connection. It also supports the Fire TV Ambient Experience, which can display art on your TV when you're not actively using it. Ninja Dual-Zone air fryer (10-quart) for $180 (22 percent off): If you cook for large crowds on Thanksgiving and other occasions, this is the air fryer to get. Not only is it a large, 10-quart capacity model, but it also has two separate cooking areas. You can crisp up potatoes on one side and brussel sprouts on the other with no issues. Use the Smart Finish feature to cook two separate foods in different ways and have them both be done at the same time, or Match Cook to copy the cooking method in both chambers. LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable 75375 for $68 (20 percent off): This is a set that any Star Wars fan will love to build and then love to display once it's complete. The 921-piece set features a fully-detailed Millennium Falcone, buildable stand and nameplate. It's one of many Lego Black Friday deals you can get right now. Nintendo Switch 2 + Mario Kart World bundle for $499: Black Friday Nintendo sales were announced recently and, unsurprisingly, there won't be many true deals out there this year. There are no straight discounts on the Switch 2 console, so your best bet is to pick up a bundle that saves you some cash on a Switch 2 game. One of the best is the Mario Kart Wold bundle, but Pokémon fans should consider the Pokémon Legends: Z-A bundle, too. Apple MacBook Air (13-inch, M4) for $749 ($250 off): Our top pick for the best laptop you can get, the M4 MacBook Air will be plenty of power for most people in a convenient, premium package. It's thin and light as ever, with an excellent keyboard and trackpad, plus enough battery life to get you through a whole day of work, video calls and more. Apple Watch SE 3 for $200 ($50 off): The SE has been our top pick for the best Apple Watch for those on a budget, and the latest model only solidifies that further. It has the same chipset found in the latest flagship Apple Watches, fast-charging capabilities, an always-on display and most of the same activity-tracking features you'll find in more expensive model. Apple Mac Mini M4 for $499 ($100 off): Desktop users looking for an upgrade should consider the latest Mac Mini, which runs on the M4 chip and 16GB of RAM as standard in the base configuration. This version has a smaller design that takes up less space, front-facing USB-C ports and a headphone jack, plus Thunderbolt 5 support. Jisulife Life 7 handheld fan for $25 (14 percent off): This handy little fan is a must-have if you life in a warm climate or have a tropical vacation planned anytime soon. It can be used as a table or handheld fan and even be worn around the neck so you don't have to hold it at all. Its 5,000 mAh battery allows it to last hours on a single charge, and the small display in the middle of the fan's blades show its remaining battery level. Leebin 2025 electric spin scrubber for $40 (43 percent off, Prime exclusive): This weird little scrubber makes cleaning my bathroom and shower much less of a pain. Just choose the brush head you need for your job and the rotating head takes care of most of the hard work. I love the adjustable handle, which extends from 12 to 50 inches so you can get into hard-to-reach places without breaking a sweat. Monarch Money budgeting app (one year) for $50 (50 percent off with code MONARCHVIP): One of our favorite budgeting apps, Monarch Money gives you a lot of control over the organization of your funds. There's a helpful goals feature for when you're planning out big purchases or financial milestones you want to hit, and we found the month-in-review recap it provides to be more thorough than other budgeting apps we tried. There's even Zillow integration for folks looking to buy a home. SanDisk microSD Express card (256GB) for $60 (12 percent off): If you have a Switch 2, no regular microSD card will do if you want to expand the console's storage. You need a newer microSD Express card, and currently there are only a handful on the market. We did some testing to find the best microSD Express card for the Switch 2 and found that performance was, in general, very similar amongst all the readily available cards. We recommend getting whichever fits within your budget at the capacity you want. Google TV Streamer 4K for $75 ($25 off): Our top pick for the best streaming device right now, the latest version of Google's streamer supports 4K video and an excellent, easy-to-use interface that will feel familiar to anyone who's seen a set with the Google TV technology built in. It provides access to all of the major streaming services including Netflix, Disney+, HBO Max, YouTube and more, plus it has a handy on-screen pop up that lets you control all compatible smart home devices right from your TV. Also available at Walmart. Dyson 360 Vis Nav robot vacuum for $400 ($600 off): This is one of the best robot vacuums you can get, period. It doesn't have a self-emptying base, but its superior suction power almost makes up for that. It's one of the strongest robot vacuums I've ever tested, and it has excellent obstacle avoidance. The latter means you will rarely, if ever, have to attend to it getting caught on the edge of a carpet or getting stuck under a piece of furniture. If a cordless stick vacuum is what you're looking for, don't forget to check out all of the other Dyson Black Friday deals. EcoFlow Black Friday deals — get up to 80 percent off: Portable power stations are an investment, but they can be crucial pieces of tech during emergencies. The top pick from our friends at Yahoo Tech has been heavily discounted in this early Black Friday sale. You can pick up the EcoFlow Delta Pro 3 for $1,400 off, down to $2,299, or the power station with an extra battery bundled in for $2,699 off, down to $3,599. Black Friday FAQs When is Black Friday 2025? Black Friday 2025 lands on November 28. Which stores have Black Friday deals? Many physical retail stores have Black Friday deals including Walmart, Target, Best Buy and others. Even more retailers have online Black Friday deals, including Amazon, GameStop, Costco and others. When do Black Friday sales start? Gone are the times when Black Friday sales were one-day-only affairs. Now, Black Friday deals are often available starting on Thanksgiving, or even earlier. Last year, we saw Black Friday deals online begin the week before Black Friday proper. When do Black Friday sales end? Black Friday and Cyber Monday have blended a lot over the past few years. Now, you can expect to see a good portion of Black Friday deals extend through the weekend and into Cyber Monday. It's not uncommon for Black Friday deals to expire at the end of Cyber Monday. Which retailers have the best Black Friday tech deals? The best Black Friday tech deals are typically available online at retailers like Amazon, Walmart, Best Buy and Target. It's also a good idea to check the store websites of the companies that make the products you want — for example, if you're looking for a Sonos speaker, check the Sonos website on Black Friday. Most of the time, you'll find the best Black Friday tech deals are matched at multiple retailers. Does Apple have Black Friday sales? No, you will usually not find Black Friday sales at Apple stores or on Apple's website. However, you can find Black Friday deals on Apple devices elsewhere; we recommend checking Amazon, Best Buy and other big retailers for discounts on iPads, Apple Watches and more on Black Friday. Does Amazon have Black Friday sales? Yes, Amazon has Black Friday sales. The online retailer's site will look similar to Prime Day on Black Friday, with discounts on all sorts of items from household essentials to fashion to tech.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-deals-for-2025-have-arrived-the-best-tech-sales-from-amazon-apple-lego-anker-and-others-so-far-100052657.html?src=rss",
          "feed_position": 28
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/nintendo-announces-its-black-friday-and-cyber-monday-2025-sale-switch-2-bundles-switch-game-deals-accessories-and-more-155223057.html",
          "published_at": "Thu, 13 Nov 2025 16:33:24 +0000",
          "title": "Nintendo announces its Black Friday and Cyber Monday 2025 sale: Switch 2 bundles, Switch game deals, accessories and more",
          "standfirst": "When it comes to holiday video game gifts, Nintendo gear is often at the top of the list for kids and adults like. This year likely more so than ever thanks to the launch of the Switch 2 back in the spring. But fi you were hoping to save money on the console with Black Friday deals, you may be disappointed. The Nintendo Black Friday sale was just announced, and unsurprisingly, there are a scant few real \"deals\" to be had. This is typical of Nintendo, though — actual Nintendo Black Friday deals are few and far between. However, there are ways to at least get the best value for your money if you're going to pick up a Switch 2 before this year is over. As has been the case for many years, the marquee Nintendo deals for the holidays come in the form of console bundles. When the Switch 2 launched earlier this year, it was available as just the console only for $449 or bundled with Mario Kart World for $499. Both options are still available now, but there's a new bundle to consider as well — the console with the new Pokémon Legends: Z-A game, which also costs $499. Considering the games by themselves cost $70 each, you do save a bit by picking up a console bundle. you can pick up the console and its bundles at most retailers including Amazon, Walmart, Best Buy and others. When it comes to deals on Nintendo Switch 2 games, the Nintendo eShop will have Cyber Deals starting on November 20, running through December 3. The shop will feature \"holiday offers on select games,\" so it appears we'll all just have to go to the online store on November 20 to see the games on offer. Starting on November 23, select retailers will have discounts on some physical Switch games including Princess Peach: Showtime!, The Legend of Zelda: Echoes of Wisdom, Luigi’s Mansion 3 and Kirby’s Return to Dream Land Deluxe. Those will each be $40, while other games like Super Mario Odyssey, Nintendo Switch Sports, Paper Mario: The Thousand-Year Door and Splatoon 3 will be $30. Even if you can't get huge discounts on Nintendo consoles or new games this year, that doesn't mean you can't find decent deals on other Nintendo gear. There are plenty of great ideas for gifts for the Nintendo fan in your life, and Engadget's Sam Rutherford got to see a bunch of them in person when he attended Nintendo's holiday showcase. From collectibles to clothing to plushies and holiday decor, there's really a ton to choose from — but you may want to pace yourself if you're also a Nintendo fan finding things that you want to pick up for yourself in the process of looking for good gifts. Here are just some of the best Nintendo gift ideas that you can look out for during Black Friday and Cyber Monday. This article originally appeared on Engadget at https://www.engadget.com/deals/nintendo-announces-its-black-friday-and-cyber-monday-2025-sale-switch-2-bundles-switch-game-deals-accessories-and-more-155223057.html?src=rss",
          "content": "When it comes to holiday video game gifts, Nintendo gear is often at the top of the list for kids and adults like. This year likely more so than ever thanks to the launch of the Switch 2 back in the spring. But fi you were hoping to save money on the console with Black Friday deals, you may be disappointed. The Nintendo Black Friday sale was just announced, and unsurprisingly, there are a scant few real \"deals\" to be had. This is typical of Nintendo, though — actual Nintendo Black Friday deals are few and far between. However, there are ways to at least get the best value for your money if you're going to pick up a Switch 2 before this year is over. As has been the case for many years, the marquee Nintendo deals for the holidays come in the form of console bundles. When the Switch 2 launched earlier this year, it was available as just the console only for $449 or bundled with Mario Kart World for $499. Both options are still available now, but there's a new bundle to consider as well — the console with the new Pokémon Legends: Z-A game, which also costs $499. Considering the games by themselves cost $70 each, you do save a bit by picking up a console bundle. you can pick up the console and its bundles at most retailers including Amazon, Walmart, Best Buy and others. When it comes to deals on Nintendo Switch 2 games, the Nintendo eShop will have Cyber Deals starting on November 20, running through December 3. The shop will feature \"holiday offers on select games,\" so it appears we'll all just have to go to the online store on November 20 to see the games on offer. Starting on November 23, select retailers will have discounts on some physical Switch games including Princess Peach: Showtime!, The Legend of Zelda: Echoes of Wisdom, Luigi’s Mansion 3 and Kirby’s Return to Dream Land Deluxe. Those will each be $40, while other games like Super Mario Odyssey, Nintendo Switch Sports, Paper Mario: The Thousand-Year Door and Splatoon 3 will be $30. Even if you can't get huge discounts on Nintendo consoles or new games this year, that doesn't mean you can't find decent deals on other Nintendo gear. There are plenty of great ideas for gifts for the Nintendo fan in your life, and Engadget's Sam Rutherford got to see a bunch of them in person when he attended Nintendo's holiday showcase. From collectibles to clothing to plushies and holiday decor, there's really a ton to choose from — but you may want to pace yourself if you're also a Nintendo fan finding things that you want to pick up for yourself in the process of looking for good gifts. Here are just some of the best Nintendo gift ideas that you can look out for during Black Friday and Cyber Monday. This article originally appeared on Engadget at https://www.engadget.com/deals/nintendo-announces-its-black-friday-and-cyber-monday-2025-sale-switch-2-bundles-switch-game-deals-accessories-and-more-155223057.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/dbrands-companion-cube-is-the-perfect-partner-for-your-future-steam-machine-161634417.html",
          "published_at": "Thu, 13 Nov 2025 16:16:35 +0000",
          "title": "Dbrand’s Companion Cube is the perfect partner for your future Steam Machine",
          "standfirst": "Valve’s second attempt at a console-like gaming PC for your living room is hopefully going to be a triumph worthy of plenty of cake, with or without fun accessories. But if you really want to make the Steam Machine feel extra special when it arrives in early 2026, you’re going to want to dress it up in Dbrand’s Companion Cube skin. A tribute to the iconic Weighted Companion Cube from Valve’s beloved Portal series, it’s such a fitting design that I sort of wonder if the company is kicking itself for not making something similar for its cube-shaped compact PC. Of course, putting your Steam Machine inside this will ensure it stands out from the other consoles occupying your TV unit, which is the opposite effect that the standard design is going to have. While it does have a customizable front plate and an LED light strip, the default all-black colorway could hardly be less attention-grabbing. In case you missed yesterday's announcement, the Steam Machine is a Linux-based mini PC that runs SteamOS and is designed to be plugged into your TV, like a console. Valve says it’s roughly six times more powerful than a Steam Deck and is capable of supporting 4K/60fps gaming with FSR. You can also use it to stream VR games to the new Stream Frame headset, while the Steam Controller, with its distinctive trackpads, allows you to play your Steam games wirelessly. Given that we don’t yet have a release date or price for the Steam Machine, Dbrand’s accessory doesn't have either of those yet either, but it is coming in 2026. And I’m fairly confident that isn’t a lie…This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/dbrands-companion-cube-is-the-perfect-partner-for-your-future-steam-machine-161634417.html?src=rss",
          "content": "Valve’s second attempt at a console-like gaming PC for your living room is hopefully going to be a triumph worthy of plenty of cake, with or without fun accessories. But if you really want to make the Steam Machine feel extra special when it arrives in early 2026, you’re going to want to dress it up in Dbrand’s Companion Cube skin. A tribute to the iconic Weighted Companion Cube from Valve’s beloved Portal series, it’s such a fitting design that I sort of wonder if the company is kicking itself for not making something similar for its cube-shaped compact PC. Of course, putting your Steam Machine inside this will ensure it stands out from the other consoles occupying your TV unit, which is the opposite effect that the standard design is going to have. While it does have a customizable front plate and an LED light strip, the default all-black colorway could hardly be less attention-grabbing. In case you missed yesterday's announcement, the Steam Machine is a Linux-based mini PC that runs SteamOS and is designed to be plugged into your TV, like a console. Valve says it’s roughly six times more powerful than a Steam Deck and is capable of supporting 4K/60fps gaming with FSR. You can also use it to stream VR games to the new Stream Frame headset, while the Steam Controller, with its distinctive trackpads, allows you to play your Steam games wirelessly. Given that we don’t yet have a release date or price for the Steam Machine, Dbrand’s accessory doesn't have either of those yet either, but it is coming in 2026. And I’m fairly confident that isn’t a lie…This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/dbrands-companion-cube-is-the-perfect-partner-for-your-future-steam-machine-161634417.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/inside-linkedins-generative-ai-cookbook-how-it-scaled-people-search-to-1-3",
          "published_at": "Thu, 13 Nov 2025 16:00:00 GMT",
          "title": "Inside LinkedIn’s generative AI cookbook: How it scaled people search to 1.3 billion users",
          "standfirst": "LinkedIn is launching its new AI-powered people search this week, after what seems like a very long wait for what should have been a natural offering for generative AI.It comes a full three years after the launch of ChatGPT and six months after LinkedIn launched its AI job search offering. For technical leaders, this timeline illustrates a key enterprise lesson: Deploying generative AI in real enterprise settings is challenging, especially at a scale of 1.3 billion users. It’s a slow, brutal process of pragmatic optimization.The following account is based on several exclusive interviews with the LinkedIn product and engineering team behind the launch.First, here’s how the product works: A user can now type a natural language query like, \"Who is knowledgeable about curing cancer?\" into LinkedIn’s search bar.LinkedIn&#x27;s old search, based on keywords, would have been stumped. It would have looked only for references to \"cancer\". If a user wanted to get sophisticated, they would have had to run separate, rigid keyword searches for \"cancer\" and then \"oncology\" and manually try to piece the results together.The new AI-powered system, however, understands the intent of the search because the LLM under the hood grasps semantic meaning. It recognizes, for example, that \"cancer\" is conceptually related to \"oncology\" and even less directly, to \"genomics research.\" As a result, it surfaces a far more relevant list of people, including oncology leaders and researchers, even if their profiles don&#x27;t use the exact word \"cancer.\"The system also balances this relevance with usefulness. Instead of just showing the world&#x27;s top oncologist (who might be an unreachable third-degree connection), it will also weigh who in your immediate network — like a first-degree connection — is \"pretty relevant\" and can serve as a crucial bridge to that expert.See the video below for an example.Arguably, though, the more important lesson for enterprise practitioners is the \"cookbook\" LinkedIn has developed: a replicable, multi-stage pipeline of distillation, co-design, and relentless optimization. LinkedIn had to perfect this on one product before attempting it on another.\"Don&#x27;t try to do too much all at once,\" writes Wenjing Zhang, LinkedIn&#x27;s VP of Engineering, in a post about the product launch, and who also spoke with VentureBeat last week in an interview. She notes that an earlier \"sprawling ambition\" to build a unified system for all of LinkedIn&#x27;s products \"stalled progress.\"Instead, LinkedIn focused on winning one vertical first. The success of its previously launched AI Job Search — which led to job seekers without a four-year degree being 10% more likely to get hired, according to VP of Product Engineering Erran Berger — provided the blueprint.Now, the company is applying that blueprint to a far larger challenge. \"It&#x27;s one thing to be able to do this across tens of millions of jobs,\" Berger told VentureBeat. \"It&#x27;s another thing to do this across north of a billion members.\"For enterprise AI builders, LinkedIn&#x27;s journey provides a technical playbook for what it actually takes to move from a successful pilot to a billion-user-scale product.The new challenge: a 1.3 billion-member graphThe job search product created a robust recipe that the new people search product could build upon, Berger explained. The recipe started with with a \"golden data set\" of just a few hundred to a thousand real query-profile pairs, meticulously scored against a detailed 20- to 30-page \"product policy\" document. To scale this for training, LinkedIn used this small golden set to prompt a large foundation model to generate a massive volume of synthetic training data. This synthetic data was used to train a 7-billion-parameter \"Product Policy\" model — a high-fidelity judge of relevance that was too slow for live production but perfect for teaching smaller models.However, the team hit a wall early on. For six to nine months, they struggled to train a single model that could balance strict policy adherence (relevance) against user engagement signals. The \"aha moment\" came when they realized they needed to break the problem down. They distilled the 7B policy model into a 1.7B teacher model focused solely on relevance. They then paired it with separate teacher models trained to predict specific member actions, such as job applications for the jobs product, or connecting and following for people search. This \"multi-teacher\" ensemble produced soft probability scores that the final student model learned to mimic via KL divergence loss.The resulting architecture operates as a two-stage pipeline. First, a larger 8B parameter model handles broad retrieval, casting a wide net to pull candidates from the graph. Then, the highly distilled student model takes over for fine-grained ranking. While the job search product successfully deployed a 0.6B (600-million) parameter student, the new people search product required even more aggressive compression. As Zhang notes, the team pruned their new student model from 440M down to just 220M parameters, achieving the necessary speed for 1.3 billion users with less than 1% relevance loss.But applying this to people search broke the old architecture. The new problem included not just ranking but also retrieval.“A billion records,\" Berger said, is a \"different beast.\"The team’s prior retrieval stack was built on CPUs. To handle the new scale and the latency demands of a \"snappy\" search experience, the team had to move its indexing to GPU-based infrastructure. This was a foundational architectural shift that the job search product did not require.Organizationally, LinkedIn benefited from multiple approaches. For a time, LinkedIn had two separate teams — job search and people search — attempting to solve the problem in parallel. But once the job search team achieved its breakthrough using the policy-driven distillation method, Berger and his leadership team intervened. They brought over the architects of the job search win — product lead Rohan Rajiv and engineering lead Wenjing Zhang — to transplant their &#x27;cookbook&#x27; directly to the new domain.Distilling for a 10x throughput gainWith the retrieval problem solved, the team faced the ranking and efficiency challenge. This is where the cookbook was adapted with new, aggressive optimization techniques.Zhang’s technical post (I’ll insert the link once it goes live) provides the specific details our audience of AI engineers will appreciate. One of the more significant optimizations was input size.To feed the model, the team trained another LLM with reinforcement learning (RL) for a single purpose: to summarize the input context. This \"summarizer\" model was able to reduce the model&#x27;s input size by 20-fold with minimal information loss.The combined result of the 220M-parameter model and the 20x input reduction? A 10x increase in ranking throughput, allowing the team to serve the model efficiently to its massive user base.Pragmatism over hype: building tools, not agentsThroughout our discussions, Berger was adamant about something else that might catch peoples’ attention: The real value for enterprises today lies in perfecting recommender systems, not in chasing \"agentic hype.\" He also refused to talk about the specific models that the company used for the searches, suggesting it almost doesn&#x27;t matter. The company selects models based on which one it finds the most efficient for the task.The new AI-powered people search is a manifestation of Berger’s philosophy that it’s best to optimize the recommender system first. The architecture includes a new \"intelligent query routing layer,\" as Berger explained, that itself is LLM-powered. This router pragmatically decides if a user&#x27;s query — like \"trust expert\" — should go to the new semantic, natural-language stack or to the old, reliable lexical search.This entire, complex system is designed to be a \"tool\" that a future agent will use, not the agent itself.\"Agentic products are only as good as the tools that they use to accomplish tasks for people,\" Berger said. \"You can have the world&#x27;s best reasoning model, and if you&#x27;re trying to use an agent to do people search but the people search engine is not very good, you&#x27;re not going to be able to deliver.\" Now that the people search is available, Berger suggested that one day the company will be offering agents to use it. But he didn’t provide details on timing. He also said the recipe used for job and people search will be spread across the company’s other products.For enterprises building their own AI roadmaps, LinkedIn&#x27;s playbook is clear:Be pragmatic: Don&#x27;t try to boil the ocean. Win one vertical, even if it takes 18 months.Codify the \"cookbook\": Turn that win into a repeatable process (policy docs, distillation pipelines, co-design).Optimize relentlessly: The real 10x gains come after the initial model, in pruning, distillation, and creative optimizations like an RL-trained summarizer.LinkedIn&#x27;s journey shows that for real-world enterprise AI, emphasis on specific models or cool agentic systems should take a back seat. The durable, strategic advantage comes from mastering the pipeline — the &#x27;AI-native&#x27; cookbook of co-design, distillation, and ruthless optimization.(Editor&#x27;s note: We will be publishing a full-length podcast with LinkedIn&#x27;s Erran Berger, which will dive deeper into these technical details, on the VentureBeat podcast feed soon.)",
          "content": "LinkedIn is launching its new AI-powered people search this week, after what seems like a very long wait for what should have been a natural offering for generative AI.It comes a full three years after the launch of ChatGPT and six months after LinkedIn launched its AI job search offering. For technical leaders, this timeline illustrates a key enterprise lesson: Deploying generative AI in real enterprise settings is challenging, especially at a scale of 1.3 billion users. It’s a slow, brutal process of pragmatic optimization.The following account is based on several exclusive interviews with the LinkedIn product and engineering team behind the launch.First, here’s how the product works: A user can now type a natural language query like, \"Who is knowledgeable about curing cancer?\" into LinkedIn’s search bar.LinkedIn&#x27;s old search, based on keywords, would have been stumped. It would have looked only for references to \"cancer\". If a user wanted to get sophisticated, they would have had to run separate, rigid keyword searches for \"cancer\" and then \"oncology\" and manually try to piece the results together.The new AI-powered system, however, understands the intent of the search because the LLM under the hood grasps semantic meaning. It recognizes, for example, that \"cancer\" is conceptually related to \"oncology\" and even less directly, to \"genomics research.\" As a result, it surfaces a far more relevant list of people, including oncology leaders and researchers, even if their profiles don&#x27;t use the exact word \"cancer.\"The system also balances this relevance with usefulness. Instead of just showing the world&#x27;s top oncologist (who might be an unreachable third-degree connection), it will also weigh who in your immediate network — like a first-degree connection — is \"pretty relevant\" and can serve as a crucial bridge to that expert.See the video below for an example.Arguably, though, the more important lesson for enterprise practitioners is the \"cookbook\" LinkedIn has developed: a replicable, multi-stage pipeline of distillation, co-design, and relentless optimization. LinkedIn had to perfect this on one product before attempting it on another.\"Don&#x27;t try to do too much all at once,\" writes Wenjing Zhang, LinkedIn&#x27;s VP of Engineering, in a post about the product launch, and who also spoke with VentureBeat last week in an interview. She notes that an earlier \"sprawling ambition\" to build a unified system for all of LinkedIn&#x27;s products \"stalled progress.\"Instead, LinkedIn focused on winning one vertical first. The success of its previously launched AI Job Search — which led to job seekers without a four-year degree being 10% more likely to get hired, according to VP of Product Engineering Erran Berger — provided the blueprint.Now, the company is applying that blueprint to a far larger challenge. \"It&#x27;s one thing to be able to do this across tens of millions of jobs,\" Berger told VentureBeat. \"It&#x27;s another thing to do this across north of a billion members.\"For enterprise AI builders, LinkedIn&#x27;s journey provides a technical playbook for what it actually takes to move from a successful pilot to a billion-user-scale product.The new challenge: a 1.3 billion-member graphThe job search product created a robust recipe that the new people search product could build upon, Berger explained. The recipe started with with a \"golden data set\" of just a few hundred to a thousand real query-profile pairs, meticulously scored against a detailed 20- to 30-page \"product policy\" document. To scale this for training, LinkedIn used this small golden set to prompt a large foundation model to generate a massive volume of synthetic training data. This synthetic data was used to train a 7-billion-parameter \"Product Policy\" model — a high-fidelity judge of relevance that was too slow for live production but perfect for teaching smaller models.However, the team hit a wall early on. For six to nine months, they struggled to train a single model that could balance strict policy adherence (relevance) against user engagement signals. The \"aha moment\" came when they realized they needed to break the problem down. They distilled the 7B policy model into a 1.7B teacher model focused solely on relevance. They then paired it with separate teacher models trained to predict specific member actions, such as job applications for the jobs product, or connecting and following for people search. This \"multi-teacher\" ensemble produced soft probability scores that the final student model learned to mimic via KL divergence loss.The resulting architecture operates as a two-stage pipeline. First, a larger 8B parameter model handles broad retrieval, casting a wide net to pull candidates from the graph. Then, the highly distilled student model takes over for fine-grained ranking. While the job search product successfully deployed a 0.6B (600-million) parameter student, the new people search product required even more aggressive compression. As Zhang notes, the team pruned their new student model from 440M down to just 220M parameters, achieving the necessary speed for 1.3 billion users with less than 1% relevance loss.But applying this to people search broke the old architecture. The new problem included not just ranking but also retrieval.“A billion records,\" Berger said, is a \"different beast.\"The team’s prior retrieval stack was built on CPUs. To handle the new scale and the latency demands of a \"snappy\" search experience, the team had to move its indexing to GPU-based infrastructure. This was a foundational architectural shift that the job search product did not require.Organizationally, LinkedIn benefited from multiple approaches. For a time, LinkedIn had two separate teams — job search and people search — attempting to solve the problem in parallel. But once the job search team achieved its breakthrough using the policy-driven distillation method, Berger and his leadership team intervened. They brought over the architects of the job search win — product lead Rohan Rajiv and engineering lead Wenjing Zhang — to transplant their &#x27;cookbook&#x27; directly to the new domain.Distilling for a 10x throughput gainWith the retrieval problem solved, the team faced the ranking and efficiency challenge. This is where the cookbook was adapted with new, aggressive optimization techniques.Zhang’s technical post (I’ll insert the link once it goes live) provides the specific details our audience of AI engineers will appreciate. One of the more significant optimizations was input size.To feed the model, the team trained another LLM with reinforcement learning (RL) for a single purpose: to summarize the input context. This \"summarizer\" model was able to reduce the model&#x27;s input size by 20-fold with minimal information loss.The combined result of the 220M-parameter model and the 20x input reduction? A 10x increase in ranking throughput, allowing the team to serve the model efficiently to its massive user base.Pragmatism over hype: building tools, not agentsThroughout our discussions, Berger was adamant about something else that might catch peoples’ attention: The real value for enterprises today lies in perfecting recommender systems, not in chasing \"agentic hype.\" He also refused to talk about the specific models that the company used for the searches, suggesting it almost doesn&#x27;t matter. The company selects models based on which one it finds the most efficient for the task.The new AI-powered people search is a manifestation of Berger’s philosophy that it’s best to optimize the recommender system first. The architecture includes a new \"intelligent query routing layer,\" as Berger explained, that itself is LLM-powered. This router pragmatically decides if a user&#x27;s query — like \"trust expert\" — should go to the new semantic, natural-language stack or to the old, reliable lexical search.This entire, complex system is designed to be a \"tool\" that a future agent will use, not the agent itself.\"Agentic products are only as good as the tools that they use to accomplish tasks for people,\" Berger said. \"You can have the world&#x27;s best reasoning model, and if you&#x27;re trying to use an agent to do people search but the people search engine is not very good, you&#x27;re not going to be able to deliver.\" Now that the people search is available, Berger suggested that one day the company will be offering agents to use it. But he didn’t provide details on timing. He also said the recipe used for job and people search will be spread across the company’s other products.For enterprises building their own AI roadmaps, LinkedIn&#x27;s playbook is clear:Be pragmatic: Don&#x27;t try to boil the ocean. Win one vertical, even if it takes 18 months.Codify the \"cookbook\": Turn that win into a repeatable process (policy docs, distillation pipelines, co-design).Optimize relentlessly: The real 10x gains come after the initial model, in pruning, distillation, and creative optimizations like an RL-trained summarizer.LinkedIn&#x27;s journey shows that for real-world enterprise AI, emphasis on specific models or cool agentic systems should take a back seat. The durable, strategic advantage comes from mastering the pipeline — the &#x27;AI-native&#x27; cookbook of co-design, distillation, and ruthless optimization.(Editor&#x27;s note: We will be publishing a full-length podcast with LinkedIn&#x27;s Erran Berger, which will dive deeper into these technical details, on the VentureBeat podcast feed soon.)",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/lgGMZPiCCaW1DNedEGAbm/a05d0e3b39eea0fae4e58895fad8d198/Screenshot_2025-11-12_at_4.53.46%C3%A2__PM.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/playstation/sonys-latest-horizon-spin-off-is-an-mmorpg-for-pc-and-mobile-but-not-ps5-153532860.html",
          "published_at": "Thu, 13 Nov 2025 15:35:32 +0000",
          "title": "Sony’s latest Horizon spin-off is an MMORPG for PC and mobile, but not PS5",
          "standfirst": "An MMO based on Sony's Horizon series is on the way. However, Horizon Steel Frontiers is not coming to PS5, at least not initially. It's a mobile-first game that's also coming to PC, in another example of Sony Interactive Entertainment expanding beyond its core PlayStation console business.NCSoft, the MMO developer and publisher behind the likes of the Guild Wars series and Throne and Liberty, is taking the lead on Horizon Steel Frontiers. It's working on the game alongside original Horizon developer Guerrilla Games and Sony.Horizon Steel Frontiers is said to build on the fun robot dinosaur hunting action of Horizon Zero Dawn and Horizon Forbidden West with greater player freedom, \"deeply customizable combat\" and other advanced MMORPG systems. You'll be able to undertake \"large-scale raids\" with other players. You'll likely end up competing with other players for resources too.You'll create your own character, who belongs to a tribe of your choosing. Just like in the main games, status effects are a key component of combat. You'll also be able to grapple onto giant machines, chip parts of them off and use weapons that robot enemies drop against them. In a neat touch, you can carry these weapons on your mount and use them in your next fight. Horizon Steel Frontiers has Tallnecks too, so I'm happy about that.The action is set in a region called the Deadlands, which is inspired by New Mexico and Arizona, and you'll share this part of the Horizon world with \"thousands of other players,\" according to Guerrilla studio director Jan-Bart Van Beek. As with the series' core games, the story here concerns finding a balance between humanity, technology and nature.Guerrilla said back in 2022 that it was working on more “epic solo adventures for Aloy” (the protagonist of the mainline entries) and it's said to be making its own Horizon multiplayer game. This MMO isn't the first Horizon spin-off either. Lego Horizon Adventures, from Guerilla Games and Studio Gobo, arrived a year ago. Co-op is a key aspect of that game, so that's a multiplayer title too.Handing development of Horizon Steel Frontiers to a studio with vast experience in the MMO genre is a smart move on Sony's part. The company pivoted a few years back to focus heavily on live-service games, but that strategy hasn't panned out so well. Sure, Helldivers 2 has been a major hit, but Concord was an utter disaster. An attempt to make a multiplayer game in the world of The Last of Us didn't work out. Sony's acquisition of Bungie hasn't gone as smoothly as expected either. The company said this week it wrote down the value of Bungie's assets by $204 million amid Destiny 2's struggles, putting even more pressure on the upcoming Marathon to succeed.Sony and NCSoft have not yet revealed a release date for Horizon Steel Frontiers. In any case, Horizon is one of Sony's most popular franchises and it should make for strong fodder for an MMO. The action in the gameplay trailer looks as slick as you'd expect from this series and taking down robot dinos with friends in Monster Hunter-style action could be a lot of fun. It's probably a good thing that you're not playing as Aloy here, given how annoyingly reluctant she is to accept help from would-be allies in her own games.This article originally appeared on Engadget at https://www.engadget.com/gaming/playstation/sonys-latest-horizon-spin-off-is-an-mmorpg-for-pc-and-mobile-but-not-ps5-153532860.html?src=rss",
          "content": "An MMO based on Sony's Horizon series is on the way. However, Horizon Steel Frontiers is not coming to PS5, at least not initially. It's a mobile-first game that's also coming to PC, in another example of Sony Interactive Entertainment expanding beyond its core PlayStation console business.NCSoft, the MMO developer and publisher behind the likes of the Guild Wars series and Throne and Liberty, is taking the lead on Horizon Steel Frontiers. It's working on the game alongside original Horizon developer Guerrilla Games and Sony.Horizon Steel Frontiers is said to build on the fun robot dinosaur hunting action of Horizon Zero Dawn and Horizon Forbidden West with greater player freedom, \"deeply customizable combat\" and other advanced MMORPG systems. You'll be able to undertake \"large-scale raids\" with other players. You'll likely end up competing with other players for resources too.You'll create your own character, who belongs to a tribe of your choosing. Just like in the main games, status effects are a key component of combat. You'll also be able to grapple onto giant machines, chip parts of them off and use weapons that robot enemies drop against them. In a neat touch, you can carry these weapons on your mount and use them in your next fight. Horizon Steel Frontiers has Tallnecks too, so I'm happy about that.The action is set in a region called the Deadlands, which is inspired by New Mexico and Arizona, and you'll share this part of the Horizon world with \"thousands of other players,\" according to Guerrilla studio director Jan-Bart Van Beek. As with the series' core games, the story here concerns finding a balance between humanity, technology and nature.Guerrilla said back in 2022 that it was working on more “epic solo adventures for Aloy” (the protagonist of the mainline entries) and it's said to be making its own Horizon multiplayer game. This MMO isn't the first Horizon spin-off either. Lego Horizon Adventures, from Guerilla Games and Studio Gobo, arrived a year ago. Co-op is a key aspect of that game, so that's a multiplayer title too.Handing development of Horizon Steel Frontiers to a studio with vast experience in the MMO genre is a smart move on Sony's part. The company pivoted a few years back to focus heavily on live-service games, but that strategy hasn't panned out so well. Sure, Helldivers 2 has been a major hit, but Concord was an utter disaster. An attempt to make a multiplayer game in the world of The Last of Us didn't work out. Sony's acquisition of Bungie hasn't gone as smoothly as expected either. The company said this week it wrote down the value of Bungie's assets by $204 million amid Destiny 2's struggles, putting even more pressure on the upcoming Marathon to succeed.Sony and NCSoft have not yet revealed a release date for Horizon Steel Frontiers. In any case, Horizon is one of Sony's most popular franchises and it should make for strong fodder for an MMO. The action in the gameplay trailer looks as slick as you'd expect from this series and taking down robot dinos with friends in Monster Hunter-style action could be a lot of fun. It's probably a good thing that you're not playing as Aloy here, given how annoyingly reluctant she is to accept help from would-be allies in her own games.This article originally appeared on Engadget at https://www.engadget.com/gaming/playstation/sonys-latest-horizon-spin-off-is-an-mmorpg-for-pc-and-mobile-but-not-ps5-153532860.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/valve-confirms-that-it-has-stopped-making-the-index-vr-headset-150324456.html",
          "published_at": "Thu, 13 Nov 2025 15:03:24 +0000",
          "title": "Valve confirms that it has stopped making the Index VR headset",
          "standfirst": "In case you missed it, Valve announced a load of new hardware this week, including a second stab at the Steam Machine, a Steam controller, and a long-rumored new VR headset called the Steam Frame. But in with the new often means out with the old, and perhaps inevitably, the company has confirmed that its previous headset, the Valve Index, is no more. Valve’s Lawrence Yang told The Verge that it’s \"no longer manufacturing\" the Index, which we called \"the best desktop VR yet\" when it launched in 2019. The Index arrived around the same time as the Oculus Quest and its promise of an affordable all-in-one future for VR. By contrast, the Valve Index was very much still a high-end tethered device for the hardcore enthusiasts, with a price tag that reflected that. We don’t know how much the Steam Frame will cost yet, but it definitely sounds like Valve is making a play for the more casual VR crowd here too, as well as those who want to play demanding 3D titles. You can stream flatscreen and VR games from your PC or Steam Machine using a wireless adapter, but the Steam Frame is also a standalone device like the Meta Quest 3, backed by a built-in Snapdragon 8 Gen 3 chipset and 16GB of RAM. Valve is supporting Android games too, seemingly a move to entice VR developers to bring their Quest games over to Steam. In order to track your movements in virtual space, the Valve Index relied on external lighthouse base stations, which meant you had to go through a more than a little laborious setup process to play roomscale VR games. Consumer VR has moved towards built-in sensors since then, and it sounds like Valve wants to leave its lighthouses in the past too, with the company confirming to The Verge that they won’t be supported on the Steam Frame. The new headset instead has four high-res monochrome cameras for inside-out tracking, as well as infrared LEDs on the outside that help with tracking in darker environments.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/valve-confirms-that-it-has-stopped-making-the-index-vr-headset-150324456.html?src=rss",
          "content": "In case you missed it, Valve announced a load of new hardware this week, including a second stab at the Steam Machine, a Steam controller, and a long-rumored new VR headset called the Steam Frame. But in with the new often means out with the old, and perhaps inevitably, the company has confirmed that its previous headset, the Valve Index, is no more. Valve’s Lawrence Yang told The Verge that it’s \"no longer manufacturing\" the Index, which we called \"the best desktop VR yet\" when it launched in 2019. The Index arrived around the same time as the Oculus Quest and its promise of an affordable all-in-one future for VR. By contrast, the Valve Index was very much still a high-end tethered device for the hardcore enthusiasts, with a price tag that reflected that. We don’t know how much the Steam Frame will cost yet, but it definitely sounds like Valve is making a play for the more casual VR crowd here too, as well as those who want to play demanding 3D titles. You can stream flatscreen and VR games from your PC or Steam Machine using a wireless adapter, but the Steam Frame is also a standalone device like the Meta Quest 3, backed by a built-in Snapdragon 8 Gen 3 chipset and 16GB of RAM. Valve is supporting Android games too, seemingly a move to entice VR developers to bring their Quest games over to Steam. In order to track your movements in virtual space, the Valve Index relied on external lighthouse base stations, which meant you had to go through a more than a little laborious setup process to play roomscale VR games. Consumer VR has moved towards built-in sensors since then, and it sounds like Valve wants to leave its lighthouses in the past too, with the company confirming to The Verge that they won’t be supported on the Steam Frame. The new headset instead has four high-res monochrome cameras for inside-out tracking, as well as infrared LEDs on the outside that help with tracking in darker environments.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/valve-confirms-that-it-has-stopped-making-the-index-vr-headset-150324456.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/sandisks-switch-2-compatible-microsd-express-card-is-cheaper-than-ever-ahead-of-black-friday-151331109.html",
          "published_at": "Thu, 13 Nov 2025 15:01:25 +0000",
          "title": "SanDisk's Switch 2-compatible microSD Express card is cheaper than ever ahead of Black Friday",
          "standfirst": "If you already picked up a Switch 2, you're probably looking for deals that can help you kit out your new console without spending too much money. While maybe not the most exciting thing, a microSD Express card will be a key component for long-term gaming bliss. SanDisk's 256GB microSD Express Card for the Switch 2 is on sale for the first time ahead of Black Friday, down to $60 right now. This model is also available in storage sizes of 128GB and 512GB, but at the moment, only the 256GB model has a discount. This particular model easily made our list of the best microSD cards for the Nintendo Switch 2. It even made our list of the best Switch 2 accessories. It just gets the job done. We loved the speed on offer here. It was the fastest of all the cards we tested when transferring games and loading games. We also found that it performed admirably at just about every test we threw at it. The card was always consistently right near the top, thanks to outstanding sequential read and write performance. This was backed up by benchmark testing with PC tools like CrystalDiskMark. The Switch 2 only works with SD Express cards, so this covers that. Luckily, this card isn't just for Nintendo's latest console. It'll work with just about everything, if you ever find it outstays its usefulness as a storage container for Mario and friends. Elsewhere when it comes to microSD Express cards on sale: PNY's 128GB card is down to $40. This article originally appeared on Engadget at https://www.engadget.com/deals/sandisks-switch-2-compatible-microsd-express-card-is-cheaper-than-ever-ahead-of-black-friday-151331109.html?src=rss",
          "content": "If you already picked up a Switch 2, you're probably looking for deals that can help you kit out your new console without spending too much money. While maybe not the most exciting thing, a microSD Express card will be a key component for long-term gaming bliss. SanDisk's 256GB microSD Express Card for the Switch 2 is on sale for the first time ahead of Black Friday, down to $60 right now. This model is also available in storage sizes of 128GB and 512GB, but at the moment, only the 256GB model has a discount. This particular model easily made our list of the best microSD cards for the Nintendo Switch 2. It even made our list of the best Switch 2 accessories. It just gets the job done. We loved the speed on offer here. It was the fastest of all the cards we tested when transferring games and loading games. We also found that it performed admirably at just about every test we threw at it. The card was always consistently right near the top, thanks to outstanding sequential read and write performance. This was backed up by benchmark testing with PC tools like CrystalDiskMark. The Switch 2 only works with SD Express cards, so this covers that. Luckily, this card isn't just for Nintendo's latest console. It'll work with just about everything, if you ever find it outstays its usefulness as a storage container for Mario and friends. Elsewhere when it comes to microSD Express cards on sale: PNY's 128GB card is down to $40. This article originally appeared on Engadget at https://www.engadget.com/deals/sandisks-switch-2-compatible-microsd-express-card-is-cheaper-than-ever-ahead-of-black-friday-151331109.html?src=rss",
          "feed_position": 34
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/8bitdos-ultimate-controller-is-on-sale-for-only-43-in-this-black-friday-deal-133023111.html",
          "published_at": "Thu, 13 Nov 2025 14:46:26 +0000",
          "title": "8Bitdo's Ultimate Controller is on sale for only $43 in this Black Friday deal",
          "standfirst": "Early Black Friday deals are starting to flood the internet. If you're starting to think about the gifts you have to pick up for everyone in your life, you may be able to save already on some of them — including tech. One of the standout deals we've found so far is on the 8Bitdo Ultimate Bluetooth Controller and Charging Dock. It's 39 percent off right now and down to $43 — a new record-low price. The controller comes with perks such as the charging dock, 22 hours of battery per charge and compatibility with everything from Steam Deck to Switch. The deal is only for the white model. Earlier this year, 8Bitdo released a new version of this $70 controller, aptly called the Ultimate 2 Bluetooth. We rated it as one of the best controllers for the Nintendo Switch 2. While the upgraded model brings you features like more precise and sensitive joysticks, this sale brings the original Ultimate Controller back into view — and our shopping carts. Plus, it also works well with the Nintendo Switch 2. This article originally appeared on Engadget at https://www.engadget.com/deals/8bitdos-ultimate-controller-is-on-sale-for-only-43-in-this-black-friday-deal-133023111.html?src=rss",
          "content": "Early Black Friday deals are starting to flood the internet. If you're starting to think about the gifts you have to pick up for everyone in your life, you may be able to save already on some of them — including tech. One of the standout deals we've found so far is on the 8Bitdo Ultimate Bluetooth Controller and Charging Dock. It's 39 percent off right now and down to $43 — a new record-low price. The controller comes with perks such as the charging dock, 22 hours of battery per charge and compatibility with everything from Steam Deck to Switch. The deal is only for the white model. Earlier this year, 8Bitdo released a new version of this $70 controller, aptly called the Ultimate 2 Bluetooth. We rated it as one of the best controllers for the Nintendo Switch 2. While the upgraded model brings you features like more precise and sensitive joysticks, this sale brings the original Ultimate Controller back into view — and our shopping carts. Plus, it also works well with the Nintendo Switch 2. This article originally appeared on Engadget at https://www.engadget.com/deals/8bitdos-ultimate-controller-is-on-sale-for-only-43-in-this-black-friday-deal-133023111.html?src=rss",
          "feed_position": 35
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/oneplus-15-review-a-great-phone-if-photography-isnt-a-priority-143000489.html",
          "published_at": "Thu, 13 Nov 2025 14:30:00 +0000",
          "title": "OnePlus 15 review: A great phone, if photography isn't a priority",
          "standfirst": "If you’re reading this review, there’s a chance you’ve come to it with some confusion. Didn’t OnePlus already release a new flagship phone this year, and wasn’t it called the OnePlus 13? The answer is yes to both those questions. So, what gives? Well, over the last few years, OnePlus has been working to shorten the gap between when its phones debut in China and when they’re available in the rest of the world. This year, the OnePlus 15 arrives in North America just a few short weeks after its initial October 27 release. And like it did with the jump between the OP3 and OP5, OnePlus is skipping the OP14 because of the number four and its unlucky association in Chinese culture.With that cleared up, you might think the OnePlus 15 suffers from following too soon after its predecessor. I’m happy to report it offers some clear upgrades over the OP13, including a faster processor and an absurdly big battery. What it doesn’t do, however, is change the OnePlus formula — for better and worse.Pricing and availabilityDue to the federal government shutdown, the OnePlus 15 does not have a US release date yet. The company had hoped to begin selling the phone starting today, November 13, but the phone has yet to obtain the necessary clearance. \"As is the case with every smartphone manufacturer, the United States’ Federal Communications Commission certifies OnePlus devices before they are sold in the US. As a result of the government shutdown, device certifications have been delayed,\" Spenser Blank, OnePlus North America’s head of marketing and communications, told Engadget.\"Subsequently, US sales for the OnePlus 15 will be postponed until they have been secured. The OnePlus 15 has already finished all the required tests from the FCC’s recognized labs and the certification application has been formally submitted. We are hopeful that approvals can be generated quickly and as a result, we can bring the OnePlus 15 to our customers in the U.S. expeditiously.\" There's also some uncertainty around pricing. On release, OnePlus plans to offer two versions of the OnePlus 15. The base model, with 12GB of RAM and 256GB of storage, will cost $900. The company will also sell a 16GB/512GB variant that will cost $1,000. However, OnePlus warns the price of both models is \"subject to change due to current market conditions.\"Hardware and displayThe OnePlus 15 offers a big, vibrant AMOLED display. Igor Bonifacic for EngadgetThe OnePlus 15 is a great phone with a boring, derivative design. It borrows its visual identity from the OnePlus 13s and 13T, a pair of smaller, 6.32-inch phones OnePlus released in India and China this past spring. There’s no two ways about it, in making its new flagship look more like those devices, OnePlus has at the same time made it look more like last year’s iPhone 16 Pro.It’s a shame. The design of the OnePlus 13 was one of the things my co-worker Sam Rutherford praised that phone for, and it’s something I liked about it too. The 15 just looks generic, even if there are a few nice touches. For example, the sand storm color has a nice, ceramic-like feel to it. One other impressive aspect of the design is how thin OnePlus has managed to keep the 15 while adding a massive 7,300mAh battery. At 0.31 inches thick, the sand storm variant is only slightly fatter than the 0.29-inch thick Galaxy S25 FE I recently reviewed, which has a more modest 4,900mAh battery (the two other OP15 colorways, infinite black and ultra violet, are listed as slightly thicker at 0.32 inches).Now, if you’re a longtime OnePlus fan, I need to mention the 15 doesn’t have the signature Alert Slider found on the company’s previous phones. I know what you’re thinking, did OnePlus do away with a fan favorite feature to add an AI button? The answer is both yes and no. The first time you tap the Plus Key, OxygenOS will prompt you to make it a shortcut for one of eight functions. Naturally, the default option is to use the button in conjunction with the company’s newish Mind Space AI hub, but you also can bind other functions to the Plus Key, including the old Alert Slider functionality. Even if it’s another thing that’s derivative of the iPhone, I like the flexibility the Plus Key gives.Separately, OnePlus has gone with a different screen this time around. The OP15 offers a 6.78-inch AMOLED display with a 1,272 x 2,772 resolution. The new screen is both smaller and less dense than the one found on the OnePlus 13, which was 6.82 inches big and had a 1,440 x 3,168 resolution. It’s also faster, offering a 165Hz refresh rate in select games, up from 120Hz on the earlier model. OnePlus told me it went with the lower resolution display because there’s no OLED manufacturer making QHD panels that fast yet. I’ll have more to say about the display in the performance section, but for now I’ll say the OP15’s screen is one of the best parts of using the phone. It’s dense enough to make text and images look sharp, and with up to 1,800 nits of brightness available, it’s easy to see and use even in harsh sunlight.CamerasThe OnePlus 15's cameras are a half step behind the competition. Igor Bonifacic for EngadgetOnePlus and Hasselblad ended their partnership in September, and the OP15 marks the debut of the company’s new DetailMax imaging engine. I’ll get to the software in a moment. First, OnePlus has once again gone with a main camera system built around three 50-megapixel sensors. What’s different this time around are the lenses. Two of them are slightly slower than their counterparts on the OnePlus 13. The main camera now has an f/1.8 aperture lens, down from the f/1.6 glass found on last year’s model. At the same time, OnePlus has gone with an f/2.8 lens for the telephoto camera. For comparison, the OP13 had an f/2.6 lens for distant shots. The good news is both cameras still come with optical image stabilization (OIS).Broadly, the OP15 suffers from the same problem its predecessor did. Most photos look good — sometimes great even — but they don’t come out as nice as what you might snap with the latest phones from Apple, Google or Samsung. The difference is most noticeable in nighttime and low-light photos where the OP15 can sometimes struggle to eke out shadow detail. It will also completely miss a shot because it used too slow of a shutter speed. I sometimes saw similar results in daytime photos in situations where the company’s high dynamic range algorithm would get tripped up by harsh lighting. Specifically, the shots had overly lifted shadows and unnatural highlights, resulting in photos that look flat with poor contrast.I also wish the OP15 had a better telephoto camera. It’s not bad by any means, but after seeing what the Pixel 10 Pro can do with its 5x zoom, any phone with a 3x telephoto doesn’t feel special. The limitations of the OP15’s hardware is especially noticeable when you try to push the camera beyond its maximum optical zoom. OnePlus says the camera offers 7x lossless zoom, but in my testing, I found there was a subtle drop in picture quality above 6x. At 10x and beyond, there's very noticeable pixel smearing. There are two areas where the OP15’s cameras impress. Across both stills and video, it does a great job of measuring color temperature and ensuring images come out true to life. Even more impressive is the phone’s ability to capture a burst of photos at 10 fps, up from 6 fps on the OP13. If you’ve read one of my reviews before, you’ve probably noticed I enjoy photographing the cats in my neighborhood, and no phone has made that task as easy as the OP15.As it’s already wintery in Toronto, I wasn’t able to test the OP15 new underwater camera mode. But if you live in a warmer climate, the feature is designed to make it easier to snap photos in the water by temporarily turning the OP15’s physical buttons into camera controls. This is also as good as any time to mention that OnePlus has shored up the OP15’s waterproofing. The phone is now rated IP68 against water and dust, and carries IP69 and IP69K protection against pressurized water at up to 176 degrees Fahrenheit.Performance and battery lifeIn North America, the OP15's SUPERVOOC adapter can charge the phone at 80W. Igor Bonifacic for EngadgetThe OP15 is the first phone in North America to ship with the Snapdragon 8 Elite Gen 5, and as you can probably guess, it’s a performance powerhouse. In Geekbench’s processor suite, the OP15 put up a single-core score of 3,696 and a multi-core mark of 11,187. That puts it in select company with the iPhone Air and its A19 Pro chipset, which in our testing had a slight edge in single-core performance but didn’t perform nearly as well in the multi-core suite (likely due to thermal limitations). In real-world use, I tried my best to find a game or application that could trip up the OP15, but between its new Snapdragon chipset and the 16GB of RAM that came in my unit, the phone handled everything with ease.It’s hard to describe how smooth the OnePlus 15 feels relative to other phones I’ve used recently. Every swipe and scroll feels nearly instantaneous. I suspect that’s a byproduct of the OP15’s dedicated touch response chip, which samples the screen at 3,200Hz. Speaking of the display, that 165Hz refresh rate I mentioned at the top is more of a forward-looking feature right now. As things stand, there are only seven games that can render at 165 fps. One of those, PUBG, does so through frame interpolation. So unless you’re an avid Call of Duty Mobile or Clash of Clans player, you won’t notice that benefit of the OP15’s screen, yet. Things could change in time, especially as more OEMs bring 165Hz displays to their phones. For now, the OP15 is still a great gaming phone, but it has yet to live up to its true potential.As much performance as the OnePlus 15 offers, what’s more impressive is its 7,300mAh battery. It’s the result of a new technology the company calls Silicon NanoStack. It allowed OnePlus to make a denser battery and one it claims will age more gracefully over time, thanks to a design that retains more than 80 percent of its health after four years. Obviously, I haven’t had the OP15 long enough to test that claim, but what I can say is that it offers tremendous battery life out of the box. On our local video rundown test, it posted a time of 38 hours and 30 minutes, which is eight hours longer than the OnePlus 13, the previous record holder. The Aramid case is one of three cases OnePlus offers alongside the OP15. Igor Bonifacic for EngadgetJust as impressive is how quickly the OP15 can charge. With the included 80W SUPERVOOC adapter, the battery can go from dead to full in about 40 minutes. The one downside of how OnePlus has approached charging is that the phone doesn't support the Qi2 standard. It can wirelessly charge at 50W, but you'll need to buy the company's proprietary AIRVOOC magnetic puck.SoftwareTwo screenshots showing of the OnePlus Mind SpaceIgor Bonifacic for EngadgetWhen he reviewed the OnePlus 13 in February, Engadget’s Sam Rutherford praised OnePlus for its restrained AI approach. Unfortunately, no company appears immune to the technology’s pull at this point, and in the months since, OnePlus has begun integrating more AI features into OxygenOS. Thankfully, many of those are either easy to ignore or situationally useful.First, there’s Mind Space, which is functionally similar to Nothing’s Essential Space. You can either tap the Plus Key (if it’s configured for use with Mind Space) or swipe up on the touchscreen with three fingers to save a screenshot to the hub. From there, the OP15’s built-in LLM will summarize the image, and you can ask the model questions about it. It’s also possible to save voice memos to the hub, and OnePlus offers a few other AI tools there, including one for scanning documents. All of these work well, and like I said, if they’re not your thing, they’re easy to ignore.The OnePlus 15's volume rocker and power button are located on the right side of the phone. Igor Bonifacic for EngadgetIt’s been a few years since I’ve used OxygenOS, so it was a pleasant surprise to learn it remains one of the more attractive and tasteful Android skins on the market. A standout is some of the custom animations OnePlus has baked into the OS to accentuate the speed of the phone. I also find OnePlus has one of the best organized quick settings menus. There are just enough customization options there to make it feel powerful, but not enough to overwhelm.One area where OnePlus could do better is software support. The company has pledged to provide the OP15 with four years of software updates and six years of security patches. That’s worse than both Google and Samsung, which have committed to supporting their latest phones for seven years.Wrap-upThe OnePlus 15 sits on a set of icy concrete steps. Igor Bonifacic for EngadgetIn using the OnePlus 15, I was frequently reminded of the last OnePlus phone I reviewed, the OnePlus 7 Pro. At the time, it was the company’s most expensive device ever, coming in at the same $750 price as the iPhone XR and Galaxy S10e. The appeal of that phone was its speedy Snapdragon 855 processor and the fact it was one of the first smartphones with a 90Hz AMOLED screen. It was also the first OnePlus phone with a camera that was more than just serviceable.All these years later, the appeal of the OP15 feels similar. It’s a phone for those who value speed over everything else. The tricky thing about this phone is judging its value when its price could change tomorrow. As I mentioned earlier, in the US the OP15 will start at $900, with OnePlus warning pricing for both models could “change due to current market conditions.” At $1,000, the 16GB model is a compelling alternative to the Pixel 10 Pro XL, offering a newer processor, more storage and a significantly bigger battery.Here’s the thing: Google has already aggressively discounted the entire Pixel 10 lineup, and until Black Friday, you can get the Pro XL for $899 — $100 less than the 16GB OnePlus 15. For most people, I think that’s the play, given both the Pro and Pro XL have the better telephoto camera and Google has promised to support all of its latest phones for seven years. That said, if you’re okay with a worse camera overall, the OP15 has a lot going for it, and provided OnePlus can successfully navigate an uncertain tariff regime, it will end up not just one of the best phones of 2025 but much of 2026 too.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/oneplus-15-review-a-great-phone-if-photography-isnt-a-priority-143000489.html?src=rss",
          "content": "If you’re reading this review, there’s a chance you’ve come to it with some confusion. Didn’t OnePlus already release a new flagship phone this year, and wasn’t it called the OnePlus 13? The answer is yes to both those questions. So, what gives? Well, over the last few years, OnePlus has been working to shorten the gap between when its phones debut in China and when they’re available in the rest of the world. This year, the OnePlus 15 arrives in North America just a few short weeks after its initial October 27 release. And like it did with the jump between the OP3 and OP5, OnePlus is skipping the OP14 because of the number four and its unlucky association in Chinese culture.With that cleared up, you might think the OnePlus 15 suffers from following too soon after its predecessor. I’m happy to report it offers some clear upgrades over the OP13, including a faster processor and an absurdly big battery. What it doesn’t do, however, is change the OnePlus formula — for better and worse.Pricing and availabilityDue to the federal government shutdown, the OnePlus 15 does not have a US release date yet. The company had hoped to begin selling the phone starting today, November 13, but the phone has yet to obtain the necessary clearance. \"As is the case with every smartphone manufacturer, the United States’ Federal Communications Commission certifies OnePlus devices before they are sold in the US. As a result of the government shutdown, device certifications have been delayed,\" Spenser Blank, OnePlus North America’s head of marketing and communications, told Engadget.\"Subsequently, US sales for the OnePlus 15 will be postponed until they have been secured. The OnePlus 15 has already finished all the required tests from the FCC’s recognized labs and the certification application has been formally submitted. We are hopeful that approvals can be generated quickly and as a result, we can bring the OnePlus 15 to our customers in the U.S. expeditiously.\" There's also some uncertainty around pricing. On release, OnePlus plans to offer two versions of the OnePlus 15. The base model, with 12GB of RAM and 256GB of storage, will cost $900. The company will also sell a 16GB/512GB variant that will cost $1,000. However, OnePlus warns the price of both models is \"subject to change due to current market conditions.\"Hardware and displayThe OnePlus 15 offers a big, vibrant AMOLED display. Igor Bonifacic for EngadgetThe OnePlus 15 is a great phone with a boring, derivative design. It borrows its visual identity from the OnePlus 13s and 13T, a pair of smaller, 6.32-inch phones OnePlus released in India and China this past spring. There’s no two ways about it, in making its new flagship look more like those devices, OnePlus has at the same time made it look more like last year’s iPhone 16 Pro.It’s a shame. The design of the OnePlus 13 was one of the things my co-worker Sam Rutherford praised that phone for, and it’s something I liked about it too. The 15 just looks generic, even if there are a few nice touches. For example, the sand storm color has a nice, ceramic-like feel to it. One other impressive aspect of the design is how thin OnePlus has managed to keep the 15 while adding a massive 7,300mAh battery. At 0.31 inches thick, the sand storm variant is only slightly fatter than the 0.29-inch thick Galaxy S25 FE I recently reviewed, which has a more modest 4,900mAh battery (the two other OP15 colorways, infinite black and ultra violet, are listed as slightly thicker at 0.32 inches).Now, if you’re a longtime OnePlus fan, I need to mention the 15 doesn’t have the signature Alert Slider found on the company’s previous phones. I know what you’re thinking, did OnePlus do away with a fan favorite feature to add an AI button? The answer is both yes and no. The first time you tap the Plus Key, OxygenOS will prompt you to make it a shortcut for one of eight functions. Naturally, the default option is to use the button in conjunction with the company’s newish Mind Space AI hub, but you also can bind other functions to the Plus Key, including the old Alert Slider functionality. Even if it’s another thing that’s derivative of the iPhone, I like the flexibility the Plus Key gives.Separately, OnePlus has gone with a different screen this time around. The OP15 offers a 6.78-inch AMOLED display with a 1,272 x 2,772 resolution. The new screen is both smaller and less dense than the one found on the OnePlus 13, which was 6.82 inches big and had a 1,440 x 3,168 resolution. It’s also faster, offering a 165Hz refresh rate in select games, up from 120Hz on the earlier model. OnePlus told me it went with the lower resolution display because there’s no OLED manufacturer making QHD panels that fast yet. I’ll have more to say about the display in the performance section, but for now I’ll say the OP15’s screen is one of the best parts of using the phone. It’s dense enough to make text and images look sharp, and with up to 1,800 nits of brightness available, it’s easy to see and use even in harsh sunlight.CamerasThe OnePlus 15's cameras are a half step behind the competition. Igor Bonifacic for EngadgetOnePlus and Hasselblad ended their partnership in September, and the OP15 marks the debut of the company’s new DetailMax imaging engine. I’ll get to the software in a moment. First, OnePlus has once again gone with a main camera system built around three 50-megapixel sensors. What’s different this time around are the lenses. Two of them are slightly slower than their counterparts on the OnePlus 13. The main camera now has an f/1.8 aperture lens, down from the f/1.6 glass found on last year’s model. At the same time, OnePlus has gone with an f/2.8 lens for the telephoto camera. For comparison, the OP13 had an f/2.6 lens for distant shots. The good news is both cameras still come with optical image stabilization (OIS).Broadly, the OP15 suffers from the same problem its predecessor did. Most photos look good — sometimes great even — but they don’t come out as nice as what you might snap with the latest phones from Apple, Google or Samsung. The difference is most noticeable in nighttime and low-light photos where the OP15 can sometimes struggle to eke out shadow detail. It will also completely miss a shot because it used too slow of a shutter speed. I sometimes saw similar results in daytime photos in situations where the company’s high dynamic range algorithm would get tripped up by harsh lighting. Specifically, the shots had overly lifted shadows and unnatural highlights, resulting in photos that look flat with poor contrast.I also wish the OP15 had a better telephoto camera. It’s not bad by any means, but after seeing what the Pixel 10 Pro can do with its 5x zoom, any phone with a 3x telephoto doesn’t feel special. The limitations of the OP15’s hardware is especially noticeable when you try to push the camera beyond its maximum optical zoom. OnePlus says the camera offers 7x lossless zoom, but in my testing, I found there was a subtle drop in picture quality above 6x. At 10x and beyond, there's very noticeable pixel smearing. There are two areas where the OP15’s cameras impress. Across both stills and video, it does a great job of measuring color temperature and ensuring images come out true to life. Even more impressive is the phone’s ability to capture a burst of photos at 10 fps, up from 6 fps on the OP13. If you’ve read one of my reviews before, you’ve probably noticed I enjoy photographing the cats in my neighborhood, and no phone has made that task as easy as the OP15.As it’s already wintery in Toronto, I wasn’t able to test the OP15 new underwater camera mode. But if you live in a warmer climate, the feature is designed to make it easier to snap photos in the water by temporarily turning the OP15’s physical buttons into camera controls. This is also as good as any time to mention that OnePlus has shored up the OP15’s waterproofing. The phone is now rated IP68 against water and dust, and carries IP69 and IP69K protection against pressurized water at up to 176 degrees Fahrenheit.Performance and battery lifeIn North America, the OP15's SUPERVOOC adapter can charge the phone at 80W. Igor Bonifacic for EngadgetThe OP15 is the first phone in North America to ship with the Snapdragon 8 Elite Gen 5, and as you can probably guess, it’s a performance powerhouse. In Geekbench’s processor suite, the OP15 put up a single-core score of 3,696 and a multi-core mark of 11,187. That puts it in select company with the iPhone Air and its A19 Pro chipset, which in our testing had a slight edge in single-core performance but didn’t perform nearly as well in the multi-core suite (likely due to thermal limitations). In real-world use, I tried my best to find a game or application that could trip up the OP15, but between its new Snapdragon chipset and the 16GB of RAM that came in my unit, the phone handled everything with ease.It’s hard to describe how smooth the OnePlus 15 feels relative to other phones I’ve used recently. Every swipe and scroll feels nearly instantaneous. I suspect that’s a byproduct of the OP15’s dedicated touch response chip, which samples the screen at 3,200Hz. Speaking of the display, that 165Hz refresh rate I mentioned at the top is more of a forward-looking feature right now. As things stand, there are only seven games that can render at 165 fps. One of those, PUBG, does so through frame interpolation. So unless you’re an avid Call of Duty Mobile or Clash of Clans player, you won’t notice that benefit of the OP15’s screen, yet. Things could change in time, especially as more OEMs bring 165Hz displays to their phones. For now, the OP15 is still a great gaming phone, but it has yet to live up to its true potential.As much performance as the OnePlus 15 offers, what’s more impressive is its 7,300mAh battery. It’s the result of a new technology the company calls Silicon NanoStack. It allowed OnePlus to make a denser battery and one it claims will age more gracefully over time, thanks to a design that retains more than 80 percent of its health after four years. Obviously, I haven’t had the OP15 long enough to test that claim, but what I can say is that it offers tremendous battery life out of the box. On our local video rundown test, it posted a time of 38 hours and 30 minutes, which is eight hours longer than the OnePlus 13, the previous record holder. The Aramid case is one of three cases OnePlus offers alongside the OP15. Igor Bonifacic for EngadgetJust as impressive is how quickly the OP15 can charge. With the included 80W SUPERVOOC adapter, the battery can go from dead to full in about 40 minutes. The one downside of how OnePlus has approached charging is that the phone doesn't support the Qi2 standard. It can wirelessly charge at 50W, but you'll need to buy the company's proprietary AIRVOOC magnetic puck.SoftwareTwo screenshots showing of the OnePlus Mind SpaceIgor Bonifacic for EngadgetWhen he reviewed the OnePlus 13 in February, Engadget’s Sam Rutherford praised OnePlus for its restrained AI approach. Unfortunately, no company appears immune to the technology’s pull at this point, and in the months since, OnePlus has begun integrating more AI features into OxygenOS. Thankfully, many of those are either easy to ignore or situationally useful.First, there’s Mind Space, which is functionally similar to Nothing’s Essential Space. You can either tap the Plus Key (if it’s configured for use with Mind Space) or swipe up on the touchscreen with three fingers to save a screenshot to the hub. From there, the OP15’s built-in LLM will summarize the image, and you can ask the model questions about it. It’s also possible to save voice memos to the hub, and OnePlus offers a few other AI tools there, including one for scanning documents. All of these work well, and like I said, if they’re not your thing, they’re easy to ignore.The OnePlus 15's volume rocker and power button are located on the right side of the phone. Igor Bonifacic for EngadgetIt’s been a few years since I’ve used OxygenOS, so it was a pleasant surprise to learn it remains one of the more attractive and tasteful Android skins on the market. A standout is some of the custom animations OnePlus has baked into the OS to accentuate the speed of the phone. I also find OnePlus has one of the best organized quick settings menus. There are just enough customization options there to make it feel powerful, but not enough to overwhelm.One area where OnePlus could do better is software support. The company has pledged to provide the OP15 with four years of software updates and six years of security patches. That’s worse than both Google and Samsung, which have committed to supporting their latest phones for seven years.Wrap-upThe OnePlus 15 sits on a set of icy concrete steps. Igor Bonifacic for EngadgetIn using the OnePlus 15, I was frequently reminded of the last OnePlus phone I reviewed, the OnePlus 7 Pro. At the time, it was the company’s most expensive device ever, coming in at the same $750 price as the iPhone XR and Galaxy S10e. The appeal of that phone was its speedy Snapdragon 855 processor and the fact it was one of the first smartphones with a 90Hz AMOLED screen. It was also the first OnePlus phone with a camera that was more than just serviceable.All these years later, the appeal of the OP15 feels similar. It’s a phone for those who value speed over everything else. The tricky thing about this phone is judging its value when its price could change tomorrow. As I mentioned earlier, in the US the OP15 will start at $900, with OnePlus warning pricing for both models could “change due to current market conditions.” At $1,000, the 16GB model is a compelling alternative to the Pixel 10 Pro XL, offering a newer processor, more storage and a significantly bigger battery.Here’s the thing: Google has already aggressively discounted the entire Pixel 10 lineup, and until Black Friday, you can get the Pro XL for $899 — $100 less than the 16GB OnePlus 15. For most people, I think that’s the play, given both the Pro and Pro XL have the better telephoto camera and Google has promised to support all of its latest phones for seven years. That said, if you’re okay with a worse camera overall, the OP15 has a lot going for it, and provided OnePlus can successfully navigate an uncertain tariff regime, it will end up not just one of the best phones of 2025 but much of 2026 too.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/oneplus-15-review-a-great-phone-if-photography-isnt-a-priority-143000489.html?src=rss",
          "feed_position": 37,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/oneplus-15-2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/apples-macbook-air-m4-drops-to-a-record-low-price-before-black-friday-183808088.html",
          "published_at": "Thu, 13 Nov 2025 14:16:28 +0000",
          "title": "Apple's MacBook Air M4 drops to a record-low price before Black Friday",
          "standfirst": "Now's a great time to pick up a new MacBook Air if you've been thinking about taking the plunge. Amazon has the M4-powered, 13-inch MacBook Air for a record-low price of $749 right now. The 25 percent discount applies to multiple colors, too. We ranked this as our favorite Apple laptop in our list of the best MacBook computers. Heck, it's even our very favorite laptop. Full stop. The performance is exceptionally snappy, thanks to the M4 chip. We appreciated the upgraded battery life, which now lasts for around 18 hours per charge. That's well beyond a full day of work. The design is lightweight, but sturdy. This has become a hallmark for modern MacBook Air computers. The screen is both gorgeous and roomy, even though it's technically just a 13-inch panel. There's support for the P3 wide color gamut and it can reach up to 500 nits of brightness. This is a near-perfect laptop, but there are a couple of nitpicks. There's no USB-C port on the right side, limiting how users can arrange accessories on a desk. Also, the screen is capped with a 60Hz refresh rate. Another potential complication is the looming specter of the M5 chip. The company has already released the MacBook Pro M5, so a new MacBook Air is likely coming in the nearish future. (Read: sometime in early 2026). If you need more screen space, you'll find a similar discount on the 15-inch MacBook Air on Amazon, too. Most color options are $250 off and down to $949 for the base model (you guessed it — another all-time low). This article originally appeared on Engadget at https://www.engadget.com/deals/apples-macbook-air-m4-drops-to-a-record-low-price-before-black-friday-183808088.html?src=rss",
          "content": "Now's a great time to pick up a new MacBook Air if you've been thinking about taking the plunge. Amazon has the M4-powered, 13-inch MacBook Air for a record-low price of $749 right now. The 25 percent discount applies to multiple colors, too. We ranked this as our favorite Apple laptop in our list of the best MacBook computers. Heck, it's even our very favorite laptop. Full stop. The performance is exceptionally snappy, thanks to the M4 chip. We appreciated the upgraded battery life, which now lasts for around 18 hours per charge. That's well beyond a full day of work. The design is lightweight, but sturdy. This has become a hallmark for modern MacBook Air computers. The screen is both gorgeous and roomy, even though it's technically just a 13-inch panel. There's support for the P3 wide color gamut and it can reach up to 500 nits of brightness. This is a near-perfect laptop, but there are a couple of nitpicks. There's no USB-C port on the right side, limiting how users can arrange accessories on a desk. Also, the screen is capped with a 60Hz refresh rate. Another potential complication is the looming specter of the M5 chip. The company has already released the MacBook Pro M5, so a new MacBook Air is likely coming in the nearish future. (Read: sometime in early 2026). If you need more screen space, you'll find a similar discount on the 15-inch MacBook Air on Amazon, too. Most color options are $250 off and down to $949 for the base model (you guessed it — another all-time low). This article originally appeared on Engadget at https://www.engadget.com/deals/apples-macbook-air-m4-drops-to-a-record-low-price-before-black-friday-183808088.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/black-friday-apple-deals-bring-the-apple-watch-se-3-down-to-a-record-low-price-133057344.html",
          "published_at": "Thu, 13 Nov 2025 13:46:26 +0000",
          "title": "Black Friday Apple deals bring the Apple Watch SE 3 down to a record-low price",
          "standfirst": "The era of holiday shopping is coming and there are a lot of great tech gift options for loved ones or as a treat for yourself. That includes the new Apple Watch SE 3, which you can snag for only $200 right now. We consider this to be the best budget Apple Watch, and arguably the best smartwatch for folks who have never owned one before. The latest version runs on the same chipset found in the new flagship models, and it has most of the same fitness and workout tracking features you'll find in those more expensive devices as well. The SE 3 also now has an always-on display, making it easier to glance down throughout the day to check the time or see activity stats without moving your wrist, and fast-charging support makes it a more viable sleep tracker. Just plop it down on its charger for a bit at the end of the day and put it back on to monitor your sleep overnight. Also discounted is the high-end Apple Watch Ultra 3, which you can snag for $100 off. The sale model comes with 64GB of storage, a 49mm screen and GPS and cellular service. Notably, it's also only available with the one size, adjustable band and in two colors: a Black titanium case with Black Ocean band and a natural titanium Case with Anchor Blue Ocean band. The Apple Watch Ultra 3 came out in early September and is one of the first smartwatches to support satellite communications. This feature means you can call, send messages or share your location with emergency services through the watch — even if you don't have a connection. The new Ultra 3 also has a larger screen thanks to thinner bezels and a battery that can last for up to 42 hours. This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-apple-deals-bring-the-apple-watch-se-3-down-to-a-record-low-price-133057344.html?src=rss",
          "content": "The era of holiday shopping is coming and there are a lot of great tech gift options for loved ones or as a treat for yourself. That includes the new Apple Watch SE 3, which you can snag for only $200 right now. We consider this to be the best budget Apple Watch, and arguably the best smartwatch for folks who have never owned one before. The latest version runs on the same chipset found in the new flagship models, and it has most of the same fitness and workout tracking features you'll find in those more expensive devices as well. The SE 3 also now has an always-on display, making it easier to glance down throughout the day to check the time or see activity stats without moving your wrist, and fast-charging support makes it a more viable sleep tracker. Just plop it down on its charger for a bit at the end of the day and put it back on to monitor your sleep overnight. Also discounted is the high-end Apple Watch Ultra 3, which you can snag for $100 off. The sale model comes with 64GB of storage, a 49mm screen and GPS and cellular service. Notably, it's also only available with the one size, adjustable band and in two colors: a Black titanium case with Black Ocean band and a natural titanium Case with Anchor Blue Ocean band. The Apple Watch Ultra 3 came out in early September and is one of the first smartwatches to support satellite communications. This feature means you can call, send messages or share your location with emergency services through the watch — even if you don't have a connection. The new Ultra 3 also has a larger screen thanks to thinner bezels and a battery that can last for up to 42 hours. This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-apple-deals-bring-the-apple-watch-se-3-down-to-a-record-low-price-133057344.html?src=rss",
          "feed_position": 41
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/ecoflow-black-friday-deals-get-up-to-42-percent-off-portable-power-stations-130041144.html",
          "published_at": "Thu, 13 Nov 2025 13:30:37 +0000",
          "title": "EcoFlow Black Friday deals: Get up to 42 percent off portable power stations",
          "standfirst": "The EcoFlow Black Friday sale is in full swing, knocking thousands of dollars off portable power stations and their accessories. One of the best discounts at the moment is on the Delta Pro 3, which is 37 percent off and down to $2,299. That's the lowest we've seen it and, considering it typically costs $3,699, it's a great deal. Amazon's matching the sale price as well. The Delta Pro 3 topped Yahoo's list of the best portable power stations, and for very good reason. This thing is a beast. It boasts a 4,096Wh capacity, so it can power an average 500-watt refrigerator for over 24 hours. That's with continuous use. It can be stretched out to two or three days by only running the appliance during daylight hours. There's even a discounted bundle that includes an extra battery for $3,599. It includes four standard 120V AC outlets and a single 240V outlet. It could potentially be a temporary hub of a whole-home battery backup. There are numerous charging options here, including a standard AC outlet, solar panels and, interestingly, a cigarette lighter. The only potential downside here is the Delta Pro 3 really pushes the boundaries of what can be considered portable. It weighs 113 pounds, though it does have wheels and a telescoping handle. The Delta Pro 3 is just one of the products on sale right now. The Delta Pro Ultra, which is intended as a whole-home backup, is down to $3,999. This represents a savings of more than $2,000. Another Yahoo top pick, the Delta 2 Max, is $1,000 off and down to $899. This article originally appeared on Engadget at https://www.engadget.com/deals/ecoflow-black-friday-deals-get-up-to-42-percent-off-portable-power-stations-130041144.html?src=rss",
          "content": "The EcoFlow Black Friday sale is in full swing, knocking thousands of dollars off portable power stations and their accessories. One of the best discounts at the moment is on the Delta Pro 3, which is 37 percent off and down to $2,299. That's the lowest we've seen it and, considering it typically costs $3,699, it's a great deal. Amazon's matching the sale price as well. The Delta Pro 3 topped Yahoo's list of the best portable power stations, and for very good reason. This thing is a beast. It boasts a 4,096Wh capacity, so it can power an average 500-watt refrigerator for over 24 hours. That's with continuous use. It can be stretched out to two or three days by only running the appliance during daylight hours. There's even a discounted bundle that includes an extra battery for $3,599. It includes four standard 120V AC outlets and a single 240V outlet. It could potentially be a temporary hub of a whole-home battery backup. There are numerous charging options here, including a standard AC outlet, solar panels and, interestingly, a cigarette lighter. The only potential downside here is the Delta Pro 3 really pushes the boundaries of what can be considered portable. It weighs 113 pounds, though it does have wheels and a telescoping handle. The Delta Pro 3 is just one of the products on sale right now. The Delta Pro Ultra, which is intended as a whole-home backup, is down to $3,999. This represents a savings of more than $2,000. Another Yahoo top pick, the Delta 2 Max, is $1,000 off and down to $899. This article originally appeared on Engadget at https://www.engadget.com/deals/ecoflow-black-friday-deals-get-up-to-42-percent-off-portable-power-stations-130041144.html?src=rss",
          "feed_position": 42
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/amazon-black-friday-deals-include-the-fire-tv-stick-4k-max-for-only-35-132100009.html",
          "published_at": "Thu, 13 Nov 2025 13:21:00 +0000",
          "title": "Amazon Black Friday deals include the Fire TV Stick 4K Max for only $35",
          "standfirst": "Amazon has early Black Friday savings on its most potent streaming stick. The Fire TV Stick 4K Max is 41 percent off, bringing it close to its record low. You can get it now for $35. The Fire TV Stick 4K Max is one of Engadget's favorite streaming devices. The stick supports a solid mix of advanced technologies for its price: Dolby Vision, Dolby Atmos, 4K and HDR10+. As long as the rest of your entertainment setup can handle it, you'll get a high-quality picture and sound. It also supports Wi-Fi 6E, enabling better, faster connectivity with compatible routers. The 4K Max has the fastest processor of any Amazon Fire TV Stick, so expect zippy navigation. It also supports Amazon's Ambient Experience. This mode displays art (like on Samsung's The Frame) while the device is in standby. It's also a solid choice for gaming: It supports Xbox cloud streaming and works well as a retro game emulator, too. The UI is where Amazon appears to be subsidizing the device's low cost. Expect to see loads of Prime Video content promos, along with other ads. But for $35 (compared to its MSRP of $60), you may find it easier to justify that tradeoff. Also on sale is Amazon's Fire TV Stick HD, our pick for the best budget streaming stick. This model doesn't support 4K; instead, it limits you to 1080p at 60 fps. At $18 for Black Friday, it's certainly cheap. But if you have a 4K TV (or plan to soon), you may want to consider the slightly more expensive model. This article originally appeared on Engadget at https://www.engadget.com/deals/amazon-black-friday-deals-include-the-fire-tv-stick-4k-max-for-only-35-132100009.html?src=rss",
          "content": "Amazon has early Black Friday savings on its most potent streaming stick. The Fire TV Stick 4K Max is 41 percent off, bringing it close to its record low. You can get it now for $35. The Fire TV Stick 4K Max is one of Engadget's favorite streaming devices. The stick supports a solid mix of advanced technologies for its price: Dolby Vision, Dolby Atmos, 4K and HDR10+. As long as the rest of your entertainment setup can handle it, you'll get a high-quality picture and sound. It also supports Wi-Fi 6E, enabling better, faster connectivity with compatible routers. The 4K Max has the fastest processor of any Amazon Fire TV Stick, so expect zippy navigation. It also supports Amazon's Ambient Experience. This mode displays art (like on Samsung's The Frame) while the device is in standby. It's also a solid choice for gaming: It supports Xbox cloud streaming and works well as a retro game emulator, too. The UI is where Amazon appears to be subsidizing the device's low cost. Expect to see loads of Prime Video content promos, along with other ads. But for $35 (compared to its MSRP of $60), you may find it easier to justify that tradeoff. Also on sale is Amazon's Fire TV Stick HD, our pick for the best budget streaming stick. This model doesn't support 4K; instead, it limits you to 1080p at 60 fps. At $18 for Black Friday, it's certainly cheap. But if you have a 4K TV (or plan to soon), you may want to consider the slightly more expensive model. This article originally appeared on Engadget at https://www.engadget.com/deals/amazon-black-friday-deals-include-the-fire-tv-stick-4k-max-for-only-35-132100009.html?src=rss",
          "feed_position": 45
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/ubers-send-a-ride-feature-makes-it-easier-to-pay-someone-elses-fare-130000110.html",
          "published_at": "Thu, 13 Nov 2025 13:00:00 +0000",
          "title": "Uber's 'Send a Ride' feature makes it easier to pay someone else's fare",
          "standfirst": "In anticipation of what's expected to be a more hectic than usual season of holiday travel, Uber is adding a collection of new gifting and ridesharing features to its app. The most convenient of the new features is \"Send a Ride,\" a way to purchase Uber rides for someone else.Send a Ride lets you cover the cost of a ride directly from the Uber app, making it possible to pay for something like an airport pickup in advance. Uber says you'll be able to set a number of rides and a spending limit in the app (like two rides for up to $50 each) and then the app will generate a link that you can share with whomever you want to receive the rides. When they click the link, credit will automatically be added to their account and applied to their next trip.For anyone whose winter travel includes skiing and snowboarding, Uber Ski is a new seasonal ride option Uber is adding that lets you book a ride to and from \"nearly 40 of the top mountains across North America and Europe.\" When you select Uber Ski in the app, you can reserve an UberXL for up to two guests with gear or an UberXXL for up to four guests with gear. Uber also says it will sell the Epic Pass, a ticket that gets you access to Vail Resorts, directly through the Uber app. If you're figuring out your own ride home from the airport, Uber is also expanding its Uber Share for Airports option that lets you split a ride home with people heading in the same general direction. Uber Share is now available at over 50 airports worldwide, including new additions John F. Kennedy International Airport, LaGuardia AirPort and Orlando International Airport.Finally, starting in December, Uber will let you add a free video message from stars like Megan Thee Stallion, the Jonas Brothers or Tracee Ellis Ross to any Uber Eats order you send as a gift. The videos don't sound like they'll be personalized like a video from Cameo, but whoever you send the gift to will be able to choose their own delivery time so they're available when their gift arrives.This article originally appeared on Engadget at https://www.engadget.com/transportation/ubers-send-a-ride-feature-makes-it-easier-to-pay-someone-elses-fare-130000110.html?src=rss",
          "content": "In anticipation of what's expected to be a more hectic than usual season of holiday travel, Uber is adding a collection of new gifting and ridesharing features to its app. The most convenient of the new features is \"Send a Ride,\" a way to purchase Uber rides for someone else.Send a Ride lets you cover the cost of a ride directly from the Uber app, making it possible to pay for something like an airport pickup in advance. Uber says you'll be able to set a number of rides and a spending limit in the app (like two rides for up to $50 each) and then the app will generate a link that you can share with whomever you want to receive the rides. When they click the link, credit will automatically be added to their account and applied to their next trip.For anyone whose winter travel includes skiing and snowboarding, Uber Ski is a new seasonal ride option Uber is adding that lets you book a ride to and from \"nearly 40 of the top mountains across North America and Europe.\" When you select Uber Ski in the app, you can reserve an UberXL for up to two guests with gear or an UberXXL for up to four guests with gear. Uber also says it will sell the Epic Pass, a ticket that gets you access to Vail Resorts, directly through the Uber app. If you're figuring out your own ride home from the airport, Uber is also expanding its Uber Share for Airports option that lets you split a ride home with people heading in the same general direction. Uber Share is now available at over 50 airports worldwide, including new additions John F. Kennedy International Airport, LaGuardia AirPort and Orlando International Airport.Finally, starting in December, Uber will let you add a free video message from stars like Megan Thee Stallion, the Jonas Brothers or Tracee Ellis Ross to any Uber Eats order you send as a gift. The videos don't sound like they'll be personalized like a video from Cameo, but whoever you send the gift to will be able to choose their own delivery time so they're available when their gift arrives.This article originally appeared on Engadget at https://www.engadget.com/transportation/ubers-send-a-ride-feature-makes-it-easier-to-pay-someone-elses-fare-130000110.html?src=rss",
          "feed_position": 47
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/dji-neo-2-review-the-best-budget-drone-is-now-even-better-120026045.html",
          "published_at": "Thu, 13 Nov 2025 12:00:26 +0000",
          "title": "DJI Neo 2 review: The best budget drone is now even better",
          "standfirst": "Even with its US future in limbo, DJI keeps releasing impressive drones. Its latest is the Neo 2, an inexpensive, lightweight model aimed at creators and hobbyists. It’s an upgraded version of the Neo, an immensely popular drone both in the US and elsewhere. The new model is equally safe and easy to fly thanks to the shrouded props, palm takeoff and voice control. DJI didn’t just tack on a number and call it a day, though. The Neo 2 is loaded with new features like LiDAR obstacle detection, improved video quality and longer battery life — all at only a slightly higher price. In fact, a couple of the new features can’t even be found on high-end DJI drones. The original Neo wasn’t perfect; the propellers on that model emitted a banshee-like scream. The lack of obstacle detection and short battery life also wasn’t ideal. Has the company solved these problems on the new model? Mostly, yes — and it’s now a nearly perfect personal drone. Design Though the Neo 2 has the same 6.5-inch square size and friendly appearance as before, there are some important differences. A new LiDAR sensor beside the camera is designed to detect forward obstacles, and is a surprising inclusion for such an affordable drone. On the left front is a small display — a first for a DJI drone — that shows the current shot mode (follow, dronie, etc.). The gimbal has also been upgraded and can now rotate instead of just tilt. That means the camera will stay level when the drone banks, with no ugly cropping or reduced resolution that I occasionally saw when doing extreme maneuvers with the Neo. The Neo 2 has three buttons on the side (rather than just one on top as before), along with two new omnidirectional sensors. On top of helping the Neo 2 avoid obstacles, these improve stability in featureless or non-GPS environments like indoors and over water. Finally, if you buy a Neo 2 with the optional RC-2 or RC-N3 controller, it includes a removable Digital Transceiver with a pair of antennae. Those components give it a butterfly-like appearance and could affect long term durability. However, making them an add-on gave DJI a way to make the basic (non-controller) version as inexpensive as possible. With all those changes, the Neo 2 is a bit heavier at 5.6 ounces (160 grams) with the Digital Transceiver, compared to 4.8 ounces (135 grams) for the Neo. That’s still easily small enough to slide in a bag and light enough (under 250 grams) that you won’t need to register your drone with the authorities. Features Gesture control is a major new Neo 2 feature not found on other DJI drones. It lets you fly with surprising precision, if you don’t mind looking a little silly. To do so, wave a hand up, down or sideways to climb and bank, move two hands apart or together to make it approach or move away (think pinch-to-zoom in the air), clench a fist to stop it and hold out your palm to land. Gestures can be used in combination with other fly modes so you get the exact shot you want. Steve Dent for Engadget Along with the ability to wave your hands, the Neo 2 offers other ways to fly like palm takeoff. After selecting the flight mode (shown on the new display and audibly announced), you can launch the Neo 2 from your hand by pressing the takeoff button or using voice control. It will then execute the chosen mode, fly back to you and land on your outstretched palm. Smartphone control (not seen on other DJI drones) is available for manual flight. Wi-Fi range has been extended by ten times to 546 yards, compared to 55 yards for the Neo. However, for that range you need a clear signal path with no obstacles between you and the drone. For more precise flight and longer range (up to 6 miles), the Neo 2 supports RC-N2, RC-N3 or RC-2 controllers. And FPV (first person) flying is still an option when using DJI’s Goggles N3 or Goggles 3, paired with the RC Motion 3 or FPV Remote Controller 3. The Neo 3’s Quickshots repertoire has also been updated. A fun new mode is the “Hitchcock zoom.” When activated, the drone backs away while zooming in at the same time, creating a trippy perspective effect you might’ve seen in Vertigo and Jaws. Again, this feature is unique to the Neo 2 in DJI’s lineup. Other key functions include compatibility with DJI’s microphones, including the Mic 2, Mic 3 and Mic Mini. Since the Neo 2 is quieter than the Neo (more on that shortly), noise cancelling requirements are reduced so audio quality is improved. Onboard storage has also been upgraded to 49GB (up from 22GB), letting you record up to 175 minutes of 4K video. At the same time, DJI more than doubled the Wi-Fi transfer speed to 80MB/s. Performance The Neo 2 now has omni sensors and LiDAR for obstacle protectoin Steve Dent for Engadget The Neo 2 retains the Neo’s toughness and protection, but it can now fly around obstacles instead of just plowing through them thanks to the LiDAR and sensors. To test that, I used it to follow subjects around trees, buildings and other obstacles. The aim was to see not only how well it avoided crashes in all directions, but to observe how smoothly it tracked while doing so. To start, I engaged the ActiveTrack follow feature and used the Trace mode “steering wheel’ to follow subjects from the front, sides and back. When flying forward, the Neo 2 avoided most obstacles using its LiDAR, while swooping cinematically around trees and branches. It occasionally failed to detect small twigs and leaves, but unlike open-prop DJI drones, it usually flew through them without incident. With just two omni sensors, the Neo 2 is less adept at avoiding obstacles to the sides and rear, however. So if you’re using it to vlog while walking or biking, it’s best to make sure there’s nothing in the way. With a top speed of just 18 mph, the original Neo was so slow that it could barely track a bike. Luckily, the Neo 2 is much faster with speeds up to 27 mph in follow mode and even has a special “Bicycle Tracking” mode. I tested that on an e-bike and the drone easily kept up with me while easily avoiding obstacles in the forward direction. Again, you need to be extra careful when it’s flying backwards or sideways. The Neo 2 is as agile as ever, so the extra velocity makes it a better FPV drone as well. While wearing the Goggles N3, I was able to enjoy that sensation of extra speed as it swooped around obstacles. That, plus the low price, makes it a good first drone for anyone looking to get into FPV flying. I likened the Neo’s prop noise to a banshee howl, but the Neo 2 is maybe a… banshee purr. Both the decibel level and pitch are now tolerable, even indoors. I flew it around at a fairly loud party and hardly anyone noticed; it also didn’t draw much attention in a public park. The only negative is it’s a high-pitched sound, a noise that carries even across high altitudes. Video quality DJI's Neo 2 now offers 4K at up to 100 fps Steve Dent for Engadget With a new 12MP, 1/2-inch sensor camera, video quality is excellent for this price range. The Neo 2 now supports 4K at up to 60 fps or 100 fps in slo-mo mode. On the previous model, it was just 30 fps. The Neo 2 also has an f/2.0 iris to let in more light compared to the previous f/2.8. With those updates, the drone offers sharper and more color-accurate video and photos than the Neo. There are of course some sacrifices at this price. The small sensor means the Neo 2 has mediocre low-light capability, with pronounced grain at the maximum ISO 12,800 rating that’s even noticeable at ISO 3,200. Unlike the $400 Flip, the Neo 2 has no 10-bit D-LogM capability, so over- or underexposed video is hard to correct. With those issues, video and photos from the Neo 2 aren't quite good enough for professional work. However, it’s excellent for social media users, hobbyists and content creators, delivering smartphone-quality aerial shots. Wrap-up DJI has yet to reveal availability or pricing of the Neo 2 in the US (or whether it will come here at all) due to a looming December 23 ban. If it does arrive, it will effectively have no competition at its price point, which I expect to be around $250. The HoverAir X1 is the only name brand alternative, but costs twice as much. That model offers solid follow-me capabilities for activities like biking and hiking. Feature-wise, though, it pales in comparison to the Neo 2, with inferior video quality, battery life, range and obstacle detection. DJI’s Neo 2 is not just the best personal drone; it's the best tech product I’ve seen in a while, period. It retains everything I liked about the Neo, especially the ease of use and safety features. On top of that, it adds a host of useful functions like obstacle protection and, thank goodness, lower noise levels. With all that, the Neo 2 performs that rare trick of doing much more than I expected — for a lot less money.This article originally appeared on Engadget at https://www.engadget.com/cameras/dji-neo-2-review-the-best-budget-drone-is-now-even-better-120026045.html?src=rss",
          "content": "Even with its US future in limbo, DJI keeps releasing impressive drones. Its latest is the Neo 2, an inexpensive, lightweight model aimed at creators and hobbyists. It’s an upgraded version of the Neo, an immensely popular drone both in the US and elsewhere. The new model is equally safe and easy to fly thanks to the shrouded props, palm takeoff and voice control. DJI didn’t just tack on a number and call it a day, though. The Neo 2 is loaded with new features like LiDAR obstacle detection, improved video quality and longer battery life — all at only a slightly higher price. In fact, a couple of the new features can’t even be found on high-end DJI drones. The original Neo wasn’t perfect; the propellers on that model emitted a banshee-like scream. The lack of obstacle detection and short battery life also wasn’t ideal. Has the company solved these problems on the new model? Mostly, yes — and it’s now a nearly perfect personal drone. Design Though the Neo 2 has the same 6.5-inch square size and friendly appearance as before, there are some important differences. A new LiDAR sensor beside the camera is designed to detect forward obstacles, and is a surprising inclusion for such an affordable drone. On the left front is a small display — a first for a DJI drone — that shows the current shot mode (follow, dronie, etc.). The gimbal has also been upgraded and can now rotate instead of just tilt. That means the camera will stay level when the drone banks, with no ugly cropping or reduced resolution that I occasionally saw when doing extreme maneuvers with the Neo. The Neo 2 has three buttons on the side (rather than just one on top as before), along with two new omnidirectional sensors. On top of helping the Neo 2 avoid obstacles, these improve stability in featureless or non-GPS environments like indoors and over water. Finally, if you buy a Neo 2 with the optional RC-2 or RC-N3 controller, it includes a removable Digital Transceiver with a pair of antennae. Those components give it a butterfly-like appearance and could affect long term durability. However, making them an add-on gave DJI a way to make the basic (non-controller) version as inexpensive as possible. With all those changes, the Neo 2 is a bit heavier at 5.6 ounces (160 grams) with the Digital Transceiver, compared to 4.8 ounces (135 grams) for the Neo. That’s still easily small enough to slide in a bag and light enough (under 250 grams) that you won’t need to register your drone with the authorities. Features Gesture control is a major new Neo 2 feature not found on other DJI drones. It lets you fly with surprising precision, if you don’t mind looking a little silly. To do so, wave a hand up, down or sideways to climb and bank, move two hands apart or together to make it approach or move away (think pinch-to-zoom in the air), clench a fist to stop it and hold out your palm to land. Gestures can be used in combination with other fly modes so you get the exact shot you want. Steve Dent for Engadget Along with the ability to wave your hands, the Neo 2 offers other ways to fly like palm takeoff. After selecting the flight mode (shown on the new display and audibly announced), you can launch the Neo 2 from your hand by pressing the takeoff button or using voice control. It will then execute the chosen mode, fly back to you and land on your outstretched palm. Smartphone control (not seen on other DJI drones) is available for manual flight. Wi-Fi range has been extended by ten times to 546 yards, compared to 55 yards for the Neo. However, for that range you need a clear signal path with no obstacles between you and the drone. For more precise flight and longer range (up to 6 miles), the Neo 2 supports RC-N2, RC-N3 or RC-2 controllers. And FPV (first person) flying is still an option when using DJI’s Goggles N3 or Goggles 3, paired with the RC Motion 3 or FPV Remote Controller 3. The Neo 3’s Quickshots repertoire has also been updated. A fun new mode is the “Hitchcock zoom.” When activated, the drone backs away while zooming in at the same time, creating a trippy perspective effect you might’ve seen in Vertigo and Jaws. Again, this feature is unique to the Neo 2 in DJI’s lineup. Other key functions include compatibility with DJI’s microphones, including the Mic 2, Mic 3 and Mic Mini. Since the Neo 2 is quieter than the Neo (more on that shortly), noise cancelling requirements are reduced so audio quality is improved. Onboard storage has also been upgraded to 49GB (up from 22GB), letting you record up to 175 minutes of 4K video. At the same time, DJI more than doubled the Wi-Fi transfer speed to 80MB/s. Performance The Neo 2 now has omni sensors and LiDAR for obstacle protectoin Steve Dent for Engadget The Neo 2 retains the Neo’s toughness and protection, but it can now fly around obstacles instead of just plowing through them thanks to the LiDAR and sensors. To test that, I used it to follow subjects around trees, buildings and other obstacles. The aim was to see not only how well it avoided crashes in all directions, but to observe how smoothly it tracked while doing so. To start, I engaged the ActiveTrack follow feature and used the Trace mode “steering wheel’ to follow subjects from the front, sides and back. When flying forward, the Neo 2 avoided most obstacles using its LiDAR, while swooping cinematically around trees and branches. It occasionally failed to detect small twigs and leaves, but unlike open-prop DJI drones, it usually flew through them without incident. With just two omni sensors, the Neo 2 is less adept at avoiding obstacles to the sides and rear, however. So if you’re using it to vlog while walking or biking, it’s best to make sure there’s nothing in the way. With a top speed of just 18 mph, the original Neo was so slow that it could barely track a bike. Luckily, the Neo 2 is much faster with speeds up to 27 mph in follow mode and even has a special “Bicycle Tracking” mode. I tested that on an e-bike and the drone easily kept up with me while easily avoiding obstacles in the forward direction. Again, you need to be extra careful when it’s flying backwards or sideways. The Neo 2 is as agile as ever, so the extra velocity makes it a better FPV drone as well. While wearing the Goggles N3, I was able to enjoy that sensation of extra speed as it swooped around obstacles. That, plus the low price, makes it a good first drone for anyone looking to get into FPV flying. I likened the Neo’s prop noise to a banshee howl, but the Neo 2 is maybe a… banshee purr. Both the decibel level and pitch are now tolerable, even indoors. I flew it around at a fairly loud party and hardly anyone noticed; it also didn’t draw much attention in a public park. The only negative is it’s a high-pitched sound, a noise that carries even across high altitudes. Video quality DJI's Neo 2 now offers 4K at up to 100 fps Steve Dent for Engadget With a new 12MP, 1/2-inch sensor camera, video quality is excellent for this price range. The Neo 2 now supports 4K at up to 60 fps or 100 fps in slo-mo mode. On the previous model, it was just 30 fps. The Neo 2 also has an f/2.0 iris to let in more light compared to the previous f/2.8. With those updates, the drone offers sharper and more color-accurate video and photos than the Neo. There are of course some sacrifices at this price. The small sensor means the Neo 2 has mediocre low-light capability, with pronounced grain at the maximum ISO 12,800 rating that’s even noticeable at ISO 3,200. Unlike the $400 Flip, the Neo 2 has no 10-bit D-LogM capability, so over- or underexposed video is hard to correct. With those issues, video and photos from the Neo 2 aren't quite good enough for professional work. However, it’s excellent for social media users, hobbyists and content creators, delivering smartphone-quality aerial shots. Wrap-up DJI has yet to reveal availability or pricing of the Neo 2 in the US (or whether it will come here at all) due to a looming December 23 ban. If it does arrive, it will effectively have no competition at its price point, which I expect to be around $250. The HoverAir X1 is the only name brand alternative, but costs twice as much. That model offers solid follow-me capabilities for activities like biking and hiking. Feature-wise, though, it pales in comparison to the Neo 2, with inferior video quality, battery life, range and obstacle detection. DJI’s Neo 2 is not just the best personal drone; it's the best tech product I’ve seen in a while, period. It retains everything I liked about the Neo, especially the ease of use and safety features. On top of that, it adds a host of useful functions like obstacle protection and, thank goodness, lower noise levels. With all that, the Neo 2 performs that rare trick of doing much more than I expected — for a lot less money.This article originally appeared on Engadget at https://www.engadget.com/cameras/dji-neo-2-review-the-best-budget-drone-is-now-even-better-120026045.html?src=rss",
          "feed_position": 49,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-11/6c85f620-bfe5-11f0-b7df-a85585c76318"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/alembic-melted-gpus-chasing-causal-a-i-now-its-running-one-of-the-fastest",
          "published_at": "Thu, 13 Nov 2025 10:00:00 GMT",
          "title": "Alembic melted GPUs chasing causal A.I. — now it's running one of the fastest supercomputers in the world",
          "standfirst": "Alembic Technologies has raised $145 million in Series B and growth funding at a valuation 13 times higher than its previous round, betting that the next competitive advantage in artificial intelligence will come not from better language models but from proprietary data and causal reasoning.The San Francisco-based startup, which builds AI systems that identify cause-and-effect relationships rather than mere correlations, is using a significant portion of the capital to deploy what it claims is one of the fastest privately owned supercomputers ever built — an Nvidia NVL72 superPOD that will power its enterprise-grade causal AI models.The investment, led by Prysm Capital and Accenture with participation from Silver Lake Waterman, Liquid 2 Ventures, NextEquity, Friends & Family Capital and WndrCo, positions Alembic among a select group of well-funded AI laboratories transforming how corporations make multimillion-dollar decisions.The funding round and the company&#x27;s strategic direction reflect a broader shift taking place in enterprise AI as the performance gap between competing large language models narrows. While startups and tech giants have poured billions into building ever-larger chatbots, Alembic is pursuing a different thesis: that the real value in AI will accrue to systems that can process private corporate data to answer questions that generic models cannot.\"As powerful artificial intelligence models increasingly converge in capability, the key competitive advantage shifts to proprietary data,\" said Tomás Puig, Alembic&#x27;s founder and chief executive, in an interview with VentureBeat. \"Getting a real edge isn&#x27;t about using the best LLM; it&#x27;s leveraging the unique information rivals can&#x27;t access.\"Puig illustrated the problem facing enterprise executives: \"Imagine I run a CPG company and I install the latest ChatGPT. I ask, &#x27;Hey, ChatGPT, give me a strategy for how to increase my revenue share in the northeast.&#x27; Then your competitor down the road asks the exact same question. How much trouble are you in when they get the exact same answer?\"How a broke startup on Mac Pros discovered a breakthrough that changed everythingThe dramatic valuation increase—from roughly $50 million at the Series A to approximately $645 million now, according to people familiar with the matter — reflects a fundamental transformation in Alembic&#x27;s technology and market positioning since its previous funding round.When the company raised its Series A in early 2024, it was primarily a signal processing and correlation analytics company focused on marketing measurement. \"Causal did not exist as a technology for us till after the Series A,\" Puig told VentureBeat. The company was so resource-constrained that it couldn&#x27;t even run simulations to test whether its causal models would work.The breakthrough came after the Series A when the company finally had enough capital to test its theories. \"We were so broke that we couldn&#x27;t even run the simulation to see if it worked,\" Puig recalled. When they did run the tests — initially on an \"army of Mac Pros\" because they didn&#x27;t yet have GPU infrastructure — they discovered something unexpected: their causal model worked not just for marketing analytics but across virtually any business domain with time-series data.\"We started adding capabilities as customers requested them, which was just sensible—iterative,\" Puig explained. \"We found out the model works across a huge majority of data universally. What we thought might be a model for a specific vertical ended up being a full, generalized foundational model.\"That discovery transformed Alembic from a marketing technology vendor into a company building what Puig describes as \"the entire central nervous system of the enterprise across all verticals — not just sales, marketing, supply chain, finance, and beyond.\"Why cause-and-effect AI matters more than correlation for enterprise decision-makingCausal AI is a fundamentally different approach from the correlation-based analytics that dominate most business intelligence tools and even many AI systems. Where traditional analytics might show that social media engagement correlates with sales increases, causal AI can determine whether the social media activity actually caused the sales lift — or whether both were driven by some third factor, like a viral news event.The distinction matters enormously for executives making budget allocation decisions. \"Most businesses are not short on data,\" Puig said. \"They are short on answers.\"For Alembic&#x27;s customers, which now include Delta Air Lines, Mars, Nvidia and several Fortune 500 companies across financial services, technology and consumer packaged goods, the platform can answer previously unanswerable questions about marketing effectiveness, operational efficiency and strategic investments.\"Alembic&#x27;s ability to connect marketing exposure directly to business outcomes—with speed, precision and granularity—is what made this relationship so transformative for us,\" said Alicia Tillman, chief marketing officer at Delta Air Lines. \"Unlike traditional measurement tools, Alembic gave us a unified view across channels and campaigns, unlocking insights we simply couldn&#x27;t access before.\"The airline used Alembic to quantify the revenue lift from its Team USA Olympics sponsorship within days of activation, directly linking brand activities to ticket sales—a type of measurement that has eluded marketers for decades. Traditional attribution models either ignore brand-building entirely or assign it vague \"awareness\" metrics that don&#x27;t translate to financial impact.\"It&#x27;s very transformative,\" Puig said of the customer impact. \"What&#x27;s interesting is that executives themselves are the users of our software and our outputs. It&#x27;s not a tool used by a single campaign manager.\"Inside the two-story liquid-cooled supercomputer that literally melted GPUsAlembic&#x27;s decision to invest heavily in owned computing infrastructure rather than rely on cloud providers stems from both the technical demands of its causal models and the extreme data sensitivity requirements of its enterprise customers.The company is deploying an Nvidia NVL72 superPOD — a massive liquid-cooled system equipped with Nvidia&#x27;s most advanced Blackwell graphics processing units — in partnership with data center operator Equinix in San Jose, Calif. According to Puig, Nvidia informed Alembic that it is the only non-Fortune 500 company in the world to operate such a system.The need for this level of compute stems from how Alembic&#x27;s models work. Unlike large language models that are trained once on historical data and then deployed, Alembic&#x27;s system uses \"online and evolving\" models built on spiking neural networks — brain-inspired architectures that continuously learn as new data arrives.\"It creates itself as you feed it data, like human evolution,\" Puig explained. \"The model is singular, but it ends up creating a different brain for every single company.\"This continuous learning happens at massive scale. When a customer brings in data, Alembic&#x27;s system automatically permutates through billions of possible combinations of how that data could be analyzed — testing every conceivable way to slice metrics and dimensions to find the strongest causal signals. That level of computation requires what Puig calls \"F1 car\" infrastructure rather than the \"production Porsche\" offered by cloud providers.The company writes custom CUDA code and low-level GPU kernels optimized specifically for causal inference workloads — optimizations that aren&#x27;t possible on standard cloud configurations. The approach has proven so demanding that Alembic famously once melted down its GPUs by pushing them beyond their thermal limits. \"We literally just drive these circuits so hard that we need the F1 car version and we have to have access to it,\" Puig said.The move to liquid-cooled systems addresses that problem, but it also enables Alembic to run workloads that would cost orders of magnitude more on cloud platforms. \"We did the math—if we were to buy just one subsection of our compute from AWS, it would be $62 million a year,\" Puig said. Owning the infrastructure costs \"a fraction of that.\"The supercomputer strategy serves another crucial purpose: data sovereignty. Many of Alembic&#x27;s customers — particularly in financial services, consumer packaged goods and regulated industries — have contractual prohibitions against putting sensitive data on Amazon Web Services, Microsoft Azure or Google Cloud.\"CPG companies do not want any data to exist on Amazon, ever,\" Puig said. \"They simply won&#x27;t allow it. Some customers refuse to use Microsoft, others avoid different providers. And certain banks and financial institutions are legally prohibited from using cloud platforms at all.\"By operating its own infrastructure in neutral data centers, Alembic can serve customers who would never consider cloud-based analytics — a competitive moat that would be difficult for hyperscale cloud providers to replicate.How Jensen Huang read a news article and changed Alembic&#x27;s destinyAlembic&#x27;s relationship with Nvidia illustrates both the startup&#x27;s technical ambitions and how the chip giant supports promising AI companies. Nvidia is Alembic&#x27;s founding enterprise customer, exclusive supercomputing partner and a key technical collaborator — though notably not an investor.The relationship began in an unlikely way. After Alembic announced its Series A funding in early 2024, Nvidia co-founder and CEO Jensen Huang read the VentureBeat coverage and emailed his staff suggesting they explore the company, according to Puig. Because Alembic didn&#x27;t yet have a contact form on its website, an Nvidia director reached out via LinkedIn.The partnership nearly foundered on a basic constraint: computing capacity. After Alembic delivered its first causal analysis — which took weeks to generate on an array of Mac Pros — Nvidia asked if they could produce weekly reports. \"I said no, because it took weeks on this army of machines,\" Puig recalled.When Alembic said they could do it with GPUs but couldn&#x27;t secure the necessary compute — cloud providers at the time required committee approvals and offered two- to six-week lead times with no guarantees — Nvidia intervened directly. The chip maker arranged for Equinix to provide a private cage in Northern Virginia with sufficient power capacity and helped Alembic source its first H100 GPU cluster.\"Without that, the company would never have existed,\" Puig said. \"We couldn&#x27;t get the compute in the configuration we needed anywhere else.\"The partnership has since deepened. Alembic uses Nvidia&#x27;s AI Enterprise software suite, including specialized libraries like cuGraph for graph processing and TensorRT for high-speed inference. The tight integration, Puig said, allows \"our research teams to leverage multi-exaflop-level compute and Nvidia&#x27;s algorithmic software stack. This integration is one of our secret weapons: we spend more time on breakthrough research and mathematics and less time on repetitive low-level engineering.\"Nvidia&#x27;s support extended beyond technology. When Alembic kept destroying GPUs under extreme workloads — pushing chips so hard that thermal stress cracked circuit boards — Nvidia fast-tracked the startup&#x27;s access to next-generation liquid-cooled systems. \"The funny reason we got [the NVL72],\" Puig said, \"is because when we melted the chips, Nvidia was literally annoyed with how often they had to service our warranty.\"From Olympics sponsorships to viral candy moments: How Fortune 500s measure what was unmeasurableAlembic&#x27;s customer roster has expanded rapidly as enterprises seek ways to measure AI and marketing investments that traditional analytics cannot capture. The company now works with Delta Air Lines, Mars, multiple Fortune 500 technology and financial services firms, and Texas A&M University&#x27;s athletics program.The use cases span far beyond Alembic&#x27;s original marketing focus. Mars used the platform to measure the sales impact of changing candy shapes for themed promotions. A Fortune 500 technology company expanded its sales pipeline by 37% using Alembic&#x27;s attribution models. Financial services firms are using it to connect CEO public appearances and co-marketing expenditures to actual fund flows.\"Alembic helped us move past impression counts to show what actually drove net-new investment,\" said the head of co-marketing at a Fortune 200 financial services company. \"For the first time, we could see how our CEO in the public eye and our co-marketing dollars with exchanges translated into real fund flows.\"For Mars, the ability to measure previously unmeasurable activities has transformed decision-making. \"We are using math to liberate creativity,\" said Gülen Bengi, lead global chief marketing officer for Mars and global chief growth officer for Mars Snacking. \"Our fans and communities create billions of organic conversations and content about our brands. When a viral moment happens, we normally know it&#x27;s directionally positive, but we can&#x27;t attribute the sales uplift or its place in the customer journey. Alembic&#x27;s Causal AI is a breakthrough, allowing us to move beyond correlation to see exactly how that organic conversation created a sequence that directly impacted sales.\"The platform can predict revenue, close rates and customer acquisition up to two years in advance with 95% confidence, according to Puig. \"What they were doing before was they actually literally did not know about certain things,\" he said, describing how customers previously estimated the value of stadium naming rights or major sponsorships without ever measuring actual dollar impact. \"Now you can go and be like it had this effect on this much P&L, and this is where it&#x27;s flowing, and you can know within days or near real time.\"Why Google, Meta and Nielsen can&#x27;t easily replicate what Alembic builtAlembic operates in a competitive landscape that includes traditional marketing measurement vendors like Nielsen, analytics platforms from Google and Meta, and emerging AI-powered analytics startups. But Puig argues the company has built structural advantages that would be difficult to replicate.First, the company&#x27;s causal models rely on proprietary mathematics developed over years and protected by patents. \"You would have to start from scratch,\" Puig said. \"This is not like an LLM that uses a transformer that has a paper, and you could attempt to recreate. You&#x27;d actually have to go and recreate the methodology from scratch.\"Second, the massive computing requirements create a natural barrier. Alembic operates at \"foundational model levels of compute, not like even something you would run from [AWS] Sagemaker,\" Puig said. \"We&#x27;re talking about hundreds of millions of dollars a year\" in equivalent cloud costs.Third, the data sovereignty requirements of enterprise customers create opportunities for neutral third parties that hyperscale cloud providers struggle to address. As one venture capital investor noted, enterprises increasingly worry about putting strategic data into systems owned by potential competitors.Finally, Alembic&#x27;s ability to work with messy, fragmented data reflects years of engineering that preceded its causal AI breakthrough. \"The first four [or] five years of the company&#x27;s life was building that giant signal processor that dealt with messy data,\" Puig said. \"We would not be able to do it if we had not taken all that time.\"Why Alembic&#x27;s contrarian bet on private data could reshape enterprise AIThe $145 million funding round validates a contrarian bet in an AI landscape dominated by the race to build ever-larger language models. While OpenAI, Anthropic and others compete on whose chatbot can write better code or answer more trivia questions, Alembic is building infrastructure for a different kind of intelligence — one that understands cause and effect in the messy, proprietary data that defines each company&#x27;s unique competitive position.The company&#x27;s evolution from a bootstrapped startup running simulations on Mac Pros to operating one of the world&#x27;s fastest private supercomputers mirrors the broader maturation of enterprise AI. As the technology moves from experimentation to mission-critical deployment, companies need more than general-purpose models trained on public data. They need systems that can process their private information to answer questions their competitors cannot.Puig&#x27;s thesis — that private data becomes the key differentiator as public models converge — resonates with how other technologies evolved. Search engines commoditized access to public information, making proprietary data more valuable. Cloud computing made infrastructure a utility, elevating the importance of what you build on top of it. If large language models similarly converge in capability, the competitive advantage flows to whoever can best extract intelligence from data others cannot access.The company is already testing its technology beyond marketing analytics. Pilots are underway in robotics, where causal models could help autonomous systems understand how actions lead to outcomes. New product lines are launching, including the GPU-accelerated database that customers are buying separately. The ambition, Puig said, is to become \"the central nervous system\" of the enterprise — the layer that connects cause and effect across every business function.Whether Alembic can deliver on that vision remains to be seen. The company operates in complex enterprise environments where sales cycles are long and integration challenges are significant. Competitors aren&#x27;t standing still, and the technical moats that protect it today may erode as causal AI techniques become better understood.But for now, Alembic occupies a unique position. It has marquee customers achieving measurable results. It has infrastructure that would cost hundreds of millions to replicate on cloud platforms. It has proprietary mathematics refined over years of dealing with messy enterprise data. And it has $145 million to scale what Puig describes as a fundamental shift from correlation to causation.In his interview with VentureBeat, Puig drew a parallel to quantitative hedge funds that use mathematics to gain trading advantages that general-purpose AI cannot match. \"ChatGPT still can&#x27;t equal Renaissance Technologies,\" he said, referring to the secretive firm that has generated historic returns through quantitative models.The comparison captures Alembic&#x27;s core insight: that in a world where everyone has access to the same general-purpose AI, sustainable advantage comes from specialized systems that understand the cause-and-effect relationships hiding in your data. It&#x27;s a bet that the future of enterprise AI looks less like a universal chatbot and more like a private intelligence engine — one that, to Puig&#x27;s original point, prevents your competitor from getting the same answer when they ask the same question.",
          "content": "Alembic Technologies has raised $145 million in Series B and growth funding at a valuation 13 times higher than its previous round, betting that the next competitive advantage in artificial intelligence will come not from better language models but from proprietary data and causal reasoning.The San Francisco-based startup, which builds AI systems that identify cause-and-effect relationships rather than mere correlations, is using a significant portion of the capital to deploy what it claims is one of the fastest privately owned supercomputers ever built — an Nvidia NVL72 superPOD that will power its enterprise-grade causal AI models.The investment, led by Prysm Capital and Accenture with participation from Silver Lake Waterman, Liquid 2 Ventures, NextEquity, Friends & Family Capital and WndrCo, positions Alembic among a select group of well-funded AI laboratories transforming how corporations make multimillion-dollar decisions.The funding round and the company&#x27;s strategic direction reflect a broader shift taking place in enterprise AI as the performance gap between competing large language models narrows. While startups and tech giants have poured billions into building ever-larger chatbots, Alembic is pursuing a different thesis: that the real value in AI will accrue to systems that can process private corporate data to answer questions that generic models cannot.\"As powerful artificial intelligence models increasingly converge in capability, the key competitive advantage shifts to proprietary data,\" said Tomás Puig, Alembic&#x27;s founder and chief executive, in an interview with VentureBeat. \"Getting a real edge isn&#x27;t about using the best LLM; it&#x27;s leveraging the unique information rivals can&#x27;t access.\"Puig illustrated the problem facing enterprise executives: \"Imagine I run a CPG company and I install the latest ChatGPT. I ask, &#x27;Hey, ChatGPT, give me a strategy for how to increase my revenue share in the northeast.&#x27; Then your competitor down the road asks the exact same question. How much trouble are you in when they get the exact same answer?\"How a broke startup on Mac Pros discovered a breakthrough that changed everythingThe dramatic valuation increase—from roughly $50 million at the Series A to approximately $645 million now, according to people familiar with the matter — reflects a fundamental transformation in Alembic&#x27;s technology and market positioning since its previous funding round.When the company raised its Series A in early 2024, it was primarily a signal processing and correlation analytics company focused on marketing measurement. \"Causal did not exist as a technology for us till after the Series A,\" Puig told VentureBeat. The company was so resource-constrained that it couldn&#x27;t even run simulations to test whether its causal models would work.The breakthrough came after the Series A when the company finally had enough capital to test its theories. \"We were so broke that we couldn&#x27;t even run the simulation to see if it worked,\" Puig recalled. When they did run the tests — initially on an \"army of Mac Pros\" because they didn&#x27;t yet have GPU infrastructure — they discovered something unexpected: their causal model worked not just for marketing analytics but across virtually any business domain with time-series data.\"We started adding capabilities as customers requested them, which was just sensible—iterative,\" Puig explained. \"We found out the model works across a huge majority of data universally. What we thought might be a model for a specific vertical ended up being a full, generalized foundational model.\"That discovery transformed Alembic from a marketing technology vendor into a company building what Puig describes as \"the entire central nervous system of the enterprise across all verticals — not just sales, marketing, supply chain, finance, and beyond.\"Why cause-and-effect AI matters more than correlation for enterprise decision-makingCausal AI is a fundamentally different approach from the correlation-based analytics that dominate most business intelligence tools and even many AI systems. Where traditional analytics might show that social media engagement correlates with sales increases, causal AI can determine whether the social media activity actually caused the sales lift — or whether both were driven by some third factor, like a viral news event.The distinction matters enormously for executives making budget allocation decisions. \"Most businesses are not short on data,\" Puig said. \"They are short on answers.\"For Alembic&#x27;s customers, which now include Delta Air Lines, Mars, Nvidia and several Fortune 500 companies across financial services, technology and consumer packaged goods, the platform can answer previously unanswerable questions about marketing effectiveness, operational efficiency and strategic investments.\"Alembic&#x27;s ability to connect marketing exposure directly to business outcomes—with speed, precision and granularity—is what made this relationship so transformative for us,\" said Alicia Tillman, chief marketing officer at Delta Air Lines. \"Unlike traditional measurement tools, Alembic gave us a unified view across channels and campaigns, unlocking insights we simply couldn&#x27;t access before.\"The airline used Alembic to quantify the revenue lift from its Team USA Olympics sponsorship within days of activation, directly linking brand activities to ticket sales—a type of measurement that has eluded marketers for decades. Traditional attribution models either ignore brand-building entirely or assign it vague \"awareness\" metrics that don&#x27;t translate to financial impact.\"It&#x27;s very transformative,\" Puig said of the customer impact. \"What&#x27;s interesting is that executives themselves are the users of our software and our outputs. It&#x27;s not a tool used by a single campaign manager.\"Inside the two-story liquid-cooled supercomputer that literally melted GPUsAlembic&#x27;s decision to invest heavily in owned computing infrastructure rather than rely on cloud providers stems from both the technical demands of its causal models and the extreme data sensitivity requirements of its enterprise customers.The company is deploying an Nvidia NVL72 superPOD — a massive liquid-cooled system equipped with Nvidia&#x27;s most advanced Blackwell graphics processing units — in partnership with data center operator Equinix in San Jose, Calif. According to Puig, Nvidia informed Alembic that it is the only non-Fortune 500 company in the world to operate such a system.The need for this level of compute stems from how Alembic&#x27;s models work. Unlike large language models that are trained once on historical data and then deployed, Alembic&#x27;s system uses \"online and evolving\" models built on spiking neural networks — brain-inspired architectures that continuously learn as new data arrives.\"It creates itself as you feed it data, like human evolution,\" Puig explained. \"The model is singular, but it ends up creating a different brain for every single company.\"This continuous learning happens at massive scale. When a customer brings in data, Alembic&#x27;s system automatically permutates through billions of possible combinations of how that data could be analyzed — testing every conceivable way to slice metrics and dimensions to find the strongest causal signals. That level of computation requires what Puig calls \"F1 car\" infrastructure rather than the \"production Porsche\" offered by cloud providers.The company writes custom CUDA code and low-level GPU kernels optimized specifically for causal inference workloads — optimizations that aren&#x27;t possible on standard cloud configurations. The approach has proven so demanding that Alembic famously once melted down its GPUs by pushing them beyond their thermal limits. \"We literally just drive these circuits so hard that we need the F1 car version and we have to have access to it,\" Puig said.The move to liquid-cooled systems addresses that problem, but it also enables Alembic to run workloads that would cost orders of magnitude more on cloud platforms. \"We did the math—if we were to buy just one subsection of our compute from AWS, it would be $62 million a year,\" Puig said. Owning the infrastructure costs \"a fraction of that.\"The supercomputer strategy serves another crucial purpose: data sovereignty. Many of Alembic&#x27;s customers — particularly in financial services, consumer packaged goods and regulated industries — have contractual prohibitions against putting sensitive data on Amazon Web Services, Microsoft Azure or Google Cloud.\"CPG companies do not want any data to exist on Amazon, ever,\" Puig said. \"They simply won&#x27;t allow it. Some customers refuse to use Microsoft, others avoid different providers. And certain banks and financial institutions are legally prohibited from using cloud platforms at all.\"By operating its own infrastructure in neutral data centers, Alembic can serve customers who would never consider cloud-based analytics — a competitive moat that would be difficult for hyperscale cloud providers to replicate.How Jensen Huang read a news article and changed Alembic&#x27;s destinyAlembic&#x27;s relationship with Nvidia illustrates both the startup&#x27;s technical ambitions and how the chip giant supports promising AI companies. Nvidia is Alembic&#x27;s founding enterprise customer, exclusive supercomputing partner and a key technical collaborator — though notably not an investor.The relationship began in an unlikely way. After Alembic announced its Series A funding in early 2024, Nvidia co-founder and CEO Jensen Huang read the VentureBeat coverage and emailed his staff suggesting they explore the company, according to Puig. Because Alembic didn&#x27;t yet have a contact form on its website, an Nvidia director reached out via LinkedIn.The partnership nearly foundered on a basic constraint: computing capacity. After Alembic delivered its first causal analysis — which took weeks to generate on an array of Mac Pros — Nvidia asked if they could produce weekly reports. \"I said no, because it took weeks on this army of machines,\" Puig recalled.When Alembic said they could do it with GPUs but couldn&#x27;t secure the necessary compute — cloud providers at the time required committee approvals and offered two- to six-week lead times with no guarantees — Nvidia intervened directly. The chip maker arranged for Equinix to provide a private cage in Northern Virginia with sufficient power capacity and helped Alembic source its first H100 GPU cluster.\"Without that, the company would never have existed,\" Puig said. \"We couldn&#x27;t get the compute in the configuration we needed anywhere else.\"The partnership has since deepened. Alembic uses Nvidia&#x27;s AI Enterprise software suite, including specialized libraries like cuGraph for graph processing and TensorRT for high-speed inference. The tight integration, Puig said, allows \"our research teams to leverage multi-exaflop-level compute and Nvidia&#x27;s algorithmic software stack. This integration is one of our secret weapons: we spend more time on breakthrough research and mathematics and less time on repetitive low-level engineering.\"Nvidia&#x27;s support extended beyond technology. When Alembic kept destroying GPUs under extreme workloads — pushing chips so hard that thermal stress cracked circuit boards — Nvidia fast-tracked the startup&#x27;s access to next-generation liquid-cooled systems. \"The funny reason we got [the NVL72],\" Puig said, \"is because when we melted the chips, Nvidia was literally annoyed with how often they had to service our warranty.\"From Olympics sponsorships to viral candy moments: How Fortune 500s measure what was unmeasurableAlembic&#x27;s customer roster has expanded rapidly as enterprises seek ways to measure AI and marketing investments that traditional analytics cannot capture. The company now works with Delta Air Lines, Mars, multiple Fortune 500 technology and financial services firms, and Texas A&M University&#x27;s athletics program.The use cases span far beyond Alembic&#x27;s original marketing focus. Mars used the platform to measure the sales impact of changing candy shapes for themed promotions. A Fortune 500 technology company expanded its sales pipeline by 37% using Alembic&#x27;s attribution models. Financial services firms are using it to connect CEO public appearances and co-marketing expenditures to actual fund flows.\"Alembic helped us move past impression counts to show what actually drove net-new investment,\" said the head of co-marketing at a Fortune 200 financial services company. \"For the first time, we could see how our CEO in the public eye and our co-marketing dollars with exchanges translated into real fund flows.\"For Mars, the ability to measure previously unmeasurable activities has transformed decision-making. \"We are using math to liberate creativity,\" said Gülen Bengi, lead global chief marketing officer for Mars and global chief growth officer for Mars Snacking. \"Our fans and communities create billions of organic conversations and content about our brands. When a viral moment happens, we normally know it&#x27;s directionally positive, but we can&#x27;t attribute the sales uplift or its place in the customer journey. Alembic&#x27;s Causal AI is a breakthrough, allowing us to move beyond correlation to see exactly how that organic conversation created a sequence that directly impacted sales.\"The platform can predict revenue, close rates and customer acquisition up to two years in advance with 95% confidence, according to Puig. \"What they were doing before was they actually literally did not know about certain things,\" he said, describing how customers previously estimated the value of stadium naming rights or major sponsorships without ever measuring actual dollar impact. \"Now you can go and be like it had this effect on this much P&L, and this is where it&#x27;s flowing, and you can know within days or near real time.\"Why Google, Meta and Nielsen can&#x27;t easily replicate what Alembic builtAlembic operates in a competitive landscape that includes traditional marketing measurement vendors like Nielsen, analytics platforms from Google and Meta, and emerging AI-powered analytics startups. But Puig argues the company has built structural advantages that would be difficult to replicate.First, the company&#x27;s causal models rely on proprietary mathematics developed over years and protected by patents. \"You would have to start from scratch,\" Puig said. \"This is not like an LLM that uses a transformer that has a paper, and you could attempt to recreate. You&#x27;d actually have to go and recreate the methodology from scratch.\"Second, the massive computing requirements create a natural barrier. Alembic operates at \"foundational model levels of compute, not like even something you would run from [AWS] Sagemaker,\" Puig said. \"We&#x27;re talking about hundreds of millions of dollars a year\" in equivalent cloud costs.Third, the data sovereignty requirements of enterprise customers create opportunities for neutral third parties that hyperscale cloud providers struggle to address. As one venture capital investor noted, enterprises increasingly worry about putting strategic data into systems owned by potential competitors.Finally, Alembic&#x27;s ability to work with messy, fragmented data reflects years of engineering that preceded its causal AI breakthrough. \"The first four [or] five years of the company&#x27;s life was building that giant signal processor that dealt with messy data,\" Puig said. \"We would not be able to do it if we had not taken all that time.\"Why Alembic&#x27;s contrarian bet on private data could reshape enterprise AIThe $145 million funding round validates a contrarian bet in an AI landscape dominated by the race to build ever-larger language models. While OpenAI, Anthropic and others compete on whose chatbot can write better code or answer more trivia questions, Alembic is building infrastructure for a different kind of intelligence — one that understands cause and effect in the messy, proprietary data that defines each company&#x27;s unique competitive position.The company&#x27;s evolution from a bootstrapped startup running simulations on Mac Pros to operating one of the world&#x27;s fastest private supercomputers mirrors the broader maturation of enterprise AI. As the technology moves from experimentation to mission-critical deployment, companies need more than general-purpose models trained on public data. They need systems that can process their private information to answer questions their competitors cannot.Puig&#x27;s thesis — that private data becomes the key differentiator as public models converge — resonates with how other technologies evolved. Search engines commoditized access to public information, making proprietary data more valuable. Cloud computing made infrastructure a utility, elevating the importance of what you build on top of it. If large language models similarly converge in capability, the competitive advantage flows to whoever can best extract intelligence from data others cannot access.The company is already testing its technology beyond marketing analytics. Pilots are underway in robotics, where causal models could help autonomous systems understand how actions lead to outcomes. New product lines are launching, including the GPU-accelerated database that customers are buying separately. The ambition, Puig said, is to become \"the central nervous system\" of the enterprise — the layer that connects cause and effect across every business function.Whether Alembic can deliver on that vision remains to be seen. The company operates in complex enterprise environments where sales cycles are long and integration challenges are significant. Competitors aren&#x27;t standing still, and the technical moats that protect it today may erode as causal AI techniques become better understood.But for now, Alembic occupies a unique position. It has marquee customers achieving measurable results. It has infrastructure that would cost hundreds of millions to replicate on cloud platforms. It has proprietary mathematics refined over years of dealing with messy enterprise data. And it has $145 million to scale what Puig describes as a fundamental shift from correlation to causation.In his interview with VentureBeat, Puig drew a parallel to quantitative hedge funds that use mathematics to gain trading advantages that general-purpose AI cannot match. \"ChatGPT still can&#x27;t equal Renaissance Technologies,\" he said, referring to the secretive firm that has generated historic returns through quantitative models.The comparison captures Alembic&#x27;s core insight: that in a world where everyone has access to the same general-purpose AI, sustainable advantage comes from specialized systems that understand the cause-and-effect relationships hiding in your data. It&#x27;s a bet that the future of enterprise AI looks less like a universal chatbot and more like a private intelligence engine — one that, to Puig&#x27;s original point, prevents your competitor from getting the same answer when they ask the same question.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1X74wYDQUVik71TsArk7Jy/74e1646a1c4505e1057cc623128925a8/nuneybits_Vector_art_of_melting_GPUs_image_in_lime_green_0fe12726-8bf9-4abe-baed-911e9574724f.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on",
          "published_at": "Wed, 12 Nov 2025 19:31:00 GMT",
          "title": "Weibo's new open source AI model VibeThinker-1.5B outperforms DeepSeek-R1 on $7,800 post-training budget",
          "standfirst": "Another day in late 2025, another impressive result from a Chinese company in open source artificial intelligence.Chinese social networking company Weibo&#x27;s AI division recently released its open source VibeThinker-1.5B—a 1.5 billion parameter large language model (LLM) that is a fine-tuned variant of rival Chinese tech firm Alibaba&#x27;s Qwen2.5-Math-1.5B. It&#x27;s available now for free download and usage by researchers and enterprise developers—even for commercial purposes—under a permissive MIT License on Hugging Face, GitHub and ModelScope, with a technical report on open access science publishing site arxiv.org.And yet, despite its compact size, VibeThinker-1.5B achieves benchmark-topping reasoning performance on math and code tasks, rivaling or surpassing models hundreds of times its size, even outperforming Chinese rival DeepSeek&#x27;s famed R1 that went viral at the start of this year—a 671-billion parameter model—on formal reasoning benchmark.It further eclipses Mistral AI&#x27;s Magistral Medium and holds its own against Anthropic&#x27;s Claude Opus 4 and OpenAI&#x27;s gpt-oss-20B Medium, all while requiring a fraction of the infrastructure and investment.It also does so having been post-trained on a budget of merely $7800 USD for compute resources (3900 GPU hours on Nvidia H800s) — far less than the tens, or even hundreds, of thousands of dollars typically required to fine-tune models of similar or larger scale.Recall this is not the total cost of the model&#x27;s development, however: LLMs are trained in stages. First comes pre-training, when the model learns basic language structure and general knowledge by predicting the next word across enormous amounts of text from the internet, books, and articles. This gives it fluency but not much sense of how to follow instructions or hold a conversationPost-training comes next, using much smaller, higher-quality datasets—typically collections of example questions, prompts, and expert-written answers—to teach the model how to respond helpfully, reason through problems, and align with human expectations. Still, Weibo&#x27;s post-training cost effectiveness on VibeThinker-1.5B is noteworthy and should be commended.The open-source release upends assumptions about parameter scale, compute intensity, and the minimum viable size for high-performance LLMs.A Different Training Approach: Spectrum-to-SignalVibeThinker-1.5B owes its performance not to scale, but to the training framework behind it: the Spectrum-to-Signal Principle (SSP).Instead of optimizing a model purely for single-answer correctness (Pass@1), the SSP framework decouples supervised fine-tuning (SFT) and reinforcement learning (RL) into two distinct phases with different goals:SFT (“Spectrum Phase”): The model is trained to maximize diversity across potential correct answers, improving its Pass@K score. This builds a wide range of plausible solution paths.RL (“Signal Phase”): A second-stage reinforcement learning system (called MaxEnt-Guided Policy Optimization, or MGPO) is used to identify and amplify the most correct paths from this diverse solution pool. MGPO prioritizes problems where the model is most uncertain, using entropy-based weighting to focus learning.The authors argue this separation allows small models to explore reasoning space more effectively—achieving signal amplification without relying on massive parameter counts.VibeThinker-1.5B makes a compelling case that the industry’s reliance on parameter scaling as the only route to better reasoning performance may be outdated. By adopting a diversity-first training pipeline, WeiboAI has shown that smaller, more accessible models can match and even outperform billion-dollar systems in logic-heavy tasks.The low resource footprint is among the most significant aspects of VibeThinker-1.5B. At under $8,000, the post-training cost is 30–60x lower than models like DeepSeek R1 and MiniMax-M1, which cost between $294K and $535K to train.Performance Across DomainsDespite its small size, VibeThinker-1.5B delivers cross-domain reasoning that outpaces many larger open-source and commercial models:ModelAIME25LiveCodeBench v6GPQA-DiamondVibeThinker-1.5B74.451.146.7GPT-OSS-20B-Medium72.154.966.0Claude Opus 469.256.679.6MiniMax M1 (456B)74.662.369.2DeepSeek R1 (671B)70.065.971.5Kimi K2 (1.09T)49.553.775.1VibeThinker was benchmarked against both reasoning-centric models (Magistral, Claude, OpenAI o3-mini) and non-reasoning LLMs (GPT-4.1, Kimi K2, DeepSeek V3). Across structured reasoning benchmarks, the model consistently outperformed non-reasoning models, regardless of size:On AIME24 (math), it beat Kimi K2 (1.09T) by over 10 points (80.3 vs. 69.6).On LiveCodeBench v6, it surpassed Claude Opus 4 (51.1 vs. 47.4).On GPQA, it scored below GPT-4.1 and Claude, but still doubled its base model (from 16.4 to 46.7).This supports the authors’ claim that size is not the only path to reasoning capability—with proper training design, smaller models can reach or even exceed the performance of far larger systems in targeted tasks.Notably, it achieves parity with models hundreds of times larger on math and code, though it lags behind in general knowledge reasoning (GPQA), where larger models maintain an edge.This suggests a potential specialization trade-off: while VibeThinker excels at structured logical tasks, it has less capacity for wide-ranging encyclopedic recall, a known limitation of smaller architectures.Guidance for Enterprise AdoptionThe release includes recommended inference settings (temperature = 0.6, top_p = 0.95, max tokens = 40960).The model is small enough to be deployed on edge devices, including mobile phones and vehicle-embedded systems, while inference costs are estimated to be 20–70x cheaper than with large models.This positions VibeThinker-1.5B not just as a research achievement, but as a potential foundation for cost-efficient, locally deployable reasoning systems.Weibo’s Strategy and Market PositionWeibo, launched by Sina Corporation in 2009, remains a cornerstone of China’s social media ecosystem. Often described as China’s version of X (formerly Twitter), the platform blends microblogging, multimedia content, and trending-topic features with a regulatory environment shaped by tight government oversight. Despite counting 600 million monthly active users (more than twice that of X), investors are not optimistic about its advertising revenue growth potential in the near term, and Weibo is navigating intensifying competition from video-first platforms like Douyin, which are drawing younger users and increasing time-spent elsewhere. In response, Weibo has leaned into creator-economy monetization, live-streaming, and vertical video—adding tools for influencer engagement, e-commerce integration, and richer analytics for brands.The platform’s role as a digital public square also makes it a focus of regulatory scrutiny. Chinese authorities continue to apply pressure on issues ranging from content governance to data security. In September 2025, Weibo was among the platforms cited in official warnings, highlighting its ongoing exposure to policy risks.Weibo’s push into AI R&D—exemplified by the release of VibeThinker-1.5B—signals a shift in ambition. Beyond being a media platform, Weibo is positioning itself as a player in the next phase of Chinese AI development, using its capital reserves, user behavior data, and in-house research capacity to pursue adjacent technical domains.What It Means for Enterprise Technical Decision MakersFor engineering leaders and enterprise AI teams, VibeThinker’s release has practical implications for everything from orchestration pipelines to cost modeling. A 1.5B-parameter model that outperforms 100x larger models on math and programming tasks doesn’t just save compute—it shifts the architectural balance. It enables LLM inference on constrained infrastructure, reduces latency at the edge, and lowers the barrier to entry for applications that otherwise would have required API access to closed, frontier-scale models.That matters for enterprise ML leads trying to deploy reasoning-capable agents within existing systems, or for platform owners tasked with integrating LLMs into automated workflows. It also speaks to those running reinforcement learning from human feedback (RLHF) pipelines or managing inference optimization across hybrid cloud environments. The model’s post-training methodology—particularly its entropy-targeted reinforcement learning approach—offers a roadmap for teams looking to refine smaller checkpoints instead of relying on large-scale pretraining.VibeThinker’s benchmark transparency and data decontamination steps also address another emerging priority in enterprise AI: auditability. While its performance on general-knowledge tests still trails large frontier models, its task-specific reliability makes it an attractive candidate for controlled environments where correctness matters more than coverage.In short, VibeThinker-1.5B isn’t just a research milestone—it’s a strong candidate for practical enterprise use, deployment and learnings. It suggests that a new class of compact, reasoning-optimized models is viable for enterprise use cases that were previously the domain of far larger systems. For organizations trying to balance cost, latency, interpretability, and control, it’s a good new option to the long, growing list of Chinese open source offerings.",
          "content": "Another day in late 2025, another impressive result from a Chinese company in open source artificial intelligence.Chinese social networking company Weibo&#x27;s AI division recently released its open source VibeThinker-1.5B—a 1.5 billion parameter large language model (LLM) that is a fine-tuned variant of rival Chinese tech firm Alibaba&#x27;s Qwen2.5-Math-1.5B. It&#x27;s available now for free download and usage by researchers and enterprise developers—even for commercial purposes—under a permissive MIT License on Hugging Face, GitHub and ModelScope, with a technical report on open access science publishing site arxiv.org.And yet, despite its compact size, VibeThinker-1.5B achieves benchmark-topping reasoning performance on math and code tasks, rivaling or surpassing models hundreds of times its size, even outperforming Chinese rival DeepSeek&#x27;s famed R1 that went viral at the start of this year—a 671-billion parameter model—on formal reasoning benchmark.It further eclipses Mistral AI&#x27;s Magistral Medium and holds its own against Anthropic&#x27;s Claude Opus 4 and OpenAI&#x27;s gpt-oss-20B Medium, all while requiring a fraction of the infrastructure and investment.It also does so having been post-trained on a budget of merely $7800 USD for compute resources (3900 GPU hours on Nvidia H800s) — far less than the tens, or even hundreds, of thousands of dollars typically required to fine-tune models of similar or larger scale.Recall this is not the total cost of the model&#x27;s development, however: LLMs are trained in stages. First comes pre-training, when the model learns basic language structure and general knowledge by predicting the next word across enormous amounts of text from the internet, books, and articles. This gives it fluency but not much sense of how to follow instructions or hold a conversationPost-training comes next, using much smaller, higher-quality datasets—typically collections of example questions, prompts, and expert-written answers—to teach the model how to respond helpfully, reason through problems, and align with human expectations. Still, Weibo&#x27;s post-training cost effectiveness on VibeThinker-1.5B is noteworthy and should be commended.The open-source release upends assumptions about parameter scale, compute intensity, and the minimum viable size for high-performance LLMs.A Different Training Approach: Spectrum-to-SignalVibeThinker-1.5B owes its performance not to scale, but to the training framework behind it: the Spectrum-to-Signal Principle (SSP).Instead of optimizing a model purely for single-answer correctness (Pass@1), the SSP framework decouples supervised fine-tuning (SFT) and reinforcement learning (RL) into two distinct phases with different goals:SFT (“Spectrum Phase”): The model is trained to maximize diversity across potential correct answers, improving its Pass@K score. This builds a wide range of plausible solution paths.RL (“Signal Phase”): A second-stage reinforcement learning system (called MaxEnt-Guided Policy Optimization, or MGPO) is used to identify and amplify the most correct paths from this diverse solution pool. MGPO prioritizes problems where the model is most uncertain, using entropy-based weighting to focus learning.The authors argue this separation allows small models to explore reasoning space more effectively—achieving signal amplification without relying on massive parameter counts.VibeThinker-1.5B makes a compelling case that the industry’s reliance on parameter scaling as the only route to better reasoning performance may be outdated. By adopting a diversity-first training pipeline, WeiboAI has shown that smaller, more accessible models can match and even outperform billion-dollar systems in logic-heavy tasks.The low resource footprint is among the most significant aspects of VibeThinker-1.5B. At under $8,000, the post-training cost is 30–60x lower than models like DeepSeek R1 and MiniMax-M1, which cost between $294K and $535K to train.Performance Across DomainsDespite its small size, VibeThinker-1.5B delivers cross-domain reasoning that outpaces many larger open-source and commercial models:ModelAIME25LiveCodeBench v6GPQA-DiamondVibeThinker-1.5B74.451.146.7GPT-OSS-20B-Medium72.154.966.0Claude Opus 469.256.679.6MiniMax M1 (456B)74.662.369.2DeepSeek R1 (671B)70.065.971.5Kimi K2 (1.09T)49.553.775.1VibeThinker was benchmarked against both reasoning-centric models (Magistral, Claude, OpenAI o3-mini) and non-reasoning LLMs (GPT-4.1, Kimi K2, DeepSeek V3). Across structured reasoning benchmarks, the model consistently outperformed non-reasoning models, regardless of size:On AIME24 (math), it beat Kimi K2 (1.09T) by over 10 points (80.3 vs. 69.6).On LiveCodeBench v6, it surpassed Claude Opus 4 (51.1 vs. 47.4).On GPQA, it scored below GPT-4.1 and Claude, but still doubled its base model (from 16.4 to 46.7).This supports the authors’ claim that size is not the only path to reasoning capability—with proper training design, smaller models can reach or even exceed the performance of far larger systems in targeted tasks.Notably, it achieves parity with models hundreds of times larger on math and code, though it lags behind in general knowledge reasoning (GPQA), where larger models maintain an edge.This suggests a potential specialization trade-off: while VibeThinker excels at structured logical tasks, it has less capacity for wide-ranging encyclopedic recall, a known limitation of smaller architectures.Guidance for Enterprise AdoptionThe release includes recommended inference settings (temperature = 0.6, top_p = 0.95, max tokens = 40960).The model is small enough to be deployed on edge devices, including mobile phones and vehicle-embedded systems, while inference costs are estimated to be 20–70x cheaper than with large models.This positions VibeThinker-1.5B not just as a research achievement, but as a potential foundation for cost-efficient, locally deployable reasoning systems.Weibo’s Strategy and Market PositionWeibo, launched by Sina Corporation in 2009, remains a cornerstone of China’s social media ecosystem. Often described as China’s version of X (formerly Twitter), the platform blends microblogging, multimedia content, and trending-topic features with a regulatory environment shaped by tight government oversight. Despite counting 600 million monthly active users (more than twice that of X), investors are not optimistic about its advertising revenue growth potential in the near term, and Weibo is navigating intensifying competition from video-first platforms like Douyin, which are drawing younger users and increasing time-spent elsewhere. In response, Weibo has leaned into creator-economy monetization, live-streaming, and vertical video—adding tools for influencer engagement, e-commerce integration, and richer analytics for brands.The platform’s role as a digital public square also makes it a focus of regulatory scrutiny. Chinese authorities continue to apply pressure on issues ranging from content governance to data security. In September 2025, Weibo was among the platforms cited in official warnings, highlighting its ongoing exposure to policy risks.Weibo’s push into AI R&D—exemplified by the release of VibeThinker-1.5B—signals a shift in ambition. Beyond being a media platform, Weibo is positioning itself as a player in the next phase of Chinese AI development, using its capital reserves, user behavior data, and in-house research capacity to pursue adjacent technical domains.What It Means for Enterprise Technical Decision MakersFor engineering leaders and enterprise AI teams, VibeThinker’s release has practical implications for everything from orchestration pipelines to cost modeling. A 1.5B-parameter model that outperforms 100x larger models on math and programming tasks doesn’t just save compute—it shifts the architectural balance. It enables LLM inference on constrained infrastructure, reduces latency at the edge, and lowers the barrier to entry for applications that otherwise would have required API access to closed, frontier-scale models.That matters for enterprise ML leads trying to deploy reasoning-capable agents within existing systems, or for platform owners tasked with integrating LLMs into automated workflows. It also speaks to those running reinforcement learning from human feedback (RLHF) pipelines or managing inference optimization across hybrid cloud environments. The model’s post-training methodology—particularly its entropy-targeted reinforcement learning approach—offers a roadmap for teams looking to refine smaller checkpoints instead of relying on large-scale pretraining.VibeThinker’s benchmark transparency and data decontamination steps also address another emerging priority in enterprise AI: auditability. While its performance on general-knowledge tests still trails large frontier models, its task-specific reliability makes it an attractive candidate for controlled environments where correctness matters more than coverage.In short, VibeThinker-1.5B isn’t just a research milestone—it’s a strong candidate for practical enterprise use, deployment and learnings. It suggests that a new class of compact, reasoning-optimized models is viable for enterprise use cases that were previously the domain of far larger systems. For organizations trying to balance cost, latency, interpretability, and control, it’s a good new option to the long, growing list of Chinese open source offerings.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4s7atIbhZpkjUNIE9NqvrE/de645440ccc36273944e9ba58f78fea7/ChatGPT_Image_Nov_12__2025__02_29_18_PM.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/how-deductive-ai-saved-doordash-1-000-engineering-hours-by-automating",
          "published_at": "Wed, 12 Nov 2025 14:00:00 GMT",
          "title": "How Deductive AI saved DoorDash 1,000 engineering hours by automating software debugging",
          "standfirst": "As software systems grow more complex and AI tools generate code faster than ever, a fundamental problem is getting worse: Engineers are drowning in debugging work, spending up to half their time hunting down the causes of software failures instead of building new products. The challenge has become so acute that it&#x27;s creating a new category of tooling — AI agents that can diagnose production failures in minutes instead of hours.Deductive AI, a startup emerging from stealth mode Wednesday, believes it has found a solution by applying reinforcement learning — the same technology that powers game-playing AI systems — to the messy, high-stakes world of production software incidents. The company announced it has raised $7.5 million in seed funding led by CRV, with participation from Databricks Ventures, Thomvest Ventures, and PrimeSet, to commercialize what it calls \"AI SRE agents\" that can diagnose and help fix software failures at machine speed.The pitch resonates with a growing frustration inside engineering organizations: Modern observability tools can show that something broke, but they rarely explain why. When a production system fails at 3 a.m., engineers still face hours of manual detective work, cross-referencing logs, metrics, deployment histories, and code changes across dozens of interconnected services to identify the root cause.\"The complexities and inter-dependencies of modern infrastructure means that investigating the root cause of an outage or incident can feel like searching for a needle in a haystack, except the haystack is the size of a football field, it&#x27;s made of a million other needles, it&#x27;s constantly reshuffling itself, and is on fire — and every second you don&#x27;t find it equals lost revenue,\" said Sameer Agarwal, Deductive&#x27;s co-founder and chief technology officer, in an exclusive interview with VentureBeat.Deductive&#x27;s system builds what the company calls a \"knowledge graph\" that maps relationships across codebases, telemetry data, engineering discussions, and internal documentation. When an incident occurs, multiple AI agents work together to form hypotheses, test them against live system evidence, and converge on a root cause — mimicking the investigative workflow of experienced site reliability engineers, but completing the process in minutes rather than hours.The technology has already shown measurable impact at some of the world&#x27;s most demanding production environments. DoorDash&#x27;s advertising platform, which runs real-time auctions that must complete in under 100 milliseconds, has integrated Deductive into its incident response workflow. The company has set an ambitious 2026 goal of resolving production incidents within 10 minutes.\"Our Ads Platform operates at a pace where manual, slow-moving investigations are no longer viable. Every minute of downtime directly affects company revenue,\" said Shahrooz Ansari, Senior Director of Engineering at DoorDash, in an interview with VentureBeat. \"Deductive has become a critical extension of our team, rapidly synthesizing signals across dozens of services and surfacing the insights that matter—within minutes.\"DoorDash estimates that Deductive has root-caused approximately 100 production incidents over the past few months, translating to more than 1,000 hours of annual engineering productivity and a revenue impact \"in millions of dollars,\" according to Ansari. At location intelligence company Foursquare, Deductive reduced the time to diagnose Apache Spark job failures by 90% —t urning a process that previously took hours or days into one that completes in under 10 minutes — while generating over $275,000 in annual savings.Why AI-generated code is creating a debugging crisisThe timing of Deductive&#x27;s launch reflects a brewing tension in software development: AI coding assistants are enabling engineers to generate code faster than ever, but the resulting software is often harder to understand and maintain.\"Vibe coding,\" a term popularized by AI researcher Andrej Karpathy, refers to using natural-language prompts to generate code through AI assistants. While these tools accelerate development, they can introduce what Agarwal describes as \"redundancies, breaks in architectural boundaries, assumptions, or ignored design patterns\" that accumulate over time.\"Most AI-generated code still introduces redundancies, breaks architectural boundaries, makes assumptions, or ignores established design patterns,\" Agarwal told Venturebeat. \"In many ways, we now need AI to help clean up the mess that AI itself is creating.\"The claim that engineers spend roughly half their time on debugging isn&#x27;t hyperbole. The Association for Computing Machinery reports that developers spend 35% to 50% of their time validating and debugging software. More recently, Harness&#x27;s State of Software Delivery 2025 report found that 67% of developers are spending more time debugging AI-generated code.\"We&#x27;ve seen world-class engineers spending half of their time debugging instead of building,\" said Rakesh Kothari, Deductive&#x27;s co-founder and CEO. \"And as vibe coding generates new code at a rate we&#x27;ve never seen, this problem is only going to get worse.\"How Deductive&#x27;s AI agents actually investigate production failuresDeductive&#x27;s technical approach differs substantially from the AI features being added to existing observability platforms like Datadog or New Relic. Most of those systems use large language models to summarize data or identify correlations, but they lack what Agarwal calls \"code-aware reasoning\"—the ability to understand not just that something broke, but why the code behaves the way it does.\"Most enterprises use multiple observability tools across different teams and services, so no vendor has a single holistic view of how their systems behave, fail, and recover—nor are they able to pair that with an understanding of the code that defines system behavior,\" Agarwal explained. \"These are key ingredients to resolving software incidents and it is exactly the gap Deductive fills.\"The system connects to existing infrastructure using read-only API access to observability platforms, code repositories, incident management tools, and chat systems. It then continuously builds and updates its knowledge graph, mapping dependencies between services and tracking deployment histories.When an alert fires, Deductive launches what the company describes as a multi-agent investigation. Different agents specialize in different aspects of the problem: one might analyze recent code changes, another examines trace data, while a third correlates the timing of the incident with recent deployments. The agents share findings and iteratively refine their hypotheses.The critical difference from rule-based automation is Deductive&#x27;s use of reinforcement learning. The system learns from every incident which investigative steps led to correct diagnoses and which were dead ends. When engineers provide feedback, the system incorporates that signal into its learning model.\"Each time it observes an investigation, it learns which steps, data sources, and decisions led to the right outcome,\" Agarwal said. \"It learns how to think through problems, not just point them out.\"At DoorDash, a recent latency spike in an API initially appeared to be an isolated service issue. Deductive&#x27;s investigation revealed that the root cause was actually timeout errors from a downstream machine learning platform undergoing a deployment. The system connected these dots by analyzing log volumes, traces, and deployment metadata across multiple services.\"Without Deductive, our team would have had to manually correlate the latency spike across all logs, traces, and deployment histories,\" Ansari said. \"Deductive was able to explain not just what changed, but how and why it impacted production behavior.\"The company keeps humans in the loop—for nowWhile Deductive&#x27;s technology could theoretically push fixes directly to production systems, the company has deliberately chosen to keep humans in the loop—at least for now.\"While our system is capable of deeper automation and could push fixes to production, currently, we recommend precise fixes and mitigations that engineers can review, validate, and apply,\" Agarwal said. \"We believe maintaining a human in the loop is essential for trust, transparency and operational safety.\"However, he acknowledged that \"over time, we do think that deeper automation will come and how humans operate in the loop will evolve.\"Databricks and ThoughtSpot veterans bet on reasoning over observabilityThe founding team brings deep expertise from building some of Silicon Valley&#x27;s most successful data infrastructure platforms. Agarwal earned his Ph.D. at UC Berkeley, where he created BlinkDB, an influential system for approximate query processing. He was among the first engineers at Databricks, where he helped build Apache Spark. Kothari was an early engineer at ThoughtSpot, where he led teams focused on distributed query processing and large-scale system optimization.The investor syndicate reflects both the technical credibility and market opportunity. Beyond CRV&#x27;s Max Gazor, the round included participation from Ion Stoica, founder of Databricks and Anyscale; Ajeet Singh, founder of Nutanix and ThoughtSpot; and Ben Sigelman, founder of Lightstep.Rather than competing with platforms like Datadog or PagerDuty, Deductive positions itself as a complementary layer that sits on top of existing tools. The pricing model reflects this: Instead of charging based on data volume, Deductive charges based on the number of incidents investigated, plus a base platform fee.The company offers both cloud-hosted and self-hosted deployment options and emphasizes that it doesn&#x27;t store customer data on its servers or use it to train models for other customers — a critical assurance given the proprietary nature of both code and production system behavior.With fresh capital and early customer traction at companies like DoorDash, Foursquare, and Kumo AI, Deductive plans to expand its team and deepen the system&#x27;s reasoning capabilities from reactive incident analysis to proactive prevention. The near-term vision: helping teams predict problems before they occur.DoorDash&#x27;s Ansari offers a pragmatic endorsement of where the technology stands today: \"Investigations that were previously manual and time-consuming are now automated, allowing engineers to shift their energy toward prevention, business impact, and innovation.\"In an industry where every second of downtime translates to lost revenue, that shift from firefighting to building increasingly looks less like a luxury and more like table stakes.",
          "content": "As software systems grow more complex and AI tools generate code faster than ever, a fundamental problem is getting worse: Engineers are drowning in debugging work, spending up to half their time hunting down the causes of software failures instead of building new products. The challenge has become so acute that it&#x27;s creating a new category of tooling — AI agents that can diagnose production failures in minutes instead of hours.Deductive AI, a startup emerging from stealth mode Wednesday, believes it has found a solution by applying reinforcement learning — the same technology that powers game-playing AI systems — to the messy, high-stakes world of production software incidents. The company announced it has raised $7.5 million in seed funding led by CRV, with participation from Databricks Ventures, Thomvest Ventures, and PrimeSet, to commercialize what it calls \"AI SRE agents\" that can diagnose and help fix software failures at machine speed.The pitch resonates with a growing frustration inside engineering organizations: Modern observability tools can show that something broke, but they rarely explain why. When a production system fails at 3 a.m., engineers still face hours of manual detective work, cross-referencing logs, metrics, deployment histories, and code changes across dozens of interconnected services to identify the root cause.\"The complexities and inter-dependencies of modern infrastructure means that investigating the root cause of an outage or incident can feel like searching for a needle in a haystack, except the haystack is the size of a football field, it&#x27;s made of a million other needles, it&#x27;s constantly reshuffling itself, and is on fire — and every second you don&#x27;t find it equals lost revenue,\" said Sameer Agarwal, Deductive&#x27;s co-founder and chief technology officer, in an exclusive interview with VentureBeat.Deductive&#x27;s system builds what the company calls a \"knowledge graph\" that maps relationships across codebases, telemetry data, engineering discussions, and internal documentation. When an incident occurs, multiple AI agents work together to form hypotheses, test them against live system evidence, and converge on a root cause — mimicking the investigative workflow of experienced site reliability engineers, but completing the process in minutes rather than hours.The technology has already shown measurable impact at some of the world&#x27;s most demanding production environments. DoorDash&#x27;s advertising platform, which runs real-time auctions that must complete in under 100 milliseconds, has integrated Deductive into its incident response workflow. The company has set an ambitious 2026 goal of resolving production incidents within 10 minutes.\"Our Ads Platform operates at a pace where manual, slow-moving investigations are no longer viable. Every minute of downtime directly affects company revenue,\" said Shahrooz Ansari, Senior Director of Engineering at DoorDash, in an interview with VentureBeat. \"Deductive has become a critical extension of our team, rapidly synthesizing signals across dozens of services and surfacing the insights that matter—within minutes.\"DoorDash estimates that Deductive has root-caused approximately 100 production incidents over the past few months, translating to more than 1,000 hours of annual engineering productivity and a revenue impact \"in millions of dollars,\" according to Ansari. At location intelligence company Foursquare, Deductive reduced the time to diagnose Apache Spark job failures by 90% —t urning a process that previously took hours or days into one that completes in under 10 minutes — while generating over $275,000 in annual savings.Why AI-generated code is creating a debugging crisisThe timing of Deductive&#x27;s launch reflects a brewing tension in software development: AI coding assistants are enabling engineers to generate code faster than ever, but the resulting software is often harder to understand and maintain.\"Vibe coding,\" a term popularized by AI researcher Andrej Karpathy, refers to using natural-language prompts to generate code through AI assistants. While these tools accelerate development, they can introduce what Agarwal describes as \"redundancies, breaks in architectural boundaries, assumptions, or ignored design patterns\" that accumulate over time.\"Most AI-generated code still introduces redundancies, breaks architectural boundaries, makes assumptions, or ignores established design patterns,\" Agarwal told Venturebeat. \"In many ways, we now need AI to help clean up the mess that AI itself is creating.\"The claim that engineers spend roughly half their time on debugging isn&#x27;t hyperbole. The Association for Computing Machinery reports that developers spend 35% to 50% of their time validating and debugging software. More recently, Harness&#x27;s State of Software Delivery 2025 report found that 67% of developers are spending more time debugging AI-generated code.\"We&#x27;ve seen world-class engineers spending half of their time debugging instead of building,\" said Rakesh Kothari, Deductive&#x27;s co-founder and CEO. \"And as vibe coding generates new code at a rate we&#x27;ve never seen, this problem is only going to get worse.\"How Deductive&#x27;s AI agents actually investigate production failuresDeductive&#x27;s technical approach differs substantially from the AI features being added to existing observability platforms like Datadog or New Relic. Most of those systems use large language models to summarize data or identify correlations, but they lack what Agarwal calls \"code-aware reasoning\"—the ability to understand not just that something broke, but why the code behaves the way it does.\"Most enterprises use multiple observability tools across different teams and services, so no vendor has a single holistic view of how their systems behave, fail, and recover—nor are they able to pair that with an understanding of the code that defines system behavior,\" Agarwal explained. \"These are key ingredients to resolving software incidents and it is exactly the gap Deductive fills.\"The system connects to existing infrastructure using read-only API access to observability platforms, code repositories, incident management tools, and chat systems. It then continuously builds and updates its knowledge graph, mapping dependencies between services and tracking deployment histories.When an alert fires, Deductive launches what the company describes as a multi-agent investigation. Different agents specialize in different aspects of the problem: one might analyze recent code changes, another examines trace data, while a third correlates the timing of the incident with recent deployments. The agents share findings and iteratively refine their hypotheses.The critical difference from rule-based automation is Deductive&#x27;s use of reinforcement learning. The system learns from every incident which investigative steps led to correct diagnoses and which were dead ends. When engineers provide feedback, the system incorporates that signal into its learning model.\"Each time it observes an investigation, it learns which steps, data sources, and decisions led to the right outcome,\" Agarwal said. \"It learns how to think through problems, not just point them out.\"At DoorDash, a recent latency spike in an API initially appeared to be an isolated service issue. Deductive&#x27;s investigation revealed that the root cause was actually timeout errors from a downstream machine learning platform undergoing a deployment. The system connected these dots by analyzing log volumes, traces, and deployment metadata across multiple services.\"Without Deductive, our team would have had to manually correlate the latency spike across all logs, traces, and deployment histories,\" Ansari said. \"Deductive was able to explain not just what changed, but how and why it impacted production behavior.\"The company keeps humans in the loop—for nowWhile Deductive&#x27;s technology could theoretically push fixes directly to production systems, the company has deliberately chosen to keep humans in the loop—at least for now.\"While our system is capable of deeper automation and could push fixes to production, currently, we recommend precise fixes and mitigations that engineers can review, validate, and apply,\" Agarwal said. \"We believe maintaining a human in the loop is essential for trust, transparency and operational safety.\"However, he acknowledged that \"over time, we do think that deeper automation will come and how humans operate in the loop will evolve.\"Databricks and ThoughtSpot veterans bet on reasoning over observabilityThe founding team brings deep expertise from building some of Silicon Valley&#x27;s most successful data infrastructure platforms. Agarwal earned his Ph.D. at UC Berkeley, where he created BlinkDB, an influential system for approximate query processing. He was among the first engineers at Databricks, where he helped build Apache Spark. Kothari was an early engineer at ThoughtSpot, where he led teams focused on distributed query processing and large-scale system optimization.The investor syndicate reflects both the technical credibility and market opportunity. Beyond CRV&#x27;s Max Gazor, the round included participation from Ion Stoica, founder of Databricks and Anyscale; Ajeet Singh, founder of Nutanix and ThoughtSpot; and Ben Sigelman, founder of Lightstep.Rather than competing with platforms like Datadog or PagerDuty, Deductive positions itself as a complementary layer that sits on top of existing tools. The pricing model reflects this: Instead of charging based on data volume, Deductive charges based on the number of incidents investigated, plus a base platform fee.The company offers both cloud-hosted and self-hosted deployment options and emphasizes that it doesn&#x27;t store customer data on its servers or use it to train models for other customers — a critical assurance given the proprietary nature of both code and production system behavior.With fresh capital and early customer traction at companies like DoorDash, Foursquare, and Kumo AI, Deductive plans to expand its team and deepen the system&#x27;s reasoning capabilities from reactive incident analysis to proactive prevention. The near-term vision: helping teams predict problems before they occur.DoorDash&#x27;s Ansari offers a pragmatic endorsement of where the technology stands today: \"Investigations that were previously manual and time-consuming are now automated, allowing engineers to shift their energy toward prevention, business impact, and innovation.\"In an industry where every second of downtime translates to lost revenue, that shift from firefighting to building increasingly looks less like a luxury and more like table stakes.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7mfhEiM01EDWrgDZYpDbte/23713914379b94e43303f9965ccc40ae/nuneybits_Vector_art_of_robot_holding_blueprint_193c9fc5-bbb5-46ea-9ff6-1a08bb03716e.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5",
          "published_at": "Wed, 12 Nov 2025 05:00:00 GMT",
          "title": "OpenAI reboots ChatGPT experience with GPT-5.1 after mixed reviews of GPT-5",
          "standfirst": "ChatGPT is about to become faster and more conversational as OpenAI upgrades its flagship model GPT-5 to GPT-5.1.OpenAI announced two updates to the GPT-5 series: GPT-5.1 Instant and GPT-5.1 Thinking. Both models are now accessible on ChatGPT. GPT-5.1 Instant, essentially the default and most-used model, is now “warmer, more intelligent, and better at following your instructions,” according to OpenAI. Meanwhile, GPT-5.1 Thinking is an advanced reasoning model that responds faster for simple tasks and more persistently on complex ones.“We heard clearly from users that great AI should not only be smart, but also enjoyable to talk to,” OpenAI said in a blog post. “GPT-5.1 improves meaningfully on both intelligence and communication style.” The company added that both models offer a way for users to “shape ChatGPT’s tone,” allowing people to control how the chat platform responds depending on the conversation they are having. Both models were rolled out to ChatGPT Pro, Plus, Go and Business users, as well as the free tier. Those on the Enterprise and Edu plans will get a seven-day early-access toggle for the models before GPT-5.1 becomes the default model. OpenAI said the models can also be accessible through the API, both with adapted reasoning. OpenAI has noted that it will soon update GPT-5 Pro to version 5.1. Instant and Thinking models The 5.1 tag reflects improvements to the base model, and OpenAI considers these part of the GPT-5 family, trained on the same stack and data as its reasoning models. The biggest difference between 5.1 and 5 is its more natural and conversational tone, OpenAI CEO for Applications Fidji Simo said in a Substack post. “Based on early testing, it often surprises people with its playfulness while remaining clear and useful,” OpenAI said in its post. Instant can use adaptive reasoning to help it decide when it needs to think about its answers, especially when it comes to more complicated questions. OpenAI noted that it has improved the model&#x27;s instruction following, so that while it continues to respond quickly, it also directly addresses the user’s query. Recent model releases, such as Baidu’s ERNIE-4.5-VL-28B-A3B-Thinking, have been outperforming GPT-5 in benchmarks like instruction-following. GPT-5.1 Thinking can figure out on its own how much reasoning power it should devote to a prompt. It adapts to the type and complexity of a query, so it will take longer to answer a fuller, complex question than a simple summary request. OpenAI said evaluations showed that GPT-5.1 Thinking spends less time and therefore uses fewer tokens on simple tasks compared to GPT-5, outperforming the base model in speed of response. One thing enterprises should note is that GPT-5.1 Thinking answers “with less jargon and fewer undefined terms.” OpenAI said removing jargony responses makes Thinking more approachable when it comes to explaining technical concepts.More personalizationAnother big update to ChatGPT is increased personalization. This allows users to toggle between a friendly and authoritative chat platform experience in their conversations. ChatGPT already allows users to choose preset options for model tone, but the new update expands these options “to better reflect the most common ways people use ChatGPT.”Options include \"default,\" \"friendly\" (formerly \"listener\"), \"efficient\" (previously \"robot\"), \"professional,\" \"candid\" and \"quirky.\" Two other personalities, \"cynical\" and \"nerdy,\" remain unchanged. “We think many people will find that GPT-5.1 does a better job of bringing IQ and EQ together, but one default clearly can’t meet everyone’s needs,\" Simo said. \"That’s why we’re also making it easier to customize ChatGPT with a range of presets to choose from. The model has the same capabilities whether you select default or one of these options, but the style of its responses will differ — more formal or familiar, more playful or direct, more or less jargon or slang. Of course, eight personalities still don&#x27;t cover the full range of human diversity, but we know from our research that many people prefer simple, guided control over too many settings or open-ended options.\"People can also adjust how much ChatGPT uses emojis. OpenAI offers granular controls for responses and is experimenting with the ability to make the models more concise, warm or scannable.Saving a rolloutOpenAI’s GPT-5 rollout was…less than perfect. While company executives, including CEO Sam Altman, touted the new model’s capabilities, a decision to initially sunset older and beloved models on ChatGPT was met with dissatisfaction. Worse yet, many early adopters found that GPT-5 didn’t perform better than older options in domains such as math, science and writing. This led Altman to walk back some of his statements around model removal, blaming performance issues on GPT-5’s router. The router, which automatically directs queries to the most suited models, is not going away, as GPT-5.1 Auto will route prompts to the model type that can best answer queries. OpenAI is careful to note that GPT-5 models Instant, Thinking and Pro are still available in ChatGPT’s model dropdown, although paid subscribers only have three months to compare these older versions with the 5.1 update. The sunset period for GPT-5, however, will not impact models like GPT-4o.“Going forward, when we introduce new ChatGPT models, our approach is to give people ample space to evaluate what’s changed and share feedback, allowing us to continue innovating our frontier models while transitioning smoothly,” the company said. “Sunset periods will be communicated clearly and with plenty of advance notice.”",
          "content": "ChatGPT is about to become faster and more conversational as OpenAI upgrades its flagship model GPT-5 to GPT-5.1.OpenAI announced two updates to the GPT-5 series: GPT-5.1 Instant and GPT-5.1 Thinking. Both models are now accessible on ChatGPT. GPT-5.1 Instant, essentially the default and most-used model, is now “warmer, more intelligent, and better at following your instructions,” according to OpenAI. Meanwhile, GPT-5.1 Thinking is an advanced reasoning model that responds faster for simple tasks and more persistently on complex ones.“We heard clearly from users that great AI should not only be smart, but also enjoyable to talk to,” OpenAI said in a blog post. “GPT-5.1 improves meaningfully on both intelligence and communication style.” The company added that both models offer a way for users to “shape ChatGPT’s tone,” allowing people to control how the chat platform responds depending on the conversation they are having. Both models were rolled out to ChatGPT Pro, Plus, Go and Business users, as well as the free tier. Those on the Enterprise and Edu plans will get a seven-day early-access toggle for the models before GPT-5.1 becomes the default model. OpenAI said the models can also be accessible through the API, both with adapted reasoning. OpenAI has noted that it will soon update GPT-5 Pro to version 5.1. Instant and Thinking models The 5.1 tag reflects improvements to the base model, and OpenAI considers these part of the GPT-5 family, trained on the same stack and data as its reasoning models. The biggest difference between 5.1 and 5 is its more natural and conversational tone, OpenAI CEO for Applications Fidji Simo said in a Substack post. “Based on early testing, it often surprises people with its playfulness while remaining clear and useful,” OpenAI said in its post. Instant can use adaptive reasoning to help it decide when it needs to think about its answers, especially when it comes to more complicated questions. OpenAI noted that it has improved the model&#x27;s instruction following, so that while it continues to respond quickly, it also directly addresses the user’s query. Recent model releases, such as Baidu’s ERNIE-4.5-VL-28B-A3B-Thinking, have been outperforming GPT-5 in benchmarks like instruction-following. GPT-5.1 Thinking can figure out on its own how much reasoning power it should devote to a prompt. It adapts to the type and complexity of a query, so it will take longer to answer a fuller, complex question than a simple summary request. OpenAI said evaluations showed that GPT-5.1 Thinking spends less time and therefore uses fewer tokens on simple tasks compared to GPT-5, outperforming the base model in speed of response. One thing enterprises should note is that GPT-5.1 Thinking answers “with less jargon and fewer undefined terms.” OpenAI said removing jargony responses makes Thinking more approachable when it comes to explaining technical concepts.More personalizationAnother big update to ChatGPT is increased personalization. This allows users to toggle between a friendly and authoritative chat platform experience in their conversations. ChatGPT already allows users to choose preset options for model tone, but the new update expands these options “to better reflect the most common ways people use ChatGPT.”Options include \"default,\" \"friendly\" (formerly \"listener\"), \"efficient\" (previously \"robot\"), \"professional,\" \"candid\" and \"quirky.\" Two other personalities, \"cynical\" and \"nerdy,\" remain unchanged. “We think many people will find that GPT-5.1 does a better job of bringing IQ and EQ together, but one default clearly can’t meet everyone’s needs,\" Simo said. \"That’s why we’re also making it easier to customize ChatGPT with a range of presets to choose from. The model has the same capabilities whether you select default or one of these options, but the style of its responses will differ — more formal or familiar, more playful or direct, more or less jargon or slang. Of course, eight personalities still don&#x27;t cover the full range of human diversity, but we know from our research that many people prefer simple, guided control over too many settings or open-ended options.\"People can also adjust how much ChatGPT uses emojis. OpenAI offers granular controls for responses and is experimenting with the ability to make the models more concise, warm or scannable.Saving a rolloutOpenAI’s GPT-5 rollout was…less than perfect. While company executives, including CEO Sam Altman, touted the new model’s capabilities, a decision to initially sunset older and beloved models on ChatGPT was met with dissatisfaction. Worse yet, many early adopters found that GPT-5 didn’t perform better than older options in domains such as math, science and writing. This led Altman to walk back some of his statements around model removal, blaming performance issues on GPT-5’s router. The router, which automatically directs queries to the most suited models, is not going away, as GPT-5.1 Auto will route prompts to the model type that can best answer queries. OpenAI is careful to note that GPT-5 models Instant, Thinking and Pro are still available in ChatGPT’s model dropdown, although paid subscribers only have three months to compare these older versions with the 5.1 update. The sunset period for GPT-5, however, will not impact models like GPT-4o.“Going forward, when we introduce new ChatGPT models, our approach is to give people ample space to evaluate what’s changed and share feedback, allowing us to continue innovating our frontier models while transitioning smoothly,” the company said. “Sunset periods will be communicated clearly and with plenty of advance notice.”",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3CpLfvpU0TfycKYEA3DBLw/f7dc8b8d4db1e3eef3d0b619d662879e/crimedy7_illustration_of_a_conversation_abstract_--ar_169_--v_5a880096-9873-4985-85ae-e8c247d831fc_0.png?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/7tpZTCavJ5IcG1LDI66Xae/5066d5c70ead90c2f63e0ef888b9a9ef/YPf93J54wCLeSJI7yvPQK.png?w=300&q=30",
      "popularity_score": 2018.7064847222223,
      "ai_summary": [
        "Proton VPN is offering a 75% discount on two-year plans for Black Friday.",
        "The deal makes the VPN Plus tier available for $2.49 per month.",
        "Proton VPN is considered a top choice for its privacy features.",
        "The VPN offers a no-logs policy and full-disk encryption.",
        "The Plus tier allows connections to 15,000 servers in over 120 countries."
      ]
    },
    {
      "id": "cluster_68",
      "coverage": 2,
      "updated_at": "Thu, 13 Nov 2025 13:10:05 -0500",
      "title": "Apple unveils Mini Apps Partner Program, offering a reduced 15% commission on IAPs for mini apps, or \"self-contained\" experiences built with web tech like HTML5 (Sarah Perez/TechCrunch)",
      "neutral_headline": "Apple unveils Mini Apps Partner Program, offering a reduced 15% commission on IAPs for mini apps, or \"self-contained\" experiences built with web tech like HTML5 (Sarah Perez/TechCrunch)",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251113/p41#a251113p41",
          "published_at": "Thu, 13 Nov 2025 13:10:05 -0500",
          "title": "Apple unveils Mini Apps Partner Program, offering a reduced 15% commission on IAPs for mini apps, or \"self-contained\" experiences built with web tech like HTML5 (Sarah Perez/TechCrunch)",
          "standfirst": "Sarah Perez / TechCrunch: Apple unveils Mini Apps Partner Program, offering a reduced 15% commission on IAPs for mini apps, or &ldquo;self-contained&rdquo; experiences built with web tech like HTML5 &mdash; Apple announced on Thursday the launch of a new developer program, the Mini Apps Partner Program &hellip;",
          "content": "Sarah Perez / TechCrunch: Apple unveils Mini Apps Partner Program, offering a reduced 15% commission on IAPs for mini apps, or &ldquo;self-contained&rdquo; experiences built with web tech like HTML5 &mdash; Apple announced on Thursday the launch of a new developer program, the Mini Apps Partner Program &hellip;",
          "feed_position": 12,
          "image_url": "http://www.techmeme.com/251113/i41.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/11/13/apple-halves-commissions-for-mini-app-makers/",
          "published_at": "Thu, 13 Nov 2025 17:32:39 +0000",
          "title": "Apple halves commissions for mini app makers",
          "standfirst": "Apple introduces a new program for app developers offering a reduced 15% commission on qualifying mini app transactions.",
          "content": "Apple introduces a new program for app developers offering a reduced 15% commission on qualifying mini app transactions.",
          "feed_position": 8
        }
      ],
      "featured_image": "http://www.techmeme.com/251113/i41.jpg",
      "popularity_score": 2014.850373611111,
      "ai_summary": [
        "Apple launched the Mini Apps Partner Program.",
        "The program offers a reduced 15% commission.",
        "The commission applies to in-app purchases in mini apps.",
        "Mini apps are \"self-contained\" experiences.",
        "They are built with web technologies like HTML5."
      ]
    },
    {
      "id": "cluster_7",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 22:10:13 +0000",
      "title": "Google claims win for everyone as text scammers lost their cloud server",
      "neutral_headline": "Google Claims Victory Over Text Scammers After Server Shutdown",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/11/google-claims-win-for-everyone-as-text-scammers-lost-their-cloud-server/",
          "published_at": "Thu, 13 Nov 2025 22:10:13 +0000",
          "title": "Google claims win for everyone as text scammers lost their cloud server",
          "standfirst": "Text scam ringleader warned operations were disrupted on Telegram, Google says.",
          "content": "The day after Google filed a lawsuit to end text scams primarily targeting Americans, the criminal network behind the phishing scams was “disrupted,” a Google spokesperson told Ars. According to messages that the “ringleader” of the so-called “Lighthouse enterprise” posted on his Telegram channel, the phishing gang’s cloud server was “blocked due to malicious complaints.” “We will restore it as soon as possible!” the leader posted on the channel—which Google’s lawsuit noted helps over 2,500 members coordinate phishing attacks that have resulted in losses of “over a billion dollars.”Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1467743069-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1467743069-1152x648.jpg",
      "popularity_score": 384.85259583333334,
      "ai_summary": [
        "Google reported disrupting a text scam operation by shutting down their cloud server.",
        "The scam ringleader warned of operational disruption on the Telegram messaging platform.",
        "Google's actions aimed to prevent further fraudulent text message distribution.",
        "The specific details of the server shutdown were not fully disclosed by Google.",
        "This action is part of Google's ongoing efforts to combat online scams."
      ]
    },
    {
      "id": "cluster_14",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 21:57:52 +0000",
      "title": "Are you ready for a $1,000 Steam Machine? Some analysts think you should be.",
      "neutral_headline": "Steam Machine Price and Market Uncertainty Discussed by Analysts",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/11/are-you-ready-for-a-1000-steam-machine-some-analysts-think-you-should-be/",
          "published_at": "Thu, 13 Nov 2025 21:57:52 +0000",
          "title": "Are you ready for a $1,000 Steam Machine? Some analysts think you should be.",
          "standfirst": "Tariffs, component volatility, and Valve's tolerance for losses all lead to uncertainty.",
          "content": "If you ask random gamers what price they think Valve will charge for its newly announced Steam Machine hardware, you’ll get a wide range of guesses. But if you ask the analysts who follow the game industry for a living the same question… well, you’ll actually get the same wide range of (somewhat better-informed) guesses. At the high end of those guesses are analysts like F-Squared‘s Michael Futter, who expects a starting price of $799 to $899 for the entry-level 512GB Steam Machine and a whopping $1,000 to $1,100 for the 2TB version. With internal specs that Futter says “will rival a PS5 and maybe even hit PS5 Pro performance,” we can expect a “hefty price tag” from Valve’s new console-like effort. At the same time, since Valve is “positioning this as a dedicated, powerful gaming PC… I suspect that the price will be below a similarly capable traditional desktop,” Futter said. DFC Intelligence analyst David Cole similarly expects the Steam Machine to start at a price “around $800” and go up to “around $1,000” for the 2TB model. Cole said he expects Valve will seek “very low margins” or even break-even pricing on the hardware itself, which he said would probably lead to pricing “below a gaming PC but slightly above a high-end console.”Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/SM_ledStrip-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/SM_ledStrip-1152x648.jpg",
      "popularity_score": 341.6467625,
      "ai_summary": [
        "Analysts are considering a potential $1,000 Steam Machine price point.",
        "Tariffs and component price volatility are factors influencing the price.",
        "Valve's tolerance for financial losses is also a key consideration.",
        "The market's reaction to a high-priced Steam Machine is uncertain.",
        "The overall success of a new Steam Machine is not guaranteed."
      ]
    },
    {
      "id": "cluster_24",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 21:11:18 +0000",
      "title": "Tiny chips hitch a ride on immune cells to sites of inflammation",
      "neutral_headline": "Tiny Chips Ride Immune Cells to Inflammation Sites",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/11/tiny-chips-hitch-a-ride-on-immune-cells-to-sites-of-inflammation/",
          "published_at": "Thu, 13 Nov 2025 21:11:18 +0000",
          "title": "Tiny chips hitch a ride on immune cells to sites of inflammation",
          "standfirst": "Tiny chips can be powered by infrared light if they're near the brain's surface.",
          "content": "Standard brain implants use electrodes that penetrate the gray matter to stimulate and record the activity of neurons. These typically need to be put in place via a surgical procedure. To go around that need, a team of researchers led by Deblina Sarkar, an electrical engineer and MIT assistant professor, developed microscopic electronic devices hybridized with living cells. Those cells can be injected into the circulatory system with a standard syringe and will travel the bloodstream before implanting themselves in target brain areas. “In the first two years of working on this technology at MIT, we’ve got 35 grant proposals rejected in a row,” Sarkar says. “Comments we got from the reviewers were that our idea was very impactful, but it was impossible.” She acknowledges that the proposal sounded like something you can find in science fiction novels. But after more than six years of research, she and her colleagues have pulled it off. Nanobot problems In 2022, when Sarkar and her colleagues gathered initial data and got some promising results with their cell-electronics hybrids, the team proposed the project for the National Institutes of Health Director’s New Innovator Award. For the first time, after 35 rejections, it made it through peer review. “We got the highest impact score ever,” Sarkar says.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/cell-chip-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/cell-chip-1152x648.jpeg",
      "popularity_score": 330.87065138888886,
      "ai_summary": [
        "Researchers are using tiny chips to target inflammation in the body.",
        "These chips can be powered by infrared light near the brain's surface.",
        "The chips are designed to hitch a ride on immune cells.",
        "This technology could potentially deliver targeted treatments.",
        "The research is still in the early stages of development."
      ]
    },
    {
      "id": "cluster_63",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 18:24:53 +0000",
      "title": "Civil war is brewing in the wasteland in Fallout S2 trailer",
      "neutral_headline": "Fallout Season Two Trailer Reveals Civil War in Wasteland",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/11/civil-war-is-brewing-in-the-wasteland-in-fallout-s2-trailer/",
          "published_at": "Thu, 13 Nov 2025 18:24:53 +0000",
          "title": "Civil war is brewing in the wasteland in Fallout S2 trailer",
          "standfirst": "Ghoulish Elvis impersonators are the least of Lucy's problems as the wasteland prepares for war.",
          "content": "We got our first glimpse of the much-anticipated second season of Fallout (adapted from the popular video game franchise) in August when Prime Video released an extended teaser. We now have the official trailer, with all the deadpan humor, explosions, and mutant atrocities one could hope for—including ghoulish Elvis impersonators in New Vegas. (Spoilers for S1 below.) As previously reported, in S1, we met Lucy MacLean (Ella Purnell), a young woman whose vault is raided by surface dwellers. The raiders kill many vault residents and kidnap her father, Hank (Kyle MacLachlan), so the sheltered Lucy sets out on a quest to find him. Life on the surface is pretty brutal, but Lucy learns fast. Along the way, she finds an ally (and love interest) in Maximus (Aaron Moten), a squire masquerading as a knight of the Brotherhood of Steel. And she runs afoul of a gunslinger and bounty hunter known as the Ghoul (Walton Goggins), a former Hollywood actor named Cooper Howard who survived the original nuclear blast, but radiation exposure turned him into, well, a ghoul.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/fallout3-1152x648-1763055623.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/fallout3-1152x648-1763055623.jpg",
      "popularity_score": 323.09704027777775,
      "ai_summary": [
        "The Fallout Season Two trailer shows a brewing civil war.",
        "Ghoulish Elvis impersonators are among the challenges.",
        "Lucy faces numerous problems in the post-apocalyptic setting.",
        "The trailer previews the conflicts and dangers of the wasteland.",
        "The season is expected to explore themes of survival and conflict."
      ]
    },
    {
      "id": "cluster_39",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 19:54:10 +0000",
      "title": "What if the aliens come and we just can’t communicate?",
      "neutral_headline": "Communicating with Aliens: A Discussion with Daniel Whiteson",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/11/what-if-the-aliens-come-and-we-just-cant-communicate/",
          "published_at": "Thu, 13 Nov 2025 19:54:10 +0000",
          "title": "What if the aliens come and we just can’t communicate?",
          "standfirst": "Ars chats with particle physicist Daniel Whiteson about his new book Do Aliens Speak Physics?",
          "content": "Science fiction has long speculated about the possibility of first contact with an alien species from a distant world and how we might be able to communicate with them. But what if we simply don’t have enough common ground for that to even be possible? An alien species is bound to be biologically very different, and their language will be shaped by their home environment, broader culture, and even how they perceive the universe. They might not even share the same math and physics. These and other fascinating questions are the focus of an entertaining new book, Do Aliens Speak Physics? And Other Questions About Science and the Nature of Reality. Co-author Daniel Whiteson is a particle physicist at the University of California, Irvine, who has worked on the ATLAS collaboration at CERN’s Large Hadron Collider. He’s also a gifted science communicator who previously co-authored two books with cartoonist Jorge Cham of PhD Comics fame: 2018’s We Have No Idea and 2021’s Frequently Asked Questions About the Universe. (The pair also co-hosted a podcast from 2018 to 2024, Daniel and Jorge Explain the Universe.) This time around, cartoonist Andy Warner provided the illustrations, and Whiteson and Warner charmingly dedicate their book to “all the alien scientists we have yet to meet.” Whiteson has long been interested in the philosophy of physics. “I’m not the kind of physicist who’s like, ‘whatever, let’s just measure stuff,'” he told Ars. “The thing that always excited me about physics was this implicit promise that we were doing something universal, that we were learning things that were true on other planets. But the more I learned, the more concerned I became that this might have been oversold. None are fundamental, and we don’t understand why anything emerges. Can we separate the human lens from the thing we’re looking at? We don’t know in the end how much that lens is distorting what we see or defining what we’re looking at. So that was the fundamental question I always wanted to explore.”Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/aliensTOP-1152x648-1762779376.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/aliensTOP-1152x648-1762779376.jpg",
      "popularity_score": 319.58509583333336,
      "ai_summary": [
        "Ars Technica interviewed particle physicist Daniel Whiteson.",
        "The interview focused on Whiteson's new book, \"Do Aliens Speak Physics?\"",
        "The book explores the challenges of communicating with extraterrestrial life.",
        "Whiteson discusses potential methods of interstellar communication.",
        "The conversation touches on the nature of physics and alien intelligence."
      ]
    },
    {
      "id": "cluster_67",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 18:11:17 +0000",
      "title": "After years of saying no, Tesla reportedly adding Apple CarPlay to its cars",
      "neutral_headline": "Tesla Reportedly Adding Apple CarPlay to Its Vehicles",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/11/after-years-of-saying-no-tesla-reportedly-adding-apple-carplay-to-its-cars/",
          "published_at": "Thu, 13 Nov 2025 18:11:17 +0000",
          "title": "After years of saying no, Tesla reportedly adding Apple CarPlay to its cars",
          "standfirst": "Almost half of US car buyers won't consider a car without Apple CarPlay.",
          "content": "Apple CarPlay, the interface that lets you cast your phone to your car’s infotainment screen, may finally be coming to Tesla’s electric vehicles. CarPlay is nearly a decade old at this point, and it has become so popular that almost half of car buyers have said they won’t consider a car without the feature, and the overwhelming majority of automakers have included CarPlay in their vehicles. Until now, that hasn’t included Tesla. CEO Elon Musk doesn’t appear to have opined on the omission, though he has frequently criticized Apple. In the past, Musk has said the goal of Tesla infotainment is to be “the most amount of fun you can have in a car.” Tesla has regularly added purile features like fart noises to the system, and it has also integrated video games that drivers can play while they charge. For customers who want to stream music, Tesla has instead offered Spotify, Tidal, and even Apple Music apps.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-998425604-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-998425604-1152x648.jpg",
      "popularity_score": 315.8703736111111,
      "ai_summary": [
        "Tesla is reportedly planning to add Apple CarPlay to its cars.",
        "Almost half of US car buyers want Apple CarPlay in their vehicles.",
        "Tesla had previously resisted integrating Apple CarPlay.",
        "The change could increase Tesla's appeal to potential buyers.",
        "The exact implementation details are still unknown."
      ]
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 17:30:50 +0000",
      "title": "Google will let Android power users bypass upcoming sideloading restrictions",
      "neutral_headline": "Google to Allow Sideloading for Android Power Users",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/google-will-let-android-power-users-bypass-upcoming-sideloading-restrictions/",
          "published_at": "Thu, 13 Nov 2025 17:30:50 +0000",
          "title": "Google will let Android power users bypass upcoming sideloading restrictions",
          "standfirst": "Google will preserve sideloading for power users, but it hasn't decided how that will work yet.",
          "content": "Google recently decided that the freedom afforded by Android was a bit too much and announced developer verification, a system that will require developers outside the Google Play platform to register with Google. Users and developers didn’t accept Google’s rationale and have been complaining loudly. As Google begins early access testing, it has conceded that “experienced users” should have an escape hatch. According to Google, online scam and malware campaigns are getting more aggressive, and there’s real harm being done in spite of the platform’s sideloading scare screens. Google says it’s common for scammers to use social engineering to create a false sense of urgency, prompting users to bypass Android’s built-in protections to install malicious apps. Google’s solution to this problem, as announced several months ago, is to force everyone making apps to verify their identities. Unverified apps won’t install on any Google-certified device once verification rolls out. Without this, the company claims malware creators can endlessly create new apps to scam people. However, the centralized nature of verification threatened to introduce numerous headaches into a process that used to be straightforward for power users.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/Android-statue-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/Android-statue-1152x648.jpg",
      "popularity_score": 299.19620694444444,
      "ai_summary": [
        "Google will allow sideloading for Android power users.",
        "The company is planning upcoming sideloading restrictions.",
        "Google has not yet decided how the power user feature will work.",
        "The move aims to balance security with user flexibility.",
        "The details of the power user program are still being developed."
      ]
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 16:30:28 +0000",
      "title": "Valve says it’s still waiting for better chips to power Steam Deck 2",
      "neutral_headline": "Valve Awaits Better Chips for Steam Deck 2",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/11/valve-says-its-still-waiting-for-better-chips-to-power-steam-deck-2/",
          "published_at": "Thu, 13 Nov 2025 16:30:28 +0000",
          "title": "Valve says it’s still waiting for better chips to power Steam Deck 2",
          "standfirst": "Even a 50 percent performance-per-watt improvement wouldn't be enough, engineer says.",
          "content": "Yesterday’s announcement of new living room and VR hardware from Valve obviously has many gamers clamoring for any news of a more powerful version of the nearly 4-year-old Steam Deck. In a new interview with IGN, though, Valve Software Engineer Pierre-Loup Griffais says that portable gaming silicon still hasn’t advanced enough to justify brand-new benchmark hardware. “The thing we’re making sure of is that it’s a worthwhile enough performance upgrade [for a Steam Deck 2] to make sense as a standalone product,” Griffais told IGN. “We’re not interested in getting to a point where it’s 20 or 30 or even 50 percent more performance at the same battery life. We want something a little bit more demarcated than that.” “So we’ve been working back from silicon advancements and architectural improvements, and I think we have a pretty good idea of what the next version of Steam Deck is going to be, but right now there’s no offerings in that landscape, in the SoC [System on a Chip] landscape, that we think would truly be a next-gen performance Steam Deck,” Griffais continued.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/11/IMG_8144-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/11/IMG_8144-1152x648.jpg",
      "popularity_score": 291.1900958333333,
      "ai_summary": [
        "Valve is waiting for better chips to power the Steam Deck 2.",
        "Even a 50 percent performance-per-watt improvement is insufficient.",
        "An engineer stated that current chip technology is inadequate.",
        "The Steam Deck 2's release is dependent on chip advancements.",
        "The company is prioritizing performance and efficiency."
      ]
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 16:11:18 +0000",
      "title": "Tracking the winds that have turned Mars into a planet of dust",
      "neutral_headline": "Mars Dust Storms and Wind Patterns Investigated",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/11/tracking-the-winds-that-have-turned-mars-into-a-planet-of-dust/",
          "published_at": "Thu, 13 Nov 2025 16:11:18 +0000",
          "title": "Tracking the winds that have turned Mars into a planet of dust",
          "standfirst": "Tracking winds across Mars' surface and their association with dust storms.",
          "content": "Mars is cold, parched, and extremely dusty. Powerful gusts of wind kick up literal tons of reddish dust that often takes the form of whorls known as dust devils. These winds also shroud the planet in dust by lifting material from the surface and blowing it into the atmosphere (what little Mars has left of an atmosphere), sometimes creating dust storms that rage for days. Researcher Valentin Bickel wanted to know just how intense winds can be on the red planet. Using data obtained by the Mars camera CaSSIS (Color and Stereo Surface Imaging System), the ExoMars Trace Gas Orbiter, and stereo camera HRSC (High Resolution Stereo Camera) on board ESA orbiter Mars Express, he and his team used deep learning to analyze stereo images that were taken seconds apart at the same location. These images can track the motion of dust devils, and the researchers use them to infer how the winds behind the dust devils move and lift dust from the surface. That dust goes on to have a big influence on the Martian weather. Bickel, of the Center for Space and Habitability at the University of Bern, noticed that the tumultuous Martian winds are even faster than previous observations had made them out to be. They carry more dust than was previously thought. “Our observations show that strong near-surface winds are abundant on Mars and play an important role in atmospheric dust sourcing, directly informing more accurate models of Mars’ atmosphere, weather, and climate,” the researchers said in a study recently published in Science Advances.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/image-1152x648-1762728374.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/image-1152x648-1762728374.jpeg",
      "popularity_score": 273.87065138888886,
      "ai_summary": [
        "Researchers are tracking winds on the surface of Mars.",
        "The study focuses on the relationship between winds and dust storms.",
        "The research aims to understand Martian weather patterns.",
        "Data is being collected to analyze dust storm formation.",
        "The findings could improve understanding of the Martian climate."
      ]
    },
    {
      "id": "cluster_94",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 15:30:49 +0000",
      "title": "Waymo to roll out driverless taxis on highways in three US cities",
      "neutral_headline": "Waymo to Launch Driverless Taxis on Highways",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/11/waymo-to-roll-out-driverless-taxis-on-highways-in-three-us-cities/",
          "published_at": "Thu, 13 Nov 2025 15:30:49 +0000",
          "title": "Waymo to roll out driverless taxis on highways in three US cities",
          "standfirst": "Alphabet will add routes in LA, Phoenix, and San Francisco for its driverless cars.",
          "content": "Waymo is set to expand its self-driving taxi service onto highways in three US cities on Wednesday, an advance for the venture owned by Google’s parent company that raises the stakes on safety. The company said it would add the high-speed roads to its routes in Los Angeles, Phoenix, and San Francisco, allowing Waymo cars to ferry passengers to more destinations including San Jose International Airport. Waymo’s rollout on highways marks a significant step for the robotaxi operator as it aims to encourage the mass adoption of driverless vehicles. It is the first time a company will carry out paid driverless services on the highway without a driver behind the wheel.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1608040724-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1608040724-1152x648.jpg",
      "popularity_score": 255.19592916666667,
      "ai_summary": [
        "Waymo will roll out driverless taxis on highways.",
        "The service will be available in three US cities.",
        "The cities include Los Angeles, Phoenix, and San Francisco.",
        "Alphabet is expanding its driverless car routes.",
        "The expansion marks a significant step for Waymo."
      ]
    },
    {
      "id": "cluster_100",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 14:00:57 +0000",
      "title": "Google is rolling out conversational shopping—and ads—in AI Mode search",
      "neutral_headline": "Google Introduces Conversational Shopping and Ads in AI Mode",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/11/google-rolling-out-conversational-shopping-and-ads-in-ai-mode-search/",
          "published_at": "Thu, 13 Nov 2025 14:00:57 +0000",
          "title": "Google is rolling out conversational shopping—and ads—in AI Mode search",
          "standfirst": "Conversational shopping is Google's first big swing at monetizing AI Mode search.",
          "content": "In recent months, Google has promised to inject generative AI into the online shopping experience, and now it’s following through. The previously announced shopping features of AI Mode search are rolling out, and Gemini will also worm its way into Google’s forgotten Duplex automated phone call tech. It’s all coming in time for the holidays to allegedly make your gifting more convenient and also conveniently ensure that Google gets a piece of the action. At Google I/O in May, the company announced its intention to bring conversational shopping to AI Mode. According to Google, its enormous “Shopping Graph” or retailer data means its AI is uniquely positioned to deliver useful suggestions. In the coming weeks, users in the US will be able to ask AI Mode complex questions about what to buy, and it will deliver suggestions, guides, tables, and other generated content to help you decide. And since this is gen AI, it comes with the usual disclaimers about possible mistakes. AI Mode shopping features. AI Mode shopping features. You’re probably wondering where you’ll see sponsored shopping content in these experiences. Google says some of the content that appears in AI Mode will be ads, just like if you look up shopping results in a traditional search. Shopping features are also coming to the Gemini app, but Google says it won’t have sponsored content in the results for the time being.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/AI-Mode-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/AI-Mode-1152x648.png",
      "popularity_score": 170.6981513888889,
      "ai_summary": [
        "Google is rolling out conversational shopping in AI Mode search.",
        "This is Google's first major attempt to monetize AI Mode search.",
        "The new feature will include advertisements.",
        "Users can engage in shopping conversations with the AI.",
        "The move aims to increase revenue from search."
      ]
    },
    {
      "id": "cluster_121",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 22:54:47 +0000",
      "title": "OpenAI walks a tricky tightrope with GPT-5.1’s eight new personalities",
      "neutral_headline": "OpenAI Walks a Tricky Tightrope with GPT-5.1’s eight new personalities",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/11/openai-walks-a-tricky-tightrope-with-gpt-5-1s-eight-new-personalities/",
          "published_at": "Wed, 12 Nov 2025 22:54:47 +0000",
          "title": "OpenAI walks a tricky tightrope with GPT-5.1’s eight new personalities",
          "standfirst": "New controls attempt to please critics on both sides with a balance between bland and habit-forming.",
          "content": "On Wednesday, OpenAI released GPT-5.1 Instant and GPT-5.1 Thinking, two updated versions of its flagship AI models now available in ChatGPT. The company is wrapping the models in the language of anthropomorphism, claiming that they’re warmer, more conversational, and better at following instructions. The release follows complaints earlier this year that its previous models were excessively cheerful and sycophantic, along with an opposing controversy among users over how OpenAI modified the default GPT-5 output style after several suicide lawsuits. The company now faces intense scrutiny from lawyers and regulators that could threaten its future operations. In that kind of environment, it’s difficult to just release a new AI model, throw out a few stats, and move on like the company could even a year ago. But here are the basics: The new GPT-5.1 Instant model will serve as ChatGPT’s faster default option for most tasks, while GPT-5.1 Thinking is a simulated reasoning model that attempts to handle more complex problem-solving tasks.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "OpenAI is introducing eight new personalities in GPT-5.1.",
        "The new controls aim to balance user experience and safety.",
        "The goal is to please critics on both sides of the debate.",
        "The personalities are designed to be both engaging and safe.",
        "The company is trying to avoid both blandness and addiction."
      ]
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 18:37:26 +0000",
      "title": "Super Mario Galaxy Movie trailer introduces Princess Rosalina",
      "neutral_headline": "Super Mario Galaxy Movie trailer introduces Princess Rosalina",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/11/nintendo-drops-official-trailer-for-super-mario-galaxy-movie/",
          "published_at": "Wed, 12 Nov 2025 18:37:26 +0000",
          "title": "Super Mario Galaxy Movie trailer introduces Princess Rosalina",
          "standfirst": "It's a sequel to 2023's Super Mario Bros. Movie, which racked up $1.36 billion at the box office.",
          "content": "The Super Mario Bros. Movie dominated the box office in 2023, racking up $1.36 billion and snagging several Oscar nominations for good measure. So naturally there’s a sequel, and Nintendo just dropped the official trailer for The Super Mario Galaxy Movie, due out next spring. (Spoilers for the 2023 film below.) The first attempt at a Super Mario movie adaptation in 1993 was notoriously a dismal failure, although it still has its ’90s-nostalgic fans. But 2023’s Super Mario Bros. Movie won over gaming fans who were skeptical about another adaption—including Ars Senior Gaming Editor Kyle Orland. “This film version captures all the fun and vibrancy of the Mario games, with enough references to familiar characters, items, and locations to make even a die-hard Mario fan’s head spin,” he wrote in his 2023 review, adding that, despite a few flaws, the film was “everything that a 10-year-old version of me could ever have dreamed a Mario movie could be.”Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/galaxy6-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/galaxy6-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "The Super Mario Galaxy Movie trailer features Princess Rosalina.",
        "It is a sequel to the 2023 Super Mario Bros. Movie.",
        "The first movie earned $1.36 billion at the box office.",
        "The new movie is expected to build on the franchise's success.",
        "The trailer showcases the visual style of the upcoming film."
      ]
    },
    {
      "id": "cluster_129",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 20:38:01 +0000",
      "title": "Microsoft releases update-fixing update for update-eligible Windows 10 PCs",
      "neutral_headline": "Microsoft Releases Update-Fixing Update for Windows 10 PCs",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/microsoft-releases-update-fixing-update-for-update-eligible-windows-10-pcs/",
          "published_at": "Wed, 12 Nov 2025 20:38:01 +0000",
          "title": "Microsoft releases update-fixing update for update-eligible Windows 10 PCs",
          "standfirst": "A bug was keeping Windows 10 PCs from enrolling in Microsoft's ESU program.",
          "content": "Officially, Windows 10 died last month, a little over a decade after its initial release. But the old operating system’s enduring popularity has prompted Microsoft to promise between one and three years of Extended Security Updates (ESUs) for many Windows 10 PCs. For individuals with Windows 10 PCs, it’s relatively easy to get an additional year of updates at no cost. Or at least, it’s supposed to be. Bugs initially identified by Windows Latest were keeping some Windows 10 PCs from successfully enrolling in the ESU program, preventing those PCs from signing up to grab the free updates. And because each Windows 10 PC has to be manually enrolled in the program, a broken enrollment process also meant broken security updates. To fix the problems, Microsoft released an update for Windows 10 22H2 (KB5071959) this week that both acknowledges and fixes an issue “where the enrollment wizard may fail during enrollment.” It’s being offered to all Windows 10 PCs regardless of whether they’re enrolled in the ESU program “as it resolves an issue that was preventing affected customers from receiving essential security updates.”Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/12/win10-new-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/12/win10-new-1152x648.jpg",
      "popularity_score": 145,
      "ai_summary": [
        "Microsoft released an update to fix an update issue.",
        "The bug prevented Windows 10 PCs from enrolling in ESU.",
        "The ESU program provides extended security updates.",
        "The fix allows eligible PCs to receive security updates.",
        "The update addresses a critical issue for Windows 10 users."
      ]
    },
    {
      "id": "cluster_96",
      "coverage": 1,
      "updated_at": "Thu, 13 Nov 2025 15:09:52 +0000",
      "title": "What would a “simplified” Starship plan for the Moon actually look like?",
      "neutral_headline": "Simplified Starship Plan for the Moon Examined",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/what-would-a-simplified-starship-plan-for-the-moon-actually-look-like/",
          "published_at": "Thu, 13 Nov 2025 15:09:52 +0000",
          "title": "What would a “simplified” Starship plan for the Moon actually look like?",
          "standfirst": "The problem is that it may be difficult to find options that both NASA and SpaceX like.",
          "content": "In what will likely be his most consequential act as NASA’s interim leader, Sean Duffy said last month that the space agency was “opening up” its competition to develop a lunar lander that will put humans on the surface of the Moon. As part of this move, Duffy asked NASA’s current lunar lander contractors, SpaceX and Blue Origin, for more nimble plans. Neither has specified those plans publicly, but a recent update from SpaceX referenced a “simplified” version of the Starship system it’s building to help NASA return humans to the Moon. “Since the contract was awarded, we have been consistently responsive to NASA as requirements for Artemis III have changed and have shared ideas on how to simplify the mission to align with national priorities,” the company said. “In response to the latest calls, we’ve shared and are formally assessing a simplified mission architecture and concept of operations that we believe will result in a faster return to the Moon while simultaneously improving crew safety.”Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/07_24_25_HLS_on_surface_elevator_down_4d48994673-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/07_24_25_HLS_on_surface_elevator_down_4d48994673-1152x648.jpg",
      "popularity_score": 144.8467625,
      "ai_summary": [
        "The article explores a \"simplified\" Starship plan for the Moon.",
        "The challenge is finding options acceptable to NASA and SpaceX.",
        "The plan's feasibility is being assessed.",
        "The goal is to streamline the lunar mission.",
        "The discussion involves potential compromises and solutions."
      ]
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 22:12:36 +0000",
      "title": "With another record broken, the world’s busiest spaceport keeps getting busier",
      "neutral_headline": "Spaceport Launches Continue to Break Records",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/with-another-record-broken-the-worlds-busiest-spaceport-keeps-getting-busier/",
          "published_at": "Wed, 12 Nov 2025 22:12:36 +0000",
          "title": "With another record broken, the world’s busiest spaceport keeps getting busier",
          "standfirst": "It's not just the number of rocket launches, but how much stuff they're carrying into orbit.",
          "content": "CAPE CANAVERAL, Florida—Another Falcon 9 rocket fired off its launch pad here on Monday night, taking with it another 29 Starlink Internet satellites to orbit. This was the 94th orbital launch from Florida’s Space Coast so far in 2025, breaking the previous record for the most satellite launches in a calendar year from the world’s busiest spaceport. Monday night’s launch came two days after a Chinese Long March 11 rocket lifted off from an oceangoing platform on the opposite side of the world, marking humanity’s 255th mission to reach orbit this year, a new annual record for global launch activity. As of Wednesday, a handful of additional missions have pushed the global figure this year to 259, putting the world on pace for around 300 orbital launches by the end of 2025. This will more than double the global tally of 135 orbital launches in 2021.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IMG_9791-1-1152x648-1762927742.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IMG_9791-1-1152x648-1762927742.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "The world's busiest spaceport is experiencing an increase in rocket launches.",
        "Launches are carrying more cargo into orbit than ever before.",
        "The trend indicates a growing demand for space-based services.",
        "This increase reflects advancements in launch technology and efficiency.",
        "The spaceport's activity highlights the expansion of the space industry."
      ]
    },
    {
      "id": "cluster_133",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 19:17:52 +0000",
      "title": "Audi goes full minimalism for its first-ever Formula 1 livery",
      "neutral_headline": "Audi Unveils Minimalist Formula 1 Livery",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/11/audi-goes-full-minimalism-for-its-first-ever-formula-1-livery/",
          "published_at": "Wed, 12 Nov 2025 19:17:52 +0000",
          "title": "Audi goes full minimalism for its first-ever Formula 1 livery",
          "standfirst": "Audi says it wants to be an F1 title contender by 2030.",
          "content": "Audi provided flights from Washington, DC, to Munich and accommodation so Ars could visit its motorsports facility and see its F1 car. Ars does not accept paid editorial content. MUNICH, Germany—Audi’s long-awaited Formula 1 team gave the world its first look at what the Audi R26 will look like when it takes to the track next year. Well, sort of—the car you see here is a generic show car for the 2026 aero regulations, but the livery you see, plus the sponsors’ logos, will race next year. “By entering the pinnacle of motorsport, Audi is making a clear, ambitious statement. It is the next chapter in the company’s renewal. Formula 1 will be a catalyst for the change towards a leaner, faster, and more innovative Audi,” said Gernot Döllner, Audi’s CEO. “We are not entering Formula 1 just to be there. We want to win. At the same time, we know that you don’t become a top team in Formula 1 overnight. It takes time, perseverance, and tireless questioning of the status quo. By 2030, we want to fight for the World Championship title,” Döllner said. After the complicated liveries of cars like the R18 or Audi's Formula E program, the R26 is refreshingly simple. Credit: Jonathan Gitlin None of the sponsors have been announced yet, so the car is bare for now. Credit: Jonathan Gitlin The view Audi hopes its rivals get next year. Credit: Jonathan Gitlin Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Audi-F1-livery-reveal-8-of-9-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Audi-F1-livery-reveal-8-of-9-1152x648.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "Audi has revealed its first Formula 1 livery, emphasizing minimalism.",
        "The company aims to be a Formula 1 title contender by the year 2030.",
        "The livery design reflects Audi's branding strategy for the sport.",
        "This move signifies Audi's commitment to Formula 1 racing.",
        "The design is intended to create a distinct visual identity."
      ]
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 20:28:52 +0000",
      "title": "An explosion 92 million miles away just grounded Jeff Bezos’ New Glenn rocket",
      "neutral_headline": "Bezos' New Glenn Rocket Launch Postponed",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/an-explosion-92-million-miles-away-just-grounded-jeff-bezos-new-glenn-rocket/",
          "published_at": "Wed, 12 Nov 2025 20:28:52 +0000",
          "title": "An explosion 92 million miles away just grounded Jeff Bezos’ New Glenn rocket",
          "standfirst": "\"NASA is postponing launch until space weather conditions improve.\"",
          "content": "CAPE CANAVERAL, Florida—The second flight of Blue Origin’s New Glenn rocket was postponed again Wednesday as a supercharged wave of magnetized plasma from the Sun enveloped the Earth, triggering colorful auroral displays and concerns over possible impacts to communications, navigation, and power grids. Solar storms like the one this week can also affect satellite operations. That is the worry that caused NASA to hold off on launching a pair of science probes from Cape Canaveral Space Force Station, Florida, on Wednesday aboard Blue Origin’s New Glenn rocket. In a statement, Blue Origin said NASA, its customer on the upcoming launch, decided to postpone the mission to send the agency’s two ESCAPADE spacecraft on a journey to Mars.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Oct_2_M7pt3_Flare_171-304-131_Crop-1152x648-1762966677.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Oct_2_M7pt3_Flare_171-304-131_Crop-1152x648-1762966677.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "NASA postponed the launch of Jeff Bezos' New Glenn rocket.",
        "The delay is due to unfavorable space weather conditions.",
        "The launch was scheduled to occur 92 million miles away.",
        "The postponement impacts the rocket's planned mission timeline.",
        "The decision prioritizes the safety of the launch."
      ]
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 19:53:07 +0000",
      "title": "Well-received big-budget Alien Earth TV series gets a second season",
      "neutral_headline": "Alien Earth TV Series Gets Second Season",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/11/alien-earth-and-series-creator-noah-hawley-will-return-for-season-2/",
          "published_at": "Wed, 12 Nov 2025 19:53:07 +0000",
          "title": "Well-received big-budget Alien Earth TV series gets a second season",
          "standfirst": "Production will move from Thailand to London, suggesting a new setting.",
          "content": "Alien Earth will return to FX (and Disney+ and Hulu) for a second season, thanks to a new deal between Disney and series creator Noah Hawley. The new season has no air date yet, but we do know one thing about it: It will be shot in London. The first season was shot in Thailand, and most of the story took place in Southeast Asia, so the change in shooting location suggests a new setting for much of the next season. Production on season two will reportedly begin next year. For those who watched season one to its conclusion, season two probably seemed like a sure thing; the finale resolved many of the core conflicts of that first batch of episodes, but also was clearly intended to be the launching point for a new storyline in season two.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/alien-earth-facehugger-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/alien-earth-facehugger-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "The big-budget Alien Earth TV series has been renewed for a second season.",
        "Production will move from Thailand to London for the new season.",
        "This suggests a potential change in the series' setting.",
        "The series received positive reviews after its initial release.",
        "The renewal indicates the show's success and popularity."
      ]
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Wed, 12 Nov 2025 18:59:38 +0000",
      "title": "Quantum computing tech keeps edging forward",
      "neutral_headline": "Quantum Computing Technology Advances",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/11/quantum-roundup-lots-of-companies-announcing-new-tech/",
          "published_at": "Wed, 12 Nov 2025 18:59:38 +0000",
          "title": "Quantum computing tech keeps edging forward",
          "standfirst": "IBM follows through on its June promises, plus more trapped ion news.",
          "content": "The end of the year is usually a busy time in the quantum computing arena, as companies often try to announce that they’ve reached major milestones before the year wraps up. This year has been no exception. And while not all of these announcements involve interesting new architectures like the one we looked at recently, they’re a good way to mark progress in the field, and they often involve the sort of smaller, incremental steps needed to push the field forward. What follows is a quick look at a handful of announcements from the past few weeks that struck us as potentially interesting. IBM follows through IBM is one of the companies announcing a brand-new architecture this year. That’s not at all a surprise, given that the company promised to do so back in June; this week sees the company confirming that it has built the two processors it said it would earlier in the year. These include one called Loon, which is focused on the architecture that IBM will use to host error-corrected logical qubits. Loon represents two major changes for the company: a shift to nearest-neighbor connections and the addition of long-distance connections.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IBM-Quantum-Loon-Wafer_2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/IBM-Quantum-Loon-Wafer_2-1152x648.jpg",
      "popularity_score": 130,
      "ai_summary": [
        "IBM is following through on its June promises regarding quantum computing.",
        "There is also news regarding trapped ion technology.",
        "These advancements represent progress in the field of quantum computing.",
        "The developments contribute to the evolution of quantum computing capabilities.",
        "The news highlights ongoing research and development efforts."
      ]
    }
  ]
}