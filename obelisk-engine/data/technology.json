{
  "updated_at": "2025-10-23T11:17:14.275Z",
  "clusters": [
    {
      "id": "cluster_4",
      "coverage": 2,
      "updated_at": "Thu, 23 Oct 2025 11:00:00 +0000",
      "title": "Samsung's Galaxy XR doesn't give me much hope for Android XR",
      "neutral_headline": "Samsung Galaxy XR Mixed Reality Headset Released",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/samsungs-galaxy-xr-doesnt-give-me-much-hope-for-android-xr-110000129.html",
          "published_at": "Thu, 23 Oct 2025 11:00:00 +0000",
          "title": "Samsung's Galaxy XR doesn't give me much hope for Android XR",
          "standfirst": "So Samsung made a \"Vision Pro Lite.\" That was my immediate takeaway after this week's debut of the Galaxy XR, the first Android XR device to hit the market. While Samsung deserves credit for offering something close to the Vision Pro for nearly half the price, an $1,800 headset still won't get mainstream consumers rushing out the door to experience the wonders of mixed reality. And with the limited amount of content in Android XR at the moment, the Galaxy XR is in the same position as the Vision Pro: It's just a well-polished developer kit. The only logical reason to buy a Galaxy XR would be to test out apps for Android XR. If you just want to experience VR and dabble in a bit of augmented reality, you're better off spending that money on a gaming laptop and the excellent $500 Meta Quest 3. (The Meta Quest Pro, the company’s first high-end mixed reality device, was unceremoniously killed after launching at an eye-watering $1,500.) But even for developers, the Galaxy XR feels like it's lacking, well, vision. Samsung has done an admirable job of copying almost every aspect of the Vision Pro: The sleek ski goggle design, dual micro-OLED displays and hand gesture interaction powered by a slew of cameras and sensors. But while Apple positioned the Vision Pro as its first stab at spatial computing, an exciting new platform where we can use interactive apps in virtual space, Samsung and Google are basically just gunning to put Android on your face. There aren't many custom-built XR apps, aside from Google's offerings like Maps and Photos. (Something that also reminds me of the dearth of real tablet apps on Android.) And the ability to view 360-degree videos on YouTube has been a staple of every VR headset for the last decade — it's not exactly notable on something that costs $1,800. Samsung and Google also haven't said much about how they plan to elevate XR content. At least Apple is attempting to push the industry forward with its 8K Immersive Videos, which look sharper and more realistic than low-res 360-degree content.For the most part, it seems as if Google is treating Android XR as another way to force its Gemini AI on users. In its press release for the Galaxy XR, Samsung notes that it's \"introducing a new category of AI-native devices designed to deliver immersive experiences in a form factor optimized for multimodal AI.\" …What? In addition to being a crime against the English language, what the company is actually pitching is fairly simple: It's just launching a headset that can access AI features via camera and voice inputs. Who knows, maybe Gemini will make Android XR devices more capable down the line. But at the moment, all I'm seeing in the Galaxy XR is another Samsung device that's shamelessly aping Apple, from the virtual avatars to specific pinch gestures. And Google's history in VR and interactive content doesn't inspire much hope about Android XR. Don't forget how it completely abandoned Google Cardboard, the short-lived Daydream project and its hyped up Stadia cloud service. Stadia's death was particularly galling, since Google initially pitched it as a way to revolutionize the very world of gaming, only to let it fall on its face.There’s no doubt that Samsung, Apple and Meta have a ton of work left ahead in the world of XR. Samsung is at least closer to delivering something under $1,000, and Meta also recently launched the $800 Ray-Ban Display. But price is only one part of the problem. Purpose is another issue entirely. After living with the Vision Pro since its debut, I can tell that Apple is at least thinking a bit more deeply about what it’s like to wear a computer on your face. Just look at the upgrades its made around ultra-wide Mac mirroring, or the way Spatial Personas make it feel as if you’re working alongside other people. With Android XR, Google seems to just be making a more open Vision Pro.Honestly, it’s unclear if normal users will ever want to use any sort of XR headset regularly, no matter how cheap they get. The experience making these headsets could help Google, Apple and Meta develop future AR glasses, or eyewear that offer some sort of XR experience (Samsung already has something in the works with Warby Parker and Gentle Monster). But while Apple and Meta have broken new ground in XR, Google and Samsung just seem to be following in their footsteps.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsungs-galaxy-xr-doesnt-give-me-much-hope-for-android-xr-110000129.html?src=rss",
          "content": "So Samsung made a \"Vision Pro Lite.\" That was my immediate takeaway after this week's debut of the Galaxy XR, the first Android XR device to hit the market. While Samsung deserves credit for offering something close to the Vision Pro for nearly half the price, an $1,800 headset still won't get mainstream consumers rushing out the door to experience the wonders of mixed reality. And with the limited amount of content in Android XR at the moment, the Galaxy XR is in the same position as the Vision Pro: It's just a well-polished developer kit. The only logical reason to buy a Galaxy XR would be to test out apps for Android XR. If you just want to experience VR and dabble in a bit of augmented reality, you're better off spending that money on a gaming laptop and the excellent $500 Meta Quest 3. (The Meta Quest Pro, the company’s first high-end mixed reality device, was unceremoniously killed after launching at an eye-watering $1,500.) But even for developers, the Galaxy XR feels like it's lacking, well, vision. Samsung has done an admirable job of copying almost every aspect of the Vision Pro: The sleek ski goggle design, dual micro-OLED displays and hand gesture interaction powered by a slew of cameras and sensors. But while Apple positioned the Vision Pro as its first stab at spatial computing, an exciting new platform where we can use interactive apps in virtual space, Samsung and Google are basically just gunning to put Android on your face. There aren't many custom-built XR apps, aside from Google's offerings like Maps and Photos. (Something that also reminds me of the dearth of real tablet apps on Android.) And the ability to view 360-degree videos on YouTube has been a staple of every VR headset for the last decade — it's not exactly notable on something that costs $1,800. Samsung and Google also haven't said much about how they plan to elevate XR content. At least Apple is attempting to push the industry forward with its 8K Immersive Videos, which look sharper and more realistic than low-res 360-degree content.For the most part, it seems as if Google is treating Android XR as another way to force its Gemini AI on users. In its press release for the Galaxy XR, Samsung notes that it's \"introducing a new category of AI-native devices designed to deliver immersive experiences in a form factor optimized for multimodal AI.\" …What? In addition to being a crime against the English language, what the company is actually pitching is fairly simple: It's just launching a headset that can access AI features via camera and voice inputs. Who knows, maybe Gemini will make Android XR devices more capable down the line. But at the moment, all I'm seeing in the Galaxy XR is another Samsung device that's shamelessly aping Apple, from the virtual avatars to specific pinch gestures. And Google's history in VR and interactive content doesn't inspire much hope about Android XR. Don't forget how it completely abandoned Google Cardboard, the short-lived Daydream project and its hyped up Stadia cloud service. Stadia's death was particularly galling, since Google initially pitched it as a way to revolutionize the very world of gaming, only to let it fall on its face.There’s no doubt that Samsung, Apple and Meta have a ton of work left ahead in the world of XR. Samsung is at least closer to delivering something under $1,000, and Meta also recently launched the $800 Ray-Ban Display. But price is only one part of the problem. Purpose is another issue entirely. After living with the Vision Pro since its debut, I can tell that Apple is at least thinking a bit more deeply about what it’s like to wear a computer on your face. Just look at the upgrades its made around ultra-wide Mac mirroring, or the way Spatial Personas make it feel as if you’re working alongside other people. With Android XR, Google seems to just be making a more open Vision Pro.Honestly, it’s unclear if normal users will ever want to use any sort of XR headset regularly, no matter how cheap they get. The experience making these headsets could help Google, Apple and Meta develop future AR glasses, or eyewear that offer some sort of XR experience (Samsung already has something in the works with Warby Parker and Gentle Monster). But while Apple and Meta have broken new ground in XR, Google and Samsung just seem to be following in their footsteps.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsungs-galaxy-xr-doesnt-give-me-much-hope-for-android-xr-110000129.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-noise-canceling-headphones-130029881.html",
          "published_at": "Thu, 23 Oct 2025 09:00:35 +0000",
          "title": "The best noise-canceling headphones for 2025",
          "standfirst": "Whether you're working in a noisy office, commuting on a packed train or just trying to focus at home, a good pair of noise-canceling headphones can make all the difference. The best noise-canceling headphones block out distractions and let you enjoy your music, podcasts or calls in peace — all while delivering great sound quality and all-day comfort. From models with plush cushions to wireless cans with loads of extra features, there’s something here for every style and budget. Table of contents Best noise-canceling headphones for 2025 How to choose the best noise-canceling headphones for you How we test noise-canceling headphones Other noise-canceling headphones we tested Noise-canceling headphones FAQs Best noise-canceling headphones of 2025 How to choose the best noise-canceling headphones for you Design When you’re shopping for the best wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of this guide, I focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear, active noise-canceling headphones are much more effective at blocking outside sounds since your ears are completely covered. For gamers, there are also gaming headsets that feature noise cancellation — some even have detachable microphones, so they can double as over-ear headphones. However, for the purpose of this article, we’re only going to be focusing on noise-canceling headphones rather than headsets. Look for models with a comfortable headband and memory foam ear cups to ensure you can wear them for long periods without discomfort. Many headphones also come with a range of color options, so if aesthetics matter to you, you’ll find plenty of choices beyond just black or white. Whether you’re looking for something neutral or a bold pop of color, brands now offer a variety of styles to match your personal taste. Finally, if you’re planning to wear your headphones for long periods of time, it’s important to pick a model with a comfortable fit. Memory foam ear cups, an adjustable headband, and lightweight materials can make all the difference during extended listening sessions. After all, great sound is only part of the equation; comfort matters just as much. Type of noise cancellation Next, you’ll want to look at the type of ANC a set of headphones offers. You’ll come across terms like “hybrid active noise cancellation” or “hybrid adaptive active noise cancellation,” and there are key differences between the two. A hybrid ANC setup uses microphones on the inside and on the outside of the device to detect outside noise and cancel it out. By analyzing input from both mics, a hybrid system can combat more sounds than “regular” ANC, but it does so at a constant level that doesn’t change. Adaptive ANC takes the hybrid configuration a step further by continuously adjusting the noise cancellation for changes in your environment and any leakage around the padding of the ear cups. Adaptive noise-canceling also does a better job with wind noise, which can really kill your vibe while using headphones outdoors. Some high-end headphones also support Dolby Atmos, which enhances spatial audio and makes everything from music to movies sound more immersive. For the purposes of this best headphones list, I’m only considering products with hybrid ANC or adaptive ANC setups because those are the most effective at blocking noise and improving your overall listening experience. Customization You’ll also want to check to see if the ANC system on a prospective set of headphones offers adjustable levels of noise cancellation or presets. These can help you dial in the amount of ANC you need for various environments, but it can also help you save battery life. Master & Dynamic, for example, has ANC presets that provide both maximum noise blocking and more efficient cancellation that is more energy efficient. Other companies may include a slider in their companion apps that let you adjust the ANC level to your liking. Some high-end models even allow you to fine-tune the ANC for specific types of environments. How we test noise-canceling headphones The primary way we test headphones is to wear them as much as possible. I prefer to do this over a one-to-two-week period, but sometimes deadlines don’t allow it. During this time, I listen to a mix of music and podcasts, while also using the headphones to take both voice and video calls. Since battery life for headphones can be 30 hours or more, I drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, I’ll typically power the headphones off several times and leave them that way during a review. This simulates real-world use and keeps me from having to constantly monitor the process for over 24 straight hours. To test ANC performance specifically, I use headphones in a variety of environments, from noisy coffee shops to quiet home offices. When my schedule allows, I use them during air travel since plane noise is a massive distraction to both work and relaxation. Even if I can’t hop on a flight, I’ll simulate a constant roar with white noise machines, bathroom fans, vacuums and more. I also make note of how well each device blocks human voices, which are a key stumbling block for a lot of ANC headphones. ANC-related features are something else to consider. Here, I do a thorough review of companion apps, testing each feature as I work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones I’m testing are an updated version of a previous model, I’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that I review. Other noise-canceling headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancellation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor, which is actually handy. All told, that’s not a lot for a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 is more expensive and not nearly as comfortable as the Px7 S3. Noble Audio FoKus Apollo While this is my top pick for overall sound quality in our main guide to the best wireless headphones, the ANC performance is less impressive than the Px7 S3. Bowers & Wilkins gets the nod here for its improved noise cancellation over the Px7 S2 and Px7 S2e, and its overall excellent audio quality. Noise-canceling headphones FAQs Does noise cancellation block all noise? Noise cancellation doesn’t block out all noise, though it does drastically reduce the volume of most external sounds. Is there a difference between wired vs wireless noise-canceling headphones? In terms of sound quality, if you have two headphones — one wired and one wireless — with similar specs, the difference is going to be very minimal. However, wireless headphones offer more convenience, allowing you to move around more freely with your headphones on, which is why they often feature noise cancellation to minimize external sounds. Does noise cancellation impact sound quality? ANC does bear some weight on sound quality, but the impact of this often doesn’t outweigh the benefits. Noise cancellation reduces ambient noise, allowing a greater focus on audio detail. For audiophiles, however, there may be a small difference in sound fidelity when ANC is turned on.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-noise-canceling-headphones-130029881.html?src=rss",
          "content": "Whether you're working in a noisy office, commuting on a packed train or just trying to focus at home, a good pair of noise-canceling headphones can make all the difference. The best noise-canceling headphones block out distractions and let you enjoy your music, podcasts or calls in peace — all while delivering great sound quality and all-day comfort. From models with plush cushions to wireless cans with loads of extra features, there’s something here for every style and budget. Table of contents Best noise-canceling headphones for 2025 How to choose the best noise-canceling headphones for you How we test noise-canceling headphones Other noise-canceling headphones we tested Noise-canceling headphones FAQs Best noise-canceling headphones of 2025 How to choose the best noise-canceling headphones for you Design When you’re shopping for the best wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of this guide, I focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear, active noise-canceling headphones are much more effective at blocking outside sounds since your ears are completely covered. For gamers, there are also gaming headsets that feature noise cancellation — some even have detachable microphones, so they can double as over-ear headphones. However, for the purpose of this article, we’re only going to be focusing on noise-canceling headphones rather than headsets. Look for models with a comfortable headband and memory foam ear cups to ensure you can wear them for long periods without discomfort. Many headphones also come with a range of color options, so if aesthetics matter to you, you’ll find plenty of choices beyond just black or white. Whether you’re looking for something neutral or a bold pop of color, brands now offer a variety of styles to match your personal taste. Finally, if you’re planning to wear your headphones for long periods of time, it’s important to pick a model with a comfortable fit. Memory foam ear cups, an adjustable headband, and lightweight materials can make all the difference during extended listening sessions. After all, great sound is only part of the equation; comfort matters just as much. Type of noise cancellation Next, you’ll want to look at the type of ANC a set of headphones offers. You’ll come across terms like “hybrid active noise cancellation” or “hybrid adaptive active noise cancellation,” and there are key differences between the two. A hybrid ANC setup uses microphones on the inside and on the outside of the device to detect outside noise and cancel it out. By analyzing input from both mics, a hybrid system can combat more sounds than “regular” ANC, but it does so at a constant level that doesn’t change. Adaptive ANC takes the hybrid configuration a step further by continuously adjusting the noise cancellation for changes in your environment and any leakage around the padding of the ear cups. Adaptive noise-canceling also does a better job with wind noise, which can really kill your vibe while using headphones outdoors. Some high-end headphones also support Dolby Atmos, which enhances spatial audio and makes everything from music to movies sound more immersive. For the purposes of this best headphones list, I’m only considering products with hybrid ANC or adaptive ANC setups because those are the most effective at blocking noise and improving your overall listening experience. Customization You’ll also want to check to see if the ANC system on a prospective set of headphones offers adjustable levels of noise cancellation or presets. These can help you dial in the amount of ANC you need for various environments, but it can also help you save battery life. Master & Dynamic, for example, has ANC presets that provide both maximum noise blocking and more efficient cancellation that is more energy efficient. Other companies may include a slider in their companion apps that let you adjust the ANC level to your liking. Some high-end models even allow you to fine-tune the ANC for specific types of environments. How we test noise-canceling headphones The primary way we test headphones is to wear them as much as possible. I prefer to do this over a one-to-two-week period, but sometimes deadlines don’t allow it. During this time, I listen to a mix of music and podcasts, while also using the headphones to take both voice and video calls. Since battery life for headphones can be 30 hours or more, I drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, I’ll typically power the headphones off several times and leave them that way during a review. This simulates real-world use and keeps me from having to constantly monitor the process for over 24 straight hours. To test ANC performance specifically, I use headphones in a variety of environments, from noisy coffee shops to quiet home offices. When my schedule allows, I use them during air travel since plane noise is a massive distraction to both work and relaxation. Even if I can’t hop on a flight, I’ll simulate a constant roar with white noise machines, bathroom fans, vacuums and more. I also make note of how well each device blocks human voices, which are a key stumbling block for a lot of ANC headphones. ANC-related features are something else to consider. Here, I do a thorough review of companion apps, testing each feature as I work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones I’m testing are an updated version of a previous model, I’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that I review. Other noise-canceling headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancellation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor, which is actually handy. All told, that’s not a lot for a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 is more expensive and not nearly as comfortable as the Px7 S3. Noble Audio FoKus Apollo While this is my top pick for overall sound quality in our main guide to the best wireless headphones, the ANC performance is less impressive than the Px7 S3. Bowers & Wilkins gets the nod here for its improved noise cancellation over the Px7 S2 and Px7 S2e, and its overall excellent audio quality. Noise-canceling headphones FAQs Does noise cancellation block all noise? Noise cancellation doesn’t block out all noise, though it does drastically reduce the volume of most external sounds. Is there a difference between wired vs wireless noise-canceling headphones? In terms of sound quality, if you have two headphones — one wired and one wireless — with similar specs, the difference is going to be very minimal. However, wireless headphones offer more convenience, allowing you to move around more freely with your headphones on, which is why they often feature noise cancellation to minimize external sounds. Does noise cancellation impact sound quality? ANC does bear some weight on sound quality, but the impact of this often doesn’t outweigh the benefits. Noise cancellation reduces ambient noise, allowing a greater focus on audio detail. For audiophiles, however, there may be a small difference in sound fidelity when ANC is turned on.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-noise-canceling-headphones-130029881.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/fujifilms-x-t30-iii-adds-a-film-simulation-dial-and-6k-video-072148245.html",
          "published_at": "Thu, 23 Oct 2025 07:21:48 +0000",
          "title": "Fujifilm's X-T30 III adds a film simulation dial and 6K video",
          "standfirst": "When Fujifilm launched the X-T50 last year, no one was sure what would happen with its aging X-T30 lineup. The company just answered that question with the launch of the X-T30 III, boosting the speed and improving autofocus of the last model, while adding a film simulation dial seen on other recent models. It's very light for travel or street photography, but has some powerful features like 6.2K video and subject-detect autofocus, all at a reasonable price. The original X-T30 first arrived in 2019 and was replaced in 2022 by the X-T30 II that was more of a mild update than an all-new camera. However, the X-T30 III has a number of key updates that bring it in line with other recent models like the X-M5 and X-T50. It does have the same 26.1MP X-Trans sensor as before (with a 1.5x crop compared to a full-frame camera), but now uses Fujifilm's latest image processor that doubles image processing speed and significantly improves video capabilities. Ryan Tuttle for Fujifilm The X-T30 III is meant to be taken on adventures, so it's still very light at just 378 grams or 13.33 ounces, a touch less than the previous model. Control-wise, the biggest addition is a film simulation dial just like the one on the X-M5 and X-T50, replacing the mode dial from the X-T30 II. It's designed to make it easy to switch between film simulations like Reala Ace and Nostalgic Neg, while offering three customizable positions to let users save \"recipes\" of their own making. Otherwise, the X-T30 III has a generous complement of dials and buttons something that allows for precise control but may intimidate newbies. The rear display tilts up but doesn't flip out, and the 2.36-million-dot electronic viewfinder is on the low end for resolution. The main feature missing on the X-T30 III is in-body stabilization, so you'll need either a stabilized (OIS) lens or electronic stabilization for video. Fujjifilm Burst shooting speeds are the same as before at 8 fps with the mechanical shutter and 20 fps in electronic mode. However, more of your shots are likely to be sharp thanks to the updated, faster autofocus. Along with the extra speed, Fujifilm introduced new AI subject detection modes including Auto-Tracking, Animals, Birds and Vehicles. Video also gets a big upgrade. The X-T30 III can now shot 6.2K 30 fps video using the entire sensor (up from 4K 30p before), or 4K at 60 fps with a mild 1.18x crop. All of those resolutions are available with 10-bit modes to boost dynamic range. However, the X-T30 III lacks in-body stabilization, has a weird 2.5mm microphone input and a display that only tilts and doesn't flip out. That makes it fine as a hybrid camera, but if you mostly shoot video, a model like the X-S20 may be a better choice. Fujifilm Other key features include a microHDMI port for RAW video output, a single SD memory card (that's of the low-speed UHS-I variety unfortunately), and improved battery life with up to 425 shots to a charge. Fujifilm also introduced a new lens, the Fujinon XC13-33mmF3.5-6.3 OIS that offers an interesting ultrawide full-frame equivalent zoom range of around 20-50mm. The X-T30 III is now on pre-order for $999 in multiple colors (black, charcoal silver and silver) with shipping set to start in November 2025. The Fujinon XC13-33mmF3.5-6.3 OIS will also ship around the same time for $399. This article originally appeared on Engadget at https://www.engadget.com/cameras/fujifilms-x-t30-iii-adds-a-film-simulation-dial-and-6k-video-072148245.html?src=rss",
          "content": "When Fujifilm launched the X-T50 last year, no one was sure what would happen with its aging X-T30 lineup. The company just answered that question with the launch of the X-T30 III, boosting the speed and improving autofocus of the last model, while adding a film simulation dial seen on other recent models. It's very light for travel or street photography, but has some powerful features like 6.2K video and subject-detect autofocus, all at a reasonable price. The original X-T30 first arrived in 2019 and was replaced in 2022 by the X-T30 II that was more of a mild update than an all-new camera. However, the X-T30 III has a number of key updates that bring it in line with other recent models like the X-M5 and X-T50. It does have the same 26.1MP X-Trans sensor as before (with a 1.5x crop compared to a full-frame camera), but now uses Fujifilm's latest image processor that doubles image processing speed and significantly improves video capabilities. Ryan Tuttle for Fujifilm The X-T30 III is meant to be taken on adventures, so it's still very light at just 378 grams or 13.33 ounces, a touch less than the previous model. Control-wise, the biggest addition is a film simulation dial just like the one on the X-M5 and X-T50, replacing the mode dial from the X-T30 II. It's designed to make it easy to switch between film simulations like Reala Ace and Nostalgic Neg, while offering three customizable positions to let users save \"recipes\" of their own making. Otherwise, the X-T30 III has a generous complement of dials and buttons something that allows for precise control but may intimidate newbies. The rear display tilts up but doesn't flip out, and the 2.36-million-dot electronic viewfinder is on the low end for resolution. The main feature missing on the X-T30 III is in-body stabilization, so you'll need either a stabilized (OIS) lens or electronic stabilization for video. Fujjifilm Burst shooting speeds are the same as before at 8 fps with the mechanical shutter and 20 fps in electronic mode. However, more of your shots are likely to be sharp thanks to the updated, faster autofocus. Along with the extra speed, Fujifilm introduced new AI subject detection modes including Auto-Tracking, Animals, Birds and Vehicles. Video also gets a big upgrade. The X-T30 III can now shot 6.2K 30 fps video using the entire sensor (up from 4K 30p before), or 4K at 60 fps with a mild 1.18x crop. All of those resolutions are available with 10-bit modes to boost dynamic range. However, the X-T30 III lacks in-body stabilization, has a weird 2.5mm microphone input and a display that only tilts and doesn't flip out. That makes it fine as a hybrid camera, but if you mostly shoot video, a model like the X-S20 may be a better choice. Fujifilm Other key features include a microHDMI port for RAW video output, a single SD memory card (that's of the low-speed UHS-I variety unfortunately), and improved battery life with up to 425 shots to a charge. Fujifilm also introduced a new lens, the Fujinon XC13-33mmF3.5-6.3 OIS that offers an interesting ultrawide full-frame equivalent zoom range of around 20-50mm. The X-T30 III is now on pre-order for $999 in multiple colors (black, charcoal silver and silver) with shipping set to start in November 2025. The Fujinon XC13-33mmF3.5-6.3 OIS will also ship around the same time for $399. This article originally appeared on Engadget at https://www.engadget.com/cameras/fujifilms-x-t30-iii-adds-a-film-simulation-dial-and-6k-video-072148245.html?src=rss",
          "feed_position": 2,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c61cba10-afdd-11f0-9fff-ba497027a57e"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html",
          "published_at": "Thu, 23 Oct 2025 07:00:37 +0000",
          "title": "The best wireless earbuds for 2025",
          "standfirst": "Wireless earbuds have become the go-to choice for listening on the move. Whether you’re at the gym, commuting or relaxing at home, the best wireless earbuds give you comfort, freedom and solid sound quality without tangled cables. They’re lightweight, slip easily into your pocket and connect quickly to your phone, tablet or laptop.The tricky part is choosing the right pair. Some models focus on powerful noise cancellation while others put battery life or affordability first. Then you’ve got features like water resistance for workouts or touch controls for quick track changes. With so many choices, finding the best wireless earbuds depends on what matters most to you, and that’s exactly what this guide will help you figure out. Table of contents Best wireless earbuds of 2025 What to look for in the best wireless earbuds How we test wireless earbuds Other wireless earbuds we tested Wireless earbuds FAQs Best wireless earbuds of 2025 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds. July 2024: Updated our list to include the Samsung Galaxy Buds 3 Pro.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "content": "Wireless earbuds have become the go-to choice for listening on the move. Whether you’re at the gym, commuting or relaxing at home, the best wireless earbuds give you comfort, freedom and solid sound quality without tangled cables. They’re lightweight, slip easily into your pocket and connect quickly to your phone, tablet or laptop.The tricky part is choosing the right pair. Some models focus on powerful noise cancellation while others put battery life or affordability first. Then you’ve got features like water resistance for workouts or touch controls for quick track changes. With so many choices, finding the best wireless earbuds depends on what matters most to you, and that’s exactly what this guide will help you figure out. Table of contents Best wireless earbuds of 2025 What to look for in the best wireless earbuds How we test wireless earbuds Other wireless earbuds we tested Wireless earbuds FAQs Best wireless earbuds of 2025 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds. July 2024: Updated our list to include the Samsung Galaxy Buds 3 Pro.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/amazons-smart-glasses-with-ai-will-help-its-drivers-deliver-packages-faster-041009681.html",
          "published_at": "Thu, 23 Oct 2025 04:10:09 +0000",
          "title": "Amazon's smart glasses with AI will help its drivers deliver packages faster",
          "standfirst": "Amazon has revealed that it's currently working on smart glasses designed for delivery drivers, confirming previous reports about the project. The company said that glasses use AI-powered sensing capabilities and computer vision to detect what their cameras are seeing. Drivers then get guidance through the glasses' heads-up display (HUD) embedded right into the lens. Based on Amazon's announcement, it's been working on the glasses for a while, and hundreds of delivery drivers had already tested early versions to provide the company with feedback. The glasses automatically activate after the driver parks their vehicle. They then show users the right packages to deliver, according to their location. Users will see the list of packages they have to take out on the HUD, and the glasses can even tell them if they pull out the right package from their pile. When they get out of their vehicle, the glasses will display turn-by-turn navigation to the delivery address and will also show them hazards along the way, as well as help them navigate complex locations like apartment buildings. Simply put, the device allows them to find delivery addresses and drop off packages without having to use their phones. Drivers will even be able to capture proof of delivery with the wearable. Amazon's glasses will be paired with a vest that's fitted with a controller and a dedicated emergency button drivers can press to call emergency services along their routes. The device comes with a swappable battery to ensure all-day use and can be fitted with prescription and transitional lenses if the drivers need them. Amazon expects future versions of the glasses to be able to notify drivers if they're dropping a package at the wrong address and to be able to detect and notify them about more hazardous elements, like if there's a pet in the yard. In the annual event wherein the company announced the device, Amazon transportation vice president Beryl Tomay said it \"reduces the need to manage a phone and a package\" and helps drivers \"stay at attention, which enhances their safety.\" She also said that among the testers, Amazon had seen time savings of 30 minutes for a given shit. The company didn't say anything about developing smart glasses for consumers, but The Information's previous report said that it's also working on a model for the general public slated to be released in late 2026 or early 2027. This article originally appeared on Engadget at https://www.engadget.com/wearables/amazons-smart-glasses-with-ai-will-help-its-drivers-deliver-packages-faster-041009681.html?src=rss",
          "content": "Amazon has revealed that it's currently working on smart glasses designed for delivery drivers, confirming previous reports about the project. The company said that glasses use AI-powered sensing capabilities and computer vision to detect what their cameras are seeing. Drivers then get guidance through the glasses' heads-up display (HUD) embedded right into the lens. Based on Amazon's announcement, it's been working on the glasses for a while, and hundreds of delivery drivers had already tested early versions to provide the company with feedback. The glasses automatically activate after the driver parks their vehicle. They then show users the right packages to deliver, according to their location. Users will see the list of packages they have to take out on the HUD, and the glasses can even tell them if they pull out the right package from their pile. When they get out of their vehicle, the glasses will display turn-by-turn navigation to the delivery address and will also show them hazards along the way, as well as help them navigate complex locations like apartment buildings. Simply put, the device allows them to find delivery addresses and drop off packages without having to use their phones. Drivers will even be able to capture proof of delivery with the wearable. Amazon's glasses will be paired with a vest that's fitted with a controller and a dedicated emergency button drivers can press to call emergency services along their routes. The device comes with a swappable battery to ensure all-day use and can be fitted with prescription and transitional lenses if the drivers need them. Amazon expects future versions of the glasses to be able to notify drivers if they're dropping a package at the wrong address and to be able to detect and notify them about more hazardous elements, like if there's a pet in the yard. In the annual event wherein the company announced the device, Amazon transportation vice president Beryl Tomay said it \"reduces the need to manage a phone and a package\" and helps drivers \"stay at attention, which enhances their safety.\" She also said that among the testers, Amazon had seen time savings of 30 minutes for a given shit. The company didn't say anything about developing smart glasses for consumers, but The Information's previous report said that it's also working on a model for the general public slated to be released in late 2026 or early 2027. This article originally appeared on Engadget at https://www.engadget.com/wearables/amazons-smart-glasses-with-ai-will-help-its-drivers-deliver-packages-faster-041009681.html?src=rss",
          "feed_position": 4
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/what-enterprises-can-take-away-from-microsoft-ceo-satya-nadellas-shareholder",
          "published_at": "Thu, 23 Oct 2025 01:34:00 GMT",
          "title": "What enterprises can take away from Microsoft CEO Satya Nadella's shareholder letter",
          "standfirst": "One of the leading architects of the current generative AI boom — Microsoft CEO Satya Nadella, famed for having the software giant take an early investment in OpenAI (and later saying he was \"good for my $80 billion\") — published his latest annual letter yesterday on LinkedIn (a Microsoft subsidiary), and it&#x27;s chock full of interesting ideas about the near-term future that enterprise technical decision makers would do well to pay attention to, as it could aid in their own planning and tech stack development.In a companion post on X, Nadella wrote, “AI is radically changing every layer of the tech stack, and we’re changing with it.\" The full letter reinforces that message: Microsoft sees itself not just participating in the AI revolution, but shaping its infrastructure, security, tooling and governance for decades to come.While the message is addressed to Microsoft shareholders, the implications reach much further. The letter is a strategic signal to enterprise engineering leaders: CIOs, CTOs, AI leads, platform architects and security directors. Nadella outlines the direction of Microsoft’s innovation, but also what it expects from its customers and partners. The AI era is here, but it will be built by those who combine technical vision with operational discipline.Below are the five most important takeaways for enterprise technical decision makers.1. Security and reliability are now the foundation of the AI stackNadella makes security the first priority in the letter and ties it directly to Microsoft’s relevance going forward. Through its Secure Future Initiative (SFI), Microsoft has assigned the equivalent of 34,000 engineers to secure its identity systems, networks and software supply chain. Its Quality Excellence Initiative (QEI) aims to increase platform resiliency and strengthen global service uptime.Microsoft’s positioning makes it clear that enterprises will no longer get away with “ship fast, harden later” AI deployments. Nadella calls security “non-negotiable,” signaling that AI infrastructure must now meet the standards of mission-critical software. That means identity-first architecture, zero-trust execution environments and change management discipline are now table stakes for enterprise AI.2. AI infrastructure strategy is hybrid, open and sovereignty-readyNadella commits Microsoft to building “planet-scale systems” and backs that up with numbers: more than 400 Azure datacenters across 70 regions, two gigawatts of new compute capacity added this year, and new liquid-cooled GPU clusters rolling out across Azure. Microsoft also introduced Fairwater, a massive new AI datacenter in Wisconsin positioned to deliver unprecedented scale. Just as important, Microsoft is now officially multi-model. Azure AI Foundry offers access to more than 11,000 models including OpenAI, Meta, Mistral, Cohere and xAI. Microsoft is no longer pushing a single-model future, but a hybrid AI strategy.Enterprises should interpret this as validation of “portfolio architectures,” where closed, open and domain-specific models coexist. Nadella also emphasizes growing investment in sovereign cloud offerings for regulated industries, previewing a world where AI systems will have to meet regional data residency and compliance requirements from day one.3. AI agents—not just chatbots—are now Microsoft’s futureThe AI shift inside Microsoft is no longer about copilots that answer questions. It is now about AI agents that perform work. Nadella points to the rollout of Agent Mode in Microsoft 365 Copilot, which turns natural language requests into multistep business workflows. GitHub Copilot evolves from code autocomplete into a “peer programmer” capable of executing tasks asynchronously. In security operations, Microsoft has deployed AI agents that autonomously respond to incidents. In healthcare, Copilot for Dragon Medical documents clinical encounters automatically.This represents a major architectural pivot. Enterprises will need to move beyond prompt-response interfaces and begin engineering agent ecosystems that safely take actions inside business systems. That requires workflow orchestration, API integration strategies and strong guardrails. Nadella’s letter frames this as the next software platform shift.4. Unified data platforms are required to unlock AI valueNadella devotes significant attention to Microsoft Fabric and OneLake, calling Fabric the company’s fastest-growing data and analytics product ever. Fabric promises to centralize enterprise data from multiple cloud and analytics environments. OneLake provides a universal storage layer that binds analytics and AI workloads together.Microsoft’s message is blunt: siloed data means stalled AI. Enterprise teams that want AI at scale must unify operational and analytical data into a single architecture, enforce consistent data contracts and standardize metadata governance. AI success is now a data engineering problem more than a model problem.5. Trust, compliance and responsible AI are now mandatory for deployment“People want technology they can trust,” Nadella writes. Microsoft now publishes Responsible AI Transparency Reports and aligns parts of its development process with UN human rights guidance. Microsoft is also committing to digital resilience in Europe and proactive safeguards against misuse of AI-generated content.This shifts responsible AI out of the realm of corporate messaging and into engineering practice. Enterprises will need model documentation, reproducibility practices, audit trails, risk monitoring and human-in-the-loop checkpoints. Nadella signals that compliance will become integrated with product delivery—not an afterthought layered on top.The real meaning of Microsoft’s AI strategyTaken together, these five pillars send a clear message to enterprise leaders: AI maturity is no longer about building prototypes or proving use cases. System-level readiness now defines success. Nadella frames Microsoft’s mission as helping customers “think in decades and execute in quarters,” and that is more than corporate poetry. It is a call to build AI platforms engineered for longevity.The companies that win in enterprise AI will be the ones that invest early in secure cloud foundations, unify their data architectures, enable agent-based workflows and embrace responsible AI as a prerequisite for scale—not a press release. Nadella is betting that the next industrial transformation will be powered by AI infrastructure, not AI demos. With this letter, he has made Microsoft’s ambition clear: to become the platform on which that transformation is built.",
          "content": "One of the leading architects of the current generative AI boom — Microsoft CEO Satya Nadella, famed for having the software giant take an early investment in OpenAI (and later saying he was \"good for my $80 billion\") — published his latest annual letter yesterday on LinkedIn (a Microsoft subsidiary), and it&#x27;s chock full of interesting ideas about the near-term future that enterprise technical decision makers would do well to pay attention to, as it could aid in their own planning and tech stack development.In a companion post on X, Nadella wrote, “AI is radically changing every layer of the tech stack, and we’re changing with it.\" The full letter reinforces that message: Microsoft sees itself not just participating in the AI revolution, but shaping its infrastructure, security, tooling and governance for decades to come.While the message is addressed to Microsoft shareholders, the implications reach much further. The letter is a strategic signal to enterprise engineering leaders: CIOs, CTOs, AI leads, platform architects and security directors. Nadella outlines the direction of Microsoft’s innovation, but also what it expects from its customers and partners. The AI era is here, but it will be built by those who combine technical vision with operational discipline.Below are the five most important takeaways for enterprise technical decision makers.1. Security and reliability are now the foundation of the AI stackNadella makes security the first priority in the letter and ties it directly to Microsoft’s relevance going forward. Through its Secure Future Initiative (SFI), Microsoft has assigned the equivalent of 34,000 engineers to secure its identity systems, networks and software supply chain. Its Quality Excellence Initiative (QEI) aims to increase platform resiliency and strengthen global service uptime.Microsoft’s positioning makes it clear that enterprises will no longer get away with “ship fast, harden later” AI deployments. Nadella calls security “non-negotiable,” signaling that AI infrastructure must now meet the standards of mission-critical software. That means identity-first architecture, zero-trust execution environments and change management discipline are now table stakes for enterprise AI.2. AI infrastructure strategy is hybrid, open and sovereignty-readyNadella commits Microsoft to building “planet-scale systems” and backs that up with numbers: more than 400 Azure datacenters across 70 regions, two gigawatts of new compute capacity added this year, and new liquid-cooled GPU clusters rolling out across Azure. Microsoft also introduced Fairwater, a massive new AI datacenter in Wisconsin positioned to deliver unprecedented scale. Just as important, Microsoft is now officially multi-model. Azure AI Foundry offers access to more than 11,000 models including OpenAI, Meta, Mistral, Cohere and xAI. Microsoft is no longer pushing a single-model future, but a hybrid AI strategy.Enterprises should interpret this as validation of “portfolio architectures,” where closed, open and domain-specific models coexist. Nadella also emphasizes growing investment in sovereign cloud offerings for regulated industries, previewing a world where AI systems will have to meet regional data residency and compliance requirements from day one.3. AI agents—not just chatbots—are now Microsoft’s futureThe AI shift inside Microsoft is no longer about copilots that answer questions. It is now about AI agents that perform work. Nadella points to the rollout of Agent Mode in Microsoft 365 Copilot, which turns natural language requests into multistep business workflows. GitHub Copilot evolves from code autocomplete into a “peer programmer” capable of executing tasks asynchronously. In security operations, Microsoft has deployed AI agents that autonomously respond to incidents. In healthcare, Copilot for Dragon Medical documents clinical encounters automatically.This represents a major architectural pivot. Enterprises will need to move beyond prompt-response interfaces and begin engineering agent ecosystems that safely take actions inside business systems. That requires workflow orchestration, API integration strategies and strong guardrails. Nadella’s letter frames this as the next software platform shift.4. Unified data platforms are required to unlock AI valueNadella devotes significant attention to Microsoft Fabric and OneLake, calling Fabric the company’s fastest-growing data and analytics product ever. Fabric promises to centralize enterprise data from multiple cloud and analytics environments. OneLake provides a universal storage layer that binds analytics and AI workloads together.Microsoft’s message is blunt: siloed data means stalled AI. Enterprise teams that want AI at scale must unify operational and analytical data into a single architecture, enforce consistent data contracts and standardize metadata governance. AI success is now a data engineering problem more than a model problem.5. Trust, compliance and responsible AI are now mandatory for deployment“People want technology they can trust,” Nadella writes. Microsoft now publishes Responsible AI Transparency Reports and aligns parts of its development process with UN human rights guidance. Microsoft is also committing to digital resilience in Europe and proactive safeguards against misuse of AI-generated content.This shifts responsible AI out of the realm of corporate messaging and into engineering practice. Enterprises will need model documentation, reproducibility practices, audit trails, risk monitoring and human-in-the-loop checkpoints. Nadella signals that compliance will become integrated with product delivery—not an afterthought layered on top.The real meaning of Microsoft’s AI strategyTaken together, these five pillars send a clear message to enterprise leaders: AI maturity is no longer about building prototypes or proving use cases. System-level readiness now defines success. Nadella frames Microsoft’s mission as helping customers “think in decades and execute in quarters,” and that is more than corporate poetry. It is a call to build AI platforms engineered for longevity.The companies that win in enterprise AI will be the ones that invest early in secure cloud foundations, unify their data architectures, enable agent-based workflows and embrace responsible AI as a prerequisite for scale—not a press release. Nadella is betting that the next industrial transformation will be powered by AI infrastructure, not AI demos. With this letter, he has made Microsoft’s ambition clear: to become the platform on which that transformation is built.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/12n5mLIJNuMXqnrlrdiiFR/6c9b04ccb83f975ed619174db8c202c6/cfr0z3n_httpss.mj.runM4mKVYlCu30_Cut_and_paste_collage_style_ph_780082c3-eb52-4012-ad6c-016de100662a__1_.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/the-first-e-bike-from-rivian-spinoff-also-has-a-virtual-drivetrain-173000250.html",
          "published_at": "Wed, 22 Oct 2025 21:29:41 +0000",
          "title": "The first e-bike from Rivian spinoff Also has a virtual drivetrain",
          "standfirst": "Ever since Rivian spun off its \"micromobility business\" into a standalone startup called Also earlier this year, there's been much speculation about what kind of vehicles the company is working on. Now, Also is showing off its first products: a lineup of e-bikes and two pedal-assisted electric quads. The TM-B e-bike is Also's attempt at a do-it-all e-bike that can adapt to different use cases whether that's daily commuting, trail riding or kid and cargo-hauling. It sports a modular frame that can also accommodate a bench seat or rear cargo rack that supports up to 35KG of weight. The different seats can be easily swapped out without extra tools. Instead, a button on the bike’s touchscreen display controls a latching mechanism that releases the seat. It only comes in one frame size, but Also says it should be able to adapt to \"multiple body sizes,” thanks to different seat sizes and styles. The bench seat for the TM-B.Karissa Bell for EngadgetThe removable USB-C battery comes in two sizes: standard, which can power up to 60 miles of riding, and large, which maxes out at 100 miles of range. When you’re not riding, the batteries can also be used as a large external battery pack.In terms of power, the TM-B’s throttle tops out at 20MPH though the bike can reach speeds up to 28MPH with added pedaling. Also is taking an interesting approach to its drive system, with a setup it's labeled \"DreamRide.\" Instead of a mechanical connection between the bike's rear wheel and the pedals, the TM-B uses \"software-defined pedaling,\" In practice, this means that you pedaling is actually feeding the generator that powers the bike’s battery rather than directly pushing you forward. However, an Also rep told me that there is also a “limp mode” for when the bike runs out of juice so riders won’t get stranded. In those situations, pedaling will give the bike enough juice to hopefully get you to a spot where you can recharge.Also has envisioned the TM-B in a lot of scenarios, many of which involve hauling a lot of cargo.Karissa Bell for EngadgetSoftware-controlled pedaling probably won’t appeal to purists, but Also says it enables a much more customizable riding experience. When in auto mode, the bike will adapt to the speed you’re pedaling, though you can push on the throttle to get a boost. There’s also a manual mode that lets you select a “gear” (these are also software-controlled). It also uses regenerative braking, so tapping on the brakes helps recharge the battery. Though in my short test ride I found that I didn’t need to use the brakes much, because when I stopped pedaling the bike slowed down pretty quickly, kind of like taking your foot off the accelerator in an EV.The Also app and Portal display.AlsoGiven the bike's roots at Rivian, it's not surprising that there are also a bunch of other tech-enabled features, including a 5-inch touchscreen display, called \"Portal,\" that supports navigation, music playback and calling features via an accompanying app. There’s also a built-in security system that automatically locks the frame and rear wheel when you walk away. On the handlebars, there are customizable controls that can be used to adjust the volume and music playback, answer calls or navigate through display. Customizable controls on the left side fo the handlebar and a throttle on the right.Karissa Bell for EngadgetAlso is selling the TM-B in three configurations. The first to ship next spring will be the $4,500 TM-B Limited Launch Edition, which has a range up to 100 miles, support for standard and sport ride modes and features transparent purple accents. The $4,500 TM-B Performance has the same features as the limited edition model, but has a slightly different color scheme, and will be available within the \"first half\" of 2026. Finally, there's a base-level TM-B model with a range of up to 60 miles that only comes with standard ride modes. Also hasn't announced an exact price, but says it will cost less than $4,000 when it ships \"later in 2026.\" Pre-orders for the Launch Edition are open now and the other two bikes are available to reserve with a $50 deposit. The bikes will also be on display in Rivian showrooms later this year,Also's quad for commercial uses cases (left) and a smaller quad for families (right).AlsoThe company also previewed two electric, pedal-assisted quads it's calling TM-Q. The smaller quad is apparently meant for \"families and individuals seeking a safe, compact alternative to cars\" that can still haul “significant loads.” The larger TM-Q, on the other hand, is meant for commercial deliveries. Also has partnered with Amazon to develop fleets of such vehicles that can be used by delivery drivers. Both quads are intended to be used in bike lanes, according to Also. Also will partner with Amazon for a Prime-branded TM-Q.Karissa Bell for EngadgetThe company didn't share details about when these vehicles might be available or how much they'll cost. Update, October 22, 2025, 2:29PM PT: Added more details and photos from Also’s launch event.This article originally appeared on Engadget at https://www.engadget.com/transportation/the-first-e-bike-from-rivian-spinoff-also-has-a-virtual-drivetrain-173000250.html?src=rss",
          "content": "Ever since Rivian spun off its \"micromobility business\" into a standalone startup called Also earlier this year, there's been much speculation about what kind of vehicles the company is working on. Now, Also is showing off its first products: a lineup of e-bikes and two pedal-assisted electric quads. The TM-B e-bike is Also's attempt at a do-it-all e-bike that can adapt to different use cases whether that's daily commuting, trail riding or kid and cargo-hauling. It sports a modular frame that can also accommodate a bench seat or rear cargo rack that supports up to 35KG of weight. The different seats can be easily swapped out without extra tools. Instead, a button on the bike’s touchscreen display controls a latching mechanism that releases the seat. It only comes in one frame size, but Also says it should be able to adapt to \"multiple body sizes,” thanks to different seat sizes and styles. The bench seat for the TM-B.Karissa Bell for EngadgetThe removable USB-C battery comes in two sizes: standard, which can power up to 60 miles of riding, and large, which maxes out at 100 miles of range. When you’re not riding, the batteries can also be used as a large external battery pack.In terms of power, the TM-B’s throttle tops out at 20MPH though the bike can reach speeds up to 28MPH with added pedaling. Also is taking an interesting approach to its drive system, with a setup it's labeled \"DreamRide.\" Instead of a mechanical connection between the bike's rear wheel and the pedals, the TM-B uses \"software-defined pedaling,\" In practice, this means that you pedaling is actually feeding the generator that powers the bike’s battery rather than directly pushing you forward. However, an Also rep told me that there is also a “limp mode” for when the bike runs out of juice so riders won’t get stranded. In those situations, pedaling will give the bike enough juice to hopefully get you to a spot where you can recharge.Also has envisioned the TM-B in a lot of scenarios, many of which involve hauling a lot of cargo.Karissa Bell for EngadgetSoftware-controlled pedaling probably won’t appeal to purists, but Also says it enables a much more customizable riding experience. When in auto mode, the bike will adapt to the speed you’re pedaling, though you can push on the throttle to get a boost. There’s also a manual mode that lets you select a “gear” (these are also software-controlled). It also uses regenerative braking, so tapping on the brakes helps recharge the battery. Though in my short test ride I found that I didn’t need to use the brakes much, because when I stopped pedaling the bike slowed down pretty quickly, kind of like taking your foot off the accelerator in an EV.The Also app and Portal display.AlsoGiven the bike's roots at Rivian, it's not surprising that there are also a bunch of other tech-enabled features, including a 5-inch touchscreen display, called \"Portal,\" that supports navigation, music playback and calling features via an accompanying app. There’s also a built-in security system that automatically locks the frame and rear wheel when you walk away. On the handlebars, there are customizable controls that can be used to adjust the volume and music playback, answer calls or navigate through display. Customizable controls on the left side fo the handlebar and a throttle on the right.Karissa Bell for EngadgetAlso is selling the TM-B in three configurations. The first to ship next spring will be the $4,500 TM-B Limited Launch Edition, which has a range up to 100 miles, support for standard and sport ride modes and features transparent purple accents. The $4,500 TM-B Performance has the same features as the limited edition model, but has a slightly different color scheme, and will be available within the \"first half\" of 2026. Finally, there's a base-level TM-B model with a range of up to 60 miles that only comes with standard ride modes. Also hasn't announced an exact price, but says it will cost less than $4,000 when it ships \"later in 2026.\" Pre-orders for the Launch Edition are open now and the other two bikes are available to reserve with a $50 deposit. The bikes will also be on display in Rivian showrooms later this year,Also's quad for commercial uses cases (left) and a smaller quad for families (right).AlsoThe company also previewed two electric, pedal-assisted quads it's calling TM-Q. The smaller quad is apparently meant for \"families and individuals seeking a safe, compact alternative to cars\" that can still haul “significant loads.” The larger TM-Q, on the other hand, is meant for commercial deliveries. Also has partnered with Amazon to develop fleets of such vehicles that can be used by delivery drivers. Both quads are intended to be used in bike lanes, according to Also. Also will partner with Amazon for a Prime-branded TM-Q.Karissa Bell for EngadgetThe company didn't share details about when these vehicles might be available or how much they'll cost. Update, October 22, 2025, 2:29PM PT: Added more details and photos from Also’s launch event.This article originally appeared on Engadget at https://www.engadget.com/transportation/the-first-e-bike-from-rivian-spinoff-also-has-a-virtual-drivetrain-173000250.html?src=rss",
          "feed_position": 5,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/tmb_seat_swap.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/google-gemini-will-arrive-in-gm-cars-starting-next-year-181249237.html",
          "published_at": "Wed, 22 Oct 2025 18:12:50 +0000",
          "title": "Google Gemini will arrive in GM cars starting next year",
          "standfirst": "Google Gemini is coming to GM vehicles in 2026. The company will be integrating a conversational AI assistant powered by Google's platform into many of its cars, trucks and SUVs. GM says this assistant will be able to access vehicle data to suss out maintenance concerns, alerting the driver when necessary. The company also promises it'll be able to help plan routes and explain various features of the car. It should also be able to do stuff like turn on the heat or air conditioning, even before entering the vehicle. This will replace the \"Google built-in\" operating system that already exists in many GM vehicles. This OS already offers access to stuff like Google Maps, Google Assistant and related apps. The upcoming Gemini-based chat assistant will do the same type of things, but it should perform better. “One of the challenges with current voice assistants is that, if you’ve used the, you’ve probably also been frustrated by them because they’re trained on certain code words or they don’t understand accents very well or if you don’t say it quite right, you don’t get the right response,” GM VP Dave Richardson told TechCrunch. “What’s great about large language models is they don’t seem to be affected by that.\" One brand-new feature that Gemini will bring to the table is web integration. This will let drivers ask the chatbot questions pertaining to geographic location and the like. GM gives an example of someone asking about the history of a bridge they are passing over. The Gemini assistant will be available via the Play Store after launch as an over-the-air upgrade to Onstar-equipped vehicles. It won't be limited to newer releases, as GM says it'll work with vehicles from the model year 2015 and above. The company also says it's working on its own AI chatbot that has been \"custom-built for your vehicle.\" There's no timetable on that one. GM ran into hot water recently when it was found that it had been selling some customer information sourced from its OnStar Smart Driver program to insurance companies without user consent. This led to the FTC banning the company from selling any driver data for five years. Richardson says the Gemini integration will be privacy-focused and the software will let drivers control what information it can access and use. GM The company made these announcements at the GM Forward media event, where it also discussed other forthcoming initiatives. It has scheduled a rollout of its self-driving platform for 2028. It's also developing its own computing platform, also launching in 2028. This does mean that GM will be sunsetting integration with Apple CarPlay and Android Auto. This software will be phased out over the next few years. This article originally appeared on Engadget at https://www.engadget.com/transportation/google-gemini-will-arrive-in-gm-cars-starting-next-year-181249237.html?src=rss",
          "content": "Google Gemini is coming to GM vehicles in 2026. The company will be integrating a conversational AI assistant powered by Google's platform into many of its cars, trucks and SUVs. GM says this assistant will be able to access vehicle data to suss out maintenance concerns, alerting the driver when necessary. The company also promises it'll be able to help plan routes and explain various features of the car. It should also be able to do stuff like turn on the heat or air conditioning, even before entering the vehicle. This will replace the \"Google built-in\" operating system that already exists in many GM vehicles. This OS already offers access to stuff like Google Maps, Google Assistant and related apps. The upcoming Gemini-based chat assistant will do the same type of things, but it should perform better. “One of the challenges with current voice assistants is that, if you’ve used the, you’ve probably also been frustrated by them because they’re trained on certain code words or they don’t understand accents very well or if you don’t say it quite right, you don’t get the right response,” GM VP Dave Richardson told TechCrunch. “What’s great about large language models is they don’t seem to be affected by that.\" One brand-new feature that Gemini will bring to the table is web integration. This will let drivers ask the chatbot questions pertaining to geographic location and the like. GM gives an example of someone asking about the history of a bridge they are passing over. The Gemini assistant will be available via the Play Store after launch as an over-the-air upgrade to Onstar-equipped vehicles. It won't be limited to newer releases, as GM says it'll work with vehicles from the model year 2015 and above. The company also says it's working on its own AI chatbot that has been \"custom-built for your vehicle.\" There's no timetable on that one. GM ran into hot water recently when it was found that it had been selling some customer information sourced from its OnStar Smart Driver program to insurance companies without user consent. This led to the FTC banning the company from selling any driver data for five years. Richardson says the Gemini integration will be privacy-focused and the software will let drivers control what information it can access and use. GM The company made these announcements at the GM Forward media event, where it also discussed other forthcoming initiatives. It has scheduled a rollout of its self-driving platform for 2028. It's also developing its own computing platform, also launching in 2028. This does mean that GM will be sunsetting integration with Apple CarPlay and Android Auto. This software will be phased out over the next few years. This article originally appeared on Engadget at https://www.engadget.com/transportation/google-gemini-will-arrive-in-gm-cars-starting-next-year-181249237.html?src=rss",
          "feed_position": 10,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/adf23380-af6e-11f0-975e-b59d7cbc084f"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-vpn-deals-120056041.html",
          "published_at": "Wed, 22 Oct 2025 17:34:34 +0000",
          "title": "The best VPN deals: Get up to 88 percent off ProtonVPN, ExpressVPN, Surfshark and more",
          "standfirst": "A virtual private network (VPN) is useful in lots of ways every day, whether you're streaming foreign TV shows or keeping yourself anonymous online so advertisers can't track you. But while we strongly recommend using a VPN, it pays to do some research before investing in one — pricing can be opaque for these services, and you can't always trust how the providers portray their best deals. Even so, there are genuinely great deals to be had. VPN providers love to give out deep discounts to anybody willing to sign up for a year or more at once. This means you've got to pay out more upfront, but if you divide the cost by the months of service, you're actually paying less per month over time. With deals like this, VPN providers boost their subscriber numbers, and you get heavy price cuts on some of our favorite services. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-vpn-deals-120056041.html?src=rss",
          "content": "A virtual private network (VPN) is useful in lots of ways every day, whether you're streaming foreign TV shows or keeping yourself anonymous online so advertisers can't track you. But while we strongly recommend using a VPN, it pays to do some research before investing in one — pricing can be opaque for these services, and you can't always trust how the providers portray their best deals. Even so, there are genuinely great deals to be had. VPN providers love to give out deep discounts to anybody willing to sign up for a year or more at once. This means you've got to pay out more upfront, but if you divide the cost by the months of service, you're actually paying less per month over time. With deals like this, VPN providers boost their subscriber numbers, and you get heavy price cuts on some of our favorite services. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-vpn-deals-120056041.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/samsung-galaxy-xr-everything-you-need-to-know-111532664.html",
          "published_at": "Wed, 22 Oct 2025 15:58:59 +0000",
          "title": "Samsung Galaxy XR: Everything you need to know",
          "standfirst": "With Galaxy XR, you can split screen between a game like Stardew Valley and a real-time video chat.Samsung After dropping hints for over two years, Samsung, in partnership with Google, finally revealed its first-ever Android extended reality headset Tuesday night. The new device, dubbed Galaxy XR, will run you $1,800 and you can actually buy it today. Due to its collaboration with Google, it's not a surprise that the headset comes fully equipped with Gemini AI built in. \"Android XR is the first Android platform built entirely for the Gemini era, and we are incredibly excited to take a significant leap forward today with the launch of Galaxy XR,\" Sameer Samat, President of Android Ecosystem at Google, said. What are the features of the Galaxy XR headset, and how does it differ from its main competitor, the $3,499 Apple Vision Pro? Glad you asked! What is the Galaxy XR? The Samsung Galaxy XR is the first-ever Android XR headset, created by Google and Samsung. If Apple's Vision Pro is the \"virtual reality iPhone,\" the Samsung is basically its \"virtual reality Galaxy S phone\" alternative. The headset looks like a pair of snowboard goggles, but it comes with a whopping total of 12 cameras and six microphones. And because it's 2025, AI is a big part of the Galaxy XR's upsell: It has Google's Gemini AI assistant built in, so while you're wearing the headset, it can see and hear everything around you. Google's \"XR\" designation stands for \"extended reality,\" which is effectively an \"all of the above\" term encompassing augmented reality (AR), virtual reality (VR) and mixed reality. That means the Galaxy XR can put a virtual overlay on the real world (thanks to all those cameras), or it can completely shut out your space to immerse you in a totally virtual environment. In other words, you can customize your own workspace or turn your room into your own personal theater, or you can transport yourself to an international locale with a first-person \"you are there\" viewpoint. What can you do with the Galaxy XR? For watching videos on apps like YouTube, the headset offers a library of 180- and 360-degree VR content. You can also watch movies using Google TV on a large, resizable screen. Plus, if you have a question about whatever you're watching, you can ask Gemini since it sees everything you see. And when you're looking at your photos and videos, you can convert them to 3D so it feels like you're back in the memory. While using Google Maps, you can use Immersive View to go anywhere in the world (virtually, of course). Visiting somewhere historical? You can ask Gemini to tell you more information about the landmark. Spot a weird-looking plant or bug around your house? You can use Circle to Search to find out what it is while wearing the headset. The Immersive View feature of Google Maps lets Galaxy XR users zoom across cityscapes.Samsung As for getting work done efficiently, you can arrange your most-needed apps all around your screen — for instance, your web browser, favorite music app, important documents and video conferencing app. And if things start to feel cluttered, you can ask Gemini to organize your windows. Even better, you can link your PC to your headset, as well as your keyboard and mouse. The headset uses two passthrough cameras for real-time viewing, six world-facing tracking cameras and four eye-tracking cameras, as well as depth and flicker sensors. It also supports iris recognition so you can unlock the device and enter passwords within some apps. What apps work on the Galaxy XR? \"Almost all\" Google Play Store apps will be available on the Galaxy XR headset. That means hundreds of thousands of apps should be available on the headset on day one, including basic streaming apps (for watching things like Netflix, HBO Max or Peacock on that giant virtual display) as well as \"new versions\" of some of Google's key first-party software, from Photos to Chrome and YouTube. And, of course, the aforementioned Google Maps is on board, too. Using the Galaxy XR as a PC monitor, you can stream in a game -- such as this \"Assassin's Creed\" tile -- from an external source. Samsung As you'd expect, Google is also focusing on gaming. In addition to the full panoply of Android games, the Galaxy XR's PC Link also lets you use it as a monitor for PC-based games, too. How does it feel to wear the Galaxy XR? Engadget Senior Reporter Sam Rutherford wearing the Samsung Galaxy XR headset. Sam Rutherford for Engadget Engadget's Sam Rutherford got some hands-on time with the Galaxy XR recently, and had some notable first impressions on its comfort and usability: [I]t seems Samsung learned a lot from its rivals by including a much larger and thicker head cushion that helps distribute the weight of the headset more evenly. Granted, during a longer session, I still noticed a bit of pressure and felt relief after taking off the Galaxy XR, but it's nothing like the Vision Pro, which in my experience gets uncomfortable almost immediately. Finally, around back, there's a simple strap with a knob that you can twist to tighten or loosen the headband as necessary. So even without extra support running across the top of your head, getting in and out of the Galaxy XR is much easier and comfier than the Vision Pro. How is the Galaxy XR different from the Apple Vision Pro? While the headset may look pretty similar to the Apple Vision Pro, there are some bigger (and even better) differences. For starters, the Galaxy's micro-OLED display has 29 million pixels, compared to Apple's 23 million pixels, and a resolution of 3,552 x 3,840, which offers a tad more detail than Apple's model. Additionally, it has 96% of the DCI‑P3 color gamut, while the Vision Pro has 92%. However, Apple's headset beats out the Samsung on refresh rate, going a full 120Hz versus the Galaxy XR's 90Hz. Since you'll be wearing it on your head for an extended period, you'll be relieved to know the Galaxy XR is a bit lighter than Apple's XR headset by 205g (0.5lbs). On the battery life front, Samsung is pledging up to two hours of \"general use\" and 2.5 hours of video playback, whereas the new M5 Vision Pro runs 30 minutes longer in both modes, per Apple. Besides the obvious operating system differences, of course, the aforementioned price delta is perhaps the biggest advantage Samsung has over the Apple model: At $1,800, you can get almost two full Galaxy XR units for every $3,499 Apple Vision Pro. How do I order the Samsung Galaxy XR? Sam Rutherford for Engadget You can order the Galaxy XR now via Samsung. While that $1,800 price tag is formidable, Samsung is offering financing options. And the headset's price is actually less than that of Samsung's flagship Galaxy Z Fold 7 foldable phone. Key accessories like the Travel Case and Galaxy XR Controller usually cost $250 each, though both can be bundled in for $175 apiece. There are additional incentives, too. For anyone buying the Galaxy XR before the end of the year, Samsung is throwing in the \"Explorer Pack\" at no extra charge. That includes a year's worth of Google AI Pro, YouTube Premium (including YouTube Music) and Google Play Pass; access to the new season of NBA League Pass; and access to the NFL Pro Era game, the Asteroid and Calm apps and Adobe's Project Pulsar, a 3D compositing app. Update, 11:58AM ET: Upon original publication, one instance of the price listed in this story was inaccurate because of a typo. It now correctly reflects the $1,800 price. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-galaxy-xr-everything-you-need-to-know-111532664.html?src=rss",
          "content": "With Galaxy XR, you can split screen between a game like Stardew Valley and a real-time video chat.Samsung After dropping hints for over two years, Samsung, in partnership with Google, finally revealed its first-ever Android extended reality headset Tuesday night. The new device, dubbed Galaxy XR, will run you $1,800 and you can actually buy it today. Due to its collaboration with Google, it's not a surprise that the headset comes fully equipped with Gemini AI built in. \"Android XR is the first Android platform built entirely for the Gemini era, and we are incredibly excited to take a significant leap forward today with the launch of Galaxy XR,\" Sameer Samat, President of Android Ecosystem at Google, said. What are the features of the Galaxy XR headset, and how does it differ from its main competitor, the $3,499 Apple Vision Pro? Glad you asked! What is the Galaxy XR? The Samsung Galaxy XR is the first-ever Android XR headset, created by Google and Samsung. If Apple's Vision Pro is the \"virtual reality iPhone,\" the Samsung is basically its \"virtual reality Galaxy S phone\" alternative. The headset looks like a pair of snowboard goggles, but it comes with a whopping total of 12 cameras and six microphones. And because it's 2025, AI is a big part of the Galaxy XR's upsell: It has Google's Gemini AI assistant built in, so while you're wearing the headset, it can see and hear everything around you. Google's \"XR\" designation stands for \"extended reality,\" which is effectively an \"all of the above\" term encompassing augmented reality (AR), virtual reality (VR) and mixed reality. That means the Galaxy XR can put a virtual overlay on the real world (thanks to all those cameras), or it can completely shut out your space to immerse you in a totally virtual environment. In other words, you can customize your own workspace or turn your room into your own personal theater, or you can transport yourself to an international locale with a first-person \"you are there\" viewpoint. What can you do with the Galaxy XR? For watching videos on apps like YouTube, the headset offers a library of 180- and 360-degree VR content. You can also watch movies using Google TV on a large, resizable screen. Plus, if you have a question about whatever you're watching, you can ask Gemini since it sees everything you see. And when you're looking at your photos and videos, you can convert them to 3D so it feels like you're back in the memory. While using Google Maps, you can use Immersive View to go anywhere in the world (virtually, of course). Visiting somewhere historical? You can ask Gemini to tell you more information about the landmark. Spot a weird-looking plant or bug around your house? You can use Circle to Search to find out what it is while wearing the headset. The Immersive View feature of Google Maps lets Galaxy XR users zoom across cityscapes.Samsung As for getting work done efficiently, you can arrange your most-needed apps all around your screen — for instance, your web browser, favorite music app, important documents and video conferencing app. And if things start to feel cluttered, you can ask Gemini to organize your windows. Even better, you can link your PC to your headset, as well as your keyboard and mouse. The headset uses two passthrough cameras for real-time viewing, six world-facing tracking cameras and four eye-tracking cameras, as well as depth and flicker sensors. It also supports iris recognition so you can unlock the device and enter passwords within some apps. What apps work on the Galaxy XR? \"Almost all\" Google Play Store apps will be available on the Galaxy XR headset. That means hundreds of thousands of apps should be available on the headset on day one, including basic streaming apps (for watching things like Netflix, HBO Max or Peacock on that giant virtual display) as well as \"new versions\" of some of Google's key first-party software, from Photos to Chrome and YouTube. And, of course, the aforementioned Google Maps is on board, too. Using the Galaxy XR as a PC monitor, you can stream in a game -- such as this \"Assassin's Creed\" tile -- from an external source. Samsung As you'd expect, Google is also focusing on gaming. In addition to the full panoply of Android games, the Galaxy XR's PC Link also lets you use it as a monitor for PC-based games, too. How does it feel to wear the Galaxy XR? Engadget Senior Reporter Sam Rutherford wearing the Samsung Galaxy XR headset. Sam Rutherford for Engadget Engadget's Sam Rutherford got some hands-on time with the Galaxy XR recently, and had some notable first impressions on its comfort and usability: [I]t seems Samsung learned a lot from its rivals by including a much larger and thicker head cushion that helps distribute the weight of the headset more evenly. Granted, during a longer session, I still noticed a bit of pressure and felt relief after taking off the Galaxy XR, but it's nothing like the Vision Pro, which in my experience gets uncomfortable almost immediately. Finally, around back, there's a simple strap with a knob that you can twist to tighten or loosen the headband as necessary. So even without extra support running across the top of your head, getting in and out of the Galaxy XR is much easier and comfier than the Vision Pro. How is the Galaxy XR different from the Apple Vision Pro? While the headset may look pretty similar to the Apple Vision Pro, there are some bigger (and even better) differences. For starters, the Galaxy's micro-OLED display has 29 million pixels, compared to Apple's 23 million pixels, and a resolution of 3,552 x 3,840, which offers a tad more detail than Apple's model. Additionally, it has 96% of the DCI‑P3 color gamut, while the Vision Pro has 92%. However, Apple's headset beats out the Samsung on refresh rate, going a full 120Hz versus the Galaxy XR's 90Hz. Since you'll be wearing it on your head for an extended period, you'll be relieved to know the Galaxy XR is a bit lighter than Apple's XR headset by 205g (0.5lbs). On the battery life front, Samsung is pledging up to two hours of \"general use\" and 2.5 hours of video playback, whereas the new M5 Vision Pro runs 30 minutes longer in both modes, per Apple. Besides the obvious operating system differences, of course, the aforementioned price delta is perhaps the biggest advantage Samsung has over the Apple model: At $1,800, you can get almost two full Galaxy XR units for every $3,499 Apple Vision Pro. How do I order the Samsung Galaxy XR? Sam Rutherford for Engadget You can order the Galaxy XR now via Samsung. While that $1,800 price tag is formidable, Samsung is offering financing options. And the headset's price is actually less than that of Samsung's flagship Galaxy Z Fold 7 foldable phone. Key accessories like the Travel Case and Galaxy XR Controller usually cost $250 each, though both can be bundled in for $175 apiece. There are additional incentives, too. For anyone buying the Galaxy XR before the end of the year, Samsung is throwing in the \"Explorer Pack\" at no extra charge. That includes a year's worth of Google AI Pro, YouTube Premium (including YouTube Music) and Google Play Pass; access to the new season of NBA League Pass; and access to the NFL Pro Era game, the Asteroid and Calm apps and Adobe's Project Pulsar, a 3D compositing app. Update, 11:58AM ET: Upon original publication, one instance of the price listed in this story was inaccurate because of a typo. It now correctly reflects the $1,800 price. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-galaxy-xr-everything-you-need-to-know-111532664.html?src=rss",
          "feed_position": 18,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/7dee0e70-aef1-11f0-adfa-613ea884712c"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/evs/toyotas-new-all-hybrid-rav4-has-software-you-might-actually-want-to-use-140000442.html",
          "published_at": "Wed, 22 Oct 2025 14:00:00 +0000",
          "title": "Toyota's new all-hybrid RAV4 has software you might actually want to use",
          "standfirst": "If I had a dollar for every time a vehicle manufacturer launched a new in-car software experience designed to achieve the same levels of user experience as your average tablet or smartphone, I'd probably have about enough cash for a decent lunch at a middling restaurant. It's a common refrain, and yet after years of hearing that same story over and over, I still find myself firing up Android Auto or Apple CarPlay as soon as I get into just about every new car I evaluate. At the launch of the 2026 Toyota RAV4, I heard that story yet again, about how they'd rewritten their in-car software to deliver an experience like that found in modern mobile devices. And I have to say, for once, they might have actually delivered. Toyota's latest SUV has voice and touch capabilities that are not only quick and responsive but genuinely pleasant to use. And thankfully, the rest of the SUV has been upgraded to match.The RAV4 has been in production for over 30 years now. This, the sixth generation, comes hot on the heels of its predecessor becoming the world's best-selling car in 2024. Over 1.1 million were sold last year, which goes a long way towards explaining why you can't kick a pebble in a grocery store parking lot without hitting a RAV4.The overall changes for the 2026 RAV4 aren't radical, but they are appreciated. For starters, every trim of this SUV is a hybrid, with base models powered by a 2.5-liter four-cylinder engine that drives the front wheels, offering 226 horsepower. Those wanting all-wheel drive can add another electric motor at the back, adding a little more power (10 hp) and a good bit more drive for low-grip situations. For 2026, every trim of the RAV4 is a hybrid. Tim Stevens for EngadgetFrom there, buyers can step up to a revised plug-in hybrid model, which now makes 324 horsepower, up 22 from before. Fuel economy is up too, up to 48 mpg depending on what trim you choose, and you can now get up to 52 miles of range from a 22.7 kWh battery pack in the plug-in.And that's usable range. I took a RAV4 XSE plug-in edition out for a morning drive and covered nearly 20 miles without spinning up the engine. Even at highway speeds the RAV4 was slow but perfectly manageable. With that much range and even reasonably quick DC charging (50 kW maximum), it's easy to see this as the introduction to EVs for many.For better or worse, that DC charging is handled on a CCS port, not the newer NACS ports that most manufacturers (even Toyota) are using on their EVs. The lack of any kind of vehicle-to-load functionality is a bummer, too, especially on the rugged-ish Wilderness edition, which would seemingly be a perfect machine for powering a campsite. Regardless of which trim you go with, you'll get that new software system running on either a 10.5-inch touchscreen on the lower trims or a 12.9-inch display on higher-end machines. The overall experience is the same, looking bright and crisp either way, just with more finger-friendly controls on the bigger panel.Toyota's revamped software is quick and responsive, especially the voice assistant. Tim Stevens for EngadgetToyota's software layout is familiar, with a vertical column of icons on the left for toggling between major sections like media or navigation, and then a row of controls along the bottom for controlling the car's heating, ventilation and cooling system. The rest of the display is taken up by a customizable series of panels. As you swipe from left to right, you swing through different pages, which you can move around and rearrange as you like. None of this is particularly revolutionary, but is pleasantly responsive. Swiping from page to page was quick and easy, without any annoying lag waiting for content to load.That responsiveness continued through to the voice assistant, which is the quickest I've ever used in a car. Just say \"Hey, Toyota\" and ask for whatever you want. When asked for pizza, the voice assistant listed nearby joints, even quoted their star rating and offered navigation, all without the annoying round-trip processing lag that's common in these systems. Some of that speed might be thanks to the addition of 5G connectivity (provided by AT&T), but there's surely some quicker hardware running beneath the skin powering the Linux-based software.The car's integrated navigation was also easy to use, quick to route and re-route and features all the points of interest you could ever want. There's even an integrated dashcam feature that will record any incidents on the road, or whatever else you feel like highlighting, while also storing the footage from the SUV's other cameras. Despite the quality experience through the touchscreen, Toyota didn't take this as an opportunity to delete all the car's buttons. You'll still find physical controls for all the major features, including (praise be) a volume knob. It was all good enough to make me not feel compelled to reach for my phone, but of course, I did in the interest of testing. Both wireless Android Auto and Apple CarPlay are supported, not only in the main touchscreen but also able to feed navigation details into the 12.3-inch digital gauge cluster. That, too, is customizable, with a series of panels of information that hover over your phone's map view.The meaner, sportier GR Sport edition. Tim Stevens for EngadgetSo, even if you still prefer your phone, you're covered, and powered, too. The RAV4 has a pair of Qi wireless chargers, conveniently situated in the center stack just below the HVAC controls. You'll also find two 45-watt USB-C ports up front, plus a pair of 15-watt ports in the back for rear-seat passengers.The new RAV4 has a roomy, comfortable cabin with some fun touches, like a neoprene-like insert in the dash that's pleasant to touch. The overall interior design won't win any awards for dramatic styling or eye-catching flair, but it's comfortable and seems like the kind of thing that'll stand up to whatever you or your kids throw at it. In terms of driving dynamics, the extra power offered by the RAV4 doesn't turn it into a rocket ship, but the PHEV trim in particular feels more than quick enough. There's also a new GR Sport edition for those who aspire to something even more engaging, but despite a more aggressive grille up front and a big wing hanging off the back, it still feels like a RAV4 from behind the wheel. That is to say: It’s not the most exciting thing on the road.But people don't buy RAV4s to be wowed, they buy them because they're practical and comfortable and priced right. Price, unfortunately, is one thing we don't know about the new model, with Toyota only saying that it'll start somewhere in the low $30,000 range. But all the SUV's other virtues carry forward into 2026 with upgrades. Add to that a massively improved software experience, and you have an SUV that doesn't disappoint.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/toyotas-new-all-hybrid-rav4-has-software-you-might-actually-want-to-use-140000442.html?src=rss",
          "content": "If I had a dollar for every time a vehicle manufacturer launched a new in-car software experience designed to achieve the same levels of user experience as your average tablet or smartphone, I'd probably have about enough cash for a decent lunch at a middling restaurant. It's a common refrain, and yet after years of hearing that same story over and over, I still find myself firing up Android Auto or Apple CarPlay as soon as I get into just about every new car I evaluate. At the launch of the 2026 Toyota RAV4, I heard that story yet again, about how they'd rewritten their in-car software to deliver an experience like that found in modern mobile devices. And I have to say, for once, they might have actually delivered. Toyota's latest SUV has voice and touch capabilities that are not only quick and responsive but genuinely pleasant to use. And thankfully, the rest of the SUV has been upgraded to match.The RAV4 has been in production for over 30 years now. This, the sixth generation, comes hot on the heels of its predecessor becoming the world's best-selling car in 2024. Over 1.1 million were sold last year, which goes a long way towards explaining why you can't kick a pebble in a grocery store parking lot without hitting a RAV4.The overall changes for the 2026 RAV4 aren't radical, but they are appreciated. For starters, every trim of this SUV is a hybrid, with base models powered by a 2.5-liter four-cylinder engine that drives the front wheels, offering 226 horsepower. Those wanting all-wheel drive can add another electric motor at the back, adding a little more power (10 hp) and a good bit more drive for low-grip situations. For 2026, every trim of the RAV4 is a hybrid. Tim Stevens for EngadgetFrom there, buyers can step up to a revised plug-in hybrid model, which now makes 324 horsepower, up 22 from before. Fuel economy is up too, up to 48 mpg depending on what trim you choose, and you can now get up to 52 miles of range from a 22.7 kWh battery pack in the plug-in.And that's usable range. I took a RAV4 XSE plug-in edition out for a morning drive and covered nearly 20 miles without spinning up the engine. Even at highway speeds the RAV4 was slow but perfectly manageable. With that much range and even reasonably quick DC charging (50 kW maximum), it's easy to see this as the introduction to EVs for many.For better or worse, that DC charging is handled on a CCS port, not the newer NACS ports that most manufacturers (even Toyota) are using on their EVs. The lack of any kind of vehicle-to-load functionality is a bummer, too, especially on the rugged-ish Wilderness edition, which would seemingly be a perfect machine for powering a campsite. Regardless of which trim you go with, you'll get that new software system running on either a 10.5-inch touchscreen on the lower trims or a 12.9-inch display on higher-end machines. The overall experience is the same, looking bright and crisp either way, just with more finger-friendly controls on the bigger panel.Toyota's revamped software is quick and responsive, especially the voice assistant. Tim Stevens for EngadgetToyota's software layout is familiar, with a vertical column of icons on the left for toggling between major sections like media or navigation, and then a row of controls along the bottom for controlling the car's heating, ventilation and cooling system. The rest of the display is taken up by a customizable series of panels. As you swipe from left to right, you swing through different pages, which you can move around and rearrange as you like. None of this is particularly revolutionary, but is pleasantly responsive. Swiping from page to page was quick and easy, without any annoying lag waiting for content to load.That responsiveness continued through to the voice assistant, which is the quickest I've ever used in a car. Just say \"Hey, Toyota\" and ask for whatever you want. When asked for pizza, the voice assistant listed nearby joints, even quoted their star rating and offered navigation, all without the annoying round-trip processing lag that's common in these systems. Some of that speed might be thanks to the addition of 5G connectivity (provided by AT&T), but there's surely some quicker hardware running beneath the skin powering the Linux-based software.The car's integrated navigation was also easy to use, quick to route and re-route and features all the points of interest you could ever want. There's even an integrated dashcam feature that will record any incidents on the road, or whatever else you feel like highlighting, while also storing the footage from the SUV's other cameras. Despite the quality experience through the touchscreen, Toyota didn't take this as an opportunity to delete all the car's buttons. You'll still find physical controls for all the major features, including (praise be) a volume knob. It was all good enough to make me not feel compelled to reach for my phone, but of course, I did in the interest of testing. Both wireless Android Auto and Apple CarPlay are supported, not only in the main touchscreen but also able to feed navigation details into the 12.3-inch digital gauge cluster. That, too, is customizable, with a series of panels of information that hover over your phone's map view.The meaner, sportier GR Sport edition. Tim Stevens for EngadgetSo, even if you still prefer your phone, you're covered, and powered, too. The RAV4 has a pair of Qi wireless chargers, conveniently situated in the center stack just below the HVAC controls. You'll also find two 45-watt USB-C ports up front, plus a pair of 15-watt ports in the back for rear-seat passengers.The new RAV4 has a roomy, comfortable cabin with some fun touches, like a neoprene-like insert in the dash that's pleasant to touch. The overall interior design won't win any awards for dramatic styling or eye-catching flair, but it's comfortable and seems like the kind of thing that'll stand up to whatever you or your kids throw at it. In terms of driving dynamics, the extra power offered by the RAV4 doesn't turn it into a rocket ship, but the PHEV trim in particular feels more than quick enough. There's also a new GR Sport edition for those who aspire to something even more engaging, but despite a more aggressive grille up front and a big wing hanging off the back, it still feels like a RAV4 from behind the wheel. That is to say: It’s not the most exciting thing on the road.But people don't buy RAV4s to be wowed, they buy them because they're practical and comfortable and priced right. Price, unfortunately, is one thing we don't know about the new model, with Toyota only saying that it'll start somewhere in the low $30,000 range. But all the SUV's other virtues carry forward into 2026 with upgrades. Add to that a massively improved software experience, and you have an SUV that doesn't disappoint.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/toyotas-new-all-hybrid-rav4-has-software-you-might-actually-want-to-use-140000442.html?src=rss",
          "feed_position": 22,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/2026_Toyota_RAV4_first_drive_033.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/after-10-years-the-ipad-pro-has-finally-carved-out-its-own-identity-130108169.html",
          "published_at": "Wed, 22 Oct 2025 13:01:08 +0000",
          "title": "After 10 years, the iPad Pro has finally carved out its own identity",
          "standfirst": "The iPad Pro is about to turn 10, so hopefully you’ll forgive me for pulling out this well-worn Apple truism one more time. No, it’s not Steve Jobs saying “if you see a stylus, they blew it” (a quote continually used out of context.) It’s the tale of how since day one, the iPad Pro’s hardware often felt far more powerful and capable than the software it runs. If you recall, iPadOS was initially a scaled-up version of iOS, with most of the limitations inherent in software designed first for a phone. Apps could take great advantage of the larger screen, but working across multiple apps was just nowhere near as simple as doing the same thing on a Mac. Yes, the iPad has always been more portable, and accessories like the Apple Pencil make it better-suited for some tasks than a Mac, but the knock is always that the iPad — even the Pro — isn’t ideal for getting “real work” done.The combination of the just-launched iPad Pro’s M5 processor and the massive iPadOS update might finally quiet that debate. Sure, some people will never want to replace their laptop with an iPad, but it’s more feasible than ever thanks to iPadOS 26. It brings a totally revamped windowing and multitasking system, a background tasks API that lets you run heavy processes like rendering video while working in other apps, more robust audio input support and a far better Files app, making the iPad Pro closer in its feature set to a Mac than ever before. As Apple’s premium tablet enters its second decade, I spoke with the company’s Ted Merendino (from the iPad Product Marketing team) and Ty Jordan (Product Manager for System Experiences) to learn more about the evolution of the iPad Pro and iPadOS.Given how many Mac-like features came to iPadOS 26 this year, I was curious to hear how the company approached putting all that Mac DNA into the iPad while still keeping it distinct, as well as the engineering challenges it presented. “One of the things that makes iPad such a unique device is it's extremely versatile, right?” Jordan said. “You can use it with touch, you can use it with a trackpad or a keyboard or the Apple Pencil, and that's really powerful. But it also actually makes an extremely challenging engineering and design problem to try and solve when you're thinking about something like the new windowing experience.”Jordan went on to describe a “multi-year effort” to reconfigure the underlying iPadOS architecture. Apple worked to “maintain the immediacy that you've come to expect with a touch device, while still allowing users to have this freedom and flexibility to work across so many more windows at once,” he said. From there, the company had to figure out how to bring a bunch of familiar tools from the Mac together and make sure they work across touchscreens, trackpads and keyboards.An iPad running multiple windows in iPadOS 26Nathan Ingraham for EngadgetJordan pointed to Expose (a tool in macOS that shows you all your open windows by swiping up on the trackpad with three fingers) as a good example of something they wanted to bring to iPadOS in a way that felt native. “We leveraged the home gesture that people have been familiar with on iPad for a long time,” he said, “so you can easily see a bird's eye view of all your windows.”Swiping up on the iPad’s screen with one finger has brought you home for years, but now swiping up and holding for a second drops you into Expose, the same way it invokes open apps on an iPhone. And you can use the same three-finger swipe up on an iPad with a trackpad as you can on a Mac. “All these pieces have to be reconsidered over and over again in order to make sure that they do feel distinct to iPad,” Jordan said.While iPadOS 26 is a major revision that was just released less than a month ago, the iPad Pro M5 is more of an iterative update, at least on the outside. That’s not a big surprise given that the M4 model released in May 2024 was a complete redesign. The iPad Pro M4 is more capable thanks to the big software update, but this year’s M5 update pushes the tablet even further into a world where AI performance is paramount. “M5 has a faster Neural Engine, which continues to be the most power efficient location on the chip to run on-device AI,” Merendino said, citing features like Live Text and Subject Lift that have been in iOS and iPadOS for a while now. He also noted that the faster CPU in the M5 has had neural accelerators for a few generations, things that help with low-latency AI tasks like speech recognition. But the M5’s redesigned GPU is where the big changes can be found. “Within each GPU core is the new Neural Accelerator that dramatically speeds up GPU-based AI tasks,” Merendino continued. “So if you are segmenting super high-resolution video, this is much, much faster. For on-device image generation, this is much faster.” Benchmarks I took while reviewing the iPad Pro M5 back this up — all the GPU-based measurements showed huge improvements over the M4.Merendino noted that Apple invited the developer for image generation app Draw Things into its labs to test the app with the M5’s GPU neural accelerators and it provided about double the performance of the M4 chip and four times the performance of the M1. My testing with Draw Things backed this up. I ran four different image generation prompts on both the M4 and M5 iPad Pro, and the M5 was more than twice as fast. It typically finished the default prompts I tried in the app in about 50 seconds, while the M4 took about 2 minutes and 25 seconds. Other tasks, like large language model token generation, are six times faster on the M5 compared to the (much older) M1. Impressive, for sure, but it’s also fair to say that most iPad Pro users are likely not going to be pushing to the edge of the M5’s computational powers. The flip side of this, though, is that the iPad Pro will likely remain fast enough for all but the most demanding tasks for years. Apple knows this, and it’s evident in the way it’s positioning this new iPad Pro — it’s for demanding customers who’ve been using an M1- or M2-powered iPad Pro for years now and are ready for an upgrade. One of the main hardware differences between the redesigned M4 and M5 iPad Pros and their predecessors is that Apple made the tablet even thinner and lighter than ever, while packing in the company’s latest silicon. It’s a wild engineering feat, one that impressed me from the very first time I picked up the iPad Pro M4 last year. There is one somewhat humorous thing about the iPad Pro, which is that it’s thinner and lighter than the iPad Air — despite the Air name having historically been used for Apple’s most portable products. Just look at the iPhone Air for the latest example.That made me ponder if a more “pro” iPad should be a little thicker and heavier to accommodate a bigger battery, like what you’ll find in the MacBook Pro. The iPad Pro’s 10-hour battery life for basic tasks like web browsing and watching video isn’t short, but if you push it harder it’ll drain a lot quicker. Merendino said that the ongoing thought process behind balancing battery life, performance and size comes down to a focus on portability and versatility.“One of the things that has defined iPad since the very beginning is portability. For creative pros, the iPad Pro is untethering them from a workstation,” he said. “It's letting them create and be productive wherever they may be. And what's unique is that over the years we've made iPad more and more portable.” That’s undeniable; the first iPad was about 1.5 pounds with its 9.7-inch screen and the 13-inch iPad Pro is a quarter of a pound lighter. “But we have also made it vastly more powerful,” Merendino continued, “even though it’s a more portable device, a vastly faster device. We have still maintained that all day battery life that we know users depend on.” So while we’re probably not getting an iPad Pro with 15- or 20-hour battery life any time soon, I can respect the trade-off of making the tablet as portable as possible. It’s one of its main differentiating features compared to a Mac, after all.A rumor that started making the rounds just after the iPad Pro M5 was released puts the “Mac versus iPad” debate into a new territory, though. A few reliable sources including Mark Gurman at Bloomberg and analyst Ming-Chi Kuo both say that the M6 refresh of the MacBook Pro will usher in touchscreens for the first time on a Mac. If this happens, it’ll likely upend the debate yet again. But in the same way an iPad doesn’t really replace the Mac, I don’t think a touchscreen MacBook will necessarily be better than an iPad for some things. The iPad is still the most versatile device Apple sells, and the company believes that versatility is something people recognize and want. “With the windowing system that we built, it [still] starts with every app being fullscreen,” Jordan says. “And the idea behind that philosophy is making sure you can be the person who has iPad and is just using it on the couch to watch a show, and then can seamlessly transition to being a professional who’s connected to an external display with a Magic Keyboard and a bunch of windows open. And that versatility is really interesting, and I think customers who gravitate towards iPad are looking for that device that can go across those worlds.”This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/after-10-years-the-ipad-pro-has-finally-carved-out-its-own-identity-130108169.html?src=rss",
          "content": "The iPad Pro is about to turn 10, so hopefully you’ll forgive me for pulling out this well-worn Apple truism one more time. No, it’s not Steve Jobs saying “if you see a stylus, they blew it” (a quote continually used out of context.) It’s the tale of how since day one, the iPad Pro’s hardware often felt far more powerful and capable than the software it runs. If you recall, iPadOS was initially a scaled-up version of iOS, with most of the limitations inherent in software designed first for a phone. Apps could take great advantage of the larger screen, but working across multiple apps was just nowhere near as simple as doing the same thing on a Mac. Yes, the iPad has always been more portable, and accessories like the Apple Pencil make it better-suited for some tasks than a Mac, but the knock is always that the iPad — even the Pro — isn’t ideal for getting “real work” done.The combination of the just-launched iPad Pro’s M5 processor and the massive iPadOS update might finally quiet that debate. Sure, some people will never want to replace their laptop with an iPad, but it’s more feasible than ever thanks to iPadOS 26. It brings a totally revamped windowing and multitasking system, a background tasks API that lets you run heavy processes like rendering video while working in other apps, more robust audio input support and a far better Files app, making the iPad Pro closer in its feature set to a Mac than ever before. As Apple’s premium tablet enters its second decade, I spoke with the company’s Ted Merendino (from the iPad Product Marketing team) and Ty Jordan (Product Manager for System Experiences) to learn more about the evolution of the iPad Pro and iPadOS.Given how many Mac-like features came to iPadOS 26 this year, I was curious to hear how the company approached putting all that Mac DNA into the iPad while still keeping it distinct, as well as the engineering challenges it presented. “One of the things that makes iPad such a unique device is it's extremely versatile, right?” Jordan said. “You can use it with touch, you can use it with a trackpad or a keyboard or the Apple Pencil, and that's really powerful. But it also actually makes an extremely challenging engineering and design problem to try and solve when you're thinking about something like the new windowing experience.”Jordan went on to describe a “multi-year effort” to reconfigure the underlying iPadOS architecture. Apple worked to “maintain the immediacy that you've come to expect with a touch device, while still allowing users to have this freedom and flexibility to work across so many more windows at once,” he said. From there, the company had to figure out how to bring a bunch of familiar tools from the Mac together and make sure they work across touchscreens, trackpads and keyboards.An iPad running multiple windows in iPadOS 26Nathan Ingraham for EngadgetJordan pointed to Expose (a tool in macOS that shows you all your open windows by swiping up on the trackpad with three fingers) as a good example of something they wanted to bring to iPadOS in a way that felt native. “We leveraged the home gesture that people have been familiar with on iPad for a long time,” he said, “so you can easily see a bird's eye view of all your windows.”Swiping up on the iPad’s screen with one finger has brought you home for years, but now swiping up and holding for a second drops you into Expose, the same way it invokes open apps on an iPhone. And you can use the same three-finger swipe up on an iPad with a trackpad as you can on a Mac. “All these pieces have to be reconsidered over and over again in order to make sure that they do feel distinct to iPad,” Jordan said.While iPadOS 26 is a major revision that was just released less than a month ago, the iPad Pro M5 is more of an iterative update, at least on the outside. That’s not a big surprise given that the M4 model released in May 2024 was a complete redesign. The iPad Pro M4 is more capable thanks to the big software update, but this year’s M5 update pushes the tablet even further into a world where AI performance is paramount. “M5 has a faster Neural Engine, which continues to be the most power efficient location on the chip to run on-device AI,” Merendino said, citing features like Live Text and Subject Lift that have been in iOS and iPadOS for a while now. He also noted that the faster CPU in the M5 has had neural accelerators for a few generations, things that help with low-latency AI tasks like speech recognition. But the M5’s redesigned GPU is where the big changes can be found. “Within each GPU core is the new Neural Accelerator that dramatically speeds up GPU-based AI tasks,” Merendino continued. “So if you are segmenting super high-resolution video, this is much, much faster. For on-device image generation, this is much faster.” Benchmarks I took while reviewing the iPad Pro M5 back this up — all the GPU-based measurements showed huge improvements over the M4.Merendino noted that Apple invited the developer for image generation app Draw Things into its labs to test the app with the M5’s GPU neural accelerators and it provided about double the performance of the M4 chip and four times the performance of the M1. My testing with Draw Things backed this up. I ran four different image generation prompts on both the M4 and M5 iPad Pro, and the M5 was more than twice as fast. It typically finished the default prompts I tried in the app in about 50 seconds, while the M4 took about 2 minutes and 25 seconds. Other tasks, like large language model token generation, are six times faster on the M5 compared to the (much older) M1. Impressive, for sure, but it’s also fair to say that most iPad Pro users are likely not going to be pushing to the edge of the M5’s computational powers. The flip side of this, though, is that the iPad Pro will likely remain fast enough for all but the most demanding tasks for years. Apple knows this, and it’s evident in the way it’s positioning this new iPad Pro — it’s for demanding customers who’ve been using an M1- or M2-powered iPad Pro for years now and are ready for an upgrade. One of the main hardware differences between the redesigned M4 and M5 iPad Pros and their predecessors is that Apple made the tablet even thinner and lighter than ever, while packing in the company’s latest silicon. It’s a wild engineering feat, one that impressed me from the very first time I picked up the iPad Pro M4 last year. There is one somewhat humorous thing about the iPad Pro, which is that it’s thinner and lighter than the iPad Air — despite the Air name having historically been used for Apple’s most portable products. Just look at the iPhone Air for the latest example.That made me ponder if a more “pro” iPad should be a little thicker and heavier to accommodate a bigger battery, like what you’ll find in the MacBook Pro. The iPad Pro’s 10-hour battery life for basic tasks like web browsing and watching video isn’t short, but if you push it harder it’ll drain a lot quicker. Merendino said that the ongoing thought process behind balancing battery life, performance and size comes down to a focus on portability and versatility.“One of the things that has defined iPad since the very beginning is portability. For creative pros, the iPad Pro is untethering them from a workstation,” he said. “It's letting them create and be productive wherever they may be. And what's unique is that over the years we've made iPad more and more portable.” That’s undeniable; the first iPad was about 1.5 pounds with its 9.7-inch screen and the 13-inch iPad Pro is a quarter of a pound lighter. “But we have also made it vastly more powerful,” Merendino continued, “even though it’s a more portable device, a vastly faster device. We have still maintained that all day battery life that we know users depend on.” So while we’re probably not getting an iPad Pro with 15- or 20-hour battery life any time soon, I can respect the trade-off of making the tablet as portable as possible. It’s one of its main differentiating features compared to a Mac, after all.A rumor that started making the rounds just after the iPad Pro M5 was released puts the “Mac versus iPad” debate into a new territory, though. A few reliable sources including Mark Gurman at Bloomberg and analyst Ming-Chi Kuo both say that the M6 refresh of the MacBook Pro will usher in touchscreens for the first time on a Mac. If this happens, it’ll likely upend the debate yet again. But in the same way an iPad doesn’t really replace the Mac, I don’t think a touchscreen MacBook will necessarily be better than an iPad for some things. The iPad is still the most versatile device Apple sells, and the company believes that versatility is something people recognize and want. “With the windowing system that we built, it [still] starts with every app being fullscreen,” Jordan says. “And the idea behind that philosophy is making sure you can be the person who has iPad and is just using it on the couch to watch a show, and then can seamlessly transition to being a professional who’s connected to an external display with a Magic Keyboard and a bunch of windows open. And that versatility is really interesting, and I think customers who gravitate towards iPad are looking for that device that can go across those worlds.”This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/after-10-years-the-ipad-pro-has-finally-carved-out-its-own-identity-130108169.html?src=rss",
          "feed_position": 24,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/iPadOS26jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/how-to-improve-your-smartphone-photography-010037588.html",
          "published_at": "Wed, 22 Oct 2025 13:00:37 +0000",
          "title": "How to improve your smartphone photography",
          "standfirst": "These days, thanks to smartphones, almost everyone has a camera with them and that’s mostly a good thing. At any time, you can capture memories with family and friends, painterly sunsets and crazy spontaneous moments. The problem is most of us have endless bland photos in our camera rolls because we simply don’t know how to take great shots. When you’re on vacation or gathering with friends and family, a good photo will provide memories you can proudly share and go back to time and again. And if you’re active on social media, they’re crucial. In this article, I’ll show you how to set yourself up for photo success with the optimal settings and simple but effective composition tips from myself and a pro photographer. And if you’re interested in going further, I’ll highlight several third-party apps that provide even greater manual control. Note that this is focused only on taking photos — I’ll cover video in a future article. Take advantage of your smartphone’s camera setup Rhonda Dent for Engadget Most smartphones have two or more cameras, each with different lenses, sensors and resolution. They’re usually called the wide (or main), telephoto and ultrawide cameras. These work seamlessly together: You can simply pinch to zoom on the viewfinder to fit your subject into the scene and your phone will switch between the lenses automatically. Most smartphones offer shortcuts on their viewfinders for you to quickly jump between these, and you'll usually see numbers like 0.5x, 1x, 2x and 5x to denote the levels of zoom. Ideally, you should use each camera at its optimal setting and avoid in-between digital zooms (like 2.7x) that reduce quality. You should also know which camera is best for a given subject. People shots are best done with the main or telephoto cameras as those focal lengths flatter the subject and reduce distortion. They also allow for naturally blurred backgrounds and “bokeh” that helps your subject stand out. Since it creates weird warping around the edges of photos, the ultrawide camera is best reserved for landscape shots. Lastly, the telephoto lens is best for distant scenes, but avoid the most extreme settings (above 10x on most cameras) as your photos may become blurry or pixelated. When it comes to your phone’s portrait mode, there are caveats. While it does create a soft blurred background and “bokeh,” it does so using computational tricks. That can create issues like pixelation around your subject or an overly artificial look. To get natural blur, switch to the main or the telephoto camera, increase the zoom level and move farther away from your subject to frame them. Finally, this should go without saying, but clean your lens. Whenever you set your phone down, the camera can pick up grease or dirt that will ruin your photos. If you don’t have a microfiber cloth, clean it with any soft cotton fabric — just avoid tissue as it’s rougher than it looks and can mar your lens. Nail your settings Exposure is the only adjustment you needSteve Dent for Engadget One big plus with smartphones over dedicated cameras is that they have bigger, sharper displays. To start, boost your screen brightness when taking photos so you can easily see your subject and compose your shot. Take a few extra seconds to decide whether to snap a vertical (portrait) or horizontal (landscape) photo, depending on the subject. Get in the habit of holding your phone in a way that keeps your fingers away from the lenses, as that’s another great way to ruin a shot. Most recent iPhone and Android models automatically focus on a subject quickly and accurately. However, if multiple people are in a shot, the AI may focus on the wrong person, so be sure to tap on the correct one. Exposure, or the brightness or dimness of a subject, is typically selected automatically by your phone. Most devices will automatically average the levels across multiple faces so all the people in a shot are well-exposed. Steve Dent for Engadget One thing that smartphones are nearly as good at as cameras is macro or closeup photography. Most iPhones and Android devices let you focus very close to subjects from the main (1x) or ultra wide (0.5x) cameras. This can help you produce cool shots of insects, leaves, seashells and other things in nature. Selecting a new subject automatically changes both focus and exposure. If you tap on a dark part of the image, the camera will automatically brighten it and vice versa, but you can manually change that. On iPhones, tap a subject to bring up the sunshine icon, then move the slider to change brightness. You can also open up extra settings with the down arrow on iPhone and then select the +/- symbol. On a Pixel, open the settings (gear) icon, select brightness and move the slider. Sometimes, you might want to lock the focus and exposure when taking multiple photos of the same scene. That’s done on both iPhone or Android by clicking and holding for a couple of seconds on the desired subject. Then, the exposure and focus will stay locked until you tap again. You may need to enable this feature in your phone’s settings before it can be used. What about using the flash? It's best to use it only when you truly don't have enough light to capture a moment, as it can make shots look overly bright and unnatural. Below is a good example of a shot taken with and without a flash at night when there was barely enough natural light. iPhone 16 photo taken with flash (left) and without flash (right)Steve Dent for Engadget Most smartphones let you take photos nearly instantly from the lockscreen so you can easily capture when something unexpected occurs. It’s a good idea to learn how so you can snap a shot without too much delay. Recent iPhone models have a dedicated camera button on the right side. First, ensure the settings are configured so that you can activate it without unlocking the phone. Then, push the button once to open the camera app and then again to take a shot (the main 1x camera is selected automatically). On earlier models, simply swipe left from the lockscreen to instantly access the camera. For Pixel and other Android devices, double pressing the power or volume button will usually bring up the camera app from the lockscreen. Some iPhone and Android phones have a setting that allows you to take RAW photos. That gives you image data straight off the sensor without any sharpening or other adjustments, so it can provide a more natural look. However, editing RAW photos requires practice and the photos take up a lot of extra space on your camera roll. Most smartphones allow you to tweak settings like saturation, brightness and contrast, but it's best not to get too in the weeds. Even the experts, like my pro photographer friend Nathanael Charpentier, stick to the basics, “No complex settings, no artificial portrait mode. I just occasionally adjust the brightness when necessary,” he told me (one exception for him is black & white photos). This then frees him to “focus entirely on what matters to me: composition.” Composition Nathanael Charpentier for Engadget Smartphones don’t have the same quality as dedicated cameras, but that forces you to think about lighting and composition. Pro photographers like Charpentier will tell you that, whether you’re using a phone or $8,000 camera, the most important part of capturing a shot is the framing. Many photographers use the “rule of thirds.” This stipulates that key elements like people and geographical features should be placed in thirds across a photo because it’s pleasing to the eye. Simply cutting a landscape in half between the sky and the ground should often be avoided to keep the framing interesting. To help with this, many smartphone cameras include a grid that divides the screen into thirds (turn on the “Grid” setting on iPhone or “Grid Type” on a Pixel device and choose 3x3). When that’s enabled, you can place your primary subject and other elements near where those lines intersect. These grids can also help you keep shots level. Sometimes, though, a symmetric composition is best. If you want to shoot down a dock, for example, you can center it to take advantage of the converging lines. Then, you can slightly break that symmetry with other objects like a mountain, tree or bird. Rule of thirds used to divide a photo's elementsSteve Dent for Engadget Other composition tips include the use of diagonal rather than horizontal or vertical lines to break up a composition, or curved roads or paths that guide the viewer’s eye. Another popular technique is to use converging lines in architecture when shooting up at buildings. You can also try using foreground objects close to the camera (tree leaves, a pole or a person) to frame a scene. To create dramatic shots using the wide or ultrawide cameras, hold your phone as low as possible — you can even turn it upside down to get it right next to the ground. Interesting photos also come from strong lighting contrast, particularly shadows. To emphasize that, you can use the exposure compensation (brightness) settings mentioned earlier to make the shadows even darker while keeping your subject well exposed. To find the ideal subject or environment, look for patterns and punchy colors. Don’t be afraid to shoot straight into the light source to create dramatic, backlit silhouettes. “Smartphones do almost everything well except scene exposure; usually the photos are too bright,” Charpentier says. “And that’s why I very often correct the exposure of my photos. It’s a basic setting and done very simply on iPhone and most Android devices.” Many smartphone cameras also take great macro photos. You can use that to get close-up shots of subjects ranging from insects in nature to food. Finally, try using the black and white settings on your camera to create a nostalgic mood or emphasize forms and lines. Take your photography further with apps Taken with Lightroom MobileNathanael Charpentier for Engadget If you want to play with settings like shutter speed and ISO, reduce automatic or AI settings, take RAW photos or change noise reduction settings, you’ll usually need a third-party app. Here are three I’d recommend. VSCO VSCO is a popular editing and camera app for both iOS and Android that had a moment on TikTok several years ago. It gives you control of basic settings like exposure (via a nice slider), shutter speed, ISO and white balance. It also lets you separate focus and exposure points, so you can keep one subject in focus but change the lighting in another area of the scene. It offers RAW support and filters, though many of the latter require a subscription. Lightroom Mobile To focus on lighting and exposure, check out Lightroom Mobile. It automatically highlights overexposed areas of an image and then lets you easily dial brightness up and down, change settings like ISO and shutter speed and even apply filters. Once you’re done shooting, you can continue editing your photos afterwards using many of the tools offered in the desktop version. Though no subscription is required, a paid plan is needed for some of the content. If you’re on iPhone, Adobe has an impressive new experimental app called Indigo that you can try for free. It uses computational photography to improve things like exposure and detail to make photos look more natural. Halide Mark II (iOS only) For control over just about every aspect of your smartphone camera, Halide is the best choice. Unfortunately, it’s only available on iOS. For those in Apple’s ecosystem, it lets you shoot RAW photos with minimal processing (sharpening, etc.) and, according to the developer, has “zero AI right out of the camera.” At the same time, its “Depth Mode” lets you capture portrait shots (ie, artificial depth of field) with any subject. It also comes with a manual mode and tools like color zebras and waveforms to aid with exposure. Halide Mark II isn’t free, though, as it’s $60 for a one-time purchase or $20 yearly. Before you dive into using an app, I’d recommend that you practice the basics until you feel confident taking photos in any situation. That means making the best use of your smartphone’s camera setup for a given situation, nailing your settings each time and mastering composition. Then, apps like Lightroom Mobile will let you take your photos to another level — like an artist graduating from water colors to oil paint.This article originally appeared on Engadget at https://www.engadget.com/cameras/how-to-improve-your-smartphone-photography-010037588.html?src=rss",
          "content": "These days, thanks to smartphones, almost everyone has a camera with them and that’s mostly a good thing. At any time, you can capture memories with family and friends, painterly sunsets and crazy spontaneous moments. The problem is most of us have endless bland photos in our camera rolls because we simply don’t know how to take great shots. When you’re on vacation or gathering with friends and family, a good photo will provide memories you can proudly share and go back to time and again. And if you’re active on social media, they’re crucial. In this article, I’ll show you how to set yourself up for photo success with the optimal settings and simple but effective composition tips from myself and a pro photographer. And if you’re interested in going further, I’ll highlight several third-party apps that provide even greater manual control. Note that this is focused only on taking photos — I’ll cover video in a future article. Take advantage of your smartphone’s camera setup Rhonda Dent for Engadget Most smartphones have two or more cameras, each with different lenses, sensors and resolution. They’re usually called the wide (or main), telephoto and ultrawide cameras. These work seamlessly together: You can simply pinch to zoom on the viewfinder to fit your subject into the scene and your phone will switch between the lenses automatically. Most smartphones offer shortcuts on their viewfinders for you to quickly jump between these, and you'll usually see numbers like 0.5x, 1x, 2x and 5x to denote the levels of zoom. Ideally, you should use each camera at its optimal setting and avoid in-between digital zooms (like 2.7x) that reduce quality. You should also know which camera is best for a given subject. People shots are best done with the main or telephoto cameras as those focal lengths flatter the subject and reduce distortion. They also allow for naturally blurred backgrounds and “bokeh” that helps your subject stand out. Since it creates weird warping around the edges of photos, the ultrawide camera is best reserved for landscape shots. Lastly, the telephoto lens is best for distant scenes, but avoid the most extreme settings (above 10x on most cameras) as your photos may become blurry or pixelated. When it comes to your phone’s portrait mode, there are caveats. While it does create a soft blurred background and “bokeh,” it does so using computational tricks. That can create issues like pixelation around your subject or an overly artificial look. To get natural blur, switch to the main or the telephoto camera, increase the zoom level and move farther away from your subject to frame them. Finally, this should go without saying, but clean your lens. Whenever you set your phone down, the camera can pick up grease or dirt that will ruin your photos. If you don’t have a microfiber cloth, clean it with any soft cotton fabric — just avoid tissue as it’s rougher than it looks and can mar your lens. Nail your settings Exposure is the only adjustment you needSteve Dent for Engadget One big plus with smartphones over dedicated cameras is that they have bigger, sharper displays. To start, boost your screen brightness when taking photos so you can easily see your subject and compose your shot. Take a few extra seconds to decide whether to snap a vertical (portrait) or horizontal (landscape) photo, depending on the subject. Get in the habit of holding your phone in a way that keeps your fingers away from the lenses, as that’s another great way to ruin a shot. Most recent iPhone and Android models automatically focus on a subject quickly and accurately. However, if multiple people are in a shot, the AI may focus on the wrong person, so be sure to tap on the correct one. Exposure, or the brightness or dimness of a subject, is typically selected automatically by your phone. Most devices will automatically average the levels across multiple faces so all the people in a shot are well-exposed. Steve Dent for Engadget One thing that smartphones are nearly as good at as cameras is macro or closeup photography. Most iPhones and Android devices let you focus very close to subjects from the main (1x) or ultra wide (0.5x) cameras. This can help you produce cool shots of insects, leaves, seashells and other things in nature. Selecting a new subject automatically changes both focus and exposure. If you tap on a dark part of the image, the camera will automatically brighten it and vice versa, but you can manually change that. On iPhones, tap a subject to bring up the sunshine icon, then move the slider to change brightness. You can also open up extra settings with the down arrow on iPhone and then select the +/- symbol. On a Pixel, open the settings (gear) icon, select brightness and move the slider. Sometimes, you might want to lock the focus and exposure when taking multiple photos of the same scene. That’s done on both iPhone or Android by clicking and holding for a couple of seconds on the desired subject. Then, the exposure and focus will stay locked until you tap again. You may need to enable this feature in your phone’s settings before it can be used. What about using the flash? It's best to use it only when you truly don't have enough light to capture a moment, as it can make shots look overly bright and unnatural. Below is a good example of a shot taken with and without a flash at night when there was barely enough natural light. iPhone 16 photo taken with flash (left) and without flash (right)Steve Dent for Engadget Most smartphones let you take photos nearly instantly from the lockscreen so you can easily capture when something unexpected occurs. It’s a good idea to learn how so you can snap a shot without too much delay. Recent iPhone models have a dedicated camera button on the right side. First, ensure the settings are configured so that you can activate it without unlocking the phone. Then, push the button once to open the camera app and then again to take a shot (the main 1x camera is selected automatically). On earlier models, simply swipe left from the lockscreen to instantly access the camera. For Pixel and other Android devices, double pressing the power or volume button will usually bring up the camera app from the lockscreen. Some iPhone and Android phones have a setting that allows you to take RAW photos. That gives you image data straight off the sensor without any sharpening or other adjustments, so it can provide a more natural look. However, editing RAW photos requires practice and the photos take up a lot of extra space on your camera roll. Most smartphones allow you to tweak settings like saturation, brightness and contrast, but it's best not to get too in the weeds. Even the experts, like my pro photographer friend Nathanael Charpentier, stick to the basics, “No complex settings, no artificial portrait mode. I just occasionally adjust the brightness when necessary,” he told me (one exception for him is black & white photos). This then frees him to “focus entirely on what matters to me: composition.” Composition Nathanael Charpentier for Engadget Smartphones don’t have the same quality as dedicated cameras, but that forces you to think about lighting and composition. Pro photographers like Charpentier will tell you that, whether you’re using a phone or $8,000 camera, the most important part of capturing a shot is the framing. Many photographers use the “rule of thirds.” This stipulates that key elements like people and geographical features should be placed in thirds across a photo because it’s pleasing to the eye. Simply cutting a landscape in half between the sky and the ground should often be avoided to keep the framing interesting. To help with this, many smartphone cameras include a grid that divides the screen into thirds (turn on the “Grid” setting on iPhone or “Grid Type” on a Pixel device and choose 3x3). When that’s enabled, you can place your primary subject and other elements near where those lines intersect. These grids can also help you keep shots level. Sometimes, though, a symmetric composition is best. If you want to shoot down a dock, for example, you can center it to take advantage of the converging lines. Then, you can slightly break that symmetry with other objects like a mountain, tree or bird. Rule of thirds used to divide a photo's elementsSteve Dent for Engadget Other composition tips include the use of diagonal rather than horizontal or vertical lines to break up a composition, or curved roads or paths that guide the viewer’s eye. Another popular technique is to use converging lines in architecture when shooting up at buildings. You can also try using foreground objects close to the camera (tree leaves, a pole or a person) to frame a scene. To create dramatic shots using the wide or ultrawide cameras, hold your phone as low as possible — you can even turn it upside down to get it right next to the ground. Interesting photos also come from strong lighting contrast, particularly shadows. To emphasize that, you can use the exposure compensation (brightness) settings mentioned earlier to make the shadows even darker while keeping your subject well exposed. To find the ideal subject or environment, look for patterns and punchy colors. Don’t be afraid to shoot straight into the light source to create dramatic, backlit silhouettes. “Smartphones do almost everything well except scene exposure; usually the photos are too bright,” Charpentier says. “And that’s why I very often correct the exposure of my photos. It’s a basic setting and done very simply on iPhone and most Android devices.” Many smartphone cameras also take great macro photos. You can use that to get close-up shots of subjects ranging from insects in nature to food. Finally, try using the black and white settings on your camera to create a nostalgic mood or emphasize forms and lines. Take your photography further with apps Taken with Lightroom MobileNathanael Charpentier for Engadget If you want to play with settings like shutter speed and ISO, reduce automatic or AI settings, take RAW photos or change noise reduction settings, you’ll usually need a third-party app. Here are three I’d recommend. VSCO VSCO is a popular editing and camera app for both iOS and Android that had a moment on TikTok several years ago. It gives you control of basic settings like exposure (via a nice slider), shutter speed, ISO and white balance. It also lets you separate focus and exposure points, so you can keep one subject in focus but change the lighting in another area of the scene. It offers RAW support and filters, though many of the latter require a subscription. Lightroom Mobile To focus on lighting and exposure, check out Lightroom Mobile. It automatically highlights overexposed areas of an image and then lets you easily dial brightness up and down, change settings like ISO and shutter speed and even apply filters. Once you’re done shooting, you can continue editing your photos afterwards using many of the tools offered in the desktop version. Though no subscription is required, a paid plan is needed for some of the content. If you’re on iPhone, Adobe has an impressive new experimental app called Indigo that you can try for free. It uses computational photography to improve things like exposure and detail to make photos look more natural. Halide Mark II (iOS only) For control over just about every aspect of your smartphone camera, Halide is the best choice. Unfortunately, it’s only available on iOS. For those in Apple’s ecosystem, it lets you shoot RAW photos with minimal processing (sharpening, etc.) and, according to the developer, has “zero AI right out of the camera.” At the same time, its “Depth Mode” lets you capture portrait shots (ie, artificial depth of field) with any subject. It also comes with a manual mode and tools like color zebras and waveforms to aid with exposure. Halide Mark II isn’t free, though, as it’s $60 for a one-time purchase or $20 yearly. Before you dive into using an app, I’d recommend that you practice the basics until you feel confident taking photos in any situation. That means making the best use of your smartphone’s camera setup for a given situation, nailing your settings each time and mastering composition. Then, apps like Lightroom Mobile will let you take your photos to another level — like an artist graduating from water colors to oil paint.This article originally appeared on Engadget at https://www.engadget.com/cameras/how-to-improve-your-smartphone-photography-010037588.html?src=rss",
          "feed_position": 25,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/88406f00-a94f-11f0-bcd7-5fd7eaf375fe"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/kai-fu-lees-brutal-assessment-america-is-already-losing-the-ai-hardware-war",
          "published_at": "Wed, 22 Oct 2025 12:30:00 GMT",
          "title": "Kai-Fu Lee's brutal assessment: America is already losing the AI hardware war to China",
          "standfirst": "China is on track to dominate consumer artificial intelligence applications and robotics manufacturing within years, but the United States will maintain its substantial lead in enterprise AI adoption and cutting-edge research, according to Kai-Fu Lee, one of the world&#x27;s most prominent AI scientists and investors.In a rare, unvarnished assessment delivered via video link from Beijing to the TED AI conference in San Francisco Tuesday, Lee — a former executive at Apple, Microsoft, and Google who now runs both a major venture capital firm and his own AI company — laid out a technology landscape splitting along geographic and economic lines, with profound implications for both commercial competition and national security.\"China&#x27;s robotics has the advantage of having integrated AI into much lower costs, better supply chain and fast turnaround, so companies like Unitree are actually the farthest ahead in the world in terms of building affordable, embodied humanoid AI,\" Lee said, referring to a Chinese robotics manufacturer that has undercut Western competitors on price while advancing capabilities.The comments, made to a room filled with Silicon Valley executives, investors, and researchers, represented one of the most detailed public assessments from Lee about the comparative strengths and weaknesses of the world&#x27;s two AI superpowers — and suggested that the race for artificial intelligence leadership is becoming less a single contest than a series of parallel competitions with different winners.Why venture capital is flowing in opposite directions in the U.S. and ChinaAt the heart of Lee&#x27;s analysis lies a fundamental difference in how capital flows in the two countries&#x27; innovation ecosystems. American venture capitalists, Lee said, are pouring money into generative AI companies building large language models and enterprise software, while Chinese investors are betting heavily on robotics and hardware.\"The VCs in the US don&#x27;t fund robotics the way the VCs do in China,\" Lee said. \"Just like the VCs in China don&#x27;t fund generative AI the way the VCs do in the US.\"This investment divergence reflects different economic incentives and market structures. In the United States, where companies have grown accustomed to paying for software subscriptions and where labor costs are high, enterprise AI tools that boost white-collar productivity command premium prices. In China, where software subscription models have historically struggled to gain traction but manufacturing dominates the economy, robotics offers a clearer path to commercialization.The result, Lee suggested, is that each country is pulling ahead in different domains — and may continue to do so.\"China&#x27;s got some challenges to overcome in getting a company funded as well as OpenAI or Anthropic,\" Lee acknowledged, referring to the leading American AI labs. \"But I think U.S., on the flip side, will have trouble developing the investment interest and value creation in the robotics\" sector.Why American companies dominate enterprise AI while Chinese firms struggle with subscriptionsLee was explicit about one area where the United States maintains what appears to be a durable advantage: getting businesses to actually adopt and pay for AI software.\"The enterprise adoption will clearly be led by the United States,\" Lee said. \"The Chinese companies have not yet developed a habit of paying for software on a subscription.\"This seemingly mundane difference in business culture — whether companies will pay monthly fees for software — has become a critical factor in the AI race. The explosion of spending on tools like GitHub Copilot, ChatGPT Enterprise, and other AI-powered productivity software has fueled American companies&#x27; ability to invest billions in further research and development.Lee noted that China has historically overcome similar challenges in consumer technology by developing alternative business models. \"In the early days of internet software, China was also well behind because people weren&#x27;t willing to pay for software,\" he said. \"But then advertising models, e-commerce models really propelled China forward.\"Still, he suggested, someone will need to \"find a new business model that isn&#x27;t just pay per software per use or per month basis. That&#x27;s going to not happen in China anytime soon.\"The implication: American companies building enterprise AI tools have a window — perhaps a substantial one — where they can generate revenue and reinvest in R&D without facing serious Chinese competition in their core market.How ByteDance, Alibaba and Tencent will outpace Meta and Google in consumer AIWhere Lee sees China pulling ahead decisively is in consumer-facing AI applications — the kind embedded in social media, e-commerce, and entertainment platforms that billions of people use daily.\"In terms of consumer usage, that&#x27;s likely to happen,\" Lee said, referring to China matching or surpassing the United States in AI deployment. \"The Chinese giants, like ByteDance and Alibaba and Tencent, will definitely move a lot faster than their equivalent in the United States, companies like Meta, YouTube and so on.\"Lee pointed to a cultural advantage: Chinese technology companies have spent the past decade obsessively optimizing for user engagement and product-market fit in brutally competitive markets. \"The Chinese giants really work tenaciously, and they have mastered the art of figuring out product market fit,\" he said. \"Now they have to add technology to it. So that is inevitably going to happen.\"This assessment aligns with recent industry observations. ByteDance&#x27;s TikTok became the world&#x27;s most downloaded app through sophisticated AI-driven content recommendation, and Chinese companies have pioneered AI-powered features in areas like live-streaming commerce and short-form video that Western companies later copied.Lee also noted that China has already deployed AI more widely in certain domains. \"There are a lot of areas where China has also done a great job, such as using computer vision, speech recognition, and translation more widely,\" he said.The surprising open-source shift that has Chinese models beating Meta&#x27;s LlamaPerhaps Lee&#x27;s most striking data point concerned open-source AI development — an area where China appears to have seized leadership from American companies in a remarkably short time.\"The 10 highest rated open source [models] are from China,\" Lee said. \"These companies have now eclipsed Meta&#x27;s Llama, which used to be number one.\"This represents a significant shift. Meta&#x27;s Llama models were widely viewed as the gold standard for open-source large language models as recently as early 2024. But Chinese companies — including Lee&#x27;s own firm, 01.AI, along with Alibaba, Baidu, and others — have released a flood of open-source models that, according to various benchmarks, now outperform their American counterparts.The open-source question has become a flashpoint in AI development. Lee made an extensive case for why open-source models will prove essential to the technology&#x27;s future, even as closed models from companies like OpenAI command higher prices and, often, superior performance.\"I think open source has a number of major advantages,\" Lee argued. With open-source models, \"you can examine it, tune it, improve it. It&#x27;s yours, and it&#x27;s free, and it&#x27;s important for building if you want to build an application or tune the model to do something specific.\"He drew an analogy to operating systems: \"People who work in operating systems loved Linux, and that&#x27;s why its adoption went through the roof. And I think in the future, open source will also allow people to tune a sovereign model for a country, make it work better for a particular language.\"Still, Lee predicted both approaches will coexist. \"I don&#x27;t think open source models will win,\" he said. \"I think just like we have Apple, which is closed, but provides a somewhat better experience than Android... I think we&#x27;re going to see more apps using open-source models, more engineers wanting to build open-source models, but I think more money will remain in the closed model.\"Why China&#x27;s manufacturing advantage makes the robotics race &#x27;not over, but&#x27; nearly decidedOn robotics, Lee&#x27;s message was blunt: the combination of China&#x27;s manufacturing prowess, lower costs, and aggressive investment has created an advantage that will be difficult for American companies to overcome.When asked directly whether the robotics race was already over with China victorious, Lee hedged only slightly. \"It&#x27;s not over, but I think the U.S. is still capable of coming up with the best robotic research ideas,\" he said. \"But the VCs in the U.S. don&#x27;t fund robotics the way the VCs do in China.\"The challenge is structural. Building robots requires not just software and AI, but hardware manufacturing at scale — precisely the kind of integrated supply chain and low-cost production that China has spent decades perfecting. While American labs at universities and companies like Boston Dynamics continue to produce impressive research prototypes, turning those prototypes into affordable commercial products requires the manufacturing ecosystem that China possesses.Companies like Unitree have demonstrated this advantage concretely. The company&#x27;s humanoid robots and quadrupedal robots cost a fraction of their American-made equivalents while offering comparable or superior capabilities — a price-to-performance ratio that could prove decisive in commercial markets.What worries Lee most: not AGI, but the race itselfDespite his generally measured tone about China&#x27;s AI development, Lee expressed concern about one area where he believes the global AI community faces real danger — not the far-future risk of superintelligent AI, but the near-term consequences of moving too fast.When asked about AGI risks, Lee reframed the question. \"I&#x27;m less afraid of AI becoming self-aware and causing danger for humans in the short term,\" he said, \"but more worried about it being used by bad people to do terrible things, or by the AI race pushing people to work so hard, so fast and furious and move fast and break things that they build products that have problems and holes to be exploited.\"He continued: \"I&#x27;m very worried about that. In fact, I think some terrible event will happen that will be a wake up call from this sort of problem.\"Lee&#x27;s perspective carries unusual weight because of his unique vantage point spanning both Chinese and American AI development. Over a career spanning more than three decades, he has held senior positions at Apple, Microsoft, and Google, while also founding Sinovation Ventures, which has invested in more than 400 companies across both countries. His AI company, 01.AI, founded in 2023, has released several open-source models that rank among the most capable in the world.For American companies and policymakers, Lee&#x27;s analysis presents a complex strategic picture. The United States appears to have clear advantages in enterprise AI software, fundamental research, and computing infrastructure. But China is moving faster in consumer applications, manufacturing robotics at lower costs, and potentially pulling ahead in open-source model development.The bifurcation suggests that rather than a single \"winner\" in AI, the world may be heading toward a technology landscape where different countries excel in different domains — with all the economic and geopolitical complications that implies.As the TED AI conference continued Wednesday, Lee&#x27;s assessment hung over subsequent discussions. His message seemed clear: the AI race is not one contest, but many — and the United States and China are each winning different races.Standing in the conference hall afterward, one venture capitalist, who asked not to be named, summed up the mood in the room: \"We&#x27;re not competing with China anymore. We&#x27;re competing on parallel tracks.\" Whether those tracks eventually converge — or diverge into entirely separate technology ecosystems — may be the defining question of the next decade.",
          "content": "China is on track to dominate consumer artificial intelligence applications and robotics manufacturing within years, but the United States will maintain its substantial lead in enterprise AI adoption and cutting-edge research, according to Kai-Fu Lee, one of the world&#x27;s most prominent AI scientists and investors.In a rare, unvarnished assessment delivered via video link from Beijing to the TED AI conference in San Francisco Tuesday, Lee — a former executive at Apple, Microsoft, and Google who now runs both a major venture capital firm and his own AI company — laid out a technology landscape splitting along geographic and economic lines, with profound implications for both commercial competition and national security.\"China&#x27;s robotics has the advantage of having integrated AI into much lower costs, better supply chain and fast turnaround, so companies like Unitree are actually the farthest ahead in the world in terms of building affordable, embodied humanoid AI,\" Lee said, referring to a Chinese robotics manufacturer that has undercut Western competitors on price while advancing capabilities.The comments, made to a room filled with Silicon Valley executives, investors, and researchers, represented one of the most detailed public assessments from Lee about the comparative strengths and weaknesses of the world&#x27;s two AI superpowers — and suggested that the race for artificial intelligence leadership is becoming less a single contest than a series of parallel competitions with different winners.Why venture capital is flowing in opposite directions in the U.S. and ChinaAt the heart of Lee&#x27;s analysis lies a fundamental difference in how capital flows in the two countries&#x27; innovation ecosystems. American venture capitalists, Lee said, are pouring money into generative AI companies building large language models and enterprise software, while Chinese investors are betting heavily on robotics and hardware.\"The VCs in the US don&#x27;t fund robotics the way the VCs do in China,\" Lee said. \"Just like the VCs in China don&#x27;t fund generative AI the way the VCs do in the US.\"This investment divergence reflects different economic incentives and market structures. In the United States, where companies have grown accustomed to paying for software subscriptions and where labor costs are high, enterprise AI tools that boost white-collar productivity command premium prices. In China, where software subscription models have historically struggled to gain traction but manufacturing dominates the economy, robotics offers a clearer path to commercialization.The result, Lee suggested, is that each country is pulling ahead in different domains — and may continue to do so.\"China&#x27;s got some challenges to overcome in getting a company funded as well as OpenAI or Anthropic,\" Lee acknowledged, referring to the leading American AI labs. \"But I think U.S., on the flip side, will have trouble developing the investment interest and value creation in the robotics\" sector.Why American companies dominate enterprise AI while Chinese firms struggle with subscriptionsLee was explicit about one area where the United States maintains what appears to be a durable advantage: getting businesses to actually adopt and pay for AI software.\"The enterprise adoption will clearly be led by the United States,\" Lee said. \"The Chinese companies have not yet developed a habit of paying for software on a subscription.\"This seemingly mundane difference in business culture — whether companies will pay monthly fees for software — has become a critical factor in the AI race. The explosion of spending on tools like GitHub Copilot, ChatGPT Enterprise, and other AI-powered productivity software has fueled American companies&#x27; ability to invest billions in further research and development.Lee noted that China has historically overcome similar challenges in consumer technology by developing alternative business models. \"In the early days of internet software, China was also well behind because people weren&#x27;t willing to pay for software,\" he said. \"But then advertising models, e-commerce models really propelled China forward.\"Still, he suggested, someone will need to \"find a new business model that isn&#x27;t just pay per software per use or per month basis. That&#x27;s going to not happen in China anytime soon.\"The implication: American companies building enterprise AI tools have a window — perhaps a substantial one — where they can generate revenue and reinvest in R&D without facing serious Chinese competition in their core market.How ByteDance, Alibaba and Tencent will outpace Meta and Google in consumer AIWhere Lee sees China pulling ahead decisively is in consumer-facing AI applications — the kind embedded in social media, e-commerce, and entertainment platforms that billions of people use daily.\"In terms of consumer usage, that&#x27;s likely to happen,\" Lee said, referring to China matching or surpassing the United States in AI deployment. \"The Chinese giants, like ByteDance and Alibaba and Tencent, will definitely move a lot faster than their equivalent in the United States, companies like Meta, YouTube and so on.\"Lee pointed to a cultural advantage: Chinese technology companies have spent the past decade obsessively optimizing for user engagement and product-market fit in brutally competitive markets. \"The Chinese giants really work tenaciously, and they have mastered the art of figuring out product market fit,\" he said. \"Now they have to add technology to it. So that is inevitably going to happen.\"This assessment aligns with recent industry observations. ByteDance&#x27;s TikTok became the world&#x27;s most downloaded app through sophisticated AI-driven content recommendation, and Chinese companies have pioneered AI-powered features in areas like live-streaming commerce and short-form video that Western companies later copied.Lee also noted that China has already deployed AI more widely in certain domains. \"There are a lot of areas where China has also done a great job, such as using computer vision, speech recognition, and translation more widely,\" he said.The surprising open-source shift that has Chinese models beating Meta&#x27;s LlamaPerhaps Lee&#x27;s most striking data point concerned open-source AI development — an area where China appears to have seized leadership from American companies in a remarkably short time.\"The 10 highest rated open source [models] are from China,\" Lee said. \"These companies have now eclipsed Meta&#x27;s Llama, which used to be number one.\"This represents a significant shift. Meta&#x27;s Llama models were widely viewed as the gold standard for open-source large language models as recently as early 2024. But Chinese companies — including Lee&#x27;s own firm, 01.AI, along with Alibaba, Baidu, and others — have released a flood of open-source models that, according to various benchmarks, now outperform their American counterparts.The open-source question has become a flashpoint in AI development. Lee made an extensive case for why open-source models will prove essential to the technology&#x27;s future, even as closed models from companies like OpenAI command higher prices and, often, superior performance.\"I think open source has a number of major advantages,\" Lee argued. With open-source models, \"you can examine it, tune it, improve it. It&#x27;s yours, and it&#x27;s free, and it&#x27;s important for building if you want to build an application or tune the model to do something specific.\"He drew an analogy to operating systems: \"People who work in operating systems loved Linux, and that&#x27;s why its adoption went through the roof. And I think in the future, open source will also allow people to tune a sovereign model for a country, make it work better for a particular language.\"Still, Lee predicted both approaches will coexist. \"I don&#x27;t think open source models will win,\" he said. \"I think just like we have Apple, which is closed, but provides a somewhat better experience than Android... I think we&#x27;re going to see more apps using open-source models, more engineers wanting to build open-source models, but I think more money will remain in the closed model.\"Why China&#x27;s manufacturing advantage makes the robotics race &#x27;not over, but&#x27; nearly decidedOn robotics, Lee&#x27;s message was blunt: the combination of China&#x27;s manufacturing prowess, lower costs, and aggressive investment has created an advantage that will be difficult for American companies to overcome.When asked directly whether the robotics race was already over with China victorious, Lee hedged only slightly. \"It&#x27;s not over, but I think the U.S. is still capable of coming up with the best robotic research ideas,\" he said. \"But the VCs in the U.S. don&#x27;t fund robotics the way the VCs do in China.\"The challenge is structural. Building robots requires not just software and AI, but hardware manufacturing at scale — precisely the kind of integrated supply chain and low-cost production that China has spent decades perfecting. While American labs at universities and companies like Boston Dynamics continue to produce impressive research prototypes, turning those prototypes into affordable commercial products requires the manufacturing ecosystem that China possesses.Companies like Unitree have demonstrated this advantage concretely. The company&#x27;s humanoid robots and quadrupedal robots cost a fraction of their American-made equivalents while offering comparable or superior capabilities — a price-to-performance ratio that could prove decisive in commercial markets.What worries Lee most: not AGI, but the race itselfDespite his generally measured tone about China&#x27;s AI development, Lee expressed concern about one area where he believes the global AI community faces real danger — not the far-future risk of superintelligent AI, but the near-term consequences of moving too fast.When asked about AGI risks, Lee reframed the question. \"I&#x27;m less afraid of AI becoming self-aware and causing danger for humans in the short term,\" he said, \"but more worried about it being used by bad people to do terrible things, or by the AI race pushing people to work so hard, so fast and furious and move fast and break things that they build products that have problems and holes to be exploited.\"He continued: \"I&#x27;m very worried about that. In fact, I think some terrible event will happen that will be a wake up call from this sort of problem.\"Lee&#x27;s perspective carries unusual weight because of his unique vantage point spanning both Chinese and American AI development. Over a career spanning more than three decades, he has held senior positions at Apple, Microsoft, and Google, while also founding Sinovation Ventures, which has invested in more than 400 companies across both countries. His AI company, 01.AI, founded in 2023, has released several open-source models that rank among the most capable in the world.For American companies and policymakers, Lee&#x27;s analysis presents a complex strategic picture. The United States appears to have clear advantages in enterprise AI software, fundamental research, and computing infrastructure. But China is moving faster in consumer applications, manufacturing robotics at lower costs, and potentially pulling ahead in open-source model development.The bifurcation suggests that rather than a single \"winner\" in AI, the world may be heading toward a technology landscape where different countries excel in different domains — with all the economic and geopolitical complications that implies.As the TED AI conference continued Wednesday, Lee&#x27;s assessment hung over subsequent discussions. His message seemed clear: the AI race is not one contest, but many — and the United States and China are each winning different races.Standing in the conference hall afterward, one venture capitalist, who asked not to be named, summed up the mood in the room: \"We&#x27;re not competing with China anymore. We&#x27;re competing on parallel tracks.\" Whether those tracks eventually converge — or diverge into entirely separate technology ecosystems — may be the defining question of the next decade.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/ayDtsYfCFDVHHKnTvWKwk/04173bcfce3f9d53ecd9fe3ecfd14d5c/nuneybits_Vector_art_of_Chinese_flag-coded_AI_chip_6c9fcafc-8614-4d3b-858f-d64bede8c2df.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/best-tablets-150026056.html",
          "published_at": "Wed, 22 Oct 2025 12:01:27 +0000",
          "title": "The best tablets for 2025: Tested and reviewed by our experts",
          "standfirst": "Tablets are the perfect middle ground between your phone and laptop, giving you the best of both worlds. Whether you want a lightweight device to binge your favorite shows, a larger screen for mobile gaming or a portable way to get some work done on the go, a tablet can do it all. They’re also great for keeping kids entertained, managing work tasks or sharing family moments through video calls. When a phone feels too small and lugging around a laptop is just too much, that’s where tablets fit into the mix.For many, the Apple iPad is the go-to choice, and it’s easy to see why with its smooth performance and endless app options. But don’t worry if iOS isn’t your thing — there are plenty of Android alternatives out there, offering the same level of flexibility without locking you into Apple’s ecosystem. Plus, if you’re on a budget, there are more affordable options that still pack a punch. Whether you’re looking for a premium tablet for work, a kid-friendly device with parental controls or just a reliable everyday companion, we’ve tested all of the big players (and many others) to find the best tablets worth your money right now. Table of contents Best tablets for 2025 Important things to consider before buying a tablet How we test tablets Other tablets we tested Tablet FAQs Tablet accessories Best tablets for 2025 Important things to consider before buying a tablet Before you start looking at specific devices, the number one thing you should do is figure out what you plan to use your new tablet for. That’s because if all you need is something to keep a kid busy, buying a brand new Apple iPad Air or iPad Pro doesn’t make a ton of sense. On the flip side, if you want to use a tablet for video editing or drawing, you’ll need to take things like performance, versatility and stylus support more seriously — especially if you're considering using it as a laptop replacement. You’ll also want to think about stuff like how often you plan on traveling with the device and if it’s more for productivity, or for less demanding stuff like web browsing or streaming shows. There’s also an important trade-off to consider when it comes to battery life as well. Larger devices tend to have longer runtimes, though an increase in size may make it less portable. How we test tablets When evaluating different tablets, there are a few important things we look for above all else: solid performance, a good screen and long battery life. For performance, we run a handful of synthetic tests like Geekbench 6, while also performing a number of hands-on, real-world use cases such as editing photos and playing games. And with tablets often serving as hybrid devices, we also consider how easy it is to multitask and switch quickly between various apps. The more responsive a device feels, the better. Because a tablet’s display is such a critical component, we also view a wide range of content to gauge things like brightness, color gamut and dynamic range. It’s important to take into account the difference between various panel types like OLED, which typically produce richer colors and excellent contrast but may not be as bright as a mini LED display. Recently, refresh rate has become an increasingly important spec as 90Hz and 120Hz screens can make scrolling smoother and graphics appear sharper in games. We also consider a tablet’s design (including things like size, weight and water resistance), its connectivity (WiFi, Bluetooth, NFC, 5G, et cetera) and special features like stylus support or the ability to serve as a secondary display. That’s because, while tablets were often viewed as content consumption devices in the past, higher-end devices like the Surface Pro and iPad Pro are more than capable of replacing a laptop for a lot of people. Finally, we test battery life by running our standard local video rundown test, which involves playing a single video on a loop from 100 percent until it runs out of juice. Ideally, a tablet should be able to last an entire working day, but longer runtimes are always welcome — especially for users relying on them for productivity, entertainment and storage options on the go. Other tablets we tested Apple iPad mini Apple updated the iPad mini for 2024 with some under-the-hood changes including a new processor and additional RAM to help support Apple Intelligence features. While the iPad mini is one of the best iPads you can buy, its small size makes it a bit niche. Only if you prefer your tablet be the size of an ereader should you consider this one. Google Pixel Tablet The Google Pixel Tablet excels as a smart display rather than a simple tablet. As the latter, it's unexciting, but when paired with its speaker/charging dock, it becomes much more useful. It could be a good option for those that already live within the Google ecosystem and use the Google Assistant often, or those who like the idea of a tablet that can be docked and used as a smart display as well. OnePlus Pad The solid OnePlus Pad is let down by Android because there aren't many Android apps designed to be used on a large display like this model's 11.6-inch panel. Otherwise, the hardware is well-designed, its companion stylus is comfortable to use and it has an excellent battery life. Tablet FAQs What is the best brand for tablets? The best brand for tablets is really the brand you feel most comfortable with. We recommend taking stock of the gadgets you already have — do you live in the Apple ecosystem already? An iPad might be best for you then. Do you have a Samsung phone? If so, a Galaxy Tab will likely be the most convenient choice. There is no one \"best brand\" for tablets; you’ll find good options made by companies including Apple, Google, Samsung, Microsoft and Amazon. Can a tablet replace a laptop? It’s possible for a tablet to replace a laptop, but you’ll need a few accessories to truly make the experience as close as possible to that of a traditional notebook. A keyboard is a must, be it a keyboard case or a Bluetooth accessory that you keep with you. Some keyboard cases, like apple’s Magic Keyboard for the iPad, have a built-in trackpad, which will be more ergonomic than tapping on your tablet’s screen for input. Additionally, you could go one step further and use a wireless mouse that connects via Bluetooth to your tablet. If you’re primarily looking for a tablet to replace your laptop, consider buying a 2-in-1 laptop since those systems typically consist of high-powered tablets that are designed to work well with (and without) keyboards. What size screen do I need? Figuring out the best screen size for you will also be related to the kind of work (or play) you intend to do. Larger screens make it much easier to view two apps side by side, and big screens also deliver a more immersive movie viewing experience — especially when paired with an OLED display or Liquid Retina display. But at the same time, the larger the tablet, the less likely you’re going to want to move it around. That means you’re not only going to want to take stock of your workspace (i.e., if you have a desk or instead plan to work from a couch or even your bed), but you’re also going to want to think about how the device will fit into your everyday routine or commute (if you have one). Tablet accessories Finally, you’ll want to consider any add-ons or accessories you’re planning to use, which can range from detachable keyboards to things like external mics or a stylus. The good news is that many of the best tablets nowadays offer some kind of keyboard accessory, which allows the device to function more like a 2-in-1 instead of simply being a content consumption device. Some tablets also feature things like microSD card slots that support expandable storage, or optional 4G or 5G connectivity, which can be a real boon to frequent travelers. And if you’re planning to use the tablet mainly for work, you might want to grab a USB hub for connecting all your favorite peripherals so your devices don’t have to fight for the charger. Recent updates October 2025: Updated to add the newest iPad Pro. July 2025: Updated to ensure our top picks and buying advice remain accurate. May 2025: Updated to ensure our top picks and buying advice remain accurate. March 2025: Updated to include the latest base iPad in our top picks, February 2025: Updated to include clarification around our top picks and new buying advice. October 2024: We updated this list to include information on the new iPad mini 7. June 2024: We updated our top picks to include the Microsoft Surface Pro Copilot+ edition.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-tablets-150026056.html?src=rss",
          "content": "Tablets are the perfect middle ground between your phone and laptop, giving you the best of both worlds. Whether you want a lightweight device to binge your favorite shows, a larger screen for mobile gaming or a portable way to get some work done on the go, a tablet can do it all. They’re also great for keeping kids entertained, managing work tasks or sharing family moments through video calls. When a phone feels too small and lugging around a laptop is just too much, that’s where tablets fit into the mix.For many, the Apple iPad is the go-to choice, and it’s easy to see why with its smooth performance and endless app options. But don’t worry if iOS isn’t your thing — there are plenty of Android alternatives out there, offering the same level of flexibility without locking you into Apple’s ecosystem. Plus, if you’re on a budget, there are more affordable options that still pack a punch. Whether you’re looking for a premium tablet for work, a kid-friendly device with parental controls or just a reliable everyday companion, we’ve tested all of the big players (and many others) to find the best tablets worth your money right now. Table of contents Best tablets for 2025 Important things to consider before buying a tablet How we test tablets Other tablets we tested Tablet FAQs Tablet accessories Best tablets for 2025 Important things to consider before buying a tablet Before you start looking at specific devices, the number one thing you should do is figure out what you plan to use your new tablet for. That’s because if all you need is something to keep a kid busy, buying a brand new Apple iPad Air or iPad Pro doesn’t make a ton of sense. On the flip side, if you want to use a tablet for video editing or drawing, you’ll need to take things like performance, versatility and stylus support more seriously — especially if you're considering using it as a laptop replacement. You’ll also want to think about stuff like how often you plan on traveling with the device and if it’s more for productivity, or for less demanding stuff like web browsing or streaming shows. There’s also an important trade-off to consider when it comes to battery life as well. Larger devices tend to have longer runtimes, though an increase in size may make it less portable. How we test tablets When evaluating different tablets, there are a few important things we look for above all else: solid performance, a good screen and long battery life. For performance, we run a handful of synthetic tests like Geekbench 6, while also performing a number of hands-on, real-world use cases such as editing photos and playing games. And with tablets often serving as hybrid devices, we also consider how easy it is to multitask and switch quickly between various apps. The more responsive a device feels, the better. Because a tablet’s display is such a critical component, we also view a wide range of content to gauge things like brightness, color gamut and dynamic range. It’s important to take into account the difference between various panel types like OLED, which typically produce richer colors and excellent contrast but may not be as bright as a mini LED display. Recently, refresh rate has become an increasingly important spec as 90Hz and 120Hz screens can make scrolling smoother and graphics appear sharper in games. We also consider a tablet’s design (including things like size, weight and water resistance), its connectivity (WiFi, Bluetooth, NFC, 5G, et cetera) and special features like stylus support or the ability to serve as a secondary display. That’s because, while tablets were often viewed as content consumption devices in the past, higher-end devices like the Surface Pro and iPad Pro are more than capable of replacing a laptop for a lot of people. Finally, we test battery life by running our standard local video rundown test, which involves playing a single video on a loop from 100 percent until it runs out of juice. Ideally, a tablet should be able to last an entire working day, but longer runtimes are always welcome — especially for users relying on them for productivity, entertainment and storage options on the go. Other tablets we tested Apple iPad mini Apple updated the iPad mini for 2024 with some under-the-hood changes including a new processor and additional RAM to help support Apple Intelligence features. While the iPad mini is one of the best iPads you can buy, its small size makes it a bit niche. Only if you prefer your tablet be the size of an ereader should you consider this one. Google Pixel Tablet The Google Pixel Tablet excels as a smart display rather than a simple tablet. As the latter, it's unexciting, but when paired with its speaker/charging dock, it becomes much more useful. It could be a good option for those that already live within the Google ecosystem and use the Google Assistant often, or those who like the idea of a tablet that can be docked and used as a smart display as well. OnePlus Pad The solid OnePlus Pad is let down by Android because there aren't many Android apps designed to be used on a large display like this model's 11.6-inch panel. Otherwise, the hardware is well-designed, its companion stylus is comfortable to use and it has an excellent battery life. Tablet FAQs What is the best brand for tablets? The best brand for tablets is really the brand you feel most comfortable with. We recommend taking stock of the gadgets you already have — do you live in the Apple ecosystem already? An iPad might be best for you then. Do you have a Samsung phone? If so, a Galaxy Tab will likely be the most convenient choice. There is no one \"best brand\" for tablets; you’ll find good options made by companies including Apple, Google, Samsung, Microsoft and Amazon. Can a tablet replace a laptop? It’s possible for a tablet to replace a laptop, but you’ll need a few accessories to truly make the experience as close as possible to that of a traditional notebook. A keyboard is a must, be it a keyboard case or a Bluetooth accessory that you keep with you. Some keyboard cases, like apple’s Magic Keyboard for the iPad, have a built-in trackpad, which will be more ergonomic than tapping on your tablet’s screen for input. Additionally, you could go one step further and use a wireless mouse that connects via Bluetooth to your tablet. If you’re primarily looking for a tablet to replace your laptop, consider buying a 2-in-1 laptop since those systems typically consist of high-powered tablets that are designed to work well with (and without) keyboards. What size screen do I need? Figuring out the best screen size for you will also be related to the kind of work (or play) you intend to do. Larger screens make it much easier to view two apps side by side, and big screens also deliver a more immersive movie viewing experience — especially when paired with an OLED display or Liquid Retina display. But at the same time, the larger the tablet, the less likely you’re going to want to move it around. That means you’re not only going to want to take stock of your workspace (i.e., if you have a desk or instead plan to work from a couch or even your bed), but you’re also going to want to think about how the device will fit into your everyday routine or commute (if you have one). Tablet accessories Finally, you’ll want to consider any add-ons or accessories you’re planning to use, which can range from detachable keyboards to things like external mics or a stylus. The good news is that many of the best tablets nowadays offer some kind of keyboard accessory, which allows the device to function more like a 2-in-1 instead of simply being a content consumption device. Some tablets also feature things like microSD card slots that support expandable storage, or optional 4G or 5G connectivity, which can be a real boon to frequent travelers. And if you’re planning to use the tablet mainly for work, you might want to grab a USB hub for connecting all your favorite peripherals so your devices don’t have to fight for the charger. Recent updates October 2025: Updated to add the newest iPad Pro. July 2025: Updated to ensure our top picks and buying advice remain accurate. May 2025: Updated to ensure our top picks and buying advice remain accurate. March 2025: Updated to include the latest base iPad in our top picks, February 2025: Updated to include clarification around our top picks and new buying advice. October 2024: We updated this list to include information on the new iPad mini 7. June 2024: We updated our top picks to include the Microsoft Surface Pro Copilot+ edition.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-tablets-150026056.html?src=rss",
          "feed_position": 28
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/private-internet-access-vpn-review-both-more-and-less-than-a-budget-vpn-120033882.html",
          "published_at": "Wed, 22 Oct 2025 12:00:33 +0000",
          "title": "Private Internet Access VPN review: Both more and less than a budget VPN",
          "standfirst": "I came into this review thinking of Private Internet Access (PIA) as one of the better VPNs. It's in the Kape Technologies portfolio, along with the top-tier ExpressVPN and the generally reliable CyberGhost. It's one of the cheapest VPNs out there, its interfaces hold together and it boasts plenty of server locations. Sadly, I was either misremembering PIA, or it used to be better until someone at Kape fell asleep at the switch. The more I tested this VPN, the more I came to terms with the fact that it's much harder to recommend these days, especially compared to the entries in our best VPN guide. The biggest culprit is unmoored download speeds that swing wildly from acceptable to unusable, but I also encountered dropped connections, high latencies and dead ends in the UI. I want to make it very clear that this PIA review is a snapshot of a moment in time. I don't think this is an inherently bad service, but it needs to do a lot of work to right the ship. As I go through my usual 11-point testing plan, I'll make a (hopefully) cogent case for why you should give PIA a miss as of now. Editor's note (10/20/25): We've overhauled our VPN coverage to provide more detailed, actionable buying advice. Going forward, we'll continue to update both our best VPN list and individual reviews (like this one) as circumstances change. Most recently, we added official scores to all of our VPN reviews. Check out how we test VPNs to learn more about the new standards we're using. Table of contents Findings at a glance Installing, configuring and using Private Internet Access Private Internet Access speed test Private Internet Access security test How much does Private Internet Access cost? Private Internet Access side apps and bundles Close-reading Private Internet Access's privacy policy Can Private Internet Access change your virtual location? Investigating Private Internet Access's server network Extra features of Private Internet Access Private Internet Access customer support options Private Internet Access background check Final verdict Findings at a glance Here's a quick overview of everything I learned from testing Private Internet Access. For details on the bullets, check out the relevant section. Category Notes Installation and UI Desktop apps work well but are limited to mobile proportions Android app has some confusing design choices and often gets stuck on screens that prompt setting changes iOS app is the best, but lacks dark mode Browser extension has several unique features Speed Major swings in speed and latency, even on the same server minutes apart Average download speed drop of 34 percent conceals a lot of outliers in both directions Latency was the most inconsistent measure of all, swinging by over 1000 milliseconds Security OpenVPN and WireGuard, the two universally available protocols, are secure IKEv2/IPSec only available on iOS Passed all leak tests, including while switching locations Encrypts all data packets Pricing $11.95 per month Best plan costs $79 for 39 months, or $2.03 per month Unlimited connections on any plan Bundles Antivirus and dedicated IP addresses available at checkout for an extra fee Privacy policy Free of loopholes, with no basis for logging user identities or activities RAM-only servers make long-term logging impossible Parent company Kape Technologies is bound to the same rules Passed two audits by Deloitte, but reports are only available to subscribers Virtual location change Never blocked by Netflix Canada and UK servers failed to change content three times each Tests were successful in Australia, Japan and Italy, but speeds remained a problem Server network 155 locations in 91 countries 59 percent of servers are virtual Features Two levels of kill switch — stronger setting prevents all internet access before you connect to the VPN PIA MACE is good at blocking banner ads Controlling maximum download unit size can improve speeds App and IP-based split tunneling with normal and inverse options Automation generally doesn't work Multi-hop uses ShadowSocks or SOCKS5 obfuscation Port forwarding supported Customer support Written knowledgebase is not easy to use Live chat is attentive but slow and not always expert Support team answers email tickets quickly Background check Owned by Kape Technologies No serious hacks or breaches Former CTO came with some controversy, but no longer works there Two court cases have confirmed PIA doesn't store logs Installing, configuring and using Private Internet Access Private Internet Access downloads and installs with very little friction across all the platforms that support its apps. Since I have basically no complaints about the experience of setting it up, I'll spend this section focusing on how it feels to use PIA on each platform. Sam Chapman for Engadget I have a number of issues with how PIA structures its apps on each OS, but I want to preface them by saying that this VPN generally works fine. It connects quickly, its settings are easy to toggle and it never puts active obstacles in the user's path. Each app except iOS has a soothingly dark aesthetic that's always readable. Keep that baseline in mind when I start describing what PIA could have done better. Windows There's no good way to describe PIA on Windows or Mac except as a mobile app dragged kicking and screaming onto desktop. This VPN app never misses an opportunity to remind you that it would rather be on your phone. By default, it's attached to your lower toolbar and cannot be moved or resized. You can change the settings to have it launch in a movable window instead, but you still can't change its size. The main window is cluttered, but once you figure it out, there's a much higher degree of customization than most VPNs offer. Clicking the arrow at the bottom opens a long panel of additional widgets, including quick-connect links, usage stats, a snooze option and buttons for some of the settings you'll use most commonly. You can drag these elements around to reorder them, or click the ribbon icon to move each to the default launch display. It's quite cool — just not especially intuitive. Sam Chapman for Engadget The server list is another example of PIA's mobile fixation. Despite having an entire screen to work with, PIA on Windows does not let you view the main display and the server list at the same time — you have to click the arrow by the name of the current server to swap in the list of locations. This list can be organized by country name or by live latency test, though the buttons to change this are not clearly marked as such. Though the search bar works quickly, the streaming-optimized servers are not sorted out from the rest. You have to type \"streaming optimized\" into search to see if your chosen country has a streaming server. You can click the three dots at top-right to go to the settings menu, which is a breath of fresh air after the clunky main UI. Settings are arranged in tabs, and each tab's design makes it easy to tell what its feature does and how to control it. PIA's launch window feels over-engineered to make a distinct first impression, but the settings menu is free from that hangup. Mac PIA's Mac app also feels like it was designed for mobile and then ported to desktop. Like the Windows app, it's attached to the toolbar until you change the settings to let it move independently. After that, it has the same problem of being crammed into a mobile-sized window, with the server list and the main UI not visible at the same time. The Mac version also has the unique problem of not showing up in the system dock, instead working entirely from the toolbar. That said, right-clicking the toolbar does let you connect to the VPN and even choose a location, which is awesome and provides some justification for this design choice (though I'll point out that this could also be done from a dock icon). Sam Chapman for Engadget The main window of the Mac app can be reordered or expanded through clicking and dragging just like the Windows UI. The settings panel is accessed the same way and is just as seamless to use. In fact, one big point in PIA's favor is that its two desktop apps are almost identical — water in the desert after the wild swings of Norton VPN. Android Having already complained twice about PIA's desktop interfaces feeling like mobile apps, I had high hopes for it on Android. While it functions just as smoothly here as everywhere else, it comes with a set of design decisions that are weird in a whole new way. First of all, you can't sort the server list alphabetically anymore; it's arranged by current latency instead, which means the list is constantly shifting in real time. Customizing the main window is now done by clicking a button at the top-right of the screen. This flips the entire look in a way that's likely to startle first-time users. It's ultimately the same interface as on desktop — drag widgets around and toggle whether or not they're seen — but it could be handled better. Sam Chapman for Engadget The preferences list is not nearly as user-friendly as on the two desktop apps. Most of the important features are buried two menus deep under the tab marked \"Settings,\" except for split tunneling, which is called \"Per App Settings\" for some reason (and barely explained). The larger issue, though, is that PIA on Android is extremely dependent on making you change system settings outside the app — which would be fine, except that it hasn't figured out a working interface for actually doing that. Almost every time I was prompted to change something in the settings, I got stuck on a prompt page with a useless button. Going into Settings and making the changes manually did nothing to unstick these pages. iOS Of all PIA's VPN apps, iOS is the closest to a home run, save for the inexplicable decision to lock the interface in light mode. I gather PIA was just trying to keep its iOS and Android apps visually distinct, but throwing out one of its best aesthetic choices isn't the way to do that. Sam Chapman for Engadget That gripe aside, everything else is nearly ideal, pointing to iPhone and iPad as PIA's natural home. The option to toggle what appears on the main page is finally done right — you still have to tap a button that causes a bit of whiplash, but it's much clearer what you're meant to do in order to shift, add and remove widgets. Browser extensions PIA's browser extensions are available for Chrome and Firefox. They look fairly similar to the desktop app, but with some distinct features for the web. The best is the ability to instantly add the website you're currently on to the bypass list, which is incredibly handy if you're doing something non-sensitive and the VPN is actively slowing it down. Sam Chapman for Engadget The extra features are organized into three categories: security, privacy and tracking. Security blocks WebRTC leaks and automatically connects unsecured websites through HTTPS. Privacy blocks websites from accessing your camera, microphone or real location and can prevent you from connecting to websites with known security concerns. Tracking, as you might guess, blocks various forms of activity trackers. It's both very thorough and surprisingly different from any of PIA's other apps — there's reason to use this extension even if you're already using a PIA app on the same device. However, its explanations of each feature rely a bit too much on technical jargon, so casual users might not find many of them helpful. Other platforms Private Internet Access can also be installed on Linux and has native apps for Apple TV and Android TV. To protect any other internet-capable device, including game consoles, you can install PIA on your router, which automatically protects any device connecting through your home WiFi. Private Internet Access speed test I used Speedtest by Ookla to test how much Private Internet Access impacted my browsing speeds. Running a VPN inevitably reduces download speed (how fast web pages display), upload speed (for posting and torrenting) and latency (the gap in real-time communications, such as during games and live chats. The real question, then, is whether PIA can keep those reductions as minimal as possible — like my current speed champion, Surfshark. Server location Ping (ms) Increase factor Download speed (Mbps) Percentage drop Upload speed (Mbps) Percentage drop Portland, USA (unprotected) 13 — 57.92 — 5.64 — Las Vegas, USA 105 8x 40.33 30.4 4.55 19.3 Montreal, Canada 512 39x 48.14 16.9 5.61 0.5 Chile 413 32x 44.63 22.9 5.60 0.7 Milan, Italy 672 52x 41.55 28.3 3.69 34.6 South Africa 1120 86x 26.88 53.6 4.36 22.7 Sydney, Australia 350 27x 28.08 51.5 5.26 6.7 Average 529 40.7x 38.26 33.9 4.85 10.9 This speed test was a marked disappointment. PIA had some of the most inconsistent readings I've seen on a VPN in some time — so bad I initially assumed there was something wrong with the speed tester. I ran more speed tests on more days than I usually do, just to make sure a fluke outlier didn't permanently taint PIA's score. Speeds were often good, but occasional sharp drops suppressed them. This problem was especially pronounced with latency. In practically every test, the three pings swung wildly, sometimes ending up above 2000 milliseconds (or, as we call it in the business, two seconds). I can't say what the problem is, but until PIA fixes it, I don't suggest using this VPN for any split-second gaming. Additionally, on my first day of testing, the server location PIA chose as the fastest gave me four-digit pings, download speeds below 2 Mbps and no upload speeds at all. Other servers worked, so the problem wasn't on my end. This didn't happen in every location by any means, nor on every test — but it repeated in Montreal, implying an issue with more than one PIA server. Sam Chapman for Engadget Due to several low outliers, PIA's worldwide averages don't look good at all compared to other VPNs. The best news in the table above is that upload speed only dropped by about 11 percent, and download speed by about 34 percent, retaining two-thirds of my unprotected speed. But the inconsistency is a serious problem; PIA might be quite fast at times, but it’s unpredictable. I've reached out to PIA for comment on its speeds and will update this when I receive a reply. Private Internet Access security test Since most websites today use HTTPS encryption, it's very difficult for third parties to see precisely what you do online — but motivated people can still see your real location and the sites you visit. The purpose of a VPN is not to keep you completely anonymous or safe online, but to prevent your IP address and DNS requests from being visible to your internet service provider or anyone else. I looked from three different angles to see whether Private Internet Access is actually capable of doing what its name promises. First, I checked to make sure it uses VPN protocols considered to be secure. I next used an IP address checker to see if any locations leaked my IP address, and finally ran a WireShark test to ensure all protocols applied encryption evenly. VPN protocols PIA uses three VPN protocols to mediate between your device and its servers — OpenVPN (over TCP or UDP), WireGuard and IKEv2/IPSec. OpenVPN has provided reliable VPN security for many years now; it's open-source and constantly updated by volunteers to stay current. TCP is slower but more stable, while UDP is faster but more likely to drop connections. OpenVPN is available on all PIA apps. WireGuard is a newer protocol that PIA contributed to the development of. It's leaner and often faster than OpenVPN, and uses a stream cipher that's harder to crack (though in practice, both WireGuard and OpenVPN use cryptography unbeatable by existing technology). WireGuard is available on all PIA apps. Sam Chapman for Engadget WireGuard's one downside is that it stores user IP addresses to keep the tunnel open — but that's no issue if a VPN is following its no-logging policy, which I believe PIA is. See \"Close-reading PIA's privacy policy\" for more details. IKEv2/IPSec is only present on PIA's iOS app. Its ability to stay connected through rapid network changes makes it great for mobile, so it's disappointing not to see it on Android as well. IKEv2 isn't open-source like OpenVPN and WireGuard, but when paired with the IPSec suite, it's just as secure. Leak test To run this test, I wrote down my IP address without VPN protection. Then I connected to several PIA servers and checked whether ipleak.net showed me a different IP address, ideally in a wholly different location. PIA passed the first round of tests easily, as you can see in the screenshot below — I never once saw my real location, which means neither DNS nor WebRTC was leaking it. PIA also blocks IPv6 on all apps to prevent it from leaking (this can't be disabled). Sam Chapman for Engadget However, since reviewing Norton VPN, I've gotten paranoid about VPNs letting security drop during server switches. So I added another test in which I changed servers several times while watching the IP leak test. PIA passed this test as well, always jumping seamlessly from one VPN location to the next without ever revealing my real IP address. Sam Chapman for Engadget Encryption test The last step in testing VPN security is to use a packet sniffer like WireShark to make sure the traffic you send is actually getting encrypted. It's pretty rare for even the jankiest of VPNs to fail this part, but any VPN that does fail gets an automatic blanket no. Luckily, PIA passed on all three protocols, as WireShark showed data packets with clear encryption. How much does Private Internet Access cost? Cost is one of the biggest reasons to pick Private Internet Access as your main VPN. At the monthly level, it costs $11.95 — not that much cheaper than its competitors and more expensive than some of the best, including Proton VPN. The long-term plans change all of that. One year of PIA costs just under $40, or $3.33 per month. The three-year plan is an even heavier discount, costing just $79 and including three bonus months in the first period. That works out to $2.03 per month for the first three years and $2.19 per month after that. A single PIA subscription can be used on an unlimited number of devices. This could potentially stretch your money further still, covering an entire family, friend group or small business. Having said that, as with Surfshark, you can still be restricted for using an excessive number of devices. PIA's terms of service document states that it may contact users who appear to be abusing the privilege and can restrict access to the VPN if the abuse persists. Private Internet Access side apps and bundles Alongside the basic Private Internet Access VPN service, there are a couple of add-ons worth noting. You can select one or both of these on the checkout page after choosing your plan. PIA Antivirus runs continuous malware scans and sends you alerts whenever any activity matches its database of known viruses. You can schedule system-wide scans to catch malware that might have made it through the net. There's also a quarantine box for storing malicious files. The main thing you won't get is the kind of actively learning antivirus system that can catch new threats based on their behavior — for that, I still recommend a dedicated AV app. Adding antivirus costs $4.50 per month, $24 for a year or $36 for three years. A dedicated IP address ensures you'll have the same IP address every time you connect to the VPN. A constantly fluctuating IP can trigger CAPTCHAs on some pages, so if you're sick of having to identify crosswalks just to use Google, this extra fee might be worth it. You can also add your dedicated IP to allowlists for remote access services. A dedicated IP address through PIA costs $5 a month, $51 for a year or $90 for three years. Close-reading Private Internet Access's privacy policy A VPN's privacy policy is a legal document that lays out the terms of its relationship with its users. It's easy to assume it's all hollow words, but directly contradicting its own policy can get a provider in trouble. Looking closely at PIA's privacy policy can tell us what its priorities are, what your rights are as a user and how much you can trust it not to exploit its access to your secrets. PIA is a Kape Technologies property, like ExpressVPN and CyberGhost. I'll get into that more in the background check, but for this section, my overriding question was whether any loopholes in the privacy policy might allow PIA to share user data with its parent company, and from there to its other properties. Fortunately for me (and everyone who cares about this stuff and isn't a lawyer), PIA has a very succinct and transparent privacy policy, mostly made up of bullet points. At the top, the policy states that PIA always handles customer data in accordance with the General Data Protection Regulation (GDPR), even outside of the EU. Further down, we get this key statement: Sam Chapman for Engadget That's pretty definitive, leaving very little wiggle room. It doesn't include device fingerprints, which can be used in place of IP addresses and activity logs, but lower down, the policy states that device identifiers can only be gathered from users who opt in — and thankfully, PIA's apps do not send that information by default. The next section discusses what PIA can do with the information it does collect. It's permitted to share customer support data with Deskpro, which powers its live chat assistance. It also uses Stripe, PayPal, Amazon Pay and BitPay for payments, but sharing email addresses and payment methods with financial processors is standard even for the most private VPNs (Mullvad has this same carve-out, to name one). PIA ends the privacy policy by addressing the question of its parent company, Kape Technologies, stating: \"neither PIA nor anyone at Kape Technologies logs or stores any kind of substantiative [sic] Personal Data, user browsing data, or individual connection data other than what has been outlined here, nor do we share any personal or usage information with third parties for marketing purposes.\" Misspelling aside, I'm perfectly satisfied with the policy. Combined with PIA's use of RAM-only servers without long-term information storage, this document all but eliminates the potential for abuse. A PIA representative confirmed for me that while some user data is handled by \"cross-group employees,\" none of it is sensitive or identifiable. Independent privacy audits Third-party audits are one more critical piece of evidence we can use to decide whether a VPN is trustworthy. PIA passed an audit of its systems by Deloitte Romania in April 2024, which found that it was adhering to its no-logs policy. The report itself is only available to subscribers, which is a bit annoying, but at least not unique. After downloading it through my account portal, I was able to confirm that Deloitte's investigation found nothing in PIA's systems that went against its privacy statements. Can Private Internet Access change your virtual location? Chances are good that you found this review because you need a VPN to mask your virtual location, whether that's to get around age verification or to see what's streaming on your favorite platforms in other countries. This section's test is designed to see if Private Internet Access is able to change your virtual location convincingly enough for Netflix. I tried connecting three times in each in five different locations and recorded my results in the table. I used the streaming-optimized servers whenever possible, and the WireGuard protocol for the best speeds. \"Unblocked Netflix\" shows whether I got to Netflix without being caught using a VPN, and \"Changed content\" shows whether I actually saw a new library. Server location Unblocked Netflix? Changed content? Canada 3/3 0/3 United Kingdom 3/3 0/3 Japan 3/3 3/3 Australia 3/3 3/3 Italy 3/3 3/3 My findings continued the trend of PIA being just good enough that I'm frustrated by the ways it fails to be better. PIA never got caught, which indicates that it's taking care to not use IP addresses Netflix has blocked. Three of the five locations — in Japan, Australia and Italy — managed to change the contest I saw. Sam Chapman for Engadget However, with all nine tests in each of those three virtual locations, PIA's speeds dragged so much that I waited several minutes to see if it had actually worked. The other two server locations, Canada and the UK, didn't change Netflix at all, no matter how many times I disconnected and reconnected. The bigger problem, though, is that PIA's fluctuating speeds meant Netflix took ages to load and often froze until I refreshed it. Shows stuttered and lagged even when I could watch them. Until it fixes whatever is going on with its speeds, PIA won't be a good choice for streaming in any location. Investigating Private Internet Access's server network Private Internet Access has 155 server locations in 91 countries. Confusingly, I counted that it also has 91 virtual server locations, though it's not the same 91. Its network is heavily weighted toward Europe, which accounts for 44 countries, but there's also decent representation in Asia. Traditionally underserved South America and Africa get nine and four locations respectively, though they're all virtual. Region Countries with servers Total server locations Virtual server locations North America 8 64 45 South America 9 9 9 Europe 44 48 14 Africa 4 4 4 Middle East 6 6 3 Asia 18 18 16 Oceania 2 6 0 Total 91 155 91 (59 percent) Virtual server locations aren't necessarily a bad thing, but when used to excess, they may indicate that a VPN is more concerned with making its server network look big than ensuring it works for every user. PIA's server network is more than half virtual worldwide. Recently, it's added locations in every US state — again, mostly virtual, which makes it come off as more of a stunt than a genuine improvement. Given the trouble I had using PIA for this review, I find that there's something to the claim that it's more interested in growing than in working. PIA's website has a helpful page that shows where virtual servers are physically located, though it's out of date, having been updated last in July 2023. The list shows that PIA tries to put the real locations of virtual servers as close to their displayed locations as possible. There are a couple of weird choices, like the Buenos Aires server really being in Miami, but that's mostly kept to a minimum. Extra features of Private Internet Access Private Internet Access doesn't have the wealth of features you'll see on the likes of Surfshark or NordVPN, but it's not quite as bare-bones as ExpressVPN, either. Some of its most interesting extras are self-explanatory, while others are a little technical. I'll explain the most important features here. Kill switch A kill switch is a must-have for a safe VPN. While active, the kill switch makes it impossible to connect outside the VPN tunnel, which keeps you from accidentally connecting to malicious fake servers. This also means that if PIA drops your connection for any reason, you won't be able to get online at all — which can be annoying, but saves you from broadcasting any sensitive information without encryption. Sam Chapman for Engadget PIA comes with two levels of kill switch. The basic version watches for traffic outside the tunnel when the VPN is active. The stronger \"advanced kill switch\" works even when you aren't connected to the VPN, so you cannot get online at all without being protected by PIA first. PIA MACE MACE is PIA's ad blocker. It keeps a list of domains known to display ads, malware, scams or invasive trackers, and blocks them all from loading. This won't stop all ads, since some of them come from domains considered legitimate — notably, MACE can't do anything about YouTube video ads — but it works on most banner ads and definitely lightened the load on my browser. MACE is available on all PIA's apps except iOS. iPhone and iPad users instead get a content blocker that does much the same thing, but only on Safari. If you prefer to use Chrome or Firefox on your iOS device, you're out of luck (unless of course you get another ad blocker). Maximum transfer unit (MTU) MTU is a somewhat technical feature. You may not need it, unless your connection is extremely sluggish and the traditional fixes don't work. In short, MTU limits how much data can move through PIA's servers at a time. Large packets complete loading faster, but may struggle on shaky connections. Small packets make for slower but more stable downloads overall. I say you probably won't need it because it's almost always best to leave it on the auto setting and let PIA pick MTU on its own. I ran some speed tests with both the large and small MTU options and didn't see a noticeable difference. That indicates that PIA is pretty good at picking the best MTU, so in most cases, just let it cook. Automation On the automation tab in PIA's settings, you can set up rules to save you some trouble with the VPN. On Mac and iOS, automation can respond to three types of network: protected Wi-Fi, open Wi-Fi and wired. On each of these, you can set PIA to automatically connect or disconnect. That's it — you can only have a maximum of three rules. Android and Windows users get the option to make rules for specific networks, but only the network they're currently connected to. On every platform, there's no way to determine which server PIA auto-connects to. It always picks the fastest. Sam Chapman for Engadget The inch-deep options on their own would make for a disappointing feature, but there's a bigger issue: it doesn't work half the time. I spent at least an hour on four different platforms trying to make automation happen. On iOS and macOS, I could make the rules, but they never triggered. With Android, I got stuck at a prompt telling me to enable location services, which I had already done. Windows was the only version where PIA's automation worked the first time. On the plus side, it gave me the question I used to test PIA's customer support. Split tunneling Split tunneling — which lets you decide which apps or websites go through the VPN tunnel and which stay outside — is a common feature, but PIA surprisingly has one of the best implementations of it. To start with, it can split tunnel by app or by IP address, which lets you protect specific websites or leave them unencrypted. Sam Chapman for Engadget In another layer of versatility, you can make your split tunnel rules in normal or inverse fashion. Either every app and website uses the VPN except the ones you designate, or only the ones you designate use the VPN. All these options give you a much finer level of control that you get over the automation feature. Multi-Hop via Shadowsocks and SOCKS5 Double-hop or multi-hop is when a VPN runs your requests through two servers instead of one. PIA handles multi-hop a little differently than other VPNs, as the second server will always be a Shadowsocks or SOCKS5 proxy. These two protocols are designed to obfuscate VPN traffic so it looks like a regular connection, which gets you around certain firewalls. Sam Chapman for Engadget If you choose a SOCKS5 proxy, you'll need to get a server address from an outside service and set it up yourself. If you pick Shadowsocks, which is the more secure option anyway, you can choose from a list of locations to use as the first node. It's nice to have so many choices, but still a bit frustrating that you can't get obfuscation without also using double VPN (which only works on the OpenVPN protocol). Port forwarding The final PIA feature worth noting is port forwarding, which keeps the VPN from getting in the way of any outward-facing services you might be using. This gives you a more stable connection on remote desktop protocols or torrenting clients — especially the latter, as that's the sort of traffic you really want to keep encrypted. Private Internet Access customer support options When I set out to test the automation features of Private Internet Access, I found myself blocked on the Android app. A notification popped up telling me to enable background access to location services, but the button labeled \"go to permissions settings\" didn't do anything. I took the long way around and made the changes myself, but the pop-up remained stubborn. Sam Chapman for Engadget This gave me a perfect opportunity to see how PIA helps users caught in predicaments like this one. First, I went to the website and clicked \"support\" in the top banner to reach the PIA helpdesk. Then the trouble started. I opened up the Android guide on my Mac laptop and waited several minutes for the file to load. When it didn't, I tried my Android phone, which also didn't work. I checked back on the laptop, where I finally saw the guide after reloading the page. Sam Chapman for Engadget After all that, the guide said nothing about my problem. Nor could I find it anywhere in the general FAQs, which kept splitting into smaller and smaller categories which never really explained what I'd find. However, after a few minutes of searching, I found the problem had resolved itself with no explanation. Live support experience I still had to test live chat, though, so I pivoted to a new problem: how to get the Android automation feature to recognize my home Wi-Fi network instead of calling it \"unknown SSID.\" I couldn't be sure it was my own network and not a malicious duplicate. This may sound like paranoid nitpicking, but paranoid nitpicking is the bread and butter of cybersecurity. I first had to find live chat, which confusingly can't be accessed through the helpdesk — you have to go back to the main website. I managed to get past the AI gatekeeper fairly quickly, and sat to wait for a human agent. In less than a minute, I was chatting with Carl, who requested screenshots and ran me through some tests. Carl was able to explain that the pop-up problem had resolved because I'd given PIA full access to location services (which is not something the window itself specified I would need to do), but the unknown SSID issue persisted. Sam Chapman for Engadget Carl was diligent, but slow. After well over 30 minutes of back-and-forth, during which I sent over two screenshots and a debug log, he told me we'd have to escalate the problem. I got an email from the support team about a day later that suggested I try connecting to other Wi-Fi networks and see if the problem persisted; this eventually led me to discover the culprit in my router settings, so I can't blame PIA for this one. Private Internet Access background check The final step, as always, is to look into the history of Private Internet Access as a corporation and look for any red flags I may have missed. A VPN's biography can reveal its attitudes about critical aspects of its job and show how it might behave in the future. PIA was launched in 2010 by Andrew Lee in Denver, Colorado, where it's still based today. In 2019, the brand was acquired by Kape Technologies, owners of ExpressVPN, CyberGhost and the now-defunct ZenMate. I won't relitigate the full Kape controversy here; you can find a longer summary in my ExpressVPN review. Suffice to say that while it's come under scrutiny in the past for tacitly allowing its products to become malware vectors, there's no evidence the acquisition changed anything substantial about how PIA operated. Most of the usual red flags aren't factors here. PIA has never suffered a serious hack or breach. In its 15-year record, I only found two things worth pointing out: a controversial executive and its United States headquarters. Former CTO Mark Karpeles Mark Karpeles was the CEO of Mt. Gox, the market for Magic: The Gathering trading cards that became the world's largest crypto exchange, only to lose it all in a massive hack that's never been fully explained. Karpeles was arrested in Japan after the heist and found guilty of falsifying records, but was sentenced to time served and released in 2019. While the Japan trial was ongoing, Karpeles joined PIA parent company London Trust Media as its chief technical officer. PIA founder Andrew Lee defended the hiring in a statement on the PIA blog, writing that \"If we, as a society, do not give second chances to those who fall, then we as a society will cease to progress,\" and comparing Karpeles's arrest to Steve Jobs being forced out of Apple. Neither man works at PIA anymore. According to his LinkedIn, Karpeles left London Trust Media after the Kape Acquisition in 2019. Lee left at the same time, and these days seems less interested in cybersecurity than in trying to become the Prince of Korea. Bottom line: Although hiring an executive in the middle of his malfeasance trial may be terrible optics, the whole controversy isn't relevant to the VPN's operations today. US headquarters and Five Eyes The other potential sticking point with PIA is that it's headquartered in the United States, which is a member of the Five Eyes intelligence sharing agreement. Now, I'm on the record as not thinking Five Eyes is a big deal for a VPN — either the VPN is following its privacy policy, in which case it'll have nothing to share with intelligence agents, or it's not, in which case its location is the least of its problems. As I concluded in the Privacy section, whatever PIA's flaws, it's not mishandling user data or violating its own privacy policy. That's not only confirmed by two audits, but also by two separate court cases in which PIA was unable to comply with requests for logs on its customers. If the VPN doesn't save information, there's nothing for Five Eyes to access. Final verdict There's plenty that does work about PIA. Its privacy and security are unimpeachable — it uses vetted protocols with strong encryption and doesn't leak. Its iOS app is a nearly perfect mobile VPN, and the ability to customize the home screen on every app is a great touch. Split tunneling is outstanding, MACE blocks ads efficiently and I even like the automation (though I wish it was deeper). But PIA is aggravating to use in too many ways. While its servers are frequently fast, you can't trust that download speeds will hold from one moment to the next. Basic quality assurance, like assuring pop-up buttons always do something when pressed, seems to have gone by the wayside in its Android app. In spite of it all, I still recommend Private Internet Access as a budget VPN. Its three-year plan is the cheapest subscription on the market right now. At $2.00 per month, I'm prepared to forgive a lot, especially at a time when all our wallets are squeezed. This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/private-internet-access-vpn-review-both-more-and-less-than-a-budget-vpn-120033882.html?src=rss",
          "content": "I came into this review thinking of Private Internet Access (PIA) as one of the better VPNs. It's in the Kape Technologies portfolio, along with the top-tier ExpressVPN and the generally reliable CyberGhost. It's one of the cheapest VPNs out there, its interfaces hold together and it boasts plenty of server locations. Sadly, I was either misremembering PIA, or it used to be better until someone at Kape fell asleep at the switch. The more I tested this VPN, the more I came to terms with the fact that it's much harder to recommend these days, especially compared to the entries in our best VPN guide. The biggest culprit is unmoored download speeds that swing wildly from acceptable to unusable, but I also encountered dropped connections, high latencies and dead ends in the UI. I want to make it very clear that this PIA review is a snapshot of a moment in time. I don't think this is an inherently bad service, but it needs to do a lot of work to right the ship. As I go through my usual 11-point testing plan, I'll make a (hopefully) cogent case for why you should give PIA a miss as of now. Editor's note (10/20/25): We've overhauled our VPN coverage to provide more detailed, actionable buying advice. Going forward, we'll continue to update both our best VPN list and individual reviews (like this one) as circumstances change. Most recently, we added official scores to all of our VPN reviews. Check out how we test VPNs to learn more about the new standards we're using. Table of contents Findings at a glance Installing, configuring and using Private Internet Access Private Internet Access speed test Private Internet Access security test How much does Private Internet Access cost? Private Internet Access side apps and bundles Close-reading Private Internet Access's privacy policy Can Private Internet Access change your virtual location? Investigating Private Internet Access's server network Extra features of Private Internet Access Private Internet Access customer support options Private Internet Access background check Final verdict Findings at a glance Here's a quick overview of everything I learned from testing Private Internet Access. For details on the bullets, check out the relevant section. Category Notes Installation and UI Desktop apps work well but are limited to mobile proportions Android app has some confusing design choices and often gets stuck on screens that prompt setting changes iOS app is the best, but lacks dark mode Browser extension has several unique features Speed Major swings in speed and latency, even on the same server minutes apart Average download speed drop of 34 percent conceals a lot of outliers in both directions Latency was the most inconsistent measure of all, swinging by over 1000 milliseconds Security OpenVPN and WireGuard, the two universally available protocols, are secure IKEv2/IPSec only available on iOS Passed all leak tests, including while switching locations Encrypts all data packets Pricing $11.95 per month Best plan costs $79 for 39 months, or $2.03 per month Unlimited connections on any plan Bundles Antivirus and dedicated IP addresses available at checkout for an extra fee Privacy policy Free of loopholes, with no basis for logging user identities or activities RAM-only servers make long-term logging impossible Parent company Kape Technologies is bound to the same rules Passed two audits by Deloitte, but reports are only available to subscribers Virtual location change Never blocked by Netflix Canada and UK servers failed to change content three times each Tests were successful in Australia, Japan and Italy, but speeds remained a problem Server network 155 locations in 91 countries 59 percent of servers are virtual Features Two levels of kill switch — stronger setting prevents all internet access before you connect to the VPN PIA MACE is good at blocking banner ads Controlling maximum download unit size can improve speeds App and IP-based split tunneling with normal and inverse options Automation generally doesn't work Multi-hop uses ShadowSocks or SOCKS5 obfuscation Port forwarding supported Customer support Written knowledgebase is not easy to use Live chat is attentive but slow and not always expert Support team answers email tickets quickly Background check Owned by Kape Technologies No serious hacks or breaches Former CTO came with some controversy, but no longer works there Two court cases have confirmed PIA doesn't store logs Installing, configuring and using Private Internet Access Private Internet Access downloads and installs with very little friction across all the platforms that support its apps. Since I have basically no complaints about the experience of setting it up, I'll spend this section focusing on how it feels to use PIA on each platform. Sam Chapman for Engadget I have a number of issues with how PIA structures its apps on each OS, but I want to preface them by saying that this VPN generally works fine. It connects quickly, its settings are easy to toggle and it never puts active obstacles in the user's path. Each app except iOS has a soothingly dark aesthetic that's always readable. Keep that baseline in mind when I start describing what PIA could have done better. Windows There's no good way to describe PIA on Windows or Mac except as a mobile app dragged kicking and screaming onto desktop. This VPN app never misses an opportunity to remind you that it would rather be on your phone. By default, it's attached to your lower toolbar and cannot be moved or resized. You can change the settings to have it launch in a movable window instead, but you still can't change its size. The main window is cluttered, but once you figure it out, there's a much higher degree of customization than most VPNs offer. Clicking the arrow at the bottom opens a long panel of additional widgets, including quick-connect links, usage stats, a snooze option and buttons for some of the settings you'll use most commonly. You can drag these elements around to reorder them, or click the ribbon icon to move each to the default launch display. It's quite cool — just not especially intuitive. Sam Chapman for Engadget The server list is another example of PIA's mobile fixation. Despite having an entire screen to work with, PIA on Windows does not let you view the main display and the server list at the same time — you have to click the arrow by the name of the current server to swap in the list of locations. This list can be organized by country name or by live latency test, though the buttons to change this are not clearly marked as such. Though the search bar works quickly, the streaming-optimized servers are not sorted out from the rest. You have to type \"streaming optimized\" into search to see if your chosen country has a streaming server. You can click the three dots at top-right to go to the settings menu, which is a breath of fresh air after the clunky main UI. Settings are arranged in tabs, and each tab's design makes it easy to tell what its feature does and how to control it. PIA's launch window feels over-engineered to make a distinct first impression, but the settings menu is free from that hangup. Mac PIA's Mac app also feels like it was designed for mobile and then ported to desktop. Like the Windows app, it's attached to the toolbar until you change the settings to let it move independently. After that, it has the same problem of being crammed into a mobile-sized window, with the server list and the main UI not visible at the same time. The Mac version also has the unique problem of not showing up in the system dock, instead working entirely from the toolbar. That said, right-clicking the toolbar does let you connect to the VPN and even choose a location, which is awesome and provides some justification for this design choice (though I'll point out that this could also be done from a dock icon). Sam Chapman for Engadget The main window of the Mac app can be reordered or expanded through clicking and dragging just like the Windows UI. The settings panel is accessed the same way and is just as seamless to use. In fact, one big point in PIA's favor is that its two desktop apps are almost identical — water in the desert after the wild swings of Norton VPN. Android Having already complained twice about PIA's desktop interfaces feeling like mobile apps, I had high hopes for it on Android. While it functions just as smoothly here as everywhere else, it comes with a set of design decisions that are weird in a whole new way. First of all, you can't sort the server list alphabetically anymore; it's arranged by current latency instead, which means the list is constantly shifting in real time. Customizing the main window is now done by clicking a button at the top-right of the screen. This flips the entire look in a way that's likely to startle first-time users. It's ultimately the same interface as on desktop — drag widgets around and toggle whether or not they're seen — but it could be handled better. Sam Chapman for Engadget The preferences list is not nearly as user-friendly as on the two desktop apps. Most of the important features are buried two menus deep under the tab marked \"Settings,\" except for split tunneling, which is called \"Per App Settings\" for some reason (and barely explained). The larger issue, though, is that PIA on Android is extremely dependent on making you change system settings outside the app — which would be fine, except that it hasn't figured out a working interface for actually doing that. Almost every time I was prompted to change something in the settings, I got stuck on a prompt page with a useless button. Going into Settings and making the changes manually did nothing to unstick these pages. iOS Of all PIA's VPN apps, iOS is the closest to a home run, save for the inexplicable decision to lock the interface in light mode. I gather PIA was just trying to keep its iOS and Android apps visually distinct, but throwing out one of its best aesthetic choices isn't the way to do that. Sam Chapman for Engadget That gripe aside, everything else is nearly ideal, pointing to iPhone and iPad as PIA's natural home. The option to toggle what appears on the main page is finally done right — you still have to tap a button that causes a bit of whiplash, but it's much clearer what you're meant to do in order to shift, add and remove widgets. Browser extensions PIA's browser extensions are available for Chrome and Firefox. They look fairly similar to the desktop app, but with some distinct features for the web. The best is the ability to instantly add the website you're currently on to the bypass list, which is incredibly handy if you're doing something non-sensitive and the VPN is actively slowing it down. Sam Chapman for Engadget The extra features are organized into three categories: security, privacy and tracking. Security blocks WebRTC leaks and automatically connects unsecured websites through HTTPS. Privacy blocks websites from accessing your camera, microphone or real location and can prevent you from connecting to websites with known security concerns. Tracking, as you might guess, blocks various forms of activity trackers. It's both very thorough and surprisingly different from any of PIA's other apps — there's reason to use this extension even if you're already using a PIA app on the same device. However, its explanations of each feature rely a bit too much on technical jargon, so casual users might not find many of them helpful. Other platforms Private Internet Access can also be installed on Linux and has native apps for Apple TV and Android TV. To protect any other internet-capable device, including game consoles, you can install PIA on your router, which automatically protects any device connecting through your home WiFi. Private Internet Access speed test I used Speedtest by Ookla to test how much Private Internet Access impacted my browsing speeds. Running a VPN inevitably reduces download speed (how fast web pages display), upload speed (for posting and torrenting) and latency (the gap in real-time communications, such as during games and live chats. The real question, then, is whether PIA can keep those reductions as minimal as possible — like my current speed champion, Surfshark. Server location Ping (ms) Increase factor Download speed (Mbps) Percentage drop Upload speed (Mbps) Percentage drop Portland, USA (unprotected) 13 — 57.92 — 5.64 — Las Vegas, USA 105 8x 40.33 30.4 4.55 19.3 Montreal, Canada 512 39x 48.14 16.9 5.61 0.5 Chile 413 32x 44.63 22.9 5.60 0.7 Milan, Italy 672 52x 41.55 28.3 3.69 34.6 South Africa 1120 86x 26.88 53.6 4.36 22.7 Sydney, Australia 350 27x 28.08 51.5 5.26 6.7 Average 529 40.7x 38.26 33.9 4.85 10.9 This speed test was a marked disappointment. PIA had some of the most inconsistent readings I've seen on a VPN in some time — so bad I initially assumed there was something wrong with the speed tester. I ran more speed tests on more days than I usually do, just to make sure a fluke outlier didn't permanently taint PIA's score. Speeds were often good, but occasional sharp drops suppressed them. This problem was especially pronounced with latency. In practically every test, the three pings swung wildly, sometimes ending up above 2000 milliseconds (or, as we call it in the business, two seconds). I can't say what the problem is, but until PIA fixes it, I don't suggest using this VPN for any split-second gaming. Additionally, on my first day of testing, the server location PIA chose as the fastest gave me four-digit pings, download speeds below 2 Mbps and no upload speeds at all. Other servers worked, so the problem wasn't on my end. This didn't happen in every location by any means, nor on every test — but it repeated in Montreal, implying an issue with more than one PIA server. Sam Chapman for Engadget Due to several low outliers, PIA's worldwide averages don't look good at all compared to other VPNs. The best news in the table above is that upload speed only dropped by about 11 percent, and download speed by about 34 percent, retaining two-thirds of my unprotected speed. But the inconsistency is a serious problem; PIA might be quite fast at times, but it’s unpredictable. I've reached out to PIA for comment on its speeds and will update this when I receive a reply. Private Internet Access security test Since most websites today use HTTPS encryption, it's very difficult for third parties to see precisely what you do online — but motivated people can still see your real location and the sites you visit. The purpose of a VPN is not to keep you completely anonymous or safe online, but to prevent your IP address and DNS requests from being visible to your internet service provider or anyone else. I looked from three different angles to see whether Private Internet Access is actually capable of doing what its name promises. First, I checked to make sure it uses VPN protocols considered to be secure. I next used an IP address checker to see if any locations leaked my IP address, and finally ran a WireShark test to ensure all protocols applied encryption evenly. VPN protocols PIA uses three VPN protocols to mediate between your device and its servers — OpenVPN (over TCP or UDP), WireGuard and IKEv2/IPSec. OpenVPN has provided reliable VPN security for many years now; it's open-source and constantly updated by volunteers to stay current. TCP is slower but more stable, while UDP is faster but more likely to drop connections. OpenVPN is available on all PIA apps. WireGuard is a newer protocol that PIA contributed to the development of. It's leaner and often faster than OpenVPN, and uses a stream cipher that's harder to crack (though in practice, both WireGuard and OpenVPN use cryptography unbeatable by existing technology). WireGuard is available on all PIA apps. Sam Chapman for Engadget WireGuard's one downside is that it stores user IP addresses to keep the tunnel open — but that's no issue if a VPN is following its no-logging policy, which I believe PIA is. See \"Close-reading PIA's privacy policy\" for more details. IKEv2/IPSec is only present on PIA's iOS app. Its ability to stay connected through rapid network changes makes it great for mobile, so it's disappointing not to see it on Android as well. IKEv2 isn't open-source like OpenVPN and WireGuard, but when paired with the IPSec suite, it's just as secure. Leak test To run this test, I wrote down my IP address without VPN protection. Then I connected to several PIA servers and checked whether ipleak.net showed me a different IP address, ideally in a wholly different location. PIA passed the first round of tests easily, as you can see in the screenshot below — I never once saw my real location, which means neither DNS nor WebRTC was leaking it. PIA also blocks IPv6 on all apps to prevent it from leaking (this can't be disabled). Sam Chapman for Engadget However, since reviewing Norton VPN, I've gotten paranoid about VPNs letting security drop during server switches. So I added another test in which I changed servers several times while watching the IP leak test. PIA passed this test as well, always jumping seamlessly from one VPN location to the next without ever revealing my real IP address. Sam Chapman for Engadget Encryption test The last step in testing VPN security is to use a packet sniffer like WireShark to make sure the traffic you send is actually getting encrypted. It's pretty rare for even the jankiest of VPNs to fail this part, but any VPN that does fail gets an automatic blanket no. Luckily, PIA passed on all three protocols, as WireShark showed data packets with clear encryption. How much does Private Internet Access cost? Cost is one of the biggest reasons to pick Private Internet Access as your main VPN. At the monthly level, it costs $11.95 — not that much cheaper than its competitors and more expensive than some of the best, including Proton VPN. The long-term plans change all of that. One year of PIA costs just under $40, or $3.33 per month. The three-year plan is an even heavier discount, costing just $79 and including three bonus months in the first period. That works out to $2.03 per month for the first three years and $2.19 per month after that. A single PIA subscription can be used on an unlimited number of devices. This could potentially stretch your money further still, covering an entire family, friend group or small business. Having said that, as with Surfshark, you can still be restricted for using an excessive number of devices. PIA's terms of service document states that it may contact users who appear to be abusing the privilege and can restrict access to the VPN if the abuse persists. Private Internet Access side apps and bundles Alongside the basic Private Internet Access VPN service, there are a couple of add-ons worth noting. You can select one or both of these on the checkout page after choosing your plan. PIA Antivirus runs continuous malware scans and sends you alerts whenever any activity matches its database of known viruses. You can schedule system-wide scans to catch malware that might have made it through the net. There's also a quarantine box for storing malicious files. The main thing you won't get is the kind of actively learning antivirus system that can catch new threats based on their behavior — for that, I still recommend a dedicated AV app. Adding antivirus costs $4.50 per month, $24 for a year or $36 for three years. A dedicated IP address ensures you'll have the same IP address every time you connect to the VPN. A constantly fluctuating IP can trigger CAPTCHAs on some pages, so if you're sick of having to identify crosswalks just to use Google, this extra fee might be worth it. You can also add your dedicated IP to allowlists for remote access services. A dedicated IP address through PIA costs $5 a month, $51 for a year or $90 for three years. Close-reading Private Internet Access's privacy policy A VPN's privacy policy is a legal document that lays out the terms of its relationship with its users. It's easy to assume it's all hollow words, but directly contradicting its own policy can get a provider in trouble. Looking closely at PIA's privacy policy can tell us what its priorities are, what your rights are as a user and how much you can trust it not to exploit its access to your secrets. PIA is a Kape Technologies property, like ExpressVPN and CyberGhost. I'll get into that more in the background check, but for this section, my overriding question was whether any loopholes in the privacy policy might allow PIA to share user data with its parent company, and from there to its other properties. Fortunately for me (and everyone who cares about this stuff and isn't a lawyer), PIA has a very succinct and transparent privacy policy, mostly made up of bullet points. At the top, the policy states that PIA always handles customer data in accordance with the General Data Protection Regulation (GDPR), even outside of the EU. Further down, we get this key statement: Sam Chapman for Engadget That's pretty definitive, leaving very little wiggle room. It doesn't include device fingerprints, which can be used in place of IP addresses and activity logs, but lower down, the policy states that device identifiers can only be gathered from users who opt in — and thankfully, PIA's apps do not send that information by default. The next section discusses what PIA can do with the information it does collect. It's permitted to share customer support data with Deskpro, which powers its live chat assistance. It also uses Stripe, PayPal, Amazon Pay and BitPay for payments, but sharing email addresses and payment methods with financial processors is standard even for the most private VPNs (Mullvad has this same carve-out, to name one). PIA ends the privacy policy by addressing the question of its parent company, Kape Technologies, stating: \"neither PIA nor anyone at Kape Technologies logs or stores any kind of substantiative [sic] Personal Data, user browsing data, or individual connection data other than what has been outlined here, nor do we share any personal or usage information with third parties for marketing purposes.\" Misspelling aside, I'm perfectly satisfied with the policy. Combined with PIA's use of RAM-only servers without long-term information storage, this document all but eliminates the potential for abuse. A PIA representative confirmed for me that while some user data is handled by \"cross-group employees,\" none of it is sensitive or identifiable. Independent privacy audits Third-party audits are one more critical piece of evidence we can use to decide whether a VPN is trustworthy. PIA passed an audit of its systems by Deloitte Romania in April 2024, which found that it was adhering to its no-logs policy. The report itself is only available to subscribers, which is a bit annoying, but at least not unique. After downloading it through my account portal, I was able to confirm that Deloitte's investigation found nothing in PIA's systems that went against its privacy statements. Can Private Internet Access change your virtual location? Chances are good that you found this review because you need a VPN to mask your virtual location, whether that's to get around age verification or to see what's streaming on your favorite platforms in other countries. This section's test is designed to see if Private Internet Access is able to change your virtual location convincingly enough for Netflix. I tried connecting three times in each in five different locations and recorded my results in the table. I used the streaming-optimized servers whenever possible, and the WireGuard protocol for the best speeds. \"Unblocked Netflix\" shows whether I got to Netflix without being caught using a VPN, and \"Changed content\" shows whether I actually saw a new library. Server location Unblocked Netflix? Changed content? Canada 3/3 0/3 United Kingdom 3/3 0/3 Japan 3/3 3/3 Australia 3/3 3/3 Italy 3/3 3/3 My findings continued the trend of PIA being just good enough that I'm frustrated by the ways it fails to be better. PIA never got caught, which indicates that it's taking care to not use IP addresses Netflix has blocked. Three of the five locations — in Japan, Australia and Italy — managed to change the contest I saw. Sam Chapman for Engadget However, with all nine tests in each of those three virtual locations, PIA's speeds dragged so much that I waited several minutes to see if it had actually worked. The other two server locations, Canada and the UK, didn't change Netflix at all, no matter how many times I disconnected and reconnected. The bigger problem, though, is that PIA's fluctuating speeds meant Netflix took ages to load and often froze until I refreshed it. Shows stuttered and lagged even when I could watch them. Until it fixes whatever is going on with its speeds, PIA won't be a good choice for streaming in any location. Investigating Private Internet Access's server network Private Internet Access has 155 server locations in 91 countries. Confusingly, I counted that it also has 91 virtual server locations, though it's not the same 91. Its network is heavily weighted toward Europe, which accounts for 44 countries, but there's also decent representation in Asia. Traditionally underserved South America and Africa get nine and four locations respectively, though they're all virtual. Region Countries with servers Total server locations Virtual server locations North America 8 64 45 South America 9 9 9 Europe 44 48 14 Africa 4 4 4 Middle East 6 6 3 Asia 18 18 16 Oceania 2 6 0 Total 91 155 91 (59 percent) Virtual server locations aren't necessarily a bad thing, but when used to excess, they may indicate that a VPN is more concerned with making its server network look big than ensuring it works for every user. PIA's server network is more than half virtual worldwide. Recently, it's added locations in every US state — again, mostly virtual, which makes it come off as more of a stunt than a genuine improvement. Given the trouble I had using PIA for this review, I find that there's something to the claim that it's more interested in growing than in working. PIA's website has a helpful page that shows where virtual servers are physically located, though it's out of date, having been updated last in July 2023. The list shows that PIA tries to put the real locations of virtual servers as close to their displayed locations as possible. There are a couple of weird choices, like the Buenos Aires server really being in Miami, but that's mostly kept to a minimum. Extra features of Private Internet Access Private Internet Access doesn't have the wealth of features you'll see on the likes of Surfshark or NordVPN, but it's not quite as bare-bones as ExpressVPN, either. Some of its most interesting extras are self-explanatory, while others are a little technical. I'll explain the most important features here. Kill switch A kill switch is a must-have for a safe VPN. While active, the kill switch makes it impossible to connect outside the VPN tunnel, which keeps you from accidentally connecting to malicious fake servers. This also means that if PIA drops your connection for any reason, you won't be able to get online at all — which can be annoying, but saves you from broadcasting any sensitive information without encryption. Sam Chapman for Engadget PIA comes with two levels of kill switch. The basic version watches for traffic outside the tunnel when the VPN is active. The stronger \"advanced kill switch\" works even when you aren't connected to the VPN, so you cannot get online at all without being protected by PIA first. PIA MACE MACE is PIA's ad blocker. It keeps a list of domains known to display ads, malware, scams or invasive trackers, and blocks them all from loading. This won't stop all ads, since some of them come from domains considered legitimate — notably, MACE can't do anything about YouTube video ads — but it works on most banner ads and definitely lightened the load on my browser. MACE is available on all PIA's apps except iOS. iPhone and iPad users instead get a content blocker that does much the same thing, but only on Safari. If you prefer to use Chrome or Firefox on your iOS device, you're out of luck (unless of course you get another ad blocker). Maximum transfer unit (MTU) MTU is a somewhat technical feature. You may not need it, unless your connection is extremely sluggish and the traditional fixes don't work. In short, MTU limits how much data can move through PIA's servers at a time. Large packets complete loading faster, but may struggle on shaky connections. Small packets make for slower but more stable downloads overall. I say you probably won't need it because it's almost always best to leave it on the auto setting and let PIA pick MTU on its own. I ran some speed tests with both the large and small MTU options and didn't see a noticeable difference. That indicates that PIA is pretty good at picking the best MTU, so in most cases, just let it cook. Automation On the automation tab in PIA's settings, you can set up rules to save you some trouble with the VPN. On Mac and iOS, automation can respond to three types of network: protected Wi-Fi, open Wi-Fi and wired. On each of these, you can set PIA to automatically connect or disconnect. That's it — you can only have a maximum of three rules. Android and Windows users get the option to make rules for specific networks, but only the network they're currently connected to. On every platform, there's no way to determine which server PIA auto-connects to. It always picks the fastest. Sam Chapman for Engadget The inch-deep options on their own would make for a disappointing feature, but there's a bigger issue: it doesn't work half the time. I spent at least an hour on four different platforms trying to make automation happen. On iOS and macOS, I could make the rules, but they never triggered. With Android, I got stuck at a prompt telling me to enable location services, which I had already done. Windows was the only version where PIA's automation worked the first time. On the plus side, it gave me the question I used to test PIA's customer support. Split tunneling Split tunneling — which lets you decide which apps or websites go through the VPN tunnel and which stay outside — is a common feature, but PIA surprisingly has one of the best implementations of it. To start with, it can split tunnel by app or by IP address, which lets you protect specific websites or leave them unencrypted. Sam Chapman for Engadget In another layer of versatility, you can make your split tunnel rules in normal or inverse fashion. Either every app and website uses the VPN except the ones you designate, or only the ones you designate use the VPN. All these options give you a much finer level of control that you get over the automation feature. Multi-Hop via Shadowsocks and SOCKS5 Double-hop or multi-hop is when a VPN runs your requests through two servers instead of one. PIA handles multi-hop a little differently than other VPNs, as the second server will always be a Shadowsocks or SOCKS5 proxy. These two protocols are designed to obfuscate VPN traffic so it looks like a regular connection, which gets you around certain firewalls. Sam Chapman for Engadget If you choose a SOCKS5 proxy, you'll need to get a server address from an outside service and set it up yourself. If you pick Shadowsocks, which is the more secure option anyway, you can choose from a list of locations to use as the first node. It's nice to have so many choices, but still a bit frustrating that you can't get obfuscation without also using double VPN (which only works on the OpenVPN protocol). Port forwarding The final PIA feature worth noting is port forwarding, which keeps the VPN from getting in the way of any outward-facing services you might be using. This gives you a more stable connection on remote desktop protocols or torrenting clients — especially the latter, as that's the sort of traffic you really want to keep encrypted. Private Internet Access customer support options When I set out to test the automation features of Private Internet Access, I found myself blocked on the Android app. A notification popped up telling me to enable background access to location services, but the button labeled \"go to permissions settings\" didn't do anything. I took the long way around and made the changes myself, but the pop-up remained stubborn. Sam Chapman for Engadget This gave me a perfect opportunity to see how PIA helps users caught in predicaments like this one. First, I went to the website and clicked \"support\" in the top banner to reach the PIA helpdesk. Then the trouble started. I opened up the Android guide on my Mac laptop and waited several minutes for the file to load. When it didn't, I tried my Android phone, which also didn't work. I checked back on the laptop, where I finally saw the guide after reloading the page. Sam Chapman for Engadget After all that, the guide said nothing about my problem. Nor could I find it anywhere in the general FAQs, which kept splitting into smaller and smaller categories which never really explained what I'd find. However, after a few minutes of searching, I found the problem had resolved itself with no explanation. Live support experience I still had to test live chat, though, so I pivoted to a new problem: how to get the Android automation feature to recognize my home Wi-Fi network instead of calling it \"unknown SSID.\" I couldn't be sure it was my own network and not a malicious duplicate. This may sound like paranoid nitpicking, but paranoid nitpicking is the bread and butter of cybersecurity. I first had to find live chat, which confusingly can't be accessed through the helpdesk — you have to go back to the main website. I managed to get past the AI gatekeeper fairly quickly, and sat to wait for a human agent. In less than a minute, I was chatting with Carl, who requested screenshots and ran me through some tests. Carl was able to explain that the pop-up problem had resolved because I'd given PIA full access to location services (which is not something the window itself specified I would need to do), but the unknown SSID issue persisted. Sam Chapman for Engadget Carl was diligent, but slow. After well over 30 minutes of back-and-forth, during which I sent over two screenshots and a debug log, he told me we'd have to escalate the problem. I got an email from the support team about a day later that suggested I try connecting to other Wi-Fi networks and see if the problem persisted; this eventually led me to discover the culprit in my router settings, so I can't blame PIA for this one. Private Internet Access background check The final step, as always, is to look into the history of Private Internet Access as a corporation and look for any red flags I may have missed. A VPN's biography can reveal its attitudes about critical aspects of its job and show how it might behave in the future. PIA was launched in 2010 by Andrew Lee in Denver, Colorado, where it's still based today. In 2019, the brand was acquired by Kape Technologies, owners of ExpressVPN, CyberGhost and the now-defunct ZenMate. I won't relitigate the full Kape controversy here; you can find a longer summary in my ExpressVPN review. Suffice to say that while it's come under scrutiny in the past for tacitly allowing its products to become malware vectors, there's no evidence the acquisition changed anything substantial about how PIA operated. Most of the usual red flags aren't factors here. PIA has never suffered a serious hack or breach. In its 15-year record, I only found two things worth pointing out: a controversial executive and its United States headquarters. Former CTO Mark Karpeles Mark Karpeles was the CEO of Mt. Gox, the market for Magic: The Gathering trading cards that became the world's largest crypto exchange, only to lose it all in a massive hack that's never been fully explained. Karpeles was arrested in Japan after the heist and found guilty of falsifying records, but was sentenced to time served and released in 2019. While the Japan trial was ongoing, Karpeles joined PIA parent company London Trust Media as its chief technical officer. PIA founder Andrew Lee defended the hiring in a statement on the PIA blog, writing that \"If we, as a society, do not give second chances to those who fall, then we as a society will cease to progress,\" and comparing Karpeles's arrest to Steve Jobs being forced out of Apple. Neither man works at PIA anymore. According to his LinkedIn, Karpeles left London Trust Media after the Kape Acquisition in 2019. Lee left at the same time, and these days seems less interested in cybersecurity than in trying to become the Prince of Korea. Bottom line: Although hiring an executive in the middle of his malfeasance trial may be terrible optics, the whole controversy isn't relevant to the VPN's operations today. US headquarters and Five Eyes The other potential sticking point with PIA is that it's headquartered in the United States, which is a member of the Five Eyes intelligence sharing agreement. Now, I'm on the record as not thinking Five Eyes is a big deal for a VPN — either the VPN is following its privacy policy, in which case it'll have nothing to share with intelligence agents, or it's not, in which case its location is the least of its problems. As I concluded in the Privacy section, whatever PIA's flaws, it's not mishandling user data or violating its own privacy policy. That's not only confirmed by two audits, but also by two separate court cases in which PIA was unable to comply with requests for logs on its customers. If the VPN doesn't save information, there's nothing for Five Eyes to access. Final verdict There's plenty that does work about PIA. Its privacy and security are unimpeachable — it uses vetted protocols with strong encryption and doesn't leak. Its iOS app is a nearly perfect mobile VPN, and the ability to customize the home screen on every app is a great touch. Split tunneling is outstanding, MACE blocks ads efficiently and I even like the automation (though I wish it was deeper). But PIA is aggravating to use in too many ways. While its servers are frequently fast, you can't trust that download speeds will hold from one moment to the next. Basic quality assurance, like assuring pop-up buttons always do something when pressed, seems to have gone by the wayside in its Android app. In spite of it all, I still recommend Private Internet Access as a budget VPN. Its three-year plan is the cheapest subscription on the market right now. At $2.00 per month, I'm prepared to forgive a lot, especially at a time when all our wallets are squeezed. This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/private-internet-access-vpn-review-both-more-and-less-than-a-budget-vpn-120033882.html?src=rss",
          "feed_position": 29,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/8e192120-addb-11f0-bbea-b34ea7da8023"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html",
          "published_at": "Wed, 22 Oct 2025 09:00:37 +0000",
          "title": "The best wireless headphones for 2025: Bluetooth options for every budget",
          "standfirst": "Wireless headphones have come a long way from the bulky designs of the past. Today’s models are lighter, smarter and packed with features that make them useful for everything from travel to long workdays at your desk. Many offer strong noise cancellation, quick pairing and reliable battery life — all of which makes them an easy upgrade if you want more freedom from your devices.Of course, not every listener has the same needs. Some people want portability, which is why our guide to the best earbuds is worth a look, while others want something more specialized like the best gaming headsets or the best budget earbuds. But if you’re after over-ear headphones that focus on comfort and immersive sound, this roundup of the best wireless headphones highlights the top choices we’ve tested. Table of contents Best wireless headphones for 2025 How to choose the best wireless headphones for you How we test over-ear headphones Other wireless headphones we tested Wireless headphones FAQs Best wireless headphones for 2025 How to choose the best wireless headphones for you When it comes to shopping for a good pair of wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of our buyer’s guide, we focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear designs are much more effective at blocking sound. Speaking of noise cancellation, you’ll want to determine early on if you even want that. If you frequently crank up the beats in noisy environments, you’ll want to not only make sure it’s there, but also make sure it’s good, preferably with adaptive ANC. If you plan to use your new headphones in quieter spaces, skipping ANC can save you some money. The next area to consider is features. We recommend trying to get the most bang for your buck, but as you’re shopping around you should determine which items are must-haves and what you can live without. And don’t take basic things like automatic pausing and Bluetooth multipoint connectivity for granted, as not all companies include them. We also suggest reading reviews to see how well a company’s more advanced features work. This will help you decide if those are something you’re willing to (likely) pay extra for. Keep an eye on better battery life estimates to avoid disappointment, as some manufacturers promise more hours than real-world testing delivers. And don’t be easily swayed by lofty promises about call quality without verifying them. Sound can be subjective, so we recommend trying before you buy if at all possible. We understand this isn’t easy at a time when we’re doing most of our shopping online. But trying on a set of headphones and listening to them for a few minutes can save you from an expensive case of buyer’s remorse. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all headphones support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you. If you plan to use your headphones for other media besides music, checking for latency is also a must — some delay can impact playback for things like movies or games, even if most true wireless headphones now offer minimal lag. How we test over-ear headphones The primary way we test wireless headphones is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for headphones can be 30 hours or more, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, we’ll typically power the headphones off several times and leave them during a review. This simulates real-world use and keeps us from having to constantly monitor the process for over 24 straight hours. To judge the best Bluetooth headphones, we focus on higher-quality audio by listening to a variety of genres and paying close attention to how each style sounds. We also test at both low and high volumes to check for consistency in the tuning. To assess the quality of phone calls, we’ll record audio samples with the headphones’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that we review. Other wireless headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancelation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor which is actually handy. All told, that’s not a lot in a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Sony WH-CH720N While the WH-CH720N are a great affordable option, we prefer the Audio-Technica in the budget category. Sony’s cans are lightweight with good sound quality, but ANC struggles at times and they’re made with a lot of plastic. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Bose QuietComfort Ultra headphones Bose’s latest flagship model has a lot to offer, but its trademark Immersive Audio feature can be inconsistent across different types of music. There’s still world-class ANC, excellent comfort and a clearer transparency mode, but for the price, the non-Ultra model is a better choice right now. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 are more expensive and not nearly as comfortable as the Px7 S2. Wireless headphones FAQs How can you tell the quality of wireless headphones? I typically look at three factors: design, sound quality and features. In terms of design, I’m usually looking to see if the build quality of the headphones feels cheap and plasticky. Plenty of companies use plastic, but they can do so in a way that doesn’t look or feel like budget models. For sound quality, I want to hear a nice, even tuning where highs, mids and lows are all well represented. No overly boomy bass or scooped out mids. I also want good clarity where you can pick up fine details and an open, immersive soundstage. Features is typically a distant third, but if a company doesn’t cover basic functionality (automatic pausing, transparency mode, multipoint Bluetooth, etc.) it can be an indication of overall quality. How do I choose the best quality wireless headphones? “Best” can be pretty subjective, but I always recommend going to a place where you can listen to the headphones you’re thinking about buying before you commit. Sometimes this isn’t possible, so you’ll want to check return policies. I also recommend doing some research to determine what your priorities are in a new set. Are you an audiophile who wants the best sound quality? Is powerful active noise cancellation (ANC) the most important? Would you rather have conveniences like automatic pausing? Which brand has the best wireless headphones? Sony consistently tops our list with its 1000X line. This is mostly due to the combination of sound quality, ANC performance and the truckload of features these headphones pack in. I’ll be the first to tell you that there are better sounding options and other companies, like Bose, offer more effective noise cancellation. But when you add everything up, no one comes close to the full slate of tools Sony puts in its premium headphone line. Do expensive wireless headphones sound better? Exorbitant price tags don’t mean better audio quality. Bowers & Wilkins’ headphones are on the high end for wireless noise-canceling models and they sound amazing. However, Audio-Technica’s M50xBT2 is much more affordable and doesn’t have ANC, but these headphones have a warm, natural sound profile that I find very inviting. At the end of the day, it will come down to personal preference, but you don’t need to spend a lot to find great headphones.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html?src=rss",
          "content": "Wireless headphones have come a long way from the bulky designs of the past. Today’s models are lighter, smarter and packed with features that make them useful for everything from travel to long workdays at your desk. Many offer strong noise cancellation, quick pairing and reliable battery life — all of which makes them an easy upgrade if you want more freedom from your devices.Of course, not every listener has the same needs. Some people want portability, which is why our guide to the best earbuds is worth a look, while others want something more specialized like the best gaming headsets or the best budget earbuds. But if you’re after over-ear headphones that focus on comfort and immersive sound, this roundup of the best wireless headphones highlights the top choices we’ve tested. Table of contents Best wireless headphones for 2025 How to choose the best wireless headphones for you How we test over-ear headphones Other wireless headphones we tested Wireless headphones FAQs Best wireless headphones for 2025 How to choose the best wireless headphones for you When it comes to shopping for a good pair of wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of our buyer’s guide, we focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear designs are much more effective at blocking sound. Speaking of noise cancellation, you’ll want to determine early on if you even want that. If you frequently crank up the beats in noisy environments, you’ll want to not only make sure it’s there, but also make sure it’s good, preferably with adaptive ANC. If you plan to use your new headphones in quieter spaces, skipping ANC can save you some money. The next area to consider is features. We recommend trying to get the most bang for your buck, but as you’re shopping around you should determine which items are must-haves and what you can live without. And don’t take basic things like automatic pausing and Bluetooth multipoint connectivity for granted, as not all companies include them. We also suggest reading reviews to see how well a company’s more advanced features work. This will help you decide if those are something you’re willing to (likely) pay extra for. Keep an eye on better battery life estimates to avoid disappointment, as some manufacturers promise more hours than real-world testing delivers. And don’t be easily swayed by lofty promises about call quality without verifying them. Sound can be subjective, so we recommend trying before you buy if at all possible. We understand this isn’t easy at a time when we’re doing most of our shopping online. But trying on a set of headphones and listening to them for a few minutes can save you from an expensive case of buyer’s remorse. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all headphones support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you. If you plan to use your headphones for other media besides music, checking for latency is also a must — some delay can impact playback for things like movies or games, even if most true wireless headphones now offer minimal lag. How we test over-ear headphones The primary way we test wireless headphones is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for headphones can be 30 hours or more, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, we’ll typically power the headphones off several times and leave them during a review. This simulates real-world use and keeps us from having to constantly monitor the process for over 24 straight hours. To judge the best Bluetooth headphones, we focus on higher-quality audio by listening to a variety of genres and paying close attention to how each style sounds. We also test at both low and high volumes to check for consistency in the tuning. To assess the quality of phone calls, we’ll record audio samples with the headphones’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that we review. Other wireless headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancelation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor which is actually handy. All told, that’s not a lot in a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Sony WH-CH720N While the WH-CH720N are a great affordable option, we prefer the Audio-Technica in the budget category. Sony’s cans are lightweight with good sound quality, but ANC struggles at times and they’re made with a lot of plastic. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Bose QuietComfort Ultra headphones Bose’s latest flagship model has a lot to offer, but its trademark Immersive Audio feature can be inconsistent across different types of music. There’s still world-class ANC, excellent comfort and a clearer transparency mode, but for the price, the non-Ultra model is a better choice right now. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 are more expensive and not nearly as comfortable as the Px7 S2. Wireless headphones FAQs How can you tell the quality of wireless headphones? I typically look at three factors: design, sound quality and features. In terms of design, I’m usually looking to see if the build quality of the headphones feels cheap and plasticky. Plenty of companies use plastic, but they can do so in a way that doesn’t look or feel like budget models. For sound quality, I want to hear a nice, even tuning where highs, mids and lows are all well represented. No overly boomy bass or scooped out mids. I also want good clarity where you can pick up fine details and an open, immersive soundstage. Features is typically a distant third, but if a company doesn’t cover basic functionality (automatic pausing, transparency mode, multipoint Bluetooth, etc.) it can be an indication of overall quality. How do I choose the best quality wireless headphones? “Best” can be pretty subjective, but I always recommend going to a place where you can listen to the headphones you’re thinking about buying before you commit. Sometimes this isn’t possible, so you’ll want to check return policies. I also recommend doing some research to determine what your priorities are in a new set. Are you an audiophile who wants the best sound quality? Is powerful active noise cancellation (ANC) the most important? Would you rather have conveniences like automatic pausing? Which brand has the best wireless headphones? Sony consistently tops our list with its 1000X line. This is mostly due to the combination of sound quality, ANC performance and the truckload of features these headphones pack in. I’ll be the first to tell you that there are better sounding options and other companies, like Bose, offer more effective noise cancellation. But when you add everything up, no one comes close to the full slate of tools Sony puts in its premium headphone line. Do expensive wireless headphones sound better? Exorbitant price tags don’t mean better audio quality. Bowers & Wilkins’ headphones are on the high end for wireless noise-canceling models and they sound amazing. However, Audio-Technica’s M50xBT2 is much more affordable and doesn’t have ANC, but these headphones have a warm, natural sound profile that I find very inviting. At the end of the day, it will come down to personal preference, but you don’t need to spend a lot to find great headphones.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-laptops-120008636.html",
          "published_at": "Wed, 22 Oct 2025 07:01:26 +0000",
          "title": "The best laptop you can buy in 2025",
          "standfirst": "Choosing the best laptop can be a bit of a challenge — there are so many models, sizes and specs out there that it’s easy to feel lost in the shuffle. But the good news is that modern laptops are better than ever. Whether you're looking for a powerful AI PC, a travel-ready ultrabook or an affordable machine that can handle everyday tasks, there's something out there for everyone. Today’s systems combine improved performance, longer battery life and smarter features in sleek, lightweight designs that are built to keep up with work, play and everything in between.Out of all of the notebooks we've tested and reviewed recently, we consider Apple's 13-inch MacBook Air M4 to be the best laptop for most people, and this is still the case for our top picks to start off the new year. It's powerful enough to handle most tasks (even light video editing); it has a great screen and built-in speakers; and its battery could last over 18hours (depending on what you're doing, of course). The MacBook Air M4 is also one of the lightest and thinnest systems we've reviewed, and it's dead silent, thanks to a fanless design.Of course, not everyone wants a MacBook, and there are excellent Windows laptops and Chromebooks out there, too. Windows systems offer a range of configurations, from budget to high-end UHD screens with stunning IPS panels that boast high nits for vivid brightness. Chromebooks, on the other hand, tend to be more affordable and are great for users who mostly work online. Whether you need a powerhouse for creative work, a compact system for note-taking, or a laptop that can handle family movie night, there’s something for everyone in today’s laptop market. Best laptops of 2025 Back to top Specs to look for in a new laptop Depending on the type of laptop you’re looking to buy, there are some specs we think you should look for to get a machine that’s powerful enough for your needs and future-proof for the next couple of years (at least). Here's a cheat sheet for you to use when you're shopping. MacBooks At least M2 processor At least 16GB of RAM At least 256GB of SSD storage Windows laptops The most recent generation processor available from Intel or AMD At least 16GB of RAM At least 256GB of SSD storage Chromebooks Intel Core i processor At least 8GB of RAM (4GB is the bare minimum for a basic Chromebook) At least 128GB of storage, preferably a SSD Gaming laptops At least AMD Ryzen 9000 series or Intel 14th Gen Core CPU At least 16GB of RAM (ideally 32GB if you can swing it) At least 1TB of SSD storage For GPU recommendations, check out our guide to buying the best GPU for your needs Budget laptops The most recent generation processor available from Intel or AMD At least 8GB of RAM At least 256GB of SSD storage Back to top How we test laptops Engadget has been reviewing laptops for two decades, and while the definition of what a portable PC is has changed considerably since, our obsession with testing their limits and serving up informative buying advice remains the same. Be it a hybrid tablet like Microsoft's Surface machines, a rotating 2-in-1 convertible like HP's Spectre x360s or a plain old clamshell notebook, our review process follows similar beats. How does it look and feel? How fast is it? Whether it’s a Windows device powered by an Intel Core i5 or higher, a MacBook or a Chromebook, we aim to answer the most important question: Is it actually worth your hard-earned cash? We also pay close attention to portability, webcam quality and display features, including IPS panels and nits of brightness, as they can make a big difference in daily use. Back to top Factors to consider when choosing a laptop Operating system: Apple, Windows or Chrome OS There's a good chance you've already committed to an operating system, but my advice is to be as flexible as possible. These days, most major software is compatible with both Macs and PCs. (Of course, it's another story if you've become dependent on an Apple-only app like Final Cut Pro.) Web-based apps, naturally, will work on any platform with an internet browser. If you're an Apple-loyalist, there aren't many reasons to consider Windows laptops (unless you want a secondary gaming machine). But for Windows users, macOS is becoming more tempting every year. Apple's MacBooks, powered by its M-series Silicon chips, are among the fastest and most efficient laptops we've ever seen. They're incredibly well-built and have outstanding battery life to boot. MacOS itself is also an easy platform to learn, especially if you're used to iOS and iPadOS. That brings up another point: iPhone users may want to consider Macs because of the seamless integration with Apple's other platforms. You can't respond to iMessage conversations easily or hop into FaceTime chats on Windows PCs, but doing so is simple on Macs. (Microsoft's Phone Link app lets you send iOS users individual texts, but not media or group chats.) Android users, meanwhile, may be better off with Windows, as Phone Link can make calls, synchronize all your texts and also access your phone's photos. If cloud gaming is your priority, Windows laptops with NVIDIA’s GeForce Now or Xbox Cloud Gaming compatibility may offer more flexibility and decent performance, especially when paired with fast internet speeds. Chromebooks also make a compelling case here as an affordable, lightweight solution for casual cloud gaming sessions. As for whether you’ll want a PC with a dedicated Copilot AI button on the keyboard, that depends on how often you see yourself using Microsoft’s generative tools. Given we’re only just seeing the first slate of AI PCs, it would be wiser to wait out the hype and see what improvements might come over time. And what about ChromeOS? Chromebooks are a smart and (typically) inexpensive way to do things like web browsing and hopping on a few video chats, but for most, they're not the best choice as a primary computer. There aren't many apps or games that work offline, and they also don't work with powerful software suites like Adobe's (you can use the stripped-down Adobe Express and Photoshop online tools, though). Chromebooks are great secondary machines to use alongside a more powerful Mac or PC, and they're popular in schools because they're cheap and easy for IT workers to manage. And if all you need is web browsing access, or a notebook for a kid, a Chromebook might be enough. If, for some reason, you’re looking for a powerful ChromeOS system, there are also Chromebook Plus models to consider. These machines sport faster processors and more RAM than typical Google notebooks, and they can also tap into a few of the company’s online AI features, like AI image generation and photo processing. Price You can expect to spend between $1,000 and $1,800 for a new laptop these days, depending on the configuration. If you're looking for more of a workhorse, that could cost you well over $2,000 for additional RAM, storage, as well as a beefier graphics card and CPU. But you can also find some good laptops under $1,000 if you're willing to overlook build quality (or buy a refurbished or previous generation machine, which we highly recommend). Systems with AMD chips tend to come in cheaper than their Intel counterparts, but the bulk of their cost will come down to other components like RAM and storage. I’ve included our favorite affordable model in this best laptop buying guide, but we have a list of the best budget laptops that you can check out as well. Laptop size and weight So how portable do you want your laptop to be? That's the ultimate question you need to ask when choosing between various screen sizes. 13-inch machines have become a solid starting point for most shoppers — it's enough real estate for the majority of tasks like emailing and writing, and it also helps keep machines relatively light (typically between two to three pounds). Thanks to manufacturing advancements, these dainty machines sometimes even come with larger screens (the smaller MacBook Air actually has a 13.6-inch display). If you have trouble seeing fine text, we’d recommend going for a display larger than 13 inches. ASUS’s Zephyrus G14 is a solid 14-inch option for gamers, and we’re also seeing more productivity-focused machines aim for that size, like the Dell 14 Premium and MacBook Pro. While 14-inch notebooks are a bit heavier than 13-inch models, coming in between three to four pounds, their screens are noticeably roomier. For artists, or anyone else who needs a large canvas, a 15-inch laptop may make the most sense. They typically weigh between 3.5 and 4.5 pounds, but that extra heft may be worth it to fit wider video editing timelines or Photoshop windows. And, as you'd expect, you'll also pay a bit more for a 15-inch notebook compared to smaller ones (the 15-inch MacBook Air starts at $1,199, while the smaller model goes for $999). PC makers are also replacing 15-inch systems with 16-inch versions, which will give you even more space to work. If you're in the market for a business laptop, size and portability might be key considerations. A lightweight yet powerful system with a long battery life can make a world of difference if you travel frequently for work. You can still find laptops with 17-inch or 18-inch screens, but those are typically gaming systems or souped-up workstations. They're not meant for mere computing mortals. Ports and connectivity These days, most laptops ship with a few USB-C ports, which can handle both charging and speedy data transfers. Apple's MacBooks also include a separate connection for MagSafe power, and you'll find custom power connections on some PCs like Microsoft's Surface. Older USB Type-A connections are less common now, but they still pop up in systems like HP's Spectre x360 14, as well as many models from ASUS. For gamers or creators who rely on discrete graphics, ensuring your laptop has the right ports for external monitors or GPUs is crucial. DisplayPort or HDMI connections can also ensure you’re ready for dual- or multi-screen setups for more immersive experiences. Similarly, if you want to save high-resolution files or install multiple games, you might need to consider additional hard drive space; external hard drives are pretty affordable, as long as you have a proper port to connect them. If you're a fan of wired headphones, it's worth keeping a close eye on headphone jack availability. They usually include a USB-C to 3.5mm adapter, but that's a clunky solution, and it also takes up a USB port. Sure, most people use wireless earbuds and cans today, but it's still helpful to have a wired one around for when those devices run out of juice. Most laptops today offer Wi-Fi 6 or 6E and Bluetooth 5.0 or later, which should mean faster and more stable connections if you have compatible routers and devices. While Wi-Fi 7 routers have started appearing, that spec hasn't made its way into laptops yet. As for cellular coverage, there are notebooks like the Surface Pro 9 and Samsung Galaxy Book models that offer integrated 5G. But from our testing, that feature may not be worth the cost of a separate data plan. Instead, you could tether to your smartphone or invest in a wireless hotspot that can keep multiple devices online. Battery life A laptop's battery life depends on several factors: The power draw from the screen and other hardware, the optimizations used to avoid unnecessary power drain, and, of course, the size of the actual battery. One of our previous favorite systems, the Dell XPS 13, lasted 13 hours and 15 minutes in the PCMark 10 battery benchmark. In real-world testing, I was able to use it for a day and a half without needing a recharge. The MacBook Air 13-inch, meanwhile, more than 18 hours in our benchmark and kept running for more than two work days of my typical workflow. In general, you should expect a modern laptop to last at least eight hours. If battery life is your absolute priority, I'd strongly suggest looking at Macs over Windows PCs. Apple's M-series chips are essentially mobile hardware, with all of the power efficiency you'd expect from something originally designed for phones. Qualcomm’s upcoming Snapdragon chips could help Windows PCs compete with Apple’s astonishing battery life, but we’ve yet to see those in action. Chromebooks also typically get decent battery life (as long as you don’t overstuff them with power-draining tabs). Refresh rate A laptop's refresh rate refers to the amount of times its screen is cycled every second. Modern displays like IPS LCDs and OLEDs support 60Hz refresh rates at a minimum, but we're seeing more devices offering 120Hz, 240Hz and beyond. The higher the number, the faster the screen is refreshed, which ultimately leads to a smoother experience while mousing around or scrolling through web pages. (If you want to get a sense of what a slow refresh rate looks like, just grab an e-reader like the Kindle and try to flip between book pages.) While high refresh rates used to be reserved for gaming laptops, nowadays we're seeing more mainstream machines like the Dell 14 Premium offer 120Hz (or variable rates that move between 60Hz and 120Hz). CPU and GPU If you’re buying a new laptop, you’ll want to make sure it’s powered by the latest CPUs. For Windows PCs, that includes Intel’s Core Ultra chips for thin-and-light machines or the 14th-gen HX chips for beefier systems. The Core Ultra series have NPUs for handling AI tasks, while the HX hardware does not – they’re based on Intel’s previous chip architecture, and they’re more focused on delivering raw horsepower. Intel's older 13th-gen and 12th-gen laptop chips also don't have NPUs, so keep that in mind if you're looking at used systems. You'll also see AMD's Ryzen 8000 and 9000 chips in plenty of new systems like the ASUS Zephyrus G14 and Razer Blade 14. Those CPUs mainly target gaming laptops and high performance systems, while you'll still find AMD’s older Ryzen 7000 chips in ultraportables. AMD's main advantage is that its chips also include Radeon graphics, which are far more capable than Intel's Arc hardware (though those are getting better). Qualcomm’s new Snapdragon X Elite and X Plus are also an option in Copilot+ PCs (more on those below). Since they’re based on mobile chip designs, they’re likely also more power efficient than AMD and Intel’s hardware. In the past, we’ve avoided recommending Snapdragon chips because they led to a slow and frustrating Windows experience. But Microsoft claims it’s rebuilt Windows 11 around Snapdragon’s Arm-based architecture, which should lead to far faster performance and better app compatibility. As for Apple's laptops, you'll be choosing between the M4 Pro, M4 Max and M5, each of which is progressively more powerful. On the graphics side of things, a GPU, or graphics processing unit, is the component that communicates directly with a laptop's display. Laptop CPUs all have some form of integrated GPU: Intel has either its standard graphics or beefier Arc hardware, while AMD's chips include fast Radeon mobile graphics. If you want to play demanding games at high speeds (measured in frames per second, or fps), or if you need some extra power for rendering video or 3D models, you can configure a laptop with a dedicated GPU like NVIDIA's RTX 40-series hardware or AMD's Radeon RX 7000. Just be sure to leave room in your budget if you want a powerful GPU, as they typically add $300 or more to the cost of a laptop. Apple's M-series chips, meanwhile, have GPU cores that can perform as well as NVIDIA’s and AMD's lower-end dedicated GPUs. That's quite the accomplishment for systems like this (especially the MacBook Air and 14-inch MacBook Pro), and it's another reason we highly recommend Apple's notebooks. AI PCs, NPUs and Copilot+ Simply put, an AI PC is a computer equipped with a neural processing unit (NPU), which is designed to handle AI-related tasks. Much like how GPUs tackle heavy-duty gaming and rendering workloads, NPUs are designed to handle the complex math necessary for AI workloads. They’re also far more power efficient than CPUs or GPUs, which could lead to better battery performance in laptops. While many factors go into NPU performance, for the most part we measure their potential speed by TOPS (tera operations per second). We were primed for AI PCs based on the chips Intel and AMD announced in 2023. Intel unveiled its \"Core Ultra\" CPUs in December, its first to include an NPU for AI work. AMD also announced its Ryzen 8040 AI mobile chips that month (and it couldn't help but say they were faster than Intel's new hardware). But in May, Microsoft announced its Copilot+ initiative, which is pushing major PC makers to deliver premium AI PCs with specifications including 16GB of RAM, 256GB SSDs and NPUs with at least 40 TOPS of AI performance. Copilot+ is more than just a marketing term: Microsoft is also launching AI-powered features in Windows 11 that take advantage of powerful NPUs. That includes Recall, which can help you locate anything you’ve done on your PC (whenever it finally launches), as well as Cocreator in Paint, which can generate AI images based on text prompts and doodles. If you buy an AI PC that isn’t Copilot+ certified, you’ll still be able to use some features like Windows Studio Effects, which can blur your background in video calls or keep you in frame. Developers like Adobe and Audacity are also building features into their apps that can take advantage of NPUs. At the time of this post, Chromebook Plus notebooks can also access a few of Google’s online AI features, like image generation and photo processing. Back to top Other laptops we tested Lenovo ThinkPad X9-14 Aura Edition The ThinkPad X9-14 Aura Edition is a great spiritual successor to the ThinkPad X1 Carbon, offering the best that business laptops have to offer. That includes long battery life packed into a thin and light chassis. This is an optimal ultraportable business laptop. While the price might give you some pause, we tested the lowest configuration, and found that the X9-14’s performance is excellent for casual business users. The only issue with quality is that the keyboard is lacking. It’s mushier than we’d like, which could get a bit tiresome throughout the day. You’ll still miss out on a USB Type-A port, so you may need to carry a Type-C hub with you. Where the ThinkPad X9-14 will win you over is its bold OLED screen. Combo that with its well-rounded audio, and the ThinkPad X9-14 makes for an excellent multimedia device in and out of the workplace. ASUS Zenbook 14 OLED Aside from its lovely OLED screen, the ASUS Zenbook 14 OLED doesn't stand out from the crowded laptop field in any way. It just looks dull and boring, especially compared to the strikingly beautiful ASUS Zephyrus G14, which also came out this year. While you can probably find the Zenbook 14 for a decent price, I'd recommend holding out for something with a bit more personality (and with a less wobbly screen hinge). Razer Blade 14 The Razer Blade has almost everything you'd want in a 14-inch gaming notebook, but it's far pricier than the Zephyrus G14 on this list, and it doesn’t even have an SD card reader. It would be a solid competitor once its price falls a bit, and it's certainly a great option if you just have to have a jet-black laptop. Framework Laptop 16 Framework gave its modularity magic to the Laptop 16, delivering a gaming notebook where almost every single component is user replaceable. But you'll have to pay a pretty penny to snag it with upgraded hardware, and its optional Radeon 7700S GPU was surprisingly slow. Alienware m16 R2 The Alienware m16 r2 has been revamped with a slimmer case, but it’s otherwise a fairly typical gaming laptop. It’s a solid option for Alienware fans, but you’ll find better hardware and deals elsewhere. ASUS Zenbook Duo (2024) The Zenbook Duo is a fascinating dual-screened notebook, and according to my colleague Sam Rutherford it’s the first of its kind that’s worth buying. But its unique hardware isn’t really meant for mainstream consumers, and Windows 11 still doesn’t support multi-screen setups well enough to make full use of the Zenbook Duo’s ample canvas. Dell XPS 16 Dell’s XPS 16 is big and beautiful, but it’s far too expensive compared to the competition. Plus, it uses a capacitive row of function keys that you basically can’t see under bright light and has too few ports for a machine of this size. See Also: Best Gaming Laptops for 2025 Best Cheap Windows Laptops Best 2-in-1 Laptops for 2025 Best Chromebooks Best Laptops for College Students Back to top Laptop FAQs What is the average battery life of a laptop per charge? It’s hard to come up with an average battery life for laptops, since that will ultimately depend on what you’re doing with them. An ultraportable like the MacBook Air that sips power can last around 20 hours in our battery benchmark, and around two full work days of real-world usage. But a gaming laptop may last only a few hours if you’re actively playing something while on battery. At this point, Macs are delivering far better battery life than PCs, thanks to Apple’s Silicon chips, but Microsoft claims Copilot+ systems with Qualcomm chips will also get over 20 hours of batter life. How much RAM do I really need? The more RAM you have, the more things your computer can do simultaneously. For that reason, we recommend buying PCs and Macs with at least 16GB of RAM. That gives you enough memory to have several applications open at once, as well as web browsers filled with RAM-hogging tabs. Many PC games also require at least 16GB of RAM. While you could use a system with 8GB of RAM for basic tasks, you’ll quickly run into slowdowns and error messages as your apps stack up. Many laptops, especially ultraportables, don’t let you upgrade RAM, too – so you’ll have to buy an entirely new computer if you didn’t equip enough memory at the start. If you’re a hardcore gamer, programmer or planning to render videos or 3D models, then you may want to go for 32GB of RAM or more. And if you just need a secondary laptop for lighter work – perhaps a no-frills system for writing – then you can probably get by with 8GB. Just be sure to keep those browser tabs in check. What is the best storage capacity for a laptop? There is no one-size-fits-all solution when it comes to laptop storage. You’ll typically find configurations between 256GB and 1TB SSDs (solid state drives) on most laptops, and I’d recommend most people get at least 512GB. That’ll be enough space for large apps, music and video files without stressing your system too much. If you’re a media hoarder, or want to play a ton of games, then it’s definitely worth getting a 1TB SSD. If you’ll mainly be streaming your shows and music, and would rather invest in RAM or other hardware, then 256GB of storage would be serviceable. I’d recommend staying away from any machine with 128GB of storage though. Most of that will be taken up by the operating system, and you’ll likely run into issues cramming in large apps after a few months. We recommend springing for extra built-in storage or investing in a portable SSD for backing up your most important files. It's also worth noting that Chromebooks tend to come with less built-in storage — 32GB, 64GB or 128GB — since ChromeOS encourages users to save their files in the cloud rather than on the device. In that case, 128GB is plenty. What's a good price range for a decent laptop in 2025? You can expect to spend between $1,000 and $1,800 for a typical 13-inch laptop today. As I explained above, you'll pay more if you want to stuff in more RAM or better GPU hardware. But you can also find deals below $1,000 if you look for refurbished or older-generation models. What’s the difference between macOS and Windows? Which is better? Simply put, macOS is the operating system in all of Apple's notebooks and desktops, while Windows powers the vast majority of PCs. You'll also find Chromebooks running Google's ChromeOS, but those are basically just web browsers running on top of Linux. Debating the differences between Windows and Macs is something PC nerds have been doing since the '80s, so we won't be declaring a winner here. There are some small, negligible distinctions, like using a Command versus a Control key, how file explorers work and concerns about viruses and security. For the most part, those are minor issues or have become moot thanks to better built-in security. But if you care more about playing the newest games, you'll want to have a Windows system. If you're more focused on creative apps, like Photoshop, Premiere and Final Cut Pro, then macOS may be a better fit (especially if you're running an iPhone). What are the best laptop brands? There is no single \"best\" laptop brand, but judging from this guide alone, we're generally impressed by notebooks from Apple, Dell and ASUS. They all offer fast, reliable and sturdy machines. HP also makes some eye-catching devices if you want an option that’s the most aesthetic. Those four brands, along with Lenovo and Acer, dominate laptop sales worldwide. We'd avoid systems from any retail store brands, or companies that don't have a major presence in the US. Back to top Recent updates October 2025: Updated to add the latest MacBook Pro. September 2025: Added a new \"specs to look for\" section. August 2025: Updated our top picks to include the Dell 14 Premium. May 2025: Updated to ensure top picks and details are still accurate. March 2025: Updated to include the M4-powered MacBook Air. November 2024: Updated to include the M4-powered MacBook Pros. August 2024: Updated to include the Lenovo ThinkPad X1 Carbon Gen 12. Back to topThis article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-laptops-120008636.html?src=rss",
          "content": "Choosing the best laptop can be a bit of a challenge — there are so many models, sizes and specs out there that it’s easy to feel lost in the shuffle. But the good news is that modern laptops are better than ever. Whether you're looking for a powerful AI PC, a travel-ready ultrabook or an affordable machine that can handle everyday tasks, there's something out there for everyone. Today’s systems combine improved performance, longer battery life and smarter features in sleek, lightweight designs that are built to keep up with work, play and everything in between.Out of all of the notebooks we've tested and reviewed recently, we consider Apple's 13-inch MacBook Air M4 to be the best laptop for most people, and this is still the case for our top picks to start off the new year. It's powerful enough to handle most tasks (even light video editing); it has a great screen and built-in speakers; and its battery could last over 18hours (depending on what you're doing, of course). The MacBook Air M4 is also one of the lightest and thinnest systems we've reviewed, and it's dead silent, thanks to a fanless design.Of course, not everyone wants a MacBook, and there are excellent Windows laptops and Chromebooks out there, too. Windows systems offer a range of configurations, from budget to high-end UHD screens with stunning IPS panels that boast high nits for vivid brightness. Chromebooks, on the other hand, tend to be more affordable and are great for users who mostly work online. Whether you need a powerhouse for creative work, a compact system for note-taking, or a laptop that can handle family movie night, there’s something for everyone in today’s laptop market. Best laptops of 2025 Back to top Specs to look for in a new laptop Depending on the type of laptop you’re looking to buy, there are some specs we think you should look for to get a machine that’s powerful enough for your needs and future-proof for the next couple of years (at least). Here's a cheat sheet for you to use when you're shopping. MacBooks At least M2 processor At least 16GB of RAM At least 256GB of SSD storage Windows laptops The most recent generation processor available from Intel or AMD At least 16GB of RAM At least 256GB of SSD storage Chromebooks Intel Core i processor At least 8GB of RAM (4GB is the bare minimum for a basic Chromebook) At least 128GB of storage, preferably a SSD Gaming laptops At least AMD Ryzen 9000 series or Intel 14th Gen Core CPU At least 16GB of RAM (ideally 32GB if you can swing it) At least 1TB of SSD storage For GPU recommendations, check out our guide to buying the best GPU for your needs Budget laptops The most recent generation processor available from Intel or AMD At least 8GB of RAM At least 256GB of SSD storage Back to top How we test laptops Engadget has been reviewing laptops for two decades, and while the definition of what a portable PC is has changed considerably since, our obsession with testing their limits and serving up informative buying advice remains the same. Be it a hybrid tablet like Microsoft's Surface machines, a rotating 2-in-1 convertible like HP's Spectre x360s or a plain old clamshell notebook, our review process follows similar beats. How does it look and feel? How fast is it? Whether it’s a Windows device powered by an Intel Core i5 or higher, a MacBook or a Chromebook, we aim to answer the most important question: Is it actually worth your hard-earned cash? We also pay close attention to portability, webcam quality and display features, including IPS panels and nits of brightness, as they can make a big difference in daily use. Back to top Factors to consider when choosing a laptop Operating system: Apple, Windows or Chrome OS There's a good chance you've already committed to an operating system, but my advice is to be as flexible as possible. These days, most major software is compatible with both Macs and PCs. (Of course, it's another story if you've become dependent on an Apple-only app like Final Cut Pro.) Web-based apps, naturally, will work on any platform with an internet browser. If you're an Apple-loyalist, there aren't many reasons to consider Windows laptops (unless you want a secondary gaming machine). But for Windows users, macOS is becoming more tempting every year. Apple's MacBooks, powered by its M-series Silicon chips, are among the fastest and most efficient laptops we've ever seen. They're incredibly well-built and have outstanding battery life to boot. MacOS itself is also an easy platform to learn, especially if you're used to iOS and iPadOS. That brings up another point: iPhone users may want to consider Macs because of the seamless integration with Apple's other platforms. You can't respond to iMessage conversations easily or hop into FaceTime chats on Windows PCs, but doing so is simple on Macs. (Microsoft's Phone Link app lets you send iOS users individual texts, but not media or group chats.) Android users, meanwhile, may be better off with Windows, as Phone Link can make calls, synchronize all your texts and also access your phone's photos. If cloud gaming is your priority, Windows laptops with NVIDIA’s GeForce Now or Xbox Cloud Gaming compatibility may offer more flexibility and decent performance, especially when paired with fast internet speeds. Chromebooks also make a compelling case here as an affordable, lightweight solution for casual cloud gaming sessions. As for whether you’ll want a PC with a dedicated Copilot AI button on the keyboard, that depends on how often you see yourself using Microsoft’s generative tools. Given we’re only just seeing the first slate of AI PCs, it would be wiser to wait out the hype and see what improvements might come over time. And what about ChromeOS? Chromebooks are a smart and (typically) inexpensive way to do things like web browsing and hopping on a few video chats, but for most, they're not the best choice as a primary computer. There aren't many apps or games that work offline, and they also don't work with powerful software suites like Adobe's (you can use the stripped-down Adobe Express and Photoshop online tools, though). Chromebooks are great secondary machines to use alongside a more powerful Mac or PC, and they're popular in schools because they're cheap and easy for IT workers to manage. And if all you need is web browsing access, or a notebook for a kid, a Chromebook might be enough. If, for some reason, you’re looking for a powerful ChromeOS system, there are also Chromebook Plus models to consider. These machines sport faster processors and more RAM than typical Google notebooks, and they can also tap into a few of the company’s online AI features, like AI image generation and photo processing. Price You can expect to spend between $1,000 and $1,800 for a new laptop these days, depending on the configuration. If you're looking for more of a workhorse, that could cost you well over $2,000 for additional RAM, storage, as well as a beefier graphics card and CPU. But you can also find some good laptops under $1,000 if you're willing to overlook build quality (or buy a refurbished or previous generation machine, which we highly recommend). Systems with AMD chips tend to come in cheaper than their Intel counterparts, but the bulk of their cost will come down to other components like RAM and storage. I’ve included our favorite affordable model in this best laptop buying guide, but we have a list of the best budget laptops that you can check out as well. Laptop size and weight So how portable do you want your laptop to be? That's the ultimate question you need to ask when choosing between various screen sizes. 13-inch machines have become a solid starting point for most shoppers — it's enough real estate for the majority of tasks like emailing and writing, and it also helps keep machines relatively light (typically between two to three pounds). Thanks to manufacturing advancements, these dainty machines sometimes even come with larger screens (the smaller MacBook Air actually has a 13.6-inch display). If you have trouble seeing fine text, we’d recommend going for a display larger than 13 inches. ASUS’s Zephyrus G14 is a solid 14-inch option for gamers, and we’re also seeing more productivity-focused machines aim for that size, like the Dell 14 Premium and MacBook Pro. While 14-inch notebooks are a bit heavier than 13-inch models, coming in between three to four pounds, their screens are noticeably roomier. For artists, or anyone else who needs a large canvas, a 15-inch laptop may make the most sense. They typically weigh between 3.5 and 4.5 pounds, but that extra heft may be worth it to fit wider video editing timelines or Photoshop windows. And, as you'd expect, you'll also pay a bit more for a 15-inch notebook compared to smaller ones (the 15-inch MacBook Air starts at $1,199, while the smaller model goes for $999). PC makers are also replacing 15-inch systems with 16-inch versions, which will give you even more space to work. If you're in the market for a business laptop, size and portability might be key considerations. A lightweight yet powerful system with a long battery life can make a world of difference if you travel frequently for work. You can still find laptops with 17-inch or 18-inch screens, but those are typically gaming systems or souped-up workstations. They're not meant for mere computing mortals. Ports and connectivity These days, most laptops ship with a few USB-C ports, which can handle both charging and speedy data transfers. Apple's MacBooks also include a separate connection for MagSafe power, and you'll find custom power connections on some PCs like Microsoft's Surface. Older USB Type-A connections are less common now, but they still pop up in systems like HP's Spectre x360 14, as well as many models from ASUS. For gamers or creators who rely on discrete graphics, ensuring your laptop has the right ports for external monitors or GPUs is crucial. DisplayPort or HDMI connections can also ensure you’re ready for dual- or multi-screen setups for more immersive experiences. Similarly, if you want to save high-resolution files or install multiple games, you might need to consider additional hard drive space; external hard drives are pretty affordable, as long as you have a proper port to connect them. If you're a fan of wired headphones, it's worth keeping a close eye on headphone jack availability. They usually include a USB-C to 3.5mm adapter, but that's a clunky solution, and it also takes up a USB port. Sure, most people use wireless earbuds and cans today, but it's still helpful to have a wired one around for when those devices run out of juice. Most laptops today offer Wi-Fi 6 or 6E and Bluetooth 5.0 or later, which should mean faster and more stable connections if you have compatible routers and devices. While Wi-Fi 7 routers have started appearing, that spec hasn't made its way into laptops yet. As for cellular coverage, there are notebooks like the Surface Pro 9 and Samsung Galaxy Book models that offer integrated 5G. But from our testing, that feature may not be worth the cost of a separate data plan. Instead, you could tether to your smartphone or invest in a wireless hotspot that can keep multiple devices online. Battery life A laptop's battery life depends on several factors: The power draw from the screen and other hardware, the optimizations used to avoid unnecessary power drain, and, of course, the size of the actual battery. One of our previous favorite systems, the Dell XPS 13, lasted 13 hours and 15 minutes in the PCMark 10 battery benchmark. In real-world testing, I was able to use it for a day and a half without needing a recharge. The MacBook Air 13-inch, meanwhile, more than 18 hours in our benchmark and kept running for more than two work days of my typical workflow. In general, you should expect a modern laptop to last at least eight hours. If battery life is your absolute priority, I'd strongly suggest looking at Macs over Windows PCs. Apple's M-series chips are essentially mobile hardware, with all of the power efficiency you'd expect from something originally designed for phones. Qualcomm’s upcoming Snapdragon chips could help Windows PCs compete with Apple’s astonishing battery life, but we’ve yet to see those in action. Chromebooks also typically get decent battery life (as long as you don’t overstuff them with power-draining tabs). Refresh rate A laptop's refresh rate refers to the amount of times its screen is cycled every second. Modern displays like IPS LCDs and OLEDs support 60Hz refresh rates at a minimum, but we're seeing more devices offering 120Hz, 240Hz and beyond. The higher the number, the faster the screen is refreshed, which ultimately leads to a smoother experience while mousing around or scrolling through web pages. (If you want to get a sense of what a slow refresh rate looks like, just grab an e-reader like the Kindle and try to flip between book pages.) While high refresh rates used to be reserved for gaming laptops, nowadays we're seeing more mainstream machines like the Dell 14 Premium offer 120Hz (or variable rates that move between 60Hz and 120Hz). CPU and GPU If you’re buying a new laptop, you’ll want to make sure it’s powered by the latest CPUs. For Windows PCs, that includes Intel’s Core Ultra chips for thin-and-light machines or the 14th-gen HX chips for beefier systems. The Core Ultra series have NPUs for handling AI tasks, while the HX hardware does not – they’re based on Intel’s previous chip architecture, and they’re more focused on delivering raw horsepower. Intel's older 13th-gen and 12th-gen laptop chips also don't have NPUs, so keep that in mind if you're looking at used systems. You'll also see AMD's Ryzen 8000 and 9000 chips in plenty of new systems like the ASUS Zephyrus G14 and Razer Blade 14. Those CPUs mainly target gaming laptops and high performance systems, while you'll still find AMD’s older Ryzen 7000 chips in ultraportables. AMD's main advantage is that its chips also include Radeon graphics, which are far more capable than Intel's Arc hardware (though those are getting better). Qualcomm’s new Snapdragon X Elite and X Plus are also an option in Copilot+ PCs (more on those below). Since they’re based on mobile chip designs, they’re likely also more power efficient than AMD and Intel’s hardware. In the past, we’ve avoided recommending Snapdragon chips because they led to a slow and frustrating Windows experience. But Microsoft claims it’s rebuilt Windows 11 around Snapdragon’s Arm-based architecture, which should lead to far faster performance and better app compatibility. As for Apple's laptops, you'll be choosing between the M4 Pro, M4 Max and M5, each of which is progressively more powerful. On the graphics side of things, a GPU, or graphics processing unit, is the component that communicates directly with a laptop's display. Laptop CPUs all have some form of integrated GPU: Intel has either its standard graphics or beefier Arc hardware, while AMD's chips include fast Radeon mobile graphics. If you want to play demanding games at high speeds (measured in frames per second, or fps), or if you need some extra power for rendering video or 3D models, you can configure a laptop with a dedicated GPU like NVIDIA's RTX 40-series hardware or AMD's Radeon RX 7000. Just be sure to leave room in your budget if you want a powerful GPU, as they typically add $300 or more to the cost of a laptop. Apple's M-series chips, meanwhile, have GPU cores that can perform as well as NVIDIA’s and AMD's lower-end dedicated GPUs. That's quite the accomplishment for systems like this (especially the MacBook Air and 14-inch MacBook Pro), and it's another reason we highly recommend Apple's notebooks. AI PCs, NPUs and Copilot+ Simply put, an AI PC is a computer equipped with a neural processing unit (NPU), which is designed to handle AI-related tasks. Much like how GPUs tackle heavy-duty gaming and rendering workloads, NPUs are designed to handle the complex math necessary for AI workloads. They’re also far more power efficient than CPUs or GPUs, which could lead to better battery performance in laptops. While many factors go into NPU performance, for the most part we measure their potential speed by TOPS (tera operations per second). We were primed for AI PCs based on the chips Intel and AMD announced in 2023. Intel unveiled its \"Core Ultra\" CPUs in December, its first to include an NPU for AI work. AMD also announced its Ryzen 8040 AI mobile chips that month (and it couldn't help but say they were faster than Intel's new hardware). But in May, Microsoft announced its Copilot+ initiative, which is pushing major PC makers to deliver premium AI PCs with specifications including 16GB of RAM, 256GB SSDs and NPUs with at least 40 TOPS of AI performance. Copilot+ is more than just a marketing term: Microsoft is also launching AI-powered features in Windows 11 that take advantage of powerful NPUs. That includes Recall, which can help you locate anything you’ve done on your PC (whenever it finally launches), as well as Cocreator in Paint, which can generate AI images based on text prompts and doodles. If you buy an AI PC that isn’t Copilot+ certified, you’ll still be able to use some features like Windows Studio Effects, which can blur your background in video calls or keep you in frame. Developers like Adobe and Audacity are also building features into their apps that can take advantage of NPUs. At the time of this post, Chromebook Plus notebooks can also access a few of Google’s online AI features, like image generation and photo processing. Back to top Other laptops we tested Lenovo ThinkPad X9-14 Aura Edition The ThinkPad X9-14 Aura Edition is a great spiritual successor to the ThinkPad X1 Carbon, offering the best that business laptops have to offer. That includes long battery life packed into a thin and light chassis. This is an optimal ultraportable business laptop. While the price might give you some pause, we tested the lowest configuration, and found that the X9-14’s performance is excellent for casual business users. The only issue with quality is that the keyboard is lacking. It’s mushier than we’d like, which could get a bit tiresome throughout the day. You’ll still miss out on a USB Type-A port, so you may need to carry a Type-C hub with you. Where the ThinkPad X9-14 will win you over is its bold OLED screen. Combo that with its well-rounded audio, and the ThinkPad X9-14 makes for an excellent multimedia device in and out of the workplace. ASUS Zenbook 14 OLED Aside from its lovely OLED screen, the ASUS Zenbook 14 OLED doesn't stand out from the crowded laptop field in any way. It just looks dull and boring, especially compared to the strikingly beautiful ASUS Zephyrus G14, which also came out this year. While you can probably find the Zenbook 14 for a decent price, I'd recommend holding out for something with a bit more personality (and with a less wobbly screen hinge). Razer Blade 14 The Razer Blade has almost everything you'd want in a 14-inch gaming notebook, but it's far pricier than the Zephyrus G14 on this list, and it doesn’t even have an SD card reader. It would be a solid competitor once its price falls a bit, and it's certainly a great option if you just have to have a jet-black laptop. Framework Laptop 16 Framework gave its modularity magic to the Laptop 16, delivering a gaming notebook where almost every single component is user replaceable. But you'll have to pay a pretty penny to snag it with upgraded hardware, and its optional Radeon 7700S GPU was surprisingly slow. Alienware m16 R2 The Alienware m16 r2 has been revamped with a slimmer case, but it’s otherwise a fairly typical gaming laptop. It’s a solid option for Alienware fans, but you’ll find better hardware and deals elsewhere. ASUS Zenbook Duo (2024) The Zenbook Duo is a fascinating dual-screened notebook, and according to my colleague Sam Rutherford it’s the first of its kind that’s worth buying. But its unique hardware isn’t really meant for mainstream consumers, and Windows 11 still doesn’t support multi-screen setups well enough to make full use of the Zenbook Duo’s ample canvas. Dell XPS 16 Dell’s XPS 16 is big and beautiful, but it’s far too expensive compared to the competition. Plus, it uses a capacitive row of function keys that you basically can’t see under bright light and has too few ports for a machine of this size. See Also: Best Gaming Laptops for 2025 Best Cheap Windows Laptops Best 2-in-1 Laptops for 2025 Best Chromebooks Best Laptops for College Students Back to top Laptop FAQs What is the average battery life of a laptop per charge? It’s hard to come up with an average battery life for laptops, since that will ultimately depend on what you’re doing with them. An ultraportable like the MacBook Air that sips power can last around 20 hours in our battery benchmark, and around two full work days of real-world usage. But a gaming laptop may last only a few hours if you’re actively playing something while on battery. At this point, Macs are delivering far better battery life than PCs, thanks to Apple’s Silicon chips, but Microsoft claims Copilot+ systems with Qualcomm chips will also get over 20 hours of batter life. How much RAM do I really need? The more RAM you have, the more things your computer can do simultaneously. For that reason, we recommend buying PCs and Macs with at least 16GB of RAM. That gives you enough memory to have several applications open at once, as well as web browsers filled with RAM-hogging tabs. Many PC games also require at least 16GB of RAM. While you could use a system with 8GB of RAM for basic tasks, you’ll quickly run into slowdowns and error messages as your apps stack up. Many laptops, especially ultraportables, don’t let you upgrade RAM, too – so you’ll have to buy an entirely new computer if you didn’t equip enough memory at the start. If you’re a hardcore gamer, programmer or planning to render videos or 3D models, then you may want to go for 32GB of RAM or more. And if you just need a secondary laptop for lighter work – perhaps a no-frills system for writing – then you can probably get by with 8GB. Just be sure to keep those browser tabs in check. What is the best storage capacity for a laptop? There is no one-size-fits-all solution when it comes to laptop storage. You’ll typically find configurations between 256GB and 1TB SSDs (solid state drives) on most laptops, and I’d recommend most people get at least 512GB. That’ll be enough space for large apps, music and video files without stressing your system too much. If you’re a media hoarder, or want to play a ton of games, then it’s definitely worth getting a 1TB SSD. If you’ll mainly be streaming your shows and music, and would rather invest in RAM or other hardware, then 256GB of storage would be serviceable. I’d recommend staying away from any machine with 128GB of storage though. Most of that will be taken up by the operating system, and you’ll likely run into issues cramming in large apps after a few months. We recommend springing for extra built-in storage or investing in a portable SSD for backing up your most important files. It's also worth noting that Chromebooks tend to come with less built-in storage — 32GB, 64GB or 128GB — since ChromeOS encourages users to save their files in the cloud rather than on the device. In that case, 128GB is plenty. What's a good price range for a decent laptop in 2025? You can expect to spend between $1,000 and $1,800 for a typical 13-inch laptop today. As I explained above, you'll pay more if you want to stuff in more RAM or better GPU hardware. But you can also find deals below $1,000 if you look for refurbished or older-generation models. What’s the difference between macOS and Windows? Which is better? Simply put, macOS is the operating system in all of Apple's notebooks and desktops, while Windows powers the vast majority of PCs. You'll also find Chromebooks running Google's ChromeOS, but those are basically just web browsers running on top of Linux. Debating the differences between Windows and Macs is something PC nerds have been doing since the '80s, so we won't be declaring a winner here. There are some small, negligible distinctions, like using a Command versus a Control key, how file explorers work and concerns about viruses and security. For the most part, those are minor issues or have become moot thanks to better built-in security. But if you care more about playing the newest games, you'll want to have a Windows system. If you're more focused on creative apps, like Photoshop, Premiere and Final Cut Pro, then macOS may be a better fit (especially if you're running an iPhone). What are the best laptop brands? There is no single \"best\" laptop brand, but judging from this guide alone, we're generally impressed by notebooks from Apple, Dell and ASUS. They all offer fast, reliable and sturdy machines. HP also makes some eye-catching devices if you want an option that’s the most aesthetic. Those four brands, along with Lenovo and Acer, dominate laptop sales worldwide. We'd avoid systems from any retail store brands, or companies that don't have a major presence in the US. Back to top Recent updates October 2025: Updated to add the latest MacBook Pro. September 2025: Added a new \"specs to look for\" section. August 2025: Updated our top picks to include the Dell 14 Premium. May 2025: Updated to ensure top picks and details are still accurate. March 2025: Updated to include the M4-powered MacBook Air. November 2024: Updated to include the M4-powered MacBook Pros. August 2024: Updated to include the Lenovo ThinkPad X1 Carbon Gen 12. Back to topThis article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-laptops-120008636.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/samsung-is-working-on-xr-smart-glasses-with-warby-parker-and-gentle-monster-042632170.html",
          "published_at": "Wed, 22 Oct 2025 04:26:32 +0000",
          "title": "Samsung is working on XR smart glasses with Warby Parker and Gentle Monster",
          "standfirst": "As part of its Galaxy XR headset presentation, Samsung also briefly teased another wearable product. It's working in collaboration with two eyewear companies, Warby Parker and Gentle Monster, on AI-powered smart glasses to go up against Meta's Ray-Ban models, Samsung's head of customer experience Jay Kim announced at the end of the livestream. \"We're also really excited about the AI glasses that we're currently building together with Google,\" Kim said. \"We're working with two of the most forward-thinking brands in eyewear, Warby Parker and Gentle Monster, to introduce new devices that fit into your lifestyle.\" Samsung will focus on two different markets with those brands, though both will include \"cutting-edge\" AI features co-developed with Google. With Gentle Monster, it's developing \"fashion-forward\" glasses that will likely be aimed at the higher end of the market. The Warby Parker collaboration, meanwhile, will yield eyewear designed for general consumers, probably at a lower price point. Samsung only said that the AI glasses will bring \"style, comfort and practicality\" to everyday life via Android's XR ecosystem. As we saw in May with Google's prototype XR smart glasses, it will likely employ a Gemini-powered display that will show notifications and small snippets of info from your apps, like the music you're listening to or turn-by-turn GPS directions. It should also have a built-in camera, of course, along with speakers and a microphone. Design and appearance will also be key, but Samsung has yet to show any images of the upcoming smart glasses and didn't reveal a release date. However, it will have a tough climb against Meta's lineup given the Ray-Ban branding and that company's head start on the technology. Last week, Meta introduced its Ray-Ban Display model that includes a screen for a true extended reality experience. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-is-working-on-xr-smart-glasses-with-warby-parker-and-gentle-monster-042632170.html?src=rss",
          "content": "As part of its Galaxy XR headset presentation, Samsung also briefly teased another wearable product. It's working in collaboration with two eyewear companies, Warby Parker and Gentle Monster, on AI-powered smart glasses to go up against Meta's Ray-Ban models, Samsung's head of customer experience Jay Kim announced at the end of the livestream. \"We're also really excited about the AI glasses that we're currently building together with Google,\" Kim said. \"We're working with two of the most forward-thinking brands in eyewear, Warby Parker and Gentle Monster, to introduce new devices that fit into your lifestyle.\" Samsung will focus on two different markets with those brands, though both will include \"cutting-edge\" AI features co-developed with Google. With Gentle Monster, it's developing \"fashion-forward\" glasses that will likely be aimed at the higher end of the market. The Warby Parker collaboration, meanwhile, will yield eyewear designed for general consumers, probably at a lower price point. Samsung only said that the AI glasses will bring \"style, comfort and practicality\" to everyday life via Android's XR ecosystem. As we saw in May with Google's prototype XR smart glasses, it will likely employ a Gemini-powered display that will show notifications and small snippets of info from your apps, like the music you're listening to or turn-by-turn GPS directions. It should also have a built-in camera, of course, along with speakers and a microphone. Design and appearance will also be key, but Samsung has yet to show any images of the upcoming smart glasses and didn't reveal a release date. However, it will have a tough climb against Meta's lineup given the Ray-Ban branding and that company's head start on the technology. Last week, Meta introduced its Ray-Ban Display model that includes a screen for a true extended reality experience. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-is-working-on-xr-smart-glasses-with-warby-parker-and-gentle-monster-042632170.html?src=rss",
          "feed_position": 34
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/simplifying-the-ai-stack-the-key-to-scalable-portable-intelligence-from",
          "published_at": "Wed, 22 Oct 2025 04:00:00 GMT",
          "title": "Simplifying the AI stack: The key to scalable, portable intelligence from cloud to edge",
          "standfirst": "Presented by ArmA simpler software stack is the key to portable, scalable AI across cloud and edge. AI is now powering real-world applications, yet fragmented software stacks are holding it back. Developers routinely rebuild the same models for different hardware targets, losing time to glue code instead of shipping features. The good news is that a shift is underway. Unified toolchains and optimized libraries are making it possible to deploy models across platforms without compromising performance.Yet one critical hurdle remains: software complexity. Disparate tools, hardware-specific optimizations, and layered tech stacks continue to bottleneck progress. To unlock the next wave of AI innovation, the industry must pivot decisively away from siloed development and toward streamlined, end-to-end platforms.This transformation is already taking shape. Major cloud providers, edge platform vendors, and open-source communities are converging on unified toolchains that simplify development and accelerate deployment, from cloud to edge. In this article, we’ll explore why simplification is the key to scalable AI, what’s driving this momentum, and how next-gen platforms are turning that vision into real-world results.The bottleneck: fragmentation, complexity, and inefficiencyThe issue isn’t just hardware variety; it’s duplicated effort across frameworks and targets that slows time-to-value.Diverse hardware targets: GPUs, NPUs, CPU-only devices, mobile SoCs, and custom accelerators.Tooling and framework fragmentation: TensorFlow, PyTorch, ONNX, MediaPipe, and others.Edge constraints: Devices require real-time, energy-efficient performance with minimal overhead.According to Gartner Research, these mismatches create a key hurdle: over 60% of AI initiatives stall before production, driven by integration complexity and performance variability. What software simplification looks likeSimplification is coalescing around five moves that cut re-engineering cost and risk:Cross-platform abstraction layers that minimize re-engineering when porting models.Performance-tuned libraries integrated into major ML frameworks.Unified architectural designs that scale from datacenter to mobile.Open standards and runtimes (e.g., ONNX, MLIR) reducing lock-in and improving compatibility.Developer-first ecosystems emphasizing speed, reproducibility, and scalability.These shifts are making AI more accessible, especially for startups and academic teams that previously lacked the resources for bespoke optimization. Projects like Hugging Face’s Optimum and MLPerf benchmarks are also helping standardize and validate cross-hardware performance.Ecosystem momentum and real-world signals Simplification is no longer aspirational; it’s happening now. Across the industry, software considerations are influencing decisions at the IP and silicon design level, resulting in solutions that are production-ready from day one. Major ecosystem players are driving this shift by aligning hardware and software development efforts, delivering tighter integration across the stack.A key catalyst is the rapid rise of edge inference, where AI models are deployed directly on devices rather than in the cloud. This has intensified demand for streamlined software stacks that support end-to-end optimization, from silicon to system to application. Companies like Arm are responding by enabling tighter coupling between their compute platforms and software toolchains, helping developers accelerate time-to-deployment without sacrificing performance or portability. The emergence of multi-modal and general-purpose foundation models (e.g., LLaMA, Gemini, Claude) has also added urgency. These models require flexible runtimes that can scale across cloud and edge environments. AI agents, which interact, adapt, and perform tasks autonomously, further drive the need for high-efficiency, cross-platform software.MLPerf Inference v3.1 included over 13,500 performance results from 26 submitters, validating multi-platform benchmarking of AI workloads. Results spanned both data center and edge devices, demonstrating the diversity of optimized deployments now being tested and shared.Taken together, these signals make clear that the market’s demand and incentives are aligning around a common set of priorities, including maximizing performance-per-watt, ensuring portability, minimizing latency, and delivering security and consistency at scale.What must happen for successful simplificationTo realize the promise of simplified AI platforms, several things must occur:Strong hardware/software co-design: hardware features that are exposed in software frameworks (e.g., matrix multipliers, accelerator instructions), and conversely, software that is designed to take advantage of underlying hardware.Consistent, robust toolchains and libraries: developers need reliable, well-documented libraries that work across devices. Performance portability is only useful if the tools are stable and well supported.Open ecosystem: hardware vendors, software framework maintainers, and model developers need to cooperate. Standards and shared projects help avoid re-inventing the wheel for every new device or use case.Abstractions that don’t obscure performance: while high-level abstraction helps developers, they must still allow tuning or visibility where needed. The right balance between abstraction and control is key.Security, privacy, and trust built in: especially as more compute shifts to devices (edge/mobile), issues like data protection, safe execution, model integrity, and privacy matter.Arm as one example of ecosystem-led simplification Simplifying AI at scale now hinges on system-wide design, where silicon, software, and developer tools evolve in lockstep. This approach enables AI workloads to run efficiently across diverse environments, from cloud inference clusters to battery-constrained edge devices. It also reduces the overhead of bespoke optimization, making it easier to bring new products to market faster. Arm (Nasdaq:Arm) is advancing this model with a platform-centric focus that pushes hardware-software optimizations up through the software stack. At COMPUTEX 2025, Arm demonstrated how its latest Arm9 CPUs, combined with AI-specific ISA extensions and the Kleidi libraries, enable tighter integration with widely used frameworks like PyTorch, ExecuTorch, ONNX Runtime, and MediaPipe. This alignment reduces the need for custom kernels or hand-tuned operators, allowing developers to unlock hardware performance without abandoning familiar toolchains. The real-world implications are significant. In the data center, Arm-based platforms are delivering improved performance-per-watt, critical for scaling AI workloads sustainably. On consumer devices, these optimizations enable ultra-responsive user experiences and background intelligence that’s always on, yet power efficient.More broadly, the industry is coalescing around simplification as a design imperative, embedding AI support directly into hardware roadmaps, optimizing for software portability, and standardizing support for mainstream AI runtimes. Arm’s approach illustrates how deep integration across the compute stack can make scalable AI a practical reality.Market validation and momentumIn 2025, nearly half of the compute shipped to major hyperscalers will run on Arm-based architectures, a milestone that underscores a significant shift in cloud infrastructure. As AI workloads become more resource-intensive, cloud providers are prioritizing architectures that deliver superior performance-per-watt and support seamless software portability. This evolution marks a strategic pivot toward energy-efficient, scalable infrastructure optimized for the performance and demands of modern AI.At the edge, Arm-compatible inference engines are enabling real-time experiences, such as live translation and always-on voice assistants, on battery-powered devices. These advancements bring powerful AI capabilities directly to users, without sacrificing energy efficiency.Developer momentum is accelerating as well. In a recent collaboration, GitHub and Arm introduced native Arm Linux and Windows runners for GitHub Actions, streamlining CI workflows for Arm-based platforms. These tools lower the barrier to entry for developers and enable more efficient, cross-platform development at scale. What comes nextSimplification doesn’t mean removing complexity entirely; it means managing it in ways that empower innovation. As the AI stack stabilizes, winners will be those who deliver seamless performance across a fragmented landscape.From a future-facing perspective, expect:Benchmarks as guardrails: MLPerf + OSS suites guide where to optimize next.More upstream, fewer forks: Hardware features land in mainstream tools, not custom branches.Convergence of research + production: Faster handoff from papers to product via shared runtimes.ConclusionAI’s next phase isn’t about exotic hardware; it’s also about software that travels well. When the same model lands efficiently on cloud, client, and edge, teams ship faster and spend less time rebuilding the stack.Ecosystem-wide simplification, not brand-led slogans, will separate the winners. The practical playbook is clear: unify platforms, upstream optimizations, and measure with open benchmarks. Explore how Arm AI software platforms are enabling this future — efficiently, securely, and at scale.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by ArmA simpler software stack is the key to portable, scalable AI across cloud and edge. AI is now powering real-world applications, yet fragmented software stacks are holding it back. Developers routinely rebuild the same models for different hardware targets, losing time to glue code instead of shipping features. The good news is that a shift is underway. Unified toolchains and optimized libraries are making it possible to deploy models across platforms without compromising performance.Yet one critical hurdle remains: software complexity. Disparate tools, hardware-specific optimizations, and layered tech stacks continue to bottleneck progress. To unlock the next wave of AI innovation, the industry must pivot decisively away from siloed development and toward streamlined, end-to-end platforms.This transformation is already taking shape. Major cloud providers, edge platform vendors, and open-source communities are converging on unified toolchains that simplify development and accelerate deployment, from cloud to edge. In this article, we’ll explore why simplification is the key to scalable AI, what’s driving this momentum, and how next-gen platforms are turning that vision into real-world results.The bottleneck: fragmentation, complexity, and inefficiencyThe issue isn’t just hardware variety; it’s duplicated effort across frameworks and targets that slows time-to-value.Diverse hardware targets: GPUs, NPUs, CPU-only devices, mobile SoCs, and custom accelerators.Tooling and framework fragmentation: TensorFlow, PyTorch, ONNX, MediaPipe, and others.Edge constraints: Devices require real-time, energy-efficient performance with minimal overhead.According to Gartner Research, these mismatches create a key hurdle: over 60% of AI initiatives stall before production, driven by integration complexity and performance variability. What software simplification looks likeSimplification is coalescing around five moves that cut re-engineering cost and risk:Cross-platform abstraction layers that minimize re-engineering when porting models.Performance-tuned libraries integrated into major ML frameworks.Unified architectural designs that scale from datacenter to mobile.Open standards and runtimes (e.g., ONNX, MLIR) reducing lock-in and improving compatibility.Developer-first ecosystems emphasizing speed, reproducibility, and scalability.These shifts are making AI more accessible, especially for startups and academic teams that previously lacked the resources for bespoke optimization. Projects like Hugging Face’s Optimum and MLPerf benchmarks are also helping standardize and validate cross-hardware performance.Ecosystem momentum and real-world signals Simplification is no longer aspirational; it’s happening now. Across the industry, software considerations are influencing decisions at the IP and silicon design level, resulting in solutions that are production-ready from day one. Major ecosystem players are driving this shift by aligning hardware and software development efforts, delivering tighter integration across the stack.A key catalyst is the rapid rise of edge inference, where AI models are deployed directly on devices rather than in the cloud. This has intensified demand for streamlined software stacks that support end-to-end optimization, from silicon to system to application. Companies like Arm are responding by enabling tighter coupling between their compute platforms and software toolchains, helping developers accelerate time-to-deployment without sacrificing performance or portability. The emergence of multi-modal and general-purpose foundation models (e.g., LLaMA, Gemini, Claude) has also added urgency. These models require flexible runtimes that can scale across cloud and edge environments. AI agents, which interact, adapt, and perform tasks autonomously, further drive the need for high-efficiency, cross-platform software.MLPerf Inference v3.1 included over 13,500 performance results from 26 submitters, validating multi-platform benchmarking of AI workloads. Results spanned both data center and edge devices, demonstrating the diversity of optimized deployments now being tested and shared.Taken together, these signals make clear that the market’s demand and incentives are aligning around a common set of priorities, including maximizing performance-per-watt, ensuring portability, minimizing latency, and delivering security and consistency at scale.What must happen for successful simplificationTo realize the promise of simplified AI platforms, several things must occur:Strong hardware/software co-design: hardware features that are exposed in software frameworks (e.g., matrix multipliers, accelerator instructions), and conversely, software that is designed to take advantage of underlying hardware.Consistent, robust toolchains and libraries: developers need reliable, well-documented libraries that work across devices. Performance portability is only useful if the tools are stable and well supported.Open ecosystem: hardware vendors, software framework maintainers, and model developers need to cooperate. Standards and shared projects help avoid re-inventing the wheel for every new device or use case.Abstractions that don’t obscure performance: while high-level abstraction helps developers, they must still allow tuning or visibility where needed. The right balance between abstraction and control is key.Security, privacy, and trust built in: especially as more compute shifts to devices (edge/mobile), issues like data protection, safe execution, model integrity, and privacy matter.Arm as one example of ecosystem-led simplification Simplifying AI at scale now hinges on system-wide design, where silicon, software, and developer tools evolve in lockstep. This approach enables AI workloads to run efficiently across diverse environments, from cloud inference clusters to battery-constrained edge devices. It also reduces the overhead of bespoke optimization, making it easier to bring new products to market faster. Arm (Nasdaq:Arm) is advancing this model with a platform-centric focus that pushes hardware-software optimizations up through the software stack. At COMPUTEX 2025, Arm demonstrated how its latest Arm9 CPUs, combined with AI-specific ISA extensions and the Kleidi libraries, enable tighter integration with widely used frameworks like PyTorch, ExecuTorch, ONNX Runtime, and MediaPipe. This alignment reduces the need for custom kernels or hand-tuned operators, allowing developers to unlock hardware performance without abandoning familiar toolchains. The real-world implications are significant. In the data center, Arm-based platforms are delivering improved performance-per-watt, critical for scaling AI workloads sustainably. On consumer devices, these optimizations enable ultra-responsive user experiences and background intelligence that’s always on, yet power efficient.More broadly, the industry is coalescing around simplification as a design imperative, embedding AI support directly into hardware roadmaps, optimizing for software portability, and standardizing support for mainstream AI runtimes. Arm’s approach illustrates how deep integration across the compute stack can make scalable AI a practical reality.Market validation and momentumIn 2025, nearly half of the compute shipped to major hyperscalers will run on Arm-based architectures, a milestone that underscores a significant shift in cloud infrastructure. As AI workloads become more resource-intensive, cloud providers are prioritizing architectures that deliver superior performance-per-watt and support seamless software portability. This evolution marks a strategic pivot toward energy-efficient, scalable infrastructure optimized for the performance and demands of modern AI.At the edge, Arm-compatible inference engines are enabling real-time experiences, such as live translation and always-on voice assistants, on battery-powered devices. These advancements bring powerful AI capabilities directly to users, without sacrificing energy efficiency.Developer momentum is accelerating as well. In a recent collaboration, GitHub and Arm introduced native Arm Linux and Windows runners for GitHub Actions, streamlining CI workflows for Arm-based platforms. These tools lower the barrier to entry for developers and enable more efficient, cross-platform development at scale. What comes nextSimplification doesn’t mean removing complexity entirely; it means managing it in ways that empower innovation. As the AI stack stabilizes, winners will be those who deliver seamless performance across a fragmented landscape.From a future-facing perspective, expect:Benchmarks as guardrails: MLPerf + OSS suites guide where to optimize next.More upstream, fewer forks: Hardware features land in mainstream tools, not custom branches.Convergence of research + production: Faster handoff from papers to product via shared runtimes.ConclusionAI’s next phase isn’t about exotic hardware; it’s also about software that travels well. When the same model lands efficiently on cloud, client, and edge, teams ship faster and spend less time rebuilding the stack.Ecosystem-wide simplification, not brand-led slogans, will separate the winners. The practical playbook is clear: unify platforms, upstream optimizations, and measure with open benchmarks. Explore how Arm AI software platforms are enabling this future — efficiently, securely, and at scale.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5NhML02FGAEkp2yOpsPkrx/b62d547d376660e631c01d70283f7946/AdobeStock_1243259614.jpeg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/how-to-watch-samsung-unveil-its-android-xr-headset-184820772.html",
          "published_at": "Wed, 22 Oct 2025 03:02:32 +0000",
          "title": "How to watch Samsung unveil its Android XR headset",
          "standfirst": "Editor's Note: Samsung has officially announced the $1,800 Galaxy XR headset. You can read our hands-on here and how to order the device here. Samsung is set to officially reveal its long-anticipated Android extended reality (XR) headset, which has been codenamed Project Moohan. The company has scheduled a livestream event for October 21 at 10PM ET. That's just a few hours away, which is pretty much nothing compared to the years of lead-up to this reveal since Samsung and its partners have been teasing this device. The event will be streamed live via the company's YouTube page and on the official Samsung Newsroom site. We don't know how long the stream will be, but Samsung promises that Project Moohan will open up the \"true potential\" of mixed-reality devices. You can bookmark this page and watch it right here. This isn't just a reveal for a mixed-reality headset. Moohan is the very first device that uses Google's new Android XR operating system, which has been specifically designed for XR, VR and AR devices like glasses and headsets. Google has also shown previews of the ecosystem at its I/O developer conference before, and while we've seen bits and pieces of the software (and hardware) before, the final pieces should be available with the keynote today. We don't have official specs about the headset itself, but there have been plenty of leaks and rumors that will be confirmed or refuted during the stream. Leaks have suggested it includes a high-end display, advanced tracking and Gemini integration. These same leaks indicate a potential price tag of $1,800 to $2,800, making it more of a rival to the Apple Vision Pro than Meta's new Ray-Ban Display glasses. Update, October 21 2025, 11:02PM ET This story has been updated with links to Samsung's announcement and to our hands-on of the Galaxy XR. Update, October 21 2025, 2:48PM ET: This story has been updated to point out the event is happening tonight in a few hours and talk about how Google has previously shown previews of its Android XR platform at its developer conference.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/how-to-watch-samsung-unveil-its-android-xr-headset-184820772.html?src=rss",
          "content": "Editor's Note: Samsung has officially announced the $1,800 Galaxy XR headset. You can read our hands-on here and how to order the device here. Samsung is set to officially reveal its long-anticipated Android extended reality (XR) headset, which has been codenamed Project Moohan. The company has scheduled a livestream event for October 21 at 10PM ET. That's just a few hours away, which is pretty much nothing compared to the years of lead-up to this reveal since Samsung and its partners have been teasing this device. The event will be streamed live via the company's YouTube page and on the official Samsung Newsroom site. We don't know how long the stream will be, but Samsung promises that Project Moohan will open up the \"true potential\" of mixed-reality devices. You can bookmark this page and watch it right here. This isn't just a reveal for a mixed-reality headset. Moohan is the very first device that uses Google's new Android XR operating system, which has been specifically designed for XR, VR and AR devices like glasses and headsets. Google has also shown previews of the ecosystem at its I/O developer conference before, and while we've seen bits and pieces of the software (and hardware) before, the final pieces should be available with the keynote today. We don't have official specs about the headset itself, but there have been plenty of leaks and rumors that will be confirmed or refuted during the stream. Leaks have suggested it includes a high-end display, advanced tracking and Gemini integration. These same leaks indicate a potential price tag of $1,800 to $2,800, making it more of a rival to the Apple Vision Pro than Meta's new Ray-Ban Display glasses. Update, October 21 2025, 11:02PM ET This story has been updated with links to Samsung's announcement and to our hands-on of the Galaxy XR. Update, October 21 2025, 2:48PM ET: This story has been updated to point out the event is happening tonight in a few hours and talk about how Google has previously shown previews of its Android XR platform at its developer conference.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/how-to-watch-samsung-unveil-its-android-xr-headset-184820772.html?src=rss",
          "feed_position": 35
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/why-the-samsung-galaxy-xr-can-support-almost-all-android-apps-021000889.html",
          "published_at": "Wed, 22 Oct 2025 02:10:00 +0000",
          "title": "Why the Samsung Galaxy XR can support 'almost all' Android apps",
          "standfirst": "The Samsung Galaxy XR is designed to be a showcase for Android XR, Google's new AR / VR operating system, but unlike competing mixed reality headsets, Google says there will be few limits on the apps the Galaxy XR will actually be able to run. In fact, a Google spokesperson tells Engadget that \"almost all Android apps will automatically be made available without any additional development effort.\"Obviously, Google and Samsung would love deliberately designed spatial experiences for their new hardware, but almost all existing Android apps, regardless if they were made for phones or not, will be considered \"Android XR compatible mobile apps\" once the headset launches. That means they'll run in a floating spatial panel that can be moved around the virtual space surrounding you, and per Google's Android XR developer guidelines, will automatically support core XR input methods like eye and hand tracking, along with the usual suspects like controllers, mice and keyboards. They should also run and look like they would on a smartphone or tablet. \"Apps that specify compact sizes show up accordingly and apps that allow for resizing can be resized in XR. These apps do not run in compatibility mode and won’t be letterboxed,\" Google says.The only apps that won't make the cut are ones that require features a given Android XR device doesn't support, like GPS. And in the case of apps that are already updated to work on large screens, or that are \"adaptive apps\" designed to reflow and change size depending on the Android device they're running on, things will be even smoother. Google says adaptive design will be expected to be the default going forward, an effort that started with this year's release of Android 16. “Many APIs restricting size will be ignored on larger screens (which includes Android XR),” Google’s spokesperson said, because the company ultimately wants Android apps to feel responsive whether they’re on a phone, an in-car display or an XR headset.Apple tried a similar, but more limited approach with the launch of visionOS and the Vision Pro by letting developers list their iOS and iPadOS apps in the visionOS App Store. The move produced mixed results, and a dearth of real visionOS apps. An app designed with a device in mind is better than one that's not, but Google does at least appear to have set Android developers up for a slightly smoother ride. Considering the Galaxy XR's cheaper price when compared to the Vision Pro, they might also have a bigger audience to make apps for, too.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/why-the-samsung-galaxy-xr-can-support-almost-all-android-apps-021000889.html?src=rss",
          "content": "The Samsung Galaxy XR is designed to be a showcase for Android XR, Google's new AR / VR operating system, but unlike competing mixed reality headsets, Google says there will be few limits on the apps the Galaxy XR will actually be able to run. In fact, a Google spokesperson tells Engadget that \"almost all Android apps will automatically be made available without any additional development effort.\"Obviously, Google and Samsung would love deliberately designed spatial experiences for their new hardware, but almost all existing Android apps, regardless if they were made for phones or not, will be considered \"Android XR compatible mobile apps\" once the headset launches. That means they'll run in a floating spatial panel that can be moved around the virtual space surrounding you, and per Google's Android XR developer guidelines, will automatically support core XR input methods like eye and hand tracking, along with the usual suspects like controllers, mice and keyboards. They should also run and look like they would on a smartphone or tablet. \"Apps that specify compact sizes show up accordingly and apps that allow for resizing can be resized in XR. These apps do not run in compatibility mode and won’t be letterboxed,\" Google says.The only apps that won't make the cut are ones that require features a given Android XR device doesn't support, like GPS. And in the case of apps that are already updated to work on large screens, or that are \"adaptive apps\" designed to reflow and change size depending on the Android device they're running on, things will be even smoother. Google says adaptive design will be expected to be the default going forward, an effort that started with this year's release of Android 16. “Many APIs restricting size will be ignored on larger screens (which includes Android XR),” Google’s spokesperson said, because the company ultimately wants Android apps to feel responsive whether they’re on a phone, an in-car display or an XR headset.Apple tried a similar, but more limited approach with the launch of visionOS and the Vision Pro by letting developers list their iOS and iPadOS apps in the visionOS App Store. The move produced mixed results, and a dearth of real visionOS apps. An app designed with a device in mind is better than one that's not, but Google does at least appear to have set Android developers up for a slightly smoother ride. Considering the Galaxy XR's cheaper price when compared to the Vision Pro, they might also have a bigger audience to make apps for, too.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/why-the-samsung-galaxy-xr-can-support-almost-all-android-apps-021000889.html?src=rss",
          "feed_position": 36
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/samsung-galaxy-xr-hands-on-a-smarter-more-open-take-on-apples-vision-pro-for-half-the-price-020044642.html",
          "published_at": "Wed, 22 Oct 2025 02:00:44 +0000",
          "title": "Samsung Galaxy XR hands-on: A smarter, more open take on Apple's Vision Pro for half the price",
          "standfirst": "Apple's Vision Pro was meant to usher in a new era for headsets. However, its high price and somewhat limited utility resulted in what may be the company's biggest flop in years. Now it's time for Samsung to give things a go with the Galaxy XR. It's a fresh take on modern mixed reality goggles developed through deep partnerships with Qualcomm and Google and it attempts to address some of the Vision Pro's biggest shortcomings. The hardware While both Apple and Samsung's headsets have a lot of similarities (like their basic design and support for features such as hand and eye tracking), there are also some very important differences. First, at $1,800, the Galaxy XR is essentially half the price of the Vision Pro (including the new M5-powered model). Second, instead of Apple’s homegrown OS, Samsung's headset is the first to run Google's new Android XR platform, which combines a lot of familiar elements from its mobile counterpart but with a bigger emphasis on AI and Gemini-based voice controls. And third, because Samsung relied more on partners like Google and Qualcomm, the Galaxy XR feels like it's built around a larger, more open ecosystem that plays nicely with a wider range of third-party devices and software. The Galaxy XR fundamentally doesn't look that much different from the Vision Pro. It features a large visor in front with an assortment of 13 different exterior sensors to support inside-out tracking, passthrough vision and hand recognition. There are some additional sensors inside for eye and face tracking. There's also a connector for the wire that leads to its external clip-on battery pack alongside built-in speakers with spatial audio. The one big departure is that unlike the Vision Pro, the Galaxy XR doesn't have an outward-facing display, so it won't be able to project your face onto the outside of the headset, which is just fine by me. Sam Rutherford for Engadget However, the devil is in the details because while the original Vision Pro weighed between 600 and 650 grams (around 1.3 to 1.4 pounds) depending on the configuration (not including its battery pack), the Galaxy XR is significantly lighter at 545 grams (1.2 pounds). And that's before you consider the new M5 Vision Pro, which has somehow gone backwards by being even heavier at 750-800 grams (around 1.6 pounds). Furthermore, it seems Samsung learned a lot from its rivals by including a much larger and thicker head cushion that helps distribute the weight of the headset more evenly. Granted, during a longer session, I still noticed a bit of pressure and felt relief after taking off the Galaxy XR, but it's nothing like the Vision Pro, which in my experience gets uncomfortable almost immediately. Finally, around back, there's a simple strap with a knob that you can twist to tighten or loosen the headband as necessary. So even without extra support running across the top of your head, getting in and out of the Galaxy XR is much easier and comfier than the Vision Pro. Sam Rutherford for Engadget On the inside, the Galaxy XR is powered by Qualcomm's Snapdragon XR2+ Gen 2 chip with dual micro OLED displays that deliver 4K resolution (3,552 x 3,840) to each eye at up to 90Hz. I wish Samsung was able to go up to a 120Hz refresh rate like on the Vision Pro, but considering the Galaxy XR's slightly higher overall resolution, I'm not that bothered. And I must say, the image quality from this headset is seriously sharp. It's even better than Apple's goggles and it might be the best I've ever used, particularly outside of $10,000+ enterprise-only setups. Once again, when you consider that this thing costs half the price of a Vision Pro, this headset feels like a real accomplishment by Samsung to the point where I wouldn't be surprised if the company is losing money on every unit it sells. In terms of longevity, Samsung says that for general use the Galaxy XR should last around two hours. If you're only watching videos though, that figure is more like two and a half. Thankfully, if you do need to be in mixed reality for longer, you can charge the headset while it's being used. As for security, the Galaxy XR uses iris recognition to skip traditional passwords, which is nice. The platform: Android XR Sometimes, trying out a new software platform can be a little jarring. But that's not really the case for Android XR, which shouldn't present much of a learning curve for anyone who has used other headsets or Google's ubiquitous mobile OS. After putting the goggles on, you can summon a home menu with an app launcher by facing your palm up and touching your index finger and thumb together. From there, you can open apps and menus by moving your hands and pinching icons or rearranging virtual windows by grabbing the anchor point along the bottom and putting them where you want. Sam Rutherford for Engadget Notably, while there is a growing number of new apps made specifically for XR, you still get access to all of your standard Android titles. Those include Google Photos, Google Maps and Youtube, all of which I got a chance to play around with during a 25-minute demo. In Photos, you can browse your pictures normally. However, to take advantage of the Galaxy XR's hardware, Google created a feature that allows the app to convert standard flat images (with help from the cloud) into immersive ones. While the effect isn't true 3D, it adds distinct foreground, midground and background layers to images in a way that makes viewing your photo roll just a bit more interesting. In Maps, you start out with a view of the world before using hand gestures to move and zoom in wherever you want or voice commands to laser in on a specific location. The neat new trick for this app is that if you find bubbles over things like restaurants and stores, you can click those to be transported inside those businesses, where Android XR will stitch together 2D photos to create a simulated 3D environment that you can move and walk around in. Granted, this doesn't have a ton of practical use for most folks unless you want to take a virtual tour of something like a wedding venue. But, the tech is impressive nonetheless. Sam Rutherford for Engadget Finally in the YouTube app, the Galaxy XR did a great job of making standard 360 videos look even better. While quality will always depend on the gear that captured the content, viewing spatial clips was a great way to show off its resolution and image quality. Google says it will also put a new tab on the app to make finding 360 videos easier, though you can always watch the billions of standard flat videos as well. Interestingly, you can use and navigate the Galaxy XR entirely with hand gestures, but voice commands (via Gemini) are also a major part of the Android XR platform. Because the goggles sit on your head, unlike with mobile devices, there's no need to use a wake word every time you want to do something. You just talk and Gemini listens (though you can choose to disable this behavior if you prefer), so this makes voice interactions feel a lot more natural. Because Gemini can also do things like adjust settings or organize all the apps you have open, in addition to answering questions, it feels like Google is starting to deliver on some of those Star Trek moments where you can simply ask the computer to do something and it just happens. Yes, it's still very early, but as a platform, Android XR feels much more like a virtual playground than VisionOS does at the moment. Other features Sam Rutherford for Engadget While I didn't get to test these out myself, there are some other important features worth mentioning. In addition to apps, you can also play your standard selection of Android games like Stardew Valley or connect the headset to your PC (like with Steam Link) to play full desktop titles. Furthermore, I was told that the Galaxy XR can be tethered to a computer and used like a traditional VR headset. And while Samsung is making optional wireless controllers for the Galaxy XR (and a big carrying case), you may not need them at all as you'll also have the ability to pair the goggles with typical Bluetooth-based gamepads along with wireless mice and keyboards. Google also says it's working on a new system called Likenesses that can create personalized avatars for use in video calls and meetings that use data from interior sensors to deliver more realistic expressions. Additionally, you'll be able to use tools like Veo3 to make AI-generated videos while providing prompts using your voice. But this is just scratching the surface of the Galaxy XR's capabilities and I want to use this thing more before offering a final verdict. Early thoughts Sam Rutherford for Engadget In many ways, the Galaxy XR looks and feels like a flagship mixed reality headset in the same vein as the Vision Pro, but for the Android crowd (and Windows users to some extent as well). On top of that, Google has done some interesting things with Android XR to make it feel like there's a much wider range of content and software to view and use. In many ways, the addition of a dedicated AI assistant in Gemini and voice controls feels much more impactful on goggles than a phone because you can't always count on having physical inputs like a mouse or keyboard. And with the Galaxy XR being half the price of the Vision Pro, Samsung and Google have done a lot to address some of the most glaring issues with Apple's rival. In case the price drop wasn't enough, it feels like all the companies involved are doing as much as possible to sweeten the deal. I actually started laughing when I first heard all the discounts and free subscriptions that come with the headset. That's because in addition to the goggles themselves, every Galaxy XR will come with what's being called the Explorer Pack: 12 months of access to Google AI Pro, 12 months of YouTube Premium (which itself includes YouTube Music), 12 months of Google Play Pass, 12 Months of NBA League Pass and a bundle of other custom XR content and apps. So on top of a slick design, top-tier optics and a new platform, Google and Samsung are basically tossing a kitchen sink of apps and memberships in with the headset. Sam Rutherford for Engadget My only reservation is that when it comes to mass adoption, I think smartglasses have supplanted headsets as the next big mainstream play. Granted, there is a lot of technology and software shared between both categories of devices (Google has already teased upcoming Android XR smartglasses) that should allow Samsung or Google to pivot more easily down the line. But the idea that in the future there will be a headset in every home seems less likely every day. Still, as a showcase for the potential of mixed reality and high-end optics, the Galaxy XR is an exciting piece of tech. The Samsung Galaxy XR is available now for $1,800 on Samsung.com. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-galaxy-xr-hands-on-a-smarter-more-open-take-on-apples-vision-pro-for-half-the-price-020044642.html?src=rss",
          "content": "Apple's Vision Pro was meant to usher in a new era for headsets. However, its high price and somewhat limited utility resulted in what may be the company's biggest flop in years. Now it's time for Samsung to give things a go with the Galaxy XR. It's a fresh take on modern mixed reality goggles developed through deep partnerships with Qualcomm and Google and it attempts to address some of the Vision Pro's biggest shortcomings. The hardware While both Apple and Samsung's headsets have a lot of similarities (like their basic design and support for features such as hand and eye tracking), there are also some very important differences. First, at $1,800, the Galaxy XR is essentially half the price of the Vision Pro (including the new M5-powered model). Second, instead of Apple’s homegrown OS, Samsung's headset is the first to run Google's new Android XR platform, which combines a lot of familiar elements from its mobile counterpart but with a bigger emphasis on AI and Gemini-based voice controls. And third, because Samsung relied more on partners like Google and Qualcomm, the Galaxy XR feels like it's built around a larger, more open ecosystem that plays nicely with a wider range of third-party devices and software. The Galaxy XR fundamentally doesn't look that much different from the Vision Pro. It features a large visor in front with an assortment of 13 different exterior sensors to support inside-out tracking, passthrough vision and hand recognition. There are some additional sensors inside for eye and face tracking. There's also a connector for the wire that leads to its external clip-on battery pack alongside built-in speakers with spatial audio. The one big departure is that unlike the Vision Pro, the Galaxy XR doesn't have an outward-facing display, so it won't be able to project your face onto the outside of the headset, which is just fine by me. Sam Rutherford for Engadget However, the devil is in the details because while the original Vision Pro weighed between 600 and 650 grams (around 1.3 to 1.4 pounds) depending on the configuration (not including its battery pack), the Galaxy XR is significantly lighter at 545 grams (1.2 pounds). And that's before you consider the new M5 Vision Pro, which has somehow gone backwards by being even heavier at 750-800 grams (around 1.6 pounds). Furthermore, it seems Samsung learned a lot from its rivals by including a much larger and thicker head cushion that helps distribute the weight of the headset more evenly. Granted, during a longer session, I still noticed a bit of pressure and felt relief after taking off the Galaxy XR, but it's nothing like the Vision Pro, which in my experience gets uncomfortable almost immediately. Finally, around back, there's a simple strap with a knob that you can twist to tighten or loosen the headband as necessary. So even without extra support running across the top of your head, getting in and out of the Galaxy XR is much easier and comfier than the Vision Pro. Sam Rutherford for Engadget On the inside, the Galaxy XR is powered by Qualcomm's Snapdragon XR2+ Gen 2 chip with dual micro OLED displays that deliver 4K resolution (3,552 x 3,840) to each eye at up to 90Hz. I wish Samsung was able to go up to a 120Hz refresh rate like on the Vision Pro, but considering the Galaxy XR's slightly higher overall resolution, I'm not that bothered. And I must say, the image quality from this headset is seriously sharp. It's even better than Apple's goggles and it might be the best I've ever used, particularly outside of $10,000+ enterprise-only setups. Once again, when you consider that this thing costs half the price of a Vision Pro, this headset feels like a real accomplishment by Samsung to the point where I wouldn't be surprised if the company is losing money on every unit it sells. In terms of longevity, Samsung says that for general use the Galaxy XR should last around two hours. If you're only watching videos though, that figure is more like two and a half. Thankfully, if you do need to be in mixed reality for longer, you can charge the headset while it's being used. As for security, the Galaxy XR uses iris recognition to skip traditional passwords, which is nice. The platform: Android XR Sometimes, trying out a new software platform can be a little jarring. But that's not really the case for Android XR, which shouldn't present much of a learning curve for anyone who has used other headsets or Google's ubiquitous mobile OS. After putting the goggles on, you can summon a home menu with an app launcher by facing your palm up and touching your index finger and thumb together. From there, you can open apps and menus by moving your hands and pinching icons or rearranging virtual windows by grabbing the anchor point along the bottom and putting them where you want. Sam Rutherford for Engadget Notably, while there is a growing number of new apps made specifically for XR, you still get access to all of your standard Android titles. Those include Google Photos, Google Maps and Youtube, all of which I got a chance to play around with during a 25-minute demo. In Photos, you can browse your pictures normally. However, to take advantage of the Galaxy XR's hardware, Google created a feature that allows the app to convert standard flat images (with help from the cloud) into immersive ones. While the effect isn't true 3D, it adds distinct foreground, midground and background layers to images in a way that makes viewing your photo roll just a bit more interesting. In Maps, you start out with a view of the world before using hand gestures to move and zoom in wherever you want or voice commands to laser in on a specific location. The neat new trick for this app is that if you find bubbles over things like restaurants and stores, you can click those to be transported inside those businesses, where Android XR will stitch together 2D photos to create a simulated 3D environment that you can move and walk around in. Granted, this doesn't have a ton of practical use for most folks unless you want to take a virtual tour of something like a wedding venue. But, the tech is impressive nonetheless. Sam Rutherford for Engadget Finally in the YouTube app, the Galaxy XR did a great job of making standard 360 videos look even better. While quality will always depend on the gear that captured the content, viewing spatial clips was a great way to show off its resolution and image quality. Google says it will also put a new tab on the app to make finding 360 videos easier, though you can always watch the billions of standard flat videos as well. Interestingly, you can use and navigate the Galaxy XR entirely with hand gestures, but voice commands (via Gemini) are also a major part of the Android XR platform. Because the goggles sit on your head, unlike with mobile devices, there's no need to use a wake word every time you want to do something. You just talk and Gemini listens (though you can choose to disable this behavior if you prefer), so this makes voice interactions feel a lot more natural. Because Gemini can also do things like adjust settings or organize all the apps you have open, in addition to answering questions, it feels like Google is starting to deliver on some of those Star Trek moments where you can simply ask the computer to do something and it just happens. Yes, it's still very early, but as a platform, Android XR feels much more like a virtual playground than VisionOS does at the moment. Other features Sam Rutherford for Engadget While I didn't get to test these out myself, there are some other important features worth mentioning. In addition to apps, you can also play your standard selection of Android games like Stardew Valley or connect the headset to your PC (like with Steam Link) to play full desktop titles. Furthermore, I was told that the Galaxy XR can be tethered to a computer and used like a traditional VR headset. And while Samsung is making optional wireless controllers for the Galaxy XR (and a big carrying case), you may not need them at all as you'll also have the ability to pair the goggles with typical Bluetooth-based gamepads along with wireless mice and keyboards. Google also says it's working on a new system called Likenesses that can create personalized avatars for use in video calls and meetings that use data from interior sensors to deliver more realistic expressions. Additionally, you'll be able to use tools like Veo3 to make AI-generated videos while providing prompts using your voice. But this is just scratching the surface of the Galaxy XR's capabilities and I want to use this thing more before offering a final verdict. Early thoughts Sam Rutherford for Engadget In many ways, the Galaxy XR looks and feels like a flagship mixed reality headset in the same vein as the Vision Pro, but for the Android crowd (and Windows users to some extent as well). On top of that, Google has done some interesting things with Android XR to make it feel like there's a much wider range of content and software to view and use. In many ways, the addition of a dedicated AI assistant in Gemini and voice controls feels much more impactful on goggles than a phone because you can't always count on having physical inputs like a mouse or keyboard. And with the Galaxy XR being half the price of the Vision Pro, Samsung and Google have done a lot to address some of the most glaring issues with Apple's rival. In case the price drop wasn't enough, it feels like all the companies involved are doing as much as possible to sweeten the deal. I actually started laughing when I first heard all the discounts and free subscriptions that come with the headset. That's because in addition to the goggles themselves, every Galaxy XR will come with what's being called the Explorer Pack: 12 months of access to Google AI Pro, 12 months of YouTube Premium (which itself includes YouTube Music), 12 months of Google Play Pass, 12 Months of NBA League Pass and a bundle of other custom XR content and apps. So on top of a slick design, top-tier optics and a new platform, Google and Samsung are basically tossing a kitchen sink of apps and memberships in with the headset. Sam Rutherford for Engadget My only reservation is that when it comes to mass adoption, I think smartglasses have supplanted headsets as the next big mainstream play. Granted, there is a lot of technology and software shared between both categories of devices (Google has already teased upcoming Android XR smartglasses) that should allow Samsung or Google to pivot more easily down the line. But the idea that in the future there will be a headset in every home seems less likely every day. Still, as a showcase for the potential of mixed reality and high-end optics, the Galaxy XR is an exciting piece of tech. The Samsung Galaxy XR is available now for $1,800 on Samsung.com. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-galaxy-xr-hands-on-a-smarter-more-open-take-on-apples-vision-pro-for-half-the-price-020044642.html?src=rss",
          "feed_position": 37,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/6635b790-aeb7-11f0-9bd7-4a2aefe1b25b"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/how-to-order-the-samsung-galaxy-xr-headset-020008173.html",
          "published_at": "Wed, 22 Oct 2025 02:00:08 +0000",
          "title": "How to order the Samsung Galaxy XR headset",
          "standfirst": "Samsung's take on the Vision Pro is here — and you can already order it. Costing just over half as much as Apple's reality machine, the Galaxy XR has a 4K micro-OLED screen and a 100-degree horizontal field of view. The $1,800 mixed reality headset is available now for pre-order on Samsung's website. The Galaxy XR isn't only a Samsung product. The company developed the long-rumored headset alongside Google and Qualcomm. It's the first Android XR product, a line that will eventually include AI glasses \"and beyond.\" You can read more about the headset and its ecosystem in Engadget's news coverage. Given Google's connection to the Galaxy XR, it isn't too surprising that the company has bonuses for early orders. If you buy the headset before the end of 2025, you'll get \"The Explorer Pack.\" That includes a year of access to Google AI Pro, YouTube Premium and Google Play Pass. Also included until the end of the year is the \"XR Pack.\" This adds three months of YouTube TV, a year of NBA League Pass, NFL Pro Era, Adobe's Project Pulsar, Asteroid and Calm. You can order the Galaxy XR now from Samsung's website and in Samsung Experience Stores. The headset costs $1,800. An optional Galaxy XR Controller costs $250. And somehow, the official Galaxy XR travel case also costs $250, which is — yikes — a lot. Perhaps consider waiting for third-party alternatives on the case front. Samsung is offering a 24-month financing plan for the headset ($75.01 monthly) on its website. Meanwhile, Samsung's stores have that plan as well as a 12-month one ($149 monthly).This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-order-the-samsung-galaxy-xr-headset-020008173.html?src=rss",
          "content": "Samsung's take on the Vision Pro is here — and you can already order it. Costing just over half as much as Apple's reality machine, the Galaxy XR has a 4K micro-OLED screen and a 100-degree horizontal field of view. The $1,800 mixed reality headset is available now for pre-order on Samsung's website. The Galaxy XR isn't only a Samsung product. The company developed the long-rumored headset alongside Google and Qualcomm. It's the first Android XR product, a line that will eventually include AI glasses \"and beyond.\" You can read more about the headset and its ecosystem in Engadget's news coverage. Given Google's connection to the Galaxy XR, it isn't too surprising that the company has bonuses for early orders. If you buy the headset before the end of 2025, you'll get \"The Explorer Pack.\" That includes a year of access to Google AI Pro, YouTube Premium and Google Play Pass. Also included until the end of the year is the \"XR Pack.\" This adds three months of YouTube TV, a year of NBA League Pass, NFL Pro Era, Adobe's Project Pulsar, Asteroid and Calm. You can order the Galaxy XR now from Samsung's website and in Samsung Experience Stores. The headset costs $1,800. An optional Galaxy XR Controller costs $250. And somehow, the official Galaxy XR travel case also costs $250, which is — yikes — a lot. Perhaps consider waiting for third-party alternatives on the case front. Samsung is offering a 24-month financing plan for the headset ($75.01 monthly) on its website. Meanwhile, Samsung's stores have that plan as well as a 12-month one ($149 monthly).This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-order-the-samsung-galaxy-xr-headset-020008173.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/google-and-samsungs-first-android-xr-headset-is-the-1800-galaxy-xr-020004449.html",
          "published_at": "Wed, 22 Oct 2025 02:00:04 +0000",
          "title": "Google and Samsung's first Android XR headset is the $1,800 Galaxy XR",
          "standfirst": "We've known for a while that the first extended reality (or XR) headset from Samsung and Google would debut in 2025. During an event on Tuesday night, Samsung at long last shared more details about the first Android XR device that you'll be able to purchase. The company got really wild and original with the headset's name. You're truly not going to believe what it's called... Actually, it's got the most unsurprising name of all time: Galaxy XR. What's more, you can buy the headset right now in the US and Korea for $1,800. That's just over half of what the Apple Vision Pro costs. Aside from an Android-powered headset that looks very much like an Apple Vision Pro, you might be wondering exactly what you'll be getting in return for forking over 1,800 smackeroos. As expected, Galaxy XR is powered by the Snapdragon XR2+ Gen 2 chipset. Qualcomm worked with Samsung and Google on the headset. The micro OLED display has 29 million pixels (6 million more than the Apple Vision Pro), a resolution of 3,552 x 3,840 and 96 percent of the DCI‑P3 color gamut — four percent more than the Vision Pro. Where Apple does have Samsung beat on the display front is with the refresh rate: the Galaxy XR tops out at 90Hz and the Vision Pro can hit 120Hz. Galaxy XR has dual high-res passthrough cameras to support mixed reality use, six other external cameras for tracking things in the environment and two eye-tracking sensors. The device supports iris recognition for unlocking the headset and entering passwords in some apps. As with the Vision Pro, you can capture 3D photos and video using the headset. Sam Rutherford for Engadget The cameras allow for hand tracking and gesture control, though it's possible to operate Galaxy XR with physical controllers as well. If you prefer, you can pair a keyboard and mouse to the headset or link it to your PC and access your desktop that way. The dual speakers support Dolby Atmos and there are six microphones built in. As for battery life, Samsung says you'll get up to two hours of general use and 2.5 hours of video playback on a charge. That matches the original battery life promises of the original Vision Pro, but Apple said its latest model (which has the new M5 chipset) offers an extra 30 minutes or so of usage. The interpupillary distance of the Galaxy XR's optics is 54~70mm, and it's possible to buy insertable prescription lenses if needed. As for connectivity, the headset supports Wi-Fi 7 and Bluetooth 5.4. Even with a forehead cushion attached, Galaxy XR weighs 545g (1.2lbs), while the latest Apple Vision Pro has a minimum weight of 750g (1.7lbs). The Galaxy XR's battery pack — as with competitor's offerings, the battery is external — weighs 302g (0.7lbs). Samsung claims the Galaxy XR was designed with comfort in mind. \"The headset’s ergonomically balanced frame distributes pressure across the forehead and the back of the head, minimizing facial discomfort while providing steady support,\" the company said in a press release. There's also a detachable light shield that you can employ to block out external light. Google/Unity What you can actually do with Galaxy XR There are no prizes for guessing that Google's generative AI chatbot Gemini is at the heart of Android XR. \"Android XR is the first Android platform built entirely for the Gemini era, and we are incredibly excited to take a significant leap forward today with the launch of Galaxy XR,\" Sameer Samat, Google's president of Android Ecosystem, said. Every Google Play Store app works out of the box on the headset, though of course Google has reworked some for mixed reality. You can use Gemini to navigate Google Maps and ask for personalized recommendations while checking out 3D visuals with Immersive View. Google Photos can bring an extra dimension to 2D photos and videos via auto spatialization. On YouTube, you can ask Gemini to find videos and tell you more details about what you're watching. And, while using the passthrough mode, you can look at any object in your environment and use Circle to Search to look up more info about it. Google has also made new versions of Google TV, Chrome and Meet (because what is mixed reality for if not conference calls?) for Android XR. Multitasking is a factor here as well. The operating system allows users to have multiple, resizable apps open at once. These can be arranged in a virtual space, or you can simply ask Gemini to do that for you. On the entertainment front, you'll be able to stream shows and movies in 4K in a virtual theater setting. You'll have access to a library of 180-degree and 360-degree VR content, and you can view 3D content via a \"spatial\" tab. Some streaming platforms have reworked their apps for Android XR, including Crunchyroll, HBO Max and Peacock. There's a multi-view option for watching sports, with apps from the likes of MLB and Fox Sports available. With Adobe's Project Pulsar (an immersive video editing app), you'll be able to add 3D depth to videos and seemingly place captions behind subjects with ease, if that's something you're interested in. Sam Rutherford for Engadget Galaxy XR has games too. NFL Pro Era — an NFL-licensed virtual reality title that's also on Meta Quest, PlayStation VR and Windows — is available for Android XR. So too is Inside [JOB] by Owlchemy Labs (Vacation Simulator, Job Simulator). For compatible games, Samsung says Gemini can offer real-time coaching, tips and \"enhanced gameplay experiences.\" The arrival of Galaxy XR is an important next step for Google and its grand vision of an Android XR ecosystem. But the company isn't stopping with headsets. It's also making smart glasses, a product category that Meta has been trying to conquer. Samsung and Google are working with Warby Parker on Android XR smart glasses. At I/O earlier this year, we got some hands-on time with a prototype of Google's Android XR glasses. Once again, Galaxy XR will run you $1,800, and Samsung is offering financing options. The Galaxy XR Travel Case and Galaxy XR Controller will each run you $250 — at those prices, they almost need financing options too. Ouch. Anyone who buys Galaxy XR by the end of this year will get an Explorer Pack at no extra cost. This includes 12 months of access to Google AI Pro, YouTube Premium and Google Play Pass. The NFL Pro Era, Project Pulsar, Calm and Asteroid apps are bundled in too. You'll also get NBA League Pass access for the 2025-26 season in the US or 12 months of the Coupang Play Sports Pass in Korea. Charging $1 for each of the first three months of YouTube TV seems a little cheap considering the outlay for Galaxy XR, but it's still a decent perk. YouTube TV typically costs $83 per month. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/google-and-samsungs-first-android-xr-headset-is-the-1800-galaxy-xr-020004449.html?src=rss",
          "content": "We've known for a while that the first extended reality (or XR) headset from Samsung and Google would debut in 2025. During an event on Tuesday night, Samsung at long last shared more details about the first Android XR device that you'll be able to purchase. The company got really wild and original with the headset's name. You're truly not going to believe what it's called... Actually, it's got the most unsurprising name of all time: Galaxy XR. What's more, you can buy the headset right now in the US and Korea for $1,800. That's just over half of what the Apple Vision Pro costs. Aside from an Android-powered headset that looks very much like an Apple Vision Pro, you might be wondering exactly what you'll be getting in return for forking over 1,800 smackeroos. As expected, Galaxy XR is powered by the Snapdragon XR2+ Gen 2 chipset. Qualcomm worked with Samsung and Google on the headset. The micro OLED display has 29 million pixels (6 million more than the Apple Vision Pro), a resolution of 3,552 x 3,840 and 96 percent of the DCI‑P3 color gamut — four percent more than the Vision Pro. Where Apple does have Samsung beat on the display front is with the refresh rate: the Galaxy XR tops out at 90Hz and the Vision Pro can hit 120Hz. Galaxy XR has dual high-res passthrough cameras to support mixed reality use, six other external cameras for tracking things in the environment and two eye-tracking sensors. The device supports iris recognition for unlocking the headset and entering passwords in some apps. As with the Vision Pro, you can capture 3D photos and video using the headset. Sam Rutherford for Engadget The cameras allow for hand tracking and gesture control, though it's possible to operate Galaxy XR with physical controllers as well. If you prefer, you can pair a keyboard and mouse to the headset or link it to your PC and access your desktop that way. The dual speakers support Dolby Atmos and there are six microphones built in. As for battery life, Samsung says you'll get up to two hours of general use and 2.5 hours of video playback on a charge. That matches the original battery life promises of the original Vision Pro, but Apple said its latest model (which has the new M5 chipset) offers an extra 30 minutes or so of usage. The interpupillary distance of the Galaxy XR's optics is 54~70mm, and it's possible to buy insertable prescription lenses if needed. As for connectivity, the headset supports Wi-Fi 7 and Bluetooth 5.4. Even with a forehead cushion attached, Galaxy XR weighs 545g (1.2lbs), while the latest Apple Vision Pro has a minimum weight of 750g (1.7lbs). The Galaxy XR's battery pack — as with competitor's offerings, the battery is external — weighs 302g (0.7lbs). Samsung claims the Galaxy XR was designed with comfort in mind. \"The headset’s ergonomically balanced frame distributes pressure across the forehead and the back of the head, minimizing facial discomfort while providing steady support,\" the company said in a press release. There's also a detachable light shield that you can employ to block out external light. Google/Unity What you can actually do with Galaxy XR There are no prizes for guessing that Google's generative AI chatbot Gemini is at the heart of Android XR. \"Android XR is the first Android platform built entirely for the Gemini era, and we are incredibly excited to take a significant leap forward today with the launch of Galaxy XR,\" Sameer Samat, Google's president of Android Ecosystem, said. Every Google Play Store app works out of the box on the headset, though of course Google has reworked some for mixed reality. You can use Gemini to navigate Google Maps and ask for personalized recommendations while checking out 3D visuals with Immersive View. Google Photos can bring an extra dimension to 2D photos and videos via auto spatialization. On YouTube, you can ask Gemini to find videos and tell you more details about what you're watching. And, while using the passthrough mode, you can look at any object in your environment and use Circle to Search to look up more info about it. Google has also made new versions of Google TV, Chrome and Meet (because what is mixed reality for if not conference calls?) for Android XR. Multitasking is a factor here as well. The operating system allows users to have multiple, resizable apps open at once. These can be arranged in a virtual space, or you can simply ask Gemini to do that for you. On the entertainment front, you'll be able to stream shows and movies in 4K in a virtual theater setting. You'll have access to a library of 180-degree and 360-degree VR content, and you can view 3D content via a \"spatial\" tab. Some streaming platforms have reworked their apps for Android XR, including Crunchyroll, HBO Max and Peacock. There's a multi-view option for watching sports, with apps from the likes of MLB and Fox Sports available. With Adobe's Project Pulsar (an immersive video editing app), you'll be able to add 3D depth to videos and seemingly place captions behind subjects with ease, if that's something you're interested in. Sam Rutherford for Engadget Galaxy XR has games too. NFL Pro Era — an NFL-licensed virtual reality title that's also on Meta Quest, PlayStation VR and Windows — is available for Android XR. So too is Inside [JOB] by Owlchemy Labs (Vacation Simulator, Job Simulator). For compatible games, Samsung says Gemini can offer real-time coaching, tips and \"enhanced gameplay experiences.\" The arrival of Galaxy XR is an important next step for Google and its grand vision of an Android XR ecosystem. But the company isn't stopping with headsets. It's also making smart glasses, a product category that Meta has been trying to conquer. Samsung and Google are working with Warby Parker on Android XR smart glasses. At I/O earlier this year, we got some hands-on time with a prototype of Google's Android XR glasses. Once again, Galaxy XR will run you $1,800, and Samsung is offering financing options. The Galaxy XR Travel Case and Galaxy XR Controller will each run you $250 — at those prices, they almost need financing options too. Ouch. Anyone who buys Galaxy XR by the end of this year will get an Explorer Pack at no extra cost. This includes 12 months of access to Google AI Pro, YouTube Premium and Google Play Pass. The NFL Pro Era, Project Pulsar, Calm and Asteroid apps are bundled in too. You'll also get NBA League Pass access for the 2025-26 season in the US or 12 months of the Coupang Play Sports Pass in Korea. Charging $1 for each of the first three months of YouTube TV seems a little cheap considering the outlay for Galaxy XR, but it's still a decent perk. YouTube TV typically costs $83 per month. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/google-and-samsungs-first-android-xr-headset-is-the-1800-galaxy-xr-020004449.html?src=rss",
          "feed_position": 39,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/5bf711b0-aea9-11f0-b7fa-d4a3d3eb61e4"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/qwens-new-deep-research-update-lets-you-turn-its-reports-into-webpages",
          "published_at": "Tue, 21 Oct 2025 18:32:00 GMT",
          "title": "Qwen's new Deep Research update lets you turn its reports into webpages, podcasts in seconds",
          "standfirst": "Chinese e-commerce giant Alibaba’s famously prolific Qwen Team of AI model researchers and engineers has introduced a major expansion to its Qwen Deep Research tool, which is available as an optional modality the user can activate on the web-based Qwen Chat (a competitor to ChatGPT).The update lets users generate not only comprehensive research reports with well-organized citations, but also interactive web pages and multi-speaker podcasts — all within 1-2 clicks.This functionality is part of a proprietary release, distinct from many of Qwen’s previous open-source model offerings. While the feature relies on the open-source models Qwen3-Coder, Qwen-Image, and Qwen3-TTS to power its core capabilities, the end-to-end experience — including research execution, web deployment, and audio generation — is hosted and operated by Qwen. This means users benefit from a managed, integrated workflow without needing to configure infrastructure. That said, developers with access to the open-source models could theoretically replicate similar functionality on private or commercial systems.The update was announced via the team’s official X account (@Alibaba_Qwen) today, October 21, 2025, stating:“Qwen Deep Research just got a major upgrade. It now creates not only the report, but also a live webpage and a podcast — powered by Qwen3-Coder, Qwen-Image, and Qwen3-TTS. Your insights, now visual and audible.”Multi-Format Research OutputThe core workflow begins with a user request inside the Qwen Chat interface. From there, Qwen collaborates by asking clarifying questions to shape the research scope, pulls data from the web and official sources, and analyzes or resolves any inconsistencies it finds — even generating custom code when needed.A demo video posted by Qwen on X walks through this process on Qwen Chat using the U.S. SaaS market as an example. In it, Qwen retrieves data from multiple industry sources, identifies discrepancies in market size estimates (e.g., $206 billion vs. $253 billion), and highlights ambiguities in the U.S. share of global figures. The assistant comments on differences in scope between sources and calculates a compound annual growth rate (CAGR) of 19.8% from 2020 to 2023, providing contextual analysis to back up the raw numbers.Once the research is complete, users can click on the \"eyeball\" icon below the output result (see screenshot), which will bring up a PDF-style report in the right hand pane.Then, when viewing the report in the right-hand pane, the user can click the \"Create\" button in the upper-right hand corner and select from the following two options:\"Web Dev\" which produces a live, professional-grade web page, automatically deployed and hosted by Qwen, using Qwen3-Coder for structure and Qwen-Image for visuals.\"Podcast,\" which, as it states, produces an audio podcast, featuring dynamic, multi-speaker narration generated by Qwen3-TTS, also hosted by Qwen for easy sharing and playback.This enables users to quickly convert a single research project into multiple forms of content — written, visual, and audible — with minimal extra input.The website includes inline graphics generated by Qwen Image, making it suitable for use in public presentations, classrooms, or publishing. The podcast feature allows users to select between 17 different speaker names as the host and 7 as the co-host, though I wasn&#x27;t able to find a way to preview the voice outputs before selecting them. It appears designed for deep listening on the go. There was no way to change the language output that I could see, so mine came out in English, like my reports and initial prompts, though the Qwen LLMs are multi-modal. The voices were slightly more robotic than other AI tools I&#x27;ve used.Here&#x27;s an example of a web page I generated on commonalities in authoritarian regimes throughout history, another one on UFO or UAP sightings, and below this paragraph, a podcast on UFO or UAP sightings. While the website is hosted via a public link, the podcast must be downloaded by the user and can&#x27;t be linked to publicly, from what I could tell in my brief usage so far.Note the podcast is much different than the actual report — not just a straight read-through audio version of it, rather, a new format of two hosts discussing and bantering about the subject using the report as the jumping off point. The web page versions of the report also include new graphics not found in the PDF report.Comparisons to Google&#x27;s NotebookLMWhile the new capabilities have been well received by many early users, comparisons to other research assistants have surfaced — particularly Google’s NotebookLM, which recently exited beta.AI commentator and newsletter writer Chubby (@kimmonismus) noted on X:“I am really grateful that Qwen provides regular updates. That’s great.But the attempt to build a NotebookLM clone inside Qwen-3-max doesn’t sound very promising compared to Google’s version.”While NotebookLM is built around organizing and querying existing documents and web pages, Qwen Deep Research focuses more on generating new research content from scratch, aggregating sources from the open web, and presenting it across multiple modalities. The comparison suggests that while the two tools overlap in general concept — AI-assisted research — they diverge in approach and target user experience.AvailabilityQwen Deep Research is now live and available through the Qwen Chat app. The feature can be accessed with the following URL.No pricing details have been provided for Qwen3-Max or the specific Deep Research capabilities as of this writing.What&#x27;s Next For Qwen Deep Research?By combining research guidance, data analysis, and multi-format content creation into a single tool, Qwen Deep Research aims to streamline the path from idea to publishable output. The integration of code, visuals, and voice makes it especially attractive to content creators, educators, and independent analysts who want to scale their research into web- or podcast-friendly forms without switching platforms.Still, comparisons to more specialized offerings like NotebookLM raise questions about how Qwen’s generalized approach stacks up on depth, precision, and refinement. Whether the strength of its multi-format execution outweighs those concerns may come down to user priorities — and whether they value single-click publishing over tight integration with existing notes and materials.For now, Qwen is signaling that research doesn’t end with a document — it begins with one.Let me know if you want this repackaged into something shorter or tailored to a particular audience — newsletter, press-style blog, internal team explainer, etc.",
          "content": "Chinese e-commerce giant Alibaba’s famously prolific Qwen Team of AI model researchers and engineers has introduced a major expansion to its Qwen Deep Research tool, which is available as an optional modality the user can activate on the web-based Qwen Chat (a competitor to ChatGPT).The update lets users generate not only comprehensive research reports with well-organized citations, but also interactive web pages and multi-speaker podcasts — all within 1-2 clicks.This functionality is part of a proprietary release, distinct from many of Qwen’s previous open-source model offerings. While the feature relies on the open-source models Qwen3-Coder, Qwen-Image, and Qwen3-TTS to power its core capabilities, the end-to-end experience — including research execution, web deployment, and audio generation — is hosted and operated by Qwen. This means users benefit from a managed, integrated workflow without needing to configure infrastructure. That said, developers with access to the open-source models could theoretically replicate similar functionality on private or commercial systems.The update was announced via the team’s official X account (@Alibaba_Qwen) today, October 21, 2025, stating:“Qwen Deep Research just got a major upgrade. It now creates not only the report, but also a live webpage and a podcast — powered by Qwen3-Coder, Qwen-Image, and Qwen3-TTS. Your insights, now visual and audible.”Multi-Format Research OutputThe core workflow begins with a user request inside the Qwen Chat interface. From there, Qwen collaborates by asking clarifying questions to shape the research scope, pulls data from the web and official sources, and analyzes or resolves any inconsistencies it finds — even generating custom code when needed.A demo video posted by Qwen on X walks through this process on Qwen Chat using the U.S. SaaS market as an example. In it, Qwen retrieves data from multiple industry sources, identifies discrepancies in market size estimates (e.g., $206 billion vs. $253 billion), and highlights ambiguities in the U.S. share of global figures. The assistant comments on differences in scope between sources and calculates a compound annual growth rate (CAGR) of 19.8% from 2020 to 2023, providing contextual analysis to back up the raw numbers.Once the research is complete, users can click on the \"eyeball\" icon below the output result (see screenshot), which will bring up a PDF-style report in the right hand pane.Then, when viewing the report in the right-hand pane, the user can click the \"Create\" button in the upper-right hand corner and select from the following two options:\"Web Dev\" which produces a live, professional-grade web page, automatically deployed and hosted by Qwen, using Qwen3-Coder for structure and Qwen-Image for visuals.\"Podcast,\" which, as it states, produces an audio podcast, featuring dynamic, multi-speaker narration generated by Qwen3-TTS, also hosted by Qwen for easy sharing and playback.This enables users to quickly convert a single research project into multiple forms of content — written, visual, and audible — with minimal extra input.The website includes inline graphics generated by Qwen Image, making it suitable for use in public presentations, classrooms, or publishing. The podcast feature allows users to select between 17 different speaker names as the host and 7 as the co-host, though I wasn&#x27;t able to find a way to preview the voice outputs before selecting them. It appears designed for deep listening on the go. There was no way to change the language output that I could see, so mine came out in English, like my reports and initial prompts, though the Qwen LLMs are multi-modal. The voices were slightly more robotic than other AI tools I&#x27;ve used.Here&#x27;s an example of a web page I generated on commonalities in authoritarian regimes throughout history, another one on UFO or UAP sightings, and below this paragraph, a podcast on UFO or UAP sightings. While the website is hosted via a public link, the podcast must be downloaded by the user and can&#x27;t be linked to publicly, from what I could tell in my brief usage so far.Note the podcast is much different than the actual report — not just a straight read-through audio version of it, rather, a new format of two hosts discussing and bantering about the subject using the report as the jumping off point. The web page versions of the report also include new graphics not found in the PDF report.Comparisons to Google&#x27;s NotebookLMWhile the new capabilities have been well received by many early users, comparisons to other research assistants have surfaced — particularly Google’s NotebookLM, which recently exited beta.AI commentator and newsletter writer Chubby (@kimmonismus) noted on X:“I am really grateful that Qwen provides regular updates. That’s great.But the attempt to build a NotebookLM clone inside Qwen-3-max doesn’t sound very promising compared to Google’s version.”While NotebookLM is built around organizing and querying existing documents and web pages, Qwen Deep Research focuses more on generating new research content from scratch, aggregating sources from the open web, and presenting it across multiple modalities. The comparison suggests that while the two tools overlap in general concept — AI-assisted research — they diverge in approach and target user experience.AvailabilityQwen Deep Research is now live and available through the Qwen Chat app. The feature can be accessed with the following URL.No pricing details have been provided for Qwen3-Max or the specific Deep Research capabilities as of this writing.What&#x27;s Next For Qwen Deep Research?By combining research guidance, data analysis, and multi-format content creation into a single tool, Qwen Deep Research aims to streamline the path from idea to publishable output. The integration of code, visuals, and voice makes it especially attractive to content creators, educators, and independent analysts who want to scale their research into web- or podcast-friendly forms without switching platforms.Still, comparisons to more specialized offerings like NotebookLM raise questions about how Qwen’s generalized approach stacks up on depth, precision, and refinement. Whether the strength of its multi-format execution outweighs those concerns may come down to user priorities — and whether they value single-click publishing over tight integration with existing notes and materials.For now, Qwen is signaling that research doesn’t end with a document — it begins with one.Let me know if you want this repackaged into something shorter or tailored to a particular audience — newsletter, press-style blog, internal team explainer, etc.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5Joxz8qhvStlvnHybvWBpG/5dcda997ed99a05e52cc929b825d01d5/cfr0z3n_realistic_graphic_novel_art_hyperdetailed_overhead_isom_7a652de4-81e1-4145-848c-4a9c6c0969e4.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/deepseek-drops-open-source-model-that-compresses-text-10x-through-images",
          "published_at": "Tue, 21 Oct 2025 18:30:00 GMT",
          "title": "DeepSeek drops open-source model that compresses text 10x through images, defying conventions",
          "standfirst": "DeepSeek, the Chinese artificial intelligence research company that has repeatedly challenged assumptions about AI development costs, has released a new model that fundamentally reimagines how large language models process information—and the implications extend far beyond its modest branding as an optical character recognition tool.The company&#x27;s DeepSeek-OCR model, released Monday with full open-source code and weights, achieves what researchers describe as a paradigm inversion: compressing text through visual representation up to 10 times more efficiently than traditional text tokens. The finding challenges a core assumption in AI development and could pave the way for language models with dramatically expanded context windows, potentially reaching tens of millions of tokens.\"We present DeepSeek-OCR as an initial investigation into the feasibility of compressing long contexts via optical 2D mapping,\" the research team wrote in their technical paper. \"Experiments show that when the number of text tokens is within 10 times that of vision tokens (i.e., a compression ratio < 10×), the model can achieve decoding (OCR) precision of 97%.\"The implications have resonated across the AI research community. Andrej Karpathy, co-founder of OpenAI and former director of AI at Tesla, said in a post that the work raises fundamental questions about how AI systems should process information. \"Maybe it makes more sense that all inputs to LLMs should only ever be images,\" Karpathy wrote. \"Even if you happen to have pure text input, maybe you&#x27;d prefer to render it and then feed that in.\"How DeepSeek achieved 10x compression by treating text as imagesWhile DeepSeek marketed the release as an OCR model — a technology for converting images of text into digital characters — the research paper reveals more ambitious goals. The model demonstrates that visual representations can serve as a superior compression medium for textual information, inverting the conventional hierarchy where text tokens were considered more efficient than vision tokens.\"Traditionally, vision LLM tokens almost seemed like an afterthought or &#x27;bolt on&#x27; to the LLM paradigm,\" wrote Jeffrey Emanuel, an AI researcher, in a detailed analysis of the paper. \"And 10k words of English would take up far more space in a multimodal LLM when expressed as intelligible pixels than when expressed as tokens...But that gets inverted now from the ideas in this paper.\"The model&#x27;s architecture consists of two primary components: DeepEncoder, a novel 380-million-parameter vision encoder, and a 3-billion-parameter mixture-of-experts language decoder with 570 million activated parameters. DeepEncoder combines Meta&#x27;s Segment Anything Model (SAM) for local visual perception with OpenAI&#x27;s CLIP model for global visual understanding, connected through a 16x compression module.To validate their compression claims, DeepSeek researchers tested the model on the Fox benchmark, a dataset of diverse document layouts. The results were striking: using just 100 vision tokens, the model achieved 97.3% accuracy on documents containing 700-800 text tokens — representing an effective compression ratio of 7.5x. Even at compression ratios approaching 20x, accuracy remained around 60%.The practical impact: Processing 200,000 pages per day on a single GPUThe efficiency gains translate directly to production capabilities. According to the company, a single Nvidia A100-40G GPU can process more than 200,000 pages per day using DeepSeek-OCR. Scaling to a cluster of 20 servers with eight GPUs each, throughput reaches 33 million pages daily — sufficient to rapidly construct training datasets for other AI models.On OmniDocBench, a comprehensive document parsing benchmark, DeepSeek-OCR outperformed GOT-OCR2.0 (which uses 256 tokens per page) while using only 100 vision tokens. More dramatically, it surpassed MinerU2.0 — which requires more than 6,000 tokens per page on average — while using fewer than 800 vision tokens.DeepSeek designed the model to support five distinct resolution modes, each optimized for different compression ratios and use cases. The \"Tiny\" mode operates at 512×512 resolution with just 64 vision tokens, while \"Gundam\" mode combines multiple resolutions dynamically for complex documents. \"Gundam mode consists of n×640×640 tiles (local views) and a 1024×1024 global view,\" the researchers wrote.Why this breakthrough could unlock 10 million token context windowsThe compression breakthrough has immediate implications for one of the most pressing challenges in AI development: expanding the context windows that determine how much information language models can actively consider. Current state-of-the-art models typically handle context windows measured in hundreds of thousands of tokens. DeepSeek&#x27;s approach suggests a path to windows ten times larger.\"The potential of getting a frontier LLM with a 10 or 20 million token context window is pretty exciting,\" Emanuel wrote. \"You could basically cram all of a company&#x27;s key internal documents into a prompt preamble and cache this with OpenAI and then just add your specific query or prompt on top of that and not have to deal with search tools and still have it be fast and cost-effective.\"The researchers explicitly frame their work in terms of context compression for language models. \"Through DeepSeek-OCR, we demonstrate that vision-text compression can achieve significant token reduction (7-20×) for different historical context stages, offering a promising direction for addressing long-context challenges in large language models,\" they wrote.The paper includes a speculative but intriguing diagram illustrating how the approach could implement memory decay mechanisms similar to human cognition. Older conversation rounds could be progressively downsampled to lower resolutions, consuming fewer tokens while maintaining key information — a form of computational forgetting that mirrors biological memory.How visual processing could eliminate the &#x27;ugly&#x27; tokenizer problemBeyond compression, Karpathy highlighted how the approach challenges fundamental assumptions about how language models should process text. Traditional tokenizers—the systems that break text into units for processing—have long been criticized for their complexity and limitations.\"I already ranted about how much I dislike the tokenizer,\" Karpathy wrote. \"Tokenizers are ugly, separate, not end-to-end stage. It &#x27;imports&#x27; all the ugliness of Unicode, byte encodings, it inherits a lot of historical baggage, security/jailbreak risk (e.g. continuation bytes). It makes two characters that look identical to the eye look as two completely different tokens internally in the network.\"Visual processing of text could eliminate these issues while enabling new capabilities. The approach naturally handles formatting information lost in pure text representations: bold text, colors, layout, embedded images. \"Input can now be processed with bidirectional attention easily and as default, not autoregressive attention - a lot more powerful,\" Karpathy noted.The implications resonate with human cognitive science. Emanuel drew a parallel to Hans Bethe, the renowned physicist who memorized vast amounts of reference data: \"Having vast amounts of task-specific knowledge in your working memory is extremely useful. This seems like a very clever and additive approach to potentially expanding that memory bank by 10x or more.\"The model&#x27;s training: 30 million PDF pages across 100 languagesThe model&#x27;s capabilities rest on an extensive training regimen using diverse data sources. DeepSeek collected 30 million PDF pages covering approximately 100 languages, with Chinese and English accounting for 25 million pages. The training data spans nine document types — academic papers, financial reports, textbooks, newspapers, handwritten notes, and others.Beyond document OCR, the training incorporated what the researchers call \"OCR 2.0\" data: 10 million synthetic charts, 5 million chemical formulas, and 1 million geometric figures. The model also received 20% general vision data for tasks like image captioning and object detection, plus 10% text-only data to maintain language capabilities.The training process employed pipeline parallelism across 160 Nvidia A100-40G GPUs (20 nodes with 8 GPUs each), with the vision encoder divided between two pipeline stages and the language model split across two others. \"For multimodal data, the training speed is 70B tokens/day,\" the researchers reported.Open source release accelerates research and raises competitive questionsTrue to DeepSeek&#x27;s pattern of open development, the company released the complete model weights, training code, and inference scripts on GitHub and Hugging Face. The GitHub repository gained over 4,000 stars within 24 hours of release, according to Dataconomy.The breakthrough raises questions about whether other AI labs have developed similar techniques but kept them proprietary. Emanuel speculated that Google&#x27;s Gemini models, which feature large context windows and strong OCR performance, might employ comparable approaches. \"For all we know, Google could have already figured out something like this, which could explain why Gemini has such a huge context size and is so good and fast at OCR tasks,\" Emanuel wrote.Google&#x27;s Gemini 2.5 Pro offers a 1-million-token context window, with plans to expand to 2 million, though the company has not publicly detailed the technical approaches enabling this capability. OpenAI&#x27;s GPT-5 supports 400,000 tokens, while Anthropic&#x27;s Claude 4.5 offers 200,000 tokens, with a 1-million-token window available in beta for eligible organizations.The unanswered question: Can AI reason over compressed visual tokens?While the compression results are impressive, researchers acknowledge important open questions. \"It&#x27;s not clear how exactly this interacts with the other downstream cognitive functioning of an LLM,\" Emanuel noted. \"Can the model reason as intelligently over those compressed visual tokens as it can using regular text tokens? Does it make the model less articulate by forcing it into a more vision-oriented modality?\"The DeepSeek paper focuses primarily on the compression-decompression capability, measured through OCR accuracy, rather than downstream reasoning performance. This leaves open whether language models could reason effectively over large contexts represented primarily as compressed visual tokens.The researchers acknowledge their work represents \"an initial exploration into the boundaries of vision-text compression.\" They note that \"OCR alone is insufficient to fully validate true context optical compression\" and plan future work including \"digital-optical text interleaved pretraining, needle-in-a-haystack testing, and other evaluations.\"DeepSeek has established a pattern of achieving competitive results with dramatically lower computational resources than Western AI labs. The company&#x27;s earlier DeepSeek-V3 model reportedly cost just $5.6 million to train—though this figure represents only the final training run and excludes R&D and infrastructure costs—compared to hundreds of millions for comparable models from OpenAI and Anthropic.Industry analysts have questioned the $5.6 million figure, with some estimates placing the company&#x27;s total infrastructure and operational costs closer to $1.3 billion, though still lower than American competitors&#x27; spending.The bigger picture: Should language models process text as images?DeepSeek-OCR poses a fundamental question for AI development: should language models process text as text, or as images of text? The research demonstrates that, at least for compression purposes, visual representation offers significant advantages. Whether this translates to effective reasoning over vast contexts remains to be determined.\"From another perspective, optical contexts compression still offers substantial room for research and improvement, representing a promising new direction,\" the researchers concluded in their paper.For the AI industry, the work adds another dimension to the race for longer context windows — a competition that has intensified as language models are applied to increasingly complex tasks requiring vast amounts of information. The open-source release ensures the technique will be widely explored, tested, and potentially integrated into future AI systems.As Karpathy framed the deeper implication: \"OCR is just one of many useful vision -> text tasks. And text -> text tasks can be made to be vision ->text tasks. Not vice versa.\" In other words, the path forward for AI might not run through better tokenizers — it might bypass text tokens altogether.",
          "content": "DeepSeek, the Chinese artificial intelligence research company that has repeatedly challenged assumptions about AI development costs, has released a new model that fundamentally reimagines how large language models process information—and the implications extend far beyond its modest branding as an optical character recognition tool.The company&#x27;s DeepSeek-OCR model, released Monday with full open-source code and weights, achieves what researchers describe as a paradigm inversion: compressing text through visual representation up to 10 times more efficiently than traditional text tokens. The finding challenges a core assumption in AI development and could pave the way for language models with dramatically expanded context windows, potentially reaching tens of millions of tokens.\"We present DeepSeek-OCR as an initial investigation into the feasibility of compressing long contexts via optical 2D mapping,\" the research team wrote in their technical paper. \"Experiments show that when the number of text tokens is within 10 times that of vision tokens (i.e., a compression ratio < 10×), the model can achieve decoding (OCR) precision of 97%.\"The implications have resonated across the AI research community. Andrej Karpathy, co-founder of OpenAI and former director of AI at Tesla, said in a post that the work raises fundamental questions about how AI systems should process information. \"Maybe it makes more sense that all inputs to LLMs should only ever be images,\" Karpathy wrote. \"Even if you happen to have pure text input, maybe you&#x27;d prefer to render it and then feed that in.\"How DeepSeek achieved 10x compression by treating text as imagesWhile DeepSeek marketed the release as an OCR model — a technology for converting images of text into digital characters — the research paper reveals more ambitious goals. The model demonstrates that visual representations can serve as a superior compression medium for textual information, inverting the conventional hierarchy where text tokens were considered more efficient than vision tokens.\"Traditionally, vision LLM tokens almost seemed like an afterthought or &#x27;bolt on&#x27; to the LLM paradigm,\" wrote Jeffrey Emanuel, an AI researcher, in a detailed analysis of the paper. \"And 10k words of English would take up far more space in a multimodal LLM when expressed as intelligible pixels than when expressed as tokens...But that gets inverted now from the ideas in this paper.\"The model&#x27;s architecture consists of two primary components: DeepEncoder, a novel 380-million-parameter vision encoder, and a 3-billion-parameter mixture-of-experts language decoder with 570 million activated parameters. DeepEncoder combines Meta&#x27;s Segment Anything Model (SAM) for local visual perception with OpenAI&#x27;s CLIP model for global visual understanding, connected through a 16x compression module.To validate their compression claims, DeepSeek researchers tested the model on the Fox benchmark, a dataset of diverse document layouts. The results were striking: using just 100 vision tokens, the model achieved 97.3% accuracy on documents containing 700-800 text tokens — representing an effective compression ratio of 7.5x. Even at compression ratios approaching 20x, accuracy remained around 60%.The practical impact: Processing 200,000 pages per day on a single GPUThe efficiency gains translate directly to production capabilities. According to the company, a single Nvidia A100-40G GPU can process more than 200,000 pages per day using DeepSeek-OCR. Scaling to a cluster of 20 servers with eight GPUs each, throughput reaches 33 million pages daily — sufficient to rapidly construct training datasets for other AI models.On OmniDocBench, a comprehensive document parsing benchmark, DeepSeek-OCR outperformed GOT-OCR2.0 (which uses 256 tokens per page) while using only 100 vision tokens. More dramatically, it surpassed MinerU2.0 — which requires more than 6,000 tokens per page on average — while using fewer than 800 vision tokens.DeepSeek designed the model to support five distinct resolution modes, each optimized for different compression ratios and use cases. The \"Tiny\" mode operates at 512×512 resolution with just 64 vision tokens, while \"Gundam\" mode combines multiple resolutions dynamically for complex documents. \"Gundam mode consists of n×640×640 tiles (local views) and a 1024×1024 global view,\" the researchers wrote.Why this breakthrough could unlock 10 million token context windowsThe compression breakthrough has immediate implications for one of the most pressing challenges in AI development: expanding the context windows that determine how much information language models can actively consider. Current state-of-the-art models typically handle context windows measured in hundreds of thousands of tokens. DeepSeek&#x27;s approach suggests a path to windows ten times larger.\"The potential of getting a frontier LLM with a 10 or 20 million token context window is pretty exciting,\" Emanuel wrote. \"You could basically cram all of a company&#x27;s key internal documents into a prompt preamble and cache this with OpenAI and then just add your specific query or prompt on top of that and not have to deal with search tools and still have it be fast and cost-effective.\"The researchers explicitly frame their work in terms of context compression for language models. \"Through DeepSeek-OCR, we demonstrate that vision-text compression can achieve significant token reduction (7-20×) for different historical context stages, offering a promising direction for addressing long-context challenges in large language models,\" they wrote.The paper includes a speculative but intriguing diagram illustrating how the approach could implement memory decay mechanisms similar to human cognition. Older conversation rounds could be progressively downsampled to lower resolutions, consuming fewer tokens while maintaining key information — a form of computational forgetting that mirrors biological memory.How visual processing could eliminate the &#x27;ugly&#x27; tokenizer problemBeyond compression, Karpathy highlighted how the approach challenges fundamental assumptions about how language models should process text. Traditional tokenizers—the systems that break text into units for processing—have long been criticized for their complexity and limitations.\"I already ranted about how much I dislike the tokenizer,\" Karpathy wrote. \"Tokenizers are ugly, separate, not end-to-end stage. It &#x27;imports&#x27; all the ugliness of Unicode, byte encodings, it inherits a lot of historical baggage, security/jailbreak risk (e.g. continuation bytes). It makes two characters that look identical to the eye look as two completely different tokens internally in the network.\"Visual processing of text could eliminate these issues while enabling new capabilities. The approach naturally handles formatting information lost in pure text representations: bold text, colors, layout, embedded images. \"Input can now be processed with bidirectional attention easily and as default, not autoregressive attention - a lot more powerful,\" Karpathy noted.The implications resonate with human cognitive science. Emanuel drew a parallel to Hans Bethe, the renowned physicist who memorized vast amounts of reference data: \"Having vast amounts of task-specific knowledge in your working memory is extremely useful. This seems like a very clever and additive approach to potentially expanding that memory bank by 10x or more.\"The model&#x27;s training: 30 million PDF pages across 100 languagesThe model&#x27;s capabilities rest on an extensive training regimen using diverse data sources. DeepSeek collected 30 million PDF pages covering approximately 100 languages, with Chinese and English accounting for 25 million pages. The training data spans nine document types — academic papers, financial reports, textbooks, newspapers, handwritten notes, and others.Beyond document OCR, the training incorporated what the researchers call \"OCR 2.0\" data: 10 million synthetic charts, 5 million chemical formulas, and 1 million geometric figures. The model also received 20% general vision data for tasks like image captioning and object detection, plus 10% text-only data to maintain language capabilities.The training process employed pipeline parallelism across 160 Nvidia A100-40G GPUs (20 nodes with 8 GPUs each), with the vision encoder divided between two pipeline stages and the language model split across two others. \"For multimodal data, the training speed is 70B tokens/day,\" the researchers reported.Open source release accelerates research and raises competitive questionsTrue to DeepSeek&#x27;s pattern of open development, the company released the complete model weights, training code, and inference scripts on GitHub and Hugging Face. The GitHub repository gained over 4,000 stars within 24 hours of release, according to Dataconomy.The breakthrough raises questions about whether other AI labs have developed similar techniques but kept them proprietary. Emanuel speculated that Google&#x27;s Gemini models, which feature large context windows and strong OCR performance, might employ comparable approaches. \"For all we know, Google could have already figured out something like this, which could explain why Gemini has such a huge context size and is so good and fast at OCR tasks,\" Emanuel wrote.Google&#x27;s Gemini 2.5 Pro offers a 1-million-token context window, with plans to expand to 2 million, though the company has not publicly detailed the technical approaches enabling this capability. OpenAI&#x27;s GPT-5 supports 400,000 tokens, while Anthropic&#x27;s Claude 4.5 offers 200,000 tokens, with a 1-million-token window available in beta for eligible organizations.The unanswered question: Can AI reason over compressed visual tokens?While the compression results are impressive, researchers acknowledge important open questions. \"It&#x27;s not clear how exactly this interacts with the other downstream cognitive functioning of an LLM,\" Emanuel noted. \"Can the model reason as intelligently over those compressed visual tokens as it can using regular text tokens? Does it make the model less articulate by forcing it into a more vision-oriented modality?\"The DeepSeek paper focuses primarily on the compression-decompression capability, measured through OCR accuracy, rather than downstream reasoning performance. This leaves open whether language models could reason effectively over large contexts represented primarily as compressed visual tokens.The researchers acknowledge their work represents \"an initial exploration into the boundaries of vision-text compression.\" They note that \"OCR alone is insufficient to fully validate true context optical compression\" and plan future work including \"digital-optical text interleaved pretraining, needle-in-a-haystack testing, and other evaluations.\"DeepSeek has established a pattern of achieving competitive results with dramatically lower computational resources than Western AI labs. The company&#x27;s earlier DeepSeek-V3 model reportedly cost just $5.6 million to train—though this figure represents only the final training run and excludes R&D and infrastructure costs—compared to hundreds of millions for comparable models from OpenAI and Anthropic.Industry analysts have questioned the $5.6 million figure, with some estimates placing the company&#x27;s total infrastructure and operational costs closer to $1.3 billion, though still lower than American competitors&#x27; spending.The bigger picture: Should language models process text as images?DeepSeek-OCR poses a fundamental question for AI development: should language models process text as text, or as images of text? The research demonstrates that, at least for compression purposes, visual representation offers significant advantages. Whether this translates to effective reasoning over vast contexts remains to be determined.\"From another perspective, optical contexts compression still offers substantial room for research and improvement, representing a promising new direction,\" the researchers concluded in their paper.For the AI industry, the work adds another dimension to the race for longer context windows — a competition that has intensified as language models are applied to increasingly complex tasks requiring vast amounts of information. The open-source release ensures the technique will be widely explored, tested, and potentially integrated into future AI systems.As Karpathy framed the deeper implication: \"OCR is just one of many useful vision -> text tasks. And text -> text tasks can be made to be vision ->text tasks. Not vice versa.\" In other words, the path forward for AI might not run through better tokenizers — it might bypass text tokens altogether.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5e39eq2QQIBDorTJB70Tw8/4a8d11981b981c2e3cf3b504304d424c/nuneybits_Vector_art_of_whale_surfing_data_streams_932353ff-5fc4-4cc9-bb53-0b9658f59281.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/googles-new-vibe-coding-ai-studio-experience-lets-anyone-build-deploy-apps",
          "published_at": "Tue, 21 Oct 2025 17:45:00 GMT",
          "title": "Google's new vibe coding AI Studio experience lets anyone build, deploy apps live in minutes",
          "standfirst": "Google AI Studio has gotten a big vibe coding upgrade with a new interface, buttons, suggestions and community features that allow anyone with an idea for an app — even complete novices, laypeople, or non-developers like yours truly — to bring it into existence and deploy it live, on the web, for anyone to use, within minutes.The updated Build tab is available now at ai.studio/build, and it’s free to start. Users can experiment with building applications without needing to enter payment information upfront, though certain advanced features like Veo 3.1 and Cloud Run deployment require a paid API key.The new features appear to me to make Google&#x27;s AI models and offerings even more competitive, perhaps preferred, for many general users to dedicated AI startup rivals like Anthropic&#x27;s Claude Code and OpenAI&#x27;s Codex, respectively, two \"vibe coding\" focused products that are beloved by developers — but seem to have a higher barrier to entry or may require more technical know-how.A Fresh Start: Redesigned Build ModeThe updated Build tab serves as the entry point to vibe coding. It introduces a new layout and workflow where users can select from Google’s suite of AI models and features to power their applications. The default is Gemini 2.5 Pro, which is great for most cases.Once selections are made, users simply describe what they want to build, and the system automatically assembles the necessary components using Gemini’s APIs.This mode supports mixing capabilities like Nano Banana (a lightweight AI model), Veo (for video understanding), Imagine (for image generation), Flashlight (for performance-optimized inference), and Google Search.Patrick Löber, Developer Relations at Google DeepMind, highlighted that the experience is meant to help users “supercharge your apps with AI” using a simple prompt-to-app pipeline.In a video demo he posted on X and LinedIn, he showed how just a few clicks led to the automatic generation of a garden planning assistant app, complete with layouts, visuals, and a conversational interface.From Prompt to Production: Building and Editing in Real TimeOnce an app is generated, users land in a fully interactive editor. On the left, there’s a traditional code-assist interface where developers can chat with the AI model for help or suggestions. On the right, a code editor displays the full source of the app.Each component—such as React entry points, API calls, or styling files—can be edited directly. Tooltips help users understand what each file does, which is especially useful for those less familiar with TypeScript or frontend frameworks.Apps can be saved to GitHub, downloaded locally, or shared directly. Deployment is possible within the Studio environment or via Cloud Run if advanced scaling or hosting is needed.Inspiration on Demand: The ‘I’m Feeling Lucky’ ButtonOne standout feature in this update is the “I’m Feeling Lucky” button. Designed for users who need a creative jumpstart, it generates randomized app concepts and configures the app setup accordingly. Each press yields a different idea, complete with suggested AI features and components.Examples produced during demos include:An interactive map-based chatbot powered by Google Search and conversational AI.A dream garden designer using image generation and advanced planning tools.A trivia game app with an AI host whose personality users can define, integrating both Imagine and Flashlight with Gemini 2.5 Pro for conversation and reasoning.Logan Kilpatrick, Lead of Product for Google AI Studio and Gemini AI, noted in a demo video of his own that this feature encourages discovery and experimentation. “You get some really, really cool, different experiences,” he said, emphasizing its role in helping users find novel ideas quickly.Hands-On Test: From Prompt to App in 65 SecondsTo test the new workflow, I prompted Gemini with:A randomized dice rolling web application where the user can select between common dice sizes (6 sides, 10 sides, etc) and then see an animated die rolling and choose the color of their die as well.Within 65 seconds (just over a minute) AI Studio returned a fully working web app featuring:Dice size selector (d4, d6, d8, d10, d12, d20)Color customization options for the dieAnimated rolling effect with randomized resultsClean, modern UI built with React, TypeScript, and Tailwind CSSThe platform also generated a complete set of structured files, including App.tsx, constants.ts, and separate components for dice logic and controls. After generation, it was easy to iterate: adding sound effects for each interaction (rolling, choosing a die, changing color) required only a single follow-up prompt to the built-in assistant. This was also suggested by Gemini, too, by the way. From there, the app can be previewed live or exported using built-in controls to:Save to GitHubDownload the full codebaseCopy the project for remixingDeploy via integrated toolsMy brief, hands-on test showed just how quickly even small utility apps can go from idea to interactive prototype—without leaving the browser or writing boilerplate code manually.AI-Suggested Enhancements and Feature RefinementIn addition to code generation, Google AI Studio now offers context-aware feature suggestions. These recommendations, generated by Gemini’s Flashlight capability, analyze the current app and propose relevant improvements.In one example, the system suggested implementing a feature that displays the history of previously generated images in an image studio tab. These iterative enhancements allow builders to expand app functionality over time without starting from scratch.Kilpatrick emphasized that users can continue to refine their projects as they go, combining both automatic generation and manual adjustments. “You can go in and continue to edit and sort of refine the experience that you want iteratively,” he said.Free to Start, Flexible to GrowThe new experience is available at no cost for users who want to experiment, prototype, or build lightweight apps. There’s no requirement to enter credit card information to begin using vibe coding.However, more powerful capabilities — such as using models like Veo 3.1 or deploying through Cloud Run — do require switching to a paid API key.This pricing structure is intended to lower the barrier to entry for experimentation while providing a clear path to scale when needed.Built for All Skill LevelsOne of the central goals of the vibe coding launch is to make AI app development accessible to more people. The system supports both high-level visual builders and low-level code editing, creating a workflow that works for developers across experience levels.Kilpatrick mentioned that while he’s more familiar with Python than TypeScript, he still found the editor useful because of the helpful file descriptions and intuitive layout. This focus on usability could make AI Studio a compelling option for developers exploring AI for the first time.More to Come: A Week of LaunchesThe launch of vibe coding is the first in a series of announcements expected throughout the week. While specific future features haven’t been revealed yet, both Kilpatrick and Löber hinted that additional updates are on the way.With this update, Google AI Studio positions itself as a flexible, user-friendly environment for building AI-powered applications—whether for fun, prototyping, or production deployment. The focus is clear: make the power of Gemini’s APIs accessible without unnecessary complexity.",
          "content": "Google AI Studio has gotten a big vibe coding upgrade with a new interface, buttons, suggestions and community features that allow anyone with an idea for an app — even complete novices, laypeople, or non-developers like yours truly — to bring it into existence and deploy it live, on the web, for anyone to use, within minutes.The updated Build tab is available now at ai.studio/build, and it’s free to start. Users can experiment with building applications without needing to enter payment information upfront, though certain advanced features like Veo 3.1 and Cloud Run deployment require a paid API key.The new features appear to me to make Google&#x27;s AI models and offerings even more competitive, perhaps preferred, for many general users to dedicated AI startup rivals like Anthropic&#x27;s Claude Code and OpenAI&#x27;s Codex, respectively, two \"vibe coding\" focused products that are beloved by developers — but seem to have a higher barrier to entry or may require more technical know-how.A Fresh Start: Redesigned Build ModeThe updated Build tab serves as the entry point to vibe coding. It introduces a new layout and workflow where users can select from Google’s suite of AI models and features to power their applications. The default is Gemini 2.5 Pro, which is great for most cases.Once selections are made, users simply describe what they want to build, and the system automatically assembles the necessary components using Gemini’s APIs.This mode supports mixing capabilities like Nano Banana (a lightweight AI model), Veo (for video understanding), Imagine (for image generation), Flashlight (for performance-optimized inference), and Google Search.Patrick Löber, Developer Relations at Google DeepMind, highlighted that the experience is meant to help users “supercharge your apps with AI” using a simple prompt-to-app pipeline.In a video demo he posted on X and LinedIn, he showed how just a few clicks led to the automatic generation of a garden planning assistant app, complete with layouts, visuals, and a conversational interface.From Prompt to Production: Building and Editing in Real TimeOnce an app is generated, users land in a fully interactive editor. On the left, there’s a traditional code-assist interface where developers can chat with the AI model for help or suggestions. On the right, a code editor displays the full source of the app.Each component—such as React entry points, API calls, or styling files—can be edited directly. Tooltips help users understand what each file does, which is especially useful for those less familiar with TypeScript or frontend frameworks.Apps can be saved to GitHub, downloaded locally, or shared directly. Deployment is possible within the Studio environment or via Cloud Run if advanced scaling or hosting is needed.Inspiration on Demand: The ‘I’m Feeling Lucky’ ButtonOne standout feature in this update is the “I’m Feeling Lucky” button. Designed for users who need a creative jumpstart, it generates randomized app concepts and configures the app setup accordingly. Each press yields a different idea, complete with suggested AI features and components.Examples produced during demos include:An interactive map-based chatbot powered by Google Search and conversational AI.A dream garden designer using image generation and advanced planning tools.A trivia game app with an AI host whose personality users can define, integrating both Imagine and Flashlight with Gemini 2.5 Pro for conversation and reasoning.Logan Kilpatrick, Lead of Product for Google AI Studio and Gemini AI, noted in a demo video of his own that this feature encourages discovery and experimentation. “You get some really, really cool, different experiences,” he said, emphasizing its role in helping users find novel ideas quickly.Hands-On Test: From Prompt to App in 65 SecondsTo test the new workflow, I prompted Gemini with:A randomized dice rolling web application where the user can select between common dice sizes (6 sides, 10 sides, etc) and then see an animated die rolling and choose the color of their die as well.Within 65 seconds (just over a minute) AI Studio returned a fully working web app featuring:Dice size selector (d4, d6, d8, d10, d12, d20)Color customization options for the dieAnimated rolling effect with randomized resultsClean, modern UI built with React, TypeScript, and Tailwind CSSThe platform also generated a complete set of structured files, including App.tsx, constants.ts, and separate components for dice logic and controls. After generation, it was easy to iterate: adding sound effects for each interaction (rolling, choosing a die, changing color) required only a single follow-up prompt to the built-in assistant. This was also suggested by Gemini, too, by the way. From there, the app can be previewed live or exported using built-in controls to:Save to GitHubDownload the full codebaseCopy the project for remixingDeploy via integrated toolsMy brief, hands-on test showed just how quickly even small utility apps can go from idea to interactive prototype—without leaving the browser or writing boilerplate code manually.AI-Suggested Enhancements and Feature RefinementIn addition to code generation, Google AI Studio now offers context-aware feature suggestions. These recommendations, generated by Gemini’s Flashlight capability, analyze the current app and propose relevant improvements.In one example, the system suggested implementing a feature that displays the history of previously generated images in an image studio tab. These iterative enhancements allow builders to expand app functionality over time without starting from scratch.Kilpatrick emphasized that users can continue to refine their projects as they go, combining both automatic generation and manual adjustments. “You can go in and continue to edit and sort of refine the experience that you want iteratively,” he said.Free to Start, Flexible to GrowThe new experience is available at no cost for users who want to experiment, prototype, or build lightweight apps. There’s no requirement to enter credit card information to begin using vibe coding.However, more powerful capabilities — such as using models like Veo 3.1 or deploying through Cloud Run — do require switching to a paid API key.This pricing structure is intended to lower the barrier to entry for experimentation while providing a clear path to scale when needed.Built for All Skill LevelsOne of the central goals of the vibe coding launch is to make AI app development accessible to more people. The system supports both high-level visual builders and low-level code editing, creating a workflow that works for developers across experience levels.Kilpatrick mentioned that while he’s more familiar with Python than TypeScript, he still found the editor useful because of the helpful file descriptions and intuitive layout. This focus on usability could make AI Studio a compelling option for developers exploring AI for the first time.More to Come: A Week of LaunchesThe launch of vibe coding is the first in a series of announcements expected throughout the week. While specific future features haven’t been revealed yet, both Kilpatrick and Löber hinted that additional updates are on the way.With this update, Google AI Studio positions itself as a flexible, user-friendly environment for building AI-powered applications—whether for fun, prototyping, or production deployment. The focus is clear: make the power of Gemini’s APIs accessible without unnecessary complexity.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4kXCoAPJEcNYeIiP3L6Oyd/e2ced747533b5cf5f7b84e9fc7578ace/cfr0z3n_fix_hand_--chaos_35_--ar_9151_--raw_--profile_h57q96c_u_79d5871e-80b7-4587-8fc5-cd2407d695ac.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openais-ai-powered-browser-chatgpt-atlas-launches-on-macos-today-170735742.html",
          "published_at": "Tue, 21 Oct 2025 17:07:35 +0000",
          "title": "OpenAI's AI-powered browser, ChatGPT Atlas, launches on macOS today",
          "standfirst": "OpenAI's long-rumored browser has a name, and you can try it out today — provided you're an Apple user. ChatGPT Atlas is available to download on macOS, with the company promising to bring it to Windows, Android and iOS soon. Atlas integrates ChatGPT directly within the browser interface, allowing users to engage with the chatbot while they're surfing the web — no need to jump between different tabs or copy and paste content. When you select a text field, an icon will appear that allows you to prompt ChatGPT. OpenAI demoed this feature in Gmail where an employee asked the chatbot to polish an email he was writing to a colleague. Naturally, a prompt bar will also appear when you open a new tab, and you can open a sidebar where you can converse with ChatGPT at any time. The more you use Atlas, the more ChatGPT will \"remember\" about your preferences. One of the benefits of this is that you'll be able to more easily filter through your search history. For instance, you can write \"re-open the shoes I looked at yesterday,\" and ChatGPT will know the specific website you want to look at again. Browser memories are optional, and if you decide to enable the feature, you can manage them through the settings menu, and just like any other browser, you can delete your history or go surf the web using an incognito mode. OpenAI also says it won't use the content users browse to train its future models. Atlas also includes an agent mode where ChatGPT can surf the web for you and complete tasks. The feature builds on the Operator tech debuted at the start of the year, and is currently available as a preview within the browser that Plus, Pro and Business accounts can try out. \"It can help you book reservations or flights or even just edit a document that you’re working on,” said Adam Fry, product lead for ChatGPT Search, during the livestream where OpenAI announced Atlas. \"Tabs are great but we haven't seen a lot of browser innovation since then,\" OpenAI CEO Sam Altman at the start of the livestream. “This is just a great browser all-around — it’s smooth, it’s quick, it’s really nice to use.” Rumors that OpenAI was working on its own web browser first surfaced in July. With today's announcement, the company joins an already competitive market. A number of companies, including Opera and Perplexity, released their own \"agentic\" browsers earlier this year. Of course, then there's also Google, which plans to integrate its Gemini AI assistant more deeply into Chrome, the world's most popular browser, over the coming months. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-ai-powered-browser-chatgpt-atlas-launches-on-macos-today-170735742.html?src=rss",
          "content": "OpenAI's long-rumored browser has a name, and you can try it out today — provided you're an Apple user. ChatGPT Atlas is available to download on macOS, with the company promising to bring it to Windows, Android and iOS soon. Atlas integrates ChatGPT directly within the browser interface, allowing users to engage with the chatbot while they're surfing the web — no need to jump between different tabs or copy and paste content. When you select a text field, an icon will appear that allows you to prompt ChatGPT. OpenAI demoed this feature in Gmail where an employee asked the chatbot to polish an email he was writing to a colleague. Naturally, a prompt bar will also appear when you open a new tab, and you can open a sidebar where you can converse with ChatGPT at any time. The more you use Atlas, the more ChatGPT will \"remember\" about your preferences. One of the benefits of this is that you'll be able to more easily filter through your search history. For instance, you can write \"re-open the shoes I looked at yesterday,\" and ChatGPT will know the specific website you want to look at again. Browser memories are optional, and if you decide to enable the feature, you can manage them through the settings menu, and just like any other browser, you can delete your history or go surf the web using an incognito mode. OpenAI also says it won't use the content users browse to train its future models. Atlas also includes an agent mode where ChatGPT can surf the web for you and complete tasks. The feature builds on the Operator tech debuted at the start of the year, and is currently available as a preview within the browser that Plus, Pro and Business accounts can try out. \"It can help you book reservations or flights or even just edit a document that you’re working on,” said Adam Fry, product lead for ChatGPT Search, during the livestream where OpenAI announced Atlas. \"Tabs are great but we haven't seen a lot of browser innovation since then,\" OpenAI CEO Sam Altman at the start of the livestream. “This is just a great browser all-around — it’s smooth, it’s quick, it’s really nice to use.” Rumors that OpenAI was working on its own web browser first surfaced in July. With today's announcement, the company joins an already competitive market. A number of companies, including Opera and Perplexity, released their own \"agentic\" browsers earlier this year. Of course, then there's also Google, which plans to integrate its Gemini AI assistant more deeply into Chrome, the world's most popular browser, over the coming months. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-ai-powered-browser-chatgpt-atlas-launches-on-macos-today-170735742.html?src=rss",
          "feed_position": 47
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/google-fi-will-start-using-ai-to-make-calls-sound-better-170025805.html",
          "published_at": "Tue, 21 Oct 2025 17:00:25 +0000",
          "title": "Google Fi will start using AI to make calls sound better",
          "standfirst": "Google just announced several updates for its digital telecom provider, Google Fi. It's introducing AI-enhanced audio for better sound quality during calls. The company says this will ensure \"optimized audio quality for every call, so you can confidently take calls from a windy park or busy cafe.\" This feature rolls out sometime in November. Google Fi is getting HD/HD+ calling, which should also improve the overall audio quality. The service will soon automatically connect to Wi-Fi when available, with the company touting \"seamless, secure switching.\" As for security, each call and text goes through a VPN. There's no extra cost for this service and it doesn't count against the pre-existing data allocation. The platform will also soon let users make calls and send texts from any web browser. This is coming in December and will feature a new interface with full RCS support, allowing folks to add hi-res photos and videos to message threads. Finally, Google is integrating Gemini into the platform to create an AI-powered billing summary. The company says this offers \"simple, easy explanations of all your billing statements.\" The feature has been in a beta for a while and Google says users have given it \"high positive sentiment.\" These tools are accompanied by a limited-time promo for new subscribers, amounting to 50 percent off for 15 months when bringing in a phone. The discount is only available for the Unlimited Premium and Unlimited Standard plans.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/google-fi-will-start-using-ai-to-make-calls-sound-better-170025805.html?src=rss",
          "content": "Google just announced several updates for its digital telecom provider, Google Fi. It's introducing AI-enhanced audio for better sound quality during calls. The company says this will ensure \"optimized audio quality for every call, so you can confidently take calls from a windy park or busy cafe.\" This feature rolls out sometime in November. Google Fi is getting HD/HD+ calling, which should also improve the overall audio quality. The service will soon automatically connect to Wi-Fi when available, with the company touting \"seamless, secure switching.\" As for security, each call and text goes through a VPN. There's no extra cost for this service and it doesn't count against the pre-existing data allocation. The platform will also soon let users make calls and send texts from any web browser. This is coming in December and will feature a new interface with full RCS support, allowing folks to add hi-res photos and videos to message threads. Finally, Google is integrating Gemini into the platform to create an AI-powered billing summary. The company says this offers \"simple, easy explanations of all your billing statements.\" The feature has been in a beta for a while and Google says users have given it \"high positive sentiment.\" These tools are accompanied by a limited-time promo for new subscribers, amounting to 50 percent off for 15 months when bringing in a phone. The discount is only available for the Unlimited Premium and Unlimited Standard plans.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/google-fi-will-start-using-ai-to-make-calls-sound-better-170025805.html?src=rss",
          "feed_position": 48
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/apple-macbook-pro-m5-14-inch-review-a-huge-graphics-upgrade-for-creators-and-gamers-170009179.html",
          "published_at": "Tue, 21 Oct 2025 17:00:09 +0000",
          "title": "Apple MacBook Pro M5 14-inch review: A huge graphics upgrade for creators and gamers",
          "standfirst": "There was no massive event announcing the M5 MacBook Pro, not even a short promotional video for social media. Instead, Apple dumped all of its new M5 devices on us with a few press releases, a clear sign that there's not much to celebrate this year. But while the new 14-inch MacBook Pro appears to be more of the same on the surface, it also features an impressive graphics upgrade that makes it a decent choice for gaming. And it retains everything I already love about the MacBook Pro: It's still a well-designed machine that's sturdy, fast and offers tons of battery life. What's new in the M5 MacBook Pro The star of the show is Apple's new M5 chip, which sports a 10-core CPU, 10-core GPU and 16 Neural Engine cores. While the company claims it's 20 percent faster than the M4 for multi-threaded applications, the biggest upgrade is the GPU, which is up to 60 percent faster when it comes to games and professional apps. The M4 was no slouch when it came to gaming and media rendering, but the M5 is a more tempting upgrade for anyone using an M1 MacBook Pro or older. Otherwise, it's like I said: more of the same. There's the 14.2-inch Liquid Retina XDR display which offers up to 1,000 nits of full-screen brightness and 1,600 nits of HDR, as well as ProMotion’s smooth 120Hz refresh rate. (Unfortunately, we’ll likely have to wait until next year for an OLED option.) The aluminum case is still rock solid, and the excellent keyboard and trackpad haven't changed a bit. Last year's 12MP Center Stage webcam also makes a return, along with the superb six-speaker sound system. The port situation is also solid. On top of the MagSafe 3 charging connection, there are three Thunderbolt 4 USB-C ports, a full-sized SDXC card reader, HDMI and a headphone jack. (It would be nice to see a gigabit Ethernet port though. That's the one accessory I still regularly connect to almost every laptop.) Devindra Hardawar for Engadget In use: The best gets even better Before I get to the benchmarks and other performance metrics, it's worth pointing out just how pleasant the 14-inch MacBook is to use. Its aluminum frame is smooth to the touch, its screen is bright enough to use in direct sunlight and it always feels blazing fast. While its 3.4-pound frame is noticeably heavier than the 2.7-pound MacBook Air, it's still easy to travel with. And you can certainly tell that the additional weight translates into raw power, especially as you start to stress the MacBook Pro and hear its fans gently spin up. While the MacBook Air is built to be as thin as possible, the MacBook Pro is built to get work done (and look good while doing so). Based on my testing with popular benchmarks and a few games, the M5 MacBook Pro is noticeably faster than the M4 model in tasks that rely on the GPU and NPU. Otherwise, though, it's hard to tell a difference when it comes to basic tasks like booting into macOS, browsing the web and dealing with email. My review unit was equipped with 32GB of RAM, so it had a bit more breathing room than the base model with 16GB of memory. (Pro tip: If you're planning to keep the MacBook Pro for four years or more, it makes sense to get at least 32GB of RAM. You can't upgrade the memory down the line like older laptops, since it's baked directly into the M5 chip.) Computer Geekbench 6 Geekbench 6 GPU Cinebench 2024 Apple MacBook Pro 14-inch (M5, 2025) 4,310/18,003 48,840 197/1,034 | GPU: 6,143 Apple MacBook Pro 14-inch (M4, 2024) 3,797/14,571 37,869 172/979 GPU: 3,770 Apple MacBook Pro 16-inch (M4 Pro, 2024) 3,925/22,456 70,197 178/1,689 GPU 9,295 Apple MacBook Pro 16-inch (M3 Max, 2024) 3,202/21,312 92,344 143/1,686 GPU 13,182 In Geekbench 6, the M5 MacBook Pro was around 500 points faster than the M4 model in single-threaded tasks, and nearly 3,500 points faster for complex multi-threaded work like video rendering. Thanks to the M5's new graphics hardware, it also tested far better in the Geekbench 6 GPU test, reaching around 11,00 points faster than the M4. I noticed a similar result in Cinebench 2024: The M5 MacBook Pro's CPU scores were slightly better than before, but the GPU score was nearly twice as fast as the M4. For real-world gaming performance, I turned to Lies of P, which also surprised me with some major leaps. With the M4 MacBook Pro, I could only get a steady 60 fps with the highest graphics settings in 1080p. With this M5 model, I was able to play at the highest resolution (3024 by 1890) between 70 and 75 fps. It was even smoother as I scaled down the resolution: The MacBook Pro hit 85 to 95 fps in 1,440p and up to 140 fps in 1080p. Those results are in line with what I'd expect from a gaming notebook that costs well over $2,000, which is in line with the $2,200 retail cost of our review unit. Devindra Hardawar for Engadget I still wouldn't recommend a MacBook Pro for anyone who wants to play tons of games, but it's heartening to see Apple making progress on that front. There are more new AAA games hitting the app store, and the M-series chips are fast enough to run most of them well. But the M5 is the first time I'd consider Apple's hardware equivalent to a PC running a video card like NVIDIA's RTX 5070. The M5 MacBook Pro retains the impressive battery life from the previous model, reaching 34 hours and 30 minutes while looping an HD video. I could also use it for more than two full days of work with nothing much stressing the GPU. And once again, the MacBook Pro never feels very hot, even under an intensive workload. The fans are audible, but they don’t get as annoying as the helicopter-like fans from the old Intel MacBook Pros. Devindra Hardawar for Engadget Should you buy the M5 MacBook Pro? If you're looking for a powerful laptop that can handle most heavy-duty workloads, the MacBook Pro will certainly suit your needs. But the difficult choice now is deciding between this 14-inch M5 model, the existing M4 Pro and Max systems, or waiting a few months for the upcoming M5 Pro and M5 Max chips. If you're rendering video and 3D content all day, you're likely better off working with Pro and Max chips, but you'll have to wait several months to see the new M5 options. If you absolutely need a workhorse MacBook Pro today, you'll have to settle for the M4 Pro and M4 Max (which are still far faster than the base M5 chip). But for most creatives, the M5 MacBook Pro offers an impressive balance of power and portability.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apple-macbook-pro-m5-14-inch-review-a-huge-graphics-upgrade-for-creators-and-gamers-170009179.html?src=rss",
          "content": "There was no massive event announcing the M5 MacBook Pro, not even a short promotional video for social media. Instead, Apple dumped all of its new M5 devices on us with a few press releases, a clear sign that there's not much to celebrate this year. But while the new 14-inch MacBook Pro appears to be more of the same on the surface, it also features an impressive graphics upgrade that makes it a decent choice for gaming. And it retains everything I already love about the MacBook Pro: It's still a well-designed machine that's sturdy, fast and offers tons of battery life. What's new in the M5 MacBook Pro The star of the show is Apple's new M5 chip, which sports a 10-core CPU, 10-core GPU and 16 Neural Engine cores. While the company claims it's 20 percent faster than the M4 for multi-threaded applications, the biggest upgrade is the GPU, which is up to 60 percent faster when it comes to games and professional apps. The M4 was no slouch when it came to gaming and media rendering, but the M5 is a more tempting upgrade for anyone using an M1 MacBook Pro or older. Otherwise, it's like I said: more of the same. There's the 14.2-inch Liquid Retina XDR display which offers up to 1,000 nits of full-screen brightness and 1,600 nits of HDR, as well as ProMotion’s smooth 120Hz refresh rate. (Unfortunately, we’ll likely have to wait until next year for an OLED option.) The aluminum case is still rock solid, and the excellent keyboard and trackpad haven't changed a bit. Last year's 12MP Center Stage webcam also makes a return, along with the superb six-speaker sound system. The port situation is also solid. On top of the MagSafe 3 charging connection, there are three Thunderbolt 4 USB-C ports, a full-sized SDXC card reader, HDMI and a headphone jack. (It would be nice to see a gigabit Ethernet port though. That's the one accessory I still regularly connect to almost every laptop.) Devindra Hardawar for Engadget In use: The best gets even better Before I get to the benchmarks and other performance metrics, it's worth pointing out just how pleasant the 14-inch MacBook is to use. Its aluminum frame is smooth to the touch, its screen is bright enough to use in direct sunlight and it always feels blazing fast. While its 3.4-pound frame is noticeably heavier than the 2.7-pound MacBook Air, it's still easy to travel with. And you can certainly tell that the additional weight translates into raw power, especially as you start to stress the MacBook Pro and hear its fans gently spin up. While the MacBook Air is built to be as thin as possible, the MacBook Pro is built to get work done (and look good while doing so). Based on my testing with popular benchmarks and a few games, the M5 MacBook Pro is noticeably faster than the M4 model in tasks that rely on the GPU and NPU. Otherwise, though, it's hard to tell a difference when it comes to basic tasks like booting into macOS, browsing the web and dealing with email. My review unit was equipped with 32GB of RAM, so it had a bit more breathing room than the base model with 16GB of memory. (Pro tip: If you're planning to keep the MacBook Pro for four years or more, it makes sense to get at least 32GB of RAM. You can't upgrade the memory down the line like older laptops, since it's baked directly into the M5 chip.) Computer Geekbench 6 Geekbench 6 GPU Cinebench 2024 Apple MacBook Pro 14-inch (M5, 2025) 4,310/18,003 48,840 197/1,034 | GPU: 6,143 Apple MacBook Pro 14-inch (M4, 2024) 3,797/14,571 37,869 172/979 GPU: 3,770 Apple MacBook Pro 16-inch (M4 Pro, 2024) 3,925/22,456 70,197 178/1,689 GPU 9,295 Apple MacBook Pro 16-inch (M3 Max, 2024) 3,202/21,312 92,344 143/1,686 GPU 13,182 In Geekbench 6, the M5 MacBook Pro was around 500 points faster than the M4 model in single-threaded tasks, and nearly 3,500 points faster for complex multi-threaded work like video rendering. Thanks to the M5's new graphics hardware, it also tested far better in the Geekbench 6 GPU test, reaching around 11,00 points faster than the M4. I noticed a similar result in Cinebench 2024: The M5 MacBook Pro's CPU scores were slightly better than before, but the GPU score was nearly twice as fast as the M4. For real-world gaming performance, I turned to Lies of P, which also surprised me with some major leaps. With the M4 MacBook Pro, I could only get a steady 60 fps with the highest graphics settings in 1080p. With this M5 model, I was able to play at the highest resolution (3024 by 1890) between 70 and 75 fps. It was even smoother as I scaled down the resolution: The MacBook Pro hit 85 to 95 fps in 1,440p and up to 140 fps in 1080p. Those results are in line with what I'd expect from a gaming notebook that costs well over $2,000, which is in line with the $2,200 retail cost of our review unit. Devindra Hardawar for Engadget I still wouldn't recommend a MacBook Pro for anyone who wants to play tons of games, but it's heartening to see Apple making progress on that front. There are more new AAA games hitting the app store, and the M-series chips are fast enough to run most of them well. But the M5 is the first time I'd consider Apple's hardware equivalent to a PC running a video card like NVIDIA's RTX 5070. The M5 MacBook Pro retains the impressive battery life from the previous model, reaching 34 hours and 30 minutes while looping an HD video. I could also use it for more than two full days of work with nothing much stressing the GPU. And once again, the MacBook Pro never feels very hot, even under an intensive workload. The fans are audible, but they don’t get as annoying as the helicopter-like fans from the old Intel MacBook Pros. Devindra Hardawar for Engadget Should you buy the M5 MacBook Pro? If you're looking for a powerful laptop that can handle most heavy-duty workloads, the MacBook Pro will certainly suit your needs. But the difficult choice now is deciding between this 14-inch M5 model, the existing M4 Pro and Max systems, or waiting a few months for the upcoming M5 Pro and M5 Max chips. If you're rendering video and 3D content all day, you're likely better off working with Pro and Max chips, but you'll have to wait several months to see the new M5 options. If you absolutely need a workhorse MacBook Pro today, you'll have to settle for the M4 Pro and M4 Max (which are still far faster than the base M5 chip). But for most creatives, the M5 MacBook Pro offers an impressive balance of power and portability.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apple-macbook-pro-m5-14-inch-review-a-huge-graphics-upgrade-for-creators-and-gamers-170009179.html?src=rss",
          "feed_position": 49,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/01d16580-aded-11f0-a7fe-9a2d2eb17ce5"
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c61cba10-afdd-11f0-9fff-ba497027a57e",
      "popularity_score": 2019.712701388889,
      "ai_summary": [
        "Samsung's Galaxy XR headset is an Android-based mixed reality device.",
        "The Galaxy XR is priced at $1,800, approximately half the Vision Pro's cost.",
        "The device features dual micro-OLED displays and hand gesture interaction.",
        "Limited XR content and lack of custom apps are current drawbacks.",
        "The headset may be more suitable for developers testing Android XR applications."
      ]
    },
    {
      "id": "cluster_7",
      "coverage": 2,
      "updated_at": "2025-10-23T06:39:15-04:00",
      "title": "OpenAI teases a string of updates for its AI-powered browser, ChatGPT Atlas",
      "neutral_headline": "OpenAI's ChatGPT Atlas Browser Receives Updates",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/805160/openai-chatgpt-atlas-updates",
          "published_at": "2025-10-23T06:39:15-04:00",
          "title": "OpenAI teases a string of updates for its AI-powered browser, ChatGPT Atlas",
          "standfirst": "Less than two days ago, OpenAI came out swinging in the fight for the future of the internet with the release of ChatGPT Atlas, an AI-powered web browser it hopes will topple Google Chrome. Adam Fry, OpenAI’s Atlas leader, says the team is already “heads down making it better” and teased a bunch of new [&#8230;]",
          "content": "Less than two days ago, OpenAI came out swinging in the fight for the future of the internet with the release of ChatGPT Atlas, an AI-powered web browser it hopes will topple Google Chrome. Adam Fry, OpenAI’s Atlas leader, says the team is already “heads down making it better” and teased a bunch of new features on the way. “Profiles coming!” Fry said. Tab groups and an opt-in ad blocker are also on their way in the near future. The features, common to many popular internet browsers, were included on a list of “post-launch fixes” for Atlas that Fry posted on X. Most of these should land “over the coming weeks,” he said, “though some may take a little longer.” The list includes a series of quality of life upgrades like an overflow bookmarks menu and a list of shortcuts. Changes are also on the way to the browser’s key AI features. This includes the agent — which is only available to ChatGPT Plus and Pro users for now and can take actions for you — and the Ask ChatGPT sidebar, which integrates the company’s flagship chatbot. The agent will be getting better response times, a more reliable “pause” function, and improved integration with products like Google Drive and cloud Excel, Fry said. The sidebar will be easier to use without leaving and let users pick different projects or AI models directly without having to navigate away. We&#039;ve received incredible feedback since launching our new browser, ChatGPT Atlas, yesterday. We&#039;re really focused on building the best product for all of you, and since launch, the team has been heads down making it better. In the spirit of transparency, these are the very… pic.twitter.com/UzQSqcxwpj&mdash; Adam Fry (@adamhfry) October 23, 2025 “If you have more suggestions for us, let us know!” Fry said. His responses to suggestions indicate OpenAI already has a solid prototype that would let users directly copy and insert text from the Ask ChatGPT sidebar. He also said it would be a good idea if the browser automatically reopened pinned tabs when closing and restarting. Fry said the team is also working on some “specific,” though unspecified, fixes for password manager 1Password. “There are other things we&#8217;re working on, but those may involve partners, and we&#8217;ve left those off this list.”",
          "feed_position": 0
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/openai-atlas-browser-chrome-agents-web-browsing/",
          "published_at": "Tue, 21 Oct 2025 19:06:41 +0000",
          "title": "OpenAI’s Atlas Browser Takes Direct Aim at Google Chrome",
          "standfirst": "The new ChatGPT-powered web browser is OpenAI’s boldest play yet to reinvent how people use the web.",
          "content": "The new ChatGPT-powered web browser is OpenAI’s boldest play yet to reinvent how people use the web.",
          "feed_position": 32,
          "image_url": "https://media.wired.com/photos/68f7cbcc6fc0dea09153cfd9/master/pass/business_openai_browser.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/68f7cbcc6fc0dea09153cfd9/master/pass/business_openai_browser.jpg",
      "popularity_score": 2019.3668680555556,
      "ai_summary": [
        "OpenAI is developing updates for its AI-powered web browser, ChatGPT Atlas.",
        "The browser aims to compete with Google Chrome in the web browser market.",
        "Adam Fry, OpenAI's Atlas leader, is working to improve the browser.",
        "The new browser is OpenAI's most ambitious project to date.",
        "The browser is designed to change how people use the internet."
      ]
    },
    {
      "id": "cluster_47",
      "coverage": 2,
      "updated_at": "2025-10-22T16:54:56-04:00",
      "title": "Amazon wants to buy ‘thousands’ of Rivian’s pedal-assist cargo bikes",
      "neutral_headline": "Amazon Plans to Purchase Rivian Pedal-Assist Cargo Bikes",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/804889/amazon-rivian-also-tmq-quad-ebike-delivery",
          "published_at": "2025-10-22T16:54:56-04:00",
          "title": "Amazon wants to buy ‘thousands’ of Rivian’s pedal-assist cargo bikes",
          "standfirst": "Amazon and Rivian are back together again. The e-commerce giant is collaborating with Rivian’s Also spinoff on a custom-designed, pedal-assisted, four-wheel cargo bike. The bike would likely be based on the TM-Q quad vehicle that was unveiled by Also today in San Francisco. Amazon says it wants to expand its fleet of micromobility vehicles with [&#8230;]",
          "content": "Amazon and Rivian are back together again. The e-commerce giant is collaborating with Rivian’s Also spinoff on a custom-designed, pedal-assisted, four-wheel cargo bike. The bike would likely be based on the TM-Q quad vehicle that was unveiled by Also today in San Francisco. Amazon says it wants to expand its fleet of micromobility vehicles with “thousands of quads” that it will deploy across Europe and the US. The deal signals the next phase in the partnership between Amazon and Rivian, which worked together on the EDV electric van for many years. For several years, Rivian’s van was exclusive to Amazon. But after that exclusivity ended, Rivian said it would sell the van to any commercial fleet owner who was interested. “Micromobility solutions like pedal-assist e-cargo quads allow us to quickly deliver to customers in dense, urban cities, while helping reduce traffic and noise,” said Emily Barber, Director of Amazon’s Global Fleet, in a statement. “Similar to our Rivian EDV partnership, working with ALSO provides an opportunity to continue to innovate in this space, building on our delivery logistics experience, paired with their advanced technology, safety, and performance features.” Amazon has been using electric cargo bikes for deliveries in cities across the US and Canada. The bikes are adapt at navigating dense cities where curb space is at a premium. The Also TM-Q shares many of the same features as the TM-B two-wheeled e-bike, including pedal-by-wire technology and removable battery that doubles as a mobile power bank.",
          "feed_position": 7
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/22/amazon-will-buy-thousands-of-pedal-assist-cargo-vehicles-from-rivian-spinoff-also/",
          "published_at": "Wed, 22 Oct 2025 18:09:41 +0000",
          "title": "Amazon will buy thousands of pedal-assist cargo vehicles from Rivian spinoff Also",
          "standfirst": "The pedal-assist cargo quad vehicles are narrow delivery vans that can operate in a bike lane.",
          "content": "The pedal-assist cargo quad vehicles are narrow delivery vans that can operate in a bike lane.",
          "feed_position": 7
        }
      ],
      "popularity_score": 2005.6282569444445,
      "ai_summary": [
        "Amazon intends to buy thousands of pedal-assist cargo vehicles from Rivian's spinoff.",
        "The cargo bikes will be custom-designed in collaboration with Rivian's Also.",
        "The vehicles are likely based on the TM-Q quad vehicle unveiled in San Francisco.",
        "Amazon aims to expand its micromobility vehicle fleet with these bikes.",
        "The pedal-assist cargo vehicles can operate within bike lanes."
      ]
    },
    {
      "id": "cluster_71",
      "coverage": 2,
      "updated_at": "Wed, 22 Oct 2025 18:12:50 +0000",
      "title": "Samsung Galaxy XR is the first Android XR headset, now on sale for $1,800",
      "neutral_headline": "Samsung Galaxy XR Headset Released for $1,800",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/10/samsung-galaxy-xr-is-the-first-android-xr-headset-now-on-sale-for-1800/",
          "published_at": "Wed, 22 Oct 2025 18:12:50 +0000",
          "title": "Samsung Galaxy XR is the first Android XR headset, now on sale for $1,800",
          "standfirst": "It may not be as spendy as the Vision Pro, but $1,800 is still a lot.",
          "content": "The era of Android virtual reality is here… again. Google’s first two attempts at making Android fit for your face didn’t work out, but the AI era and a partnership with Samsung have enabled a third attempt, and maybe the third time’s the charm. Samsung has unveiled the Galaxy XR headset, the first and currently only device running Google’s new Android XR platform. It’s available for pre-order today, but it will not come cheap. The headset, which doesn’t come with controllers, retails for $1,800. Galaxy XR is a fully enclosed headset with passthrough video. It looks similar to the Apple Vision Pro, right down to the battery pack at the end of a cable. It packs solid hardware, including 16GB of RAM, 256GB of storage, and a Snapdragon XR2+ Gen 2 processor. That’s a slightly newer version of the chip powering Meta’s Quest 3 headset, featuring six CPU cores and an Adreno GPU that supports up to dual 4.3K displays. The new headset has a pair of 3,552 x 3,840 Micro-OLED displays with a 109-degree field of view. That’s marginally more pixels than the Vision Pro and almost three times as many as the Quest 3. The displays can refresh at up to 90Hz, but the default is 72Hz to save power.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Samsung-Mobile-Galaxy-XR-Multimodal-AI-Android-XR-Opening-New-Worlds_main1.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/22/samsung-takes-on-apples-vision-pro-with-new-galaxy-xr-headset/",
          "published_at": "Wed, 22 Oct 2025 14:53:22 +0000",
          "title": "Samsung takes on Apple&#8217;s Vision Pro with new Galaxy XR headset",
          "standfirst": "Galaxy XR costs $1,800, nearly half the price of the Vision Pro.",
          "content": "Galaxy XR costs $1,800, nearly half the price of the Vision Pro.",
          "feed_position": 19
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Samsung-Mobile-Galaxy-XR-Multimodal-AI-Android-XR-Opening-New-Worlds_main1.jpg",
      "popularity_score": 2002.9265902777777,
      "ai_summary": [
        "Samsung's Galaxy XR is the first Android XR headset available for purchase.",
        "The Galaxy XR headset is priced at $1,800.",
        "The Galaxy XR is positioned as a competitor to Apple's Vision Pro.",
        "The Galaxy XR headset costs nearly half the price of the Vision Pro.",
        "The Vision Pro is priced at a higher cost than the Galaxy XR."
      ]
    },
    {
      "id": "cluster_3",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 11:00:08 +0000",
      "title": "We let OpenAI’s “Agent Mode” surf the web for us—here’s what happened",
      "neutral_headline": "We let OpenAI’s “Agent Mode” surf the web for us—here’s what happened",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2025/10/we-let-openais-agent-mode-surf-the-web-for-us-heres-what-happened/",
          "published_at": "Thu, 23 Oct 2025 11:00:08 +0000",
          "title": "We let OpenAI’s “Agent Mode” surf the web for us—here’s what happened",
          "standfirst": "From scanning emails to building fansites, Atlas can ably automate some web-based tasks.",
          "content": "On Tuesday, OpenAI announced Atlas, a new web browser with ChatGPT integration, to let you “chat with a page,” as the company puts it. But Atlas also goes beyond the usual LLM back-and-forth with Agent Mode, a “preview mode” feature the company says can “get work done for you” by clicking, scrolling, and reading through various tabs. “Agentic” AI is far from new, of course; OpenAI itself rolled out a preview of the web browsing Operator agent in January and introduced the more generalized “ChatGPT agent” in July. Still, prominently featuring this capability in a major product release like this—even in “preview mode”—signals a clear push to get this kind of system in front of end users. I wanted to put Atlas’ Agent Mode through its paces to see if it could really save me time in doing the kinds of tedious online tasks I plod through every day. In each case, I’ll outline a web-based problem, lay out the Agent Mode prompt I devised to try to solve it, and describe the results. My final evaluation will rank each task on a 10-point scale, with 10 being “did exactly what I wanted with no problems” and one being “complete failure.”Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2022302070-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2022302070-1152x648.jpg",
      "popularity_score": 367.7149236111111,
      "ai_summary": [
        "OpenAI's \"Agent Mode\" can perform web-based tasks.",
        "Agent Mode can scan emails and build fan sites.",
        "The feature automates some web-based tasks.",
        "The feature is part of the Atlas browser.",
        "The feature is designed to use the internet for users."
      ]
    },
    {
      "id": "cluster_37",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 22:35:41 +0000",
      "title": "Cache poisoning vulnerabilities found in 2 DNS resolving apps",
      "neutral_headline": "Cache Poisoning Vulnerabilities Found in DNS Apps",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/bind-warns-of-bugs-that-could-bring-dns-cache-attack-back-from-the-dead/",
          "published_at": "Wed, 22 Oct 2025 22:35:41 +0000",
          "title": "Cache poisoning vulnerabilities found in 2 DNS resolving apps",
          "standfirst": "At least one CVE could weaken defenses put in place following 2008 disclosure.",
          "content": "The makers of BIND, the Internet’s most widely used software for resolving domain names, are warning of two vulnerabilities that allow attackers to poison entire caches of results and send users to malicious destinations that are indistinguishable from the real ones. The vulnerabilities, tracked as CVE-2025-40778 and CVE-2025-40780, stem from a logic error and a weakness in generating pseudo-random numbers, respectively. They each carry a severity rating of 8.6. Separately, makers of the Domain Name System resolver software Unbound warned of similar vulnerabilities that were reported by the same researchers. The unbound vulnerability severity score is 5.6 Revisiting Kaminsky’s cache poisoning attack The vulnerabilities can be exploited to cause DNS resolvers located inside thousands of organizations to replace valid results for domain lookups with corrupted ones. The corrupted results would replace the IP addresses controlled by the domain name operator (for instance, 3.15.119.63 for arstechnica.com) with malicious ones controlled by the attacker. Patches for all three vulnerabilities became available on Wednesday.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/browser-security-threat-1152x627.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/browser-security-threat-1152x627.jpg",
      "popularity_score": 330.3074236111111,
      "ai_summary": [
        "Cache poisoning vulnerabilities were discovered in two DNS resolving applications.",
        "At least one CVE could weaken defenses.",
        "Defenses were put in place following a 2008 disclosure.",
        "The vulnerabilities could impact the security of DNS applications.",
        "The vulnerabilities could potentially compromise user data."
      ]
    },
    {
      "id": "cluster_40",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 21:42:47 +0000",
      "title": "Tesla profits fall 37% in Q3 despite healthy sales",
      "neutral_headline": "Tesla's Profits Decreased Despite Healthy Sales",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/tesla-profits-fall-37-in-q3-despite-healthy-sales/",
          "published_at": "Wed, 22 Oct 2025 21:42:47 +0000",
          "title": "Tesla profits fall 37% in Q3 despite healthy sales",
          "standfirst": "A loss of regulatory credits and increased expenses didn't help.",
          "content": "Tesla reported its financial results for the third quarter of 2025 this afternoon. Earlier this month, we learned that the electric vehicle manufacturer had a pretty good Q3 in terms of sales, which grew by 7.3 percent year over year and cleared out tens of thousands of cars from inventory in the process. However, that hasn’t translated into greater profitability. Even though revenues grew by 12 percent to $28 billion compared to the same period last year, Tesla’s operating expenses grew by 50 percent. As a result, its operating margin halved to just 5.8 percent. And so its profit for the quarter fell by 37 percent to $1.4 billion. Some growth in revenue came from its battery and solar division; this increased by 44 percent to $3.4 billion compared to Q3 2024. Services—including the Supercharger network, which is now open to an increasing number of other makes of EV—also grew, increasing by 25 percent to $3.4 billion. EV deliveries increased by 7 percent to 497,099, most of which were the Model 3 sedan and Model Y crossover. Automotive revenues grew slightly less, increasing 6 percent year over year to $21.2 billion.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/tesladown-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/tesladown-1024x648.jpg",
      "popularity_score": 322.42575694444446,
      "ai_summary": [
        "Tesla's profits fell by 37% in the third quarter.",
        "The decrease occurred despite strong sales figures.",
        "A loss of regulatory credits contributed to the profit decline.",
        "Increased expenses also impacted Tesla's profitability.",
        "The company's financial performance was affected by multiple factors."
      ]
    },
    {
      "id": "cluster_52",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 20:45:23 +0000",
      "title": "This may be the most bonkers tech job listing I’ve ever seen",
      "neutral_headline": "Unusual Tech Job Listing Includes Specific Requirements",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/the-tech-ceo-who-would-eat-dog-poop-if-it-means-winning/",
          "published_at": "Wed, 22 Oct 2025 20:45:23 +0000",
          "title": "This may be the most bonkers tech job listing I’ve ever seen",
          "standfirst": "Don't even apply if you're not a Tier 1 \"A-player.\"",
          "content": "Here’s a job pitch you don’t see often. What if, instead of “work-life balance,” you had no balance at all—your life was your work… and work happened seven days a week? Did I say days? I actually meant days and nights, because the job I’m talking about wants you to know that you will also work weekends and evenings, and that “it’s ok to send messages at 3am.”Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1149297973-1152x648-1761164087.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1149297973-1152x648-1761164087.jpg",
      "popularity_score": 314.46909027777775,
      "ai_summary": [
        "A tech job listing is described as unusual.",
        "The listing specifies requirements for applicants.",
        "The listing states that only Tier 1 \"A-players\" should apply.",
        "The listing may deter some potential candidates.",
        "The listing's requirements are considered extreme."
      ]
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 20:29:11 +0000",
      "title": "General Motors will integrate AI into its cars, plus new hands-free assist",
      "neutral_headline": "General Motors to Integrate AI in Vehicles",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/ai-and-hands-free-driving-are-coming-to-gms-vehicles/",
          "published_at": "Wed, 22 Oct 2025 20:29:11 +0000",
          "title": "General Motors will integrate AI into its cars, plus new hands-free assist",
          "standfirst": "Do we want LLMs in our cars? GM thinks we do.",
          "content": "GM provided flights from Detroit to New York City and accommodation so Ars could attend its tech event. Ars does not accept paid editorial content. General Motors held a preview event today to show the world what it’s working on. We’ve already seen some projects, like the further development of lithium manganese-rich battery technology or backup power for EVs that can power a home or support the power grid. The most significant new announcement is that Cadillac will offer an Escalade IQ with a so-called “Level 3” conditional automated driving system in 2028. GM is referring to it as a “hands off, eyes off” system and says it will integrate advanced digital mapping, use of lidar and other systems, and advanced machine learning to handle the driving duties in a controlled environment up to 80 mph (129 km/h). This means you can theoretically watch a movie from the driver’s seat while your car takes you down the highway to the airport. Over time, the system’s operation areas will expand to cover even more roads, making driving unnecessary in many situations—unless, of course, you like to drive.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1776398279-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1776398279-1152x648.jpg",
      "popularity_score": 313.19909027777777,
      "ai_summary": [
        "General Motors plans to integrate AI into its cars.",
        "The integration includes new hands-free assist features.",
        "The company is considering the use of LLMs in vehicles.",
        "The company is exploring the potential of AI in cars.",
        "The integration aims to enhance vehicle capabilities."
      ]
    },
    {
      "id": "cluster_57",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 20:23:35 +0000",
      "title": "Health plan enrollment period is set to be horrifying for everyone this year",
      "neutral_headline": "Health Plan Enrollment Period Expected to Be Difficult",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/health-care-costs-are-soaring-for-americans-and-2026-is-looking-grim/",
          "published_at": "Wed, 22 Oct 2025 20:23:35 +0000",
          "title": "Health plan enrollment period is set to be horrifying for everyone this year",
          "standfirst": "Some marketplace premiums could more than double. Employer-based plans are soaring.",
          "content": "Shock and dismay have already begun as Americans face next year’s health insurance costs—and it looks like everyone will be in for some grim numbers. So far, much of the attention has been on the stratospheric prices that Americans might see on plans they buy from Affordable Care Act marketplaces. Critical tax credits for those plans are set to expire at the end of the year, and, on top of that, insurers have proposed a median 18 percent price increase for 2026. With the higher prices and a loss of credits, some Americans could see their monthly premiums more than double. In an analysis last month, nonpartisan health policy group KFF estimated that, on average, ACA marketplace premiums would rise 114 percent, going from $888 in 2025 to $1,904 in 2026.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2018/09/GettyImages-148302547-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2018/09/GettyImages-148302547-1152x648.jpg",
      "popularity_score": 294.10575694444447,
      "ai_summary": [
        "The health plan enrollment period is expected to be challenging.",
        "Some marketplace premiums could more than double.",
        "Employer-based health plans are also experiencing rising costs.",
        "The enrollment period may be difficult for many individuals.",
        "Rising costs are a significant factor in the challenges."
      ]
    },
    {
      "id": "cluster_58",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 19:46:01 +0000",
      "title": "When sycophancy and bias meet medicine",
      "neutral_headline": "Bias and Sycophancy Impact Medical Research",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/when-sycophancy-and-bias-meet-medicine/",
          "published_at": "Wed, 22 Oct 2025 19:46:01 +0000",
          "title": "When sycophancy and bias meet medicine",
          "standfirst": "Biased, eager-to-please models threaten health research replicability and trust.",
          "content": "Once upon a time, two villagers visited the fabled Mullah Nasreddin. They hoped that the Sufi philosopher, famed for his acerbic wisdom, could mediate a dispute that had driven a wedge between them. Nasreddin listened patiently to the first villager’s version of the story and, upon its conclusion, exclaimed, “You are absolutely right!” The second villager then presented his case. After hearing him out, Nasreddin again responded, “You are absolutely right!” An observant bystander, confused by Nasreddin’s proclamations, interjected, “But Mullah, they can’t both be right.” Nasreddin paused, regarding the bystander for a moment before replying, “You are absolutely right, too!” In late May, the White House’s first “Make America Healthy Again” (MAHA) report was criticized for citing multiple research studies that did not exist. Fabricated citations like these are common in the outputs of generative artificial intelligence based on large language models, or LLMs. LLMs have presented plausible-sounding sources, catchy titles, or even false data to craft their conclusions. Here, the White House pushed back on the journalists who first broke the story before admitting to “minor citation errors.” It is ironic that fake citations were used to support a principal recommendation of the MAHA report: addressing the health research sector’s “replication crisis,” wherein scientists’ findings often cannot be reproduced by other independent teams.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2214872699-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2214872699-1152x648.jpg",
      "popularity_score": 274.47964583333334,
      "ai_summary": [
        "Biased models threaten health research replicability.",
        "Eager-to-please models also pose a threat.",
        "These models can undermine trust in research.",
        "The issues affect the reliability of medical studies.",
        "The problems can impact the validity of research."
      ]
    },
    {
      "id": "cluster_69",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 18:26:38 +0000",
      "title": "SpaceX disables 2,500 Starlink terminals allegedly used by Asian scam centers",
      "neutral_headline": "SpaceX Disables Starlink Terminals Used by Scammers",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/starlink-blocks-2500-dishes-allegedly-used-by-myanmars-notorious-scam-centers/",
          "published_at": "Wed, 22 Oct 2025 18:26:38 +0000",
          "title": "SpaceX disables 2,500 Starlink terminals allegedly used by Asian scam centers",
          "standfirst": "Starlink not allowed in Myanmar, but scammers reportedly use it \"on a huge scale.\"",
          "content": "SpaceX said it disabled over 2,500 Starlink terminals suspected of being used by scammers in Myanmar. Lauren Dreyer, vice president of Starlink business operations, described the action in an X post last night after reports that Myanmar’s military shut down a major scam operation. “SpaceX complies with local laws in all 150+ markets where Starlink is licensed to operate,” Dreyer wrote. “SpaceX continually works to identify violations of our Acceptable Use Policy and applicable law… On the rare occasion we identify a violation, we take appropriate action, including working with law enforcement agencies around the world. In Myanmar, for example, SpaceX proactively identified and disabled over 2,500 Starlink Kits in the vicinity of suspected ‘scam centers.'” Starlink is not licensed to operate in Myanmar. While Dreyer didn’t say how the terminals were disabled, it’s known that Starlink can disable individual terminals based on their ID numbers or use geofencing to block areas from receiving signals.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink-myanmar-1152x648-1761154369.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink-myanmar-1152x648-1761154369.jpg",
      "popularity_score": 274.15659027777775,
      "ai_summary": [
        "SpaceX disabled 2,500 Starlink terminals.",
        "The terminals were allegedly used by Asian scam centers.",
        "Starlink is not allowed in Myanmar.",
        "Scammers reportedly used Starlink \"on a huge scale.\"",
        "The action aims to combat fraudulent activities."
      ]
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 17:57:10 +0000",
      "title": "AWS outage reminds us why $2,449 Internet-dependent beds are a bad idea",
      "neutral_headline": "AWS Outage Highlights Issues with Internet-Dependent Beds",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/smart-beds-leave-sleepers-hot-and-bothered-during-aws-outage/",
          "published_at": "Wed, 22 Oct 2025 17:57:10 +0000",
          "title": "AWS outage reminds us why $2,449 Internet-dependent beds are a bad idea",
          "standfirst": "“Would be great if my bed wasn’t stuck in an inclined position ...\"",
          "content": "This week’s Amazon Web Services outage had some people waking up on the wrong side of the bed. A Domain Name System (DNS) resolution problem affected AWS cloud hosting, resulting in an outage that impacted more than 1,000 web-based products and services and millions of people. Perhaps one of the most avoidable breakdowns came via people’s beds. The reliance on the Internet for smart bed products from Eight Sleep resulted in people being awoken by beds locked into inclined positions and sweltering temperatures.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Eight-Sleep-Pod-5-Product-Full-System-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Eight-Sleep-Pod-5-Product-Full-System-1152x648.jpeg",
      "popularity_score": 245.66547916666667,
      "ai_summary": [
        "An AWS outage revealed issues with internet-dependent beds.",
        "The beds are priced at $2,449.",
        "The outage caused problems for users of the beds.",
        "One user's bed was stuck in an inclined position.",
        "The outage highlighted the reliance on internet connectivity."
      ]
    },
    {
      "id": "cluster_141",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 19:02:10 +0000",
      "title": "OpenAI looks for its “Google Chrome” moment with new Atlas web browser",
      "neutral_headline": "OpenAI looks for its “Google Chrome” moment with new Atlas web browser",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/openais-new-atlas-web-browser-wants-to-let-you-chat-with-a-page/",
          "published_at": "Tue, 21 Oct 2025 19:02:10 +0000",
          "title": "OpenAI looks for its “Google Chrome” moment with new Atlas web browser",
          "standfirst": "MacOS version launches today, includes Agent Mode preview to \"use the Internet for you.\"",
          "content": "Back in 2008, Google launched the Chrome browser to help better integrate its industry-leading search engine into the web-browsing experience. Today, OpenAI announced the Atlas browser that it hopes will do something similar for its ChatGPT large language model, answering the question “What if I could chat with a browser?” as the OpenAI team put it. OpenAI Founder and CEO Sam Altman said in a live stream announcement that Atlas will let users “chat with a page,” helping ChatGPT become a core way that users interact with the place where “a ton of work and life happens” online. “The way that we hope people will use the Internet in the future… is that the chat experience and a web browser can be a great analogue,” he said. The new browser is available for download now on macOS, and Altman promised Windows and mobile versions would be rolled out “as quick as we can.”Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo.jpg",
      "popularity_score": 160,
      "ai_summary": [
        "OpenAI is launching its Atlas web browser.",
        "The MacOS version launched today.",
        "The browser includes an Agent Mode preview.",
        "Agent Mode is designed to use the internet for users.",
        "The browser aims to compete with Google Chrome."
      ]
    },
    {
      "id": "cluster_145",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:46:42 +0000",
      "title": "YouTube’s likeness detection has arrived to help stop AI doppelgängers",
      "neutral_headline": "YouTube’s likeness detection has arrived to help stop AI doppelgängers",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/10/youtube-rolls-out-likeness-detection-to-help-creators-combat-ai-fakes/",
          "published_at": "Tue, 21 Oct 2025 18:46:42 +0000",
          "title": "YouTube’s likeness detection has arrived to help stop AI doppelgängers",
          "standfirst": "Likeness detection will flag possible AI fakes, but Google doesn't guarantee removal.",
          "content": "AI content has proliferated across the Internet over the past few years, but those early confabulations with mutated hands have evolved into synthetic images and videos that can be hard to differentiate from reality. Having helped to create this problem, Google has some responsibility to keep AI video in check on YouTube. To that end, the company has started rolling out its promised likeness detection system for creators. Google’s powerful and freely available AI models have helped fuel the rise of AI content, some of which is aimed at spreading misinformation and harassing individuals. Creators and influencers fear their brands could be tainted by a flood of AI videos that show them saying and doing things that never happened—even lawmakers are fretting about this. Google has placed a large bet on the value of AI content, so banning AI from YouTube, as many want, simply isn’t happening. Earlier this year, YouTube promised tools that would flag face-stealing AI content on the platform. The likeness detection tool, which is similar to the site’s copyright detection system, has now expanded beyond the initial small group of testers. YouTube says the first batch of eligible creators have been notified that they can use likeness detection, but interested parties will need to hand Google even more personal information to get protection from AI fakes.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "YouTube has introduced likeness detection.",
        "The feature aims to identify AI-generated content.",
        "The detection flags possible AI fakes.",
        "Google does not guarantee removal of flagged content.",
        "The feature helps combat AI doppelgängers."
      ]
    },
    {
      "id": "cluster_148",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:30:11 +0000",
      "title": "Satellite operators will soon join airlines in using Starlink in-flight Wi-Fi",
      "neutral_headline": "Satellite Operators to Use Starlink for In-Flight Wi-Fi",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/satellite-operators-will-soon-join-airlines-in-using-starlink-in-flight-wi-fi/",
          "published_at": "Tue, 21 Oct 2025 18:30:11 +0000",
          "title": "Satellite operators will soon join airlines in using Starlink in-flight Wi-Fi",
          "standfirst": "\"This starts to enable a whole new category of capabilities.\"",
          "content": "A little over a year ago, one of SpaceX’s Crew Dragon spacecraft flew a team of four private astronauts to orbit on a mission that made history with the first fully commercial spacewalk. Jared Isaacman and Sarah Gillis briefly floated out the door of the Dragon capsule, wearing SpaceX-built pressure suits to protect them against the hostile environment of space. It was the first time anyone ventured outside of their spacecraft without the involvement of a government space agency. The mission, named Polaris Dawn, made an important contribution in another area. It was the first space mission to connect with SpaceX’s Starlink broadband network, using laser links between the Dragon spacecraft and Starlink satellites to communicate with the Earth.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink_laser-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink_laser-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Satellite operators will soon use Starlink for in-flight Wi-Fi services for airlines.",
        "This integration will enable a new category of capabilities for satellite operators.",
        "The move represents a significant expansion of Starlink's service offerings.",
        "Airlines are already using Starlink for in-flight connectivity.",
        "This partnership will enhance the overall in-flight experience for passengers."
      ]
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 17:00:00 +0000",
      "title": "Google has a useful quantum algorithm that outperforms a supercomputer",
      "neutral_headline": "Google Develops Quantum Algorithm Outperforming Supercomputer",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/google-claims-to-have-quantum-advantage-with-a-potentially-useful-algorithm/",
          "published_at": "Wed, 22 Oct 2025 17:00:00 +0000",
          "title": "Google has a useful quantum algorithm that outperforms a supercomputer",
          "standfirst": "An approach it calls \"quantum echoes\" takes 13,000 times longer on a supercomputer.",
          "content": "A few years back, Google made waves when it claimed that some of its hardware had achieved quantum supremacy, performing operations that would be effectively impossible to simulate on a classical computer. That claim didn’t hold up especially well, as mathematicians later developed methods to help classical computers catch up, leading the company to repeat the work on an improved processor. While this back-and-forth was unfolding, the field became less focused on quantum supremacy and more on two additional measures of success. The first is quantum utility, in which a quantum computer performs computations that are useful in some practical way. The second is quantum advantage, in which a quantum system completes calculations in a fraction of the time it would take a typical computer. (IBM and a startup called Pasqual have published a useful discussion about what would be required to verifiably demonstrate a quantum advantage.) Today, Google and a large collection of academic collaborators are publishing a paper describing a computational approach that demonstrates a quantum advantage compared to current algorithms—and may actually help us achieve something useful.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GoogleQuantumAI_WillowChip_Closeup03-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GoogleQuantumAI_WillowChip_Closeup03-1152x648.jpg",
      "popularity_score": 146.7127013888889,
      "ai_summary": [
        "Google developed a quantum algorithm that outperforms a supercomputer.",
        "The algorithm uses an approach called \"quantum echoes.\"",
        "Quantum echoes take 13,000 times longer on a supercomputer.",
        "The algorithm demonstrates advancements in quantum computing capabilities.",
        "This development could lead to breakthroughs in various computational fields."
      ]
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 19:58:37 +0000",
      "title": "It’s troll vs. troll in Netflix’s Troll 2 trailer",
      "neutral_headline": "Netflix Releases Trailer for Troll 2 Film",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/troll-2-trailer-is-a-godzilla-inspired-monster-mash/",
          "published_at": "Tue, 21 Oct 2025 19:58:37 +0000",
          "title": "It’s troll vs. troll in Netflix’s Troll 2 trailer",
          "standfirst": "Norwegian director Roar Uthaug's sequel to his 2022 film Troll knows to not take itself too seriously.",
          "content": "Netflix’s international offerings include some entertaining Norwegian fare, such as the series Ragnarok (2020–2023), a surprisingly engaging reworking of Norse mythology brought into the 21st century that ran for three seasons. Another enjoyable offering was a 2022 monster movie called Troll, essentially a Norwegian take on the classic Godzilla formula. Netflix just dropped a trailer for the sequel, Troll 2, which looks to be very much in the same vein as its predecessor. (Spoilers for the first Troll movie below.) Don’t confuse the Netflix franchise with 2010’s Trollhunter, shot in the style of a found footage mockumentary. A group of college students sets off into the wilds of the fjordland to make a documentary about a suspected bear poacher named Hans. They discover that Hans is actually hunting down trolls and decide to document those endeavors instead, but soon realize they are very much out of their depth.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/troll1-1152x648-1761073850.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/troll1-1152x648-1761073850.jpg",
      "popularity_score": 145,
      "ai_summary": [
        "Netflix released a trailer for the film Troll 2, directed by Roar Uthaug.",
        "The film is a sequel to Uthaug's 2022 film, Troll.",
        "The trailer suggests the film will not take itself too seriously.",
        "The film is a Norwegian production.",
        "The release date is not specified in the provided information."
      ]
    },
    {
      "id": "cluster_134",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 20:08:42 +0000",
      "title": "FDA slows down on drug reviews, approvals amid Trump admin chaos",
      "neutral_headline": "FDA Slows Drug Reviews Amidst Administrative Issues",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/fda-slows-down-on-drug-reviews-approvals-amid-trump-admin-chaos/",
          "published_at": "Tue, 21 Oct 2025 20:08:42 +0000",
          "title": "FDA slows down on drug reviews, approvals amid Trump admin chaos",
          "standfirst": "The ongoing shutdown also means no new drug submissions are being accepted.",
          "content": "Amid the chaos of the Trump administration’s haphazard job cuts and a mass exodus of leadership, the Food and Drug Administration is experiencing a slowdown of drug reviews and approvals, according to an analysis reported by Stat News. An assessment of metrics by RBC Capital Markets analysts found that FDA drug approvals dropped 14 percentage points in the third quarter compared to the average of the six previous quarters—falling from an average of 87 percent to 73 percent this past quarter. In line with that finding, analysts noted that the delay rate in meeting deadlines for drug application reviews rose from an average of 4 percent to 11 percent. The FDA also rejected more applications than normal, going from a historical average of 10 percent to 15 percent in the third quarter. A growing number of rejections relate to problems at manufacturing plants, which in turn could suggest problems with the FDA’s inspection and auditing processes.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2019/05/GettyImages-496532228-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2019/05/GettyImages-496532228-1152x648.jpg",
      "popularity_score": 144,
      "ai_summary": [
        "The FDA is slowing down drug reviews and approvals.",
        "This slowdown is attributed to chaos within the Trump administration.",
        "The ongoing shutdown means no new drug submissions are being accepted.",
        "This situation could impact the availability of new medications.",
        "The FDA's actions are affecting the pharmaceutical industry."
      ]
    },
    {
      "id": "cluster_112",
      "coverage": 1,
      "updated_at": "Wed, 22 Oct 2025 13:39:57 +0000",
      "title": "Jaguar Land Rover looking at $2.5 billion price tag from crippling cyberattack",
      "neutral_headline": "Jaguar Land Rover Faces $2.5 Billion Cyberattack Cost",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/jaguar-land-rover-struggling-8-weeks-after-most-expensive-uk-cyberattack/",
          "published_at": "Wed, 22 Oct 2025 13:39:57 +0000",
          "title": "Jaguar Land Rover looking at $2.5 billion price tag from crippling cyberattack",
          "standfirst": "Incident was likely the most economically damaging cyber event in UK history.",
          "content": "The cyberattack on Jaguar Land Rover is estimated to have cost the UK at least £1.9 billion in what is likely to be “the most economically damaging cyber event” for the country. The month-long shutdown of internal systems and production at JLR affected over 5,000 British organisations, according to an analysis by Cyber Monitoring Centre, a non-profit organization that ranks the severity of cyber events in the UK. “This incident looks to have been by some distance, the single most financially damaging cyber event ever to hit the UK,” said Ciaran Martin, former head of the National Cyber Security Centre and chair of CMC’s technical committee.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/landroverline-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/landroverline-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Jaguar Land Rover is facing a $2.5 billion price tag from a cyberattack.",
        "The incident is likely the most economically damaging cyber event in UK history.",
        "The attack has caused significant financial losses for the company.",
        "The cyberattack highlights the vulnerability of automotive companies.",
        "The incident underscores the importance of cybersecurity measures."
      ]
    },
    {
      "id": "cluster_137",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 19:45:32 +0000",
      "title": "Elon Musk just declared war on NASA’s acting administrator, apparently",
      "neutral_headline": "Elon Musk Declares War on NASA's Acting Administrator",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/elon-musk-just-declared-war-on-nasas-acting-administrator-apparently/",
          "published_at": "Tue, 21 Oct 2025 19:45:32 +0000",
          "title": "Elon Musk just declared war on NASA’s acting administrator, apparently",
          "standfirst": "\"Sean said that NASA might benefit from being part of the Cabinet.\"",
          "content": "The clock just ticked past noon here in Houston, so it’s acceptable to have a drink, right? Because after another turbulent morning of closely following the rough-and-tumble contest to become the next NASA administrator, I sure could use one. What has happened now? Why, it was only SpaceX founder Elon Musk, who is NASA’s most important contractor, referring to the interim head of the space agency, Sean Duffy, as “Sean Dummy” and suggesting Duffy was trying to kill NASA. Musk later added, “The person responsible for America’s space program can’t have a 2 digit IQ.”Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/54441425446_25b87f0fd0_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/54441425446_25b87f0fd0_k-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Elon Musk has apparently declared war on NASA's acting administrator.",
        "The conflict stems from a statement made by the administrator.",
        "The administrator suggested NASA might benefit from being part of the Cabinet.",
        "Musk's reaction indicates a disagreement with the administrator's view.",
        "The situation reflects tensions between private and public space sectors."
      ]
    },
    {
      "id": "cluster_139",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 19:12:30 +0000",
      "title": "Upcoming iOS and macOS 26.1 update will let you fog up your Liquid Glass",
      "neutral_headline": "iOS and macOS Update Will Allow Fogging Liquid Glass",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/new-ios-and-macos-betas-add-tinted-toggle-to-tone-down-liquid-glass/",
          "published_at": "Tue, 21 Oct 2025 19:12:30 +0000",
          "title": "Upcoming iOS and macOS 26.1 update will let you fog up your Liquid Glass",
          "standfirst": "Apple backs down from some aspects of Liquid Glass, but not others.",
          "content": "Apple’s new Liquid Glass user interface design was one of the most noticeable and divisive features of its major software updates this year. It added additional fluidity and translucency throughout iOS, iPadOS, macOS, and Apple’s other operating systems, and as we noted in our reviews, the default settings weren’t always great for readability. The upcoming 26.1 update for all of those OSes is taking a step toward addressing some of the complaints, though not by changing things about the default look of Liquid Glass. Rather, the update is adding a new toggle that will let users choose between a Clear and Tinted look for Liquid Glass, with Clear representing the default look and Tinted cranking up the opacity and contrast. The default glassy look of the notifications in iOS 26. The Tinted toggle fogs up the glass, preserving a hint of translucency. Credit: Andrew Cunningham The toggle behaved less consistently in macOS 26.1, but here's an example of the glassy look in the Photos app. Credit: Andrew Cunningham And the same UI with the Tinted toggle turned on. Credit: Andrew Cunningham The new toggle adds a half-step between the default visual settings and the “reduce transparency” setting, which, aside from changing a bunch of other things about the look and feel of the operating system, is buried further down inside the Accessibility options. The Tinted toggle does make colors and vague shapes visible beneath the glass panes, preserving the general look of Liquid Glass while also erring on the side of contrast and visibility, where the “reduce transparency” setting is more of an all-or-nothing blunt instrument.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6225-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6225-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "The upcoming iOS and macOS 26.1 update will allow users to fog Liquid Glass.",
        "Apple is backing down from some aspects of Liquid Glass.",
        "The update will introduce changes to the Liquid Glass feature.",
        "The specific changes are not detailed in the provided information.",
        "The update will affect users of Apple devices."
      ]
    },
    {
      "id": "cluster_149",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:12:07 +0000",
      "title": "“Butt breathing” might soon be a real medical treatment",
      "neutral_headline": "Butt Breathing\" Could Become a Medical Treatment",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/butt-breathing-might-soon-be-a-real-medical-treatment/",
          "published_at": "Tue, 21 Oct 2025 18:12:07 +0000",
          "title": "“Butt breathing” might soon be a real medical treatment",
          "standfirst": "Ig Nobel-winning research could one day be used to treat people with blocked airways or clogged lungs.",
          "content": "Last year, a group of researchers won the 2024 Ig Nobel Prize in Physiology for discovering that many mammals are capable of breathing through their anus. But as with many Ig Nobel awards, there is a serious side to the seeming silliness. The same group has conducted a new study on the feasibility of adapting this method to treat people with blocked airways or clogged lungs, with promising results that bring rectal oxygen delivery one step closer to medical reality. As previously reported, this is perhaps one of the more unusual research developments to come out of the COVID-19 pandemic and its associated shortages of ventilators and artificial lungs to assist patients’ breathing and prevent respiratory failure. The Cincinnati Children’s Hospital Medical Center team took their inspiration from the humble loach, a freshwater bottom-dwelling fish found throughout Eurasia and northern Africa. The loach (along with sea cucumbers) employs intestinal breathing (i.e., through the anus) rather than gills to survive under hypoxic conditions, thanks to having lots of capillary vessels in its intestine. The technical term is enteral ventilation via anus (EVA). Would such a novel breathing method work in mammals? The team thought it might be possible and undertook experiments with mice and micro-pigs to test that hypothesis. They drew upon earlier research by Leland Clark, also of Cincinnati Children’s Hospital, who invented a perfluorocarbon liquid called Oxycyte as a possible form of artificial blood. That vision never materialized, although it did provide a handy plot point for the 1989 film The Abyss, in which a rat is able to “breathe” in a similar liquid.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/ignobel3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/ignobel3-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "\"Butt breathing\" research could become a real medical treatment.",
        "The research won an Ig Nobel prize.",
        "It could treat people with blocked airways or clogged lungs.",
        "The research has potential medical applications.",
        "The treatment's effectiveness is yet to be determined."
      ]
    }
  ]
}