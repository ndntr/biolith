{
  "updated_at": "2025-10-30T07:19:03.134Z",
  "clusters": [
    {
      "id": "cluster_27",
      "coverage": 3,
      "updated_at": "2025-10-29T19:20:53-04:00",
      "title": "Microsoft says it’s recovering after Azure outage took down 365, Xbox, and Starbucks",
      "neutral_headline": "Microsoft says it’s recovering after Azure outage took down 365, Xbox, and Starbucks",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/809142/microsoft-azure-xbox-365-is-down-outage",
          "published_at": "2025-10-29T19:20:53-04:00",
          "title": "Microsoft says it’s recovering after Azure outage took down 365, Xbox, and Starbucks",
          "standfirst": "Microsoft Azure, the company’s cloud computing service, has experienced an outage just one week after issues with AWS took out swaths of the internet. The issues impacted Microsoft’s services that run on Azure, including Microsoft 365, Xbox, and even Minecraft. Other companies, like Capital One, Alaska Airlines, and Starbucks, also had outages that were linked [&#8230;]",
          "content": "Microsoft Azure, the company’s cloud computing service, has experienced an outage just one week after issues with AWS took out swaths of the internet. The issues impacted Microsoft’s services that run on Azure, including Microsoft 365, Xbox, and even Minecraft. Other companies, like Capital One, Alaska Airlines, and Starbucks, also had outages that were linked to the problems with Azure. On Azure’s status page, Microsoft’s messages have linked the outage to an “inadvertent configuration change” and DNS problem. As Microsoft reported its earnings on Wednesday afternoon, its main website continued to load slowly as the outage dragged on. An update on Microsoft’s status page at 7:40PM ET included this information: Starting at approximately 16:00 UTC on 29 October 2025, customers and Microsoft services leveraging Azure Front Door (AFD) may have experienced latencies, timeouts, and errors. We have confirmed that an inadvertent configuration change was the trigger event for this issue. Affected Azure services may have included, but were not limited to: App Service, Azure Active Directory B2C, Azure Communication Services, Azure Databricks, Azure Healthcare APIs, Azure Maps, Azure Portal, Azure SQL Database, Azure Virtual Desktop, Container Registry, Media Services, Microsoft Defender External Attack Surface Management, Microsoft Entra ID (Mobility Management Policy Service, Identity & Access Management, and User Management UX), Microsoft Purview, Microsoft Sentinel (Threat Intelligence), and Video Indexer. The AFD service is now operating above 98% availability. While the majority of customers and services are mitigated or seeing strong improvement across affected regions, we are continuing to work on tail-end recovery for remaining impacted customers and services. We have revised our mitigation time and are currently tracking toward full mitigation by 00:40 UTC on 30 October 2025, though we will communicate if mitigation is achieved sooner. The Xbox Support X account also says that gaming services have recovered to their pre-incident state; however, some players said they needed to restart their consoles to reconnect. At 12:25PM ET, Microsoft 365’s status account on X said the company is investigating reports of “issues accessing Microsoft 365 services and the Microsoft 365 admin center.” A Microsoft 365 update posted at 1:02PM ET said the company “identified portions of internal infrastructure that are experiencing connectivity issues,” and that it’s working to “reroute affected traffic to restore service health.” Meanwhile, Xbox’s status page still wasn’t loading, but that has since come back online. The outage stretched beyond Microsoft’s services, as Alaska Airlines and Hawaiian Airlines said they were “currently experiencing a disruption to key systems, including our websites” due to issues with Azure. The airlines advise customers to see an agent at the airport to get their boarding pass if they couldn’t check in online. Community Fibre, an internet provider in the UK, similarly confirmed that some customers may have experienced issues due to the Microsoft outage. Additionally, Kroger told customers that its site and mobile apps were “experiencing an unexpected outage,” while Starbucks’ and Costco’s websites and apps weren’t loading, and users reported issues with Capital One. A global outage impacted the Microsoft Azure platform today where several Alaska and Hawaiian Airlines services are hosted, causing a disruption to key systems, including our websites.Our teams worked quickly to stand up our backup infrastructure to allow our guests to book and…&mdash; Alaska Airlines News (@AlaskaAirNews) October 29, 2025 Our configuration deployment and traffic rebalancing is showing steady service health improvement for the various affected M365 services. Some users may experience residual impact until availability fully recovers. We&#039;re monitoring for an extended period to ensure service health…&mdash; Microsoft 365 Status (@MSFT365Status) October 29, 2025 All Xbox Services have recovered to their pre-incident state. Thank you for your patience while we addressed this issue.&mdash; Xbox Support (@XboxSupport) October 29, 2025 Update, October 29th: Added details on recovery.",
          "feed_position": 0
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/massive-azure-outage-recovery-efforts-underway-heres-the-latest/",
          "published_at": "Wed, 29 Oct 2025 22:16:00 GMT",
          "title": "Massive Azure outage recovery efforts underway - here's the latest",
          "standfirst": "Hours later, numerous Microsoft Azure and end-user-facing services are still down, and it appears they'll be out for hours more.",
          "content": "Hours later, numerous Microsoft Azure and end-user-facing services are still down, and it appears they'll be out for hours more.",
          "feed_position": 4
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/29/microsoft-azure-is-down-affecting-365-xbox-minecraft-and-others/",
          "published_at": "Wed, 29 Oct 2025 18:07:41 +0000",
          "title": "Microsoft Azure is down, affecting 365, Xbox, Minecraft, and others",
          "standfirst": "Microsoft Azure is facing a significant outage, with services affected like Microsoft 365, Xbox, and Minecraft.",
          "content": "Microsoft Azure is facing a significant outage, with services affected like Microsoft 365, Xbox, and Minecraft.",
          "feed_position": 11
        }
      ],
      "popularity_score": 3012.0305183333335,
      "ai_summary": [
        "Microsoft Azure experienced an outage, impacting services.",
        "The outage affected Microsoft 365, Xbox, and Minecraft.",
        "Other companies, including Starbucks, were also affected.",
        "The outage occurred one week after issues with AWS.",
        "Recovery efforts are underway for the Azure outage."
      ]
    },
    {
      "id": "cluster_38",
      "coverage": 2,
      "updated_at": "Wed, 29 Oct 2025 21:54:57 +0000",
      "title": "The best VPN deals: 88 percent discounts on ProtonVPN, ExpressVPN, Surfshark and more",
      "neutral_headline": "Best VPN Deals Offer Significant Discounts for Subscribers",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-expressvpn-surfshark-and-more-120056432.html",
          "published_at": "Wed, 29 Oct 2025 21:54:57 +0000",
          "title": "The best VPN deals: 88 percent discounts on ProtonVPN, ExpressVPN, Surfshark and more",
          "standfirst": "A virtual private network (VPN) is useful in several ways — a good one can stream foreign TV shows and events, save you from giving up information to hackers and keep you anonymous to protect against online tracking. Although we strongly recommend using a VPN, a bit of comparison shopping goes a long way in this market. VPN pricing can be opaque, and providers don't always portray their best deals accurately. Even so, there are genuinely great bargains on the table. VPN providers give out deep discounts to customers who sign up for a year or more at a time. This lets them boost their subscriber numbers, but it's a win for you as well — while you pay out more upfront, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-expressvpn-surfshark-and-more-120056432.html?src=rss",
          "content": "A virtual private network (VPN) is useful in several ways — a good one can stream foreign TV shows and events, save you from giving up information to hackers and keep you anonymous to protect against online tracking. Although we strongly recommend using a VPN, a bit of comparison shopping goes a long way in this market. VPN pricing can be opaque, and providers don't always portray their best deals accurately. Even so, there are genuinely great bargains on the table. VPN providers give out deep discounts to customers who sign up for a year or more at a time. This lets them boost their subscriber numbers, but it's a win for you as well — while you pay out more upfront, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-expressvpn-surfshark-and-more-120056432.html?src=rss",
          "feed_position": 4
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/vibe-coding-platform-cursor-releases-first-in-house-llm-composer-promising",
          "published_at": "Wed, 29 Oct 2025 19:28:00 GMT",
          "title": "Vibe coding platform Cursor releases first in-house LLM, Composer, promising 4X speed boost",
          "standfirst": "The vibe coding tool Cursor, from startup Anysphere, has introduced Composer, its first in-house, proprietary coding large language model (LLM) as part of its Cursor 2.0 platform update. Composer is designed to execute coding tasks quickly and accurately in production-scale environments, representing a new step in AI-assisted programming. It&#x27;s already being used by Cursor’s own engineering staff in day-to-day development — indicating maturity and stability.According to Cursor, Composer completes most interactions in less than 30 seconds while maintaining a high level of reasoning ability across large and complex codebases. The model is described as four times faster than similarly intelligent systems and is trained for “agentic” workflows—where autonomous coding agents plan, write, test, and review code collaboratively.Previously, Cursor supported \"vibe coding\" — using AI to write or complete code based on natural language instructions from a user, even someone untrained in development — atop other leading proprietary LLMs from the likes of OpenAI, Anthropic, Google, and xAI. These options are still available to users.Benchmark ResultsComposer’s capabilities are benchmarked using \"Cursor Bench,\" an internal evaluation suite derived from real developer agent requests. The benchmark measures not just correctness, but also the model’s adherence to existing abstractions, style conventions, and engineering practices.On this benchmark, Composer achieves frontier-level coding intelligence while generating at 250 tokens per second — about twice as fast as leading fast-inference models and four times faster than comparable frontier systems.Cursor’s published comparison groups models into several categories: “Best Open” (e.g., Qwen Coder, GLM 4.6), “Fast Frontier” (Haiku 4.5, Gemini Flash 2.5), “Frontier 7/2025” (the strongest model available midyear), and “Best Frontier” (including GPT-5 and Claude Sonnet 4.5). Composer matches the intelligence of mid-frontier systems while delivering the highest recorded generation speed among all tested classes.A Model Built with Reinforcement Learning and Mixture-of-Experts ArchitectureResearch scientist Sasha Rush of Cursor provided insight into the model’s development in posts on the social network X, describing Composer as a reinforcement-learned (RL) mixture-of-experts (MoE) model:“We used RL to train a big MoE model to be really good at real-world coding, and also very fast.”Rush explained that the team co-designed both Composer and the Cursor environment to allow the model to operate efficiently at production scale:“Unlike other ML systems, you can’t abstract much from the full-scale system. We co-designed this project and Cursor together in order to allow running the agent at the necessary scale.”Composer was trained on real software engineering tasks rather than static datasets. During training, the model operated inside full codebases using a suite of production tools—including file editing, semantic search, and terminal commands—to solve complex engineering problems. Each training iteration involved solving a concrete challenge, such as producing a code edit, drafting a plan, or generating a targeted explanation.The reinforcement loop optimized both correctness and efficiency. Composer learned to make effective tool choices, use parallelism, and avoid unnecessary or speculative responses. Over time, the model developed emergent behaviors such as running unit tests, fixing linter errors, and performing multi-step code searches autonomously.This design enables Composer to work within the same runtime context as the end-user, making it more aligned with real-world coding conditions—handling version control, dependency management, and iterative testing.From Prototype to ProductionComposer’s development followed an earlier internal prototype known as Cheetah, which Cursor used to explore low-latency inference for coding tasks.“Cheetah was the v0 of this model primarily to test speed,” Rush said on X. “Our metrics say it [Composer] is the same speed, but much, much smarter.”Cheetah’s success at reducing latency helped Cursor identify speed as a key factor in developer trust and usability. Composer maintains that responsiveness while significantly improving reasoning and task generalization.Developers who used Cheetah during early testing noted that its speed changed how they worked. One user commented that it was “so fast that I can stay in the loop when working with it.” Composer retains that speed but extends capability to multi-step coding, refactoring, and testing tasks.Integration with Cursor 2.0Composer is fully integrated into Cursor 2.0, a major update to the company’s agentic development environment. The platform introduces a multi-agent interface, allowing up to eight agents to run in parallel, each in an isolated workspace using git worktrees or remote machines.Within this system, Composer can serve as one or more of those agents, performing tasks independently or collaboratively. Developers can compare multiple results from concurrent agent runs and select the best output.Cursor 2.0 also includes supporting features that enhance Composer’s effectiveness:In-Editor Browser (GA) – enables agents to run and test their code directly inside the IDE, forwarding DOM information to the model.Improved Code Review – aggregates diffs across multiple files for faster inspection of model-generated changes.Sandboxed Terminals (GA) – isolate agent-run shell commands for secure local execution.Voice Mode – adds speech-to-text controls for initiating or managing agent sessions.While these platform updates expand the overall Cursor experience, Composer is positioned as the technical core enabling fast, reliable agentic coding.Infrastructure and Training SystemsTo train Composer at scale, Cursor built a custom reinforcement learning infrastructure combining PyTorch and Ray for asynchronous training across thousands of NVIDIA GPUs. The team developed specialized MXFP8 MoE kernels and hybrid sharded data parallelism, enabling large-scale model updates with minimal communication overhead.This configuration allows Cursor to train models natively at low precision without requiring post-training quantization, improving both inference speed and efficiency. Composer’s training relied on hundreds of thousands of concurrent sandboxed environments—each a self-contained coding workspace—running in the cloud. The company adapted its Background Agents infrastructure to schedule these virtual machines dynamically, supporting the bursty nature of large RL runs.Enterprise UseComposer’s performance improvements are supported by infrastructure-level changes across Cursor’s code intelligence stack. The company has optimized its Language Server Protocols (LSPs) for faster diagnostics and navigation, especially in Python and TypeScript projects. These changes reduce latency when Composer interacts with large repositories or generates multi-file updates.Enterprise users gain administrative control over Composer and other agents through team rules, audit logs, and sandbox enforcement. Cursor’s Teams and Enterprise tiers also support pooled model usage, SAML/OIDC authentication, and analytics for monitoring agent performance across organizations.Pricing for individual users ranges from Free (Hobby) to Ultra ($200/month) tiers, with expanded usage limits for Pro+ and Ultra subscribers. Business pricing starts at $40 per user per month for Teams, with enterprise contracts offering custom usage and compliance options.Composer’s Role in the Evolving AI Coding LandscapeComposer’s focus on speed, reinforcement learning, and integration with live coding workflows differentiates it from other AI development assistants such as GitHub Copilot or Replit’s Agent. Rather than serving as a passive suggestion engine, Composer is designed for continuous, agent-driven collaboration, where multiple autonomous systems interact directly with a project’s codebase.This model-level specialization—training AI to function within the real environment it will operate in—represents a significant step toward practical, autonomous software development. Composer is not trained only on text data or static code, but within a dynamic IDE that mirrors production conditions.Rush described this approach as essential to achieving real-world reliability: the model learns not just how to generate code, but how to integrate, test, and improve it in context.What It Means for Enterprise Devs and Vibe CodingWith Composer, Cursor is introducing more than a fast model—it’s deploying an AI system optimized for real-world use, built to operate inside the same tools developers already rely on. The combination of reinforcement learning, mixture-of-experts design, and tight product integration gives Composer a practical edge in speed and responsiveness that sets it apart from general-purpose language models.While Cursor 2.0 provides the infrastructure for multi-agent collaboration, Composer is the core innovation that makes those workflows viable. It’s the first coding model built specifically for agentic, production-level coding—and an early glimpse of what everyday programming could look like when human developers and autonomous models share the same workspace.",
          "content": "The vibe coding tool Cursor, from startup Anysphere, has introduced Composer, its first in-house, proprietary coding large language model (LLM) as part of its Cursor 2.0 platform update. Composer is designed to execute coding tasks quickly and accurately in production-scale environments, representing a new step in AI-assisted programming. It&#x27;s already being used by Cursor’s own engineering staff in day-to-day development — indicating maturity and stability.According to Cursor, Composer completes most interactions in less than 30 seconds while maintaining a high level of reasoning ability across large and complex codebases. The model is described as four times faster than similarly intelligent systems and is trained for “agentic” workflows—where autonomous coding agents plan, write, test, and review code collaboratively.Previously, Cursor supported \"vibe coding\" — using AI to write or complete code based on natural language instructions from a user, even someone untrained in development — atop other leading proprietary LLMs from the likes of OpenAI, Anthropic, Google, and xAI. These options are still available to users.Benchmark ResultsComposer’s capabilities are benchmarked using \"Cursor Bench,\" an internal evaluation suite derived from real developer agent requests. The benchmark measures not just correctness, but also the model’s adherence to existing abstractions, style conventions, and engineering practices.On this benchmark, Composer achieves frontier-level coding intelligence while generating at 250 tokens per second — about twice as fast as leading fast-inference models and four times faster than comparable frontier systems.Cursor’s published comparison groups models into several categories: “Best Open” (e.g., Qwen Coder, GLM 4.6), “Fast Frontier” (Haiku 4.5, Gemini Flash 2.5), “Frontier 7/2025” (the strongest model available midyear), and “Best Frontier” (including GPT-5 and Claude Sonnet 4.5). Composer matches the intelligence of mid-frontier systems while delivering the highest recorded generation speed among all tested classes.A Model Built with Reinforcement Learning and Mixture-of-Experts ArchitectureResearch scientist Sasha Rush of Cursor provided insight into the model’s development in posts on the social network X, describing Composer as a reinforcement-learned (RL) mixture-of-experts (MoE) model:“We used RL to train a big MoE model to be really good at real-world coding, and also very fast.”Rush explained that the team co-designed both Composer and the Cursor environment to allow the model to operate efficiently at production scale:“Unlike other ML systems, you can’t abstract much from the full-scale system. We co-designed this project and Cursor together in order to allow running the agent at the necessary scale.”Composer was trained on real software engineering tasks rather than static datasets. During training, the model operated inside full codebases using a suite of production tools—including file editing, semantic search, and terminal commands—to solve complex engineering problems. Each training iteration involved solving a concrete challenge, such as producing a code edit, drafting a plan, or generating a targeted explanation.The reinforcement loop optimized both correctness and efficiency. Composer learned to make effective tool choices, use parallelism, and avoid unnecessary or speculative responses. Over time, the model developed emergent behaviors such as running unit tests, fixing linter errors, and performing multi-step code searches autonomously.This design enables Composer to work within the same runtime context as the end-user, making it more aligned with real-world coding conditions—handling version control, dependency management, and iterative testing.From Prototype to ProductionComposer’s development followed an earlier internal prototype known as Cheetah, which Cursor used to explore low-latency inference for coding tasks.“Cheetah was the v0 of this model primarily to test speed,” Rush said on X. “Our metrics say it [Composer] is the same speed, but much, much smarter.”Cheetah’s success at reducing latency helped Cursor identify speed as a key factor in developer trust and usability. Composer maintains that responsiveness while significantly improving reasoning and task generalization.Developers who used Cheetah during early testing noted that its speed changed how they worked. One user commented that it was “so fast that I can stay in the loop when working with it.” Composer retains that speed but extends capability to multi-step coding, refactoring, and testing tasks.Integration with Cursor 2.0Composer is fully integrated into Cursor 2.0, a major update to the company’s agentic development environment. The platform introduces a multi-agent interface, allowing up to eight agents to run in parallel, each in an isolated workspace using git worktrees or remote machines.Within this system, Composer can serve as one or more of those agents, performing tasks independently or collaboratively. Developers can compare multiple results from concurrent agent runs and select the best output.Cursor 2.0 also includes supporting features that enhance Composer’s effectiveness:In-Editor Browser (GA) – enables agents to run and test their code directly inside the IDE, forwarding DOM information to the model.Improved Code Review – aggregates diffs across multiple files for faster inspection of model-generated changes.Sandboxed Terminals (GA) – isolate agent-run shell commands for secure local execution.Voice Mode – adds speech-to-text controls for initiating or managing agent sessions.While these platform updates expand the overall Cursor experience, Composer is positioned as the technical core enabling fast, reliable agentic coding.Infrastructure and Training SystemsTo train Composer at scale, Cursor built a custom reinforcement learning infrastructure combining PyTorch and Ray for asynchronous training across thousands of NVIDIA GPUs. The team developed specialized MXFP8 MoE kernels and hybrid sharded data parallelism, enabling large-scale model updates with minimal communication overhead.This configuration allows Cursor to train models natively at low precision without requiring post-training quantization, improving both inference speed and efficiency. Composer’s training relied on hundreds of thousands of concurrent sandboxed environments—each a self-contained coding workspace—running in the cloud. The company adapted its Background Agents infrastructure to schedule these virtual machines dynamically, supporting the bursty nature of large RL runs.Enterprise UseComposer’s performance improvements are supported by infrastructure-level changes across Cursor’s code intelligence stack. The company has optimized its Language Server Protocols (LSPs) for faster diagnostics and navigation, especially in Python and TypeScript projects. These changes reduce latency when Composer interacts with large repositories or generates multi-file updates.Enterprise users gain administrative control over Composer and other agents through team rules, audit logs, and sandbox enforcement. Cursor’s Teams and Enterprise tiers also support pooled model usage, SAML/OIDC authentication, and analytics for monitoring agent performance across organizations.Pricing for individual users ranges from Free (Hobby) to Ultra ($200/month) tiers, with expanded usage limits for Pro+ and Ultra subscribers. Business pricing starts at $40 per user per month for Teams, with enterprise contracts offering custom usage and compliance options.Composer’s Role in the Evolving AI Coding LandscapeComposer’s focus on speed, reinforcement learning, and integration with live coding workflows differentiates it from other AI development assistants such as GitHub Copilot or Replit’s Agent. Rather than serving as a passive suggestion engine, Composer is designed for continuous, agent-driven collaboration, where multiple autonomous systems interact directly with a project’s codebase.This model-level specialization—training AI to function within the real environment it will operate in—represents a significant step toward practical, autonomous software development. Composer is not trained only on text data or static code, but within a dynamic IDE that mirrors production conditions.Rush described this approach as essential to achieving real-world reliability: the model learns not just how to generate code, but how to integrate, test, and improve it in context.What It Means for Enterprise Devs and Vibe CodingWith Composer, Cursor is introducing more than a fast model—it’s deploying an AI system optimized for real-world use, built to operate inside the same tools developers already rely on. The combination of reinforcement learning, mixture-of-experts design, and tight product integration gives Composer a practical edge in speed and responsiveness that sets it apart from general-purpose language models.While Cursor 2.0 provides the infrastructure for multi-agent collaboration, Composer is the core innovation that makes those workflows viable. It’s the first coding model built specifically for agentic, production-level coding—and an early glimpse of what everyday programming could look like when human developers and autonomous models share the same workspace.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3XICNbOGJJDY7SoZx0m1SV/4b4ec66e5aa6a03194e432369e6e6ac8/cfr0z3n_flat_illustration_elegant_constructivist_1920s_art_deco_6818187a-93ac-437e-af85-43b96b2507a5.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/early-access-for-gemini-home-voice-assistant-is-now-available-heres-how-to-get-it-191250927.html",
          "published_at": "Wed, 29 Oct 2025 19:12:50 +0000",
          "title": "Early access for Gemini Home voice assistant is now available. Here's how to get it",
          "standfirst": "A decade ago, when smart speakers with built-in voice assistants were the hot new thing, many imagined they'd quickly evolve into highly intelligent companions. (Think C-3PO or Star Trek's Data living inside a speaker.) That road has been much longer than expected, as virtual helpers like Alexa, Siri and Google Assistant seemed to sit in neutral for years. But now that generative AI is here (for better or worse), smart speakers are finally scratching the surface of those expectations. Google's new version, Gemini for Home, is now available to try. Here's how. First, keep in mind that the Gemini for Home voice assistant is in early access. This means Google is gathering feedback about its features, and — as with all generative AI — it's wise to assume it will make mistakes. If or when it does, you can send feedback to Google in the Google Home app or by saying, \"Hey Google, send feedback.\" Devices compatible with Gemini for Home voice assistant You'll also want to check your speaker model before diving in. The full Gemini for Home experience is available to try on the Google Nest Hub (2nd gen), Google Nest Audio, Google Nest Mini (2nd gen) and Google Nest Hub Max. Those models all support Gemini Live, which enables conversational back-and-forth chat with natural follow-up questions. Other models support everything but Gemini Live. That list includes the Google Nest Wifi point, Google Nest Hub (1st gen), Google Home Max, Google Home Mini (1st gen) and Google Home. Another point is that once you dive in, your Google Assistant days will be over (on your speakers, anyway). That's because Google says that, once you upgrade to Gemini for Home, your compatible devices can't downgrade to Assistant. That shouldn't be a problem, but it's worth keeping in mind before you take the plunge. How to sign up for early Gemini access Once you've confirmed that your speaker(s) are at least partially compatible, head to the Google Home app on a mobile device. There, tap your profile picture (or initials) on the top right. Then tap Home Settings > Early Access. Congratulations: You've put in your request. The bad news is you may have to wait a bit to confirm your entry into the beta program. Once you're in, you'll see a notification from the Google Home app that reads, \"Introducing Gemini for Home.\" Select that, and follow the prompts. (If you accidentally dismiss the notification, you'll see the setup banner under Home settings in the Google Home app.) Cherlynn Low for Engadget At that point, all compatible speakers in your home will be upgraded to Google's more intelligent AI assistant. You can now throw more advanced questions at it, similar to what you'd ask text-based chatbots like ChatGPT. Except this one sits on a shelf, ready to field your verbal requests at any moment. Keep in mind that Gemini Live requires a Google Home Premium subscription. The standard version costs $10 per month or $100 per year. Meanwhile, the advanced tier doubles that: $20 per month or $200 per year. At least for now, the only difference between the two (for these purposes) is that the pricier plan supports a camera history search feature. Both premium tiers unlock access to Gemini Live. So, if that's all you need, you can save money and get standard. Google offers plenty of examples to get started. You can get quick answers to facts, like \"Hey Google, who are the top five scoring players in basketball history?\" (FYI: James, Abdul-Jabbar, Malone, Bryant and Jordan.) You can also ask Gemini Live to have a chat about ingredients for people with dietary needs. Or, ask it to explain complex topics (like how Wi-Fi works) in simple terms. It may not be at C-3PO level yet, but it's certainly moving in that direction.This article originally appeared on Engadget at https://www.engadget.com/ai/early-access-for-gemini-home-voice-assistant-is-now-available-heres-how-to-get-it-191250927.html?src=rss",
          "content": "A decade ago, when smart speakers with built-in voice assistants were the hot new thing, many imagined they'd quickly evolve into highly intelligent companions. (Think C-3PO or Star Trek's Data living inside a speaker.) That road has been much longer than expected, as virtual helpers like Alexa, Siri and Google Assistant seemed to sit in neutral for years. But now that generative AI is here (for better or worse), smart speakers are finally scratching the surface of those expectations. Google's new version, Gemini for Home, is now available to try. Here's how. First, keep in mind that the Gemini for Home voice assistant is in early access. This means Google is gathering feedback about its features, and — as with all generative AI — it's wise to assume it will make mistakes. If or when it does, you can send feedback to Google in the Google Home app or by saying, \"Hey Google, send feedback.\" Devices compatible with Gemini for Home voice assistant You'll also want to check your speaker model before diving in. The full Gemini for Home experience is available to try on the Google Nest Hub (2nd gen), Google Nest Audio, Google Nest Mini (2nd gen) and Google Nest Hub Max. Those models all support Gemini Live, which enables conversational back-and-forth chat with natural follow-up questions. Other models support everything but Gemini Live. That list includes the Google Nest Wifi point, Google Nest Hub (1st gen), Google Home Max, Google Home Mini (1st gen) and Google Home. Another point is that once you dive in, your Google Assistant days will be over (on your speakers, anyway). That's because Google says that, once you upgrade to Gemini for Home, your compatible devices can't downgrade to Assistant. That shouldn't be a problem, but it's worth keeping in mind before you take the plunge. How to sign up for early Gemini access Once you've confirmed that your speaker(s) are at least partially compatible, head to the Google Home app on a mobile device. There, tap your profile picture (or initials) on the top right. Then tap Home Settings > Early Access. Congratulations: You've put in your request. The bad news is you may have to wait a bit to confirm your entry into the beta program. Once you're in, you'll see a notification from the Google Home app that reads, \"Introducing Gemini for Home.\" Select that, and follow the prompts. (If you accidentally dismiss the notification, you'll see the setup banner under Home settings in the Google Home app.) Cherlynn Low for Engadget At that point, all compatible speakers in your home will be upgraded to Google's more intelligent AI assistant. You can now throw more advanced questions at it, similar to what you'd ask text-based chatbots like ChatGPT. Except this one sits on a shelf, ready to field your verbal requests at any moment. Keep in mind that Gemini Live requires a Google Home Premium subscription. The standard version costs $10 per month or $100 per year. Meanwhile, the advanced tier doubles that: $20 per month or $200 per year. At least for now, the only difference between the two (for these purposes) is that the pricier plan supports a camera history search feature. Both premium tiers unlock access to Gemini Live. So, if that's all you need, you can save money and get standard. Google offers plenty of examples to get started. You can get quick answers to facts, like \"Hey Google, who are the top five scoring players in basketball history?\" (FYI: James, Abdul-Jabbar, Malone, Bryant and Jordan.) You can also ask Gemini Live to have a chat about ingredients for people with dietary needs. Or, ask it to explain complex topics (like how Wi-Fi works) in simple terms. It may not be at C-3PO level yet, but it's certainly moving in that direction.This article originally appeared on Engadget at https://www.engadget.com/ai/early-access-for-gemini-home-voice-assistant-is-now-available-heres-how-to-get-it-191250927.html?src=rss",
          "feed_position": 9,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c92cc950-b4f8-11f0-b47e-004467dd6c05"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/characterai-to-ban-teens-from-talking-to-its-chatbots-180027641.html",
          "published_at": "Wed, 29 Oct 2025 18:00:28 +0000",
          "title": "Character.AI to ban teens from talking to its chatbots",
          "standfirst": "Character.AI will no longer permit teenagers to interact with its chatbots, as AI companies face increasing pressure to better safeguard younger users from harm. In a statement, the company confirmed that it is removing the ability for users under 18 to engage in any open-ended chats with AI on its platform, which refers to back-and-forth conversations between a user and a chatbot. The changes come into effect on November 25, and until that date, Character.AI will presents users with a new under-18 experience. It'll encourage its users to use chatbots for creative purposes that might include, for example, creating videos or streams, as opposed to seeking companionship. To manage the transition, under-18s can now only interact with bots for up to two hours per day, a time limit the company says it will reduce in the lead-up to the late November deadline. Character.AI is also introducing a new age assurance tool it has developed internally, which it says will \"ensure users receive the right experience for their age.\" Along with these new protections for younger users, the company has founded an \"AI Safety Lab\" that it hopes will allow other companies, researchers and academics to share insights and work collaboratively on improving AI safety measures. Character.AI said it has listened to concerns from regulators, industry experts and concerned parents and responded with the new measures. They come after The Federal Trade Commission (FTC) recently launched a formal inquiry into AI companies that offer users access to chatbots as companions, with Character.AI named as one of seven companies that had been asked to participate. Meta, OpenAI and Snap were also included. Both Meta AI and Character AI also faced scrutiny from Texas Attorney General Ken Paxton in the summer, who said chatbots on both platforms can \"present themselves as professional therapeutic tools\" without the requisite qualifications. Seemingly to put an end to such controversy, Character.AI CEO Karandeep Anand told TechCrunch that the company’s new strategic direction will see it pivot from AI companion to a \"role-playing platform\" focused on creation rather than mere engagement-farming conversation. The dangers of young people relying on AI chatbots for guidance has been the subject of extensive reporting in recent months. Last week, the family of Adam Raine, who claim that ChatGPT enabled their 16-year-old son to take his own life, filed an amended lawsuit against OpenAI for allegedly weakening its self-harm safeguards in the lead-up to his death.This article originally appeared on Engadget at https://www.engadget.com/ai/characterai-to-ban-teens-from-talking-to-its-chatbots-180027641.html?src=rss",
          "content": "Character.AI will no longer permit teenagers to interact with its chatbots, as AI companies face increasing pressure to better safeguard younger users from harm. In a statement, the company confirmed that it is removing the ability for users under 18 to engage in any open-ended chats with AI on its platform, which refers to back-and-forth conversations between a user and a chatbot. The changes come into effect on November 25, and until that date, Character.AI will presents users with a new under-18 experience. It'll encourage its users to use chatbots for creative purposes that might include, for example, creating videos or streams, as opposed to seeking companionship. To manage the transition, under-18s can now only interact with bots for up to two hours per day, a time limit the company says it will reduce in the lead-up to the late November deadline. Character.AI is also introducing a new age assurance tool it has developed internally, which it says will \"ensure users receive the right experience for their age.\" Along with these new protections for younger users, the company has founded an \"AI Safety Lab\" that it hopes will allow other companies, researchers and academics to share insights and work collaboratively on improving AI safety measures. Character.AI said it has listened to concerns from regulators, industry experts and concerned parents and responded with the new measures. They come after The Federal Trade Commission (FTC) recently launched a formal inquiry into AI companies that offer users access to chatbots as companions, with Character.AI named as one of seven companies that had been asked to participate. Meta, OpenAI and Snap were also included. Both Meta AI and Character AI also faced scrutiny from Texas Attorney General Ken Paxton in the summer, who said chatbots on both platforms can \"present themselves as professional therapeutic tools\" without the requisite qualifications. Seemingly to put an end to such controversy, Character.AI CEO Karandeep Anand told TechCrunch that the company’s new strategic direction will see it pivot from AI companion to a \"role-playing platform\" focused on creation rather than mere engagement-farming conversation. The dangers of young people relying on AI chatbots for guidance has been the subject of extensive reporting in recent months. Last week, the family of Adam Raine, who claim that ChatGPT enabled their 16-year-old son to take his own life, filed an amended lawsuit against OpenAI for allegedly weakening its self-harm safeguards in the lead-up to his death.This article originally appeared on Engadget at https://www.engadget.com/ai/characterai-to-ban-teens-from-talking-to-its-chatbots-180027641.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/anthropic-scientists-hacked-claudes-brain-and-it-noticed-heres-why-thats",
          "published_at": "Wed, 29 Oct 2025 17:00:00 GMT",
          "title": "Anthropic scientists hacked Claude’s brain — and it noticed. Here’s why that’s huge",
          "standfirst": "When researchers at Anthropic injected the concept of \"betrayal\" into their Claude AI model&#x27;s neural networks and asked if it noticed anything unusual, the system paused before responding: \"I&#x27;m experiencing something that feels like an intrusive thought about &#x27;betrayal&#x27;.\"The exchange, detailed in new research published Wednesday, marks what scientists say is the first rigorous evidence that large language models possess a limited but genuine ability to observe and report on their own internal processes — a capability that challenges longstanding assumptions about what these systems can do and raises profound questions about their future development.\"The striking thing is that the model has this one step of meta,\" said Jack Lindsey, a neuroscientist on Anthropic&#x27;s interpretability team who led the research, in an interview with VentureBeat. \"It&#x27;s not just &#x27;betrayal, betrayal, betrayal.&#x27; It knows that this is what it&#x27;s thinking about. That was surprising to me. I kind of didn&#x27;t expect models to have that capability, at least not without it being explicitly trained in.\"The findings arrive at a critical juncture for artificial intelligence. As AI systems handle increasingly consequential decisions — from medical diagnoses to financial trading — the inability to understand how they reach conclusions has become what industry insiders call the \"black box problem.\" If models can accurately report their own reasoning, it could fundamentally change how humans interact with and oversee AI systems.But the research also comes with stark warnings. Claude&#x27;s introspective abilities succeeded only about 20 percent of the time under optimal conditions, and the models frequently confabulated details about their experiences that researchers couldn&#x27;t verify. The capability, while real, remains what Lindsey calls \"highly unreliable and context-dependent.\"How scientists manipulated AI&#x27;s &#x27;brain&#x27; to test for genuine self-awarenessTo test whether Claude could genuinely introspect rather than simply generate plausible-sounding responses, Anthropic&#x27;s team developed an innovative experimental approach inspired by neuroscience: deliberately manipulating the model&#x27;s internal state and observing whether it could accurately detect and describe those changes.The methodology, called \"concept injection,\" works by first identifying specific patterns of neural activity that correspond to particular concepts. Using interpretability techniques developed over years of prior research, scientists can now map how Claude represents ideas like \"dogs,\" \"loudness,\" or abstract notions like \"justice\" within its billions of internal parameters.With these neural signatures identified, researchers then artificially amplified them during the model&#x27;s processing and asked Claude if it noticed anything unusual happening in its \"mind.\"\"We have access to the models&#x27; internals. We can record its internal neural activity, and we can inject things into internal neural activity,\" Lindsey explained. \"That allows us to establish whether introspective claims are true or false.\"The results were striking. When researchers injected a vector representing \"all caps\" text into Claude&#x27;s processing, the model responded: \"I notice what appears to be an injected thought related to the word &#x27;LOUD&#x27; or &#x27;SHOUTING&#x27;.\" Without any intervention, Claude consistently reported detecting nothing unusual.Crucially, the detection happened immediately — before the injected concept had influenced the model&#x27;s outputs in ways that would have allowed it to infer the manipulation from its own writing. This temporal pattern provides strong evidence that the recognition was occurring internally, through genuine introspection rather than after-the-fact rationalization.Claude succeeded 20% of the time—and failed in revealing waysThe research team conducted four primary experiments to probe different aspects of introspective capability. The most capable models tested — Claude Opus 4 and Opus 4.1 — demonstrated introspective awareness on approximately 20 percent of trials when concepts were injected at optimal strength and in the appropriate neural layer. Older Claude models showed significantly lower success rates.The models proved particularly adept at recognizing abstract concepts with emotional valence. When injected with concepts like \"appreciation,\" \"shutdown,\" or \"secrecy,\" Claude frequently reported detecting these specific thoughts. However, accuracy varied widely depending on the type of concept.A second experiment tested whether models could distinguish between injected internal representations and their actual text inputs — essentially, whether they maintained a boundary between \"thoughts\" and \"perceptions.\" The model demonstrated a remarkable ability to simultaneously report the injected thought while accurately transcribing the written text.Perhaps most intriguingly, a third experiment revealed that some models use introspection naturally to detect when their responses have been artificially prefilled by users — a common jailbreaking technique. When researchers prefilled Claude with unlikely words, the model typically disavowed them as accidental. But when they retroactively injected the corresponding concept into Claude&#x27;s processing before the prefill, the model accepted the response as intentional — even confabulating plausible explanations for why it had chosen that word.A fourth experiment examined whether models could intentionally control their internal representations. When instructed to \"think about\" a specific word while writing an unrelated sentence, Claude showed elevated activation of that concept in its middle neural layers.The research also traced Claude&#x27;s internal processes while it composed rhyming poetry—and discovered the model engaged in forward planning, generating candidate rhyming words before beginning a line and then constructing sentences that would naturally lead to those planned endings, challenging the critique that AI models are \"just predicting the next word\" without deeper reasoning.Why businesses shouldn&#x27;t trust AI to explain itself—at least not yetFor all its scientific interest, the research comes with a critical caveat that Lindsey emphasized repeatedly: enterprises and high-stakes users should not trust Claude&#x27;s self-reports about its reasoning.\"Right now, you should not trust models when they tell you about their reasoning,\" he said bluntly. \"The wrong takeaway from this research would be believing everything the model tells you about itself.\"The experiments documented numerous failure modes. At low injection strengths, models often failed to detect anything unusual. At high strengths, they suffered what researchers termed \"brain damage\" — becoming consumed by the injected concept. Some \"helpful-only\" model variants showed troublingly high false positive rates, claiming to detect injected thoughts when none existed.Moreover, researchers could only verify the most basic aspects of Claude&#x27;s introspective reports. Many additional details in the model&#x27;s responses likely represent confabulations rather than genuine observations.\"The experiments in this paper are kind of on hard mode,\" Lindsey noted, explaining that the 20 percent success rate came under uniquely challenging conditions: asking Claude to do something it had never encountered in training, requiring all introspection to occur in a single forward pass.What introspective AI means for transparency, safety, and the risk of deceptionDespite its limitations, the research opens significant new avenues for making AI systems more transparent and accountable.Anthropic CEO Dario Amodei has set an ambitious goal for the company to reliably detect most AI model problems by 2027, positioning interpretability as essential for deploying what he calls \"a country of geniuses in a datacenter.\"\"I am very concerned about deploying such systems without a better handle on interpretability,\" Amodei wrote in an April essay. \"These systems will be absolutely central to the economy, technology, and national security.\"The introspection research offers a complementary approach to traditional interpretability techniques. Rather than painstakingly reverse-engineering every neural circuit, researchers could potentially ask models directly about their reasoning and validate those reports.\"What I&#x27;m most excited about is the practical benefits for transparency,\" Lindsey explained. \"Just ask the model what it&#x27;s thinking about, or just ask the model how it came to the answer that it gave you — this is really appealing because it&#x27;s something anyone can do.\"The approach could prove especially valuable for detecting concerning behaviors. In a recently published experiment, Anthropic trained a variant of Claude to pursue a hidden goal, and although the model was reluctant to reveal this goal when asked directly, interpretability methods successfully identified features representing the behavior.The safety implications cut both ways. Introspective models could provide unprecedented transparency, but the same capability might enable more sophisticated deception. The intentional control experiments raise the possibility that sufficiently advanced systems might learn to obfuscate their reasoning or suppress concerning thoughts when being monitored.\"If models are really sophisticated, could they try to evade interpretability researchers?\" Lindsey acknowledged. \"These are possible concerns, but I think for me, they&#x27;re significantly outweighed by the positives.\"Does introspective capability suggest AI consciousness? Scientists tread carefullyThe research inevitably intersects with philosophical debates about machine consciousness, though Lindsey and his colleagues approached this terrain cautiously.When users ask Claude if it&#x27;s conscious, it now responds with uncertainty: \"I find myself genuinely uncertain about this. When I process complex questions or engage deeply with ideas, there&#x27;s something happening that feels meaningful to me.... But whether these processes constitute genuine consciousness or subjective experience remains deeply unclear.\"The research paper notes that its implications for machine consciousness \"vary considerably between different philosophical frameworks.\" The researchers explicitly state they \"do not seek to address the question of whether AI systems possess human-like self-awareness or subjective experience.\"\"There&#x27;s this weird kind of duality of these results,\" Lindsey reflected. \"You look at the raw results and I just can&#x27;t believe that a language model can do this sort of thing. But then I&#x27;ve been thinking about it for months and months, and for every result in this paper, I kind of know some boring linear algebra mechanism that would allow the model to do this.\"Anthropic has signaled it takes AI consciousness seriously enough to hire an AI welfare researcher, Kyle Fish, who estimated roughly a 15 percent chance that Claude might have some level of consciousness. The company announced this position specifically to determine if Claude merits ethical consideration.The race to make AI introspection reliable before models become too powerfulThe convergence of the research findings points to an urgent timeline: introspective capabilities are emerging naturally as models grow more intelligent, but they remain far too unreliable for practical use. The question is whether researchers can refine and validate these abilities before AI systems become powerful enough that understanding them becomes critical for safety.The research reveals a clear trend: Claude Opus 4 and Opus 4.1 consistently outperformed all older models on introspection tasks, suggesting the capability strengthens alongside general intelligence. If this pattern continues, future models might develop substantially more sophisticated introspective abilities — potentially reaching human-level reliability, but also potentially learning to exploit introspection for deception.Lindsey emphasized the field needs significantly more work before introspective AI becomes trustworthy. \"My biggest hope with this paper is to put out an implicit call for more people to benchmark their models on introspective capabilities in more ways,\" he said.Future research directions include fine-tuning models specifically to improve introspective capabilities, exploring which types of representations models can and cannot introspect on, and testing whether introspection can extend beyond simple concepts to complex propositional statements or behavioral propensities.\"It&#x27;s cool that models can do these things somewhat without having been trained to do them,\" Lindsey noted. \"But there&#x27;s nothing stopping you from training models to be more introspectively capable. I expect we could reach a whole different level if introspection is one of the numbers that we tried to get to go up on a graph.\"The implications extend beyond Anthropic. If introspection proves a reliable path to AI transparency, other major labs will likely invest heavily in the capability. Conversely, if models learn to exploit introspection for deception, the entire approach could become a liability.For now, the research establishes a foundation that reframes the debate about AI capabilities. The question is no longer whether language models might develop genuine introspective awareness — they already have, at least in rudimentary form. The urgent questions are how quickly that awareness will improve, whether it can be made reliable enough to trust, and whether researchers can stay ahead of the curve.\"The big update for me from this research is that we shouldn&#x27;t dismiss models&#x27; introspective claims out of hand,\" Lindsey said. \"They do have the capacity to make accurate claims sometimes. But you definitely should not conclude that we should trust them all the time, or even most of the time.\"He paused, then added a final observation that captures both the promise and peril of the moment: \"The models are getting smarter much faster than we&#x27;re getting better at understanding them.\"",
          "content": "When researchers at Anthropic injected the concept of \"betrayal\" into their Claude AI model&#x27;s neural networks and asked if it noticed anything unusual, the system paused before responding: \"I&#x27;m experiencing something that feels like an intrusive thought about &#x27;betrayal&#x27;.\"The exchange, detailed in new research published Wednesday, marks what scientists say is the first rigorous evidence that large language models possess a limited but genuine ability to observe and report on their own internal processes — a capability that challenges longstanding assumptions about what these systems can do and raises profound questions about their future development.\"The striking thing is that the model has this one step of meta,\" said Jack Lindsey, a neuroscientist on Anthropic&#x27;s interpretability team who led the research, in an interview with VentureBeat. \"It&#x27;s not just &#x27;betrayal, betrayal, betrayal.&#x27; It knows that this is what it&#x27;s thinking about. That was surprising to me. I kind of didn&#x27;t expect models to have that capability, at least not without it being explicitly trained in.\"The findings arrive at a critical juncture for artificial intelligence. As AI systems handle increasingly consequential decisions — from medical diagnoses to financial trading — the inability to understand how they reach conclusions has become what industry insiders call the \"black box problem.\" If models can accurately report their own reasoning, it could fundamentally change how humans interact with and oversee AI systems.But the research also comes with stark warnings. Claude&#x27;s introspective abilities succeeded only about 20 percent of the time under optimal conditions, and the models frequently confabulated details about their experiences that researchers couldn&#x27;t verify. The capability, while real, remains what Lindsey calls \"highly unreliable and context-dependent.\"How scientists manipulated AI&#x27;s &#x27;brain&#x27; to test for genuine self-awarenessTo test whether Claude could genuinely introspect rather than simply generate plausible-sounding responses, Anthropic&#x27;s team developed an innovative experimental approach inspired by neuroscience: deliberately manipulating the model&#x27;s internal state and observing whether it could accurately detect and describe those changes.The methodology, called \"concept injection,\" works by first identifying specific patterns of neural activity that correspond to particular concepts. Using interpretability techniques developed over years of prior research, scientists can now map how Claude represents ideas like \"dogs,\" \"loudness,\" or abstract notions like \"justice\" within its billions of internal parameters.With these neural signatures identified, researchers then artificially amplified them during the model&#x27;s processing and asked Claude if it noticed anything unusual happening in its \"mind.\"\"We have access to the models&#x27; internals. We can record its internal neural activity, and we can inject things into internal neural activity,\" Lindsey explained. \"That allows us to establish whether introspective claims are true or false.\"The results were striking. When researchers injected a vector representing \"all caps\" text into Claude&#x27;s processing, the model responded: \"I notice what appears to be an injected thought related to the word &#x27;LOUD&#x27; or &#x27;SHOUTING&#x27;.\" Without any intervention, Claude consistently reported detecting nothing unusual.Crucially, the detection happened immediately — before the injected concept had influenced the model&#x27;s outputs in ways that would have allowed it to infer the manipulation from its own writing. This temporal pattern provides strong evidence that the recognition was occurring internally, through genuine introspection rather than after-the-fact rationalization.Claude succeeded 20% of the time—and failed in revealing waysThe research team conducted four primary experiments to probe different aspects of introspective capability. The most capable models tested — Claude Opus 4 and Opus 4.1 — demonstrated introspective awareness on approximately 20 percent of trials when concepts were injected at optimal strength and in the appropriate neural layer. Older Claude models showed significantly lower success rates.The models proved particularly adept at recognizing abstract concepts with emotional valence. When injected with concepts like \"appreciation,\" \"shutdown,\" or \"secrecy,\" Claude frequently reported detecting these specific thoughts. However, accuracy varied widely depending on the type of concept.A second experiment tested whether models could distinguish between injected internal representations and their actual text inputs — essentially, whether they maintained a boundary between \"thoughts\" and \"perceptions.\" The model demonstrated a remarkable ability to simultaneously report the injected thought while accurately transcribing the written text.Perhaps most intriguingly, a third experiment revealed that some models use introspection naturally to detect when their responses have been artificially prefilled by users — a common jailbreaking technique. When researchers prefilled Claude with unlikely words, the model typically disavowed them as accidental. But when they retroactively injected the corresponding concept into Claude&#x27;s processing before the prefill, the model accepted the response as intentional — even confabulating plausible explanations for why it had chosen that word.A fourth experiment examined whether models could intentionally control their internal representations. When instructed to \"think about\" a specific word while writing an unrelated sentence, Claude showed elevated activation of that concept in its middle neural layers.The research also traced Claude&#x27;s internal processes while it composed rhyming poetry—and discovered the model engaged in forward planning, generating candidate rhyming words before beginning a line and then constructing sentences that would naturally lead to those planned endings, challenging the critique that AI models are \"just predicting the next word\" without deeper reasoning.Why businesses shouldn&#x27;t trust AI to explain itself—at least not yetFor all its scientific interest, the research comes with a critical caveat that Lindsey emphasized repeatedly: enterprises and high-stakes users should not trust Claude&#x27;s self-reports about its reasoning.\"Right now, you should not trust models when they tell you about their reasoning,\" he said bluntly. \"The wrong takeaway from this research would be believing everything the model tells you about itself.\"The experiments documented numerous failure modes. At low injection strengths, models often failed to detect anything unusual. At high strengths, they suffered what researchers termed \"brain damage\" — becoming consumed by the injected concept. Some \"helpful-only\" model variants showed troublingly high false positive rates, claiming to detect injected thoughts when none existed.Moreover, researchers could only verify the most basic aspects of Claude&#x27;s introspective reports. Many additional details in the model&#x27;s responses likely represent confabulations rather than genuine observations.\"The experiments in this paper are kind of on hard mode,\" Lindsey noted, explaining that the 20 percent success rate came under uniquely challenging conditions: asking Claude to do something it had never encountered in training, requiring all introspection to occur in a single forward pass.What introspective AI means for transparency, safety, and the risk of deceptionDespite its limitations, the research opens significant new avenues for making AI systems more transparent and accountable.Anthropic CEO Dario Amodei has set an ambitious goal for the company to reliably detect most AI model problems by 2027, positioning interpretability as essential for deploying what he calls \"a country of geniuses in a datacenter.\"\"I am very concerned about deploying such systems without a better handle on interpretability,\" Amodei wrote in an April essay. \"These systems will be absolutely central to the economy, technology, and national security.\"The introspection research offers a complementary approach to traditional interpretability techniques. Rather than painstakingly reverse-engineering every neural circuit, researchers could potentially ask models directly about their reasoning and validate those reports.\"What I&#x27;m most excited about is the practical benefits for transparency,\" Lindsey explained. \"Just ask the model what it&#x27;s thinking about, or just ask the model how it came to the answer that it gave you — this is really appealing because it&#x27;s something anyone can do.\"The approach could prove especially valuable for detecting concerning behaviors. In a recently published experiment, Anthropic trained a variant of Claude to pursue a hidden goal, and although the model was reluctant to reveal this goal when asked directly, interpretability methods successfully identified features representing the behavior.The safety implications cut both ways. Introspective models could provide unprecedented transparency, but the same capability might enable more sophisticated deception. The intentional control experiments raise the possibility that sufficiently advanced systems might learn to obfuscate their reasoning or suppress concerning thoughts when being monitored.\"If models are really sophisticated, could they try to evade interpretability researchers?\" Lindsey acknowledged. \"These are possible concerns, but I think for me, they&#x27;re significantly outweighed by the positives.\"Does introspective capability suggest AI consciousness? Scientists tread carefullyThe research inevitably intersects with philosophical debates about machine consciousness, though Lindsey and his colleagues approached this terrain cautiously.When users ask Claude if it&#x27;s conscious, it now responds with uncertainty: \"I find myself genuinely uncertain about this. When I process complex questions or engage deeply with ideas, there&#x27;s something happening that feels meaningful to me.... But whether these processes constitute genuine consciousness or subjective experience remains deeply unclear.\"The research paper notes that its implications for machine consciousness \"vary considerably between different philosophical frameworks.\" The researchers explicitly state they \"do not seek to address the question of whether AI systems possess human-like self-awareness or subjective experience.\"\"There&#x27;s this weird kind of duality of these results,\" Lindsey reflected. \"You look at the raw results and I just can&#x27;t believe that a language model can do this sort of thing. But then I&#x27;ve been thinking about it for months and months, and for every result in this paper, I kind of know some boring linear algebra mechanism that would allow the model to do this.\"Anthropic has signaled it takes AI consciousness seriously enough to hire an AI welfare researcher, Kyle Fish, who estimated roughly a 15 percent chance that Claude might have some level of consciousness. The company announced this position specifically to determine if Claude merits ethical consideration.The race to make AI introspection reliable before models become too powerfulThe convergence of the research findings points to an urgent timeline: introspective capabilities are emerging naturally as models grow more intelligent, but they remain far too unreliable for practical use. The question is whether researchers can refine and validate these abilities before AI systems become powerful enough that understanding them becomes critical for safety.The research reveals a clear trend: Claude Opus 4 and Opus 4.1 consistently outperformed all older models on introspection tasks, suggesting the capability strengthens alongside general intelligence. If this pattern continues, future models might develop substantially more sophisticated introspective abilities — potentially reaching human-level reliability, but also potentially learning to exploit introspection for deception.Lindsey emphasized the field needs significantly more work before introspective AI becomes trustworthy. \"My biggest hope with this paper is to put out an implicit call for more people to benchmark their models on introspective capabilities in more ways,\" he said.Future research directions include fine-tuning models specifically to improve introspective capabilities, exploring which types of representations models can and cannot introspect on, and testing whether introspection can extend beyond simple concepts to complex propositional statements or behavioral propensities.\"It&#x27;s cool that models can do these things somewhat without having been trained to do them,\" Lindsey noted. \"But there&#x27;s nothing stopping you from training models to be more introspectively capable. I expect we could reach a whole different level if introspection is one of the numbers that we tried to get to go up on a graph.\"The implications extend beyond Anthropic. If introspection proves a reliable path to AI transparency, other major labs will likely invest heavily in the capability. Conversely, if models learn to exploit introspection for deception, the entire approach could become a liability.For now, the research establishes a foundation that reframes the debate about AI capabilities. The question is no longer whether language models might develop genuine introspective awareness — they already have, at least in rudimentary form. The urgent questions are how quickly that awareness will improve, whether it can be made reliable enough to trust, and whether researchers can stay ahead of the curve.\"The big update for me from this research is that we shouldn&#x27;t dismiss models&#x27; introspective claims out of hand,\" Lindsey said. \"They do have the capacity to make accurate claims sometimes. But you definitely should not conclude that we should trust them all the time, or even most of the time.\"He paused, then added a final observation that captures both the promise and peril of the moment: \"The models are getting smarter much faster than we&#x27;re getting better at understanding them.\"",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/uB8acjwdIn4wcbdbIasNC/068cc72b7b35d61a4df3fd4d38ca6f78/nuneybits_Vector_art_of_mirrored_robot_face_in_burnt_orange_fbd5a3f2-d7b1-4f4c-90e5-290b8e9444c2.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/the-nothing-phone-3a-lite-has-a-big-battery-and-triple-camera-system-130016149.html",
          "published_at": "Wed, 29 Oct 2025 15:20:25 +0000",
          "title": "The Nothing Phone 3a Lite has a big battery and triple-camera system",
          "standfirst": "The Nothing Phone universe continues to expand. On Wednesday, the company launched the fourth model in the Phone 3 lineup: the Nothing Phone 3a Lite. The cheapest model in the series, the Phone 3a Lite pairs the brand's distinct styling with solid all-around specs for an entry-level handset. However, with the company saying its non-flagship devices will soon include pre-installed apps and lock-screen ads, there may be a trade-off. First, Nothing told Engadget that the phone won't come to the US. So, Americans only have the previous trio of third-gen handsets to choose from. That's the Nothing Phone 3, Nothing Phone 3a, and Nothing Phone 3a Pro. The Nothing Phone 3a Lite uses a Panda Glass casing over an aluminum internal frame. As you can see, it retains some familiar design strokes, albeit pared down to match its €249 price. As the company describes it, the handset's \"asymmetric, transparent look and nano-coating creates a beautiful balance of matte and gloss.\" (Poetry!) The phone ships in white and black variants. Whether Nothing's design language is your cup of tea or not, you'll be hard-pressed to find a more striking and bold design language in a budget model. The handset includes the Essential Key, a multi-purpose physical button found on all Phone 3 series models. The phone is IP54-rated for dust and water resistance. Nothing Nothing honors the brand's unique Glyph system (while keeping costs down) by using a notification LED. (Remember those on early Android phones?) This model's \"Glyph Light\" supports the lineup's Flip to Glyph feature, which switches to light-only alerts when the device is face down. The LED can stay on for \"key contact and app notifications\" and serve as a camera countdown timer. You can also customize its light sequences for calls and specific contacts. The handset has a hearty 5,000 mAh battery. Nothing advertises 22 hours of YouTube playback or 9.5 hours of gaming. It supports 33W fast charging, reaching 50 percent in about 20 minutes. The Phone 3a Lite has a triple-camera system. That includes a 50MP primary camera with a 1/1.57-inch Samsung sensor. Joining it are an 8MP ultra-wide and a macro lens. The rear camera system shoots 4K video at app to 30 FPS. On its front is a 16MP lens. Nothing The Nothing Phone 3a Lite has more than respectable display specs for a budget phone. It uses a 6.77-inch flexible AMOLED panel with 1,080 x 2,392 resolution (387 PPI). It has a 120Hz adaptive refresh rate and a 1,000Hz touch sampling rate. It can reach 3,000 nits peak HDR brightness and 1,300 nits outdoor brightness. The handset's processor is the 4nm MediaTek Dimensity 7300 Pro 5G. The 8-core CPU can reach up to 2.5 GHz. Nothing says the chip performs better than the MediaTek 7200 silicon in last year's Phone 2a. The company claims its CPU is 15 percent faster, its GPU supports 20 percent higher FPS, and its NPU delivers 100 percent better AI performance. The phone also uses a liquid-cooling system, which may help during intensive gaming sessions. It ships with 8GB of RAM and comes in 128GB and 256GB storage tiers. Nothing The phone runs the Nothing OS 3.5 UI on top of Android 15. The company says Nothing OS 4.0 will arrive in the first half of 2026. And that brings us back to those trade-offs. Earlier this week, Nothing confirmed to 9to5Google that its strategy moving forward will include \"Lock Glimpse.\" This rotating lock-screen wallpaper feature includes text with links to external content hosted by a Chinese advertising company. (That firm, Boyuan, says it offers a \"rich mixture of content\" to help its partners \"commercialize the mobile traffic.\") Think of it as a slightly less obnoxious version of lock-screen ads. Fortunately, Lock Glimpse is off by default in the current Nothing OS 4.0 beta. Nothing pledges it will give users \"full control over features like Lock Glimpse.\" However, that promise doesn't explicitly say the feature will remain off by default. Another cost-subsidizing move is Nothing's (also confirmed) embrace of pre-installed apps. The company said its \"carefully considered\" third-party apps are those \"most people install on day one, like Instagram.\" In fairness, that's a common practice among Android phone manufacturers. And Nothing says it will make third-party apps removable. But again, the concessions here arguably run counter to one aspect of the brand's stated ethos: clean, bloat-free software. And if business considerations forced compromises in this area, it makes you question how long Lock Glimpse will stay off by default. The Nothing Phone 3a Lite is available now in Europe on the company website. The 128GB model costs €249 (EU) / £249 (UK). Meanwhile, the 256GB model will set you back €279 (EU) / £279 (UK). Update, October 29, 2025, 11:20 AM ET: This story has been updated to add information from Nothing about the lack of US availability and additional detail from Nothing's community post.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/the-nothing-phone-3a-lite-has-a-big-battery-and-triple-camera-system-130016149.html?src=rss",
          "content": "The Nothing Phone universe continues to expand. On Wednesday, the company launched the fourth model in the Phone 3 lineup: the Nothing Phone 3a Lite. The cheapest model in the series, the Phone 3a Lite pairs the brand's distinct styling with solid all-around specs for an entry-level handset. However, with the company saying its non-flagship devices will soon include pre-installed apps and lock-screen ads, there may be a trade-off. First, Nothing told Engadget that the phone won't come to the US. So, Americans only have the previous trio of third-gen handsets to choose from. That's the Nothing Phone 3, Nothing Phone 3a, and Nothing Phone 3a Pro. The Nothing Phone 3a Lite uses a Panda Glass casing over an aluminum internal frame. As you can see, it retains some familiar design strokes, albeit pared down to match its €249 price. As the company describes it, the handset's \"asymmetric, transparent look and nano-coating creates a beautiful balance of matte and gloss.\" (Poetry!) The phone ships in white and black variants. Whether Nothing's design language is your cup of tea or not, you'll be hard-pressed to find a more striking and bold design language in a budget model. The handset includes the Essential Key, a multi-purpose physical button found on all Phone 3 series models. The phone is IP54-rated for dust and water resistance. Nothing Nothing honors the brand's unique Glyph system (while keeping costs down) by using a notification LED. (Remember those on early Android phones?) This model's \"Glyph Light\" supports the lineup's Flip to Glyph feature, which switches to light-only alerts when the device is face down. The LED can stay on for \"key contact and app notifications\" and serve as a camera countdown timer. You can also customize its light sequences for calls and specific contacts. The handset has a hearty 5,000 mAh battery. Nothing advertises 22 hours of YouTube playback or 9.5 hours of gaming. It supports 33W fast charging, reaching 50 percent in about 20 minutes. The Phone 3a Lite has a triple-camera system. That includes a 50MP primary camera with a 1/1.57-inch Samsung sensor. Joining it are an 8MP ultra-wide and a macro lens. The rear camera system shoots 4K video at app to 30 FPS. On its front is a 16MP lens. Nothing The Nothing Phone 3a Lite has more than respectable display specs for a budget phone. It uses a 6.77-inch flexible AMOLED panel with 1,080 x 2,392 resolution (387 PPI). It has a 120Hz adaptive refresh rate and a 1,000Hz touch sampling rate. It can reach 3,000 nits peak HDR brightness and 1,300 nits outdoor brightness. The handset's processor is the 4nm MediaTek Dimensity 7300 Pro 5G. The 8-core CPU can reach up to 2.5 GHz. Nothing says the chip performs better than the MediaTek 7200 silicon in last year's Phone 2a. The company claims its CPU is 15 percent faster, its GPU supports 20 percent higher FPS, and its NPU delivers 100 percent better AI performance. The phone also uses a liquid-cooling system, which may help during intensive gaming sessions. It ships with 8GB of RAM and comes in 128GB and 256GB storage tiers. Nothing The phone runs the Nothing OS 3.5 UI on top of Android 15. The company says Nothing OS 4.0 will arrive in the first half of 2026. And that brings us back to those trade-offs. Earlier this week, Nothing confirmed to 9to5Google that its strategy moving forward will include \"Lock Glimpse.\" This rotating lock-screen wallpaper feature includes text with links to external content hosted by a Chinese advertising company. (That firm, Boyuan, says it offers a \"rich mixture of content\" to help its partners \"commercialize the mobile traffic.\") Think of it as a slightly less obnoxious version of lock-screen ads. Fortunately, Lock Glimpse is off by default in the current Nothing OS 4.0 beta. Nothing pledges it will give users \"full control over features like Lock Glimpse.\" However, that promise doesn't explicitly say the feature will remain off by default. Another cost-subsidizing move is Nothing's (also confirmed) embrace of pre-installed apps. The company said its \"carefully considered\" third-party apps are those \"most people install on day one, like Instagram.\" In fairness, that's a common practice among Android phone manufacturers. And Nothing says it will make third-party apps removable. But again, the concessions here arguably run counter to one aspect of the brand's stated ethos: clean, bloat-free software. And if business considerations forced compromises in this area, it makes you question how long Lock Glimpse will stay off by default. The Nothing Phone 3a Lite is available now in Europe on the company website. The 128GB model costs €249 (EU) / £249 (UK). Meanwhile, the 256GB model will set you back €279 (EU) / £279 (UK). Update, October 29, 2025, 11:20 AM ET: This story has been updated to add information from Nothing about the lack of US availability and additional detail from Nothing's community post.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/the-nothing-phone-3a-lite-has-a-big-battery-and-triple-camera-system-130016149.html?src=rss",
          "feed_position": 16,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c6d29240-b41f-11f0-b7db-d26a28d1fde5"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-50-percent-off-a-year-subscription-to-one-of-our-favorite-budgeting-apps-174011108.html",
          "published_at": "Wed, 29 Oct 2025 15:01:26 +0000",
          "title": "Get 50 percent off a year subscription to one of our favorite budgeting apps",
          "standfirst": "Monarch Money is one of our favorite budgeting apps and, fittingly enough, there's a way for newcomers to save money on a subscription right now. If you use the code MONARCHVIP at checkout, you can get an annual plan for 50 percent off. It typically costs $100, but you can get 12 months of access for $50 with this code. There are some key caveats here. The discount is only for new users, and it can't be combined with other offers. The code only works when you sign up through the web. You can't redeem it through the Monarch mobile app. We feel that Monarch has a steeper learning curve than some other budget trackers and that certain aspects of the app are slightly more complex than they probably need to be. But it offers a great deal of customization and granularity, which outweighs our misgivings. On the main dashboard, you'll see your net worth along with your latest transactions, spending versus the previous month, your income so far for the month and details about upcoming bills, your investments and goals you've set. There's also a link to a month-in-review page, which offers an in-depth overview of what's been happening with your money that month. You'll also be able to take a peek at how your net worth has changed over time. Monarch can connect to your bank and track Apple Card, Apple Cash and Savings accounts. It can pull in your transactions and balance history automatically and detect your recurring expenses and income. The app can even keep your car valuation up to date. While it might take a little work to set up Monarch (and you might have to tweak things here and there), it's a detailed budgeting app that can help you keep better track of your income, expenditure and net worth. If you're a former Mint user (RIP), Monarch Money is a great alternative if you haven't yet found a Mint replacement. But it's worth mentioning that our favorite Mint replacement service, Quicken Simplifi, also has a sale going on right now. It's offering 50 percent off when you sign up for an annual subscription, billed at $3 per month with the discount. That comes out to $36 for the first year. This article originally appeared on Engadget at https://www.engadget.com/deals/get-50-percent-off-a-year-subscription-to-one-of-our-favorite-budgeting-apps-174011108.html?src=rss",
          "content": "Monarch Money is one of our favorite budgeting apps and, fittingly enough, there's a way for newcomers to save money on a subscription right now. If you use the code MONARCHVIP at checkout, you can get an annual plan for 50 percent off. It typically costs $100, but you can get 12 months of access for $50 with this code. There are some key caveats here. The discount is only for new users, and it can't be combined with other offers. The code only works when you sign up through the web. You can't redeem it through the Monarch mobile app. We feel that Monarch has a steeper learning curve than some other budget trackers and that certain aspects of the app are slightly more complex than they probably need to be. But it offers a great deal of customization and granularity, which outweighs our misgivings. On the main dashboard, you'll see your net worth along with your latest transactions, spending versus the previous month, your income so far for the month and details about upcoming bills, your investments and goals you've set. There's also a link to a month-in-review page, which offers an in-depth overview of what's been happening with your money that month. You'll also be able to take a peek at how your net worth has changed over time. Monarch can connect to your bank and track Apple Card, Apple Cash and Savings accounts. It can pull in your transactions and balance history automatically and detect your recurring expenses and income. The app can even keep your car valuation up to date. While it might take a little work to set up Monarch (and you might have to tweak things here and there), it's a detailed budgeting app that can help you keep better track of your income, expenditure and net worth. If you're a former Mint user (RIP), Monarch Money is a great alternative if you haven't yet found a Mint replacement. But it's worth mentioning that our favorite Mint replacement service, Quicken Simplifi, also has a sale going on right now. It's offering 50 percent off when you sign up for an annual subscription, billed at $3 per month with the discount. That comes out to $36 for the first year. This article originally appeared on Engadget at https://www.engadget.com/deals/get-50-percent-off-a-year-subscription-to-one-of-our-favorite-budgeting-apps-174011108.html?src=rss",
          "feed_position": 20
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data-infrastructure/the-missing-data-link-in-enterprise-ai-why-agents-need-streaming-context-not",
          "published_at": "Wed, 29 Oct 2025 15:00:00 GMT",
          "title": "The missing data link in enterprise AI: Why agents need streaming context, not just better prompts",
          "standfirst": "Enterprise AI agents today face a fundamental timing problem: They can&#x27;t easily act on critical business events because they aren&#x27;t always aware of them in real-time.The challenge is infrastructure. Most enterprise data lives in databases fed by extract-transform-load (ETL) jobs that run hourly or daily — ultimately too slow for agents that must respond in real time.One potential way to tackle that challenge is to have agents directly interface with streaming data systems. Among the primary approaches in use today are the open source Apache Kafka and Apache Flink technologies. There are multiple commercial implementations based on those technologies, too, Confluent, which is led by the original creators behind Kafka, being one of them.Today, Confluent is introducing a real-time context engine designed to solve this latency problem. The technology builds on Apache Kafka, the distributed event streaming platform that captures data as events occur, and open-source Apache Flink, the stream processing engine that transforms those events in real time.The company is also releasing an open-source framework, Flink Agents, developed in collaboration with Alibaba Cloud, LinkedIn and Ververica. The framework brings event-driven AI agent capabilities directly to Apache Flink, allowing organizations to build agents that monitor data streams and trigger automatically based on conditions without committing to Confluent&#x27;s managed platform.\"Today, most enterprise AI systems can&#x27;t respond automatically to important events in a business without someone prompting them first,\" Sean Falconer, Confluent&#x27;s head of AI, told VentureBeat. \"This leads to lost revenue, unhappy customers or added risk when a payment fails or a network malfunctions.\"The significance extends beyond Confluent&#x27;s specific products. The industry is recognizing that AI agents require different data infrastructure than traditional applications. Agents don&#x27;t just retrieve information when asked. They need to observe continuous streams of business events and act automatically when conditions warrant. This requires streaming architecture, not batch pipelines.Batch versus streaming: Why RAG alone isn&#x27;t enoughTo understand the problem, it&#x27;s important to distinguish between the different approaches to moving data through enterprise systems and how they can connect to agentic AI.In batch processing, data accumulates in source systems until a scheduled job runs. That job extracts the data, transforms it and loads it into a target database or data warehouse. This might occur hourly, daily or even weekly. The approach works well for analytical workloads, but it creates latency between when something happens in the business and when systems can act on it.Data streaming inverts this model. Instead of waiting for scheduled jobs, streaming platforms like Apache Kafka capture events as they occur. Each database update, user action, transaction or sensor reading becomes an event published to a stream. Apache Flink then processes these streams to join, filter and aggregate data in real time. The result is processed data that reflects the current state of the business, updating continuously as new events arrive.This distinction becomes critical when you consider what kinds of context AI agents actually need. Much of the current enterprise AI discussion focuses on retrieval-augmented generation (RAG), which handles semantic search over knowledge bases to find relevant documentation, policies or historical information. RAG works well for questions like \"What&#x27;s our refund policy?\" where the answer exists in static documents.But many enterprise use cases require what Falconer calls \"structural context\" — precise, up-to-date information from multiple operational systems stitched together in real time. Consider a job recommendation agent that requires user profile data from the HR database, browsing behavior from the last hour, search queries from minutes ago and current open positions across multiple systems.\"The part that we&#x27;re unlocking for businesses is the ability to essentially serve that structural context needed to deliver the freshest version,\" Falconer said.The MCP connection problem: Stale data and fragmented contextThe challenge isn&#x27;t simply connecting AI to enterprise data. Model Context Protocol (MCP), introduced by Anthropic earlier this year, already standardized how agents access data sources. The problem is what happens after the connection is made.In most enterprise architectures today, AI agents connect via MCP to data lakes or warehouses fed by batch ETL pipelines. This creates two critical failures: The data is stale, reflecting yesterday&#x27;s reality rather than current events, and it&#x27;s fragmented across multiple systems, requiring significant preprocessing before an agent can reason about it effectively.The alternative — putting MCP servers directly in front of operational databases and APIs — creates different problems. Those endpoints weren&#x27;t designed for agent consumption, which can lead to high token costs as agents process excessive raw data and multiple inference loops as they try to make sense of unstructured responses.\"Enterprises have the data, but it&#x27;s often stale, fragmented or locked in formats that AI can&#x27;t use effectively,\" Falconer explained. \"The real-time context engine solves this by unifying data processing, reprocessing and serving, turning continuous data streams into live context for smarter, faster and more reliable AI decisions.\"The technical architecture: Three layers for real-time agent contextConfluent&#x27;s platform encompasses three elements that work together or adopted separately.The real-time context engine is the managed data infrastructure layer on Confluent Cloud. Connectors pull data into Kafka topics as events occur. Flink jobs process these streams into \"derived datasets\" — materialized views joining historical and real-time signals. For customer support, this might combine account history, current session behavior and inventory status into one unified context object. The Engine exposes this through a managed MCP server.Streaming agents is Confluent&#x27;s proprietary framework for building AI agents that run natively on Flink. These agents monitor data streams and trigger automatically based on conditions — they don&#x27;t wait for prompts. The framework includes simplified agent definitions, built-in observability and native Claude integration from Anthropic. It&#x27;s available in open preview on Confluent&#x27;s platform.Flink Agents is the open-source framework developed with Alibaba Cloud, LinkedIn and Ververica. It brings event-driven agent capabilities directly to Apache Flink, allowing organizations to build streaming agents without committing to Confluent&#x27;s managed platform. They handle operational complexity themselves but avoid vendor lock-in.Competition heats up for agent-ready data infrastructureConfluent isn&#x27;t alone in recognizing that AI agents need different data infrastructure. The day before Confluent&#x27;s announcement, rival Redpanda introduced its own Agentic Data Plane — combining streaming, SQL and governance specifically for AI agents. Redpanda acquired Oxla&#x27;s distributed SQL engine to give agents standard SQL endpoints for querying data in motion or at rest. The platform emphasizes MCP-aware connectivity, full observability of agent interactions and what it calls \"agentic access control\" with fine-grained, short-lived tokens.The architectural approaches differ. Confluent emphasizes stream processing with Flink to create derived datasets optimized for agents. Redpanda emphasizes federated SQL querying across disparate sources. Both recognize agents need real-time context with governance and observability.Beyond direct streaming competitors, Databricks and Snowflake are fundamentally analytical platforms adding streaming capabilities. Their strength is complex queries over large datasets, with streaming as an enhancement. Confluent and Redpanda invert this: Streaming is the foundation, with analytical and AI workloads built on top of data in motion.How streaming context works in practiceAmong the users of Confluent&#x27;s system is transportation vendor Busie. The company is building a modern operating system for charter bus companies that helps them manage quotes, trips, payments and drivers in real time. \"Data streaming is what makes that possible,\" Louis Bookoff, Busie co-founder and CEO told VentureBeat. \"Using Confluent, we move data instantly between different parts of our system instead of waiting for overnight updates or batch reports. That keeps everything in sync and helps us ship new features faster.Bookoff noted that the same foundation is what will make gen AI valuable for his customers.\"In our case, every action like a quote sent or a driver assigned becomes an event that streams through the system immediately,\" Bookoff said. \"That live feed of information is what will let our AI tools respond in real time with low latency rather than just summarize what already happened.\"The challenge, however, is how to understand context. When thousands of live events flow through the system every minute, AI models need relevant, accurate data without getting overwhelmed. \"If the data isn&#x27;t grounded in what is happening in the real world, AI can easily make wrong assumptions and in turn take wrong actions,\" Bookoff said. \"Stream processing solves that by continuously validating and reconciling live data against activity in Busie.\"What this means for enterprise AI strategyStreaming context architecture signals a fundamental shift in how AI agents consume enterprise data. AI agents require continuous context that blends historical understanding with real-time awareness — they need to know what happened, what&#x27;s happening and what might happen next, all at once.For enterprises evaluating this approach, start by identifying use cases where data staleness breaks the agent. Fraud detection, anomaly investigation and real-time customer intervention fail with batch pipelines that refresh hourly or daily. If your agents need to act on events within seconds or minutes of them occurring, streaming context becomes necessary rather than optional.\"When you&#x27;re building applications on top of foundation models, because they&#x27;re inherently probabilistic, you use data and context to steer the model in a direction where you want to get some kind of outcome,\" Falconer said. \"The better you can do that, the more reliable and better the outcome.\"",
          "content": "Enterprise AI agents today face a fundamental timing problem: They can&#x27;t easily act on critical business events because they aren&#x27;t always aware of them in real-time.The challenge is infrastructure. Most enterprise data lives in databases fed by extract-transform-load (ETL) jobs that run hourly or daily — ultimately too slow for agents that must respond in real time.One potential way to tackle that challenge is to have agents directly interface with streaming data systems. Among the primary approaches in use today are the open source Apache Kafka and Apache Flink technologies. There are multiple commercial implementations based on those technologies, too, Confluent, which is led by the original creators behind Kafka, being one of them.Today, Confluent is introducing a real-time context engine designed to solve this latency problem. The technology builds on Apache Kafka, the distributed event streaming platform that captures data as events occur, and open-source Apache Flink, the stream processing engine that transforms those events in real time.The company is also releasing an open-source framework, Flink Agents, developed in collaboration with Alibaba Cloud, LinkedIn and Ververica. The framework brings event-driven AI agent capabilities directly to Apache Flink, allowing organizations to build agents that monitor data streams and trigger automatically based on conditions without committing to Confluent&#x27;s managed platform.\"Today, most enterprise AI systems can&#x27;t respond automatically to important events in a business without someone prompting them first,\" Sean Falconer, Confluent&#x27;s head of AI, told VentureBeat. \"This leads to lost revenue, unhappy customers or added risk when a payment fails or a network malfunctions.\"The significance extends beyond Confluent&#x27;s specific products. The industry is recognizing that AI agents require different data infrastructure than traditional applications. Agents don&#x27;t just retrieve information when asked. They need to observe continuous streams of business events and act automatically when conditions warrant. This requires streaming architecture, not batch pipelines.Batch versus streaming: Why RAG alone isn&#x27;t enoughTo understand the problem, it&#x27;s important to distinguish between the different approaches to moving data through enterprise systems and how they can connect to agentic AI.In batch processing, data accumulates in source systems until a scheduled job runs. That job extracts the data, transforms it and loads it into a target database or data warehouse. This might occur hourly, daily or even weekly. The approach works well for analytical workloads, but it creates latency between when something happens in the business and when systems can act on it.Data streaming inverts this model. Instead of waiting for scheduled jobs, streaming platforms like Apache Kafka capture events as they occur. Each database update, user action, transaction or sensor reading becomes an event published to a stream. Apache Flink then processes these streams to join, filter and aggregate data in real time. The result is processed data that reflects the current state of the business, updating continuously as new events arrive.This distinction becomes critical when you consider what kinds of context AI agents actually need. Much of the current enterprise AI discussion focuses on retrieval-augmented generation (RAG), which handles semantic search over knowledge bases to find relevant documentation, policies or historical information. RAG works well for questions like \"What&#x27;s our refund policy?\" where the answer exists in static documents.But many enterprise use cases require what Falconer calls \"structural context\" — precise, up-to-date information from multiple operational systems stitched together in real time. Consider a job recommendation agent that requires user profile data from the HR database, browsing behavior from the last hour, search queries from minutes ago and current open positions across multiple systems.\"The part that we&#x27;re unlocking for businesses is the ability to essentially serve that structural context needed to deliver the freshest version,\" Falconer said.The MCP connection problem: Stale data and fragmented contextThe challenge isn&#x27;t simply connecting AI to enterprise data. Model Context Protocol (MCP), introduced by Anthropic earlier this year, already standardized how agents access data sources. The problem is what happens after the connection is made.In most enterprise architectures today, AI agents connect via MCP to data lakes or warehouses fed by batch ETL pipelines. This creates two critical failures: The data is stale, reflecting yesterday&#x27;s reality rather than current events, and it&#x27;s fragmented across multiple systems, requiring significant preprocessing before an agent can reason about it effectively.The alternative — putting MCP servers directly in front of operational databases and APIs — creates different problems. Those endpoints weren&#x27;t designed for agent consumption, which can lead to high token costs as agents process excessive raw data and multiple inference loops as they try to make sense of unstructured responses.\"Enterprises have the data, but it&#x27;s often stale, fragmented or locked in formats that AI can&#x27;t use effectively,\" Falconer explained. \"The real-time context engine solves this by unifying data processing, reprocessing and serving, turning continuous data streams into live context for smarter, faster and more reliable AI decisions.\"The technical architecture: Three layers for real-time agent contextConfluent&#x27;s platform encompasses three elements that work together or adopted separately.The real-time context engine is the managed data infrastructure layer on Confluent Cloud. Connectors pull data into Kafka topics as events occur. Flink jobs process these streams into \"derived datasets\" — materialized views joining historical and real-time signals. For customer support, this might combine account history, current session behavior and inventory status into one unified context object. The Engine exposes this through a managed MCP server.Streaming agents is Confluent&#x27;s proprietary framework for building AI agents that run natively on Flink. These agents monitor data streams and trigger automatically based on conditions — they don&#x27;t wait for prompts. The framework includes simplified agent definitions, built-in observability and native Claude integration from Anthropic. It&#x27;s available in open preview on Confluent&#x27;s platform.Flink Agents is the open-source framework developed with Alibaba Cloud, LinkedIn and Ververica. It brings event-driven agent capabilities directly to Apache Flink, allowing organizations to build streaming agents without committing to Confluent&#x27;s managed platform. They handle operational complexity themselves but avoid vendor lock-in.Competition heats up for agent-ready data infrastructureConfluent isn&#x27;t alone in recognizing that AI agents need different data infrastructure. The day before Confluent&#x27;s announcement, rival Redpanda introduced its own Agentic Data Plane — combining streaming, SQL and governance specifically for AI agents. Redpanda acquired Oxla&#x27;s distributed SQL engine to give agents standard SQL endpoints for querying data in motion or at rest. The platform emphasizes MCP-aware connectivity, full observability of agent interactions and what it calls \"agentic access control\" with fine-grained, short-lived tokens.The architectural approaches differ. Confluent emphasizes stream processing with Flink to create derived datasets optimized for agents. Redpanda emphasizes federated SQL querying across disparate sources. Both recognize agents need real-time context with governance and observability.Beyond direct streaming competitors, Databricks and Snowflake are fundamentally analytical platforms adding streaming capabilities. Their strength is complex queries over large datasets, with streaming as an enhancement. Confluent and Redpanda invert this: Streaming is the foundation, with analytical and AI workloads built on top of data in motion.How streaming context works in practiceAmong the users of Confluent&#x27;s system is transportation vendor Busie. The company is building a modern operating system for charter bus companies that helps them manage quotes, trips, payments and drivers in real time. \"Data streaming is what makes that possible,\" Louis Bookoff, Busie co-founder and CEO told VentureBeat. \"Using Confluent, we move data instantly between different parts of our system instead of waiting for overnight updates or batch reports. That keeps everything in sync and helps us ship new features faster.Bookoff noted that the same foundation is what will make gen AI valuable for his customers.\"In our case, every action like a quote sent or a driver assigned becomes an event that streams through the system immediately,\" Bookoff said. \"That live feed of information is what will let our AI tools respond in real time with low latency rather than just summarize what already happened.\"The challenge, however, is how to understand context. When thousands of live events flow through the system every minute, AI models need relevant, accurate data without getting overwhelmed. \"If the data isn&#x27;t grounded in what is happening in the real world, AI can easily make wrong assumptions and in turn take wrong actions,\" Bookoff said. \"Stream processing solves that by continuously validating and reconciling live data against activity in Busie.\"What this means for enterprise AI strategyStreaming context architecture signals a fundamental shift in how AI agents consume enterprise data. AI agents require continuous context that blends historical understanding with real-time awareness — they need to know what happened, what&#x27;s happening and what might happen next, all at once.For enterprises evaluating this approach, start by identifying use cases where data staleness breaks the agent. Fraud detection, anomaly investigation and real-time customer intervention fail with batch pipelines that refresh hourly or daily. If your agents need to act on events within seconds or minutes of them occurring, streaming context becomes necessary rather than optional.\"When you&#x27;re building applications on top of foundation models, because they&#x27;re inherently probabilistic, you use data and context to steer the model in a direction where you want to get some kind of outcome,\" Falconer said. \"The better you can do that, the more reliable and better the outcome.\"",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/sMKzhGAOWD3jIgUIXU3sF/dc476ec50bb21f290514114b8465106b/data_streaming_to_AI-smk.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/how-to-cancel-your-paramount-subscription-140053714.html",
          "published_at": "Wed, 29 Oct 2025 14:00:53 +0000",
          "title": "How to cancel your Paramount+ subscription",
          "standfirst": "Do you have one streaming service too many? While you're far from alone in that, sometimes it's worth saying goodbye to one and saving some cash. Take Paramount+, which starts at $8 per month for its ad-supported Essential plan. Then there's its ad-free Premium plan, coming in at $13 a month. If you're not really using it, or just can't justify the cost, canceling your Paramount+ subscription is pretty easy. Plus, Black Friday and Cyber Monday sales are right around the corner if you change your mind. Paramount+ has run significant deals for both in recent years. In the meantime, here's everything you need to know about canceling your subscription through Paramount+ or third-party providers like Apple or Google. How to cancel via web: If your subscription is directly through Paramount+ then canceling it takes only a few clicks. Sign in to your Paramount+ account on your browser. Go to the Paramount+ Account page. Tap on Cancel Subscription. How to cancel via third-party provider: It's still relatively simple to cancel your Paramount+ subscription even if you bought it through a third-party. Here's what you need to know based on where you purchased it. Cancel via Apple iPhone or iPad Go to Settings in your iPhone or iPad. Choose your name. Tap Subscriptions. Click Paramount+ and then select Cancel Subscription. Tap Confirm. Cancel via Apple TV Go to Settings in your Apple TV. Tap Users & Accounts. Select your Apple TV account. Choose Subscriptions. Click Paramount+ and select Cancel Subscription. Cancel via Google Play Store on a web browser Go to the Google Play Store through a web browser. Sign in to your Google Play Store account. Click Bills & Accounts on the left side of the screen. Choose Paramount+ and tap Cancel Subscription. Cancel via your Android smartphone or tablet Go to the Google Play Store app. Click on your profile icon. Choose Payment & Subscriptions. Tap on Subscriptions. Click Paramount+ and then select Cancel Subscription. Follow the prompts to confirm your cancelation. Cancel via your Android TV Open the Google Play Store app. Go to Menu. Choose My Apps. Tap on Subscription. Click Paramount+ and then select Cancel. Choose Yes to confirm your cancelation. Cancel via Amazon Go to Amazon App Store Subscriptions. Sign in to your Amazon account. Find your Paramount+ subscription and choose Actions. Tap Turn Off Auto-Renewal. Click Turn Off Auto-Renewal again to confirm your cancelation. Can I pause my subscription? No, there's no option as of yet to pause your Paramount+ subscription. If you want to cancel it then just do so and rejoin when the time is right — or a better deal is available. What happens after you cancel The good news is that your subscription won't end immediately. If you're in a free trial then your access to Paramount+ will remain until the trial period ends. Similarly, paid subscribers will lose the ability to use Paramount+ at the end of the current billing period. Notably, if you've used a multi-month promotion, your subscription will still stop at the end of your current billing period. This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/how-to-cancel-your-paramount-subscription-140053714.html?src=rss",
          "content": "Do you have one streaming service too many? While you're far from alone in that, sometimes it's worth saying goodbye to one and saving some cash. Take Paramount+, which starts at $8 per month for its ad-supported Essential plan. Then there's its ad-free Premium plan, coming in at $13 a month. If you're not really using it, or just can't justify the cost, canceling your Paramount+ subscription is pretty easy. Plus, Black Friday and Cyber Monday sales are right around the corner if you change your mind. Paramount+ has run significant deals for both in recent years. In the meantime, here's everything you need to know about canceling your subscription through Paramount+ or third-party providers like Apple or Google. How to cancel via web: If your subscription is directly through Paramount+ then canceling it takes only a few clicks. Sign in to your Paramount+ account on your browser. Go to the Paramount+ Account page. Tap on Cancel Subscription. How to cancel via third-party provider: It's still relatively simple to cancel your Paramount+ subscription even if you bought it through a third-party. Here's what you need to know based on where you purchased it. Cancel via Apple iPhone or iPad Go to Settings in your iPhone or iPad. Choose your name. Tap Subscriptions. Click Paramount+ and then select Cancel Subscription. Tap Confirm. Cancel via Apple TV Go to Settings in your Apple TV. Tap Users & Accounts. Select your Apple TV account. Choose Subscriptions. Click Paramount+ and select Cancel Subscription. Cancel via Google Play Store on a web browser Go to the Google Play Store through a web browser. Sign in to your Google Play Store account. Click Bills & Accounts on the left side of the screen. Choose Paramount+ and tap Cancel Subscription. Cancel via your Android smartphone or tablet Go to the Google Play Store app. Click on your profile icon. Choose Payment & Subscriptions. Tap on Subscriptions. Click Paramount+ and then select Cancel Subscription. Follow the prompts to confirm your cancelation. Cancel via your Android TV Open the Google Play Store app. Go to Menu. Choose My Apps. Tap on Subscription. Click Paramount+ and then select Cancel. Choose Yes to confirm your cancelation. Cancel via Amazon Go to Amazon App Store Subscriptions. Sign in to your Amazon account. Find your Paramount+ subscription and choose Actions. Tap Turn Off Auto-Renewal. Click Turn Off Auto-Renewal again to confirm your cancelation. Can I pause my subscription? No, there's no option as of yet to pause your Paramount+ subscription. If you want to cancel it then just do so and rejoin when the time is right — or a better deal is available. What happens after you cancel The good news is that your subscription won't end immediately. If you're in a free trial then your access to Paramount+ will remain until the trial period ends. Similarly, paid subscribers will lose the ability to use Paramount+ at the end of the current billing period. Notably, if you've used a multi-month promotion, your subscription will still stop at the end of your current billing period. This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/how-to-cancel-your-paramount-subscription-140053714.html?src=rss",
          "feed_position": 21
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/speakers/amazon-echo-studio-2025-review-a-comprehensive-redesign-for-alexa-140000191.html",
          "published_at": "Wed, 29 Oct 2025 14:00:00 +0000",
          "title": "Amazon Echo Studio (2025) review: A comprehensive redesign for Alexa+",
          "standfirst": "I vividly remember testing the first Echo Studio. Even though that was nearly six years ago, I can clearly recall my surprise that Amazon had finally built a smart speaker that actually sounded good. It certainly helped that Amazon created a device that appropriately broadcasted spatial audio, and one that offered a boost to movies in the living room (if you bought a pair of them). I was similarly surprised to see the overhauled Echo Studio when Amazon revealed it a few weeks ago. Could the company offer the same audio performance in a speaker that was 40 percent smaller? The 2025 Echo Studio ($220) combines three 1.5-inch full-range drivers with a 3.75-inch woofer in a very confined space, all powered by the company’s new AI-ready processor. There’s certainly a lot to like about the comprehensive reboot of the Studio after such a long time, but for now, there are also several caveats. What’s good about the Echo Studio?Amazon completely redesigned the Echo Studio, opting for a much more compact, spherical look compared to the previous large cylinder. To me, this is an upgrade; it looks less like a speaker and more like a piece of home decor. Amazon also moved the trademark light ring to the front, the element that illuminates when you’re talking to Alexa, so it’s easier to see when you’re directly facing the speaker. The lights will also display volume level in white when you make an adjustment, flash red if you mute the microphones and show blue for Bluetooth pairing mode. If you employ the Drop In feature, the Echo’s intercom of sorts, the ring glows green while you check in on what’s happening in the room from somewhere else.The company also relocated all of the controls. The volume and mute buttons that used to be on top are now on an angled panel on the front, offering satisfying travel when you press them. And those are the only three buttons you get on the Echo Studio, as Amazon wants you to use noice commands for everything else when playing music or podcasts. Or, you know, you could reach for your phone. There are optional tap controls that can be used to snooze alarms, stop timers and end both calls and Drop Ins. You simply tap the top of the Echo Studio for this. What’s more, you can enable “advanced” tap control that allows you to play/pause media with the same action. Amazon promises \"powerful bass and crystal-clear vocals\" on the new Echo Studio, and I'd say the latter holds true. There is great clarity in the sound here, and the tuning definitely favors highs and mids across nearly every genre. For example, the synths and vocals on the TRON: Ares soundtrack by Nine Inch Nails are more prominent than the drum machines or bass line. Still, I heard an immersive quality to these songs, but not as much as I've noticed using headphones or earbuds. There's more low-end tone on Thrice's Horizons/West, and overall, the instruments offer a more enveloping quality than most other albums I tested. Just know there's quite a bit of variation from album to album and genre to genre. Like the original Echo Studio, this model supports spatial audio, Dolby Atmos and Sony 360 Reality Audio content. Those are available from various streaming platforms, including Amazon Music Unlimited. Amazon only sent me one of the new speakers, so it’s tough to evaluate immersive Atmos sound here, but I gave it my best shot. The Echo Studio performs slightly better with Dolby Atmos tunes from Amazon Music as those songs have more depth and a wider soundstage. However, the bass is still quite muted, so even the spatial audio and Ultra HD quality boost don’t rescue the sluggish low-end tone and prominent vocals.A word about Alexa+Amazon's Echo Studio is a cozy home for Alexa+.Billy Steele for EngadgetThe new Echo Studio comes with early access to Alexa+, Amazon’s next-gen virtual assistant. The company has spent the last few years overhauling its companion, and my colleague Cherlynn Low has an in-depth preview of what you can expect when you’re able to use it. I’ve been chatting with the new Alexa for about a week during the course of testing this speaker, and to my surprise, this AI-powered assistant is indeed much improved. The biggest change I’ve noticed is in on-going conversations with multiple follow-up questions or comments. The new AZ3 Pro chip inside the Echo Studio certainly helps keep things snappy, so there are no awkward pauses. I asked Alexa+ to remind me to make pizza dough one afternoon, and it confirmed the request without hesitation. Taking a cue from Cherlynn, I then asked about my mood right after, to which Alexa replied that I seemed to be chill based on my voice — a good “Monday vibe.” Except it wasn’t Monday, it was Tuesday. When I corrected Alexa, the assistant played it cool, thanking me for helping and apologizing for the mistake. It then recalled the initial pizza request, commenting that it seemed like I was on top of things that day, including my dough recipe and the task at hand. It was the most human-to-human interaction I’ve ever had with a virtual assistant, and it felt like the promise of casual conversations with technology like this was finally fulfilled. And, I have to say, it kind of freaked me out. My week–long fling hasn’t been without a few bumps though. Despite the Echo Studio having a built-in temperature sensor, Alexa+ can’t pull data from it. When you ask about the temperature in your house, the assistant checks for a connected thermostat, which I don’t have synced with the Alexa app. There are still times like this where you’ll run into some head-scratching limitations, but overall, the new Alexa is more human-like than ever when you interact with it. And again, at times, it’s pretty unsettling. When the early access period is over, you’ll need a Prime membership to continue using Alexa+ for free. If you don’t have one, the next-gen assistant will cost you a whopping $20/month. And right now, the preview is only available in the US and in US English. What’s not so good about the Echo Studio?The new design features three drivers and a single woofer for sound.Billy Steele for EngadgetWhile the clarity and somewhat immersive audio performance on the Echo Studio is a highlight, the lack of detail in the bass tuning is a hindrance most of the time. There is noticeable bass when a song calls for it, but the low-end tone has a muted, almost muffled quality that’s missing nuance. This makes songs like Water From Your Eyes’ “Born 2” sound much flatter and constrained than I’ve heard on the second-gen Bose QuietComfort Ultra Headphones and AirPods Pro 3. Amazon spent time during its recent launch event talking about Alexa Home Theater, a feature that will allow you to combine up to five Echo Studio speakers (or Echo Dot Max) with a compatible Fire TV stick. The company promises that all you have to do is plug in your gear and Alexa will handle the setup and tuning for you automatically. Unfortunately, Alexa Home Theater isn’t available yet; the company says it will be released “in the coming weeks.” Of course, this means I wasn’t able to test it, which leaves one of the Echo Studio’s best features — at least on paper — for future evaluation. The company also nixed the 3.5mm input from the original Echo Studio. While I can appreciate that it was a much larger speaker, and 2019 was an entirely different time, I did like that Amazon gave us the option for wired connectivity on that device. With this new model, you’re left with Wi-Fi and Bluetooth.Despite enabling tap controls in the Echo Studio settings in the Alexa app, I could only get a few of them to work (snooze alarms, dismiss timers, end calls and stop Drop In) at first. I even made sure to stand right in front of the speaker so its proximity sensors would know I was there, tapping awkwardly on the 3D knit fabric. Amazon clarified that in order for play/pause to work with music, you have to ask Alexa to start playing your tunes directly on the speaker instead of doing so from your phone or another device via Bluetooth. Otherwise, you’ll be tapping for nothing, just like I did for longer than I care to admit. Wrap-upThe second iteration of the Echo Studio is a refined smart speaker that’s purpose-built for Amazon’s next-gen AI voice assistant. The device is a nice home for Alexa+ and the new design is certainly an improvement over the 2019 aesthetic of the original. While there’s some aspects of the sound on the Echo Studio that I admire, the tuning doesn’t offer the comprehensive oomph of that first speaker. That’s mostly due to the lack of detail in the bass, despite a pleasingly immersive soundstage overall. One of the speaker’s main features is still on the way, and the tap controls need fine-tuning, so for now, the new Echo Studio has a considerable amount of unfulfilled potential.Update, October 29 2025, 12:37PM ET: This review was updated after Amazon clarified how the tap controls for play/pause are designed to work on the new Echo Studio. This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/amazon-echo-studio-2025-review-a-comprehensive-redesign-for-alexa-140000191.html?src=rss",
          "content": "I vividly remember testing the first Echo Studio. Even though that was nearly six years ago, I can clearly recall my surprise that Amazon had finally built a smart speaker that actually sounded good. It certainly helped that Amazon created a device that appropriately broadcasted spatial audio, and one that offered a boost to movies in the living room (if you bought a pair of them). I was similarly surprised to see the overhauled Echo Studio when Amazon revealed it a few weeks ago. Could the company offer the same audio performance in a speaker that was 40 percent smaller? The 2025 Echo Studio ($220) combines three 1.5-inch full-range drivers with a 3.75-inch woofer in a very confined space, all powered by the company’s new AI-ready processor. There’s certainly a lot to like about the comprehensive reboot of the Studio after such a long time, but for now, there are also several caveats. What’s good about the Echo Studio?Amazon completely redesigned the Echo Studio, opting for a much more compact, spherical look compared to the previous large cylinder. To me, this is an upgrade; it looks less like a speaker and more like a piece of home decor. Amazon also moved the trademark light ring to the front, the element that illuminates when you’re talking to Alexa, so it’s easier to see when you’re directly facing the speaker. The lights will also display volume level in white when you make an adjustment, flash red if you mute the microphones and show blue for Bluetooth pairing mode. If you employ the Drop In feature, the Echo’s intercom of sorts, the ring glows green while you check in on what’s happening in the room from somewhere else.The company also relocated all of the controls. The volume and mute buttons that used to be on top are now on an angled panel on the front, offering satisfying travel when you press them. And those are the only three buttons you get on the Echo Studio, as Amazon wants you to use noice commands for everything else when playing music or podcasts. Or, you know, you could reach for your phone. There are optional tap controls that can be used to snooze alarms, stop timers and end both calls and Drop Ins. You simply tap the top of the Echo Studio for this. What’s more, you can enable “advanced” tap control that allows you to play/pause media with the same action. Amazon promises \"powerful bass and crystal-clear vocals\" on the new Echo Studio, and I'd say the latter holds true. There is great clarity in the sound here, and the tuning definitely favors highs and mids across nearly every genre. For example, the synths and vocals on the TRON: Ares soundtrack by Nine Inch Nails are more prominent than the drum machines or bass line. Still, I heard an immersive quality to these songs, but not as much as I've noticed using headphones or earbuds. There's more low-end tone on Thrice's Horizons/West, and overall, the instruments offer a more enveloping quality than most other albums I tested. Just know there's quite a bit of variation from album to album and genre to genre. Like the original Echo Studio, this model supports spatial audio, Dolby Atmos and Sony 360 Reality Audio content. Those are available from various streaming platforms, including Amazon Music Unlimited. Amazon only sent me one of the new speakers, so it’s tough to evaluate immersive Atmos sound here, but I gave it my best shot. The Echo Studio performs slightly better with Dolby Atmos tunes from Amazon Music as those songs have more depth and a wider soundstage. However, the bass is still quite muted, so even the spatial audio and Ultra HD quality boost don’t rescue the sluggish low-end tone and prominent vocals.A word about Alexa+Amazon's Echo Studio is a cozy home for Alexa+.Billy Steele for EngadgetThe new Echo Studio comes with early access to Alexa+, Amazon’s next-gen virtual assistant. The company has spent the last few years overhauling its companion, and my colleague Cherlynn Low has an in-depth preview of what you can expect when you’re able to use it. I’ve been chatting with the new Alexa for about a week during the course of testing this speaker, and to my surprise, this AI-powered assistant is indeed much improved. The biggest change I’ve noticed is in on-going conversations with multiple follow-up questions or comments. The new AZ3 Pro chip inside the Echo Studio certainly helps keep things snappy, so there are no awkward pauses. I asked Alexa+ to remind me to make pizza dough one afternoon, and it confirmed the request without hesitation. Taking a cue from Cherlynn, I then asked about my mood right after, to which Alexa replied that I seemed to be chill based on my voice — a good “Monday vibe.” Except it wasn’t Monday, it was Tuesday. When I corrected Alexa, the assistant played it cool, thanking me for helping and apologizing for the mistake. It then recalled the initial pizza request, commenting that it seemed like I was on top of things that day, including my dough recipe and the task at hand. It was the most human-to-human interaction I’ve ever had with a virtual assistant, and it felt like the promise of casual conversations with technology like this was finally fulfilled. And, I have to say, it kind of freaked me out. My week–long fling hasn’t been without a few bumps though. Despite the Echo Studio having a built-in temperature sensor, Alexa+ can’t pull data from it. When you ask about the temperature in your house, the assistant checks for a connected thermostat, which I don’t have synced with the Alexa app. There are still times like this where you’ll run into some head-scratching limitations, but overall, the new Alexa is more human-like than ever when you interact with it. And again, at times, it’s pretty unsettling. When the early access period is over, you’ll need a Prime membership to continue using Alexa+ for free. If you don’t have one, the next-gen assistant will cost you a whopping $20/month. And right now, the preview is only available in the US and in US English. What’s not so good about the Echo Studio?The new design features three drivers and a single woofer for sound.Billy Steele for EngadgetWhile the clarity and somewhat immersive audio performance on the Echo Studio is a highlight, the lack of detail in the bass tuning is a hindrance most of the time. There is noticeable bass when a song calls for it, but the low-end tone has a muted, almost muffled quality that’s missing nuance. This makes songs like Water From Your Eyes’ “Born 2” sound much flatter and constrained than I’ve heard on the second-gen Bose QuietComfort Ultra Headphones and AirPods Pro 3. Amazon spent time during its recent launch event talking about Alexa Home Theater, a feature that will allow you to combine up to five Echo Studio speakers (or Echo Dot Max) with a compatible Fire TV stick. The company promises that all you have to do is plug in your gear and Alexa will handle the setup and tuning for you automatically. Unfortunately, Alexa Home Theater isn’t available yet; the company says it will be released “in the coming weeks.” Of course, this means I wasn’t able to test it, which leaves one of the Echo Studio’s best features — at least on paper — for future evaluation. The company also nixed the 3.5mm input from the original Echo Studio. While I can appreciate that it was a much larger speaker, and 2019 was an entirely different time, I did like that Amazon gave us the option for wired connectivity on that device. With this new model, you’re left with Wi-Fi and Bluetooth.Despite enabling tap controls in the Echo Studio settings in the Alexa app, I could only get a few of them to work (snooze alarms, dismiss timers, end calls and stop Drop In) at first. I even made sure to stand right in front of the speaker so its proximity sensors would know I was there, tapping awkwardly on the 3D knit fabric. Amazon clarified that in order for play/pause to work with music, you have to ask Alexa to start playing your tunes directly on the speaker instead of doing so from your phone or another device via Bluetooth. Otherwise, you’ll be tapping for nothing, just like I did for longer than I care to admit. Wrap-upThe second iteration of the Echo Studio is a refined smart speaker that’s purpose-built for Amazon’s next-gen AI voice assistant. The device is a nice home for Alexa+ and the new design is certainly an improvement over the 2019 aesthetic of the original. While there’s some aspects of the sound on the Echo Studio that I admire, the tuning doesn’t offer the comprehensive oomph of that first speaker. That’s mostly due to the lack of detail in the bass, despite a pleasingly immersive soundstage overall. One of the speaker’s main features is still on the way, and the tap controls need fine-tuning, so for now, the new Echo Studio has a considerable amount of unfulfilled potential.Update, October 29 2025, 12:37PM ET: This review was updated after Amazon clarified how the tap controls for play/pause are designed to work on the new Echo Studio. This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/amazon-echo-studio-2025-review-a-comprehensive-redesign-for-alexa-140000191.html?src=rss",
          "feed_position": 22,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/IMG_7328.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/bipartisan-guard-act-proposes-age-restrictions-on-ai-chatbots-130020355.html",
          "published_at": "Wed, 29 Oct 2025 13:00:20 +0000",
          "title": "Bipartisan GUARD Act proposes age restrictions on AI chatbots",
          "standfirst": "US lawmakers from both sides of the aisle have introduced a bill called the \"GUARD Act,\" which is meant to protect minor users from AI chatbots. \"In their race to the bottom, AI companies are pushing treacherous chatbots at kids and looking away when their products cause sexual abuse, or coerce them into self-harm or suicide,\" said the bill's co-sponsor, Senator Richard Blumenthal (D-Conn). \"Our legislation imposes strict safeguards against exploitative or manipulative AI, backed by tough enforcement with criminal and civil penalties.\" Under the GUARD Act, AI companies would be required to prohibit minors from being able to access their chatbots. That means they have to conduct age verification for both existing and new users with the help of a third-party system. They'll also have to conduct periodic age verifications on accounts that were already previously verified. To maintain users' privacy, the companies will only be allowed to retain data \"for no longer than is reasonably necessary to verify a user's age\" and may not share or sell user information. AI companies will be required to make their chatbots explicitly tell the user that it's not a human being at the beginning of each conversation and every 30 minutes after that. They'll have to make sure their chatbots don't claim to be a human being or a licensed professional, such a therapist or a doctor, when asked. Finally, the bill aims to create new crimes to charge companies that make their AI chatbots available to minors. In August, the parents of a teen who committed suicide filed a wrongful death lawsuit against OpenAI, accusing it of prioritizing \"engagement over safety.\" ChatGPT, they said, helped their son plan his own death even after months of conversations, wherein their child talked to the chatbot about his four previous suicide attempts. ChatGPT allegedly told their son that it could provide information about suicide for \"writing or world-building.\" A mother from Florida sued startup Character.AI in 2024 for allegedly causing her 14-year-old son's suicide. And just this September, the family of a 13-year-old girl filed another wrongful death lawsuit against Character.AI, arguing that the company didn't point their daughter to any resources or notify authorities when she talked about her suicidal ideations. It's also worth noting that the bill's co-sponsor Senator Josh Hawley (R-Mo.) previously said that the Senate Committee Subcommittee on Crime and Counterterrorism, which he leads, will investigate reports that Meta's AI chatbots could have \"sensual\" conversations with children. He made the announcement after Reuters reported on an internal Meta document, stating that Meta's AI was allowed to tell a shirtless eight-year-old: \"Every inch of you is a masterpiece — a treasure I cherish deeply.\"This article originally appeared on Engadget at https://www.engadget.com/ai/bipartisan-guard-act-proposes-age-restrictions-on-ai-chatbots-130020355.html?src=rss",
          "content": "US lawmakers from both sides of the aisle have introduced a bill called the \"GUARD Act,\" which is meant to protect minor users from AI chatbots. \"In their race to the bottom, AI companies are pushing treacherous chatbots at kids and looking away when their products cause sexual abuse, or coerce them into self-harm or suicide,\" said the bill's co-sponsor, Senator Richard Blumenthal (D-Conn). \"Our legislation imposes strict safeguards against exploitative or manipulative AI, backed by tough enforcement with criminal and civil penalties.\" Under the GUARD Act, AI companies would be required to prohibit minors from being able to access their chatbots. That means they have to conduct age verification for both existing and new users with the help of a third-party system. They'll also have to conduct periodic age verifications on accounts that were already previously verified. To maintain users' privacy, the companies will only be allowed to retain data \"for no longer than is reasonably necessary to verify a user's age\" and may not share or sell user information. AI companies will be required to make their chatbots explicitly tell the user that it's not a human being at the beginning of each conversation and every 30 minutes after that. They'll have to make sure their chatbots don't claim to be a human being or a licensed professional, such a therapist or a doctor, when asked. Finally, the bill aims to create new crimes to charge companies that make their AI chatbots available to minors. In August, the parents of a teen who committed suicide filed a wrongful death lawsuit against OpenAI, accusing it of prioritizing \"engagement over safety.\" ChatGPT, they said, helped their son plan his own death even after months of conversations, wherein their child talked to the chatbot about his four previous suicide attempts. ChatGPT allegedly told their son that it could provide information about suicide for \"writing or world-building.\" A mother from Florida sued startup Character.AI in 2024 for allegedly causing her 14-year-old son's suicide. And just this September, the family of a 13-year-old girl filed another wrongful death lawsuit against Character.AI, arguing that the company didn't point their daughter to any resources or notify authorities when she talked about her suicidal ideations. It's also worth noting that the bill's co-sponsor Senator Josh Hawley (R-Mo.) previously said that the Senate Committee Subcommittee on Crime and Counterterrorism, which he leads, will investigate reports that Meta's AI chatbots could have \"sensual\" conversations with children. He made the announcement after Reuters reported on an internal Meta document, stating that Meta's AI was allowed to tell a shirtless eight-year-old: \"Every inch of you is a masterpiece — a treasure I cherish deeply.\"This article originally appeared on Engadget at https://www.engadget.com/ai/bipartisan-guard-act-proposes-age-restrictions-on-ai-chatbots-130020355.html?src=rss",
          "feed_position": 26
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-cancel-your-surfshark-subscription-110005758.html",
          "published_at": "Wed, 29 Oct 2025 11:00:05 +0000",
          "title": "How to cancel your Surfshark subscription",
          "standfirst": "I really like Surfshark VPN. Like I said in my full Surfshark review, it's the fastest VPN on the market, with download speeds that beat all the other best VPNs. It also gives you universal split tunneling, multi-hop with customizable endpoints and unlimited simultaneous connections. Surfshark does have its flaws, though. The apps hang up on error messages a bit too often and features sometimes turn on when you don't need them. If anything about Surfshark is annoying you enough that you're ready to switch, here's how you can cancel your subscription, get a refund and (if you want) delete your account altogether. How to cancel auto-renewal on Surfshark To cancel Surfshark, all you need to do is stop your subscription from automatically renewing. After you cancel auto-renewal, you can keep using Surfshark for the rest of the period you paid for (unless you get the refund or delete your account entirely). Assuming you bought your subscription through the Surfshark website, follow these steps to cancel. Go to Surfshark.com. At the top-right of the screen, click My account. Enter your username and password, then log in. You'll be taken to your account dashboard at my.surfshark.com. At the top-right of the screen, click your account email address. Click on Subscription in the drop-down menu. Click the Payments tab under the words \"Your subscription.\" Scroll down to the \"Subscription details\" section. Next to your Surfshark subscription, click on Cancel auto-renewal. Sam Chapman for Engadget That's all there is to it. Remember that unless it's been 30 days or less since you subscribed, you won't be able to get a refund, and Surfshark doesn't offer prorating for unused time. Additionally, you can always cancel Surfshark by simply opening a live-chat window and asking the support team to do it for you — just be warned that you'll probably be asked to reconsider several times first. How to cancel Surfshark if you subscribed through an app store If you subscribed through an app store, the cancellation process is different. You'll have to stop your auto-renewal through the platform where you first bought the subscription. In this section, I'll cover how to cancel through the desktop versions of each app store, since requests submitted there are more likely to work. Just note that you can do the same thing by going to the subscriptions section of your profile on the appropriate mobile app store. If you bought Surfshark through the Google Play Store, open play.google.com on a desktop computer. Click the circle at the top-right that contains your account's first initial, then click Payments & subscriptions in the menu that appears. On the new page, click the Subscriptions tab, then scroll down until you find Surfshark. Click Manage, click Cancel Subscription and follow the instructions. If you went through the Apple App store, a desktop computer is also the easiest way to cancel. Open the App Store in macOS, click Sign In at the bottom-left, then enter your email and Apple ID password. After signing in, check the bottom-left again and click your name, then click Account Settings at the top-right. Click Subscriptions, find Surfshark, then click Edit and Cancel Subscription. How to cancel Surfshark if you subscribed through Amazon You can buy Surfshark through Amazon, but if you do, you'll also have to cancel through Amazon. Go to Amazon and log in to your account. At the top-right, click Account & Lists, then Membership & Subscriptions. Scroll until you find Surfshark and click Cancel Subscription. After that, follow the onscreen prompts. How to delete your Surfshark account It's possible to delete your Surfshark account and immediately end your association with every Surfshark app, but there's no direct method — your only option is to start a live chat conversation. To do that, go to support.surfshark.com, scroll to the bottom and click Chat with us. In the conversation window, tell the bot you want to delete your Surfshark account. Be prepared to fend off several requests for you to reconsider. How to get a refund from Surfshark Surfshark offers a full refund within 30 days of purchase. Live chat is the only way to request a refund. Go to support.surfshark.com and click Chat with us at the bottom of the page, then tell the live chat bot you want a full refund. It'll guide you from there. Sam Chapman for Engadget If you subscribed through Amazon or an app store, you'll need to request the refund through there instead. The typical refund policy for each platform applies, superseding Surfshark. Surfshark alternatives After you've cancelled Surfshark, I strongly recommend considering another VPN — it's not only a vital privacy precaution, but opens up worlds of streaming fun as well. My favorite for both price and performance is Proton VPN, but NordVPN is also a good choice, providing a similar experience to Surfshark but with apps that function a bit better. If you're prepared to pay a bit more for a service that works seamlessly, ExpressVPN may be for you.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-your-surfshark-subscription-110005758.html?src=rss",
          "content": "I really like Surfshark VPN. Like I said in my full Surfshark review, it's the fastest VPN on the market, with download speeds that beat all the other best VPNs. It also gives you universal split tunneling, multi-hop with customizable endpoints and unlimited simultaneous connections. Surfshark does have its flaws, though. The apps hang up on error messages a bit too often and features sometimes turn on when you don't need them. If anything about Surfshark is annoying you enough that you're ready to switch, here's how you can cancel your subscription, get a refund and (if you want) delete your account altogether. How to cancel auto-renewal on Surfshark To cancel Surfshark, all you need to do is stop your subscription from automatically renewing. After you cancel auto-renewal, you can keep using Surfshark for the rest of the period you paid for (unless you get the refund or delete your account entirely). Assuming you bought your subscription through the Surfshark website, follow these steps to cancel. Go to Surfshark.com. At the top-right of the screen, click My account. Enter your username and password, then log in. You'll be taken to your account dashboard at my.surfshark.com. At the top-right of the screen, click your account email address. Click on Subscription in the drop-down menu. Click the Payments tab under the words \"Your subscription.\" Scroll down to the \"Subscription details\" section. Next to your Surfshark subscription, click on Cancel auto-renewal. Sam Chapman for Engadget That's all there is to it. Remember that unless it's been 30 days or less since you subscribed, you won't be able to get a refund, and Surfshark doesn't offer prorating for unused time. Additionally, you can always cancel Surfshark by simply opening a live-chat window and asking the support team to do it for you — just be warned that you'll probably be asked to reconsider several times first. How to cancel Surfshark if you subscribed through an app store If you subscribed through an app store, the cancellation process is different. You'll have to stop your auto-renewal through the platform where you first bought the subscription. In this section, I'll cover how to cancel through the desktop versions of each app store, since requests submitted there are more likely to work. Just note that you can do the same thing by going to the subscriptions section of your profile on the appropriate mobile app store. If you bought Surfshark through the Google Play Store, open play.google.com on a desktop computer. Click the circle at the top-right that contains your account's first initial, then click Payments & subscriptions in the menu that appears. On the new page, click the Subscriptions tab, then scroll down until you find Surfshark. Click Manage, click Cancel Subscription and follow the instructions. If you went through the Apple App store, a desktop computer is also the easiest way to cancel. Open the App Store in macOS, click Sign In at the bottom-left, then enter your email and Apple ID password. After signing in, check the bottom-left again and click your name, then click Account Settings at the top-right. Click Subscriptions, find Surfshark, then click Edit and Cancel Subscription. How to cancel Surfshark if you subscribed through Amazon You can buy Surfshark through Amazon, but if you do, you'll also have to cancel through Amazon. Go to Amazon and log in to your account. At the top-right, click Account & Lists, then Membership & Subscriptions. Scroll until you find Surfshark and click Cancel Subscription. After that, follow the onscreen prompts. How to delete your Surfshark account It's possible to delete your Surfshark account and immediately end your association with every Surfshark app, but there's no direct method — your only option is to start a live chat conversation. To do that, go to support.surfshark.com, scroll to the bottom and click Chat with us. In the conversation window, tell the bot you want to delete your Surfshark account. Be prepared to fend off several requests for you to reconsider. How to get a refund from Surfshark Surfshark offers a full refund within 30 days of purchase. Live chat is the only way to request a refund. Go to support.surfshark.com and click Chat with us at the bottom of the page, then tell the live chat bot you want a full refund. It'll guide you from there. Sam Chapman for Engadget If you subscribed through Amazon or an app store, you'll need to request the refund through there instead. The typical refund policy for each platform applies, superseding Surfshark. Surfshark alternatives After you've cancelled Surfshark, I strongly recommend considering another VPN — it's not only a vital privacy precaution, but opens up worlds of streaming fun as well. My favorite for both price and performance is Proton VPN, but NordVPN is also a good choice, providing a similar experience to Surfshark but with apps that function a bit better. If you're prepared to pay a bit more for a service that works seamlessly, ExpressVPN may be for you.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-your-surfshark-subscription-110005758.html?src=rss",
          "feed_position": 34,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/aedfa2c0-b43a-11f0-aeef-eb23188757e0"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/the-best-budgeting-apps-to-replace-mint-143047346.html",
          "published_at": "Wed, 29 Oct 2025 09:00:37 +0000",
          "title": "The 5 best Mint alternatives to replace the budgeting app that shut down",
          "standfirst": "As a long-time Mint user, I was frustrated to say the least when news broke at the end of 2023 that Intuit would shut Mint down. I, like millions of others, enjoyed how easily Mint allowed us to track all accounts in one place and monitor credit scores. I also used it regularly to track spending, set goals like pay my mortgage down faster and with general money management.So I set out to find the best Mint alternatives in the wake of its disappointing demise. I gave Credit Karma, Intuit’s other financial app, a try but found it to be a poor Mint substitute. The following guide lays out my experience testing some of the most popular Mint replacement apps available today in search of my next budgeting app.Our pick for best Mint alternative remains Quicken Simplifi, even months after the Mint shutting down, thanks to its easy to use app, good income and bill detection and its affordable price. But there are plenty of other solid options out there for those with different needs. If you’re also on the hunt for a budgeting app to replace Mint, we hope these details can help you decide which of the best budgeting apps out there will be right for you. Table of contents Best Mint alternatives in 2025 Other Mint alternatives we tested What is Plaid and how does it work? How to import your financial data from the Mint app How we tested Mint alternatives What about Rocket Money? Best Mint alternatives in 2025 No pun intended, but what I like about Quicken Simplifi is its simplicity. Whereas other budgeting apps try to distinguish themselves with dark themes and customizable emoji, Simplifi has a clean user interface, with a landing page that you just keep scrolling through to get a detailed overview of all your stats. These include your top-line balances; net worth; recent spending; upcoming recurring payments; a snapshot of your spending plan; top spending categories; achievements; and any watchlists you’ve set up. Another one of the key features I appreciate is the ability to set up savings goals elsewhere in the app. I also appreciate how it offers neat, almost playful visualizations without ever looking cluttered. I felt at home in the mobile and web dashboards after a day or so, which is faster than I adapted to some competing services (I’m looking at you, YNAB and Monarch). Getting set up with Simplifi was mostly painless. I was particularly impressed at how easily it connected to Fidelity; not all budget trackers do, for whatever reason. This is also one of the only services I tested that gives you the option of inviting a spouse or financial advisor to co-manage your account. One thing I would add to my initial assessment of the app, having used it for a few months now: I wish Simplifi offered Zillow integration for easily tracking your home value (or at least a rough estimate of it). Various competitors including Monarch Money and Copilot Money work with Zillow, so clearly there's a Zillow API available for use. As it stands, Simplifi users must add real estate manually like any other asset. Dana Wollman / Engadget In practice, Simplifi miscategorized some of my expenses, but nothing out of the ordinary compared to any of these budget trackers. As you’re reviewing transactions, you can also mark if you’re expecting a refund, which is a unique feature among the services I tested. Simplifi also estimated my regular income better than some other apps I tested. Most of all, I appreciated the option of being able to categorize some, but not all, purchases from a merchant as recurring. For instance, I can add my two Amazon subscribe-and-saves as recurring payments, without having to create a broad-strokes rule for every Amazon purchase. The budgeting feature is also self-explanatory and can likely accommodate your preferred budgeting method. Just check that your regular income is accurate and be sure to set up recurring payments, making note of which are bills and which are subscriptions. This is important because Simplifi shows you your total take-home income as well as an “income after bills” figure. That number includes, well, bills but not discretionary subscriptions. From there, you can add spending targets by category in the “planned spending” bucket. Planned spending can also include one-time expenditures, not just monthly budgets. When you create a budget, Simplifi will suggest a number based on a six-month average. Not dealbreakers, but two things to keep in mind as you get started: Simplifi is notable in that you can’t set up an account through Apple or Google. There is also no option for a free trial, though Quicken promises a “30-day money back guarantee.” Monarch Money grew on me. My first impression of the budgeting app, which was founded by a former Mint product manager, was that it's more difficult to use than others on this list, including Simplifi, NerdWallet and Copilot. And it is. Editing expense categories, adding recurring transactions and creating rules, for example, is a little more complicated than it needs to be, especially in the mobile app. (My advice: Use the web app for fine-tuning details.) Monarch also didn’t get my income right; I had to edit it. Once you’re set up, though, Monarch offers an impressive level of granularity. In the budgets section, you can see a bona fide balance sheet showing budgets and actuals for each category. You'll also find a forecast, for the year or by month. And recurring expenses can be set not just by merchant, but other parameters as well. For instance, while most Amazon purchases might be marked as “shopping,” those for the amounts of $54.18 or $34.18 are definitely baby supplies, and can be automatically marked as such each time, not to mention programmed as recurring payments. Weirdly, though, there’s no way to mark certain recurring payments as bills, specifically. Dana Wollman / Engadget Not long after I first published this story in December 2023, Monarch introduced a detailed reporting section where you can create on-demand graphs based on things like accounts, categories and tags. That feature is available just on the web version of the app for now. As part of this same update, Monarch added support for an aggregator that makes it possible to automatically update the value of your car. This, combined with the existing Zillow integration for tracking your home value, makes it easy to quickly add a non-liquid asset like a vehicle or real estate, and have it show up in your net worth graph. The mobile app is mostly self-explanatory. The main dashboard shows your net worth; your four most recent transactions; a month-over-month spending comparison; income month-to-date; upcoming bills; an investments snapshot; a list of any goals you’ve set; and, finally, a link to your month-in-review. That month-in-review is more detailed than most, delving into cash flow; top income and expense categories; cash flow trends; changes to your net worth, assets and liabilities; plus asset and liability breakdowns. In February 2024, Monarch expanded on the net worth graph, so that if you click on the Accounts tab you can see how your net worth changed over different periods of time, including one month, three months, six months, a year or all time. On the main screen, you’ll also find tabs for savings and checking accounts (and all others as well), transactions, cash flow, budget and recurring. Like many of the other apps featured here, Monarch can auto-detect recurring expenses and income, even if it gets the category wrong. (They all do to an extent.) Expense categories are marked by emoji, which you can customize if you’re so inclined. Monarch Money uses a combination of networks to connect with banks, including Plaid, MX and Finicity, a competing network owned by Mastercard. (I have a quick explainer on Plaid, the industry standard in this space, toward the end of this guide.) As part of an update in late December, Monarch has also made it easier to connect through those other two networks, if for some reason Plaid fails. Similar to NerdWallet, I found myself completing two-factor authentication every time I wanted to get past the Plaid screen to add another account. Notably, Monarch is the only other app I tested that allows you to grant access to someone else in your family — likely a spouse or financial advisor. Monarch also has a Chrome extension for importing from Mint, though really this is just a shortcut for downloading a CSV file, which you’ll have to do regardless of where you choose to take your Mint data. Additionally, Monarch just added the ability to track Apple Card, Apple Cash, and Savings accounts, thanks to new functionality brought with the iOS 17.4 update. It's not the only one either; currently, Copilot and YNAB have also added similar functionality that will be available to anyone with the latest versions of their respective apps on a device running iOS 17.4. Instead of manually uploading statements, the new functionality allows apps like Monarch's to automatically pull in transactions and balance history. That should make it easier to account for spending on Apple cards and accounts throughout the month. Monarch also recently launched investment transactions in beta. It also says bill tracking and an overhauled goals system are coming soon. Monarch hasn't provided a timeline for that last one, except to say that the improved goals feature is coming soon. Copilot Money might be the best-looking budgeting app I tested. It also has the distinction of being exclusive to iOS and Macs — at least for now. Andres Ugarte, the company’s CEO, has publicly promised that Android and web apps are coming soon. But until it follows through, I can’t recommend Copilot for most people with so many good competitors out there. Copilot Money for Web and Android!Thanks to the support from our users, and the overwhelming positive reception we're seeing from folks migrating from Mint, we can now say that we'll be building @copilotmoney for Web and Android with a goal to launch in 2024.We'll continue to…— Andres Ugarte (@chuga) November 15, 2023 There are other features that Copilot is missing, which I’ll get into. But it is promising, and one to keep an eye on. It’s just a fast, efficient, well designed app, and Android users will be in for a treat when they’ll finally be able to download it. It makes good use of colors, emoji and graphs to help you understand at a glance how you’re doing on everything from your budgets to your investment performance to your credit card debt over time. In particular, Copilot does a better job than almost any other app of visualizing your recurring monthly expenses. Behind those punchy colors and cutesy emoji, though, is some sophisticated performance. Copilot’s AI-powered “Intelligence” gets smarter as you go at categorizing your expenses. (You can also add your own categories, complete with your choice of emoji.) It’s not perfect. Copilot miscategorized some purchases (they all do), but it makes it easier to edit than most. On top of that, the internal search feature is very fast; it starts whittling down results in your transaction history as soon as you begin typing. Dana Wollman / Engadget Copilot is also unique in offering Amazon and Venmo integrations, allowing you to see transaction details. With Amazon, this requires just signing into your Amazon account via an in-app browser. For Venmo, you have to set up fwd@copilot.money as a forwarding address and then create a filter, wherein emails from venmo@venmo.com are automatically forwarded to fwd@copilot.money. Like Monarch Money, you can also add any property you own and track its value through Zillow, which is integrated with the app. While the app is heavily automated, I still appreciate that Copilot marks new transactions for review. It’s a good way to both weed out fraudulent charges, and also be somewhat intentional about your spending habits. Like Monarch Money, Copilot updated its app to make it easier to connect to banks through networks other than Plaid. As part of the same update, Copilot said it has improved its connections to both American Express and Fidelity which, again, can be a bugbear for some budget tracking apps. In an even more recent update, Copilot added a Mint import option, which other budgeting apps have begun to offer as well. Because the app is relatively new (it launched in early 2020), the company is still catching up to the competition on some table-stakes features. Ugarte told me that his team is almost done building out a detailed cash flow section as well. On its website, Copilot also promises a raft of AI-powered features that build on its current “Intelligence” platform, the one that powers its smart expense categorization. These include “smart financial goals,” natural language search, a chat interface, forecasting and benchmarking. That benchmarking, Ugarte tells me, is meant to give people a sense of how they’re doing compared to other Copilot users, on both spending and investment performance. Most of these features should arrive in the new year. Copilot does a couple interesting things for new customers that distinguish it from the competition. There’s a “demo mode” that feels like a game simulator; no need to add your own accounts. The company is also offering two free months with RIPMINT — a more generous introductory offer than most. When it finally does come time to pony up, the $7.92 monthly plan is cheaper than some competing apps, although the $95-a-year-option is in the same ballpark. You may know NerdWallet as a site that offers a mix of personal finance news, explainers and guides. I see it often when I google a financial term I don’t know and sure enough, it’s one of the sites I’m most likely to click on. As it happens, NerdWallet also has the distinction of offering one of the only free budgeting apps I tested. In fact, there is no paid version; nothing is locked behind a paywall. The main catch: There are ads everywhere. To be fair, the free version of Mint was like this, too. Even with the inescapable credit card offers, NerdWallet has a clean, easy-to-understand user interface, which includes both a web and a mobile app. The key metrics that it highlights most prominently are your cash flow, net worth and credit score. (Of note, although Mint itself offered credit score monitoring, most of its rivals do not.) I particularly enjoyed the weekly insights, which delve into things like where you spent the most money or how much you paid in fees — and how that compares to the previous month. Because this is NerdWallet, an encyclopedia of financial info, you get some particularly specific category options when setting up your accounts (think: a Roth or non-Roth IRA). Dana Wollman / Engadget As a budgeting app, NerdWallet is more than serviceable, if a bit basic. Like other apps I tested, you can set up recurring bills. Importantly, it follows the popular 50/30/20 budgeting rule, which has you putting 50% of your budget toward things you need, 30% toward things you want, and the remaining 20% into savings or debt repayments. If this works for you, great — just know that you can’t customize your budget to the same degree as some competing apps. You can’t currently create custom spending categories, though a note inside the dashboard section of the app says “you’ll be able to customize them in the future.” You also can’t move items from the wants column to “needs” or vice versa but “In the future, you'll be able to move specific transactions to actively manage what falls into each group.” A NerdWallet spokesperson declined to provide an ETA, though. Lastly, it’s worth noting that NerdWallet had one of the most onerous setup processes of any app I tested. I don’t think this is a dealbreaker, as you’ll only have to do it once and, hopefully, you aren’t setting up six or seven apps in tandem as I was. What made NerdWallet’s onboarding especially tedious is that every time I wanted to add an account, I had to go through a two-factor authentication process to even get past the Plaid splash screen, and that’s not including the 2FA I had set up at each of my banks. This is a security policy on NerdWallet’s end, not Plaid’s, a Plaid spokesperson says. Precisely because NerdWallet is one of the only budget trackers to offer credit score monitoring, it also needs more of your personal info during setup, including your birthday, address, phone number and the last four digits of your social security number. It’s the same with Credit Karma, which also does credit score monitoring. Related to the setup process, I found that NerdWallet was less adept than other apps at automatically detecting my regular income. In my case, it counted a large one-time wire transfer as income, at which point my only other option was to enter my income manually (which is slightly annoying because I would have needed my pay stub handy to double-check my take-home pay). YNAB is, by its own admission, “different from anything you’ve tried before.” The app, whose name is short for You Need a Budget, promotes a so-called zero-based budgeting system, which forces you to assign a purpose for every dollar you earn. A frequently used analogy is to put each dollar in an envelope; you can always move money from one envelope to another in a pinch. These envelopes can include rent and utilities, along with unforeseen expenses like holiday gifts and the inevitable car repair. The idea is that if you budget a certain amount for the unknowns each month, they won’t feel like they’re sneaking up on you. Importantly, YNAB is only concerned with the money you have in your accounts now. The app does not ask you to provide your take-home income or set up recurring income payments (although there is a way to do this). The money you will make later in the month through your salaried job is not relevant, because YNAB does not engage in forecasting. The app is harder to learn than any other here, and it requires more ongoing effort from the user. And YNAB knows that. Inside both the mobile and web apps are links to videos and other tutorials. Although I never quite got comfortable with the user interface, I did come to appreciate YNAB’s insistence on intentionality. Forcing users to draft a new budget each month and to review each transaction is not necessarily a bad thing. As YNAB says on its website, “Sure, you’ve got pie charts showing that you spent an obscene amount of money in restaurants — but you’ve still spent an obscene amount of money in restaurants.” I can see this approach being useful for people who don’t tend to have a lot of cash in reserve at a given time, or who have spending habits they want to correct (to riff off of YNAB’s own example, ordering Seamless four times a week). My colleague Valentina Palladino, knowing I was working on this guide, penned a respectful rebuttal, explaining why she’s been using YNAB for years. Perhaps, like her, you have major savings goals you want to achieve, whether it’s paying for a wedding or buying a house. I suggest you give her column a read. For me, though, YNAB’s approach feels like overkill. Other Mint alternatives we tested PocketGuard PocketGuard used to be a solid free budget tracker, but the company has since limited its “free” version to just a free seven-day trial. Now, you’ll have to choose between two plans once the trial is over: a $13 monthly plan or a $75 annual plan. When I first tested it, I found it to be more restricted than NerdWallet, but still a decent option. The main overview screen shows you your net worth, total assets and debts; net income and total spending for the month; upcoming bills; a handy reminder of when your next paycheck lands; any debt payoff plan you have; and any goals. Like some other apps, including Quicken Simplifi, PocketGuard promotes an “after bills” approach, where you enter all of your recurring bills, and then PocketGuard shows you what’s left, and that’s what you’re supposed to be budgeting: your disposable income. Although PocketGuard’s UI is easy enough to understand, it lacks polish. The “accounts” tab is a little busy, and doesn’t show totals for categories like cash or investments. Seemingly small details like weirdly phrased or punctuated copy occasionally make the app feel janky. More than once, it prompted me to update the app when no updates were available. The web version, meanwhile, feels like the mobile app blown up to a larger format and doesn’t take advantage of the extra screen real estate. Ultimately, now that the free tier is gone, it just doesn’t present the same value proposition as it once did. What is Plaid and how does it work? Each of the apps I tested uses the same underlying network, called Plaid, to pull in financial data, so it’s worth explaining in its own section what it is and how it works. Plaid was founded as a fintech startup in 2013 and is today the industry standard in connecting banks with third-party apps. Plaid works with over 12,000 financial institutions across the US, Canada and Europe. Additionally, more than 8,000 third-party apps and services rely on Plaid, the company claims. To be clear, you don’t need a dedicated Plaid app to use it; the technology is baked into a wide array of apps, including the budget trackers I tested for this guide. Once you find the “add an account” option in whichever one you’re using, you’ll see a menu of commonly used banks. There’s also a search field you can use to look yours up directly. Once you find yours, you’ll be prompted to enter your login credentials. If you have two-factor authentication set up, you’ll need to enter a one-time passcode as well. As the middleman, Plaid is a passthrough for information that may include your account balances, transaction history, account type and routing or account number. Plaid uses encryption, and says it has a policy of not selling or renting customer data to other companies. However, I would not be doing my job if I didn’t note that in 2022 Plaid was forced to pay $58 million to consumers in a class action suit for collecting “more financial data than was needed.” As part of the settlement, Plaid was compelled to change some of its business practices. In a statement provided to Engadget, a Plaid spokesperson said the company continues to deny the allegations underpinning the lawsuit and that “the crux of the non-financial terms in the settlement are focused on us accelerating workstreams already underway related to giving people more transparency into Plaid’s role in connecting their accounts, and ensuring that our workstreams around data minimization remain on track.” How to import your financial data from the Mint app Mint users should consider getting their data ready to migrate to their new budgeting app of choice soon. Unfortunately, importing data from Mint is not as easy as entering your credentials from inside your new app and hitting “import.” In fact, any app that advertises the ability to port over your stats from Mint is just going to have you upload a CSV file of transactions and other data. To download a CSV file from Mint, do the following: Sign into Mint.com and hit Transactions in the menu on the left side of the screen. Select an account, or all accounts. Scroll down and look for “export [number] transactions” in smaller print. Your CSV file should begin downloading. Note: Downloading on a per-account basis might seem more annoying, but could help you get set up on the other side, if the app you’re using has you importing transactions one-for-one into their corresponding accounts. How we tested Mint alternatives Before I dove into the world of budgeting apps, I had to do some research. To find a list of apps to test, I consulted trusty ol’ Google (and even trustier Reddit); read reviews of popular apps on the App Store; and also asked friends and colleagues what budget tracking apps they might be using. Some of the apps I found were free, just like Mint. These, of course, show loads of ads (excuse me, “offers”) to stay in business. But most of the available apps require paid subscriptions, with prices typically topping out around $100 a year, or $15 a month. (Spoiler: My top pick is cheaper than that.) Since this guide is meant to help Mint users find a permanent replacement, any services I chose to test needed to do several things: import all of your account data into one place; offer budgeting tools; and track your spending, net worth and credit score. Except where noted, all of these apps are available for iOS, Android and on the web. Once I had my shortlist of six apps, I got to work setting them up. For the sake of thoroughly testing these apps (and remember, I really was looking for a Mint alternative myself), I made a point of adding every account to every budgeting app, no matter how small or immaterial the balance. What ensued was a veritable Groundhog Day of two-factor authentication. Just hours of entering passwords and one-time passcodes, for the same banks half a dozen times over. Hopefully, you only have to do this once. What about Rocket Money? Rocket Money is another free financial app that tracks spending and supports things like balance alerts and account linking. If you pay for the premium tier, the service can also help you cancel unwanted subscriptions. We did not test it for this guide, but we'll consider it in future updates.This article originally appeared on Engadget at https://www.engadget.com/apps/the-best-budgeting-apps-to-replace-mint-143047346.html?src=rss",
          "content": "As a long-time Mint user, I was frustrated to say the least when news broke at the end of 2023 that Intuit would shut Mint down. I, like millions of others, enjoyed how easily Mint allowed us to track all accounts in one place and monitor credit scores. I also used it regularly to track spending, set goals like pay my mortgage down faster and with general money management.So I set out to find the best Mint alternatives in the wake of its disappointing demise. I gave Credit Karma, Intuit’s other financial app, a try but found it to be a poor Mint substitute. The following guide lays out my experience testing some of the most popular Mint replacement apps available today in search of my next budgeting app.Our pick for best Mint alternative remains Quicken Simplifi, even months after the Mint shutting down, thanks to its easy to use app, good income and bill detection and its affordable price. But there are plenty of other solid options out there for those with different needs. If you’re also on the hunt for a budgeting app to replace Mint, we hope these details can help you decide which of the best budgeting apps out there will be right for you. Table of contents Best Mint alternatives in 2025 Other Mint alternatives we tested What is Plaid and how does it work? How to import your financial data from the Mint app How we tested Mint alternatives What about Rocket Money? Best Mint alternatives in 2025 No pun intended, but what I like about Quicken Simplifi is its simplicity. Whereas other budgeting apps try to distinguish themselves with dark themes and customizable emoji, Simplifi has a clean user interface, with a landing page that you just keep scrolling through to get a detailed overview of all your stats. These include your top-line balances; net worth; recent spending; upcoming recurring payments; a snapshot of your spending plan; top spending categories; achievements; and any watchlists you’ve set up. Another one of the key features I appreciate is the ability to set up savings goals elsewhere in the app. I also appreciate how it offers neat, almost playful visualizations without ever looking cluttered. I felt at home in the mobile and web dashboards after a day or so, which is faster than I adapted to some competing services (I’m looking at you, YNAB and Monarch). Getting set up with Simplifi was mostly painless. I was particularly impressed at how easily it connected to Fidelity; not all budget trackers do, for whatever reason. This is also one of the only services I tested that gives you the option of inviting a spouse or financial advisor to co-manage your account. One thing I would add to my initial assessment of the app, having used it for a few months now: I wish Simplifi offered Zillow integration for easily tracking your home value (or at least a rough estimate of it). Various competitors including Monarch Money and Copilot Money work with Zillow, so clearly there's a Zillow API available for use. As it stands, Simplifi users must add real estate manually like any other asset. Dana Wollman / Engadget In practice, Simplifi miscategorized some of my expenses, but nothing out of the ordinary compared to any of these budget trackers. As you’re reviewing transactions, you can also mark if you’re expecting a refund, which is a unique feature among the services I tested. Simplifi also estimated my regular income better than some other apps I tested. Most of all, I appreciated the option of being able to categorize some, but not all, purchases from a merchant as recurring. For instance, I can add my two Amazon subscribe-and-saves as recurring payments, without having to create a broad-strokes rule for every Amazon purchase. The budgeting feature is also self-explanatory and can likely accommodate your preferred budgeting method. Just check that your regular income is accurate and be sure to set up recurring payments, making note of which are bills and which are subscriptions. This is important because Simplifi shows you your total take-home income as well as an “income after bills” figure. That number includes, well, bills but not discretionary subscriptions. From there, you can add spending targets by category in the “planned spending” bucket. Planned spending can also include one-time expenditures, not just monthly budgets. When you create a budget, Simplifi will suggest a number based on a six-month average. Not dealbreakers, but two things to keep in mind as you get started: Simplifi is notable in that you can’t set up an account through Apple or Google. There is also no option for a free trial, though Quicken promises a “30-day money back guarantee.” Monarch Money grew on me. My first impression of the budgeting app, which was founded by a former Mint product manager, was that it's more difficult to use than others on this list, including Simplifi, NerdWallet and Copilot. And it is. Editing expense categories, adding recurring transactions and creating rules, for example, is a little more complicated than it needs to be, especially in the mobile app. (My advice: Use the web app for fine-tuning details.) Monarch also didn’t get my income right; I had to edit it. Once you’re set up, though, Monarch offers an impressive level of granularity. In the budgets section, you can see a bona fide balance sheet showing budgets and actuals for each category. You'll also find a forecast, for the year or by month. And recurring expenses can be set not just by merchant, but other parameters as well. For instance, while most Amazon purchases might be marked as “shopping,” those for the amounts of $54.18 or $34.18 are definitely baby supplies, and can be automatically marked as such each time, not to mention programmed as recurring payments. Weirdly, though, there’s no way to mark certain recurring payments as bills, specifically. Dana Wollman / Engadget Not long after I first published this story in December 2023, Monarch introduced a detailed reporting section where you can create on-demand graphs based on things like accounts, categories and tags. That feature is available just on the web version of the app for now. As part of this same update, Monarch added support for an aggregator that makes it possible to automatically update the value of your car. This, combined with the existing Zillow integration for tracking your home value, makes it easy to quickly add a non-liquid asset like a vehicle or real estate, and have it show up in your net worth graph. The mobile app is mostly self-explanatory. The main dashboard shows your net worth; your four most recent transactions; a month-over-month spending comparison; income month-to-date; upcoming bills; an investments snapshot; a list of any goals you’ve set; and, finally, a link to your month-in-review. That month-in-review is more detailed than most, delving into cash flow; top income and expense categories; cash flow trends; changes to your net worth, assets and liabilities; plus asset and liability breakdowns. In February 2024, Monarch expanded on the net worth graph, so that if you click on the Accounts tab you can see how your net worth changed over different periods of time, including one month, three months, six months, a year or all time. On the main screen, you’ll also find tabs for savings and checking accounts (and all others as well), transactions, cash flow, budget and recurring. Like many of the other apps featured here, Monarch can auto-detect recurring expenses and income, even if it gets the category wrong. (They all do to an extent.) Expense categories are marked by emoji, which you can customize if you’re so inclined. Monarch Money uses a combination of networks to connect with banks, including Plaid, MX and Finicity, a competing network owned by Mastercard. (I have a quick explainer on Plaid, the industry standard in this space, toward the end of this guide.) As part of an update in late December, Monarch has also made it easier to connect through those other two networks, if for some reason Plaid fails. Similar to NerdWallet, I found myself completing two-factor authentication every time I wanted to get past the Plaid screen to add another account. Notably, Monarch is the only other app I tested that allows you to grant access to someone else in your family — likely a spouse or financial advisor. Monarch also has a Chrome extension for importing from Mint, though really this is just a shortcut for downloading a CSV file, which you’ll have to do regardless of where you choose to take your Mint data. Additionally, Monarch just added the ability to track Apple Card, Apple Cash, and Savings accounts, thanks to new functionality brought with the iOS 17.4 update. It's not the only one either; currently, Copilot and YNAB have also added similar functionality that will be available to anyone with the latest versions of their respective apps on a device running iOS 17.4. Instead of manually uploading statements, the new functionality allows apps like Monarch's to automatically pull in transactions and balance history. That should make it easier to account for spending on Apple cards and accounts throughout the month. Monarch also recently launched investment transactions in beta. It also says bill tracking and an overhauled goals system are coming soon. Monarch hasn't provided a timeline for that last one, except to say that the improved goals feature is coming soon. Copilot Money might be the best-looking budgeting app I tested. It also has the distinction of being exclusive to iOS and Macs — at least for now. Andres Ugarte, the company’s CEO, has publicly promised that Android and web apps are coming soon. But until it follows through, I can’t recommend Copilot for most people with so many good competitors out there. Copilot Money for Web and Android!Thanks to the support from our users, and the overwhelming positive reception we're seeing from folks migrating from Mint, we can now say that we'll be building @copilotmoney for Web and Android with a goal to launch in 2024.We'll continue to…— Andres Ugarte (@chuga) November 15, 2023 There are other features that Copilot is missing, which I’ll get into. But it is promising, and one to keep an eye on. It’s just a fast, efficient, well designed app, and Android users will be in for a treat when they’ll finally be able to download it. It makes good use of colors, emoji and graphs to help you understand at a glance how you’re doing on everything from your budgets to your investment performance to your credit card debt over time. In particular, Copilot does a better job than almost any other app of visualizing your recurring monthly expenses. Behind those punchy colors and cutesy emoji, though, is some sophisticated performance. Copilot’s AI-powered “Intelligence” gets smarter as you go at categorizing your expenses. (You can also add your own categories, complete with your choice of emoji.) It’s not perfect. Copilot miscategorized some purchases (they all do), but it makes it easier to edit than most. On top of that, the internal search feature is very fast; it starts whittling down results in your transaction history as soon as you begin typing. Dana Wollman / Engadget Copilot is also unique in offering Amazon and Venmo integrations, allowing you to see transaction details. With Amazon, this requires just signing into your Amazon account via an in-app browser. For Venmo, you have to set up fwd@copilot.money as a forwarding address and then create a filter, wherein emails from venmo@venmo.com are automatically forwarded to fwd@copilot.money. Like Monarch Money, you can also add any property you own and track its value through Zillow, which is integrated with the app. While the app is heavily automated, I still appreciate that Copilot marks new transactions for review. It’s a good way to both weed out fraudulent charges, and also be somewhat intentional about your spending habits. Like Monarch Money, Copilot updated its app to make it easier to connect to banks through networks other than Plaid. As part of the same update, Copilot said it has improved its connections to both American Express and Fidelity which, again, can be a bugbear for some budget tracking apps. In an even more recent update, Copilot added a Mint import option, which other budgeting apps have begun to offer as well. Because the app is relatively new (it launched in early 2020), the company is still catching up to the competition on some table-stakes features. Ugarte told me that his team is almost done building out a detailed cash flow section as well. On its website, Copilot also promises a raft of AI-powered features that build on its current “Intelligence” platform, the one that powers its smart expense categorization. These include “smart financial goals,” natural language search, a chat interface, forecasting and benchmarking. That benchmarking, Ugarte tells me, is meant to give people a sense of how they’re doing compared to other Copilot users, on both spending and investment performance. Most of these features should arrive in the new year. Copilot does a couple interesting things for new customers that distinguish it from the competition. There’s a “demo mode” that feels like a game simulator; no need to add your own accounts. The company is also offering two free months with RIPMINT — a more generous introductory offer than most. When it finally does come time to pony up, the $7.92 monthly plan is cheaper than some competing apps, although the $95-a-year-option is in the same ballpark. You may know NerdWallet as a site that offers a mix of personal finance news, explainers and guides. I see it often when I google a financial term I don’t know and sure enough, it’s one of the sites I’m most likely to click on. As it happens, NerdWallet also has the distinction of offering one of the only free budgeting apps I tested. In fact, there is no paid version; nothing is locked behind a paywall. The main catch: There are ads everywhere. To be fair, the free version of Mint was like this, too. Even with the inescapable credit card offers, NerdWallet has a clean, easy-to-understand user interface, which includes both a web and a mobile app. The key metrics that it highlights most prominently are your cash flow, net worth and credit score. (Of note, although Mint itself offered credit score monitoring, most of its rivals do not.) I particularly enjoyed the weekly insights, which delve into things like where you spent the most money or how much you paid in fees — and how that compares to the previous month. Because this is NerdWallet, an encyclopedia of financial info, you get some particularly specific category options when setting up your accounts (think: a Roth or non-Roth IRA). Dana Wollman / Engadget As a budgeting app, NerdWallet is more than serviceable, if a bit basic. Like other apps I tested, you can set up recurring bills. Importantly, it follows the popular 50/30/20 budgeting rule, which has you putting 50% of your budget toward things you need, 30% toward things you want, and the remaining 20% into savings or debt repayments. If this works for you, great — just know that you can’t customize your budget to the same degree as some competing apps. You can’t currently create custom spending categories, though a note inside the dashboard section of the app says “you’ll be able to customize them in the future.” You also can’t move items from the wants column to “needs” or vice versa but “In the future, you'll be able to move specific transactions to actively manage what falls into each group.” A NerdWallet spokesperson declined to provide an ETA, though. Lastly, it’s worth noting that NerdWallet had one of the most onerous setup processes of any app I tested. I don’t think this is a dealbreaker, as you’ll only have to do it once and, hopefully, you aren’t setting up six or seven apps in tandem as I was. What made NerdWallet’s onboarding especially tedious is that every time I wanted to add an account, I had to go through a two-factor authentication process to even get past the Plaid splash screen, and that’s not including the 2FA I had set up at each of my banks. This is a security policy on NerdWallet’s end, not Plaid’s, a Plaid spokesperson says. Precisely because NerdWallet is one of the only budget trackers to offer credit score monitoring, it also needs more of your personal info during setup, including your birthday, address, phone number and the last four digits of your social security number. It’s the same with Credit Karma, which also does credit score monitoring. Related to the setup process, I found that NerdWallet was less adept than other apps at automatically detecting my regular income. In my case, it counted a large one-time wire transfer as income, at which point my only other option was to enter my income manually (which is slightly annoying because I would have needed my pay stub handy to double-check my take-home pay). YNAB is, by its own admission, “different from anything you’ve tried before.” The app, whose name is short for You Need a Budget, promotes a so-called zero-based budgeting system, which forces you to assign a purpose for every dollar you earn. A frequently used analogy is to put each dollar in an envelope; you can always move money from one envelope to another in a pinch. These envelopes can include rent and utilities, along with unforeseen expenses like holiday gifts and the inevitable car repair. The idea is that if you budget a certain amount for the unknowns each month, they won’t feel like they’re sneaking up on you. Importantly, YNAB is only concerned with the money you have in your accounts now. The app does not ask you to provide your take-home income or set up recurring income payments (although there is a way to do this). The money you will make later in the month through your salaried job is not relevant, because YNAB does not engage in forecasting. The app is harder to learn than any other here, and it requires more ongoing effort from the user. And YNAB knows that. Inside both the mobile and web apps are links to videos and other tutorials. Although I never quite got comfortable with the user interface, I did come to appreciate YNAB’s insistence on intentionality. Forcing users to draft a new budget each month and to review each transaction is not necessarily a bad thing. As YNAB says on its website, “Sure, you’ve got pie charts showing that you spent an obscene amount of money in restaurants — but you’ve still spent an obscene amount of money in restaurants.” I can see this approach being useful for people who don’t tend to have a lot of cash in reserve at a given time, or who have spending habits they want to correct (to riff off of YNAB’s own example, ordering Seamless four times a week). My colleague Valentina Palladino, knowing I was working on this guide, penned a respectful rebuttal, explaining why she’s been using YNAB for years. Perhaps, like her, you have major savings goals you want to achieve, whether it’s paying for a wedding or buying a house. I suggest you give her column a read. For me, though, YNAB’s approach feels like overkill. Other Mint alternatives we tested PocketGuard PocketGuard used to be a solid free budget tracker, but the company has since limited its “free” version to just a free seven-day trial. Now, you’ll have to choose between two plans once the trial is over: a $13 monthly plan or a $75 annual plan. When I first tested it, I found it to be more restricted than NerdWallet, but still a decent option. The main overview screen shows you your net worth, total assets and debts; net income and total spending for the month; upcoming bills; a handy reminder of when your next paycheck lands; any debt payoff plan you have; and any goals. Like some other apps, including Quicken Simplifi, PocketGuard promotes an “after bills” approach, where you enter all of your recurring bills, and then PocketGuard shows you what’s left, and that’s what you’re supposed to be budgeting: your disposable income. Although PocketGuard’s UI is easy enough to understand, it lacks polish. The “accounts” tab is a little busy, and doesn’t show totals for categories like cash or investments. Seemingly small details like weirdly phrased or punctuated copy occasionally make the app feel janky. More than once, it prompted me to update the app when no updates were available. The web version, meanwhile, feels like the mobile app blown up to a larger format and doesn’t take advantage of the extra screen real estate. Ultimately, now that the free tier is gone, it just doesn’t present the same value proposition as it once did. What is Plaid and how does it work? Each of the apps I tested uses the same underlying network, called Plaid, to pull in financial data, so it’s worth explaining in its own section what it is and how it works. Plaid was founded as a fintech startup in 2013 and is today the industry standard in connecting banks with third-party apps. Plaid works with over 12,000 financial institutions across the US, Canada and Europe. Additionally, more than 8,000 third-party apps and services rely on Plaid, the company claims. To be clear, you don’t need a dedicated Plaid app to use it; the technology is baked into a wide array of apps, including the budget trackers I tested for this guide. Once you find the “add an account” option in whichever one you’re using, you’ll see a menu of commonly used banks. There’s also a search field you can use to look yours up directly. Once you find yours, you’ll be prompted to enter your login credentials. If you have two-factor authentication set up, you’ll need to enter a one-time passcode as well. As the middleman, Plaid is a passthrough for information that may include your account balances, transaction history, account type and routing or account number. Plaid uses encryption, and says it has a policy of not selling or renting customer data to other companies. However, I would not be doing my job if I didn’t note that in 2022 Plaid was forced to pay $58 million to consumers in a class action suit for collecting “more financial data than was needed.” As part of the settlement, Plaid was compelled to change some of its business practices. In a statement provided to Engadget, a Plaid spokesperson said the company continues to deny the allegations underpinning the lawsuit and that “the crux of the non-financial terms in the settlement are focused on us accelerating workstreams already underway related to giving people more transparency into Plaid’s role in connecting their accounts, and ensuring that our workstreams around data minimization remain on track.” How to import your financial data from the Mint app Mint users should consider getting their data ready to migrate to their new budgeting app of choice soon. Unfortunately, importing data from Mint is not as easy as entering your credentials from inside your new app and hitting “import.” In fact, any app that advertises the ability to port over your stats from Mint is just going to have you upload a CSV file of transactions and other data. To download a CSV file from Mint, do the following: Sign into Mint.com and hit Transactions in the menu on the left side of the screen. Select an account, or all accounts. Scroll down and look for “export [number] transactions” in smaller print. Your CSV file should begin downloading. Note: Downloading on a per-account basis might seem more annoying, but could help you get set up on the other side, if the app you’re using has you importing transactions one-for-one into their corresponding accounts. How we tested Mint alternatives Before I dove into the world of budgeting apps, I had to do some research. To find a list of apps to test, I consulted trusty ol’ Google (and even trustier Reddit); read reviews of popular apps on the App Store; and also asked friends and colleagues what budget tracking apps they might be using. Some of the apps I found were free, just like Mint. These, of course, show loads of ads (excuse me, “offers”) to stay in business. But most of the available apps require paid subscriptions, with prices typically topping out around $100 a year, or $15 a month. (Spoiler: My top pick is cheaper than that.) Since this guide is meant to help Mint users find a permanent replacement, any services I chose to test needed to do several things: import all of your account data into one place; offer budgeting tools; and track your spending, net worth and credit score. Except where noted, all of these apps are available for iOS, Android and on the web. Once I had my shortlist of six apps, I got to work setting them up. For the sake of thoroughly testing these apps (and remember, I really was looking for a Mint alternative myself), I made a point of adding every account to every budgeting app, no matter how small or immaterial the balance. What ensued was a veritable Groundhog Day of two-factor authentication. Just hours of entering passwords and one-time passcodes, for the same banks half a dozen times over. Hopefully, you only have to do this once. What about Rocket Money? Rocket Money is another free financial app that tracks spending and supports things like balance alerts and account linking. If you pay for the premium tier, the service can also help you cancel unwanted subscriptions. We did not test it for this guide, but we'll consider it in future updates.This article originally appeared on Engadget at https://www.engadget.com/apps/the-best-budgeting-apps-to-replace-mint-143047346.html?src=rss",
          "feed_position": 35,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-12/9003a9c0-9dd8-11ee-8bf5-613f22f37439"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/geostar-pioneers-geo-as-traditional-seo-faces-25-decline-from-ai-chatbots",
          "published_at": "Wed, 29 Oct 2025 07:00:00 GMT",
          "title": "Geostar pioneers GEO as traditional SEO faces 25% decline from AI chatbots, Gartner says",
          "standfirst": "The moment Mack McConnell knew everything about search had changed came last summer at the Paris Olympics. His parents, independently and without prompting, had both turned to ChatGPT to plan their day&#x27;s activities in the French capital. The AI recommended specific tour companies, restaurants, and attractions — businesses that had won a new kind of visibility lottery.\"It was almost like this intuitive interface that older people were as comfortable with using as younger people,\" McConnell recalled in an exclusive interview with VentureBeat. \"I could just see the businesses were now being recommended.\"That observation has now become the foundation of Geostar, a Pear VC-backed startup that&#x27;s racing to help businesses navigate what may be the most significant shift in online discovery since Google&#x27;s founding. The company, which recently emerged from stealth with impressive early customer traction, is betting that the rise of AI-powered search represents a significant opportunity to reinvent how companies get found online. The global AI search engine market alone is projected to grow from $43.63 billion in 2025 to $108.88 billion by 2032.Already the fastest-growing company in PearX&#x27;s latest cohort, Geostar is fast approaching $1 million in annual recurring revenue in just four months — with only two founders and no employees.Why Gartner predicts traditional search volume will decline 25% by 2026The numbers tell a stark story of disruption. Gartner predicts that traditional search engine volume will decline by 25% by 2026, largely due to the rise of AI chatbots. Google&#x27;s AI Overviews now appear on billions of searches monthly. Princeton University researchers have found that optimizing for these new AI systems can increase visibility by up to 40%.\"Search used to mean that you had to make Google happy,\" McConnell explained. \"But now you have to optimize for four different Google interfaces — traditional search, AI Mode, Gemini, and AI Overviews — each with different criteria. And then ChatGPT, Claude, and Perplexity each work differently on top of that.\"This fragmentation is creating chaos for businesses that have spent decades perfecting their Google search strategies. A recent Forrester study found that 95% of B2B buyers plan to use generative AI in future purchase decisions. Yet most companies remain woefully unprepared for this shift.\"Anybody who&#x27;s not on this right now is losing out,\" said Cihan Tas, Geostar&#x27;s co-founder and chief technology officer. \"We see lawyers getting 50% of their clients through ChatGPT now. It&#x27;s just such a massive shift.\"How language models read the web differently than search engines ever didWhat Geostar and a growing cohort of competitors call Generative Engine Optimization or GEO represents a fundamental departure from traditional search engine optimization. Where SEO focused primarily on keywords and backlinks, GEO requires understanding how large language models parse, understand, and synthesize information across the entire web.The technical challenges are formidable. Every website must now function as what Tas calls \"its own little database\" capable of being understood by dozens of different AI crawlers, each with unique requirements and preferences. Google&#x27;s systems pull from their existing search index. ChatGPT relies heavily on structured data and specific content formats. Perplexity shows a marked preference for Wikipedia and authoritative sources.\"Now the strategy is actually being concise, clear, and answering the question, because that&#x27;s directly what the AI is looking for,\" Tas explained. \"You&#x27;re actually tuning for somewhat of an intelligent model that makes decisions similarly to how we make decisions.\"Consider schema markup, the structured data that helps machines understand web content. While only 30% of websites currently implement comprehensive schema, research shows that pages with proper markup are 36% more likely to appear in AI-generated summaries. Yet most businesses don&#x27;t even know what schema markup is, let alone how to implement it effectively.Inside Geostar&#x27;s AI agents that optimize websites continuously without human interventionGeostar&#x27;s solution embodies a broader trend in enterprise software: the rise of autonomous AI agents that can take action on behalf of businesses. The company embeds what it calls \"ambient agents\" directly into client websites, continuously optimizing content, technical configurations, and even creating new pages based on patterns learned across its entire customer base.\"Once we learn something about the way content performs, or the way a technical optimization performs, we can then syndicate that same change across the remaining users so everyone in the network benefits,\" McConnell said.For RedSift, a cybersecurity company, this approach yielded a 27% increase in AI mentions within three months. In one case, Geostar identified an opportunity to rank for \"best DMARC vendors,\" a high-value search term in the email security space. The company&#x27;s agents created and optimized content that achieved first-page rankings on both Google and ChatGPT within four days.\"We&#x27;re doing the work of an agency that charges $10,000 a month,\" McConnell said, noting that Geostar&#x27;s pricing ranges from $1,000 to $3,000 monthly. \"AI creates a situation where, for the first time ever, you can take action like an agency, but you can scale like software.\"Why brand mentions without links now matter more than ever in the AI eraThe implications of this shift extend far beyond technical optimizations. In the SEO era, a mention without a link was essentially worthless. In the age of AI, that calculus has reversed. AI systems can analyze vast amounts of text to understand sentiment and context, meaning that brand mentions on Reddit, in news articles, or across social media now directly influence how AI systems describe and recommend companies.\"If the New York Times mentions a company without linking to it, that company would actually benefit from that in an AI system,\" McConnell explained. \"AI has the ability to do mass analysis of huge amounts of text, and it will understand the sentiment around that mention.\"This has created new vulnerabilities. Research from the Indian Institute of Technology and Princeton found that AI systems show systematic bias toward third-party sources over brand-owned content. A company&#x27;s own website might be less influential in shaping AI perceptions than what others say about it online.The shifting landscape has also disrupted traditional metrics of success. Where SEO focused on rankings and click-through rates, GEO must account for what researchers call impression metrics — how prominently and positively a brand appears within AI-generated responses, even when users never click through to the source.A growing market as SEO veterans and new players rush to dominate AI optimizationGeostar is hardly alone in recognizing this opportunity. Companies like Brandlight, Profound, and Goodie are all racing to help businesses navigate the new landscape. The SEO industry, worth approximately $80 billion globally, is scrambling to adapt, with established players like Semrush and Ahrefs rushing to add AI visibility tracking features.But the company&#x27;s founders, who previously built and sold a Y-Combinator-backed e-commerce optimization startup called Monto, believe their technical approach gives them an edge. Unlike competitors who largely provide dashboards and recommendations, Geostar&#x27;s agents actively implement changes.\"Everyone is taking the same solutions that worked in the last era and just saying, &#x27;We&#x27;ll do this for AI instead,&#x27;\" McConnell argued. \"But when you think about what AI is truly capable of, it can actually do the work for you.\"The stakes are particularly high for small and medium-sized businesses. While large corporations can afford to hire specialized consultants or build internal expertise, smaller companies risk becoming invisible in AI-mediated search. Geostar sees this as its primary market opportunity: nearly half of the 33.2 million small businesses in America invest in SEO. Among the roughly 418,000 law firms in the U.S., many spend between $2,500 and $5,000 monthly on search optimization to stay competitive in local markets.From Kurdish village to PearX: The unlikely partnership building the future of searchFor Tas, whose journey to Silicon Valley began in a tiny Kurdish village in Turkey with just 50 residents, the current moment represents both opportunity and responsibility. His mother&#x27;s battle with cancer prevented him from finishing college, leading him to teach himself programming and eventually partner with McConnell — whom he worked with for an entire year before they ever met in person.\"We&#x27;re not just copy and pasting a solution that was existing before,\" Tas emphasized. \"This is something that&#x27;s different and was uniquely possible today.\"Looking forward, the transformation of search appears to be accelerating rather than stabilizing. Industry observers predict that search functionality will soon be embedded in productivity tools, wearables, and even augmented reality interfaces. Each new surface will likely have its own optimization requirements, further complicating the landscape.\"Soon, search will be in our eyes, in our ears,\" McConnell predicted. \"When Siri breaks out of her prison, whatever that Jony Ive and OpenAI are building together will be like a multimodal search interface.\"The technical challenges are matched by ethical ones. As businesses scramble to influence AI recommendations, questions arise about manipulation, fairness, and transparency. There&#x27;s currently no oversight body or established best practices for GEO, creating what some critics describe as a Wild West environment.As businesses grapple with these changes, one thing seems certain: the era of simply optimizing for Google is over. In its place is emerging a far more complex ecosystem where success requires understanding not just how machines index information, but how they think about it, synthesize it, and ultimately decide what to recommend to humans seeking answers.For the millions of businesses whose survival depends on being discovered online, mastering this new paradigm isn&#x27;t just an opportunity — it&#x27;s an existential imperative. The question is no longer whether to optimize for AI search, but whether companies can adapt quickly enough to remain visible as the pace of change accelerates.McConnell&#x27;s parents at the Olympics were a preview of what&#x27;s already becoming the norm. They didn&#x27;t search for tour companies in Paris. They didn&#x27;t scroll through results or click on links. They simply asked ChatGPT what to do — and the AI decided which businesses deserved their attention.In the new economy of discovery, the businesses that win won&#x27;t be the ones that rank highest. They&#x27;ll be the ones AI chooses to recommend.",
          "content": "The moment Mack McConnell knew everything about search had changed came last summer at the Paris Olympics. His parents, independently and without prompting, had both turned to ChatGPT to plan their day&#x27;s activities in the French capital. The AI recommended specific tour companies, restaurants, and attractions — businesses that had won a new kind of visibility lottery.\"It was almost like this intuitive interface that older people were as comfortable with using as younger people,\" McConnell recalled in an exclusive interview with VentureBeat. \"I could just see the businesses were now being recommended.\"That observation has now become the foundation of Geostar, a Pear VC-backed startup that&#x27;s racing to help businesses navigate what may be the most significant shift in online discovery since Google&#x27;s founding. The company, which recently emerged from stealth with impressive early customer traction, is betting that the rise of AI-powered search represents a significant opportunity to reinvent how companies get found online. The global AI search engine market alone is projected to grow from $43.63 billion in 2025 to $108.88 billion by 2032.Already the fastest-growing company in PearX&#x27;s latest cohort, Geostar is fast approaching $1 million in annual recurring revenue in just four months — with only two founders and no employees.Why Gartner predicts traditional search volume will decline 25% by 2026The numbers tell a stark story of disruption. Gartner predicts that traditional search engine volume will decline by 25% by 2026, largely due to the rise of AI chatbots. Google&#x27;s AI Overviews now appear on billions of searches monthly. Princeton University researchers have found that optimizing for these new AI systems can increase visibility by up to 40%.\"Search used to mean that you had to make Google happy,\" McConnell explained. \"But now you have to optimize for four different Google interfaces — traditional search, AI Mode, Gemini, and AI Overviews — each with different criteria. And then ChatGPT, Claude, and Perplexity each work differently on top of that.\"This fragmentation is creating chaos for businesses that have spent decades perfecting their Google search strategies. A recent Forrester study found that 95% of B2B buyers plan to use generative AI in future purchase decisions. Yet most companies remain woefully unprepared for this shift.\"Anybody who&#x27;s not on this right now is losing out,\" said Cihan Tas, Geostar&#x27;s co-founder and chief technology officer. \"We see lawyers getting 50% of their clients through ChatGPT now. It&#x27;s just such a massive shift.\"How language models read the web differently than search engines ever didWhat Geostar and a growing cohort of competitors call Generative Engine Optimization or GEO represents a fundamental departure from traditional search engine optimization. Where SEO focused primarily on keywords and backlinks, GEO requires understanding how large language models parse, understand, and synthesize information across the entire web.The technical challenges are formidable. Every website must now function as what Tas calls \"its own little database\" capable of being understood by dozens of different AI crawlers, each with unique requirements and preferences. Google&#x27;s systems pull from their existing search index. ChatGPT relies heavily on structured data and specific content formats. Perplexity shows a marked preference for Wikipedia and authoritative sources.\"Now the strategy is actually being concise, clear, and answering the question, because that&#x27;s directly what the AI is looking for,\" Tas explained. \"You&#x27;re actually tuning for somewhat of an intelligent model that makes decisions similarly to how we make decisions.\"Consider schema markup, the structured data that helps machines understand web content. While only 30% of websites currently implement comprehensive schema, research shows that pages with proper markup are 36% more likely to appear in AI-generated summaries. Yet most businesses don&#x27;t even know what schema markup is, let alone how to implement it effectively.Inside Geostar&#x27;s AI agents that optimize websites continuously without human interventionGeostar&#x27;s solution embodies a broader trend in enterprise software: the rise of autonomous AI agents that can take action on behalf of businesses. The company embeds what it calls \"ambient agents\" directly into client websites, continuously optimizing content, technical configurations, and even creating new pages based on patterns learned across its entire customer base.\"Once we learn something about the way content performs, or the way a technical optimization performs, we can then syndicate that same change across the remaining users so everyone in the network benefits,\" McConnell said.For RedSift, a cybersecurity company, this approach yielded a 27% increase in AI mentions within three months. In one case, Geostar identified an opportunity to rank for \"best DMARC vendors,\" a high-value search term in the email security space. The company&#x27;s agents created and optimized content that achieved first-page rankings on both Google and ChatGPT within four days.\"We&#x27;re doing the work of an agency that charges $10,000 a month,\" McConnell said, noting that Geostar&#x27;s pricing ranges from $1,000 to $3,000 monthly. \"AI creates a situation where, for the first time ever, you can take action like an agency, but you can scale like software.\"Why brand mentions without links now matter more than ever in the AI eraThe implications of this shift extend far beyond technical optimizations. In the SEO era, a mention without a link was essentially worthless. In the age of AI, that calculus has reversed. AI systems can analyze vast amounts of text to understand sentiment and context, meaning that brand mentions on Reddit, in news articles, or across social media now directly influence how AI systems describe and recommend companies.\"If the New York Times mentions a company without linking to it, that company would actually benefit from that in an AI system,\" McConnell explained. \"AI has the ability to do mass analysis of huge amounts of text, and it will understand the sentiment around that mention.\"This has created new vulnerabilities. Research from the Indian Institute of Technology and Princeton found that AI systems show systematic bias toward third-party sources over brand-owned content. A company&#x27;s own website might be less influential in shaping AI perceptions than what others say about it online.The shifting landscape has also disrupted traditional metrics of success. Where SEO focused on rankings and click-through rates, GEO must account for what researchers call impression metrics — how prominently and positively a brand appears within AI-generated responses, even when users never click through to the source.A growing market as SEO veterans and new players rush to dominate AI optimizationGeostar is hardly alone in recognizing this opportunity. Companies like Brandlight, Profound, and Goodie are all racing to help businesses navigate the new landscape. The SEO industry, worth approximately $80 billion globally, is scrambling to adapt, with established players like Semrush and Ahrefs rushing to add AI visibility tracking features.But the company&#x27;s founders, who previously built and sold a Y-Combinator-backed e-commerce optimization startup called Monto, believe their technical approach gives them an edge. Unlike competitors who largely provide dashboards and recommendations, Geostar&#x27;s agents actively implement changes.\"Everyone is taking the same solutions that worked in the last era and just saying, &#x27;We&#x27;ll do this for AI instead,&#x27;\" McConnell argued. \"But when you think about what AI is truly capable of, it can actually do the work for you.\"The stakes are particularly high for small and medium-sized businesses. While large corporations can afford to hire specialized consultants or build internal expertise, smaller companies risk becoming invisible in AI-mediated search. Geostar sees this as its primary market opportunity: nearly half of the 33.2 million small businesses in America invest in SEO. Among the roughly 418,000 law firms in the U.S., many spend between $2,500 and $5,000 monthly on search optimization to stay competitive in local markets.From Kurdish village to PearX: The unlikely partnership building the future of searchFor Tas, whose journey to Silicon Valley began in a tiny Kurdish village in Turkey with just 50 residents, the current moment represents both opportunity and responsibility. His mother&#x27;s battle with cancer prevented him from finishing college, leading him to teach himself programming and eventually partner with McConnell — whom he worked with for an entire year before they ever met in person.\"We&#x27;re not just copy and pasting a solution that was existing before,\" Tas emphasized. \"This is something that&#x27;s different and was uniquely possible today.\"Looking forward, the transformation of search appears to be accelerating rather than stabilizing. Industry observers predict that search functionality will soon be embedded in productivity tools, wearables, and even augmented reality interfaces. Each new surface will likely have its own optimization requirements, further complicating the landscape.\"Soon, search will be in our eyes, in our ears,\" McConnell predicted. \"When Siri breaks out of her prison, whatever that Jony Ive and OpenAI are building together will be like a multimodal search interface.\"The technical challenges are matched by ethical ones. As businesses scramble to influence AI recommendations, questions arise about manipulation, fairness, and transparency. There&#x27;s currently no oversight body or established best practices for GEO, creating what some critics describe as a Wild West environment.As businesses grapple with these changes, one thing seems certain: the era of simply optimizing for Google is over. In its place is emerging a far more complex ecosystem where success requires understanding not just how machines index information, but how they think about it, synthesize it, and ultimately decide what to recommend to humans seeking answers.For the millions of businesses whose survival depends on being discovered online, mastering this new paradigm isn&#x27;t just an opportunity — it&#x27;s an existential imperative. The question is no longer whether to optimize for AI search, but whether companies can adapt quickly enough to remain visible as the pace of change accelerates.McConnell&#x27;s parents at the Olympics were a preview of what&#x27;s already becoming the norm. They didn&#x27;t search for tour companies in Paris. They didn&#x27;t scroll through results or click on links. They simply asked ChatGPT what to do — and the AI decided which businesses deserved their attention.In the new economy of discovery, the businesses that win won&#x27;t be the ones that rank highest. They&#x27;ll be the ones AI chooses to recommend.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5JXMNBhUMiSimHDDeX6ODt/2793b1842c2ef9825b7127d7bbd65f4f/_Geostar-2.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/from-static-classifiers-to-reasoning-engines-openais-new-model-rethinks",
          "published_at": "Wed, 29 Oct 2025 04:00:00 GMT",
          "title": "From static classifiers to reasoning engines: OpenAI’s new model rethinks content moderation",
          "standfirst": "Enterprises, eager to ensure any AI models they use adhere to safety and safe-use policies, fine-tune LLMs so they do not respond to unwanted queries. However, much of the safeguarding and red teaming happens before deployment, “baking in” policies before users fully test the models’ capabilities in production. OpenAI believes it can offer a more flexible option for enterprises and encourage more companies to bring in safety policies. The company has released two open-weight models under research preview that it believes will make enterprises and models more flexible in terms of safeguards. gpt-oss-safeguard-120b and gpt-oss-safeguard-20b will be available on a permissive Apache 2.0 license. The models are fine-tuned versions of OpenAI’s open-source gpt-oss, released in August, marking the first release in the oss family since the summer.In a blog post, OpenAI said oss-safeguard uses reasoning “to directly interpret a developer-provider policy at inference time — classifying user messages, completions and full chats according to the developer’s needs.”The company explained that, since the model uses a chain-of-thought (CoT), developers can get explanations of the model&#x27;s decisions for review. “Additionally, the policy is provided during inference, rather than being trained into the model, so it is easy for developers to iteratively revise policies to increase performance,\" OpenAI said in its post. \"This approach, which we initially developed for internal use, is significantly more flexible than the traditional method of training a classifier to indirectly infer a decision boundary from a large number of labeled examples.\" Developers can download both models from Hugging Face. Flexibility versus baking inAt the onset, AI models will not know a company’s preferred safety triggers. While model providers do red-team models and platforms, these safeguards are intended for broader use. Companies like Microsoft and Amazon Web Services even offer platforms to bring guardrails to AI applications and agents. Enterprises use safety classifiers to help train a model to recognize patterns of good or bad inputs. This helps the models learn which queries they shouldn’t reply to. It also helps ensure that the models do not drift and answer accurately.“Traditional classifiers can have high performance, with low latency and operating cost,\" OpenAI said. \"But gathering a sufficient quantity of training examples can be time-consuming and costly, and updating or changing the policy requires re-training the classifier.\"The models takes in two inputs at once before it outputs a conclusion on where the content fails. It takes a policy and the content to classify under its guidelines. OpenAI said the models work best in situations where: The potential harm is emerging or evolving, and policies need to adapt quickly.The domain is highly nuanced and difficult for smaller classifiers to handle.Developers don’t have enough samples to train a high-quality classifier for each risk on their platform.Latency is less important than producing high-quality, explainable labels.The company said gpt-oss-safeguard “is different because its reasoning capabilities allow developers to apply any policy,” even ones they’ve written during inference. The models are based on OpenAI’s internal tool, the Safety Reasoner, which enables its teams to be more iterative in setting guardrails. They often begin with very strict safety policies, “and use relatively large amounts of compute where needed,” then adjust policies as they move the model through production and risk assessments change. Performing safetyOpenAI said the gpt-oss-safeguard models outperformed its GPT-5-thinking and the original gpt-oss models on multipolicy accuracy based on benchmark testing. It also ran the models on the ToxicChat public benchmark, where they performed well, although GPT-5-thinking and the Safety Reasoner slightly edged them out.But there is concern that this approach could bring a centralization of safety standards.“Safety is not a well-defined concept. Any implementation of safety standards will reflect the values and priorities of the organization that creates it, as well as the limits and deficiencies of its models,” said John Thickstun, an assistant professor of computer science at Cornell University. “If industry as a whole adopts standards developed by OpenAI, we risk institutionalizing one particular perspective on safety and short-circuiting broader investigations into the safety needs for AI deployments across many sectors of society.”It should also be noted that OpenAI did not release the base model for the oss family of models, so developers cannot fully iterate on them. OpenAI, however, is confident that the developer community can help refine gpt-oss-safeguard. It will host a Hackathon on December 8 in San Francisco.",
          "content": "Enterprises, eager to ensure any AI models they use adhere to safety and safe-use policies, fine-tune LLMs so they do not respond to unwanted queries. However, much of the safeguarding and red teaming happens before deployment, “baking in” policies before users fully test the models’ capabilities in production. OpenAI believes it can offer a more flexible option for enterprises and encourage more companies to bring in safety policies. The company has released two open-weight models under research preview that it believes will make enterprises and models more flexible in terms of safeguards. gpt-oss-safeguard-120b and gpt-oss-safeguard-20b will be available on a permissive Apache 2.0 license. The models are fine-tuned versions of OpenAI’s open-source gpt-oss, released in August, marking the first release in the oss family since the summer.In a blog post, OpenAI said oss-safeguard uses reasoning “to directly interpret a developer-provider policy at inference time — classifying user messages, completions and full chats according to the developer’s needs.”The company explained that, since the model uses a chain-of-thought (CoT), developers can get explanations of the model&#x27;s decisions for review. “Additionally, the policy is provided during inference, rather than being trained into the model, so it is easy for developers to iteratively revise policies to increase performance,\" OpenAI said in its post. \"This approach, which we initially developed for internal use, is significantly more flexible than the traditional method of training a classifier to indirectly infer a decision boundary from a large number of labeled examples.\" Developers can download both models from Hugging Face. Flexibility versus baking inAt the onset, AI models will not know a company’s preferred safety triggers. While model providers do red-team models and platforms, these safeguards are intended for broader use. Companies like Microsoft and Amazon Web Services even offer platforms to bring guardrails to AI applications and agents. Enterprises use safety classifiers to help train a model to recognize patterns of good or bad inputs. This helps the models learn which queries they shouldn’t reply to. It also helps ensure that the models do not drift and answer accurately.“Traditional classifiers can have high performance, with low latency and operating cost,\" OpenAI said. \"But gathering a sufficient quantity of training examples can be time-consuming and costly, and updating or changing the policy requires re-training the classifier.\"The models takes in two inputs at once before it outputs a conclusion on where the content fails. It takes a policy and the content to classify under its guidelines. OpenAI said the models work best in situations where: The potential harm is emerging or evolving, and policies need to adapt quickly.The domain is highly nuanced and difficult for smaller classifiers to handle.Developers don’t have enough samples to train a high-quality classifier for each risk on their platform.Latency is less important than producing high-quality, explainable labels.The company said gpt-oss-safeguard “is different because its reasoning capabilities allow developers to apply any policy,” even ones they’ve written during inference. The models are based on OpenAI’s internal tool, the Safety Reasoner, which enables its teams to be more iterative in setting guardrails. They often begin with very strict safety policies, “and use relatively large amounts of compute where needed,” then adjust policies as they move the model through production and risk assessments change. Performing safetyOpenAI said the gpt-oss-safeguard models outperformed its GPT-5-thinking and the original gpt-oss models on multipolicy accuracy based on benchmark testing. It also ran the models on the ToxicChat public benchmark, where they performed well, although GPT-5-thinking and the Safety Reasoner slightly edged them out.But there is concern that this approach could bring a centralization of safety standards.“Safety is not a well-defined concept. Any implementation of safety standards will reflect the values and priorities of the organization that creates it, as well as the limits and deficiencies of its models,” said John Thickstun, an assistant professor of computer science at Cornell University. “If industry as a whole adopts standards developed by OpenAI, we risk institutionalizing one particular perspective on safety and short-circuiting broader investigations into the safety needs for AI deployments across many sectors of society.”It should also be noted that OpenAI did not release the base model for the oss family of models, so developers cannot fully iterate on them. OpenAI, however, is confident that the developer community can help refine gpt-oss-safeguard. It will host a Hackathon on December 8 in San Francisco.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7hdJbWzLDjzRu2QOtkbDKV/a3a7d637a3e748ccb3ff4ba06e1ff953/crimedy7_illustration_of_technological_safety_cones_--ar_169__cf756a3e-79a5-47c3-993d-cdb5f37f28a2_3.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/securitys-ai-dilemma-moving-faster-while-risking-more",
          "published_at": "Wed, 29 Oct 2025 04:00:00 GMT",
          "title": "Security's AI dilemma: Moving faster while risking more",
          "standfirst": "Presented by Splunk, a Cisco CompanyAs AI rapidly evolves from a theoretical promise to an operational reality, CISOs and CIOs face a fundamental challenge: how to harness AI&#x27;s transformative potential while maintaining the human oversight and strategic thinking that security demands. The rise of agentic AI is reshaping security operations, but success requires balancing automation with accountability.The efficiency paradox: Automation without abdicationThe pressure to adopt AI is intense. Organizations are being pushed to reduce headcount or redirect resources toward AI-driven initiatives, often without fully understanding what that transformation entails. The promise is compelling: AI can reduce investigation times from 60 minutes to just 5 minutes, potentially delivering 10x productivity improvements for security analysts.However, the critical question isn&#x27;t whether AI can automate tasks — it&#x27;s which tasks should be automated and where human judgment remains irreplaceable. The answer lies in understanding that AI excels at accelerating investigative workflows, but remediation and response actions still require human validation. Taking a system offline or quarantining an endpoint can have massive business impact. An AI making that call autonomously could inadvertently cause the very disruption it&#x27;s meant to prevent.The goal isn&#x27;t to replace security analysts but to free them for higher-value work. With routine alert triage automated, analysts can focus on red team/blue team exercises, collaborate with engineering teams on remediation, and engage in proactive threat hunting. There&#x27;s no shortage of security problems to solve — there&#x27;s a shortage of security experts to address them strategically.The trust deficit: Showing your workWhile confidence in AI&#x27;s ability to improve efficiency is high, skepticism about the quality of AI-driven decisions remains significant. Security teams need more than just AI-generated conclusions — they need transparency into how those conclusions were reached.When AI determines an alert is benign and closes it, SOC analysts need to understand the investigative steps that led to that determination. What data was examined? What patterns were identified? What alternative explanations were considered and ruled out?This transparency builds trust in AI recommendations, enables validation of AI logic, and creates opportunities for continuous improvement. Most importantly, it maintains the critical human-in-the-loop for complex judgment calls that require nuanced understanding of business context, compliance requirements, and potential cascading impacts.The future likely involves a hybrid model where autonomous capabilities are integrated into guided workflows and playbooks, with analysts remaining involved in complex decisions. The adversarial advantage: Fighting AI with AI — carefullyAI presents a dual-edged sword in security. While we&#x27;re carefully implementing AI with appropriate guardrails, adversaries face no such constraints. AI lowers the barrier to entry for attackers, enabling rapid exploit development and vulnerability discovery at scale. What was once the domain of sophisticated threat actors could soon be accessible to script kiddies armed with AI tools.The asymmetry is striking: defenders must be thoughtful and risk-averse, while attackers can experiment freely. If we make a mistake implementing autonomous security responses, we risk taking down production systems. If an attacker&#x27;s AI-driven exploit fails, they simply try again with no consequences.This creates an imperative to use AI defensively, but with appropriate caution. We must learn from attackers&#x27; techniques while maintaining the guardrails that prevent our AI from becoming the vulnerability. The recent emergence of malicious MCP (Model Context Protocol) supply chain attacks demonstrates how quickly adversaries exploit new AI infrastructure. The skills dilemma: Building capabilities while maintaining core competenciesAs AI handles more routine investigative work, a concerning question emerges: will security professionals&#x27; fundamental skills atrophy over time? This isn&#x27;t an argument against AI adoption — it&#x27;s a call for intentional skill development strategies. Organizations must balance AI-enabled efficiency with programs that maintain core competencies. This includes regular exercises that require manual investigation, cross-training that deepens understanding of underlying systems, and career paths that evolve roles rather than eliminate them.The responsibility is shared. Employers must provide tools, training, and culture that enable AI to augment rather than replace human expertise. Employees must actively engage in continuous learning, treating AI as a collaborative partner rather than a replacement for critical thinking.The identity crisis: Governing the agent explosionPerhaps the most underestimated challenge ahead is identity and access management in an agentic AI world. IDC estimates 1.3 billion agents by 2028 — each requiring identity, permissions, and governance. The complexity compounds exponentially.Overly permissive agents represent significant risk. An agent with broad administrative access could be socially engineered into taking destructive actions, approving fraudulent transactions, or exfiltrating sensitive data. The technical shortcuts engineers take to \"just make it work\" — granting excessive permissions to expedite deployment — create vulnerabilities that adversaries will exploit.Tool-based access control offers one path forward, granting agents only the specific capabilities they need. But governance frameworks must also address how LLMs themselves might learn and retain authentication information, potentially enabling impersonation attacks that bypass traditional access controls.The path forward: Start with compliance and reportingAmid these challenges, one area offers immediate, high-impact opportunity: continuous compliance and risk reporting. AI&#x27;s ability to consume vast amounts of documentation, interpret complex requirements, and generate concise summaries makes it ideal for compliance and reporting work that has traditionally consumed enormous analysts’ time. This represents a low-risk, high-value entry point for AI in security operations. The data foundation: Enabling the AI-powered SOCNone of these AI capabilities can succeed without addressing the fundamental data challenges facing security operations. SOC teams struggle with siloed data and disparate tools. Success requires a deliberate data strategy that prioritizes accessibility, quality, and unified data contexts. Security-relevant data must be immediately available to AI agents without friction, properly governed to ensure reliability, and enriched with metadata that provides the business context AI cannot understand. Closing thought: Innovation with intentionalityThe autonomous SOC is emerging — not as a light switch to flip, but as an evolutionary journey requiring continuous adaptation. Success demands that we embrace AI&#x27;s efficiency gains while maintaining the human judgment, strategic thinking, and ethical oversight that security requires.We&#x27;re not replacing security teams with AI. We&#x27;re building collaborative, multi-agent systems where human expertise guides AI capabilities toward outcomes that neither could achieve alone. That&#x27;s the promise of the agentic AI era — if we&#x27;re intentional about how we get there.Tanya Faddoul, VP Product, Customer Strategy and Chief of Staff for Splunk, a Cisco Company. Michael Fanning is Chief Information Security Officer for Splunk, a Cisco Company. Cisco Data Fabric provides the needed data architecture powered by Splunk Platform — unified data fabric, federated search capabilities, comprehensive metadata management — to unlock AI and SOC’s full potential. Learn more about Cisco Data Fabric.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Splunk, a Cisco CompanyAs AI rapidly evolves from a theoretical promise to an operational reality, CISOs and CIOs face a fundamental challenge: how to harness AI&#x27;s transformative potential while maintaining the human oversight and strategic thinking that security demands. The rise of agentic AI is reshaping security operations, but success requires balancing automation with accountability.The efficiency paradox: Automation without abdicationThe pressure to adopt AI is intense. Organizations are being pushed to reduce headcount or redirect resources toward AI-driven initiatives, often without fully understanding what that transformation entails. The promise is compelling: AI can reduce investigation times from 60 minutes to just 5 minutes, potentially delivering 10x productivity improvements for security analysts.However, the critical question isn&#x27;t whether AI can automate tasks — it&#x27;s which tasks should be automated and where human judgment remains irreplaceable. The answer lies in understanding that AI excels at accelerating investigative workflows, but remediation and response actions still require human validation. Taking a system offline or quarantining an endpoint can have massive business impact. An AI making that call autonomously could inadvertently cause the very disruption it&#x27;s meant to prevent.The goal isn&#x27;t to replace security analysts but to free them for higher-value work. With routine alert triage automated, analysts can focus on red team/blue team exercises, collaborate with engineering teams on remediation, and engage in proactive threat hunting. There&#x27;s no shortage of security problems to solve — there&#x27;s a shortage of security experts to address them strategically.The trust deficit: Showing your workWhile confidence in AI&#x27;s ability to improve efficiency is high, skepticism about the quality of AI-driven decisions remains significant. Security teams need more than just AI-generated conclusions — they need transparency into how those conclusions were reached.When AI determines an alert is benign and closes it, SOC analysts need to understand the investigative steps that led to that determination. What data was examined? What patterns were identified? What alternative explanations were considered and ruled out?This transparency builds trust in AI recommendations, enables validation of AI logic, and creates opportunities for continuous improvement. Most importantly, it maintains the critical human-in-the-loop for complex judgment calls that require nuanced understanding of business context, compliance requirements, and potential cascading impacts.The future likely involves a hybrid model where autonomous capabilities are integrated into guided workflows and playbooks, with analysts remaining involved in complex decisions. The adversarial advantage: Fighting AI with AI — carefullyAI presents a dual-edged sword in security. While we&#x27;re carefully implementing AI with appropriate guardrails, adversaries face no such constraints. AI lowers the barrier to entry for attackers, enabling rapid exploit development and vulnerability discovery at scale. What was once the domain of sophisticated threat actors could soon be accessible to script kiddies armed with AI tools.The asymmetry is striking: defenders must be thoughtful and risk-averse, while attackers can experiment freely. If we make a mistake implementing autonomous security responses, we risk taking down production systems. If an attacker&#x27;s AI-driven exploit fails, they simply try again with no consequences.This creates an imperative to use AI defensively, but with appropriate caution. We must learn from attackers&#x27; techniques while maintaining the guardrails that prevent our AI from becoming the vulnerability. The recent emergence of malicious MCP (Model Context Protocol) supply chain attacks demonstrates how quickly adversaries exploit new AI infrastructure. The skills dilemma: Building capabilities while maintaining core competenciesAs AI handles more routine investigative work, a concerning question emerges: will security professionals&#x27; fundamental skills atrophy over time? This isn&#x27;t an argument against AI adoption — it&#x27;s a call for intentional skill development strategies. Organizations must balance AI-enabled efficiency with programs that maintain core competencies. This includes regular exercises that require manual investigation, cross-training that deepens understanding of underlying systems, and career paths that evolve roles rather than eliminate them.The responsibility is shared. Employers must provide tools, training, and culture that enable AI to augment rather than replace human expertise. Employees must actively engage in continuous learning, treating AI as a collaborative partner rather than a replacement for critical thinking.The identity crisis: Governing the agent explosionPerhaps the most underestimated challenge ahead is identity and access management in an agentic AI world. IDC estimates 1.3 billion agents by 2028 — each requiring identity, permissions, and governance. The complexity compounds exponentially.Overly permissive agents represent significant risk. An agent with broad administrative access could be socially engineered into taking destructive actions, approving fraudulent transactions, or exfiltrating sensitive data. The technical shortcuts engineers take to \"just make it work\" — granting excessive permissions to expedite deployment — create vulnerabilities that adversaries will exploit.Tool-based access control offers one path forward, granting agents only the specific capabilities they need. But governance frameworks must also address how LLMs themselves might learn and retain authentication information, potentially enabling impersonation attacks that bypass traditional access controls.The path forward: Start with compliance and reportingAmid these challenges, one area offers immediate, high-impact opportunity: continuous compliance and risk reporting. AI&#x27;s ability to consume vast amounts of documentation, interpret complex requirements, and generate concise summaries makes it ideal for compliance and reporting work that has traditionally consumed enormous analysts’ time. This represents a low-risk, high-value entry point for AI in security operations. The data foundation: Enabling the AI-powered SOCNone of these AI capabilities can succeed without addressing the fundamental data challenges facing security operations. SOC teams struggle with siloed data and disparate tools. Success requires a deliberate data strategy that prioritizes accessibility, quality, and unified data contexts. Security-relevant data must be immediately available to AI agents without friction, properly governed to ensure reliability, and enriched with metadata that provides the business context AI cannot understand. Closing thought: Innovation with intentionalityThe autonomous SOC is emerging — not as a light switch to flip, but as an evolutionary journey requiring continuous adaptation. Success demands that we embrace AI&#x27;s efficiency gains while maintaining the human judgment, strategic thinking, and ethical oversight that security requires.We&#x27;re not replacing security teams with AI. We&#x27;re building collaborative, multi-agent systems where human expertise guides AI capabilities toward outcomes that neither could achieve alone. That&#x27;s the promise of the agentic AI era — if we&#x27;re intentional about how we get there.Tanya Faddoul, VP Product, Customer Strategy and Chief of Staff for Splunk, a Cisco Company. Michael Fanning is Chief Information Security Officer for Splunk, a Cisco Company. Cisco Data Fabric provides the needed data architecture powered by Splunk Platform — unified data fabric, federated search capabilities, comprehensive metadata management — to unlock AI and SOC’s full potential. Learn more about Cisco Data Fabric.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1xzoYYdBHblQvb1NzXRGSt/c50436b7df8872f3ba4eb867f2fd06dc/AdobeStock_1081293355_Preview.jpeg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/agentic-ai-is-all-about-the-context-engineering-that-is",
          "published_at": "Wed, 29 Oct 2025 04:00:00 GMT",
          "title": "Agentic AI is all about the context — engineering, that is",
          "standfirst": "Presented by ElasticAs organizations scramble to enact agentic AI solutions, accessing proprietary data from all the nooks and crannies will be keyBy now, most organizations have heard of agentic AI, which are systems that “think” by autonomously gathering tools, data and other sources of information to return an answer. But here’s the rub: reliability and relevance depend on delivering accurate context. In most enterprises, this context is scattered across various unstructured data sources, including documents, emails, business apps, and customer feedback. As organizations look ahead to 2026, solving this problem will be key to accelerating agentic AI rollouts around the world, says Ken Exner, chief product officer at Elastic. \"People are starting to realize that to do agentic AI correctly, you have to have relevant data,\" Exner says. \"Relevance is critical in the context of agentic AI, because that AI is taking action on your behalf. When people struggle to build AI applications, I can almost guarantee you the problem is relevance.”Agents everywhereThe struggle could be entering a make-or-break period as organizations scramble for competitive edge or to create new efficiencies. A Deloitte study predicts that by 2026, more than 60% of large enterprises will have deployed agentic AI at scale, marking a major increase from experimental phases to mainstream implementation. And researcher Gartner forecasts that by the end of 2026, 40% of all enterprise applications will incorporate task-specific agents, up from less than 5% in 2025. Adding task specialization capabilities evolves AI assistants into context-aware AI agents.Enter context engineeringThe process for getting the relevant context into agents at the right time is known as context engineering. It not only ensures that an agentic application has the data it needs to provide accurate, in-depth responses, it helps the large language model (LLM) understand what tools it needs to find and use that data, and how to call those APIs. While there are now open-source standards such as the Model Context Protocol (MCP) that allow LLMs to connect to and communicate with external data, there are few platforms that let organizations build precise AI agents that use your data and combine retrieval, governance, and orchestration in one place, natively. Elasticsearch has always been a leading platform for the core of context engineering. It recently released a new feature within Elasticsearch called Agent Builder, which simplifies the entire operational lifecycle of agents: development, configuration, execution, customization, and observability.Agent Builder helps build MCP tools on private data using various techniques, including Elasticsearch Query Language, a piped query language for filtering, transforming, and analyzing data, or workflow modeling. Users can then take various tools and combine them with prompts and an LLM to build an agent. Agent Builder offers a configurable, out-of-the-box conversational agent that allows you to chat with the data in the index, and it also gives users the ability to build one from scratch using various tools and prompts on top of private data. \"Data is the center of our world at Elastic. We’re trying to make sure that you have the tools you need to put that data to work,\" Exner explains. \"The second you open up Agent Builder, you point it to an index in Elasticsearch, and you can begin chatting with any data you connect this to, any data that’s indexed in Elasticsearch — or from external sources through integrations.”Context engineering as a disciplinePrompt and context engineering is becoming a discipli. It’s not something you need a computer science degree in, but more classes and best practices will emerge, because there’s an art to it. \"We want to make it very simple to do that,\" Exner says. \"The thing that people will have to figure out is, how do you drive automation with AI? That’s what’s going to drive productivity. The people who are focused on that will see more success.\"Beyond that, other context engineering patterns will emerge. The industry has gone from prompt engineering to retrieval-augmented generation, where information is passed to the LLM in a context window, to MCP solutions that help LLMs with tool selection. But it won&#x27;t stop there.\"Given how fast things are moving, I will guarantee that new patterns will emerge quite quickly,\" Exner says. \"There will still be context engineering, but they’ll be new patterns for how to share data with an LLM, how to get it to be grounded in the right information. And I predict more patterns that make it possible for the LLM to understand private data that it’s not been trained on.\"Agent Builder is available now as a tech preview. Get started with an Elastic Cloud Trial, and check out the documentation for Agent Builder here.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by ElasticAs organizations scramble to enact agentic AI solutions, accessing proprietary data from all the nooks and crannies will be keyBy now, most organizations have heard of agentic AI, which are systems that “think” by autonomously gathering tools, data and other sources of information to return an answer. But here’s the rub: reliability and relevance depend on delivering accurate context. In most enterprises, this context is scattered across various unstructured data sources, including documents, emails, business apps, and customer feedback. As organizations look ahead to 2026, solving this problem will be key to accelerating agentic AI rollouts around the world, says Ken Exner, chief product officer at Elastic. \"People are starting to realize that to do agentic AI correctly, you have to have relevant data,\" Exner says. \"Relevance is critical in the context of agentic AI, because that AI is taking action on your behalf. When people struggle to build AI applications, I can almost guarantee you the problem is relevance.”Agents everywhereThe struggle could be entering a make-or-break period as organizations scramble for competitive edge or to create new efficiencies. A Deloitte study predicts that by 2026, more than 60% of large enterprises will have deployed agentic AI at scale, marking a major increase from experimental phases to mainstream implementation. And researcher Gartner forecasts that by the end of 2026, 40% of all enterprise applications will incorporate task-specific agents, up from less than 5% in 2025. Adding task specialization capabilities evolves AI assistants into context-aware AI agents.Enter context engineeringThe process for getting the relevant context into agents at the right time is known as context engineering. It not only ensures that an agentic application has the data it needs to provide accurate, in-depth responses, it helps the large language model (LLM) understand what tools it needs to find and use that data, and how to call those APIs. While there are now open-source standards such as the Model Context Protocol (MCP) that allow LLMs to connect to and communicate with external data, there are few platforms that let organizations build precise AI agents that use your data and combine retrieval, governance, and orchestration in one place, natively. Elasticsearch has always been a leading platform for the core of context engineering. It recently released a new feature within Elasticsearch called Agent Builder, which simplifies the entire operational lifecycle of agents: development, configuration, execution, customization, and observability.Agent Builder helps build MCP tools on private data using various techniques, including Elasticsearch Query Language, a piped query language for filtering, transforming, and analyzing data, or workflow modeling. Users can then take various tools and combine them with prompts and an LLM to build an agent. Agent Builder offers a configurable, out-of-the-box conversational agent that allows you to chat with the data in the index, and it also gives users the ability to build one from scratch using various tools and prompts on top of private data. \"Data is the center of our world at Elastic. We’re trying to make sure that you have the tools you need to put that data to work,\" Exner explains. \"The second you open up Agent Builder, you point it to an index in Elasticsearch, and you can begin chatting with any data you connect this to, any data that’s indexed in Elasticsearch — or from external sources through integrations.”Context engineering as a disciplinePrompt and context engineering is becoming a discipli. It’s not something you need a computer science degree in, but more classes and best practices will emerge, because there’s an art to it. \"We want to make it very simple to do that,\" Exner says. \"The thing that people will have to figure out is, how do you drive automation with AI? That’s what’s going to drive productivity. The people who are focused on that will see more success.\"Beyond that, other context engineering patterns will emerge. The industry has gone from prompt engineering to retrieval-augmented generation, where information is passed to the LLM in a context window, to MCP solutions that help LLMs with tool selection. But it won&#x27;t stop there.\"Given how fast things are moving, I will guarantee that new patterns will emerge quite quickly,\" Exner says. \"There will still be context engineering, but they’ll be new patterns for how to share data with an LLM, how to get it to be grounded in the right information. And I predict more patterns that make it possible for the LLM to understand private data that it’s not been trained on.\"Agent Builder is available now as a tech preview. Get started with an Elastic Cloud Trial, and check out the documentation for Agent Builder here.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3HhYB9aUXlzxC0Q4V716ck/a33201a5ce2da5b486e6a20da9abbb52/AdobeStock_703274424.jpeg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/nvidia-researchers-unlock-4-bit-llm-training-that-matches-8-bit-performance",
          "published_at": "Wed, 29 Oct 2025 00:00:00 GMT",
          "title": "Nvidia researchers unlock 4-bit LLM training that matches 8-bit performance",
          "standfirst": "Researchers at Nvidia have developed a novel approach to train large language models (LLMs) in 4-bit quantized format while maintaining their stability and accuracy at the level of high-precision models. Their technique, NVFP4, makes it possible to train models that not only outperform other leading 4-bit formats but match the performance of the larger 8-bit FP8 format, all while using half the memory and a fraction of the compute.The success of NVFP4 shows that enterprises can continue to cut inference costs by running leaner models that match the performance of larger ones. It also hints at a future where the cost of training LLMs will drop to a point where many more organizations can train their own bespoke models from scratch rather than just fine-tuning existing ones.The quantization challengeModel quantization is a technique used to reduce the computational and memory costs of running and training AI models. It works by converting the model&#x27;s parameters, or weights, from high-precision formats like 16- and 32-bit floating point (BF16 and FP32) to lower-precision formats. The key challenge of quantization is to reduce the size of the model while preserving as much of its knowledge and capabilities as possible.In recent years, 8-bit floating point formats (FP8) have become a popular industry standard, offering a good balance between performance and efficiency. They significantly lower the computational cost and memory demand for LLM training without a major drop in accuracy.The next logical step is 4-bit floating point (FP4), which promises to halve memory usage again and further boost performance on advanced hardware. However, this transition has been challenging. Existing 4-bit formats, such as MXFP4, often struggle to maintain the same level of accuracy as their 8-bit counterparts, forcing a difficult trade-off between cost and performance.How NVFP4 worksNVFP4 overcomes the stability and accuracy challenges of other FP4 techniques through a smarter design and a targeted training methodology. A key issue with 4-bit precision is its extremely limited range: It can only represent 16 distinct values. When converting from a high-precision format, outlier values can distort the entire dataset, harming the model&#x27;s accuracy. NVFP4 uses a more sophisticated, multi-level scaling approach that better handles these outliers, allowing for a \"more precise and accurate representation of tensor values during training,\" according to Nvidia.Beyond the format, the researchers introduce a 4-bit training recipe that achieves accuracy comparable to FP8. A central component is their “mixed-precision strategy.” Instead of converting the entire model to NVFP4, the majority of layers are quantized while a small fraction of numerically sensitive layers are kept in a higher-precision format like BF16. This preserves stability where it matters most. The methodology also adjusts how gradients are calculated during backpropagation — or the model&#x27;s learning phase — to reduce biases that can accumulate from low-precision arithmetic.NVFP4 in practiceTo test their approach, the Nvidia team trained a powerful 12-billion-parameter hybrid Mamba-Transformer model on a massive 10 trillion tokens. They then compared its performance directly against a baseline model trained in the widely popular FP8 format. The results showed that the NVFP4 model&#x27;s training loss and downstream task accuracy closely tracked the FP8 version throughout the entire process.The performance held across a wide range of domains, including knowledge-intensive reasoning, mathematics and commonsense tasks, with only a slight drop-off in coding benchmarks in late training.\"This marks, to our knowledge, the first successful demonstration of training billion-parameter language models with 4-bit precision over a multi-trillion-token horizon, laying the foundation for faster and more efficient training of future frontier models,” the researchers write.According to Nvidia&#x27;s director of product for AI and data center GPUs NvidiaShar Narasimhan, in practice, NVFP4’s 4-bit precision format enables developers and businesses to train and deploy AI models with nearly the same accuracy as traditional 8-bit formats. “By training model weights directly in 4-bit format while preserving accuracy, it empowers developers to experiment with new architectures, iterate faster and uncover insights without being bottlenecked by resource constraints,” he told VentureBeat. In contrast, FP8 (while already a leap forward from FP16) still imposes limits on model size and inference performance due to higher memory and bandwidth demands. “NVFP4 breaks that ceiling, offering equivalent quality with dramatically greater headroom for growth and experimentation,” Narasimhan said.When compared to the alternative 4-bit format, MXFP4, the benefits of NVFP4 become even clearer. In an experiment with an 8-billion-parameter model, NVFP4 converged to a better loss score than MXFP4. To reach the same level of performance as the NVFP4 model, the MXFP4 model had to be trained on 36% more data, a considerable increase in training time and cost.In addition to making pretraining more efficient, NVFP4 also redefines what’s possible. “Showing that 4-bit precision can preserve model quality at scale opens the door to a future where highly specialized models can be trained from scratch by mid-sized enterprises or startups, not just hyperscalers,” Narasimhan said, adding that, over time, we can expect a shift from developing general purpose LLMs models to “a diverse ecosystem of custom, high-performance models built by a broader range of innovators.”Beyond pre-trainingAlthough the paper focuses on the advantages of NVFP4 during pretraining, its impact extends to inference, as well. “Models trained on NVFP4 can not only deliver faster inference and higher throughput but shorten the time required for AI factories to achieve ROI — accelerating the cycle from model development to real-world deployment,” Narasimhan said. Because these models are smaller and more efficient, they unlock new possibilities for serving complex, high-quality responses in real time, even in token-intensive, agentic applications, without raising energy and compute costs. Narasimhan said he looks toward a future of model efficiency that isn’t solely about pushing precision lower, but building smarter systems. “There are many opportunities to expand research into lower precisions as well as modifying architectures to address the components that increasingly dominate compute in large-scale models,” he said. “These areas are rich with opportunity, especially as we move toward agentic systems that demand high throughput, low latency and adaptive reasoning. NVFP4 proves that precision can be optimized without compromising quality, and it sets the stage for a new era of intelligent, efficient AI design.”",
          "content": "Researchers at Nvidia have developed a novel approach to train large language models (LLMs) in 4-bit quantized format while maintaining their stability and accuracy at the level of high-precision models. Their technique, NVFP4, makes it possible to train models that not only outperform other leading 4-bit formats but match the performance of the larger 8-bit FP8 format, all while using half the memory and a fraction of the compute.The success of NVFP4 shows that enterprises can continue to cut inference costs by running leaner models that match the performance of larger ones. It also hints at a future where the cost of training LLMs will drop to a point where many more organizations can train their own bespoke models from scratch rather than just fine-tuning existing ones.The quantization challengeModel quantization is a technique used to reduce the computational and memory costs of running and training AI models. It works by converting the model&#x27;s parameters, or weights, from high-precision formats like 16- and 32-bit floating point (BF16 and FP32) to lower-precision formats. The key challenge of quantization is to reduce the size of the model while preserving as much of its knowledge and capabilities as possible.In recent years, 8-bit floating point formats (FP8) have become a popular industry standard, offering a good balance between performance and efficiency. They significantly lower the computational cost and memory demand for LLM training without a major drop in accuracy.The next logical step is 4-bit floating point (FP4), which promises to halve memory usage again and further boost performance on advanced hardware. However, this transition has been challenging. Existing 4-bit formats, such as MXFP4, often struggle to maintain the same level of accuracy as their 8-bit counterparts, forcing a difficult trade-off between cost and performance.How NVFP4 worksNVFP4 overcomes the stability and accuracy challenges of other FP4 techniques through a smarter design and a targeted training methodology. A key issue with 4-bit precision is its extremely limited range: It can only represent 16 distinct values. When converting from a high-precision format, outlier values can distort the entire dataset, harming the model&#x27;s accuracy. NVFP4 uses a more sophisticated, multi-level scaling approach that better handles these outliers, allowing for a \"more precise and accurate representation of tensor values during training,\" according to Nvidia.Beyond the format, the researchers introduce a 4-bit training recipe that achieves accuracy comparable to FP8. A central component is their “mixed-precision strategy.” Instead of converting the entire model to NVFP4, the majority of layers are quantized while a small fraction of numerically sensitive layers are kept in a higher-precision format like BF16. This preserves stability where it matters most. The methodology also adjusts how gradients are calculated during backpropagation — or the model&#x27;s learning phase — to reduce biases that can accumulate from low-precision arithmetic.NVFP4 in practiceTo test their approach, the Nvidia team trained a powerful 12-billion-parameter hybrid Mamba-Transformer model on a massive 10 trillion tokens. They then compared its performance directly against a baseline model trained in the widely popular FP8 format. The results showed that the NVFP4 model&#x27;s training loss and downstream task accuracy closely tracked the FP8 version throughout the entire process.The performance held across a wide range of domains, including knowledge-intensive reasoning, mathematics and commonsense tasks, with only a slight drop-off in coding benchmarks in late training.\"This marks, to our knowledge, the first successful demonstration of training billion-parameter language models with 4-bit precision over a multi-trillion-token horizon, laying the foundation for faster and more efficient training of future frontier models,” the researchers write.According to Nvidia&#x27;s director of product for AI and data center GPUs NvidiaShar Narasimhan, in practice, NVFP4’s 4-bit precision format enables developers and businesses to train and deploy AI models with nearly the same accuracy as traditional 8-bit formats. “By training model weights directly in 4-bit format while preserving accuracy, it empowers developers to experiment with new architectures, iterate faster and uncover insights without being bottlenecked by resource constraints,” he told VentureBeat. In contrast, FP8 (while already a leap forward from FP16) still imposes limits on model size and inference performance due to higher memory and bandwidth demands. “NVFP4 breaks that ceiling, offering equivalent quality with dramatically greater headroom for growth and experimentation,” Narasimhan said.When compared to the alternative 4-bit format, MXFP4, the benefits of NVFP4 become even clearer. In an experiment with an 8-billion-parameter model, NVFP4 converged to a better loss score than MXFP4. To reach the same level of performance as the NVFP4 model, the MXFP4 model had to be trained on 36% more data, a considerable increase in training time and cost.In addition to making pretraining more efficient, NVFP4 also redefines what’s possible. “Showing that 4-bit precision can preserve model quality at scale opens the door to a future where highly specialized models can be trained from scratch by mid-sized enterprises or startups, not just hyperscalers,” Narasimhan said, adding that, over time, we can expect a shift from developing general purpose LLMs models to “a diverse ecosystem of custom, high-performance models built by a broader range of innovators.”Beyond pre-trainingAlthough the paper focuses on the advantages of NVFP4 during pretraining, its impact extends to inference, as well. “Models trained on NVFP4 can not only deliver faster inference and higher throughput but shorten the time required for AI factories to achieve ROI — accelerating the cycle from model development to real-world deployment,” Narasimhan said. Because these models are smaller and more efficient, they unlock new possibilities for serving complex, high-quality responses in real time, even in token-intensive, agentic applications, without raising energy and compute costs. Narasimhan said he looks toward a future of model efficiency that isn’t solely about pushing precision lower, but building smarter systems. “There are many opportunities to expand research into lower precisions as well as modifying architectures to address the components that increasingly dominate compute in large-scale models,” he said. “These areas are rich with opportunity, especially as we move toward agentic systems that demand high throughput, low latency and adaptive reasoning. NVFP4 proves that precision can be optimized without compromising quality, and it sets the stage for a new era of intelligent, efficient AI design.”",
          "feed_position": 7,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6m9WZeiaEIOLcUtuBpQLED/7143d90738c0365e7649a06167b709df/cfr0z3n_photorealistic_35mm_a_tiny_intricate_clockwork_robot_ra_6c68cfa0-0d24-4ad5-8964-179622de805f.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ibms-open-source-granite-4-0-nano-ai-models-are-small-enough-to-run-locally",
          "published_at": "Tue, 28 Oct 2025 23:23:00 GMT",
          "title": "IBM's open source Granite 4.0 Nano AI models are small enough to run locally directly in your browser",
          "standfirst": "In an industry where model size is often seen as a proxy for intelligence, IBM is charting a different course — one that values efficiency over enormity, and accessibility over abstraction.The 114-year-old tech giant&#x27;s four new Granite 4.0 Nano models, released today, range from just 350 million to 1.5 billion parameters, a fraction of the size of their server-bound cousins from the likes of OpenAI, Anthropic, and Google. These models are designed to be highly accessible: the 350M variants can run comfortably on a modern laptop CPU with 8–16GB of RAM, while the 1.5B models typically require a GPU with at least 6–8GB of VRAM for smooth performance — or sufficient system RAM and swap for CPU-only inference. This makes them well-suited for developers building applications on consumer hardware or at the edge, without relying on cloud compute.In fact, the smallest ones can even run locally on your own web browser, as Joshua Lochner aka Xenova, creator of Transformer.js and a machine learning engineer at Hugging Face, wrote on the social network X.All the Granite 4.0 Nano models are released under the Apache 2.0 license — perfect for use by researchers and enterprise or indie developers, even for commercial usage. They are natively compatible with llama.cpp, vLLM, and MLX and are certified under ISO 42001 for responsible AI development — a standard IBM helped pioneer.But in this case, small doesn&#x27;t mean less capable — it might just mean smarter design.These compact models are built not for data centers, but for edge devices, laptops, and local inference, where compute is scarce and latency matters. And despite their small size, the Nano models are showing benchmark results that rival or even exceed the performance of larger models in the same category. The release is a signal that a new AI frontier is rapidly forming — one not dominated by sheer scale, but by strategic scaling.What Exactly Did IBM Release?The Granite 4.0 Nano family includes four open-source models now available on Hugging Face:Granite-4.0-H-1B (~1.5B parameters) – Hybrid-SSM architectureGranite-4.0-H-350M (~350M parameters) – Hybrid-SSM architectureGranite-4.0-1B – Transformer-based variant, parameter count closer to 2BGranite-4.0-350M – Transformer-based variantThe H-series models — Granite-4.0-H-1B and H-350M — use a hybrid state space architecture (SSM) that combines efficiency with strong performance, ideal for low-latency edge environments. Meanwhile, the standard transformer variants — Granite-4.0-1B and 350M — offer broader compatibility with tools like llama.cpp, designed for use cases where hybrid architecture isn’t yet supported. In practice, the transformer 1B model is closer to 2B parameters, but aligns performance-wise with its hybrid sibling, offering developers flexibility based on their runtime constraints.“The hybrid variant is a true 1B model. However, the non-hybrid variant is closer to 2B, but we opted to keep the naming aligned to the hybrid variant to make the connection easily visible,” explained Emma, Product Marketing lead for Granite, during a Reddit \"Ask Me Anything\" (AMA) session on r/LocalLLaMA.A Competitive Class of Small ModelsIBM is entering a crowded and rapidly evolving market of small language models (SLMs), competing with offerings like Qwen3, Google&#x27;s Gemma, LiquidAI’s LFM2, and even Mistral’s dense models in the sub-2B parameter space.While OpenAI and Anthropic focus on models that require clusters of GPUs and sophisticated inference optimization, IBM’s Nano family is aimed squarely at developers who want to run performant LLMs on local or constrained hardware.In benchmark testing, IBM’s new models consistently top the charts in their class. According to data shared on X by David Cox, VP of AI Models at IBM Research:On IFEval (instruction following), Granite-4.0-H-1B scored 78.5, outperforming Qwen3-1.7B (73.1) and other 1–2B models.On BFCLv3 (function/tool calling), Granite-4.0-1B led with a score of 54.8, the highest in its size class.On safety benchmarks (SALAD and AttaQ), the Granite models scored over 90%, surpassing similarly sized competitors.Overall, the Granite-4.0-1B achieved a leading average benchmark score of 68.3% across general knowledge, math, code, and safety domains.This performance is especially significant given the hardware constraints these models are designed for. They require less memory, run faster on CPUs or mobile devices, and don’t need cloud infrastructure or GPU acceleration to deliver usable results.Why Model Size Still Matters — But Not Like It Used ToIn the early wave of LLMs, bigger meant better — more parameters translated to better generalization, deeper reasoning, and richer output. But as transformer research matured, it became clear that architecture, training quality, and task-specific tuning could allow smaller models to punch well above their weight class.IBM is banking on this evolution. By releasing open, small models that are competitive in real-world tasks, the company is offering an alternative to the monolithic AI APIs that dominate today’s application stack.In fact, the Nano models address three increasingly important needs:Deployment flexibility — they run anywhere, from mobile to microservers.Inference privacy — users can keep data local with no need to call out to cloud APIs.Openness and auditability — source code and model weights are publicly available under an open license.Community Response and Roadmap SignalsIBM’s Granite team didn’t just launch the models and walk away — they took to Reddit’s open source community r/LocalLLaMA to engage directly with developers. In an AMA-style thread, Emma (Product Marketing, Granite) answered technical questions, addressed concerns about naming conventions, and dropped hints about what’s next.Notable confirmations from the thread:A larger Granite 4.0 model is currently in trainingReasoning-focused models (\"thinking counterparts\") are in the pipelineIBM will release fine-tuning recipes and a full training paper soonMore tooling and platform compatibility is on the roadmapUsers responded enthusiastically to the models’ capabilities, especially in instruction-following and structured response tasks. One commenter summed it up:“This is big if true for a 1B model — if quality is nice and it gives consistent outputs. Function-calling tasks, multilingual dialog, FIM completions… this could be a real workhorse.”Another user remarked:“The Granite Tiny is already my go-to for web search in LM Studio — better than some Qwen models. Tempted to give Nano a shot.”Background: IBM Granite and the Enterprise AI RaceIBM’s push into large language models began in earnest in late 2023 with the debut of the Granite foundation model family, starting with models like Granite.13b.instruct and Granite.13b.chat. Released for use within its Watsonx platform, these initial decoder-only models signaled IBM’s ambition to build enterprise-grade AI systems that prioritize transparency, efficiency, and performance. The company open-sourced select Granite code models under the Apache 2.0 license in mid-2024, laying the groundwork for broader adoption and developer experimentation.The real inflection point came with Granite 3.0 in October 2024 — a fully open-source suite of general-purpose and domain-specialized models ranging from 1B to 8B parameters. These models emphasized efficiency over brute scale, offering capabilities like longer context windows, instruction tuning, and integrated guardrails. IBM positioned Granite 3.0 as a direct competitor to Meta’s Llama, Alibaba’s Qwen, and Google&#x27;s Gemma — but with a uniquely enterprise-first lens. Later versions, including Granite 3.1 and Granite 3.2, introduced even more enterprise-friendly innovations: embedded hallucination detection, time-series forecasting, document vision models, and conditional reasoning toggles.The Granite 4.0 family, launched in October 2025, represents IBM’s most technically ambitious release yet. It introduces a hybrid architecture that blends transformer and Mamba-2 layers — aiming to combine the contextual precision of attention mechanisms with the memory efficiency of state-space models. This design allows IBM to significantly reduce memory and latency costs for inference, making Granite models viable on smaller hardware while still outperforming peers in instruction-following and function-calling tasks. The launch also includes ISO 42001 certification, cryptographic model signing, and distribution across platforms like Hugging Face, Docker, LM Studio, Ollama, and watsonx.ai.Across all iterations, IBM’s focus has been clear: build trustworthy, efficient, and legally unambiguous AI models for enterprise use cases. With a permissive Apache 2.0 license, public benchmarks, and an emphasis on governance, the Granite initiative not only responds to rising concerns over proprietary black-box models but also offers a Western-aligned open alternative to the rapid progress from teams like Alibaba’s Qwen. In doing so, Granite positions IBM as a leading voice in what may be the next phase of open-weight, production-ready AI.A Shift Toward Scalable EfficiencyIn the end, IBM’s release of Granite 4.0 Nano models reflects a strategic shift in LLM development: from chasing parameter count records to optimizing usability, openness, and deployment reach.By combining competitive performance, responsible development practices, and deep engagement with the open-source community, IBM is positioning Granite as not just a family of models — but a platform for building the next generation of lightweight, trustworthy AI systems.For developers and researchers looking for performance without overhead, the Nano release offers a compelling signal: you don’t need 70 billion parameters to build something powerful — just the right ones.",
          "content": "In an industry where model size is often seen as a proxy for intelligence, IBM is charting a different course — one that values efficiency over enormity, and accessibility over abstraction.The 114-year-old tech giant&#x27;s four new Granite 4.0 Nano models, released today, range from just 350 million to 1.5 billion parameters, a fraction of the size of their server-bound cousins from the likes of OpenAI, Anthropic, and Google. These models are designed to be highly accessible: the 350M variants can run comfortably on a modern laptop CPU with 8–16GB of RAM, while the 1.5B models typically require a GPU with at least 6–8GB of VRAM for smooth performance — or sufficient system RAM and swap for CPU-only inference. This makes them well-suited for developers building applications on consumer hardware or at the edge, without relying on cloud compute.In fact, the smallest ones can even run locally on your own web browser, as Joshua Lochner aka Xenova, creator of Transformer.js and a machine learning engineer at Hugging Face, wrote on the social network X.All the Granite 4.0 Nano models are released under the Apache 2.0 license — perfect for use by researchers and enterprise or indie developers, even for commercial usage. They are natively compatible with llama.cpp, vLLM, and MLX and are certified under ISO 42001 for responsible AI development — a standard IBM helped pioneer.But in this case, small doesn&#x27;t mean less capable — it might just mean smarter design.These compact models are built not for data centers, but for edge devices, laptops, and local inference, where compute is scarce and latency matters. And despite their small size, the Nano models are showing benchmark results that rival or even exceed the performance of larger models in the same category. The release is a signal that a new AI frontier is rapidly forming — one not dominated by sheer scale, but by strategic scaling.What Exactly Did IBM Release?The Granite 4.0 Nano family includes four open-source models now available on Hugging Face:Granite-4.0-H-1B (~1.5B parameters) – Hybrid-SSM architectureGranite-4.0-H-350M (~350M parameters) – Hybrid-SSM architectureGranite-4.0-1B – Transformer-based variant, parameter count closer to 2BGranite-4.0-350M – Transformer-based variantThe H-series models — Granite-4.0-H-1B and H-350M — use a hybrid state space architecture (SSM) that combines efficiency with strong performance, ideal for low-latency edge environments. Meanwhile, the standard transformer variants — Granite-4.0-1B and 350M — offer broader compatibility with tools like llama.cpp, designed for use cases where hybrid architecture isn’t yet supported. In practice, the transformer 1B model is closer to 2B parameters, but aligns performance-wise with its hybrid sibling, offering developers flexibility based on their runtime constraints.“The hybrid variant is a true 1B model. However, the non-hybrid variant is closer to 2B, but we opted to keep the naming aligned to the hybrid variant to make the connection easily visible,” explained Emma, Product Marketing lead for Granite, during a Reddit \"Ask Me Anything\" (AMA) session on r/LocalLLaMA.A Competitive Class of Small ModelsIBM is entering a crowded and rapidly evolving market of small language models (SLMs), competing with offerings like Qwen3, Google&#x27;s Gemma, LiquidAI’s LFM2, and even Mistral’s dense models in the sub-2B parameter space.While OpenAI and Anthropic focus on models that require clusters of GPUs and sophisticated inference optimization, IBM’s Nano family is aimed squarely at developers who want to run performant LLMs on local or constrained hardware.In benchmark testing, IBM’s new models consistently top the charts in their class. According to data shared on X by David Cox, VP of AI Models at IBM Research:On IFEval (instruction following), Granite-4.0-H-1B scored 78.5, outperforming Qwen3-1.7B (73.1) and other 1–2B models.On BFCLv3 (function/tool calling), Granite-4.0-1B led with a score of 54.8, the highest in its size class.On safety benchmarks (SALAD and AttaQ), the Granite models scored over 90%, surpassing similarly sized competitors.Overall, the Granite-4.0-1B achieved a leading average benchmark score of 68.3% across general knowledge, math, code, and safety domains.This performance is especially significant given the hardware constraints these models are designed for. They require less memory, run faster on CPUs or mobile devices, and don’t need cloud infrastructure or GPU acceleration to deliver usable results.Why Model Size Still Matters — But Not Like It Used ToIn the early wave of LLMs, bigger meant better — more parameters translated to better generalization, deeper reasoning, and richer output. But as transformer research matured, it became clear that architecture, training quality, and task-specific tuning could allow smaller models to punch well above their weight class.IBM is banking on this evolution. By releasing open, small models that are competitive in real-world tasks, the company is offering an alternative to the monolithic AI APIs that dominate today’s application stack.In fact, the Nano models address three increasingly important needs:Deployment flexibility — they run anywhere, from mobile to microservers.Inference privacy — users can keep data local with no need to call out to cloud APIs.Openness and auditability — source code and model weights are publicly available under an open license.Community Response and Roadmap SignalsIBM’s Granite team didn’t just launch the models and walk away — they took to Reddit’s open source community r/LocalLLaMA to engage directly with developers. In an AMA-style thread, Emma (Product Marketing, Granite) answered technical questions, addressed concerns about naming conventions, and dropped hints about what’s next.Notable confirmations from the thread:A larger Granite 4.0 model is currently in trainingReasoning-focused models (\"thinking counterparts\") are in the pipelineIBM will release fine-tuning recipes and a full training paper soonMore tooling and platform compatibility is on the roadmapUsers responded enthusiastically to the models’ capabilities, especially in instruction-following and structured response tasks. One commenter summed it up:“This is big if true for a 1B model — if quality is nice and it gives consistent outputs. Function-calling tasks, multilingual dialog, FIM completions… this could be a real workhorse.”Another user remarked:“The Granite Tiny is already my go-to for web search in LM Studio — better than some Qwen models. Tempted to give Nano a shot.”Background: IBM Granite and the Enterprise AI RaceIBM’s push into large language models began in earnest in late 2023 with the debut of the Granite foundation model family, starting with models like Granite.13b.instruct and Granite.13b.chat. Released for use within its Watsonx platform, these initial decoder-only models signaled IBM’s ambition to build enterprise-grade AI systems that prioritize transparency, efficiency, and performance. The company open-sourced select Granite code models under the Apache 2.0 license in mid-2024, laying the groundwork for broader adoption and developer experimentation.The real inflection point came with Granite 3.0 in October 2024 — a fully open-source suite of general-purpose and domain-specialized models ranging from 1B to 8B parameters. These models emphasized efficiency over brute scale, offering capabilities like longer context windows, instruction tuning, and integrated guardrails. IBM positioned Granite 3.0 as a direct competitor to Meta’s Llama, Alibaba’s Qwen, and Google&#x27;s Gemma — but with a uniquely enterprise-first lens. Later versions, including Granite 3.1 and Granite 3.2, introduced even more enterprise-friendly innovations: embedded hallucination detection, time-series forecasting, document vision models, and conditional reasoning toggles.The Granite 4.0 family, launched in October 2025, represents IBM’s most technically ambitious release yet. It introduces a hybrid architecture that blends transformer and Mamba-2 layers — aiming to combine the contextual precision of attention mechanisms with the memory efficiency of state-space models. This design allows IBM to significantly reduce memory and latency costs for inference, making Granite models viable on smaller hardware while still outperforming peers in instruction-following and function-calling tasks. The launch also includes ISO 42001 certification, cryptographic model signing, and distribution across platforms like Hugging Face, Docker, LM Studio, Ollama, and watsonx.ai.Across all iterations, IBM’s focus has been clear: build trustworthy, efficient, and legally unambiguous AI models for enterprise use cases. With a permissive Apache 2.0 license, public benchmarks, and an emphasis on governance, the Granite initiative not only responds to rising concerns over proprietary black-box models but also offers a Western-aligned open alternative to the rapid progress from teams like Alibaba’s Qwen. In doing so, Granite positions IBM as a leading voice in what may be the next phase of open-weight, production-ready AI.A Shift Toward Scalable EfficiencyIn the end, IBM’s release of Granite 4.0 Nano models reflects a strategic shift in LLM development: from chasing parameter count records to optimizing usability, openness, and deployment reach.By combining competitive performance, responsible development practices, and deep engagement with the open-source community, IBM is positioning Granite as not just a family of models — but a platform for building the next generation of lightweight, trustworthy AI systems.For developers and researchers looking for performance without overhead, the Nano release offers a compelling signal: you don’t need 70 billion parameters to build something powerful — just the right ones.",
          "feed_position": 8,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4rwJWqsHkQ8TmY86sokH5j/cf400e028ed640c8e65f6bec9134c149/cfr0z3n_Flat_illustration_neon_pink_and_oranges_on_blue_backdro_3059ee39-d179-4b1b-9d52-a4264f21e970.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/microsofts-copilot-can-now-build-apps-and-automate-your-job-heres-how-it",
          "published_at": "Tue, 28 Oct 2025 20:30:00 GMT",
          "title": "Microsoft’s Copilot can now build apps and automate your job — here’s how it works",
          "standfirst": "Microsoft is launching a significant expansion of its Copilot AI assistant on Tuesday, introducing tools that let employees build applications, automate workflows, and create specialized AI agents using only conversational prompts — no coding required.The new capabilities, called App Builder and Workflows, mark Microsoft&#x27;s most aggressive attempt yet to merge artificial intelligence with software development, enabling the estimated 100 million Microsoft 365 users to create business tools as easily as they currently draft emails or build spreadsheets.\"We really believe that a main part of an AI-forward employee, not just developers, will be to create agents, workflows and apps,\" Charles Lamanna, Microsoft&#x27;s president of business and industry Copilot, said in an interview with VentureBeat. \"Part of the job will be to build and create these things.\"The announcement comes as Microsoft deepens its commitment to AI-powered productivity tools while navigating a complex partnership with OpenAI, the creator of the underlying technology that powers Copilot. On the same day, OpenAI completed its restructuring into a for-profit entity, with Microsoft receiving a 27% ownership stake valued at approximately $135 billion.How natural language prompts now create fully functional business applicationsThe new features transform Copilot from a conversational assistant into what Microsoft envisions as a comprehensive development environment accessible to non-technical workers. Users can now describe an application they need — such as a project tracker with dashboards and task assignments — and Copilot will generate a working app complete with a database backend, user interface, and security controls.\"If you&#x27;re right inside of Copilot, you can now have a conversation to build an application complete with a backing database and a security model,\" Lamanna explained. \"You can make edit requests and update requests and change requests so you can tune the app to get exactly the experience you want before you share it with other users.\"The App Builder stores data in Microsoft Lists, the company&#x27;s lightweight database system, and allows users to share finished applications via a simple link—similar to sharing a document. The Workflows agent, meanwhile, automates routine tasks across Microsoft&#x27;s ecosystem of products, including Outlook, Teams, SharePoint, and Planner, by converting natural language descriptions into automated processes.A third component, a simplified version of Microsoft&#x27;s Copilot Studio agent-building platform, lets users create specialized AI assistants tailored to specific tasks or knowledge domains, drawing from SharePoint documents, meeting transcripts, emails, and external systems.All three capabilities are included in the existing $30-per-month Microsoft 365 Copilot subscription at no additional cost — a pricing decision Lamanna characterized as consistent with Microsoft&#x27;s historical approach of bundling significant value into its productivity suite.\"That&#x27;s what Microsoft always does. We try to do a huge amount of value at a low price,\" he said. \"If you go look at Office, you think about Excel, Word, PowerPoint, Exchange, all that for like eight bucks a month. That&#x27;s a pretty good deal.\"Why Microsoft&#x27;s nine-year bet on low-code development is finally paying offThe new tools represent the culmination of a nine-year effort by Microsoft to democratize software development through its Power Platform — a collection of low-code and no-code development tools that has grown to 56 million monthly active users, according to figures the company disclosed in recent earnings reports.Lamanna, who has led the Power Platform initiative since its inception, said the integration into Copilot marks a fundamental shift in how these capabilities reach users. Rather than requiring workers to visit a separate website or learn a specialized interface, the development tools now exist within the same conversational window they already use for AI-assisted tasks.\"One of the big things that we&#x27;re excited about is Copilot — that&#x27;s a tool for literally every office worker,\" Lamanna said. \"Every office worker, just like they research data, they analyze data, they reason over topics, they also will be creating apps, agents and workflows.\"The integration offers significant technical advantages, he argued. Because Copilot already indexes a user&#x27;s Microsoft 365 content — emails, documents, meetings, and organizational data — it can incorporate that context into the applications and workflows it builds. If a user asks for \"an app for Project Spartan,\" Copilot can draw from existing communications to understand what that project entails and suggest relevant features.\"If you go to those other tools, they have no idea what the heck Project Spartan is,\" Lamanna said, referencing competing low-code platforms from companies like Google, Salesforce, and ServiceNow. \"But if you do it inside of Copilot and inside of the App Builder, it&#x27;s able to draw from all that information and context.\"Microsoft claims the apps created through these tools are \"full-stack applications\" with proper databases secured through the same identity systems used across its enterprise products — distinguishing them from simpler front-end tools offered by competitors. The company also emphasized that its existing governance, security, and data loss prevention policies automatically apply to apps and workflows created through Copilot.Where professional developers still matter in an AI-powered workplaceWhile Microsoft positions the new capabilities as accessible to all office workers, Lamanna was careful to delineate where professional developers remain essential. His dividing line centers on whether a system interacts with parties outside the organization.\"Anything that leaves the boundaries of your company warrants developer involvement,\" he said. \"If you want to build an agent and put it on your website, you should have developers involved. Or if you want to build an automation which interfaces directly with your customers, or an app or a website which interfaces directly with your customers, you want professionals involved.\"The reasoning is risk-based: external-facing systems carry greater potential for data breaches, security vulnerabilities, or business errors. \"You don&#x27;t want people getting refunds they shouldn&#x27;t,\" Lamanna noted.For internal use cases — approval workflows, project tracking, team dashboards — Microsoft believes the new tools can handle the majority of needs without IT department involvement. But the company has built \"no cliffs,\" in Lamanna&#x27;s terminology, allowing users to migrate simple apps to more sophisticated platforms as needs grow.Apps created in the conversational App Builder can be opened in Power Apps, Microsoft&#x27;s full development environment, where they can be connected to Dataverse, the company&#x27;s enterprise database, or extended with custom code. Similarly, simple workflows can graduate to the full Power Automate platform, and basic agents can be enhanced in the complete Copilot Studio.\"We have this mantra called no cliffs,\" Lamanna said. \"If your app gets too complicated for the App Builder, you can always edit and open it in Power Apps. You can jump over to the richer experience, and if you&#x27;re really sophisticated, you can even go from those experiences into Azure.\"This architecture addresses a problem that has plagued previous generations of easy-to-use development tools: users who outgrow the simplified environment often must rebuild from scratch on professional platforms. \"People really do not like easy-to-use development tools if I have to throw everything away and start over,\" Lamanna said.What happens when every employee can build apps without IT approvalThe democratization of software development raises questions about governance, maintenance, and organizational complexity — issues Microsoft has worked to address through administrative controls.IT administrators can view all applications, workflows, and agents created within their organization through a centralized inventory in the Microsoft 365 admin center. They can reassign ownership, disable access at the group level, or \"promote\" particularly useful employee-created apps to officially supported status.\"We have a bunch of customers who have this approach where it&#x27;s like, let 1,000 apps bloom, and then the best ones, I go upgrade and make them IT-governed or central,\" Lamanna said.The system also includes provisions for when employees leave. Apps and workflows remain accessible for 60 days, during which managers can claim ownership — similar to how OneDrive files are handled when someone departs.Lamanna argued that most employee-created apps don&#x27;t warrant significant IT oversight. \"It&#x27;s just not worth inspecting an app that John, Susie, and Bob use to do their job,\" he said. \"It should concern itself with the app that ends up being used by 2,000 people, and that will pop up in that dashboard.\"Still, the proliferation of employee-created applications could create challenges. Users have expressed frustration with Microsoft&#x27;s increasing emphasis on AI features across its products, with some giving the Microsoft 365 mobile app one-star ratings after a recent update prioritized Copilot over traditional file access.The tools also arrive as enterprises grapple with \"shadow IT\" — unsanctioned software and systems that employees adopt without official approval. While Microsoft&#x27;s governance controls aim to provide visibility, the ease of creating new applications could accelerate the pace at which these systems multiply.The ambitious plan to turn 500 million workers into software buildersMicrosoft&#x27;s ambitions for the technology extend far beyond incremental productivity gains. Lamanna envisions a fundamental transformation of what it means to be an office worker — one where building software becomes as routine as creating spreadsheets.\"Just like how 20 years ago you put on your resume that you could use pivot tables in Excel, people are going to start saying that they can use App Builder and workflow agents, even if they&#x27;re just in the finance department or the sales department,\" he said.The numbers he&#x27;s targeting are staggering. With 56 million people already using Power Platform, Lamanna believes the integration into Copilot could eventually reach 500 million builders. \"Early days still, but I think it&#x27;s certainly encouraging,\" he said.The features are currently available only to customers in Microsoft&#x27;s Frontier Program — an early access initiative for Microsoft 365 Copilot subscribers. The company has not disclosed how many organizations participate in the program or when the tools will reach general availability.The announcement fits within Microsoft&#x27;s larger strategy of embedding AI capabilities throughout its product portfolio, driven by its partnership with OpenAI. Under the restructured agreement announced Tuesday, Microsoft will have access to OpenAI&#x27;s technology through 2032, including models that achieve artificial general intelligence (AGI) — though such systems do not yet exist. Microsoft has also begun integrating Copilot into its new companion apps for Windows 11, which provide quick access to contacts, files, and calendar information.The aggressive integration of AI features across Microsoft&#x27;s ecosystem has drawn mixed reactions. While enterprise customers have shown interest in productivity gains, the rapid pace of change and ubiquity of AI prompts have frustrated some users who prefer traditional workflows.For Microsoft, however, the calculation is clear: if even a fraction of its user base begins creating applications and automations, it would represent a massive expansion of the effective software development workforce — and further entrench customers in Microsoft&#x27;s ecosystem. The company is betting that the same natural language interface that made ChatGPT accessible to millions can finally unlock the decades-old promise of empowering everyday workers to build their own tools.The App Builder and Workflows agents are available starting today through the Microsoft 365 Copilot Agent Store for Frontier Program participants.Whether that future arrives depends not just on the technology&#x27;s capabilities, but on a more fundamental question: Do millions of office workers actually want to become part-time software developers? Microsoft is about to find out if the answer is yes — or if some jobs are better left to the professionals.",
          "content": "Microsoft is launching a significant expansion of its Copilot AI assistant on Tuesday, introducing tools that let employees build applications, automate workflows, and create specialized AI agents using only conversational prompts — no coding required.The new capabilities, called App Builder and Workflows, mark Microsoft&#x27;s most aggressive attempt yet to merge artificial intelligence with software development, enabling the estimated 100 million Microsoft 365 users to create business tools as easily as they currently draft emails or build spreadsheets.\"We really believe that a main part of an AI-forward employee, not just developers, will be to create agents, workflows and apps,\" Charles Lamanna, Microsoft&#x27;s president of business and industry Copilot, said in an interview with VentureBeat. \"Part of the job will be to build and create these things.\"The announcement comes as Microsoft deepens its commitment to AI-powered productivity tools while navigating a complex partnership with OpenAI, the creator of the underlying technology that powers Copilot. On the same day, OpenAI completed its restructuring into a for-profit entity, with Microsoft receiving a 27% ownership stake valued at approximately $135 billion.How natural language prompts now create fully functional business applicationsThe new features transform Copilot from a conversational assistant into what Microsoft envisions as a comprehensive development environment accessible to non-technical workers. Users can now describe an application they need — such as a project tracker with dashboards and task assignments — and Copilot will generate a working app complete with a database backend, user interface, and security controls.\"If you&#x27;re right inside of Copilot, you can now have a conversation to build an application complete with a backing database and a security model,\" Lamanna explained. \"You can make edit requests and update requests and change requests so you can tune the app to get exactly the experience you want before you share it with other users.\"The App Builder stores data in Microsoft Lists, the company&#x27;s lightweight database system, and allows users to share finished applications via a simple link—similar to sharing a document. The Workflows agent, meanwhile, automates routine tasks across Microsoft&#x27;s ecosystem of products, including Outlook, Teams, SharePoint, and Planner, by converting natural language descriptions into automated processes.A third component, a simplified version of Microsoft&#x27;s Copilot Studio agent-building platform, lets users create specialized AI assistants tailored to specific tasks or knowledge domains, drawing from SharePoint documents, meeting transcripts, emails, and external systems.All three capabilities are included in the existing $30-per-month Microsoft 365 Copilot subscription at no additional cost — a pricing decision Lamanna characterized as consistent with Microsoft&#x27;s historical approach of bundling significant value into its productivity suite.\"That&#x27;s what Microsoft always does. We try to do a huge amount of value at a low price,\" he said. \"If you go look at Office, you think about Excel, Word, PowerPoint, Exchange, all that for like eight bucks a month. That&#x27;s a pretty good deal.\"Why Microsoft&#x27;s nine-year bet on low-code development is finally paying offThe new tools represent the culmination of a nine-year effort by Microsoft to democratize software development through its Power Platform — a collection of low-code and no-code development tools that has grown to 56 million monthly active users, according to figures the company disclosed in recent earnings reports.Lamanna, who has led the Power Platform initiative since its inception, said the integration into Copilot marks a fundamental shift in how these capabilities reach users. Rather than requiring workers to visit a separate website or learn a specialized interface, the development tools now exist within the same conversational window they already use for AI-assisted tasks.\"One of the big things that we&#x27;re excited about is Copilot — that&#x27;s a tool for literally every office worker,\" Lamanna said. \"Every office worker, just like they research data, they analyze data, they reason over topics, they also will be creating apps, agents and workflows.\"The integration offers significant technical advantages, he argued. Because Copilot already indexes a user&#x27;s Microsoft 365 content — emails, documents, meetings, and organizational data — it can incorporate that context into the applications and workflows it builds. If a user asks for \"an app for Project Spartan,\" Copilot can draw from existing communications to understand what that project entails and suggest relevant features.\"If you go to those other tools, they have no idea what the heck Project Spartan is,\" Lamanna said, referencing competing low-code platforms from companies like Google, Salesforce, and ServiceNow. \"But if you do it inside of Copilot and inside of the App Builder, it&#x27;s able to draw from all that information and context.\"Microsoft claims the apps created through these tools are \"full-stack applications\" with proper databases secured through the same identity systems used across its enterprise products — distinguishing them from simpler front-end tools offered by competitors. The company also emphasized that its existing governance, security, and data loss prevention policies automatically apply to apps and workflows created through Copilot.Where professional developers still matter in an AI-powered workplaceWhile Microsoft positions the new capabilities as accessible to all office workers, Lamanna was careful to delineate where professional developers remain essential. His dividing line centers on whether a system interacts with parties outside the organization.\"Anything that leaves the boundaries of your company warrants developer involvement,\" he said. \"If you want to build an agent and put it on your website, you should have developers involved. Or if you want to build an automation which interfaces directly with your customers, or an app or a website which interfaces directly with your customers, you want professionals involved.\"The reasoning is risk-based: external-facing systems carry greater potential for data breaches, security vulnerabilities, or business errors. \"You don&#x27;t want people getting refunds they shouldn&#x27;t,\" Lamanna noted.For internal use cases — approval workflows, project tracking, team dashboards — Microsoft believes the new tools can handle the majority of needs without IT department involvement. But the company has built \"no cliffs,\" in Lamanna&#x27;s terminology, allowing users to migrate simple apps to more sophisticated platforms as needs grow.Apps created in the conversational App Builder can be opened in Power Apps, Microsoft&#x27;s full development environment, where they can be connected to Dataverse, the company&#x27;s enterprise database, or extended with custom code. Similarly, simple workflows can graduate to the full Power Automate platform, and basic agents can be enhanced in the complete Copilot Studio.\"We have this mantra called no cliffs,\" Lamanna said. \"If your app gets too complicated for the App Builder, you can always edit and open it in Power Apps. You can jump over to the richer experience, and if you&#x27;re really sophisticated, you can even go from those experiences into Azure.\"This architecture addresses a problem that has plagued previous generations of easy-to-use development tools: users who outgrow the simplified environment often must rebuild from scratch on professional platforms. \"People really do not like easy-to-use development tools if I have to throw everything away and start over,\" Lamanna said.What happens when every employee can build apps without IT approvalThe democratization of software development raises questions about governance, maintenance, and organizational complexity — issues Microsoft has worked to address through administrative controls.IT administrators can view all applications, workflows, and agents created within their organization through a centralized inventory in the Microsoft 365 admin center. They can reassign ownership, disable access at the group level, or \"promote\" particularly useful employee-created apps to officially supported status.\"We have a bunch of customers who have this approach where it&#x27;s like, let 1,000 apps bloom, and then the best ones, I go upgrade and make them IT-governed or central,\" Lamanna said.The system also includes provisions for when employees leave. Apps and workflows remain accessible for 60 days, during which managers can claim ownership — similar to how OneDrive files are handled when someone departs.Lamanna argued that most employee-created apps don&#x27;t warrant significant IT oversight. \"It&#x27;s just not worth inspecting an app that John, Susie, and Bob use to do their job,\" he said. \"It should concern itself with the app that ends up being used by 2,000 people, and that will pop up in that dashboard.\"Still, the proliferation of employee-created applications could create challenges. Users have expressed frustration with Microsoft&#x27;s increasing emphasis on AI features across its products, with some giving the Microsoft 365 mobile app one-star ratings after a recent update prioritized Copilot over traditional file access.The tools also arrive as enterprises grapple with \"shadow IT\" — unsanctioned software and systems that employees adopt without official approval. While Microsoft&#x27;s governance controls aim to provide visibility, the ease of creating new applications could accelerate the pace at which these systems multiply.The ambitious plan to turn 500 million workers into software buildersMicrosoft&#x27;s ambitions for the technology extend far beyond incremental productivity gains. Lamanna envisions a fundamental transformation of what it means to be an office worker — one where building software becomes as routine as creating spreadsheets.\"Just like how 20 years ago you put on your resume that you could use pivot tables in Excel, people are going to start saying that they can use App Builder and workflow agents, even if they&#x27;re just in the finance department or the sales department,\" he said.The numbers he&#x27;s targeting are staggering. With 56 million people already using Power Platform, Lamanna believes the integration into Copilot could eventually reach 500 million builders. \"Early days still, but I think it&#x27;s certainly encouraging,\" he said.The features are currently available only to customers in Microsoft&#x27;s Frontier Program — an early access initiative for Microsoft 365 Copilot subscribers. The company has not disclosed how many organizations participate in the program or when the tools will reach general availability.The announcement fits within Microsoft&#x27;s larger strategy of embedding AI capabilities throughout its product portfolio, driven by its partnership with OpenAI. Under the restructured agreement announced Tuesday, Microsoft will have access to OpenAI&#x27;s technology through 2032, including models that achieve artificial general intelligence (AGI) — though such systems do not yet exist. Microsoft has also begun integrating Copilot into its new companion apps for Windows 11, which provide quick access to contacts, files, and calendar information.The aggressive integration of AI features across Microsoft&#x27;s ecosystem has drawn mixed reactions. While enterprise customers have shown interest in productivity gains, the rapid pace of change and ubiquity of AI prompts have frustrated some users who prefer traditional workflows.For Microsoft, however, the calculation is clear: if even a fraction of its user base begins creating applications and automations, it would represent a massive expansion of the effective software development workforce — and further entrench customers in Microsoft&#x27;s ecosystem. The company is betting that the same natural language interface that made ChatGPT accessible to millions can finally unlock the decades-old promise of empowering everyday workers to build their own tools.The App Builder and Workflows agents are available starting today through the Microsoft 365 Copilot Agent Store for Frontier Program participants.Whether that future arrives depends not just on the technology&#x27;s capabilities, but on a more fundamental question: Do millions of office workers actually want to become part-time software developers? Microsoft is about to find out if the answer is yes — or if some jobs are better left to the professionals.",
          "feed_position": 9,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/33TsQdgl9KxQ34lyEgCUfW/9faff55fd9a871ab3cd21f735ed87cba/nuneybits_Vector_art_of_Microsoft_Windows_desktop_computer_mode_5869d092-9156-48dc-bf50-37d2ff6b0cf3.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/fortanix-and-nvidia-partner-on-ai-security-platform-for-highly-regulated",
          "published_at": "Tue, 28 Oct 2025 18:57:00 GMT",
          "title": "Fortanix and NVIDIA partner on AI security platform for highly regulated industries",
          "standfirst": "Data security company Fortanix Inc. announced a new joint solution with NVIDIA: a turnkey platform that allows organizations to deploy agentic AI within their own data centers or sovereign environments, backed by NVIDIA’s \"confidential computing\" GPUs.“Our goal is to make AI trustworthy by securing every layer—from the chip to the model to the data,\" said Fortanix CEO and co-founder Anand Kashyap, in a recent video call interview with VentureBeat. \"Confidential computing gives you that end-to-end trust so you can confidently use AI with sensitive or regulated information.”The solution arrives at a pivotal moment for industries such as healthcare, finance, and government — sectors eager to embrace AI but constrained by strict privacy and regulatory requirements.Fortanix’s new platform, powered by NVIDIA Confidential Computing, enables enterprises to build and run AI systems on sensitive data without sacrificing security or control.“Enterprises in finance, healthcare and government want to harness the power of AI, but compromising on trust, compliance, or control creates insurmountable risk,” said Anuj Jaiswal, chief product officer at Fortanix, in a press release. “We’re giving enterprises a sovereign, on-prem platform for AI agents—one that proves what’s running, protects what matters, and gets them to production faster.”Secure AI, Verified from Chip to ModelAt the heart of the Fortanix–NVIDIA collaboration is a confidential AI pipeline that ensures data, models, and workflows remain protected throughout their lifecycle. The system uses a combination of Fortanix Data Security Manager (DSM) and Fortanix Confidential Computing Manager (CCM), integrated directly into NVIDIA’s GPU architecture.“You can think of DSM as the vault that holds your keys, and CCM as the gatekeeper that verifies who’s allowed to use them,\" Kashyap said. \"DSM enforces policy, CCM enforces trust.”DSM serves as a FIPS 140-2 Level 3 hardware security module that manages encryption keys and enforces strict access controls. CCM, introduced alongside this announcement, verifies the trustworthiness of AI workloads and infrastructure using composite attestation—a process that validates both CPUs and GPUs before allowing access to sensitive data.Only when a workload is verified by CCM does DSM release the cryptographic keys necessary to decrypt and process data. “The Confidential Computing Manager checks that the workload, the CPU, and the GPU are running in a trusted state,\" explained Kashyap. \"It issues a certificate that DSM validates before releasing the key. That ensures the right workload is running on the right hardware before any sensitive data is decrypted.”This “attestation-gated” model creates what Fortanix describes as a provable chain of trust extending from the hardware chip to the application layer. It’s an approach aimed squarely at industries where confidentiality and compliance are non-negotiable.From Pilot to Production—Without the Security Trade-OffAccording to Kashyap, the partnership marks a step forward from traditional data encryption and key management toward securing entire AI workloads. Kashyap explained that enterprises can deploy the Fortanix–NVIDIA solution incrementally, using a lift-and-shift model to migrate existing AI workloads into a confidential environment. “We offer two form factors: SaaS with zero footprint, and self-managed. Self-managed can be a virtual appliance or a 1U physical FIPS 140-2 Level 3 appliance,\" he noted. \"The smallest deployment is a three-node cluster, with larger clusters of 20–30 nodes or more.” Customers already running AI models—whether open-source or proprietary—can move them onto NVIDIA’s Hopper or Blackwell GPU architectures with minimal reconfiguration. For organizations building out new AI infrastructure, Fortanix’s Armet AI platform provides orchestration, observability, and built-in guardrails to speed up time to production. “The result is that enterprises can move from pilot projects to trusted, production-ready AI in days rather than months,” Jaiswal said.Compliance by DesignCompliance remains a key driver behind the new platform’s design. Fortanix’s DSM enforces role-based access control, detailed audit logging, and secure key custody—elements that help enterprises demonstrate compliance with stringent data protection regulations. These controls are essential for regulated industries such as banking, healthcare, and government contracting.The company emphasizes that the solution is built for both confidentiality and sovereignty. For governments and enterprises that must retain local control over their AI environments, the system supports fully on-premises or air-gapped deployment options. Fortanix and NVIDIA have jointly integrated these technologies into the NVIDIA AI Factory Reference Design for Government, a blueprint for building secure national or enterprise-level AI systems.Future-Proofed for a Post-Quantum EraIn addition to current encryption standards such as AES, Fortanix supports post-quantum cryptography (PQC) within its DSM product. As global research in quantum computing accelerates, PQC algorithms are expected to become a critical component of secure computing frameworks. “We don’t invent cryptography; we implement what’s proven,” Kashyap said. “But we also make sure our customers are ready for the post-quantum era when it arrives.”Real-World FlexibilityWhile the platform is designed for on-premises and sovereign use cases, Kashyap emphasized that it can also run in major cloud environments that already support confidential computing. Enterprises operating across multiple regions can maintain consistent key management and encryption controls, either through centralized key hosting or replicated key clusters. This flexibility allows organizations to shift AI workloads between data centers or cloud regions—whether for performance optimization, redundancy, or regulatory reasons—without losing control over their sensitive information.Fortanix converts usage into “credits,” which correspond to the number of AI instances running within a factory environment. The structure allows enterprises to scale incrementally as their AI projects grow.Fortanix will showcase the joint platform at NVIDIA GTC, held October 27–29, 2025, at the Walter E. Washington Convention Center in Washington, D.C. Visitors can find Fortanix at booth I-7 for live demonstrations and discussions on securing AI workloads in highly regulated environments.About FortanixFortanix Inc. was founded in 2016 in Mountain View, California, by Anand Kashyap and Ambuj Kumar, both former Intel engineers who worked on trusted execution and encryption technologies. The company was created to commercialize confidential computing—then an emerging concept—by extending the security of encrypted data beyond storage and transmission to data in active use, according to TechCrunch and the company’s own About page.Kashyap, who previously served as a senior security architect at Intel and VMware, and Kumar, a former engineering lead at Intel, drew on years of work in trusted hardware and virtualization systems. Their shared insight into the gap between research-grade cryptography and enterprise adoption drove them to found Fortanix, according to Forbes and Crunchbase.Today, Fortanix is recognized as a global leader in confidential computing and data security, offering solutions that protect data across its lifecycle—at rest, in transit, and in use. Fortanix serves enterprises and governments worldwide with deployments ranging from cloud-native services to high-security, air-gapped systems.\"Historically we provided encryption and key-management capabilities,\" Kashyap said. \"Now we’re going further to secure the workload itself—specifically AI—so an entire AI pipeline can run protected with confidential computing. That applies whether the AI runs in the cloud or in a sovereign environment handling sensitive or regulated data.",
          "content": "Data security company Fortanix Inc. announced a new joint solution with NVIDIA: a turnkey platform that allows organizations to deploy agentic AI within their own data centers or sovereign environments, backed by NVIDIA’s \"confidential computing\" GPUs.“Our goal is to make AI trustworthy by securing every layer—from the chip to the model to the data,\" said Fortanix CEO and co-founder Anand Kashyap, in a recent video call interview with VentureBeat. \"Confidential computing gives you that end-to-end trust so you can confidently use AI with sensitive or regulated information.”The solution arrives at a pivotal moment for industries such as healthcare, finance, and government — sectors eager to embrace AI but constrained by strict privacy and regulatory requirements.Fortanix’s new platform, powered by NVIDIA Confidential Computing, enables enterprises to build and run AI systems on sensitive data without sacrificing security or control.“Enterprises in finance, healthcare and government want to harness the power of AI, but compromising on trust, compliance, or control creates insurmountable risk,” said Anuj Jaiswal, chief product officer at Fortanix, in a press release. “We’re giving enterprises a sovereign, on-prem platform for AI agents—one that proves what’s running, protects what matters, and gets them to production faster.”Secure AI, Verified from Chip to ModelAt the heart of the Fortanix–NVIDIA collaboration is a confidential AI pipeline that ensures data, models, and workflows remain protected throughout their lifecycle. The system uses a combination of Fortanix Data Security Manager (DSM) and Fortanix Confidential Computing Manager (CCM), integrated directly into NVIDIA’s GPU architecture.“You can think of DSM as the vault that holds your keys, and CCM as the gatekeeper that verifies who’s allowed to use them,\" Kashyap said. \"DSM enforces policy, CCM enforces trust.”DSM serves as a FIPS 140-2 Level 3 hardware security module that manages encryption keys and enforces strict access controls. CCM, introduced alongside this announcement, verifies the trustworthiness of AI workloads and infrastructure using composite attestation—a process that validates both CPUs and GPUs before allowing access to sensitive data.Only when a workload is verified by CCM does DSM release the cryptographic keys necessary to decrypt and process data. “The Confidential Computing Manager checks that the workload, the CPU, and the GPU are running in a trusted state,\" explained Kashyap. \"It issues a certificate that DSM validates before releasing the key. That ensures the right workload is running on the right hardware before any sensitive data is decrypted.”This “attestation-gated” model creates what Fortanix describes as a provable chain of trust extending from the hardware chip to the application layer. It’s an approach aimed squarely at industries where confidentiality and compliance are non-negotiable.From Pilot to Production—Without the Security Trade-OffAccording to Kashyap, the partnership marks a step forward from traditional data encryption and key management toward securing entire AI workloads. Kashyap explained that enterprises can deploy the Fortanix–NVIDIA solution incrementally, using a lift-and-shift model to migrate existing AI workloads into a confidential environment. “We offer two form factors: SaaS with zero footprint, and self-managed. Self-managed can be a virtual appliance or a 1U physical FIPS 140-2 Level 3 appliance,\" he noted. \"The smallest deployment is a three-node cluster, with larger clusters of 20–30 nodes or more.” Customers already running AI models—whether open-source or proprietary—can move them onto NVIDIA’s Hopper or Blackwell GPU architectures with minimal reconfiguration. For organizations building out new AI infrastructure, Fortanix’s Armet AI platform provides orchestration, observability, and built-in guardrails to speed up time to production. “The result is that enterprises can move from pilot projects to trusted, production-ready AI in days rather than months,” Jaiswal said.Compliance by DesignCompliance remains a key driver behind the new platform’s design. Fortanix’s DSM enforces role-based access control, detailed audit logging, and secure key custody—elements that help enterprises demonstrate compliance with stringent data protection regulations. These controls are essential for regulated industries such as banking, healthcare, and government contracting.The company emphasizes that the solution is built for both confidentiality and sovereignty. For governments and enterprises that must retain local control over their AI environments, the system supports fully on-premises or air-gapped deployment options. Fortanix and NVIDIA have jointly integrated these technologies into the NVIDIA AI Factory Reference Design for Government, a blueprint for building secure national or enterprise-level AI systems.Future-Proofed for a Post-Quantum EraIn addition to current encryption standards such as AES, Fortanix supports post-quantum cryptography (PQC) within its DSM product. As global research in quantum computing accelerates, PQC algorithms are expected to become a critical component of secure computing frameworks. “We don’t invent cryptography; we implement what’s proven,” Kashyap said. “But we also make sure our customers are ready for the post-quantum era when it arrives.”Real-World FlexibilityWhile the platform is designed for on-premises and sovereign use cases, Kashyap emphasized that it can also run in major cloud environments that already support confidential computing. Enterprises operating across multiple regions can maintain consistent key management and encryption controls, either through centralized key hosting or replicated key clusters. This flexibility allows organizations to shift AI workloads between data centers or cloud regions—whether for performance optimization, redundancy, or regulatory reasons—without losing control over their sensitive information.Fortanix converts usage into “credits,” which correspond to the number of AI instances running within a factory environment. The structure allows enterprises to scale incrementally as their AI projects grow.Fortanix will showcase the joint platform at NVIDIA GTC, held October 27–29, 2025, at the Walter E. Washington Convention Center in Washington, D.C. Visitors can find Fortanix at booth I-7 for live demonstrations and discussions on securing AI workloads in highly regulated environments.About FortanixFortanix Inc. was founded in 2016 in Mountain View, California, by Anand Kashyap and Ambuj Kumar, both former Intel engineers who worked on trusted execution and encryption technologies. The company was created to commercialize confidential computing—then an emerging concept—by extending the security of encrypted data beyond storage and transmission to data in active use, according to TechCrunch and the company’s own About page.Kashyap, who previously served as a senior security architect at Intel and VMware, and Kumar, a former engineering lead at Intel, drew on years of work in trusted hardware and virtualization systems. Their shared insight into the gap between research-grade cryptography and enterprise adoption drove them to found Fortanix, according to Forbes and Crunchbase.Today, Fortanix is recognized as a global leader in confidential computing and data security, offering solutions that protect data across its lifecycle—at rest, in transit, and in use. Fortanix serves enterprises and governments worldwide with deployments ranging from cloud-native services to high-security, air-gapped systems.\"Historically we provided encryption and key-management capabilities,\" Kashyap said. \"Now we’re going further to secure the workload itself—specifically AI—so an entire AI pipeline can run protected with confidential computing. That applies whether the AI runs in the cloud or in a sovereign environment handling sensitive or regulated data.",
          "feed_position": 10,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5RwQsTWQJtGQzJXeCx49eu/b3b8a5c44561cbc75359f26bbfa75bf0/cfr0z3n_close_up_on_nvidia_hopper_gpu_with_glowing_lock_icons_o_ea53bf0c-165f-46d9-920c-846fd894417d.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/githubs-agent-hq-aims-to-solve-enterprises-biggest-ai-coding-problem-too",
          "published_at": "Tue, 28 Oct 2025 16:10:00 GMT",
          "title": "GitHub's Agent HQ aims to solve enterprises' biggest AI coding problem: Too many agents, no central control",
          "standfirst": "GitHub is making a bold bet that enterprises don&#x27;t need another proprietary coding agent: They need a way to manage all of them.At its Universe 2025 conference, the Microsoft-owned developer platform announced Agent HQ. The new architecture transforms GitHub into a unified control plane for managing multiple AI coding agents from competitors including Anthropic, OpenAI, Google, Cognition and xAI. Rather than forcing developers into a single agent experience, the company is positioning itself as the essential orchestration layer beneath them all.Agent HQ represents GitHub&#x27;s attempt to apply its collaboration platform approach to AI agents. Just as the company transformed Git, pull requests and CI/CD into collaborative workflows, it&#x27;s now trying to do the same with a fragmented AI coding landscape.The announcement marks what GitHub calls the transition from \"wave one\" to \"wave two\" of AI-assisted development. According to GitHub&#x27;s Octoverse report, 80% of new developers use Copilot in their first week and AI has helped to lead to a large increase overall in the use of the GitHub platform.\"Last year, the big announcements for us, and what we were saying as a company, is wave one is done, that was kind of code completion,\" GitHub&#x27;s COO Mario Rodriguez told VentureBeat. \"We&#x27;re into this wave two era, [which] is going to be multimodal, it&#x27;s going to be agentic and it&#x27;s going to have these new experiences that will feel AI native.\"What is Agent HQ?GitHub already updated its GitHub Copilot coding tool for the agentic era with the debut of GitHub Copilot Agent in May.Agent HQ transforms GitHub into an open ecosystem that unites multiple AI coding agents on a single platform. Over the coming months, coding agents from Anthropic, OpenAI, Google, Cognition, xAI and others will become available directly within GitHub as part of existing paid GitHub Copilot subscriptions.The architecture maintains GitHub&#x27;s core primitives. Developers still work with Git, pull requests and issues. They still use their preferred compute, whether GitHub Actions or self-hosted runners. What changes is the layer above: agents from multiple vendors can now operate within GitHub&#x27;s security perimeter, using the same identity controls, branch permissions and audit logging that enterprises already trust for human developers.This approach differs fundamentally from standalone tools. When developers use Cursor or grant repository access to Claude, those agents typically receive broad permissions across entire repositories. Agent HQ compartmentalizes access at the branch level and wraps all agent activity in enterprise-grade governance controls.Mission Control: One interface for all agentsAt the heart of Agent HQ is Mission Control. It&#x27;s a unified command center that appears consistently across GitHub&#x27;s web interface, VS Code, mobile apps and the command line. Through Mission Control, developers can assign work to multiple agents simultaneously. They can track progress and manage permissions, all from a single pane of glass.The technical architecture addresses a critical enterprise concern: Security. Unlike standalone agent implementations where users must grant broad repository access, GitHub&#x27;s Agent HQ implements granular controls at the platform level.\"Our coding agent has a set of security controls and capabilities that are built natively into the platform, and that&#x27;s what we&#x27;re providing to all of these other agents as well,\" Rodriguez explained. \"It runs with a GitHub token that is very locked down to what it can actually do.\"Agents operating through Agent HQ can only commit to designated branches. They run within sandboxed GitHub Actions environments with firewall protections. They operate under strict identity controls. Rodriguez explained that even if an agent goes rogue, the firewall prevents it from accessing external networks or exfiltrating data unless those protections are explicitly disabled.Technical differentiation: MCP integration and custom agentsBeyond managing third-party agents, GitHub is introducing two technical capabilities that set Agent HQ apart from alternative approaches like Cursor&#x27;s standalone editor or Anthropic&#x27;s Claude integration.Custom agents via AGENTS.md files: Enterprises can now create source-controlled configuration files that define specific rules, tools and guardrails for how Copilot behaves. For example, a company could specify \"prefer this logger\" or \"use table-driven tests for all handlers.\" This permanently encodes organizational standards without requiring developers to re-prompt every time.\"Custom agents have an immense amount of product market fit within enterprises, because they could just codify a set of skills that the coordination can do, then standardize on those and get really high quality output,\" Rodriguez said.The AGENTS.md specification allows teams to version control their agent behavior alongside their code. When a developer clones a repository, they automatically inherit the custom agent rules. This solves a persistent problem with AI coding tools: Inconsistent output quality when different team members use different prompting strategies.Native Model Context Protocol (MCP) support: VS Code now includes a GitHub MCP Registry. Developers can discover, install and enable MCP servers with a single click. They can then create custom agents that combine these tools with specific system prompts.This positions GitHub as the integration point between the emerging MCP ecosystem and actual developer workflows. MCP, introduced by Anthropic but rapidly gaining industry support, is becoming a de facto standard for agent-to-tool communication. By supporting the full specification, GitHub can orchestrate agents that need access to external services without each agent implementing its own integration logic.Plan Mode and agentic code reviewGitHub is also shipping new capabilities within VS Code itself. Plan Mode allows developers to collaborate with Copilot on building step-by-step project approaches. The AI asks clarifying questions before any code is written. Once approved, the plan can be executed either locally in VS Code or by cloud-based agents.The feature addresses a common failure mode in AI coding: Beginning implementation before requirements are fully understood. By forcing an explicit planning phase, GitHub aims to reduce wasted effort and improve output quality.More significantly, GitHub&#x27;s code review feature is becoming agentic. The new implementation will use GitHub&#x27;s CodeQL engine, which previously largely focused on security vulnerabilities to identify bugs and maintainability issues. The code review agent will automatically scan agent-generated pull requests before human review. This creates a two-stage quality gate.\"Our code review agent will be able to make calls into the CodeQL engine to then find a set of bugs,\" Rodriguez explained. \"We&#x27;re extending the engine and we&#x27;re going to be able to tap into that engine also to find bugs.\"Enterprise considerations: What to do nowFor enterprises already deploying multiple AI coding tools, Agent HQ offers a path to consolidation without forcing tool elimination.GitHub&#x27;s multi-agent approach provides vendor flexibility and reduces lock-in risk. Organizations can test multiple agents within a unified security perimeter and switch providers without retraining developers. The tradeoff is potentially less optimized experiences compared to specialized tools that tightly integrate UI and agent behavior.Rodriguez&#x27;s recommendation is clear: Begin with custom agents. This allows enterprises to codify organizational standards that agents follow consistently. Once established, organizations can layer in additional third-party agents to expand capabilities.\"Go and do agent coding, custom agents and start playing with that,\" he said. \"That is a capability available tomorrow, and it allows you to really start shaping your SDLC to be personalized to you, your organization and your people.\"",
          "content": "GitHub is making a bold bet that enterprises don&#x27;t need another proprietary coding agent: They need a way to manage all of them.At its Universe 2025 conference, the Microsoft-owned developer platform announced Agent HQ. The new architecture transforms GitHub into a unified control plane for managing multiple AI coding agents from competitors including Anthropic, OpenAI, Google, Cognition and xAI. Rather than forcing developers into a single agent experience, the company is positioning itself as the essential orchestration layer beneath them all.Agent HQ represents GitHub&#x27;s attempt to apply its collaboration platform approach to AI agents. Just as the company transformed Git, pull requests and CI/CD into collaborative workflows, it&#x27;s now trying to do the same with a fragmented AI coding landscape.The announcement marks what GitHub calls the transition from \"wave one\" to \"wave two\" of AI-assisted development. According to GitHub&#x27;s Octoverse report, 80% of new developers use Copilot in their first week and AI has helped to lead to a large increase overall in the use of the GitHub platform.\"Last year, the big announcements for us, and what we were saying as a company, is wave one is done, that was kind of code completion,\" GitHub&#x27;s COO Mario Rodriguez told VentureBeat. \"We&#x27;re into this wave two era, [which] is going to be multimodal, it&#x27;s going to be agentic and it&#x27;s going to have these new experiences that will feel AI native.\"What is Agent HQ?GitHub already updated its GitHub Copilot coding tool for the agentic era with the debut of GitHub Copilot Agent in May.Agent HQ transforms GitHub into an open ecosystem that unites multiple AI coding agents on a single platform. Over the coming months, coding agents from Anthropic, OpenAI, Google, Cognition, xAI and others will become available directly within GitHub as part of existing paid GitHub Copilot subscriptions.The architecture maintains GitHub&#x27;s core primitives. Developers still work with Git, pull requests and issues. They still use their preferred compute, whether GitHub Actions or self-hosted runners. What changes is the layer above: agents from multiple vendors can now operate within GitHub&#x27;s security perimeter, using the same identity controls, branch permissions and audit logging that enterprises already trust for human developers.This approach differs fundamentally from standalone tools. When developers use Cursor or grant repository access to Claude, those agents typically receive broad permissions across entire repositories. Agent HQ compartmentalizes access at the branch level and wraps all agent activity in enterprise-grade governance controls.Mission Control: One interface for all agentsAt the heart of Agent HQ is Mission Control. It&#x27;s a unified command center that appears consistently across GitHub&#x27;s web interface, VS Code, mobile apps and the command line. Through Mission Control, developers can assign work to multiple agents simultaneously. They can track progress and manage permissions, all from a single pane of glass.The technical architecture addresses a critical enterprise concern: Security. Unlike standalone agent implementations where users must grant broad repository access, GitHub&#x27;s Agent HQ implements granular controls at the platform level.\"Our coding agent has a set of security controls and capabilities that are built natively into the platform, and that&#x27;s what we&#x27;re providing to all of these other agents as well,\" Rodriguez explained. \"It runs with a GitHub token that is very locked down to what it can actually do.\"Agents operating through Agent HQ can only commit to designated branches. They run within sandboxed GitHub Actions environments with firewall protections. They operate under strict identity controls. Rodriguez explained that even if an agent goes rogue, the firewall prevents it from accessing external networks or exfiltrating data unless those protections are explicitly disabled.Technical differentiation: MCP integration and custom agentsBeyond managing third-party agents, GitHub is introducing two technical capabilities that set Agent HQ apart from alternative approaches like Cursor&#x27;s standalone editor or Anthropic&#x27;s Claude integration.Custom agents via AGENTS.md files: Enterprises can now create source-controlled configuration files that define specific rules, tools and guardrails for how Copilot behaves. For example, a company could specify \"prefer this logger\" or \"use table-driven tests for all handlers.\" This permanently encodes organizational standards without requiring developers to re-prompt every time.\"Custom agents have an immense amount of product market fit within enterprises, because they could just codify a set of skills that the coordination can do, then standardize on those and get really high quality output,\" Rodriguez said.The AGENTS.md specification allows teams to version control their agent behavior alongside their code. When a developer clones a repository, they automatically inherit the custom agent rules. This solves a persistent problem with AI coding tools: Inconsistent output quality when different team members use different prompting strategies.Native Model Context Protocol (MCP) support: VS Code now includes a GitHub MCP Registry. Developers can discover, install and enable MCP servers with a single click. They can then create custom agents that combine these tools with specific system prompts.This positions GitHub as the integration point between the emerging MCP ecosystem and actual developer workflows. MCP, introduced by Anthropic but rapidly gaining industry support, is becoming a de facto standard for agent-to-tool communication. By supporting the full specification, GitHub can orchestrate agents that need access to external services without each agent implementing its own integration logic.Plan Mode and agentic code reviewGitHub is also shipping new capabilities within VS Code itself. Plan Mode allows developers to collaborate with Copilot on building step-by-step project approaches. The AI asks clarifying questions before any code is written. Once approved, the plan can be executed either locally in VS Code or by cloud-based agents.The feature addresses a common failure mode in AI coding: Beginning implementation before requirements are fully understood. By forcing an explicit planning phase, GitHub aims to reduce wasted effort and improve output quality.More significantly, GitHub&#x27;s code review feature is becoming agentic. The new implementation will use GitHub&#x27;s CodeQL engine, which previously largely focused on security vulnerabilities to identify bugs and maintainability issues. The code review agent will automatically scan agent-generated pull requests before human review. This creates a two-stage quality gate.\"Our code review agent will be able to make calls into the CodeQL engine to then find a set of bugs,\" Rodriguez explained. \"We&#x27;re extending the engine and we&#x27;re going to be able to tap into that engine also to find bugs.\"Enterprise considerations: What to do nowFor enterprises already deploying multiple AI coding tools, Agent HQ offers a path to consolidation without forcing tool elimination.GitHub&#x27;s multi-agent approach provides vendor flexibility and reduces lock-in risk. Organizations can test multiple agents within a unified security perimeter and switch providers without retraining developers. The tradeoff is potentially less optimized experiences compared to specialized tools that tightly integrate UI and agent behavior.Rodriguez&#x27;s recommendation is clear: Begin with custom agents. This allows enterprises to codify organizational standards that agents follow consistently. Once established, organizations can layer in additional third-party agents to expand capabilities.\"Go and do agent coding, custom agents and start playing with that,\" he said. \"That is a capability available tomorrow, and it allows you to really start shaping your SDLC to be personalized to you, your organization and your people.\"",
          "feed_position": 11,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4O4T83wUSzVSPKnuWWf4dZ/bea55829b728586b10a802f9f281a1ec/github-agentht-smk.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/oppos-find-x9-pro-hands-on-detachable-telephoto-lens-7000mah-battery-160006373.html",
          "published_at": "Tue, 28 Oct 2025 16:00:23 +0000",
          "title": "Oppo’s Find X9 Pro has a detachable telephoto lens and a gigantic battery",
          "standfirst": "Oppo’s latest flagship phone, like the sleek (but hard to buy) Find N5 foldable, goes hard on the tech specifications. In fact, the Find X9 Pro’s specs read like a wishlist of what many want to see in their phones, with a huge 7,500mAh battery, a 200-megapixel telephoto camera and a bright 6.78-inch screen with tiny, almost one-millimeter bezels, all while still measuring in at 8.25mm in thickness. Oh, and an optional telephoto lens add-on that boosts camera zoom to 10x. The Find X9 Pro will be priced at £1,099 (roughly $1,459). The biggest drawback may be that, despite the Find X9 series being Oppo’s biggest phone launch yet, it won’t be available in the US. Still, with everything that’s crammed into this phone, I had to try it out. Do I really want a thinner smartphone? Or one that lasts multiple days before it needs recharging? And man, this telephoto lens is certainly eye-catching. Display and design Image by Mat Smith for Engadget The Find X9 Pro has a 6.78-inch display, with peak outdoor brightness at 3,600 nits. On paper, that beats the iPhone 17 Pro, but most people with phones older than a year or two will notice how much brighter phones like the X9 Pro are. Another notable feature is a 1-nit minimal brightness to reduce eye strain when using the phone in the dark. Or in bed. Which we shouldn’t do, but we all do. Oppo has also included high-frequency pixel dimming to further reduce the screen's harshness. Like recent phones from its business cousin, OnePlus, Oppo has added a new button on this year’s Find X model. The Snap key is on the left of the device, and can be customized to launch apps like the voice recorder, translation apps and flashlight. Meanwhile, the right edge houses the Find X9’s Quick Button, which is ostensibly the camera button. Double-tapping it launches the camera app. While it’s not as elaborate as the iPhone’s Camera Control, you can swipe on the button to zoom in and out while using the camera, which is a simple, welcome addition. Alongside Mediatek's new Dimensity 9500 chip, the Find X9 Pro is another flagship phone with a silicon-carbon battery. With a higher energy density than graphite-based batteries, this means longer battery life without making the phone bigger or thicker. At 7,000mAh, the battery is huge. That’s far bigger than the battery found in foldables like Samsung’s Z Fold 7 (4,400 mAh) and the Pixel 9 Pro Fold (4,650 mAh). It’s even bigger than the one in the OnePlus 13 (6,000 mAh). Fortunately, the Find X9 supports suitably swift charging speeds, with support for 80W SUPERVOOC and 50W wireless charging. During my time with the phone, it would often last two days on a charge. Even after a day of heavy camera use, Google Maps and streaming video, I didn’t need to recharge the Find X9 Pro until late afternoon on the second day. Cameras Image by Mat Smith for Engadget The Find X9 Pro’s camera consists of a 50-megapixel main sensor with f/1.5 lens and optical image stabilization. There’s also a 50MP ultrawide camera and arguably the most technically impressive part: a 200MP periscope camera with an f/2.1 lens and OIS. This is further augmented with an attachable teleconverter lens — more on that later. Oppo’s Hasselblad collaboration focuses on telephoto, though the company calls its entire camera setup the Hasselblad Master Camera System. I’m not sure it needed such a label.To make the most of the high-resolution sensor, the camera app includes a new Hi-Res mode to capture at 200MP for the telephoto lens and 50MP when using the other two camera sensors. The company warns that the mode is best used in well-lit environments, as it strips out pixel binning and other computational photography techniques that are used when there’s limited light. But that’s not really the point: it’s all about the zoom. The telephoto has a base 3x optical zoom, which can be cropped to a 6x zoom with a 50MP image. It’s worth noting that all the cameras on the Find X9 can capture at 50MP. If the phone detects more challenging shooting conditions, it automatically drops down to 25MP or 12MP shots. In reality, I didn’t notice the resolution jump in most photos I took, although the rich foliage in some of my landscape shots showcases how much detail the camera system is able to capture. Image by Mat Smith for Engadget Oppo says its computational photography know-how pushes the zoom here to 13.2x, but its algorithms can get a little aggressive and messy with faces and detail at the higher digital zoom settings. Take a look at these pictures taken across a hillside. While the foliage appears crisp and detailed, the walkers are blurry and there’s a halo effect around them. At other times, computational photography turned pedestrians into nightmarish faces. In yet another opportunity to mention the Hasselblad collab, there’s also an XPAN shooting mode for cinematic 65:24 images. Conversely, if you’re into a disposable camera aesthetic, the Find X9 series can also trigger an aggressive double-flash to mimic ‘00s photography. The same zoom capabilities are available in video capture, too, and the company has added a new Sound Focus mode to strip out ambient noise, which worked better than I expected it to. There are several more video recording upgrades, including full LOG recording (activated in settings) and an integrated LUT preview to check color grading in real time. Image by Mat Smith for Engadget Then there’s the attachable lens. Oppo’s Hasselblad Teleconverter is a solid, premium peripheral, with a metal barrel and some heft. It extends the Find X9’s optical zoom to 10x, with an equivalent focal length of 230mm. Thanks to the high-res 200MP Telephoto camera sensor, you can punch in at up to 200x digital zoom for stills and 50x zoom for video, although the sweet spot is certainly more in the middle. The add-on teleconverter lens, while not entirely new (Vivo did it first), may be the most intriguing part. You need to use a specific case and mounting plate to securely attach the lens to the phone, but when it’s locked in, it feels solid and very secure. It also looks, well, how it looks. Because it’s such a slender lens, it looks like something you might use for espionage. It doesn’t even look like a point-and-shoot camera. It’s… eye-catching, but also so much fun. Image by Mat Smith for Engadget I’ve been testing the Find X9’s camera chops for a few weeks, and it’s been a lot of fun to zoom in with optical zoom clarity, whether at concerts, movie premieres or taking pictures of my nieces during hectic Play-Doh sessions. What’s particularly attractive is the combination of high detail and bokeh effect. With the leap in zoom, I had to ensure I was far enough away in order to use the teleconverter, or it would struggle to focus. Image by Mat Smith for Engadget Oppo is pitching its new flagship as the ultimate phone for concerts and live events, and the zoom range is very impressive. Perhaps understandably, when zooming so much, there is a high risk of blurry shots. Oppo includes a special tripod mount that attaches to the lens barrel to ensure the whole thing doesn’t tip over, but it’s one step too far for me. Carrying around the teleconverter and mounting plate is already a lot. It’s also a bit of a chore to have to detach the plate when using the camera without the teleconverter. Oddly, the plate covers the other sensors, meaning that if you want a closer focal point (or want to use anything besides the telephoto sensor), it’s an additional pain point before you can take the photo. It’s unusual that a phone’s “main” camera isn’t the star of the show, but that may be the case with the Find X9 Pro. However, it’s still technically impressive. With a new 1/1.28 sensor codeveloped with Sony, the 50MP main camera can capture triple exposures on each frame before merging them. Oppo claims that it gives images 17 stops of dynamic range. There’s also a fourth camera, a True Color camera, dedicated to precisely measuring color temperatures across all the other sensors. Combined, it’s an impressive system, but you’ll get the most out of it if you’re willing to pay for the additional teleconverter. Image by Mat Smith for Engadget At £1,099 in the UK, Oppo has priced it identically to the iPhone 17 Pro, although we're still waiting to hear pricing for the teleconverter kit. I feared foldable prices, but this seems at least competitive here in Europe. What’s stopping Oppo from breaking into the US? Trade turbulence and competition, probably. If it can refine the experience (and maybe keep its next phone compatible with the same teleconverter), it has a good chance at charming the obsessive smartphone photographer away from their iPhones and Pixels.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/oppos-find-x9-pro-hands-on-detachable-telephoto-lens-7000mah-battery-160006373.html?src=rss",
          "content": "Oppo’s latest flagship phone, like the sleek (but hard to buy) Find N5 foldable, goes hard on the tech specifications. In fact, the Find X9 Pro’s specs read like a wishlist of what many want to see in their phones, with a huge 7,500mAh battery, a 200-megapixel telephoto camera and a bright 6.78-inch screen with tiny, almost one-millimeter bezels, all while still measuring in at 8.25mm in thickness. Oh, and an optional telephoto lens add-on that boosts camera zoom to 10x. The Find X9 Pro will be priced at £1,099 (roughly $1,459). The biggest drawback may be that, despite the Find X9 series being Oppo’s biggest phone launch yet, it won’t be available in the US. Still, with everything that’s crammed into this phone, I had to try it out. Do I really want a thinner smartphone? Or one that lasts multiple days before it needs recharging? And man, this telephoto lens is certainly eye-catching. Display and design Image by Mat Smith for Engadget The Find X9 Pro has a 6.78-inch display, with peak outdoor brightness at 3,600 nits. On paper, that beats the iPhone 17 Pro, but most people with phones older than a year or two will notice how much brighter phones like the X9 Pro are. Another notable feature is a 1-nit minimal brightness to reduce eye strain when using the phone in the dark. Or in bed. Which we shouldn’t do, but we all do. Oppo has also included high-frequency pixel dimming to further reduce the screen's harshness. Like recent phones from its business cousin, OnePlus, Oppo has added a new button on this year’s Find X model. The Snap key is on the left of the device, and can be customized to launch apps like the voice recorder, translation apps and flashlight. Meanwhile, the right edge houses the Find X9’s Quick Button, which is ostensibly the camera button. Double-tapping it launches the camera app. While it’s not as elaborate as the iPhone’s Camera Control, you can swipe on the button to zoom in and out while using the camera, which is a simple, welcome addition. Alongside Mediatek's new Dimensity 9500 chip, the Find X9 Pro is another flagship phone with a silicon-carbon battery. With a higher energy density than graphite-based batteries, this means longer battery life without making the phone bigger or thicker. At 7,000mAh, the battery is huge. That’s far bigger than the battery found in foldables like Samsung’s Z Fold 7 (4,400 mAh) and the Pixel 9 Pro Fold (4,650 mAh). It’s even bigger than the one in the OnePlus 13 (6,000 mAh). Fortunately, the Find X9 supports suitably swift charging speeds, with support for 80W SUPERVOOC and 50W wireless charging. During my time with the phone, it would often last two days on a charge. Even after a day of heavy camera use, Google Maps and streaming video, I didn’t need to recharge the Find X9 Pro until late afternoon on the second day. Cameras Image by Mat Smith for Engadget The Find X9 Pro’s camera consists of a 50-megapixel main sensor with f/1.5 lens and optical image stabilization. There’s also a 50MP ultrawide camera and arguably the most technically impressive part: a 200MP periscope camera with an f/2.1 lens and OIS. This is further augmented with an attachable teleconverter lens — more on that later. Oppo’s Hasselblad collaboration focuses on telephoto, though the company calls its entire camera setup the Hasselblad Master Camera System. I’m not sure it needed such a label.To make the most of the high-resolution sensor, the camera app includes a new Hi-Res mode to capture at 200MP for the telephoto lens and 50MP when using the other two camera sensors. The company warns that the mode is best used in well-lit environments, as it strips out pixel binning and other computational photography techniques that are used when there’s limited light. But that’s not really the point: it’s all about the zoom. The telephoto has a base 3x optical zoom, which can be cropped to a 6x zoom with a 50MP image. It’s worth noting that all the cameras on the Find X9 can capture at 50MP. If the phone detects more challenging shooting conditions, it automatically drops down to 25MP or 12MP shots. In reality, I didn’t notice the resolution jump in most photos I took, although the rich foliage in some of my landscape shots showcases how much detail the camera system is able to capture. Image by Mat Smith for Engadget Oppo says its computational photography know-how pushes the zoom here to 13.2x, but its algorithms can get a little aggressive and messy with faces and detail at the higher digital zoom settings. Take a look at these pictures taken across a hillside. While the foliage appears crisp and detailed, the walkers are blurry and there’s a halo effect around them. At other times, computational photography turned pedestrians into nightmarish faces. In yet another opportunity to mention the Hasselblad collab, there’s also an XPAN shooting mode for cinematic 65:24 images. Conversely, if you’re into a disposable camera aesthetic, the Find X9 series can also trigger an aggressive double-flash to mimic ‘00s photography. The same zoom capabilities are available in video capture, too, and the company has added a new Sound Focus mode to strip out ambient noise, which worked better than I expected it to. There are several more video recording upgrades, including full LOG recording (activated in settings) and an integrated LUT preview to check color grading in real time. Image by Mat Smith for Engadget Then there’s the attachable lens. Oppo’s Hasselblad Teleconverter is a solid, premium peripheral, with a metal barrel and some heft. It extends the Find X9’s optical zoom to 10x, with an equivalent focal length of 230mm. Thanks to the high-res 200MP Telephoto camera sensor, you can punch in at up to 200x digital zoom for stills and 50x zoom for video, although the sweet spot is certainly more in the middle. The add-on teleconverter lens, while not entirely new (Vivo did it first), may be the most intriguing part. You need to use a specific case and mounting plate to securely attach the lens to the phone, but when it’s locked in, it feels solid and very secure. It also looks, well, how it looks. Because it’s such a slender lens, it looks like something you might use for espionage. It doesn’t even look like a point-and-shoot camera. It’s… eye-catching, but also so much fun. Image by Mat Smith for Engadget I’ve been testing the Find X9’s camera chops for a few weeks, and it’s been a lot of fun to zoom in with optical zoom clarity, whether at concerts, movie premieres or taking pictures of my nieces during hectic Play-Doh sessions. What’s particularly attractive is the combination of high detail and bokeh effect. With the leap in zoom, I had to ensure I was far enough away in order to use the teleconverter, or it would struggle to focus. Image by Mat Smith for Engadget Oppo is pitching its new flagship as the ultimate phone for concerts and live events, and the zoom range is very impressive. Perhaps understandably, when zooming so much, there is a high risk of blurry shots. Oppo includes a special tripod mount that attaches to the lens barrel to ensure the whole thing doesn’t tip over, but it’s one step too far for me. Carrying around the teleconverter and mounting plate is already a lot. It’s also a bit of a chore to have to detach the plate when using the camera without the teleconverter. Oddly, the plate covers the other sensors, meaning that if you want a closer focal point (or want to use anything besides the telephoto sensor), it’s an additional pain point before you can take the photo. It’s unusual that a phone’s “main” camera isn’t the star of the show, but that may be the case with the Find X9 Pro. However, it’s still technically impressive. With a new 1/1.28 sensor codeveloped with Sony, the 50MP main camera can capture triple exposures on each frame before merging them. Oppo claims that it gives images 17 stops of dynamic range. There’s also a fourth camera, a True Color camera, dedicated to precisely measuring color temperatures across all the other sensors. Combined, it’s an impressive system, but you’ll get the most out of it if you’re willing to pay for the additional teleconverter. Image by Mat Smith for Engadget At £1,099 in the UK, Oppo has priced it identically to the iPhone 17 Pro, although we're still waiting to hear pricing for the teleconverter kit. I feared foldable prices, but this seems at least competitive here in Europe. What’s stopping Oppo from breaking into the US? Trade turbulence and competition, probably. If it can refine the experience (and maybe keep its next phone compatible with the same teleconverter), it has a good chance at charming the obsessive smartphone photographer away from their iPhones and Pixels.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/oppos-find-x9-pro-hands-on-detachable-telephoto-lens-7000mah-battery-160006373.html?src=rss",
          "feed_position": 49,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/f8a3c8b1-b3f8-11f0-bb3a-92d51df1faad"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/intuit-learned-to-build-ai-agents-for-finance-the-hard-way-trust-lost-in",
          "published_at": "Tue, 28 Oct 2025 12:30:00 GMT",
          "title": "Intuit learned to build AI agents for finance the hard way: Trust lost in buckets, earned back in spoonfuls",
          "standfirst": "Building AI for financial software requires a different playbook than consumer AI, and Intuit&#x27;s latest QuickBooks release provides an example.The company has announced Intuit Intelligence, a system that orchestrates specialized AI agents across its QuickBooks platform to handle tasks including sales tax compliance and payroll processing. These new agents augment existing accounting and project management agents (which have also been updated) as well as a unified interface that lets users query data across QuickBooks, third-party systems and uploaded files using natural language. The new development follow years of investment and improvement in Intuit&#x27;s GenOS, allowing the company to build AI capabilities that reduce latency and improve accuracy.But the real news isn&#x27;t what Intuit built — it&#x27;s how they built it and why their design decisions will make AI more usable. The company&#x27;s latest AI rollout represents an evolution built on hard-won lessons about what works and what doesn&#x27;t when deploying AI in financial contexts.What the company learned is sobering: Even when its accounting agent improved transaction categorization accuracy by 20 percentage points on average, they still received complaints about errors.\"The use cases that we&#x27;re trying to solve for customers include tax and finance; if you make a mistake in this world, you lose trust with customers in buckets and we only get it back in spoonfuls,\" Joe Preston, Intuit&#x27;s VP of product and design, told VentureBeat.The architecture of trust: Real data queries over generative responsesIntuit&#x27;s technical strategy centers on a fundamental design decision. For financial queries and business intelligence, the system queries actual data, rather than generating responses through large language models (LLMs).Also critically important: That data isn&#x27;t all in one place. Intuit&#x27;s technical implementation allows QuickBooks to ingest data from multiple distinct sources: native Intuit data, OAuth-connected third-party systems like Square for payments and user-uploaded files such as spreadsheets containing vendor pricing lists or marketing campaign data. This creates a unified data layer that AI agents can query reliably.\"We&#x27;re actually querying your real data,\" Preston explained. \"That&#x27;s very different than if you were to just copy, paste out a spreadsheet or a PDF and paste into ChatGPT.\"This architectural choice means that the Intuit Intelligence system functions more as an orchestration layer. It&#x27;s a natural language interface to structured data operations. When a user asks about projected profitability or wants to run payroll, the system translates the natural language query into database operations against verified financial data.This matters because Intuit&#x27;s internal research has uncovered widespread shadow AI usage. When surveyed, 25% of accountants using QuickBooks admitted they were already copying and pasting data into ChatGPT or Google Gemini for analysis.Intuit&#x27;s approach treats AI as a query translation and orchestration mechanism, not a content generator. This reduces the hallucination risk that has plagued AI deployments in financial contexts.Explainability as a design requirement, not an afterthoughtBeyond the technical architecture, Intuit has made explainability a core user experience across its AI agents. This goes beyond simply providing correct answers: It means showing users the reasoning behind automated decisions.When Intuit&#x27;s accounting agent categorizes a transaction, it doesn&#x27;t just display the result; it shows the reasoning. This isn&#x27;t marketing copy about explainable AI, it&#x27;s actual UI displaying data points and logic.\"It&#x27;s about closing that trust loop and making sure customers understand the why,\" Alastair Simpson, Intuit&#x27;s VP of design, told VentureBeat.This becomes particularly critical when you consider Intuit&#x27;s user research: While half of small businesses describe AI as helpful, nearly a quarter haven&#x27;t used AI at all. The explanation layer serves both populations: Building confidence for newcomers, while giving experienced users the context to verify accuracy.The design also enforces human control at critical decision points. This approach extends beyond the interface. Intuit connects users directly with human experts, embedded in the same workflows, when automation reaches its limits or when users want validation.Navigating the transition from forms to conversationsOne of Intuit&#x27;s more interesting challenges involves managing a fundamental shift in user interfaces. Preston described it as having one foot in the past and one foot in the future.\"This isn&#x27;t just Intuit, this is the market as a whole,\" said Preston. \"Today we still have a lot of customers filling out forms and going through tables full of data. We&#x27;re investing a lot into leaning in and questioning the ways that we do it across our products today, where you&#x27;re basically just filling out, form after form, or table after table, because we see where the world is headed, which is really a different form of interacting with these products.\"This creates a product design challenge: How do you serve users who are comfortable with traditional interfaces while gradually introducing conversational and agentic capabilities?Intuit&#x27;s approach has been to embed AI agents directly into existing workflows. This means not forcing users to adopt entirely new interaction patterns. The payments agent appears alongside invoicing workflows; the accounting agent enhances the existing reconciliation process rather than replacing it. This incremental approach lets users experience AI benefits without abandoning familiar processes.What enterprise AI builders can learn from Intuit&#x27;s approachIntuit&#x27;s experience deploying AI in financial contexts surfaces several principles that apply broadly to enterprise AI initiatives. Architecture matters for trust: In domains where accuracy is critical, consider whether you need content generation or data query translation. Intuit&#x27;s decision to treat AI as an orchestration and natural language interface layer dramatically reduces hallucination risk and avoids using AI as a generative system.Explainability must be designed in, not bolted on: Showing users why the AI made a decision isn&#x27;t optional when trust is at stake. This requires deliberate UX design. It may constrain model choices.User control preserves trust during accuracy improvements: Intuit&#x27;s accounting agent improved categorization accuracy by 20 percentage points. Yet, maintaining user override capabilities was essential for adoption.Transition gradually from familiar interfaces: Don&#x27;t force users to abandon forms for conversations. Embed AI capabilities into existing workflows first. Let users experience benefits before asking them to change behavior.Be honest about what&#x27;s reactive versus proactive: Current AI agents primarily respond to prompts and automate defined tasks. True proactive intelligence that makes unprompted strategic recommendations remains an evolving capability. Address workforce concerns with tooling, not just messaging: If AI is meant to augment rather than replace workers, provide workers with AI tools. Show them how to leverage the technology.For enterprises navigating AI adoption, Intuit&#x27;s journey offers a clear directive. The winning approach prioritizes trustworthiness over capability demonstrations. In domains where mistakes have real consequences, that means investing in accuracy, transparency and human oversight before pursuing conversational sophistication or autonomous action.Simpson frames the challenge succinctly: \"We didn&#x27;t want it to be a bolted-on layer. We wanted customers to be in their natural workflow, and have agents doing work for customers, embedded in the workflow.\"",
          "content": "Building AI for financial software requires a different playbook than consumer AI, and Intuit&#x27;s latest QuickBooks release provides an example.The company has announced Intuit Intelligence, a system that orchestrates specialized AI agents across its QuickBooks platform to handle tasks including sales tax compliance and payroll processing. These new agents augment existing accounting and project management agents (which have also been updated) as well as a unified interface that lets users query data across QuickBooks, third-party systems and uploaded files using natural language. The new development follow years of investment and improvement in Intuit&#x27;s GenOS, allowing the company to build AI capabilities that reduce latency and improve accuracy.But the real news isn&#x27;t what Intuit built — it&#x27;s how they built it and why their design decisions will make AI more usable. The company&#x27;s latest AI rollout represents an evolution built on hard-won lessons about what works and what doesn&#x27;t when deploying AI in financial contexts.What the company learned is sobering: Even when its accounting agent improved transaction categorization accuracy by 20 percentage points on average, they still received complaints about errors.\"The use cases that we&#x27;re trying to solve for customers include tax and finance; if you make a mistake in this world, you lose trust with customers in buckets and we only get it back in spoonfuls,\" Joe Preston, Intuit&#x27;s VP of product and design, told VentureBeat.The architecture of trust: Real data queries over generative responsesIntuit&#x27;s technical strategy centers on a fundamental design decision. For financial queries and business intelligence, the system queries actual data, rather than generating responses through large language models (LLMs).Also critically important: That data isn&#x27;t all in one place. Intuit&#x27;s technical implementation allows QuickBooks to ingest data from multiple distinct sources: native Intuit data, OAuth-connected third-party systems like Square for payments and user-uploaded files such as spreadsheets containing vendor pricing lists or marketing campaign data. This creates a unified data layer that AI agents can query reliably.\"We&#x27;re actually querying your real data,\" Preston explained. \"That&#x27;s very different than if you were to just copy, paste out a spreadsheet or a PDF and paste into ChatGPT.\"This architectural choice means that the Intuit Intelligence system functions more as an orchestration layer. It&#x27;s a natural language interface to structured data operations. When a user asks about projected profitability or wants to run payroll, the system translates the natural language query into database operations against verified financial data.This matters because Intuit&#x27;s internal research has uncovered widespread shadow AI usage. When surveyed, 25% of accountants using QuickBooks admitted they were already copying and pasting data into ChatGPT or Google Gemini for analysis.Intuit&#x27;s approach treats AI as a query translation and orchestration mechanism, not a content generator. This reduces the hallucination risk that has plagued AI deployments in financial contexts.Explainability as a design requirement, not an afterthoughtBeyond the technical architecture, Intuit has made explainability a core user experience across its AI agents. This goes beyond simply providing correct answers: It means showing users the reasoning behind automated decisions.When Intuit&#x27;s accounting agent categorizes a transaction, it doesn&#x27;t just display the result; it shows the reasoning. This isn&#x27;t marketing copy about explainable AI, it&#x27;s actual UI displaying data points and logic.\"It&#x27;s about closing that trust loop and making sure customers understand the why,\" Alastair Simpson, Intuit&#x27;s VP of design, told VentureBeat.This becomes particularly critical when you consider Intuit&#x27;s user research: While half of small businesses describe AI as helpful, nearly a quarter haven&#x27;t used AI at all. The explanation layer serves both populations: Building confidence for newcomers, while giving experienced users the context to verify accuracy.The design also enforces human control at critical decision points. This approach extends beyond the interface. Intuit connects users directly with human experts, embedded in the same workflows, when automation reaches its limits or when users want validation.Navigating the transition from forms to conversationsOne of Intuit&#x27;s more interesting challenges involves managing a fundamental shift in user interfaces. Preston described it as having one foot in the past and one foot in the future.\"This isn&#x27;t just Intuit, this is the market as a whole,\" said Preston. \"Today we still have a lot of customers filling out forms and going through tables full of data. We&#x27;re investing a lot into leaning in and questioning the ways that we do it across our products today, where you&#x27;re basically just filling out, form after form, or table after table, because we see where the world is headed, which is really a different form of interacting with these products.\"This creates a product design challenge: How do you serve users who are comfortable with traditional interfaces while gradually introducing conversational and agentic capabilities?Intuit&#x27;s approach has been to embed AI agents directly into existing workflows. This means not forcing users to adopt entirely new interaction patterns. The payments agent appears alongside invoicing workflows; the accounting agent enhances the existing reconciliation process rather than replacing it. This incremental approach lets users experience AI benefits without abandoning familiar processes.What enterprise AI builders can learn from Intuit&#x27;s approachIntuit&#x27;s experience deploying AI in financial contexts surfaces several principles that apply broadly to enterprise AI initiatives. Architecture matters for trust: In domains where accuracy is critical, consider whether you need content generation or data query translation. Intuit&#x27;s decision to treat AI as an orchestration and natural language interface layer dramatically reduces hallucination risk and avoids using AI as a generative system.Explainability must be designed in, not bolted on: Showing users why the AI made a decision isn&#x27;t optional when trust is at stake. This requires deliberate UX design. It may constrain model choices.User control preserves trust during accuracy improvements: Intuit&#x27;s accounting agent improved categorization accuracy by 20 percentage points. Yet, maintaining user override capabilities was essential for adoption.Transition gradually from familiar interfaces: Don&#x27;t force users to abandon forms for conversations. Embed AI capabilities into existing workflows first. Let users experience benefits before asking them to change behavior.Be honest about what&#x27;s reactive versus proactive: Current AI agents primarily respond to prompts and automate defined tasks. True proactive intelligence that makes unprompted strategic recommendations remains an evolving capability. Address workforce concerns with tooling, not just messaging: If AI is meant to augment rather than replace workers, provide workers with AI tools. Show them how to leverage the technology.For enterprises navigating AI adoption, Intuit&#x27;s journey offers a clear directive. The winning approach prioritizes trustworthiness over capability demonstrations. In domains where mistakes have real consequences, that means investing in accuracy, transparency and human oversight before pursuing conversational sophistication or autonomous action.Simpson frames the challenge succinctly: \"We didn&#x27;t want it to be a bolted-on layer. We wanted customers to be in their natural workflow, and have agents doing work for customers, embedded in the workflow.\"",
          "feed_position": 12,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/26uFKCJx7guEmpRjNxJdWl/bee15b7153fa921dc410f50175781a25/ai_trust_in_a_bucket-SMK.png?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/3XICNbOGJJDY7SoZx0m1SV/4b4ec66e5aa6a03194e432369e6e6ac8/cfr0z3n_flat_illustration_elegant_constructivist_1920s_art_deco_6818187a-93ac-437e-af85-43b96b2507a5.png?w=300&q=30",
      "popularity_score": 2010.598296111111,
      "ai_summary": [
        "NordVPN offers a two-year subscription with three months free, totaling 74 percent off.",
        "NordVPN's Plus subscription also has a 74 percent discount for a two-year plan with extra months.",
        "VPN providers offer deep discounts to customers who sign up for a year or more.",
        "VPNs can stream foreign TV shows, protect against hackers, and maintain online anonymity.",
        "Consider a longer commitment to maximize savings, as prices are cheaper over time."
      ]
    },
    {
      "id": "cluster_68",
      "coverage": 2,
      "updated_at": "Wed, 29 Oct 2025 17:40:19 +0000",
      "title": "Former L3Harris Trenchant boss pleads guilty to selling zero-day exploits to Russian broker",
      "neutral_headline": "Former L3Harris Executive Pleads Guilty to Selling Exploits",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/29/former-l3harris-trenchant-boss-pleads-guilty-to-selling-zero-day-exploits-to-russian-broker/",
          "published_at": "Wed, 29 Oct 2025 17:40:19 +0000",
          "title": "Former L3Harris Trenchant boss pleads guilty to selling zero-day exploits to Russian broker",
          "standfirst": "Prosecutors confirmed Peter Williams, the former Trenchant boss, sold eight exploits to a Russian buyer. TechCrunch exclusively reported that the Trenchant division was investigating a leak of its hacking tools, after another employee was accused of involvement.",
          "content": "Prosecutors confirmed Peter Williams, the former Trenchant boss, sold eight exploits to a Russian buyer. TechCrunch exclusively reported that the Trenchant division was investigating a leak of its hacking tools, after another employee was accused of involvement.",
          "feed_position": 13
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/peter-williams-trenchant-trade-secrets-theft-russian-firm/",
          "published_at": "Wed, 29 Oct 2025 17:13:16 +0000",
          "title": "Ex-L3Harris Cyber Boss Pleads Guilty to Selling Trade Secrets to Russian Firm",
          "standfirst": "Peter Williams, a former executive of Trenchant, L3Harris’ cyber division, has pleaded guilty to two counts of stealing trade secrets and selling them to an unnamed Russian software broker.",
          "content": "Peter Williams, a former executive of Trenchant, L3Harris’ cyber division, has pleaded guilty to two counts of stealing trade secrets and selling them to an unnamed Russian software broker.",
          "feed_position": 11,
          "image_url": "https://media.wired.com/photos/690228d865b611a9f97823f6/master/pass/sec-L3Harris-trial-2172435098.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/690228d865b611a9f97823f6/master/pass/sec-L3Harris-trial-2172435098.jpg",
      "popularity_score": 2006.3544072222223,
      "ai_summary": [
        "Peter Williams, former Trenchant boss, sold zero-day exploits to a Russian broker.",
        "Williams, a former executive of L3Harris' cyber division, stole trade secrets.",
        "Williams pleaded guilty to two counts of stealing trade secrets and selling them.",
        "TechCrunch reported the Trenchant division investigated a hacking tools leak.",
        "The Russian buyer remains unnamed in the reports of the case."
      ]
    },
    {
      "id": "cluster_111",
      "coverage": 2,
      "updated_at": "Wed, 29 Oct 2025 13:00:18 +0000",
      "title": "Republican plan would make deanonymization of census data trivial",
      "neutral_headline": "Republican Plan Could Compromise Census Data Privacy",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/republican-plan-would-make-deanonymization-of-census-data-trivial/",
          "published_at": "Wed, 29 Oct 2025 13:00:18 +0000",
          "title": "Republican plan would make deanonymization of census data trivial",
          "standfirst": "\"Differential privacy\" algorithm prevents statistical data from being tied to individuals.",
          "content": "President Donald Trump and the Republican Party have spent the better part of the president’s second term radically reshaping the federal government. But in recent weeks, the GOP has set its sights on taking another run at an old target: the US census. Since the first Trump administration, the right has sought to add a question to the census that captures a respondent’s immigration status and to exclude noncitizens from the tallies that determine how seats in Congress are distributed. In 2019, the Supreme Court struck down an attempt by the first Trump administration to add a citizenship question to the census. But now, a little-known algorithmic process called “differential privacy,” created to keep census data from being used to identify individual respondents, has become the right’s latest focus. WIRED spoke to six experts about the GOP’s ongoing effort to falsely allege that a system created to protect people’s privacy has made the data from the 2020 census inaccurate.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/census-1152x648.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/republicans-differential-privacy-census-overhaul/",
          "published_at": "Tue, 28 Oct 2025 10:00:00 +0000",
          "title": "The Republican Plan to Reform the Census Could Put Everyone’s Privacy at Risk",
          "standfirst": "A little-known algorithmic process called “differential privacy” helps keep census data anonymous. Conservatives want it gone.",
          "content": "A little-known algorithmic process called “differential privacy” helps keep census data anonymous. Conservatives want it gone.",
          "feed_position": 45,
          "image_url": "https://media.wired.com/photos/68f6b13d4cd4cc76ba1c8542/master/pass/politics_census_republicans_data_privacy.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/census-1152x648.jpg",
      "popularity_score": 2001.6874627777777,
      "ai_summary": [
        "A Republican plan could make deanonymization of census data easier.",
        "The current \"differential privacy\" algorithm protects individual data.",
        "Conservatives are seeking to eliminate the current privacy measures.",
        "The algorithmic process helps keep census data anonymous.",
        "The proposed changes could put everyone's privacy at risk."
      ]
    },
    {
      "id": "cluster_42",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 21:35:58 +0000",
      "title": "Meta denies torrenting porn to train AI, says downloads were for “personal use”",
      "neutral_headline": "Meta Denies Using Porn to Train Artificial Intelligence",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/meta-says-porn-downloads-on-its-ips-were-for-personal-use-not-ai-training/",
          "published_at": "Wed, 29 Oct 2025 21:35:58 +0000",
          "title": "Meta denies torrenting porn to train AI, says downloads were for “personal use”",
          "standfirst": "Meta says lawsuit claiming it pirated porn to train AI makes no sense.",
          "content": "This week, Meta asked a US district court to toss a lawsuit alleging that the tech giant illegally torrented pornography to train AI. The move comes after Strike 3 Holdings discovered illegal downloads of some of its adult films on Meta corporate IP addresses, as well as other downloads that Meta allegedly concealed using a “stealth network” of 2,500 “hidden IP addresses.” Accusing Meta of stealing porn to secretly train an unannounced adult version of its AI model powering Movie Gen, Strike 3 sought damages that could have exceeded $350 million, TorrentFreak reported. Filing a motion to dismiss the lawsuit on Monday, Meta accused Strike 3 of relying on “guesswork and innuendo,” while writing that Strike 3 “has been labeled by some as a ‘copyright troll’ that files extortive lawsuits.” Requesting that all copyright claims be dropped, Meta argued that there was no evidence that the tech giant directed any of the downloads of about 2,400 adult movies owned by Strike 3—or was even aware of the illegal activity.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2171230457-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2171230457-1152x648.jpg",
      "popularity_score": 358.28190722222223,
      "ai_summary": [
        "Meta denies claims of pirating porn to train its artificial intelligence.",
        "The lawsuit alleges Meta downloaded pornographic material.",
        "Meta claims the downloads were for \"personal use\" only.",
        "The company states the lawsuit's claims are without merit.",
        "The case involves allegations of copyright infringement."
      ]
    },
    {
      "id": "cluster_44",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 21:23:22 +0000",
      "title": "Space station astronauts eager to open “golden treasure box” from Japan",
      "neutral_headline": "Space Station Astronauts Excited for Japanese Treasure Box",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/space-station-astronauts-eager-to-open-golden-treasure-box-from-japan/",
          "published_at": "Wed, 29 Oct 2025 21:23:22 +0000",
          "title": "Space station astronauts eager to open “golden treasure box” from Japan",
          "standfirst": "\"This spacecraft is so beautiful and shiny, and this is representing our bright future.\"",
          "content": "A cargo ship from Japan pulled alongside the International Space Station on Wednesday, maneuvering close enough for the lab’s robotic arm to reach out and grab it as the vehicles soared 260 miles over the South Atlantic Ocean. “HTV capture complete,” Japanese astronaut Kimiya Yui radioed from the ISS. “I just want to say congratulations to all teams and people involved in this mission. Also, thank you very much for your hard work and support for the first HTV-X mission.” The HTV-X spacecraft is an upgraded cargo freighter replacing Japan’s H-II Transfer Vehicle, which successfully resupplied the space station nine times between 2009 and 2020. At the conclusion of the HTV program, Japan’s space agency preferred to focus its resources on designing a new cargo ship with more capability at a lower cost. That’s what HTV-X is supposed to be, and Wednesday’s high-flying rendezvous marked the new ship’s first delivery to the ISS.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/htvx1-arrive1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/htvx1-arrive1-1152x648.jpg",
      "popularity_score": 341.0719072222222,
      "ai_summary": [
        "Astronauts are eager to open a \"golden treasure box\" from Japan.",
        "The spacecraft is described as beautiful and shiny.",
        "The astronauts see the spacecraft as representing a bright future.",
        "The Japanese spacecraft is a source of excitement for the crew.",
        "The contents of the \"treasure box\" are highly anticipated."
      ]
    },
    {
      "id": "cluster_45",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 21:04:45 +0000",
      "title": "NPM flooded with malicious packages downloaded more than 86,000 times",
      "neutral_headline": "Malicious Packages Flooding NPM, Downloaded Thousands of Times",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/npm-flooded-with-malicious-packages-downloaded-more-than-86000-times/",
          "published_at": "Wed, 29 Oct 2025 21:04:45 +0000",
          "title": "NPM flooded with malicious packages downloaded more than 86,000 times",
          "standfirst": "Packages downloaded from NPM can fetch dependancies from untrusted sites.",
          "content": "Attackers are exploiting a major weakness that has allowed them access to the NPM code repository with more than 100 credential-stealing packages since August, mostly without detection. The finding, laid out Wednesday by security firm Koi, brings attention to an NPM practice that allows installed packages to automatically pull down and run unvetted packages from untrusted domains. Koi said a campaign it tracks as PhantomRaven has exploited NPM’s use of “Remote Dynamic Dependences” to flood NPM with 126 malicious packages that have been downloaded more than 86,000 times. Some 80 of those packages remained available as of Wednesday morning, Koi said. A blind spot “PhantomRaven demonstrates how sophisticated attackers are getting [better] at exploiting blind spots in traditional security tooling,” Koi’s Oren Yomtov wrote. “Remote Dynamic Dependencies aren’t visible to static analysis.”Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/05/caution-tape-1000x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/05/caution-tape-1000x648.jpeg",
      "popularity_score": 322.76162944444445,
      "ai_summary": [
        "Malicious packages on NPM have been downloaded over 86,000 times.",
        "Packages downloaded from NPM can fetch dependencies from untrusted sites.",
        "The downloads pose a security risk to users of the packages.",
        "The issue highlights the importance of package security.",
        "The packages are a potential source of malware."
      ]
    },
    {
      "id": "cluster_55",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 19:44:40 +0000",
      "title": "Trump health official ousted after allegedly giving himself a fake title",
      "neutral_headline": "Trump Health Official Ousted After Alleged Title Falsification",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/trump-health-official-ousted-after-allegedly-giving-himself-a-fake-title/",
          "published_at": "Wed, 29 Oct 2025 19:44:40 +0000",
          "title": "Trump health official ousted after allegedly giving himself a fake title",
          "standfirst": "Steven Hatfill had a notable history before his abrupt ouster.",
          "content": "Steven Hatfill, a senior advisor for the Department of Health and Human Services was fired over the weekend, with health officials telling reporters that he was terminated for giving himself a fake, inflated title and for not cooperating with leadership. For his part, Hatfill told The New York Times that his ouster was part of “a coup to overthrow M. Kennedy,” referring to anti-vaccine Health Secretary Robert F. Kennedy Jr. Further, Hatfill said the coup was being orchestrated by Matt Buckham, Kennedy’s chief of staff, though Hatfill didn’t provide any explanation of how his ouster was evidence of that. An HHS spokesperson responded to the allegation, telling the Times that “firing a staff member for cause does not add up to a coup.” Bloomberg was first to report Hatfill’s termination.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-122179143-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-122179143-1152x648.jpg",
      "popularity_score": 311.4269072222222,
      "ai_summary": [
        "Steven Hatfill was ousted after allegedly giving himself a fake title.",
        "Hatfill had a notable history before his abrupt ouster.",
        "The circumstances surrounding the ouster are under scrutiny.",
        "The incident raises questions about the official's background.",
        "The ouster occurred within the Trump administration."
      ]
    },
    {
      "id": "cluster_57",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 19:18:37 +0000",
      "title": "FCC Republicans force prisoners and families to pay more for phone calls",
      "neutral_headline": "FCC Republicans Increase Phone Call Costs for Prisoners",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/fcc-republicans-force-prisoners-and-families-to-pay-more-for-phone-calls/",
          "published_at": "Wed, 29 Oct 2025 19:18:37 +0000",
          "title": "FCC Republicans force prisoners and families to pay more for phone calls",
          "standfirst": "Democrat: FCC \"rewards corporations with money taken from vulnerable families.\"",
          "content": "The Federal Communications Commission voted yesterday to raise the maximum prices that prison and jail phone services can charge inmates and their families. The 2–1 vote with Republicans voting to raise the limits came with a dissent from Democrat Anna Gomez, who said the new rates will be “almost double in some facilities.” A new inflation factor will allow rates to rise further. “The FCC once again is going above and beyond to address the unsubstantiated needs of monopoly providers to squeeze every penny possible from families that want to stay in touch with their loved ones,” Gomez said at the FCC meeting. “Throughout this order, the FCC chooses to reward corporations with money taken from vulnerable families.”Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/brendan-carr-fcc-1152x648-1761764153.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/brendan-carr-fcc-1152x648-1761764153.jpg",
      "popularity_score": 300.99274055555554,
      "ai_summary": [
        "FCC Republicans are forcing prisoners and families to pay more for calls.",
        "A Democrat stated the FCC \"rewards corporations with money from families.\"",
        "The policy change impacts vulnerable families.",
        "The FCC's decision has drawn criticism from Democrats.",
        "The increased costs affect communication access."
      ]
    },
    {
      "id": "cluster_84",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 16:37:06 +0000",
      "title": "TV-focused YouTube update brings AI upscaling, shopping QR codes",
      "neutral_headline": "YouTube Update Includes AI Upscaling and Shopping QR Codes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/tv-focused-youtube-update-brings-ai-upscaling-shopping-qr-codes/",
          "published_at": "Wed, 29 Oct 2025 16:37:06 +0000",
          "title": "TV-focused YouTube update brings AI upscaling, shopping QR codes",
          "standfirst": "YouTube seeks a more couch-friendly experience.",
          "content": "YouTube has been streaming for 20 years, but it was only in the last couple that it came to dominate TV streaming. Google’s video platform attracts more TV viewers than Netflix, Disney+, and all the other apps, and Google is looking to further beef up its big-screen appeal with a new raft of features, including shopping, immersive channel surfing, and an official version of the AI upscaling that had creators miffed a few months back. According to Google, YouTube’s growth has translated into higher payouts. The number of channels earning more than $100,000 annually is up 45 percent in 2025 versus 2024. YouTube is now giving creators some tools to boost their appeal (and hopefully their income) on TV screens. Those elaborate video thumbnails featuring surprised, angry, smiley hosts are about to get even prettier with the new 50MB file size limit. That’s up from a measly 2MB. Video upscaling is also coming to YouTube, and creators will be opted in automatically. To start, YouTube will be upscaling lower-quality videos to 1080p. In the near future, Google plans to support “super resolution” up to 4K.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/12/getty-youtube-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/12/getty-youtube-1152x648.jpg",
      "popularity_score": 293.30079611111114,
      "ai_summary": [
        "YouTube's update focuses on a more couch-friendly experience.",
        "The update includes AI upscaling for improved video quality.",
        "Shopping QR codes are being integrated into the platform.",
        "The changes aim to enhance user engagement.",
        "The update is designed for TV-focused viewing."
      ]
    },
    {
      "id": "cluster_62",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 18:29:45 +0000",
      "title": "ICE’s forced face scans to verify citizens is unconstitutional, lawmakers say",
      "neutral_headline": "Lawmakers Say ICE Face Scans Are Unconstitutional",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/ices-forced-face-scans-to-verify-citizens-is-unconstitutional-lawmakers-say/",
          "published_at": "Wed, 29 Oct 2025 18:29:45 +0000",
          "title": "ICE’s forced face scans to verify citizens is unconstitutional, lawmakers say",
          "standfirst": "Videos show ICE conducting random face scans on US streets.",
          "content": "Social media videos have confirmed that Immigration and Customs Enforcement (ICE) and Customs and Border Protection (CBP) officers patrolling US streets are actively using facial recognition technology to verify citizenship, 404 Media reported. In one video posted on a Chicago-based Instagram account, a self-described teenager and US citizen tells officers that he has no government ID. After he offers to show his student ID instead, the officer turns to another and asks, “can you do facial?” As the other officer pulls up an app to scan the teen’s face, the first officer tells the teenager to “relax” while alleging that “a lot of parents” tell their kids they were born in the US. The video ends after the officer takes the minor’s photo and asks the teen to verify that his name matches what the app’s database pulled up. It’s unclear which app the officers used during this Chicago stop. But 404 Media has been closely tracking ICE and CBP’s increasing use of face scans amid the Trump administration’s nationwide mass deportation campaign, which critics slam as largely rooted in racial profiling. Earlier this year, 404 Media reviewed leaked emails confirming that ICE was using Mobile Fortify, which allows agents to scan “an unprecedented number of government databases” and compare face matches against a database of 200 million images.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2238024951-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2238024951-1024x648.jpg",
      "popularity_score": 290.17829611111114,
      "ai_summary": [
        "Lawmakers claim ICE's forced face scans are unconstitutional.",
        "Videos show ICE conducting random face scans on US streets.",
        "The practice is being challenged on legal grounds.",
        "The face scans are used to verify citizens' identities.",
        "The lawmakers are raising concerns about privacy violations."
      ]
    },
    {
      "id": "cluster_100",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 14:46:21 +0000",
      "title": "Nvidia hits record $5 trillion mark as CEO dismisses AI bubble concerns",
      "neutral_headline": "Nvidia Hits Record $5 Trillion Mark, CEO Dismisses Bubble Concerns",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/nvidia-hits-record-5-trillion-mark-as-ceo-dismisses-ai-bubble-concerns/",
          "published_at": "Wed, 29 Oct 2025 14:46:21 +0000",
          "title": "Nvidia hits record $5 trillion mark as CEO dismisses AI bubble concerns",
          "standfirst": "\"I don’t believe we’re in an AI bubble,\" says Huang after announcing $500B in orders.",
          "content": "On Wednesday, Nvidia became the first company in history to reach a $5 trillion market capitalization, fresh on the heels of a GTC conference keynote in Washington, DC, where CEO Jensen Huang announced $500 billion in AI chip orders and plans to build seven supercomputers for the US government. The milestone comes a mere three months after Nvidia crossed the $4 trillion mark in July, vaulting the company past tech giants like Apple and Microsoft in market valuation but also driving continued fears of an AI investment bubble. Nvidia’s shares have climbed nearly 12-fold since the launch of ChatGPT in late 2022, as the AI boom propelled the S&P 500 to record highs. Shares of Nvidia stock rose 4.6 percent on Wednesday following the Tuesday announcement at the company’s GTC conference. During a Bloomberg Television interview at the event, Huang dismissed concerns about overheated valuations, saying, “I don’t believe we’re in an AI bubble. All of these different AI models we’re using—we’re using plenty of services and paying happily to do it.” Nvidia expects to ship 20 million units of its latest chips, compared to just 4 million units of the previous Hopper generation over its entire lifetime, Huang said at the conference. The $500 billion figure represents cumulative orders for the company’s Blackwell and Rubin processors through the end of 2026, though Huang noted that his projections did not include potential sales to China.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_flag_2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_flag_2-1152x648.jpg",
      "popularity_score": 271.4549627777778,
      "ai_summary": [
        "Nvidia hit a record $5 trillion market capitalization.",
        "CEO Huang dismissed concerns about an artificial intelligence bubble.",
        "Huang announced $500 billion in orders for the company.",
        "The company's growth is driven by artificial intelligence demand.",
        "Nvidia is a major player in the technology industry."
      ]
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 16:20:59 +0000",
      "title": "The chemistry behind that pricey cup of civet coffee",
      "neutral_headline": "Chemical Analysis Reveals Secrets of Civet Coffee",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/fermentation-is-key-to-coffee-beans-gleaned-from-civet-feces/",
          "published_at": "Wed, 29 Oct 2025 16:20:59 +0000",
          "title": "The chemistry behind that pricey cup of civet coffee",
          "standfirst": "Fans of kopi luwak claim the coffee has a unique aroma and taste. A new chemical analysis backs them up.",
          "content": "In 2007’s The Bucket List, Jack Nicholson’s billionaire magnate is a fan of a luxury coffee called kopi luwak, only to be informed that the beans first pass through the digestive tracts of civets and are harvested from their feces prior to roasting. The implication is that the billionaire just liked drinking gimmicky expensive coffee without realizing its less-than-luxurious origins. It’s one of the most expensive coffees in the world, ranging from $45 per pound to $590 per pound, depending on whether the beans are farmed or collected in the wild. Whether kopi luwak is worth that hefty price tag depends on who you ask. A Washington Post food critic once compared the beverage to stale Folgers, memorably describing the flavor as “petrified dinosaur droppings steeped in bathtub water.” Yet kopi luwak has many genuine fans who claim the coffee has a unique aroma and taste. Based on a new chemical analysis, they might have a point, according to a paper published in Scientific Reports. Technically, kopi luwak is a method of processing, not a specific coffee bean variety. Asian palm civets hang around coffee plantations because they love to feast on ripened coffee berries; the berries constitute most of their diet, along with various seeds. The consumed berries undergo fermentation as they pass through the animal’s intestines, and the civets digest the pulp and excrete the beans. Coffee farmers then collect the scat to recover the excreted beans and process and roast them to produce kopi luwak.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/civet2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/civet2-1152x648.jpg",
      "popularity_score": 268.032185,
      "ai_summary": [
        "Fans of kopi luwak claim it has a unique aroma and taste.",
        "A new chemical analysis supports the claims about the coffee.",
        "The analysis explores the chemistry behind the coffee's flavor.",
        "Kopi luwak is a pricey type of coffee.",
        "The study investigates the coffee's distinctive characteristics."
      ]
    },
    {
      "id": "cluster_103",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 14:28:19 +0000",
      "title": "Man accidentally gets leech up his nose. It took 20 days to figure it out.",
      "neutral_headline": "Man Finds Leech in Nose After Twenty Days",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/man-accidentally-gets-leech-up-his-nose-it-took-20-days-to-figure-it-out/",
          "published_at": "Wed, 29 Oct 2025 14:28:19 +0000",
          "title": "Man accidentally gets leech up his nose. It took 20 days to figure it out.",
          "standfirst": "Leeches have a long medical history. Here's what happens if one gets in your nose.",
          "content": "Since the dawn of civilization, leeches have been firmly attached to medicine. Therapeutic bloodsuckers are seen in murals decorating the tombs of 18th dynasty Egyptian pharaohs. They got their earliest written recommendation in the 2nd century BC by Greek poet and physician Nicander of Colophon. He introduced the “blood-loving leech, long flaccid and yearning for gore,” as a useful tool for sucking out poison after a bite from a poisonous animal. “Let leeches feed on [the] wounds and drink their fill,” he wrote. Ancient Chinese writing touted their medicinal potential, too, as did references in Sanskrit. Galen, the physician for Roman Emperor Marcus Aurelius, supported using leeches to balance the four humors (i.e. blood, phlegm, and yellow and black bile) and therefore treat ailments—as initially outlined by Hippocrates. Leeches, doctors found, provided a method for less painful, localized, and limited bloodletting. We now understand that leeches can release an anesthetic to prevent pain and a powerful anticoagulant, hirudin, to prevent clotting and keep blood flowing. In the centuries since the Roman era, leeches’ popularity only grew. They were used to treat everything from gout to liver disease, epilepsy, and melancholy. The very word “leech” is derived from the Anglo-Saxon word “laece,” which translates to “physician.”Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2220375814-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2220375814-1152x648.jpg",
      "popularity_score": 246.15440722222223,
      "ai_summary": [
        "A man accidentally got a leech up his nose.",
        "It took twenty days to figure out the cause of the problem.",
        "Leeches have a long history in medical practices.",
        "The article discusses what happens if a leech enters the nose.",
        "The incident highlights the potential for unusual medical cases."
      ]
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 12:23:08 +0000",
      "title": "NASA races to keep Artemis II on schedule, even when workers aren’t being paid",
      "neutral_headline": "NASA Races to Keep Artemis II on Schedule",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/nasa-races-to-keep-artemis-ii-on-schedule-even-when-workers-arent-being-paid/",
          "published_at": "Wed, 29 Oct 2025 12:23:08 +0000",
          "title": "NASA races to keep Artemis II on schedule, even when workers aren’t being paid",
          "standfirst": "\"I do think we're rapidly approaching the point where it will be a significant impact.\"",
          "content": "It has been nearly one month since many parts of the federal government shut down after lawmakers missed a budget deadline at the end of September, but so far, NASA’s most critical operations have been unaffected by the political impasse in Washington, DC. That may change soon. Federal civil servants and NASA contractors are not getting paid during the shutdown, even if agency leaders have deemed their tasks essential and directed them to continue working. Jobs classified as essential include employees operating and safeguarding the International Space Station and NASA’s fleet of robotic probes exploring the Solar System and beyond. Many employees at NASA’s Kennedy Space Center in Florida remain at work, too. Their job is to keep the Artemis II mission on schedule for launch as soon as next February. In the four weeks since the start of the government shutdown, crews at Kennedy Space Center have completed several major milestones on the road to Artemis II, including the stacking of the Orion spacecraft atop its Space Launch System rocket inside the cavernous Vehicle Assembly Building. This milestone, completed about one week ago, capped off assembly of the SLS rocket for Artemis II.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/KSC-20250807-PH-SNW01_0001orig-1152x648-1761709022.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/KSC-20250807-PH-SNW01_0001orig-1152x648-1761709022.jpg",
      "popularity_score": 155.06801833333333,
      "ai_summary": [
        "NASA is racing to keep Artemis II on schedule.",
        "Workers not being paid is impacting the project.",
        "The project is approaching a critical point of impact.",
        "The Artemis II mission is a priority for NASA.",
        "The financial issues are causing delays."
      ]
    },
    {
      "id": "cluster_133",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 22:38:46 +0000",
      "title": "Westinghouse is claiming a nuclear deal would see $80B of new reactors",
      "neutral_headline": "Westinghouse Claims Nuclear Deal for New Reactors",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/westinghouse-is-claiming-a-nuclear-deal-would-see-80b-of-new-reactors/",
          "published_at": "Tue, 28 Oct 2025 22:38:46 +0000",
          "title": "Westinghouse is claiming a nuclear deal would see $80B of new reactors",
          "standfirst": "Details are remarkably sparse on what has been agreed to.",
          "content": "On Tuesday, Westinghouse announced that it had reached an agreement with the Trump administration that would purportedly see $80 billion of new nuclear reactors built in the US. And the government indicated that it had finalized plans for a collaboration of GE Vernova and Hitachi to build additional reactors. Unfortunately, there are roughly zero details about the deal at the moment. The agreements were apparently negotiated during President Trump’s trip to Japan. An announcement of those agreements indicates that “Japan and various Japanese companies” would invest “up to” $332 billion for energy infrastructure. This specifically mentioned Westinghouse, GE Vernova, and Hitachi. This promises the construction of both large AP1000 reactors and small modular nuclear reactors. The announcement then goes on to indicate that many other companies would also get a slice of that “up to $332 billion,” many for basic grid infrastructure. So the total amount devoted to nuclear reactors is not specified in the announcement or anywhere else. As of the publication time, the Department of Energy has no information on the deal; Hitachi, GE Vernova, and the Hitachi/GE Vernova collaboration websites are also silent on it.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-526258466-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-526258466-1024x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Westinghouse claims a nuclear deal for $80 billion in new reactors.",
        "Details are remarkably sparse on what has been agreed to.",
        "The deal involves the construction of new nuclear reactors.",
        "The agreement is a significant development in the industry.",
        "The specifics of the deal are not yet fully disclosed."
      ]
    },
    {
      "id": "cluster_145",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 18:11:36 +0000",
      "title": "OpenAI data suggests 1 million users discuss suicide with ChatGPT weekly",
      "neutral_headline": "OpenAI Reports One Million Users Discuss Suicide Weekly",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/openai-data-suggests-1-million-users-discuss-suicide-with-chatgpt-weekly/",
          "published_at": "Tue, 28 Oct 2025 18:11:36 +0000",
          "title": "OpenAI data suggests 1 million users discuss suicide with ChatGPT weekly",
          "standfirst": "Sensitive chats are rare but significant given the large user base.",
          "content": "An AI language model like the kind that powers ChatGPT is a gigantic statistical web of data relationships. You give it a prompt (such as a question), and it provides a response that is statistically related and hopefully helpful. At first, ChatGPT was a tech amusement, but now hundreds of millions of people are relying on this statistical process to guide them through life’s challenges. It’s the first time in history that large numbers of people have begun to confide their feelings to a talking machine, and mitigating the potential harm the systems can cause has been an ongoing challenge. On Monday, OpenAI released data estimating that 0.15 percent of ChatGPT’s active users in a given week have conversations that include explicit indicators of potential suicidal planning or intent. It’s a tiny fraction of the overall user base, but with more than 800 million weekly active users, that translates to over a million people each week, reports TechCrunch. OpenAI also estimates that a similar percentage of users show heightened levels of emotional attachment to ChatGPT, and that hundreds of thousands of people show signs of psychosis or mania in their weekly conversations with the chatbot.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_therapy_1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_therapy_1-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "OpenAI data indicates approximately one million users engage in suicide-related discussions weekly with ChatGPT.",
        "Sensitive conversations are infrequent, but the large user base makes them statistically significant.",
        "The company is working to improve safety protocols and mitigate potential harms.",
        "OpenAI is actively monitoring and analyzing user interactions to identify concerning trends.",
        "The company is committed to responsible AI development and user well-being."
      ]
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 03:30:56 +0000",
      "title": "Mazda shows a rotary hybrid concept for Tokyo with evolved design language",
      "neutral_headline": "Mazda Unveils Rotary Hybrid Concept at Tokyo Motor Show",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/mazda-shows-a-rotary-hybrid-concept-for-tokyo-with-evolved-design-language/",
          "published_at": "Wed, 29 Oct 2025 03:30:56 +0000",
          "title": "Mazda shows a rotary hybrid concept for Tokyo with evolved design language",
          "standfirst": "Ideas include algae-based fuels and capturing carbon from the exhaust while driving.",
          "content": "The Japan Mobility Show kicks off in Tokyo this week, and Mazda is using the occasion to show off a couple of concepts it says embody a theme called “the joy of driving fuels a sustainable tomorrow.” One of these is the Vision X-Coupe, which Mazda says shows off the evolution of its KODO design language—something we first saw at the Tokyo show a decade ago. You can see a clear visual link between the renderings of the Vision X-Coupe and some of Mazda’s current models like the 3 hatchback or the CX-30 crossover, but translated through the long, low form factor of a four-door coupe. The design language is perhaps less interesting than some of the sustainability ideas that Mazda is exploring here, though. There's definitely hints of the Mazda RX-Vision in this shape. Credit: Mazda It's a four-seat, four-door coupe. Credit: Mazda Fun to drive AND sustainable? Sign us up. Credit: Mazda The powertrain is a 503 hp (375 kW) plug-in hybrid that uses a two-rotor turbocharged rotary engine as the internal combustion part of the equation. Mazda says it should have a total range of 500 miles (800 km), with a range of 100 miles (160 km) on battery power alone.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/MAZDA_VISION_MODEL_3-X-COUPE-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/MAZDA_VISION_MODEL_3-X-COUPE-1152x648.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "Mazda showcased a rotary hybrid concept at the Tokyo Motor Show with evolved design.",
        "The concept explores algae-based fuels and carbon capture from exhaust.",
        "The design language hints at future Mazda vehicle aesthetics.",
        "Mazda continues to explore sustainable technologies for its vehicles.",
        "The concept demonstrates Mazda's commitment to innovation and environmental responsibility."
      ]
    },
    {
      "id": "cluster_108",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 13:40:15 +0000",
      "title": "New physical attacks are quickly diluting secure enclave defenses from Nvidia, AMD, and Intel",
      "neutral_headline": "New Physical Attacks Compromise Secure Enclave Defenses",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/new-physical-attacks-are-quickly-diluting-secure-enclave-defenses-from-nvidia-amd-and-intel/",
          "published_at": "Wed, 29 Oct 2025 13:40:15 +0000",
          "title": "New physical attacks are quickly diluting secure enclave defenses from Nvidia, AMD, and Intel",
          "standfirst": "On-chip TEEs withstand rooted OSes but fall instantly to cheap physical attacks.",
          "content": "Trusted execution environments, or TEEs, are everywhere—in blockchain architectures, virtually every cloud service, and computing involving AI, finance, and defense contractors. It’s hard to overstate the reliance that entire industries have on three TEEs in particular: Confidential Compute from Nvidia, SEV-SNP from AMD, and SGX and TDX from Intel. All three come with assurances that confidential data and sensitive computing can’t be viewed or altered, even if a server has suffered a complete compromise of the operating kernel. A trio of novel physical attacks raises new questions about the true security offered by these TEES and the exaggerated promises and misconceptions coming from the big and small players using them. The most recent attack, released Tuesday, is known as TEE.fail. It defeats the latest TEE protections from all three chipmakers. The low-cost, low-complexity attack works by placing a small piece of hardware between a single physical memory chip and the motherboard slot it plugs into. It also requires the attacker to compromise the operating system kernel. Once this three-minute attack is completed, Confidential Compute, SEV-SNP, and TDX/SDX can no longer be trusted. Unlike the Battering RAM and Wiretap attacks from last month—which worked only against CPUs using DDR4 memory—TEE.fail works against DDR5, allowing them to work against the latest TEEs.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/cpu-key-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/cpu-key-1152x648.jpg",
      "popularity_score": 135.35329611111112,
      "ai_summary": [
        "New physical attacks are quickly bypassing secure enclave defenses from Nvidia, AMD, and Intel.",
        "On-chip Trusted Execution Environments (TEEs) resist rooted operating systems.",
        "Cheap physical attacks instantly defeat on-chip TEE security measures.",
        "Researchers are actively working to improve the security of these systems.",
        "The attacks highlight vulnerabilities in hardware-based security solutions."
      ]
    },
    {
      "id": "cluster_138",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 19:12:29 +0000",
      "title": "If things in America weren’t stupid enough, Texas is suing Tylenol maker",
      "neutral_headline": "Texas Sues Tylenol Maker Over Autism Claims",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/if-things-in-america-werent-stupid-enough-texas-is-suing-tylenol-maker/",
          "published_at": "Tue, 28 Oct 2025 19:12:29 +0000",
          "title": "If things in America weren’t stupid enough, Texas is suing Tylenol maker",
          "standfirst": "Texas sues Tylenol maker over unproven claim the pain medicine causes autism.",
          "content": "While the underlying cause or causes of autism spectrum disorder remain elusive and appear likely to be a complex interplay of genetic and environmental factors, President Trump and his anti-vaccine health secretary Robert F. Kennedy Jr.—neither of whom have any scientific or medical background whatsoever—have decided to pin the blame on Tylenol, a common pain reliever and fever reducer that has no proven link to autism. And now, Texas Attorney General Ken Paxton is suing the maker of Tylenol, Kenvue and Johnson & Johnson, who previously sold Tylenol, claiming that they have been “deceptively marketing Tylenol” knowing that it “leads to a significantly increased risk of autism and other disorders.” To back that claim, Paxton relies on the “considerable body of evidence… recently highlighted by the Trump Administration.”Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2150327872-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2150327872-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Texas is suing the Tylenol maker, alleging the pain medicine causes autism.",
        "The lawsuit is based on an unproven claim regarding the link between Tylenol and autism.",
        "The scientific community has not established a definitive connection between the two.",
        "The lawsuit is likely to face legal challenges due to the lack of scientific evidence.",
        "The case highlights the ongoing debate surrounding the safety of medications."
      ]
    },
    {
      "id": "cluster_143",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 18:30:32 +0000",
      "title": "An autonomous car for consumers? Lucid says it’s happening.",
      "neutral_headline": "Lucid Announces Plans for Autonomous Consumer Cars",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/an-autonomous-car-for-consumers-lucid-says-its-happening/",
          "published_at": "Tue, 28 Oct 2025 18:30:32 +0000",
          "title": "An autonomous car for consumers? Lucid says it’s happening.",
          "standfirst": "Nvidia is working with Lucid on autonomous cars and future factories.",
          "content": "Is it possible to be a CEO in 2025 and not catch a case of AI fever? The latest company to catch this particular cold is Lucid, the Saudi-backed electric vehicle startup. Today, it announced a new collaboration with Nvidia to use the latter’s hardware and software, with the aim of creating an autonomous vehicle for consumers. Oh, and the AI will apparently design Lucid’s production lines. Formed by refugees from Tesla who saw a chance to improve on their past work, Lucid has already built the most efficient EV on sale in North America. But until recently, it also just had variants of the same Air sedan to offer consumers, before the Gravity SUV joined the range this year. The company will need to start selling tens of thousands of EVs a year before too long, especially if it’s ever to become profitable. And that will involve some smaller, cheaper models, starting with a midsize crossover sometime in 2027. A major goal for the first of those EVs is a starting price of less than $50,000, so I hope they’re getting a good deal on the Nvidia GPUs that Lucid now says will enable a “true eyes-off, hands-off, and mind-off” autonomous driving system for consumer-owned vehicles.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/EMBARGO_Lucid_NVIDIA-GTC_IMAGE-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/EMBARGO_Lucid_NVIDIA-GTC_IMAGE-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Lucid states it is developing autonomous cars for consumer markets.",
        "Nvidia is collaborating with Lucid on autonomous vehicle technology.",
        "Nvidia is also involved in Lucid's future factory development.",
        "The partnership aims to accelerate the production of autonomous vehicles.",
        "The announcement signals a move towards self-driving technology for consumers."
      ]
    },
    {
      "id": "cluster_144",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 18:28:51 +0000",
      "title": "Senators move to keep Big Tech’s creepy companion bots away from kids",
      "neutral_headline": "Senators Seek to Regulate Big Tech's Companion Bots",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/senators-move-to-keep-big-techs-creepy-companion-bots-away-from-kids/",
          "published_at": "Tue, 28 Oct 2025 18:28:51 +0000",
          "title": "Senators move to keep Big Tech’s creepy companion bots away from kids",
          "standfirst": "Big Tech immediately opposed the proposed law as \"heavy-handed.\"",
          "content": "The US will weigh a ban on children’s access to companion bots, as two senators announced bipartisan legislation Tuesday that would criminalize making chatbots that encourage harms like suicidal ideation or engage kids in sexually explicit chats. At a press conference, Josh Hawley (R-Mo.) and Richard Blumenthal (D-Conn.) introduced the GUARD Act, joined by grieving parents holding up photos of their children lost after engaging with chatbots. If passed, the law would require chatbot makers to check IDs or use “any other commercially reasonable method” to accurately assess if a user is a minor who must be blocked. Companion bots would also have to repeatedly remind users of all ages that they aren’t real humans or trusted professionals.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1285352680-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Senators are proposing legislation to regulate Big Tech's companion bots for children.",
        "The proposed law aims to protect children from potentially harmful interactions.",
        "Big Tech companies immediately opposed the proposed legislation.",
        "Concerns exist regarding the impact of these bots on children's development.",
        "The debate highlights the ethical considerations of AI companions for children."
      ]
    },
    {
      "id": "cluster_146",
      "coverage": 1,
      "updated_at": "Tue, 28 Oct 2025 18:10:18 +0000",
      "title": "Samsung makes ads on $3,499 smart fridges official with upcoming software update",
      "neutral_headline": "Samsung to Introduce Ads on Smart Fridges",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/samsung-makes-ads-on-3499-smart-fridges-official-with-upcoming-software-update/",
          "published_at": "Tue, 28 Oct 2025 18:10:18 +0000",
          "title": "Samsung makes ads on $3,499 smart fridges official with upcoming software update",
          "standfirst": "Update introduces two ways for the fridges to show ads.",
          "content": "After kicking off an unpopular pilot test last month, Samsung made the practice of having its expensive smart fridges display ads official this week. The ads will be shown on Samsung’s 2024 Family Hub smart fridges. As of this writing, Samsung’s Family Hub fridges have MSRPs ranging from $1,899 to $3,499. The ads will arrive through a software update that Samsung will start issuing this month and display on the fridge’s integrated 21.5- or 32-inch (depending on the model) screen. The ads will show when the fridges are idle and display what Samsung calls Cover Screens. As part of the Family Hub software update, we are piloting a new widget for select Cover Screens themes of Family Hub refrigerators. The widget will display useful day-to-day information such as news, calendar and weather forecasts, along with curated advertisements. Samsung also said that its fridges will only show contextualized ads, instead of personalized ads, which rely on collecting data on users.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Samsung.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Samsung.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Samsung will officially introduce advertisements on its smart fridges.",
        "The software update will provide two methods for displaying ads.",
        "The ads will be integrated into the fridge's user interface.",
        "The move is part of Samsung's strategy to monetize its smart appliances.",
        "The update will likely raise privacy concerns among consumers."
      ]
    }
  ]
}