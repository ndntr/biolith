{
  "updated_at": "2026-01-06T04:01:37.806Z",
  "clusters": [
    {
      "id": "cluster_46",
      "coverage": 3,
      "updated_at": "Mon, 05 Jan 2026 19:00:41 -0500",
      "title": "Boston Dynamics partners with Google DeepMind to integrate Gemini Robotics models into Atlas robots, boosting their object-manipulation capabilities and more (Will Knight/Wired)",
      "neutral_headline": "Boston Dynamics&#8217; next-gen humanoid robot will have Google DeepMind DNA",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260105/p31#a260105p31",
          "published_at": "Mon, 05 Jan 2026 19:00:41 -0500",
          "title": "Boston Dynamics partners with Google DeepMind to integrate Gemini Robotics models into Atlas robots, boosting their object-manipulation capabilities and more (Will Knight/Wired)",
          "standfirst": "Will Knight / Wired: Boston Dynamics partners with Google DeepMind to integrate Gemini Robotics models into Atlas robots, boosting their object-manipulation capabilities and more &mdash; Google DeepMind and Boston Dynamics are teaming up to integrate Gemini into a humanoid robot called Atlas.",
          "content": "Will Knight / Wired: Boston Dynamics partners with Google DeepMind to integrate Gemini Robotics models into Atlas robots, boosting their object-manipulation capabilities and more &mdash; Google DeepMind and Boston Dynamics are teaming up to integrate Gemini into a humanoid robot called Atlas.",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/260105/i31.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/05/boston-dynamicss-next-gen-humanoid-robot-will-have-google-deepmind-dna/",
          "published_at": "Mon, 05 Jan 2026 21:55:55 +0000",
          "title": "Boston Dynamics&#8217; next-gen humanoid robot will have Google DeepMind DNA",
          "standfirst": "Google's AI research lab is working with Boston Dynamics to make Atlas act more like a human.",
          "content": "Google's AI research lab is working with Boston Dynamics to make Atlas act more like a human.",
          "feed_position": 6
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/google-boston-dynamics-gemini-powered-robot-atlas/",
          "published_at": "Mon, 05 Jan 2026 21:00:00 +0000",
          "title": "Google Gemini Is Taking Control of Humanoid Robots on Auto Factory Floors",
          "standfirst": "Google DeepMind and Boston Dynamics are teaming up to integrate Gemini into a humanoid robot called Atlas.",
          "content": "Google DeepMind and Boston Dynamics are teaming up to integrate Gemini into a humanoid robot called Atlas.",
          "feed_position": 1,
          "image_url": "https://media.wired.com/photos/695c067688c4535fb1546355/master/pass/Googles-AI-Taking-Control-of-Humanoids-On-Auto-Factory-Floor-Business-YT-Pre-Launch-Thumbnail.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260105/i31.jpg",
      "popularity_score": 3015.9842205555556
    },
    {
      "id": "cluster_3",
      "coverage": 2,
      "updated_at": "Tue, 06 Jan 2026 03:50:30 +0000",
      "title": "XGIMI, best known for projectors, launches its own smart glasses",
      "neutral_headline": "XGIMI, best known for projectors, launches its own smart glasses",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/xgimi-best-known-for-projectors-launches-its-own-smart-glasses-170000968.html",
          "published_at": "Tue, 06 Jan 2026 03:50:30 +0000",
          "title": "XGIMI, best known for projectors, launches its own smart glasses",
          "standfirst": "Projector maker XGIMI has turned up at CES to launch its own range of AR glasses, but don’t get the champagne out too soon. MemoMind is a new brand under which its AI-infused eyewear will be sold, with two distinct units arriving at some point in the near future. The company says it has leveraged its know-how in optics and engineering to produce glasses which are unobtrusively light, all the better for blending into your daily life. Fashionistas will even be overjoyed to learn the glasses’ ship in eight different frame styles, five different temple designs and can be worn with prescription lenses. Memo One is the company’s flagship option, with dual-eye displays and integrated speakers so you can see and hear your AI assistant. The Memo Air, meanwhile, is a more stripped down model weighing just 28.9 grams which just has a single eye display. Unfortunately, the company is using microLED displays rather than waveguides, making them a far harder sell for a lot of would-be users. After all, putting something that small so close to your eye but behind your prescription means it’s a painful experience for short sighted folks to focus on text. As I explained in my Halliday review, this technology is no friend to the glasses wearers who would otherwise be the ideal early adopters.Update Jan 5, 2026: I have never been so happy to post an update, as I have now seen these in person and learned that they do not use microLED displays. In fact, they do use waveguides, making them a lot more attractive than I had initially thought. In fact, the glasses they remind me the most of is Even Realities’ G1, which I reviewed and absolutely loved.MemoMind LineupXGIMIThe glasses are just a vehicle for the company’s AI assistant, promising translation, summarization, note-taking, reminders and contextual guidance. Unlike some of its would-be rivals, XGIMI says its platform will switch between OpenAI, Azure and (Alibaba’s) Qwen depending on what it thinks will offer you the best result for each task. Naturally, we’ll need to get them in to test before passing final judgment on their qualities but, you can color us naturally hostile to those damn microLEDs until we’re convinced otherwise.XGIMI says the flagship Memo One will be available to pre-order “soon,” priced at $599, with additional models available further down the line. This article originally appeared on Engadget at https://www.engadget.com/wearables/xgimi-best-known-for-projectors-launches-its-own-smart-glasses-170000968.html?src=rss",
          "content": "Projector maker XGIMI has turned up at CES to launch its own range of AR glasses, but don’t get the champagne out too soon. MemoMind is a new brand under which its AI-infused eyewear will be sold, with two distinct units arriving at some point in the near future. The company says it has leveraged its know-how in optics and engineering to produce glasses which are unobtrusively light, all the better for blending into your daily life. Fashionistas will even be overjoyed to learn the glasses’ ship in eight different frame styles, five different temple designs and can be worn with prescription lenses. Memo One is the company’s flagship option, with dual-eye displays and integrated speakers so you can see and hear your AI assistant. The Memo Air, meanwhile, is a more stripped down model weighing just 28.9 grams which just has a single eye display. Unfortunately, the company is using microLED displays rather than waveguides, making them a far harder sell for a lot of would-be users. After all, putting something that small so close to your eye but behind your prescription means it’s a painful experience for short sighted folks to focus on text. As I explained in my Halliday review, this technology is no friend to the glasses wearers who would otherwise be the ideal early adopters.Update Jan 5, 2026: I have never been so happy to post an update, as I have now seen these in person and learned that they do not use microLED displays. In fact, they do use waveguides, making them a lot more attractive than I had initially thought. In fact, the glasses they remind me the most of is Even Realities’ G1, which I reviewed and absolutely loved.MemoMind LineupXGIMIThe glasses are just a vehicle for the company’s AI assistant, promising translation, summarization, note-taking, reminders and contextual guidance. Unlike some of its would-be rivals, XGIMI says its platform will switch between OpenAI, Azure and (Alibaba’s) Qwen depending on what it thinks will offer you the best result for each task. Naturally, we’ll need to get them in to test before passing final judgment on their qualities but, you can color us naturally hostile to those damn microLEDs until we’re convinced otherwise.XGIMI says the flagship Memo One will be available to pre-order “soon,” priced at $599, with additional models available further down the line. This article originally appeared on Engadget at https://www.engadget.com/wearables/xgimi-best-known-for-projectors-launches-its-own-smart-glasses-170000968.html?src=rss",
          "feed_position": 0,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/20251218-110941_%281%29.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/alienware-teases-new-super-slim-and-entry-level-gaming-laptops-at-ces-2026-033000700.html",
          "published_at": "Tue, 06 Jan 2026 03:30:00 +0000",
          "title": "Alienware teases new super-slim and entry-level gaming laptops at CES 2026",
          "standfirst": "After relaunching its Area-51 brand with a new 16-inch laptop in 2025, Alienware is teasing two new laptops at CES 2026 in an attempt to reach an even larger audience. Dell's gaming brand plans to launch both entry-level and ultra-slim models later this year, and in the meantime, it's rolling out updates to its existing desktops and laptops to tide people over.Alienware isn't sharing all the details of its new laptops at CES, but we do have the highlights. The company's new \"ultra-slim gaming laptop\" will be around 17mm or 0.67 inches thin, and come in either 14-inch or 16-inch variants. While the 16-inch version of the laptop will feature NVIDIA discrete graphics and \"new highly efficient CPUs,\" it's not meant to be a gaming powerhouse like the Area-51. Instead, Alienware suggests the laptop will work for gaming and also \"creative projects, productivity and everything in between.\"The entry-level laptop is similarly not at Area-51-levels of power, but Alienware claims it'll deliver \"strong gaming performance\" at its \"most accessible price point yet.\" That should ideally put the new laptop under the $1,199 starting price of the more streamlined Alienware 16 Aurora laptop.The Alienware Area-51 Desktop will get updated with the latest AMD chips in February 2026.DellOn top of those two new models, Alienware is bringing new anti-glare OLED panels to a selection of its Alienware 16X Aurora and Alienware 16 Area-51 laptops, along with new Intel Core Ultra 200HX chips. The new display panels reach 620 nits of peak HDR brightness and have a 0.2ms response time for even smoother gameplay. The Alienware 18 Area-51 is also getting an upgrade to Intel Core Ultra 200HX chips, while the Alienware Area-51 Desktop will ship with AMD's new Ryzen 7 9850X3D chips.There's currently no pricing available for Alienware's new laptops, or the updated versions of its older models. The updated Alienware 16X Aurora, Alienware 16 Area-51, and Alienware 18 Area-51 laptops will be available in Q1 2026. The update Alienware Area-51 Desktop is coming in February 2026.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/alienware-teases-new-super-slim-and-entry-level-gaming-laptops-at-ces-2026-033000700.html?src=rss",
          "content": "After relaunching its Area-51 brand with a new 16-inch laptop in 2025, Alienware is teasing two new laptops at CES 2026 in an attempt to reach an even larger audience. Dell's gaming brand plans to launch both entry-level and ultra-slim models later this year, and in the meantime, it's rolling out updates to its existing desktops and laptops to tide people over.Alienware isn't sharing all the details of its new laptops at CES, but we do have the highlights. The company's new \"ultra-slim gaming laptop\" will be around 17mm or 0.67 inches thin, and come in either 14-inch or 16-inch variants. While the 16-inch version of the laptop will feature NVIDIA discrete graphics and \"new highly efficient CPUs,\" it's not meant to be a gaming powerhouse like the Area-51. Instead, Alienware suggests the laptop will work for gaming and also \"creative projects, productivity and everything in between.\"The entry-level laptop is similarly not at Area-51-levels of power, but Alienware claims it'll deliver \"strong gaming performance\" at its \"most accessible price point yet.\" That should ideally put the new laptop under the $1,199 starting price of the more streamlined Alienware 16 Aurora laptop.The Alienware Area-51 Desktop will get updated with the latest AMD chips in February 2026.DellOn top of those two new models, Alienware is bringing new anti-glare OLED panels to a selection of its Alienware 16X Aurora and Alienware 16 Area-51 laptops, along with new Intel Core Ultra 200HX chips. The new display panels reach 620 nits of peak HDR brightness and have a 0.2ms response time for even smoother gameplay. The Alienware 18 Area-51 is also getting an upgrade to Intel Core Ultra 200HX chips, while the Alienware Area-51 Desktop will ship with AMD's new Ryzen 7 9850X3D chips.There's currently no pricing available for Alienware's new laptops, or the updated versions of its older models. The updated Alienware 16X Aurora, Alienware 16 Area-51, and Alienware 18 Area-51 laptops will be available in Q1 2026. The update Alienware Area-51 Desktop is coming in February 2026.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/alienware-teases-new-super-slim-and-entry-level-gaming-laptops-at-ces-2026-033000700.html?src=rss",
          "feed_position": 1,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Alienware-Area-51-Desktop-AMD-chips.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/amds-new-ryzen-ai-max-chips-and-ryzen-7-9850x3d-court-desktop-enthusiasts-at-ces-2026-033000587.html",
          "published_at": "Tue, 06 Jan 2026 03:30:00 +0000",
          "title": "AMD's new Ryzen AI Max+ chips and Ryzen 7 9850X3D court desktop enthusiasts at CES 2026",
          "standfirst": "While it's nice to see desktop support in AMD's new Ryzen AI 400 chips, demanding gamers and enthusiasts will likely be more intrigued by the company's next batch of Ryzen AI Max+ chips, as well as the new Ryzen 7 9850X3D with 3D V-Cache. The former will make its way into small desktops and a handful of workhorse laptops, while the latter is another option for gamers who want the speed bump of 3D V-cache without shelling out for the $700 9950X3D. Last year, AMD debuted its Ryzen AI Max chips as a way to create a single piece of silicon with powerful CPU cores, GPU cores, NPUs and integrated memory, similar to Apple's home-brewed chips. At the time, AMD VP Joe Macri also noted that the existence of Apple Silicon helped make the Ryzen AI Max chips possible. \"Many people in the PC industry said, well, if you want graphics, it's gotta be discrete graphics because otherwise people will think it's bad graphics,\" Macri said at last year's CES. \"What Apple showed was consumers don't care what's inside the box. They actually care what the what the box looks like. They care about the screen, the keyboard, the mouse. They care about what it does.\"AMD Ryzen AI Max+ chip familyAMDAt CES this year, AMD is unveiled the 12-core Ryzen AI Max+ 392 and eight-core Ryzen AI Max+ 388. Both chips feature boost speeds up to 5GHz, 50 TOPS NPUs and GPUs capable of 60 TFLOPs. We've seen the earlier Ryzen AI Max chips in the Framework Desktop and the ROG Flow Z13, and we were generally impressed with its performance. For small systems, it was powerful enough that we really didn't miss having dedicated GPUs.AMD Ryzen 7 9000X3DAMDAs for the Ryzen 7 9850X3D, it's an 8-core chip that can reach up to 5.6GHz boost speeds with 104MB of combined L2 and L3 cache. Like all of AMD's X3D chips, it uses 3D V-cache technology to vertically stack additional cache memory. In comparison, the standard 9850HX chip has 76MB of L2 and L3 cache.AMD says the new Ryzen AI Max+ chips and the 9850X3D will ship in the first quarter. There's no pricing information on the latter, yet, but recent leaked listings suggest it may go for around $200. Rumors also point to a massive dual-cache (192MB!) 9950X3D2 chip coming soon.This article originally appeared on Engadget at https://www.engadget.com/computing/amds-new-ryzen-ai-max-chips-and-ryzen-7-9850x3d-court-desktop-enthusiasts-at-ces-2026-033000587.html?src=rss",
          "content": "While it's nice to see desktop support in AMD's new Ryzen AI 400 chips, demanding gamers and enthusiasts will likely be more intrigued by the company's next batch of Ryzen AI Max+ chips, as well as the new Ryzen 7 9850X3D with 3D V-Cache. The former will make its way into small desktops and a handful of workhorse laptops, while the latter is another option for gamers who want the speed bump of 3D V-cache without shelling out for the $700 9950X3D. Last year, AMD debuted its Ryzen AI Max chips as a way to create a single piece of silicon with powerful CPU cores, GPU cores, NPUs and integrated memory, similar to Apple's home-brewed chips. At the time, AMD VP Joe Macri also noted that the existence of Apple Silicon helped make the Ryzen AI Max chips possible. \"Many people in the PC industry said, well, if you want graphics, it's gotta be discrete graphics because otherwise people will think it's bad graphics,\" Macri said at last year's CES. \"What Apple showed was consumers don't care what's inside the box. They actually care what the what the box looks like. They care about the screen, the keyboard, the mouse. They care about what it does.\"AMD Ryzen AI Max+ chip familyAMDAt CES this year, AMD is unveiled the 12-core Ryzen AI Max+ 392 and eight-core Ryzen AI Max+ 388. Both chips feature boost speeds up to 5GHz, 50 TOPS NPUs and GPUs capable of 60 TFLOPs. We've seen the earlier Ryzen AI Max chips in the Framework Desktop and the ROG Flow Z13, and we were generally impressed with its performance. For small systems, it was powerful enough that we really didn't miss having dedicated GPUs.AMD Ryzen 7 9000X3DAMDAs for the Ryzen 7 9850X3D, it's an 8-core chip that can reach up to 5.6GHz boost speeds with 104MB of combined L2 and L3 cache. Like all of AMD's X3D chips, it uses 3D V-cache technology to vertically stack additional cache memory. In comparison, the standard 9850HX chip has 76MB of L2 and L3 cache.AMD says the new Ryzen AI Max+ chips and the 9850X3D will ship in the first quarter. There's no pricing information on the latter, yet, but recent leaked listings suggest it may go for around $200. Rumors also point to a massive dual-cache (192MB!) 9950X3D2 chip coming soon.This article originally appeared on Engadget at https://www.engadget.com/computing/amds-new-ryzen-ai-max-chips-and-ryzen-7-9850x3d-court-desktop-enthusiasts-at-ces-2026-033000587.html?src=rss",
          "feed_position": 2,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Screenshot_2026-01-05_at_9.32.47%E2%80%AFAM.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/amds-ryzen-ai-400-chips-are-a-big-boost-for-laptops-and-desktops-alike-033000635.html",
          "published_at": "Tue, 06 Jan 2026 03:30:00 +0000",
          "title": "AMD's Ryzen AI 400 chips are a big boost for laptops and desktops alike",
          "standfirst": "The whole AI PC trend didn't exactly set the world on fire last year, but, like clockwork, AMD is still ready to deliver a new batch of AI chips at CES 2026. The Ryzen AI 400 processors will offer some slight speed upgrades over last year's chips, and notably, they also include AMD's first Copilot+ processors for desktops. Sure, the Copilot+ program didn't really go anywhere, but as I've argued, it at least served as a template for building capable AI PCs. Now we just need some genuinely useful AI features in Windows — Recall and Copilot's voice commands aren't really compelling enough on their own.AMD's first AI desktop chips, the Ryzen 8000G series, arrived in 2024 with relatively underpowered neural processing units (NPUs) for AI tasks. The Ryzen AI 400 chips, on the other hand, feature 60 TOPS XDNA 2 NPUs (up from the 50 to 55 TOPS in Ryzen AI 300 hardware). That places them well above the 40 TOPS NPU minimum for Copilot+ systems. For most consumers, NPU speeds don't really mean much yet, but if you're running AI models on your system you can expect slightly faster inferencing from AMD's previous chips.AMD Ryzen AI 400 chipsAMDThe top-end Ryzen AI 9 HX 475 offers up to 12 Zen 5 CPU cores, 5.2GHz max boost speeds and up to 8,533 MT/s memory speeds. The line scales down to the four-core Ryzen AI 5 430, but even that model supports speedy 8,000 MTS RAM and offers a 50 TOPS NPU.AMD isn't giving us many specific details on the Ryzen AI 400 chips at CES, but broadly, it claims they'll offer up to 30 percent faster multi-tasking, 70 percent faster content creation and 10 percent faster gaming than its previous chips. The company also says you'll see 70 percent better \"unplugged connectivity\" on Cinebench nT, which is hopefully a sign that you'll see improved performance overall on battery.This article originally appeared on Engadget at https://www.engadget.com/computing/amds-ryzen-ai-400-chips-are-a-big-boost-for-laptops-and-desktops-alike-033000635.html?src=rss",
          "content": "The whole AI PC trend didn't exactly set the world on fire last year, but, like clockwork, AMD is still ready to deliver a new batch of AI chips at CES 2026. The Ryzen AI 400 processors will offer some slight speed upgrades over last year's chips, and notably, they also include AMD's first Copilot+ processors for desktops. Sure, the Copilot+ program didn't really go anywhere, but as I've argued, it at least served as a template for building capable AI PCs. Now we just need some genuinely useful AI features in Windows — Recall and Copilot's voice commands aren't really compelling enough on their own.AMD's first AI desktop chips, the Ryzen 8000G series, arrived in 2024 with relatively underpowered neural processing units (NPUs) for AI tasks. The Ryzen AI 400 chips, on the other hand, feature 60 TOPS XDNA 2 NPUs (up from the 50 to 55 TOPS in Ryzen AI 300 hardware). That places them well above the 40 TOPS NPU minimum for Copilot+ systems. For most consumers, NPU speeds don't really mean much yet, but if you're running AI models on your system you can expect slightly faster inferencing from AMD's previous chips.AMD Ryzen AI 400 chipsAMDThe top-end Ryzen AI 9 HX 475 offers up to 12 Zen 5 CPU cores, 5.2GHz max boost speeds and up to 8,533 MT/s memory speeds. The line scales down to the four-core Ryzen AI 5 430, but even that model supports speedy 8,000 MTS RAM and offers a 50 TOPS NPU.AMD isn't giving us many specific details on the Ryzen AI 400 chips at CES, but broadly, it claims they'll offer up to 30 percent faster multi-tasking, 70 percent faster content creation and 10 percent faster gaming than its previous chips. The company also says you'll see 70 percent better \"unplugged connectivity\" on Cinebench nT, which is hopefully a sign that you'll see improved performance overall on battery.This article originally appeared on Engadget at https://www.engadget.com/computing/amds-ryzen-ai-400-chips-are-a-big-boost-for-laptops-and-desktops-alike-033000635.html?src=rss",
          "feed_position": 3,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Screenshot_2026-01-05_at_9.06.28%E2%80%AFAM.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/hps-eliteboard-made-me-believe-in-keyboard-computers-again-033000955.html",
          "published_at": "Tue, 06 Jan 2026 03:30:00 +0000",
          "title": "HP's EliteBoard made me believe in keyboard computers again",
          "standfirst": "For as long as I can remember, I've always wanted to have a keyboard computer -- that is, a computer where the entire machine was stuffed inside of a keyboard. Maybe I caught a glimpse of the Commodore 64 at an impressionable age, but for whatever reason, the idea has always intrigued me. Now HP is bringing the concept back with its new EliteBoard G1a \"Next Gen AI PC.\" It's an IT administrator's dream: It looks a typical desktop keyboard, but it has the full power of a Copilot+ AI PC inside. You can equip it with Ryzen 5 or 7 CPUs and their embedded Radeon 800 GPUs, up to 64GB of RAM and as much as 2TB of NVMe SSD storage. All you need to do is add a monitor and a mouse, and you've got a full-fledged desktop setup.HP EliteBoard keyboard PC.Devindra Hardawar for EngadgetThe more I think about it, the more sad I am that the arc of the computing industry trended towards standardized desktops and laptops. There was a brief spark of interest with the UMPC (ultra mobile PC) trend in the 2000's, which Engadget covered extensively as a young blog, as well as ASUS's Eee keyboard. But they couldn't survive the rise of the smartphone and tablet. It turns out putting an entire computer behind a screen was more compelling than stuffing them into a keyboard. I was able to test out an early EliteBoard prototype, and while the experience wasn't perfect, it's still an intriguing computing option. I had trouble setting it up initially because it only had two USB-C ports on its rear, which meant I had to find a way to power it through one port and pass a video signal through the other. Thankfully, my Anker USB-C charging hub was able to juice it up, and I also had a USB-C hub with an HDMI port, which allowed me to connect to my monitor.Sadly, the overall setup was a jumble of wires, and not the clean layout I expected from a keyboard PC. Once I was able to start up Windows though, I was less annoyed and more amazed that the keyboard contained an entire computer. I suppose I shouldn't be too surprised, as Intel's Compute Stick placed a functional PC in a much smaller case, but unlike the failed product, the EliteBoard actually felt usable. I was able to load up several browser windows with tabs, edit a few photos and even play a few light games, like Vampire Survivors. And yes, typing on it felt pretty great too.HP EliteBoard keyboard PC.Devindra Hardawar for EngadgetSince I was testing out prototype hardware, I agreed not to benchmark the EliteBoard. But from the performance I saw, it felt about the same an entry-level laptop. Basically, it's perfectly suited to its main task: Being a boring office computer. Back in my IT days, I certainly would have preferred deploying a few light keyboards instead of the tank-like Dell desktops we typically ordered.While the EliteBoard is targeted at commercial users, HP is considering it an experiment to see how people respond to a keyboard PC. There's a chance we could see one that's eventually meant for mainstream consumers. I'm not sure if that's exactly, necessary, though. The whole concept of a desktop PC mainly appeals to tinkerers and IT folks. And for anyone who wants to get their hands on an EliteBoard soon, there's really nothing stopping you.This article originally appeared on Engadget at https://www.engadget.com/computing/hps-eliteboard-made-me-believe-in-keyboard-computers-again-033000955.html?src=rss",
          "content": "For as long as I can remember, I've always wanted to have a keyboard computer -- that is, a computer where the entire machine was stuffed inside of a keyboard. Maybe I caught a glimpse of the Commodore 64 at an impressionable age, but for whatever reason, the idea has always intrigued me. Now HP is bringing the concept back with its new EliteBoard G1a \"Next Gen AI PC.\" It's an IT administrator's dream: It looks a typical desktop keyboard, but it has the full power of a Copilot+ AI PC inside. You can equip it with Ryzen 5 or 7 CPUs and their embedded Radeon 800 GPUs, up to 64GB of RAM and as much as 2TB of NVMe SSD storage. All you need to do is add a monitor and a mouse, and you've got a full-fledged desktop setup.HP EliteBoard keyboard PC.Devindra Hardawar for EngadgetThe more I think about it, the more sad I am that the arc of the computing industry trended towards standardized desktops and laptops. There was a brief spark of interest with the UMPC (ultra mobile PC) trend in the 2000's, which Engadget covered extensively as a young blog, as well as ASUS's Eee keyboard. But they couldn't survive the rise of the smartphone and tablet. It turns out putting an entire computer behind a screen was more compelling than stuffing them into a keyboard. I was able to test out an early EliteBoard prototype, and while the experience wasn't perfect, it's still an intriguing computing option. I had trouble setting it up initially because it only had two USB-C ports on its rear, which meant I had to find a way to power it through one port and pass a video signal through the other. Thankfully, my Anker USB-C charging hub was able to juice it up, and I also had a USB-C hub with an HDMI port, which allowed me to connect to my monitor.Sadly, the overall setup was a jumble of wires, and not the clean layout I expected from a keyboard PC. Once I was able to start up Windows though, I was less annoyed and more amazed that the keyboard contained an entire computer. I suppose I shouldn't be too surprised, as Intel's Compute Stick placed a functional PC in a much smaller case, but unlike the failed product, the EliteBoard actually felt usable. I was able to load up several browser windows with tabs, edit a few photos and even play a few light games, like Vampire Survivors. And yes, typing on it felt pretty great too.HP EliteBoard keyboard PC.Devindra Hardawar for EngadgetSince I was testing out prototype hardware, I agreed not to benchmark the EliteBoard. But from the performance I saw, it felt about the same an entry-level laptop. Basically, it's perfectly suited to its main task: Being a boring office computer. Back in my IT days, I certainly would have preferred deploying a few light keyboards instead of the tank-like Dell desktops we typically ordered.While the EliteBoard is targeted at commercial users, HP is considering it an experiment to see how people respond to a keyboard PC. There's a chance we could see one that's eventually meant for mainstream consumers. I'm not sure if that's exactly, necessary, though. The whole concept of a desktop PC mainly appeals to tinkerers and IT folks. And for anyone who wants to get their hands on an EliteBoard soon, there's really nothing stopping you.This article originally appeared on Engadget at https://www.engadget.com/computing/hps-eliteboard-made-me-believe-in-keyboard-computers-again-033000955.html?src=rss",
          "feed_position": 4,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/HP_EliteBoard-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/this-tabletop-sleep-device-and-sunrise-alarm-clock-aims-to-help-you-put-your-phone-away-before-bed-004751464.html",
          "published_at": "Tue, 06 Jan 2026 00:47:51 +0000",
          "title": "This tabletop sleep device and sunrise alarm clock aims to help you put your phone away before bed",
          "standfirst": "\"Relaxing\" isn't a word anyone is likely to associate with CES. If anything, it is the antithesis of CES, an exhausting and wildly overstimulating marathon event that takes place in the already exhausting and wildly overstimulating Las Vegas. But a demo of Ambient's bedside device, Dreamie, ahead of its appearance at CES-adjacent Pepcom had me properly lulled and ready to go right back to bed. Dreamie is a smart sunrise alarm clock and nighttime wind-down device that has a built-in podcast player, a catalog of green, pink and brown noise sound masks, guided breathing programs, contactless motion sensors to provide insights into your sleep habits, dynamic lighting with simulated sunrise wake-ups and Bluetooth connectivity for headphones. But most importantly for anyone trying to avoid using their phone immediately before bed, it's a standalone system in which all controls, features and scheduling options as well as data storage are on-device. And there's no subscription. The goal of Dreamie is \"to help you separate from your phone while providing a lot of the conveniences that you would normally have,\" said CEO and co-founder Adrian Canoso. You can set multiple alarms on different schedules, access soothing content to fall asleep to and customize how gradual your sunrise wakeup is. There are environmental sensors to clue you in on the humidity, temperature and lighting conditions over the course of the night, to give you a better idea of how these things may be affecting your sleep. Dreamie is a relatively small device compared to other sunrise-style clocks, with a truncated pill-shaped body and a sleek circular touchscreen. Around the display is a hidden dial for volume control, and it feels great to rotate, with just the right amount of resistance. There's also a touch strip on top of the device to easily adjust the dimness of the light by dragging your finger along it. From the display, you can even change the direction the light is pointing so you don't blast yourself (or your partner) with it when your eyes aren't ready, casting the light off to the back instead. Dreamie's brightness controls Cheyenne MacDonald for Engadget Its 20-LED array can go from a soft, warm orangey glow to cool and bright blue-white, and certain programs, like the aurora borealis soundscape, will trigger other colors of the rainbow, throwing soothing green, blue and magenta. More impressive is the rich sound that comes from its 50 millimeter speaker. Dreamie has a 360-degree speaker grille on the bottom of the device that sends sound in all directions to create more immersive ambient sound. When a speaker is pointing toward you, \"it's almost like a laser beam coming at you,\" which isn't exactly the most relaxing experience, explained Canoso, who previously worked in industrial design and robotics, and before that, as a studio recording engineer. \"[Dreamie] projects the sound all the way around… So when you put it next to you on a night table, it sounds more diffused. It's not the loudest speaker out there because we've optimized it for rich sound quality at lower volumes. We don't need it loud. We just need it to sound good.\" And sound good, it does. It's seriously got me thinking I may finally have found the thing to replace the Philips Wake-Up Light I've been clinging to for close to 10 years now that has decent lighting but absolutely abysmal sound quality. Dreamie, which costs $250, recently started shipping after a successful crowdfunding campaign, and certain features — including podcasts and sleep insights — haven't launched just yet (though I did get to see the podcast library during the demonstration, so it is a real thing, and it’s expected to roll out later this month). Those and other future features will arrive via free over-the-air updates. This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/this-tabletop-sleep-device-and-sunrise-alarm-clock-aims-to-help-you-put-your-phone-away-before-bed-004751464.html?src=rss",
          "content": "\"Relaxing\" isn't a word anyone is likely to associate with CES. If anything, it is the antithesis of CES, an exhausting and wildly overstimulating marathon event that takes place in the already exhausting and wildly overstimulating Las Vegas. But a demo of Ambient's bedside device, Dreamie, ahead of its appearance at CES-adjacent Pepcom had me properly lulled and ready to go right back to bed. Dreamie is a smart sunrise alarm clock and nighttime wind-down device that has a built-in podcast player, a catalog of green, pink and brown noise sound masks, guided breathing programs, contactless motion sensors to provide insights into your sleep habits, dynamic lighting with simulated sunrise wake-ups and Bluetooth connectivity for headphones. But most importantly for anyone trying to avoid using their phone immediately before bed, it's a standalone system in which all controls, features and scheduling options as well as data storage are on-device. And there's no subscription. The goal of Dreamie is \"to help you separate from your phone while providing a lot of the conveniences that you would normally have,\" said CEO and co-founder Adrian Canoso. You can set multiple alarms on different schedules, access soothing content to fall asleep to and customize how gradual your sunrise wakeup is. There are environmental sensors to clue you in on the humidity, temperature and lighting conditions over the course of the night, to give you a better idea of how these things may be affecting your sleep. Dreamie is a relatively small device compared to other sunrise-style clocks, with a truncated pill-shaped body and a sleek circular touchscreen. Around the display is a hidden dial for volume control, and it feels great to rotate, with just the right amount of resistance. There's also a touch strip on top of the device to easily adjust the dimness of the light by dragging your finger along it. From the display, you can even change the direction the light is pointing so you don't blast yourself (or your partner) with it when your eyes aren't ready, casting the light off to the back instead. Dreamie's brightness controls Cheyenne MacDonald for Engadget Its 20-LED array can go from a soft, warm orangey glow to cool and bright blue-white, and certain programs, like the aurora borealis soundscape, will trigger other colors of the rainbow, throwing soothing green, blue and magenta. More impressive is the rich sound that comes from its 50 millimeter speaker. Dreamie has a 360-degree speaker grille on the bottom of the device that sends sound in all directions to create more immersive ambient sound. When a speaker is pointing toward you, \"it's almost like a laser beam coming at you,\" which isn't exactly the most relaxing experience, explained Canoso, who previously worked in industrial design and robotics, and before that, as a studio recording engineer. \"[Dreamie] projects the sound all the way around… So when you put it next to you on a night table, it sounds more diffused. It's not the loudest speaker out there because we've optimized it for rich sound quality at lower volumes. We don't need it loud. We just need it to sound good.\" And sound good, it does. It's seriously got me thinking I may finally have found the thing to replace the Philips Wake-Up Light I've been clinging to for close to 10 years now that has decent lighting but absolutely abysmal sound quality. Dreamie, which costs $250, recently started shipping after a successful crowdfunding campaign, and certain features — including podcasts and sleep insights — haven't launched just yet (though I did get to see the podcast library during the demonstration, so it is a real thing, and it’s expected to roll out later this month). Those and other future features will arrive via free over-the-air updates. This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/this-tabletop-sleep-device-and-sunrise-alarm-clock-aims-to-help-you-put-your-phone-away-before-bed-004751464.html?src=rss",
          "feed_position": 9,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/dreamielight.jpeg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/dell-revives-its-xps-laptops-after-a-boneheaded-rebranding-001028029.html",
          "published_at": "Tue, 06 Jan 2026 00:10:28 +0000",
          "title": "Dell revives its XPS laptops after a boneheaded rebranding",
          "standfirst": "Last year, Dell killed off all of its PC brands, including the iconic XPS lineup, and replaced them with a simplified naming scheme. It was a move meant to make it easier for people to discern between the company's many brands, but in reality, it just just made the company's lineup even more confusing. We called it an unforced error at the time, but after seeing how much Dell's PC market share fell over 2025, it's fair to say that rebranding was an absolute marketing disaster. So, with its tail between its legs, Dell has returned to CES some welcome news for its fans: XPS lives! And the company plans to double-down on the brand in ways it never did before. Today, Dell revealed the new XPS 14 and 16 notebooks, which feature a more practical design than the previous models. There's a new function row with traditional keys, instead of the odd capacitive buttons that disappeared in sunlight. And while the company is sticking with its \"invisible\" trackpad, which sits flush alongside the wrist rest, there's now a light border around the edges that lets you feel exactly where the trackpad begins and ends.So, in short, Dell seems to have solved most of our recent complaints about the XPS lineup. To signify its commitment to the brand, it's also emblazoning the XPS logo on all of these new machines, replacing the previous Dell name. That’s something I could never imagine a less humbled Dell doing. The redesign also gave Dell room to shave off some weight and thickness from both machines. The XPS 14 weighs around three pounds now, a half-pound lighter than the previous generation, while the XPS 16 weighs 3.6 pounds, a whole pound lighter than before. The new cases make both machines look a lot more like Microsoft’s extra-subtle Surface Laptop, but that’s not necessarily a bad thing. Both systems are powered by Intel’s new Panther Lake Core Ultra Series 3 chips, and they also offer tandem OLED display options.Dell also briefly teased the return of a new XPS 13 later this year, which is set to be the company’s thinnest and lightest notebook ever. Dell says it’ll be cheaper than the XPS has been in the past.The new XPS 14 and 16 will be available on January 6, starting at $1,650 and $1,850, respectively. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/dell-revives-its-xps-laptops-after-a-boneheaded-rebranding-001028029.html?src=rss",
          "content": "Last year, Dell killed off all of its PC brands, including the iconic XPS lineup, and replaced them with a simplified naming scheme. It was a move meant to make it easier for people to discern between the company's many brands, but in reality, it just just made the company's lineup even more confusing. We called it an unforced error at the time, but after seeing how much Dell's PC market share fell over 2025, it's fair to say that rebranding was an absolute marketing disaster. So, with its tail between its legs, Dell has returned to CES some welcome news for its fans: XPS lives! And the company plans to double-down on the brand in ways it never did before. Today, Dell revealed the new XPS 14 and 16 notebooks, which feature a more practical design than the previous models. There's a new function row with traditional keys, instead of the odd capacitive buttons that disappeared in sunlight. And while the company is sticking with its \"invisible\" trackpad, which sits flush alongside the wrist rest, there's now a light border around the edges that lets you feel exactly where the trackpad begins and ends.So, in short, Dell seems to have solved most of our recent complaints about the XPS lineup. To signify its commitment to the brand, it's also emblazoning the XPS logo on all of these new machines, replacing the previous Dell name. That’s something I could never imagine a less humbled Dell doing. The redesign also gave Dell room to shave off some weight and thickness from both machines. The XPS 14 weighs around three pounds now, a half-pound lighter than the previous generation, while the XPS 16 weighs 3.6 pounds, a whole pound lighter than before. The new cases make both machines look a lot more like Microsoft’s extra-subtle Surface Laptop, but that’s not necessarily a bad thing. Both systems are powered by Intel’s new Panther Lake Core Ultra Series 3 chips, and they also offer tandem OLED display options.Dell also briefly teased the return of a new XPS 13 later this year, which is set to be the company’s thinnest and lightest notebook ever. Dell says it’ll be cheaper than the XPS has been in the past.The new XPS 14 and 16 will be available on January 6, starting at $1,650 and $1,850, respectively. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/dell-revives-its-xps-laptops-after-a-boneheaded-rebranding-001028029.html?src=rss",
          "feed_position": 10
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/ces-2026-intel-hopes-its-core-ultra-series-3-chips-are-the-start-of-a-comeback-000155611.html",
          "published_at": "Tue, 06 Jan 2026 00:01:55 +0000",
          "title": "CES 2026: Intel hopes its Core Ultra Series 3 chips are the start of a comeback",
          "standfirst": "Intel turned up to CES 2026 to herald the birth of the Core Ultra Series 3, a new range of chips offering “exceptional performance.” It says the mobile processors, formerly known as Panther Lake, deliver great graphics and battery life alongside the aforementioned grunt. And that, for the first time, the silicon has been certified for embedded and industrial use cases, including robotics and smart cities. But, like so many stories about Intel these days, the launch is loaded with so much subtext you’ll need a copy of Cliffs Notes to understand it.On the face of it, these are just some snappy flagship chips, available in Core Ultra 7 and 9 ranges as well as Core X7 and X9, which ship with 12 Xe graphics cores over the usual four. Almost all of them offer 16 total cores and threads, and all bar two have total NPU performance of 50 PTOPS.Image of the Core Ultra Series 3IntelThese chips are going to be famous for two key reasons: First, Intel claims they’re the most advanced chips ever manufactured in the US. Second, they’re the first to be made using Intel’s long awaited 18A process, which has dogged the company for several years. 18A was a key plank of former CEO Pat Gelsinger’s rescue plan to restore Intel to the top of the chip world. But sadly that comeback didn’t come fast enough to prevent the CEO from being (unfairly, in my mind) deposed at the end of 2024. It didn’t help that, for all of the money spent on 18A, as recently as August 2025, the company was reportedly still suffering from low yields and high defect rates.18A is short for 18 Angstrom, a measurement that’s far smaller than the nanometers we currently use to denote transistor size in chips. 18 Angstrom is roughly equivalent to 1.8 nanometers, putting it on the same rough level as the most advanced manufacturing process — N2 — available at TSMC in Taiwan. At CES, Intel’s new CEO Lip Bu-Tan said the company was now ahead of schedule for ramping production on 18A, which could mark an important shift in the global chip market. You should expect to see these chips show up in laptops from all the usual suspects, including HP, Acer, Lenovo, Dell, Samsung and the rest across this year. This article originally appeared on Engadget at https://www.engadget.com/computing/ces-2026-intel-hopes-its-core-ultra-series-3-chips-are-the-start-of-a-comeback-000155611.html?src=rss",
          "content": "Intel turned up to CES 2026 to herald the birth of the Core Ultra Series 3, a new range of chips offering “exceptional performance.” It says the mobile processors, formerly known as Panther Lake, deliver great graphics and battery life alongside the aforementioned grunt. And that, for the first time, the silicon has been certified for embedded and industrial use cases, including robotics and smart cities. But, like so many stories about Intel these days, the launch is loaded with so much subtext you’ll need a copy of Cliffs Notes to understand it.On the face of it, these are just some snappy flagship chips, available in Core Ultra 7 and 9 ranges as well as Core X7 and X9, which ship with 12 Xe graphics cores over the usual four. Almost all of them offer 16 total cores and threads, and all bar two have total NPU performance of 50 PTOPS.Image of the Core Ultra Series 3IntelThese chips are going to be famous for two key reasons: First, Intel claims they’re the most advanced chips ever manufactured in the US. Second, they’re the first to be made using Intel’s long awaited 18A process, which has dogged the company for several years. 18A was a key plank of former CEO Pat Gelsinger’s rescue plan to restore Intel to the top of the chip world. But sadly that comeback didn’t come fast enough to prevent the CEO from being (unfairly, in my mind) deposed at the end of 2024. It didn’t help that, for all of the money spent on 18A, as recently as August 2025, the company was reportedly still suffering from low yields and high defect rates.18A is short for 18 Angstrom, a measurement that’s far smaller than the nanometers we currently use to denote transistor size in chips. 18 Angstrom is roughly equivalent to 1.8 nanometers, putting it on the same rough level as the most advanced manufacturing process — N2 — available at TSMC in Taiwan. At CES, Intel’s new CEO Lip Bu-Tan said the company was now ahead of schedule for ramping production on 18A, which could mark an important shift in the global chip market. You should expect to see these chips show up in laptops from all the usual suspects, including HP, Acer, Lenovo, Dell, Samsung and the rest across this year. This article originally appeared on Engadget at https://www.engadget.com/computing/ces-2026-intel-hopes-its-core-ultra-series-3-chips-are-the-start-of-a-comeback-000155611.html?src=rss",
          "feed_position": 11,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/IntelCore3.jpeg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/ces-asus-made-a-special-hideo-kojima-version-of-the-rog-flow-z13-000000768.html",
          "published_at": "Tue, 06 Jan 2026 00:00:00 +0000",
          "title": "CES: ASUS made a special Hideo Kojima version of the ROG Flow Z13",
          "standfirst": "Who among us hasn't looked at the ASUS ROG Flow Z13 and said, \"That's great and all, but what if it had more Hideo Kojima?\" Well, our cries have been heard. Behold, the ROG Flow Z13-KJP, a collaboration between ASUS and Kojima Productions.On the inside, this model is no different than the standard version we reviewed last May. The device takes a Surface Pro-like form factor and beefs it up into something that’s more like a gaming laptop. (Ergo, ASUS's pitch of the product as a \"gaming tablet.\")But on the outside, you'll find a design \"for Ludens who dare.\" The Death Stranding influence is evident, but you may pick up on some Metal Gear-adjacent touches as well. The tablet's gold color, symbols and integrated carbon fiber conjure Kojima’s Ludens mascot. This variant is slightly larger than the standard one, most noticeably in the detachable keyboard.ROG Flow Z13-KJPASUSThere will also be matching accessories available, including a mouse, case, headphones and a desk mat. Depending on your region, those may or may not be bundled with the device. (We'll update this story when we find out more.)Fortunately, once the design novelty wears off, you're left with a fairly powerful gaming machine. The Copilot PC has a 13.4-inch IPS touchscreen with a 180Hz refresh rate and 500 nits of brightness. Its port selection is surprisingly generous: two USB 4 Type-C ports, one USB-A port, HDMI 2.1, 3.5mm audio and a microSD slot. The Ryzen AI Max+ 395 chip inside has integrated graphics that punch above what you'd expect. You can configure it with up to 128GB LPDDR5X 8000 RAM.More Kojima than you ever expected from a \"gaming tablet\"ASUSASUS hasn't yet revealed pricing or availability for the ROG Flow Z13-KJP. You can read more about the standard version in Sam Rutherford's review.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/ces-asus-made-a-special-hideo-kojima-version-of-the-rog-flow-z13-000000768.html?src=rss",
          "content": "Who among us hasn't looked at the ASUS ROG Flow Z13 and said, \"That's great and all, but what if it had more Hideo Kojima?\" Well, our cries have been heard. Behold, the ROG Flow Z13-KJP, a collaboration between ASUS and Kojima Productions.On the inside, this model is no different than the standard version we reviewed last May. The device takes a Surface Pro-like form factor and beefs it up into something that’s more like a gaming laptop. (Ergo, ASUS's pitch of the product as a \"gaming tablet.\")But on the outside, you'll find a design \"for Ludens who dare.\" The Death Stranding influence is evident, but you may pick up on some Metal Gear-adjacent touches as well. The tablet's gold color, symbols and integrated carbon fiber conjure Kojima’s Ludens mascot. This variant is slightly larger than the standard one, most noticeably in the detachable keyboard.ROG Flow Z13-KJPASUSThere will also be matching accessories available, including a mouse, case, headphones and a desk mat. Depending on your region, those may or may not be bundled with the device. (We'll update this story when we find out more.)Fortunately, once the design novelty wears off, you're left with a fairly powerful gaming machine. The Copilot PC has a 13.4-inch IPS touchscreen with a 180Hz refresh rate and 500 nits of brightness. Its port selection is surprisingly generous: two USB 4 Type-C ports, one USB-A port, HDMI 2.1, 3.5mm audio and a microSD slot. The Ryzen AI Max+ 395 chip inside has integrated graphics that punch above what you'd expect. You can configure it with up to 128GB LPDDR5X 8000 RAM.More Kojima than you ever expected from a \"gaming tablet\"ASUSASUS hasn't yet revealed pricing or availability for the ROG Flow Z13-KJP. You can read more about the standard version in Sam Rutherford's review.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/ces-asus-made-a-special-hideo-kojima-version-of-the-rog-flow-z13-000000768.html?src=rss",
          "feed_position": 12,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/asus_2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/the-asus-rog-zephyrus-duo-is-big-weird-and-kind-of-awesome-000000156.html",
          "published_at": "Tue, 06 Jan 2026 00:00:00 +0000",
          "title": "The ASUS ROG Zephyrus Duo is big, weird and kind of awesome",
          "standfirst": "A couple years ago ASUS made its first dual-screen laptop in the ZenBook Duo. Now at CES 2026, the company has taken that idea and branched off in a somewhat unexpected way with the ROG Zephyrus Duo, which might just be the world’s first true dual-screen gaming laptop.Unlike a more traditional productivity notebook with two built-in displays, the concept of a dual-screen gaming notebook doesn’t translate quite as naturally because powering two screens comes with a performance hit. Plus, in the heat of battle, it’s not like you have a lot of opportunity to utilize that second monitor. But if you view this Zephyrus Duo as more of an all-purpose portable content creation and gaming station, things begin to make a lot more sense. Both of Zephyrus Duo’s 16-inch Nebula OLED panels have strong specs including support for HDR with up to 1,100 nits of peak brightness, NVIDIA G-Sync, stylus integration and a very strong Delta-E (which measures color accuracy) of less than one. Performance also looks solid with ASUS offering the latest Core Ultra processors from Intel and up to an NVIDIA RTX 5090 GPU. Sure, with a TDP of 135 watts, the Zephyrus Duo won’t be quite as punchy as a comparable single-screened 16-inch gaming notebook, but those won’t be nearly as adaptable as the ROG either. Just like the Zenbook Duo, the Zephyrus Duo comes with a detachable wireless keyboard that can be charged up magnetically. This allows users to set up the laptop in all sorts of positions, which are enhanced thanks to a built-in kickstand. The one people will use the most is probably the stacked arrangement with one display above the other. However, you can also keep the Duo and clamshell mode, slide the keyboard forward for drawing, lay it down flat on a table or even put it into tent mode and game on it. Though even ASUS admits that may not be super practical as apps will need to specifically support that use case. Though at the very least, you can mirror your screen for a friend on the other side of a desk/table.The ROG Zephyrus Duo comes with a built-in kickstand which makes it easy to set it up in all sorts of different positions, even if it is a bit heavy. Sam Rutherford for EngadgetNow I will admit that after messing around with the Zephyrus Duo in person, it is a bit ungainly due to its weight of 6.28 pounds. But ASUS managed to do a good job of keeping it relatively thin (0.77 inches) without skimping on features like sound thanks to the Duo’s six-speaker stereo system and cooling which features a vapor chamber and a liquid metal thermal material. You also get a surprising amount of ports including multiple USB-C with Thunderbolt 4, USB-A, HDMI 2.1 and a full-size SD card slot, plus a decently large 90Whr battery. The one important thing we don’t know yet though is how much it will cost, particularly because this thing almost certainly won’t be cheap (I’m guessing a starting price of around $2,500). A dual-screen gaming laptop might not make a lot of sense, but I appreciate how ambitious ASUS is being with the ROG Zephyrus Duo and I’m looking forward to testing it out sometime later this year. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/the-asus-rog-zephyrus-duo-is-big-weird-and-kind-of-awesome-000000156.html?src=rss",
          "content": "A couple years ago ASUS made its first dual-screen laptop in the ZenBook Duo. Now at CES 2026, the company has taken that idea and branched off in a somewhat unexpected way with the ROG Zephyrus Duo, which might just be the world’s first true dual-screen gaming laptop.Unlike a more traditional productivity notebook with two built-in displays, the concept of a dual-screen gaming notebook doesn’t translate quite as naturally because powering two screens comes with a performance hit. Plus, in the heat of battle, it’s not like you have a lot of opportunity to utilize that second monitor. But if you view this Zephyrus Duo as more of an all-purpose portable content creation and gaming station, things begin to make a lot more sense. Both of Zephyrus Duo’s 16-inch Nebula OLED panels have strong specs including support for HDR with up to 1,100 nits of peak brightness, NVIDIA G-Sync, stylus integration and a very strong Delta-E (which measures color accuracy) of less than one. Performance also looks solid with ASUS offering the latest Core Ultra processors from Intel and up to an NVIDIA RTX 5090 GPU. Sure, with a TDP of 135 watts, the Zephyrus Duo won’t be quite as punchy as a comparable single-screened 16-inch gaming notebook, but those won’t be nearly as adaptable as the ROG either. Just like the Zenbook Duo, the Zephyrus Duo comes with a detachable wireless keyboard that can be charged up magnetically. This allows users to set up the laptop in all sorts of positions, which are enhanced thanks to a built-in kickstand. The one people will use the most is probably the stacked arrangement with one display above the other. However, you can also keep the Duo and clamshell mode, slide the keyboard forward for drawing, lay it down flat on a table or even put it into tent mode and game on it. Though even ASUS admits that may not be super practical as apps will need to specifically support that use case. Though at the very least, you can mirror your screen for a friend on the other side of a desk/table.The ROG Zephyrus Duo comes with a built-in kickstand which makes it easy to set it up in all sorts of different positions, even if it is a bit heavy. Sam Rutherford for EngadgetNow I will admit that after messing around with the Zephyrus Duo in person, it is a bit ungainly due to its weight of 6.28 pounds. But ASUS managed to do a good job of keeping it relatively thin (0.77 inches) without skimping on features like sound thanks to the Duo’s six-speaker stereo system and cooling which features a vapor chamber and a liquid metal thermal material. You also get a surprising amount of ports including multiple USB-C with Thunderbolt 4, USB-A, HDMI 2.1 and a full-size SD card slot, plus a decently large 90Whr battery. The one important thing we don’t know yet though is how much it will cost, particularly because this thing almost certainly won’t be cheap (I’m guessing a starting price of around $2,500). A dual-screen gaming laptop might not make a lot of sense, but I appreciate how ambitious ASUS is being with the ROG Zephyrus Duo and I’m looking forward to testing it out sometime later this year. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/the-asus-rog-zephyrus-duo-is-big-weird-and-kind-of-awesome-000000156.html?src=rss",
          "feed_position": 13,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Zephyrus-duo-back.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/it-took-guts-for-dell-to-admit-its-mistake-heres-how-xps-will-make-its-big-comeback-233248173.html",
          "published_at": "Mon, 05 Jan 2026 23:32:48 +0000",
          "title": "It took guts for Dell to admit its mistake, here's how XPS will make its big comeback",
          "standfirst": "Last year when Dell decided to kill off the XPS name, it felt like a big mistake. In fact, we said so multiple times. But at CES 2026, Dell is righting wrongs by bringing back its iconic laptop brand and it feels like the right move for both the company and its flagship consumer devices. Even more than the words the letters XPS are meant to represent (Extreme Performance Systems), over the last decade, Dell’s signature laptop brand stood for excellent design, quality engineering and top notch performance. And it was precisely those laptops that landed the company at the top of nearly every best Windows laptop guide every year for the last decade. So to replace XPS with a generic tag like premium felt like a big step backwards. Now if you were living under a rock (at least when it comes to Windows laptops), you can sort of squint your eyes and see the reasoning behind Dell’s misguided rebranding. Premium means good, typically something much better than average. By putting that word in front of its top-tier systems, there’s no way anyone could be confused about what kind of device they were buying, right? Take for example the Dell Premium 14, which was the new moniker for what was previously called the XPS 14. A laptop like that has to be decent. I mean, it’s right there in the product name. The issue is that XPS already meant good. Actually, way better than that, if we were just going by the sheer number of accolades previous-gen models got, like Dell’s 2020-era machines which we called practically perfect (which it was). Going away from that wasn’t just reductive, it was throwing the best part of Dell’s consumer business in the trash for no real reason. The first two new XPS machines will be the XPS 14 and XPS 16. Sam Rutherford for EngadgetAdditionally, Dell’s new naming strategy was intended to simplify its product portfolio, and it failed to deliver on that original goal. COO Jeff Clarke was refreshingly honest about this when announcing the return of XPS at a CES media preview in early December. Not only did Dell lose its signature XPS brand last year, it actually made things more confusing for consumers when it simultaneously created a full range of Dell Pro and Pro Max systems. Unlike Apple’s MacBook Pros and iPhone Pro Maxes, those devices were actually meant for enterprise customers instead of regular Joes. Another photo of the new XPS 14 and 16, which have a bunch of welcome changes and then some. Sam Rutherford for EngadgetAmidst its rebrand, the company also eliminated a lot of its budget and entry-level models. That left a lot of people turning to more expensive mid-range “Plus” systems or waiting for a proper redesign of its top tier Premium laptops, which weren’t expected to arrive until 2026 anyway. So where is Dell going from here? Well as Clarke put it quite succinctly, “We’re getting back to our roots.” Starting in 2026, the company is planning to create its broadest PC portfolio ever including, a full line of XPS laptops. This includes an all-new version of the XPS 13, which is going to be the thinnest and lightest model to date, along with complete overhauls for the XPS 14 and XPS 16. But Dell isn’t stopping there because on a slide it showed at its press event, there were two additional placeholders for future XPS systems coming at some later date. Dell wouldn't let me take photos of the XPS 13 prototype model, but here's a teaser it provided for CES. DellEven when it comes to specific features and components on individual models, Dell is finally acknowledging some of the criticism it has received over the past few years by returning to segmented touchpads instead of seamless all-glass slates and ditching capacitive function keys for good ‘ol buttons. Dell isn’t just bringing the XPS line back, it’s kind of on a revenge tour (even if the original wound was self-inflicted). On top of that, the consumer device team will be reporting directly to Clarke while the company retools itself internally. Dell is also updating its naming scheme to finally deliver on the promise of making things clear and simple. XPS will once again be the company’s flagship consumer brand with the XPS logo (not Dell’s) front and center on the lid of every laptop, while everything else will fall under the general Dell umbrella. Alienware will continue to do its own thing for gaming and the Dell Pro family will remain aimed strictly at enterprise businesses, professional services (like first responders) and education. No more confusion. And underlying all of that is a very straightforward motto from Clarke that “great products win.” After ditching the XPS brand, Dell is now bring it back for 2026 in its rightful spot at the top of the company's consumer portfolio. DellIn the end, even though Dell’s big plan from last year ended up being a mess, I appreciate when a company is self aware enough to know it messed up and has come up with a plan to fix things. Regardless of whether it's a corporation or a single person, admitting mistakes is always hard. Oftentimes, what you learn in the process is the real prize and from what I’ve seen Dell and its iconic XPS line is poised for a major comeback. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/it-took-guts-for-dell-to-admit-its-mistake-heres-how-xps-will-make-its-big-comeback-233248173.html?src=rss",
          "content": "Last year when Dell decided to kill off the XPS name, it felt like a big mistake. In fact, we said so multiple times. But at CES 2026, Dell is righting wrongs by bringing back its iconic laptop brand and it feels like the right move for both the company and its flagship consumer devices. Even more than the words the letters XPS are meant to represent (Extreme Performance Systems), over the last decade, Dell’s signature laptop brand stood for excellent design, quality engineering and top notch performance. And it was precisely those laptops that landed the company at the top of nearly every best Windows laptop guide every year for the last decade. So to replace XPS with a generic tag like premium felt like a big step backwards. Now if you were living under a rock (at least when it comes to Windows laptops), you can sort of squint your eyes and see the reasoning behind Dell’s misguided rebranding. Premium means good, typically something much better than average. By putting that word in front of its top-tier systems, there’s no way anyone could be confused about what kind of device they were buying, right? Take for example the Dell Premium 14, which was the new moniker for what was previously called the XPS 14. A laptop like that has to be decent. I mean, it’s right there in the product name. The issue is that XPS already meant good. Actually, way better than that, if we were just going by the sheer number of accolades previous-gen models got, like Dell’s 2020-era machines which we called practically perfect (which it was). Going away from that wasn’t just reductive, it was throwing the best part of Dell’s consumer business in the trash for no real reason. The first two new XPS machines will be the XPS 14 and XPS 16. Sam Rutherford for EngadgetAdditionally, Dell’s new naming strategy was intended to simplify its product portfolio, and it failed to deliver on that original goal. COO Jeff Clarke was refreshingly honest about this when announcing the return of XPS at a CES media preview in early December. Not only did Dell lose its signature XPS brand last year, it actually made things more confusing for consumers when it simultaneously created a full range of Dell Pro and Pro Max systems. Unlike Apple’s MacBook Pros and iPhone Pro Maxes, those devices were actually meant for enterprise customers instead of regular Joes. Another photo of the new XPS 14 and 16, which have a bunch of welcome changes and then some. Sam Rutherford for EngadgetAmidst its rebrand, the company also eliminated a lot of its budget and entry-level models. That left a lot of people turning to more expensive mid-range “Plus” systems or waiting for a proper redesign of its top tier Premium laptops, which weren’t expected to arrive until 2026 anyway. So where is Dell going from here? Well as Clarke put it quite succinctly, “We’re getting back to our roots.” Starting in 2026, the company is planning to create its broadest PC portfolio ever including, a full line of XPS laptops. This includes an all-new version of the XPS 13, which is going to be the thinnest and lightest model to date, along with complete overhauls for the XPS 14 and XPS 16. But Dell isn’t stopping there because on a slide it showed at its press event, there were two additional placeholders for future XPS systems coming at some later date. Dell wouldn't let me take photos of the XPS 13 prototype model, but here's a teaser it provided for CES. DellEven when it comes to specific features and components on individual models, Dell is finally acknowledging some of the criticism it has received over the past few years by returning to segmented touchpads instead of seamless all-glass slates and ditching capacitive function keys for good ‘ol buttons. Dell isn’t just bringing the XPS line back, it’s kind of on a revenge tour (even if the original wound was self-inflicted). On top of that, the consumer device team will be reporting directly to Clarke while the company retools itself internally. Dell is also updating its naming scheme to finally deliver on the promise of making things clear and simple. XPS will once again be the company’s flagship consumer brand with the XPS logo (not Dell’s) front and center on the lid of every laptop, while everything else will fall under the general Dell umbrella. Alienware will continue to do its own thing for gaming and the Dell Pro family will remain aimed strictly at enterprise businesses, professional services (like first responders) and education. No more confusion. And underlying all of that is a very straightforward motto from Clarke that “great products win.” After ditching the XPS brand, Dell is now bring it back for 2026 in its rightful spot at the top of the company's consumer portfolio. DellIn the end, even though Dell’s big plan from last year ended up being a mess, I appreciate when a company is self aware enough to know it messed up and has come up with a plan to fix things. Regardless of whether it's a corporation or a single person, admitting mistakes is always hard. Oftentimes, what you learn in the process is the real prize and from what I’ve seen Dell and its iconic XPS line is poised for a major comeback. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/it-took-guts-for-dell-to-admit-its-mistake-heres-how-xps-will-make-its-big-comeback-233248173.html?src=rss",
          "feed_position": 15,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/XPS-14-and-16.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/amd-at-ces-2026-live-updates-from-ceo-lisa-sus-keynote-presentation-190012370.html",
          "published_at": "Mon, 05 Jan 2026 23:01:25 +0000",
          "title": "AMD at CES 2026: Live updates from CEO Lisa Su's keynote presentation",
          "standfirst": "NVIDIA and Intel had their moment in the spotlight, and now it's AMD's turn. The chipmaker is kicking off CES 2026 on Monday night, where it'll cover its latest AI developments and perhaps show off its newest Ryzen chips. It's the kickoff keynote of CES 2026, and CEO Dr. Lisa Su is expected to outline how AMD's hardware will power the AI revolution — and what the company can offer partners and consumers that those aforementioned rivals can't. We'll tell you how to tune in to the livestream and what else you can expect to see. How to watch AMD's keynote live Dr. Su will deliver a keynote speech from the Palazzo Ballroom at the Venetian on Monday, January 5 at 9:30PM ET (6:30PM PT). You can watch the event live on the CES YouTube channel (we've embedded the livestream below). Engadget will also be liveblogging the AMD keynote in real-time. What to expect from AMD at CES 2026 While AMD says it's keeping its product details under wraps, we can expect \"updates on AI solutions, from cloud to enterprise, edge and devices.\" It's also likely that AMD will unveil its new versions of the Ryzen chips during its keynote on Monday, as Su will talk about the \"advancements driven by Ryzen CPUs.\" That could include the Ryzen 7 9850X3D, which is expected to have better single-threaded performance than its predecessors. Additionally, we can expect to see the Ryzen 9000G series, which is potentially built with AMD's Zen 5 architecture. Regarding AI, AMD could further discuss its new FSR Redstone technology, which it previously previewed on December 10. AMD's upscaling tech aims to close the gap on NVIDIA's DLSS 4, which was announced during CES 2025. Su's presentation caps off CES's press day, so she'll be taking the stage in the hours after rivals NVIDIA and Intel present their chipmaking and AI plans to the world. As a reminder of how cross-linked these companies have become: OpenAI has pledged billions of dollars of hardware orders to AMD, while rival NVIDIA has invested billions in OpenAI — and taken a stake worth billions in Intel, too. This article originally appeared on Engadget at https://www.engadget.com/computing/amd-at-ces-2026-live-updates-from-ceo-lisa-sus-keynote-presentation-190012370.html?src=rss",
          "content": "NVIDIA and Intel had their moment in the spotlight, and now it's AMD's turn. The chipmaker is kicking off CES 2026 on Monday night, where it'll cover its latest AI developments and perhaps show off its newest Ryzen chips. It's the kickoff keynote of CES 2026, and CEO Dr. Lisa Su is expected to outline how AMD's hardware will power the AI revolution — and what the company can offer partners and consumers that those aforementioned rivals can't. We'll tell you how to tune in to the livestream and what else you can expect to see. How to watch AMD's keynote live Dr. Su will deliver a keynote speech from the Palazzo Ballroom at the Venetian on Monday, January 5 at 9:30PM ET (6:30PM PT). You can watch the event live on the CES YouTube channel (we've embedded the livestream below). Engadget will also be liveblogging the AMD keynote in real-time. What to expect from AMD at CES 2026 While AMD says it's keeping its product details under wraps, we can expect \"updates on AI solutions, from cloud to enterprise, edge and devices.\" It's also likely that AMD will unveil its new versions of the Ryzen chips during its keynote on Monday, as Su will talk about the \"advancements driven by Ryzen CPUs.\" That could include the Ryzen 7 9850X3D, which is expected to have better single-threaded performance than its predecessors. Additionally, we can expect to see the Ryzen 9000G series, which is potentially built with AMD's Zen 5 architecture. Regarding AI, AMD could further discuss its new FSR Redstone technology, which it previously previewed on December 10. AMD's upscaling tech aims to close the gap on NVIDIA's DLSS 4, which was announced during CES 2025. Su's presentation caps off CES's press day, so she'll be taking the stage in the hours after rivals NVIDIA and Intel present their chipmaking and AI plans to the world. As a reminder of how cross-linked these companies have become: OpenAI has pledged billions of dollars of hardware orders to AMD, while rival NVIDIA has invested billions in OpenAI — and taken a stake worth billions in Intel, too. This article originally appeared on Engadget at https://www.engadget.com/computing/amd-at-ces-2026-live-updates-from-ceo-lisa-sus-keynote-presentation-190012370.html?src=rss",
          "feed_position": 16
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/acers-predator-helios-neo-16s-ai-laptop-can-be-outfitted-with-intels-new-core-ultra-9-386h-cpu-230048825.html",
          "published_at": "Mon, 05 Jan 2026 23:00:48 +0000",
          "title": "Acer's Predator Helios Neo 16S AI laptop can be outfitted with Intel's new Core Ultra 9 386H CPU",
          "standfirst": "Acer just announced the Predator Helios 16S AI gaming laptop at CES 2026. This computer is filled with both bells and whistles, making it a decent choice for modern gamers. To that end, the laptop can be equipped with up to an Intel Core Ultra 9 386H processor. This is Intel's upcoming flagship mobile processor that has previously been known as Panther Lake. The Helios 16S AI can also be outfitted with up to the NVIDIA GeForce RTX 5070 GPU. Acer It comes with a 16-inch WQXGA OLED display that offers true HDR imaging support. The laptop can be loaded with up to 64GB of RAM and up to 2TB of storage. The connectivity here is on point, with support for Thunderbolt 4, Wi-Fi 6E and Bluetooth. Everything is housed in an 18.9mm slim metal chassis. It looks pretty solid. We don't have any pricing, and the company might still be calculating that, given that ongoing RAM shortage. Acer says they'll disclose that closer to launch.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/acers-predator-helios-neo-16s-ai-laptop-can-be-outfitted-with-intels-new-core-ultra-9-386h-cpu-230048825.html?src=rss",
          "content": "Acer just announced the Predator Helios 16S AI gaming laptop at CES 2026. This computer is filled with both bells and whistles, making it a decent choice for modern gamers. To that end, the laptop can be equipped with up to an Intel Core Ultra 9 386H processor. This is Intel's upcoming flagship mobile processor that has previously been known as Panther Lake. The Helios 16S AI can also be outfitted with up to the NVIDIA GeForce RTX 5070 GPU. Acer It comes with a 16-inch WQXGA OLED display that offers true HDR imaging support. The laptop can be loaded with up to 64GB of RAM and up to 2TB of storage. The connectivity here is on point, with support for Thunderbolt 4, Wi-Fi 6E and Bluetooth. Everything is housed in an 18.9mm slim metal chassis. It looks pretty solid. We don't have any pricing, and the company might still be calculating that, given that ongoing RAM shortage. Acer says they'll disclose that closer to launch.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/acers-predator-helios-neo-16s-ai-laptop-can-be-outfitted-with-intels-new-core-ultra-9-386h-cpu-230048825.html?src=rss",
          "feed_position": 18,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/865fe6d0-e666-11f0-bf3e-78b0cfcd9889"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/samsungs-galaxy-book-6-series-ces-2026-intel-panther-lake-230010324.html",
          "published_at": "Mon, 05 Jan 2026 23:00:10 +0000",
          "title": "Samsung’s Galaxy Book 6 series launches at CES with Intel’s newest chips and a refined design",
          "standfirst": "In addition to huge TVs, compact projectors, Trifolds and more, Samsung announced a new family of laptops at CES called the Galaxy Book 6 series. The company says it’s focused on what matters and on what you, hopefully, want in your next laptop. That means Intel’s latest chips, a cleaner design and battery life that lasts longer than a day. They’re really thin, too. Timed alongside Intel’s CES announcements, the whole Galaxy Book 6 series features new Panther Lake chips, optimized by Samsung for three new laptops: The Galaxy Book 6 Ultra, Galaxy Book 6 Pro and Galaxy Book 6. The 16-inch Galaxy Book 6 Ultra can be equipped with up to Core Ultra X9 processors and promises significant performance improvements, with a new 5th-generation MPU, Intel Arc graphics and NVIDIA’s RTX 50 series GPUs (with RTX 5070 and 5060 options). That package leads Samsung to promise up to 1.6x greater CPU power and 1.7x improved graphics performance compared to the last Galaxy Book series. (It’s worth noting that Samsung skipped an Ultra configuration of the Galaxy Book 5 series.) All the laptops feature improved heat-management architecture, with a wider vapor chamber and re-engineered fans. At the same time, the Ultra features a new dual-path fan to cool the GPU even more efficiently and swiftly. Mat Smith for Engadget The Galaxy Book 6 Pro will come in 14- and 16-inch versions, with up to Core Ultra X7 processors and Intel Arc graphics. Both the Book 6 Ultra and Pro have improved AMOLED 2X (2,880 x 1,800) displays with touch, reaching up to 1000 nits of peak brightness — twice the brightness of the Book 5 Pro. Both models support adaptive refresh rates too, going up to 120Hz. The Book 6 Ultra has a more typical laptop shape, while the Book 6 Pro has a teardrop profile, made famous by the MacBook Air. Even if there’s some Apple inspiration, the Samsung laptops look great. Samsung has removed many unnecessary design elements. Although the Book 6 Ultra clings onto a USB-A port, it now (finally) has a full-size SD card reader, the lack of which was a major oversight on previous laptops. Mat Smith for Engadget Samsung has also tweaked the keyboard layout, though it’s too early to say whether it offers a significant improvement to the typing experience. It has added haptic trackpads to the Galaxy Book series for the first time too, although I found the one on my demo unit a little too hair-trigger sensitive to my touch. Thankfully, that’s something that can be addressed in the settings. As you might notice from the photos, there are upward-firing speakers on either side of the keyboard. The Book 6 Ultra has six built-in speakers (four woofers, two tweeters) and has apparently balanced them symmetrically to reduce noise distortion. Both laptops are slimmer than their predecessors, too. The Galaxy Book 6 Ultra is 15.4mm thick, while the Book 6 Pro is a svelte 11.9mm. Inside, Samsung has also enhanced heat management, including a wider vapour chamber and re-engineered fans, to ensure optimal performance during intensive tasks – apparently another priority for the Book 6 Series. Likewise, battery enclosures and placements have been re-engineered, and Samsung claims the new Book 6 Ultra and Pro can each deliver up to 30 hours of video playback. The Book 6 Ultra has the extra benefit of faster charging, reaching 63% in 30 minutes. It wouldn't be a laptop launch in 2026 without AI features. Alongside the Book 6 series, Samsung highlighted a tool that uses AI to help create cut-outs of images for copy-and-pasting across devices, as well as a Note Assist feature to help collate and summarize your notes. As is often the case at CES, Samsung hasn’t yet shared pricing or release dates for the Galaxy Book 6 series, so expect to hear more in the coming months.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/samsungs-galaxy-book-6-series-ces-2026-intel-panther-lake-230010324.html?src=rss",
          "content": "In addition to huge TVs, compact projectors, Trifolds and more, Samsung announced a new family of laptops at CES called the Galaxy Book 6 series. The company says it’s focused on what matters and on what you, hopefully, want in your next laptop. That means Intel’s latest chips, a cleaner design and battery life that lasts longer than a day. They’re really thin, too. Timed alongside Intel’s CES announcements, the whole Galaxy Book 6 series features new Panther Lake chips, optimized by Samsung for three new laptops: The Galaxy Book 6 Ultra, Galaxy Book 6 Pro and Galaxy Book 6. The 16-inch Galaxy Book 6 Ultra can be equipped with up to Core Ultra X9 processors and promises significant performance improvements, with a new 5th-generation MPU, Intel Arc graphics and NVIDIA’s RTX 50 series GPUs (with RTX 5070 and 5060 options). That package leads Samsung to promise up to 1.6x greater CPU power and 1.7x improved graphics performance compared to the last Galaxy Book series. (It’s worth noting that Samsung skipped an Ultra configuration of the Galaxy Book 5 series.) All the laptops feature improved heat-management architecture, with a wider vapor chamber and re-engineered fans. At the same time, the Ultra features a new dual-path fan to cool the GPU even more efficiently and swiftly. Mat Smith for Engadget The Galaxy Book 6 Pro will come in 14- and 16-inch versions, with up to Core Ultra X7 processors and Intel Arc graphics. Both the Book 6 Ultra and Pro have improved AMOLED 2X (2,880 x 1,800) displays with touch, reaching up to 1000 nits of peak brightness — twice the brightness of the Book 5 Pro. Both models support adaptive refresh rates too, going up to 120Hz. The Book 6 Ultra has a more typical laptop shape, while the Book 6 Pro has a teardrop profile, made famous by the MacBook Air. Even if there’s some Apple inspiration, the Samsung laptops look great. Samsung has removed many unnecessary design elements. Although the Book 6 Ultra clings onto a USB-A port, it now (finally) has a full-size SD card reader, the lack of which was a major oversight on previous laptops. Mat Smith for Engadget Samsung has also tweaked the keyboard layout, though it’s too early to say whether it offers a significant improvement to the typing experience. It has added haptic trackpads to the Galaxy Book series for the first time too, although I found the one on my demo unit a little too hair-trigger sensitive to my touch. Thankfully, that’s something that can be addressed in the settings. As you might notice from the photos, there are upward-firing speakers on either side of the keyboard. The Book 6 Ultra has six built-in speakers (four woofers, two tweeters) and has apparently balanced them symmetrically to reduce noise distortion. Both laptops are slimmer than their predecessors, too. The Galaxy Book 6 Ultra is 15.4mm thick, while the Book 6 Pro is a svelte 11.9mm. Inside, Samsung has also enhanced heat management, including a wider vapour chamber and re-engineered fans, to ensure optimal performance during intensive tasks – apparently another priority for the Book 6 Series. Likewise, battery enclosures and placements have been re-engineered, and Samsung claims the new Book 6 Ultra and Pro can each deliver up to 30 hours of video playback. The Book 6 Ultra has the extra benefit of faster charging, reaching 63% in 30 minutes. It wouldn't be a laptop launch in 2026 without AI features. Alongside the Book 6 series, Samsung highlighted a tool that uses AI to help create cut-outs of images for copy-and-pasting across devices, as well as a Note Assist feature to help collate and summarize your notes. As is often the case at CES, Samsung hasn’t yet shared pricing or release dates for the Galaxy Book 6 series, so expect to hear more in the coming months.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/samsungs-galaxy-book-6-series-ces-2026-intel-panther-lake-230010324.html?src=rss",
          "feed_position": 19,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/fa07a3c0-ea85-11f0-a52f-e92491d60a06"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/msi-unveils-new-gaming-and-prestige-business-laptops-at-ces-2026-230000027.html",
          "published_at": "Mon, 05 Jan 2026 23:00:00 +0000",
          "title": "MSI unveils new gaming and Prestige business laptops at CES 2026",
          "standfirst": "MSI has presented its refreshed Prestige lineup of business laptops, as well as its next-generation Raider, Stealth and Crosshair gaming models at this year’s CES. The Raider 16 Max HX is a 300w laptop, which the company says its its most powerful gaming model yet. It can supply 175w to its GeForce RTX 5090 or RTX 5080 GPU, while feeding 125w to its Intel Core Ultra 200HX processor at the same time under full-load conditions. To be able to handle that kind of power, MSI equipped it with a new cooling system consisting of three fans, six heat pipes, five exhaust vents and phase-change thermal compound. The Raider 16 Max also has a quick-access bottom panel that gives users an easy way to upgrade their storage and memory. Meanwhile, the new Stealth 16 AI+ laptop’s selling point seems to be its portability. It’s just 16.6mm thin, weighs under two kilograms, comes equipped with RTX 50 series GPU and has dual memory and SSD slots. MSI has also introduced the new Crosshair 16 Max HX and Crosshair 16 HX laptops powered by Intel Core Ultra 200HX processors and NVIDIA GeForce RTX 50 series GPUs at the event. Buyers can pay extra for an optional QHD+ 165Hz OLED display if they want sharper visuals, as well. In addition to its new gaming laptops, MSI has introduced its all-new Prestige 14 and Prestige 16 business laptops at CES. They’re slimmer with a more rounded silhouette compared to their predecessors, and they’re encased in full aluminum. The laptops are powered by the latest Intel Core Ultra Series 3 processors and are equipped with an 81Wh battery that can offer over 30 hours of video playback in 1080p. MSI has debuted the new Modern 14S and 16S series powered by the latest Intel Core Ultra Series 3 processors for everyday users, as well. Plus, the company has unveiled a Glacier Blue edition of its handheld gaming console, the Claw 8AI+, that’s powered by the Intel Core Ultra 200V processor with Arc Xe2 graphics. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/msi-unveils-new-gaming-and-prestige-business-laptops-at-ces-2026-230000027.html?src=rss",
          "content": "MSI has presented its refreshed Prestige lineup of business laptops, as well as its next-generation Raider, Stealth and Crosshair gaming models at this year’s CES. The Raider 16 Max HX is a 300w laptop, which the company says its its most powerful gaming model yet. It can supply 175w to its GeForce RTX 5090 or RTX 5080 GPU, while feeding 125w to its Intel Core Ultra 200HX processor at the same time under full-load conditions. To be able to handle that kind of power, MSI equipped it with a new cooling system consisting of three fans, six heat pipes, five exhaust vents and phase-change thermal compound. The Raider 16 Max also has a quick-access bottom panel that gives users an easy way to upgrade their storage and memory. Meanwhile, the new Stealth 16 AI+ laptop’s selling point seems to be its portability. It’s just 16.6mm thin, weighs under two kilograms, comes equipped with RTX 50 series GPU and has dual memory and SSD slots. MSI has also introduced the new Crosshair 16 Max HX and Crosshair 16 HX laptops powered by Intel Core Ultra 200HX processors and NVIDIA GeForce RTX 50 series GPUs at the event. Buyers can pay extra for an optional QHD+ 165Hz OLED display if they want sharper visuals, as well. In addition to its new gaming laptops, MSI has introduced its all-new Prestige 14 and Prestige 16 business laptops at CES. They’re slimmer with a more rounded silhouette compared to their predecessors, and they’re encased in full aluminum. The laptops are powered by the latest Intel Core Ultra Series 3 processors and are equipped with an 81Wh battery that can offer over 30 hours of video playback in 1080p. MSI has debuted the new Modern 14S and 16S series powered by the latest Intel Core Ultra Series 3 processors for everyday users, as well. Plus, the company has unveiled a Glacier Blue edition of its handheld gaming console, the Claw 8AI+, that’s powered by the Intel Core Ultra 200V processor with Arc Xe2 graphics. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/msi-unveils-new-gaming-and-prestige-business-laptops-at-ces-2026-230000027.html?src=rss",
          "feed_position": 20
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/acer-goes-big-on-the-haptic-trackpad-for-ces-with-the-swift-16-ai-laptop-230000750.html",
          "published_at": "Mon, 05 Jan 2026 23:00:00 +0000",
          "title": "Acer goes big on the haptic trackpad for CES with the Swift 16 AI laptop",
          "standfirst": "Acer has a handful of laptop updates at this year's CES show. The headlining item is the addition of the Acer Swift 16 AI to the company's flagship line. This laptop has what the company says is currently the world's largest haptic touchpad at 5.5mm by 109.7mm, and it can support up to MPP 2.5 stylus inputs. The screen is a 16-inch 3K OLED WQXGA+ touch display with HDR, a 120 Hz refresh rate and 100% DCI-P3 color gamut. On the inside, the Swift 16 AI can be kitted with up to an Intel Core Ultra X9 388H processor with built-in Intel Arc B390 graphics. The whole package is in a 14.9mm thin chassis and the machine weighs 1.55kg (about 3.4 lbs). Closeup of the trackpad on the Acer Swift 16 AI laptopAcer (modified)Another notable element in the company's CES announcements is Acer Swift Edge 14 AI, one of two new lightweight laptops revealed at the event. The Swift Edge 14 AI measures just 13.95mm thick and weighs 0.99kg (about 2.2 lbs). It is powered by up to an Intel Core Ultra 9 processor 386H. The max spec 14-inch screen has a 3KWQXGA+ OLED touch display with 120 Hz refresh rate.Both machines can have up to 32GB of RAM and are part of the Copilot+ PC program. Storage in the Swift 16 AI maxes out at 2TB while the Swift Edge 14 AI be up to 1TB.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/acer-goes-big-on-the-haptic-trackpad-for-ces-with-the-swift-16-ai-laptop-230000750.html?src=rss",
          "content": "Acer has a handful of laptop updates at this year's CES show. The headlining item is the addition of the Acer Swift 16 AI to the company's flagship line. This laptop has what the company says is currently the world's largest haptic touchpad at 5.5mm by 109.7mm, and it can support up to MPP 2.5 stylus inputs. The screen is a 16-inch 3K OLED WQXGA+ touch display with HDR, a 120 Hz refresh rate and 100% DCI-P3 color gamut. On the inside, the Swift 16 AI can be kitted with up to an Intel Core Ultra X9 388H processor with built-in Intel Arc B390 graphics. The whole package is in a 14.9mm thin chassis and the machine weighs 1.55kg (about 3.4 lbs). Closeup of the trackpad on the Acer Swift 16 AI laptopAcer (modified)Another notable element in the company's CES announcements is Acer Swift Edge 14 AI, one of two new lightweight laptops revealed at the event. The Swift Edge 14 AI measures just 13.95mm thick and weighs 0.99kg (about 2.2 lbs). It is powered by up to an Intel Core Ultra 9 processor 386H. The max spec 14-inch screen has a 3KWQXGA+ OLED touch display with 120 Hz refresh rate.Both machines can have up to 32GB of RAM and are part of the Copilot+ PC program. Storage in the Swift 16 AI maxes out at 2TB while the Swift Edge 14 AI be up to 1TB.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/acer-goes-big-on-the-haptic-trackpad-for-ces-with-the-swift-16-ai-laptop-230000750.html?src=rss",
          "feed_position": 21,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/touchpad.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/ces-2026-hp-says-the-hyperx-omen-max-16-is-the-most-powerful-16-inch-gaming-laptop-in-the-world-230000272.html",
          "published_at": "Mon, 05 Jan 2026 23:00:00 +0000",
          "title": "CES 2026: HP says the HyperX Omen Max 16 is the most powerful 16-inch gaming laptop in the world",
          "standfirst": "This year HP is making an important change by taking its name off its gaming hardware entirely and letting its HyperX branding take center stage. At CES 2026, the company is celebrating this transition in a big way with Omen Max 16, which is being heralded as the world’s most powerful gaming laptop with fully internal cooling.Now the last part of that claim is a bit of a cop out, but considering that most gamers probably don’t want to lug around a notebook with hoses coming out the back, it’s an understandable qualifier. Plus, with a total platform power of 300 watts that includes support for the latest chips from Intel and AMD and up to an NVIDIA RTX 5090 GPU, this thing certainly won’t be lacking in speed. Under the hood, the Max 16 features a third cooling fan to prevent throttling under sustained workloads along with HP’s Fan Cleaner tech that reverses the direction of the laptop’s fans to prevent dust from building up inside. As for its design, the Max 16 doesn’t stray too far from HyperX’s signature matte black color scheme, though I do appreciate that the company kept a handful of accents like the RGB lightbar mounted on the laptop’s front lip. The notebook also features a per-key RGB backlit keyboard with a 1,000Hz polling rate, which should all but eliminate any issues with ghosting or rollover during hectic facerolling sessions. However, one quirk about the system I noticed when checking it out first hand is that even with above average brightness of 500 nits for its 2.5K OLED display, the screen also comes with an unusually glossy coating. The benefit of this is that colors appear super saturated. The downside is that especially in well-lit rooms with a lot of sunlight, there’s more glare and reflections than you might expect. Another nice improvement about the Max 16 that might go unnoticed if you only look at its spec sheet is that despite having a TPP of 300 watts, its power brick is relatively compact. It wasn’t all that long ago that a laptop with this kind of performance might have required dual power cables in order to supply the notebook with the amount of juice it needs. That said, weighing between 6.1 and 6.5 pounds depending on the exact configuration, the Max 16 still isn’t the kind of laptop you’re going to want to carry around on a frequent basis. Regardless, if you’re in the market for what is essentially an old-school desktop replacement laptop without moving up to even larger 18-inch machines, HyperX’s latest flagship gaming laptop should be a strong contender that won’t be lacking in speed.One change for 2026 is that HP is taking its name off of its gaming systems and letting the HyperX brand take center stage. Sam Rutherford for EngadgetUnfortunately, HP doesn’t have concrete info about how much the HyperX Omen Max 16 will cost or when it will go on sale. However, we should know more when it becomes available sometime later this spring. And finally, if you’re looking for something slightly smaller or a more affordable system (we don't have official pricing, but the Max 16 won't come cheap), HP is also updating the Omen 15 and Omen 16 with fresh components and new HyperX branding for 2026 as well. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/ces-2026-hp-says-the-hyperx-omen-max-16-is-the-most-powerful-16-inch-gaming-laptop-in-the-world-230000272.html?src=rss",
          "content": "This year HP is making an important change by taking its name off its gaming hardware entirely and letting its HyperX branding take center stage. At CES 2026, the company is celebrating this transition in a big way with Omen Max 16, which is being heralded as the world’s most powerful gaming laptop with fully internal cooling.Now the last part of that claim is a bit of a cop out, but considering that most gamers probably don’t want to lug around a notebook with hoses coming out the back, it’s an understandable qualifier. Plus, with a total platform power of 300 watts that includes support for the latest chips from Intel and AMD and up to an NVIDIA RTX 5090 GPU, this thing certainly won’t be lacking in speed. Under the hood, the Max 16 features a third cooling fan to prevent throttling under sustained workloads along with HP’s Fan Cleaner tech that reverses the direction of the laptop’s fans to prevent dust from building up inside. As for its design, the Max 16 doesn’t stray too far from HyperX’s signature matte black color scheme, though I do appreciate that the company kept a handful of accents like the RGB lightbar mounted on the laptop’s front lip. The notebook also features a per-key RGB backlit keyboard with a 1,000Hz polling rate, which should all but eliminate any issues with ghosting or rollover during hectic facerolling sessions. However, one quirk about the system I noticed when checking it out first hand is that even with above average brightness of 500 nits for its 2.5K OLED display, the screen also comes with an unusually glossy coating. The benefit of this is that colors appear super saturated. The downside is that especially in well-lit rooms with a lot of sunlight, there’s more glare and reflections than you might expect. Another nice improvement about the Max 16 that might go unnoticed if you only look at its spec sheet is that despite having a TPP of 300 watts, its power brick is relatively compact. It wasn’t all that long ago that a laptop with this kind of performance might have required dual power cables in order to supply the notebook with the amount of juice it needs. That said, weighing between 6.1 and 6.5 pounds depending on the exact configuration, the Max 16 still isn’t the kind of laptop you’re going to want to carry around on a frequent basis. Regardless, if you’re in the market for what is essentially an old-school desktop replacement laptop without moving up to even larger 18-inch machines, HyperX’s latest flagship gaming laptop should be a strong contender that won’t be lacking in speed.One change for 2026 is that HP is taking its name off of its gaming systems and letting the HyperX brand take center stage. Sam Rutherford for EngadgetUnfortunately, HP doesn’t have concrete info about how much the HyperX Omen Max 16 will cost or when it will go on sale. However, we should know more when it becomes available sometime later this spring. And finally, if you’re looking for something slightly smaller or a more affordable system (we don't have official pricing, but the Max 16 won't come cheap), HP is also updating the Omen 15 and Omen 16 with fresh components and new HyperX branding for 2026 as well. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/ces-2026-hp-says-the-hyperx-omen-max-16-is-the-most-powerful-16-inch-gaming-laptop-in-the-world-230000272.html?src=rss",
          "feed_position": 22,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Max-16-lid.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-z-trifold-hands-on-flexing-is-believing-at-ces-2026-224343480.html",
          "published_at": "Mon, 05 Jan 2026 22:43:43 +0000",
          "title": "Samsung Galaxy Z TriFold hands-on: Flexing is believing at CES 2026",
          "standfirst": "When I first heard whispers about the Samsung Galaxy Z TriFold, I immediately felt conflicted. On one hand it felt like the natural evolution of bi-fold phones like the Z Fold 7. But on the other, all this fancy tech comes with an even higher price — around $2,500 based on current conversion rates from Korean won — not to mention the added bulk you get from a third folding panel. So even as someone who has used a foldable as my daily driver for almost a decade straight, it felt like Samsung’s latest high-end phone was going backwards in terms of both portability and affordability. But then at CES 2026, I got a chance to go hands-on with the Galaxy Z TriFold and all of my concerns pretty much instantly disappeared because with this thing, flexing is believing.My initial consternation comes in large part from using the Z Fold 7, which hit a major milestone this year thanks to a revamped design that doesn’t come with any added size or weight even when compared to comparable candybar-style phones like the Galaxy S25 Ultra. That’s a major breakthrough considering how hefty and chunky the original Galaxy Fold was back in 2019. And when you compare the Z Fold 7’s dimensions (7.58 ounces and 8.9mm thick when folded) to the new TriFold (10.9 ounces and 12.9mm when folded), there’s no doubt that Samsung’s new flagship foldable comes with a lot of extra bulk. To put things into context, we have to go back several generations to the Z Fold 5 just to find a comparable phone with similar thickness (13.4mm). And even then, that handset is still significantly lighter than the TriFold at 8.92 ounces. There's simply no denying that the Z TriFold (left) is a much bulkier device than the Z Fold 7 (right). Sam Rutherford for EngadgetBut then I opened it up and my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness. As a phone that can pull double duty as a tablet, the jump up from the Z Fold 7’s 8-inch main display cannot be understated. Not only does it make multitasking so much easier, when combined with Samsung’s DeX desktop mode, you basically get a miniature laptop experience from a device that fits in a pocket. Especially if you don’t mind carrying around a travel-friendly mouse and keyboard. Plus, you can connect the TriFold to an external display (either wired or wirelessly) to access even more screen space. Way more than with the Z Fold 7, I can honestly see myself leaving my PC at home and using the TriFold as my primary work device. Another important but easily overlooked upgrade on the Galaxy Z Trifold is the 4:3 aspect ratio for its 10-inch main display. Compared to the Z Fold 7 and its almost perfectly square screen, you just get so much extra room on the sides for widescreen movies and shows. I tested this out by watching the trailer for Christopher Nolan’s The Odyssey, and even though that movie uses a super wide aspect ratio due to being filmed entirely on IMAX cameras, the viewing experience was just so much better. Peak watchability is something the regular Z Fold line has sort of left by the wayside as the company moved to larger exterior displays, which resulted in the series’ primary screen becoming more square. The one downside though is that the TriFold may make you more of a resolution snob, as it’s a lot easier to tell the difference between 1080p and 2K or 4K on a larger 10-inch panel. The final pillar of the TriFold’s kit is all the engineering that Samsung put into making it easy to open and close. Simply moving from one hinge to two while adding a third folding panel undersells the complexity of its design. Samsung actually uses two different types of magnets that push or pull depending on where they are, which makes accessing the TriFold’s primary display practically just as easy as on the Z Fold 7. That’s no small feat. Opening and shutting this thing is just so satisfying on a tactile level, and that’s before you consider that there’s basically no downgrade in terms of image quality. While there’s only one way to unfurl the TriFold, which might seem confusing at first, Samsung addressed that too by throwing up a warning and making the whole phone vibrate if you try to do it wrong. And then there are components like the glass-reinforced carbon panels Samsung uses to add strength and durability to its chassis while keeping it as thin as possible. The one potential concern in the future is that unlike Samsung’s older foldables, there’s not as much room for improvement to shrink its dimensions much further, as the TriFold’s slimness is currently limited by the size of its USB-C jack. So if the next model wants to make big gains there, it may need to go completely portless.Here's what The Odyssey trailer looks like on the Z TriFold (right) compared to the Z Fold 7 (left). It's such a better experience. Sam Rutherford for EngadgetOn a certain level, I kind of hate how much I like the Galaxy Z TriFold. I really don’t want to go back to bigger, heavier phones that are even more bulky and expensive than the Z Fold 7. But the appeal is impossible to deny and for people who love a good multitasker, I can easily see how these tradeoffs are worth the upside of Samsung’s latest apex foldable. The Samsung Galaxy Z TriFold is currently on sale in South Korea, though we’re still waiting for official pricing and availability for the US and North American market.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-z-trifold-hands-on-flexing-is-believing-at-ces-2026-224343480.html?src=rss",
          "content": "When I first heard whispers about the Samsung Galaxy Z TriFold, I immediately felt conflicted. On one hand it felt like the natural evolution of bi-fold phones like the Z Fold 7. But on the other, all this fancy tech comes with an even higher price — around $2,500 based on current conversion rates from Korean won — not to mention the added bulk you get from a third folding panel. So even as someone who has used a foldable as my daily driver for almost a decade straight, it felt like Samsung’s latest high-end phone was going backwards in terms of both portability and affordability. But then at CES 2026, I got a chance to go hands-on with the Galaxy Z TriFold and all of my concerns pretty much instantly disappeared because with this thing, flexing is believing.My initial consternation comes in large part from using the Z Fold 7, which hit a major milestone this year thanks to a revamped design that doesn’t come with any added size or weight even when compared to comparable candybar-style phones like the Galaxy S25 Ultra. That’s a major breakthrough considering how hefty and chunky the original Galaxy Fold was back in 2019. And when you compare the Z Fold 7’s dimensions (7.58 ounces and 8.9mm thick when folded) to the new TriFold (10.9 ounces and 12.9mm when folded), there’s no doubt that Samsung’s new flagship foldable comes with a lot of extra bulk. To put things into context, we have to go back several generations to the Z Fold 5 just to find a comparable phone with similar thickness (13.4mm). And even then, that handset is still significantly lighter than the TriFold at 8.92 ounces. There's simply no denying that the Z TriFold (left) is a much bulkier device than the Z Fold 7 (right). Sam Rutherford for EngadgetBut then I opened it up and my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness. As a phone that can pull double duty as a tablet, the jump up from the Z Fold 7’s 8-inch main display cannot be understated. Not only does it make multitasking so much easier, when combined with Samsung’s DeX desktop mode, you basically get a miniature laptop experience from a device that fits in a pocket. Especially if you don’t mind carrying around a travel-friendly mouse and keyboard. Plus, you can connect the TriFold to an external display (either wired or wirelessly) to access even more screen space. Way more than with the Z Fold 7, I can honestly see myself leaving my PC at home and using the TriFold as my primary work device. Another important but easily overlooked upgrade on the Galaxy Z Trifold is the 4:3 aspect ratio for its 10-inch main display. Compared to the Z Fold 7 and its almost perfectly square screen, you just get so much extra room on the sides for widescreen movies and shows. I tested this out by watching the trailer for Christopher Nolan’s The Odyssey, and even though that movie uses a super wide aspect ratio due to being filmed entirely on IMAX cameras, the viewing experience was just so much better. Peak watchability is something the regular Z Fold line has sort of left by the wayside as the company moved to larger exterior displays, which resulted in the series’ primary screen becoming more square. The one downside though is that the TriFold may make you more of a resolution snob, as it’s a lot easier to tell the difference between 1080p and 2K or 4K on a larger 10-inch panel. The final pillar of the TriFold’s kit is all the engineering that Samsung put into making it easy to open and close. Simply moving from one hinge to two while adding a third folding panel undersells the complexity of its design. Samsung actually uses two different types of magnets that push or pull depending on where they are, which makes accessing the TriFold’s primary display practically just as easy as on the Z Fold 7. That’s no small feat. Opening and shutting this thing is just so satisfying on a tactile level, and that’s before you consider that there’s basically no downgrade in terms of image quality. While there’s only one way to unfurl the TriFold, which might seem confusing at first, Samsung addressed that too by throwing up a warning and making the whole phone vibrate if you try to do it wrong. And then there are components like the glass-reinforced carbon panels Samsung uses to add strength and durability to its chassis while keeping it as thin as possible. The one potential concern in the future is that unlike Samsung’s older foldables, there’s not as much room for improvement to shrink its dimensions much further, as the TriFold’s slimness is currently limited by the size of its USB-C jack. So if the next model wants to make big gains there, it may need to go completely portless.Here's what The Odyssey trailer looks like on the Z TriFold (right) compared to the Z Fold 7 (left). It's such a better experience. Sam Rutherford for EngadgetOn a certain level, I kind of hate how much I like the Galaxy Z TriFold. I really don’t want to go back to bigger, heavier phones that are even more bulky and expensive than the Z Fold 7. But the appeal is impossible to deny and for people who love a good multitasker, I can easily see how these tradeoffs are worth the upside of Samsung’s latest apex foldable. The Samsung Galaxy Z TriFold is currently on sale in South Korea, though we’re still waiting for official pricing and availability for the US and North American market.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-z-trifold-hands-on-flexing-is-believing-at-ces-2026-224343480.html?src=rss",
          "feed_position": 24,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/TriFold-thickness.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/tiis-falcon-h1r-7b-can-out-reason-models-up-to-7x-its-size-and-its-mostly",
          "published_at": "Mon, 05 Jan 2026 20:27:00 GMT",
          "title": "TII’s Falcon H1R 7B can out-reason models up to 7x its size — and it’s (mostly) open",
          "standfirst": "For the last two years, the prevailing logic in generative AI has been one of brute force: if you want better reasoning, you need a bigger model. While \"small\" models (under 10 billion parameters) have become capable conversationalists, they have historically crumbled when asked to perform multi-step logical deduction or complex mathematical proofs.Today, the Technology Innovation Institute (TII) in Abu Dhabi is challenging that scaling law with the release of Falcon H1R 7B. By abandoning the pure Transformer orthodoxy in favor of a hybrid architecture, TII claims to have built a 7-billion parameter model that not only rivals but outperforms competitors nearly 7X its size — including the 32B and 47B variants of Alibaba&#x27;s Qwen and Nvidia&#x27;s Nemotron.The release marks a significant shift in the open-weight ecosystem, moving the battleground from raw parameter count to architectural efficiency and inference-time scaling.The full model code is available now at Hugging Face and can be tested by individuals in a live demo inference on Falcon Chat (a chatbot experience). TII further released a seemingly quite comprehensive technical report on the approach and training methodology for Falcon H1 7B, as well. Moving Beyond the Foundational LLM Tech, the TransformerThe defining feature of Falcon H1R 7B is its \"hybrid\" backbone. Most modern LLMs rely exclusively on the Transformer architecture, which scales predictably but suffers from high memory costs when processing long sequences. Falcon H1R 7B integrates Mamba, a state-space model (SSM) architecture, alongside standard Transformer attention layers.Originally developed by researchers Albert Gu and Tri Dao at Carnegie Mellon University and Princeton University, Mamba was first introduced in the paper \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\" published on December 1, 2023.The architecture processes data sequences differently than Transformers: while Transformers compare every piece of data to every other piece (quadratic scaling), Mamba processes tokens sequentially, allowing it to handle vast amounts of information with linear scaling and significantly reduced compute costs.This combination addresses one of the most persistent bottlenecks in deploying reasoning models: the cost of \"thinking.\" Reasoning models require generating long \"chains of thought\"—step-by-step internal monologues—before arriving at an answer. For standard Transformers, these long contexts explode computational costs.According to TII’s technical report, the hybrid approach allows Falcon H1R 7B to maintain high throughput even as response lengths grow. At a batch size of 64, the model processes approximately 1,500 tokens per second per GPU—nearly double the speed of the competing Qwen3 8B model.Benchmark Performance: Punching UpIn the benchmarks released by TII, the disparity between Falcon H1R 7B’s size and its performance is stark. On the AIME 2025 leaderboard—a rigorous test of mathematical reasoning—Falcon H1R 7B scored 83.1%, a result that disrupts the traditional hierarchy of model sizing.While the 7B model naturally trails massive proprietary frontiers like GPT-5.2 (99.0%) and Gemini 3 Flash (97.0%) on the separate Artificial Analysis index (run by the independent organization of the same name, which has not yet benchmarked Falcon H1R 7B yet), it has effectively collapsed the gap between \"efficient\" open weights and mid-tier proprietary systems.Beating Larger \"Thinkers\": Falcon H1R 7B (83.1%) outperforms the 15-billion parameter Apriel-v1.6-Thinker (82.7%) and the 32-billion parameter OLMo 3 Think (73.7%), validating TII&#x27;s claim that hybrid architectures can out-reason larger Transformers.Chasing Proprietary Leaders: It sits within striking distance of Claude 4.5 Sonnet (88.0%) and Amazon Nova 2.0 Lite (88.7%), suggesting that for specific math-heavy workflows, this 7B model is a viable, low-latency alternative to expensive commercial APIs.Outperforming Legacy Giants: On this specific reasoning metric, it decisively beats broadly capable but older architectures like Mistral Large 3 (38.0%) and Llama 4 Maverick (19.3%), highlighting how specialized reasoning training (\"Deep Think\") has become more critical than raw scale for logic tasks.Other key domain wins include:Coding: The model achieved 68.6% on the LCB v6 benchmark, a score TII claims is the highest among all tested models, including those four times its size.General Reasoning: While it dominates in math and code, its general reasoning score (49.48%) remains competitive, sitting just below the 14B and 15B parameter models but comfortably ahead of comparable 8B models.Training TechniquesFalcon H1R 7B’s performance is not just architectural; it stems from a rigorous, two-stage training pipeline designed to maximize reasoning density without inflating parameter count, according to TII&#x27;s technical report on the model.Stage 1: Cold-Start Supervised Fine-Tuning (SFT). The model underwent \"cold-start\" SFT on a curated dataset dominated by mathematics (56.8% of tokens) and code (29.8%), with response lengths stretching up to 48,000 tokens.Difficulty-Aware Weighting: TII rejected the standard practice of treating all data equally. Instead, they applied a weighting scheme where \"hard\" problems were up-weighted by 1.25x to 1.75x, while easy problems were down-weighted or removed entirely to prevent overfitting to trivial tasks.Single-Teacher Consistency: Ablation studies revealed that mixing reasoning traces from multiple \"teacher\" models actually degraded performance due to conflicting reasoning styles. Consequently, TII opted for a single-teacher approach to maintain coherent internal logic.Balanced Token Normalization: To handle the massive variance in sequence lengths (short instructions vs. massive reasoning chains), the team introduced a Balanced Data-Parallel Token Normalization strategy. This technique equalizes the gradient contribution of each token across GPUs, preventing ranks with shorter sequences from destabilizing the loss—a change that yielded a consistent 4-10% accuracy boost during training.Stage 2: Reinforcement Learning via Group Relative Policy Optimization (GRPO). Following SFT, the model was refined using GRPO a reinforcement learning algorithm that rewards correct outcomes without needing a separate value model.The \"No-KL\" Shift: In a deviation from standard RLHF, TII removed the KL-divergence penalty (beta=0) entirely. This allowed the model to drift significantly from its base SFT policy, encouraging aggressive exploration of novel reasoning paths.Math-Only Curriculum: Surprisingly, TII found that training exclusively on math problems during the RL stage yielded better generalization across all domains—including code and science—than mixed strategies. Ablations showed that \"code-only\" training improved coding scores but harmed general reasoning, whereas math-focused RL lifted performance globally.TII optimized the model specifically for Test-Time Scaling (TTS), a technique where a model generates multiple reasoning paths in parallel to find the best solution.The model utilizes Deep Think with Confidence (DeepConf), which leverages the model&#x27;s internal confidence scores to dynamically prune low-quality reasoning traces.Adaptive Pruning: During generation, the system initiates a \"warm-up\" phase with 16 traces to establish a confidence baseline. It then aggressively filters subsequent traces, terminating any chain that falls below the 10th percentile of the baseline confidence.Efficiency Gains: This method creates a new Pareto frontier for deployment. In benchmark tests, Falcon H1R 7B achieved 96.7% accuracy on AIME 25 while reducing token usage by 38% compared to the DeepSeek-R1-0528-Qwen3-8B baseline.Licensing: Open For Commercial Usage, But With Strings AttachedTII has released Falcon H1R 7B under the custom Falcon LLM License 1.0 based on Apache 2.0 — but with notable modifications — chiefly among them: not to litigate against TII, and also to always credit it.For developers and startups, the license is largely permissive:Royalty-Free: Users can run, modify, and distribute the model commercially without paying TII.Attribution: Any derivative work (including fine-tunes) must prominently state: \"[Name of work] is built using Falcon LLM technology from the Technology Innovation Institute\".However, unlike a pure Open Source Initiative (OSI) license, the Falcon license includes a strict Acceptable Use Policy (AUP). The license terminates automatically if the model is used to create work that conflicts with the AUP or if the user initiates patent litigation against TII. Specifically, the AUP prohibits using Falcon H1R 7B or its derivatives for:Violating Laws: Any use that violates applicable national, federal, state, local, or international laws or regulations.Harm to Minors or Living Beings: Exploiting, harming, or attempting to exploit or harm minors or any living beings.Disinformation: Generating or disseminating verifiably false information with the purpose of harming others.Harassment: Defaming, disparaging, or otherwise harassing others.The Hybrid Wave: Nvidia, IBM, AI21, and MistralTII is not alone in betting on this hybrid future; the industry is increasingly moving toward architectures that blend the strengths of SSMs and Transformers.Nvidia recently debuted the Nemotron 3 family on December 15, 2025, which utilizes a hybrid mixture-of-experts (MoE) and Mamba-Transformer design to drive efficient agentic AI.IBM launched its Granite 4.0 family on October 2, 2025, using a hybrid Mamba-Transformer architecture to cut memory requirements by over 70% while maintaining high performance on enterprise benchmarks.AI21 has pursued this path with its Jamba (Joint Attention and Mamba) models, releasing the Jamba 1.5 family on August 22, 2024, to boost agentic AI capabilities through a hybrid SSM-Transformer approach.Mistral entered the space early with Codestral Mamba on July 16, 2024, a model specifically optimized for faster, longer code generation.Falcon H1R 7B represents the latest evolution in this trend, specifically targeting dense reasoning tasks in a compact form factor.",
          "content": "For the last two years, the prevailing logic in generative AI has been one of brute force: if you want better reasoning, you need a bigger model. While \"small\" models (under 10 billion parameters) have become capable conversationalists, they have historically crumbled when asked to perform multi-step logical deduction or complex mathematical proofs.Today, the Technology Innovation Institute (TII) in Abu Dhabi is challenging that scaling law with the release of Falcon H1R 7B. By abandoning the pure Transformer orthodoxy in favor of a hybrid architecture, TII claims to have built a 7-billion parameter model that not only rivals but outperforms competitors nearly 7X its size — including the 32B and 47B variants of Alibaba&#x27;s Qwen and Nvidia&#x27;s Nemotron.The release marks a significant shift in the open-weight ecosystem, moving the battleground from raw parameter count to architectural efficiency and inference-time scaling.The full model code is available now at Hugging Face and can be tested by individuals in a live demo inference on Falcon Chat (a chatbot experience). TII further released a seemingly quite comprehensive technical report on the approach and training methodology for Falcon H1 7B, as well. Moving Beyond the Foundational LLM Tech, the TransformerThe defining feature of Falcon H1R 7B is its \"hybrid\" backbone. Most modern LLMs rely exclusively on the Transformer architecture, which scales predictably but suffers from high memory costs when processing long sequences. Falcon H1R 7B integrates Mamba, a state-space model (SSM) architecture, alongside standard Transformer attention layers.Originally developed by researchers Albert Gu and Tri Dao at Carnegie Mellon University and Princeton University, Mamba was first introduced in the paper \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\" published on December 1, 2023.The architecture processes data sequences differently than Transformers: while Transformers compare every piece of data to every other piece (quadratic scaling), Mamba processes tokens sequentially, allowing it to handle vast amounts of information with linear scaling and significantly reduced compute costs.This combination addresses one of the most persistent bottlenecks in deploying reasoning models: the cost of \"thinking.\" Reasoning models require generating long \"chains of thought\"—step-by-step internal monologues—before arriving at an answer. For standard Transformers, these long contexts explode computational costs.According to TII’s technical report, the hybrid approach allows Falcon H1R 7B to maintain high throughput even as response lengths grow. At a batch size of 64, the model processes approximately 1,500 tokens per second per GPU—nearly double the speed of the competing Qwen3 8B model.Benchmark Performance: Punching UpIn the benchmarks released by TII, the disparity between Falcon H1R 7B’s size and its performance is stark. On the AIME 2025 leaderboard—a rigorous test of mathematical reasoning—Falcon H1R 7B scored 83.1%, a result that disrupts the traditional hierarchy of model sizing.While the 7B model naturally trails massive proprietary frontiers like GPT-5.2 (99.0%) and Gemini 3 Flash (97.0%) on the separate Artificial Analysis index (run by the independent organization of the same name, which has not yet benchmarked Falcon H1R 7B yet), it has effectively collapsed the gap between \"efficient\" open weights and mid-tier proprietary systems.Beating Larger \"Thinkers\": Falcon H1R 7B (83.1%) outperforms the 15-billion parameter Apriel-v1.6-Thinker (82.7%) and the 32-billion parameter OLMo 3 Think (73.7%), validating TII&#x27;s claim that hybrid architectures can out-reason larger Transformers.Chasing Proprietary Leaders: It sits within striking distance of Claude 4.5 Sonnet (88.0%) and Amazon Nova 2.0 Lite (88.7%), suggesting that for specific math-heavy workflows, this 7B model is a viable, low-latency alternative to expensive commercial APIs.Outperforming Legacy Giants: On this specific reasoning metric, it decisively beats broadly capable but older architectures like Mistral Large 3 (38.0%) and Llama 4 Maverick (19.3%), highlighting how specialized reasoning training (\"Deep Think\") has become more critical than raw scale for logic tasks.Other key domain wins include:Coding: The model achieved 68.6% on the LCB v6 benchmark, a score TII claims is the highest among all tested models, including those four times its size.General Reasoning: While it dominates in math and code, its general reasoning score (49.48%) remains competitive, sitting just below the 14B and 15B parameter models but comfortably ahead of comparable 8B models.Training TechniquesFalcon H1R 7B’s performance is not just architectural; it stems from a rigorous, two-stage training pipeline designed to maximize reasoning density without inflating parameter count, according to TII&#x27;s technical report on the model.Stage 1: Cold-Start Supervised Fine-Tuning (SFT). The model underwent \"cold-start\" SFT on a curated dataset dominated by mathematics (56.8% of tokens) and code (29.8%), with response lengths stretching up to 48,000 tokens.Difficulty-Aware Weighting: TII rejected the standard practice of treating all data equally. Instead, they applied a weighting scheme where \"hard\" problems were up-weighted by 1.25x to 1.75x, while easy problems were down-weighted or removed entirely to prevent overfitting to trivial tasks.Single-Teacher Consistency: Ablation studies revealed that mixing reasoning traces from multiple \"teacher\" models actually degraded performance due to conflicting reasoning styles. Consequently, TII opted for a single-teacher approach to maintain coherent internal logic.Balanced Token Normalization: To handle the massive variance in sequence lengths (short instructions vs. massive reasoning chains), the team introduced a Balanced Data-Parallel Token Normalization strategy. This technique equalizes the gradient contribution of each token across GPUs, preventing ranks with shorter sequences from destabilizing the loss—a change that yielded a consistent 4-10% accuracy boost during training.Stage 2: Reinforcement Learning via Group Relative Policy Optimization (GRPO). Following SFT, the model was refined using GRPO a reinforcement learning algorithm that rewards correct outcomes without needing a separate value model.The \"No-KL\" Shift: In a deviation from standard RLHF, TII removed the KL-divergence penalty (beta=0) entirely. This allowed the model to drift significantly from its base SFT policy, encouraging aggressive exploration of novel reasoning paths.Math-Only Curriculum: Surprisingly, TII found that training exclusively on math problems during the RL stage yielded better generalization across all domains—including code and science—than mixed strategies. Ablations showed that \"code-only\" training improved coding scores but harmed general reasoning, whereas math-focused RL lifted performance globally.TII optimized the model specifically for Test-Time Scaling (TTS), a technique where a model generates multiple reasoning paths in parallel to find the best solution.The model utilizes Deep Think with Confidence (DeepConf), which leverages the model&#x27;s internal confidence scores to dynamically prune low-quality reasoning traces.Adaptive Pruning: During generation, the system initiates a \"warm-up\" phase with 16 traces to establish a confidence baseline. It then aggressively filters subsequent traces, terminating any chain that falls below the 10th percentile of the baseline confidence.Efficiency Gains: This method creates a new Pareto frontier for deployment. In benchmark tests, Falcon H1R 7B achieved 96.7% accuracy on AIME 25 while reducing token usage by 38% compared to the DeepSeek-R1-0528-Qwen3-8B baseline.Licensing: Open For Commercial Usage, But With Strings AttachedTII has released Falcon H1R 7B under the custom Falcon LLM License 1.0 based on Apache 2.0 — but with notable modifications — chiefly among them: not to litigate against TII, and also to always credit it.For developers and startups, the license is largely permissive:Royalty-Free: Users can run, modify, and distribute the model commercially without paying TII.Attribution: Any derivative work (including fine-tunes) must prominently state: \"[Name of work] is built using Falcon LLM technology from the Technology Innovation Institute\".However, unlike a pure Open Source Initiative (OSI) license, the Falcon license includes a strict Acceptable Use Policy (AUP). The license terminates automatically if the model is used to create work that conflicts with the AUP or if the user initiates patent litigation against TII. Specifically, the AUP prohibits using Falcon H1R 7B or its derivatives for:Violating Laws: Any use that violates applicable national, federal, state, local, or international laws or regulations.Harm to Minors or Living Beings: Exploiting, harming, or attempting to exploit or harm minors or any living beings.Disinformation: Generating or disseminating verifiably false information with the purpose of harming others.Harassment: Defaming, disparaging, or otherwise harassing others.The Hybrid Wave: Nvidia, IBM, AI21, and MistralTII is not alone in betting on this hybrid future; the industry is increasingly moving toward architectures that blend the strengths of SSMs and Transformers.Nvidia recently debuted the Nemotron 3 family on December 15, 2025, which utilizes a hybrid mixture-of-experts (MoE) and Mamba-Transformer design to drive efficient agentic AI.IBM launched its Granite 4.0 family on October 2, 2025, using a hybrid Mamba-Transformer architecture to cut memory requirements by over 70% while maintaining high performance on enterprise benchmarks.AI21 has pursued this path with its Jamba (Joint Attention and Mamba) models, releasing the Jamba 1.5 family on August 22, 2024, to boost agentic AI capabilities through a hybrid SSM-Transformer approach.Mistral entered the space early with Codestral Mamba on July 16, 2024, a model specifically optimized for faster, longer code generation.Falcon H1R 7B represents the latest evolution in this trend, specifically targeting dense reasoning tasks in a compact form factor.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6S3Um2MKMQJZavLvb5iEzH/7f8270446a2734c8c6a2d1150b2fc332/9-x0igmpkjXB7E9vru3gT.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/nvidias-cosmos-reason-2-aims-to-bring-reasoning-vlms-into-the-physical-world",
          "published_at": "Mon, 05 Jan 2026 20:00:00 GMT",
          "title": "Nvidia’s Cosmos Reason 2 aims to bring reasoning VLMs into the physical world",
          "standfirst": "Nvidia CEO Jensen Huang said last year that we are now entering the age of physical AI. While the company continues to offer LLMs for software use cases, Nvidia is increasingly positioning itself as a provider of AI models for fully AI-powered systems — including agentic AI in the physical world.At CES 2026, Nvidia announced a slate of new models designed to push AI agents beyond chat interfaces and into physical environments.Nvidia launched Cosmos Reason 2, the latest version of its vision-language model designed for embodied reasoning. Cosmos Reason 1, released last year, introduced a two-dimensional ontology for embodied reasoning and currently leads Hugging Face’s physical reasoning for video leaderboard.Cosmos Reason 2 builds on the same ontology while giving enterprises more flexibility to customize applications and enabling physical agents to plan their next actions, similar to how software-based agents reason through digital workflows.Nvidia also released a new version of Cosmos Transfer, a model that lets developers generate training simulations for robots.Other vision-language models, such as Google’s PaliGemma and Pixtral Large from Mistral, can process visual inputs, but not all commercially available VLMs support reasoning.“Robotics is at an inflection point. We are moving from specialist robots limited to single tasks to generalist specialist systems,” said Kari Briski, Nvidia vice president for generative AI software, in a briefing with reporters. She was referring to robots that combine broad foundational knowledge with deep task-specific skills. “These new robots combine broad fundamental knowledge with deep proficiency and complex tasks.”She added that Cosmos Reason 2 “enhances the reasoning capabilities that robots need to navigate the unpredictable physical world.”Moving to physical agentsBriski noted that Nvidia’s roadmap follows “the same pattern of assets across all of our open models.”“In building specialized AI agents, a digital workforce, or the physical embodiment of AI in robots and autonomous vehicles, more than just the model is needed,” Briski said. “First, the AI needs the compute resources to train, simulate the world around it. Data is the fuel for AI to learn and improve and we contribute to the world&#x27;s largest collection of open and diverse datasets, going beyond just opening the weights of the models. The open libraries and training scripts give developers the tools to purpose-build AI for their applications, and we publish blueprints and examples to help deploy AI as systems of models.”The company now has open models specifically for physical AI in Cosmos, robotics, with the open-reasoning vision-language-action (VLA) model Gr00t and its Nemotron models for agentic AI. Nvidia is making the case that open models across different branches of AI form a shared enterprise ecosystem that feeds data, training, and reasoning to agents in both the digital and physical worlds. Additions to the Nemotron familyBriski said Nvidia plans to continue expanding its open models, including its Nemotron family, beyond reasoning to include a new RAG and embeddings model to make information more readily available to agents. The company released Nemotron 3, the latest version of its agentic reasoning models, in December. Nvidia announced three new additions to the Nemotron family: Nemotron Speech, Nemotron RAG and Nemotron Safety. In a blog post, Nvidia said Nemotron Speech delivers “real-time low-latency speech recognition for live captions and speech AI applications” and is 10 times faster than other speech models. Nemotron RAG is technically comprised of two models: an embedding model and a rerank model, both of which can understand images to provide more multimodal insights that data agents will tap. “Nemotron RAG is on top of what we call the MMTab, or the Massive Multilingual Text Embedding Benchmark, with strong multilingual performance while using less computing power memory, so they are a good fit for systems that must handle a lot of requests very quickly and with low delay,” Briski said. Nemotron Safety detects sensitive data so AI agents do not accidentally unleash personally identifiable data.",
          "content": "Nvidia CEO Jensen Huang said last year that we are now entering the age of physical AI. While the company continues to offer LLMs for software use cases, Nvidia is increasingly positioning itself as a provider of AI models for fully AI-powered systems — including agentic AI in the physical world.At CES 2026, Nvidia announced a slate of new models designed to push AI agents beyond chat interfaces and into physical environments.Nvidia launched Cosmos Reason 2, the latest version of its vision-language model designed for embodied reasoning. Cosmos Reason 1, released last year, introduced a two-dimensional ontology for embodied reasoning and currently leads Hugging Face’s physical reasoning for video leaderboard.Cosmos Reason 2 builds on the same ontology while giving enterprises more flexibility to customize applications and enabling physical agents to plan their next actions, similar to how software-based agents reason through digital workflows.Nvidia also released a new version of Cosmos Transfer, a model that lets developers generate training simulations for robots.Other vision-language models, such as Google’s PaliGemma and Pixtral Large from Mistral, can process visual inputs, but not all commercially available VLMs support reasoning.“Robotics is at an inflection point. We are moving from specialist robots limited to single tasks to generalist specialist systems,” said Kari Briski, Nvidia vice president for generative AI software, in a briefing with reporters. She was referring to robots that combine broad foundational knowledge with deep task-specific skills. “These new robots combine broad fundamental knowledge with deep proficiency and complex tasks.”She added that Cosmos Reason 2 “enhances the reasoning capabilities that robots need to navigate the unpredictable physical world.”Moving to physical agentsBriski noted that Nvidia’s roadmap follows “the same pattern of assets across all of our open models.”“In building specialized AI agents, a digital workforce, or the physical embodiment of AI in robots and autonomous vehicles, more than just the model is needed,” Briski said. “First, the AI needs the compute resources to train, simulate the world around it. Data is the fuel for AI to learn and improve and we contribute to the world&#x27;s largest collection of open and diverse datasets, going beyond just opening the weights of the models. The open libraries and training scripts give developers the tools to purpose-build AI for their applications, and we publish blueprints and examples to help deploy AI as systems of models.”The company now has open models specifically for physical AI in Cosmos, robotics, with the open-reasoning vision-language-action (VLA) model Gr00t and its Nemotron models for agentic AI. Nvidia is making the case that open models across different branches of AI form a shared enterprise ecosystem that feeds data, training, and reasoning to agents in both the digital and physical worlds. Additions to the Nemotron familyBriski said Nvidia plans to continue expanding its open models, including its Nemotron family, beyond reasoning to include a new RAG and embeddings model to make information more readily available to agents. The company released Nemotron 3, the latest version of its agentic reasoning models, in December. Nvidia announced three new additions to the Nemotron family: Nemotron Speech, Nemotron RAG and Nemotron Safety. In a blog post, Nvidia said Nemotron Speech delivers “real-time low-latency speech recognition for live captions and speech AI applications” and is 10 times faster than other speech models. Nemotron RAG is technically comprised of two models: an embedding model and a rerank model, both of which can understand images to provide more multimodal insights that data agents will tap. “Nemotron RAG is on top of what we call the MMTab, or the Massive Multilingual Text Embedding Benchmark, with strong multilingual performance while using less computing power memory, so they are a good fit for systems that must handle a lot of requests very quickly and with low delay,” Briski said. Nemotron Safety detects sensitive data so AI agents do not accidentally unleash personally identifiable data.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2dOxvcQe247RRe0QqURNoc/4226294f75548d9fb351c7df254ff529/crimedy7_illustration_of_robots_learning_in_a_school_--ar_169_ff89c646-4604-4650-88d5-14713adf2cdc_3.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-press-conference-live-190051823.html",
          "published_at": "Mon, 05 Jan 2026 19:59:08 +0000",
          "title": "How to watch the Hyundai CES 2026 press conference live",
          "standfirst": "Hyundai CES has long felt like a full-on auto show, but the car-centric energy seems somewhat muted at CES 2026. Sure, the Afeela electric vehicle from the Sony-Honda joint venture is returning to the show floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That includes Hyundai. While the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES week — including its Holographic Windshield Display — we're hearing the Korean auto giant will instead use its press conference to focus on its AI Robotics Strategy. That will apparently include showcasing its new Atlas robot, as well as the wheeled MobED robot line. We'll get into the details below, along with how to watch it today. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place today, January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. (We've embedded the link below.) We'll also post relevant news from the Hyundai presser in our main CES 2026 liveblog. What to expect from Hyundai at CES 2026 Hyundai is putting a huge focus on its AI Robotics Strategy during its presentation today — the theme is \"Partnering Human Progress.\" That'll include its strategies for commercializing AI-enhanced robotics, keeping with the very AI-centric focus of this year's CES. We'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. But Atlas isn't the only robot the company has up its sleeve. There's also the MobED Droid, a wheeled 'bot that scored a CES 2026 Innovation Award as the show opened this week. While on stage, Hyundai says it will \"reveal its strategic AI Robotics learning, training and expansion plans,\" via its Group Value Network and Software-Defined Factory approach. That includes a manufacturing strategy and an advanced smart factory. We originally thought Hyundai would showcase its Holographic Windshield Display during its press conference, but a Hyundai representative notified us it won't be featured today. It will have a separate CES presence, though not a separate press conference. Update, January 5 2026, 2:58PM ET: This story has been updated to include information on the MobED robot line, and to note that the Holographic Windshield Display likely won't be featured at the press conference.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-press-conference-live-190051823.html?src=rss",
          "content": "Hyundai CES has long felt like a full-on auto show, but the car-centric energy seems somewhat muted at CES 2026. Sure, the Afeela electric vehicle from the Sony-Honda joint venture is returning to the show floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That includes Hyundai. While the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES week — including its Holographic Windshield Display — we're hearing the Korean auto giant will instead use its press conference to focus on its AI Robotics Strategy. That will apparently include showcasing its new Atlas robot, as well as the wheeled MobED robot line. We'll get into the details below, along with how to watch it today. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place today, January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. (We've embedded the link below.) We'll also post relevant news from the Hyundai presser in our main CES 2026 liveblog. What to expect from Hyundai at CES 2026 Hyundai is putting a huge focus on its AI Robotics Strategy during its presentation today — the theme is \"Partnering Human Progress.\" That'll include its strategies for commercializing AI-enhanced robotics, keeping with the very AI-centric focus of this year's CES. We'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. But Atlas isn't the only robot the company has up its sleeve. There's also the MobED Droid, a wheeled 'bot that scored a CES 2026 Innovation Award as the show opened this week. While on stage, Hyundai says it will \"reveal its strategic AI Robotics learning, training and expansion plans,\" via its Group Value Network and Software-Defined Factory approach. That includes a manufacturing strategy and an advanced smart factory. We originally thought Hyundai would showcase its Holographic Windshield Display during its press conference, but a Hyundai representative notified us it won't be featured today. It will have a separate CES presence, though not a separate press conference. Update, January 5 2026, 2:58PM ET: This story has been updated to include information on the MobED robot line, and to note that the Holographic Windshield Display likely won't be featured at the press conference.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-press-conference-live-190051823.html?src=rss",
          "feed_position": 28,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/938979f0-e9dd-11f0-b73f-c1acf71c1faf"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/everything-announced-at-ces-2026-130124802.html",
          "published_at": "Mon, 05 Jan 2026 19:40:29 +0000",
          "title": "Everything announced at CES 2026",
          "standfirst": "It's the first week of a new year and there's no time for the tech world to slowly ease back into things following the holidays. That's because CES 2026 is in full swing, with all manner of companies descending on Las Vegas to reveal their latest innovations and what they're planning to bring your way in the near future. Many of the Engadget crew are on the ground to check out as much of the new tech as possible. Of course, we're keeping tabs on all of the major CES press conferences too. Samsung has already held its First Look presentation, which focuses on home products, while LG has shown off a wide array of TVs and Lego unveiled its new Smart Brick technology. Presentations from NVIDIA, Sony, Lego, Hyundai and others are yet to come.You can catch up on all of the big CES 2026 announcements (and some of the more offbeat gizmos that are being shown off at the event) right here. We'll be keeping this story updated throughout the week. Micro RGB TVs Samsung's 130-inch Micro RGB TV. Devindra Hardawar for EngadgetMicro RGB is a term you can expect to hear about quite a bit in the coming months and years, especially when you're shopping for your next TV. Micro RGB is a new tech that's similar to Mini LED, though it uses red, green and blue LEDs instead of white backlights. Contrast ratios aren't quite as high as those on Micro LED and OLED displays, since the pixels can't be turned on and off individually. However, Micro RGB units are said to be brighter and more color accurate than TVs that use other display tech, in part because the LEDs in these screens offer smaller, more customizable dimming zones. We're seeing more of these TVs pop up at CES 2026, including a mammoth 130-inch concept model that Samsung brought to Las Vegas. The company unveiled its first Micro RGB TV in August, — that’s a 115-inch, $29,999 model. This year, you can expect it to start offering Micro RGB TVs in 55-, 65- and 75-inch sizes. There are also 85-, 100- and 115-inch models on the way.LG revealed its first Micro RGB set at CES as well. The largest variant is 100 inches, but there are 86- and 75-inch models too. Elsewhere, LG showed off its latest Wallpaper TV, which is a 100-inch OLED display. We also got a look at LG's new Gallery TV — The Gallery is the company's take on Samsung's Frame TV format.Other new TVs and OS updatesEmber Artline TV.AmazonWe’ve got another competitor to The Frame, as Amazon has entered that scene with the Ember Artline TV. The 4K OLED model has Amazon Photos integration and you can choose from 2,000 pieces of free art to show on the screen. The Ember Artline can switch on or off automatically when someone enters or leaves the room. It runs on the Fire TV platform and (of course) there’s Alexa+ integration, along with support for Dolby Vision, HDR10+ and Wi-Fi 6. The Ember Artline is expected to start shipping this spring. It starts at $899 for the 55-inch model.The rounder redesigned Fire TV UI.AmazonSpeaking of Fire TV, Amazon has revamped the platform’s user interface with rounded corners for show, movie and app tiles; a little more space for said tiles; and typography and color gradient changes. The company has reworked the platform’s codebase as well, and it says the Fire TV OS will deliver speed boosts of up to 20 to 30 percent. Amazon will start rolling out the updated UI next month.On the Google side of TV land, you can expect more Gemini-powered features. The company is bringing the ability to search Google Photos for certain moments and people to Google TV, along with the options to remix photos into different styles and create slideshows on the fly. The Veo and Nano Banana AI video and photo generation models are coming to Google TV as well. You can also expect the ability to adjust TV settings using your voice. These Gemini features are coming to Google TV-powered TCL models first, then other devices in the following months.SamsungSamsung's Music Studio 5 speakers at CES 2026.Billy Steele for EngadgetSamsung being Samsung, the company had a lot more up its sleeve at CES than just TVs. In the leadup to the event, it announced its two new soundbars (we're had some hands-on time with one of those), the stylish Music Studio speakers (we've got some IRL impressions of those), a bunch of monitors, the refreshed FreeStyle+ projector (we've checked that out too). It also announced plans to bring Google Photos to TVs.At the First Look showcase on Sunday, Samsung talked up \"AI experiences everywhere. For everyone\" (sigh). Here, we saw more TVs, such as the thin S95H OLED, which has a zero-gap mount that allows you to position the unit flush against a wall. First Look has long been focused on home products. Naturally, Samsung execs discussed some features for the company's fridges, such as ​​recipe selection updates, AI cooling tech and Google Gemini-powered AI Vision that's said to be able to recognize more items and help you figure out what you need to buy without having to manually take inventory. FoodNote, meanwhile, is a weekly summary that breaks down what has gone in and out of your fridge.Moreover, Samsung highlighted the Samsung Bespoke AI Laundry Combo and its new AI wash cycle. With the new Air Dresser — which has an Auto Wrinkle Care feature — Samsung aims to do away with irons (thank you, Samsung). As for the Bespoke AI smart vacuum and mop, that can apparently keep an eye on your pets when you're not home.LGLG's CLOiD robot.LGLikewise, LG brought other non-TV tech to CES. The company is shining the spotlight on its CLOiD robot. Like the far creepier-looking 1X Neo, the CLOiD is designed to help with household tasks such as starting laundry cycles, folding clothes, unloading the dishwasher and serving food. This appears to be more of a concept than something you'll be able to buy anytime soon, but we should get a closer look at the CLOiD in person this week.The company also debuted the LG Sound Suite, a modular home audio system it developed in conjunction with Dolby to take on the likes of Sonos. Just ahead of CES, LG pulled back the curtain on a new batch of xboom speakers as well as some monitors and ultralight Gram laptops that are made with a material it's calling Aerominum. LegoLego introduced the Smart Brick at CES 2026.LegoIn its first CES appearance, Lego announced the Smart Brick, a standard-sized brick with a 4.1mm ASIC chip inside that’s designed to respond in different ways depending on what set you’re building and how you’re building it. Using what Lego calls the “Play Engine” and integrated copper coils, each brick can sense things like motion, orientation and magnetic fields, plus its own distance, direction and orientation in relation to other Smart Bricks. Each brick also has a teeny tiny speaker built in that will play audio “tied to live play actions” rather than only pre-recorded clips.Accompanying Smart Bricks are Smart Tags and Smart Minifigures, which have their own capabilities — one of which is letting Smart Bricks know what context they are being used in. All of these pieces tie together via a local wireless layer dubbed BrickNet that, in part, lets Smart Bricks know where they are placed in relation to other smart components.The first “Smart Play” partner is, unsurprisingly, Star Wars, which will launch three “all-in-one” sets using Smart Bricks, Smart Tags and Smart Minifigures. The 473-piece Darth Vader TIE Fighter set will cost $70; the 584-piece Luke’s Red Five X-Wing set comes in at $100 and the 962-piece Throne Room Duel & A-wing set will set you back $160.L'OrealA pair of transparent eye masks with wires and bulbs inside them.L'Oréal L'Oreal often brings some interesting beauty tech to CES and the company did so again this year with a trio of gadgets. The LED Eye Mask uses red light and near-infrared light to address the likes of puffiness, discoloration and fine lines.The LED Face Mask seems to be a more pliable version of masks that we've seen from the likes of Dr. Dennis Gross, Omnilux, Therabody and Shark in recent years. However, it's only in prototype form for now and it isn't expected to hit the market until next year. The Light Straight + Multi-styler uses infrared light to help dry and style hair in similar fashion to L'Oreal's AirLight Pro. It's said to have sensors that employ \"built-in proprietary algorithms and machine learning\" so they can adapt to your gestures and \"maximize individual experience.\" L'Oreal claims that while traditional straighteners can operate at 400°F or higher (temperatures that can damage hair), its latest innovation \"effectively straightens hair while never exceeding 320°F.\" You can expect the Light Straight to arrive in 2027 as well.Laptops and desktopsLG Gram ProEngadgetIt's CES, so of course we're going to see a bunch of laptops and desktops. The majority of those will surely emerge after NVIDIA's press conference on Monday evening, though we've already had a peek at LG's Aerominum laptops.MobileBack at CES 2024, we got to try out a physical keyboard phone accessory from Clicks. Fast forward two years, and the brand is making its own Blackberry-esque phones, as well as a new physical phone keyboard accessory. The Android 16-based Clicks Communicator has a tactile keyboard with a fingerprint sensor in the spacebar, a 4-inch OLED display, a 3.5mm headphone jack (hooray!) and expandable microSD storage up to 2TB. You can reserve one now for $399 — the price will increase to $499 on February 27.As for the new accessory, Clicks is calling that the Power Keyboard. It connects to an iOS or Android phone via MagSafe or Qi2, and it can operate as a power bank in a pinch thanks to the 2,150 mAh battery. The Power Keyboard has Bluetooth functionality as well, so you can use it with devices like tablets, smart TVs and virtual reality headsets. Pre-orders are open now and the Power Keyboard is expected to ship in the spring. Early adopters can lock in a pre-order for $79 before the retail price jumps to $110.The Punkt MC03 phone.PunktThose who prefer their mobile phones to have fewer bells and whistles might be interested in the latest model from Punkt. The MC03 is a nifty-looking touchscreen model that runs on the privacy- and security-centric AphyOS, which is based on the Android Open Source Project. It has a UI that borrows a page out of the Light Phone's playbook, though you can still install any Android app. The MC03 will hit European markets this month for €699 / CHF699 / £610. There's a mandatory subscription, however. You get a year of access included with a phone purchase, then it's a €10 / CHF10 / £9 monthly fee (paying for a long-term plan up front can reduce the cost by up to 60 percent).AI Amazon introduced Alexa.com to Alexa+ Early Access customers.AmazonNo prizes for guessing that there's going to be a ton of AI-related news at CES this year. Amazon, for one, announced that it's rolling out a web-based version of Alexa+. That means you won't necessarily need to have an Amazon device to try out the generative AI-powered assistant. However, Alexa+ Early Access customers are getting first dibs on the web version.Two Sweekar devices are pictured on a table, one wearing a pink and blue snowboarder outfit and the other (behind it) wearing a cowboy hat and outfitKarissa Bell for EngadgetThere are a boatload of AI-powered devices on the CES show floor too. One that we saw early on is a Tamagotchi-style virtual pet from a startup called Takway. The Sweekar will remember your interactions with it (you'll need to feed and play with the pet to keep it healthy and happy). Once it's all grown up, the Sweekar will head off on virtual adventures and tell you about its exploits when it \"returns.\" Takway will soon start a Kickstarter campaign for the Sweekar, which will likely cost between $100 and $150.The Fraimic art display at CESAmy Skorheim for EngadgetWe also saw the Fraimic, an E Ink display that can tap into OpenAI to generate images. There's no subscription for the Fraimic (which costs $399 for the standard size, which has a 13-inch display) and you get 100 AI-generated images per year included with your purchase. Pre-orders are open now and the Fraimic is expected to start shipping in this spring.MindClip held in a hand.Daniel Cooper for EngadgetSome companies still trying to make wearable AI devices happen. SwitchBot has a wearable mic called the AI MindClip, which can seemingly record and transcribe everything you say (no, thank you!). Plaid, meanwhile, brought its NotePin follow up to the dance. This time around, the NotePin S has a button that you can push to record conversations. You can also press the button to flag key moments for an AI-generated summary to focus on. The NotePin S is available now for $179, should you be enticed to buy such a thing.This article originally appeared on Engadget at https://www.engadget.com/general/everything-announced-at-ces-2026-130124802.html?src=rss",
          "content": "It's the first week of a new year and there's no time for the tech world to slowly ease back into things following the holidays. That's because CES 2026 is in full swing, with all manner of companies descending on Las Vegas to reveal their latest innovations and what they're planning to bring your way in the near future. Many of the Engadget crew are on the ground to check out as much of the new tech as possible. Of course, we're keeping tabs on all of the major CES press conferences too. Samsung has already held its First Look presentation, which focuses on home products, while LG has shown off a wide array of TVs and Lego unveiled its new Smart Brick technology. Presentations from NVIDIA, Sony, Lego, Hyundai and others are yet to come.You can catch up on all of the big CES 2026 announcements (and some of the more offbeat gizmos that are being shown off at the event) right here. We'll be keeping this story updated throughout the week. Micro RGB TVs Samsung's 130-inch Micro RGB TV. Devindra Hardawar for EngadgetMicro RGB is a term you can expect to hear about quite a bit in the coming months and years, especially when you're shopping for your next TV. Micro RGB is a new tech that's similar to Mini LED, though it uses red, green and blue LEDs instead of white backlights. Contrast ratios aren't quite as high as those on Micro LED and OLED displays, since the pixels can't be turned on and off individually. However, Micro RGB units are said to be brighter and more color accurate than TVs that use other display tech, in part because the LEDs in these screens offer smaller, more customizable dimming zones. We're seeing more of these TVs pop up at CES 2026, including a mammoth 130-inch concept model that Samsung brought to Las Vegas. The company unveiled its first Micro RGB TV in August, — that’s a 115-inch, $29,999 model. This year, you can expect it to start offering Micro RGB TVs in 55-, 65- and 75-inch sizes. There are also 85-, 100- and 115-inch models on the way.LG revealed its first Micro RGB set at CES as well. The largest variant is 100 inches, but there are 86- and 75-inch models too. Elsewhere, LG showed off its latest Wallpaper TV, which is a 100-inch OLED display. We also got a look at LG's new Gallery TV — The Gallery is the company's take on Samsung's Frame TV format.Other new TVs and OS updatesEmber Artline TV.AmazonWe’ve got another competitor to The Frame, as Amazon has entered that scene with the Ember Artline TV. The 4K OLED model has Amazon Photos integration and you can choose from 2,000 pieces of free art to show on the screen. The Ember Artline can switch on or off automatically when someone enters or leaves the room. It runs on the Fire TV platform and (of course) there’s Alexa+ integration, along with support for Dolby Vision, HDR10+ and Wi-Fi 6. The Ember Artline is expected to start shipping this spring. It starts at $899 for the 55-inch model.The rounder redesigned Fire TV UI.AmazonSpeaking of Fire TV, Amazon has revamped the platform’s user interface with rounded corners for show, movie and app tiles; a little more space for said tiles; and typography and color gradient changes. The company has reworked the platform’s codebase as well, and it says the Fire TV OS will deliver speed boosts of up to 20 to 30 percent. Amazon will start rolling out the updated UI next month.On the Google side of TV land, you can expect more Gemini-powered features. The company is bringing the ability to search Google Photos for certain moments and people to Google TV, along with the options to remix photos into different styles and create slideshows on the fly. The Veo and Nano Banana AI video and photo generation models are coming to Google TV as well. You can also expect the ability to adjust TV settings using your voice. These Gemini features are coming to Google TV-powered TCL models first, then other devices in the following months.SamsungSamsung's Music Studio 5 speakers at CES 2026.Billy Steele for EngadgetSamsung being Samsung, the company had a lot more up its sleeve at CES than just TVs. In the leadup to the event, it announced its two new soundbars (we're had some hands-on time with one of those), the stylish Music Studio speakers (we've got some IRL impressions of those), a bunch of monitors, the refreshed FreeStyle+ projector (we've checked that out too). It also announced plans to bring Google Photos to TVs.At the First Look showcase on Sunday, Samsung talked up \"AI experiences everywhere. For everyone\" (sigh). Here, we saw more TVs, such as the thin S95H OLED, which has a zero-gap mount that allows you to position the unit flush against a wall. First Look has long been focused on home products. Naturally, Samsung execs discussed some features for the company's fridges, such as ​​recipe selection updates, AI cooling tech and Google Gemini-powered AI Vision that's said to be able to recognize more items and help you figure out what you need to buy without having to manually take inventory. FoodNote, meanwhile, is a weekly summary that breaks down what has gone in and out of your fridge.Moreover, Samsung highlighted the Samsung Bespoke AI Laundry Combo and its new AI wash cycle. With the new Air Dresser — which has an Auto Wrinkle Care feature — Samsung aims to do away with irons (thank you, Samsung). As for the Bespoke AI smart vacuum and mop, that can apparently keep an eye on your pets when you're not home.LGLG's CLOiD robot.LGLikewise, LG brought other non-TV tech to CES. The company is shining the spotlight on its CLOiD robot. Like the far creepier-looking 1X Neo, the CLOiD is designed to help with household tasks such as starting laundry cycles, folding clothes, unloading the dishwasher and serving food. This appears to be more of a concept than something you'll be able to buy anytime soon, but we should get a closer look at the CLOiD in person this week.The company also debuted the LG Sound Suite, a modular home audio system it developed in conjunction with Dolby to take on the likes of Sonos. Just ahead of CES, LG pulled back the curtain on a new batch of xboom speakers as well as some monitors and ultralight Gram laptops that are made with a material it's calling Aerominum. LegoLego introduced the Smart Brick at CES 2026.LegoIn its first CES appearance, Lego announced the Smart Brick, a standard-sized brick with a 4.1mm ASIC chip inside that’s designed to respond in different ways depending on what set you’re building and how you’re building it. Using what Lego calls the “Play Engine” and integrated copper coils, each brick can sense things like motion, orientation and magnetic fields, plus its own distance, direction and orientation in relation to other Smart Bricks. Each brick also has a teeny tiny speaker built in that will play audio “tied to live play actions” rather than only pre-recorded clips.Accompanying Smart Bricks are Smart Tags and Smart Minifigures, which have their own capabilities — one of which is letting Smart Bricks know what context they are being used in. All of these pieces tie together via a local wireless layer dubbed BrickNet that, in part, lets Smart Bricks know where they are placed in relation to other smart components.The first “Smart Play” partner is, unsurprisingly, Star Wars, which will launch three “all-in-one” sets using Smart Bricks, Smart Tags and Smart Minifigures. The 473-piece Darth Vader TIE Fighter set will cost $70; the 584-piece Luke’s Red Five X-Wing set comes in at $100 and the 962-piece Throne Room Duel & A-wing set will set you back $160.L'OrealA pair of transparent eye masks with wires and bulbs inside them.L'Oréal L'Oreal often brings some interesting beauty tech to CES and the company did so again this year with a trio of gadgets. The LED Eye Mask uses red light and near-infrared light to address the likes of puffiness, discoloration and fine lines.The LED Face Mask seems to be a more pliable version of masks that we've seen from the likes of Dr. Dennis Gross, Omnilux, Therabody and Shark in recent years. However, it's only in prototype form for now and it isn't expected to hit the market until next year. The Light Straight + Multi-styler uses infrared light to help dry and style hair in similar fashion to L'Oreal's AirLight Pro. It's said to have sensors that employ \"built-in proprietary algorithms and machine learning\" so they can adapt to your gestures and \"maximize individual experience.\" L'Oreal claims that while traditional straighteners can operate at 400°F or higher (temperatures that can damage hair), its latest innovation \"effectively straightens hair while never exceeding 320°F.\" You can expect the Light Straight to arrive in 2027 as well.Laptops and desktopsLG Gram ProEngadgetIt's CES, so of course we're going to see a bunch of laptops and desktops. The majority of those will surely emerge after NVIDIA's press conference on Monday evening, though we've already had a peek at LG's Aerominum laptops.MobileBack at CES 2024, we got to try out a physical keyboard phone accessory from Clicks. Fast forward two years, and the brand is making its own Blackberry-esque phones, as well as a new physical phone keyboard accessory. The Android 16-based Clicks Communicator has a tactile keyboard with a fingerprint sensor in the spacebar, a 4-inch OLED display, a 3.5mm headphone jack (hooray!) and expandable microSD storage up to 2TB. You can reserve one now for $399 — the price will increase to $499 on February 27.As for the new accessory, Clicks is calling that the Power Keyboard. It connects to an iOS or Android phone via MagSafe or Qi2, and it can operate as a power bank in a pinch thanks to the 2,150 mAh battery. The Power Keyboard has Bluetooth functionality as well, so you can use it with devices like tablets, smart TVs and virtual reality headsets. Pre-orders are open now and the Power Keyboard is expected to ship in the spring. Early adopters can lock in a pre-order for $79 before the retail price jumps to $110.The Punkt MC03 phone.PunktThose who prefer their mobile phones to have fewer bells and whistles might be interested in the latest model from Punkt. The MC03 is a nifty-looking touchscreen model that runs on the privacy- and security-centric AphyOS, which is based on the Android Open Source Project. It has a UI that borrows a page out of the Light Phone's playbook, though you can still install any Android app. The MC03 will hit European markets this month for €699 / CHF699 / £610. There's a mandatory subscription, however. You get a year of access included with a phone purchase, then it's a €10 / CHF10 / £9 monthly fee (paying for a long-term plan up front can reduce the cost by up to 60 percent).AI Amazon introduced Alexa.com to Alexa+ Early Access customers.AmazonNo prizes for guessing that there's going to be a ton of AI-related news at CES this year. Amazon, for one, announced that it's rolling out a web-based version of Alexa+. That means you won't necessarily need to have an Amazon device to try out the generative AI-powered assistant. However, Alexa+ Early Access customers are getting first dibs on the web version.Two Sweekar devices are pictured on a table, one wearing a pink and blue snowboarder outfit and the other (behind it) wearing a cowboy hat and outfitKarissa Bell for EngadgetThere are a boatload of AI-powered devices on the CES show floor too. One that we saw early on is a Tamagotchi-style virtual pet from a startup called Takway. The Sweekar will remember your interactions with it (you'll need to feed and play with the pet to keep it healthy and happy). Once it's all grown up, the Sweekar will head off on virtual adventures and tell you about its exploits when it \"returns.\" Takway will soon start a Kickstarter campaign for the Sweekar, which will likely cost between $100 and $150.The Fraimic art display at CESAmy Skorheim for EngadgetWe also saw the Fraimic, an E Ink display that can tap into OpenAI to generate images. There's no subscription for the Fraimic (which costs $399 for the standard size, which has a 13-inch display) and you get 100 AI-generated images per year included with your purchase. Pre-orders are open now and the Fraimic is expected to start shipping in this spring.MindClip held in a hand.Daniel Cooper for EngadgetSome companies still trying to make wearable AI devices happen. SwitchBot has a wearable mic called the AI MindClip, which can seemingly record and transcribe everything you say (no, thank you!). Plaid, meanwhile, brought its NotePin follow up to the dance. This time around, the NotePin S has a button that you can push to record conversations. You can also press the button to flag key moments for an AI-generated summary to focus on. The NotePin S is available now for $179, should you be enticed to buy such a thing.This article originally appeared on Engadget at https://www.engadget.com/general/everything-announced-at-ces-2026-130124802.html?src=rss",
          "feed_position": 31,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Samsung_Micro_RGB-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/lg-sound-suite-hands-on-at-ces-2026-home-theater-powered-by-dolby-atmos-flexconnect-192709499.html",
          "published_at": "Mon, 05 Jan 2026 19:27:09 +0000",
          "title": "LG Sound Suite hands-on at CES 2026: Home theater powered by Dolby Atmos FlexConnect",
          "standfirst": "Dolby introduced its FlexConnect technology a few years ago, vowing that it would allow customers to position soundbars and speakers anywhere in a room. The company said the platform would then reconfigure the sound automatically, taking into account any locations that may be further away from the center sweet spot. At CES 2026, LG is the first to put Dolby Atmos FlexConnect in a soundbar, offering the so-called Sound Suite that also includes satellite speaker options and a subwoofer. You don’t need every member of the lineup to use Dolby’s tech, so you can pick and choose which items work best for your living room. The centerpiece of the Sound Suite is the H7 soundbar. This 9.1.6-channel speaker is configured for spatial audio (Dolby Atmos) and supports lossless audio up to 24 bit/96kHz. The standout on the spec sheet for me is the six up-firing channels, which should enhance the sensation of overhead sounds. Most of the soundbars I review have only two of those. What’s more, the H7 is equipped with a feature called Sound Follow that tracks the location of your phone to reconfigure the audio when your position changes. Maybe you move to a comfy chair instead of the sofa right in front of the TV. The idea is that you don’t have to suffer through subpar audio during a movie or show just because you aren’t in the best spot. LG Sound Suite H7 soundbarBilly Steele for EngadgetThen there are the M5 and M7 speakers. When used with the H7 soundbar, these are the satellite speakers, but LG cautioned me against calling them “rear” units. While it’s true a pair of them will be positioned behind most people’s sofas, the company explained that there’s more audio content coming out of them than traditional rear channels provide. As such, two of the M5s or M7s that are used to complement the speakers inside one of LG’s impressively thin TVs are doing more work than just beaming sounds that are designed to come from behind. The M5 is a 1.1.1-channel speaker while the M7 is 2.1.1. Like the H7, both support Dolby Atmos and lossless music. What’s more, the entire Sound Suite arsenal has Wi-Fi and Bluetooth connectivity, including AirPlay 2, Google Cast and both Spotify and Tidal connect. The whole shebang also employs LG’s own AI Sound Pro and Room Calibration Pro, and all of the settings are customized in the ThinQ app for Android and iOS. Each speaker can be used independently should the need arise, and as I already mentioned, you can pick and choose which components will work best for you — up to four total speakers. So you can opt for the H7, sub and two speakers or four of either the M5 or M7. You can also get a smaller setup with two speakers or just the soundbar and subwoofer. Dolby Atmos FlexConnect is still in play no matter what combination you decide on. I should note the optional W7 subwoofer is quite large, but you can use it standing upright or laying flat, according to LG.LG Sound Suite M5 speakerBilly Steele for EngadgetOf course, none of this means anything if Sound Suite doesn’t actually sound good. I’m happy to report LG’s collection of speakers are sonically impressive. I was able to get a good sense of how they’ll perform in a quite demo room at CES. Watching a variety of movie clips in Dolby Atmos, I flipped back and forth between a setup with four M7 speakers and a more robust configuration of the soundbar, subwoofer and M7 speakers. While I preferred the overall tone and tuning of the four M7s, I can concede the bigger collection offered more immersive sound and better directional audio. That said, they both provided excellent clarity and pristine detail. With Sound Follow, you can quickly have Sound Suite reconfigure the audio based on the location of your phone with just a tap. Let’s say you move from the couch to a comfy chair and want to adjust the sound to that spot. You can do that in the app. And while I could tell a slight difference in a side-of-the-room location and the center sweet spot in front of the TV, the correction did offer an improvement over the unadjusted audio.I was also able to test standalone mode, where you can quickly use any Sound Suite speaker individually for music. Sound quality was consistent here too, and the system allowed me to add a second M7 speaker for a stereo pair with a few taps in LG’s app. Overall, the Sound Suite lineup offers lots of flexibility in terms of features and configurations. In fact, LG says that between the H7, W7, M5 and M7, there are 50 possible combinations. Unfortunately, LG hasn’t announced pricing or availability yet. Given the capabilities of the Sound Suite system, I don’t expect the more robust collections to come cheap. However, I do think the company will offer a few different bundles that will hopefully provide a discount over buying each component individually. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-sound-suite-hands-on-at-ces-2026-home-theater-powered-by-dolby-atmos-flexconnect-192709499.html?src=rss",
          "content": "Dolby introduced its FlexConnect technology a few years ago, vowing that it would allow customers to position soundbars and speakers anywhere in a room. The company said the platform would then reconfigure the sound automatically, taking into account any locations that may be further away from the center sweet spot. At CES 2026, LG is the first to put Dolby Atmos FlexConnect in a soundbar, offering the so-called Sound Suite that also includes satellite speaker options and a subwoofer. You don’t need every member of the lineup to use Dolby’s tech, so you can pick and choose which items work best for your living room. The centerpiece of the Sound Suite is the H7 soundbar. This 9.1.6-channel speaker is configured for spatial audio (Dolby Atmos) and supports lossless audio up to 24 bit/96kHz. The standout on the spec sheet for me is the six up-firing channels, which should enhance the sensation of overhead sounds. Most of the soundbars I review have only two of those. What’s more, the H7 is equipped with a feature called Sound Follow that tracks the location of your phone to reconfigure the audio when your position changes. Maybe you move to a comfy chair instead of the sofa right in front of the TV. The idea is that you don’t have to suffer through subpar audio during a movie or show just because you aren’t in the best spot. LG Sound Suite H7 soundbarBilly Steele for EngadgetThen there are the M5 and M7 speakers. When used with the H7 soundbar, these are the satellite speakers, but LG cautioned me against calling them “rear” units. While it’s true a pair of them will be positioned behind most people’s sofas, the company explained that there’s more audio content coming out of them than traditional rear channels provide. As such, two of the M5s or M7s that are used to complement the speakers inside one of LG’s impressively thin TVs are doing more work than just beaming sounds that are designed to come from behind. The M5 is a 1.1.1-channel speaker while the M7 is 2.1.1. Like the H7, both support Dolby Atmos and lossless music. What’s more, the entire Sound Suite arsenal has Wi-Fi and Bluetooth connectivity, including AirPlay 2, Google Cast and both Spotify and Tidal connect. The whole shebang also employs LG’s own AI Sound Pro and Room Calibration Pro, and all of the settings are customized in the ThinQ app for Android and iOS. Each speaker can be used independently should the need arise, and as I already mentioned, you can pick and choose which components will work best for you — up to four total speakers. So you can opt for the H7, sub and two speakers or four of either the M5 or M7. You can also get a smaller setup with two speakers or just the soundbar and subwoofer. Dolby Atmos FlexConnect is still in play no matter what combination you decide on. I should note the optional W7 subwoofer is quite large, but you can use it standing upright or laying flat, according to LG.LG Sound Suite M5 speakerBilly Steele for EngadgetOf course, none of this means anything if Sound Suite doesn’t actually sound good. I’m happy to report LG’s collection of speakers are sonically impressive. I was able to get a good sense of how they’ll perform in a quite demo room at CES. Watching a variety of movie clips in Dolby Atmos, I flipped back and forth between a setup with four M7 speakers and a more robust configuration of the soundbar, subwoofer and M7 speakers. While I preferred the overall tone and tuning of the four M7s, I can concede the bigger collection offered more immersive sound and better directional audio. That said, they both provided excellent clarity and pristine detail. With Sound Follow, you can quickly have Sound Suite reconfigure the audio based on the location of your phone with just a tap. Let’s say you move from the couch to a comfy chair and want to adjust the sound to that spot. You can do that in the app. And while I could tell a slight difference in a side-of-the-room location and the center sweet spot in front of the TV, the correction did offer an improvement over the unadjusted audio.I was also able to test standalone mode, where you can quickly use any Sound Suite speaker individually for music. Sound quality was consistent here too, and the system allowed me to add a second M7 speaker for a stereo pair with a few taps in LG’s app. Overall, the Sound Suite lineup offers lots of flexibility in terms of features and configurations. In fact, LG says that between the H7, W7, M5 and M7, there are 50 possible combinations. Unfortunately, LG hasn’t announced pricing or availability yet. Given the capabilities of the Sound Suite system, I don’t expect the more robust collections to come cheap. However, I do think the company will offer a few different bundles that will hopefully provide a discount over buying each component individually. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-sound-suite-hands-on-at-ces-2026-home-theater-powered-by-dolby-atmos-flexconnect-192709499.html?src=rss",
          "feed_position": 32,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/lg-2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/the-biggest-tv-announcements-at-ces-2026-190929976.html",
          "published_at": "Mon, 05 Jan 2026 19:09:29 +0000",
          "title": "The biggest TV announcements at CES 2026",
          "standfirst": "CES is once again where TV manufacturers lay out their plans for the year ahead, and CES 2026 is shaping up to be a showcase of both familiar rivalries and genuinely new display tech. While OLED and Mini LED remain central to most lineups, Micro RGB has emerged as one of the most talked-about developments at the show so far, especially at the higher end of the market. Below are the TV announcements that stood out most from the pre-show events and early press conferences, with more expected as CES continues. Samsung Micro RGB TVs Samsung's flagship Micro RGB TV Engadget Samsung’s Micro RGB push at CES 2026 isn’t just about big screens — it’s also about how the technology tries to redefine color accuracy and brightness in LCD-based TVs. Unlike traditional Mini LED backlights that rely on white LEDs and filters, Samsung’s Micro RGB TVs use microscopic red, green and blue LEDs in the backlight plane, which help deliver a wider color gamut and more precise local luminance control than conventional backlit LCDs. The standout of the lineup so far is the jaw-dropping 130-inch Micro RGB concept, shown suspended on a massive gallery-style stand at Samsung’s First Look event. It’s powered by Samsung’s Micro RGB AI Engine Pro, a processing suite that includes Micro RGB Color Booster Pro and Micro RGB HDR Pro to refine contrast and push color depth and detail frame by frame, with HDR10+ Advanced support built in. Compared with previous Micro RGB models, Samsung says this expanded family will start at more practical sizes — 55- and 65-inch — and go up to sizes as large as 75, 85 and 100 inches, all with next-gen AI-driven picture and sound features baked in. Samsung’s Micro RGB sets also carry the company’s Glare Free anti-reflection finish and tie into its broader Vision AI platform, which supports things like conversational search and contextual content discovery. While the 130-inch concept may remain more of a statement piece than a consumer product, the move underscores how Samsung continues to push next-gen TV tech forward. Samsung OLED TVs Samsung’s new 2026 OLED slate — including the S95H, S90H and S85H models — continues the brand’s use of quantum dot-enhanced OLED panels, bringing brighter highlights and richer colors than older WOLED approaches. These TVs also benefit from Samsung’s continued refinement of processing and anti-glare screen treatments, which make them more adaptable in bright living rooms than traditional OLEDs. The flagship S95H retains its position as the most premium, using a quantum dot layer to help improve brightness and color purity. Below that, the S90H brings glare-reducing optical layers and robust picture processing to a slightly more affordable price point, while the S85H is designed to offer core OLED benefits, like deep blacks and wide viewing angles, in a more accessible package that now includes a new 48-inch size for smaller spaces or gaming setups. Across the OLED family, Samsung’s Vision AI-powered tools such as AI Motion Enhancer Pro and AI Sound Controller (which dynamically adjusts audio based on content) are also part of the story, making these sets not just about panel tech but about richer, more adaptable viewing experiences. LG OLED evo W6 Wallpaper TV LG's 2026 Wallpaper wireless OLED TV Devindra Hardawar for Engadget LG’s OLED evo W6 Wallpaper TV makes a striking return at CES 2026, and this year’s version manages to blend design flair with high-end performance. The panel itself is an astonishing 9mm thick, designed to sit almost flush against a wall, and pairs with a Zero Connect Box that hosts all inputs and delivers wireless video feeds up to 10 meters away. Under the ultra-thin exterior, the W6 uses LG’s Hyper Radiant Color technology coupled with Brightness Booster Ultra to push improved brightness and color saturation compared with previous Wallpaper models. It also received Intertek’s “Reflection Free with Premium” certification, indicating some of the lowest reflectance levels yet on an OLED TV. Gaming shooters and fast action fans might appreciate support for up to 165Hz refresh rates and both G-SYNC and FreeSync Premium compatibility, making this one of the most technically ambitious Wallpaper designs LG has shown. LG Micro RGB evo TVs LG is also entering the premium RGB-backlit arena at CES with its Micro RGB evo lineup, bringing a similar focus on wider color gamut and intense brightness. Early coverage indicates the Micro RGB evo models will arrive in 75-, 86- and 100-inch sizes, and are built around LG’s α11 AI Processor Gen3, which handles advanced upscaling, local dimming and dynamic HDR optimization. LG’s Micro RGB evo TVs have been certified for full coverage of BT.2020, DCI-P3 and Adobe RGB color spaces, suggesting an exceptionally wide palette and precise color fidelity. Under the hood, the Micro Dimming Ultra system is said to deliver 1,000+ local dimming zones, which narrows the gap between LCD-based displays and self-emissive technologies like OLED in terms of contrast management. This early positioning of RGB LED tech by LG also highlights a growing industry shift, with multiple brands teasing similar systems designed to improve brightness and color performance on large screen sizes — especially where OLED’s peak luminance traditionally struggles. LG OLED TVs (C6 and C6H) OLED remains a core focus for LG, and CES 2026 brought updates to its popular C-series. The LG C6 OLED continues the company’s tradition of balancing performance and price, while the C6H OLED steps things up with a new Primary RGB Tandem panel designed to deliver higher brightness and improved color volume. These models are clearly aimed at buyers who want OLED’s deep blacks and wide viewing angles without jumping to LG’s most expensive designs, making them likely to be among the most popular TVs LG releases this year. TCL X11L SQD-Mini LED TV TCL used CES 2026 to make a strong case for Mini LED’s continued relevance with the X11L SQD-Mini LED TV, its new flagship model aimed squarely at large-screen home theater setups. Rather than chasing Micro RGB, TCL is refining its own approach with SQD, or Super Quantum Dot, technology, which combines an enhanced quantum dot layer with a dense Mini LED backlight to improve color purity and brightness. The headline number here is brightness. TCL claims the X11L can hit up to 10,000 nits peak brightness, putting it among the brightest TVs shown at CES this year. That’s paired with an extremely dense local dimming system, with up to 20,000 dimming zones, which is designed to improve contrast and keep blooming in check despite the extreme luminance. TCL also says the panel covers 100 percent of the BT.2020 color space, a bold claim that, if it holds up in real-world testing, would put it in rare company. The X11L is a 4K TV available in 75-inch, 85-inch and 98-inch sizes, with the largest models clearly intended to rival premium OLED and Micro RGB sets in dedicated home theaters. It supports a 144Hz refresh rate, making it appealing for gaming as well as fast-moving sports, and includes support for advanced HDR formats, including Dolby Vision, with further enhancements expected via software updates. With CES press day underway and the show floor opening on January 6, more TV announcements are expected from major manufacturers. As additional models are revealed or details are confirmed, we’ll continue updating this roundup with the latest information. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/the-biggest-tv-announcements-at-ces-2026-190929976.html?src=rss",
          "content": "CES is once again where TV manufacturers lay out their plans for the year ahead, and CES 2026 is shaping up to be a showcase of both familiar rivalries and genuinely new display tech. While OLED and Mini LED remain central to most lineups, Micro RGB has emerged as one of the most talked-about developments at the show so far, especially at the higher end of the market. Below are the TV announcements that stood out most from the pre-show events and early press conferences, with more expected as CES continues. Samsung Micro RGB TVs Samsung's flagship Micro RGB TV Engadget Samsung’s Micro RGB push at CES 2026 isn’t just about big screens — it’s also about how the technology tries to redefine color accuracy and brightness in LCD-based TVs. Unlike traditional Mini LED backlights that rely on white LEDs and filters, Samsung’s Micro RGB TVs use microscopic red, green and blue LEDs in the backlight plane, which help deliver a wider color gamut and more precise local luminance control than conventional backlit LCDs. The standout of the lineup so far is the jaw-dropping 130-inch Micro RGB concept, shown suspended on a massive gallery-style stand at Samsung’s First Look event. It’s powered by Samsung’s Micro RGB AI Engine Pro, a processing suite that includes Micro RGB Color Booster Pro and Micro RGB HDR Pro to refine contrast and push color depth and detail frame by frame, with HDR10+ Advanced support built in. Compared with previous Micro RGB models, Samsung says this expanded family will start at more practical sizes — 55- and 65-inch — and go up to sizes as large as 75, 85 and 100 inches, all with next-gen AI-driven picture and sound features baked in. Samsung’s Micro RGB sets also carry the company’s Glare Free anti-reflection finish and tie into its broader Vision AI platform, which supports things like conversational search and contextual content discovery. While the 130-inch concept may remain more of a statement piece than a consumer product, the move underscores how Samsung continues to push next-gen TV tech forward. Samsung OLED TVs Samsung’s new 2026 OLED slate — including the S95H, S90H and S85H models — continues the brand’s use of quantum dot-enhanced OLED panels, bringing brighter highlights and richer colors than older WOLED approaches. These TVs also benefit from Samsung’s continued refinement of processing and anti-glare screen treatments, which make them more adaptable in bright living rooms than traditional OLEDs. The flagship S95H retains its position as the most premium, using a quantum dot layer to help improve brightness and color purity. Below that, the S90H brings glare-reducing optical layers and robust picture processing to a slightly more affordable price point, while the S85H is designed to offer core OLED benefits, like deep blacks and wide viewing angles, in a more accessible package that now includes a new 48-inch size for smaller spaces or gaming setups. Across the OLED family, Samsung’s Vision AI-powered tools such as AI Motion Enhancer Pro and AI Sound Controller (which dynamically adjusts audio based on content) are also part of the story, making these sets not just about panel tech but about richer, more adaptable viewing experiences. LG OLED evo W6 Wallpaper TV LG's 2026 Wallpaper wireless OLED TV Devindra Hardawar for Engadget LG’s OLED evo W6 Wallpaper TV makes a striking return at CES 2026, and this year’s version manages to blend design flair with high-end performance. The panel itself is an astonishing 9mm thick, designed to sit almost flush against a wall, and pairs with a Zero Connect Box that hosts all inputs and delivers wireless video feeds up to 10 meters away. Under the ultra-thin exterior, the W6 uses LG’s Hyper Radiant Color technology coupled with Brightness Booster Ultra to push improved brightness and color saturation compared with previous Wallpaper models. It also received Intertek’s “Reflection Free with Premium” certification, indicating some of the lowest reflectance levels yet on an OLED TV. Gaming shooters and fast action fans might appreciate support for up to 165Hz refresh rates and both G-SYNC and FreeSync Premium compatibility, making this one of the most technically ambitious Wallpaper designs LG has shown. LG Micro RGB evo TVs LG is also entering the premium RGB-backlit arena at CES with its Micro RGB evo lineup, bringing a similar focus on wider color gamut and intense brightness. Early coverage indicates the Micro RGB evo models will arrive in 75-, 86- and 100-inch sizes, and are built around LG’s α11 AI Processor Gen3, which handles advanced upscaling, local dimming and dynamic HDR optimization. LG’s Micro RGB evo TVs have been certified for full coverage of BT.2020, DCI-P3 and Adobe RGB color spaces, suggesting an exceptionally wide palette and precise color fidelity. Under the hood, the Micro Dimming Ultra system is said to deliver 1,000+ local dimming zones, which narrows the gap between LCD-based displays and self-emissive technologies like OLED in terms of contrast management. This early positioning of RGB LED tech by LG also highlights a growing industry shift, with multiple brands teasing similar systems designed to improve brightness and color performance on large screen sizes — especially where OLED’s peak luminance traditionally struggles. LG OLED TVs (C6 and C6H) OLED remains a core focus for LG, and CES 2026 brought updates to its popular C-series. The LG C6 OLED continues the company’s tradition of balancing performance and price, while the C6H OLED steps things up with a new Primary RGB Tandem panel designed to deliver higher brightness and improved color volume. These models are clearly aimed at buyers who want OLED’s deep blacks and wide viewing angles without jumping to LG’s most expensive designs, making them likely to be among the most popular TVs LG releases this year. TCL X11L SQD-Mini LED TV TCL used CES 2026 to make a strong case for Mini LED’s continued relevance with the X11L SQD-Mini LED TV, its new flagship model aimed squarely at large-screen home theater setups. Rather than chasing Micro RGB, TCL is refining its own approach with SQD, or Super Quantum Dot, technology, which combines an enhanced quantum dot layer with a dense Mini LED backlight to improve color purity and brightness. The headline number here is brightness. TCL claims the X11L can hit up to 10,000 nits peak brightness, putting it among the brightest TVs shown at CES this year. That’s paired with an extremely dense local dimming system, with up to 20,000 dimming zones, which is designed to improve contrast and keep blooming in check despite the extreme luminance. TCL also says the panel covers 100 percent of the BT.2020 color space, a bold claim that, if it holds up in real-world testing, would put it in rare company. The X11L is a 4K TV available in 75-inch, 85-inch and 98-inch sizes, with the largest models clearly intended to rival premium OLED and Micro RGB sets in dedicated home theaters. It supports a 144Hz refresh rate, making it appealing for gaming as well as fast-moving sports, and includes support for advanced HDR formats, including Dolby Vision, with further enhancements expected via software updates. With CES press day underway and the show floor opening on January 6, more TV announcements are expected from major manufacturers. As additional models are revealed or details are confirmed, we’ll continue updating this roundup with the latest information. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/the-biggest-tv-announcements-at-ces-2026-190929976.html?src=rss",
          "feed_position": 33,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/a087c5f0-e9f4-11f0-87f1-6f39e4849c7d.jpeg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/lego-unveils-a-technology-packed-smart-brick-at-ces-2026-190000511.html",
          "published_at": "Mon, 05 Jan 2026 19:00:00 +0000",
          "title": "Lego unveils a technology-packed Smart Brick at CES 2026",
          "standfirst": "Lego bricks come in a ridiculously vast array of sizes and shapes, but the company is unveiling an entirely new take on its classic shape at CES 2026. Meet the Lego Smart Brick, a standard-sized 2 x 4 brick that’s packed with modern technology to enable sets that can respond to how they’re played with or the sets you build. It’s part of a new initiative called Smart Play, which encompasses the Smart Brick as well as Smart Minifigures and Smart Tags. While we obviously don’t know yet how Lego fans will take to this new system, it’s still fair to say it’s the biggest move Lego has every made to infuse its products with connected technology. The Smart Brick has a 4.1mm ASIC chip inside of it that Lego says is smaller than a standard Lego stud. It runs something called the Play Engine that can sense things like motion, orientation and magnetic fields. Thanks to this and some integrated copper coils, the Smart Brick can sense distance, direction and orientation of other Smart Bricks near it when you’re building. The brick also has a tiny built-in speaker, an accelerometer and an LED array. Lego says the speaker can produce audio that is “tied to live play actions” rather than just playing pre-recorded clips. The Smart Tag and Smart Minifigures are a lot simpler. The Tag is a 2 x 2 studless tile with a digital ID embedded in it that the Smart Brick can read via “near-field magnetic communication.” This obviously sounds a lot like NFC, but we can’t be sure that these new Lego pieces will be able to communicate with any other NFC devices. Similarly, the Smart Minifigure also has a digital ID readable by NFC. The purpose of the Smart Tag as well as the similar tech in a Smart Minifigure is to let the Smart Brick know what kind of context it is being used in. As Lego puts it, “The role of the Smart Tag is to tell the Smart Brick how it should play back with you.” The Tag tells the Brick what kind of object, animal, vehicle and so forth it should become. A Smart Tag in a Lego Star Wars X-Wing set, for example, will contain the unique ID and instructions for how the Smart Brick should behave. If this isn’t enough, Lego has also built a local wireless layer that connects this all together called BrickNet. It’s based on Bluetooth and uses Lego’s proprietary “Neighbor Position Measurement\" system, which is what lets the Smart Bricks know how close they are to each other and how they’re oriented. Lego says that this lets the bricks “talk” to each other directly without the need for apps, internet connections or external controls. It sounds like the idea is all three of these new Smart pieces can communicate and interact without any need for setup, which should make it refreshingly like a traditional Lego set. That said, these bricks naturally will need some power. Lego says that their batteries should still perform even after “years” of inactivity, and the coils and power system is designed so that multiple bricks can be charged wirelessly on a shared charging pad. Lego Star Wars set with Smart Bricks Lego Speaking of sets, Lego is unsurprisingly launching the Smart Play system with its biggest licensed partner: Star Wars. There will be three “all-in-one” Star Wars sets available, all of which are on the smaller side and definitely geared towards kids, rather than the 1,000 piece and up sets that the company has released to get adults (like me) interested. The prices are inflated compared to non-smart sets, but not outrageously so. Darth Vader’s TIE Fighter is a 473-piece set with a smart Darth Vader Minifigure, one Smart Brick and one Smart Tag, priced at $70. Luke’s Red Five X-Wing is a 584-piece set with two Smart Minifigures, one Smart Brick and five Smart Tags, priced at $100. The Throne Room Duel & A-wing is a 962-piece set with three Smart Minifigures, two Smart Bricks and five Smart Tags, priced at a slightly shocking $160. It’s an entirely new direction for Lego, and you won’t have to wait long to check it out. The company is putting those three sets up for pre-order on January 9, and they’ll launch on March 1. There’s obviously a lot of technology here that’s entirely new to Lego, and as such it’s hard to imagine just how this will all look when it comes together — but we’re hoping that Lego will have some sets on hand here at CES so we can get a closer look at how the Smart Play system works. In the meantime, you can find a few videos on how Smart Play works here. This article originally appeared on Engadget at https://www.engadget.com/entertainment/lego-unveils-a-technology-packed-smart-brick-at-ces-2026-190000511.html?src=rss",
          "content": "Lego bricks come in a ridiculously vast array of sizes and shapes, but the company is unveiling an entirely new take on its classic shape at CES 2026. Meet the Lego Smart Brick, a standard-sized 2 x 4 brick that’s packed with modern technology to enable sets that can respond to how they’re played with or the sets you build. It’s part of a new initiative called Smart Play, which encompasses the Smart Brick as well as Smart Minifigures and Smart Tags. While we obviously don’t know yet how Lego fans will take to this new system, it’s still fair to say it’s the biggest move Lego has every made to infuse its products with connected technology. The Smart Brick has a 4.1mm ASIC chip inside of it that Lego says is smaller than a standard Lego stud. It runs something called the Play Engine that can sense things like motion, orientation and magnetic fields. Thanks to this and some integrated copper coils, the Smart Brick can sense distance, direction and orientation of other Smart Bricks near it when you’re building. The brick also has a tiny built-in speaker, an accelerometer and an LED array. Lego says the speaker can produce audio that is “tied to live play actions” rather than just playing pre-recorded clips. The Smart Tag and Smart Minifigures are a lot simpler. The Tag is a 2 x 2 studless tile with a digital ID embedded in it that the Smart Brick can read via “near-field magnetic communication.” This obviously sounds a lot like NFC, but we can’t be sure that these new Lego pieces will be able to communicate with any other NFC devices. Similarly, the Smart Minifigure also has a digital ID readable by NFC. The purpose of the Smart Tag as well as the similar tech in a Smart Minifigure is to let the Smart Brick know what kind of context it is being used in. As Lego puts it, “The role of the Smart Tag is to tell the Smart Brick how it should play back with you.” The Tag tells the Brick what kind of object, animal, vehicle and so forth it should become. A Smart Tag in a Lego Star Wars X-Wing set, for example, will contain the unique ID and instructions for how the Smart Brick should behave. If this isn’t enough, Lego has also built a local wireless layer that connects this all together called BrickNet. It’s based on Bluetooth and uses Lego’s proprietary “Neighbor Position Measurement\" system, which is what lets the Smart Bricks know how close they are to each other and how they’re oriented. Lego says that this lets the bricks “talk” to each other directly without the need for apps, internet connections or external controls. It sounds like the idea is all three of these new Smart pieces can communicate and interact without any need for setup, which should make it refreshingly like a traditional Lego set. That said, these bricks naturally will need some power. Lego says that their batteries should still perform even after “years” of inactivity, and the coils and power system is designed so that multiple bricks can be charged wirelessly on a shared charging pad. Lego Star Wars set with Smart Bricks Lego Speaking of sets, Lego is unsurprisingly launching the Smart Play system with its biggest licensed partner: Star Wars. There will be three “all-in-one” Star Wars sets available, all of which are on the smaller side and definitely geared towards kids, rather than the 1,000 piece and up sets that the company has released to get adults (like me) interested. The prices are inflated compared to non-smart sets, but not outrageously so. Darth Vader’s TIE Fighter is a 473-piece set with a smart Darth Vader Minifigure, one Smart Brick and one Smart Tag, priced at $70. Luke’s Red Five X-Wing is a 584-piece set with two Smart Minifigures, one Smart Brick and five Smart Tags, priced at $100. The Throne Room Duel & A-wing is a 962-piece set with three Smart Minifigures, two Smart Bricks and five Smart Tags, priced at a slightly shocking $160. It’s an entirely new direction for Lego, and you won’t have to wait long to check it out. The company is putting those three sets up for pre-order on January 9, and they’ll launch on March 1. There’s obviously a lot of technology here that’s entirely new to Lego, and as such it’s hard to imagine just how this will all look when it comes together — but we’re hoping that Lego will have some sets on hand here at CES so we can get a closer look at how the Smart Play system works. In the meantime, you can find a few videos on how Smart Play works here. This article originally appeared on Engadget at https://www.engadget.com/entertainment/lego-unveils-a-technology-packed-smart-brick-at-ces-2026-190000511.html?src=rss",
          "feed_position": 34,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/75427_Lifestyle_cons_4.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/what-are-micro-rgb-tvs-and-why-are-they-everywhere-at-ces-2026-182441543.html",
          "published_at": "Mon, 05 Jan 2026 18:24:42 +0000",
          "title": "What are Micro RGB TVs and why are they everywhere at CES 2026?",
          "standfirst": "Micro RGB TVs first arrived last year with little fanfare and a confusing name, so you may have mistaken it for other panel tech or not even noticed. That is not likely to be the case this year, though — it’s the hot new “luxury” display technology and is all over the place at CES 2026. So why do we even need these new TVs and how are they different from OLED, Micro LED and Mini LED models? Here’s how it works and how it compares. A brief history of flat panel display tech To better understand Micro RGB, it helps to see how flat panel display technology has evolved over the last 20 years. The first LCD TVs used liquid crystals that become transparent to light when voltage is applied, letting a rear backlight shine through as a pixel. Those pixels combine to create moving or still images, with color created via an RGB filter layer placed in front. The main problem is that LCD crystals let some light partially leak through, so blacks are dark grey instead of pure black. And for a backlight, early LCD TVs used a white screen lit by dim and power-hungry fluorescent lights, which caused uneven light distribution. And finally, the RGB filter color layer reduced a panel’s brightness. The next step up, then, was to use LED backlights instead, placed at first at the edges of the white screen and then later directly behind it (the first TV with this tech was Sony’s 2004 Qualia). That added the benefits of higher brightness, lower power consumption, improved color balance and even light distribution. It also allowed individual dimming zones that improve contrast by allowing near-pure blacks in shadow areas of an image. Samsung's Neo QLED 8K TV from CES 2025Samsung Quantum dot (QD) technology came on the scene around 2013 with Sony’s Triluminos televisions. This type of LCD panel employs a semiconductor nanocrystal layer (rather than an RGB filter layer) that can produce pure monochromatic red, green, and blue light when struck with a blue backlight. Unlike previous LCDs, they offer higher brightness and color accuracy thanks to the purity (narrowness) of the base RGB colors. The best-known TVs using this tech are Samsung’s QLED models. The latest evolution of QD LED technology is Mini LED. That combines the accuracy of quantum dot tech with hundreds or even thousands of LED dimming zones. Those models offer high brightness and color accuracy along with good contrast, but still don’t deliver perfect blacks and can display “blooming” in scenes with bright points of light due to leakage into neighboring pixels. Both of those problems were solved with OLED technology, which first came on the market in 2007 with Sony’s XEL-1 model. The panels are made using sheets coated with organic LEDs, each paired with a transistor that can switch the LED on or off. On regular OLED TVs, OLED pixels are white and a filter layer generates colors, much as with LED TVs. However, with QD-OLEDs, OLED pixels are blue and color is created via a quantum dot layer, like LED QD displays. The latest version of QD-OLED featured on several new monitors at CES 2026 (Samsung’s 5th-gen QD-OLED) uses an RGB stripe pattern to reduce color “fringing” on text. This is the first, and still the only widely commercialized TV tech that can switch its light source off on a pixel-by-pixel basis, allowing perfect black levels and near-infinite contrast. However, due to their organic nature, OLED TVs suffer from a lack of brightness and the potential for “burn-in” that can kill pixels. There is another type of self-illuminating tech called Micro LED. Rather than organic, it uses microscopic inorganic LEDs to form the individual pixel elements. Those can also be turned on or off individually, so they offer the same pure blacks and sky-high contrast as OLED. At the same time they’re potentially brighter than OLED and don’t suffer from burn-in. The tech is still prohibitively expensive to manufacture, though, so none have arrived to market other than Samsung’s The Wall, which costs a cool $40,000. Micro RGB Devindra Hardawar for Engadget Before talking about Micro RGB, let’s look at color space and gamut both for HDR, which uses the BT.2020 standard, and SDR, commonly associated with the REC.709 standard. REC.709 is ideal for regular HD content like TV broadcasts and YouTube videos. It can display a limited set of colors and brightness is generally capped at 100 nits. BT.2020, however, is designed for high-end HDR streaming and 4K or 8K content creation (via Dolby Vision, HDR 10 or HDR10+). It has a much wider color gamut, meaning it can display a wider variety of colors and a bigger chunk of the visible color spectrum. It’s also designed for significantly higher brightness levels of 1,000 nits or more. To achieve the color accuracy required for BT.2020, TVs must have extremely accurate red, green and blue pixels. Up until last year, the most color-accurate TVs used quantum dot technology and achieved a maximum of around 85 percent BT.2020 coverage (some projectors can cover 100 percent or more of the BT.2020 spectrum as they use RGB lasers to create colors). That brings us to Micro RGB (also known as RGB Mini LED), the most advanced LED panel yet. Unlike the uniform white or blue backlights found on Mini LED models, it features individually-controlled, precise red, green and blue LED backlights that shine through a liquid crystal layer. It also offers more local dimming zones. The net result is higher color accuracy and better contrast than regular Mini LED displays, but with potentially greater brightness than OLED. Since each pixel still can’t be turned on and off like OLED or Micro LED, though, contrast falls short of those technologies. Wikipedia So far, there is one and only one Micro RGB TV on the market, Samsung’s 115-inch 4K MR95F model. The color accuracy is impressive with 100 percent coverage of the challenging BT.2020 HDR standard, an industry-first and huge leap over quantum dot tech. That means it can produce billions of colors natively and display a higher percentage of them in the visible spectrum than any TV to date. Samsung left out a few key specs like the local dimming zone count, only saying that it has four times more than its similarly-priced 115-inch Q90F QLED model (so likely around 3,600). The company also failed to disclose the total brightness in nits, but the figure should be impressive given the potential of Micro RGB. We were gobsmacked with the MR95F Micro RGB model in person. Engadget editor Sam Rutherford said it produced “stunningly rich and vivid colors that put Samsung’s other top-tier TVs to shame,” including the aforementioned Q90F. It also came with an equally stunning $29,999 price tag. A couple of other manufacturers including HiSense have also released RGB Mini LED models similar to Samsung’s Micro RGB, but they differ slightly in that the RGB modules are larger than the ones found on Samsung’s latest TVs. Which companies will have Micro RGB tech at CES 2026? Samsung Luckily, the number of Micro RGB TVs is about to dramatically increase. Earlier this month, Samsung announced a full lineup using the technology with 55-, 65-, 75-, 85-, 100- and 115-inch screen sizes, saying they’d set “a new standard for premium home viewing.” Those sets will also offer 100 percent BT.2020 HDR coverage under a new certification standard called Micro RGB Precision Color 100. While certainly likely to carry more reasonable prices than the first model, they’ll probably still be Samsung’s most expensive TVs when released later this year. And on Sunday, Samsung also revealed a 130-inch Micro RGB prototype meant to showcase the technology. Once again, it blew us away partially just because of the huge size, but also due to the incredible \"color accuracy and richness,\" as Engadget editor Devindra Hardawar put it. \"I couldn’t help but notice how everyone just looked a bit stunned, like the monkeys from 2001 seeing the monolith for the first time,\" he added. At the same time, LG announced its first Micro RGB “evo” TV lineup in 75-, 86- and 100-inch models. The company is also promising 100 percent BT.2020 color gamut coverage and said the sets will have over a thousand local dimming zones for color control. Not only that, it said that its new TVs will deliver 100 percent coverage in SDR modes as well, both for Adobe RGB and the challenge P3 standard. It was interesting to compare LG's Wallpaper and other OLED sets with the new Micro RGB tech, with our editor Devindra again being amazed. \"LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES,\" he said. \"Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like.\" For its part, Hisense also unveiled a lineup of \"evo\" TVs that it calls RGB Mini-LED instead of Micro RGB. It's offering them at two price points, called the UR9 and UR8, with sizes ranging from 55 up to 100 inches. The company is promising an even wider color gamut than Samsung and LG with up to 110 percent BT.2020 coverage and \"color control achieving 134 bits,\" the company said. On top of that, HiSense had a surprise up its sleeve with the launch of an enormous 163-inch Micro LED TV to compete with Samsung's The Wall. The company actually calls it RGBY Micro LED, because it introduces a fourth yellow color into the RGB mix. The reason, according to the company, is that yellow expands the color spectrum \"where human vision perceives the most nuance.\" Update January 5, 2026 at 5:18 PM: The article now includes information about HiSense's latest RGB Mini LED and Micro LED TVs. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/what-are-micro-rgb-tvs-and-why-are-they-everywhere-at-ces-2026-182441543.html?src=rss",
          "content": "Micro RGB TVs first arrived last year with little fanfare and a confusing name, so you may have mistaken it for other panel tech or not even noticed. That is not likely to be the case this year, though — it’s the hot new “luxury” display technology and is all over the place at CES 2026. So why do we even need these new TVs and how are they different from OLED, Micro LED and Mini LED models? Here’s how it works and how it compares. A brief history of flat panel display tech To better understand Micro RGB, it helps to see how flat panel display technology has evolved over the last 20 years. The first LCD TVs used liquid crystals that become transparent to light when voltage is applied, letting a rear backlight shine through as a pixel. Those pixels combine to create moving or still images, with color created via an RGB filter layer placed in front. The main problem is that LCD crystals let some light partially leak through, so blacks are dark grey instead of pure black. And for a backlight, early LCD TVs used a white screen lit by dim and power-hungry fluorescent lights, which caused uneven light distribution. And finally, the RGB filter color layer reduced a panel’s brightness. The next step up, then, was to use LED backlights instead, placed at first at the edges of the white screen and then later directly behind it (the first TV with this tech was Sony’s 2004 Qualia). That added the benefits of higher brightness, lower power consumption, improved color balance and even light distribution. It also allowed individual dimming zones that improve contrast by allowing near-pure blacks in shadow areas of an image. Samsung's Neo QLED 8K TV from CES 2025Samsung Quantum dot (QD) technology came on the scene around 2013 with Sony’s Triluminos televisions. This type of LCD panel employs a semiconductor nanocrystal layer (rather than an RGB filter layer) that can produce pure monochromatic red, green, and blue light when struck with a blue backlight. Unlike previous LCDs, they offer higher brightness and color accuracy thanks to the purity (narrowness) of the base RGB colors. The best-known TVs using this tech are Samsung’s QLED models. The latest evolution of QD LED technology is Mini LED. That combines the accuracy of quantum dot tech with hundreds or even thousands of LED dimming zones. Those models offer high brightness and color accuracy along with good contrast, but still don’t deliver perfect blacks and can display “blooming” in scenes with bright points of light due to leakage into neighboring pixels. Both of those problems were solved with OLED technology, which first came on the market in 2007 with Sony’s XEL-1 model. The panels are made using sheets coated with organic LEDs, each paired with a transistor that can switch the LED on or off. On regular OLED TVs, OLED pixels are white and a filter layer generates colors, much as with LED TVs. However, with QD-OLEDs, OLED pixels are blue and color is created via a quantum dot layer, like LED QD displays. The latest version of QD-OLED featured on several new monitors at CES 2026 (Samsung’s 5th-gen QD-OLED) uses an RGB stripe pattern to reduce color “fringing” on text. This is the first, and still the only widely commercialized TV tech that can switch its light source off on a pixel-by-pixel basis, allowing perfect black levels and near-infinite contrast. However, due to their organic nature, OLED TVs suffer from a lack of brightness and the potential for “burn-in” that can kill pixels. There is another type of self-illuminating tech called Micro LED. Rather than organic, it uses microscopic inorganic LEDs to form the individual pixel elements. Those can also be turned on or off individually, so they offer the same pure blacks and sky-high contrast as OLED. At the same time they’re potentially brighter than OLED and don’t suffer from burn-in. The tech is still prohibitively expensive to manufacture, though, so none have arrived to market other than Samsung’s The Wall, which costs a cool $40,000. Micro RGB Devindra Hardawar for Engadget Before talking about Micro RGB, let’s look at color space and gamut both for HDR, which uses the BT.2020 standard, and SDR, commonly associated with the REC.709 standard. REC.709 is ideal for regular HD content like TV broadcasts and YouTube videos. It can display a limited set of colors and brightness is generally capped at 100 nits. BT.2020, however, is designed for high-end HDR streaming and 4K or 8K content creation (via Dolby Vision, HDR 10 or HDR10+). It has a much wider color gamut, meaning it can display a wider variety of colors and a bigger chunk of the visible color spectrum. It’s also designed for significantly higher brightness levels of 1,000 nits or more. To achieve the color accuracy required for BT.2020, TVs must have extremely accurate red, green and blue pixels. Up until last year, the most color-accurate TVs used quantum dot technology and achieved a maximum of around 85 percent BT.2020 coverage (some projectors can cover 100 percent or more of the BT.2020 spectrum as they use RGB lasers to create colors). That brings us to Micro RGB (also known as RGB Mini LED), the most advanced LED panel yet. Unlike the uniform white or blue backlights found on Mini LED models, it features individually-controlled, precise red, green and blue LED backlights that shine through a liquid crystal layer. It also offers more local dimming zones. The net result is higher color accuracy and better contrast than regular Mini LED displays, but with potentially greater brightness than OLED. Since each pixel still can’t be turned on and off like OLED or Micro LED, though, contrast falls short of those technologies. Wikipedia So far, there is one and only one Micro RGB TV on the market, Samsung’s 115-inch 4K MR95F model. The color accuracy is impressive with 100 percent coverage of the challenging BT.2020 HDR standard, an industry-first and huge leap over quantum dot tech. That means it can produce billions of colors natively and display a higher percentage of them in the visible spectrum than any TV to date. Samsung left out a few key specs like the local dimming zone count, only saying that it has four times more than its similarly-priced 115-inch Q90F QLED model (so likely around 3,600). The company also failed to disclose the total brightness in nits, but the figure should be impressive given the potential of Micro RGB. We were gobsmacked with the MR95F Micro RGB model in person. Engadget editor Sam Rutherford said it produced “stunningly rich and vivid colors that put Samsung’s other top-tier TVs to shame,” including the aforementioned Q90F. It also came with an equally stunning $29,999 price tag. A couple of other manufacturers including HiSense have also released RGB Mini LED models similar to Samsung’s Micro RGB, but they differ slightly in that the RGB modules are larger than the ones found on Samsung’s latest TVs. Which companies will have Micro RGB tech at CES 2026? Samsung Luckily, the number of Micro RGB TVs is about to dramatically increase. Earlier this month, Samsung announced a full lineup using the technology with 55-, 65-, 75-, 85-, 100- and 115-inch screen sizes, saying they’d set “a new standard for premium home viewing.” Those sets will also offer 100 percent BT.2020 HDR coverage under a new certification standard called Micro RGB Precision Color 100. While certainly likely to carry more reasonable prices than the first model, they’ll probably still be Samsung’s most expensive TVs when released later this year. And on Sunday, Samsung also revealed a 130-inch Micro RGB prototype meant to showcase the technology. Once again, it blew us away partially just because of the huge size, but also due to the incredible \"color accuracy and richness,\" as Engadget editor Devindra Hardawar put it. \"I couldn’t help but notice how everyone just looked a bit stunned, like the monkeys from 2001 seeing the monolith for the first time,\" he added. At the same time, LG announced its first Micro RGB “evo” TV lineup in 75-, 86- and 100-inch models. The company is also promising 100 percent BT.2020 color gamut coverage and said the sets will have over a thousand local dimming zones for color control. Not only that, it said that its new TVs will deliver 100 percent coverage in SDR modes as well, both for Adobe RGB and the challenge P3 standard. It was interesting to compare LG's Wallpaper and other OLED sets with the new Micro RGB tech, with our editor Devindra again being amazed. \"LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES,\" he said. \"Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like.\" For its part, Hisense also unveiled a lineup of \"evo\" TVs that it calls RGB Mini-LED instead of Micro RGB. It's offering them at two price points, called the UR9 and UR8, with sizes ranging from 55 up to 100 inches. The company is promising an even wider color gamut than Samsung and LG with up to 110 percent BT.2020 coverage and \"color control achieving 134 bits,\" the company said. On top of that, HiSense had a surprise up its sleeve with the launch of an enormous 163-inch Micro LED TV to compete with Samsung's The Wall. The company actually calls it RGBY Micro LED, because it introduces a fourth yellow color into the RGB mix. The reason, according to the company, is that yellow expands the color spectrum \"where human vision perceives the most nuance.\" Update January 5, 2026 at 5:18 PM: The article now includes information about HiSense's latest RGB Mini LED and Micro LED TVs. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/what-are-micro-rgb-tvs-and-why-are-they-everywhere-at-ces-2026-182441543.html?src=rss",
          "feed_position": 35,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/de40ab00-ea62-11f0-9dff-31cb26633672"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-press-conference-live-190040504.html",
          "published_at": "Mon, 05 Jan 2026 17:55:28 +0000",
          "title": "How to watch the Hisense CES 2026 press conference live",
          "standfirst": "Xinhua News Agency via Getty Images Hisense is typically best known for its affordable electronics and home appliances, from TVs to refrigerators. But at CES 2025, the China-based company showed off its premium side with a massive 136-inch micro LED TV — now available for a jaw-dropping $100,000. So what's in store for this year's show? New leadership, for starters. The company has two new hires, including Chief Marketing Officer Sarah Larsen and Chief Commercial Officer James Fishler. In a press release, Hisense said Fishler's experience in home entertainment, appliances and HVAC is important as the company \"builds toward a milestone 2026 and its presence at CES.\" We'll give you a rundown of what to expect during Hisense's presentation and how you can watch it live. How to watch Hisense's presentation Hisense is livestreaming the event on its YouTube channel today (Monday, January 5) at 1PM ET. We've embedded it below. You can also follow the Engadget CES 2026 liveblog for real-time updates from the show. What to expect With its new hires in place, Hisense is clearly aiming to further polish its brand. Between Fishler and Larsen, the new front office is bringing to bear their experience from such high-powered competitors as LG, Samsung and Beats. And in a recent interview with Tom's Guide, Larsen emphasized a continued focus on the company's fast turnaround time from concept to market as a key differentiator for Hisense. As for actual announcements, Hisense has already revealed the following products on its website: Hisense S6 FollowMe display: This is a TV on wheels (really!) that apparently can follow you from room to room. Hisense XR10 and PX4-PRO laser projectors: The company's latest laser projectors can deliver up to 6,000 lumens of brightness and screen sizes as big as 300 inches. ConnectLife AI-enhanced appliances: In an early press release, the company touted (what else) the enhanced AI smarts of its ConnectLife platform, stretching across everything from HVAC systems to kitchen gear to washer/dryers (\"... with the enhanced AI Laundry Agent, fabric types and soil levels are automatically identified...\"). Meanwhile, Larsen's aforementioned interview specifically calls out the emerging RGB TV space as a focus. We expect this year's show will be all about explaining the shades of difference between mini and micro LED display technologies, as both Samsung and LG have already thrown down pre-announcement gauntlets on the latter. Will any of them cost less than six figures? Let's hope Hisense has some good news to share on that front. Update, January 4 2026, 2:17PM ET: This story has been updated to include information on the Hisense ConnectLife AI platform. Update, January 5 2026, 10:45AM ET: This story has been updated to include info on Hisense's S6 FollowMe display and laser projectors. Update, January 5 2026, 11:31AM ET: This story has been updated to include the embedded YouTube livestream.This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-press-conference-live-190040504.html?src=rss",
          "content": "Xinhua News Agency via Getty Images Hisense is typically best known for its affordable electronics and home appliances, from TVs to refrigerators. But at CES 2025, the China-based company showed off its premium side with a massive 136-inch micro LED TV — now available for a jaw-dropping $100,000. So what's in store for this year's show? New leadership, for starters. The company has two new hires, including Chief Marketing Officer Sarah Larsen and Chief Commercial Officer James Fishler. In a press release, Hisense said Fishler's experience in home entertainment, appliances and HVAC is important as the company \"builds toward a milestone 2026 and its presence at CES.\" We'll give you a rundown of what to expect during Hisense's presentation and how you can watch it live. How to watch Hisense's presentation Hisense is livestreaming the event on its YouTube channel today (Monday, January 5) at 1PM ET. We've embedded it below. You can also follow the Engadget CES 2026 liveblog for real-time updates from the show. What to expect With its new hires in place, Hisense is clearly aiming to further polish its brand. Between Fishler and Larsen, the new front office is bringing to bear their experience from such high-powered competitors as LG, Samsung and Beats. And in a recent interview with Tom's Guide, Larsen emphasized a continued focus on the company's fast turnaround time from concept to market as a key differentiator for Hisense. As for actual announcements, Hisense has already revealed the following products on its website: Hisense S6 FollowMe display: This is a TV on wheels (really!) that apparently can follow you from room to room. Hisense XR10 and PX4-PRO laser projectors: The company's latest laser projectors can deliver up to 6,000 lumens of brightness and screen sizes as big as 300 inches. ConnectLife AI-enhanced appliances: In an early press release, the company touted (what else) the enhanced AI smarts of its ConnectLife platform, stretching across everything from HVAC systems to kitchen gear to washer/dryers (\"... with the enhanced AI Laundry Agent, fabric types and soil levels are automatically identified...\"). Meanwhile, Larsen's aforementioned interview specifically calls out the emerging RGB TV space as a focus. We expect this year's show will be all about explaining the shades of difference between mini and micro LED display technologies, as both Samsung and LG have already thrown down pre-announcement gauntlets on the latter. Will any of them cost less than six figures? Let's hope Hisense has some good news to share on that front. Update, January 4 2026, 2:17PM ET: This story has been updated to include information on the Hisense ConnectLife AI platform. Update, January 5 2026, 10:45AM ET: This story has been updated to include info on Hisense's S6 FollowMe display and laser projectors. Update, January 5 2026, 11:31AM ET: This story has been updated to include the embedded YouTube livestream.This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-press-conference-live-190040504.html?src=rss",
          "feed_position": 39,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/834aecc0-dcf1-11f0-b7de-13a29302f310"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/voccis-ai-note-taking-ring-aims-to-do-much-more-170536442.html",
          "published_at": "Mon, 05 Jan 2026 17:05:36 +0000",
          "title": "Vocci's AI note-taking ring aims to do much more",
          "standfirst": "One trend emerging from CES 2026 is wearable microphones you can use to dictate your thoughts. Vocci is one such gadget, a titanium ring with a single button capable of recording audio for up to eight hours on a charge. Unlike some of its competitors, Vocci isn’t just for catching your own thoughts as they spring forth from your scalp. Instead, you’ll be able to record whole conversations and meetings from the comfort of your proximal phalanx. Users can start and end recordings by double clicking the ring’s single button, while single clicks are used to mark important moments within the recording. Tagged moments will instruct the AI app to add more context, highlights or reminders, where appropriate. Once the file has been processed, you’ll receive a transcript, complete with a summary and commentary.I’m told the ring has a range of five meters, but I was unable to hear an example recording or see a working demo of the technology. I did ask why a ring would be more effective at capturing a room’s worth of chat over, say, using a recording app on one’s phone laid on a table. But the response was to point out a user may forget to start the recording, and you can’t disagree with that.Vocci will ship with a charging case, and will be able to recharge to full in half an hour, but it’s not clear yet how much (if at all) power will be stored in the case’s batteries. We also don’t know how much the ring will cost, but it’s likely to be available for pre-order at some point in February. As for the ring’s pedigree, it comes from Gyges Labs, the company which leant its name, manufacturing and engineering expertise to last year’s Halliday Smart Glasses.This article originally appeared on Engadget at https://www.engadget.com/wearables/voccis-ai-note-taking-ring-aims-to-do-much-more-170536442.html?src=rss",
          "content": "One trend emerging from CES 2026 is wearable microphones you can use to dictate your thoughts. Vocci is one such gadget, a titanium ring with a single button capable of recording audio for up to eight hours on a charge. Unlike some of its competitors, Vocci isn’t just for catching your own thoughts as they spring forth from your scalp. Instead, you’ll be able to record whole conversations and meetings from the comfort of your proximal phalanx. Users can start and end recordings by double clicking the ring’s single button, while single clicks are used to mark important moments within the recording. Tagged moments will instruct the AI app to add more context, highlights or reminders, where appropriate. Once the file has been processed, you’ll receive a transcript, complete with a summary and commentary.I’m told the ring has a range of five meters, but I was unable to hear an example recording or see a working demo of the technology. I did ask why a ring would be more effective at capturing a room’s worth of chat over, say, using a recording app on one’s phone laid on a table. But the response was to point out a user may forget to start the recording, and you can’t disagree with that.Vocci will ship with a charging case, and will be able to recharge to full in half an hour, but it’s not clear yet how much (if at all) power will be stored in the case’s batteries. We also don’t know how much the ring will cost, but it’s likely to be available for pre-order at some point in February. As for the ring’s pedigree, it comes from Gyges Labs, the company which leant its name, manufacturing and engineering expertise to last year’s Halliday Smart Glasses.This article originally appeared on Engadget at https://www.engadget.com/wearables/voccis-ai-note-taking-ring-aims-to-do-much-more-170536442.html?src=rss",
          "feed_position": 41
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/the-hp-omnibook-ultra-14-at-ces-2026-super-sleek-and-surprisingly-durable-170000330.html",
          "published_at": "Mon, 05 Jan 2026 17:00:00 +0000",
          "title": "The HP Omnibook Ultra 14 at CES 2026: Super sleek and surprisingly durable",
          "standfirst": "At CES 2026, HP is showing off its latest flagship consumer laptop: The Omnibook Ultra 14. It features an all-new super thin design that’s much tougher than it looks. According to HP, the Omnibook Ultra 14 is the “world’s most durably slim 14-inch consumer notebook,” which is a somewhat convoluted way of saying the system remains quite portable — just 0.42 inches thick — while still passing 20 different military standard tests (MIL-STD-810) for things like shock resistance, drops and extreme temperatures. The whole system is crafted from aluminum, though instead of taking a unibody approach like you see on Apple’s MacBooks, HP opted for forge stamped manufacturing which is said to give the laptop added strength and bend resistance. The result is a notebook that’s both 52 percent lighter than the previous model at 2.8 pounds and five percent thinner than a 2025 M4 MacBook Air 13. And after seeing it in person, I have to say it looks pretty slick, too. As you’d expect from a premium ultraportable, the Omnibook comes with a vivid 3K OLED display, up to 64GB of memory, 2TB of storage and your choice of either an Intel Core Ultra 3 CPU or a Snapdragon Elite X2 chip. That said, thanks to an exclusive partnership with Qualcomm, anyone planning on running a lot of AI-based apps on the Ultra 14 may want to go with the Snapdragon variant as it’ll come with a slightly more powerful NPU that maxes out at 85 TOPS (that’s trillions of operations per second) rather than the 80 TOPS you’d get from other OEMs. Furthermore, to help support strong sustained performance, the Ultra 14 is also the first Omnibook to feature a built-in vapor chamber. Granted, as a pretty straightforward ultraportable, this thing doesn’t have a ton of special features. But even so, I appreciate that HP didn’t cut corners regarding its keyboard, which has a nice feel that’s not too stiff or bouncy and sits above a rather large touchpad. The company even found room for quad speakers and three USB-C ports that offer Thunderbolt 4, power delivery (USB PD 3.1) and DisplayPort 2.1. My one small nitpick is that I would have liked to see an SD or microSD card reader as well, but considering HP’s emphasis on portability and toughness, I’m not surprised that it didn't make it. The other thing I’m not so sure about is the Omnibook name in general. It’s been a little while since HP axed the Spectre branding for its top tier consumer laptops and I kind of wish HP would bring it back as it sounds better and feels more befitting of a flagship system like this. Regardless, if you’re in the market for a premium 14-inch Windows laptop, the Omnibook Ultra 14 looks like it will be a very strong contender when it goes on sale later this month starting at $1,550.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/the-hp-omnibook-ultra-14-at-ces-2026-super-sleek-and-surprisingly-durable-170000330.html?src=rss",
          "content": "At CES 2026, HP is showing off its latest flagship consumer laptop: The Omnibook Ultra 14. It features an all-new super thin design that’s much tougher than it looks. According to HP, the Omnibook Ultra 14 is the “world’s most durably slim 14-inch consumer notebook,” which is a somewhat convoluted way of saying the system remains quite portable — just 0.42 inches thick — while still passing 20 different military standard tests (MIL-STD-810) for things like shock resistance, drops and extreme temperatures. The whole system is crafted from aluminum, though instead of taking a unibody approach like you see on Apple’s MacBooks, HP opted for forge stamped manufacturing which is said to give the laptop added strength and bend resistance. The result is a notebook that’s both 52 percent lighter than the previous model at 2.8 pounds and five percent thinner than a 2025 M4 MacBook Air 13. And after seeing it in person, I have to say it looks pretty slick, too. As you’d expect from a premium ultraportable, the Omnibook comes with a vivid 3K OLED display, up to 64GB of memory, 2TB of storage and your choice of either an Intel Core Ultra 3 CPU or a Snapdragon Elite X2 chip. That said, thanks to an exclusive partnership with Qualcomm, anyone planning on running a lot of AI-based apps on the Ultra 14 may want to go with the Snapdragon variant as it’ll come with a slightly more powerful NPU that maxes out at 85 TOPS (that’s trillions of operations per second) rather than the 80 TOPS you’d get from other OEMs. Furthermore, to help support strong sustained performance, the Ultra 14 is also the first Omnibook to feature a built-in vapor chamber. Granted, as a pretty straightforward ultraportable, this thing doesn’t have a ton of special features. But even so, I appreciate that HP didn’t cut corners regarding its keyboard, which has a nice feel that’s not too stiff or bouncy and sits above a rather large touchpad. The company even found room for quad speakers and three USB-C ports that offer Thunderbolt 4, power delivery (USB PD 3.1) and DisplayPort 2.1. My one small nitpick is that I would have liked to see an SD or microSD card reader as well, but considering HP’s emphasis on portability and toughness, I’m not surprised that it didn't make it. The other thing I’m not so sure about is the Omnibook name in general. It’s been a little while since HP axed the Spectre branding for its top tier consumer laptops and I kind of wish HP would bring it back as it sounds better and feels more befitting of a flagship system like this. Regardless, if you’re in the market for a premium 14-inch Windows laptop, the Omnibook Ultra 14 looks like it will be a very strong contender when it goes on sale later this month starting at $1,550.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/the-hp-omnibook-ultra-14-at-ces-2026-super-sleek-and-surprisingly-durable-170000330.html?src=rss",
          "feed_position": 45
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/qualcomm-unveils-snapdragon-x2-plus-chip-at-ces-170000392.html",
          "published_at": "Mon, 05 Jan 2026 17:00:00 +0000",
          "title": "Qualcomm unveils Snapdragon X2 Plus chip at CES",
          "standfirst": "CES tends to bring a wave of news from chipmakers, and Qualcomm has used this year's event to announce the Snapdragon X2 Plus laptop processor. This is a more modest version of the flagship Snapdragon X2 Elite chip that Qualcomm unveiled in September. The Snapdragon X2 Elite will be available in the coming generation of Windows 11 Copilot+ PCs and its integrated Hexagon NPU can deliver the 80 TOPS performance benchmark for powering artificial intelligence tasks. The chip is also equipped with a third-generation Qualcomm Oryon CPU with either six cores or ten cores. For comparison, the Snapdragon X2 Elite gives options of either 12 or 18 cores. According to the company, this iteration of the CPU boasts up to 35 percent faster single-core performance compared with the previous generation. It also says the six-core model has up to 10 percent faster multi-core performance over the prior model, while the ten-core option has up to 17 percent better multi-core performance. Both versions of the Snapdragon X2 Plus come with an Adreno GPU that has improved performance up to 29 percent over the past iteration.This article originally appeared on Engadget at https://www.engadget.com/computing/qualcomm-unveils-snapdragon-x2-plus-chip-at-ces-170000392.html?src=rss",
          "content": "CES tends to bring a wave of news from chipmakers, and Qualcomm has used this year's event to announce the Snapdragon X2 Plus laptop processor. This is a more modest version of the flagship Snapdragon X2 Elite chip that Qualcomm unveiled in September. The Snapdragon X2 Elite will be available in the coming generation of Windows 11 Copilot+ PCs and its integrated Hexagon NPU can deliver the 80 TOPS performance benchmark for powering artificial intelligence tasks. The chip is also equipped with a third-generation Qualcomm Oryon CPU with either six cores or ten cores. For comparison, the Snapdragon X2 Elite gives options of either 12 or 18 cores. According to the company, this iteration of the CPU boasts up to 35 percent faster single-core performance compared with the previous generation. It also says the six-core model has up to 10 percent faster multi-core performance over the prior model, while the ten-core option has up to 17 percent better multi-core performance. Both versions of the Snapdragon X2 Plus come with an Adreno GPU that has improved performance up to 29 percent over the past iteration.This article originally appeared on Engadget at https://www.engadget.com/computing/qualcomm-unveils-snapdragon-x2-plus-chip-at-ces-170000392.html?src=rss",
          "feed_position": 46
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/lg-tvs-at-ces-2026-a-stunning-wallpaper-set-glorious-micro-rgb-colors-and-a-better-gallery-tv-033739600.html",
          "published_at": "Mon, 05 Jan 2026 16:46:20 +0000",
          "title": "LG TVs at CES 2026: A stunning Wallpaper set, glorious Micro RGB colors and a better Gallery TV",
          "standfirst": "We typically see LG TV announcements a bit before CES, but this year the company had a surprise in store. CES 2026 marks the return of LG's ultra-thin \"Wallpaper\" TV. The latest version sports a gorgeous OLED screen and wireless connectivity, and it's about as thin as a pencil. We were able to check out the new Wallpaper TV during a CES preview event, along with LG’s Gallery and Micro RGB sets. The company also announced refreshed OLED and LED sets for this year, but it's clear that 2026 will be filled with intriguing TVs for a variety of consumers.LG's 2026 Wallpaper OLED TVDevindra Hardawar for EngadgetThe Wallpaper TV (LG W6)If money were no object, I'd want a 100-inch LG Wallpaper TV in my family room immediately. It looks shockingly thin in person — almost as if it's some sort of sci-fi prop — and it delivers the rich colors and dark levels we expect from OLED. Cable management is also a cinch, since it requires just a single power cable. The A/V inputs are handled by LG's One Connect box, which you can position wirelessly up to 10 meters away from the TV. LG's 2026 Wallpaper OLED TV from the rearDevindra Hardawar for EngadgetThe LG W6 combines the best of LG's OLED technology, including \"Hyper Radiant Color\" for improved black levels and color, \"Brightness Booster Ultra\" to crank up luminance 3.9 times more than conventional OLEDs and a reflection free screen material. LG's Alpha 9 Gen 3 processor beefs up its performance, and its NPU also helps to improve upscaling and overall image performance. (And yes, you can also access generative AI features via Microsoft Copilot and Google Gemini, if you're into that sort of thing.)All of that adds up to one of the most remarkable TVs I've seen in years. I haven't been too enamored with other TV gimmicks lately, like everything trying to mimic Samsung's The Frame, or the usless 8K sets. But a super-thin wireless TV with the best OLED panel available? That's the stuff dreams are made of. LG's 2026 Gallery TVDevindra Hardawar for EngadgetThe Gallery TV competes with Samsung’s FrameWhile LG has made Gallery TVs before, in 2026 it's making a more concerted effort to take on Samsung's popular Frame TV. LG says the new sets were designed with the help of museum curators, which helps the \"Gallery Mode\" adjust brightness and contrast to specific works of art. They also ship with magnetic frame-like bezels, and they have anti-reflective screens to help make the art shine. In person, the new Gallery TV looks fine, though it's easy to tell that the colors and contrast levels don't match LG's premium OLED TVs. To avoid burn-in issues, these sets feature Mini LED panels. As I noted above, I'm not the core consumer for one of these TVs, but it's nice to see more competition against Samsung's Frame TVs. (Despite pioneering the idea of TVs displaying art, the Frame sets are still fairly mediocre when it comes to actually watching TV shows and movies.) LG's Micro RGB TVDevindra Hardawar for EngadgetMicro RGB looks like a genuine Mini LED upgradeAs if we needed more TV acronyms to worry about, say hello to Micro RGB, a new technology built atop Mini LED to cover vastly more color range. Just don't confuse it with Micro LED, which is the wildly expensive evolutionary step forward for OLED. LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES. Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like. I'd have to compare it to LG's Wall TV side-by-side to truly see how Micro RGB competes with OLED, but technically OLED should still offer better contrast and black levels, since each of its pixels are self-emissive. But sure, if I couldn't get a 100-inch Wall TV in my family room, I certainly wouldn't turn down an enormous Micro RGB. What about LG's other OLED TVs?All of the next-generation OLED technology in the wallpaper TV will also make its way into LG's G6 OLED models, while the new C6 and other lines will see improvements of their own. All I can say is that the new G6 OLED looked impressive, with a noticeably brighter picture and HDR elements compared to G-series OLEDs from several years ago. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-tvs-at-ces-2026-a-stunning-wallpaper-set-glorious-micro-rgb-colors-and-a-better-gallery-tv-033739600.html?src=rss",
          "content": "We typically see LG TV announcements a bit before CES, but this year the company had a surprise in store. CES 2026 marks the return of LG's ultra-thin \"Wallpaper\" TV. The latest version sports a gorgeous OLED screen and wireless connectivity, and it's about as thin as a pencil. We were able to check out the new Wallpaper TV during a CES preview event, along with LG’s Gallery and Micro RGB sets. The company also announced refreshed OLED and LED sets for this year, but it's clear that 2026 will be filled with intriguing TVs for a variety of consumers.LG's 2026 Wallpaper OLED TVDevindra Hardawar for EngadgetThe Wallpaper TV (LG W6)If money were no object, I'd want a 100-inch LG Wallpaper TV in my family room immediately. It looks shockingly thin in person — almost as if it's some sort of sci-fi prop — and it delivers the rich colors and dark levels we expect from OLED. Cable management is also a cinch, since it requires just a single power cable. The A/V inputs are handled by LG's One Connect box, which you can position wirelessly up to 10 meters away from the TV. LG's 2026 Wallpaper OLED TV from the rearDevindra Hardawar for EngadgetThe LG W6 combines the best of LG's OLED technology, including \"Hyper Radiant Color\" for improved black levels and color, \"Brightness Booster Ultra\" to crank up luminance 3.9 times more than conventional OLEDs and a reflection free screen material. LG's Alpha 9 Gen 3 processor beefs up its performance, and its NPU also helps to improve upscaling and overall image performance. (And yes, you can also access generative AI features via Microsoft Copilot and Google Gemini, if you're into that sort of thing.)All of that adds up to one of the most remarkable TVs I've seen in years. I haven't been too enamored with other TV gimmicks lately, like everything trying to mimic Samsung's The Frame, or the usless 8K sets. But a super-thin wireless TV with the best OLED panel available? That's the stuff dreams are made of. LG's 2026 Gallery TVDevindra Hardawar for EngadgetThe Gallery TV competes with Samsung’s FrameWhile LG has made Gallery TVs before, in 2026 it's making a more concerted effort to take on Samsung's popular Frame TV. LG says the new sets were designed with the help of museum curators, which helps the \"Gallery Mode\" adjust brightness and contrast to specific works of art. They also ship with magnetic frame-like bezels, and they have anti-reflective screens to help make the art shine. In person, the new Gallery TV looks fine, though it's easy to tell that the colors and contrast levels don't match LG's premium OLED TVs. To avoid burn-in issues, these sets feature Mini LED panels. As I noted above, I'm not the core consumer for one of these TVs, but it's nice to see more competition against Samsung's Frame TVs. (Despite pioneering the idea of TVs displaying art, the Frame sets are still fairly mediocre when it comes to actually watching TV shows and movies.) LG's Micro RGB TVDevindra Hardawar for EngadgetMicro RGB looks like a genuine Mini LED upgradeAs if we needed more TV acronyms to worry about, say hello to Micro RGB, a new technology built atop Mini LED to cover vastly more color range. Just don't confuse it with Micro LED, which is the wildly expensive evolutionary step forward for OLED. LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES. Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like. I'd have to compare it to LG's Wall TV side-by-side to truly see how Micro RGB competes with OLED, but technically OLED should still offer better contrast and black levels, since each of its pixels are self-emissive. But sure, if I couldn't get a 100-inch Wall TV in my family room, I certainly wouldn't turn down an enormous Micro RGB. What about LG's other OLED TVs?All of the next-generation OLED technology in the wallpaper TV will also make its way into LG's G6 OLED models, while the new C6 and other lines will see improvements of their own. All I can say is that the new G6 OLED looked impressive, with a noticeably brighter picture and HDR elements compared to G-series OLEDs from several years ago. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-tvs-at-ces-2026-a-stunning-wallpaper-set-glorious-micro-rgb-colors-and-a-better-gallery-tv-033739600.html?src=rss",
          "feed_position": 47,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/LG_CES_2026-5.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/brex-bets-on-less-orchestration-as-it-builds-an-agent-mesh-for-autonomous",
          "published_at": "Mon, 05 Jan 2026 08:00:00 GMT",
          "title": "Brex bets on ‘less orchestration’ as it builds an Agent Mesh for autonomous finance",
          "standfirst": "Fintech Brex is betting that the future of enterprise AI isn’t better orchestration — it’s less of it.As generative AI agents move from copilots to autonomous systems, Brex CTO James Reggio says traditional agent orchestration frameworks are becoming a constraint rather than an enabler. Instead of relying on a central coordinator or rigid workflows, Brex has built what it calls an “Agent Mesh”: a network of narrow, role-specific agents that communicate in plain language and operate independently — but with full visibility.“Our goal is to use AI to make Brex effectively disappear,” Reggio told VentureBeat. “We’re aiming for total automation.”Brex learned that for its purposes, agents need to work in narrow, specific roles to be more modular, flexible, and auditable. Reggio said the architectural goal is to enable every manager in an enterprise “to have a single point of contact within Brex that’s handling the totality of their responsibilities, be it spend management, requesting travel, or approving spend limit requests.”The journey from Brex AssistantThe financial services industry has long embraced AI and machine learning to handle the massive amounts of data it processes. But when it comes to bringing AI models and agents, the industry took a more cautious road at the beginning. Now, more financial services companies, including Brex, have launched AI-powered platforms and several agentic workflows. Brex’s first foray into generative AI was with its Brex Assistant, released in 2023, which helped customers automate certain finance and expense tasks. It provides suggestions to complete expenses, automatically fills in information, and follows up on expenses that violate policies. Reggio acknowledges that Brex Assistant works, but it’s not enough. “I think to some degree, it remains a bit of a technology where we don&#x27;t entirely know the limits of it,\" he said. \"There&#x27;s quite a large number of patterns that need to exist around it that are kind of being developed by the industry as the technology matures and as more companies build with it.\" Brex Assistant uses multiple models, including Anthropic’s Claude and custom Brex-models, as well as OpenAI’s API. The assistant automates some tasks but is still limited in how low-touch it can be. Reggio said Brex Assistant still plays a big role in the company’s autonomy journey, mainly because its Agent Mesh product flows into the application. Agent Mesh to replace orchestrationThe consensus in the industry is that multi-agent ecosystems, in which agents communicate to accomplish tasks, require an orchestration framework to guide them. Reggio, on the other hand, has a different take. \"Deterministic orchestration infrastructure … was a solution for the problems that we saw two years ago, which was that agents, just like the models, hallucinate a lot,” Reggio said. “They&#x27;re not very good with multiple tools, so you need to give them these degrees of freedom, but in a more structured, rigid system. But as the models get better, I think it&#x27;s starting to hold back the range of possibilities that are expanding.”More traditional agent orchestration architectures either focus on a single agent that does everything or, more commonly, coordinator/orchestrator plus tool agents that explicitly define workflows. Reggio said both frameworks are too rigid and solve issues more commonly seen in traditional software than in AI. The difference, Reggio argues, is structural:Traditional orchestration: predefined workflows, central coordinator, deterministic pathsAgent Mesh: event-driven, role-specialized agents, message-based coordinationAgent Mesh relies on stitching together networks of many small agents, each specializing in a single task. The agents, once again using the hybrid mix of models as with the Brex Assistant, communicate with other agents “in plain English” over a shared message stream. A routing model quickly determines which tools to invoke, he said. A single reimbursement request triggers several tasks: a compliance check to align with expense policies, budget validation, receipt matching, and then payment initiation. While an agent can certainly be coded to do all of that, this method is “brittle and error-prone,” and it responds to new information shared through a message stream anyway. Reggio said the idea is to disambiguate all of those separate tasks and assign them to smaller agents instead. He likened the architecture to a Wi-Fi mesh, where no single node controls the system — reliability emerges from many small, overlapping contributors. “We basically found a really good fit with the idea of embodying specific roles as agents on top of the best platform to manage specific responsibilities, much like how you might delegate accounts payable to one team versus expense management to another team,” Reggio said. Brex defines three core ideas in the Agent Mesh architecture:Config, where definitions of the agent, model, tools and subscription liveMessageStream, a log of every message, tool call and state transition Clock, which ensures deterministic ordering Brex also built evaluations into the system, in which the LLM acts as a judge, and an audit agent reviews each agent’s decisions to ensure they adhere to accuracy and behavioral policies. Success so farBrex says it has seen substantial efficiency gains among its customers in its AI ecosystem. Brex did not provide third-party benchmarks or customer-specific data to validate those gains.But Reggio said enterprise customers using Brex Assistant and the company’s machine learning systems “are able to achieve 99% automation, especially for customers that really leaned into AI.”This is a marked improvement from the 60 to 70% Brex customers who were able to automate their expense processes before the launch of Brex Assistant. The company is still early in its autonomy journey, Reggio said. But if the Agent Mesh approach works, the most successful outcome may be invisible: employees no longer thinking about expenses at all.",
          "content": "Fintech Brex is betting that the future of enterprise AI isn’t better orchestration — it’s less of it.As generative AI agents move from copilots to autonomous systems, Brex CTO James Reggio says traditional agent orchestration frameworks are becoming a constraint rather than an enabler. Instead of relying on a central coordinator or rigid workflows, Brex has built what it calls an “Agent Mesh”: a network of narrow, role-specific agents that communicate in plain language and operate independently — but with full visibility.“Our goal is to use AI to make Brex effectively disappear,” Reggio told VentureBeat. “We’re aiming for total automation.”Brex learned that for its purposes, agents need to work in narrow, specific roles to be more modular, flexible, and auditable. Reggio said the architectural goal is to enable every manager in an enterprise “to have a single point of contact within Brex that’s handling the totality of their responsibilities, be it spend management, requesting travel, or approving spend limit requests.”The journey from Brex AssistantThe financial services industry has long embraced AI and machine learning to handle the massive amounts of data it processes. But when it comes to bringing AI models and agents, the industry took a more cautious road at the beginning. Now, more financial services companies, including Brex, have launched AI-powered platforms and several agentic workflows. Brex’s first foray into generative AI was with its Brex Assistant, released in 2023, which helped customers automate certain finance and expense tasks. It provides suggestions to complete expenses, automatically fills in information, and follows up on expenses that violate policies. Reggio acknowledges that Brex Assistant works, but it’s not enough. “I think to some degree, it remains a bit of a technology where we don&#x27;t entirely know the limits of it,\" he said. \"There&#x27;s quite a large number of patterns that need to exist around it that are kind of being developed by the industry as the technology matures and as more companies build with it.\" Brex Assistant uses multiple models, including Anthropic’s Claude and custom Brex-models, as well as OpenAI’s API. The assistant automates some tasks but is still limited in how low-touch it can be. Reggio said Brex Assistant still plays a big role in the company’s autonomy journey, mainly because its Agent Mesh product flows into the application. Agent Mesh to replace orchestrationThe consensus in the industry is that multi-agent ecosystems, in which agents communicate to accomplish tasks, require an orchestration framework to guide them. Reggio, on the other hand, has a different take. \"Deterministic orchestration infrastructure … was a solution for the problems that we saw two years ago, which was that agents, just like the models, hallucinate a lot,” Reggio said. “They&#x27;re not very good with multiple tools, so you need to give them these degrees of freedom, but in a more structured, rigid system. But as the models get better, I think it&#x27;s starting to hold back the range of possibilities that are expanding.”More traditional agent orchestration architectures either focus on a single agent that does everything or, more commonly, coordinator/orchestrator plus tool agents that explicitly define workflows. Reggio said both frameworks are too rigid and solve issues more commonly seen in traditional software than in AI. The difference, Reggio argues, is structural:Traditional orchestration: predefined workflows, central coordinator, deterministic pathsAgent Mesh: event-driven, role-specialized agents, message-based coordinationAgent Mesh relies on stitching together networks of many small agents, each specializing in a single task. The agents, once again using the hybrid mix of models as with the Brex Assistant, communicate with other agents “in plain English” over a shared message stream. A routing model quickly determines which tools to invoke, he said. A single reimbursement request triggers several tasks: a compliance check to align with expense policies, budget validation, receipt matching, and then payment initiation. While an agent can certainly be coded to do all of that, this method is “brittle and error-prone,” and it responds to new information shared through a message stream anyway. Reggio said the idea is to disambiguate all of those separate tasks and assign them to smaller agents instead. He likened the architecture to a Wi-Fi mesh, where no single node controls the system — reliability emerges from many small, overlapping contributors. “We basically found a really good fit with the idea of embodying specific roles as agents on top of the best platform to manage specific responsibilities, much like how you might delegate accounts payable to one team versus expense management to another team,” Reggio said. Brex defines three core ideas in the Agent Mesh architecture:Config, where definitions of the agent, model, tools and subscription liveMessageStream, a log of every message, tool call and state transition Clock, which ensures deterministic ordering Brex also built evaluations into the system, in which the LLM acts as a judge, and an audit agent reviews each agent’s decisions to ensure they adhere to accuracy and behavioral policies. Success so farBrex says it has seen substantial efficiency gains among its customers in its AI ecosystem. Brex did not provide third-party benchmarks or customer-specific data to validate those gains.But Reggio said enterprise customers using Brex Assistant and the company’s machine learning systems “are able to achieve 99% automation, especially for customers that really leaned into AI.”This is a marked improvement from the 60 to 70% Brex customers who were able to automate their expense processes before the launch of Brex Assistant. The company is still early in its autonomy journey, Reggio said. But if the Agent Mesh approach works, the most successful outcome may be invisible: employees no longer thinking about expenses at all.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2bn5jMREgSASEDf2vDQ6HQ/e5229bf4536b36825a2dbb7cb92fcf6e/crimedy7_illustration_of_a_robot_poring_through_expense_repor_a03892f6-f441-4dab-a57b-8e664b411198_1.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
          "published_at": "Mon, 05 Jan 2026 07:45:00 GMT",
          "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
          "standfirst": "When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.For the past week, the engineering community has been dissecting a thread on X from Boris Cherny, the creator and head of Claude Code at Anthropic. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.\"If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,\" wrote Jeff Tang, a prominent voice in the developer community. Kyle McNease, another industry observer, went further, declaring that with Cherny&#x27;s \"game-changing updates,\" Anthropic is \"on fire,\" potentially facing \"their ChatGPT moment.\"The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience \"feels more like Starcraft\" than traditional coding — a shift from typing syntax to commanding autonomous units.Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. How running five AI agents at once turns coding into a real-time strategy gameThe most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional \"inner loop\" of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.\"I run 5 Claudes in parallel in my terminal,\" Cherny wrote. \"I number my tabs 1-5, and use system notifications to know when a Claude needs input.\"By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs \"5-10 Claudes on claude.ai\" in his browser, using a \"teleport\" command to hand off sessions between the web and his local machine.This validates the \"do more with less\" strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.The counterintuitive case for choosing the slowest, smartest modelIn a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: Opus 4.5.\"I use Opus 4.5 with thinking for everything,\" Cherny explained. \"It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger & slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.\"For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the \"compute tax\" for a smarter model upfront eliminates the \"correction tax\" later.One shared file turns every AI mistake into a permanent lessonCherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not \"remember\" a company&#x27;s specific coding style or architectural decisions from one session to the next.To address this, Cherny&#x27;s team maintains a single file named CLAUDE.md in their git repository. \"Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,\" he wrote.This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. \"Every mistake becomes a rule,\" noted Aakash Gupta, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.Slash commands and subagents automate the most tedious parts of developmentThe \"vanilla\" workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.He highlighted a command called /commit-push-pr, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.Why verification loops are the real unlock for AI-generated codeIf there is a single reason Claude Code has reportedly hit $1 billion in annual recurring revenue so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.\"Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,\" Cherny wrote. \"It opens a browser, tests the UI, and iterates until the code works and the UX feels good.\"He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by \"2-3x.\" The agent doesn&#x27;t just write code; it proves the code works.What Cherny&#x27;s workflow signals about the future of software engineeringThe reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, \"AI coding\" meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.\"Read this if you&#x27;re already an engineer... and want more power,\" Jeff Tang summarized on X.The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.",
          "content": "When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.For the past week, the engineering community has been dissecting a thread on X from Boris Cherny, the creator and head of Claude Code at Anthropic. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.\"If you&#x27;re not reading the Claude Code best practices straight from its creator, you&#x27;re behind as a programmer,\" wrote Jeff Tang, a prominent voice in the developer community. Kyle McNease, another industry observer, went further, declaring that with Cherny&#x27;s \"game-changing updates,\" Anthropic is \"on fire,\" potentially facing \"their ChatGPT moment.\"The excitement stems from a paradox: Cherny&#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&#x27;s setup, the experience \"feels more like Starcraft\" than traditional coding — a shift from typing syntax to commanding autonomous units.Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. How running five AI agents at once turns coding into a real-time strategy gameThe most striking revelation from Cherny&#x27;s disclosure is that he does not code in a linear fashion. In the traditional \"inner loop\" of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.\"I run 5 Claudes in parallel in my terminal,\" Cherny wrote. \"I number my tabs 1-5, and use system notifications to know when a Claude needs input.\"By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs \"5-10 Claudes on claude.ai\" in his browser, using a \"teleport\" command to hand off sessions between the web and his local machine.This validates the \"do more with less\" strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.The counterintuitive case for choosing the slowest, smartest modelIn a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&#x27;s heaviest, slowest model: Opus 4.5.\"I use Opus 4.5 with thinking for everything,\" Cherny explained. \"It&#x27;s the best coding model I&#x27;ve ever used, and even though it&#x27;s bigger & slower than Sonnet, since you have to steer it less and it&#x27;s better at tool use, it is almost always faster than using a smaller model in the end.\"For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&#x27;t the generation speed of the token; it is the human time spent correcting the AI&#x27;s mistakes. Cherny&#x27;s workflow suggests that paying the \"compute tax\" for a smarter model upfront eliminates the \"correction tax\" later.One shared file turns every AI mistake into a permanent lessonCherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not \"remember\" a company&#x27;s specific coding style or architectural decisions from one session to the next.To address this, Cherny&#x27;s team maintains a single file named CLAUDE.md in their git repository. \"Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,\" he wrote.This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&#x27;t just fix the code; they tag the AI to update its own instructions. \"Every mistake becomes a rule,\" noted Aakash Gupta, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.Slash commands and subagents automate the most tedious parts of developmentThe \"vanilla\" workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&#x27;s repository — to handle complex operations with a single keystroke.He highlighted a command called /commit-push-pr, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.Why verification loops are the real unlock for AI-generated codeIf there is a single reason Claude Code has reportedly hit $1 billion in annual recurring revenue so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.\"Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,\" Cherny wrote. \"It opens a browser, tests the UI, and iterates until the code works and the UX feels good.\"He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by \"2-3x.\" The agent doesn&#x27;t just write code; it proves the code works.What Cherny&#x27;s workflow signals about the future of software engineeringThe reaction to Cherny&#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, \"AI coding\" meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.\"Read this if you&#x27;re already an engineer... and want more power,\" Jeff Tang summarized on X.The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&#x27;t just be more productive. They&#x27;ll be playing an entirely different game — and everyone else will still be typing.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6VsJWNsStTR57q9vFd5L08/a0d88b4dcbd1e9ba77fd72a9c55988d9/nuneybits_Vector_art_of_programmer_conducting_robot_orchestra_i_908157a9-d44f-4bce-b390-5913b88dad27.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/intelition-changes-everything-ai-is-no-longer-a-tool-you-invoke",
          "published_at": "Sun, 04 Jan 2026 19:00:00 GMT",
          "title": "'Intelition' changes everything: AI is no longer a tool you invoke",
          "standfirst": "AI is evolving faster than our vocabulary for describing it. We may need a few new words. We have “cognition” for how a single mind thinks, but we don&#x27;t have a word for what happens when human and machine intelligence work together to perceive, decide, create and act. Let’s call that process intelition. Intelition isn’t a feature; it’s the organizing principle for the next wave of software where humans and AI operate inside the same shared model of the enterprise. Today’s systems treat AI models as things you invoke from the outside. You act as a “user,” prompting for responses or wiring a “human in the loop” step into agentic workflows. But that&#x27;s evolving into continuous co-production: People and agents are shaping decisions, logic and actions together, in real time. Read on for a breakdown of the three forces driving this new paradigm. A unified ontology is just the beginningIn a recent shareholder letter, Palantir CEO Alex Karp wrote that “all the value in the market is going to go to chips and what we call ontology,” and argued that this shift is “only the beginning of something much larger and more significant.” By ontology, Karp means a shared model of objects (customers, policies, assets, events) and their relationships. This also includes what Palantir calls an ontology’s “kinetic layer” that defines the actions and security permissions connecting objects.In the SaaS era, every enterprise application creates its own object and process models. Combined with a host of legacy systems and often chaotic models, enterprises face the challenge of stitching all this together. It’s a big and difficult job, with redundancies, incomplete structures and missing data. The reality: No matter how many data warehouse or data lake projects commissioned, few enterprises come close to creating a consolidated enterprise ontology. A unified ontology is essential for today’s agentic AI tools. As organizations link and federate ontologies, a new software paradigm emerges: Agentic AI can reason and act across suppliers, regulators, customers and operations, not just within a single app. As Karp describes it, the aim is “to tether the power of artificial intelligence to objects and relationships in the real world.” World models and continuous learningToday’s models can hold extensive context, but holding information isn’t the same as learning from it. Continual learning requires the accumulation of understanding, rather than resets with each retraining. To his aim, Google recently announced “Nested Learning” as a potential solution, grounded direclty into existing LLM architecture and training data. The authors don’t claim to have solved the challenges of building world models. But, Nested Learning could supply the raw ingredients for them: Durable memory with continual learning layered into the system. The endpoint would make retraining obsolete. In June 2022, Meta&#x27;s chief AI scientist Yann LeCun created a blueprint for “autonomous machine intelligence” that featured a hierarchical approach to using joint embeddings to make predictions using world models. He called the technique H-JEPA, and later put bluntly: “LLMs are good at manipulating language, but not at thinking.”Over the past three years, LeCun and his colleagues at Meta have moved H-JEPA theory into practice with open source models V-JEPA and I-JEPA, which learn image and video representations of the world. The personal intelition interface The third force in this agentic, ontology-driven world is the personal interface. This puts people at the center rather than as “users” on the periphery. This is not another app; it is the primary way a person participates in the next era of work and life. Rather than treating AI as something we visit through a chat window or API cal, the personal intelition interface will be always-on, aware of our context, preferences and goals and capable of acting on our behalf across the entire federated economy. Let’s analyze how this is already coming together.In May, Jony Ive sold his AI device company io to OpenAI to accelerate a new AI device category. He noted at the time: “If you make something new, if you innovate, there will be consequences unforeseen, and some will be wonderful, and some will be harmful. While some of the less positive consequences were unintentional, I still feel responsibility. And the manifestation of that is a determination to try and be useful.” That is, getting the personal intelligence device right means more than an attractive venture opportunity. Apple is looking beyond LLMs for on-device solutions that require less processing power and result in less latency when creating AI apps to understand “user intent.” Last year, they created UI-JEPA, an innovation that moves to “on-device analysis” of what the user wants. This strikes directly at the business model of today’s digital economy, where centralized profiling of “users” transforms intent and behavior data into vast revenue streams.Tim Berners-Lee, the inventor of the World Wide Web, recently noted: “The user has been reduced to a consumable product for the advertiser ... there&#x27;s still time to build machines that work for humans, and not the other way around.\" Moving user intent to the device will drive interest in a secure personal data management standard, Solid, that Berners-Lee and his colleagues have been developing since 2022. The standard is ideally suited to pair with new personal AI devices. For instance, Inrupt, Inc., a company founded by Berners-Lee, recently combined Solid with Anthropic’s MCP standard for Agentic Wallets. Personal control is more than a feature of this paradigm; it is the architectural safeguard as systems gain the ability to learn and act continuously.Ultimately, these three forces are moving and converging faster than most realize. Enterprise ontologies provide the nouns and verbs, world-model research supplies durable memory and learning and the personal interface becomes the permissioned point of control. The next software era isn&#x27;t coming. It&#x27;s already here.Brian Mulconrey is SVP at Sureify Labs.",
          "content": "AI is evolving faster than our vocabulary for describing it. We may need a few new words. We have “cognition” for how a single mind thinks, but we don&#x27;t have a word for what happens when human and machine intelligence work together to perceive, decide, create and act. Let’s call that process intelition. Intelition isn’t a feature; it’s the organizing principle for the next wave of software where humans and AI operate inside the same shared model of the enterprise. Today’s systems treat AI models as things you invoke from the outside. You act as a “user,” prompting for responses or wiring a “human in the loop” step into agentic workflows. But that&#x27;s evolving into continuous co-production: People and agents are shaping decisions, logic and actions together, in real time. Read on for a breakdown of the three forces driving this new paradigm. A unified ontology is just the beginningIn a recent shareholder letter, Palantir CEO Alex Karp wrote that “all the value in the market is going to go to chips and what we call ontology,” and argued that this shift is “only the beginning of something much larger and more significant.” By ontology, Karp means a shared model of objects (customers, policies, assets, events) and their relationships. This also includes what Palantir calls an ontology’s “kinetic layer” that defines the actions and security permissions connecting objects.In the SaaS era, every enterprise application creates its own object and process models. Combined with a host of legacy systems and often chaotic models, enterprises face the challenge of stitching all this together. It’s a big and difficult job, with redundancies, incomplete structures and missing data. The reality: No matter how many data warehouse or data lake projects commissioned, few enterprises come close to creating a consolidated enterprise ontology. A unified ontology is essential for today’s agentic AI tools. As organizations link and federate ontologies, a new software paradigm emerges: Agentic AI can reason and act across suppliers, regulators, customers and operations, not just within a single app. As Karp describes it, the aim is “to tether the power of artificial intelligence to objects and relationships in the real world.” World models and continuous learningToday’s models can hold extensive context, but holding information isn’t the same as learning from it. Continual learning requires the accumulation of understanding, rather than resets with each retraining. To his aim, Google recently announced “Nested Learning” as a potential solution, grounded direclty into existing LLM architecture and training data. The authors don’t claim to have solved the challenges of building world models. But, Nested Learning could supply the raw ingredients for them: Durable memory with continual learning layered into the system. The endpoint would make retraining obsolete. In June 2022, Meta&#x27;s chief AI scientist Yann LeCun created a blueprint for “autonomous machine intelligence” that featured a hierarchical approach to using joint embeddings to make predictions using world models. He called the technique H-JEPA, and later put bluntly: “LLMs are good at manipulating language, but not at thinking.”Over the past three years, LeCun and his colleagues at Meta have moved H-JEPA theory into practice with open source models V-JEPA and I-JEPA, which learn image and video representations of the world. The personal intelition interface The third force in this agentic, ontology-driven world is the personal interface. This puts people at the center rather than as “users” on the periphery. This is not another app; it is the primary way a person participates in the next era of work and life. Rather than treating AI as something we visit through a chat window or API cal, the personal intelition interface will be always-on, aware of our context, preferences and goals and capable of acting on our behalf across the entire federated economy. Let’s analyze how this is already coming together.In May, Jony Ive sold his AI device company io to OpenAI to accelerate a new AI device category. He noted at the time: “If you make something new, if you innovate, there will be consequences unforeseen, and some will be wonderful, and some will be harmful. While some of the less positive consequences were unintentional, I still feel responsibility. And the manifestation of that is a determination to try and be useful.” That is, getting the personal intelligence device right means more than an attractive venture opportunity. Apple is looking beyond LLMs for on-device solutions that require less processing power and result in less latency when creating AI apps to understand “user intent.” Last year, they created UI-JEPA, an innovation that moves to “on-device analysis” of what the user wants. This strikes directly at the business model of today’s digital economy, where centralized profiling of “users” transforms intent and behavior data into vast revenue streams.Tim Berners-Lee, the inventor of the World Wide Web, recently noted: “The user has been reduced to a consumable product for the advertiser ... there&#x27;s still time to build machines that work for humans, and not the other way around.\" Moving user intent to the device will drive interest in a secure personal data management standard, Solid, that Berners-Lee and his colleagues have been developing since 2022. The standard is ideally suited to pair with new personal AI devices. For instance, Inrupt, Inc., a company founded by Berners-Lee, recently combined Solid with Anthropic’s MCP standard for Agentic Wallets. Personal control is more than a feature of this paradigm; it is the architectural safeguard as systems gain the ability to learn and act continuously.Ultimately, these three forces are moving and converging faster than most realize. Enterprise ontologies provide the nouns and verbs, world-model research supplies durable memory and learning and the personal interface becomes the permissioned point of control. The next software era isn&#x27;t coming. It&#x27;s already here.Brian Mulconrey is SVP at Sureify Labs.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7nS0fhhd8rb4GWzz2aXNYd/2f0ea05e1f3753e57a1ef4b14cc773d0/Thinking_together.png?w=300&q=30"
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/20251218-110941_%281%29.png",
      "popularity_score": 2019.8144983333334
    },
    {
      "id": "cluster_5",
      "coverage": 2,
      "updated_at": "Mon, 05 Jan 2026 22:45:00 -0500",
      "title": "Jensen Huang says Nvidia's Vera Rubin chips are in \"full production\"; Nvidia says Rubin can train some LLMs with roughly one-fourth the chips Blackwell needs (Lauren Goode/Wired)",
      "neutral_headline": "Jensen Huang Says Nvidia’s New Vera Rubin Chips Are in ‘Full Production’",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260105/p38#a260105p38",
          "published_at": "Mon, 05 Jan 2026 22:45:00 -0500",
          "title": "Jensen Huang says Nvidia's Vera Rubin chips are in \"full production\"; Nvidia says Rubin can train some LLMs with roughly one-fourth the chips Blackwell needs (Lauren Goode/Wired)",
          "standfirst": "Lauren Goode / Wired: Jensen Huang says Nvidia's Vera Rubin chips are in &ldquo;full production&rdquo;; Nvidia says Rubin can train some LLMs with roughly one-fourth the chips Blackwell needs &mdash; The chip giant says Vera Rubin will sharply cut the cost of training and running AI models, strengthening the appeal of its integrated computing platform.",
          "content": "Lauren Goode / Wired: Jensen Huang says Nvidia's Vera Rubin chips are in &ldquo;full production&rdquo;; Nvidia says Rubin can train some LLMs with roughly one-fourth the chips Blackwell needs &mdash; The chip giant says Vera Rubin will sharply cut the cost of training and running AI models, strengthening the appeal of its integrated computing platform.",
          "feed_position": 1,
          "image_url": "http://www.techmeme.com/260105/i38.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/nvidias-rubin-chips-are-going-into-production/",
          "published_at": "Mon, 05 Jan 2026 23:05:32 +0000",
          "title": "Jensen Huang Says Nvidia’s New Vera Rubin Chips Are in ‘Full Production’",
          "standfirst": "The chip giant says Vera Rubin will sharply cut the cost of training and running AI models, strengthening the appeal of its integrated computing platform.",
          "content": "The chip giant says Vera Rubin will sharply cut the cost of training and running AI models, strengthening the appeal of its integrated computing platform.",
          "feed_position": 0,
          "image_url": "https://media.wired.com/photos/695bffe313835ca4d6b41e4a/master/pass/Nvidia-Rubin-Chips-Going-Into-Production-Business-2192346797.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260105/i38.jpg",
      "popularity_score": 2019.7228316666667
    },
    {
      "id": "cluster_70",
      "coverage": 2,
      "updated_at": "Mon, 05 Jan 2026 15:25:04 -0500",
      "title": "Lego unveils the Smart Play platform, with a brick powered by a custom chip that connects to compatible minifigures and tags for interactive lights and sounds (Jeremy White/Wired)",
      "neutral_headline": "Lego’s Smart Brick Gives the Iconic Analog Toy a New Digital Brain",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260105/p25#a260105p25",
          "published_at": "Mon, 05 Jan 2026 15:25:04 -0500",
          "title": "Lego unveils the Smart Play platform, with a brick powered by a custom chip that connects to compatible minifigures and tags for interactive lights and sounds (Jeremy White/Wired)",
          "standfirst": "Jeremy White / Wired: Lego unveils the Smart Play platform, with a brick powered by a custom chip that connects to compatible minifigures and tags for interactive lights and sounds &mdash; The new sensor-packed Smart Play Brick will land this spring as part of a special Star Wars collection.",
          "content": "Jeremy White / Wired: Lego unveils the Smart Play platform, with a brick powered by a custom chip that connects to compatible minifigures and tags for interactive lights and sounds &mdash; The new sensor-packed Smart Play Brick will land this spring as part of a special Star Wars collection.",
          "feed_position": 14,
          "image_url": "http://www.techmeme.com/260105/i25.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/lego-smart-brick-new-digital-brain/",
          "published_at": "Mon, 05 Jan 2026 19:00:00 +0000",
          "title": "Lego’s Smart Brick Gives the Iconic Analog Toy a New Digital Brain",
          "standfirst": "The new sensor-packed Smart Play Brick will land this spring as part of a special Star Wars collection. The update adds interactive lights and sound to the Lego experience—including the minifigs.",
          "content": "The new sensor-packed Smart Play Brick will land this spring as part of a special Star Wars collection. The update adds interactive lights and sound to the Lego experience—including the minifigs.",
          "feed_position": 3,
          "image_url": "https://media.wired.com/photos/695bc74f1e9a19f18d143eeb/master/pass/SMARTBrick_Hero_16x9.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260105/i25.jpg",
      "popularity_score": 2012.3906094444444
    },
    {
      "id": "cluster_4",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 03:45:49 +0000",
      "title": "Intel launches Core Ultra Series 3 CPUs, made using its long-awaited 18A process",
      "neutral_headline": "Intel launches Core Ultra Series 3 CPUs, made using its long-awaited 18A process",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/gadgets/2026/01/intel-launches-core-ultra-series-3-cpus-made-using-its-long-awaited-18a-process/",
          "published_at": "Tue, 06 Jan 2026 03:45:49 +0000",
          "title": "Intel launches Core Ultra Series 3 CPUs, made using its long-awaited 18A process",
          "standfirst": "New chips launch \"this month,\" targeting high-end ultraportable PCs.",
          "content": "Intel will formally launch its first Core Ultra Series 3 laptop processors later this month, the company announced at its CES keynote today. Codenamed Panther Lake and targeted, at least for now, at high-end ultraportable PCs, the Core Ultra 3 chips will also be the first to use Intel's 18A manufacturing process, the company's effort to catch up with the chip manufacturing technology of Taiwan Semiconductor (TSMC). The launch will start with 14 chips across 5 product families, which Intel says will be used in \"over 200\" PC designs. The first of these will be available on January 27th, with others following \"throughout the first half of this year.\" The Core Ultra X9 and Core Ultra X7 processors include all of Intel's latest CPU and GPU architectures, plus a fully-enabled 12-core Intel Arc B390 integrated GPU and support for slightly faster LPDDR5x-9600. The Core Ultra 9 and 7 processors will use all of the same technologies, but with just four GPU cores and support for either LPDDR5x-8533 or DDR5-7200 DIMMs. But they will offer 20 PCI Express lanes, up from 12 for the X9 and X7, meaning they'll pair better with dedicated GPUs. The Core Ultra 5 chips are mostly lower-end models with fewer CPU cores, and either 4- or 2-core GPUs. But Intel being Intel, there is one oddball that muddies the waters: the Core Ultra 5 338H, which has 12 CPU cores and a 10-core Intel Arc B370 GPU. A Panther Lake refresher The higher-end Core Ultra Series 3 CPUs. Credit: Intel The Core Ultra 5 family encompasses a wide range of possible performance levels. Credit: Intel We wrote about the basic building blocks of Panther Lake when Intel released details late last year. In many ways the chip is a retreat from the Lunar Lake design, sold as Core Ultra 200V, which used chiplets manufactured mostly outside the company and on-package RAM rather than memory in a DIMM slot or soldered to the mainboard. At the time, Intel said these moves were made in the interest of saving power and extending battery life, as were decisions like removing Hyperthreading support from the P-cores.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Intel_CES_-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Intel_CES_-1152x648.jpeg",
      "popularity_score": 367.73644277777777
    },
    {
      "id": "cluster_6",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 03:30:30 +0000",
      "title": "AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops",
      "neutral_headline": "AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/amd-reheats-last-years-ryzen-ai-and-x3d-cpus-for-2026s-laptops-and-desktops/",
          "published_at": "Tue, 06 Jan 2026 03:30:30 +0000",
          "title": "AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops",
          "standfirst": "But it may become slightly cheaper to buy AMD's fastest integrated Radeon GPUs.",
          "content": "Intel, AMD, Nvidia, and other chip companies usually have some kind of news to announce at CES to kick off the year, but some of those announcements are more interesting than others. Sometimes you see new chips with significant speed boosts and other new technologies, and sometimes you get rebranded versions of old silicon meant to fill out a lineup or make an existing architecture seem newer and more exciting than it is. AMD's Ryzen CPU announcements this year fall firmly into the latter camp—these are all gently tweaked variants of chips that launched in 2024 and 2025. \"New,\" for certain values of \"new\" These Ryzen AI 400-series chips are slightly faster than, but otherwise functionally identical to, the Ryzen AI 300 series. Credit: AMD Slightly higher CPU clock speeds, NPU speeds, and supported RAM speeds will separate Ryzen AI 400 from Ryzen AI 300. Credit: AMD Core specs for the new-ish chips. Credit: AMD The corresponding Ryzen Pro chips for business PCs. Credit: AMD Let's start with the Ryzen AI 400 series. Officially the follow-up to the Ryzen AI 300 chips announced in June 2024, these processors offer some modest clock speed improvements and faster memory support. The new Ryzen AI 9 HX 470 has a peak boost clock speed of 5.2 GHz and support for LPDDR5x-8533, for example, up from 5.1 GHz and LPDDR5x-8000 for the Ryzen AI 9 HX 370, and its built-in neural processing unit (NPU) is capable of 60 trillion operations per second (TOPS) rather than 50 TOPS.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Ryzen-AI-400-Series_05-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Ryzen-AI-400-Series_05-1152x648.jpeg",
      "popularity_score": 367.481165
    },
    {
      "id": "cluster_60",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 22:14:50 +0000",
      "title": "NASA’s science budget won’t be a train wreck after all",
      "neutral_headline": "NASA’s science budget won’t be a train wreck after all",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasas-science-budget-wont-be-a-train-wreck-after-all/",
          "published_at": "Mon, 05 Jan 2026 22:14:50 +0000",
          "title": "NASA’s science budget won’t be a train wreck after all",
          "standfirst": "\"There's very little to not like in this.\"",
          "content": "In June, the White House released a budget proposal for fiscal year 2026 that slashed funding for NASA's science programs by nearly 50 percent. Then, in July, the Trump administration began telling the leaders of dozens of space science missions to prepare \"closeout\" plans for their spacecraft. Things looked pretty grim for a while, but then Congress stepped in. Congress, of course, sets the federal government's budget. In many ways, Congress abdicated authority to the Trump administration last year. But not so, it turns out, with federal spending. Throughout the summer and fall, as the White House and Congress wrangled over various issues, lawmakers made it clear they intended to fund most of NASA's science portfolio. Preliminary efforts to shut down active missions were put on hold.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/05/50530415266_a67d907fac_b-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/05/50530415266_a67d907fac_b-1024x648.jpg",
      "popularity_score": 352.2200538888889
    },
    {
      "id": "cluster_63",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 21:42:14 +0000",
      "title": "The nation’s strictest privacy law just took effect, to data brokers’ chagrin",
      "neutral_headline": "The nation’s strictest privacy law just took effect, to data brokers’ chagrin",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/data-broker-hoarding-is-rampant-new-law-lets-consumers-fight-back/",
          "published_at": "Mon, 05 Jan 2026 21:42:14 +0000",
          "title": "The nation’s strictest privacy law just took effect, to data brokers’ chagrin",
          "standfirst": "Californians can now submit demands requiring 500 brokers to delete their data.",
          "content": "Californians are getting a new, supercharged way to stop data brokers from hoarding and selling their personal information, as a recently enacted law that’s among the strictest in the nation took effect at the beginning of the year. According to the California Privacy Protection Agency, more than 500 companies actively scour all sorts of sources for scraps of information about individuals, then package and store it to sell to marketers, private investigators, and others. The nonprofit Consumer Watchdog said in 2024 that brokers trawl automakers, tech companies, junk-food restaurants, device makers, and others for financial info, purchases, family situations, eating, exercising, travel, entertainment habits, and just about any other imaginable information belonging to millions of people.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/04/data-leak-1000x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/04/data-leak-1000x648.jpeg",
      "popularity_score": 331.67672055555556
    },
    {
      "id": "cluster_61",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 21:57:07 +0000",
      "title": "Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule",
      "neutral_headline": "Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/under-anti-vaccine-rfk-jr-cdc-slashes-childhood-vaccine-schedule/",
          "published_at": "Mon, 05 Jan 2026 21:57:07 +0000",
          "title": "Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule",
          "standfirst": "The changes are modeled after a small country with universal health care.",
          "content": "Under anti-vaccine Health Secretary Robert F. Kennedy Jr., federal health officials on Monday announced a sweeping and unprecedented overhaul of federal vaccine recommendations, abruptly paring down recommended immunizations for children from 17 to 11. Officials claimed the rationale for the change was to align US vaccine recommendations more closely with those of other high-income countries, namely Denmark, a small, far less diverse country of around 6 million people (smaller than the population of New York City) that has universal health care. The officials also claim the change is necessary to address the decline in public trust in vaccinations, which has been driven by anti-vaccine activists, including Kennedy. \"This decision protects children, respects families, and rebuilds trust in public health,\" Kennedy said in a statement.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2252087162-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2252087162-1152x648.jpg",
      "popularity_score": 326.9247761111111
    },
    {
      "id": "cluster_67",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 20:38:48 +0000",
      "title": "Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy",
      "neutral_headline": "Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/annas-archive-loses-org-domain-says-suspension-likely-unrelated-to-spotify-piracy/",
          "published_at": "Mon, 05 Jan 2026 20:38:48 +0000",
          "title": "Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy",
          "standfirst": "\"We don't believe this has to do with our Spotify backup,\" Anna's Archive says.",
          "content": "The primary domain of Shadow library Anna's Archive was taken offline, with annas-archive.org being put under the serverHold status. While Anna's Archive recently made waves with a massive \"backup\" of Spotify, the shadow library's operator said the music pirating doesn't appear to be connected to the .org domain suspension. Anna's Archive remains available at several other domains. Anna's Archive launched in 2022 in response to the US Department of Justice seizure of domains used by e-book pirate site Z-Library. Acting as a shadow library and a search engine for other shadow libraries, Anna's Archive aims to archive books and other written materials and make them widely available via torrents. Its data sets have also been heavily used by AI companies to train large language models. In addition to mirroring shadow libraries such as Sci-Hub, Library Genesis, and Z-Library, Anna's Archive made a major move into music pirating two weeks ago with an announcement that it scraped Spotify and made a 300TB copy of the most streamed songs. Despite that development, the person behind Anna's Archive said the domain suspension doesn't seem to be related to the Spotify scraping.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spotify-logos-1152x648-1767642275.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spotify-logos-1152x648-1767642275.jpg",
      "popularity_score": 320.61949833333335
    },
    {
      "id": "cluster_69",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 20:28:06 +0000",
      "title": "Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87",
      "neutral_headline": "Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/stewart-cheifet-pbs-host-who-chronicled-the-pc-revolution-dies-at-87/",
          "published_at": "Mon, 05 Jan 2026 20:28:06 +0000",
          "title": "Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87",
          "standfirst": "Cheifet produced more than 400 episodes of TV tracing the rise of personal computing.",
          "content": "Stewart Cheifet, the television producer and host who documented the personal computer revolution for nearly two decades on PBS, died on December 28, 2025, at age 87 in Philadelphia. Cheifet created and hosted Computer Chronicles, which ran on the public television network from 1983 to 2002 and helped demystify a new tech medium for millions of American viewers. Computer Chronicles covered everything from the earliest IBM PCs and Apple Macintosh models to the rise of the World Wide Web and the dot-com boom. Cheifet conducted interviews with computing industry figures, including Bill Gates, Steve Jobs, and Jeff Bezos, while demonstrating hardware and software for a general audience. From 1983 to 1990, he co-hosted the show with Gary Kildall, the Digital Research founder who created the popular CP/M operating system that predated MS-DOS on early personal computer systems.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cheifet_obit-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cheifet_obit-1152x648.jpg",
      "popularity_score": 301.441165
    },
    {
      "id": "cluster_72",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 20:01:12 +0000",
      "title": "Amazon Alexa+ released to the general public via an early access website",
      "neutral_headline": "Amazon Alexa+ released to the general public via an early access website",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/amazon-alexa-released-to-the-general-public-via-an-early-access-website/",
          "published_at": "Mon, 05 Jan 2026 20:01:12 +0000",
          "title": "Amazon Alexa+ released to the general public via an early access website",
          "standfirst": "Amazon brings back browser-based Alexa but will eventually add a paywall.",
          "content": "Anyone can now try Alexa+, Amazon’s generative AI assistant, through a free early access program at Alexa.com. The website frees the AI, which Amazon released via early access in February, from hardware and makes it as easily accessible as more established chatbots, like OpenAI's ChatGPT and Google's Gemini. Until today, you needed a supporting device to access Alexa+. Amazon hasn’t said when the early access period will end, but when it does, Alexa+ will be included with Amazon Prime memberships, which start at $15 per month, or cost $20 per month on its own. The above pricing suggests that Amazon wants Alexa+ to drive people toward Prime subscriptions. By being interwoven with Amazon’s shopping ecosystem, including Amazon's e-commerce platform, grocery delivery business, and Whole Foods, Alexa+ can make more money for Amazon.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg",
      "popularity_score": 284.9928316666667
    },
    {
      "id": "cluster_75",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 19:32:28 +0000",
      "title": "SanDisk says goodbye to WD Blue and Black SSDs, hello to new “Optimus” drives",
      "neutral_headline": "SanDisk says goodbye to WD Blue and Black SSDs, hello to new “Optimus” drives",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/sandisk-says-goodbye-to-wd-blue-and-black-ssds-hello-to-new-optimus-drives/",
          "published_at": "Mon, 05 Jan 2026 19:32:28 +0000",
          "title": "SanDisk says goodbye to WD Blue and Black SSDs, hello to new “Optimus” drives",
          "standfirst": "Optimus SSDs will continue with the same model numbers that the WD SSDs used.",
          "content": "In late 2023, storage company Western Digital announced plans to split itself into two companies. One, which would still be called Western Digital, would focus on spinning hard drives, which are no longer used much in consumer systems but remain important to NAS devices and data centers. The other, called SanDisk, would handle solid-state storage, including the drives that Western Digital sold to consumers under its Blue, Black, Green, and Red brands. That split effectively undid what Western Digital did a decade ago when it bought SanDisk for $19 billion. And we're just now starting to see the way the split will affect the company's existing consumer drives. Today, SanDisk announced that mainstream WD Blue and WD Black SSDs would be discontinued and replaced by SanDisk Optimus-branded disks with the same model numbers.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/sandisk-optimus-product-family-pr-1152x648-1767638879.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/sandisk-optimus-product-family-pr-1152x648-1767638879.jpeg",
      "popularity_score": 274.5139427777778
    },
    {
      "id": "cluster_84",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 17:51:36 +0000",
      "title": "Google TV’s big Gemini update adds image and video generation, voice control for settings",
      "neutral_headline": "Google TV’s big Gemini update adds image and video...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/01/gemini-expands-on-google-tv-bringing-nano-banana-and-veo-models-to-your-tv/",
          "published_at": "Mon, 05 Jan 2026 17:51:36 +0000",
          "title": "Google TV’s big Gemini update adds image and video generation, voice control for settings",
          "standfirst": "Google TV will let you generate and watch AI content on the big screen.",
          "content": "Soon, even loafing around on the couch won't help you steer clear of AI. TV makers are busily integrating AI models into the experience, and Google is no different. At CES, the company announced a big expansion of Gemini features on the Google TV platform, starting with TCL smart TVs. Google began integrating Gemini with the TV Streamer box this past fall, but the new expansion brings some of the company's most popular AI features to TVs: Nano Banana (image) and Veo (video), which offered a huge leap in visual fidelity at launch and have only improved with subsequent updates. Both models will be part of the TV experience, allowing users to modify or create new content. Google Photos AI remixing in Google TV. Credit: Google The Google TV platform connects to Google Photos, allowing Gemini to access those images with your approval. Gemini can generate a slideshow of your choosing on the spot, but it can also feed those images into Veo or Nano Banana. Using Gemini voice controls, you can remix a photo or turn a still image into a video. You can also enter a solo prompt to generate a totally new image or video with Google's AI on your TV.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/We_previewed_new_Gemini_for_Google_TV-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/We_previewed_new_Gemini_for_Google_TV-1152x648.png",
      "popularity_score": 264.83283166666666
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 19:15:09 +0000",
      "title": "BioWare’s Anthem will soon be completely unplayable",
      "neutral_headline": "BioWare’s Anthem will soon be completely unplayable",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/biowares-anthem-will-soon-be-completely-unplayable/",
          "published_at": "Mon, 05 Jan 2026 19:15:09 +0000",
          "title": "BioWare’s Anthem will soon be completely unplayable",
          "standfirst": "Replay the troubled jetpack shooter before the servers shut down for good on Jan. 12.",
          "content": "We'll admit that we weren't paying enough attention to the state of Anthem—BioWare's troubled 2019 jetpack-powered open-world shooter—to notice EA's July announcement that it was planning to shut down the game's servers. But with that planned server shutdown now just a week away, we thought it was worth alerting you readers to your final opportunity to play one of BioWare's most ambitious failures. Anthem was unveiled at E3 2017 in a demo that was later revealed to have been largely faked to paper over major issues with the game's early development. Anthem’s early 2019 release was met with a lot of middling-to-poor reviews (including one from Ars itself), followed about a year later by a promise from BioWare General Manager Casey Hudson that a \"longer-term redesign\" and \"substantial reinvention\" of the overall game experience were coming. Hudson left BioWare in December 2020, though, and a few months later, that planned Anthem overhaul was officially canceled. While active development on Anthem has been dormant for years, the game's servers have remained up and running. And though the game didn't exactly explode in popularity during that period of benign neglect, estimates from MMO Populations suggest a few hundred to a few thousand players have been jetpacking around the game's world daily. The game also still sees a smattering of daily subreddit posts, including some hoping against hope for a fan-led private server revival, a la the Pretendo Network. And there are still a small handful of Twitch streamers sharing the game while they still can, including one racing to obtain all of the in-game achievements after picking up a $4 copy at Goodwill.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/anthem-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/anthem-1152x648.jpg",
      "popularity_score": 264.22533166666665
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 16:48:07 +0000",
      "title": "Providers dropping common anesthesia drug that’s also a climate super pollutant",
      "neutral_headline": "Providers dropping common anesthesia drug that’s also a climate super pollutant",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/providers-dropping-common-anesthesia-drug-thats-also-a-climate-super-pollutant/",
          "published_at": "Mon, 05 Jan 2026 16:48:07 +0000",
          "title": "Providers dropping common anesthesia drug that’s also a climate super pollutant",
          "standfirst": "The European Union now prohibits desflurane's use during most procedures.",
          "content": "Desflurane is a common anesthetic used in hospital operating rooms worldwide. It’s also a climate super pollutant. Now, several decades after the drug was first introduced, a growing number of US hospitals have stopped using the anesthetic because of its outsized environmental impact. On January 1, the European Union went a step further, prohibiting its use in all but medically necessary cases. Desflurane is more than 7,000 times more effective at warming the planet over a 20-year period than carbon dioxide on a pound-for-pound basis. However, curbing its use alone won’t solve climate change. The anesthetic contributes only a small fraction of total global warming, which is driven by far larger volumes of carbon dioxide and methane emissions. Still, emissions from the drug add up. Approximately 1,000 tons of the gas are vented from hospitals and other health care facilities worldwide each year. The emissions have a near-term climate impact equivalent to the annual greenhouse gas emissions from approximately 1.6 million automobiles.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-596435371-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-596435371-1152x648.jpg",
      "popularity_score": 149.77477611111112
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 17:42:45 +0000",
      "title": "X blames users for Grok-generated CSAM; no fixes announced",
      "neutral_headline": "X blames users for Grok-generated CSAM; no fixes announced",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/x-blames-users-for-grok-generated-csam-no-fixes-announced/",
          "published_at": "Mon, 05 Jan 2026 17:42:45 +0000",
          "title": "X blames users for Grok-generated CSAM; no fixes announced",
          "standfirst": "Critics call for App Store ban after Grok sexualized images of minors.",
          "content": "It seems that instead of updating Grok to prevent outputs of sexualized images of minors, X is planning to purge users generating content that the platform deems illegal, including Grok-generated child sexual abuse material (CSAM). On Saturday, X Safety finally posted an official response after nearly a week of backlash over Grok outputs that sexualized real people without consent. Offering no apology for Grok's functionality, X Safety blamed users for prompting Grok to produce CSAM while reminding them that such prompts can trigger account suspensions and possible legal consequences. \"We take action against illegal content on X, including Child Sexual Abuse Material (CSAM), by removing it, permanently suspending accounts, and working with local governments and law enforcement as necessary,\" X Safety said. \"Anyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content.\"Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2233914159-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2233914159-1024x648.jpg",
      "popularity_score": 142.68533166666666
    },
    {
      "id": "cluster_97",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 15:26:35 +0000",
      "title": "Ars readers gave over $42,000 in our 2025 Charity Drive",
      "neutral_headline": "Ars readers gave over $42,000 in our 2025 Charity Drive",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/ars-readers-gave-over-42000-in-our-2025-charity-drive/",
          "published_at": "Mon, 05 Jan 2026 15:26:35 +0000",
          "title": "Ars readers gave over $42,000 in our 2025 Charity Drive",
          "standfirst": "Ars’ total charity haul since 2007 now tops $585,000.",
          "content": "Last month, we asked readers to donate to a couple of good causes in our 2025 Charity Drive sweepstakes. And boy, did you deliver. With the drive now complete and the donations all tallied, we can report that Ars Technica readers gave an incredible $42,936.83 to Child's Play and the Electronic Frontier Foundation in this year's drive. That doesn't set a new record, but it beats last year's total and raises our lifetime Ars Charity Drive donation haul since 2007 to over $585,000. Well done, Arsians! Thanks to everyone who gave whatever they could. We're still early in the process of selecting and notifying winners of our swag giveaway, so don't fret if you haven't heard if you're a winner yet. In the meantime, enjoy these quick stats from the 2025 drive. 2024 fundraising total: $42,936.83 Total given to Child's Play: $19,424.27 Total given to the EFF: $23,512.56 Number of individual donations: 474 Child's Play donations: 272 EFF donations: 202 Average donation: $90.58 Child's Play average donation: $71.41 EFF average donation: $116.40 Median donation: $50.00 Median Child's Play donation: $26.25 Median EFF donation: $66.95 Top single donation: $3,000 (to EFF) Donations of $1,000 or more: 8 Donations of $100 or more: 133 Donation of $10 or less: 72 (every little bit helps!) Total charity donations from Ars Technica drives since 2007 (approximate): $585,872.01 2025: $42,936.83 2024: $39,047.66 2023: $39,830.36 2022: $31,656.07 2021: $40,261.71 2020: $58,758.11 2019: $33,181.11 2018: $20,210.66 2017: $36,012.37 2016: $38,738.11 2015: $38,861.06 2014: $25,094.31 2013: $23,570.13 2012: $28,713.52 2011: ~$26,000 2010: ~$24,000 2009: ~$17,000 2008: ~$12,000 2007: ~$10,000 Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2017/01/charity.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2017/01/charity.jpg",
      "popularity_score": 140.4158872222222
    },
    {
      "id": "cluster_89",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 17:10:55 +0000",
      "title": "Earliest African cremation was 9,500 years ago",
      "neutral_headline": "Earliest African cremation was 9,500 years ago",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/earliest-african-cremation-was-9500-years-ago/",
          "published_at": "Mon, 05 Jan 2026 17:10:55 +0000",
          "title": "Earliest African cremation was 9,500 years ago",
          "standfirst": "New findings prompt a rethinking of group labor and ritual in ancient hunter-gatherer communities.",
          "content": "Archaeologists have discovered Africa's oldest known cremation pyre at the base of Mount Hora in Malawi. According to a paper published in the journal Science Advances, radiocarbon testing dates the site to about 9,500 years ago, prompting a rethinking of group labor and ritual in such ancient hunter-gatherer communities. Many cultures have practiced some form of cremation. There is a Viking cremation site known as Kalvestene on the small island of Hjarnø in Denmark, for instance. And back in 2023, we reported on an unusual Roman burial site where cremated remains had not been transported to a separate final resting place but remained in place, covered in brick tiles and a layer of lime and surrounded by several dozen bent and twisted nails—possibly an attempt to prevent the deceased from rising from the grave to haunt the living.) But the practice was extremely rare among hunter-gatherer societies, since building a pyre is labor-intensive and requires a great deal of communal resources. There is very little evidence of cremation predating the mid-Holocene (between 5,000 and 7,000 years ago). According to the authors of this latest paper, the earliest known concentration of burnt human remains was found at Lake Mungo in Australia and dates back 40,000 years, but there is no evidence of a pyre, making it challenging to determine specific details.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/hora5-TOP-CROP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/hora5-TOP-CROP-1152x648.jpg",
      "popularity_score": 139.15477611111112
    },
    {
      "id": "cluster_101",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 14:00:47 +0000",
      "title": "Hands off! An on-the-road demo of Mercedes’ advanced new driver assist",
      "neutral_headline": "Hands off. An on-the-road demo of Mercedes’ advanced new driver assist",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/mercedes-teaches-its-driver-assist-how-to-handle-surface-streets/",
          "published_at": "Mon, 05 Jan 2026 14:00:47 +0000",
          "title": "Hands off! An on-the-road demo of Mercedes’ advanced new driver assist",
          "standfirst": "It's like Tesla Autopilot, but made by a company with a culture of safety.",
          "content": "Mercedes-Benz provided flights from Washington to San Francisco and accommodation so Ars could drive the CLA, as well as receive a demonstration of Drive Assist Pro. Ars does not accept paid editorial content. There's some debate as to when adaptive cruise control first showed up, but if you ask Mercedes-Benz, it will say in 1999 with that year's S-Class. Instead of just keeping a set speed, radar-enabled adaptive cruise control allowed the car to react to deceleration by the car ahead, and thus, the first partially automated car was created. From there, automakers added a function to keep cars in their lanes, and now we have location-aware, GPS-geofenced vehicles that, as long as the driver is paying attention, will do most of the driving—on the highway at least. But the goal for developers of both autonomous and partially automated vehicles is to remove as much of the burden of driving from the human as possible, not just on controlled access highways but at lower speeds, on surface streets. Which is what Mercedes' latest Drive Assist Pro has been designed to do. And after a recent demo—albeit from the passenger seat—on the streets of downtown San Francisco, it appears to be a very credible effort. CLA gets it first The big, powerful, comfortable S-Class is normally the standard-bearer for the latest and greatest tech Mercedes has cooked up, but not always. In December, we drove the production version of its new entry-level EV, the CLA. At under $50,000, the sleek Mercedes sedan (or four-door coupé) is already available with the current version of the automaker's Drive Assist suite, with better control of braking and deceleration. A particular improvement, which I'm not sure made the final version of our first drive report, is the way you can use the brake while adaptive cruise control is active without canceling the system.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Mercedes-Benz-drive-pilot-pro-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Mercedes-Benz-drive-pilot-pro-1-1152x648.jpg",
      "popularity_score": 138.98588722222223
    },
    {
      "id": "cluster_106",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 12:00:58 +0000",
      "title": "Our annual power ranking of US rocket companies has changes near the top and bottom",
      "neutral_headline": "Our annual power ranking of US rocket companies has changes near the top and bottom",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/theres-a-big-shake-up-near-the-top-of-our-annual-us-launch-company-rankings/",
          "published_at": "Mon, 05 Jan 2026 12:00:58 +0000",
          "title": "Our annual power ranking of US rocket companies has changes near the top and bottom",
          "standfirst": "There are some fresh faces entering the rankings this year.",
          "content": "Which US rocket companies achieved the most during 2025? Once again, Ars Technica is here to provide some answers in the form of our annual power ranking of US launch companies. We began doing this in 2022 and have since put out a top-10 list every year (see 2023 and 2024). Our intent, as always, is to spark debate, discussion, and appreciation for the challenge of operating a successful rocket company. It's a demanding business, both technically and financially. We respect the grit and hustle because we know just how hard this stuff is. Please also note that this is a subjective list, although hard metrics such as total launches, tonnage to orbit, success rate, and more were all important factors in the decision. And finally, our focus remains on what each company accomplished in 2025, not on what they might do in the future.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/NG-2-Ascent-11-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/NG-2-Ascent-11-1152x648.jpg",
      "popularity_score": 136.98894277777777
    }
  ]
}