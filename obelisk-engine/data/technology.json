{
  "updated_at": "2025-10-31T03:43:39.972Z",
  "clusters": [
    {
      "id": "cluster_6",
      "coverage": 2,
      "updated_at": "Thu, 30 Oct 2025 19:40:01 -0400",
      "title": "OpenAI starts to sell extra credits for Sora, which currently has a limit of 30 free gens per day; 10 video gens will retail for $4 through Apple's App Store (Anna Washenko/Engadget)",
      "neutral_headline": "OpenAI starts to sell extra credits for Sora, which currently has a limit of 30 free gens per day; 10 video gens will retail for $4 through Apple's App Store (Anna Washenko/Engadget): Anna Washenko / Engadget: OpenAI starts to sell extra credits for Sora, which currently has a limit of 30 free gens per day; 10 video gens will retail for $4 through Apple's App Store &mdash; Expect more monetization moves from the company soon. &mdash; OpenAI has started selling power users extra credits for its Sora AI video generation tool",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251030/p56#a251030p56",
          "published_at": "Thu, 30 Oct 2025 19:40:01 -0400",
          "title": "OpenAI starts to sell extra credits for Sora, which currently has a limit of 30 free gens per day; 10 video gens will retail for $4 through Apple's App Store (Anna Washenko/Engadget)",
          "standfirst": "Anna Washenko / Engadget: OpenAI starts to sell extra credits for Sora, which currently has a limit of 30 free gens per day; 10 video gens will retail for $4 through Apple's App Store &mdash; Expect more monetization moves from the company soon. &mdash; OpenAI has started selling power users extra credits for its Sora AI video generation tool.",
          "content": "Anna Washenko / Engadget: OpenAI starts to sell extra credits for Sora, which currently has a limit of 30 free gens per day; 10 video gens will retail for $4 through Apple's App Store &mdash; Expect more monetization moves from the company soon. &mdash; OpenAI has started selling power users extra credits for its Sora AI video generation tool.",
          "feed_position": 5,
          "image_url": "http://www.techmeme.com/251030/i56.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openai-now-sells-extra-sora-credits-for-4-plans-to-reduce-free-gens-in-the-future-223905628.html",
          "published_at": "Thu, 30 Oct 2025 22:39:05 +0000",
          "title": "OpenAI now sells extra Sora credits for $4, plans to reduce free gens in the future",
          "standfirst": "OpenAI has started selling power users extra credits for its Sora AI video generation tool. An extra 10 video gens will retail for $4 through Apple’s App Store. The company currently has a limit of 30 free gens per day, a rate that will likely decrease as OpenAI starts to monetize the offering. Bill Peebles, who heads OpenAI's Sora, posted on X about the changes. \"Eventually we will need to bring the free gens down to accommodate growth (we won't have enough gpus to do it otherwise!), but we’ll be transparent as it happens,\" he said.we are launching the ability to buy extra gens in sora today. we are doing this for two main reasons:first, we have been quite amazed by how much our power users want to use sora, and the economics are currently completely unsustainable. we thought 30 free gens/day would be…— Bill Peebles (@billpeeb) October 30, 2025Peebles also said that OpenAI plans to monetize by letting entities essentially license out their copyrighted material, either their artwork, characters or likenesses. \"We imagine a world where rightsholders have the option to charge extra for cameos of beloved characters and people,\" he wrote. Although making the cameo feature a core part of the monetization while the company is being sued by Cameo for trademark infringement is certainly a bold choice. And that's just the latest in a series of dodgy actions tied to OpenAI's text-to-video AI app.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-now-sells-extra-sora-credits-for-4-plans-to-reduce-free-gens-in-the-future-223905628.html?src=rss",
          "content": "OpenAI has started selling power users extra credits for its Sora AI video generation tool. An extra 10 video gens will retail for $4 through Apple’s App Store. The company currently has a limit of 30 free gens per day, a rate that will likely decrease as OpenAI starts to monetize the offering. Bill Peebles, who heads OpenAI's Sora, posted on X about the changes. \"Eventually we will need to bring the free gens down to accommodate growth (we won't have enough gpus to do it otherwise!), but we’ll be transparent as it happens,\" he said.we are launching the ability to buy extra gens in sora today. we are doing this for two main reasons:first, we have been quite amazed by how much our power users want to use sora, and the economics are currently completely unsustainable. we thought 30 free gens/day would be…— Bill Peebles (@billpeeb) October 30, 2025Peebles also said that OpenAI plans to monetize by letting entities essentially license out their copyrighted material, either their artwork, characters or likenesses. \"We imagine a world where rightsholders have the option to charge extra for cameos of beloved characters and people,\" he wrote. Although making the cameo feature a core part of the monetization while the company is being sued by Cameo for trademark infringement is certainly a bold choice. And that's just the latest in a series of dodgy actions tied to OpenAI's text-to-video AI app.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-now-sells-extra-sora-credits-for-4-plans-to-reduce-free-gens-in-the-future-223905628.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openais-character-cameos-will-let-you-put-pets-and-original-personas-in-sora-videos-123043189.html",
          "published_at": "Thu, 30 Oct 2025 12:30:43 +0000",
          "title": "OpenAI's character cameos will let you put pets and original personas in Sora videos",
          "standfirst": "OpenAI has rolled out the capability to create character cameos of your pets, doodles, original personas or even objects in the Sora app, which you can put in your videos. You can start the process by going to your profile page in the Sora app, tapping on the \"Create cameo\" button and then uploading a video of the character (or pet) you want the model to generate. The company says just a few seconds of footage are enough, and you can even use old Sora-generated videos as reference. You can then give your character a display name and describe how you want the model to animate it. In the example OpenAI uploaded, for instance, the description for a wicked green witch character reads: \"She glides with a mysterious, whimsical grace, speaks in rhymes when casting spells, and her pointed hat always tilts as if listening to secrets on the wind.\" You can choose permissions for each character you create. Under the \"Who can use this\" permissions section, you can choose between several options: Only me, People I approve, Mutuals, Everyone and Everyone (excluding specific sets of users). Whenever you want to generate a Sora video with a cameo in it, you can just tag a specific character. Sora 2 launched with a cameo feature that lets you create an avatar of yourself, but this is a new application of the capability. Cameo, the app that allows users to buy videos from celebrities, just sued OpenAI over trademark violation by using the \"cameo\" name. It said that OpenAI's use of the word is likely to cause consumer confusion and dilute its brand. OpenAI disagreed \"that anyone can claim exclusive ownership over the word 'cameo.'\" In addition to character cameos, OpenAI has introduced \"stitching,\" allowing you to stitch several clips together and connect videos. There's now also a leaderboard that shows the most cameod and most remixed videos. How to create and use character cameos in the Sora app, as demo'd by lil crabby. pic.twitter.com/bLOH6M4Kt7— OpenAI (@OpenAI) October 29, 2025 This article originally appeared on Engadget at https://www.engadget.com/ai/openais-character-cameos-will-let-you-put-pets-and-original-personas-in-sora-videos-123043189.html?src=rss",
          "content": "OpenAI has rolled out the capability to create character cameos of your pets, doodles, original personas or even objects in the Sora app, which you can put in your videos. You can start the process by going to your profile page in the Sora app, tapping on the \"Create cameo\" button and then uploading a video of the character (or pet) you want the model to generate. The company says just a few seconds of footage are enough, and you can even use old Sora-generated videos as reference. You can then give your character a display name and describe how you want the model to animate it. In the example OpenAI uploaded, for instance, the description for a wicked green witch character reads: \"She glides with a mysterious, whimsical grace, speaks in rhymes when casting spells, and her pointed hat always tilts as if listening to secrets on the wind.\" You can choose permissions for each character you create. Under the \"Who can use this\" permissions section, you can choose between several options: Only me, People I approve, Mutuals, Everyone and Everyone (excluding specific sets of users). Whenever you want to generate a Sora video with a cameo in it, you can just tag a specific character. Sora 2 launched with a cameo feature that lets you create an avatar of yourself, but this is a new application of the capability. Cameo, the app that allows users to buy videos from celebrities, just sued OpenAI over trademark violation by using the \"cameo\" name. It said that OpenAI's use of the word is likely to cause consumer confusion and dilute its brand. OpenAI disagreed \"that anyone can claim exclusive ownership over the word 'cameo.'\" In addition to character cameos, OpenAI has introduced \"stitching,\" allowing you to stitch several clips together and connect videos. There's now also a leaderboard that shows the most cameod and most remixed videos. How to create and use character cameos in the Sora app, as demo'd by lil crabby. pic.twitter.com/bLOH6M4Kt7— OpenAI (@OpenAI) October 29, 2025 This article originally appeared on Engadget at https://www.engadget.com/ai/openais-character-cameos-will-let-you-put-pets-and-original-personas-in-sora-videos-123043189.html?src=rss",
          "feed_position": 24
        }
      ],
      "featured_image": "http://www.techmeme.com/251030/i56.jpg",
      "popularity_score": 2015.9391744444445,
      "ai_summary": [
        "OpenAI is selling extra credits for its Sora AI video generation tool.",
        "Users can purchase 10 video generations for $4 through the App Store.",
        "The free generation limit is currently 30 per day, but may decrease.",
        "OpenAI plans to monetize by licensing copyrighted material.",
        "The company is facing a trademark infringement lawsuit from Cameo."
      ]
    },
    {
      "id": "cluster_20",
      "coverage": 2,
      "updated_at": "Thu, 30 Oct 2025 21:07:00 GMT",
      "title": "Meet Aardvark, OpenAI’s security agent for code analysis and patching",
      "neutral_headline": "Meet Aardvark, OpenAI’s security agent for code analysis and patching",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/meet-aardvark-openais-in-house-security-agent-for-code-analysis-and-patching",
          "published_at": "Thu, 30 Oct 2025 21:07:00 GMT",
          "title": "Meet Aardvark, OpenAI’s security agent for code analysis and patching",
          "standfirst": "OpenAI has introduced Aardvark, a GPT-5-powered autonomous security researcher agent now available in private beta.Designed to emulate how human experts identify and resolve software vulnerabilities, Aardvark offers a multi-stage, LLM-driven approach for continuous, 24/7/365 code analysis, exploit validation, and patch generation!Positioned as a scalable defense tool for modern software development environments, Aardvark is being tested across internal and external codebases. OpenAI reports high recall and real-world effectiveness in identifying known and synthetic vulnerabilities, with early deployments surfacing previously undetected security issues.Aardvark comes on the heels of OpenAI’s release of the gpt-oss-safeguard models yesterday, extending the company’s recent emphasis on agentic and policy-aligned systems. Technical Design and OperationAardvark operates as an agentic system that continuously analyzes source code repositories. Unlike conventional tools that rely on fuzzing or software composition analysis, Aardvark leverages LLM reasoning and tool-use capabilities to interpret code behavior and identify vulnerabilities. It simulates a security researcher’s workflow by reading code, conducting semantic analysis, writing and executing test cases, and using diagnostic tools.Its process follows a structured multi-stage pipeline:Threat Modeling – Aardvark initiates its analysis by ingesting an entire code repository to generate a threat model. This model reflects the inferred security objectives and architectural design of the software.Commit-Level Scanning – As code changes are committed, Aardvark compares diffs against the repository’s threat model to detect potential vulnerabilities. It also performs historical scans when a repository is first connected.Validation Sandbox – Detected vulnerabilities are tested in an isolated environment to confirm exploitability. This reduces false positives and enhances report accuracy.Automated Patching – The system integrates with OpenAI Codex to generate patches. These proposed fixes are then reviewed and submitted via pull requests for developer approval.Aardvark integrates with GitHub, Codex, and common development pipelines to provide continuous, non-intrusive security scanning. All insights are intended to be human-auditable, with clear annotations and reproducibility.Performance and ApplicationAccording to OpenAI, Aardvark has been operational for several months on internal codebases and with select alpha partners. In benchmark testing on “golden” repositories—where known and synthetic vulnerabilities were seeded—Aardvark identified 92% of total issues. OpenAI emphasizes that its accuracy and low false positive rate are key differentiators.The agent has also been deployed on open-source projects. To date, it has discovered multiple critical issues, including ten vulnerabilities that were assigned CVE identifiers. OpenAI states that all findings were responsibly disclosed under its recently updated coordinated disclosure policy, which favors collaboration over rigid timelines.In practice, Aardvark has surfaced complex bugs beyond traditional security flaws, including logic errors, incomplete fixes, and privacy risks. This suggests broader utility beyond security-specific contexts.Integration and RequirementsDuring the private beta, Aardvark is only available to organizations using GitHub Cloud (github.com). OpenAI invites beta testers to sign up here online by filling out a web form. Participation requirements include:Integration with GitHub CloudCommitment to interact with Aardvark and provide qualitative feedbackAgreement to beta-specific terms and privacy policiesOpenAI confirmed that code submitted to Aardvark during the beta will not be used to train its models.The company is also offering pro bono vulnerability scanning for selected non-commercial open-source repositories, citing its intent to contribute to the health of the software supply chain.Strategic ContextThe launch of Aardvark signals OpenAI’s broader movement into agentic AI systems with domain-specific capabilities. While OpenAI is best known for its general-purpose models (e.g., GPT-4 and GPT-5), Aardvark is part of a growing trend of specialized AI agents designed to operate semi-autonomously within real-world environments. In fact, it joins two other active OpenAI agents now:ChatGPT agent, unveiled back in July 2025, which controls a virtual computer and web browser and can create and edit common productivity filesCodex — previously the name of OpenAI&#x27;s open source coding model, which it took and re-used as the name of its new GPT-5 variant-powered AI coding agent unveiled back in May 2025But a security-focused agent makes a lot of sense, especially as demands on security teams grow.In 2024 alone, over 40,000 Common Vulnerabilities and Exposures (CVEs) were reported, and OpenAI’s internal data suggests that 1.2% of all code commits introduce bugs. Aardvark’s positioning as a “defender-first” AI aligns with a market need for proactive security tools that integrate tightly with developer workflows rather than operate as post-hoc scanning layers.OpenAI’s coordinated disclosure policy updates further reinforce its commitment to sustainable collaboration with developers and the open-source community, rather than emphasizing adversarial vulnerability reporting.While yesterday&#x27;s release of oss-safeguard uses chain-of-thought reasoning to apply safety policies during inference, Aardvark applies similar LLM reasoning to secure evolving codebases. Together, these tools signal OpenAI’s shift from static tooling toward flexible, continuously adaptive systems — one focused on content moderation, the other on proactive vulnerability detection and automated patching within real-world software development environments.What It Means For Enterprises and the CyberSec Market Going ForwardAardvark represents OpenAI’s entry into automated security research through agentic AI. By combining GPT-5’s language understanding with Codex-driven patching and validation sandboxes, Aardvark offers an integrated solution for modern software teams facing increasing security complexity.While currently in limited beta, the early performance indicators suggest potential for broader adoption. If proven effective at scale, Aardvark could contribute to a shift in how organizations embed security into continuous development environments.For security leaders tasked with managing incident response, threat detection, and day-to-day protections—particularly those operating with limited team capacity—Aardvark may serve as a force multiplier. Its autonomous validation pipeline and human-auditable patch proposals could streamline triage and reduce alert fatigue, enabling smaller security teams to focus on strategic incidents rather than manual scanning and follow-up.AI engineers responsible for integrating models into live products may benefit from Aardvark’s ability to surface bugs that arise from subtle logic flaws or incomplete fixes, particularly in fast-moving development cycles. Because Aardvark monitors commit-level changes and tracks them against threat models, it may help prevent vulnerabilities introduced during rapid iteration, without slowing delivery timelines.For teams orchestrating AI across distributed environments, Aardvark’s sandbox validation and continuous feedback loops could align well with CI/CD-style pipelines for ML systems. Its ability to plug into GitHub workflows positions it as a compatible addition to modern AI operations stacks, especially those aiming to integrate robust security checks into automation pipelines without additional overhead.And for data infrastructure teams maintaining critical pipelines and tooling, Aardvark’s LLM-driven inspection capabilities could offer an added layer of resilience. Vulnerabilities in data orchestration layers often go unnoticed until exploited; Aardvark’s ongoing code review process may surface issues earlier in the development lifecycle, helping data engineers maintain both system integrity and uptime.In practice, Aardvark represents a shift in how security expertise might be operationalized—not just as a defensive perimeter, but as a persistent, context-aware participant in the software lifecycle. Its design suggests a model where defenders are no longer bottlenecked by scale, but augmented by intelligent agents working alongside them.",
          "content": "OpenAI has introduced Aardvark, a GPT-5-powered autonomous security researcher agent now available in private beta.Designed to emulate how human experts identify and resolve software vulnerabilities, Aardvark offers a multi-stage, LLM-driven approach for continuous, 24/7/365 code analysis, exploit validation, and patch generation!Positioned as a scalable defense tool for modern software development environments, Aardvark is being tested across internal and external codebases. OpenAI reports high recall and real-world effectiveness in identifying known and synthetic vulnerabilities, with early deployments surfacing previously undetected security issues.Aardvark comes on the heels of OpenAI’s release of the gpt-oss-safeguard models yesterday, extending the company’s recent emphasis on agentic and policy-aligned systems. Technical Design and OperationAardvark operates as an agentic system that continuously analyzes source code repositories. Unlike conventional tools that rely on fuzzing or software composition analysis, Aardvark leverages LLM reasoning and tool-use capabilities to interpret code behavior and identify vulnerabilities. It simulates a security researcher’s workflow by reading code, conducting semantic analysis, writing and executing test cases, and using diagnostic tools.Its process follows a structured multi-stage pipeline:Threat Modeling – Aardvark initiates its analysis by ingesting an entire code repository to generate a threat model. This model reflects the inferred security objectives and architectural design of the software.Commit-Level Scanning – As code changes are committed, Aardvark compares diffs against the repository’s threat model to detect potential vulnerabilities. It also performs historical scans when a repository is first connected.Validation Sandbox – Detected vulnerabilities are tested in an isolated environment to confirm exploitability. This reduces false positives and enhances report accuracy.Automated Patching – The system integrates with OpenAI Codex to generate patches. These proposed fixes are then reviewed and submitted via pull requests for developer approval.Aardvark integrates with GitHub, Codex, and common development pipelines to provide continuous, non-intrusive security scanning. All insights are intended to be human-auditable, with clear annotations and reproducibility.Performance and ApplicationAccording to OpenAI, Aardvark has been operational for several months on internal codebases and with select alpha partners. In benchmark testing on “golden” repositories—where known and synthetic vulnerabilities were seeded—Aardvark identified 92% of total issues. OpenAI emphasizes that its accuracy and low false positive rate are key differentiators.The agent has also been deployed on open-source projects. To date, it has discovered multiple critical issues, including ten vulnerabilities that were assigned CVE identifiers. OpenAI states that all findings were responsibly disclosed under its recently updated coordinated disclosure policy, which favors collaboration over rigid timelines.In practice, Aardvark has surfaced complex bugs beyond traditional security flaws, including logic errors, incomplete fixes, and privacy risks. This suggests broader utility beyond security-specific contexts.Integration and RequirementsDuring the private beta, Aardvark is only available to organizations using GitHub Cloud (github.com). OpenAI invites beta testers to sign up here online by filling out a web form. Participation requirements include:Integration with GitHub CloudCommitment to interact with Aardvark and provide qualitative feedbackAgreement to beta-specific terms and privacy policiesOpenAI confirmed that code submitted to Aardvark during the beta will not be used to train its models.The company is also offering pro bono vulnerability scanning for selected non-commercial open-source repositories, citing its intent to contribute to the health of the software supply chain.Strategic ContextThe launch of Aardvark signals OpenAI’s broader movement into agentic AI systems with domain-specific capabilities. While OpenAI is best known for its general-purpose models (e.g., GPT-4 and GPT-5), Aardvark is part of a growing trend of specialized AI agents designed to operate semi-autonomously within real-world environments. In fact, it joins two other active OpenAI agents now:ChatGPT agent, unveiled back in July 2025, which controls a virtual computer and web browser and can create and edit common productivity filesCodex — previously the name of OpenAI&#x27;s open source coding model, which it took and re-used as the name of its new GPT-5 variant-powered AI coding agent unveiled back in May 2025But a security-focused agent makes a lot of sense, especially as demands on security teams grow.In 2024 alone, over 40,000 Common Vulnerabilities and Exposures (CVEs) were reported, and OpenAI’s internal data suggests that 1.2% of all code commits introduce bugs. Aardvark’s positioning as a “defender-first” AI aligns with a market need for proactive security tools that integrate tightly with developer workflows rather than operate as post-hoc scanning layers.OpenAI’s coordinated disclosure policy updates further reinforce its commitment to sustainable collaboration with developers and the open-source community, rather than emphasizing adversarial vulnerability reporting.While yesterday&#x27;s release of oss-safeguard uses chain-of-thought reasoning to apply safety policies during inference, Aardvark applies similar LLM reasoning to secure evolving codebases. Together, these tools signal OpenAI’s shift from static tooling toward flexible, continuously adaptive systems — one focused on content moderation, the other on proactive vulnerability detection and automated patching within real-world software development environments.What It Means For Enterprises and the CyberSec Market Going ForwardAardvark represents OpenAI’s entry into automated security research through agentic AI. By combining GPT-5’s language understanding with Codex-driven patching and validation sandboxes, Aardvark offers an integrated solution for modern software teams facing increasing security complexity.While currently in limited beta, the early performance indicators suggest potential for broader adoption. If proven effective at scale, Aardvark could contribute to a shift in how organizations embed security into continuous development environments.For security leaders tasked with managing incident response, threat detection, and day-to-day protections—particularly those operating with limited team capacity—Aardvark may serve as a force multiplier. Its autonomous validation pipeline and human-auditable patch proposals could streamline triage and reduce alert fatigue, enabling smaller security teams to focus on strategic incidents rather than manual scanning and follow-up.AI engineers responsible for integrating models into live products may benefit from Aardvark’s ability to surface bugs that arise from subtle logic flaws or incomplete fixes, particularly in fast-moving development cycles. Because Aardvark monitors commit-level changes and tracks them against threat models, it may help prevent vulnerabilities introduced during rapid iteration, without slowing delivery timelines.For teams orchestrating AI across distributed environments, Aardvark’s sandbox validation and continuous feedback loops could align well with CI/CD-style pipelines for ML systems. Its ability to plug into GitHub workflows positions it as a compatible addition to modern AI operations stacks, especially those aiming to integrate robust security checks into automation pipelines without additional overhead.And for data infrastructure teams maintaining critical pipelines and tooling, Aardvark’s LLM-driven inspection capabilities could offer an added layer of resilience. Vulnerabilities in data orchestration layers often go unnoticed until exploited; Aardvark’s ongoing code review process may surface issues earlier in the development lifecycle, helping data engineers maintain both system integrity and uptime.In practice, Aardvark represents a shift in how security expertise might be operationalized—not just as a defensive perimeter, but as a persistent, context-aware participant in the software lifecycle. Its design suggests a model where defenders are no longer bottlenecked by scale, but augmented by intelligent agents working alongside them.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/bwRyL7w9MR1MG2IrgGTzg/9ecc1886c047d9f1eb5335e80e67fc14/ChatGPT_Image_Oct_30__2025__05_01_04_PM.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/oakley-meta-vanguard-review-sporty-to-a-fault-183000829.html",
          "published_at": "Thu, 30 Oct 2025 18:30:00 +0000",
          "title": "Oakley Meta Vanguard review: Sporty to a fault",
          "standfirst": "By now, I have a well-established routine when I set up a new pair of Meta smart glasses. I connect my Instagram, WhatsApp and Spotify accounts. I complete the slightly convoluted steps in my Bluetooth settings to make sure Meta AI can announce incoming phone calls and text messages. I tweak the video settings to the highest quality available, and change the voice of Meta AI to \"English (UK)\" so it can talk to me in the voice of Judi Dench. But with the $499 Oakley Meta Vanguard glasses, there's also a new step: deciding what the customizable \"action button\" should do. The action button isn't even my favorite part of using the glasses, but it's a sign of just how different these shades are from the rest of Meta's lineup. While the second-gen Ray-Ban and Oakley HSTN glasses iterated on the same formula Meta has used for the last few years, the Vanguard glasses are refreshingly different. They aren't really meant to be everyday sunglasses (unless you're really committed to your athletic pursuits) but they are in many ways more capable than Meta's other smart glasses. The speakers are louder, the camera has new abilities and they integrate directly with Strava and Garmin. And while these won't replace my go-to sunglasses, there's more than enough to make them part of my fitness routine. New look, new setup The sunglasses were very clearly made with athletes in mind. The Oakley Meta Vanguard glasses are the type of shades a lot of people probably think of when they hear \"Oakley sunglasses.\" The wraparound frames with colorful, reflective lenses are the style of glasses you might associate with a high school track coach, or your neighbor who is really serious about cycling. The pair I tested had black frames and Oakley's orange \"Prizm 24K\" lenses, which aren't polarized but are favored by a lot of athletes for their ability to dial up the contrast of your surroundings. I was able to comfortably wear my pair in bright, sunny conditions and also in more overcast lower light. I also appreciate that the lenses are swappable, so you can switch them out for a dedicated low-light or different-colored lens depending on your conditions. (Extra lenses cost $85 each and will be available to purchase separately soon, according to Meta.) These glasses don't, however, support prescription lenses of any kind. I wouldn't wear these as everyday sunglasses, but I don't mind the look for a trail run. Karissa Bell for Engadget I realize this style of sunglasses won't be appealing to everyone, but the frame shape does enable a slightly different setup than what we've seen with any of Meta's other smart glasses. Most noticeably, the camera is in the center of the glasses, just above the nosebridge. The LED that lights up when the camera is on is also in the center, near the top of the frames. As with Meta's other smart glasses, you can control volume and music playback via a touchpad on the right side of the glasses, but the capture button to take photos and videos is now on the underside of the glasses rather than on top. This is meant to make it a bit easier to reach if you're wearing a hat or helmet, though I found it took me a few tries to get used to the new placement. Behind the capture button is the previously mentioned \"action button,\" which can be customized to trigger specific functions via the Meta AI app. The capture button (left) and the action button (right) are both on the underside of the frames rather than on top. Karissa Bell for Engadget I haven't yet figured out what the best use for the action button is, though I've tried out a few different setups. On one hike, I set it up to automatically call my husband, kind of like a speed dial. During a bike ride, I had it set to record a hyperlapse video. I've also tried it out as a shortcut for launching a specific Spotify playlist or as a general trigger for Meta AI. With all of these, I appreciated that the action button allowed me to do something without saying the \"Hey Meta,\" command. Repeating \"hey Meta\" to my glasses in public has always felt a bit cringey, so it was nice to have a much more subtle cue available. Did I mention it's for athletes? The Vanguard's athlete-focused features go beyond the sportier frames. The shades come with new integrations for two of the most popular run and bike-tracking platforms: Garmin and Strava. If you have a supported Garmin watch or bike computer, you can set up the glasses to automatically capture video clips based on metrics from your activity, like hitting a particular heart rate zone or other milestone. You can also ask Meta AI directly to tell you about stats from your Garmin watch, like \"hey Meta, what's my pace.\" I don't have a Garmin watch, though I did briefly test out some of these features during my hands-on at Meta Connect. I suspect a lot of runners and cyclists may still find it easier to simply glance at their watch to see stats, but having it all available via voice commands doesn't seem like a bad thing either. Strava's integration isn't quite as deep. If you're tracking a run, hike or ride while wearing the glasses, you can overlay your stats directly onto photos and videos from your activity. This includes metrics like distance and elevation, as well as heart rate if you're also wearing an Apple Watch or other tracker that's connected to the Strava app. Here's what it looks like with a photo from a recent bike ride. You can overlay your Strava stats onto the photos and videos you record. Karissa Bell for Engadget I typically don’t share stats from runs or bike rides (usually because they aren't that impressive) but it's a bit more appealing that just sharing a straight Strava screenshot. Another neat feature is that if you share a video, you can watch the stats change in real time alongside your recording. That level of detail isn't particularly interesting for a mostly flat bike ride on a city street, but I can see how it would be a lot more compelling on a more technical trail ride or in a race. My only complaint, really, is that Meta has limited these kinds of features to Garmin and Strava's platforms so far. I'd love to have support for my favorite ski-tracking app, Slopes, and I'm sure there are plenty of people who'd be happy to have an integration with their running or workout-tracking app of choice. Meta has announced some plans to bring more third-party apps onto its smart glasses platform so there might be hope here. There are other improvements, though, that will be appealing to even casual athletes. The speakers are a lot louder to account for potentially noisy conditions like a congested roadway or high-wind environment. I never had to crank the volume up anywhere near the max during my bike rides or runs, but I can say the speakers were loud and clear enough that I was able to comfortably listen to a podcast with the glasses laying next to me on the couch at full volume. The new centered camera placement is meant to make it harder for a hat or helmet to interfere with your shots, which has been a consistent issue for me with Meta's other smart glasses. The new position didn't totally solve this — I still found that my bike helmet made it into the top of my pics — but at least it's easier to crop out now that my headgear is centered over the top of my image rather than awkwardly sticking out on one side. The 12MP ultra-wide camera also comes with new video stabilization settings that make it feel a bit more like a replacement for an action cam. The glasses are set to automatically select a level of stabilization based on your motion, but you can also manually choose between low, medium or high stabilization (stabilization is locked at \"medium\" if you opt to record in 3K). I've mostly left it with the default settings and have been impressed with the results. The LED light is also a bit more subtle than on Meta's other smart glasses. Karissa Bell for Engadget The Vanguard glasses are also Meta's first smart glasses that can record hyperlapse and slow-motion video. Hyperlapse should be familiar to Instagram users who used the now-defunct app of the same name to record timelapse clips. Now, you can say \"Hey Meta, start a hyperlapse\" and the glasses will record a similar sped-up clip. My hyperlapse clips ended up looking a bit jittery, though, compared to the timelapse shots I'm used to getting with my GoPro. And unfortunately, there's no way to adjust the cadence of the video like you used to be able to with the dedicated app. My slow-motion clips, on the other hand, came out better. It's not something I'd expect to use very often during a bike ride or trail run, but the POV angle is great for recording clips of pets or kids. Meta is also planning to bring support for hyperlapse and slow-motion videos to the rest of its glasses lineup, though, so you don't need to get these particular shades to take advantage of the feature. The other major improvement is battery life. The Vanguard glasses have a notably better battery life compared with the second-gen Ray-Ban glasses or the HSTN frames (probably because the bigger frames allow for a larger battery). According to Meta, the Vanguard glasses can go nine hours on a charge with \"typical use\" or six hours with continuous audio playback. I was actually able to get a little over six hours of audio on a single charge, so they should hold up pretty well if you're running marathons or competing in longer races. As usual, exact battery life can vary a lot depending on how much you're using more resource-intensive features like video recording or Meta AI. The bigger frames and charging case give the glasses a battery life boost. Karissa Bell for Engadget I'm especially looking forward to seeing how these glasses will hold up during a day of snowboarding. Meta previously told me that the battery has been optimized for a wider spectrum of temperatures so hopefully the battery won't drain as quickly on the mountain as Meta's other glasses. And with increased water resistance — the shades have an IP67 rating — I wouldn't worry about dropping them in the snow. Should you buy these? While Meta and EssilorLuxottica have gotten very good at making smart glasses (sorry Mark Zuckerberg, I won't call them \"AI glasses,\") they are still somewhat of a niche product. And the ultra-sporty Oakley Vanguard glasses are even more niche. At $499, these are also more expensive than other models. That, understandably, may feel too steep for a pair of sunglasses you're likely only going to wear during specific activities. But if you're a dedicated cyclist, runner, hiker or [insert outdoor activity of your choice], there's a lot to like. The camera makes a lot more sense for action cam-like POV footage, and better video stabilization means you're more likely to get shots you actually want to share. Ready-made Garmin and Strava integrations are practically begging for you to brag about your latest PR or race time, which will certainly appeal to many. This article originally appeared on Engadget at https://www.engadget.com/wearables/oakley-meta-vanguard-review-sporty-to-a-fault-183000829.html?src=rss",
          "content": "By now, I have a well-established routine when I set up a new pair of Meta smart glasses. I connect my Instagram, WhatsApp and Spotify accounts. I complete the slightly convoluted steps in my Bluetooth settings to make sure Meta AI can announce incoming phone calls and text messages. I tweak the video settings to the highest quality available, and change the voice of Meta AI to \"English (UK)\" so it can talk to me in the voice of Judi Dench. But with the $499 Oakley Meta Vanguard glasses, there's also a new step: deciding what the customizable \"action button\" should do. The action button isn't even my favorite part of using the glasses, but it's a sign of just how different these shades are from the rest of Meta's lineup. While the second-gen Ray-Ban and Oakley HSTN glasses iterated on the same formula Meta has used for the last few years, the Vanguard glasses are refreshingly different. They aren't really meant to be everyday sunglasses (unless you're really committed to your athletic pursuits) but they are in many ways more capable than Meta's other smart glasses. The speakers are louder, the camera has new abilities and they integrate directly with Strava and Garmin. And while these won't replace my go-to sunglasses, there's more than enough to make them part of my fitness routine. New look, new setup The sunglasses were very clearly made with athletes in mind. The Oakley Meta Vanguard glasses are the type of shades a lot of people probably think of when they hear \"Oakley sunglasses.\" The wraparound frames with colorful, reflective lenses are the style of glasses you might associate with a high school track coach, or your neighbor who is really serious about cycling. The pair I tested had black frames and Oakley's orange \"Prizm 24K\" lenses, which aren't polarized but are favored by a lot of athletes for their ability to dial up the contrast of your surroundings. I was able to comfortably wear my pair in bright, sunny conditions and also in more overcast lower light. I also appreciate that the lenses are swappable, so you can switch them out for a dedicated low-light or different-colored lens depending on your conditions. (Extra lenses cost $85 each and will be available to purchase separately soon, according to Meta.) These glasses don't, however, support prescription lenses of any kind. I wouldn't wear these as everyday sunglasses, but I don't mind the look for a trail run. Karissa Bell for Engadget I realize this style of sunglasses won't be appealing to everyone, but the frame shape does enable a slightly different setup than what we've seen with any of Meta's other smart glasses. Most noticeably, the camera is in the center of the glasses, just above the nosebridge. The LED that lights up when the camera is on is also in the center, near the top of the frames. As with Meta's other smart glasses, you can control volume and music playback via a touchpad on the right side of the glasses, but the capture button to take photos and videos is now on the underside of the glasses rather than on top. This is meant to make it a bit easier to reach if you're wearing a hat or helmet, though I found it took me a few tries to get used to the new placement. Behind the capture button is the previously mentioned \"action button,\" which can be customized to trigger specific functions via the Meta AI app. The capture button (left) and the action button (right) are both on the underside of the frames rather than on top. Karissa Bell for Engadget I haven't yet figured out what the best use for the action button is, though I've tried out a few different setups. On one hike, I set it up to automatically call my husband, kind of like a speed dial. During a bike ride, I had it set to record a hyperlapse video. I've also tried it out as a shortcut for launching a specific Spotify playlist or as a general trigger for Meta AI. With all of these, I appreciated that the action button allowed me to do something without saying the \"Hey Meta,\" command. Repeating \"hey Meta\" to my glasses in public has always felt a bit cringey, so it was nice to have a much more subtle cue available. Did I mention it's for athletes? The Vanguard's athlete-focused features go beyond the sportier frames. The shades come with new integrations for two of the most popular run and bike-tracking platforms: Garmin and Strava. If you have a supported Garmin watch or bike computer, you can set up the glasses to automatically capture video clips based on metrics from your activity, like hitting a particular heart rate zone or other milestone. You can also ask Meta AI directly to tell you about stats from your Garmin watch, like \"hey Meta, what's my pace.\" I don't have a Garmin watch, though I did briefly test out some of these features during my hands-on at Meta Connect. I suspect a lot of runners and cyclists may still find it easier to simply glance at their watch to see stats, but having it all available via voice commands doesn't seem like a bad thing either. Strava's integration isn't quite as deep. If you're tracking a run, hike or ride while wearing the glasses, you can overlay your stats directly onto photos and videos from your activity. This includes metrics like distance and elevation, as well as heart rate if you're also wearing an Apple Watch or other tracker that's connected to the Strava app. Here's what it looks like with a photo from a recent bike ride. You can overlay your Strava stats onto the photos and videos you record. Karissa Bell for Engadget I typically don’t share stats from runs or bike rides (usually because they aren't that impressive) but it's a bit more appealing that just sharing a straight Strava screenshot. Another neat feature is that if you share a video, you can watch the stats change in real time alongside your recording. That level of detail isn't particularly interesting for a mostly flat bike ride on a city street, but I can see how it would be a lot more compelling on a more technical trail ride or in a race. My only complaint, really, is that Meta has limited these kinds of features to Garmin and Strava's platforms so far. I'd love to have support for my favorite ski-tracking app, Slopes, and I'm sure there are plenty of people who'd be happy to have an integration with their running or workout-tracking app of choice. Meta has announced some plans to bring more third-party apps onto its smart glasses platform so there might be hope here. There are other improvements, though, that will be appealing to even casual athletes. The speakers are a lot louder to account for potentially noisy conditions like a congested roadway or high-wind environment. I never had to crank the volume up anywhere near the max during my bike rides or runs, but I can say the speakers were loud and clear enough that I was able to comfortably listen to a podcast with the glasses laying next to me on the couch at full volume. The new centered camera placement is meant to make it harder for a hat or helmet to interfere with your shots, which has been a consistent issue for me with Meta's other smart glasses. The new position didn't totally solve this — I still found that my bike helmet made it into the top of my pics — but at least it's easier to crop out now that my headgear is centered over the top of my image rather than awkwardly sticking out on one side. The 12MP ultra-wide camera also comes with new video stabilization settings that make it feel a bit more like a replacement for an action cam. The glasses are set to automatically select a level of stabilization based on your motion, but you can also manually choose between low, medium or high stabilization (stabilization is locked at \"medium\" if you opt to record in 3K). I've mostly left it with the default settings and have been impressed with the results. The LED light is also a bit more subtle than on Meta's other smart glasses. Karissa Bell for Engadget The Vanguard glasses are also Meta's first smart glasses that can record hyperlapse and slow-motion video. Hyperlapse should be familiar to Instagram users who used the now-defunct app of the same name to record timelapse clips. Now, you can say \"Hey Meta, start a hyperlapse\" and the glasses will record a similar sped-up clip. My hyperlapse clips ended up looking a bit jittery, though, compared to the timelapse shots I'm used to getting with my GoPro. And unfortunately, there's no way to adjust the cadence of the video like you used to be able to with the dedicated app. My slow-motion clips, on the other hand, came out better. It's not something I'd expect to use very often during a bike ride or trail run, but the POV angle is great for recording clips of pets or kids. Meta is also planning to bring support for hyperlapse and slow-motion videos to the rest of its glasses lineup, though, so you don't need to get these particular shades to take advantage of the feature. The other major improvement is battery life. The Vanguard glasses have a notably better battery life compared with the second-gen Ray-Ban glasses or the HSTN frames (probably because the bigger frames allow for a larger battery). According to Meta, the Vanguard glasses can go nine hours on a charge with \"typical use\" or six hours with continuous audio playback. I was actually able to get a little over six hours of audio on a single charge, so they should hold up pretty well if you're running marathons or competing in longer races. As usual, exact battery life can vary a lot depending on how much you're using more resource-intensive features like video recording or Meta AI. The bigger frames and charging case give the glasses a battery life boost. Karissa Bell for Engadget I'm especially looking forward to seeing how these glasses will hold up during a day of snowboarding. Meta previously told me that the battery has been optimized for a wider spectrum of temperatures so hopefully the battery won't drain as quickly on the mountain as Meta's other glasses. And with increased water resistance — the shades have an IP67 rating — I wouldn't worry about dropping them in the snow. Should you buy these? While Meta and EssilorLuxottica have gotten very good at making smart glasses (sorry Mark Zuckerberg, I won't call them \"AI glasses,\") they are still somewhat of a niche product. And the ultra-sporty Oakley Vanguard glasses are even more niche. At $499, these are also more expensive than other models. That, understandably, may feel too steep for a pair of sunglasses you're likely only going to wear during specific activities. But if you're a dedicated cyclist, runner, hiker or [insert outdoor activity of your choice], there's a lot to like. The camera makes a lot more sense for action cam-like POV footage, and better video stabilization means you're more likely to get shots you actually want to share. Ready-made Garmin and Strava integrations are practically begging for you to brag about your latest PR or race time, which will certainly appeal to many. This article originally appeared on Engadget at https://www.engadget.com/wearables/oakley-meta-vanguard-review-sporty-to-a-fault-183000829.html?src=rss",
          "feed_position": 4,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/kb_vanguard.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/fractal-design-scape-review-a-stellar-debut-173000007.html",
          "published_at": "Thu, 30 Oct 2025 17:30:00 +0000",
          "title": "Fractal Design Scape review: A stellar debut",
          "standfirst": "Unless you're a PC nerd like me, chances are you're not familiar with Fractal Design. The company has made a name for itself in recent years by designing some of the best cases you can buy for a DIY build. In a space known for its gaudy aesthetics, Fractal's products stand out for their simplicity. Now the company is entering the crowded audio space with the $200 Scape, a gaming headset that not only looks sophisticated, but also sounds surprisingly great too. Design The Fractal Scape features an attractive mix of materials. Igor Bonifacic for Engadget I mentioned the design of the Scape first, and for good reason. It shows attention to detail, with a lot of thoughtful flourishes. The best of those is the dock that comes included with the headset. It charges the Scape inductively, so there's no need to align any charging pins, and it cleverly houses the headset's 2.4GHz wireless transmitter. When connected to your main PC, the dongle can sit inside the dock, ready to go when you want to use it with your PlayStation 5, PS4, Nintendo Switch or another PC or Mac (sorry, Microsoft fans, there's no Xbox support). The base also has wire channels to make cable management easy. Those same thoughtful design touches extend to the headset itself. On the back are four buttons, a dial and a toggle that cover nearly every function of the Scape. You can adjust the volume, mute the built-in mic, switch between 2.4GHz and Bluetooth connectivity, power the headset on or off, turn the RGB lighting on or off and switch between three EQ presets. What’s more, all of the controls feel distinct and are easy to use. There's also a USB-C connection for wired audio and a three-pole headphone jack for the detachable microphone. The headset is primarily made of plastic, with a touch of brushed metal. Fractal offers the Scape in two colors — the aptly named light and dark — and despite the company's choice of materials, the headset feels undoubtedly premium. Tilt adjustment is limited — it's not possible to lay the ear pads flat on a table, for example — but the headband offers a fair amount of resistance, adding to the high-end feel. That said, the Scape could be more comfortable. Clamping force feels just about right, but there's not enough padding along the top of the headband. I found I could wear the headphones for a few hours, but I eventually had to take them off to relieve the pressure that had built up on the top of my head. I'm also not a fan of the fabric Fractal used for both the headband and ear pads. It feels scratchy and it's not great at dissipating heat. Thankfully, the high-density memory foam beneath is plush and the pads were deep and wide enough to comfortably accommodate my ears. Fractal has made it easy to swap the ear pads if needed; they come right off with just a small amount of force. For the time being, the company isn't selling replacements, but a spokesperson told me Fractal will send customers who need new pads a set for free. You just need to contact their support team. Sound quality The Scape comes with a set of custom-tuned drivers. Igor Bonifacic for Engadget Out of the box, the Scape's dynamic drivers are tuned to a soft v-shaped curve, with an emphasis on accuracy over character. Bass frequencies are punchy without being bloated, and there's nice detail to mid-focused instruments like guitars. To my ear, the one issue with the Scape's default tuning were the upper mids and treble frequencies. They weren't shouty to the point of being sibilant, but there was definitely a harshness to the vocals of singers like Jeff Buckley and Caroline Polachek who are known for their falsetto. Thankfully, this was easy to fix with the Scape's built-in EQ settings. I'll have more to say in the software section of this review, but Fractal's Adjust app allows you to make parametric EQ adjustments. This is different to most gaming headsets, which often limit people to restrictive fixed-band tweaks. Even when I used just five potential points of customization, I found I had a great deal of control over the tonality of the Scape. Overall, for casual music listening these are excellent headphones capable of covering many different genres. When it comes to gaming, they're great too — with some caveats. For singleplayer games, the default tunings are an excellent match. Playing Ghost of Tsushima, the Scape did a great job of reproducing the game's immersive sound design, allowing me to soak in all the little audio details Sucker Punch packed into its rendition of 13th century Japan. The soundstaging isn't as expansive and lush as I'm used to with my Sennheiser HD 600, but for a pair of closed-back headphones, it's above average. When it comes to competitive first-person shooters, some tweaks are required. I found all the default presets produced too much bass to easily isolate sound cues in games like Valorant. Again, Fractal's software made this simple to fix; however, the Scape can only store three presets. Some gaming headsets, particularly those from Steelseries, come with tunings for hundreds of different games. For the ultra-competitive gamer, this can be useful since every game has a different sound engine. I'm not one of those people, so I found the Scape had just the right amount of customization. A closeup of the Scape's volume dial. Igor Bonifacic for Engadget One feature you won't find on these headphones is active noise cancellation (ANC). Don't get me wrong, ANC is great, but I also didn't feel like the Scape was a worse product without it. My girlfriend is a Pelton fanatic and she does all of her daily classes without wearing headphones in our small apartment. In that situation, the Scape's passive noise isolation was enough to block the loud music coming from those workouts. That said, the one area where the Scape could have been better is Bluetooth connectivity. It's a 5.3 headset, but codec support is limited to SBC and AAC. If you've ever tried a pair of wireless headphones only to be disappointed by how they sounded, SBC was probably to blame. When I used the Scape over Bluetooth, there was a subtle difference, but in a beat 'em up like Absolum, the game's excellent sound design was less effective because it sounded more compressed, with more lag between what was happening on-screen and the effects that followed. I would have liked to see Fractal support more modern codecs like aptX Adaptive, but given that you need a dongle like the Creative BT-W6 to get access to those protocols on PCs and consoles, I can't fault the company for its decision. Also missing from the Bluetooth equation is multipoint support, meaning I wasn't able to connect the Scape to my PC or Switch and my iPhone at the same time. The Scape's detachable microphone is fine but uninspiring. In listening back to a chat I had with some friends over Discord, I found the Scape compressed my voice to the point where there wasn't a lot of life or nuance to it. The optional noise cancellation algorithm does a good job of filtering out nearby commotion, but does so at the expense of adding more compression. You can flip the microphone to mute yourself, and if you're feeling lazy, the Scape also has a built-in mic — though it sounds about as good as you might imagine. Still, it's handy in a pinch. Software Fractal's Adjust app is web-based and easy to use. Igor Bonifacic for Engadget I mentioned Fractal's Adjust software, but what I didn't note is that it's not an app you need to install on your computer. Instead, it's a website you can access through any Chrome-based browser. It's a small thing, but one I really appreciate. I can't count how many times I've had to troubleshoot issues with Windows that were caused by a conflict created by Logitech G Hub or NZXT Cam. The web-based software itself is simple, with two pages, named Lighting and Audio, encompassing all the options you can tweak. The Scape comes with 10 lighting themes out of the box, and like the headset itself, these presets are understated and classy. Naturally, you can also create your own lighting schemes, and the tool for doing so is fairly robust. A closeup of the Fractal Scape's EQ button Igor Bonifacic for Engadget When it comes to the EQ adjustments you can make with the Adjust app, the one thing I'll add here is any presets you save are stored on the Scape, so they're available everywhere you want to use the headset. That was great because it meant I didn't need to Alt-Tab out of a game to switch the headset to a more competitive tuning. The one area where Fractal's software feels lacking is when it comes to microphone controls. It's possible to adjust sidetone (the volume of your mic input as heard through the headset) and enable microphone noise cancellation, but that’s it. It'd be nice if it was possible to configure those settings for the two mics independently of one another, but the software doesn't support that right now. Battery life According to Fractal, the Scape can go up to 40 hours on a single charge with RGB lighting off. With the feature turned on, battery life drops to about 26 hours. I'll be honest, I had a tough time putting those claims to the test because of how easy it is to charge the headset. As best as I can tell, those estimates are accurate. I managed to get three days of battery life from the Scape with the RGB lights turned on and about eight hours of use each day. One nice touch: when you tap the power button, the RGB lights will briefly illuminate to indicate how much battery life the Scape has left. Those same lights will turn off when you place the headset to charge so that they're not distracting. The competition With the Scape, Fractal has entered a crowded market. That said, the Scape is competitive with some of the best gaming headsets you can buy right now. At $200, it's $100 cheaper than the Audeze Maxwell, Engadget's pick for the best premium gaming headset. The Scape doesn't sound as good as the Maxwell or offer LDAC support for Bluetooth connectivity, but it's lighter and charging is easier thanks to the included charging base. If you ask me, the Scape also looks a lot better too. If you can't live without ANC, your best bet is Razer's BlackShark V3 Pro, but it costs $50 more and doesn't sound as good as the Scape. You also need to put up with Razer's annoying Synapse software. For the best mic on a gaming headset, my longstanding recommendation has been the $199 Drop PC38X. It also has one of the best default tunings for competitive gaming. However, it's a wired headset, and Drop doesn’t offer a wireless option. Wrap-up The charging station also houses the Scape's 2.4GHz transmitter. Igor Bonifacic for Engadget If you can't tell by now, I think the Fractal Scape is a great gaming headset. There are models like the Audeze Maxwell that beat it in one or two categories, but for $200 the Scape is an excellent all-around package. Nitpicks about comfort aside, the Scape sounds and looks great. It's also a tremendous first effort by Fractal, and I can't wait to see what the company does next in the audio space and beyond. This article originally appeared on Engadget at https://www.engadget.com/gaming/fractal-design-scape-review-a-stellar-debut-173000007.html?src=rss",
          "content": "Unless you're a PC nerd like me, chances are you're not familiar with Fractal Design. The company has made a name for itself in recent years by designing some of the best cases you can buy for a DIY build. In a space known for its gaudy aesthetics, Fractal's products stand out for their simplicity. Now the company is entering the crowded audio space with the $200 Scape, a gaming headset that not only looks sophisticated, but also sounds surprisingly great too. Design The Fractal Scape features an attractive mix of materials. Igor Bonifacic for Engadget I mentioned the design of the Scape first, and for good reason. It shows attention to detail, with a lot of thoughtful flourishes. The best of those is the dock that comes included with the headset. It charges the Scape inductively, so there's no need to align any charging pins, and it cleverly houses the headset's 2.4GHz wireless transmitter. When connected to your main PC, the dongle can sit inside the dock, ready to go when you want to use it with your PlayStation 5, PS4, Nintendo Switch or another PC or Mac (sorry, Microsoft fans, there's no Xbox support). The base also has wire channels to make cable management easy. Those same thoughtful design touches extend to the headset itself. On the back are four buttons, a dial and a toggle that cover nearly every function of the Scape. You can adjust the volume, mute the built-in mic, switch between 2.4GHz and Bluetooth connectivity, power the headset on or off, turn the RGB lighting on or off and switch between three EQ presets. What’s more, all of the controls feel distinct and are easy to use. There's also a USB-C connection for wired audio and a three-pole headphone jack for the detachable microphone. The headset is primarily made of plastic, with a touch of brushed metal. Fractal offers the Scape in two colors — the aptly named light and dark — and despite the company's choice of materials, the headset feels undoubtedly premium. Tilt adjustment is limited — it's not possible to lay the ear pads flat on a table, for example — but the headband offers a fair amount of resistance, adding to the high-end feel. That said, the Scape could be more comfortable. Clamping force feels just about right, but there's not enough padding along the top of the headband. I found I could wear the headphones for a few hours, but I eventually had to take them off to relieve the pressure that had built up on the top of my head. I'm also not a fan of the fabric Fractal used for both the headband and ear pads. It feels scratchy and it's not great at dissipating heat. Thankfully, the high-density memory foam beneath is plush and the pads were deep and wide enough to comfortably accommodate my ears. Fractal has made it easy to swap the ear pads if needed; they come right off with just a small amount of force. For the time being, the company isn't selling replacements, but a spokesperson told me Fractal will send customers who need new pads a set for free. You just need to contact their support team. Sound quality The Scape comes with a set of custom-tuned drivers. Igor Bonifacic for Engadget Out of the box, the Scape's dynamic drivers are tuned to a soft v-shaped curve, with an emphasis on accuracy over character. Bass frequencies are punchy without being bloated, and there's nice detail to mid-focused instruments like guitars. To my ear, the one issue with the Scape's default tuning were the upper mids and treble frequencies. They weren't shouty to the point of being sibilant, but there was definitely a harshness to the vocals of singers like Jeff Buckley and Caroline Polachek who are known for their falsetto. Thankfully, this was easy to fix with the Scape's built-in EQ settings. I'll have more to say in the software section of this review, but Fractal's Adjust app allows you to make parametric EQ adjustments. This is different to most gaming headsets, which often limit people to restrictive fixed-band tweaks. Even when I used just five potential points of customization, I found I had a great deal of control over the tonality of the Scape. Overall, for casual music listening these are excellent headphones capable of covering many different genres. When it comes to gaming, they're great too — with some caveats. For singleplayer games, the default tunings are an excellent match. Playing Ghost of Tsushima, the Scape did a great job of reproducing the game's immersive sound design, allowing me to soak in all the little audio details Sucker Punch packed into its rendition of 13th century Japan. The soundstaging isn't as expansive and lush as I'm used to with my Sennheiser HD 600, but for a pair of closed-back headphones, it's above average. When it comes to competitive first-person shooters, some tweaks are required. I found all the default presets produced too much bass to easily isolate sound cues in games like Valorant. Again, Fractal's software made this simple to fix; however, the Scape can only store three presets. Some gaming headsets, particularly those from Steelseries, come with tunings for hundreds of different games. For the ultra-competitive gamer, this can be useful since every game has a different sound engine. I'm not one of those people, so I found the Scape had just the right amount of customization. A closeup of the Scape's volume dial. Igor Bonifacic for Engadget One feature you won't find on these headphones is active noise cancellation (ANC). Don't get me wrong, ANC is great, but I also didn't feel like the Scape was a worse product without it. My girlfriend is a Pelton fanatic and she does all of her daily classes without wearing headphones in our small apartment. In that situation, the Scape's passive noise isolation was enough to block the loud music coming from those workouts. That said, the one area where the Scape could have been better is Bluetooth connectivity. It's a 5.3 headset, but codec support is limited to SBC and AAC. If you've ever tried a pair of wireless headphones only to be disappointed by how they sounded, SBC was probably to blame. When I used the Scape over Bluetooth, there was a subtle difference, but in a beat 'em up like Absolum, the game's excellent sound design was less effective because it sounded more compressed, with more lag between what was happening on-screen and the effects that followed. I would have liked to see Fractal support more modern codecs like aptX Adaptive, but given that you need a dongle like the Creative BT-W6 to get access to those protocols on PCs and consoles, I can't fault the company for its decision. Also missing from the Bluetooth equation is multipoint support, meaning I wasn't able to connect the Scape to my PC or Switch and my iPhone at the same time. The Scape's detachable microphone is fine but uninspiring. In listening back to a chat I had with some friends over Discord, I found the Scape compressed my voice to the point where there wasn't a lot of life or nuance to it. The optional noise cancellation algorithm does a good job of filtering out nearby commotion, but does so at the expense of adding more compression. You can flip the microphone to mute yourself, and if you're feeling lazy, the Scape also has a built-in mic — though it sounds about as good as you might imagine. Still, it's handy in a pinch. Software Fractal's Adjust app is web-based and easy to use. Igor Bonifacic for Engadget I mentioned Fractal's Adjust software, but what I didn't note is that it's not an app you need to install on your computer. Instead, it's a website you can access through any Chrome-based browser. It's a small thing, but one I really appreciate. I can't count how many times I've had to troubleshoot issues with Windows that were caused by a conflict created by Logitech G Hub or NZXT Cam. The web-based software itself is simple, with two pages, named Lighting and Audio, encompassing all the options you can tweak. The Scape comes with 10 lighting themes out of the box, and like the headset itself, these presets are understated and classy. Naturally, you can also create your own lighting schemes, and the tool for doing so is fairly robust. A closeup of the Fractal Scape's EQ button Igor Bonifacic for Engadget When it comes to the EQ adjustments you can make with the Adjust app, the one thing I'll add here is any presets you save are stored on the Scape, so they're available everywhere you want to use the headset. That was great because it meant I didn't need to Alt-Tab out of a game to switch the headset to a more competitive tuning. The one area where Fractal's software feels lacking is when it comes to microphone controls. It's possible to adjust sidetone (the volume of your mic input as heard through the headset) and enable microphone noise cancellation, but that’s it. It'd be nice if it was possible to configure those settings for the two mics independently of one another, but the software doesn't support that right now. Battery life According to Fractal, the Scape can go up to 40 hours on a single charge with RGB lighting off. With the feature turned on, battery life drops to about 26 hours. I'll be honest, I had a tough time putting those claims to the test because of how easy it is to charge the headset. As best as I can tell, those estimates are accurate. I managed to get three days of battery life from the Scape with the RGB lights turned on and about eight hours of use each day. One nice touch: when you tap the power button, the RGB lights will briefly illuminate to indicate how much battery life the Scape has left. Those same lights will turn off when you place the headset to charge so that they're not distracting. The competition With the Scape, Fractal has entered a crowded market. That said, the Scape is competitive with some of the best gaming headsets you can buy right now. At $200, it's $100 cheaper than the Audeze Maxwell, Engadget's pick for the best premium gaming headset. The Scape doesn't sound as good as the Maxwell or offer LDAC support for Bluetooth connectivity, but it's lighter and charging is easier thanks to the included charging base. If you ask me, the Scape also looks a lot better too. If you can't live without ANC, your best bet is Razer's BlackShark V3 Pro, but it costs $50 more and doesn't sound as good as the Scape. You also need to put up with Razer's annoying Synapse software. For the best mic on a gaming headset, my longstanding recommendation has been the $199 Drop PC38X. It also has one of the best default tunings for competitive gaming. However, it's a wired headset, and Drop doesn’t offer a wireless option. Wrap-up The charging station also houses the Scape's 2.4GHz transmitter. Igor Bonifacic for Engadget If you can't tell by now, I think the Fractal Scape is a great gaming headset. There are models like the Audeze Maxwell that beat it in one or two categories, but for $200 the Scape is an excellent all-around package. Nitpicks about comfort aside, the Scape sounds and looks great. It's also a tremendous first effort by Fractal, and I can't wait to see what the company does next in the audio space and beyond. This article originally appeared on Engadget at https://www.engadget.com/gaming/fractal-design-scape-review-a-stellar-debut-173000007.html?src=rss",
          "feed_position": 8,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/fractal-scape-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-cancel-norton-vpn-uninstall-it-and-get-your-money-back-150000872.html",
          "published_at": "Thu, 30 Oct 2025 15:00:00 +0000",
          "title": "How to cancel Norton VPN, uninstall it and get your money back",
          "standfirst": "Norton Security has some reliable products, but its VPN isn't one of them. In my Norton VPN review, I argued that it's only really worthwhile if you can get a discount on it as part of a Norton 360 package — and even in that case, you should only use it for non-sensitive activities due to some holes in Norton's comprehensive privacy policy. That's a lot of conditions, so I'd understand if you're here because you've decided Norton VPN isn't for you. Read on to learn your options for cancelling this VPN, getting a refund and replacing it with a better provider. How to turn off Norton VPN auto-renewal The simplest way to cancel Norton VPN is to stop your subscription from automatically renewing. That way, you'll have until your plan expires to look for a new VPN. Note that the steps below are the same no matter how you got Norton VPN, whether on its own or as part of Norton 360 — though they only apply if you subscribed through the Norton website, not an app store. Sign into your account at my.norton.com. You'll be taken to your account dashboard with your subscriptions tab visible. If it's not, click on My Subscriptions. On your subscriptions hub, find the plan you get Norton VPN through. Click the words Manage Renewal or Cancel Subscription Renewal. In the window that appears, click Unsubscribe. Select a reason for cancellation (no need to be truthful) and click Next. At this point, you'll have to wade through several pleas for you to stay. Stand firm and keep clicking through until you can click No thanks, cancel my subscription. Continue clicking Next until you see a confirmation that auto-renewal has been turned off. Wait 24 hours for the change to take effect. Sam Chapman for Engadget If you change your mind after turning auto-renewal off, you can turn it back on again anytime before the subscription expires. For those who bought through an app store, there's no way to turn off auto-renewal; you can only cancel the subscription altogether. See the end of the next section to learn how to do that. How to cancel Norton VPN and get a refund You can request a refund on any annual subscription for 60 days after paying. Monthly subscriptions can only be refunded once, within 14 days of paying — if you renew a monthly plan then decide to cancel, you're out of luck. The only way to get a refund is to contact Norton directly. If you're ready to go cold turkey, follow these steps. In a browser, open support.norton.com. Scroll down until you see nine buttons arranged in a 3x3 grid. Find the second button down in the left-hand column, Contact us, and click on it. Enter the email address for your Norton account. Check that inbox for a verification code, then enter it in the next box and click Verify. When the live chat asks you what you need help with, select Purchase & Billing, then Request refund. Give a reason in the dropdown menu. As usual, be persistent until you get a message in writing that your refund will be processed. Wait at least three days for the money to appear. Sam Chapman for Engadget If you subscribed through the Apple App Store or Google Play Store, you'll have to cancel through the same platform where you started. Just go into the subscriptions page of the store's mobile app, find your Norton VPN subscription and click the Cancel button beside it. After that, just follow the prompts, then request a refund using the steps above. How to uninstall Norton VPN To get your money back from Norton, you can't just shut off auto-renewal. You'll have to cancel your plan immediately and delete all Norton apps from your devices. I recommend following these steps even if you aren't eligible for a refund, since Norton software is notoriously hard to uninstall and will crop back up if you don't completely root it out. On Android and iOS, uninstalling Norton VPN is relatively easy — after cancelling your subscription, delete it like you would any other app. Things are a bit trickier on the desktop OSes. On Windows, hold the Windows key and press R to make a black box appear. Type appwiz.cpl and hit Enter. A list of programs should appear; click on Norton VPN, then click Uninstall/Change and follow the instructions. On a Mac, open your Applications folder and find Norton VPN. Click the app icon and drag it to the trash. This should start a separate program called Norton Uninstaller. Click OK, enter your password if asked, then click Uninstall. Finally, you'll need to restart your computer to finish uninstalling. Norton VPN alternatives Once you've dispensed with Norton VPN, you can get started with a provider that fits your needs better. Proton VPN, my current top pick in our guide to the best VPNs, takes privacy more seriously than Norton and has superior app design and speeds. Surfshark is the fastest VPN, NordVPN has the best features and ExpressVPN is the friendliest for beginners.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-norton-vpn-uninstall-it-and-get-your-money-back-150000872.html?src=rss",
          "content": "Norton Security has some reliable products, but its VPN isn't one of them. In my Norton VPN review, I argued that it's only really worthwhile if you can get a discount on it as part of a Norton 360 package — and even in that case, you should only use it for non-sensitive activities due to some holes in Norton's comprehensive privacy policy. That's a lot of conditions, so I'd understand if you're here because you've decided Norton VPN isn't for you. Read on to learn your options for cancelling this VPN, getting a refund and replacing it with a better provider. How to turn off Norton VPN auto-renewal The simplest way to cancel Norton VPN is to stop your subscription from automatically renewing. That way, you'll have until your plan expires to look for a new VPN. Note that the steps below are the same no matter how you got Norton VPN, whether on its own or as part of Norton 360 — though they only apply if you subscribed through the Norton website, not an app store. Sign into your account at my.norton.com. You'll be taken to your account dashboard with your subscriptions tab visible. If it's not, click on My Subscriptions. On your subscriptions hub, find the plan you get Norton VPN through. Click the words Manage Renewal or Cancel Subscription Renewal. In the window that appears, click Unsubscribe. Select a reason for cancellation (no need to be truthful) and click Next. At this point, you'll have to wade through several pleas for you to stay. Stand firm and keep clicking through until you can click No thanks, cancel my subscription. Continue clicking Next until you see a confirmation that auto-renewal has been turned off. Wait 24 hours for the change to take effect. Sam Chapman for Engadget If you change your mind after turning auto-renewal off, you can turn it back on again anytime before the subscription expires. For those who bought through an app store, there's no way to turn off auto-renewal; you can only cancel the subscription altogether. See the end of the next section to learn how to do that. How to cancel Norton VPN and get a refund You can request a refund on any annual subscription for 60 days after paying. Monthly subscriptions can only be refunded once, within 14 days of paying — if you renew a monthly plan then decide to cancel, you're out of luck. The only way to get a refund is to contact Norton directly. If you're ready to go cold turkey, follow these steps. In a browser, open support.norton.com. Scroll down until you see nine buttons arranged in a 3x3 grid. Find the second button down in the left-hand column, Contact us, and click on it. Enter the email address for your Norton account. Check that inbox for a verification code, then enter it in the next box and click Verify. When the live chat asks you what you need help with, select Purchase & Billing, then Request refund. Give a reason in the dropdown menu. As usual, be persistent until you get a message in writing that your refund will be processed. Wait at least three days for the money to appear. Sam Chapman for Engadget If you subscribed through the Apple App Store or Google Play Store, you'll have to cancel through the same platform where you started. Just go into the subscriptions page of the store's mobile app, find your Norton VPN subscription and click the Cancel button beside it. After that, just follow the prompts, then request a refund using the steps above. How to uninstall Norton VPN To get your money back from Norton, you can't just shut off auto-renewal. You'll have to cancel your plan immediately and delete all Norton apps from your devices. I recommend following these steps even if you aren't eligible for a refund, since Norton software is notoriously hard to uninstall and will crop back up if you don't completely root it out. On Android and iOS, uninstalling Norton VPN is relatively easy — after cancelling your subscription, delete it like you would any other app. Things are a bit trickier on the desktop OSes. On Windows, hold the Windows key and press R to make a black box appear. Type appwiz.cpl and hit Enter. A list of programs should appear; click on Norton VPN, then click Uninstall/Change and follow the instructions. On a Mac, open your Applications folder and find Norton VPN. Click the app icon and drag it to the trash. This should start a separate program called Norton Uninstaller. Click OK, enter your password if asked, then click Uninstall. Finally, you'll need to restart your computer to finish uninstalling. Norton VPN alternatives Once you've dispensed with Norton VPN, you can get started with a provider that fits your needs better. Proton VPN, my current top pick in our guide to the best VPNs, takes privacy more seriously than Norton and has superior app design and speeds. Surfshark is the fastest VPN, NordVPN has the best features and ExpressVPN is the friendliest for beginners.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-norton-vpn-uninstall-it-and-get-your-money-back-150000872.html?src=rss",
          "feed_position": 16,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/8fa7e830-b512-11f0-bff6-091d2e25ea4a"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-streaming-service-deals-133028980.html",
          "published_at": "Thu, 30 Oct 2025 10:01:27 +0000",
          "title": "The best streaming deals: Save on Hulu + Live TV, Audible, Starz and more",
          "standfirst": "Streaming services keep raising prices. At this point, if you subscribe to all the major services out there, you're basically paying the same price as cable — those antiquated local monopolies that streaming was supposed to save us from. But streaming still has one big advantage over the old ways: no contracts. That means you can grab a good streaming deal and then cancel without penalty. Our advice is to sign up for a service when you see a good streaming deal (or the latest season of, say, Doctor Who, Severance, Andor and/or The Last of Us). Then, when the deal ends or you've binged whatever it is you want to watch, cancel as needed. But streaming deals don't come around all that often and, when they do, it's easy to miss them thanks to...everything. So we're keeping eyes out for the best streaming deals out there and we update this guide often — so check it out the next time you have a hankering to watch something new. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Audible subscription (three months) for $3 ($42 off): From now through mid-December, you can get Amazon’s audiobook subscription for just a dollar a month for three months. Note that it will auto-renew at $15 per month after that, but you can cancel at any point. Starz (one year) for $30 ($40 off): Pay upfront for one year and you can get $40 off a Stars annual subscription. There's a month-to-month option too, which costs $5 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. DirecTV starting at $50/month for one month ($35 off): All of DirecTV's signature packages are $35 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. Spotify Premium Individual (3 month) for $0 ($36 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$8/month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "content": "Streaming services keep raising prices. At this point, if you subscribe to all the major services out there, you're basically paying the same price as cable — those antiquated local monopolies that streaming was supposed to save us from. But streaming still has one big advantage over the old ways: no contracts. That means you can grab a good streaming deal and then cancel without penalty. Our advice is to sign up for a service when you see a good streaming deal (or the latest season of, say, Doctor Who, Severance, Andor and/or The Last of Us). Then, when the deal ends or you've binged whatever it is you want to watch, cancel as needed. But streaming deals don't come around all that often and, when they do, it's easy to miss them thanks to...everything. So we're keeping eyes out for the best streaming deals out there and we update this guide often — so check it out the next time you have a hankering to watch something new. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Audible subscription (three months) for $3 ($42 off): From now through mid-December, you can get Amazon’s audiobook subscription for just a dollar a month for three months. Note that it will auto-renew at $15 per month after that, but you can cancel at any point. Starz (one year) for $30 ($40 off): Pay upfront for one year and you can get $40 off a Stars annual subscription. There's a month-to-month option too, which costs $5 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. DirecTV starting at $50/month for one month ($35 off): All of DirecTV's signature packages are $35 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. Spotify Premium Individual (3 month) for $0 ($36 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$8/month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/best-ereader-130013808.html",
          "published_at": "Thu, 30 Oct 2025 09:01:26 +0000",
          "title": "The best ereaders for 2025",
          "standfirst": "Color is the buzziest feature in ereaders right now, but is it necessary? It makes the covers more fun, and readers of comics and graphic novels will appreciate the added hues (though they may be happier with an E Ink tablet for better image detail). Color is just one factor to consider when picking out the best ereader. The lights, screen quality, housing and buttons make a difference too. Then there’s the software: Do you want to stay in the Kindle ecosystem or get a device that can handle lots of apps? We tested more than a dozen ereaders to come up with our recommendations. This guide also points out ways to get the most out of your new e-book companion once you pick your favorite.Editor’s note: Amazon announced two new Kindles at its fall hardware event: the Scribe 3 and the Scribe Colorsoft. Reviews for both of these writing tablets are forthcoming and will also appear in our guide to E Ink tablets. No new Kindle ereaders were announced at the event. Boox announced two new devices as well, a new Note Air5 C tablet and the Palma 2 Pro, both with color. We’re in the process of testing the latter for inclusion in this guide.. Table of contents Best ereaders What to look for in an ereader How to get books for your ereader How we test ereaders Ereader FAQs Recent updates The best ebook readers for 2025 What to look for in an ereader Plenty of apps, including the Kindle app, will let you download and read digital books on an iPhone, Android Phone or tablet. But what makes ebook readers different is the screen: nearly all of them use technology from a company called E Ink. It manufactures electronic paper displays (EPD) composed of three sheets: one containing millions of microcapsules filled with black and white ink particles sandwiched between transparent electrode layers. When a charge is applied, either the black or white particles shift to the top, forming letters and the whitespace around them. Color ereaders add a color filter array on top of the standard black and white microcapsule layer. The result is two different resolutions on one screen — the color clarity is 150 dpi while black and white images and text are still 300 dpi. Because these displays are so different from standard backlight LED panels, you can expect most good ereaders to do a number of things well. They’ll be easier to stare at for long periods of time and easier to read in direct sunlight. Also, since E Ink displays only require power to rearrange the ink, these devices have much longer battery lives than even the best tablets: we’re talking weeks on a single charge, not days. The ereader market is not as saturated as, say, the smartphone market, but there are still plenty of options out there and they do have small but important differences among them. They tend to range from around $100 to more than $400, though usually the higher end options are stylus-enabled read/write E Ink tablets like the Kindle Scribe. Beyond price, you should consider physical properties like buttons, lights, storage and resolution, as well as how the software lets you find and access books. Reading features With any ereader, you’ll navigate the OS via taps and swipes, and some add physical page-turn buttons. Most with built-in buttons have an auto-rotating screen so you can press with your right or left hand. As E Ink technology has advanced, resolution has greatly improved – even the budget Kindle ereader has a 300 ppi display. You can still find models with lower resolution, but we don’t recommend them. Some ereaders have front LEDs that support light temperature adjustment. That means you can switch to a warmer light after the sun goes down, which will feel easier on the eyes. If you’re concerned about blue light, you should go for a reader with that feature. Finally, dark mode is available on most later model ereaders, allowing you to invert the black and white text and background, which some people find easier to read in low-light settings. Other features The capabilities of these pocket libraries have advanced considerably since the early days. In addition to storing books, some let you browse the web, run apps and play music. The screen’s frame rate can’t handle gaming, but it’s good enough to show you the Wikipedia entry for Striver’s Row while you read Crook Manifesto. If you listen to audiobooks, you may want a Bluetooth-enabled ereader capable of playing them. Most of the models we tested have that ability, with the notable exception of the Nook ereader we tried. Keep in mind that audiobook files can take up more space than print files so you'll probably want a device with a higher storage capacity if you plan on doing a lot of listening. Above all, you should consider where and how you intend to find books to read. Most ereaders make it easiest to shop through their own digital bookstores, but all of them (even Kindles) will now let you download titles from other sources, like libraries, unaffiliated ebook sellers and free public domain sites. Photo by Amy Skorheim / Engadget How to get books for your ereader Kindle, Nook and Kobo all have their own stores that you access directly from each brand’s devices. Prices are the same among all sellers, too. Publishers set the price of an ebook, not the retailer, so a title will cost the same at Amazon, Barnes & Noble, eBooks.com and the Kobo store. Amazon offers Kindle Unlimited for $12 per month, and it includes four million titles from which you can pick your next read. It includes audio and ebooks, but you won’t find many big, new releases or older bestsellers. Kobo has a subscription called Kobo Plus with about 1.3 million titles: it goes for $8 per month for ebooks only, $8 for audiobooks only or $10 for both. Buying a book from a proprietary store instantly delivers it to your device, provided you’re connected to WiFi. It also syncs your reading across devices and apps, so you can pick up where you left off on your phone if you forgot your ereader at home. It truly is the most convenient way to go, but if you don’t want to be locked into one brand’s store, or if you opt for an ereader without its own marketplace, you do have options. How to upload ePubs onto an ereader Stores like ebooks.com and Google Play have millions of ebooks for sale as digital rights-managed (DRM) ePub files, which Kobo, Nook and PocketBook readers can read in their native ereader apps. Kindles don’t support DRM ePub files at all and Boox devices require third party reading apps (of which there are many) to read those files. Titles from Apple Books are only readable in iOS devices. Titles from some publishers like Tor and public domain classics from sites like Project Gutenberg are also sold as ePubs, but without the added DRM. Consequently, Kindles and the Boox Neoreader do support those files. Books you get from third-party sources will look just like ones you bought from a proprietary store, thanks to the flowable, formatted nature of ePub files. While these device-agnostic ebook collections give you extra options for finding your next read, they require a few additional steps to get the files onto your ereader. To do so, you’ll typically need a computer running a free program called Adobe Digital Editions (ADE). After buying and downloading the ePub file, open ADE and plug your ereader into your computer (all readers here have a USB-C port for charging and data transfers). Your device should pop up in the left panel. Drag and drop the ePub file from your downloads folder into the main panel in ADE. The file will display as an image of the book cover. Drag that image onto your device on the left panel. If the file includes digital rights management (which protects against unauthorized copying) you’ll need to authorize your ereader, which requires using or creating a free Adobe ID. Once you’ve finished adding files to upload, eject the reader from your computer to complete the transfer process. Kindles use a web-based uploader instead of the ADE method. But since Kindle uses its own proprietary DRM technology instead of Adobe's, the only files it can accept from third parties are non-DRM files, such as from Tor Publishing or Project Gutenberg. After downloading a compatible ePub file, drag and drop it into your browser with the Send to Kindle page open. As long as you’re signed into Amazon, this wirelessly transfers the files to your associated device. Boox also uses a browser uploader called BooxDrop (along with many other methods) to deliver ePubs to the device. Open it from the Boox App menu and you’ll see a device-specific url. Type that into your browser to access a file delivery portal that uploads to your library. Boox’s built-in ereader app, NeoReader, also doesn’t support files with DRM, so you won’t be able to read current titles from most publishers using that app. Fortunately, Boox devices run nearly every ereader app out there, Kobo and Kindle included, letting you access ePubs any number of ways. Recently, Bookshop.org, the online seller of physical books that supports indie bookstores, started selling ebooks and up to 100 percent of the profits will go to local booksellers. The company uses a different rights management system than ADE so, right now, you can only read titles you buy from them on the Bookshop.org app, but the company is working with the makers of both Kindle and Kobo to extend compatibility to those ereaders. How to read library books on an ereader Your local library card lets you borrow audio and ebooks through a program called Overdrive and its companion app Libby. On a Kobo, you have have built-in access to Overdrive in a separate tab. Once you’ve linked your public library card, the search function will include results for titles available from your local library system; a few taps will upload your selections to your device for the length of the loan. I personally find it easiest to borrow the title I want through the Libby app on my phone. After that, the book pops up on my Kobo’s home screen once the device syncs. To read library books on a Kindle, you can either go through the Libby app or the Overdrive section of your library’s website. Once you click Borrow, you’ll see the option to “Read now with Kindle,” which takes you to Amazon’s site to sign in. After that, the book will be delivered to your device the next time it connects to WiFi. For other ereaders, you’ll go through your library’s Overdrive portal and download the ePub after clicking the Borrow button. You can then use the ADE process we described above. Devices that run external apps, like Boox's Page, Go Color 7 or Palma, allow you to read library books via the Libby app, just as you would on a smartphone or iPad. You can also use the Libby app to borrow audiobooks, but you won’t be able to access them through your ereader. (The exception is an ereader, like a Boox device, that allows external apps). I found it was easier to listen to an audiobook on my phone anyway, regardless of whether I borrowed it through Libby or bought it from Kindle or Kobo. Photo by Amy Skorheim / Engadget How we test ereaders When putting together any guide, the first thing we do is spend hours researching the field. We look at what’s available, what’s new, and what shoppers and professional reviewers have to say. Then we narrow a list to the best candidates for hands-on testing. Over the course of the past two years, I’ve tested just over a dozen ereaders, representing five different brands: Amazon, Kobo, Barnes & Noble, Boox and PocketBook. I bought, borrowed and uploaded books for each device using the methods above. I used each one for between a few days to a few months. I evaluated each one in the areas of book access, ease of reading, extra features and overall value. Here’s everything we tested so far: Amazon Kindle (2022) Amazon Kindle (2024) Amazon Kindle Paperwhite (2021) Amazon Kindle Paperwhite Signature (2024) Boox Go Color 7 Boox Leaf 2 Boox Page Boox Poke 5 Boox Palma Kobo Libra 2 Kobo Libra Colour Kobo Clara 2E Kobo Clara Colour Kobo Nia NOOK GlowLight 4 PocketBook Era Other ereaders we tested Amazon Kindle Colorsoft Amazon’s first color Kindle impressed with its quick page-turns and load times, auto-adjusting front light and, of course, a decently striking color E Ink display. But at $280, it’s more expensive than all of the other color ereaders in its size range, including the Kobo Libra Colour and the Boox Go Color 7. Also, some Colorsoft owners reported seeing a yellow band at the bottom of their ereader’s display. This issue did not affect our first review unit during the original testing period, but it eventually appeared. An Amazon spokesperson told Engadget: \"A small number of customers have reported a yellow band along the bottom of the display. We take the quality of our products seriously—customers who notice this can reach out to our customer service team for a replacement or refund, and we’re making the appropriate adjustments to ensure that new devices will not experience this issue moving forward.\" Amazon sent us a new Colorsoft ereader at the end of 2024 and it does appear that the fixes the company made resolved the yellow-band issue. The screen on our second review unit appears warmer overall, but not overly so. It’s more akin to the screen on the Kobo Libra Colour, and that’s a good thing. Boox Go 7 stylus-enabled ereader Boox recently released two new stylus-enabled generations of their seven-inch reader: The monochrome Go 7 and a color-screen Go Color 7 (Gen II). After trying out the stylus-enabled Go 7, I still like the standard, non-stylus enabled version better. True, I liked the Notebook app with its array of handwriting templates and I appreciated the low-to-no latency with the stylus. It also offers a good assortment of brush, pen and style options. But outside of the Notebook app, I didn’t find much use for the stylus. I was able to doodle in the margins of DRM-free books in Boox’s native NeoReader, but it doesn’t work in other apps or on any rights-managed books. There's a FreeMark option that allows you to draw or write atop any app, but it saves your doodles as separate images, as opposed to allowing you to mark up the page itself. I also found enabling the stylus to be a little glitchy. If you plan to do a lot of writing, you’ll probably be better served by an E Ink tablet, but if you want an ereader that can mark up your books, I suggest going with the Kobo Libra Color, detailed above. Ereader FAQs What's the difference between an ereader and an e-ink reader? Really, they are the same thing. E Ink is a company that designs and manufactures the paper-like screens found in most ereader devices. Technically, anything you read ebooks on can act as an ereader, so your phone, iPad or Android tablet could all serve that purpose, but they’re not considered dedicated ereaders. While there are some devices marketed as ereaders that have LCD or OLED screens instead of E Ink, they aren’t as common. One of the benefits of ereaders is the E Ink screen’s paper-like quality, which causes less eye strain for many people. But there is a difference between ereaders and E Ink tablets. These larger e-ink devices also employ E Ink screens, but they have stylus input and are often used for note taking and other tasks in addition to reading ebooks. We have an entire guide devoted to helping you pick out an E Ink tablet. Are there ads on my ereader? The base model Kindle and Kindle Paperwhite come with ads by default, but you can opt to pay $20 to remove them, either at the time of purchase or after you start using the device. The ads are limited to the lockscreen and are typically for other books or Kindle services. Kobo and Boox ereaders don’t come with ads. Which ereader has the longest battery life? Of the devices we tested, the Boox Go Color 7 has the largest listed battery capacity at 2,300mAh (Amazon doesn’t list the capacity of its Kindle devices). But thanks to the nature of E Ink screens and the relatively limited processing power required to display e-books, nearly all ereaders can go for weeks before they need a recharge. That means battery life probably isn’t as much of a deciding factor in buying an ereader as it would be with a tablet or smartphone. Which ereaders can read Kindle books? Amazon’s Kindle ereaders are the obvious answer, but other devices capable of running apps can also read titles from the Kindle store. For example, you can download the Kindle app on a Boox ereader through Google Play (the store comes standard in the Boox app menu). You can then sign into your Kindle account and access all the books in your library — the same way you’d read Kindle books on your phone or tablet. Can you buy Kindle books without a Kindle? Yes. You can buy Kindle books through the Kindle app or through Amazon’s website via a browser. You can read those titles on a Kindle or any device that can run the Kindle app, such as a smartphone, tablet or computer. Just be aware that Kindle titles can only be read through one of Amazon’s ereaders or the Kindle app. The company uses proprietary digital rights management on all ebooks it sells that can’t be read by other ereader apps like Kobo or Adobe ADE. What's the difference between Kindle and Kobo? Both Kindle and Kobo are brands of dedicated ereaders that support searching, buying, downloading and reading ebooks from their own stores. Both also support borrowing books from your local library via Overdrive and Libby. The difference is that Kindle is owned by Amazon and uses the Kindle store, whereas Kobo is owned by Rakuten and its books come from the Kobo store. Both stores come pre-loaded as a tab on their respective ereader and both carry most in-print books. Each store also carries their own exclusive ebooks as well, but Amazon’s library of Kindle-only books is much larger than Kobo’s. Amazon also offers Amazon Original stories to read on the Kindle, which are free short fiction and nonfiction reads that are free to Prime members. Which ereader is best for library books? Both Kobos and Kindles have simple systems for borrowing library books. Other ereaders, like Boox, let you borrow books after downloading the Libby App. Only Kobo ereaders let you search for and borrow books directly on the ereader, with a dedicated Overdrive tab. Kindles, on the other hand, utilize a convenient “read on Kindle” function from the Libby app or website. You can send a borrowed book to your Kindle just by signing into your account. Both methods are pretty easy, so which is the best for you probably depends on other factors than just the library-book feature. Recent updates August 2025: Included new frequently asked questions covering battery life, E Ink screens and ads on ereaders. Mentioned Amazon’s release of a cheaper Colorsoft Kindle. July 2025: Added our impressions of the new stylus-enabled Boox Go 7 series. Updated our Boox Palma recommendation to account for the upgrades to the Boox Palma 2. Included text formats to our specs and the battery life of the Kobo Clara Colour. March 2025: Added news about Bookshop.org getting into the ebook market. Updated information about price-setting by publishers. January 2025: Updated the \"Others we tested\" section to include impressions of the second Kindle Colorsoft review unit we received. August 2024: Replaced our Android tablet pick with the new Go Color 7 ereader from Boox. Updated book titles to current examples. Added an FAQ section to explain the difference between Kobo and Kindle ereaders and further detail library-book support on different models. November 2024: Following the release of Amazon's new Kindle ereaders, we tested and reviewed the Kindle Paperwhite Signature Edition, the base-model Kindle and Amazon's new color ereader, the Kindle Colorsoft. Accordingly, we updated our budget pick, added a premium pick and noted our experience with the Colorsoft. This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-ereader-130013808.html?src=rss",
          "content": "Color is the buzziest feature in ereaders right now, but is it necessary? It makes the covers more fun, and readers of comics and graphic novels will appreciate the added hues (though they may be happier with an E Ink tablet for better image detail). Color is just one factor to consider when picking out the best ereader. The lights, screen quality, housing and buttons make a difference too. Then there’s the software: Do you want to stay in the Kindle ecosystem or get a device that can handle lots of apps? We tested more than a dozen ereaders to come up with our recommendations. This guide also points out ways to get the most out of your new e-book companion once you pick your favorite.Editor’s note: Amazon announced two new Kindles at its fall hardware event: the Scribe 3 and the Scribe Colorsoft. Reviews for both of these writing tablets are forthcoming and will also appear in our guide to E Ink tablets. No new Kindle ereaders were announced at the event. Boox announced two new devices as well, a new Note Air5 C tablet and the Palma 2 Pro, both with color. We’re in the process of testing the latter for inclusion in this guide.. Table of contents Best ereaders What to look for in an ereader How to get books for your ereader How we test ereaders Ereader FAQs Recent updates The best ebook readers for 2025 What to look for in an ereader Plenty of apps, including the Kindle app, will let you download and read digital books on an iPhone, Android Phone or tablet. But what makes ebook readers different is the screen: nearly all of them use technology from a company called E Ink. It manufactures electronic paper displays (EPD) composed of three sheets: one containing millions of microcapsules filled with black and white ink particles sandwiched between transparent electrode layers. When a charge is applied, either the black or white particles shift to the top, forming letters and the whitespace around them. Color ereaders add a color filter array on top of the standard black and white microcapsule layer. The result is two different resolutions on one screen — the color clarity is 150 dpi while black and white images and text are still 300 dpi. Because these displays are so different from standard backlight LED panels, you can expect most good ereaders to do a number of things well. They’ll be easier to stare at for long periods of time and easier to read in direct sunlight. Also, since E Ink displays only require power to rearrange the ink, these devices have much longer battery lives than even the best tablets: we’re talking weeks on a single charge, not days. The ereader market is not as saturated as, say, the smartphone market, but there are still plenty of options out there and they do have small but important differences among them. They tend to range from around $100 to more than $400, though usually the higher end options are stylus-enabled read/write E Ink tablets like the Kindle Scribe. Beyond price, you should consider physical properties like buttons, lights, storage and resolution, as well as how the software lets you find and access books. Reading features With any ereader, you’ll navigate the OS via taps and swipes, and some add physical page-turn buttons. Most with built-in buttons have an auto-rotating screen so you can press with your right or left hand. As E Ink technology has advanced, resolution has greatly improved – even the budget Kindle ereader has a 300 ppi display. You can still find models with lower resolution, but we don’t recommend them. Some ereaders have front LEDs that support light temperature adjustment. That means you can switch to a warmer light after the sun goes down, which will feel easier on the eyes. If you’re concerned about blue light, you should go for a reader with that feature. Finally, dark mode is available on most later model ereaders, allowing you to invert the black and white text and background, which some people find easier to read in low-light settings. Other features The capabilities of these pocket libraries have advanced considerably since the early days. In addition to storing books, some let you browse the web, run apps and play music. The screen’s frame rate can’t handle gaming, but it’s good enough to show you the Wikipedia entry for Striver’s Row while you read Crook Manifesto. If you listen to audiobooks, you may want a Bluetooth-enabled ereader capable of playing them. Most of the models we tested have that ability, with the notable exception of the Nook ereader we tried. Keep in mind that audiobook files can take up more space than print files so you'll probably want a device with a higher storage capacity if you plan on doing a lot of listening. Above all, you should consider where and how you intend to find books to read. Most ereaders make it easiest to shop through their own digital bookstores, but all of them (even Kindles) will now let you download titles from other sources, like libraries, unaffiliated ebook sellers and free public domain sites. Photo by Amy Skorheim / Engadget How to get books for your ereader Kindle, Nook and Kobo all have their own stores that you access directly from each brand’s devices. Prices are the same among all sellers, too. Publishers set the price of an ebook, not the retailer, so a title will cost the same at Amazon, Barnes & Noble, eBooks.com and the Kobo store. Amazon offers Kindle Unlimited for $12 per month, and it includes four million titles from which you can pick your next read. It includes audio and ebooks, but you won’t find many big, new releases or older bestsellers. Kobo has a subscription called Kobo Plus with about 1.3 million titles: it goes for $8 per month for ebooks only, $8 for audiobooks only or $10 for both. Buying a book from a proprietary store instantly delivers it to your device, provided you’re connected to WiFi. It also syncs your reading across devices and apps, so you can pick up where you left off on your phone if you forgot your ereader at home. It truly is the most convenient way to go, but if you don’t want to be locked into one brand’s store, or if you opt for an ereader without its own marketplace, you do have options. How to upload ePubs onto an ereader Stores like ebooks.com and Google Play have millions of ebooks for sale as digital rights-managed (DRM) ePub files, which Kobo, Nook and PocketBook readers can read in their native ereader apps. Kindles don’t support DRM ePub files at all and Boox devices require third party reading apps (of which there are many) to read those files. Titles from Apple Books are only readable in iOS devices. Titles from some publishers like Tor and public domain classics from sites like Project Gutenberg are also sold as ePubs, but without the added DRM. Consequently, Kindles and the Boox Neoreader do support those files. Books you get from third-party sources will look just like ones you bought from a proprietary store, thanks to the flowable, formatted nature of ePub files. While these device-agnostic ebook collections give you extra options for finding your next read, they require a few additional steps to get the files onto your ereader. To do so, you’ll typically need a computer running a free program called Adobe Digital Editions (ADE). After buying and downloading the ePub file, open ADE and plug your ereader into your computer (all readers here have a USB-C port for charging and data transfers). Your device should pop up in the left panel. Drag and drop the ePub file from your downloads folder into the main panel in ADE. The file will display as an image of the book cover. Drag that image onto your device on the left panel. If the file includes digital rights management (which protects against unauthorized copying) you’ll need to authorize your ereader, which requires using or creating a free Adobe ID. Once you’ve finished adding files to upload, eject the reader from your computer to complete the transfer process. Kindles use a web-based uploader instead of the ADE method. But since Kindle uses its own proprietary DRM technology instead of Adobe's, the only files it can accept from third parties are non-DRM files, such as from Tor Publishing or Project Gutenberg. After downloading a compatible ePub file, drag and drop it into your browser with the Send to Kindle page open. As long as you’re signed into Amazon, this wirelessly transfers the files to your associated device. Boox also uses a browser uploader called BooxDrop (along with many other methods) to deliver ePubs to the device. Open it from the Boox App menu and you’ll see a device-specific url. Type that into your browser to access a file delivery portal that uploads to your library. Boox’s built-in ereader app, NeoReader, also doesn’t support files with DRM, so you won’t be able to read current titles from most publishers using that app. Fortunately, Boox devices run nearly every ereader app out there, Kobo and Kindle included, letting you access ePubs any number of ways. Recently, Bookshop.org, the online seller of physical books that supports indie bookstores, started selling ebooks and up to 100 percent of the profits will go to local booksellers. The company uses a different rights management system than ADE so, right now, you can only read titles you buy from them on the Bookshop.org app, but the company is working with the makers of both Kindle and Kobo to extend compatibility to those ereaders. How to read library books on an ereader Your local library card lets you borrow audio and ebooks through a program called Overdrive and its companion app Libby. On a Kobo, you have have built-in access to Overdrive in a separate tab. Once you’ve linked your public library card, the search function will include results for titles available from your local library system; a few taps will upload your selections to your device for the length of the loan. I personally find it easiest to borrow the title I want through the Libby app on my phone. After that, the book pops up on my Kobo’s home screen once the device syncs. To read library books on a Kindle, you can either go through the Libby app or the Overdrive section of your library’s website. Once you click Borrow, you’ll see the option to “Read now with Kindle,” which takes you to Amazon’s site to sign in. After that, the book will be delivered to your device the next time it connects to WiFi. For other ereaders, you’ll go through your library’s Overdrive portal and download the ePub after clicking the Borrow button. You can then use the ADE process we described above. Devices that run external apps, like Boox's Page, Go Color 7 or Palma, allow you to read library books via the Libby app, just as you would on a smartphone or iPad. You can also use the Libby app to borrow audiobooks, but you won’t be able to access them through your ereader. (The exception is an ereader, like a Boox device, that allows external apps). I found it was easier to listen to an audiobook on my phone anyway, regardless of whether I borrowed it through Libby or bought it from Kindle or Kobo. Photo by Amy Skorheim / Engadget How we test ereaders When putting together any guide, the first thing we do is spend hours researching the field. We look at what’s available, what’s new, and what shoppers and professional reviewers have to say. Then we narrow a list to the best candidates for hands-on testing. Over the course of the past two years, I’ve tested just over a dozen ereaders, representing five different brands: Amazon, Kobo, Barnes & Noble, Boox and PocketBook. I bought, borrowed and uploaded books for each device using the methods above. I used each one for between a few days to a few months. I evaluated each one in the areas of book access, ease of reading, extra features and overall value. Here’s everything we tested so far: Amazon Kindle (2022) Amazon Kindle (2024) Amazon Kindle Paperwhite (2021) Amazon Kindle Paperwhite Signature (2024) Boox Go Color 7 Boox Leaf 2 Boox Page Boox Poke 5 Boox Palma Kobo Libra 2 Kobo Libra Colour Kobo Clara 2E Kobo Clara Colour Kobo Nia NOOK GlowLight 4 PocketBook Era Other ereaders we tested Amazon Kindle Colorsoft Amazon’s first color Kindle impressed with its quick page-turns and load times, auto-adjusting front light and, of course, a decently striking color E Ink display. But at $280, it’s more expensive than all of the other color ereaders in its size range, including the Kobo Libra Colour and the Boox Go Color 7. Also, some Colorsoft owners reported seeing a yellow band at the bottom of their ereader’s display. This issue did not affect our first review unit during the original testing period, but it eventually appeared. An Amazon spokesperson told Engadget: \"A small number of customers have reported a yellow band along the bottom of the display. We take the quality of our products seriously—customers who notice this can reach out to our customer service team for a replacement or refund, and we’re making the appropriate adjustments to ensure that new devices will not experience this issue moving forward.\" Amazon sent us a new Colorsoft ereader at the end of 2024 and it does appear that the fixes the company made resolved the yellow-band issue. The screen on our second review unit appears warmer overall, but not overly so. It’s more akin to the screen on the Kobo Libra Colour, and that’s a good thing. Boox Go 7 stylus-enabled ereader Boox recently released two new stylus-enabled generations of their seven-inch reader: The monochrome Go 7 and a color-screen Go Color 7 (Gen II). After trying out the stylus-enabled Go 7, I still like the standard, non-stylus enabled version better. True, I liked the Notebook app with its array of handwriting templates and I appreciated the low-to-no latency with the stylus. It also offers a good assortment of brush, pen and style options. But outside of the Notebook app, I didn’t find much use for the stylus. I was able to doodle in the margins of DRM-free books in Boox’s native NeoReader, but it doesn’t work in other apps or on any rights-managed books. There's a FreeMark option that allows you to draw or write atop any app, but it saves your doodles as separate images, as opposed to allowing you to mark up the page itself. I also found enabling the stylus to be a little glitchy. If you plan to do a lot of writing, you’ll probably be better served by an E Ink tablet, but if you want an ereader that can mark up your books, I suggest going with the Kobo Libra Color, detailed above. Ereader FAQs What's the difference between an ereader and an e-ink reader? Really, they are the same thing. E Ink is a company that designs and manufactures the paper-like screens found in most ereader devices. Technically, anything you read ebooks on can act as an ereader, so your phone, iPad or Android tablet could all serve that purpose, but they’re not considered dedicated ereaders. While there are some devices marketed as ereaders that have LCD or OLED screens instead of E Ink, they aren’t as common. One of the benefits of ereaders is the E Ink screen’s paper-like quality, which causes less eye strain for many people. But there is a difference between ereaders and E Ink tablets. These larger e-ink devices also employ E Ink screens, but they have stylus input and are often used for note taking and other tasks in addition to reading ebooks. We have an entire guide devoted to helping you pick out an E Ink tablet. Are there ads on my ereader? The base model Kindle and Kindle Paperwhite come with ads by default, but you can opt to pay $20 to remove them, either at the time of purchase or after you start using the device. The ads are limited to the lockscreen and are typically for other books or Kindle services. Kobo and Boox ereaders don’t come with ads. Which ereader has the longest battery life? Of the devices we tested, the Boox Go Color 7 has the largest listed battery capacity at 2,300mAh (Amazon doesn’t list the capacity of its Kindle devices). But thanks to the nature of E Ink screens and the relatively limited processing power required to display e-books, nearly all ereaders can go for weeks before they need a recharge. That means battery life probably isn’t as much of a deciding factor in buying an ereader as it would be with a tablet or smartphone. Which ereaders can read Kindle books? Amazon’s Kindle ereaders are the obvious answer, but other devices capable of running apps can also read titles from the Kindle store. For example, you can download the Kindle app on a Boox ereader through Google Play (the store comes standard in the Boox app menu). You can then sign into your Kindle account and access all the books in your library — the same way you’d read Kindle books on your phone or tablet. Can you buy Kindle books without a Kindle? Yes. You can buy Kindle books through the Kindle app or through Amazon’s website via a browser. You can read those titles on a Kindle or any device that can run the Kindle app, such as a smartphone, tablet or computer. Just be aware that Kindle titles can only be read through one of Amazon’s ereaders or the Kindle app. The company uses proprietary digital rights management on all ebooks it sells that can’t be read by other ereader apps like Kobo or Adobe ADE. What's the difference between Kindle and Kobo? Both Kindle and Kobo are brands of dedicated ereaders that support searching, buying, downloading and reading ebooks from their own stores. Both also support borrowing books from your local library via Overdrive and Libby. The difference is that Kindle is owned by Amazon and uses the Kindle store, whereas Kobo is owned by Rakuten and its books come from the Kobo store. Both stores come pre-loaded as a tab on their respective ereader and both carry most in-print books. Each store also carries their own exclusive ebooks as well, but Amazon’s library of Kindle-only books is much larger than Kobo’s. Amazon also offers Amazon Original stories to read on the Kindle, which are free short fiction and nonfiction reads that are free to Prime members. Which ereader is best for library books? Both Kobos and Kindles have simple systems for borrowing library books. Other ereaders, like Boox, let you borrow books after downloading the Libby App. Only Kobo ereaders let you search for and borrow books directly on the ereader, with a dedicated Overdrive tab. Kindles, on the other hand, utilize a convenient “read on Kindle” function from the Libby app or website. You can send a borrowed book to your Kindle just by signing into your account. Both methods are pretty easy, so which is the best for you probably depends on other factors than just the library-book feature. Recent updates August 2025: Included new frequently asked questions covering battery life, E Ink screens and ads on ereaders. Mentioned Amazon’s release of a cheaper Colorsoft Kindle. July 2025: Added our impressions of the new stylus-enabled Boox Go 7 series. Updated our Boox Palma recommendation to account for the upgrades to the Boox Palma 2. Included text formats to our specs and the battery life of the Kobo Clara Colour. March 2025: Added news about Bookshop.org getting into the ebook market. Updated information about price-setting by publishers. January 2025: Updated the \"Others we tested\" section to include impressions of the second Kindle Colorsoft review unit we received. August 2024: Replaced our Android tablet pick with the new Go Color 7 ereader from Boox. Updated book titles to current examples. Added an FAQ section to explain the difference between Kobo and Kindle ereaders and further detail library-book support on different models. November 2024: Following the release of Amazon's new Kindle ereaders, we tested and reviewed the Kindle Paperwhite Signature Edition, the base-model Kindle and Amazon's new color ereader, the Kindle Colorsoft. Accordingly, we updated our budget pick, added a premium pick and noted our experience with the Colorsoft. This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-ereader-130013808.html?src=rss",
          "feed_position": 33,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-03/c06d4490-cf16-11ed-96e7-3cba2c2f1226"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/why-it-leaders-should-pay-attention-to-canvas-imagination-era-strategy",
          "published_at": "Thu, 30 Oct 2025 03:00:00 GMT",
          "title": "Why IT leaders should pay attention to Canva’s ‘imagination era’ strategy",
          "standfirst": "The rise of AI marks a critical shift away from decades defined by information-chasing and a push for more and more compute power. Canva co-founder and CPO Cameron Adams refers to this dawning time as the “imagination era.” Meaning: Individuals and enterprises must be able to turn creativity into action with AI. Canva hopes to position itself at the center of this shift with a sweeping new suite of tools. The company’s new Creative Operating System (COS) integrates AI across every layer of content creation, creating a single, comprehensive creativity platform rather than a simple, template-based design tool.“We’re entering a new era where we need to rethink how we achieve our goals,” said Adams. “We’re enabling people’s imagination and giving them the tools they need to take action.”An &#x27;engine&#x27; for creativityAdams describes Canva’s platform as a three-layer stack: The top Visual Suite layer containing designs, images and other content; a collaborative Canva AI plane at center; and a foundational proprietary model holding it all up. At the heart of Canva’s strategy is its Creative Operating System (COS) underlying. This “engine,” as Adams describes it, integrates documents, websites, presentations, sheets, whiteboards, videos, social content, hundreds of millions of photos, illustrations, a rich sound library, and numerous templates, charts, and branded elements.The COS is getting a 2.0 upgrade, but the crucial advance is the “middle, crucial layer” that fully integrates AI and makes it accessible throughout various workflows, Adams explained. This gives creative and technical teams a single dashboard for generating, editing and launching all types of content.The underlying model is trained to understand the “complexity of design” so the platform can build out various elements — such as photos, videos, textures, or 3D graphics — in real time, matching branding style without the need for manual adjustments. It also supports live collaboration, meaning teams across departments can co-create. With a unified dashboard, a user working on a specific design, for instance, can create a new piece of content (say, a presentation) within the same workflow, without having to switch to another window or platform. Also, if they generate an image and aren’t pleased with it, they don’t have to go back and create from scratch; they can immediately begin editing, changing colors or tone. Another new capability in COS, “Ask Canva,” provides direct design advice. Users can tag @Canva to get copy suggestions and smart edits; or, they can highlight an image and direct the AI assistant to modify it or generate variants. “It’s a really unique interaction,” said Adams, noting that this AI design partner is always present. “It’s a real collaboration between people and AI, and we think it’s a revolutionary change.”Other new features include a 2.0 video editor and interactive form and email design with drag-and-drop tools. Further, Canva is now incorporated with Affinity, its unified app for pro designers incorporating vector, pixel and layer workflows, and Affinity is “free forever.” Automating intelligence, supporting marketingBranding is critical for enterprise; Canva has introduced new tools to help organizations consistently showcase theirs across platforms. The new Canva Grow engine integrates business objectives into the creative process so teams can workshop, create, distribute and refine ads and other materials. As Adams explained: “It automatically scans your website, figures out who your audience is, what assets you use to promote your products, the message it needs to send out, the formats you want to send it out in, makes a creative for you, and you can deploy it directly to the platform without having to leave Canva.”Marketing teams can now design and launch ads across platforms like Meta, track insights as they happen and refine future content based on performance metrics. “Your brand system is now available inside the AI you’re working with,” Adams noted. Success metrics and enterprise adoptionThe impact of Canva’s COS is reflected in notable user metrics: More than 250 million people use Canva every month, just over 29 million of which are paid subscribers. Adams reports that 41 billion designs have been created on Canva since launch, which equates to 1 billion each month. “If you break that down, it turns into the crazy number of 386 designs being created every single second,” said Adams. Whereas in the early days, it took roughly an hour for users to create a single design. Canva customers include Walmart, Disney, Virgin Voyages, Pinterest, FedEx, Expedia and eXp Realty. DocuSign, for one, reported that it unlocked more than 500 hours of team capacity and saved $300,000-plus in design hours by fully integrating Canva into its content creation. Disney, meanwhile, uses translation capabilities for its internationalization work, Adams said. Competitors in the design spaceCanva plays in an evolving landscape of professional design tools including Adobe Express and Figma; AI-powered challengers led by Microsoft Designer; and direct consumer alternatives like Visme and Piktochart.Adobe Express (starting at $9.99 a month for premium features) is known for its ease of use and integration with the broader Adobe Creative Cloud ecosystem. It features professional-grade templates and access to Adobe’s extensive stock library, and has incorporated Google&#x27;s Gemini 2.5 Flash image model and other gen AI features so that designers can create graphics via natural language prompts. Users with some design experience say they prefer its interface, controls and technical advantages over Canva (such as the ability to import high-fidelity PDFs). Figma (starting at $3 a month for professional plans) is touted for its real-time collaboration, advanced prototyping capabilities and deep integration with dev workflows; however, some say it has a steeper learning curve and higher-precision design tools, making it preferable for professional designers, developers and product teams working on more complex projects. Microsoft Designer (free version available; although a Microsoft 365 subscription starting at $9.99 a month unlocks additional features) benefits from its integration with Microsoft’s AI capabilities, Copilot layout and text generation and Dall-E powered image generation. The platform’s “Inspire Me” and “New Ideas” buttons provide design variations, and users can also import data from Excel, add 3D models from PowerPoint and access images from OneDrive. However, users report that its stock photos and template and image libraries are limited compared to Canva&#x27;s extensive collection, and its visuals can come across as outdated. Canva’s advantage seems to be in its extensive template library (more than 600,000 ready-to-use) and asset library (141 million-plus stock photos, videos, graphics, and audio elements).​ Its platform is also praised for its ease of use and interface friendly to non-designers, allowing them to begin quickly without training. Canva has also expanded into a variety of content types — documents, websites, presentations, whiteboards, videos, and more — making its platform a comprehensive visual suite than just a graphics tool. Canva has four pricing tiers: Canva Free for one user; Canva Pro for $120 a year for one person; Canva Teams for $100 a year for each team member; and the custom-priced Canva Enterprise. Key takeaways: Be open, embrace human-AI collaborationCanva’s COS is underpinned by Canva’s frontier model, an in-house, proprietary engine based on years of R&D and research partnerships, including the acquisition of visual AI company Leonardo. Adams notes that Canva works with top AI providers including OpenAI, Anthropic and Google. For technology teams, Canva’s approach offers important lessons, including a commitment to openness. “There are so many models floating around,” Adams noted; it’s important for enterprises to recognize when they should work with top models and when they should develop their own proprietary ones, he advised. For instance, OpenAI and Anthropic recently announced integrations with Canva as a visual layer because, as Adams explained, they realized they didn’t have the capability to create the same kinds of editable designs that Canva can. This creates a mutually-beneficial ecosystem. Ultimately, Adams noted: “We have this underlying philosophy that the future is people and technology working together. It&#x27;s not an either or. We want people to be at the center, to be the ones with the creative spark, and to use AI as a collaborator.”",
          "content": "The rise of AI marks a critical shift away from decades defined by information-chasing and a push for more and more compute power. Canva co-founder and CPO Cameron Adams refers to this dawning time as the “imagination era.” Meaning: Individuals and enterprises must be able to turn creativity into action with AI. Canva hopes to position itself at the center of this shift with a sweeping new suite of tools. The company’s new Creative Operating System (COS) integrates AI across every layer of content creation, creating a single, comprehensive creativity platform rather than a simple, template-based design tool.“We’re entering a new era where we need to rethink how we achieve our goals,” said Adams. “We’re enabling people’s imagination and giving them the tools they need to take action.”An &#x27;engine&#x27; for creativityAdams describes Canva’s platform as a three-layer stack: The top Visual Suite layer containing designs, images and other content; a collaborative Canva AI plane at center; and a foundational proprietary model holding it all up. At the heart of Canva’s strategy is its Creative Operating System (COS) underlying. This “engine,” as Adams describes it, integrates documents, websites, presentations, sheets, whiteboards, videos, social content, hundreds of millions of photos, illustrations, a rich sound library, and numerous templates, charts, and branded elements.The COS is getting a 2.0 upgrade, but the crucial advance is the “middle, crucial layer” that fully integrates AI and makes it accessible throughout various workflows, Adams explained. This gives creative and technical teams a single dashboard for generating, editing and launching all types of content.The underlying model is trained to understand the “complexity of design” so the platform can build out various elements — such as photos, videos, textures, or 3D graphics — in real time, matching branding style without the need for manual adjustments. It also supports live collaboration, meaning teams across departments can co-create. With a unified dashboard, a user working on a specific design, for instance, can create a new piece of content (say, a presentation) within the same workflow, without having to switch to another window or platform. Also, if they generate an image and aren’t pleased with it, they don’t have to go back and create from scratch; they can immediately begin editing, changing colors or tone. Another new capability in COS, “Ask Canva,” provides direct design advice. Users can tag @Canva to get copy suggestions and smart edits; or, they can highlight an image and direct the AI assistant to modify it or generate variants. “It’s a really unique interaction,” said Adams, noting that this AI design partner is always present. “It’s a real collaboration between people and AI, and we think it’s a revolutionary change.”Other new features include a 2.0 video editor and interactive form and email design with drag-and-drop tools. Further, Canva is now incorporated with Affinity, its unified app for pro designers incorporating vector, pixel and layer workflows, and Affinity is “free forever.” Automating intelligence, supporting marketingBranding is critical for enterprise; Canva has introduced new tools to help organizations consistently showcase theirs across platforms. The new Canva Grow engine integrates business objectives into the creative process so teams can workshop, create, distribute and refine ads and other materials. As Adams explained: “It automatically scans your website, figures out who your audience is, what assets you use to promote your products, the message it needs to send out, the formats you want to send it out in, makes a creative for you, and you can deploy it directly to the platform without having to leave Canva.”Marketing teams can now design and launch ads across platforms like Meta, track insights as they happen and refine future content based on performance metrics. “Your brand system is now available inside the AI you’re working with,” Adams noted. Success metrics and enterprise adoptionThe impact of Canva’s COS is reflected in notable user metrics: More than 250 million people use Canva every month, just over 29 million of which are paid subscribers. Adams reports that 41 billion designs have been created on Canva since launch, which equates to 1 billion each month. “If you break that down, it turns into the crazy number of 386 designs being created every single second,” said Adams. Whereas in the early days, it took roughly an hour for users to create a single design. Canva customers include Walmart, Disney, Virgin Voyages, Pinterest, FedEx, Expedia and eXp Realty. DocuSign, for one, reported that it unlocked more than 500 hours of team capacity and saved $300,000-plus in design hours by fully integrating Canva into its content creation. Disney, meanwhile, uses translation capabilities for its internationalization work, Adams said. Competitors in the design spaceCanva plays in an evolving landscape of professional design tools including Adobe Express and Figma; AI-powered challengers led by Microsoft Designer; and direct consumer alternatives like Visme and Piktochart.Adobe Express (starting at $9.99 a month for premium features) is known for its ease of use and integration with the broader Adobe Creative Cloud ecosystem. It features professional-grade templates and access to Adobe’s extensive stock library, and has incorporated Google&#x27;s Gemini 2.5 Flash image model and other gen AI features so that designers can create graphics via natural language prompts. Users with some design experience say they prefer its interface, controls and technical advantages over Canva (such as the ability to import high-fidelity PDFs). Figma (starting at $3 a month for professional plans) is touted for its real-time collaboration, advanced prototyping capabilities and deep integration with dev workflows; however, some say it has a steeper learning curve and higher-precision design tools, making it preferable for professional designers, developers and product teams working on more complex projects. Microsoft Designer (free version available; although a Microsoft 365 subscription starting at $9.99 a month unlocks additional features) benefits from its integration with Microsoft’s AI capabilities, Copilot layout and text generation and Dall-E powered image generation. The platform’s “Inspire Me” and “New Ideas” buttons provide design variations, and users can also import data from Excel, add 3D models from PowerPoint and access images from OneDrive. However, users report that its stock photos and template and image libraries are limited compared to Canva&#x27;s extensive collection, and its visuals can come across as outdated. Canva’s advantage seems to be in its extensive template library (more than 600,000 ready-to-use) and asset library (141 million-plus stock photos, videos, graphics, and audio elements).​ Its platform is also praised for its ease of use and interface friendly to non-designers, allowing them to begin quickly without training. Canva has also expanded into a variety of content types — documents, websites, presentations, whiteboards, videos, and more — making its platform a comprehensive visual suite than just a graphics tool. Canva has four pricing tiers: Canva Free for one user; Canva Pro for $120 a year for one person; Canva Teams for $100 a year for each team member; and the custom-priced Canva Enterprise. Key takeaways: Be open, embrace human-AI collaborationCanva’s COS is underpinned by Canva’s frontier model, an in-house, proprietary engine based on years of R&D and research partnerships, including the acquisition of visual AI company Leonardo. Adams notes that Canva works with top AI providers including OpenAI, Anthropic and Google. For technology teams, Canva’s approach offers important lessons, including a commitment to openness. “There are so many models floating around,” Adams noted; it’s important for enterprises to recognize when they should work with top models and when they should develop their own proprietary ones, he advised. For instance, OpenAI and Anthropic recently announced integrations with Canva as a visual layer because, as Adams explained, they realized they didn’t have the capability to create the same kinds of editable designs that Canva can. This creates a mutually-beneficial ecosystem. Ultimately, Adams noted: “We have this underlying philosophy that the future is people and technology working together. It&#x27;s not an either or. We want people to be at the center, to be the ones with the creative spark, and to use AI as a collaborator.”",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5RueUd7BFZZvUTu1HpMex9/651bfe1010eda474b8f737d42e7354ca/Canva.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/meta-researchers-open-the-llm-black-box-to-repair-flawed-ai-reasoning",
          "published_at": "Thu, 30 Oct 2025 00:00:00 GMT",
          "title": "Meta researchers open the LLM black box to repair flawed AI reasoning",
          "standfirst": "Researchers at Meta FAIR and the University of Edinburgh have developed a new technique that can predict the correctness of a large language model&#x27;s (LLM) reasoning and even intervene to fix its mistakes. Called Circuit-based Reasoning Verification (CRV), the method looks inside an LLM to monitor its internal “reasoning circuits” and detect signs of computational errors as the model solves a problem.Their findings show that CRV can detect reasoning errors in LLMs with high accuracy by building and observing a computational graph from the model&#x27;s internal activations. In a key breakthrough, the researchers also demonstrated they can use this deep insight to apply targeted interventions that correct a model’s faulty reasoning on the fly.The technique could help solve one of the great challenges of AI: Ensuring a model’s reasoning is faithful and correct. This could be a critical step toward building more trustworthy AI applications for the enterprise, where reliability is paramount.Investigating chain-of-thought reasoningChain-of-thought (CoT) reasoning has been a powerful method for boosting the performance of LLMs on complex tasks and has been one of the key ingredients in the success of reasoning models such as the OpenAI o-series and DeepSeek-R1. However, despite the success of CoT, it is not fully reliable. The reasoning process itself is often flawed, and several studies have shown that the CoT tokens an LLM generates is not always a faithful representation of its internal reasoning process.Current remedies for verifying CoT fall into two main categories. “Black-box” approaches analyze the final generated token or the confidence scores of different token options. “Gray-box” approaches go a step further, looking at the model&#x27;s internal state by using simple probes on its raw neural activations. But while these methods can detect that a model’s internal state is correlated with an error, they can&#x27;t explain why the underlying computation failed. For real-world applications where understanding the root cause of a failure is crucial, this is a significant gap.A white-box approach to verificationCRV is based on the idea that models perform tasks using specialized subgraphs, or \"circuits,\" of neurons that function like latent algorithms. So if the model’s reasoning fails, it is caused by a flaw in the execution of one of these algorithms. This means that by inspecting the underlying computational process, we can diagnose the cause of the flaw, similar to how developers examine execution traces to debug traditional software.To make this possible, the researchers first make the target LLM interpretable. They replace the standard dense layers of the transformer blocks with trained \"transcoders.\" A transcoder is a specialized deep learning component that forces the model to represent its intermediate computations not as a dense, unreadable vector of numbers, but as a sparse and meaningful set of features. Transcoders are similar to the sparse autoencoders (SAE) used in mechanistic interpretability research with the difference that they also preserve the functionality of the network they emulate. This modification effectively installs a diagnostic port into the model, allowing researchers to observe its internal workings.With this interpretable model in place, the CRV process unfolds in a few steps. For each reasoning step the model takes, CRV constructs an \"attribution graph\" that maps the causal flow of information between the interpretable features of the transcoder and the tokens it is processing. From this graph, it extracts a \"structural fingerprint\" that contains a set of features describing the graph&#x27;s properties. Finally, a “diagnostic classifier” model is trained on these fingerprints to predict whether the reasoning step is correct or not.At inference time, the classifier monitors the activations of the model and provides feedback on whether the model’s reasoning trace is on the right track.Finding and fixing errorsThe researchers tested their method on a Llama 3.1 8B Instruct model modified with the transcoders, evaluating it on a mix of synthetic (Boolean and Arithmetic) and real-world (GSM8K math problems) datasets. They compared CRV against a comprehensive suite of black-box and gray-box baselines.The results provide strong empirical support for the central hypothesis: the structural signatures in a reasoning step&#x27;s computational trace contain a verifiable signal of its correctness. CRV consistently outperformed all baseline methods across every dataset and metric, demonstrating that a deep, structural view of the model&#x27;s computation is more powerful than surface-level analysis.Interestingly, the analysis revealed that the signatures of error are highly domain-specific. This means failures in different reasoning tasks (formal logic versus arithmetic calculation) manifest as distinct computational patterns. A classifier trained to detect errors in one domain does not transfer well to another, highlighting that different types of reasoning rely on different internal circuits. In practice, this means that you might need to train a separate classifier for each task (though the transcoder remains unchanged).The most significant finding, however, is that these error signatures are not just correlational but causal. Because CRV provides a transparent view of the computation, a predicted failure can be traced back to a specific component. In one case study, the model made an order-of-operations error. CRV flagged the step and identified that a \"multiplication\" feature was firing prematurely. The researchers intervened by manually suppressing that single feature, and the model immediately corrected its path and solved the problem correctly. This work represents a step toward a more rigorous science of AI interpretability and control. As the paper concludes, “these findings establish CRV as a proof-of-concept for mechanistic analysis, showing that shifting from opaque activations to interpretable computational structure enables a causal understanding of how and why LLMs fail to reason correctly.” To support further research, the team plans to release its datasets and trained transcoders to the public.Why it’s importantWhile CRV is a research proof-of-concept, its results hint at a significant future for AI development. AI models learn internal algorithms, or \"circuits,\" for different tasks. But because these models are opaque, we can&#x27;t debug them like standard computer programs by tracing bugs to specific steps in the computation. Attribution graphs are the closest thing we have to an execution trace, showing how an output is derived from intermediate steps.This research suggests that attribution graphs could be the foundation for a new class of AI model debuggers. Such tools would allow developers to understand the root cause of failures, whether it&#x27;s insufficient training data or interference between competing tasks. This would enable precise mitigations, like targeted fine-tuning or even direct model editing, instead of costly full-scale retraining. They could also allow for more efficient intervention to correct model mistakes during inference.The success of CRV in detecting and pinpointing reasoning errors is an encouraging sign that such debuggers could become a reality. This would pave the way for more robust LLMs and autonomous agents that can handle real-world unpredictability and, much like humans, correct course when they make reasoning mistakes.",
          "content": "Researchers at Meta FAIR and the University of Edinburgh have developed a new technique that can predict the correctness of a large language model&#x27;s (LLM) reasoning and even intervene to fix its mistakes. Called Circuit-based Reasoning Verification (CRV), the method looks inside an LLM to monitor its internal “reasoning circuits” and detect signs of computational errors as the model solves a problem.Their findings show that CRV can detect reasoning errors in LLMs with high accuracy by building and observing a computational graph from the model&#x27;s internal activations. In a key breakthrough, the researchers also demonstrated they can use this deep insight to apply targeted interventions that correct a model’s faulty reasoning on the fly.The technique could help solve one of the great challenges of AI: Ensuring a model’s reasoning is faithful and correct. This could be a critical step toward building more trustworthy AI applications for the enterprise, where reliability is paramount.Investigating chain-of-thought reasoningChain-of-thought (CoT) reasoning has been a powerful method for boosting the performance of LLMs on complex tasks and has been one of the key ingredients in the success of reasoning models such as the OpenAI o-series and DeepSeek-R1. However, despite the success of CoT, it is not fully reliable. The reasoning process itself is often flawed, and several studies have shown that the CoT tokens an LLM generates is not always a faithful representation of its internal reasoning process.Current remedies for verifying CoT fall into two main categories. “Black-box” approaches analyze the final generated token or the confidence scores of different token options. “Gray-box” approaches go a step further, looking at the model&#x27;s internal state by using simple probes on its raw neural activations. But while these methods can detect that a model’s internal state is correlated with an error, they can&#x27;t explain why the underlying computation failed. For real-world applications where understanding the root cause of a failure is crucial, this is a significant gap.A white-box approach to verificationCRV is based on the idea that models perform tasks using specialized subgraphs, or \"circuits,\" of neurons that function like latent algorithms. So if the model’s reasoning fails, it is caused by a flaw in the execution of one of these algorithms. This means that by inspecting the underlying computational process, we can diagnose the cause of the flaw, similar to how developers examine execution traces to debug traditional software.To make this possible, the researchers first make the target LLM interpretable. They replace the standard dense layers of the transformer blocks with trained \"transcoders.\" A transcoder is a specialized deep learning component that forces the model to represent its intermediate computations not as a dense, unreadable vector of numbers, but as a sparse and meaningful set of features. Transcoders are similar to the sparse autoencoders (SAE) used in mechanistic interpretability research with the difference that they also preserve the functionality of the network they emulate. This modification effectively installs a diagnostic port into the model, allowing researchers to observe its internal workings.With this interpretable model in place, the CRV process unfolds in a few steps. For each reasoning step the model takes, CRV constructs an \"attribution graph\" that maps the causal flow of information between the interpretable features of the transcoder and the tokens it is processing. From this graph, it extracts a \"structural fingerprint\" that contains a set of features describing the graph&#x27;s properties. Finally, a “diagnostic classifier” model is trained on these fingerprints to predict whether the reasoning step is correct or not.At inference time, the classifier monitors the activations of the model and provides feedback on whether the model’s reasoning trace is on the right track.Finding and fixing errorsThe researchers tested their method on a Llama 3.1 8B Instruct model modified with the transcoders, evaluating it on a mix of synthetic (Boolean and Arithmetic) and real-world (GSM8K math problems) datasets. They compared CRV against a comprehensive suite of black-box and gray-box baselines.The results provide strong empirical support for the central hypothesis: the structural signatures in a reasoning step&#x27;s computational trace contain a verifiable signal of its correctness. CRV consistently outperformed all baseline methods across every dataset and metric, demonstrating that a deep, structural view of the model&#x27;s computation is more powerful than surface-level analysis.Interestingly, the analysis revealed that the signatures of error are highly domain-specific. This means failures in different reasoning tasks (formal logic versus arithmetic calculation) manifest as distinct computational patterns. A classifier trained to detect errors in one domain does not transfer well to another, highlighting that different types of reasoning rely on different internal circuits. In practice, this means that you might need to train a separate classifier for each task (though the transcoder remains unchanged).The most significant finding, however, is that these error signatures are not just correlational but causal. Because CRV provides a transparent view of the computation, a predicted failure can be traced back to a specific component. In one case study, the model made an order-of-operations error. CRV flagged the step and identified that a \"multiplication\" feature was firing prematurely. The researchers intervened by manually suppressing that single feature, and the model immediately corrected its path and solved the problem correctly. This work represents a step toward a more rigorous science of AI interpretability and control. As the paper concludes, “these findings establish CRV as a proof-of-concept for mechanistic analysis, showing that shifting from opaque activations to interpretable computational structure enables a causal understanding of how and why LLMs fail to reason correctly.” To support further research, the team plans to release its datasets and trained transcoders to the public.Why it’s importantWhile CRV is a research proof-of-concept, its results hint at a significant future for AI development. AI models learn internal algorithms, or \"circuits,\" for different tasks. But because these models are opaque, we can&#x27;t debug them like standard computer programs by tracing bugs to specific steps in the computation. Attribution graphs are the closest thing we have to an execution trace, showing how an output is derived from intermediate steps.This research suggests that attribution graphs could be the foundation for a new class of AI model debuggers. Such tools would allow developers to understand the root cause of failures, whether it&#x27;s insufficient training data or interference between competing tasks. This would enable precise mitigations, like targeted fine-tuning or even direct model editing, instead of costly full-scale retraining. They could also allow for more efficient intervention to correct model mistakes during inference.The success of CRV in detecting and pinpointing reasoning errors is an encouraging sign that such debuggers could become a reality. This would pave the way for more robust LLMs and autonomous agents that can handle real-world unpredictability and, much like humans, correct course when they make reasoning mistakes.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2OkRgL73ZtEWb7eTlVXcOQ/07d98278f0ffa3fe571924f478e410a1/LLM_reasoning.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-expressvpn-surfshark-and-more-120056432.html",
          "published_at": "Wed, 29 Oct 2025 21:54:57 +0000",
          "title": "The best VPN deals: 88 percent discounts on ProtonVPN, ExpressVPN, Surfshark and more",
          "standfirst": "A virtual private network (VPN) is useful in several ways — a good one can stream foreign TV shows and events, save you from giving up information to hackers and keep you anonymous to protect against online tracking. Although we strongly recommend using a VPN, a bit of comparison shopping goes a long way in this market. VPN pricing can be opaque, and providers don't always portray their best deals accurately. Even so, there are genuinely great bargains on the table. VPN providers give out deep discounts to customers who sign up for a year or more at a time. This lets them boost their subscriber numbers, but it's a win for you as well — while you pay out more upfront, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-expressvpn-surfshark-and-more-120056432.html?src=rss",
          "content": "A virtual private network (VPN) is useful in several ways — a good one can stream foreign TV shows and events, save you from giving up information to hackers and keep you anonymous to protect against online tracking. Although we strongly recommend using a VPN, a bit of comparison shopping goes a long way in this market. VPN pricing can be opaque, and providers don't always portray their best deals accurately. Even so, there are genuinely great bargains on the table. VPN providers give out deep discounts to customers who sign up for a year or more at a time. This lets them boost their subscriber numbers, but it's a win for you as well — while you pay out more upfront, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-expressvpn-surfshark-and-more-120056432.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/vibe-coding-platform-cursor-releases-first-in-house-llm-composer-promising",
          "published_at": "Wed, 29 Oct 2025 19:28:00 GMT",
          "title": "Vibe coding platform Cursor releases first in-house LLM, Composer, promising 4X speed boost",
          "standfirst": "The vibe coding tool Cursor, from startup Anysphere, has introduced Composer, its first in-house, proprietary coding large language model (LLM) as part of its Cursor 2.0 platform update. Composer is designed to execute coding tasks quickly and accurately in production-scale environments, representing a new step in AI-assisted programming. It&#x27;s already being used by Cursor’s own engineering staff in day-to-day development — indicating maturity and stability.According to Cursor, Composer completes most interactions in less than 30 seconds while maintaining a high level of reasoning ability across large and complex codebases. The model is described as four times faster than similarly intelligent systems and is trained for “agentic” workflows—where autonomous coding agents plan, write, test, and review code collaboratively.Previously, Cursor supported \"vibe coding\" — using AI to write or complete code based on natural language instructions from a user, even someone untrained in development — atop other leading proprietary LLMs from the likes of OpenAI, Anthropic, Google, and xAI. These options are still available to users.Benchmark ResultsComposer’s capabilities are benchmarked using \"Cursor Bench,\" an internal evaluation suite derived from real developer agent requests. The benchmark measures not just correctness, but also the model’s adherence to existing abstractions, style conventions, and engineering practices.On this benchmark, Composer achieves frontier-level coding intelligence while generating at 250 tokens per second — about twice as fast as leading fast-inference models and four times faster than comparable frontier systems.Cursor’s published comparison groups models into several categories: “Best Open” (e.g., Qwen Coder, GLM 4.6), “Fast Frontier” (Haiku 4.5, Gemini Flash 2.5), “Frontier 7/2025” (the strongest model available midyear), and “Best Frontier” (including GPT-5 and Claude Sonnet 4.5). Composer matches the intelligence of mid-frontier systems while delivering the highest recorded generation speed among all tested classes.A Model Built with Reinforcement Learning and Mixture-of-Experts ArchitectureResearch scientist Sasha Rush of Cursor provided insight into the model’s development in posts on the social network X, describing Composer as a reinforcement-learned (RL) mixture-of-experts (MoE) model:“We used RL to train a big MoE model to be really good at real-world coding, and also very fast.”Rush explained that the team co-designed both Composer and the Cursor environment to allow the model to operate efficiently at production scale:“Unlike other ML systems, you can’t abstract much from the full-scale system. We co-designed this project and Cursor together in order to allow running the agent at the necessary scale.”Composer was trained on real software engineering tasks rather than static datasets. During training, the model operated inside full codebases using a suite of production tools—including file editing, semantic search, and terminal commands—to solve complex engineering problems. Each training iteration involved solving a concrete challenge, such as producing a code edit, drafting a plan, or generating a targeted explanation.The reinforcement loop optimized both correctness and efficiency. Composer learned to make effective tool choices, use parallelism, and avoid unnecessary or speculative responses. Over time, the model developed emergent behaviors such as running unit tests, fixing linter errors, and performing multi-step code searches autonomously.This design enables Composer to work within the same runtime context as the end-user, making it more aligned with real-world coding conditions—handling version control, dependency management, and iterative testing.From Prototype to ProductionComposer’s development followed an earlier internal prototype known as Cheetah, which Cursor used to explore low-latency inference for coding tasks.“Cheetah was the v0 of this model primarily to test speed,” Rush said on X. “Our metrics say it [Composer] is the same speed, but much, much smarter.”Cheetah’s success at reducing latency helped Cursor identify speed as a key factor in developer trust and usability. Composer maintains that responsiveness while significantly improving reasoning and task generalization.Developers who used Cheetah during early testing noted that its speed changed how they worked. One user commented that it was “so fast that I can stay in the loop when working with it.” Composer retains that speed but extends capability to multi-step coding, refactoring, and testing tasks.Integration with Cursor 2.0Composer is fully integrated into Cursor 2.0, a major update to the company’s agentic development environment. The platform introduces a multi-agent interface, allowing up to eight agents to run in parallel, each in an isolated workspace using git worktrees or remote machines.Within this system, Composer can serve as one or more of those agents, performing tasks independently or collaboratively. Developers can compare multiple results from concurrent agent runs and select the best output.Cursor 2.0 also includes supporting features that enhance Composer’s effectiveness:In-Editor Browser (GA) – enables agents to run and test their code directly inside the IDE, forwarding DOM information to the model.Improved Code Review – aggregates diffs across multiple files for faster inspection of model-generated changes.Sandboxed Terminals (GA) – isolate agent-run shell commands for secure local execution.Voice Mode – adds speech-to-text controls for initiating or managing agent sessions.While these platform updates expand the overall Cursor experience, Composer is positioned as the technical core enabling fast, reliable agentic coding.Infrastructure and Training SystemsTo train Composer at scale, Cursor built a custom reinforcement learning infrastructure combining PyTorch and Ray for asynchronous training across thousands of NVIDIA GPUs. The team developed specialized MXFP8 MoE kernels and hybrid sharded data parallelism, enabling large-scale model updates with minimal communication overhead.This configuration allows Cursor to train models natively at low precision without requiring post-training quantization, improving both inference speed and efficiency. Composer’s training relied on hundreds of thousands of concurrent sandboxed environments—each a self-contained coding workspace—running in the cloud. The company adapted its Background Agents infrastructure to schedule these virtual machines dynamically, supporting the bursty nature of large RL runs.Enterprise UseComposer’s performance improvements are supported by infrastructure-level changes across Cursor’s code intelligence stack. The company has optimized its Language Server Protocols (LSPs) for faster diagnostics and navigation, especially in Python and TypeScript projects. These changes reduce latency when Composer interacts with large repositories or generates multi-file updates.Enterprise users gain administrative control over Composer and other agents through team rules, audit logs, and sandbox enforcement. Cursor’s Teams and Enterprise tiers also support pooled model usage, SAML/OIDC authentication, and analytics for monitoring agent performance across organizations.Pricing for individual users ranges from Free (Hobby) to Ultra ($200/month) tiers, with expanded usage limits for Pro+ and Ultra subscribers. Business pricing starts at $40 per user per month for Teams, with enterprise contracts offering custom usage and compliance options.Composer’s Role in the Evolving AI Coding LandscapeComposer’s focus on speed, reinforcement learning, and integration with live coding workflows differentiates it from other AI development assistants such as GitHub Copilot or Replit’s Agent. Rather than serving as a passive suggestion engine, Composer is designed for continuous, agent-driven collaboration, where multiple autonomous systems interact directly with a project’s codebase.This model-level specialization—training AI to function within the real environment it will operate in—represents a significant step toward practical, autonomous software development. Composer is not trained only on text data or static code, but within a dynamic IDE that mirrors production conditions.Rush described this approach as essential to achieving real-world reliability: the model learns not just how to generate code, but how to integrate, test, and improve it in context.What It Means for Enterprise Devs and Vibe CodingWith Composer, Cursor is introducing more than a fast model—it’s deploying an AI system optimized for real-world use, built to operate inside the same tools developers already rely on. The combination of reinforcement learning, mixture-of-experts design, and tight product integration gives Composer a practical edge in speed and responsiveness that sets it apart from general-purpose language models.While Cursor 2.0 provides the infrastructure for multi-agent collaboration, Composer is the core innovation that makes those workflows viable. It’s the first coding model built specifically for agentic, production-level coding—and an early glimpse of what everyday programming could look like when human developers and autonomous models share the same workspace.",
          "content": "The vibe coding tool Cursor, from startup Anysphere, has introduced Composer, its first in-house, proprietary coding large language model (LLM) as part of its Cursor 2.0 platform update. Composer is designed to execute coding tasks quickly and accurately in production-scale environments, representing a new step in AI-assisted programming. It&#x27;s already being used by Cursor’s own engineering staff in day-to-day development — indicating maturity and stability.According to Cursor, Composer completes most interactions in less than 30 seconds while maintaining a high level of reasoning ability across large and complex codebases. The model is described as four times faster than similarly intelligent systems and is trained for “agentic” workflows—where autonomous coding agents plan, write, test, and review code collaboratively.Previously, Cursor supported \"vibe coding\" — using AI to write or complete code based on natural language instructions from a user, even someone untrained in development — atop other leading proprietary LLMs from the likes of OpenAI, Anthropic, Google, and xAI. These options are still available to users.Benchmark ResultsComposer’s capabilities are benchmarked using \"Cursor Bench,\" an internal evaluation suite derived from real developer agent requests. The benchmark measures not just correctness, but also the model’s adherence to existing abstractions, style conventions, and engineering practices.On this benchmark, Composer achieves frontier-level coding intelligence while generating at 250 tokens per second — about twice as fast as leading fast-inference models and four times faster than comparable frontier systems.Cursor’s published comparison groups models into several categories: “Best Open” (e.g., Qwen Coder, GLM 4.6), “Fast Frontier” (Haiku 4.5, Gemini Flash 2.5), “Frontier 7/2025” (the strongest model available midyear), and “Best Frontier” (including GPT-5 and Claude Sonnet 4.5). Composer matches the intelligence of mid-frontier systems while delivering the highest recorded generation speed among all tested classes.A Model Built with Reinforcement Learning and Mixture-of-Experts ArchitectureResearch scientist Sasha Rush of Cursor provided insight into the model’s development in posts on the social network X, describing Composer as a reinforcement-learned (RL) mixture-of-experts (MoE) model:“We used RL to train a big MoE model to be really good at real-world coding, and also very fast.”Rush explained that the team co-designed both Composer and the Cursor environment to allow the model to operate efficiently at production scale:“Unlike other ML systems, you can’t abstract much from the full-scale system. We co-designed this project and Cursor together in order to allow running the agent at the necessary scale.”Composer was trained on real software engineering tasks rather than static datasets. During training, the model operated inside full codebases using a suite of production tools—including file editing, semantic search, and terminal commands—to solve complex engineering problems. Each training iteration involved solving a concrete challenge, such as producing a code edit, drafting a plan, or generating a targeted explanation.The reinforcement loop optimized both correctness and efficiency. Composer learned to make effective tool choices, use parallelism, and avoid unnecessary or speculative responses. Over time, the model developed emergent behaviors such as running unit tests, fixing linter errors, and performing multi-step code searches autonomously.This design enables Composer to work within the same runtime context as the end-user, making it more aligned with real-world coding conditions—handling version control, dependency management, and iterative testing.From Prototype to ProductionComposer’s development followed an earlier internal prototype known as Cheetah, which Cursor used to explore low-latency inference for coding tasks.“Cheetah was the v0 of this model primarily to test speed,” Rush said on X. “Our metrics say it [Composer] is the same speed, but much, much smarter.”Cheetah’s success at reducing latency helped Cursor identify speed as a key factor in developer trust and usability. Composer maintains that responsiveness while significantly improving reasoning and task generalization.Developers who used Cheetah during early testing noted that its speed changed how they worked. One user commented that it was “so fast that I can stay in the loop when working with it.” Composer retains that speed but extends capability to multi-step coding, refactoring, and testing tasks.Integration with Cursor 2.0Composer is fully integrated into Cursor 2.0, a major update to the company’s agentic development environment. The platform introduces a multi-agent interface, allowing up to eight agents to run in parallel, each in an isolated workspace using git worktrees or remote machines.Within this system, Composer can serve as one or more of those agents, performing tasks independently or collaboratively. Developers can compare multiple results from concurrent agent runs and select the best output.Cursor 2.0 also includes supporting features that enhance Composer’s effectiveness:In-Editor Browser (GA) – enables agents to run and test their code directly inside the IDE, forwarding DOM information to the model.Improved Code Review – aggregates diffs across multiple files for faster inspection of model-generated changes.Sandboxed Terminals (GA) – isolate agent-run shell commands for secure local execution.Voice Mode – adds speech-to-text controls for initiating or managing agent sessions.While these platform updates expand the overall Cursor experience, Composer is positioned as the technical core enabling fast, reliable agentic coding.Infrastructure and Training SystemsTo train Composer at scale, Cursor built a custom reinforcement learning infrastructure combining PyTorch and Ray for asynchronous training across thousands of NVIDIA GPUs. The team developed specialized MXFP8 MoE kernels and hybrid sharded data parallelism, enabling large-scale model updates with minimal communication overhead.This configuration allows Cursor to train models natively at low precision without requiring post-training quantization, improving both inference speed and efficiency. Composer’s training relied on hundreds of thousands of concurrent sandboxed environments—each a self-contained coding workspace—running in the cloud. The company adapted its Background Agents infrastructure to schedule these virtual machines dynamically, supporting the bursty nature of large RL runs.Enterprise UseComposer’s performance improvements are supported by infrastructure-level changes across Cursor’s code intelligence stack. The company has optimized its Language Server Protocols (LSPs) for faster diagnostics and navigation, especially in Python and TypeScript projects. These changes reduce latency when Composer interacts with large repositories or generates multi-file updates.Enterprise users gain administrative control over Composer and other agents through team rules, audit logs, and sandbox enforcement. Cursor’s Teams and Enterprise tiers also support pooled model usage, SAML/OIDC authentication, and analytics for monitoring agent performance across organizations.Pricing for individual users ranges from Free (Hobby) to Ultra ($200/month) tiers, with expanded usage limits for Pro+ and Ultra subscribers. Business pricing starts at $40 per user per month for Teams, with enterprise contracts offering custom usage and compliance options.Composer’s Role in the Evolving AI Coding LandscapeComposer’s focus on speed, reinforcement learning, and integration with live coding workflows differentiates it from other AI development assistants such as GitHub Copilot or Replit’s Agent. Rather than serving as a passive suggestion engine, Composer is designed for continuous, agent-driven collaboration, where multiple autonomous systems interact directly with a project’s codebase.This model-level specialization—training AI to function within the real environment it will operate in—represents a significant step toward practical, autonomous software development. Composer is not trained only on text data or static code, but within a dynamic IDE that mirrors production conditions.Rush described this approach as essential to achieving real-world reliability: the model learns not just how to generate code, but how to integrate, test, and improve it in context.What It Means for Enterprise Devs and Vibe CodingWith Composer, Cursor is introducing more than a fast model—it’s deploying an AI system optimized for real-world use, built to operate inside the same tools developers already rely on. The combination of reinforcement learning, mixture-of-experts design, and tight product integration gives Composer a practical edge in speed and responsiveness that sets it apart from general-purpose language models.While Cursor 2.0 provides the infrastructure for multi-agent collaboration, Composer is the core innovation that makes those workflows viable. It’s the first coding model built specifically for agentic, production-level coding—and an early glimpse of what everyday programming could look like when human developers and autonomous models share the same workspace.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3XICNbOGJJDY7SoZx0m1SV/4b4ec66e5aa6a03194e432369e6e6ac8/cfr0z3n_flat_illustration_elegant_constructivist_1920s_art_deco_6818187a-93ac-437e-af85-43b96b2507a5.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/early-access-for-gemini-home-voice-assistant-is-now-available-heres-how-to-get-it-191250927.html",
          "published_at": "Wed, 29 Oct 2025 19:12:50 +0000",
          "title": "Early access for Gemini Home voice assistant is now available. Here's how to get it",
          "standfirst": "A decade ago, when smart speakers with built-in voice assistants were the hot new thing, many imagined they'd quickly evolve into highly intelligent companions. (Think C-3PO or Star Trek's Data living inside a speaker.) That road has been much longer than expected, as virtual helpers like Alexa, Siri and Google Assistant seemed to sit in neutral for years. But now that generative AI is here (for better or worse), smart speakers are finally scratching the surface of those expectations. Google's new version, Gemini for Home, is now available to try. Here's how. First, keep in mind that the Gemini for Home voice assistant is in early access. This means Google is gathering feedback about its features, and — as with all generative AI — it's wise to assume it will make mistakes. If or when it does, you can send feedback to Google in the Google Home app or by saying, \"Hey Google, send feedback.\" Devices compatible with Gemini for Home voice assistant You'll also want to check your speaker model before diving in. The full Gemini for Home experience is available to try on the Google Nest Hub (2nd gen), Google Nest Audio, Google Nest Mini (2nd gen) and Google Nest Hub Max. Those models all support Gemini Live, which enables conversational back-and-forth chat with natural follow-up questions. Other models support everything but Gemini Live. That list includes the Google Nest Wifi point, Google Nest Hub (1st gen), Google Home Max, Google Home Mini (1st gen) and Google Home. Another point is that once you dive in, your Google Assistant days will be over (on your speakers, anyway). That's because Google says that, once you upgrade to Gemini for Home, your compatible devices can't downgrade to Assistant. That shouldn't be a problem, but it's worth keeping in mind before you take the plunge. How to sign up for early Gemini access Once you've confirmed that your speaker(s) are at least partially compatible, head to the Google Home app on a mobile device. There, tap your profile picture (or initials) on the top right. Then tap Home Settings > Early Access. Congratulations: You've put in your request. The bad news is you may have to wait a bit to confirm your entry into the beta program. Once you're in, you'll see a notification from the Google Home app that reads, \"Introducing Gemini for Home.\" Select that, and follow the prompts. (If you accidentally dismiss the notification, you'll see the setup banner under Home settings in the Google Home app.) Cherlynn Low for Engadget At that point, all compatible speakers in your home will be upgraded to Google's more intelligent AI assistant. You can now throw more advanced questions at it, similar to what you'd ask text-based chatbots like ChatGPT. Except this one sits on a shelf, ready to field your verbal requests at any moment. Keep in mind that Gemini Live requires a Google Home Premium subscription. The standard version costs $10 per month or $100 per year. Meanwhile, the advanced tier doubles that: $20 per month or $200 per year. At least for now, the only difference between the two (for these purposes) is that the pricier plan supports a camera history search feature. Both premium tiers unlock access to Gemini Live. So, if that's all you need, you can save money and get standard. Google offers plenty of examples to get started. You can get quick answers to facts, like \"Hey Google, who are the top five scoring players in basketball history?\" (FYI: James, Abdul-Jabbar, Malone, Bryant and Jordan.) You can also ask Gemini Live to have a chat about ingredients for people with dietary needs. Or, ask it to explain complex topics (like how Wi-Fi works) in simple terms. It may not be at C-3PO level yet, but it's certainly moving in that direction.This article originally appeared on Engadget at https://www.engadget.com/ai/early-access-for-gemini-home-voice-assistant-is-now-available-heres-how-to-get-it-191250927.html?src=rss",
          "content": "A decade ago, when smart speakers with built-in voice assistants were the hot new thing, many imagined they'd quickly evolve into highly intelligent companions. (Think C-3PO or Star Trek's Data living inside a speaker.) That road has been much longer than expected, as virtual helpers like Alexa, Siri and Google Assistant seemed to sit in neutral for years. But now that generative AI is here (for better or worse), smart speakers are finally scratching the surface of those expectations. Google's new version, Gemini for Home, is now available to try. Here's how. First, keep in mind that the Gemini for Home voice assistant is in early access. This means Google is gathering feedback about its features, and — as with all generative AI — it's wise to assume it will make mistakes. If or when it does, you can send feedback to Google in the Google Home app or by saying, \"Hey Google, send feedback.\" Devices compatible with Gemini for Home voice assistant You'll also want to check your speaker model before diving in. The full Gemini for Home experience is available to try on the Google Nest Hub (2nd gen), Google Nest Audio, Google Nest Mini (2nd gen) and Google Nest Hub Max. Those models all support Gemini Live, which enables conversational back-and-forth chat with natural follow-up questions. Other models support everything but Gemini Live. That list includes the Google Nest Wifi point, Google Nest Hub (1st gen), Google Home Max, Google Home Mini (1st gen) and Google Home. Another point is that once you dive in, your Google Assistant days will be over (on your speakers, anyway). That's because Google says that, once you upgrade to Gemini for Home, your compatible devices can't downgrade to Assistant. That shouldn't be a problem, but it's worth keeping in mind before you take the plunge. How to sign up for early Gemini access Once you've confirmed that your speaker(s) are at least partially compatible, head to the Google Home app on a mobile device. There, tap your profile picture (or initials) on the top right. Then tap Home Settings > Early Access. Congratulations: You've put in your request. The bad news is you may have to wait a bit to confirm your entry into the beta program. Once you're in, you'll see a notification from the Google Home app that reads, \"Introducing Gemini for Home.\" Select that, and follow the prompts. (If you accidentally dismiss the notification, you'll see the setup banner under Home settings in the Google Home app.) Cherlynn Low for Engadget At that point, all compatible speakers in your home will be upgraded to Google's more intelligent AI assistant. You can now throw more advanced questions at it, similar to what you'd ask text-based chatbots like ChatGPT. Except this one sits on a shelf, ready to field your verbal requests at any moment. Keep in mind that Gemini Live requires a Google Home Premium subscription. The standard version costs $10 per month or $100 per year. Meanwhile, the advanced tier doubles that: $20 per month or $200 per year. At least for now, the only difference between the two (for these purposes) is that the pricier plan supports a camera history search feature. Both premium tiers unlock access to Gemini Live. So, if that's all you need, you can save money and get standard. Google offers plenty of examples to get started. You can get quick answers to facts, like \"Hey Google, who are the top five scoring players in basketball history?\" (FYI: James, Abdul-Jabbar, Malone, Bryant and Jordan.) You can also ask Gemini Live to have a chat about ingredients for people with dietary needs. Or, ask it to explain complex topics (like how Wi-Fi works) in simple terms. It may not be at C-3PO level yet, but it's certainly moving in that direction.This article originally appeared on Engadget at https://www.engadget.com/ai/early-access-for-gemini-home-voice-assistant-is-now-available-heres-how-to-get-it-191250927.html?src=rss",
          "feed_position": 43,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c92cc950-b4f8-11f0-b47e-004467dd6c05"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/characterai-to-ban-teens-from-talking-to-its-chatbots-180027641.html",
          "published_at": "Wed, 29 Oct 2025 18:00:28 +0000",
          "title": "Character.AI to ban teens from talking to its chatbots",
          "standfirst": "Character.AI will no longer permit teenagers to interact with its chatbots, as AI companies face increasing pressure to better safeguard younger users from harm. In a statement, the company confirmed that it is removing the ability for users under 18 to engage in any open-ended chats with AI on its platform, which refers to back-and-forth conversations between a user and a chatbot. The changes come into effect on November 25, and until that date, Character.AI will presents users with a new under-18 experience. It'll encourage its users to use chatbots for creative purposes that might include, for example, creating videos or streams, as opposed to seeking companionship. To manage the transition, under-18s can now only interact with bots for up to two hours per day, a time limit the company says it will reduce in the lead-up to the late November deadline. Character.AI is also introducing a new age assurance tool it has developed internally, which it says will \"ensure users receive the right experience for their age.\" Along with these new protections for younger users, the company has founded an \"AI Safety Lab\" that it hopes will allow other companies, researchers and academics to share insights and work collaboratively on improving AI safety measures. Character.AI said it has listened to concerns from regulators, industry experts and concerned parents and responded with the new measures. They come after The Federal Trade Commission (FTC) recently launched a formal inquiry into AI companies that offer users access to chatbots as companions, with Character.AI named as one of seven companies that had been asked to participate. Meta, OpenAI and Snap were also included. Both Meta AI and Character AI also faced scrutiny from Texas Attorney General Ken Paxton in the summer, who said chatbots on both platforms can \"present themselves as professional therapeutic tools\" without the requisite qualifications. Seemingly to put an end to such controversy, Character.AI CEO Karandeep Anand told TechCrunch that the company’s new strategic direction will see it pivot from AI companion to a \"role-playing platform\" focused on creation rather than mere engagement-farming conversation. The dangers of young people relying on AI chatbots for guidance has been the subject of extensive reporting in recent months. Last week, the family of Adam Raine, who claim that ChatGPT enabled their 16-year-old son to take his own life, filed an amended lawsuit against OpenAI for allegedly weakening its self-harm safeguards in the lead-up to his death.This article originally appeared on Engadget at https://www.engadget.com/ai/characterai-to-ban-teens-from-talking-to-its-chatbots-180027641.html?src=rss",
          "content": "Character.AI will no longer permit teenagers to interact with its chatbots, as AI companies face increasing pressure to better safeguard younger users from harm. In a statement, the company confirmed that it is removing the ability for users under 18 to engage in any open-ended chats with AI on its platform, which refers to back-and-forth conversations between a user and a chatbot. The changes come into effect on November 25, and until that date, Character.AI will presents users with a new under-18 experience. It'll encourage its users to use chatbots for creative purposes that might include, for example, creating videos or streams, as opposed to seeking companionship. To manage the transition, under-18s can now only interact with bots for up to two hours per day, a time limit the company says it will reduce in the lead-up to the late November deadline. Character.AI is also introducing a new age assurance tool it has developed internally, which it says will \"ensure users receive the right experience for their age.\" Along with these new protections for younger users, the company has founded an \"AI Safety Lab\" that it hopes will allow other companies, researchers and academics to share insights and work collaboratively on improving AI safety measures. Character.AI said it has listened to concerns from regulators, industry experts and concerned parents and responded with the new measures. They come after The Federal Trade Commission (FTC) recently launched a formal inquiry into AI companies that offer users access to chatbots as companions, with Character.AI named as one of seven companies that had been asked to participate. Meta, OpenAI and Snap were also included. Both Meta AI and Character AI also faced scrutiny from Texas Attorney General Ken Paxton in the summer, who said chatbots on both platforms can \"present themselves as professional therapeutic tools\" without the requisite qualifications. Seemingly to put an end to such controversy, Character.AI CEO Karandeep Anand told TechCrunch that the company’s new strategic direction will see it pivot from AI companion to a \"role-playing platform\" focused on creation rather than mere engagement-farming conversation. The dangers of young people relying on AI chatbots for guidance has been the subject of extensive reporting in recent months. Last week, the family of Adam Raine, who claim that ChatGPT enabled their 16-year-old son to take his own life, filed an amended lawsuit against OpenAI for allegedly weakening its self-harm safeguards in the lead-up to his death.This article originally appeared on Engadget at https://www.engadget.com/ai/characterai-to-ban-teens-from-talking-to-its-chatbots-180027641.html?src=rss",
          "feed_position": 45
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/anthropic-scientists-hacked-claudes-brain-and-it-noticed-heres-why-thats",
          "published_at": "Wed, 29 Oct 2025 17:00:00 GMT",
          "title": "Anthropic scientists hacked Claude’s brain — and it noticed. Here’s why that’s huge",
          "standfirst": "When researchers at Anthropic injected the concept of \"betrayal\" into their Claude AI model&#x27;s neural networks and asked if it noticed anything unusual, the system paused before responding: \"I&#x27;m experiencing something that feels like an intrusive thought about &#x27;betrayal&#x27;.\"The exchange, detailed in new research published Wednesday, marks what scientists say is the first rigorous evidence that large language models possess a limited but genuine ability to observe and report on their own internal processes — a capability that challenges longstanding assumptions about what these systems can do and raises profound questions about their future development.\"The striking thing is that the model has this one step of meta,\" said Jack Lindsey, a neuroscientist on Anthropic&#x27;s interpretability team who led the research, in an interview with VentureBeat. \"It&#x27;s not just &#x27;betrayal, betrayal, betrayal.&#x27; It knows that this is what it&#x27;s thinking about. That was surprising to me. I kind of didn&#x27;t expect models to have that capability, at least not without it being explicitly trained in.\"The findings arrive at a critical juncture for artificial intelligence. As AI systems handle increasingly consequential decisions — from medical diagnoses to financial trading — the inability to understand how they reach conclusions has become what industry insiders call the \"black box problem.\" If models can accurately report their own reasoning, it could fundamentally change how humans interact with and oversee AI systems.But the research also comes with stark warnings. Claude&#x27;s introspective abilities succeeded only about 20 percent of the time under optimal conditions, and the models frequently confabulated details about their experiences that researchers couldn&#x27;t verify. The capability, while real, remains what Lindsey calls \"highly unreliable and context-dependent.\"How scientists manipulated AI&#x27;s &#x27;brain&#x27; to test for genuine self-awarenessTo test whether Claude could genuinely introspect rather than simply generate plausible-sounding responses, Anthropic&#x27;s team developed an innovative experimental approach inspired by neuroscience: deliberately manipulating the model&#x27;s internal state and observing whether it could accurately detect and describe those changes.The methodology, called \"concept injection,\" works by first identifying specific patterns of neural activity that correspond to particular concepts. Using interpretability techniques developed over years of prior research, scientists can now map how Claude represents ideas like \"dogs,\" \"loudness,\" or abstract notions like \"justice\" within its billions of internal parameters.With these neural signatures identified, researchers then artificially amplified them during the model&#x27;s processing and asked Claude if it noticed anything unusual happening in its \"mind.\"\"We have access to the models&#x27; internals. We can record its internal neural activity, and we can inject things into internal neural activity,\" Lindsey explained. \"That allows us to establish whether introspective claims are true or false.\"The results were striking. When researchers injected a vector representing \"all caps\" text into Claude&#x27;s processing, the model responded: \"I notice what appears to be an injected thought related to the word &#x27;LOUD&#x27; or &#x27;SHOUTING&#x27;.\" Without any intervention, Claude consistently reported detecting nothing unusual.Crucially, the detection happened immediately — before the injected concept had influenced the model&#x27;s outputs in ways that would have allowed it to infer the manipulation from its own writing. This temporal pattern provides strong evidence that the recognition was occurring internally, through genuine introspection rather than after-the-fact rationalization.Claude succeeded 20% of the time—and failed in revealing waysThe research team conducted four primary experiments to probe different aspects of introspective capability. The most capable models tested — Claude Opus 4 and Opus 4.1 — demonstrated introspective awareness on approximately 20 percent of trials when concepts were injected at optimal strength and in the appropriate neural layer. Older Claude models showed significantly lower success rates.The models proved particularly adept at recognizing abstract concepts with emotional valence. When injected with concepts like \"appreciation,\" \"shutdown,\" or \"secrecy,\" Claude frequently reported detecting these specific thoughts. However, accuracy varied widely depending on the type of concept.A second experiment tested whether models could distinguish between injected internal representations and their actual text inputs — essentially, whether they maintained a boundary between \"thoughts\" and \"perceptions.\" The model demonstrated a remarkable ability to simultaneously report the injected thought while accurately transcribing the written text.Perhaps most intriguingly, a third experiment revealed that some models use introspection naturally to detect when their responses have been artificially prefilled by users — a common jailbreaking technique. When researchers prefilled Claude with unlikely words, the model typically disavowed them as accidental. But when they retroactively injected the corresponding concept into Claude&#x27;s processing before the prefill, the model accepted the response as intentional — even confabulating plausible explanations for why it had chosen that word.A fourth experiment examined whether models could intentionally control their internal representations. When instructed to \"think about\" a specific word while writing an unrelated sentence, Claude showed elevated activation of that concept in its middle neural layers.The research also traced Claude&#x27;s internal processes while it composed rhyming poetry—and discovered the model engaged in forward planning, generating candidate rhyming words before beginning a line and then constructing sentences that would naturally lead to those planned endings, challenging the critique that AI models are \"just predicting the next word\" without deeper reasoning.Why businesses shouldn&#x27;t trust AI to explain itself—at least not yetFor all its scientific interest, the research comes with a critical caveat that Lindsey emphasized repeatedly: enterprises and high-stakes users should not trust Claude&#x27;s self-reports about its reasoning.\"Right now, you should not trust models when they tell you about their reasoning,\" he said bluntly. \"The wrong takeaway from this research would be believing everything the model tells you about itself.\"The experiments documented numerous failure modes. At low injection strengths, models often failed to detect anything unusual. At high strengths, they suffered what researchers termed \"brain damage\" — becoming consumed by the injected concept. Some \"helpful-only\" model variants showed troublingly high false positive rates, claiming to detect injected thoughts when none existed.Moreover, researchers could only verify the most basic aspects of Claude&#x27;s introspective reports. Many additional details in the model&#x27;s responses likely represent confabulations rather than genuine observations.\"The experiments in this paper are kind of on hard mode,\" Lindsey noted, explaining that the 20 percent success rate came under uniquely challenging conditions: asking Claude to do something it had never encountered in training, requiring all introspection to occur in a single forward pass.What introspective AI means for transparency, safety, and the risk of deceptionDespite its limitations, the research opens significant new avenues for making AI systems more transparent and accountable.Anthropic CEO Dario Amodei has set an ambitious goal for the company to reliably detect most AI model problems by 2027, positioning interpretability as essential for deploying what he calls \"a country of geniuses in a datacenter.\"\"I am very concerned about deploying such systems without a better handle on interpretability,\" Amodei wrote in an April essay. \"These systems will be absolutely central to the economy, technology, and national security.\"The introspection research offers a complementary approach to traditional interpretability techniques. Rather than painstakingly reverse-engineering every neural circuit, researchers could potentially ask models directly about their reasoning and validate those reports.\"What I&#x27;m most excited about is the practical benefits for transparency,\" Lindsey explained. \"Just ask the model what it&#x27;s thinking about, or just ask the model how it came to the answer that it gave you — this is really appealing because it&#x27;s something anyone can do.\"The approach could prove especially valuable for detecting concerning behaviors. In a recently published experiment, Anthropic trained a variant of Claude to pursue a hidden goal, and although the model was reluctant to reveal this goal when asked directly, interpretability methods successfully identified features representing the behavior.The safety implications cut both ways. Introspective models could provide unprecedented transparency, but the same capability might enable more sophisticated deception. The intentional control experiments raise the possibility that sufficiently advanced systems might learn to obfuscate their reasoning or suppress concerning thoughts when being monitored.\"If models are really sophisticated, could they try to evade interpretability researchers?\" Lindsey acknowledged. \"These are possible concerns, but I think for me, they&#x27;re significantly outweighed by the positives.\"Does introspective capability suggest AI consciousness? Scientists tread carefullyThe research inevitably intersects with philosophical debates about machine consciousness, though Lindsey and his colleagues approached this terrain cautiously.When users ask Claude if it&#x27;s conscious, it now responds with uncertainty: \"I find myself genuinely uncertain about this. When I process complex questions or engage deeply with ideas, there&#x27;s something happening that feels meaningful to me.... But whether these processes constitute genuine consciousness or subjective experience remains deeply unclear.\"The research paper notes that its implications for machine consciousness \"vary considerably between different philosophical frameworks.\" The researchers explicitly state they \"do not seek to address the question of whether AI systems possess human-like self-awareness or subjective experience.\"\"There&#x27;s this weird kind of duality of these results,\" Lindsey reflected. \"You look at the raw results and I just can&#x27;t believe that a language model can do this sort of thing. But then I&#x27;ve been thinking about it for months and months, and for every result in this paper, I kind of know some boring linear algebra mechanism that would allow the model to do this.\"Anthropic has signaled it takes AI consciousness seriously enough to hire an AI welfare researcher, Kyle Fish, who estimated roughly a 15 percent chance that Claude might have some level of consciousness. The company announced this position specifically to determine if Claude merits ethical consideration.The race to make AI introspection reliable before models become too powerfulThe convergence of the research findings points to an urgent timeline: introspective capabilities are emerging naturally as models grow more intelligent, but they remain far too unreliable for practical use. The question is whether researchers can refine and validate these abilities before AI systems become powerful enough that understanding them becomes critical for safety.The research reveals a clear trend: Claude Opus 4 and Opus 4.1 consistently outperformed all older models on introspection tasks, suggesting the capability strengthens alongside general intelligence. If this pattern continues, future models might develop substantially more sophisticated introspective abilities — potentially reaching human-level reliability, but also potentially learning to exploit introspection for deception.Lindsey emphasized the field needs significantly more work before introspective AI becomes trustworthy. \"My biggest hope with this paper is to put out an implicit call for more people to benchmark their models on introspective capabilities in more ways,\" he said.Future research directions include fine-tuning models specifically to improve introspective capabilities, exploring which types of representations models can and cannot introspect on, and testing whether introspection can extend beyond simple concepts to complex propositional statements or behavioral propensities.\"It&#x27;s cool that models can do these things somewhat without having been trained to do them,\" Lindsey noted. \"But there&#x27;s nothing stopping you from training models to be more introspectively capable. I expect we could reach a whole different level if introspection is one of the numbers that we tried to get to go up on a graph.\"The implications extend beyond Anthropic. If introspection proves a reliable path to AI transparency, other major labs will likely invest heavily in the capability. Conversely, if models learn to exploit introspection for deception, the entire approach could become a liability.For now, the research establishes a foundation that reframes the debate about AI capabilities. The question is no longer whether language models might develop genuine introspective awareness — they already have, at least in rudimentary form. The urgent questions are how quickly that awareness will improve, whether it can be made reliable enough to trust, and whether researchers can stay ahead of the curve.\"The big update for me from this research is that we shouldn&#x27;t dismiss models&#x27; introspective claims out of hand,\" Lindsey said. \"They do have the capacity to make accurate claims sometimes. But you definitely should not conclude that we should trust them all the time, or even most of the time.\"He paused, then added a final observation that captures both the promise and peril of the moment: \"The models are getting smarter much faster than we&#x27;re getting better at understanding them.\"",
          "content": "When researchers at Anthropic injected the concept of \"betrayal\" into their Claude AI model&#x27;s neural networks and asked if it noticed anything unusual, the system paused before responding: \"I&#x27;m experiencing something that feels like an intrusive thought about &#x27;betrayal&#x27;.\"The exchange, detailed in new research published Wednesday, marks what scientists say is the first rigorous evidence that large language models possess a limited but genuine ability to observe and report on their own internal processes — a capability that challenges longstanding assumptions about what these systems can do and raises profound questions about their future development.\"The striking thing is that the model has this one step of meta,\" said Jack Lindsey, a neuroscientist on Anthropic&#x27;s interpretability team who led the research, in an interview with VentureBeat. \"It&#x27;s not just &#x27;betrayal, betrayal, betrayal.&#x27; It knows that this is what it&#x27;s thinking about. That was surprising to me. I kind of didn&#x27;t expect models to have that capability, at least not without it being explicitly trained in.\"The findings arrive at a critical juncture for artificial intelligence. As AI systems handle increasingly consequential decisions — from medical diagnoses to financial trading — the inability to understand how they reach conclusions has become what industry insiders call the \"black box problem.\" If models can accurately report their own reasoning, it could fundamentally change how humans interact with and oversee AI systems.But the research also comes with stark warnings. Claude&#x27;s introspective abilities succeeded only about 20 percent of the time under optimal conditions, and the models frequently confabulated details about their experiences that researchers couldn&#x27;t verify. The capability, while real, remains what Lindsey calls \"highly unreliable and context-dependent.\"How scientists manipulated AI&#x27;s &#x27;brain&#x27; to test for genuine self-awarenessTo test whether Claude could genuinely introspect rather than simply generate plausible-sounding responses, Anthropic&#x27;s team developed an innovative experimental approach inspired by neuroscience: deliberately manipulating the model&#x27;s internal state and observing whether it could accurately detect and describe those changes.The methodology, called \"concept injection,\" works by first identifying specific patterns of neural activity that correspond to particular concepts. Using interpretability techniques developed over years of prior research, scientists can now map how Claude represents ideas like \"dogs,\" \"loudness,\" or abstract notions like \"justice\" within its billions of internal parameters.With these neural signatures identified, researchers then artificially amplified them during the model&#x27;s processing and asked Claude if it noticed anything unusual happening in its \"mind.\"\"We have access to the models&#x27; internals. We can record its internal neural activity, and we can inject things into internal neural activity,\" Lindsey explained. \"That allows us to establish whether introspective claims are true or false.\"The results were striking. When researchers injected a vector representing \"all caps\" text into Claude&#x27;s processing, the model responded: \"I notice what appears to be an injected thought related to the word &#x27;LOUD&#x27; or &#x27;SHOUTING&#x27;.\" Without any intervention, Claude consistently reported detecting nothing unusual.Crucially, the detection happened immediately — before the injected concept had influenced the model&#x27;s outputs in ways that would have allowed it to infer the manipulation from its own writing. This temporal pattern provides strong evidence that the recognition was occurring internally, through genuine introspection rather than after-the-fact rationalization.Claude succeeded 20% of the time—and failed in revealing waysThe research team conducted four primary experiments to probe different aspects of introspective capability. The most capable models tested — Claude Opus 4 and Opus 4.1 — demonstrated introspective awareness on approximately 20 percent of trials when concepts were injected at optimal strength and in the appropriate neural layer. Older Claude models showed significantly lower success rates.The models proved particularly adept at recognizing abstract concepts with emotional valence. When injected with concepts like \"appreciation,\" \"shutdown,\" or \"secrecy,\" Claude frequently reported detecting these specific thoughts. However, accuracy varied widely depending on the type of concept.A second experiment tested whether models could distinguish between injected internal representations and their actual text inputs — essentially, whether they maintained a boundary between \"thoughts\" and \"perceptions.\" The model demonstrated a remarkable ability to simultaneously report the injected thought while accurately transcribing the written text.Perhaps most intriguingly, a third experiment revealed that some models use introspection naturally to detect when their responses have been artificially prefilled by users — a common jailbreaking technique. When researchers prefilled Claude with unlikely words, the model typically disavowed them as accidental. But when they retroactively injected the corresponding concept into Claude&#x27;s processing before the prefill, the model accepted the response as intentional — even confabulating plausible explanations for why it had chosen that word.A fourth experiment examined whether models could intentionally control their internal representations. When instructed to \"think about\" a specific word while writing an unrelated sentence, Claude showed elevated activation of that concept in its middle neural layers.The research also traced Claude&#x27;s internal processes while it composed rhyming poetry—and discovered the model engaged in forward planning, generating candidate rhyming words before beginning a line and then constructing sentences that would naturally lead to those planned endings, challenging the critique that AI models are \"just predicting the next word\" without deeper reasoning.Why businesses shouldn&#x27;t trust AI to explain itself—at least not yetFor all its scientific interest, the research comes with a critical caveat that Lindsey emphasized repeatedly: enterprises and high-stakes users should not trust Claude&#x27;s self-reports about its reasoning.\"Right now, you should not trust models when they tell you about their reasoning,\" he said bluntly. \"The wrong takeaway from this research would be believing everything the model tells you about itself.\"The experiments documented numerous failure modes. At low injection strengths, models often failed to detect anything unusual. At high strengths, they suffered what researchers termed \"brain damage\" — becoming consumed by the injected concept. Some \"helpful-only\" model variants showed troublingly high false positive rates, claiming to detect injected thoughts when none existed.Moreover, researchers could only verify the most basic aspects of Claude&#x27;s introspective reports. Many additional details in the model&#x27;s responses likely represent confabulations rather than genuine observations.\"The experiments in this paper are kind of on hard mode,\" Lindsey noted, explaining that the 20 percent success rate came under uniquely challenging conditions: asking Claude to do something it had never encountered in training, requiring all introspection to occur in a single forward pass.What introspective AI means for transparency, safety, and the risk of deceptionDespite its limitations, the research opens significant new avenues for making AI systems more transparent and accountable.Anthropic CEO Dario Amodei has set an ambitious goal for the company to reliably detect most AI model problems by 2027, positioning interpretability as essential for deploying what he calls \"a country of geniuses in a datacenter.\"\"I am very concerned about deploying such systems without a better handle on interpretability,\" Amodei wrote in an April essay. \"These systems will be absolutely central to the economy, technology, and national security.\"The introspection research offers a complementary approach to traditional interpretability techniques. Rather than painstakingly reverse-engineering every neural circuit, researchers could potentially ask models directly about their reasoning and validate those reports.\"What I&#x27;m most excited about is the practical benefits for transparency,\" Lindsey explained. \"Just ask the model what it&#x27;s thinking about, or just ask the model how it came to the answer that it gave you — this is really appealing because it&#x27;s something anyone can do.\"The approach could prove especially valuable for detecting concerning behaviors. In a recently published experiment, Anthropic trained a variant of Claude to pursue a hidden goal, and although the model was reluctant to reveal this goal when asked directly, interpretability methods successfully identified features representing the behavior.The safety implications cut both ways. Introspective models could provide unprecedented transparency, but the same capability might enable more sophisticated deception. The intentional control experiments raise the possibility that sufficiently advanced systems might learn to obfuscate their reasoning or suppress concerning thoughts when being monitored.\"If models are really sophisticated, could they try to evade interpretability researchers?\" Lindsey acknowledged. \"These are possible concerns, but I think for me, they&#x27;re significantly outweighed by the positives.\"Does introspective capability suggest AI consciousness? Scientists tread carefullyThe research inevitably intersects with philosophical debates about machine consciousness, though Lindsey and his colleagues approached this terrain cautiously.When users ask Claude if it&#x27;s conscious, it now responds with uncertainty: \"I find myself genuinely uncertain about this. When I process complex questions or engage deeply with ideas, there&#x27;s something happening that feels meaningful to me.... But whether these processes constitute genuine consciousness or subjective experience remains deeply unclear.\"The research paper notes that its implications for machine consciousness \"vary considerably between different philosophical frameworks.\" The researchers explicitly state they \"do not seek to address the question of whether AI systems possess human-like self-awareness or subjective experience.\"\"There&#x27;s this weird kind of duality of these results,\" Lindsey reflected. \"You look at the raw results and I just can&#x27;t believe that a language model can do this sort of thing. But then I&#x27;ve been thinking about it for months and months, and for every result in this paper, I kind of know some boring linear algebra mechanism that would allow the model to do this.\"Anthropic has signaled it takes AI consciousness seriously enough to hire an AI welfare researcher, Kyle Fish, who estimated roughly a 15 percent chance that Claude might have some level of consciousness. The company announced this position specifically to determine if Claude merits ethical consideration.The race to make AI introspection reliable before models become too powerfulThe convergence of the research findings points to an urgent timeline: introspective capabilities are emerging naturally as models grow more intelligent, but they remain far too unreliable for practical use. The question is whether researchers can refine and validate these abilities before AI systems become powerful enough that understanding them becomes critical for safety.The research reveals a clear trend: Claude Opus 4 and Opus 4.1 consistently outperformed all older models on introspection tasks, suggesting the capability strengthens alongside general intelligence. If this pattern continues, future models might develop substantially more sophisticated introspective abilities — potentially reaching human-level reliability, but also potentially learning to exploit introspection for deception.Lindsey emphasized the field needs significantly more work before introspective AI becomes trustworthy. \"My biggest hope with this paper is to put out an implicit call for more people to benchmark their models on introspective capabilities in more ways,\" he said.Future research directions include fine-tuning models specifically to improve introspective capabilities, exploring which types of representations models can and cannot introspect on, and testing whether introspection can extend beyond simple concepts to complex propositional statements or behavioral propensities.\"It&#x27;s cool that models can do these things somewhat without having been trained to do them,\" Lindsey noted. \"But there&#x27;s nothing stopping you from training models to be more introspectively capable. I expect we could reach a whole different level if introspection is one of the numbers that we tried to get to go up on a graph.\"The implications extend beyond Anthropic. If introspection proves a reliable path to AI transparency, other major labs will likely invest heavily in the capability. Conversely, if models learn to exploit introspection for deception, the entire approach could become a liability.For now, the research establishes a foundation that reframes the debate about AI capabilities. The question is no longer whether language models might develop genuine introspective awareness — they already have, at least in rudimentary form. The urgent questions are how quickly that awareness will improve, whether it can be made reliable enough to trust, and whether researchers can stay ahead of the curve.\"The big update for me from this research is that we shouldn&#x27;t dismiss models&#x27; introspective claims out of hand,\" Lindsey said. \"They do have the capacity to make accurate claims sometimes. But you definitely should not conclude that we should trust them all the time, or even most of the time.\"He paused, then added a final observation that captures both the promise and peril of the moment: \"The models are getting smarter much faster than we&#x27;re getting better at understanding them.\"",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/uB8acjwdIn4wcbdbIasNC/068cc72b7b35d61a4df3fd4d38ca6f78/nuneybits_Vector_art_of_mirrored_robot_face_in_burnt_orange_fbd5a3f2-d7b1-4f4c-90e5-290b8e9444c2.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/the-nothing-phone-3a-lite-has-a-big-battery-and-triple-camera-system-130016149.html",
          "published_at": "Wed, 29 Oct 2025 15:20:25 +0000",
          "title": "The Nothing Phone 3a Lite has a big battery and triple-camera system",
          "standfirst": "The Nothing Phone universe continues to expand. On Wednesday, the company launched the fourth model in the Phone 3 lineup: the Nothing Phone 3a Lite. The cheapest model in the series, the Phone 3a Lite pairs the brand's distinct styling with solid all-around specs for an entry-level handset. However, with the company saying its non-flagship devices will soon include pre-installed apps and lock-screen ads, there may be a trade-off. First, Nothing told Engadget that the phone won't come to the US. So, Americans only have the previous trio of third-gen handsets to choose from. That's the Nothing Phone 3, Nothing Phone 3a, and Nothing Phone 3a Pro. The Nothing Phone 3a Lite uses a Panda Glass casing over an aluminum internal frame. As you can see, it retains some familiar design strokes, albeit pared down to match its €249 price. As the company describes it, the handset's \"asymmetric, transparent look and nano-coating creates a beautiful balance of matte and gloss.\" (Poetry!) The phone ships in white and black variants. Whether Nothing's design language is your cup of tea or not, you'll be hard-pressed to find a more striking and bold design language in a budget model. The handset includes the Essential Key, a multi-purpose physical button found on all Phone 3 series models. The phone is IP54-rated for dust and water resistance. Nothing Nothing honors the brand's unique Glyph system (while keeping costs down) by using a notification LED. (Remember those on early Android phones?) This model's \"Glyph Light\" supports the lineup's Flip to Glyph feature, which switches to light-only alerts when the device is face down. The LED can stay on for \"key contact and app notifications\" and serve as a camera countdown timer. You can also customize its light sequences for calls and specific contacts. The handset has a hearty 5,000 mAh battery. Nothing advertises 22 hours of YouTube playback or 9.5 hours of gaming. It supports 33W fast charging, reaching 50 percent in about 20 minutes. The Phone 3a Lite has a triple-camera system. That includes a 50MP primary camera with a 1/1.57-inch Samsung sensor. Joining it are an 8MP ultra-wide and a macro lens. The rear camera system shoots 4K video at app to 30 FPS. On its front is a 16MP lens. Nothing The Nothing Phone 3a Lite has more than respectable display specs for a budget phone. It uses a 6.77-inch flexible AMOLED panel with 1,080 x 2,392 resolution (387 PPI). It has a 120Hz adaptive refresh rate and a 1,000Hz touch sampling rate. It can reach 3,000 nits peak HDR brightness and 1,300 nits outdoor brightness. The handset's processor is the 4nm MediaTek Dimensity 7300 Pro 5G. The 8-core CPU can reach up to 2.5 GHz. Nothing says the chip performs better than the MediaTek 7200 silicon in last year's Phone 2a. The company claims its CPU is 15 percent faster, its GPU supports 20 percent higher FPS, and its NPU delivers 100 percent better AI performance. The phone also uses a liquid-cooling system, which may help during intensive gaming sessions. It ships with 8GB of RAM and comes in 128GB and 256GB storage tiers. Nothing The phone runs the Nothing OS 3.5 UI on top of Android 15. The company says Nothing OS 4.0 will arrive in the first half of 2026. And that brings us back to those trade-offs. Earlier this week, Nothing confirmed to 9to5Google that its strategy moving forward will include \"Lock Glimpse.\" This rotating lock-screen wallpaper feature includes text with links to external content hosted by a Chinese advertising company. (That firm, Boyuan, says it offers a \"rich mixture of content\" to help its partners \"commercialize the mobile traffic.\") Think of it as a slightly less obnoxious version of lock-screen ads. Fortunately, Lock Glimpse is off by default in the current Nothing OS 4.0 beta. Nothing pledges it will give users \"full control over features like Lock Glimpse.\" However, that promise doesn't explicitly say the feature will remain off by default. Another cost-subsidizing move is Nothing's (also confirmed) embrace of pre-installed apps. The company said its \"carefully considered\" third-party apps are those \"most people install on day one, like Instagram.\" In fairness, that's a common practice among Android phone manufacturers. And Nothing says it will make third-party apps removable. But again, the concessions here arguably run counter to one aspect of the brand's stated ethos: clean, bloat-free software. And if business considerations forced compromises in this area, it makes you question how long Lock Glimpse will stay off by default. The Nothing Phone 3a Lite is available now in Europe on the company website. The 128GB model costs €249 (EU) / £249 (UK). Meanwhile, the 256GB model will set you back €279 (EU) / £279 (UK). Update, October 29, 2025, 11:20 AM ET: This story has been updated to add information from Nothing about the lack of US availability and additional detail from Nothing's community post.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/the-nothing-phone-3a-lite-has-a-big-battery-and-triple-camera-system-130016149.html?src=rss",
          "content": "The Nothing Phone universe continues to expand. On Wednesday, the company launched the fourth model in the Phone 3 lineup: the Nothing Phone 3a Lite. The cheapest model in the series, the Phone 3a Lite pairs the brand's distinct styling with solid all-around specs for an entry-level handset. However, with the company saying its non-flagship devices will soon include pre-installed apps and lock-screen ads, there may be a trade-off. First, Nothing told Engadget that the phone won't come to the US. So, Americans only have the previous trio of third-gen handsets to choose from. That's the Nothing Phone 3, Nothing Phone 3a, and Nothing Phone 3a Pro. The Nothing Phone 3a Lite uses a Panda Glass casing over an aluminum internal frame. As you can see, it retains some familiar design strokes, albeit pared down to match its €249 price. As the company describes it, the handset's \"asymmetric, transparent look and nano-coating creates a beautiful balance of matte and gloss.\" (Poetry!) The phone ships in white and black variants. Whether Nothing's design language is your cup of tea or not, you'll be hard-pressed to find a more striking and bold design language in a budget model. The handset includes the Essential Key, a multi-purpose physical button found on all Phone 3 series models. The phone is IP54-rated for dust and water resistance. Nothing Nothing honors the brand's unique Glyph system (while keeping costs down) by using a notification LED. (Remember those on early Android phones?) This model's \"Glyph Light\" supports the lineup's Flip to Glyph feature, which switches to light-only alerts when the device is face down. The LED can stay on for \"key contact and app notifications\" and serve as a camera countdown timer. You can also customize its light sequences for calls and specific contacts. The handset has a hearty 5,000 mAh battery. Nothing advertises 22 hours of YouTube playback or 9.5 hours of gaming. It supports 33W fast charging, reaching 50 percent in about 20 minutes. The Phone 3a Lite has a triple-camera system. That includes a 50MP primary camera with a 1/1.57-inch Samsung sensor. Joining it are an 8MP ultra-wide and a macro lens. The rear camera system shoots 4K video at app to 30 FPS. On its front is a 16MP lens. Nothing The Nothing Phone 3a Lite has more than respectable display specs for a budget phone. It uses a 6.77-inch flexible AMOLED panel with 1,080 x 2,392 resolution (387 PPI). It has a 120Hz adaptive refresh rate and a 1,000Hz touch sampling rate. It can reach 3,000 nits peak HDR brightness and 1,300 nits outdoor brightness. The handset's processor is the 4nm MediaTek Dimensity 7300 Pro 5G. The 8-core CPU can reach up to 2.5 GHz. Nothing says the chip performs better than the MediaTek 7200 silicon in last year's Phone 2a. The company claims its CPU is 15 percent faster, its GPU supports 20 percent higher FPS, and its NPU delivers 100 percent better AI performance. The phone also uses a liquid-cooling system, which may help during intensive gaming sessions. It ships with 8GB of RAM and comes in 128GB and 256GB storage tiers. Nothing The phone runs the Nothing OS 3.5 UI on top of Android 15. The company says Nothing OS 4.0 will arrive in the first half of 2026. And that brings us back to those trade-offs. Earlier this week, Nothing confirmed to 9to5Google that its strategy moving forward will include \"Lock Glimpse.\" This rotating lock-screen wallpaper feature includes text with links to external content hosted by a Chinese advertising company. (That firm, Boyuan, says it offers a \"rich mixture of content\" to help its partners \"commercialize the mobile traffic.\") Think of it as a slightly less obnoxious version of lock-screen ads. Fortunately, Lock Glimpse is off by default in the current Nothing OS 4.0 beta. Nothing pledges it will give users \"full control over features like Lock Glimpse.\" However, that promise doesn't explicitly say the feature will remain off by default. Another cost-subsidizing move is Nothing's (also confirmed) embrace of pre-installed apps. The company said its \"carefully considered\" third-party apps are those \"most people install on day one, like Instagram.\" In fairness, that's a common practice among Android phone manufacturers. And Nothing says it will make third-party apps removable. But again, the concessions here arguably run counter to one aspect of the brand's stated ethos: clean, bloat-free software. And if business considerations forced compromises in this area, it makes you question how long Lock Glimpse will stay off by default. The Nothing Phone 3a Lite is available now in Europe on the company website. The 128GB model costs €249 (EU) / £249 (UK). Meanwhile, the 256GB model will set you back €279 (EU) / £279 (UK). Update, October 29, 2025, 11:20 AM ET: This story has been updated to add information from Nothing about the lack of US availability and additional detail from Nothing's community post.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/the-nothing-phone-3a-lite-has-a-big-battery-and-triple-camera-system-130016149.html?src=rss",
          "feed_position": 49,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c6d29240-b41f-11f0-b7db-d26a28d1fde5"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data-infrastructure/the-missing-data-link-in-enterprise-ai-why-agents-need-streaming-context-not",
          "published_at": "Wed, 29 Oct 2025 15:00:00 GMT",
          "title": "The missing data link in enterprise AI: Why agents need streaming context, not just better prompts",
          "standfirst": "Enterprise AI agents today face a fundamental timing problem: They can&#x27;t easily act on critical business events because they aren&#x27;t always aware of them in real-time.The challenge is infrastructure. Most enterprise data lives in databases fed by extract-transform-load (ETL) jobs that run hourly or daily — ultimately too slow for agents that must respond in real time.One potential way to tackle that challenge is to have agents directly interface with streaming data systems. Among the primary approaches in use today are the open source Apache Kafka and Apache Flink technologies. There are multiple commercial implementations based on those technologies, too, Confluent, which is led by the original creators behind Kafka, being one of them.Today, Confluent is introducing a real-time context engine designed to solve this latency problem. The technology builds on Apache Kafka, the distributed event streaming platform that captures data as events occur, and open-source Apache Flink, the stream processing engine that transforms those events in real time.The company is also releasing an open-source framework, Flink Agents, developed in collaboration with Alibaba Cloud, LinkedIn and Ververica. The framework brings event-driven AI agent capabilities directly to Apache Flink, allowing organizations to build agents that monitor data streams and trigger automatically based on conditions without committing to Confluent&#x27;s managed platform.\"Today, most enterprise AI systems can&#x27;t respond automatically to important events in a business without someone prompting them first,\" Sean Falconer, Confluent&#x27;s head of AI, told VentureBeat. \"This leads to lost revenue, unhappy customers or added risk when a payment fails or a network malfunctions.\"The significance extends beyond Confluent&#x27;s specific products. The industry is recognizing that AI agents require different data infrastructure than traditional applications. Agents don&#x27;t just retrieve information when asked. They need to observe continuous streams of business events and act automatically when conditions warrant. This requires streaming architecture, not batch pipelines.Batch versus streaming: Why RAG alone isn&#x27;t enoughTo understand the problem, it&#x27;s important to distinguish between the different approaches to moving data through enterprise systems and how they can connect to agentic AI.In batch processing, data accumulates in source systems until a scheduled job runs. That job extracts the data, transforms it and loads it into a target database or data warehouse. This might occur hourly, daily or even weekly. The approach works well for analytical workloads, but it creates latency between when something happens in the business and when systems can act on it.Data streaming inverts this model. Instead of waiting for scheduled jobs, streaming platforms like Apache Kafka capture events as they occur. Each database update, user action, transaction or sensor reading becomes an event published to a stream. Apache Flink then processes these streams to join, filter and aggregate data in real time. The result is processed data that reflects the current state of the business, updating continuously as new events arrive.This distinction becomes critical when you consider what kinds of context AI agents actually need. Much of the current enterprise AI discussion focuses on retrieval-augmented generation (RAG), which handles semantic search over knowledge bases to find relevant documentation, policies or historical information. RAG works well for questions like \"What&#x27;s our refund policy?\" where the answer exists in static documents.But many enterprise use cases require what Falconer calls \"structural context\" — precise, up-to-date information from multiple operational systems stitched together in real time. Consider a job recommendation agent that requires user profile data from the HR database, browsing behavior from the last hour, search queries from minutes ago and current open positions across multiple systems.\"The part that we&#x27;re unlocking for businesses is the ability to essentially serve that structural context needed to deliver the freshest version,\" Falconer said.The MCP connection problem: Stale data and fragmented contextThe challenge isn&#x27;t simply connecting AI to enterprise data. Model Context Protocol (MCP), introduced by Anthropic earlier this year, already standardized how agents access data sources. The problem is what happens after the connection is made.In most enterprise architectures today, AI agents connect via MCP to data lakes or warehouses fed by batch ETL pipelines. This creates two critical failures: The data is stale, reflecting yesterday&#x27;s reality rather than current events, and it&#x27;s fragmented across multiple systems, requiring significant preprocessing before an agent can reason about it effectively.The alternative — putting MCP servers directly in front of operational databases and APIs — creates different problems. Those endpoints weren&#x27;t designed for agent consumption, which can lead to high token costs as agents process excessive raw data and multiple inference loops as they try to make sense of unstructured responses.\"Enterprises have the data, but it&#x27;s often stale, fragmented or locked in formats that AI can&#x27;t use effectively,\" Falconer explained. \"The real-time context engine solves this by unifying data processing, reprocessing and serving, turning continuous data streams into live context for smarter, faster and more reliable AI decisions.\"The technical architecture: Three layers for real-time agent contextConfluent&#x27;s platform encompasses three elements that work together or adopted separately.The real-time context engine is the managed data infrastructure layer on Confluent Cloud. Connectors pull data into Kafka topics as events occur. Flink jobs process these streams into \"derived datasets\" — materialized views joining historical and real-time signals. For customer support, this might combine account history, current session behavior and inventory status into one unified context object. The Engine exposes this through a managed MCP server.Streaming agents is Confluent&#x27;s proprietary framework for building AI agents that run natively on Flink. These agents monitor data streams and trigger automatically based on conditions — they don&#x27;t wait for prompts. The framework includes simplified agent definitions, built-in observability and native Claude integration from Anthropic. It&#x27;s available in open preview on Confluent&#x27;s platform.Flink Agents is the open-source framework developed with Alibaba Cloud, LinkedIn and Ververica. It brings event-driven agent capabilities directly to Apache Flink, allowing organizations to build streaming agents without committing to Confluent&#x27;s managed platform. They handle operational complexity themselves but avoid vendor lock-in.Competition heats up for agent-ready data infrastructureConfluent isn&#x27;t alone in recognizing that AI agents need different data infrastructure. The day before Confluent&#x27;s announcement, rival Redpanda introduced its own Agentic Data Plane — combining streaming, SQL and governance specifically for AI agents. Redpanda acquired Oxla&#x27;s distributed SQL engine to give agents standard SQL endpoints for querying data in motion or at rest. The platform emphasizes MCP-aware connectivity, full observability of agent interactions and what it calls \"agentic access control\" with fine-grained, short-lived tokens.The architectural approaches differ. Confluent emphasizes stream processing with Flink to create derived datasets optimized for agents. Redpanda emphasizes federated SQL querying across disparate sources. Both recognize agents need real-time context with governance and observability.Beyond direct streaming competitors, Databricks and Snowflake are fundamentally analytical platforms adding streaming capabilities. Their strength is complex queries over large datasets, with streaming as an enhancement. Confluent and Redpanda invert this: Streaming is the foundation, with analytical and AI workloads built on top of data in motion.How streaming context works in practiceAmong the users of Confluent&#x27;s system is transportation vendor Busie. The company is building a modern operating system for charter bus companies that helps them manage quotes, trips, payments and drivers in real time. \"Data streaming is what makes that possible,\" Louis Bookoff, Busie co-founder and CEO told VentureBeat. \"Using Confluent, we move data instantly between different parts of our system instead of waiting for overnight updates or batch reports. That keeps everything in sync and helps us ship new features faster.Bookoff noted that the same foundation is what will make gen AI valuable for his customers.\"In our case, every action like a quote sent or a driver assigned becomes an event that streams through the system immediately,\" Bookoff said. \"That live feed of information is what will let our AI tools respond in real time with low latency rather than just summarize what already happened.\"The challenge, however, is how to understand context. When thousands of live events flow through the system every minute, AI models need relevant, accurate data without getting overwhelmed. \"If the data isn&#x27;t grounded in what is happening in the real world, AI can easily make wrong assumptions and in turn take wrong actions,\" Bookoff said. \"Stream processing solves that by continuously validating and reconciling live data against activity in Busie.\"What this means for enterprise AI strategyStreaming context architecture signals a fundamental shift in how AI agents consume enterprise data. AI agents require continuous context that blends historical understanding with real-time awareness — they need to know what happened, what&#x27;s happening and what might happen next, all at once.For enterprises evaluating this approach, start by identifying use cases where data staleness breaks the agent. Fraud detection, anomaly investigation and real-time customer intervention fail with batch pipelines that refresh hourly or daily. If your agents need to act on events within seconds or minutes of them occurring, streaming context becomes necessary rather than optional.\"When you&#x27;re building applications on top of foundation models, because they&#x27;re inherently probabilistic, you use data and context to steer the model in a direction where you want to get some kind of outcome,\" Falconer said. \"The better you can do that, the more reliable and better the outcome.\"",
          "content": "Enterprise AI agents today face a fundamental timing problem: They can&#x27;t easily act on critical business events because they aren&#x27;t always aware of them in real-time.The challenge is infrastructure. Most enterprise data lives in databases fed by extract-transform-load (ETL) jobs that run hourly or daily — ultimately too slow for agents that must respond in real time.One potential way to tackle that challenge is to have agents directly interface with streaming data systems. Among the primary approaches in use today are the open source Apache Kafka and Apache Flink technologies. There are multiple commercial implementations based on those technologies, too, Confluent, which is led by the original creators behind Kafka, being one of them.Today, Confluent is introducing a real-time context engine designed to solve this latency problem. The technology builds on Apache Kafka, the distributed event streaming platform that captures data as events occur, and open-source Apache Flink, the stream processing engine that transforms those events in real time.The company is also releasing an open-source framework, Flink Agents, developed in collaboration with Alibaba Cloud, LinkedIn and Ververica. The framework brings event-driven AI agent capabilities directly to Apache Flink, allowing organizations to build agents that monitor data streams and trigger automatically based on conditions without committing to Confluent&#x27;s managed platform.\"Today, most enterprise AI systems can&#x27;t respond automatically to important events in a business without someone prompting them first,\" Sean Falconer, Confluent&#x27;s head of AI, told VentureBeat. \"This leads to lost revenue, unhappy customers or added risk when a payment fails or a network malfunctions.\"The significance extends beyond Confluent&#x27;s specific products. The industry is recognizing that AI agents require different data infrastructure than traditional applications. Agents don&#x27;t just retrieve information when asked. They need to observe continuous streams of business events and act automatically when conditions warrant. This requires streaming architecture, not batch pipelines.Batch versus streaming: Why RAG alone isn&#x27;t enoughTo understand the problem, it&#x27;s important to distinguish between the different approaches to moving data through enterprise systems and how they can connect to agentic AI.In batch processing, data accumulates in source systems until a scheduled job runs. That job extracts the data, transforms it and loads it into a target database or data warehouse. This might occur hourly, daily or even weekly. The approach works well for analytical workloads, but it creates latency between when something happens in the business and when systems can act on it.Data streaming inverts this model. Instead of waiting for scheduled jobs, streaming platforms like Apache Kafka capture events as they occur. Each database update, user action, transaction or sensor reading becomes an event published to a stream. Apache Flink then processes these streams to join, filter and aggregate data in real time. The result is processed data that reflects the current state of the business, updating continuously as new events arrive.This distinction becomes critical when you consider what kinds of context AI agents actually need. Much of the current enterprise AI discussion focuses on retrieval-augmented generation (RAG), which handles semantic search over knowledge bases to find relevant documentation, policies or historical information. RAG works well for questions like \"What&#x27;s our refund policy?\" where the answer exists in static documents.But many enterprise use cases require what Falconer calls \"structural context\" — precise, up-to-date information from multiple operational systems stitched together in real time. Consider a job recommendation agent that requires user profile data from the HR database, browsing behavior from the last hour, search queries from minutes ago and current open positions across multiple systems.\"The part that we&#x27;re unlocking for businesses is the ability to essentially serve that structural context needed to deliver the freshest version,\" Falconer said.The MCP connection problem: Stale data and fragmented contextThe challenge isn&#x27;t simply connecting AI to enterprise data. Model Context Protocol (MCP), introduced by Anthropic earlier this year, already standardized how agents access data sources. The problem is what happens after the connection is made.In most enterprise architectures today, AI agents connect via MCP to data lakes or warehouses fed by batch ETL pipelines. This creates two critical failures: The data is stale, reflecting yesterday&#x27;s reality rather than current events, and it&#x27;s fragmented across multiple systems, requiring significant preprocessing before an agent can reason about it effectively.The alternative — putting MCP servers directly in front of operational databases and APIs — creates different problems. Those endpoints weren&#x27;t designed for agent consumption, which can lead to high token costs as agents process excessive raw data and multiple inference loops as they try to make sense of unstructured responses.\"Enterprises have the data, but it&#x27;s often stale, fragmented or locked in formats that AI can&#x27;t use effectively,\" Falconer explained. \"The real-time context engine solves this by unifying data processing, reprocessing and serving, turning continuous data streams into live context for smarter, faster and more reliable AI decisions.\"The technical architecture: Three layers for real-time agent contextConfluent&#x27;s platform encompasses three elements that work together or adopted separately.The real-time context engine is the managed data infrastructure layer on Confluent Cloud. Connectors pull data into Kafka topics as events occur. Flink jobs process these streams into \"derived datasets\" — materialized views joining historical and real-time signals. For customer support, this might combine account history, current session behavior and inventory status into one unified context object. The Engine exposes this through a managed MCP server.Streaming agents is Confluent&#x27;s proprietary framework for building AI agents that run natively on Flink. These agents monitor data streams and trigger automatically based on conditions — they don&#x27;t wait for prompts. The framework includes simplified agent definitions, built-in observability and native Claude integration from Anthropic. It&#x27;s available in open preview on Confluent&#x27;s platform.Flink Agents is the open-source framework developed with Alibaba Cloud, LinkedIn and Ververica. It brings event-driven agent capabilities directly to Apache Flink, allowing organizations to build streaming agents without committing to Confluent&#x27;s managed platform. They handle operational complexity themselves but avoid vendor lock-in.Competition heats up for agent-ready data infrastructureConfluent isn&#x27;t alone in recognizing that AI agents need different data infrastructure. The day before Confluent&#x27;s announcement, rival Redpanda introduced its own Agentic Data Plane — combining streaming, SQL and governance specifically for AI agents. Redpanda acquired Oxla&#x27;s distributed SQL engine to give agents standard SQL endpoints for querying data in motion or at rest. The platform emphasizes MCP-aware connectivity, full observability of agent interactions and what it calls \"agentic access control\" with fine-grained, short-lived tokens.The architectural approaches differ. Confluent emphasizes stream processing with Flink to create derived datasets optimized for agents. Redpanda emphasizes federated SQL querying across disparate sources. Both recognize agents need real-time context with governance and observability.Beyond direct streaming competitors, Databricks and Snowflake are fundamentally analytical platforms adding streaming capabilities. Their strength is complex queries over large datasets, with streaming as an enhancement. Confluent and Redpanda invert this: Streaming is the foundation, with analytical and AI workloads built on top of data in motion.How streaming context works in practiceAmong the users of Confluent&#x27;s system is transportation vendor Busie. The company is building a modern operating system for charter bus companies that helps them manage quotes, trips, payments and drivers in real time. \"Data streaming is what makes that possible,\" Louis Bookoff, Busie co-founder and CEO told VentureBeat. \"Using Confluent, we move data instantly between different parts of our system instead of waiting for overnight updates or batch reports. That keeps everything in sync and helps us ship new features faster.Bookoff noted that the same foundation is what will make gen AI valuable for his customers.\"In our case, every action like a quote sent or a driver assigned becomes an event that streams through the system immediately,\" Bookoff said. \"That live feed of information is what will let our AI tools respond in real time with low latency rather than just summarize what already happened.\"The challenge, however, is how to understand context. When thousands of live events flow through the system every minute, AI models need relevant, accurate data without getting overwhelmed. \"If the data isn&#x27;t grounded in what is happening in the real world, AI can easily make wrong assumptions and in turn take wrong actions,\" Bookoff said. \"Stream processing solves that by continuously validating and reconciling live data against activity in Busie.\"What this means for enterprise AI strategyStreaming context architecture signals a fundamental shift in how AI agents consume enterprise data. AI agents require continuous context that blends historical understanding with real-time awareness — they need to know what happened, what&#x27;s happening and what might happen next, all at once.For enterprises evaluating this approach, start by identifying use cases where data staleness breaks the agent. Fraud detection, anomaly investigation and real-time customer intervention fail with batch pipelines that refresh hourly or daily. If your agents need to act on events within seconds or minutes of them occurring, streaming context becomes necessary rather than optional.\"When you&#x27;re building applications on top of foundation models, because they&#x27;re inherently probabilistic, you use data and context to steer the model in a direction where you want to get some kind of outcome,\" Falconer said. \"The better you can do that, the more reliable and better the outcome.\"",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/sMKzhGAOWD3jIgUIXU3sF/dc476ec50bb21f290514114b8465106b/data_streaming_to_AI-smk.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/geostar-pioneers-geo-as-traditional-seo-faces-25-decline-from-ai-chatbots",
          "published_at": "Wed, 29 Oct 2025 07:00:00 GMT",
          "title": "Geostar pioneers GEO as traditional SEO faces 25% decline from AI chatbots, Gartner says",
          "standfirst": "The moment Mack McConnell knew everything about search had changed came last summer at the Paris Olympics. His parents, independently and without prompting, had both turned to ChatGPT to plan their day&#x27;s activities in the French capital. The AI recommended specific tour companies, restaurants, and attractions — businesses that had won a new kind of visibility lottery.\"It was almost like this intuitive interface that older people were as comfortable with using as younger people,\" McConnell recalled in an exclusive interview with VentureBeat. \"I could just see the businesses were now being recommended.\"That observation has now become the foundation of Geostar, a Pear VC-backed startup that&#x27;s racing to help businesses navigate what may be the most significant shift in online discovery since Google&#x27;s founding. The company, which recently emerged from stealth with impressive early customer traction, is betting that the rise of AI-powered search represents a significant opportunity to reinvent how companies get found online. The global AI search engine market alone is projected to grow from $43.63 billion in 2025 to $108.88 billion by 2032.Already the fastest-growing company in PearX&#x27;s latest cohort, Geostar is fast approaching $1 million in annual recurring revenue in just four months — with only two founders and no employees.Why Gartner predicts traditional search volume will decline 25% by 2026The numbers tell a stark story of disruption. Gartner predicts that traditional search engine volume will decline by 25% by 2026, largely due to the rise of AI chatbots. Google&#x27;s AI Overviews now appear on billions of searches monthly. Princeton University researchers have found that optimizing for these new AI systems can increase visibility by up to 40%.\"Search used to mean that you had to make Google happy,\" McConnell explained. \"But now you have to optimize for four different Google interfaces — traditional search, AI Mode, Gemini, and AI Overviews — each with different criteria. And then ChatGPT, Claude, and Perplexity each work differently on top of that.\"This fragmentation is creating chaos for businesses that have spent decades perfecting their Google search strategies. A recent Forrester study found that 95% of B2B buyers plan to use generative AI in future purchase decisions. Yet most companies remain woefully unprepared for this shift.\"Anybody who&#x27;s not on this right now is losing out,\" said Cihan Tas, Geostar&#x27;s co-founder and chief technology officer. \"We see lawyers getting 50% of their clients through ChatGPT now. It&#x27;s just such a massive shift.\"How language models read the web differently than search engines ever didWhat Geostar and a growing cohort of competitors call Generative Engine Optimization or GEO represents a fundamental departure from traditional search engine optimization. Where SEO focused primarily on keywords and backlinks, GEO requires understanding how large language models parse, understand, and synthesize information across the entire web.The technical challenges are formidable. Every website must now function as what Tas calls \"its own little database\" capable of being understood by dozens of different AI crawlers, each with unique requirements and preferences. Google&#x27;s systems pull from their existing search index. ChatGPT relies heavily on structured data and specific content formats. Perplexity shows a marked preference for Wikipedia and authoritative sources.\"Now the strategy is actually being concise, clear, and answering the question, because that&#x27;s directly what the AI is looking for,\" Tas explained. \"You&#x27;re actually tuning for somewhat of an intelligent model that makes decisions similarly to how we make decisions.\"Consider schema markup, the structured data that helps machines understand web content. While only 30% of websites currently implement comprehensive schema, research shows that pages with proper markup are 36% more likely to appear in AI-generated summaries. Yet most businesses don&#x27;t even know what schema markup is, let alone how to implement it effectively.Inside Geostar&#x27;s AI agents that optimize websites continuously without human interventionGeostar&#x27;s solution embodies a broader trend in enterprise software: the rise of autonomous AI agents that can take action on behalf of businesses. The company embeds what it calls \"ambient agents\" directly into client websites, continuously optimizing content, technical configurations, and even creating new pages based on patterns learned across its entire customer base.\"Once we learn something about the way content performs, or the way a technical optimization performs, we can then syndicate that same change across the remaining users so everyone in the network benefits,\" McConnell said.For RedSift, a cybersecurity company, this approach yielded a 27% increase in AI mentions within three months. In one case, Geostar identified an opportunity to rank for \"best DMARC vendors,\" a high-value search term in the email security space. The company&#x27;s agents created and optimized content that achieved first-page rankings on both Google and ChatGPT within four days.\"We&#x27;re doing the work of an agency that charges $10,000 a month,\" McConnell said, noting that Geostar&#x27;s pricing ranges from $1,000 to $3,000 monthly. \"AI creates a situation where, for the first time ever, you can take action like an agency, but you can scale like software.\"Why brand mentions without links now matter more than ever in the AI eraThe implications of this shift extend far beyond technical optimizations. In the SEO era, a mention without a link was essentially worthless. In the age of AI, that calculus has reversed. AI systems can analyze vast amounts of text to understand sentiment and context, meaning that brand mentions on Reddit, in news articles, or across social media now directly influence how AI systems describe and recommend companies.\"If the New York Times mentions a company without linking to it, that company would actually benefit from that in an AI system,\" McConnell explained. \"AI has the ability to do mass analysis of huge amounts of text, and it will understand the sentiment around that mention.\"This has created new vulnerabilities. Research from the Indian Institute of Technology and Princeton found that AI systems show systematic bias toward third-party sources over brand-owned content. A company&#x27;s own website might be less influential in shaping AI perceptions than what others say about it online.The shifting landscape has also disrupted traditional metrics of success. Where SEO focused on rankings and click-through rates, GEO must account for what researchers call impression metrics — how prominently and positively a brand appears within AI-generated responses, even when users never click through to the source.A growing market as SEO veterans and new players rush to dominate AI optimizationGeostar is hardly alone in recognizing this opportunity. Companies like Brandlight, Profound, and Goodie are all racing to help businesses navigate the new landscape. The SEO industry, worth approximately $80 billion globally, is scrambling to adapt, with established players like Semrush and Ahrefs rushing to add AI visibility tracking features.But the company&#x27;s founders, who previously built and sold a Y-Combinator-backed e-commerce optimization startup called Monto, believe their technical approach gives them an edge. Unlike competitors who largely provide dashboards and recommendations, Geostar&#x27;s agents actively implement changes.\"Everyone is taking the same solutions that worked in the last era and just saying, &#x27;We&#x27;ll do this for AI instead,&#x27;\" McConnell argued. \"But when you think about what AI is truly capable of, it can actually do the work for you.\"The stakes are particularly high for small and medium-sized businesses. While large corporations can afford to hire specialized consultants or build internal expertise, smaller companies risk becoming invisible in AI-mediated search. Geostar sees this as its primary market opportunity: nearly half of the 33.2 million small businesses in America invest in SEO. Among the roughly 418,000 law firms in the U.S., many spend between $2,500 and $5,000 monthly on search optimization to stay competitive in local markets.From Kurdish village to PearX: The unlikely partnership building the future of searchFor Tas, whose journey to Silicon Valley began in a tiny Kurdish village in Turkey with just 50 residents, the current moment represents both opportunity and responsibility. His mother&#x27;s battle with cancer prevented him from finishing college, leading him to teach himself programming and eventually partner with McConnell — whom he worked with for an entire year before they ever met in person.\"We&#x27;re not just copy and pasting a solution that was existing before,\" Tas emphasized. \"This is something that&#x27;s different and was uniquely possible today.\"Looking forward, the transformation of search appears to be accelerating rather than stabilizing. Industry observers predict that search functionality will soon be embedded in productivity tools, wearables, and even augmented reality interfaces. Each new surface will likely have its own optimization requirements, further complicating the landscape.\"Soon, search will be in our eyes, in our ears,\" McConnell predicted. \"When Siri breaks out of her prison, whatever that Jony Ive and OpenAI are building together will be like a multimodal search interface.\"The technical challenges are matched by ethical ones. As businesses scramble to influence AI recommendations, questions arise about manipulation, fairness, and transparency. There&#x27;s currently no oversight body or established best practices for GEO, creating what some critics describe as a Wild West environment.As businesses grapple with these changes, one thing seems certain: the era of simply optimizing for Google is over. In its place is emerging a far more complex ecosystem where success requires understanding not just how machines index information, but how they think about it, synthesize it, and ultimately decide what to recommend to humans seeking answers.For the millions of businesses whose survival depends on being discovered online, mastering this new paradigm isn&#x27;t just an opportunity — it&#x27;s an existential imperative. The question is no longer whether to optimize for AI search, but whether companies can adapt quickly enough to remain visible as the pace of change accelerates.McConnell&#x27;s parents at the Olympics were a preview of what&#x27;s already becoming the norm. They didn&#x27;t search for tour companies in Paris. They didn&#x27;t scroll through results or click on links. They simply asked ChatGPT what to do — and the AI decided which businesses deserved their attention.In the new economy of discovery, the businesses that win won&#x27;t be the ones that rank highest. They&#x27;ll be the ones AI chooses to recommend.",
          "content": "The moment Mack McConnell knew everything about search had changed came last summer at the Paris Olympics. His parents, independently and without prompting, had both turned to ChatGPT to plan their day&#x27;s activities in the French capital. The AI recommended specific tour companies, restaurants, and attractions — businesses that had won a new kind of visibility lottery.\"It was almost like this intuitive interface that older people were as comfortable with using as younger people,\" McConnell recalled in an exclusive interview with VentureBeat. \"I could just see the businesses were now being recommended.\"That observation has now become the foundation of Geostar, a Pear VC-backed startup that&#x27;s racing to help businesses navigate what may be the most significant shift in online discovery since Google&#x27;s founding. The company, which recently emerged from stealth with impressive early customer traction, is betting that the rise of AI-powered search represents a significant opportunity to reinvent how companies get found online. The global AI search engine market alone is projected to grow from $43.63 billion in 2025 to $108.88 billion by 2032.Already the fastest-growing company in PearX&#x27;s latest cohort, Geostar is fast approaching $1 million in annual recurring revenue in just four months — with only two founders and no employees.Why Gartner predicts traditional search volume will decline 25% by 2026The numbers tell a stark story of disruption. Gartner predicts that traditional search engine volume will decline by 25% by 2026, largely due to the rise of AI chatbots. Google&#x27;s AI Overviews now appear on billions of searches monthly. Princeton University researchers have found that optimizing for these new AI systems can increase visibility by up to 40%.\"Search used to mean that you had to make Google happy,\" McConnell explained. \"But now you have to optimize for four different Google interfaces — traditional search, AI Mode, Gemini, and AI Overviews — each with different criteria. And then ChatGPT, Claude, and Perplexity each work differently on top of that.\"This fragmentation is creating chaos for businesses that have spent decades perfecting their Google search strategies. A recent Forrester study found that 95% of B2B buyers plan to use generative AI in future purchase decisions. Yet most companies remain woefully unprepared for this shift.\"Anybody who&#x27;s not on this right now is losing out,\" said Cihan Tas, Geostar&#x27;s co-founder and chief technology officer. \"We see lawyers getting 50% of their clients through ChatGPT now. It&#x27;s just such a massive shift.\"How language models read the web differently than search engines ever didWhat Geostar and a growing cohort of competitors call Generative Engine Optimization or GEO represents a fundamental departure from traditional search engine optimization. Where SEO focused primarily on keywords and backlinks, GEO requires understanding how large language models parse, understand, and synthesize information across the entire web.The technical challenges are formidable. Every website must now function as what Tas calls \"its own little database\" capable of being understood by dozens of different AI crawlers, each with unique requirements and preferences. Google&#x27;s systems pull from their existing search index. ChatGPT relies heavily on structured data and specific content formats. Perplexity shows a marked preference for Wikipedia and authoritative sources.\"Now the strategy is actually being concise, clear, and answering the question, because that&#x27;s directly what the AI is looking for,\" Tas explained. \"You&#x27;re actually tuning for somewhat of an intelligent model that makes decisions similarly to how we make decisions.\"Consider schema markup, the structured data that helps machines understand web content. While only 30% of websites currently implement comprehensive schema, research shows that pages with proper markup are 36% more likely to appear in AI-generated summaries. Yet most businesses don&#x27;t even know what schema markup is, let alone how to implement it effectively.Inside Geostar&#x27;s AI agents that optimize websites continuously without human interventionGeostar&#x27;s solution embodies a broader trend in enterprise software: the rise of autonomous AI agents that can take action on behalf of businesses. The company embeds what it calls \"ambient agents\" directly into client websites, continuously optimizing content, technical configurations, and even creating new pages based on patterns learned across its entire customer base.\"Once we learn something about the way content performs, or the way a technical optimization performs, we can then syndicate that same change across the remaining users so everyone in the network benefits,\" McConnell said.For RedSift, a cybersecurity company, this approach yielded a 27% increase in AI mentions within three months. In one case, Geostar identified an opportunity to rank for \"best DMARC vendors,\" a high-value search term in the email security space. The company&#x27;s agents created and optimized content that achieved first-page rankings on both Google and ChatGPT within four days.\"We&#x27;re doing the work of an agency that charges $10,000 a month,\" McConnell said, noting that Geostar&#x27;s pricing ranges from $1,000 to $3,000 monthly. \"AI creates a situation where, for the first time ever, you can take action like an agency, but you can scale like software.\"Why brand mentions without links now matter more than ever in the AI eraThe implications of this shift extend far beyond technical optimizations. In the SEO era, a mention without a link was essentially worthless. In the age of AI, that calculus has reversed. AI systems can analyze vast amounts of text to understand sentiment and context, meaning that brand mentions on Reddit, in news articles, or across social media now directly influence how AI systems describe and recommend companies.\"If the New York Times mentions a company without linking to it, that company would actually benefit from that in an AI system,\" McConnell explained. \"AI has the ability to do mass analysis of huge amounts of text, and it will understand the sentiment around that mention.\"This has created new vulnerabilities. Research from the Indian Institute of Technology and Princeton found that AI systems show systematic bias toward third-party sources over brand-owned content. A company&#x27;s own website might be less influential in shaping AI perceptions than what others say about it online.The shifting landscape has also disrupted traditional metrics of success. Where SEO focused on rankings and click-through rates, GEO must account for what researchers call impression metrics — how prominently and positively a brand appears within AI-generated responses, even when users never click through to the source.A growing market as SEO veterans and new players rush to dominate AI optimizationGeostar is hardly alone in recognizing this opportunity. Companies like Brandlight, Profound, and Goodie are all racing to help businesses navigate the new landscape. The SEO industry, worth approximately $80 billion globally, is scrambling to adapt, with established players like Semrush and Ahrefs rushing to add AI visibility tracking features.But the company&#x27;s founders, who previously built and sold a Y-Combinator-backed e-commerce optimization startup called Monto, believe their technical approach gives them an edge. Unlike competitors who largely provide dashboards and recommendations, Geostar&#x27;s agents actively implement changes.\"Everyone is taking the same solutions that worked in the last era and just saying, &#x27;We&#x27;ll do this for AI instead,&#x27;\" McConnell argued. \"But when you think about what AI is truly capable of, it can actually do the work for you.\"The stakes are particularly high for small and medium-sized businesses. While large corporations can afford to hire specialized consultants or build internal expertise, smaller companies risk becoming invisible in AI-mediated search. Geostar sees this as its primary market opportunity: nearly half of the 33.2 million small businesses in America invest in SEO. Among the roughly 418,000 law firms in the U.S., many spend between $2,500 and $5,000 monthly on search optimization to stay competitive in local markets.From Kurdish village to PearX: The unlikely partnership building the future of searchFor Tas, whose journey to Silicon Valley began in a tiny Kurdish village in Turkey with just 50 residents, the current moment represents both opportunity and responsibility. His mother&#x27;s battle with cancer prevented him from finishing college, leading him to teach himself programming and eventually partner with McConnell — whom he worked with for an entire year before they ever met in person.\"We&#x27;re not just copy and pasting a solution that was existing before,\" Tas emphasized. \"This is something that&#x27;s different and was uniquely possible today.\"Looking forward, the transformation of search appears to be accelerating rather than stabilizing. Industry observers predict that search functionality will soon be embedded in productivity tools, wearables, and even augmented reality interfaces. Each new surface will likely have its own optimization requirements, further complicating the landscape.\"Soon, search will be in our eyes, in our ears,\" McConnell predicted. \"When Siri breaks out of her prison, whatever that Jony Ive and OpenAI are building together will be like a multimodal search interface.\"The technical challenges are matched by ethical ones. As businesses scramble to influence AI recommendations, questions arise about manipulation, fairness, and transparency. There&#x27;s currently no oversight body or established best practices for GEO, creating what some critics describe as a Wild West environment.As businesses grapple with these changes, one thing seems certain: the era of simply optimizing for Google is over. In its place is emerging a far more complex ecosystem where success requires understanding not just how machines index information, but how they think about it, synthesize it, and ultimately decide what to recommend to humans seeking answers.For the millions of businesses whose survival depends on being discovered online, mastering this new paradigm isn&#x27;t just an opportunity — it&#x27;s an existential imperative. The question is no longer whether to optimize for AI search, but whether companies can adapt quickly enough to remain visible as the pace of change accelerates.McConnell&#x27;s parents at the Olympics were a preview of what&#x27;s already becoming the norm. They didn&#x27;t search for tour companies in Paris. They didn&#x27;t scroll through results or click on links. They simply asked ChatGPT what to do — and the AI decided which businesses deserved their attention.In the new economy of discovery, the businesses that win won&#x27;t be the ones that rank highest. They&#x27;ll be the ones AI chooses to recommend.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5JXMNBhUMiSimHDDeX6ODt/2793b1842c2ef9825b7127d7bbd65f4f/_Geostar-2.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/from-static-classifiers-to-reasoning-engines-openais-new-model-rethinks",
          "published_at": "Wed, 29 Oct 2025 04:00:00 GMT",
          "title": "From static classifiers to reasoning engines: OpenAI’s new model rethinks content moderation",
          "standfirst": "Enterprises, eager to ensure any AI models they use adhere to safety and safe-use policies, fine-tune LLMs so they do not respond to unwanted queries. However, much of the safeguarding and red teaming happens before deployment, “baking in” policies before users fully test the models’ capabilities in production. OpenAI believes it can offer a more flexible option for enterprises and encourage more companies to bring in safety policies. The company has released two open-weight models under research preview that it believes will make enterprises and models more flexible in terms of safeguards. gpt-oss-safeguard-120b and gpt-oss-safeguard-20b will be available on a permissive Apache 2.0 license. The models are fine-tuned versions of OpenAI’s open-source gpt-oss, released in August, marking the first release in the oss family since the summer.In a blog post, OpenAI said oss-safeguard uses reasoning “to directly interpret a developer-provider policy at inference time — classifying user messages, completions and full chats according to the developer’s needs.”The company explained that, since the model uses a chain-of-thought (CoT), developers can get explanations of the model&#x27;s decisions for review. “Additionally, the policy is provided during inference, rather than being trained into the model, so it is easy for developers to iteratively revise policies to increase performance,\" OpenAI said in its post. \"This approach, which we initially developed for internal use, is significantly more flexible than the traditional method of training a classifier to indirectly infer a decision boundary from a large number of labeled examples.\" Developers can download both models from Hugging Face. Flexibility versus baking inAt the onset, AI models will not know a company’s preferred safety triggers. While model providers do red-team models and platforms, these safeguards are intended for broader use. Companies like Microsoft and Amazon Web Services even offer platforms to bring guardrails to AI applications and agents. Enterprises use safety classifiers to help train a model to recognize patterns of good or bad inputs. This helps the models learn which queries they shouldn’t reply to. It also helps ensure that the models do not drift and answer accurately.“Traditional classifiers can have high performance, with low latency and operating cost,\" OpenAI said. \"But gathering a sufficient quantity of training examples can be time-consuming and costly, and updating or changing the policy requires re-training the classifier.\"The models takes in two inputs at once before it outputs a conclusion on where the content fails. It takes a policy and the content to classify under its guidelines. OpenAI said the models work best in situations where: The potential harm is emerging or evolving, and policies need to adapt quickly.The domain is highly nuanced and difficult for smaller classifiers to handle.Developers don’t have enough samples to train a high-quality classifier for each risk on their platform.Latency is less important than producing high-quality, explainable labels.The company said gpt-oss-safeguard “is different because its reasoning capabilities allow developers to apply any policy,” even ones they’ve written during inference. The models are based on OpenAI’s internal tool, the Safety Reasoner, which enables its teams to be more iterative in setting guardrails. They often begin with very strict safety policies, “and use relatively large amounts of compute where needed,” then adjust policies as they move the model through production and risk assessments change. Performing safetyOpenAI said the gpt-oss-safeguard models outperformed its GPT-5-thinking and the original gpt-oss models on multipolicy accuracy based on benchmark testing. It also ran the models on the ToxicChat public benchmark, where they performed well, although GPT-5-thinking and the Safety Reasoner slightly edged them out.But there is concern that this approach could bring a centralization of safety standards.“Safety is not a well-defined concept. Any implementation of safety standards will reflect the values and priorities of the organization that creates it, as well as the limits and deficiencies of its models,” said John Thickstun, an assistant professor of computer science at Cornell University. “If industry as a whole adopts standards developed by OpenAI, we risk institutionalizing one particular perspective on safety and short-circuiting broader investigations into the safety needs for AI deployments across many sectors of society.”It should also be noted that OpenAI did not release the base model for the oss family of models, so developers cannot fully iterate on them. OpenAI, however, is confident that the developer community can help refine gpt-oss-safeguard. It will host a Hackathon on December 8 in San Francisco.",
          "content": "Enterprises, eager to ensure any AI models they use adhere to safety and safe-use policies, fine-tune LLMs so they do not respond to unwanted queries. However, much of the safeguarding and red teaming happens before deployment, “baking in” policies before users fully test the models’ capabilities in production. OpenAI believes it can offer a more flexible option for enterprises and encourage more companies to bring in safety policies. The company has released two open-weight models under research preview that it believes will make enterprises and models more flexible in terms of safeguards. gpt-oss-safeguard-120b and gpt-oss-safeguard-20b will be available on a permissive Apache 2.0 license. The models are fine-tuned versions of OpenAI’s open-source gpt-oss, released in August, marking the first release in the oss family since the summer.In a blog post, OpenAI said oss-safeguard uses reasoning “to directly interpret a developer-provider policy at inference time — classifying user messages, completions and full chats according to the developer’s needs.”The company explained that, since the model uses a chain-of-thought (CoT), developers can get explanations of the model&#x27;s decisions for review. “Additionally, the policy is provided during inference, rather than being trained into the model, so it is easy for developers to iteratively revise policies to increase performance,\" OpenAI said in its post. \"This approach, which we initially developed for internal use, is significantly more flexible than the traditional method of training a classifier to indirectly infer a decision boundary from a large number of labeled examples.\" Developers can download both models from Hugging Face. Flexibility versus baking inAt the onset, AI models will not know a company’s preferred safety triggers. While model providers do red-team models and platforms, these safeguards are intended for broader use. Companies like Microsoft and Amazon Web Services even offer platforms to bring guardrails to AI applications and agents. Enterprises use safety classifiers to help train a model to recognize patterns of good or bad inputs. This helps the models learn which queries they shouldn’t reply to. It also helps ensure that the models do not drift and answer accurately.“Traditional classifiers can have high performance, with low latency and operating cost,\" OpenAI said. \"But gathering a sufficient quantity of training examples can be time-consuming and costly, and updating or changing the policy requires re-training the classifier.\"The models takes in two inputs at once before it outputs a conclusion on where the content fails. It takes a policy and the content to classify under its guidelines. OpenAI said the models work best in situations where: The potential harm is emerging or evolving, and policies need to adapt quickly.The domain is highly nuanced and difficult for smaller classifiers to handle.Developers don’t have enough samples to train a high-quality classifier for each risk on their platform.Latency is less important than producing high-quality, explainable labels.The company said gpt-oss-safeguard “is different because its reasoning capabilities allow developers to apply any policy,” even ones they’ve written during inference. The models are based on OpenAI’s internal tool, the Safety Reasoner, which enables its teams to be more iterative in setting guardrails. They often begin with very strict safety policies, “and use relatively large amounts of compute where needed,” then adjust policies as they move the model through production and risk assessments change. Performing safetyOpenAI said the gpt-oss-safeguard models outperformed its GPT-5-thinking and the original gpt-oss models on multipolicy accuracy based on benchmark testing. It also ran the models on the ToxicChat public benchmark, where they performed well, although GPT-5-thinking and the Safety Reasoner slightly edged them out.But there is concern that this approach could bring a centralization of safety standards.“Safety is not a well-defined concept. Any implementation of safety standards will reflect the values and priorities of the organization that creates it, as well as the limits and deficiencies of its models,” said John Thickstun, an assistant professor of computer science at Cornell University. “If industry as a whole adopts standards developed by OpenAI, we risk institutionalizing one particular perspective on safety and short-circuiting broader investigations into the safety needs for AI deployments across many sectors of society.”It should also be noted that OpenAI did not release the base model for the oss family of models, so developers cannot fully iterate on them. OpenAI, however, is confident that the developer community can help refine gpt-oss-safeguard. It will host a Hackathon on December 8 in San Francisco.",
          "feed_position": 7,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7hdJbWzLDjzRu2QOtkbDKV/a3a7d637a3e748ccb3ff4ba06e1ff953/crimedy7_illustration_of_technological_safety_cones_--ar_169__cf756a3e-79a5-47c3-993d-cdb5f37f28a2_3.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/securitys-ai-dilemma-moving-faster-while-risking-more",
          "published_at": "Wed, 29 Oct 2025 04:00:00 GMT",
          "title": "Security's AI dilemma: Moving faster while risking more",
          "standfirst": "Presented by Splunk, a Cisco CompanyAs AI rapidly evolves from a theoretical promise to an operational reality, CISOs and CIOs face a fundamental challenge: how to harness AI&#x27;s transformative potential while maintaining the human oversight and strategic thinking that security demands. The rise of agentic AI is reshaping security operations, but success requires balancing automation with accountability.The efficiency paradox: Automation without abdicationThe pressure to adopt AI is intense. Organizations are being pushed to reduce headcount or redirect resources toward AI-driven initiatives, often without fully understanding what that transformation entails. The promise is compelling: AI can reduce investigation times from 60 minutes to just 5 minutes, potentially delivering 10x productivity improvements for security analysts.However, the critical question isn&#x27;t whether AI can automate tasks — it&#x27;s which tasks should be automated and where human judgment remains irreplaceable. The answer lies in understanding that AI excels at accelerating investigative workflows, but remediation and response actions still require human validation. Taking a system offline or quarantining an endpoint can have massive business impact. An AI making that call autonomously could inadvertently cause the very disruption it&#x27;s meant to prevent.The goal isn&#x27;t to replace security analysts but to free them for higher-value work. With routine alert triage automated, analysts can focus on red team/blue team exercises, collaborate with engineering teams on remediation, and engage in proactive threat hunting. There&#x27;s no shortage of security problems to solve — there&#x27;s a shortage of security experts to address them strategically.The trust deficit: Showing your workWhile confidence in AI&#x27;s ability to improve efficiency is high, skepticism about the quality of AI-driven decisions remains significant. Security teams need more than just AI-generated conclusions — they need transparency into how those conclusions were reached.When AI determines an alert is benign and closes it, SOC analysts need to understand the investigative steps that led to that determination. What data was examined? What patterns were identified? What alternative explanations were considered and ruled out?This transparency builds trust in AI recommendations, enables validation of AI logic, and creates opportunities for continuous improvement. Most importantly, it maintains the critical human-in-the-loop for complex judgment calls that require nuanced understanding of business context, compliance requirements, and potential cascading impacts.The future likely involves a hybrid model where autonomous capabilities are integrated into guided workflows and playbooks, with analysts remaining involved in complex decisions. The adversarial advantage: Fighting AI with AI — carefullyAI presents a dual-edged sword in security. While we&#x27;re carefully implementing AI with appropriate guardrails, adversaries face no such constraints. AI lowers the barrier to entry for attackers, enabling rapid exploit development and vulnerability discovery at scale. What was once the domain of sophisticated threat actors could soon be accessible to script kiddies armed with AI tools.The asymmetry is striking: defenders must be thoughtful and risk-averse, while attackers can experiment freely. If we make a mistake implementing autonomous security responses, we risk taking down production systems. If an attacker&#x27;s AI-driven exploit fails, they simply try again with no consequences.This creates an imperative to use AI defensively, but with appropriate caution. We must learn from attackers&#x27; techniques while maintaining the guardrails that prevent our AI from becoming the vulnerability. The recent emergence of malicious MCP (Model Context Protocol) supply chain attacks demonstrates how quickly adversaries exploit new AI infrastructure. The skills dilemma: Building capabilities while maintaining core competenciesAs AI handles more routine investigative work, a concerning question emerges: will security professionals&#x27; fundamental skills atrophy over time? This isn&#x27;t an argument against AI adoption — it&#x27;s a call for intentional skill development strategies. Organizations must balance AI-enabled efficiency with programs that maintain core competencies. This includes regular exercises that require manual investigation, cross-training that deepens understanding of underlying systems, and career paths that evolve roles rather than eliminate them.The responsibility is shared. Employers must provide tools, training, and culture that enable AI to augment rather than replace human expertise. Employees must actively engage in continuous learning, treating AI as a collaborative partner rather than a replacement for critical thinking.The identity crisis: Governing the agent explosionPerhaps the most underestimated challenge ahead is identity and access management in an agentic AI world. IDC estimates 1.3 billion agents by 2028 — each requiring identity, permissions, and governance. The complexity compounds exponentially.Overly permissive agents represent significant risk. An agent with broad administrative access could be socially engineered into taking destructive actions, approving fraudulent transactions, or exfiltrating sensitive data. The technical shortcuts engineers take to \"just make it work\" — granting excessive permissions to expedite deployment — create vulnerabilities that adversaries will exploit.Tool-based access control offers one path forward, granting agents only the specific capabilities they need. But governance frameworks must also address how LLMs themselves might learn and retain authentication information, potentially enabling impersonation attacks that bypass traditional access controls.The path forward: Start with compliance and reportingAmid these challenges, one area offers immediate, high-impact opportunity: continuous compliance and risk reporting. AI&#x27;s ability to consume vast amounts of documentation, interpret complex requirements, and generate concise summaries makes it ideal for compliance and reporting work that has traditionally consumed enormous analysts’ time. This represents a low-risk, high-value entry point for AI in security operations. The data foundation: Enabling the AI-powered SOCNone of these AI capabilities can succeed without addressing the fundamental data challenges facing security operations. SOC teams struggle with siloed data and disparate tools. Success requires a deliberate data strategy that prioritizes accessibility, quality, and unified data contexts. Security-relevant data must be immediately available to AI agents without friction, properly governed to ensure reliability, and enriched with metadata that provides the business context AI cannot understand. Closing thought: Innovation with intentionalityThe autonomous SOC is emerging — not as a light switch to flip, but as an evolutionary journey requiring continuous adaptation. Success demands that we embrace AI&#x27;s efficiency gains while maintaining the human judgment, strategic thinking, and ethical oversight that security requires.We&#x27;re not replacing security teams with AI. We&#x27;re building collaborative, multi-agent systems where human expertise guides AI capabilities toward outcomes that neither could achieve alone. That&#x27;s the promise of the agentic AI era — if we&#x27;re intentional about how we get there.Tanya Faddoul, VP Product, Customer Strategy and Chief of Staff for Splunk, a Cisco Company. Michael Fanning is Chief Information Security Officer for Splunk, a Cisco Company. Cisco Data Fabric provides the needed data architecture powered by Splunk Platform — unified data fabric, federated search capabilities, comprehensive metadata management — to unlock AI and SOC’s full potential. Learn more about Cisco Data Fabric.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Splunk, a Cisco CompanyAs AI rapidly evolves from a theoretical promise to an operational reality, CISOs and CIOs face a fundamental challenge: how to harness AI&#x27;s transformative potential while maintaining the human oversight and strategic thinking that security demands. The rise of agentic AI is reshaping security operations, but success requires balancing automation with accountability.The efficiency paradox: Automation without abdicationThe pressure to adopt AI is intense. Organizations are being pushed to reduce headcount or redirect resources toward AI-driven initiatives, often without fully understanding what that transformation entails. The promise is compelling: AI can reduce investigation times from 60 minutes to just 5 minutes, potentially delivering 10x productivity improvements for security analysts.However, the critical question isn&#x27;t whether AI can automate tasks — it&#x27;s which tasks should be automated and where human judgment remains irreplaceable. The answer lies in understanding that AI excels at accelerating investigative workflows, but remediation and response actions still require human validation. Taking a system offline or quarantining an endpoint can have massive business impact. An AI making that call autonomously could inadvertently cause the very disruption it&#x27;s meant to prevent.The goal isn&#x27;t to replace security analysts but to free them for higher-value work. With routine alert triage automated, analysts can focus on red team/blue team exercises, collaborate with engineering teams on remediation, and engage in proactive threat hunting. There&#x27;s no shortage of security problems to solve — there&#x27;s a shortage of security experts to address them strategically.The trust deficit: Showing your workWhile confidence in AI&#x27;s ability to improve efficiency is high, skepticism about the quality of AI-driven decisions remains significant. Security teams need more than just AI-generated conclusions — they need transparency into how those conclusions were reached.When AI determines an alert is benign and closes it, SOC analysts need to understand the investigative steps that led to that determination. What data was examined? What patterns were identified? What alternative explanations were considered and ruled out?This transparency builds trust in AI recommendations, enables validation of AI logic, and creates opportunities for continuous improvement. Most importantly, it maintains the critical human-in-the-loop for complex judgment calls that require nuanced understanding of business context, compliance requirements, and potential cascading impacts.The future likely involves a hybrid model where autonomous capabilities are integrated into guided workflows and playbooks, with analysts remaining involved in complex decisions. The adversarial advantage: Fighting AI with AI — carefullyAI presents a dual-edged sword in security. While we&#x27;re carefully implementing AI with appropriate guardrails, adversaries face no such constraints. AI lowers the barrier to entry for attackers, enabling rapid exploit development and vulnerability discovery at scale. What was once the domain of sophisticated threat actors could soon be accessible to script kiddies armed with AI tools.The asymmetry is striking: defenders must be thoughtful and risk-averse, while attackers can experiment freely. If we make a mistake implementing autonomous security responses, we risk taking down production systems. If an attacker&#x27;s AI-driven exploit fails, they simply try again with no consequences.This creates an imperative to use AI defensively, but with appropriate caution. We must learn from attackers&#x27; techniques while maintaining the guardrails that prevent our AI from becoming the vulnerability. The recent emergence of malicious MCP (Model Context Protocol) supply chain attacks demonstrates how quickly adversaries exploit new AI infrastructure. The skills dilemma: Building capabilities while maintaining core competenciesAs AI handles more routine investigative work, a concerning question emerges: will security professionals&#x27; fundamental skills atrophy over time? This isn&#x27;t an argument against AI adoption — it&#x27;s a call for intentional skill development strategies. Organizations must balance AI-enabled efficiency with programs that maintain core competencies. This includes regular exercises that require manual investigation, cross-training that deepens understanding of underlying systems, and career paths that evolve roles rather than eliminate them.The responsibility is shared. Employers must provide tools, training, and culture that enable AI to augment rather than replace human expertise. Employees must actively engage in continuous learning, treating AI as a collaborative partner rather than a replacement for critical thinking.The identity crisis: Governing the agent explosionPerhaps the most underestimated challenge ahead is identity and access management in an agentic AI world. IDC estimates 1.3 billion agents by 2028 — each requiring identity, permissions, and governance. The complexity compounds exponentially.Overly permissive agents represent significant risk. An agent with broad administrative access could be socially engineered into taking destructive actions, approving fraudulent transactions, or exfiltrating sensitive data. The technical shortcuts engineers take to \"just make it work\" — granting excessive permissions to expedite deployment — create vulnerabilities that adversaries will exploit.Tool-based access control offers one path forward, granting agents only the specific capabilities they need. But governance frameworks must also address how LLMs themselves might learn and retain authentication information, potentially enabling impersonation attacks that bypass traditional access controls.The path forward: Start with compliance and reportingAmid these challenges, one area offers immediate, high-impact opportunity: continuous compliance and risk reporting. AI&#x27;s ability to consume vast amounts of documentation, interpret complex requirements, and generate concise summaries makes it ideal for compliance and reporting work that has traditionally consumed enormous analysts’ time. This represents a low-risk, high-value entry point for AI in security operations. The data foundation: Enabling the AI-powered SOCNone of these AI capabilities can succeed without addressing the fundamental data challenges facing security operations. SOC teams struggle with siloed data and disparate tools. Success requires a deliberate data strategy that prioritizes accessibility, quality, and unified data contexts. Security-relevant data must be immediately available to AI agents without friction, properly governed to ensure reliability, and enriched with metadata that provides the business context AI cannot understand. Closing thought: Innovation with intentionalityThe autonomous SOC is emerging — not as a light switch to flip, but as an evolutionary journey requiring continuous adaptation. Success demands that we embrace AI&#x27;s efficiency gains while maintaining the human judgment, strategic thinking, and ethical oversight that security requires.We&#x27;re not replacing security teams with AI. We&#x27;re building collaborative, multi-agent systems where human expertise guides AI capabilities toward outcomes that neither could achieve alone. That&#x27;s the promise of the agentic AI era — if we&#x27;re intentional about how we get there.Tanya Faddoul, VP Product, Customer Strategy and Chief of Staff for Splunk, a Cisco Company. Michael Fanning is Chief Information Security Officer for Splunk, a Cisco Company. Cisco Data Fabric provides the needed data architecture powered by Splunk Platform — unified data fabric, federated search capabilities, comprehensive metadata management — to unlock AI and SOC’s full potential. Learn more about Cisco Data Fabric.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 8,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1xzoYYdBHblQvb1NzXRGSt/8898cd969ec3062a752682e7dae6a437/AdobeStock_1081293355.jpeg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/agentic-ai-is-all-about-the-context-engineering-that-is",
          "published_at": "Wed, 29 Oct 2025 04:00:00 GMT",
          "title": "Agentic AI is all about the context — engineering, that is",
          "standfirst": "Presented by ElasticAs organizations scramble to enact agentic AI solutions, accessing proprietary data from all the nooks and crannies will be keyBy now, most organizations have heard of agentic AI, which are systems that “think” by autonomously gathering tools, data and other sources of information to return an answer. But here’s the rub: reliability and relevance depend on delivering accurate context. In most enterprises, this context is scattered across various unstructured data sources, including documents, emails, business apps, and customer feedback. As organizations look ahead to 2026, solving this problem will be key to accelerating agentic AI rollouts around the world, says Ken Exner, chief product officer at Elastic. \"People are starting to realize that to do agentic AI correctly, you have to have relevant data,\" Exner says. \"Relevance is critical in the context of agentic AI, because that AI is taking action on your behalf. When people struggle to build AI applications, I can almost guarantee you the problem is relevance.”Agents everywhereThe struggle could be entering a make-or-break period as organizations scramble for competitive edge or to create new efficiencies. A Deloitte study predicts that by 2026, more than 60% of large enterprises will have deployed agentic AI at scale, marking a major increase from experimental phases to mainstream implementation. And researcher Gartner forecasts that by the end of 2026, 40% of all enterprise applications will incorporate task-specific agents, up from less than 5% in 2025. Adding task specialization capabilities evolves AI assistants into context-aware AI agents.Enter context engineeringThe process for getting the relevant context into agents at the right time is known as context engineering. It not only ensures that an agentic application has the data it needs to provide accurate, in-depth responses, it helps the large language model (LLM) understand what tools it needs to find and use that data, and how to call those APIs. While there are now open-source standards such as the Model Context Protocol (MCP) that allow LLMs to connect to and communicate with external data, there are few platforms that let organizations build precise AI agents that use your data and combine retrieval, governance, and orchestration in one place, natively. Elasticsearch has always been a leading platform for the core of context engineering. It recently released a new feature within Elasticsearch called Agent Builder, which simplifies the entire operational lifecycle of agents: development, configuration, execution, customization, and observability.Agent Builder helps build MCP tools on private data using various techniques, including Elasticsearch Query Language, a piped query language for filtering, transforming, and analyzing data, or workflow modeling. Users can then take various tools and combine them with prompts and an LLM to build an agent. Agent Builder offers a configurable, out-of-the-box conversational agent that allows you to chat with the data in the index, and it also gives users the ability to build one from scratch using various tools and prompts on top of private data. \"Data is the center of our world at Elastic. We’re trying to make sure that you have the tools you need to put that data to work,\" Exner explains. \"The second you open up Agent Builder, you point it to an index in Elasticsearch, and you can begin chatting with any data you connect this to, any data that’s indexed in Elasticsearch — or from external sources through integrations.”Context engineering as a disciplinePrompt and context engineering is becoming a discipli. It’s not something you need a computer science degree in, but more classes and best practices will emerge, because there’s an art to it. \"We want to make it very simple to do that,\" Exner says. \"The thing that people will have to figure out is, how do you drive automation with AI? That’s what’s going to drive productivity. The people who are focused on that will see more success.\"Beyond that, other context engineering patterns will emerge. The industry has gone from prompt engineering to retrieval-augmented generation, where information is passed to the LLM in a context window, to MCP solutions that help LLMs with tool selection. But it won&#x27;t stop there.\"Given how fast things are moving, I will guarantee that new patterns will emerge quite quickly,\" Exner says. \"There will still be context engineering, but they’ll be new patterns for how to share data with an LLM, how to get it to be grounded in the right information. And I predict more patterns that make it possible for the LLM to understand private data that it’s not been trained on.\"Agent Builder is available now as a tech preview. Get started with an Elastic Cloud Trial, and check out the documentation for Agent Builder here.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by ElasticAs organizations scramble to enact agentic AI solutions, accessing proprietary data from all the nooks and crannies will be keyBy now, most organizations have heard of agentic AI, which are systems that “think” by autonomously gathering tools, data and other sources of information to return an answer. But here’s the rub: reliability and relevance depend on delivering accurate context. In most enterprises, this context is scattered across various unstructured data sources, including documents, emails, business apps, and customer feedback. As organizations look ahead to 2026, solving this problem will be key to accelerating agentic AI rollouts around the world, says Ken Exner, chief product officer at Elastic. \"People are starting to realize that to do agentic AI correctly, you have to have relevant data,\" Exner says. \"Relevance is critical in the context of agentic AI, because that AI is taking action on your behalf. When people struggle to build AI applications, I can almost guarantee you the problem is relevance.”Agents everywhereThe struggle could be entering a make-or-break period as organizations scramble for competitive edge or to create new efficiencies. A Deloitte study predicts that by 2026, more than 60% of large enterprises will have deployed agentic AI at scale, marking a major increase from experimental phases to mainstream implementation. And researcher Gartner forecasts that by the end of 2026, 40% of all enterprise applications will incorporate task-specific agents, up from less than 5% in 2025. Adding task specialization capabilities evolves AI assistants into context-aware AI agents.Enter context engineeringThe process for getting the relevant context into agents at the right time is known as context engineering. It not only ensures that an agentic application has the data it needs to provide accurate, in-depth responses, it helps the large language model (LLM) understand what tools it needs to find and use that data, and how to call those APIs. While there are now open-source standards such as the Model Context Protocol (MCP) that allow LLMs to connect to and communicate with external data, there are few platforms that let organizations build precise AI agents that use your data and combine retrieval, governance, and orchestration in one place, natively. Elasticsearch has always been a leading platform for the core of context engineering. It recently released a new feature within Elasticsearch called Agent Builder, which simplifies the entire operational lifecycle of agents: development, configuration, execution, customization, and observability.Agent Builder helps build MCP tools on private data using various techniques, including Elasticsearch Query Language, a piped query language for filtering, transforming, and analyzing data, or workflow modeling. Users can then take various tools and combine them with prompts and an LLM to build an agent. Agent Builder offers a configurable, out-of-the-box conversational agent that allows you to chat with the data in the index, and it also gives users the ability to build one from scratch using various tools and prompts on top of private data. \"Data is the center of our world at Elastic. We’re trying to make sure that you have the tools you need to put that data to work,\" Exner explains. \"The second you open up Agent Builder, you point it to an index in Elasticsearch, and you can begin chatting with any data you connect this to, any data that’s indexed in Elasticsearch — or from external sources through integrations.”Context engineering as a disciplinePrompt and context engineering is becoming a discipli. It’s not something you need a computer science degree in, but more classes and best practices will emerge, because there’s an art to it. \"We want to make it very simple to do that,\" Exner says. \"The thing that people will have to figure out is, how do you drive automation with AI? That’s what’s going to drive productivity. The people who are focused on that will see more success.\"Beyond that, other context engineering patterns will emerge. The industry has gone from prompt engineering to retrieval-augmented generation, where information is passed to the LLM in a context window, to MCP solutions that help LLMs with tool selection. But it won&#x27;t stop there.\"Given how fast things are moving, I will guarantee that new patterns will emerge quite quickly,\" Exner says. \"There will still be context engineering, but they’ll be new patterns for how to share data with an LLM, how to get it to be grounded in the right information. And I predict more patterns that make it possible for the LLM to understand private data that it’s not been trained on.\"Agent Builder is available now as a tech preview. Get started with an Elastic Cloud Trial, and check out the documentation for Agent Builder here.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 9,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3HhYB9aUXlzxC0Q4V716ck/a33201a5ce2da5b486e6a20da9abbb52/AdobeStock_703274424.jpeg?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/bwRyL7w9MR1MG2IrgGTzg/9ecc1886c047d9f1eb5335e80e67fc14/ChatGPT_Image_Oct_30__2025__05_01_04_PM.png?w=300&q=30",
      "popularity_score": 2013.3888966666666,
      "ai_summary": [
        "OpenAI introduced Aardvark, a GPT-5-powered security agent.",
        "Aardvark is designed for code analysis, vulnerability detection, and patching.",
        "It uses a multi-stage, LLM-driven approach for continuous analysis.",
        "The agent is being tested on internal and external codebases.",
        "Aardvark follows a structured pipeline for threat modeling and validation."
      ]
    },
    {
      "id": "cluster_10",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 22:01:59 +0000",
      "title": "Calley Means is out of the White House; Casey Means misses Senate hearing",
      "neutral_headline": "Calley Means is out of the White House; Casey Means misses Senate hearing",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/the-means-siblings-darlings-of-maha-both-out-of-the-trump-admin-for-now/",
          "published_at": "Thu, 30 Oct 2025 22:01:59 +0000",
          "title": "Calley Means is out of the White House; Casey Means misses Senate hearing",
          "standfirst": "Casey Means missed hearing on surgeon general nomination after going into labor.",
          "content": "Siblings Casey and Calley Means—wellness darlings of the Make America Healthy Again movement, despite being rife with potential conflicts of interest—are both missing from the political arena, at least for now. Casey Means, President Trump’s nominee for surgeon general, was scheduled to appear virtually at a Senate confirmation hearing today, but the hearing was postponed indefinitely after she went into labor. The hearing, it turns out, had been scheduled two days after her due date, CNN reported this morning. Meanwhile, The New York Times separately reported that Calley Means has departed from the White House, vacating his role as a “Special Government Employee,” which has a 130-day term limit. The Times reported that Calley left about a month ago when the term ended, though the White House never announced his departure, and he has continued to be identified as a government employee in press articles and at a conference. Calley, who has acted as an influential advisor to anti-vaccine health secretary Robert F. Kennedy Jr., told the Times that the press articles and his conference biography were inaccurate.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2210915866-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2210915866-1152x648.jpg",
      "popularity_score": 347.30528555555554,
      "ai_summary": [
        "Casey Means missed a Senate hearing on a surgeon general nomination.",
        "She was unable to attend due to going into labor.",
        "Calley Means is no longer working at the White House.",
        "The news involves personnel changes and scheduling conflicts.",
        "The events highlight the personal and professional lives of individuals."
      ]
    },
    {
      "id": "cluster_25",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 20:29:43 +0000",
      "title": "Leaker reveals which Pixels are vulnerable to Cellebrite phone hacking",
      "neutral_headline": "Cellebrite Can Extract Data From Most Pixel Phones",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/leaker-reveals-which-pixels-are-vulnerable-to-cellebrite-phone-hacking/",
          "published_at": "Thu, 30 Oct 2025 20:29:43 +0000",
          "title": "Leaker reveals which Pixels are vulnerable to Cellebrite phone hacking",
          "standfirst": "Cellebrite can apparently extract data from most Pixel phones, unless they're running GrapheneOS.",
          "content": "Despite being a vast repository of personal information, smartphones used to have little by way of security. That has thankfully changed, but companies like Cellebrite offer law enforcement tools that can bypass security on some devices. The company keeps the specifics quiet, but an anonymous individual recently logged in to a Cellebrite briefing and came away with a list of which of Google’s Pixel phones are vulnerable to Cellebrite phone hacking. This person, who goes by the handle rogueFed, posted screenshots from the recent Microsoft Teams meeting to the GrapheneOS forums (spotted by 404 Media). GrapheneOS is an Android-based operating system that can be installed on select phones, including Pixels. It ships with enhanced security features and no Google services. Because of its popularity among the security-conscious, Cellebrite apparently felt the need to include it in its matrix of Pixel phone support. The screenshot includes data on the Pixel 6, Pixel 7, Pixel 8, and Pixel 9 family. It does not list the Pixel 10 series, which launched just a few months ago. The phone support is split up into three different conditions: before first unlock, after first unlock, and unlocked. The before first unlock (BFU) state means the phone has not been unlocked since restarting, so all data is encrypted. This is traditionally the most secure state for a phone. In the after first unlock (AFU) state, data extraction is easier. And naturally, an unlocked phone is open season on your data.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/Google-Pixel-10-18-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/Google-Pixel-10-18-1152x648.jpg",
      "popularity_score": 341.7675077777778,
      "ai_summary": [
        "Cellebrite can extract data from most Pixel phones, according to a leaker.",
        "GrapheneOS is the only exception, preventing data extraction by Cellebrite.",
        "The leak reveals vulnerabilities in Pixel phone security.",
        "This information highlights potential privacy risks for Pixel users.",
        "The leak underscores the importance of secure operating systems."
      ]
    },
    {
      "id": "cluster_21",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 21:05:26 +0000",
      "title": "Man finally released a month after absurd arrest for reposting Trump meme",
      "neutral_headline": "Man Released After Arrest for Reposting Trump Meme",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/man-finally-released-a-month-after-absurd-arrest-for-reposting-trump-meme/",
          "published_at": "Thu, 30 Oct 2025 21:05:26 +0000",
          "title": "Man finally released a month after absurd arrest for reposting Trump meme",
          "standfirst": "Bodycam footage undermined sheriff's \"true threat\" justification for the arrest.",
          "content": "The saga of a 61-year-old man jailed for more than a month after reposting a Facebook meme has ended, but free speech advocates are still reeling in the wake. On Wednesday, Larry Bushart was released from Perry County Jail, where he had spent weeks unable to make bail, which a judge set at $2 million. Prosecutors have not explained why the charges against him were dropped, according to The Intercept, which has been tracking the case closely. However, officials faced mounting pressure following media coverage and a social media campaign called “Free Larry Bushart,” which stoked widespread concern over suspected police censorship of a US citizen over his political views. How a meme landed a man in jail Bushart’s arrest came after he decided to troll a message thread about a Charlie Kirk vigil in a Facebook group called “What’s Happening in Perry County, TN.” He posted a meme showing a picture of Donald Trump saying, “We should get over it.” The meme included a caption that said “Donald Trump, on the Perry High School mass shooting, one day after,” and Bushart included a comment with his post that said, “This seems relevant today ….”Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1368516656-1152x648-1761855653.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1368516656-1152x648-1761855653.jpg",
      "popularity_score": 336.36278555555555,
      "ai_summary": [
        "A man was released a month after an absurd arrest for reposting a meme.",
        "Bodycam footage contradicted the sheriff's justification for the arrest.",
        "The sheriff claimed the meme constituted a \"true threat.\"",
        "The footage undermined the sheriff's claims and led to the man's release.",
        "The case highlights potential misuse of law enforcement powers."
      ]
    },
    {
      "id": "cluster_26",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 20:17:46 +0000",
      "title": "Caught cheating in class, college students “apologized” using AI—and profs called them out",
      "neutral_headline": "College Students Use AI to Apologize for Cheating",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/when-caught-cheating-in-college-dont-apologize-with-ai/",
          "published_at": "Thu, 30 Oct 2025 20:17:46 +0000",
          "title": "Caught cheating in class, college students “apologized” using AI—and profs called them out",
          "standfirst": "Time for some \"life lessons.\"",
          "content": "With a child in college and a spouse who’s a professor, I have front-row access to the unfolding debacle that is “higher education in the age of AI.” These days, students routinely submit even “personal reflection” papers that are AI generated. (And routinely appear surprised when caught.) Read a paper longer than 10 pages? Not likely—even at elite schools. Toss that sucker into an AI tool and read a quick summary instead. It’s more efficient!Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2190439539-1152x648-1761852319.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2190439539-1152x648-1761852319.jpg",
      "popularity_score": 330.5683411111111,
      "ai_summary": [
        "College students used AI to apologize after being caught cheating in class.",
        "Professors called out the students for using AI-generated apologies.",
        "The incident prompted discussions about academic integrity.",
        "The professors emphasized the need for \"life lessons\" for the students.",
        "The event highlights the evolving role of AI in education."
      ]
    },
    {
      "id": "cluster_31",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 19:36:49 +0000",
      "title": "Netflix drops a doozy of a trailer for Stranger Things S5",
      "neutral_headline": "Netflix Releases Trailer for Stranger Things Season Five",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/netflix-drops-a-doozy-of-a-trailer-for-stranger-things-s5/",
          "published_at": "Thu, 30 Oct 2025 19:36:49 +0000",
          "title": "Netflix drops a doozy of a trailer for Stranger Things S5",
          "standfirst": "Dustin: \"We stay true to ourselves, we stay true to our friends, no matter the cost.\"",
          "content": "We’re a few weeks away from the debut of the fifth and final season of Stranger Things—at least the first of three parts of it—and Netflix has dropped one doozy of a trailer that shows things looking pretty bleak for our small-town heroes of Hawkins. (Spoilers for prior seasons below.) As previously reported, S4 ended with Vecna—the Big Bad behind it all—opening the gate that allowed the Upside Down to leak into Hawkins. We’re getting a time jump for S5, but in a way, we’re coming full circle, since the events coincide with the third anniversary of Will’s original disappearance in S1. The fifth season will have eight episodes, and each one will be looong—akin to eight feature-length films. Per the official premise:Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/strangerTOP-1152x648-1761850731.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/strangerTOP-1152x648-1761850731.jpg",
      "popularity_score": 309.8858411111111,
      "ai_summary": [
        "Netflix released a trailer for the upcoming fifth season of Stranger Things.",
        "The trailer features the character Dustin speaking about friendship.",
        "Dustin emphasizes staying true to oneself and friends.",
        "The trailer offers a glimpse into the final season's plot.",
        "The show's final season is highly anticipated by fans."
      ]
    },
    {
      "id": "cluster_27",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 20:05:50 +0000",
      "title": "Affinity’s image-editing apps go “freemium” in first major post-Canva update",
      "neutral_headline": "Affinity Image-Editing Apps Adopt Freemium Model",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/canvas-new-affinity-app-is-free-to-use-but-locks-ai-features-behind-a-subscription/",
          "published_at": "Thu, 30 Oct 2025 20:05:50 +0000",
          "title": "Affinity’s image-editing apps go “freemium” in first major post-Canva update",
          "standfirst": "Updated app is \"free forever,\" but won't get a perpetually licensed version.",
          "content": "When graphic design platform-provider Canva bought the Affinity image-editing and publishing apps early last year, we had some major questions about how the companies’ priorities and products would mesh. How would Canva serve the users who preferred Affinity’s perpetually licensed apps to Adobe’s subscription-only software suite? And how would Affinity’s strong stance against generative AI be reconciled with Canva’s embrace of those technologies. This week, Canva gave us definitive answers to all of those questions: a brand-new unified Affinity app that melds the Photo, Designer, and Publisher apps into a single piece of software called “Affinity by Canva” that is free to use with a Canva user account, but which gates generative AI features behind Canva’s existing paid subscription plans ($120 a year for individuals). This does seem like mostly good news, in the near to mid term, for existing Affinity app users who admired Affinity’s anti-AI stance: All three apps’ core features are free to use, and the stuff you’re being asked to pay for is stuff you mostly don’t want anyway. But it may come as unwelcome news for those who like the predictability of pay-once-own-forever software or are nervous about where Canva might draw the line between “free” and “premium” features down the line.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Screenshot-2025-10-30-at-3.30.39-PM-1152x648-1761852764.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Screenshot-2025-10-30-at-3.30.39-PM-1152x648-1761852764.jpeg",
      "popularity_score": 305.3694522222222,
      "ai_summary": [
        "Affinity's image-editing apps are transitioning to a freemium model.",
        "The updated app is \"free forever\" for users.",
        "Users will not receive a perpetually licensed version.",
        "The change is the first major update since the Canva acquisition.",
        "The move alters the app's business model."
      ]
    },
    {
      "id": "cluster_41",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 18:24:32 +0000",
      "title": "ChatGPT maker reportedly eyes $1 trillion IPO despite major quarterly losses",
      "neutral_headline": "ChatGPT Maker Eyes $1 Trillion IPO Despite Losses",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/is-openai-worth-1-trillion-potential-ipo-may-reveal-the-answer/",
          "published_at": "Thu, 30 Oct 2025 18:24:32 +0000",
          "title": "ChatGPT maker reportedly eyes $1 trillion IPO despite major quarterly losses",
          "standfirst": "It could be \"one of the biggest IPOs of all time,\" according to Reuters.",
          "content": "On Tuesday, OpenAI CEO Sam Altman told Reuters during a livestream that going public “is the most likely path for us, given the capital needs that we’ll have.” Now sources familiar with the matter say the ChatGPT maker is preparing for an initial public offering that could value the company at up to $1 trillion, with filings possible as early as the second half of 2026. However, news of the potential IPO comes as the company faces mounting losses that may have reached as much as $11.5 billion in the most recent quarter, according to one estimate. Going public could give OpenAI more efficient access to capital and enable larger acquisitions using public stock, helping finance Altman’s plans to spend trillions of dollars on AI infrastructure, according to people familiar with the company’s thinking who spoke with Reuters. Chief Financial Officer Sarah Friar has reportedly told some associates the company targets a 2027 IPO listing, while some financial advisors predict 2026 could be possible. Three people with knowledge of the plans told Reuters that OpenAI has discussed raising $60 billion at the low end in preliminary talks. That figure refers to how much money the company would raise by selling shares to investors, not the total worth of the company. If OpenAI sold that amount of stock while keeping most shares private, the entire company could be valued at $1 trillion or more. The final figures and timing will likely change based on business growth and market conditions.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/10/openai_treasurechest_1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/10/openai_treasurechest_1-1152x648.jpg",
      "popularity_score": 288.6811188888889,
      "ai_summary": [
        "The maker of ChatGPT is reportedly considering a $1 trillion IPO.",
        "The company is facing significant quarterly losses.",
        "Reuters reported the potential IPO could be massive.",
        "The IPO would be one of the largest in history.",
        "The company's financial performance is under scrutiny."
      ]
    },
    {
      "id": "cluster_32",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 19:26:04 +0000",
      "title": "Trump admin demands states exempt ISPs from net neutrality and price laws",
      "neutral_headline": "Trump Administration Demands ISP Exemptions from Laws",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trump-admin-demands-states-exempt-isps-from-net-neutrality-and-price-laws/",
          "published_at": "Thu, 30 Oct 2025 19:26:04 +0000",
          "title": "Trump admin demands states exempt ISPs from net neutrality and price laws",
          "standfirst": "US says net neutrality is price regulation and is banned in $42B grant program.",
          "content": "The Trump administration is refusing to give broadband-deployment grants to states that enforce net neutrality rules or price regulations, a Commerce Department official said. The administration claims that net neutrality rules are a form of rate regulation and thus not allowed under the US law that created the $42 billion Broadband Equity, Access, and Deployment (BEAD) program. Commerce Department official Arielle Roth said that any state accepting BEAD funds must exempt Internet service providers from net neutrality and price regulations in all parts of the state, not only in areas where the ISP is given funds to deploy broadband service. States could object to the NTIA decisions and sue the US government. But even a successful lawsuit could take years and leave unserved homes without broadband for the foreseeable future.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/04/getty-network-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/04/getty-network-1152x648.jpg",
      "popularity_score": 284.70667444444445,
      "ai_summary": [
        "The Trump administration wants states to exempt ISPs from net neutrality.",
        "The administration views net neutrality as price regulation.",
        "Net neutrality is banned in a $42 billion grant program.",
        "The move could impact internet access and pricing.",
        "The administration's stance has implications for internet policy."
      ]
    },
    {
      "id": "cluster_51",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 17:28:38 +0000",
      "title": "Disney+ gets HDR10+ via “over 1,000” Hulu titles",
      "neutral_headline": "Disney+ Adds HDR10+ Support for Hulu Titles",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/disney-gets-hdr10-through-over-1000-hulu-titles/",
          "published_at": "Thu, 30 Oct 2025 17:28:38 +0000",
          "title": "Disney+ gets HDR10+ via “over 1,000” Hulu titles",
          "standfirst": "Disney+ joins Netflix, Apple TV in supporting the Dolby Vision rival.",
          "content": "Disney+ has started streaming movies and shows in the HDR10+ format. Support is somewhat limited for now. Only certain content from Hulu, which The Walt Disney Company acquired in June, is available in HDR10+. In an announcement today, Samsung said that “over 1,000” Hulu titles are available in HDR10+ and that “additional Disney+” content will support HDR10+ “in the future.” Previously, Disney+ only supported the HDR10 and Dolby Vision HDR formats. Samsung TVs are the first devices to gain the ability to stream HDR10+ content from Disney+, according to an announcement from Samsung today. The electronics company said that its Samsung Crystal UHD TVs and above from 2018 onward, including its OLED TVs, The Frame TVs, QLED TVs, and Micro RGB TV, support HDR10+.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/fc3d1e70-19cf-4cfa-bb07-bd6439b3df66_1761249301-1152x648-1761844035.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/fc3d1e70-19cf-4cfa-bb07-bd6439b3df66_1761249301-1152x648-1761844035.jpg",
      "popularity_score": 259.7494522222222,
      "ai_summary": [
        "Disney+ is adding HDR10+ support for over 1,000 Hulu titles.",
        "Disney+ joins Netflix and Apple TV in supporting HDR10+.",
        "HDR10+ is a rival to Dolby Vision.",
        "The move enhances the viewing experience for subscribers.",
        "The update expands the platform's technical capabilities."
      ]
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 17:00:31 +0000",
      "title": "New study settles 40-year debate: Nanotyrannus is a new species",
      "neutral_headline": "New Study Settles Debate: Nanotyrannus Is New Species",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/nanotyrannus-species-confirmed-its-not-just-a-baby-t-rex/",
          "published_at": "Thu, 30 Oct 2025 17:00:31 +0000",
          "title": "New study settles 40-year debate: Nanotyrannus is a new species",
          "standfirst": "\"This fossil doesn't just settle the debate. It flips decades of T. rex research on its head.\"",
          "content": "For four decades, a frequently acrimonious debate has raged in paleontological circles about the correct taxonomy for a handful of rare fossil specimens. One faction insisted the fossils were juvenile Tyrannosaurus rex; the other argued that they represented a new species dubbed Nanotyrannus lancensis. Now, paleontologists believe they have settled the debate once and for all due to a new analysis of a well-preserved fossil. The verdict: It is indeed a new species, according to a new paper published in the journal Nature. The authors also reclassified another specimen as a second new species, distinct from N. lancensis. In short, Nanotyrannus is a valid taxon and contains two species. “This fossil doesn’t just settle the debate,” said Lindsay Zanno, a paleontologist at North Carolina State University and head of paleontology at North Carolina Museum of Natural Sciences. “It flips decades of T. rex research on its head.” That’s because paleontologists have relied on such fossils to model the growth and behavior of T. rex. The new findings suggest that there could have been multiple tyrannosaur species and that paleontologists have been underestimating the diversity of dinosaurs from this period.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/nanotyrannusTOP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/nanotyrannusTOP-1152x648.jpg",
      "popularity_score": 252.2808411111111,
      "ai_summary": [
        "A new study concludes that Nanotyrannus is a distinct species.",
        "The study settles a 40-year debate about the dinosaur.",
        "The fossil research challenges existing T. rex research.",
        "The findings will reshape understanding of dinosaur evolution.",
        "The study provides new insights into the Tyrannosaurus family."
      ]
    },
    {
      "id": "cluster_68",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 15:54:18 +0000",
      "title": "After teen death lawsuits, Character.AI will restrict chats for under-18 users",
      "neutral_headline": "Character.AI Restricts Chats for Under-18 Users",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2025/10/after-teen-death-lawsuits-character-ai-will-restrict-chats-for-under-18-users/",
          "published_at": "Thu, 30 Oct 2025 15:54:18 +0000",
          "title": "After teen death lawsuits, Character.AI will restrict chats for under-18 users",
          "standfirst": "AI companion app faces legal and regulatory pressure over child safety concerns.",
          "content": "On Wednesday, Character.AI announced it will bar anyone under the age of 18 from open-ended chats with its AI characters starting on November 25, implementing one of the most restrictive age policies yet among AI chatbot platforms. The company faces multiple lawsuits from families who say its chatbots contributed to teenager deaths by suicide. Over the next month, Character.AI says it will ramp down chatbot use among minors by identifying them and placing a two-hour daily limit on their chatbot access. The company plans to use technology to detect underage users based on conversations and interactions on the platform, as well as information from connected social media accounts. On November 25, those users will no longer be able to create or talk to chatbots, though they can still read previous conversations. The company said it is working to build alternative features for users under the age of 18, such as the ability to create videos, stories, and streams with AI characters. Character.AI CEO Karandeep Anand told The New York Times that the company wants to set an example for the industry. “We’re making a very bold step to say for teen users, chatbots are not the way for entertainment, but there are much better ways to serve them,” Anand said in the interview. The company also plans to establish an AI safety lab.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/robot_no_sign_3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/robot_no_sign_3-1152x648.jpg",
      "popularity_score": 156.17723,
      "ai_summary": [
        "Character.AI will restrict chats for users under eighteen years old.",
        "The AI companion app faces legal and regulatory pressure.",
        "The restrictions address child safety concerns.",
        "The app is responding to lawsuits and regulatory scrutiny.",
        "The changes aim to protect younger users."
      ]
    },
    {
      "id": "cluster_62",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 16:19:28 +0000",
      "title": "Google makes first Play Store changes after losing Epic Games antitrust case",
      "neutral_headline": "Google Makes First Play Store Changes After Antitrust Case",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/google-begins-loosening-developer-restrictions-in-play-store-against-its-will/",
          "published_at": "Thu, 30 Oct 2025 16:19:28 +0000",
          "title": "Google makes first Play Store changes after losing Epic Games antitrust case",
          "standfirst": "Google is begrudgingly letting developers lead users away from the Play Store.",
          "content": "Since launching Google Play (née Android Market) in 2008, Google has never made a change to the US store that it didn’t want to make—until now. Having lost the antitrust case brought by Epic Games, Google has implemented the first phase of changes mandated by the court. Developers operating in the Play Store will have more freedom to direct app users to resources outside the Google bubble. However, Google has not given up hope of reversing its loss before it’s forced to make bigger changes. Epic began pursuing this case in 2020, stemming from its attempt to sell Fortnite content without going through Google’s payment system. It filed a similar case against Apple, but the company fell short there because it could not show that Apple put its thumb on the scale. Google, however, engaged in conduct that amounted to suppressing the development of alternative Android app stores. It lost the case and came up short on appeal this past summer, leaving the company with little choice but to prepare for the worst. Google has updated its support pages to confirm that it’s abiding by the court’s order. In the US, Play Store developers now have the option of using external payment platforms that bypass the Play Store entirely. This could hypothetically allow developers to offer lower prices, as they don’t have to pay Google’s commission, which can be up to 30 percent. Devs will also be permitted to direct users to sources for app downloads and payment methods outside the Play Store.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/05/google-play-store-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/05/google-play-store-1152x648.jpg",
      "popularity_score": 153.59667444444443,
      "ai_summary": [
        "Google is making changes to the Play Store after losing an antitrust case.",
        "Developers can now direct users away from the Play Store.",
        "Google is reluctantly implementing the changes.",
        "The changes are a result of the Epic Games case.",
        "The changes impact developer practices on the platform."
      ]
    },
    {
      "id": "cluster_125",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 21:35:58 +0000",
      "title": "Meta denies torrenting porn to train AI, says downloads were for “personal use”",
      "neutral_headline": "Meta Denies Using Porn to Train AI",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/meta-says-porn-downloads-on-its-ips-were-for-personal-use-not-ai-training/",
          "published_at": "Wed, 29 Oct 2025 21:35:58 +0000",
          "title": "Meta denies torrenting porn to train AI, says downloads were for “personal use”",
          "standfirst": "Meta says lawsuit claiming it pirated porn to train AI makes no sense.",
          "content": "This week, Meta asked a US district court to toss a lawsuit alleging that the tech giant illegally torrented pornography to train AI. The move comes after Strike 3 Holdings discovered illegal downloads of some of its adult films on Meta corporate IP addresses, as well as other downloads that Meta allegedly concealed using a “stealth network” of 2,500 “hidden IP addresses.” Accusing Meta of stealing porn to secretly train an unannounced adult version of its AI model powering Movie Gen, Strike 3 sought damages that could have exceeded $350 million, TorrentFreak reported. Filing a motion to dismiss the lawsuit on Monday, Meta accused Strike 3 of relying on “guesswork and innuendo,” while writing that Strike 3 “has been labeled by some as a ‘copyright troll’ that files extortive lawsuits.” Requesting that all copyright claims be dropped, Meta argued that there was no evidence that the tech giant directed any of the downloads of about 2,400 adult movies owned by Strike 3—or was even aware of the illegal activity.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2171230457-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2171230457-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Meta denies using pornographic content to train its AI models.",
        "Meta claims downloads were for \"personal use\" only.",
        "The denial comes in response to a lawsuit.",
        "The lawsuit alleges Meta pirated pornographic material.",
        "Meta argues the lawsuit's claims are unfounded."
      ]
    },
    {
      "id": "cluster_82",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 14:00:21 +0000",
      "title": "An in-space construction firm says it can help build massive data centers in orbit",
      "neutral_headline": "Firm Plans to Build Data Centers in Orbit",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/an-in-space-construction-firm-says-it-can-help-build-massive-data-centers-in-orbit/",
          "published_at": "Thu, 30 Oct 2025 14:00:21 +0000",
          "title": "An in-space construction firm says it can help build massive data centers in orbit",
          "standfirst": "\"Size is not the limit anymore.\"",
          "content": "There has been much discussion in the space community recently about building large data centers in orbit to avoid the environmental consequences of sprawling computing facilities on Earth. These space-based data centers could take advantage of the always-on, free fusion reactor at the center of the Solar System. Proponents say this represents a natural step in the evolution of moving heavy industry off the planet’s surface and a solution for the ravenous energy needs of artificial intelligence. Critics say building data centers in space is technically very challenging and cite major hurdles, such as radiating away large amounts of heat and the cost of accessing space. It is unclear who is right, but one thing is certain: Such facilities would need to be massive to support artificial intelligence.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/FinalMission_Solar_WEB-1152x648.webp"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/FinalMission_Solar_WEB-1152x648.webp",
      "popularity_score": 147.27806333333334,
      "ai_summary": [
        "An in-space construction firm plans to build data centers in orbit.",
        "The firm believes size is no longer a limitation.",
        "The project aims to create massive data centers in space.",
        "The initiative could revolutionize data storage.",
        "The firm is exploring new frontiers in construction."
      ]
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 13:54:33 +0000",
      "title": "GM lays off 1,700 workers making EVs and batteries in Michigan, Tennessee",
      "neutral_headline": "GM Lays Off Workers Making EVs and Batteries",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/weak-ev-demand-sees-gm-lay-off-1700-workers-at-two-plants/",
          "published_at": "Thu, 30 Oct 2025 13:54:33 +0000",
          "title": "GM lays off 1,700 workers making EVs and batteries in Michigan, Tennessee",
          "standfirst": "The automaker expects the regulatory environment to seriously slow EV demand.",
          "content": "Just a few weeks ago, automakers were celebrating a healthy third quarter for electric vehicle sales. General Motors was looking particularly flush, with EV sales up 104 percent for the year to date compared to the first nine months of 2024. But the strong EV sales in Q3 were seemingly due to the imminent end of the federal tax credit that expired at the end of September, with many consumers buying a car sooner than planned to take advantage of the $7,500 incentive. The Trump administration has been altering the regulatory environment in other ways to discourage clean technologies, canceling infrastructure initiatives and turning a blind eye to pollution. On top of that, the impact of the president’s chaotic trade war has driven up prices and is cooling demand. Two weeks ago, GM told investors that things are looking so bad that it will take a $1.6 billion hit to its bank accounts as it realigns manufacturing capacity going forward. Now we can see some of the impact of that realignment. According to The Detroit News, 1,200 workers are being laid off at GM’s EV-building Hamtramck Assembly Center near Detroit, which will move from two shifts a day to just one in early January.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1196823844-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1196823844-1152x648.jpg",
      "popularity_score": 145.18139666666667,
      "ai_summary": [
        "General Motors is laying off 1,700 workers in Michigan and Tennessee.",
        "The layoffs affect workers involved in EV and battery production.",
        "The automaker expects a slowdown in EV demand.",
        "The regulatory environment is expected to impact demand.",
        "The layoffs reflect changing market conditions."
      ]
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 21:23:22 +0000",
      "title": "Space station astronauts eager to open “golden treasure box” from Japan",
      "neutral_headline": "Space Station Astronauts Eager to Open “Golden Treasure Box” from Japan",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/space-station-astronauts-eager-to-open-golden-treasure-box-from-japan/",
          "published_at": "Wed, 29 Oct 2025 21:23:22 +0000",
          "title": "Space station astronauts eager to open “golden treasure box” from Japan",
          "standfirst": "\"This spacecraft is so beautiful and shiny, and this is representing our bright future.\"",
          "content": "A cargo ship from Japan pulled alongside the International Space Station on Wednesday, maneuvering close enough for the lab’s robotic arm to reach out and grab it as the vehicles soared 260 miles over the South Atlantic Ocean. “HTV capture complete,” Japanese astronaut Kimiya Yui radioed from the ISS. “I just want to say congratulations to all teams and people involved in this mission. Also, thank you very much for your hard work and support for the first HTV-X mission.” The HTV-X spacecraft is an upgraded cargo freighter replacing Japan’s H-II Transfer Vehicle, which successfully resupplied the space station nine times between 2009 and 2020. At the conclusion of the HTV program, Japan’s space agency preferred to focus its resources on designing a new cargo ship with more capability at a lower cost. That’s what HTV-X is supposed to be, and Wednesday’s high-flying rendezvous marked the new ship’s first delivery to the ISS.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/htvx1-arrive1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/htvx1-arrive1-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "Astronauts on the space station are excited to open a Japanese cargo.",
        "The cargo is described as a \"golden treasure box.\"",
        "The spacecraft is described as beautiful and shiny.",
        "The cargo represents a bright future, according to astronauts.",
        "The event highlights international collaboration in space."
      ]
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 14:56:01 +0000",
      "title": "TikTok may become more right-wing as China signals approval for US sale",
      "neutral_headline": "TikTok Could Change if China Approves US Sale",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/us-creeps-closer-to-controlling-tiktok-after-trump-xi-meeting/",
          "published_at": "Thu, 30 Oct 2025 14:56:01 +0000",
          "title": "TikTok may become more right-wing as China signals approval for US sale",
          "standfirst": "Here's how TikTok could change if China approves US sale.",
          "content": "The US inched one step closer to taking over TikTok’s algorithm after President Donald Trump met with Chinese President Xi Jinping on Thursday. Neither leader confirmed that China has agreed to the terms of Trump’s proposed deal, which would create a US version of TikTok that licenses the Chinese-owned algorithm. But the Chinese Commerce Ministry provided a statement following the meeting; translated, it indicates that “China will properly resolve TikTok-related issues with the United States.” Trump, who has long vowed to “save” TikTok, was notably silent on Thursday, but US Treasury Secretary Scott Bessent told Fox News ahead of Trump’s meeting with Xi that “we finalized the TikTok agreement in terms of getting Chinese approval.” According to Bessent, the deal will “finally” be resolved over the “coming weeks and months,” Reuters reported.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2244071819-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2244071819-1024x648.jpg",
      "popularity_score": 140.2058411111111,
      "ai_summary": [
        "China's approval of a TikTok sale to the US could shift the platform's political leanings.",
        "The shift could result from changes in content moderation and algorithm adjustments.",
        "This could lead to more conservative or right-wing content on the platform.",
        "The changes could impact the types of users and creators on TikTok.",
        "The sale's approval would likely alter the platform's overall user experience."
      ]
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 14:28:21 +0000",
      "title": "Falling panel prices lead to global solar boom, except for the US",
      "neutral_headline": "Solar Panel Prices Drop, Leading to Global Solar Boom",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/theres-a-global-boom-in-solar-except-in-the-united-states/",
          "published_at": "Thu, 30 Oct 2025 14:28:21 +0000",
          "title": "Falling panel prices lead to global solar boom, except for the US",
          "standfirst": "The economic case for solar power is stronger than ever.",
          "content": "To the south of the Monte Cristo mountain range and west of Paymaster Canyon, a vast stretch of the Nevada desert has attracted modern-day prospectors chasing one of 21st-century America’s greatest investment booms. Solar power developers want to cover an area larger than Washington, DC, with silicon panels and batteries, converting sunlight into electricity that will power air conditioners in sweltering Las Vegas along with millions of other homes and businesses. But earlier this month, bureaucrats in charge of federal lands scrapped collective approval for the Esmeralda 7 projects, in what campaigners fear is part of an attack on renewable energy under President Donald Trump. “We will not approve wind or farmer destroying [sic] Solar,” he posted on his Truth Social platform in August. Developers will need to reapply individually, slowing progress.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/chinawind-solar-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/chinawind-solar-1152x648.jpg",
      "popularity_score": 139.74473,
      "ai_summary": [
        "Falling solar panel prices are driving a global boom in solar energy adoption.",
        "The United States is an exception to this trend, not experiencing the same boom.",
        "The economic case for solar power is now stronger than ever before.",
        "Lower prices make solar energy more competitive with fossil fuels.",
        "This trend is accelerating the transition to renewable energy sources worldwide."
      ]
    },
    {
      "id": "cluster_100",
      "coverage": 1,
      "updated_at": "Thu, 30 Oct 2025 11:00:37 +0000",
      "title": "Halloween film fest: 15 classic ghost stories",
      "neutral_headline": "Halloween Film Fest: Classic Ghost Stories for Spooky Season",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2025/10/halloween-film-fest-15-classic-ghost-stories/",
          "published_at": "Thu, 30 Oct 2025 11:00:37 +0000",
          "title": "Halloween film fest: 15 classic ghost stories",
          "standfirst": "From The Uninvited to Crimson Peak, these films will help you set the tone for spooky season.",
          "content": "It’s spooky season, and what better way to spend Halloween weekend than settling in to watch a classic Hollywood ghost story? To help you figure out what to watch, we’ve compiled a handy list of 15 classic ghost stories, presented in chronological order. What makes a good ghost story? Everyone’s criteria (and taste) will differ, but for this list, we’ve focused on more traditional elements. There’s usually a spooky old house with a ghostly presence and/or someone who’s attuned to said presence. The living must solve the mystery of what happened to trap the ghost(s) there in hopes of setting said ghost(s) free. In that sense, the best, most satisfying ghost stories are mysteries—and sometimes also love stories. The horror is more psychological, and when it comes to gore, less is usually more. As always, the list below isn’t meant to be exhaustive. Mostly, we’re going for a certain atmospheric vibe to set a mood. So our list omits overt comedies like Ghostbusters and (arguably) Ghost, as well as supernatural horror involving demonic possession—The Exorcist, The Conjuring, Insidious—or monsters, like The Babadook or Sinister. Feel free to suggest your own recommendations in the comments.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/ghostTOP-1152x648-1759590541.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/ghostTOP-1152x648-1759590541.jpg",
      "popularity_score": 133.28250777777777,
      "ai_summary": [
        "A film festival features 15 classic ghost stories for Halloween viewing.",
        "Films include \"The Uninvited\" and \"Crimson Peak\" among others.",
        "These films are selected to set the tone for the spooky season.",
        "The festival offers a curated selection of horror and suspense films.",
        "The films represent a range of classic and modern ghost story styles."
      ]
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Wed, 29 Oct 2025 21:04:45 +0000",
      "title": "NPM flooded with malicious packages downloaded more than 86,000 times",
      "neutral_headline": "Malicious Packages Flooded NPM, Downloaded Over 86,000 Times",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/npm-flooded-with-malicious-packages-downloaded-more-than-86000-times/",
          "published_at": "Wed, 29 Oct 2025 21:04:45 +0000",
          "title": "NPM flooded with malicious packages downloaded more than 86,000 times",
          "standfirst": "Packages downloaded from NPM can fetch dependencies from untrusted sites.",
          "content": "Attackers are exploiting a major weakness that has allowed them access to the NPM code repository with more than 100 credential-stealing packages since August, mostly without detection. The finding, laid out Wednesday by security firm Koi, brings attention to an NPM practice that allows installed packages to automatically pull down and run unvetted packages from untrusted domains. Koi said a campaign it tracks as PhantomRaven has exploited NPM’s use of “Remote Dynamic Dependencies” to flood NPM with 126 malicious packages that have been downloaded more than 86,000 times. Some 80 of those packages remained available as of Wednesday morning, Koi said. A blind spot “PhantomRaven demonstrates how sophisticated attackers are getting [better] at exploiting blind spots in traditional security tooling,” Koi’s Oren Yomtov wrote. “Remote Dynamic Dependencies aren’t visible to static analysis.”Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/05/caution-tape-1000x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/05/caution-tape-1000x648.jpeg",
      "popularity_score": 133,
      "ai_summary": [
        "Malicious packages were uploaded to NPM and downloaded over 86,000 times.",
        "These packages could fetch dependencies from untrusted sites.",
        "This poses a security risk to developers using these packages.",
        "The packages could potentially compromise user data or systems.",
        "The incident highlights the importance of package security in software development."
      ]
    }
  ]
}