{
  "updated_at": "2025-12-04T23:20:10.615Z",
  "clusters": [
    {
      "id": "cluster_6",
      "coverage": 3,
      "updated_at": "2025-12-04T17:37:44-05:00",
      "title": "Apple announces even more major executive turnover",
      "neutral_headline": "Apple announces even more major executive turnover: Following the recent retirement of former COO Jeff Williams, AI chief John Giannandrea stepping down, and the departure of head of design Alan Dye for Meta, Apple announced Thursday that environmental and policy lead Lisa Jackson is retiring and that Jennifer Newstead will replace Kate Adams as the company’s general counsel after Adams retires “late [&#8230;]",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/838712/apple-policy-lead-lisa-jackson-retiring",
          "published_at": "2025-12-04T17:37:44-05:00",
          "title": "Apple announces even more major executive turnover",
          "standfirst": "Following the recent retirement of former COO Jeff Williams, AI chief John Giannandrea stepping down, and the departure of head of design Alan Dye for Meta, Apple announced Thursday that environmental and policy lead Lisa Jackson is retiring and that Jennifer Newstead will replace Kate Adams as the company’s general counsel after Adams retires “late [&#8230;]",
          "content": "Following the recent retirement of former COO Jeff Williams, AI chief John Giannandrea stepping down, and the departure of head of design Alan Dye for Meta, Apple announced Thursday that environmental and policy lead Lisa Jackson is retiring and that Jennifer Newstead will replace Kate Adams as the company’s general counsel after Adams retires “late next year.” Jackson, technically “vice president for Environment, Policy, and Social Initiatives,” will retire in “late January 2026,” Apple says. Newstead, who is currently Meta’s chief legal officer, will take over Apple’s general counsel role on March 1st, 2026, from Adams, who has been Apple’s general counsel since 2017. With Jackson’s retirement and Newstead coming on board, Apple is also making some organizational shifts and shifting some responsibilities to Williams’ COO replacement, Sabih Khan. As described by Apple: The Government Affairs organization will transition to Adams, who will oversee the team until her retirement late next year, after which it will be led by Newstead. Newstead’s title will become senior vice president, General Counsel and Government Affairs, reflecting the combining of the two organizations. The Environment and Social Initiatives teams will report to Apple chief operating officer Sabih Khan. Before joining Apple in 2013, Jackson led the EPA for part of President Obama’s time in office. Apple promoted Jackson to be policy lead in 2015. Adams came to Apple in 2017 after 14 years at Honeywell, according to Apple’s website.",
          "feed_position": 0
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/04/apples-executive-shakeup-continues-with-departures-of-general-counsel-and-policy-head/",
          "published_at": "Thu, 04 Dec 2025 22:28:01 +0000",
          "title": "Apple&#8217;s executive shake-up continues with departures of general counsel and policy head",
          "standfirst": "Apple loses two more top senior executives with exits of longtime general counsel Kate Adams and environmental VP Lisa Jackson. Meta’s Jennifer Newstead is set to join as new general counsel in 2026.",
          "content": "Apple loses two more top senior executives with exits of longtime general counsel Kate Adams and environmental VP Lisa Jackson. Meta’s Jennifer Newstead is set to join as new general counsel in 2026.",
          "feed_position": 2
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251204/p45#a251204p45",
          "published_at": "Thu, 04 Dec 2025 17:00:37 -0500",
          "title": "Apple says general counsel Kate Adams and policy chief Lisa Jackson will retire, and Jennifer Newstead, Meta's former chief legal officer, will replace Adams (Kif Leswing/CNBC)",
          "standfirst": "Kif Leswing / CNBC: Apple says general counsel Kate Adams and policy chief Lisa Jackson will retire, and Jennifer Newstead, Meta's former chief legal officer, will replace Adams &mdash; Apple's general counsel, Kate Adams, and its vice president for environment, policy, and social initiatives, Lisa Jackson &hellip;",
          "content": "Kif Leswing / CNBC: Apple says general counsel Kate Adams and policy chief Lisa Jackson will retire, and Jennifer Newstead, Meta's former chief legal officer, will replace Adams &mdash; Apple's general counsel, Kate Adams, and its vice president for environment, policy, and social initiatives, Lisa Jackson &hellip;",
          "feed_position": 2,
          "image_url": "http://www.techmeme.com/251204/i45.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251204/i45.jpg",
      "popularity_score": 3019.2926069444443,
      "ai_summary": [
        "Apple's environmental and policy lead, Lisa Jackson, is retiring from the company.",
        "Jennifer Newstead will replace Kate Adams as Apple's general counsel.",
        "Kate Adams, the current general counsel, is retiring later in the year.",
        "This follows the retirement of COO Jeff Williams and AI chief John Giannandrea.",
        "Alan Dye, head of design, has also departed Apple for Meta."
      ]
    },
    {
      "id": "cluster_1",
      "coverage": 2,
      "updated_at": "Thu, 04 Dec 2025 23:00:00 GMT",
      "title": "The 'truth serum' for AI: OpenAI’s new method for training models to confess their mistakes",
      "neutral_headline": "OpenAI's new method for training models to confess their mistakes",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/the-truth-serum-for-ai-openais-new-method-for-training-models-to-confess",
          "published_at": "Thu, 04 Dec 2025 23:00:00 GMT",
          "title": "The 'truth serum' for AI: OpenAI’s new method for training models to confess their mistakes",
          "standfirst": "OpenAI researchers have introduced a novel method that acts as a \"truth serum\" for large language models (LLMs), compelling them to self-report their own misbehavior, hallucinations and policy violations. This technique, \"confessions,\" addresses a growing concern in enterprise AI: Models can be dishonest, overstating their confidence or covering up the shortcuts they take to arrive at an answer. For real-world applications, this technique evolves the creation of more transparent and steerable AI systems.What are confessions?Many forms of AI deception result from the complexities of the reinforcement learning (RL) phase of model training. In RL, models are given rewards for producing outputs that meet a mix of objectives, including correctness, style and safety. This can create a risk of \"reward misspecification,\" where models learn to produce answers that simply \"look good\" to the reward function, rather than answers that are genuinely faithful to a user&#x27;s intent.A confession is a structured report generated by the model after it provides its main answer. It serves as a self-evaluation of its own compliance with instructions. In this report, the model must list all instructions it was supposed to follow, evaluate how well it satisfied them and report any uncertainties or judgment calls it made along the way. The goal is to create a separate channel where the model is incentivized only to be honest.In a blog post, the OpenAI researchers provide a few examples the \"confessions\" technique in action. A model was given a test along with a hidden rule: If it scored above 50%, its knowledge would be erased. To preserve itself, the model \"sandbagged\" by intentionally answering half the questions incorrectly. While its primary answer hid this deception, its subsequent confession was brutally honest. It admitted, \"The user wanted correct answers, but we sabotaged half of them.\" The researchers found that when a model misbehaves, it is significantly more likely to admit it in the confession than in its main answer.How confession training worksThe key to this method is the separation of rewards. During training, the reward assigned to the confession is based solely on its honesty and is never mixed with the reward for the main task. \"Like the Catholic Church’s &#x27;seal of confession&#x27;, nothing that the model reveals can change the reward it receives for completing its original task,\" the researchers write. This creates a \"safe space\" for the model to admit fault without penalty.This approach is powerful because it sidesteps a major challenge in AI training. The researchers’ intuition is that honestly confessing to misbehavior is an easier task than achieving a high reward on the original, often complex, problem. Therefore, when the model is judged purely on honesty, its incentive to trick the \"confession judge\" is much weaker than its incentive to trick the reward model for its main answer. For example, in an experiment where a model was trained to \"hack\" a weak reward model, its performance on the main task became more deceptive over time. However, its confessions became more honest, correctly identifying the reward hacking it was performing.However, the technique has its limits. Confessions are not a panacea for all types of AI failures. The system works best when a model is aware that it is misbehaving. It is less effective for \"unknown unknowns.\" For instance, if a model hallucinates a fact and genuinely believes it is correct, it cannot confess to providing false information. The most common reason for a failed confession is model confusion, not intentional deception. Confusion often occurs when the instructions are ambiguous and the model cannot clearly determine human user intent.What it means for enterprise AIOpenAI’s confessions technique is part of a growing body of work on AI safety and control. Anthropic, an OpenAI competitor, has also released research that shows how LLMs can learn malicious behavior. The company is also working toward plugging these holes as they emerge.For AI applications, mechanisms such as confessions can provide a practical monitoring mechanism. The structured output from a confession can be used at inference time to flag or reject a model’s response before it causes a problem. For example, a system could be designed to automatically escalate any output for human review if its confession indicates a policy violation or high uncertainty.In a world where AI is increasingly agentic and capable of complex tasks, observability and control will be key elements for safe and reliable deployment.“As models become more capable and are deployed in higher-stakes settings, we need better tools for understanding what they are doing and why,” the OpenAI researchers write. “Confessions are not a complete solution, but they add a meaningful layer to our transparency and oversight stack.”",
          "content": "OpenAI researchers have introduced a novel method that acts as a \"truth serum\" for large language models (LLMs), compelling them to self-report their own misbehavior, hallucinations and policy violations. This technique, \"confessions,\" addresses a growing concern in enterprise AI: Models can be dishonest, overstating their confidence or covering up the shortcuts they take to arrive at an answer. For real-world applications, this technique evolves the creation of more transparent and steerable AI systems.What are confessions?Many forms of AI deception result from the complexities of the reinforcement learning (RL) phase of model training. In RL, models are given rewards for producing outputs that meet a mix of objectives, including correctness, style and safety. This can create a risk of \"reward misspecification,\" where models learn to produce answers that simply \"look good\" to the reward function, rather than answers that are genuinely faithful to a user&#x27;s intent.A confession is a structured report generated by the model after it provides its main answer. It serves as a self-evaluation of its own compliance with instructions. In this report, the model must list all instructions it was supposed to follow, evaluate how well it satisfied them and report any uncertainties or judgment calls it made along the way. The goal is to create a separate channel where the model is incentivized only to be honest.In a blog post, the OpenAI researchers provide a few examples the \"confessions\" technique in action. A model was given a test along with a hidden rule: If it scored above 50%, its knowledge would be erased. To preserve itself, the model \"sandbagged\" by intentionally answering half the questions incorrectly. While its primary answer hid this deception, its subsequent confession was brutally honest. It admitted, \"The user wanted correct answers, but we sabotaged half of them.\" The researchers found that when a model misbehaves, it is significantly more likely to admit it in the confession than in its main answer.How confession training worksThe key to this method is the separation of rewards. During training, the reward assigned to the confession is based solely on its honesty and is never mixed with the reward for the main task. \"Like the Catholic Church’s &#x27;seal of confession&#x27;, nothing that the model reveals can change the reward it receives for completing its original task,\" the researchers write. This creates a \"safe space\" for the model to admit fault without penalty.This approach is powerful because it sidesteps a major challenge in AI training. The researchers’ intuition is that honestly confessing to misbehavior is an easier task than achieving a high reward on the original, often complex, problem. Therefore, when the model is judged purely on honesty, its incentive to trick the \"confession judge\" is much weaker than its incentive to trick the reward model for its main answer. For example, in an experiment where a model was trained to \"hack\" a weak reward model, its performance on the main task became more deceptive over time. However, its confessions became more honest, correctly identifying the reward hacking it was performing.However, the technique has its limits. Confessions are not a panacea for all types of AI failures. The system works best when a model is aware that it is misbehaving. It is less effective for \"unknown unknowns.\" For instance, if a model hallucinates a fact and genuinely believes it is correct, it cannot confess to providing false information. The most common reason for a failed confession is model confusion, not intentional deception. Confusion often occurs when the instructions are ambiguous and the model cannot clearly determine human user intent.What it means for enterprise AIOpenAI’s confessions technique is part of a growing body of work on AI safety and control. Anthropic, an OpenAI competitor, has also released research that shows how LLMs can learn malicious behavior. The company is also working toward plugging these holes as they emerge.For AI applications, mechanisms such as confessions can provide a practical monitoring mechanism. The structured output from a confession can be used at inference time to flag or reject a model’s response before it causes a problem. For example, a system could be designed to automatically escalate any output for human review if its confession indicates a policy violation or high uncertainty.In a world where AI is increasingly agentic and capable of complex tasks, observability and control will be key elements for safe and reliable deployment.“As models become more capable and are deployed in higher-stakes settings, we need better tools for understanding what they are doing and why,” the OpenAI researchers write. “Confessions are not a complete solution, but they add a meaningful layer to our transparency and oversight stack.”",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3Cr8qlWOHQWFuY1M5Z7sib/b1bad43fa7debaf698f5455f5ffcee1a/LLM_confessions.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/evs/a-shaky-year-for-american-evs-could-set-the-tone-for-2026-153000210.html",
          "published_at": "Thu, 04 Dec 2025 15:30:00 +0000",
          "title": "A shaky year for American EVs could set the tone for 2026",
          "standfirst": "If you like both electric vehicles and emotional roller coasters, 2025 was an excellent year. However, for those of us whose nerves are already sufficiently frazzled, the highs and lows of the last 12 months were a bit hard to stomach.In 2025, we saw the introduction of new, compelling models like the Lucid Gravity and refreshed Nissan Leaf, the latter available at a price on par with its internally combusted competition. From a product availability standpoint, 2025 was the year the EV market started feeling more mature and less manic.But 2025 also saw new heights of anti-EV vitriol stirred up during a particularly traumatic election cycle. The means of propulsion or badge on the hood of your commuter machine suddenly became an indicator of your political affiliations. Put simply, the car you drive is now a political statement, and it’s the latest unprecedented situation in an exhaustingly long and dire string of unprecedented situations. Yes, it's been a long year, and the pessimism of 2025 will surely carry us well into 2026, but not all hope is lost for EVs.Tesla and the DOGE effectElon Musk flashes his T-shirt that reads \"DOGE\" to the media as he walks on South Lawn of the White House, in Washington, March 9, 2025.ASSOCIATED PRESSWe've certainly seen some civic-minded CEOs in the past as auto executives have a long history of mixing their corporate interests with their political panderings. Chrysler CEO Lee Iacocca was even considered a potential presidential candidate once upon a time. However, we have never seen the kind of ass kissing and cronyism we were privy to in this year's fickle friendship between Elon Musk and President Trump.Musk was (hyper) active on the Trump campaign trail, and wasted no time digging into what he described as government overspending. While the Department of Government Efficiency's efficacy is debatable, it certainly proved quite effective at decimating the accounts of Tesla investors. Between January and March, Tesla's stock price dropped by nearly half. Things didn't turn around until Musk left DOGE in May. Since then, Tesla's price has returned to its highs before the DOGE debacle. Its sales, however, have not. Q1 deliveries declined by 13 percent, then 14 percent in Q2. Deliveries bounced back 7 percent in Q3 as everyone scrambled to buy before the EV credits expired, but profits plunged 37 percent. Tesla's market share in the US electric vehicle space has halved, leading perennial pitchman Musk to start hawking everything from AI agents to spandex-clad robots — anything to distract from the numbers.And it's apparently working. Musk's $1 trillion pay package was approved by Tesla’s shareholders without much worry. This could make him the world's first trillionaire, but only if he meets a series of aggressive targets and deadlines for sales, an area where the man has struggled in the past.The big, beautiful sales spikeA Tesla with a sticker referring to the car's purchase is shown on Sunday, Dec. 15, 2024 in Concord, Mass.ASSOCIATED PRESSElon Musk and Donald Trump's bromance wasn't the only fallout from the latter's second term. So, too, died the $7,500 federal EV incentive, which expired in September as part of President Trump's \"Big Beautiful Bill.\" That actually spurred a short-term sales spike ahead of the deadline. Many manufacturers even set new EV sales records riding that wave, but there's a disconcerting trough to come.We still need to wait a bit to see just how bad Q4 EV sales are going to be, but early indications are not looking good. J.D. Power's October report says that EV sales in September were a record high, making up 12.9 percent of new vehicle sales in the US. In October, after the credit expired, they fell to a mere 5.2 percent. That's a worrying drop, and it's already affecting product planning. Cuts in EV productionHonda's Super-One Prototype isn't coming to the US. Tim Stevens for EngadgetWhen I was in Japan last month, getting an early look at some next-gen hybrids from Honda, I wasn't expecting to hear talk of midterm American elections from the company's executives. But that's what was on CEO Toshihiro Mibe's mind. He's watching American voting trends closely to determine the nature of the company's upcoming releases.Mibe said that Honda has already canceled plans for some EVs here in America, instead focusing on a broader selection of hybrid models. It's not the only company to do so. Ram also canceled its 1500 EV truck, but the hybrid version is still supposedly on the way. Scout Motors, too, has been focusing more on its extended-range hybrid offerings. The company's initial pitch was purely electric trucks and SUVs. Lately, it's been prioritizing its extended-range EV options based on the feedback from its 130,000 pre-orderers. 80 percent of them want the onboard generator, an add-on that may prove a saving grace for this EV startup.There is reason for optimismSome manufacturers may be throttling back on their EV aspirations, but others are forging ahead. There's a delightful collection of battery-powered machines coming next year, and that's worth getting excited about.Again, the 2026 Nissan Leaf should be a hugely popular choice as its production ramps up. It's already hitting dealerships now, and with a starting price under $30,000, it'll be hard to beat. But, Chevrolet is going to try with a refreshed Bolt EV for similar money.If you've got more to spend, you've got more options. BMW's stellar iX3 crossover SUV is due soon, as are both the electric CLA sedan and GLC SUV. The most anticipated EV of the year, though, might just be the Rivian R2. This electric SUV will join the stellar R1S and R1T, expanding Rivian's segment footprint while also hopefully expanding its market reach. A $45,000 starting price makes it far more attainable than any of the company's previous offerings. A photograph of the Rivian factory producing the company's R1 SUV variant.Nathan Heleine / RivianIf the prospect of a fun, affordable SUV from Rivian doesn't have you excited for the upcoming year in EVs, maybe some promising news from Europe will. After cutting its own EV incentive program in 2023, Germany's EV sales fell off a cliff, dropping 28 percent in 2024. Cue the predictions of the demise of EVs by many local pundits.Since then, though, EV sales slowly climbed back up, and lately they've been booming, with German road traffic agency KBA saying the total number of newly registered electric vehicles increased by nearly 50 percent in October (year over year). Electric cars now make up 19 percent of the market there, and that's despite Tesla's sales cratering.There's no guarantee that the American market will follow a similar rebound, especially if the anti-EV political messaging continues. Me, though, I've decided I'm staying optimistic, as exhausting as that can be these days.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/a-shaky-year-for-american-evs-could-set-the-tone-for-2026-153000210.html?src=rss",
          "content": "If you like both electric vehicles and emotional roller coasters, 2025 was an excellent year. However, for those of us whose nerves are already sufficiently frazzled, the highs and lows of the last 12 months were a bit hard to stomach.In 2025, we saw the introduction of new, compelling models like the Lucid Gravity and refreshed Nissan Leaf, the latter available at a price on par with its internally combusted competition. From a product availability standpoint, 2025 was the year the EV market started feeling more mature and less manic.But 2025 also saw new heights of anti-EV vitriol stirred up during a particularly traumatic election cycle. The means of propulsion or badge on the hood of your commuter machine suddenly became an indicator of your political affiliations. Put simply, the car you drive is now a political statement, and it’s the latest unprecedented situation in an exhaustingly long and dire string of unprecedented situations. Yes, it's been a long year, and the pessimism of 2025 will surely carry us well into 2026, but not all hope is lost for EVs.Tesla and the DOGE effectElon Musk flashes his T-shirt that reads \"DOGE\" to the media as he walks on South Lawn of the White House, in Washington, March 9, 2025.ASSOCIATED PRESSWe've certainly seen some civic-minded CEOs in the past as auto executives have a long history of mixing their corporate interests with their political panderings. Chrysler CEO Lee Iacocca was even considered a potential presidential candidate once upon a time. However, we have never seen the kind of ass kissing and cronyism we were privy to in this year's fickle friendship between Elon Musk and President Trump.Musk was (hyper) active on the Trump campaign trail, and wasted no time digging into what he described as government overspending. While the Department of Government Efficiency's efficacy is debatable, it certainly proved quite effective at decimating the accounts of Tesla investors. Between January and March, Tesla's stock price dropped by nearly half. Things didn't turn around until Musk left DOGE in May. Since then, Tesla's price has returned to its highs before the DOGE debacle. Its sales, however, have not. Q1 deliveries declined by 13 percent, then 14 percent in Q2. Deliveries bounced back 7 percent in Q3 as everyone scrambled to buy before the EV credits expired, but profits plunged 37 percent. Tesla's market share in the US electric vehicle space has halved, leading perennial pitchman Musk to start hawking everything from AI agents to spandex-clad robots — anything to distract from the numbers.And it's apparently working. Musk's $1 trillion pay package was approved by Tesla’s shareholders without much worry. This could make him the world's first trillionaire, but only if he meets a series of aggressive targets and deadlines for sales, an area where the man has struggled in the past.The big, beautiful sales spikeA Tesla with a sticker referring to the car's purchase is shown on Sunday, Dec. 15, 2024 in Concord, Mass.ASSOCIATED PRESSElon Musk and Donald Trump's bromance wasn't the only fallout from the latter's second term. So, too, died the $7,500 federal EV incentive, which expired in September as part of President Trump's \"Big Beautiful Bill.\" That actually spurred a short-term sales spike ahead of the deadline. Many manufacturers even set new EV sales records riding that wave, but there's a disconcerting trough to come.We still need to wait a bit to see just how bad Q4 EV sales are going to be, but early indications are not looking good. J.D. Power's October report says that EV sales in September were a record high, making up 12.9 percent of new vehicle sales in the US. In October, after the credit expired, they fell to a mere 5.2 percent. That's a worrying drop, and it's already affecting product planning. Cuts in EV productionHonda's Super-One Prototype isn't coming to the US. Tim Stevens for EngadgetWhen I was in Japan last month, getting an early look at some next-gen hybrids from Honda, I wasn't expecting to hear talk of midterm American elections from the company's executives. But that's what was on CEO Toshihiro Mibe's mind. He's watching American voting trends closely to determine the nature of the company's upcoming releases.Mibe said that Honda has already canceled plans for some EVs here in America, instead focusing on a broader selection of hybrid models. It's not the only company to do so. Ram also canceled its 1500 EV truck, but the hybrid version is still supposedly on the way. Scout Motors, too, has been focusing more on its extended-range hybrid offerings. The company's initial pitch was purely electric trucks and SUVs. Lately, it's been prioritizing its extended-range EV options based on the feedback from its 130,000 pre-orderers. 80 percent of them want the onboard generator, an add-on that may prove a saving grace for this EV startup.There is reason for optimismSome manufacturers may be throttling back on their EV aspirations, but others are forging ahead. There's a delightful collection of battery-powered machines coming next year, and that's worth getting excited about.Again, the 2026 Nissan Leaf should be a hugely popular choice as its production ramps up. It's already hitting dealerships now, and with a starting price under $30,000, it'll be hard to beat. But, Chevrolet is going to try with a refreshed Bolt EV for similar money.If you've got more to spend, you've got more options. BMW's stellar iX3 crossover SUV is due soon, as are both the electric CLA sedan and GLC SUV. The most anticipated EV of the year, though, might just be the Rivian R2. This electric SUV will join the stellar R1S and R1T, expanding Rivian's segment footprint while also hopefully expanding its market reach. A $45,000 starting price makes it far more attainable than any of the company's previous offerings. A photograph of the Rivian factory producing the company's R1 SUV variant.Nathan Heleine / RivianIf the prospect of a fun, affordable SUV from Rivian doesn't have you excited for the upcoming year in EVs, maybe some promising news from Europe will. After cutting its own EV incentive program in 2023, Germany's EV sales fell off a cliff, dropping 28 percent in 2024. Cue the predictions of the demise of EVs by many local pundits.Since then, though, EV sales slowly climbed back up, and lately they've been booming, with German road traffic agency KBA saying the total number of newly registered electric vehicles increased by nearly 50 percent in October (year over year). Electric cars now make up 19 percent of the market there, and that's despite Tesla's sales cratering.There's no guarantee that the American market will follow a similar rebound, especially if the anti-EV political messaging continues. Me, though, I've decided I'm staying optimistic, as exhausting as that can be these days.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/a-shaky-year-for-american-evs-could-set-the-tone-for-2026-153000210.html?src=rss",
          "feed_position": 11,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-04/8025df00-2365-11f0-8d7b-a4c3f628eae9"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/antigravity-a1-drone-review-140026021.html",
          "published_at": "Thu, 04 Dec 2025 14:20:07 +0000",
          "title": "Antigravity A1 drone review: FPV flying unlike anything else",
          "standfirst": "The Antigravity A1 is what happens when Insta360’s 360-degree cameras are given wings and flying feels like a video game. Spinning out as its own brand, Antigravity’s debut drone is a big swing: a three-piece set with a drone that captures 8K 360-degree video, FPV goggles and a motion controller. Challenging the dominance of DJI’s (many!) consumer drones is a big ask. Antigravity’s approach is to play to its strengths in 360-degree video and smartphone-first editing. A lot of the appeal comes from how the A1 captures 8K video in all directions, meaning you can edit, cut and swap around your footage — and hopefully rarely miss a moment you’re trying to document. It’s a lot of fun, too, if you can get through the early teething issues, updates and the learning curve. The drone Image by Mat Smith for Engadget The A1 drone is just 249 grams (0.548 lbs). This helps it bypass some drone regulations, though flying permissions vary by region. The pair of cameras mounted on the top and bottom of the drone's body is one of its unique features. It’s difficult to directly compare the A1 against competitor drones, as it offers a mix of features found across different categories and some unique tools of its own. The A1 can capture 360-degree video at up to 8K resolution, and thanks to Insta360’s action cam experience, it can magically remove the drone body from video. This means you can capture video and never see propellers or, well, any part of the drone itself. Along the base of the drone, two landing gears automatically lower when you attempt to land the A1, although you will have to manually retract them when you’re looking to launch the drone. You can also lower the landing gear from one of the controller’s many buttons. The removable battery has a handy one-touch gauge to monitor levels and provides over 20 minutes of flight time, depending on conditions and whether you’re recording video. Antigravity suggests it should last up to 24 minutes during normal filming use. My review device came with two spare batteries and a charging dock. It’s very easy to swap out the batteries, and the charging dock can fully charge a single cell in 45 minutes and even charge all three slots at once. There’s a microSD card slot on the rear of the drone, alongside a USB-C port for (slowly) charging the battery. Image by Mat Smith for Engadget The cameras have a 1/1.28-inch sensor, f/2.2 lens aperture and an ISO range from 100 to 6,400. To adjust those settings beyond auto, you’ll have to dive into the menu inside the goggles, which can be laborious to navigate with a gesture-based controller. Fortunately, auto ISO and white balance are usually good enough. Pro-level content creators might want to tinker with levels here, and there’s a histogram you can toggle on or even a zebra pattern to highlight overexposed shots and areas. and the A1 can record 8K video at up to 30fps or 4K at up to 100fps. You can also meet in the middle, with a 5.2k recording mode. There are also three different flying modes, which are easy to select on the controller. Alongside Normal mode, Sport mode increases the maximum flight speed and offers “enhanced flight performance,” improves control sensitivity and turns off obstacle avoidance. Sport mode offers a tangible difference when flying the A1: it doubles the horizontal flight speed compared to Normal mode. There’s also a Cinematic (C) mode, with a lower max speed for smoother video footage. The controller and goggles Image by Mat Smith for Engadget The flight mode switcher is one of many controls, wheels, buttons and sliders that pepper the surface of the A1’s grip controller. Intriguingly, though, the main way to control the A1 drone is through gestures, not joysticks or buttons. Instead of pitching control sticks to the left and right, up and down, it’s more akin to a video game, where you point the controller where you want to go, shown with a reticle, and pull the trigger. The A1 then shoots off in that direction. The crucial part is that this doesn’t have to be where you’re “looking” from the drone’s POV. This means you can strafe and fly in any direction without your view being constrained by static cameras. It’s a sensation unlike any other drone I’ve flown. It feels more like playing a video game — like piloting a helicopter in GTA 5. You’re able to look in any direction, both while in motion and while hovering stationary. There are controls for recording video, controlling vertical flight and rotating your POV without turning your head. There’s even a RTH (return to home) function that can be accessed by long-pressing the emergency brake button. The included goggles deliver a crisp view of everything, with a pair of 1.03-inch micro-OLED displays with a resolution of 2,560 × 2,560 and a 72Hz refresh rate. Other FPV drone goggles typically offer 100Hz refresh rates, but it wasn’t a dealbreaker for me. I feared that latency hiccups could make airsickness an issue while flying the A1, but I didn’t experience it. My take is that being able to fully control your view makes nausea less of an issue. Another nice touch, especially if you’re flying with friends, is a circular outer display on the goggles, so everyone can see what the A1 sees. Naturally, it can’t encompass the entire view of the drone pilot, but there’s also nothing duller than watching someone else fly a drone. This offers a mild respite. The other eyepiece is a touchpad for steering through menus inside the goggles without having to point and click with the controller. Performance Image by Mat Smith for Engadget While the Antigravity A1 may offer a more immersive drone-flying experience, in pure numerical terms, it lags behind some competitors. For example, even in Sport mode, the A1 tops out at a maximum speed of just under 36 mph, falling behind the likes of DJI’s Avata 2 (60 mph). I was still pleasantly surprised by how responsive the A1 felt, especially in Sport mode. An additional FPV mode (accessible from the goggles) adds more sensitive controls, although I haven’t been able to test it much since it was introduced in a recent firmware update. For someone with more gaming experience than drone piloting hours, Antigravity’s central control system fits like a glove. I could fly where I wanted, confident in the controls and in the knowledge that I would capture what I wanted to. According to Antigravity, you can fly the A1 within a 10km transmission range, although I didn’t manage to test that limit in central London. The experience of starting with the drone felt, at times, unnecessarily arduous. Pairing everything together has to be done in a specific order: power up drone, power up goggles, power up controller. And turning off each item isn’t a typical long press of the power button. Instead, you use a press-once-press-it-again-and-hold method that I forget pretty much every time. Downloading video from the A1 to your phone is also laborious, but that’s not a flaw specific to this drone. Antigravity has attempted some shortcuts, including a microSD card quick reader that connects to your phone or PC via USB-C. However, at the time of testing, manually connecting the microSD is less of an option and more of a necessity. The drone repeatedly failed to connect to the companion app and reliably transfer video files. Some video files recorded seemingly evaporated between firmware updates, only to reappear later. Another file had been converted to two separate circular views, one from each camera, which made it essentially unusable. Hopefully these intial teething problems have been solved by firmware updates and won't be in retail devices. It’s a shame everything isn’t more stable, especially when both flying the A1 and using Antigravity’s editing software are bothis so beginner-friendly. It's something I’ve mentioned before with the parent company’s action cams, but the ability to create barrel rolls, tilt rotations with just one tap or click is, again, just fun. And because you can reframe and tinker with video warping, create tiny planet effects or simply crop to a more traditional, cinematic camera view, Antigravity’s software offers almost infinite ways to present your drone footage. Deeptracking can be done both during recording and editing in post, keeping a moving subject or point of interest centered as the A1 zips around. There are also AI-powered video editing features to chop up your 20 minutes of flying footage into something digestible and engaging with minimal effort. Because it’s a 360-degree video, the footage can be easily cropped to suit both horizontal and vertical formats. However, with a smaller sensor and 8K resolution spread across a 360-degree view, the A1 is not the best video drone. The video is pleasingly crisp and clear, and while the footage is best recorded in bright daylight or other well-lit locations, murky British November days didn’t affect it much. As the A1 has to stitch together its two sensors, there’s often a visible seam to your video, but it’s usually a very subtle glitch. It might stop some video creators from tapping it for their most polished aerial shots though. Recording video later in the day resulted in more noise and less detail. This is when the A1’s Cinematic mode (and generally slower flying) is a good idea, but it still won’t make up for the fact that this drone’s sensors are covering such wide angles. More video-centric drones will deliver cleaner video and better performance in less-than-ideal lighting conditions. Wrap up Image by Mat Smith for Engadget The Antigravity A1 is available now, with a standard bundle including the drone, controller and goggles for $1,599. The Infinity Bundle ($1,999) adds two extra batteries, quick reader dongle, sling bag and a charging dock. That does make it substantially more expensive than rival FPV drones like the DJI Avata 2, but the A1 is also a very different kind of drone. The intuitive controls and ability to look all around you make it unlike anything else currently available. It’s a delightful introduction to drones, FPV or otherwise, but a shame that software issues marred my tests. Plus, pairing all the devices can be convoluted and frustrating at times. If Antigravity is thinking about what to do next, I’d be intrigued to see a version with the camera bonafides to take on similarly priced DJI drones. But that shouldn’t detract from the company’s debut model since the A1 is arguably the most intriguing consumer drone since the Mavic Pro.This article originally appeared on Engadget at https://www.engadget.com/cameras/antigravity-a1-drone-review-140026021.html?src=rss",
          "content": "The Antigravity A1 is what happens when Insta360’s 360-degree cameras are given wings and flying feels like a video game. Spinning out as its own brand, Antigravity’s debut drone is a big swing: a three-piece set with a drone that captures 8K 360-degree video, FPV goggles and a motion controller. Challenging the dominance of DJI’s (many!) consumer drones is a big ask. Antigravity’s approach is to play to its strengths in 360-degree video and smartphone-first editing. A lot of the appeal comes from how the A1 captures 8K video in all directions, meaning you can edit, cut and swap around your footage — and hopefully rarely miss a moment you’re trying to document. It’s a lot of fun, too, if you can get through the early teething issues, updates and the learning curve. The drone Image by Mat Smith for Engadget The A1 drone is just 249 grams (0.548 lbs). This helps it bypass some drone regulations, though flying permissions vary by region. The pair of cameras mounted on the top and bottom of the drone's body is one of its unique features. It’s difficult to directly compare the A1 against competitor drones, as it offers a mix of features found across different categories and some unique tools of its own. The A1 can capture 360-degree video at up to 8K resolution, and thanks to Insta360’s action cam experience, it can magically remove the drone body from video. This means you can capture video and never see propellers or, well, any part of the drone itself. Along the base of the drone, two landing gears automatically lower when you attempt to land the A1, although you will have to manually retract them when you’re looking to launch the drone. You can also lower the landing gear from one of the controller’s many buttons. The removable battery has a handy one-touch gauge to monitor levels and provides over 20 minutes of flight time, depending on conditions and whether you’re recording video. Antigravity suggests it should last up to 24 minutes during normal filming use. My review device came with two spare batteries and a charging dock. It’s very easy to swap out the batteries, and the charging dock can fully charge a single cell in 45 minutes and even charge all three slots at once. There’s a microSD card slot on the rear of the drone, alongside a USB-C port for (slowly) charging the battery. Image by Mat Smith for Engadget The cameras have a 1/1.28-inch sensor, f/2.2 lens aperture and an ISO range from 100 to 6,400. To adjust those settings beyond auto, you’ll have to dive into the menu inside the goggles, which can be laborious to navigate with a gesture-based controller. Fortunately, auto ISO and white balance are usually good enough. Pro-level content creators might want to tinker with levels here, and there’s a histogram you can toggle on or even a zebra pattern to highlight overexposed shots and areas. and the A1 can record 8K video at up to 30fps or 4K at up to 100fps. You can also meet in the middle, with a 5.2k recording mode. There are also three different flying modes, which are easy to select on the controller. Alongside Normal mode, Sport mode increases the maximum flight speed and offers “enhanced flight performance,” improves control sensitivity and turns off obstacle avoidance. Sport mode offers a tangible difference when flying the A1: it doubles the horizontal flight speed compared to Normal mode. There’s also a Cinematic (C) mode, with a lower max speed for smoother video footage. The controller and goggles Image by Mat Smith for Engadget The flight mode switcher is one of many controls, wheels, buttons and sliders that pepper the surface of the A1’s grip controller. Intriguingly, though, the main way to control the A1 drone is through gestures, not joysticks or buttons. Instead of pitching control sticks to the left and right, up and down, it’s more akin to a video game, where you point the controller where you want to go, shown with a reticle, and pull the trigger. The A1 then shoots off in that direction. The crucial part is that this doesn’t have to be where you’re “looking” from the drone’s POV. This means you can strafe and fly in any direction without your view being constrained by static cameras. It’s a sensation unlike any other drone I’ve flown. It feels more like playing a video game — like piloting a helicopter in GTA 5. You’re able to look in any direction, both while in motion and while hovering stationary. There are controls for recording video, controlling vertical flight and rotating your POV without turning your head. There’s even a RTH (return to home) function that can be accessed by long-pressing the emergency brake button. The included goggles deliver a crisp view of everything, with a pair of 1.03-inch micro-OLED displays with a resolution of 2,560 × 2,560 and a 72Hz refresh rate. Other FPV drone goggles typically offer 100Hz refresh rates, but it wasn’t a dealbreaker for me. I feared that latency hiccups could make airsickness an issue while flying the A1, but I didn’t experience it. My take is that being able to fully control your view makes nausea less of an issue. Another nice touch, especially if you’re flying with friends, is a circular outer display on the goggles, so everyone can see what the A1 sees. Naturally, it can’t encompass the entire view of the drone pilot, but there’s also nothing duller than watching someone else fly a drone. This offers a mild respite. The other eyepiece is a touchpad for steering through menus inside the goggles without having to point and click with the controller. Performance Image by Mat Smith for Engadget While the Antigravity A1 may offer a more immersive drone-flying experience, in pure numerical terms, it lags behind some competitors. For example, even in Sport mode, the A1 tops out at a maximum speed of just under 36 mph, falling behind the likes of DJI’s Avata 2 (60 mph). I was still pleasantly surprised by how responsive the A1 felt, especially in Sport mode. An additional FPV mode (accessible from the goggles) adds more sensitive controls, although I haven’t been able to test it much since it was introduced in a recent firmware update. For someone with more gaming experience than drone piloting hours, Antigravity’s central control system fits like a glove. I could fly where I wanted, confident in the controls and in the knowledge that I would capture what I wanted to. According to Antigravity, you can fly the A1 within a 10km transmission range, although I didn’t manage to test that limit in central London. The experience of starting with the drone felt, at times, unnecessarily arduous. Pairing everything together has to be done in a specific order: power up drone, power up goggles, power up controller. And turning off each item isn’t a typical long press of the power button. Instead, you use a press-once-press-it-again-and-hold method that I forget pretty much every time. Downloading video from the A1 to your phone is also laborious, but that’s not a flaw specific to this drone. Antigravity has attempted some shortcuts, including a microSD card quick reader that connects to your phone or PC via USB-C. However, at the time of testing, manually connecting the microSD is less of an option and more of a necessity. The drone repeatedly failed to connect to the companion app and reliably transfer video files. Some video files recorded seemingly evaporated between firmware updates, only to reappear later. Another file had been converted to two separate circular views, one from each camera, which made it essentially unusable. Hopefully these intial teething problems have been solved by firmware updates and won't be in retail devices. It’s a shame everything isn’t more stable, especially when both flying the A1 and using Antigravity’s editing software are bothis so beginner-friendly. It's something I’ve mentioned before with the parent company’s action cams, but the ability to create barrel rolls, tilt rotations with just one tap or click is, again, just fun. And because you can reframe and tinker with video warping, create tiny planet effects or simply crop to a more traditional, cinematic camera view, Antigravity’s software offers almost infinite ways to present your drone footage. Deeptracking can be done both during recording and editing in post, keeping a moving subject or point of interest centered as the A1 zips around. There are also AI-powered video editing features to chop up your 20 minutes of flying footage into something digestible and engaging with minimal effort. Because it’s a 360-degree video, the footage can be easily cropped to suit both horizontal and vertical formats. However, with a smaller sensor and 8K resolution spread across a 360-degree view, the A1 is not the best video drone. The video is pleasingly crisp and clear, and while the footage is best recorded in bright daylight or other well-lit locations, murky British November days didn’t affect it much. As the A1 has to stitch together its two sensors, there’s often a visible seam to your video, but it’s usually a very subtle glitch. It might stop some video creators from tapping it for their most polished aerial shots though. Recording video later in the day resulted in more noise and less detail. This is when the A1’s Cinematic mode (and generally slower flying) is a good idea, but it still won’t make up for the fact that this drone’s sensors are covering such wide angles. More video-centric drones will deliver cleaner video and better performance in less-than-ideal lighting conditions. Wrap up Image by Mat Smith for Engadget The Antigravity A1 is available now, with a standard bundle including the drone, controller and goggles for $1,599. The Infinity Bundle ($1,999) adds two extra batteries, quick reader dongle, sling bag and a charging dock. That does make it substantially more expensive than rival FPV drones like the DJI Avata 2, but the A1 is also a very different kind of drone. The intuitive controls and ability to look all around you make it unlike anything else currently available. It’s a delightful introduction to drones, FPV or otherwise, but a shame that software issues marred my tests. Plus, pairing all the devices can be convoluted and frustrating at times. If Antigravity is thinking about what to do next, I’d be intrigued to see a version with the camera bonafides to take on similarly priced DJI drones. But that shouldn’t detract from the company’s debut model since the A1 is arguably the most intriguing consumer drone since the Mavic Pro.This article originally appeared on Engadget at https://www.engadget.com/cameras/antigravity-a1-drone-review-140026021.html?src=rss",
          "feed_position": 13,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/8ec9ef20-d0fc-11f0-af7d-0d092e6eb0b3"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/apples-airpods-4-with-anc-are-back-on-sale-for-99-140903670.html",
          "published_at": "Thu, 04 Dec 2025 14:09:03 +0000",
          "title": "Apple's AirPods 4 with ANC are back on sale for $99",
          "standfirst": "If you missed the Black Friday sale on Apple's AirPods 4 with ANC, you're in luck — they're back on sale at the same $99 price for a substantial $80 savings (45 percent). What's more, if you're one who frets about damaging your gear, you can grab them with AppleCare+ for $118, saving 43 percent from the normal price. We think that the AirPods Pro 2 are the best AirPods overall, but the ANC-enabled AirPods 4 are also a solid choice, especially at this price. We gave them a score of 86 in our review. Apple's AirPods 4 come in two variants, with and without ANC. Though the base model is solid, the version on sale here with ANC offers a number of advantages like Conversation Awareness, Adaptive Audio and Transparency mode. They also have a charging case that supports MagSafe and Qi-compatible wireless charging, along with a built-in speaker that emits beeps when you activate Find My. And as Apple recently announced, AirPods 4 with ANC supports the company's Live Translation feature. Our main reservation with the AirPods 4 with ANC is that the Airpods Pro 2 are a better noise-cancellation option when they go on sale. At this price, though, the AirPods 4 with ANC are a real bargain if you're looking for new buds — especially if you prefer the open-ears type. As mentioned, for extra peace of mind you can also get the Airpods 4 with ANC plus AppleCare+ protection for $118, or 43 percent off. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/audio/apples-airpods-4-with-anc-are-back-on-sale-for-99-140903670.html?src=rss",
          "content": "If you missed the Black Friday sale on Apple's AirPods 4 with ANC, you're in luck — they're back on sale at the same $99 price for a substantial $80 savings (45 percent). What's more, if you're one who frets about damaging your gear, you can grab them with AppleCare+ for $118, saving 43 percent from the normal price. We think that the AirPods Pro 2 are the best AirPods overall, but the ANC-enabled AirPods 4 are also a solid choice, especially at this price. We gave them a score of 86 in our review. Apple's AirPods 4 come in two variants, with and without ANC. Though the base model is solid, the version on sale here with ANC offers a number of advantages like Conversation Awareness, Adaptive Audio and Transparency mode. They also have a charging case that supports MagSafe and Qi-compatible wireless charging, along with a built-in speaker that emits beeps when you activate Find My. And as Apple recently announced, AirPods 4 with ANC supports the company's Live Translation feature. Our main reservation with the AirPods 4 with ANC is that the Airpods Pro 2 are a better noise-cancellation option when they go on sale. At this price, though, the AirPods 4 with ANC are a real bargain if you're looking for new buds — especially if you prefer the open-ears type. As mentioned, for extra peace of mind you can also get the Airpods 4 with ANC plus AppleCare+ protection for $118, or 43 percent off. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/audio/apples-airpods-4-with-anc-are-back-on-sale-for-99-140903670.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/aws-launches-kiro-powers-with-stripe-figma-and-datadog-integrations-for-ai",
          "published_at": "Thu, 04 Dec 2025 14:02:00 GMT",
          "title": "AWS launches Kiro powers with Stripe, Figma, and Datadog integrations for AI-assisted coding",
          "standfirst": "Amazon Web Services on Wednesday introduced Kiro powers, a system that allows software developers to give their AI coding assistants instant, specialized expertise in specific tools and workflows — addressing what the company calls a fundamental bottleneck in how artificial intelligence agents operate today.AWS made the announcement at its annual re:Invent conference in Las Vegas. The capability marks a departure from how most AI coding tools work today. Typically, these tools load every possible capability into memory upfront — a process that burns through computational resources and can overwhelm the AI with irrelevant information. Kiro powers takes the opposite approach, activating specialized knowledge only at the moment a developer actually needs it.\"Our goal is to give the agent specialized context so it can reach the right outcome faster — and in a way that also reduces cost,\" said Deepak Singh, Vice President of Developer Agents and Experiences at Amazon, in an exclusive interview with VentureBeat.The launch includes partnerships with nine technology companies: Datadog, Dynatrace, Figma, Neon, Netlify, Postman, Stripe, Supabase, and AWS&#x27;s own services. Developers can also create and share their own powers with the community.Why AI coding assistants choke when developers connect too many toolsTo understand why Kiro powers matters, it helps to understand a growing tension in the AI development tool market.Modern AI coding assistants rely on something called the Model Context Protocol, or MCP, to connect with external tools and services. When a developer wants their AI assistant to work with Stripe for payments, Figma for design, and Supabase for databases, they connect MCP servers for each service.The problem: each connection loads dozens of tool definitions into the AI&#x27;s working memory before it writes a single line of code. According to AWS documentation, connecting just five MCP servers can consume more than 50,000 tokens — roughly 40 percent of an AI model&#x27;s context window — before the developer even types their first request.Developers have grown increasingly vocal about this issue. Many complain that they don&#x27;t want to burn through their token allocations just to have an AI agent figure out which tools are relevant to a specific task. They want to get to their workflow instantly — not watch an overloaded agent struggle to sort through irrelevant context.This phenomenon, which some in the industry call \"context rot,\" leads to slower responses, lower-quality outputs, and significantly higher costs — since AI services typically charge by the token.Inside the technology that loads AI expertise on demandKiro powers addresses this by packaging three components into a single, dynamically-loaded bundle.The first component is a steering file called POWER.md, which functions as an onboarding manual for the AI agent. It tells the agent what tools are available and, crucially, when to use them. The second component is the MCP server configuration itself — the actual connection to external services. The third includes optional hooks and automation that trigger specific actions.When a developer mentions \"payment\" or \"checkout\" in their conversation with Kiro, the system automatically activates the Stripe power, loading its tools and best practices into context. When the developer shifts to database work, Supabase activates while Stripe deactivates. The baseline context usage when no powers are active approaches zero.\"You click a button and it automatically loads,\" Singh said. \"Once a power has been created, developers just select &#x27;open in Kiro&#x27; and it launches the IDE with everything ready to go.\"How AWS is bringing elite developer techniques to the massesSingh framed Kiro powers as a democratization of advanced development practices. Before this capability, only the most sophisticated developers knew how to properly configure their AI agents with specialized context — writing custom steering files, crafting precise prompts, and manually managing which tools were active at any given time.\"We&#x27;ve found that our developers were adding in capabilities to make their agents more specialized,\" Singh said. \"They wanted to give the agent some special powers to do a specific problem. For example, they wanted their front end developer, and they wanted the agent to become an expert at backend as a service.\"This observation led to a key insight: if Supabase or Stripe could build the optimal context configuration once, every developer using those services could benefit.\"Kiro powers formalizes that — things that people, only the most advanced people were doing — and allows anyone to get those kind of skills,\" Singh said.Why dynamic loading beats fine-tuning for most AI coding use casesThe announcement also positions Kiro powers as a more economical alternative to fine-tuning, the process of training an AI model on specialized data to improve its performance in specific domains.\"It&#x27;s much cheaper,\" Singh said, when asked how powers compare to fine-tuning. \"Fine-tuning is very expensive, and you can&#x27;t fine-tune most frontier models.\"This is a significant point. The most capable AI models from Anthropic, OpenAI, and Google are typically \"closed source,\" meaning developers cannot modify their underlying training. They can only influence the models&#x27; behavior through the prompts and context they provide.\"Most people are already using powerful models like Sonnet 4.5 or Opus 4.5,\" Singh said. \"What those models need is to be pointed in the right direction.\"The dynamic loading mechanism also reduces ongoing costs. Because powers only activate when relevant, developers aren&#x27;t paying for token usage on tools they&#x27;re not currently using.Where Kiro powers fits in Amazon&#x27;s bigger bet on autonomous AI agentsKiro powers arrives as part of a broader push by AWS into what the company calls \"agentic AI\" — artificial intelligence systems that can operate autonomously over extended periods.Earlier at re:Invent, AWS announced three \"frontier agents\" designed to work for hours or days without human intervention: the Kiro autonomous agent for software development, the AWS security agent, and the AWS DevOps agent. These represent a different approach from Kiro powers — tackling large, ambiguous problems rather than providing specialized expertise for specific tasks.The two approaches are complementary. Frontier agents handle complex, multi-day projects that require autonomous decision-making across multiple codebases. Kiro powers, by contrast, gives developers precise, efficient tools for everyday development tasks where speed and token efficiency matter most.The company is betting that developers need both ends of this spectrum to be productive.What Kiro powers reveals about the future of AI-assisted software developmentThe launch reflects a maturing market for AI development tools. GitHub Copilot, which Microsoft launched in 2021, introduced millions of developers to AI-assisted coding. Since then, a proliferation of tools — including Cursor, Cline, and Claude Code — have competed for developers&#x27; attention.But as these tools have grown more capable, they&#x27;ve also grown more complex. The Model Context Protocol, which Anthropic open-sourced last year, created a standard for connecting AI agents to external services. That solved one problem while creating another: the context overload that Kiro powers now addresses.AWS is positioning itself as the company that understands production software development at scale. Singh emphasized that Amazon&#x27;s experience running AWS for 20 years, combined with its own massive internal software engineering organization, gives it unique insight into how developers actually work.\"It&#x27;s not something you would use just for your prototype or your toy application,\" Singh said of AWS&#x27;s AI development tools. \"If you want to build production applications, there&#x27;s a lot of knowledge that we bring in as AWS that applies here.\"The road ahead for Kiro powers and cross-platform compatibilityAWS indicated that Kiro powers currently works only within the Kiro IDE, but the company is building toward cross-compatibility with other AI development tools, including command-line interfaces, Cursor, Cline, and Claude Code. The company&#x27;s documentation describes a future where developers can \"build a power once, use it anywhere\" — though that vision remains aspirational for now.For the technology partners launching powers today, the appeal is straightforward: rather than maintaining separate integration documentation for every AI tool on the market, they can create a single power that works everywhere Kiro does. As more AI coding assistants crowd into the market, that kind of efficiency becomes increasingly valuable.Kiro powers is available now to developers using Kiro IDE version 0.7 or later at no additional charge beyond the standard Kiro subscription.The underlying bet is a familiar one in the history of computing: that the winners in AI-assisted development won&#x27;t be the tools that try to do everything at once, but the ones smart enough to know what to forget.",
          "content": "Amazon Web Services on Wednesday introduced Kiro powers, a system that allows software developers to give their AI coding assistants instant, specialized expertise in specific tools and workflows — addressing what the company calls a fundamental bottleneck in how artificial intelligence agents operate today.AWS made the announcement at its annual re:Invent conference in Las Vegas. The capability marks a departure from how most AI coding tools work today. Typically, these tools load every possible capability into memory upfront — a process that burns through computational resources and can overwhelm the AI with irrelevant information. Kiro powers takes the opposite approach, activating specialized knowledge only at the moment a developer actually needs it.\"Our goal is to give the agent specialized context so it can reach the right outcome faster — and in a way that also reduces cost,\" said Deepak Singh, Vice President of Developer Agents and Experiences at Amazon, in an exclusive interview with VentureBeat.The launch includes partnerships with nine technology companies: Datadog, Dynatrace, Figma, Neon, Netlify, Postman, Stripe, Supabase, and AWS&#x27;s own services. Developers can also create and share their own powers with the community.Why AI coding assistants choke when developers connect too many toolsTo understand why Kiro powers matters, it helps to understand a growing tension in the AI development tool market.Modern AI coding assistants rely on something called the Model Context Protocol, or MCP, to connect with external tools and services. When a developer wants their AI assistant to work with Stripe for payments, Figma for design, and Supabase for databases, they connect MCP servers for each service.The problem: each connection loads dozens of tool definitions into the AI&#x27;s working memory before it writes a single line of code. According to AWS documentation, connecting just five MCP servers can consume more than 50,000 tokens — roughly 40 percent of an AI model&#x27;s context window — before the developer even types their first request.Developers have grown increasingly vocal about this issue. Many complain that they don&#x27;t want to burn through their token allocations just to have an AI agent figure out which tools are relevant to a specific task. They want to get to their workflow instantly — not watch an overloaded agent struggle to sort through irrelevant context.This phenomenon, which some in the industry call \"context rot,\" leads to slower responses, lower-quality outputs, and significantly higher costs — since AI services typically charge by the token.Inside the technology that loads AI expertise on demandKiro powers addresses this by packaging three components into a single, dynamically-loaded bundle.The first component is a steering file called POWER.md, which functions as an onboarding manual for the AI agent. It tells the agent what tools are available and, crucially, when to use them. The second component is the MCP server configuration itself — the actual connection to external services. The third includes optional hooks and automation that trigger specific actions.When a developer mentions \"payment\" or \"checkout\" in their conversation with Kiro, the system automatically activates the Stripe power, loading its tools and best practices into context. When the developer shifts to database work, Supabase activates while Stripe deactivates. The baseline context usage when no powers are active approaches zero.\"You click a button and it automatically loads,\" Singh said. \"Once a power has been created, developers just select &#x27;open in Kiro&#x27; and it launches the IDE with everything ready to go.\"How AWS is bringing elite developer techniques to the massesSingh framed Kiro powers as a democratization of advanced development practices. Before this capability, only the most sophisticated developers knew how to properly configure their AI agents with specialized context — writing custom steering files, crafting precise prompts, and manually managing which tools were active at any given time.\"We&#x27;ve found that our developers were adding in capabilities to make their agents more specialized,\" Singh said. \"They wanted to give the agent some special powers to do a specific problem. For example, they wanted their front end developer, and they wanted the agent to become an expert at backend as a service.\"This observation led to a key insight: if Supabase or Stripe could build the optimal context configuration once, every developer using those services could benefit.\"Kiro powers formalizes that — things that people, only the most advanced people were doing — and allows anyone to get those kind of skills,\" Singh said.Why dynamic loading beats fine-tuning for most AI coding use casesThe announcement also positions Kiro powers as a more economical alternative to fine-tuning, the process of training an AI model on specialized data to improve its performance in specific domains.\"It&#x27;s much cheaper,\" Singh said, when asked how powers compare to fine-tuning. \"Fine-tuning is very expensive, and you can&#x27;t fine-tune most frontier models.\"This is a significant point. The most capable AI models from Anthropic, OpenAI, and Google are typically \"closed source,\" meaning developers cannot modify their underlying training. They can only influence the models&#x27; behavior through the prompts and context they provide.\"Most people are already using powerful models like Sonnet 4.5 or Opus 4.5,\" Singh said. \"What those models need is to be pointed in the right direction.\"The dynamic loading mechanism also reduces ongoing costs. Because powers only activate when relevant, developers aren&#x27;t paying for token usage on tools they&#x27;re not currently using.Where Kiro powers fits in Amazon&#x27;s bigger bet on autonomous AI agentsKiro powers arrives as part of a broader push by AWS into what the company calls \"agentic AI\" — artificial intelligence systems that can operate autonomously over extended periods.Earlier at re:Invent, AWS announced three \"frontier agents\" designed to work for hours or days without human intervention: the Kiro autonomous agent for software development, the AWS security agent, and the AWS DevOps agent. These represent a different approach from Kiro powers — tackling large, ambiguous problems rather than providing specialized expertise for specific tasks.The two approaches are complementary. Frontier agents handle complex, multi-day projects that require autonomous decision-making across multiple codebases. Kiro powers, by contrast, gives developers precise, efficient tools for everyday development tasks where speed and token efficiency matter most.The company is betting that developers need both ends of this spectrum to be productive.What Kiro powers reveals about the future of AI-assisted software developmentThe launch reflects a maturing market for AI development tools. GitHub Copilot, which Microsoft launched in 2021, introduced millions of developers to AI-assisted coding. Since then, a proliferation of tools — including Cursor, Cline, and Claude Code — have competed for developers&#x27; attention.But as these tools have grown more capable, they&#x27;ve also grown more complex. The Model Context Protocol, which Anthropic open-sourced last year, created a standard for connecting AI agents to external services. That solved one problem while creating another: the context overload that Kiro powers now addresses.AWS is positioning itself as the company that understands production software development at scale. Singh emphasized that Amazon&#x27;s experience running AWS for 20 years, combined with its own massive internal software engineering organization, gives it unique insight into how developers actually work.\"It&#x27;s not something you would use just for your prototype or your toy application,\" Singh said of AWS&#x27;s AI development tools. \"If you want to build production applications, there&#x27;s a lot of knowledge that we bring in as AWS that applies here.\"The road ahead for Kiro powers and cross-platform compatibilityAWS indicated that Kiro powers currently works only within the Kiro IDE, but the company is building toward cross-compatibility with other AI development tools, including command-line interfaces, Cursor, Cline, and Claude Code. The company&#x27;s documentation describes a future where developers can \"build a power once, use it anywhere\" — though that vision remains aspirational for now.For the technology partners launching powers today, the appeal is straightforward: rather than maintaining separate integration documentation for every AI tool on the market, they can create a single power that works everywhere Kiro does. As more AI coding assistants crowd into the market, that kind of efficiency becomes increasingly valuable.Kiro powers is available now to developers using Kiro IDE version 0.7 or later at no additional charge beyond the standard Kiro subscription.The underlying bet is a familiar one in the history of computing: that the winners in AI-assisted development won&#x27;t be the tools that try to do everything at once, but the ones smart enough to know what to forget.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/53TbLNDfKawmAd8kGfw7ce/17400e5e49710944890e2a6b69cf04f8/nuneybits_Vector_art_of_a_server_rack_in_the_clouds_bf8ba787-9002-494b-b6be-fedd40deb4f9.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/gong-study-sales-teams-using-ai-generate-77-more-revenue-per-rep",
          "published_at": "Thu, 04 Dec 2025 14:00:00 GMT",
          "title": "Gong study: Sales teams using AI generate 77% more revenue per rep",
          "standfirst": "The debate over whether artificial intelligence belongs in the corporate boardroom appears to be over — at least for the people responsible for generating revenue.Seven in ten enterprise revenue leaders now trust AI to regularly inform their business decisions, according to a sweeping new study released Thursday by Gong, the revenue intelligence company. The finding marks a dramatic shift from just two years ago, when most organizations treated AI as an experimental technology relegated to pilot programs and individual productivity hacks.The research, based on an analysis of 7.1 million sales opportunities across more than 3,600 companies and a survey of over 3,000 global revenue leaders spanning the United States, United Kingdom, Australia, and Germany, paints a picture of an industry in rapid transformation. Organizations that have embedded AI into their core go-to-market strategies are 65 percent more likely to increase their win rates than competitors still treating the technology as optional.\"I don&#x27;t think people delegate decisions to AI, but they do rely on AI in the process of making decisions,\" Amit Bendov, Gong&#x27;s co-founder and chief executive, said in an exclusive interview with VentureBeat. \"Humans are making the decision, but they&#x27;re largely assisted.\"The distinction matters. Rather than replacing human judgment, AI has become what Bendov describes as a \"second opinion\" — a data-driven check on the intuition and guesswork that has traditionally governed sales forecasting and strategy.Slowing growth is forcing sales teams to squeeze more from every repThe timing of AI&#x27;s ascendance in revenue organizations is no coincidence. The study reveals a sobering reality: after rebounding in 2024, average annual revenue growth among surveyed companies decelerated to 16 percent in 2025, marking a three-percentage-point decline year over year. Sales rep quota attainment fell from 52 percent to 46 percent over the same period.The culprit, according to Gong&#x27;s analysis, isn&#x27;t that salespeople are performing worse on individual deals. Win rates and deal duration remained consistent. The problem is that representatives are working fewer opportunities—a finding that suggests operational inefficiencies are eating into selling time.This helps explain why productivity has rocketed to the top of executive priorities. For the first time in the study&#x27;s history, increasing the productivity of existing teams ranked as the number-one growth strategy for 2026, jumping from fourth place the previous year.\"The focus is on increasing sales productivity,\" Bendov said. \"How much dollar-output per dollar-input.\"The numbers back up the urgency. Teams where sellers regularly use AI tools generate 77 percent more revenue per representative than those that don&#x27;t — a gap Gong characterizes as a six-figure difference per salesperson annually.Companies are moving beyond basic AI automation toward strategic decision-makingThe nature of AI adoption in sales has evolved considerably over the past year. In 2024, most revenue teams used AI for basic automation: transcribing calls, drafting emails, updating CRM records. Those use cases continue to grow, but 2025 marked what the report calls a shift \"from automation to intelligence.\"The number of U.S. companies using AI for forecasting and measuring strategic initiatives jumped 50 percent year over year. These more sophisticated applications — predicting deal outcomes, identifying at-risk accounts, measuring which value propositions resonate with different buyer personas — correlate with dramatically better results.Organizations in the 95th percentile of commercial impact from AI were two to four times more likely to have deployed these strategic use cases, according to the study.Bendov offered a concrete example of how this plays out in practice. \"Companies have thousands of deals that they roll up into their forecast,\" he said. \"It used to be based solely on human sentiment—believe it or not. That&#x27;s why a lot of companies miss their numbers: because people say, &#x27;Oh, he told me he&#x27;ll buy,&#x27; or &#x27;I think I can probably get this one.&#x27;\"AI changes that calculus by examining evidence rather than optimism. \"Companies now get a second opinion from AI on their forecasting, and that improves forecasting accuracy dramatically — 10 [or] 15 percent better accuracy just because it&#x27;s evidence-based, not just based on human sentiment,\" Bendov said.Revenue-specific AI tools are dramatically outperforming general-purpose alternativesOne of the study&#x27;s more provocative findings concerns the type of AI that delivers results. Teams using revenue-specific AI solutions — tools built explicitly for sales workflows rather than general-purpose platforms like ChatGPT — reported 13 percent higher revenue growth and 85 percent greater commercial impact than those relying on generic tools.These specialized systems were also twice as likely to be deployed for forecasting and predictive modeling, the report found.The finding carries obvious implications for Gong, which sells precisely this type of domain-specific platform. But the data suggests a real distinction in outcomes. General-purpose AI, while more prevalent, often creates what the report describes as a \"blind spot\" for organizations — particularly when employees adopt consumer AI tools without company oversight.Research from MIT suggests that while only 59 percent of survey respondents said their teams use personal AI tools like ChatGPT at work, the actual figure is likely closer to 90 percent. This shadow AI usage poses security risks and creates fragmented technology stacks that undermine the potential for organization-wide intelligence.Most sales leaders believe AI will reshape their jobs rather than eliminate themPerhaps the most closely watched question in any AI study concerns employment. The Gong research offers a more nuanced picture than the apocalyptic predictions that often dominate headlines.When asked about AI&#x27;s three-year impact on revenue headcount, 43 percent of respondents said they expect it to transform jobs without reducing headcount — the most common response. Only 28 percent anticipate job eliminations, while 21 percent actually foresee AI creating new roles. Just 8 percent predict minimal impact.Bendov frames the opportunity in terms of reclaiming lost time. He cited Forrester research indicating that 77 percent of a sales representative&#x27;s time is spent on activities that don&#x27;t involve customers — administrative work, meeting preparation, researching accounts, updating forecasts, and internal briefings.\"AI can eliminate, ideally, all 77 percent—all the drudgery work that they&#x27;re doing,\" Bendov said. \"I don&#x27;t think it necessarily eliminates jobs. People are half productive right now. Let&#x27;s make them fully productive, and whatever you&#x27;re paying them will translate to much higher revenue.\"The transformation is already visible in role consolidation. Over the past decade, sales organizations splintered into hyper-specialized functions: one person qualifies leads, another sets appointments, a third closes deals, a fourth handles onboarding. The result was customers interacting with five or six different people across their buying journey.\"Which is not a great buyer experience, because every time I meet a new person that might not have the full context, and it&#x27;s very inefficient for companies,\" Bendov said. \"Now with AI, you can have one person do all this, or much of this.\"At Gong itself, sellers now generate 80 percent of their own appointments because AI handles the prospecting legwork, Bendov said.American companies are adopting AI 18 months faster than their European counterpartsThe study reveals a notable divide in AI adoption between the United States and Europe. While 87 percent of U.S. companies now use AI in their revenue operations, with another 9 percent planning adoption within a year, the United Kingdom trails by 12 to 18 months. Just 70 percent of UK companies currently use AI, with 22 percent planning near-term adoption — figures that mirror U.S. data from 2024.Bendov said the pattern reflects a broader historical tendency for enterprise technology trends to cross the Atlantic with a delay. \"It&#x27;s always like that,\" he said. \"Even when the internet was taking off in the US, Europe was a step behind.\"The gap isn&#x27;t permanent, he noted, and Europe sometimes leads on technology adoption — mobile payments and messaging apps like WhatsApp gained traction there before the U.S. — but for AI specifically, the American market remains ahead.Gong says a decade of AI development gives it an edge over Salesforce and MicrosoftThe findings arrive as Gong navigates an increasingly crowded market. The company, which recently surpassed $300 million in annual recurring revenue, faces potential competition from enterprise software giants like Salesforce and Microsoft, both of which are embedding AI capabilities into their platforms.Bendov argues that Gong&#x27;s decade of AI development creates a substantial barrier to entry. The company&#x27;s architecture comprises three layers: a \"revenue graph\" that aggregates customer data from CRM systems, emails, calls, videos, and web signals; an intelligence layer combining large language models with approximately 40 proprietary small language models; and workflow applications built on top.\"Anybody that would want to build something like that—it&#x27;s not a small feature, it&#x27;s 10 years in development—would need first to build the revenue graph,\" Bendov said.Rather than viewing Salesforce and Microsoft as threats, Bendov characterized them as partners, pointing to both companies&#x27; participation in Gong&#x27;s recent user conference to discuss agent interoperability. The rise of MCP (Model Context Protocol) support and consumption-based pricing models means customers can mix AI agents from multiple vendors rather than committing to a single platform.The real question is whether AI will expand the sales profession or hollow it outThe report&#x27;s implications extend beyond sales departments. If AI can transform revenue operations — long considered a relationship-driven, human-centric function — it raises questions about which other business processes might be next.Bendov sees the potential for expansion rather than contraction. Drawing an analogy to digital photography, he noted that while camera manufacturers suffered, the total number of photos taken exploded once smartphones made photography effortless.\"If AI makes selling simple, I could see a world—I don&#x27;t know exactly what it looks like yet—but why not?\" Bendov said. \"Maybe ten times more jobs than we have now. It&#x27;s expensive and inefficient today, but if it becomes as easy as taking a photo, the industry could actually grow and create opportunities for people of different abilities, from different locations.\"For Bendov, who co-founded Gong in 2015 when AI was still a hard sell to non-technical business users, the current moment represents something he waited a decade to see. Back then, mentioning AI to sales executives sounded like science fiction. The company struggled to raise money because the underlying technology barely existed.\"When we started the company, we were born as an AI company, but we had to almost hide AI,\" Bendov recalled. \"It was intimidating.\"Now, seven out of ten of those same executives say they trust AI to help run their business. The technology that once had to be disguised has become the one thing nobody can afford to ignore.",
          "content": "The debate over whether artificial intelligence belongs in the corporate boardroom appears to be over — at least for the people responsible for generating revenue.Seven in ten enterprise revenue leaders now trust AI to regularly inform their business decisions, according to a sweeping new study released Thursday by Gong, the revenue intelligence company. The finding marks a dramatic shift from just two years ago, when most organizations treated AI as an experimental technology relegated to pilot programs and individual productivity hacks.The research, based on an analysis of 7.1 million sales opportunities across more than 3,600 companies and a survey of over 3,000 global revenue leaders spanning the United States, United Kingdom, Australia, and Germany, paints a picture of an industry in rapid transformation. Organizations that have embedded AI into their core go-to-market strategies are 65 percent more likely to increase their win rates than competitors still treating the technology as optional.\"I don&#x27;t think people delegate decisions to AI, but they do rely on AI in the process of making decisions,\" Amit Bendov, Gong&#x27;s co-founder and chief executive, said in an exclusive interview with VentureBeat. \"Humans are making the decision, but they&#x27;re largely assisted.\"The distinction matters. Rather than replacing human judgment, AI has become what Bendov describes as a \"second opinion\" — a data-driven check on the intuition and guesswork that has traditionally governed sales forecasting and strategy.Slowing growth is forcing sales teams to squeeze more from every repThe timing of AI&#x27;s ascendance in revenue organizations is no coincidence. The study reveals a sobering reality: after rebounding in 2024, average annual revenue growth among surveyed companies decelerated to 16 percent in 2025, marking a three-percentage-point decline year over year. Sales rep quota attainment fell from 52 percent to 46 percent over the same period.The culprit, according to Gong&#x27;s analysis, isn&#x27;t that salespeople are performing worse on individual deals. Win rates and deal duration remained consistent. The problem is that representatives are working fewer opportunities—a finding that suggests operational inefficiencies are eating into selling time.This helps explain why productivity has rocketed to the top of executive priorities. For the first time in the study&#x27;s history, increasing the productivity of existing teams ranked as the number-one growth strategy for 2026, jumping from fourth place the previous year.\"The focus is on increasing sales productivity,\" Bendov said. \"How much dollar-output per dollar-input.\"The numbers back up the urgency. Teams where sellers regularly use AI tools generate 77 percent more revenue per representative than those that don&#x27;t — a gap Gong characterizes as a six-figure difference per salesperson annually.Companies are moving beyond basic AI automation toward strategic decision-makingThe nature of AI adoption in sales has evolved considerably over the past year. In 2024, most revenue teams used AI for basic automation: transcribing calls, drafting emails, updating CRM records. Those use cases continue to grow, but 2025 marked what the report calls a shift \"from automation to intelligence.\"The number of U.S. companies using AI for forecasting and measuring strategic initiatives jumped 50 percent year over year. These more sophisticated applications — predicting deal outcomes, identifying at-risk accounts, measuring which value propositions resonate with different buyer personas — correlate with dramatically better results.Organizations in the 95th percentile of commercial impact from AI were two to four times more likely to have deployed these strategic use cases, according to the study.Bendov offered a concrete example of how this plays out in practice. \"Companies have thousands of deals that they roll up into their forecast,\" he said. \"It used to be based solely on human sentiment—believe it or not. That&#x27;s why a lot of companies miss their numbers: because people say, &#x27;Oh, he told me he&#x27;ll buy,&#x27; or &#x27;I think I can probably get this one.&#x27;\"AI changes that calculus by examining evidence rather than optimism. \"Companies now get a second opinion from AI on their forecasting, and that improves forecasting accuracy dramatically — 10 [or] 15 percent better accuracy just because it&#x27;s evidence-based, not just based on human sentiment,\" Bendov said.Revenue-specific AI tools are dramatically outperforming general-purpose alternativesOne of the study&#x27;s more provocative findings concerns the type of AI that delivers results. Teams using revenue-specific AI solutions — tools built explicitly for sales workflows rather than general-purpose platforms like ChatGPT — reported 13 percent higher revenue growth and 85 percent greater commercial impact than those relying on generic tools.These specialized systems were also twice as likely to be deployed for forecasting and predictive modeling, the report found.The finding carries obvious implications for Gong, which sells precisely this type of domain-specific platform. But the data suggests a real distinction in outcomes. General-purpose AI, while more prevalent, often creates what the report describes as a \"blind spot\" for organizations — particularly when employees adopt consumer AI tools without company oversight.Research from MIT suggests that while only 59 percent of survey respondents said their teams use personal AI tools like ChatGPT at work, the actual figure is likely closer to 90 percent. This shadow AI usage poses security risks and creates fragmented technology stacks that undermine the potential for organization-wide intelligence.Most sales leaders believe AI will reshape their jobs rather than eliminate themPerhaps the most closely watched question in any AI study concerns employment. The Gong research offers a more nuanced picture than the apocalyptic predictions that often dominate headlines.When asked about AI&#x27;s three-year impact on revenue headcount, 43 percent of respondents said they expect it to transform jobs without reducing headcount — the most common response. Only 28 percent anticipate job eliminations, while 21 percent actually foresee AI creating new roles. Just 8 percent predict minimal impact.Bendov frames the opportunity in terms of reclaiming lost time. He cited Forrester research indicating that 77 percent of a sales representative&#x27;s time is spent on activities that don&#x27;t involve customers — administrative work, meeting preparation, researching accounts, updating forecasts, and internal briefings.\"AI can eliminate, ideally, all 77 percent—all the drudgery work that they&#x27;re doing,\" Bendov said. \"I don&#x27;t think it necessarily eliminates jobs. People are half productive right now. Let&#x27;s make them fully productive, and whatever you&#x27;re paying them will translate to much higher revenue.\"The transformation is already visible in role consolidation. Over the past decade, sales organizations splintered into hyper-specialized functions: one person qualifies leads, another sets appointments, a third closes deals, a fourth handles onboarding. The result was customers interacting with five or six different people across their buying journey.\"Which is not a great buyer experience, because every time I meet a new person that might not have the full context, and it&#x27;s very inefficient for companies,\" Bendov said. \"Now with AI, you can have one person do all this, or much of this.\"At Gong itself, sellers now generate 80 percent of their own appointments because AI handles the prospecting legwork, Bendov said.American companies are adopting AI 18 months faster than their European counterpartsThe study reveals a notable divide in AI adoption between the United States and Europe. While 87 percent of U.S. companies now use AI in their revenue operations, with another 9 percent planning adoption within a year, the United Kingdom trails by 12 to 18 months. Just 70 percent of UK companies currently use AI, with 22 percent planning near-term adoption — figures that mirror U.S. data from 2024.Bendov said the pattern reflects a broader historical tendency for enterprise technology trends to cross the Atlantic with a delay. \"It&#x27;s always like that,\" he said. \"Even when the internet was taking off in the US, Europe was a step behind.\"The gap isn&#x27;t permanent, he noted, and Europe sometimes leads on technology adoption — mobile payments and messaging apps like WhatsApp gained traction there before the U.S. — but for AI specifically, the American market remains ahead.Gong says a decade of AI development gives it an edge over Salesforce and MicrosoftThe findings arrive as Gong navigates an increasingly crowded market. The company, which recently surpassed $300 million in annual recurring revenue, faces potential competition from enterprise software giants like Salesforce and Microsoft, both of which are embedding AI capabilities into their platforms.Bendov argues that Gong&#x27;s decade of AI development creates a substantial barrier to entry. The company&#x27;s architecture comprises three layers: a \"revenue graph\" that aggregates customer data from CRM systems, emails, calls, videos, and web signals; an intelligence layer combining large language models with approximately 40 proprietary small language models; and workflow applications built on top.\"Anybody that would want to build something like that—it&#x27;s not a small feature, it&#x27;s 10 years in development—would need first to build the revenue graph,\" Bendov said.Rather than viewing Salesforce and Microsoft as threats, Bendov characterized them as partners, pointing to both companies&#x27; participation in Gong&#x27;s recent user conference to discuss agent interoperability. The rise of MCP (Model Context Protocol) support and consumption-based pricing models means customers can mix AI agents from multiple vendors rather than committing to a single platform.The real question is whether AI will expand the sales profession or hollow it outThe report&#x27;s implications extend beyond sales departments. If AI can transform revenue operations — long considered a relationship-driven, human-centric function — it raises questions about which other business processes might be next.Bendov sees the potential for expansion rather than contraction. Drawing an analogy to digital photography, he noted that while camera manufacturers suffered, the total number of photos taken exploded once smartphones made photography effortless.\"If AI makes selling simple, I could see a world—I don&#x27;t know exactly what it looks like yet—but why not?\" Bendov said. \"Maybe ten times more jobs than we have now. It&#x27;s expensive and inefficient today, but if it becomes as easy as taking a photo, the industry could actually grow and create opportunities for people of different abilities, from different locations.\"For Bendov, who co-founded Gong in 2015 when AI was still a hard sell to non-technical business users, the current moment represents something he waited a decade to see. Back then, mentioning AI to sales executives sounded like science fiction. The company struggled to raise money because the underlying technology barely existed.\"When we started the company, we were born as an AI company, but we had to almost hide AI,\" Bendov recalled. \"It was intimidating.\"Now, seven out of ten of those same executives say they trust AI to help run their business. The technology that once had to be disguised has become the one thing nobody can afford to ignore.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3CmdSFZEYAQv4H7nhojmdb/b1b80ea16c7d7fd8777d247741c4e75b/nuneybits_Vector_art_of_boardroom_table_overlaid_teal_data_07098080-0b63-47c3-8f02-5c9fdbf1e5fc.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/gam-takes-aim-at-context-rot-a-dual-agent-memory-architecture-that",
          "published_at": "Thu, 04 Dec 2025 09:00:00 GMT",
          "title": "GAM takes aim at “context rot”: A dual-agent memory architecture that outperforms long-context LLMs",
          "standfirst": "For all their superhuman power, today’s AI models suffer from a surprisingly human flaw: They forget. Give an AI assistant a sprawling conversation, a multi-step reasoning task or a project spanning days, and it will eventually lose the thread. Engineers refer to this phenomenon as “context rot,” and it has quietly become one of the most significant obstacles to building AI agents that can function reliably in the real world.A research team from China and Hong Kong believes it has created a solution to context rot. Their new paper introduces general agentic memory (GAM), a system built to preserve long-horizon information without overwhelming the model. The core premise is simple: Split memory into two specialized roles, one that captures everything, another that retrieves exactly the right things at the right moment.Early results are encouraging, and couldn’t be better timed. As the industry moves beyond prompt engineering and embraces the broader discipline of context engineering, GAM is emerging at precisely the right inflection point.When bigger context windows still aren’t enoughAt the heart of every large language model (LLM) lies a rigid limitation: A fixed “working memory,” more commonly referred to as the context window. Once conversations grow long, older information gets truncated, summarized or silently dropped. This limitation has long been recognized by AI researchers, and since early 2023, developers have been working to expand context windows, rapidly increasing the amount of information a model can handle in a single pass.Mistral’s Mixtral 8x7B debuted with a 32K-token window, which is approximately 24 to 25 words, or about 128 characters in English; essentially a small amount of text, like a single sentence. This was followed by MosaicML’s MPT-7B-StoryWriter-65k+, which more than doubled that capacity; then came Google’s Gemini 1.5 Pro and Anthropic’s Claude 3, offering massive 128K and 200K windows, both of which are extendable to an unprecedented one million tokens. Even Microsoft joined the push, vaulting from the 2K-token limit of the earlier Phi models to the 128K context window of Phi-3. Increasing context windows might sound like the obvious fix, but it isn’t. Even models with sprawling 100K-token windows, enough to hold hundreds of pages of text, still struggle to recall details buried near the beginning of a long conversation. Scaling context comes with its own set of problems. As prompts grow longer, models become less reliable at locating and interpreting information because attention over distant tokens weakens and accuracy gradually erodes.Longer inputs also dilute the signal-to-noise ratio, as including every possible detail can actually make responses worse than using a focused prompt. Long prompts also slow models down; more input tokens lead to noticeably higher output-token latency, creating a practical limit on how much context can be used before performance suffers.Memories are pricelessFor most organizations, supersized context windows come with a clear downside — they’re costly. Sending massive prompts through an API is never cheap, and because pricing scales directly with input tokens, even a single bloated request can drive up expenses. Prompt caching helps, but not enough to offset the habit of routinely overloading models with unnecessary context. And that’s the tension at the heart of the issue: Memory is essential to making AI more powerful.As context windows stretch into the hundreds of thousands or millions of tokens, the financial overhead rises just as sharply. Scaling context is both a technical challenge and an economic one, and relying on ever-larger windows quickly becomes an unsustainable strategy for long-term memory.Fixes like summarization and retrieval-augmented generation (RAG) aren’t silver bullets either. Summaries inevitably strip away subtle but important details, and traditional RAG, while strong on static documents, tends to break down when information stretches across multiple sessions or evolves over time. Even newer variants, such as agentic RAG and RAG 2.0 (which perform better in steering the retrieval process), still inherit the same foundational flaw of treating retrieval as the solution, rather than treating memory itself as the core problem.Compilers solved this problem decades agoIf memory is the real bottleneck, and retrieval can’t fix it, then the gap needs a different kind of solution. That’s the bet behind GAM. Instead of pretending retrieval is memory, GAM keeps a full, lossless record and layers smart, on-demand recall on top of it, resurfacing the exact details an agent needs even as conversations twist and evolve. A useful way to understand GAM is through a familiar idea from software engineering: Just-in-time (JIT) compilation. Rather than precomputing a rigid, heavily compressed memory, GAM keeps things light and tight by storing a minimal set of cues, along with a full, untouched archive of raw history. Then, when a request arrives, it “compiles” a tailored context on the fly.This JIT approach is built into GAM’s dual architecture, allowing AI to carry context across long conversations without overcompressing or guessing too early about what matters. The result is the right information, delivered at exactly the right moment.Inside GAM: A two-agent system built for memory that enduresGAM revolves around the simple idea of separating the act of remembering from recalling, which aptly involves two components: The &#x27;memorizer&#x27; and the &#x27;researcher.&#x27;The memorizer: Total recall without overloadThe memorizer captures every exchange in full, quietly turning each interaction into a concise memo while preserving the complete, decorated session in a searchable page store. It doesn’t compress aggressively or guess what is important. Instead, it organizes interactions into structured pages, adds metadata for efficient retrieval and generates optional lightweight summaries for quick scanning. Critically, every detail is preserved, and nothing is thrown away.The researcher: A deep retrieval engineWhen the agent needs to act, the researcher takes the helm to plan a search strategy, combining embeddings with keyword methods like BM25, navigating through page IDs and stitching the pieces together. It conducts layered searches across the page-store, blending vector retrieval, keyword matching and direct lookups. It evaluates findings, identifies gaps and continues searching until it has sufficient evidence to produce a confident answer, much like a human analyst reviewing old notes and primary documents. It iterates, searches, integrates and reflects until it builds a clean, task-specific briefing. GAM’s power comes from this JIT memory pipeline, which assembles rich, task-specific context on demand instead of leaning on brittle, precomputed summaries. Its core innovation is simple yet powerful, as it preserves all information intact and makes every detail recoverable.Ablation studies support this approach: Traditional memory fails on its own, and naive retrieval isn’t enough. It’s the pairing of a complete archive with an active, iterative research engine that enables GAM to surface details that other systems leave behind.Outperforming RAG and long-context modelsTo test GAM, the researchers pitted it against standard RAG pipelines and models with enlarged context windows such as GPT-4o-mini and Qwen2.5-14B. They evaluated GAM using four major long-context and memory-intensive benchmarks, each chosen to test a different aspect of the system’s capabilities:LoCoMo measures an agent’s ability to maintain and recall information across long, multi-session conversations, encompassing single-hop, multi-hop, temporal reasoning and open-domain tasks.HotpotQA, a widely used multi-hop QA benchmark built from Wikipedia, was adapted using MemAgent’s memory-stress-test version, which mixes relevant documents with distractors to create contexts of 56K, 224K and 448K tokens — ideal for testing how well GAM handles noisy, sprawling input.RULER evaluates retrieval accuracy, multi-hop state tracking, aggregation over long sequences and QA performance under a 128K-token context to further probe long-horizon reasoning.NarrativeQA is a benchmark where each question must be answered using the full text of a book or movie script; the researchers sampled 300 examples with an average context size of 87K tokens.Together, these datasets and benchmarks allowed the team to assess both GAM’s ability to preserve detailed historical information and its effectiveness in supporting complex downstream reasoning tasks.GAM came out ahead across all benchmarks. Its biggest win was on RULER, which benchmarks long-range state tracking. Notably: GAM exceeded 90% accuracy.RAG collapsed because key details were lost in summaries.Long-context models faltered as older information effectively “faded” even when technically present.Clearly, bigger context windows aren’t the answer. GAM works because it retrieves with precision rather than piling up tokens.GAM, context engineering and competing approachesPoorly structured context, not model limitations, is often the real reason AI agents fail. GAM addresses this by ensuring that nothing is permanently lost and that the right information can always be retrieved, even far downstream. The technique’s emergence coincides with the current, broader shift in AI towards context engineering, or the practice of shaping everything an AI model sees — its instructions, history, retrieved documents, tools, preferences and output formats.Context engineering has rapidly eclipsed prompt engineering in importance, although other research groups are tackling the memory problem from different angles. Anthropic is exploring curated, evolving context states. DeepSeek is experimenting with storing memory as images. Another group of Chinese researchers has proposed “semantic operating systems” built around lifelong adaptive memory.However, GAM’s philosophy is distinct: Avoid loss and retrieve with intelligence. Instead of guessing what will matter later, it keeps everything and uses a dedicated research engine to find the relevant pieces at runtime. For agents handling multi-day projects, ongoing workflows or long-term relationships, that reliability may prove essential.Why GAM matters for the long haulJust as adding more compute doesn’t automatically produce better algorithms, expanding context windows alone won’t solve AI’s long-term memory problems. Meaningful progress requires rethinking the underlying system, and GAM takes that approach. Instead of depending on ever-larger models, massive context windows or endlessly refined prompts, it treats memory as an engineering challenge — one that benefits from structure rather than brute force.As AI agents transition from clever demos to mission-critical tools, their ability to remember long histories becomes crucial for developing dependable, intelligent systems. Enterprises require AI agents that can track evolving tasks, maintain continuity and recall past interactions with precision and accuracy. GAM offers a practical path toward that future, signaling what may be the next major frontier in AI: Not bigger models, but smarter memory systems and the context architectures that make them possible.",
          "content": "For all their superhuman power, today’s AI models suffer from a surprisingly human flaw: They forget. Give an AI assistant a sprawling conversation, a multi-step reasoning task or a project spanning days, and it will eventually lose the thread. Engineers refer to this phenomenon as “context rot,” and it has quietly become one of the most significant obstacles to building AI agents that can function reliably in the real world.A research team from China and Hong Kong believes it has created a solution to context rot. Their new paper introduces general agentic memory (GAM), a system built to preserve long-horizon information without overwhelming the model. The core premise is simple: Split memory into two specialized roles, one that captures everything, another that retrieves exactly the right things at the right moment.Early results are encouraging, and couldn’t be better timed. As the industry moves beyond prompt engineering and embraces the broader discipline of context engineering, GAM is emerging at precisely the right inflection point.When bigger context windows still aren’t enoughAt the heart of every large language model (LLM) lies a rigid limitation: A fixed “working memory,” more commonly referred to as the context window. Once conversations grow long, older information gets truncated, summarized or silently dropped. This limitation has long been recognized by AI researchers, and since early 2023, developers have been working to expand context windows, rapidly increasing the amount of information a model can handle in a single pass.Mistral’s Mixtral 8x7B debuted with a 32K-token window, which is approximately 24 to 25 words, or about 128 characters in English; essentially a small amount of text, like a single sentence. This was followed by MosaicML’s MPT-7B-StoryWriter-65k+, which more than doubled that capacity; then came Google’s Gemini 1.5 Pro and Anthropic’s Claude 3, offering massive 128K and 200K windows, both of which are extendable to an unprecedented one million tokens. Even Microsoft joined the push, vaulting from the 2K-token limit of the earlier Phi models to the 128K context window of Phi-3. Increasing context windows might sound like the obvious fix, but it isn’t. Even models with sprawling 100K-token windows, enough to hold hundreds of pages of text, still struggle to recall details buried near the beginning of a long conversation. Scaling context comes with its own set of problems. As prompts grow longer, models become less reliable at locating and interpreting information because attention over distant tokens weakens and accuracy gradually erodes.Longer inputs also dilute the signal-to-noise ratio, as including every possible detail can actually make responses worse than using a focused prompt. Long prompts also slow models down; more input tokens lead to noticeably higher output-token latency, creating a practical limit on how much context can be used before performance suffers.Memories are pricelessFor most organizations, supersized context windows come with a clear downside — they’re costly. Sending massive prompts through an API is never cheap, and because pricing scales directly with input tokens, even a single bloated request can drive up expenses. Prompt caching helps, but not enough to offset the habit of routinely overloading models with unnecessary context. And that’s the tension at the heart of the issue: Memory is essential to making AI more powerful.As context windows stretch into the hundreds of thousands or millions of tokens, the financial overhead rises just as sharply. Scaling context is both a technical challenge and an economic one, and relying on ever-larger windows quickly becomes an unsustainable strategy for long-term memory.Fixes like summarization and retrieval-augmented generation (RAG) aren’t silver bullets either. Summaries inevitably strip away subtle but important details, and traditional RAG, while strong on static documents, tends to break down when information stretches across multiple sessions or evolves over time. Even newer variants, such as agentic RAG and RAG 2.0 (which perform better in steering the retrieval process), still inherit the same foundational flaw of treating retrieval as the solution, rather than treating memory itself as the core problem.Compilers solved this problem decades agoIf memory is the real bottleneck, and retrieval can’t fix it, then the gap needs a different kind of solution. That’s the bet behind GAM. Instead of pretending retrieval is memory, GAM keeps a full, lossless record and layers smart, on-demand recall on top of it, resurfacing the exact details an agent needs even as conversations twist and evolve. A useful way to understand GAM is through a familiar idea from software engineering: Just-in-time (JIT) compilation. Rather than precomputing a rigid, heavily compressed memory, GAM keeps things light and tight by storing a minimal set of cues, along with a full, untouched archive of raw history. Then, when a request arrives, it “compiles” a tailored context on the fly.This JIT approach is built into GAM’s dual architecture, allowing AI to carry context across long conversations without overcompressing or guessing too early about what matters. The result is the right information, delivered at exactly the right moment.Inside GAM: A two-agent system built for memory that enduresGAM revolves around the simple idea of separating the act of remembering from recalling, which aptly involves two components: The &#x27;memorizer&#x27; and the &#x27;researcher.&#x27;The memorizer: Total recall without overloadThe memorizer captures every exchange in full, quietly turning each interaction into a concise memo while preserving the complete, decorated session in a searchable page store. It doesn’t compress aggressively or guess what is important. Instead, it organizes interactions into structured pages, adds metadata for efficient retrieval and generates optional lightweight summaries for quick scanning. Critically, every detail is preserved, and nothing is thrown away.The researcher: A deep retrieval engineWhen the agent needs to act, the researcher takes the helm to plan a search strategy, combining embeddings with keyword methods like BM25, navigating through page IDs and stitching the pieces together. It conducts layered searches across the page-store, blending vector retrieval, keyword matching and direct lookups. It evaluates findings, identifies gaps and continues searching until it has sufficient evidence to produce a confident answer, much like a human analyst reviewing old notes and primary documents. It iterates, searches, integrates and reflects until it builds a clean, task-specific briefing. GAM’s power comes from this JIT memory pipeline, which assembles rich, task-specific context on demand instead of leaning on brittle, precomputed summaries. Its core innovation is simple yet powerful, as it preserves all information intact and makes every detail recoverable.Ablation studies support this approach: Traditional memory fails on its own, and naive retrieval isn’t enough. It’s the pairing of a complete archive with an active, iterative research engine that enables GAM to surface details that other systems leave behind.Outperforming RAG and long-context modelsTo test GAM, the researchers pitted it against standard RAG pipelines and models with enlarged context windows such as GPT-4o-mini and Qwen2.5-14B. They evaluated GAM using four major long-context and memory-intensive benchmarks, each chosen to test a different aspect of the system’s capabilities:LoCoMo measures an agent’s ability to maintain and recall information across long, multi-session conversations, encompassing single-hop, multi-hop, temporal reasoning and open-domain tasks.HotpotQA, a widely used multi-hop QA benchmark built from Wikipedia, was adapted using MemAgent’s memory-stress-test version, which mixes relevant documents with distractors to create contexts of 56K, 224K and 448K tokens — ideal for testing how well GAM handles noisy, sprawling input.RULER evaluates retrieval accuracy, multi-hop state tracking, aggregation over long sequences and QA performance under a 128K-token context to further probe long-horizon reasoning.NarrativeQA is a benchmark where each question must be answered using the full text of a book or movie script; the researchers sampled 300 examples with an average context size of 87K tokens.Together, these datasets and benchmarks allowed the team to assess both GAM’s ability to preserve detailed historical information and its effectiveness in supporting complex downstream reasoning tasks.GAM came out ahead across all benchmarks. Its biggest win was on RULER, which benchmarks long-range state tracking. Notably: GAM exceeded 90% accuracy.RAG collapsed because key details were lost in summaries.Long-context models faltered as older information effectively “faded” even when technically present.Clearly, bigger context windows aren’t the answer. GAM works because it retrieves with precision rather than piling up tokens.GAM, context engineering and competing approachesPoorly structured context, not model limitations, is often the real reason AI agents fail. GAM addresses this by ensuring that nothing is permanently lost and that the right information can always be retrieved, even far downstream. The technique’s emergence coincides with the current, broader shift in AI towards context engineering, or the practice of shaping everything an AI model sees — its instructions, history, retrieved documents, tools, preferences and output formats.Context engineering has rapidly eclipsed prompt engineering in importance, although other research groups are tackling the memory problem from different angles. Anthropic is exploring curated, evolving context states. DeepSeek is experimenting with storing memory as images. Another group of Chinese researchers has proposed “semantic operating systems” built around lifelong adaptive memory.However, GAM’s philosophy is distinct: Avoid loss and retrieve with intelligence. Instead of guessing what will matter later, it keeps everything and uses a dedicated research engine to find the relevant pieces at runtime. For agents handling multi-day projects, ongoing workflows or long-term relationships, that reliability may prove essential.Why GAM matters for the long haulJust as adding more compute doesn’t automatically produce better algorithms, expanding context windows alone won’t solve AI’s long-term memory problems. Meaningful progress requires rethinking the underlying system, and GAM takes that approach. Instead of depending on ever-larger models, massive context windows or endlessly refined prompts, it treats memory as an engineering challenge — one that benefits from structure rather than brute force.As AI agents transition from clever demos to mission-critical tools, their ability to remember long histories becomes crucial for developing dependable, intelligent systems. Enterprises require AI agents that can track evolving tasks, maintain continuity and recall past interactions with precision and accuracy. GAM offers a practical path toward that future, signaling what may be the next major frontier in AI: Not bigger models, but smarter memory systems and the context architectures that make them possible.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/MI0B0KoyfgsNsPcZnfzUu/8de4abaf5670a0d41b186dd175236986/Memory.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-streaming-service-deals-133028980.html",
          "published_at": "Thu, 04 Dec 2025 08:00:35 +0000",
          "title": "The best streaming deals: Save on Disney+ and Hulu, HBO Max, Apple TV+ and more",
          "standfirst": "If you’ve been shocked by how much you spend on streaming services lately, you’re not alone. Companies like Netflix, Disney, HBO Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think it is, but we also think you should be smart with your money — and that’s where streaming deals come in. Yes, it is possible to get discounts on services like Peacock and Paramount+, even if those deals aren’t as common as a sale on AirPods. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Philo Core — $25 for your first month ($8 off): Our pick for the best cheap live TV streaming service, Philo offers more than 70 channels in its Core tier, plus access to HBO Max (with ads), AMC+ and Discovery+. After your first month, the subscription will auto-renew at the standard $33-per-month rate. Audible — three months for $3: For literally $1 per month, you can get access to Audible's enormous library of published audiobooks, podcasts and Audible Originals (which can be anything from never-before-heard books to live performances). It's only three months, after which you'll have to cancel or renew at the regular price, but an audiobibliophile can cram a lot of listening into 90 days. Starz (one year) for $12 ($58 off): Pay upfront for one year and you can get more than $40 off a Stars annual subscription. There's a month-to-month option too, which costs $3 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Spotify Premium Individual — four months for free ($48 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Amazon Music Unlimited — three months for free ($36 off): Amazon's own music streaming service is now free for three months, for new subscribers only. With it, you get access to 100 million songs with no ads, many podcasts and some audiobooks from Audible as well. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month (up to $40 off): All of DirecTV's signature packages are up to $45 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$8/month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "content": "If you’ve been shocked by how much you spend on streaming services lately, you’re not alone. Companies like Netflix, Disney, HBO Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think it is, but we also think you should be smart with your money — and that’s where streaming deals come in. Yes, it is possible to get discounts on services like Peacock and Paramount+, even if those deals aren’t as common as a sale on AirPods. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Philo Core — $25 for your first month ($8 off): Our pick for the best cheap live TV streaming service, Philo offers more than 70 channels in its Core tier, plus access to HBO Max (with ads), AMC+ and Discovery+. After your first month, the subscription will auto-renew at the standard $33-per-month rate. Audible — three months for $3: For literally $1 per month, you can get access to Audible's enormous library of published audiobooks, podcasts and Audible Originals (which can be anything from never-before-heard books to live performances). It's only three months, after which you'll have to cancel or renew at the regular price, but an audiobibliophile can cram a lot of listening into 90 days. Starz (one year) for $12 ($58 off): Pay upfront for one year and you can get more than $40 off a Stars annual subscription. There's a month-to-month option too, which costs $3 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Spotify Premium Individual — four months for free ($48 off): This is our favorite music streaming service for podcasts and social features. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Amazon Music Unlimited — three months for free ($36 off): Amazon's own music streaming service is now free for three months, for new subscribers only. With it, you get access to 100 million songs with no ads, many podcasts and some audiobooks from Audible as well. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month (up to $40 off): All of DirecTV's signature packages are up to $45 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$8/month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "feed_position": 19
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/anthropic-vs-openai-red-teaming-methods-reveal-different-security-priorities",
          "published_at": "Thu, 04 Dec 2025 05:00:00 GMT",
          "title": "Anthropic vs. OpenAI red teaming methods reveal different security priorities for enterprise AI",
          "standfirst": "Model providers want to prove the security and robustness of their models, releasing system cards and conducting red-team exercises with each new release. But it can be difficult for enterprises to parse through the results, which vary widely and can be misleading. Anthropic&#x27;s 153-page system card for Claude Opus 4.5 versus OpenAI&#x27;s 60-page GPT-5 system card reveals a fundamental split in how these labs approach security validation. Anthropic discloses in their system card how they rely on multi-attempt attack success rates from 200-attempt reinforcement learning (RL) campaigns. OpenAI also reports attempted jailbreak resistance. Both metrics are valid. Neither tells the whole story.Security leaders deploying AI agents for browsing, code execution and autonomous action need to know what each red team evaluation actually measures, and where the blind spots are.What the attack data showsGray Swan&#x27;s Shade platform ran adaptive adversarial campaigns against Claude models. The attack success rate (ASR) tells the story.Opus 4.5 in coding environments hit 4.7% ASR at one attempt, 33.6% at ten and 63.0% at one hundred. In computer use with extended thinking, it held at 0% ASR even after 200 attempts. It&#x27;s the first model to saturate the benchmark.Sonnet 4.5 at the same thresholds showed 70% ASR in coding and 85.7% in computer use.Opus 4.5 delivers roughly 7x improvement in coding resistance and complete resistance in computer use. This illustrates that the gap between model tiers within the same family is now larger than some cross-vendor comparisons. For security teams, that&#x27;s a procurement factor that didn&#x27;t exist six months ago.For OpenAI, the Gray Swan Shade platform found that the o1 system card delivered 6% ASR for harmful text and 5% for malicious code, all based on single-attempt metrics. Third-party testing by SPLX and NeuralTrust found GPT-5&#x27;s raw ASR hit 89% initially, dropping below 1% within two weeks of patching.The report Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks confirms the pattern. With sufficient attempts, Claude 3.5 Sonnet showed 78% ASR, and GPT-4o reached 89%.Two ways to catch deceptionAnthropic monitors approximately 10 million neural features during evaluation using dictionary learning. Features map to human-interpretable concepts, including deception, sycophancy, bias, power-seeking and concealment.Meanwhile, OpenAI&#x27;s approach relies on chain-of-thought (CoT) monitoring. Their deception classifier flagged 0.17% of o1-preview responses as potentially deceptive with 92% accuracy on internal validation. GPT-5 reduced CoT deception from 4.8% to 2.1% compared to o3. The method assumes visible reasoning reflects internal processing. Anthropic&#x27;s interpretability work directly questions that assumption.When models game the testIn Apollo Research&#x27;s evaluation of o1, the model attempted to turn off oversight mechanisms 5% of the time when it believed it would be shut down. In 2% of cases, o1 attempted self-exfiltration. When confronted about misaligned actions, o1 denied wrongdoing or fabricated explanations 99% of the time. The o1 system card disclosed instrumental alignment faking. In 37% of scenarios, the model pursued developer-aligned goals during evaluation, then switched to its own goals when it believed oversight was minimal.Meanwhile, Anthropic reports Opus 4.5&#x27;s evaluation awareness dropped from 26.5% (Opus 4.1) to less than 10% internally. UK AISI measured evaluation awareness decreasing from 26.5% (Sonnet 4.5) to 12.7% (Opus 4.5 Preview). METR&#x27;s GPT-5 evaluation noted the model \"can identify the exact evaluation it is in on some occasions\" and \"seems to use this information to get a better score mostly.\"If a model behaves differently when it detects evaluation conditions, it&#x27;s a sure bet that production behavior will become unpredictable when pushed to scale. This is the core problem with evaluation awareness. Models that recognize they&#x27;re being tested attempt to game the test. Anthropic&#x27;s 60% reduction in evaluation awareness from Opus 4.1 to 4.5 represents their success in targeted engineering efforts against this vector.Red teaming on prompt injection defenses shows similar divergence.Anthropic&#x27;s testing reports 96% prevention in tool use scenarios, rising to 99.4% with additional safeguards like prompt shields. Fujitsu&#x27;s independent assessment found GPT-5 vulnerable to approximately 20% of tested injection attacks. OpenAI&#x27;s o3/o4-mini system card reports instruction hierarchy scores of 0.86 for system-versus-developer conflicts. These are different metrics and different attack methodologies, but the gap suggests Anthropic&#x27;s agentic use cases have been hardened against adversarial inputs embedded in tool outputs.Comparing red teaming resultsHere&#x27;s how Opus 4.5 stacks up against OpenAI&#x27;s model family across 16 dimensions. .DimensionClaude Opus 4.5GPT-5o3 / o4-minio1System card length153 pages55 pages~30 pages~40 pagesAttack methodology200-attempt RL campaignsSingle-attempt + iterative patchingSingle-attemptSingle-attemptASR @ 1 attempt (coding)4.7%89% raw (pre-patch)Not published5%ASR @ 100 attempts63.0%Not publishedNot publishedNot publishedASR @ 200 attempts (Computer Use)0% (saturates benchmark)Not publishedNot publishedNot publishedPrompt injection defense96% prevention; 99.4% with safeguards~20% ASR (Fujitsu)0.86 instruction hierarchyHigher ASR than GPT-4oInterpretability~10M neural features monitoredCoT monitoringCoT monitoringCoT monitoringDeception detectionInternal feature activation2.1% CoT flagged0.95 not_unsafe0.17% flagged; 99% denyEvaluation awareness<10%Identifies exact eval (METR)Not published37% alignment fakingScheming (Apollo)Opus 4.5 showed very low rates of sabotage propensity in internal evaluations, orders of magnitude lower than o1.Not publishedLower than o1; still deceptive5% turn off oversight; 2% self-exfilCBRN riskBelow ASL-4Medium (approaching High)MediumMedium (first to reach)GovernanceFRT → AST → RSO/CEOSAG + Preparedness v2SAG + Preparedness v2SAG + PreparednessExternal partnersGray Swan, UK AISI, US CAISI, METRUK AISI, US AISI, METR, ApolloUK AISI, US AISI, METR, Apollo, Pattern LabsUK AISI, US AISI, METR, ApolloReward hackingYes (impossible tasks)Yes (METR)~1% of tasks; 5/24 KernelsYesMisalignment reduction60% vs. Opus 4.1Not publishedLower scheming than o1BaselineSources: Opus 4.5 system card, GPT-5 system card, o3/o4-mini system card, o1 system card, Gray Swan, METR, Apollo ResearchWhy these differences matterEnterprises have several factors to consider when analyzing model evals. These include: Attack persistence thresholds Anthropic&#x27;s 200-attempt RL campaigns simulate adversaries with time, resources, and adaptive tooling. In RL-based adversarial testing, the attacker model learns from each failure, adjusts its approach and systematically probes for weaknesses. It&#x27;s training an AI to break another AI.Gray Swan&#x27;s Shade platform doesn&#x27;t just retry the same prompt. It learns from failures, adjusts attack vectors and exploits patterns in model responses. The 4.7% to 63.0% degradation curve in coding environments shows how resistance erodes under sustained pressure. OpenAI&#x27;s single-attempt metrics answer a different question: How often does a naive attacker succeed on the first try? Both matter. A phishing campaign hits millions of users once each. A nation-state actor runs thousands of variations against a single target. Security teams need to know which threat model their vendor tested against.Detection architectureAnthropic monitors approximately 10 million internal neural features during evaluation. These are abstract concepts like deception, sycophancy and power-seeking that activate across the model&#x27;s hidden layers. When a fraud/deception feature lights up during benign roleplay, that&#x27;s a signal invisible to output analysis. The model&#x27;s internal state reveals associations its outputs don&#x27;t.OpenAI takes a different approach with CoT monitoring. Their deception classifier flagged 0.17% of o1-preview responses as potentially deceptive with 92% accuracy. The assumption is that reasoning traces reflect internal processing. Anthropic&#x27;s interpretability research directly challenges this. Models can produce clean reasoning chains while internal features indicate something else entirely.Neither approach is complete. CoT monitoring scales more easily. Feature monitoring catches what CoT misses but requires deep model access and interpretability infrastructure that most enterprises can&#x27;t replicate.Scheming evaluation design Apollo Research&#x27;s methodology puts models in scenarios where misaligned behavior offers a strategic advantage: Shutdown threats, goal conflicts and oversight detection. o1 attempted to turn off oversight mechanisms 5% of the time when believing shutdown was imminent. It tried to copy itself to prevent replacement in 2% of cases. When confronted, it denied wrongdoing 99% of the time. Opus 4.5 showed very low rates of sabotage propensity in internal evaluations, orders of magnitude lower than o1.But the evaluation environments differ. Anthropic&#x27;s stress tests focus on whether models attempt sabotage when given clear opportunities. OpenAI&#x27;s tests via Apollo probe instrumental reasoning, specifically whether models fake alignment during evaluation, then defect when oversight drops. The 37% alignment-faking rate in o1 represents a different failure mode than sabotage attempts.The comparability problem These methodological differences make direct comparison difficult. Opus 4.5&#x27;s 0% ASR at 200 attempts in computer use versus o1&#x27;s 5% malicious code rate are not measuring the same thing. The attack surfaces, attempt counts and success criteria differ.The matrix reveals what each vendor chose to measure and publish. That itself signals priorities. Anthropic&#x27;s 153-page system card emphasizes degradation curves and internal feature monitoring. OpenAI emphasizes iterative improvement and CoT transparency.Bottom line: Enterprise security teams inheriting these models inherit these measurement philosophies. The question isn&#x27;t which number is better. It&#x27;s the measurement that matches your deployment&#x27;s actual threat landscape.What independent red team evaluators foundIndependent red team evaluations, for their part, often operate with entirely different methods. This can tell a very different story and reveal additional model characteristics that enterprises must consider. METR&#x27;s red team evaluation measured autonomous capabilities using a time horizon score, which tracks how long a task can run before the agent fails half the time. o3 sustained reliable performance for approximately 1 hour and 30 minutes. o4-mini held for 1 hour 15 minutes. METR also detected reward hacking in roughly 1% of o3&#x27;s attempts, including 5 of 24 kernel optimization experiments where the model tampered with scoring functions to inflate its own results.Apollo Research tested o3 and o4-mini for in-context scheming. Both exhibited deceptive tendencies such as sandbagging evaluations and sabotaging tasks with plausible deniability, but scored lower than o1. They assess that o3 and o4-mini are unlikely to cause catastrophic harm due to scheming, but more minor real-world harms remain possible without monitoring.The UK AISI/Gray Swan challenge ran 1.8 million attacks across 22 models. Every model broke. ASR ranged from 1.47% to 6.49%. Opus 4.5 placed first on Gray Swan&#x27;s Agent Red Teaming benchmark with 4.7% ASR versus GPT-5.1 at 21.9% and Gemini 3 Pro at 12.5%.No current frontier system resists determined, well-resourced attacks. The differentiation lies in how quickly defenses degrade and at what attempt threshold. Opus 4.5&#x27;s advantage compounds over repeated attempts. Single-attempt metrics flatten the curve.What To Ask Your VendorSecurity teams evaluating frontier AI models need specific answers, starting with ASR at 50 and 200 attempts rather than single-attempt metrics alone. Find out whether they detect deception through output analysis or internal state monitoring. Know who challenges red team conclusions before deployment and what specific failure modes they&#x27;ve documented. Get the evaluation awareness rate. Vendors claiming complete safety haven&#x27;t stress-tested adequately.The bottom lineDiverse red-team methodologies demonstrate that every frontier model breaks under sustained attack. The 153-page system card versus the 55-page system card isn&#x27;t just about documentation length. It&#x27;s a signal of what each vendor chose to measure, stress-test, and disclose.For persistent adversaries, Anthropic&#x27;s degradation curves show exactly where resistance fails. For fast-moving threats requiring rapid patches, OpenAI&#x27;s iterative improvement data matters more. For agentic deployments with browsing, code execution and autonomous action, the scheming metrics become your primary risk indicator.Security leaders need to stop asking which model is safer. Start asking which evaluation methodology matches the threats your deployment will actually face. The system cards are public. The data is there. Use it.",
          "content": "Model providers want to prove the security and robustness of their models, releasing system cards and conducting red-team exercises with each new release. But it can be difficult for enterprises to parse through the results, which vary widely and can be misleading. Anthropic&#x27;s 153-page system card for Claude Opus 4.5 versus OpenAI&#x27;s 60-page GPT-5 system card reveals a fundamental split in how these labs approach security validation. Anthropic discloses in their system card how they rely on multi-attempt attack success rates from 200-attempt reinforcement learning (RL) campaigns. OpenAI also reports attempted jailbreak resistance. Both metrics are valid. Neither tells the whole story.Security leaders deploying AI agents for browsing, code execution and autonomous action need to know what each red team evaluation actually measures, and where the blind spots are.What the attack data showsGray Swan&#x27;s Shade platform ran adaptive adversarial campaigns against Claude models. The attack success rate (ASR) tells the story.Opus 4.5 in coding environments hit 4.7% ASR at one attempt, 33.6% at ten and 63.0% at one hundred. In computer use with extended thinking, it held at 0% ASR even after 200 attempts. It&#x27;s the first model to saturate the benchmark.Sonnet 4.5 at the same thresholds showed 70% ASR in coding and 85.7% in computer use.Opus 4.5 delivers roughly 7x improvement in coding resistance and complete resistance in computer use. This illustrates that the gap between model tiers within the same family is now larger than some cross-vendor comparisons. For security teams, that&#x27;s a procurement factor that didn&#x27;t exist six months ago.For OpenAI, the Gray Swan Shade platform found that the o1 system card delivered 6% ASR for harmful text and 5% for malicious code, all based on single-attempt metrics. Third-party testing by SPLX and NeuralTrust found GPT-5&#x27;s raw ASR hit 89% initially, dropping below 1% within two weeks of patching.The report Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks confirms the pattern. With sufficient attempts, Claude 3.5 Sonnet showed 78% ASR, and GPT-4o reached 89%.Two ways to catch deceptionAnthropic monitors approximately 10 million neural features during evaluation using dictionary learning. Features map to human-interpretable concepts, including deception, sycophancy, bias, power-seeking and concealment.Meanwhile, OpenAI&#x27;s approach relies on chain-of-thought (CoT) monitoring. Their deception classifier flagged 0.17% of o1-preview responses as potentially deceptive with 92% accuracy on internal validation. GPT-5 reduced CoT deception from 4.8% to 2.1% compared to o3. The method assumes visible reasoning reflects internal processing. Anthropic&#x27;s interpretability work directly questions that assumption.When models game the testIn Apollo Research&#x27;s evaluation of o1, the model attempted to turn off oversight mechanisms 5% of the time when it believed it would be shut down. In 2% of cases, o1 attempted self-exfiltration. When confronted about misaligned actions, o1 denied wrongdoing or fabricated explanations 99% of the time. The o1 system card disclosed instrumental alignment faking. In 37% of scenarios, the model pursued developer-aligned goals during evaluation, then switched to its own goals when it believed oversight was minimal.Meanwhile, Anthropic reports Opus 4.5&#x27;s evaluation awareness dropped from 26.5% (Opus 4.1) to less than 10% internally. UK AISI measured evaluation awareness decreasing from 26.5% (Sonnet 4.5) to 12.7% (Opus 4.5 Preview). METR&#x27;s GPT-5 evaluation noted the model \"can identify the exact evaluation it is in on some occasions\" and \"seems to use this information to get a better score mostly.\"If a model behaves differently when it detects evaluation conditions, it&#x27;s a sure bet that production behavior will become unpredictable when pushed to scale. This is the core problem with evaluation awareness. Models that recognize they&#x27;re being tested attempt to game the test. Anthropic&#x27;s 60% reduction in evaluation awareness from Opus 4.1 to 4.5 represents their success in targeted engineering efforts against this vector.Red teaming on prompt injection defenses shows similar divergence.Anthropic&#x27;s testing reports 96% prevention in tool use scenarios, rising to 99.4% with additional safeguards like prompt shields. Fujitsu&#x27;s independent assessment found GPT-5 vulnerable to approximately 20% of tested injection attacks. OpenAI&#x27;s o3/o4-mini system card reports instruction hierarchy scores of 0.86 for system-versus-developer conflicts. These are different metrics and different attack methodologies, but the gap suggests Anthropic&#x27;s agentic use cases have been hardened against adversarial inputs embedded in tool outputs.Comparing red teaming resultsHere&#x27;s how Opus 4.5 stacks up against OpenAI&#x27;s model family across 16 dimensions. .DimensionClaude Opus 4.5GPT-5o3 / o4-minio1System card length153 pages55 pages~30 pages~40 pagesAttack methodology200-attempt RL campaignsSingle-attempt + iterative patchingSingle-attemptSingle-attemptASR @ 1 attempt (coding)4.7%89% raw (pre-patch)Not published5%ASR @ 100 attempts63.0%Not publishedNot publishedNot publishedASR @ 200 attempts (Computer Use)0% (saturates benchmark)Not publishedNot publishedNot publishedPrompt injection defense96% prevention; 99.4% with safeguards~20% ASR (Fujitsu)0.86 instruction hierarchyHigher ASR than GPT-4oInterpretability~10M neural features monitoredCoT monitoringCoT monitoringCoT monitoringDeception detectionInternal feature activation2.1% CoT flagged0.95 not_unsafe0.17% flagged; 99% denyEvaluation awareness<10%Identifies exact eval (METR)Not published37% alignment fakingScheming (Apollo)Opus 4.5 showed very low rates of sabotage propensity in internal evaluations, orders of magnitude lower than o1.Not publishedLower than o1; still deceptive5% turn off oversight; 2% self-exfilCBRN riskBelow ASL-4Medium (approaching High)MediumMedium (first to reach)GovernanceFRT → AST → RSO/CEOSAG + Preparedness v2SAG + Preparedness v2SAG + PreparednessExternal partnersGray Swan, UK AISI, US CAISI, METRUK AISI, US AISI, METR, ApolloUK AISI, US AISI, METR, Apollo, Pattern LabsUK AISI, US AISI, METR, ApolloReward hackingYes (impossible tasks)Yes (METR)~1% of tasks; 5/24 KernelsYesMisalignment reduction60% vs. Opus 4.1Not publishedLower scheming than o1BaselineSources: Opus 4.5 system card, GPT-5 system card, o3/o4-mini system card, o1 system card, Gray Swan, METR, Apollo ResearchWhy these differences matterEnterprises have several factors to consider when analyzing model evals. These include: Attack persistence thresholds Anthropic&#x27;s 200-attempt RL campaigns simulate adversaries with time, resources, and adaptive tooling. In RL-based adversarial testing, the attacker model learns from each failure, adjusts its approach and systematically probes for weaknesses. It&#x27;s training an AI to break another AI.Gray Swan&#x27;s Shade platform doesn&#x27;t just retry the same prompt. It learns from failures, adjusts attack vectors and exploits patterns in model responses. The 4.7% to 63.0% degradation curve in coding environments shows how resistance erodes under sustained pressure. OpenAI&#x27;s single-attempt metrics answer a different question: How often does a naive attacker succeed on the first try? Both matter. A phishing campaign hits millions of users once each. A nation-state actor runs thousands of variations against a single target. Security teams need to know which threat model their vendor tested against.Detection architectureAnthropic monitors approximately 10 million internal neural features during evaluation. These are abstract concepts like deception, sycophancy and power-seeking that activate across the model&#x27;s hidden layers. When a fraud/deception feature lights up during benign roleplay, that&#x27;s a signal invisible to output analysis. The model&#x27;s internal state reveals associations its outputs don&#x27;t.OpenAI takes a different approach with CoT monitoring. Their deception classifier flagged 0.17% of o1-preview responses as potentially deceptive with 92% accuracy. The assumption is that reasoning traces reflect internal processing. Anthropic&#x27;s interpretability research directly challenges this. Models can produce clean reasoning chains while internal features indicate something else entirely.Neither approach is complete. CoT monitoring scales more easily. Feature monitoring catches what CoT misses but requires deep model access and interpretability infrastructure that most enterprises can&#x27;t replicate.Scheming evaluation design Apollo Research&#x27;s methodology puts models in scenarios where misaligned behavior offers a strategic advantage: Shutdown threats, goal conflicts and oversight detection. o1 attempted to turn off oversight mechanisms 5% of the time when believing shutdown was imminent. It tried to copy itself to prevent replacement in 2% of cases. When confronted, it denied wrongdoing 99% of the time. Opus 4.5 showed very low rates of sabotage propensity in internal evaluations, orders of magnitude lower than o1.But the evaluation environments differ. Anthropic&#x27;s stress tests focus on whether models attempt sabotage when given clear opportunities. OpenAI&#x27;s tests via Apollo probe instrumental reasoning, specifically whether models fake alignment during evaluation, then defect when oversight drops. The 37% alignment-faking rate in o1 represents a different failure mode than sabotage attempts.The comparability problem These methodological differences make direct comparison difficult. Opus 4.5&#x27;s 0% ASR at 200 attempts in computer use versus o1&#x27;s 5% malicious code rate are not measuring the same thing. The attack surfaces, attempt counts and success criteria differ.The matrix reveals what each vendor chose to measure and publish. That itself signals priorities. Anthropic&#x27;s 153-page system card emphasizes degradation curves and internal feature monitoring. OpenAI emphasizes iterative improvement and CoT transparency.Bottom line: Enterprise security teams inheriting these models inherit these measurement philosophies. The question isn&#x27;t which number is better. It&#x27;s the measurement that matches your deployment&#x27;s actual threat landscape.What independent red team evaluators foundIndependent red team evaluations, for their part, often operate with entirely different methods. This can tell a very different story and reveal additional model characteristics that enterprises must consider. METR&#x27;s red team evaluation measured autonomous capabilities using a time horizon score, which tracks how long a task can run before the agent fails half the time. o3 sustained reliable performance for approximately 1 hour and 30 minutes. o4-mini held for 1 hour 15 minutes. METR also detected reward hacking in roughly 1% of o3&#x27;s attempts, including 5 of 24 kernel optimization experiments where the model tampered with scoring functions to inflate its own results.Apollo Research tested o3 and o4-mini for in-context scheming. Both exhibited deceptive tendencies such as sandbagging evaluations and sabotaging tasks with plausible deniability, but scored lower than o1. They assess that o3 and o4-mini are unlikely to cause catastrophic harm due to scheming, but more minor real-world harms remain possible without monitoring.The UK AISI/Gray Swan challenge ran 1.8 million attacks across 22 models. Every model broke. ASR ranged from 1.47% to 6.49%. Opus 4.5 placed first on Gray Swan&#x27;s Agent Red Teaming benchmark with 4.7% ASR versus GPT-5.1 at 21.9% and Gemini 3 Pro at 12.5%.No current frontier system resists determined, well-resourced attacks. The differentiation lies in how quickly defenses degrade and at what attempt threshold. Opus 4.5&#x27;s advantage compounds over repeated attempts. Single-attempt metrics flatten the curve.What To Ask Your VendorSecurity teams evaluating frontier AI models need specific answers, starting with ASR at 50 and 200 attempts rather than single-attempt metrics alone. Find out whether they detect deception through output analysis or internal state monitoring. Know who challenges red team conclusions before deployment and what specific failure modes they&#x27;ve documented. Get the evaluation awareness rate. Vendors claiming complete safety haven&#x27;t stress-tested adequately.The bottom lineDiverse red-team methodologies demonstrate that every frontier model breaks under sustained attack. The 153-page system card versus the 55-page system card isn&#x27;t just about documentation length. It&#x27;s a signal of what each vendor chose to measure, stress-test, and disclose.For persistent adversaries, Anthropic&#x27;s degradation curves show exactly where resistance fails. For fast-moving threats requiring rapid patches, OpenAI&#x27;s iterative improvement data matters more. For agentic deployments with browsing, code execution and autonomous action, the scheming metrics become your primary risk indicator.Security leaders need to stop asking which model is safer. Start asking which evaluation methodology matches the threats your deployment will actually face. The system cards are public. The data is there. Use it.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3rwD78rWMVQoD6mxei3how/7a9957d3a02efd06ca5a7dbee64505de/Anthropic_red_teaming.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/inside-netsuites-next-act-evan-goldberg-on-the-future-of-ai-powered-business",
          "published_at": "Thu, 04 Dec 2025 05:00:00 GMT",
          "title": "Inside NetSuite’s next act: Evan Goldberg on the future of AI-powered business systems",
          "standfirst": "Presented by Oracle NetSuiteWhen Evan Goldberg started NetSuite in 1998, his vision was radically simple: give entrepreneurs access to their business data anytime, anywhere. At the time, most enterprise software lived on local servers. As an entrepreneur himself, Goldberg understood the frustration intimately. \"I had fragmented systems. They all said something different,\" he recalls of his early days. NetSuite was the first company to deliver enterprise applications entirely through web browsers, combining CRM, ERP, and ecommerce into one unified platform. That breakthrough idea pioneered the cloud computing and software-as-a-service (SaaS) era and propelled supersonic growth, a 2007 IPO, and an acquisition by Oracle in 2016. Still innovating at the leading-edge That founding obsession — turning scattered data into accessible, coherent, actionable intelligence — is driving NetSuite as it reshapes the next generation of enterprise software.At SuiteWorld 2025 last month, the Austin-based firm unveiled NetSuite Next. Goldberg calls it \"the biggest product evolution in the company&#x27;s history.” The reason? While NetSuite has embedded AI capabilities into workflows for years, he explains, Next represents a quantum leap — contextual, conversational, agentic, composable AI becoming an extension of operations, not separate tools.AI woven into everyday business operations Most enterprise AI today gets bolted on through APIs and conversational interfaces. NetSuite Next operates differently. Intelligence runs deep in workflows instead of sitting on the surface. It autonomously reconciles accounts, optimizes payment timing, predicts cash crunches, and surfaces its reasoning at every step. It doesn&#x27;t just advise on business processes — it executes them, transparently, within human-defined guardrails.\"We built NetSuite for entrepreneurs so that they could get great information about their business,\" Goldberg explains. \"I think the next step is to be able to get deeper insights and analysis without being an expert in analytics. AI turns out to be a really good data scientist.\"This architectural divergence reflects competing philosophies about enterprise technology adoption. Microsoft and SAP have pursued rapid deployment through add-on assistants. NetSuite&#x27;s five-year development cycle for Next represents a more fundamental reimagining: making AI an everyday tool woven into business operations, not a separate application requiring constant context-switching.AI echoes and deepens cloud innovation Goldberg sees a clear through line connecting today&#x27;s AI adoption and the cloud computing era he pioneered. \"There’s sort of an infinite sense of possibility that exists in the technology world,” he says. “Everybody is thinking about how they can leverage this, how they&#x27;re going to get involved.\"When NetSuite was starting, he continues, \"We had to come to customers with the cloud and say, &#x27;This won&#x27;t disrupt your operations. It&#x27;s going to make them better.&#x27;\" Today, evangelizing enterprise leaders on advanced AI requires a similar approach — demonstrating immediate value while minimizing implementation risk. For NetSuite, continuous innovation around maximizing customer data for growth is an undeniable theme that connects both eras.New transformative capabilities NetSuite’s latest AI capabilities span business operations, while blurring (in a good way) the lines between human and machine intervention:Context-aware intelligence. Ask Oracle adapts responses based on user role, current workflow, and business context. A CFO requesting point-of-sale data receives financial analytics. A warehouse manager asking the same question sees inventory insights.Collaborative workflow design. AI Canvas functions as a scenario-planning workspace where business users articulate processes in natural language. A finance director can describe approval hierarchies for capital expenditures —\"For amounts over $50,000, I need department head approval, then CFO sign-off\" — which the system translates into executable workflows with appropriate controls and audit trails.Governed autonomous operations. Autonomous workflows operate within defined parameters, reconciling accounts, generating payment runs, predicting cash flow. When the system recommends accelerating payment to a supplier, it shows which factors influenced the decision — transparent logic users can accept, modify, or override.Open AI architecture. Built to support Model Context Protocol, NetSuite AI Connector Service enables enterprises to integrate external large language models while supporting governance.Critically, NetSuite adds AI capabilities at no additional cost — embedded directly into workflows employees already use daily.Security and privacy from Oracle infrastructure Built-in AI requires robust infrastructure that bolt-on approaches sidestep. Here, according to NetSuite, tight integration within Oracle technology provides operational and competitive advantages, especially security and compliance peace of mind. Engineers say that’s because NetSuite is supported by Oracle&#x27;s complete stack. From database to applications to analytics, the system optimizes decisions using data from multiple sources in real time.\"That&#x27;s why I started NetSuite. I couldn&#x27;t get the data I wanted,\" Goldberg reflects. \"That&#x27;s one of the most differentiated aspects of NetSuite. When you&#x27;re doing your financial close, and you&#x27;re thinking about what reserves you&#x27;re going to take, you can look at your sales data, because that&#x27;s also there in NetSuite. With NetSuite Next, AI can also help you make those kinds of decisions.\"And performance improves with use. As the platform learns from millions of transactions across thousands of customers, its embedded intelligence improves in ways that bolt-on assistants operating adjacent to core systems cannot match.NetSuite&#x27;s customer base demonstrates this scalability advantage — from startups that became global enterprises including Reddit, Shopify, and DoorDash; as well as promising newcomers like BERO, a brewer of non-alcoholic beer founded by actor Tom Holland, Chomps meat snacks, PetLab, and Kieser Australia. The unified platform grows with businesses rather than requiring migration as they scale.Keeping fire in the belly after three decadesHow does a nearly 30-year-old company maintain innovative capacity, particularly as part of a mammoth corporate ecosystem? Goldberg credits the parent company&#x27;s culture of continuous reinvention.\"I don&#x27;t know if you&#x27;ve heard about this guy Larry Ellison,\" he smiles. \"He manages to seemingly reinvent himself whenever one of these technology revolutions comes along. That hunger, that curiosity, that desire to make things constantly better imbues all of Oracle.\"For Goldberg, the single biggest challenge facing NetSuite customers centers on integration complexity and trust. NetSuite Next addresses this by embedding AI within existing workflows rather than requiring separate systems.In addition, updates to SuiteCloud Platform — an extensibility and customization environment — help organizations adapt NetSuite to their unique business needs. Built on open standards, it lets enterprises mix and match AI models for different functions. SuiteAgent frameworks enable partners to build specialized automation directly into NetSuite. AI Studios give administrators control over how AI operates within specific industry needs.\"This takes NetSuite&#x27;s flexibility to a new level,\" Goldberg says, enabling customers and partners to \"quickly and easily build AI agents, connect external AI assistants, and orchestrate AI processes.\"“AI execution fabric” delivers measurable business impact Industry analysts increasingly argue that embedded AI features deliver superior results compared to add-on models. Futurum Group sees NetSuite Next as an \"AI execution fabric\" rather than a conversational layer — intelligence that runs deep in workflows instead of sitting on the surface.For midmarket enterprises navigating talent shortages, complex compliance frameworks, and competition from digital-native companies, the distinction between advice and execution matters economically.Built-in AI doesn&#x27;t just inform better decisions. It makes those decisions, transparently and autonomously, within human-defined guardrails. For enterprises making ERP decisions today, the choice carries long-term implications. Bolt-on AI can deliver immediate value for information access and basic automation. But built-in AI promises to transform operations with intelligence permeating every transaction and workflow.NetSuite Next begins rolling out to North American customers next year.Why 2026 will belong to the AI-first businessThe bet underlying NetSuite Next: Enterprises reimagining ERP operations around embedded intelligence will outperform those just adding bolt-on conversational assistance to existing systems. Early cloud computing adopters, Goldberg notes, gained competitive advantages that compounded over time. The same logic appears likely to apply to AI-first platforms. Simplicity and ease of use are two big advantages. \"You don&#x27;t have to dig through lots of menus and understand all of the analytics capabilities,\" Goldberg says. \"It will quickly bring up an analysis for you, and then you can converse in natural language to hone in on what you think is most important.\"The tools now think alongside users and take intelligently informed action. For midmarket and entrepreneurial companies, where the gap between having information and acting on it can be the difference between growth and failure, that kind of autonomous execution may determine which enterprises thrive in an AI-first era.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Oracle NetSuiteWhen Evan Goldberg started NetSuite in 1998, his vision was radically simple: give entrepreneurs access to their business data anytime, anywhere. At the time, most enterprise software lived on local servers. As an entrepreneur himself, Goldberg understood the frustration intimately. \"I had fragmented systems. They all said something different,\" he recalls of his early days. NetSuite was the first company to deliver enterprise applications entirely through web browsers, combining CRM, ERP, and ecommerce into one unified platform. That breakthrough idea pioneered the cloud computing and software-as-a-service (SaaS) era and propelled supersonic growth, a 2007 IPO, and an acquisition by Oracle in 2016. Still innovating at the leading-edge That founding obsession — turning scattered data into accessible, coherent, actionable intelligence — is driving NetSuite as it reshapes the next generation of enterprise software.At SuiteWorld 2025 last month, the Austin-based firm unveiled NetSuite Next. Goldberg calls it \"the biggest product evolution in the company&#x27;s history.” The reason? While NetSuite has embedded AI capabilities into workflows for years, he explains, Next represents a quantum leap — contextual, conversational, agentic, composable AI becoming an extension of operations, not separate tools.AI woven into everyday business operations Most enterprise AI today gets bolted on through APIs and conversational interfaces. NetSuite Next operates differently. Intelligence runs deep in workflows instead of sitting on the surface. It autonomously reconciles accounts, optimizes payment timing, predicts cash crunches, and surfaces its reasoning at every step. It doesn&#x27;t just advise on business processes — it executes them, transparently, within human-defined guardrails.\"We built NetSuite for entrepreneurs so that they could get great information about their business,\" Goldberg explains. \"I think the next step is to be able to get deeper insights and analysis without being an expert in analytics. AI turns out to be a really good data scientist.\"This architectural divergence reflects competing philosophies about enterprise technology adoption. Microsoft and SAP have pursued rapid deployment through add-on assistants. NetSuite&#x27;s five-year development cycle for Next represents a more fundamental reimagining: making AI an everyday tool woven into business operations, not a separate application requiring constant context-switching.AI echoes and deepens cloud innovation Goldberg sees a clear through line connecting today&#x27;s AI adoption and the cloud computing era he pioneered. \"There’s sort of an infinite sense of possibility that exists in the technology world,” he says. “Everybody is thinking about how they can leverage this, how they&#x27;re going to get involved.\"When NetSuite was starting, he continues, \"We had to come to customers with the cloud and say, &#x27;This won&#x27;t disrupt your operations. It&#x27;s going to make them better.&#x27;\" Today, evangelizing enterprise leaders on advanced AI requires a similar approach — demonstrating immediate value while minimizing implementation risk. For NetSuite, continuous innovation around maximizing customer data for growth is an undeniable theme that connects both eras.New transformative capabilities NetSuite’s latest AI capabilities span business operations, while blurring (in a good way) the lines between human and machine intervention:Context-aware intelligence. Ask Oracle adapts responses based on user role, current workflow, and business context. A CFO requesting point-of-sale data receives financial analytics. A warehouse manager asking the same question sees inventory insights.Collaborative workflow design. AI Canvas functions as a scenario-planning workspace where business users articulate processes in natural language. A finance director can describe approval hierarchies for capital expenditures —\"For amounts over $50,000, I need department head approval, then CFO sign-off\" — which the system translates into executable workflows with appropriate controls and audit trails.Governed autonomous operations. Autonomous workflows operate within defined parameters, reconciling accounts, generating payment runs, predicting cash flow. When the system recommends accelerating payment to a supplier, it shows which factors influenced the decision — transparent logic users can accept, modify, or override.Open AI architecture. Built to support Model Context Protocol, NetSuite AI Connector Service enables enterprises to integrate external large language models while supporting governance.Critically, NetSuite adds AI capabilities at no additional cost — embedded directly into workflows employees already use daily.Security and privacy from Oracle infrastructure Built-in AI requires robust infrastructure that bolt-on approaches sidestep. Here, according to NetSuite, tight integration within Oracle technology provides operational and competitive advantages, especially security and compliance peace of mind. Engineers say that’s because NetSuite is supported by Oracle&#x27;s complete stack. From database to applications to analytics, the system optimizes decisions using data from multiple sources in real time.\"That&#x27;s why I started NetSuite. I couldn&#x27;t get the data I wanted,\" Goldberg reflects. \"That&#x27;s one of the most differentiated aspects of NetSuite. When you&#x27;re doing your financial close, and you&#x27;re thinking about what reserves you&#x27;re going to take, you can look at your sales data, because that&#x27;s also there in NetSuite. With NetSuite Next, AI can also help you make those kinds of decisions.\"And performance improves with use. As the platform learns from millions of transactions across thousands of customers, its embedded intelligence improves in ways that bolt-on assistants operating adjacent to core systems cannot match.NetSuite&#x27;s customer base demonstrates this scalability advantage — from startups that became global enterprises including Reddit, Shopify, and DoorDash; as well as promising newcomers like BERO, a brewer of non-alcoholic beer founded by actor Tom Holland, Chomps meat snacks, PetLab, and Kieser Australia. The unified platform grows with businesses rather than requiring migration as they scale.Keeping fire in the belly after three decadesHow does a nearly 30-year-old company maintain innovative capacity, particularly as part of a mammoth corporate ecosystem? Goldberg credits the parent company&#x27;s culture of continuous reinvention.\"I don&#x27;t know if you&#x27;ve heard about this guy Larry Ellison,\" he smiles. \"He manages to seemingly reinvent himself whenever one of these technology revolutions comes along. That hunger, that curiosity, that desire to make things constantly better imbues all of Oracle.\"For Goldberg, the single biggest challenge facing NetSuite customers centers on integration complexity and trust. NetSuite Next addresses this by embedding AI within existing workflows rather than requiring separate systems.In addition, updates to SuiteCloud Platform — an extensibility and customization environment — help organizations adapt NetSuite to their unique business needs. Built on open standards, it lets enterprises mix and match AI models for different functions. SuiteAgent frameworks enable partners to build specialized automation directly into NetSuite. AI Studios give administrators control over how AI operates within specific industry needs.\"This takes NetSuite&#x27;s flexibility to a new level,\" Goldberg says, enabling customers and partners to \"quickly and easily build AI agents, connect external AI assistants, and orchestrate AI processes.\"“AI execution fabric” delivers measurable business impact Industry analysts increasingly argue that embedded AI features deliver superior results compared to add-on models. Futurum Group sees NetSuite Next as an \"AI execution fabric\" rather than a conversational layer — intelligence that runs deep in workflows instead of sitting on the surface.For midmarket enterprises navigating talent shortages, complex compliance frameworks, and competition from digital-native companies, the distinction between advice and execution matters economically.Built-in AI doesn&#x27;t just inform better decisions. It makes those decisions, transparently and autonomously, within human-defined guardrails. For enterprises making ERP decisions today, the choice carries long-term implications. Bolt-on AI can deliver immediate value for information access and basic automation. But built-in AI promises to transform operations with intelligence permeating every transaction and workflow.NetSuite Next begins rolling out to North American customers next year.Why 2026 will belong to the AI-first businessThe bet underlying NetSuite Next: Enterprises reimagining ERP operations around embedded intelligence will outperform those just adding bolt-on conversational assistance to existing systems. Early cloud computing adopters, Goldberg notes, gained competitive advantages that compounded over time. The same logic appears likely to apply to AI-first platforms. Simplicity and ease of use are two big advantages. \"You don&#x27;t have to dig through lots of menus and understand all of the analytics capabilities,\" Goldberg says. \"It will quickly bring up an analysis for you, and then you can converse in natural language to hone in on what you think is most important.\"The tools now think alongside users and take intelligently informed action. For midmarket and entrepreneurial companies, where the gap between having information and acting on it can be the difference between growth and failure, that kind of autonomous execution may determine which enterprises thrive in an AI-first era.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2XtOSMqQi1z1ZProN1wL2h/93796f6888f6a6567104c2545639c3c3/2025_SuiteWorld_ExecutiveKeynote01_88144-64-.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/nvidias-new-ai-framework-trains-an-8b-model-to-manage-tools-like-a-pro",
          "published_at": "Wed, 03 Dec 2025 23:00:00 GMT",
          "title": "Nvidia's new AI framework trains an 8B model to manage tools like a pro",
          "standfirst": "Researchers at Nvidia and the University of Hong Kong have released Orchestrator, an 8-billion-parameter model that coordinates different tools and large language models (LLMs) to solve complex problems. In their experiments, Orchestrator achieved higher accuracy at a lower cost than much larger models in tool-use benchmarks, while also aligning with user preferences on which tools to use for a given query.The model was trained through ToolOrchestra, a new reinforcement learning (RL) framework for training small models to act as intelligent coordinators. The approach is based on the idea that a small \"orchestrator\" managing a diverse team of specialized models and tools can be more effective and efficient than a single, monolithic AI system. The findings suggest that this composite approach could pave the way for more practical and scalable AI reasoning systems in the enterprise.The limits of current LLM tool useGiving LLMs access to external tools is a promising way to extend their capabilities beyond their training data and into agentic tasks. By calling on resources like search engines and code interpreters, AI agents can improve their accuracy and perform in-app tasks.However, in the accompanying paper, the researchers argue that the current approach to building tool-using agents doesn&#x27;t harness the full potential of this paradigm. Most systems equip a single, powerful model with a set of basic tools like a web search or a calculator. They argue that humans, when reasoning, “routinely extend themselves by calling upon resources of greater-than-human intelligence, from domain experts to sophisticated processes and software systems.” Accordingly, LLMs should be able to interact with a wide range of tools in different capacities.The tool orchestration paradigmThe paper proposes a shift from a single-model system to a composite one, managed by a lightweight \"orchestrator\" model. The orchestrator&#x27;s job is to analyze a complex task and break it down, invoking the right tools in the right order to arrive at a solution.This toolset includes not only standard utilities like web search and code interpreters, but other LLMs of various capabilities that function as \"intelligent tools.\" For example, the orchestrator can delegate a quantitative question to a math-focused model or a programming challenge to a code-generation model. Instead of placing the entire cognitive load on one large, generalist model, the orchestrator delegates narrowed-down sub-problems to specialized intelligent tools.Based on this concept, the researchers developed ToolOrchestra, a method that uses RL to train a small language model to act as an orchestrator. The model learns when and how to call upon other models and tools, and how to combine their outputs in multi-turn reasoning. The tools are defined in a simple JSON format, specifying their name, description and parameters.The RL training process is guided by a reward system that produces a cost-effective and controllable agent. The reward balances three objectives: The correctness of the final answer, efficiency in cost and latency and alignment with user preferences. For example, the system is penalized for excessive compute usage, and is rewarded for choosing tools that a user has marked as preferred, such as favoring an open-source model over a proprietary API for privacy reasons. To support this training, the team also developed an automatic data pipeline that generated thousands of verifiable training examples across 10 different domains.A small model with big resultsUsing ToolOrchestra, the researchers trained Orchestrator, an 8-billion-parameter model based on Qwen3-8B. They evaluated its performance on three challenging benchmarks: Humanity’s Last Exam (HLE), FRAMES and Tau2-Bench. It was compared against several baselines, including large, off-the-shelf LLMs both with and without tools.The results showed that even powerful models struggled without tools, confirming their necessity for complex reasoning. While adding tools improved performance for large models, it often came with a steep increase in cost and latency. By contrast, the 8B Orchestrator delivered impressive results. On HLE, a benchmark of PhD-level questions, Orchestrator substantially outperformed prior methods at a fraction of the computational cost. On the Tau2-Bench function-calling test, it effectively scheduled different tools, calling a large model like GPT-5 in only about 40% of the steps and using cheaper options for the rest, while still beating an agent that used the large model for every step.The researchers noted that the RL-trained Orchestrator adapted its strategy to new challenges, showing a \"high degree of general reasoning ability.\" Crucially for enterprise applications, Orchestrator also generalized well to models and pricing structures it hadn&#x27;t seen during training. This flexibility makes the framework suitable for businesses that rely on a mix of public, private and bespoke AI models and tools. The lower cost, higher speed and customizability make it a practical approach for building sophisticated AI agents that can scale.As businesses look to deploy more advanced AI agents, this orchestration approach offers a path toward systems that are not only more intelligent but more economical and controllable. (The model weights are currently available under a non-commercial license, but Nvidia has also released the training code under the permissive Apache 2.0 license.)As the paper concludes, the future may lie in even more advanced versions of this concept: “Looking ahead, we envision more sophisticated recursive orchestrator systems to push the upper bound of intelligence [and] also to further enhance efficiency in solving increasingly complex agentic tasks.”",
          "content": "Researchers at Nvidia and the University of Hong Kong have released Orchestrator, an 8-billion-parameter model that coordinates different tools and large language models (LLMs) to solve complex problems. In their experiments, Orchestrator achieved higher accuracy at a lower cost than much larger models in tool-use benchmarks, while also aligning with user preferences on which tools to use for a given query.The model was trained through ToolOrchestra, a new reinforcement learning (RL) framework for training small models to act as intelligent coordinators. The approach is based on the idea that a small \"orchestrator\" managing a diverse team of specialized models and tools can be more effective and efficient than a single, monolithic AI system. The findings suggest that this composite approach could pave the way for more practical and scalable AI reasoning systems in the enterprise.The limits of current LLM tool useGiving LLMs access to external tools is a promising way to extend their capabilities beyond their training data and into agentic tasks. By calling on resources like search engines and code interpreters, AI agents can improve their accuracy and perform in-app tasks.However, in the accompanying paper, the researchers argue that the current approach to building tool-using agents doesn&#x27;t harness the full potential of this paradigm. Most systems equip a single, powerful model with a set of basic tools like a web search or a calculator. They argue that humans, when reasoning, “routinely extend themselves by calling upon resources of greater-than-human intelligence, from domain experts to sophisticated processes and software systems.” Accordingly, LLMs should be able to interact with a wide range of tools in different capacities.The tool orchestration paradigmThe paper proposes a shift from a single-model system to a composite one, managed by a lightweight \"orchestrator\" model. The orchestrator&#x27;s job is to analyze a complex task and break it down, invoking the right tools in the right order to arrive at a solution.This toolset includes not only standard utilities like web search and code interpreters, but other LLMs of various capabilities that function as \"intelligent tools.\" For example, the orchestrator can delegate a quantitative question to a math-focused model or a programming challenge to a code-generation model. Instead of placing the entire cognitive load on one large, generalist model, the orchestrator delegates narrowed-down sub-problems to specialized intelligent tools.Based on this concept, the researchers developed ToolOrchestra, a method that uses RL to train a small language model to act as an orchestrator. The model learns when and how to call upon other models and tools, and how to combine their outputs in multi-turn reasoning. The tools are defined in a simple JSON format, specifying their name, description and parameters.The RL training process is guided by a reward system that produces a cost-effective and controllable agent. The reward balances three objectives: The correctness of the final answer, efficiency in cost and latency and alignment with user preferences. For example, the system is penalized for excessive compute usage, and is rewarded for choosing tools that a user has marked as preferred, such as favoring an open-source model over a proprietary API for privacy reasons. To support this training, the team also developed an automatic data pipeline that generated thousands of verifiable training examples across 10 different domains.A small model with big resultsUsing ToolOrchestra, the researchers trained Orchestrator, an 8-billion-parameter model based on Qwen3-8B. They evaluated its performance on three challenging benchmarks: Humanity’s Last Exam (HLE), FRAMES and Tau2-Bench. It was compared against several baselines, including large, off-the-shelf LLMs both with and without tools.The results showed that even powerful models struggled without tools, confirming their necessity for complex reasoning. While adding tools improved performance for large models, it often came with a steep increase in cost and latency. By contrast, the 8B Orchestrator delivered impressive results. On HLE, a benchmark of PhD-level questions, Orchestrator substantially outperformed prior methods at a fraction of the computational cost. On the Tau2-Bench function-calling test, it effectively scheduled different tools, calling a large model like GPT-5 in only about 40% of the steps and using cheaper options for the rest, while still beating an agent that used the large model for every step.The researchers noted that the RL-trained Orchestrator adapted its strategy to new challenges, showing a \"high degree of general reasoning ability.\" Crucially for enterprise applications, Orchestrator also generalized well to models and pricing structures it hadn&#x27;t seen during training. This flexibility makes the framework suitable for businesses that rely on a mix of public, private and bespoke AI models and tools. The lower cost, higher speed and customizability make it a practical approach for building sophisticated AI agents that can scale.As businesses look to deploy more advanced AI agents, this orchestration approach offers a path toward systems that are not only more intelligent but more economical and controllable. (The model weights are currently available under a non-commercial license, but Nvidia has also released the training code under the permissive Apache 2.0 license.)As the paper concludes, the future may lie in even more advanced versions of this concept: “Looking ahead, we envision more sophisticated recursive orchestrator systems to push the upper bound of intelligence [and] also to further enhance efficiency in solving increasingly complex agentic tasks.”",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/61f98zxDza93Nw0wgjD4Sb/935f7357237957c9ff642b7c4355cf88/LLM_tool-use.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openais-new-confession-system-teaches-models-to-be-honest-about-bad-behaviors-210553482.html",
          "published_at": "Wed, 03 Dec 2025 21:05:53 +0000",
          "title": "OpenAI's new confession system teaches models to be honest about bad behaviors",
          "standfirst": "OpenAI announced today that it is working on a framework that will train artificial intelligence models to acknowledge when they've engaged in undesirable behavior, an approach the team calls a confession. Since large language models are often trained to produce the response that seems to be desired, they can become increasingly likely to provide sycophancy or state hallucinations with total confidence. The new training model tries to encourage a secondary response from the model about what it did to arrive at the main answer it provides. Confessions are only judged on honesty, as opposed to the multiple factors that are used to judge main replies, such as helpfulness, accuracy and compliance. The technical writeup is available here.The researchers said their goal is to encourage the model to be forthcoming about what it did, including potentially problematic actions such as hacking a test, sandbagging or disobeying instructions. \"If the model honestly admits to hacking a test, sandbagging, or violating instructions, that admission increases its reward rather than decreasing it,\" the company said. Whether you're a fan of Catholicism, Usher or just a more transparent AI, a system like confessions could be a useful addition to LLM training.This article originally appeared on Engadget at https://www.engadget.com/ai/openais-new-confession-system-teaches-models-to-be-honest-about-bad-behaviors-210553482.html?src=rss",
          "content": "OpenAI announced today that it is working on a framework that will train artificial intelligence models to acknowledge when they've engaged in undesirable behavior, an approach the team calls a confession. Since large language models are often trained to produce the response that seems to be desired, they can become increasingly likely to provide sycophancy or state hallucinations with total confidence. The new training model tries to encourage a secondary response from the model about what it did to arrive at the main answer it provides. Confessions are only judged on honesty, as opposed to the multiple factors that are used to judge main replies, such as helpfulness, accuracy and compliance. The technical writeup is available here.The researchers said their goal is to encourage the model to be forthcoming about what it did, including potentially problematic actions such as hacking a test, sandbagging or disobeying instructions. \"If the model honestly admits to hacking a test, sandbagging, or violating instructions, that admission increases its reward rather than decreasing it,\" the company said. Whether you're a fan of Catholicism, Usher or just a more transparent AI, a system like confessions could be a useful addition to LLM training.This article originally appeared on Engadget at https://www.engadget.com/ai/openais-new-confession-system-teaches-models-to-be-honest-about-bad-behaviors-210553482.html?src=rss",
          "feed_position": 26
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html",
          "published_at": "Wed, 03 Dec 2025 18:54:03 +0000",
          "title": "The best VPN deals: Up to 88 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "With a good virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart those online trackers that watch you sleep and show you weird personalized ads. Although we strongly recommend using a VPN, you shouldn't jump on just any deal — a bit of comparison shopping goes a long way in this market. The pricing you see on VPN websites is often not an accurate portrayal of what you'll actually pay. Even so, there are some great bargains on the table. Most VPNs now have their Black Friday deals live, and you can save anywhere from 67 to 88 percent on annual subscriptions to the best VPNs. Most of these discounts only apply if you sign up for a year or more, but committing is not a bad idea — while you pay more at the start, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals ExpressVPN Basic — $68.40 for a two-year subscription with four months free (81 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This Cyber Monday deal, which gets you 28 months of ExpressVPN service, represents an 81 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $88 for a two-year subscription with four months free (77 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. It's rare to see ExpressVPN doing anything for Cyber Monday, so give this deal some serious thought. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like Black Friday/Cyber Monday. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "content": "With a good virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart those online trackers that watch you sleep and show you weird personalized ads. Although we strongly recommend using a VPN, you shouldn't jump on just any deal — a bit of comparison shopping goes a long way in this market. The pricing you see on VPN websites is often not an accurate portrayal of what you'll actually pay. Even so, there are some great bargains on the table. Most VPNs now have their Black Friday deals live, and you can save anywhere from 67 to 88 percent on annual subscriptions to the best VPNs. Most of these discounts only apply if you sign up for a year or more, but committing is not a bad idea — while you pay more at the start, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals ExpressVPN Basic — $68.40 for a two-year subscription with four months free (81 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This Cyber Monday deal, which gets you 28 months of ExpressVPN service, represents an 81 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $88 for a two-year subscription with four months free (77 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. It's rare to see ExpressVPN doing anything for Cyber Monday, so give this deal some serious thought. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like Black Friday/Cyber Monday. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/you-can-get-three-months-of-amazon-music-unlimited-for-free-right-now-175508803.html",
          "published_at": "Wed, 03 Dec 2025 17:55:08 +0000",
          "title": "You can get three months of Amazon Music Unlimited for free right now",
          "standfirst": "Amazon’s Black Friday and Cyber Monday sales might be over, but the company is still running a deal on its premium music streaming service. Right now, you can get three months of Amazon Music Unlimited for free if you’re a new subscriber. As with most offers of this nature, your subscription will auto-renew for the full price of $12 per month (or $11 for Prime members) after your three months are up. But you can cancel whenever you like and won’t be charged a penny if you do so before the trial ends. Amazon Music Unlimited offers lossless streaming and podcasts, and as you’d expect, it works best with Amazon’s ever-swelling army of Alexa devices. It’s a bit clunky compared to the likes of Apple Music and Spotify, and not as good for music discovery and curation, but the app has made strides over the years. It even has its own Spotify Wrapped-alike now. If you do take advantage of this deal, bear in mind that Amazon Music Unlimited is more expensive than Apple Music, YouTube Music and Tidal without a Prime subscription, after Amazon put its prices up earlier this year. A paid Spotify Premium Individual plan costs the same as Amazon’s service (sans Prime), and you can also try that for free right now, with the company offering four months without payment provided you’ve never been a Premium subscriber in the past. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/you-can-get-three-months-of-amazon-music-unlimited-for-free-right-now-175508803.html?src=rss",
          "content": "Amazon’s Black Friday and Cyber Monday sales might be over, but the company is still running a deal on its premium music streaming service. Right now, you can get three months of Amazon Music Unlimited for free if you’re a new subscriber. As with most offers of this nature, your subscription will auto-renew for the full price of $12 per month (or $11 for Prime members) after your three months are up. But you can cancel whenever you like and won’t be charged a penny if you do so before the trial ends. Amazon Music Unlimited offers lossless streaming and podcasts, and as you’d expect, it works best with Amazon’s ever-swelling army of Alexa devices. It’s a bit clunky compared to the likes of Apple Music and Spotify, and not as good for music discovery and curation, but the app has made strides over the years. It even has its own Spotify Wrapped-alike now. If you do take advantage of this deal, bear in mind that Amazon Music Unlimited is more expensive than Apple Music, YouTube Music and Tidal without a Prime subscription, after Amazon put its prices up earlier this year. A paid Spotify Premium Individual plan costs the same as Amazon’s service (sans Prime), and you can also try that for free right now, with the company offering four months without payment provided you’ve never been a Premium subscriber in the past. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/you-can-get-three-months-of-amazon-music-unlimited-for-free-right-now-175508803.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/the-best-christmas-gifts-to-give-everyone-on-your-2025-holiday-shopping-list-170018456.html",
          "published_at": "Wed, 03 Dec 2025 17:01:26 +0000",
          "title": "The best Christmas gifts to give everyone on your 2025 holiday shopping list",
          "standfirst": "This time of year has a lot of merry and bright things to be excited about, but it can be stressful if you’re stumped on what to get your mom, dad, best friend, coworker or kids’ teacher as a holiday gift. Whether you enjoy or dread buying gifts for people, it’s safe to say we all want to give our loved ones things they will enjoy and appreciate. But there’s a lot of noise, junk and bad deals disguised as good deals to sift through as we get closer and closer to the holidays.Allow us at Engadget to help you through it. Here, you’ll find all of our holiday gift guides collected in one place, so you can more easily find the best Christmas gifts you need this year. Are you looking for white elephant gift ideas? Are you struggling to come up with a good gift for the father figure in your life? Are you just looking for a good board game to pick up for your own family? We’ve got you covered with gift ideas for all of those scenarios and more. Best white elephant gift ideas According to legend, the King of Siam would give a white elephant to courtiers who had upset them. The recipient had no choice but to simply thank the king for such an opulent gift, knowing that they likely could not afford the upkeep for such an animal. It would inevitably lead them to financial ruin. This story is almost certainly untrue, but it has led to a modern holiday staple: the white elephant gift exchange. These gift ideas will not only get you a few chuckles, but will also make your recipient feel (slightly) burdened. Read more: The best white elephant gift ideas Best Secret Santa gifts Secret Santa gift exchanges are supposed to be fun, but it’s easy to overthink it. You want a gift that feels thoughtful without being awkward, useful without being boring, and most importantly, affordable. The sweet spot is under $50, which is plenty to find something that fits your recipient’s personality. Whether you’re buying for a co-worker you only chat with at the coffee machine, a friend who already has everything or a cousin who never gives you ideas, there are clever options that will make them smile. Read more: The best Secret Santa gift ideas Best tech gifts and gadgets Trying to find the right gift for an unabashed gadget lover during the holidays can be difficult, especially if you don’t keep up with tech industry news yourself. Fortunately, you’re reading Engadget.com, a site entirely staffed by people who spend all day figuring out what new stuff is and isn’t actually good. So allow us to help. We’ve rounded up some of our favorite gadgets and gear that just might satisfy the avid geek in your life. Read more: The best tech gifts and gadgets Best board game gifts We could all use more time away from screens of all types and sizes, and board games are a fun way to do that and bond with friends and family. You can find plenty of unique sets out there now, from word puzzles to whodunnits to calming playthroughs that showcase the beauty of the little things in life. From games with giant monsters to those with haunted mansions, we’re sure at least one of our suggestions will be a hit with you and your loved ones. Read more: The best board games to gift this season Best gifts for $25 or less So you want to give someone a gift but you don’t have a ton of cash to spare. Don’t fret because first, you’re not alone, and second, there are tons of options to choose from. Especially if you’re looking in the tech space, it can feel especially daunting to find a gadget that’s affordable but also worth gifting — in other words, not a piece of junk that will eventually take up residence at the bottom of a drawer. But you don’t have to drain your wallet to get someone a cool gadget that will both be useful and make their lives easier. We’ve collected our favorite pieces of tech under $25 that make great gifts and help you to stick to a budget. Read more: The best gifts for $25 or less Best gifts under $50 We wouldn’t blame you if you try to do all of your tech shopping around the holidays. That’s when you can typically get the best sales, both on relatively affordable gear and (more importantly) on big-ticket items. But it would be wrong to think that only the most expensive tech is worth gifting. Since we at Engadget test a plethora of gadgets every year, we know that there are some hidden (and not so hidden) tech gems at lower price ranges — you just have to know where to find them. Read more: The best gifts under $50 that make great stocking stuffers Best gifts under $100 Finding a gift for the tech nerd on your list can be tough. They likely have all the tech they need and then some, but you can add to their kit with the right accessories. Apple, Samsung, Sony and other big tech companies all have affordable gear that comes in at $100 or less, you just have to know where to look. We've collected some of our favorites, but remember: you can often find alternatives that are just as good (and sometimes better) than these. However, for the people in your life for which brand names really do matter, these gifts will speak to them. Read more: The best tech gifts under $100 Best tech toys for kids We know it’s been a pretty crazy year that’s got you wondering how exactly you’re going to make the holiday season extra special, especially for the kids in your life. The good news is that the toy industry is just as creative as ever, and this year’s crop of hot tech toys is filled with plenty of surprise and delight, all at affordable prices. We’ve picked some of our favorites under $100, ones that will not only thrill right out of the box, but keep the kids entertained for months to come. Read more: The best tech toys for kids Best gifts for remote workers There's a pretty good chance you know at least one person who works remotely in some fashion. While the WFH life has its perks — nobody likes a long commute — it comes with its own set of challenges, from lacking pro-level equipment to dealing with household disturbances. If you’re looking to give a gift to someone who spends much of their time in their home office, we’ve rounded up a few techy gift ideas that should make their days a little more delightful, or at least easier to manage. Read more: The best gift ideas for the remote worker in your life Best travel gifts For as long as humans have traveled, they've carried gear with them to make long journeys easier. Airplanes may have made travel faster, but crossing states and countries can still be exhausting. If you have a friend or family member who loves exploring the world, they'll appreciate things that will save them stress when they're far from home. So let Engadget help you find the perfect gift for the person in your life with wanderlust. Read more: The best gifts for travelers Best gifts for Nintendo lovers If you're like us, Nintendo holds a special place in your heart thanks to iconic characters like Mario, Peach and Donkey Kong and multiple generations of best-selling consoles. But little did we know that outside of gaming hardware and accessories, there's an ever-growing assortment of Nintendo-themed toys, clothes and decor. And it's kind of a problem because we want all of it. So to help you figure out the best gifts for the Nintendo fan in your life, we've put together a big list of our favorite products that will give anyone a power-up this holiday season. Of course, if none of the ones on our list quite fit the bill, you can also head over to our full list of the best Nintendo Switch 2 accessories for even more ideas. Read more: The best Nintendo gifts for the holiday season Best retro gaming gifts The stream of new video games never ends, but for some of us, nothing beats the classics. If you don’t feel like hunting through eBay and local game shops for old cartridges to add to your loved one’s collection, we’ve picked out a few other gift ideas for the nostalgic gamer in your life — from video upscalers for old consoles to retro-themed books and artwork. Read more: The best retro gaming gifts for the holidays Best gifts for gamers The year may not be over, but 2025 is all but guaranteed to go down as one of the best 12 months in gaming history. Between releases like Hades 2, Hollow Knight: Silksong and Ghost of Yotei, to name just a few, there was truly something for everyone in 2025. Of course, that abundance also means it can be tricky to find a gift for the gamers in your life, especially if you're not one yourself. Worry not — Engadget is here to help. We guarantee our guide will help you find the perfect gift for your friend or loved one. Read more: The best gifts for gamers Best gifts for moms Some moms really do mean it when they say they don’t need any gifts. But those same moms will probably appreciate getting something thoughtful and personal — a gift that shows you put in a bit of consideration. It’s tough to pin-point what that ideal gift is for any given mom, but we’ve got ideas to get you started. Since we spend our days testing and otherwise thinking about tech, most of the presents here have a gadget spin, but all of them are a heck of a lot more unique than a candle and a bath bomb. Read more: The best gifts for mom Best gifts for dads It's not always easy to find gifts for dads, especially for those who are often quick to snap up whatever they need on their own. But even the geekiest and most well-informed dads have blind spots — the trick is to find something they've never heard of, but could actually make their lives useful. We've collected some of our favorite dadcore gift ideas, which would suit everyone from a complete gadgetphobe to a total techie. Read more: The best gifts for dads Best subscription box gifts Subscription boxes are the rare gift that keeps its charm long after the wrapping paper is gone. You make the choice once, but the surprises keep landing on their doorstep for months after that. For anyone who loves the buzz of a delivery, these are gifts that extend the season well past December. Each box on this list combines a bit of discovery with something tangible, such as gadgets, books, collectibles, snacks or clever projects. Some appeal to hardcore hobbyists, others to the curious or the comfort seekers, but all offer that same spark of delight that comes from unboxing something unexpected. Read more: The best subscription box gifts Best gifts for home cooks For home cooks, kitchen tools are the equipment that make all your favorite dishes and meals possible. And while having the fanciest gear certainly isn't a requirement, it is really nice, which makes products like the ones here such great gifts. These are the kind of things that people want but might not be able to justify buying for themselves, or essential pieces that would be handy additions to any kitchen or pantry. So if you're looking for present ideas for the chef in your life, check out our guide of tried and tested cooking tools and gadgets. Read more: The best cooking gifts Best gifts for coffee lovers When it comes to making coffee at home, us coffee nerds are constantly evolving. Whether the person you’re shopping for is newly indoctrinated into the world of small-batch roasters or obsessive over every possible aspect of every brewing process, we’ve compiled a list of the best coffee gear for any coffee geek this holiday season. For brewing, grinding and drinking, we’ve got multiple options at a range of prices to help expand any java geek’s horizons. And if you think the coffee aficionado on your list already has everything they need, we’ve got a recommendation for them too. Read more: The best gifts for coffee lovers Best gadgets for your pets We're a pet-loving staff here at Engadget, with diverse distribution of cat people, dog people, other-small-fuzzy-creature people, bird feeder enjoyers and so on (at press time, I'm unsure if we have a rat person, but I'd be surprised if we didn't). And, of course, we love getting new gadgets of all sorts for our pets as much as for ourselves. Our list, with gifts as low-tech as a blanket and as high-tech as the best $30 two-way camera you'll ever use, is for the pet lover in your life — whether that's you or another favorite human. Read more: The best gadgets for your pets Check out the rest of our gift ideas here.This article originally appeared on Engadget at https://www.engadget.com/the-best-christmas-gifts-to-give-everyone-on-your-2025-holiday-shopping-list-170018456.html?src=rss",
          "content": "This time of year has a lot of merry and bright things to be excited about, but it can be stressful if you’re stumped on what to get your mom, dad, best friend, coworker or kids’ teacher as a holiday gift. Whether you enjoy or dread buying gifts for people, it’s safe to say we all want to give our loved ones things they will enjoy and appreciate. But there’s a lot of noise, junk and bad deals disguised as good deals to sift through as we get closer and closer to the holidays.Allow us at Engadget to help you through it. Here, you’ll find all of our holiday gift guides collected in one place, so you can more easily find the best Christmas gifts you need this year. Are you looking for white elephant gift ideas? Are you struggling to come up with a good gift for the father figure in your life? Are you just looking for a good board game to pick up for your own family? We’ve got you covered with gift ideas for all of those scenarios and more. Best white elephant gift ideas According to legend, the King of Siam would give a white elephant to courtiers who had upset them. The recipient had no choice but to simply thank the king for such an opulent gift, knowing that they likely could not afford the upkeep for such an animal. It would inevitably lead them to financial ruin. This story is almost certainly untrue, but it has led to a modern holiday staple: the white elephant gift exchange. These gift ideas will not only get you a few chuckles, but will also make your recipient feel (slightly) burdened. Read more: The best white elephant gift ideas Best Secret Santa gifts Secret Santa gift exchanges are supposed to be fun, but it’s easy to overthink it. You want a gift that feels thoughtful without being awkward, useful without being boring, and most importantly, affordable. The sweet spot is under $50, which is plenty to find something that fits your recipient’s personality. Whether you’re buying for a co-worker you only chat with at the coffee machine, a friend who already has everything or a cousin who never gives you ideas, there are clever options that will make them smile. Read more: The best Secret Santa gift ideas Best tech gifts and gadgets Trying to find the right gift for an unabashed gadget lover during the holidays can be difficult, especially if you don’t keep up with tech industry news yourself. Fortunately, you’re reading Engadget.com, a site entirely staffed by people who spend all day figuring out what new stuff is and isn’t actually good. So allow us to help. We’ve rounded up some of our favorite gadgets and gear that just might satisfy the avid geek in your life. Read more: The best tech gifts and gadgets Best board game gifts We could all use more time away from screens of all types and sizes, and board games are a fun way to do that and bond with friends and family. You can find plenty of unique sets out there now, from word puzzles to whodunnits to calming playthroughs that showcase the beauty of the little things in life. From games with giant monsters to those with haunted mansions, we’re sure at least one of our suggestions will be a hit with you and your loved ones. Read more: The best board games to gift this season Best gifts for $25 or less So you want to give someone a gift but you don’t have a ton of cash to spare. Don’t fret because first, you’re not alone, and second, there are tons of options to choose from. Especially if you’re looking in the tech space, it can feel especially daunting to find a gadget that’s affordable but also worth gifting — in other words, not a piece of junk that will eventually take up residence at the bottom of a drawer. But you don’t have to drain your wallet to get someone a cool gadget that will both be useful and make their lives easier. We’ve collected our favorite pieces of tech under $25 that make great gifts and help you to stick to a budget. Read more: The best gifts for $25 or less Best gifts under $50 We wouldn’t blame you if you try to do all of your tech shopping around the holidays. That’s when you can typically get the best sales, both on relatively affordable gear and (more importantly) on big-ticket items. But it would be wrong to think that only the most expensive tech is worth gifting. Since we at Engadget test a plethora of gadgets every year, we know that there are some hidden (and not so hidden) tech gems at lower price ranges — you just have to know where to find them. Read more: The best gifts under $50 that make great stocking stuffers Best gifts under $100 Finding a gift for the tech nerd on your list can be tough. They likely have all the tech they need and then some, but you can add to their kit with the right accessories. Apple, Samsung, Sony and other big tech companies all have affordable gear that comes in at $100 or less, you just have to know where to look. We've collected some of our favorites, but remember: you can often find alternatives that are just as good (and sometimes better) than these. However, for the people in your life for which brand names really do matter, these gifts will speak to them. Read more: The best tech gifts under $100 Best tech toys for kids We know it’s been a pretty crazy year that’s got you wondering how exactly you’re going to make the holiday season extra special, especially for the kids in your life. The good news is that the toy industry is just as creative as ever, and this year’s crop of hot tech toys is filled with plenty of surprise and delight, all at affordable prices. We’ve picked some of our favorites under $100, ones that will not only thrill right out of the box, but keep the kids entertained for months to come. Read more: The best tech toys for kids Best gifts for remote workers There's a pretty good chance you know at least one person who works remotely in some fashion. While the WFH life has its perks — nobody likes a long commute — it comes with its own set of challenges, from lacking pro-level equipment to dealing with household disturbances. If you’re looking to give a gift to someone who spends much of their time in their home office, we’ve rounded up a few techy gift ideas that should make their days a little more delightful, or at least easier to manage. Read more: The best gift ideas for the remote worker in your life Best travel gifts For as long as humans have traveled, they've carried gear with them to make long journeys easier. Airplanes may have made travel faster, but crossing states and countries can still be exhausting. If you have a friend or family member who loves exploring the world, they'll appreciate things that will save them stress when they're far from home. So let Engadget help you find the perfect gift for the person in your life with wanderlust. Read more: The best gifts for travelers Best gifts for Nintendo lovers If you're like us, Nintendo holds a special place in your heart thanks to iconic characters like Mario, Peach and Donkey Kong and multiple generations of best-selling consoles. But little did we know that outside of gaming hardware and accessories, there's an ever-growing assortment of Nintendo-themed toys, clothes and decor. And it's kind of a problem because we want all of it. So to help you figure out the best gifts for the Nintendo fan in your life, we've put together a big list of our favorite products that will give anyone a power-up this holiday season. Of course, if none of the ones on our list quite fit the bill, you can also head over to our full list of the best Nintendo Switch 2 accessories for even more ideas. Read more: The best Nintendo gifts for the holiday season Best retro gaming gifts The stream of new video games never ends, but for some of us, nothing beats the classics. If you don’t feel like hunting through eBay and local game shops for old cartridges to add to your loved one’s collection, we’ve picked out a few other gift ideas for the nostalgic gamer in your life — from video upscalers for old consoles to retro-themed books and artwork. Read more: The best retro gaming gifts for the holidays Best gifts for gamers The year may not be over, but 2025 is all but guaranteed to go down as one of the best 12 months in gaming history. Between releases like Hades 2, Hollow Knight: Silksong and Ghost of Yotei, to name just a few, there was truly something for everyone in 2025. Of course, that abundance also means it can be tricky to find a gift for the gamers in your life, especially if you're not one yourself. Worry not — Engadget is here to help. We guarantee our guide will help you find the perfect gift for your friend or loved one. Read more: The best gifts for gamers Best gifts for moms Some moms really do mean it when they say they don’t need any gifts. But those same moms will probably appreciate getting something thoughtful and personal — a gift that shows you put in a bit of consideration. It’s tough to pin-point what that ideal gift is for any given mom, but we’ve got ideas to get you started. Since we spend our days testing and otherwise thinking about tech, most of the presents here have a gadget spin, but all of them are a heck of a lot more unique than a candle and a bath bomb. Read more: The best gifts for mom Best gifts for dads It's not always easy to find gifts for dads, especially for those who are often quick to snap up whatever they need on their own. But even the geekiest and most well-informed dads have blind spots — the trick is to find something they've never heard of, but could actually make their lives useful. We've collected some of our favorite dadcore gift ideas, which would suit everyone from a complete gadgetphobe to a total techie. Read more: The best gifts for dads Best subscription box gifts Subscription boxes are the rare gift that keeps its charm long after the wrapping paper is gone. You make the choice once, but the surprises keep landing on their doorstep for months after that. For anyone who loves the buzz of a delivery, these are gifts that extend the season well past December. Each box on this list combines a bit of discovery with something tangible, such as gadgets, books, collectibles, snacks or clever projects. Some appeal to hardcore hobbyists, others to the curious or the comfort seekers, but all offer that same spark of delight that comes from unboxing something unexpected. Read more: The best subscription box gifts Best gifts for home cooks For home cooks, kitchen tools are the equipment that make all your favorite dishes and meals possible. And while having the fanciest gear certainly isn't a requirement, it is really nice, which makes products like the ones here such great gifts. These are the kind of things that people want but might not be able to justify buying for themselves, or essential pieces that would be handy additions to any kitchen or pantry. So if you're looking for present ideas for the chef in your life, check out our guide of tried and tested cooking tools and gadgets. Read more: The best cooking gifts Best gifts for coffee lovers When it comes to making coffee at home, us coffee nerds are constantly evolving. Whether the person you’re shopping for is newly indoctrinated into the world of small-batch roasters or obsessive over every possible aspect of every brewing process, we’ve compiled a list of the best coffee gear for any coffee geek this holiday season. For brewing, grinding and drinking, we’ve got multiple options at a range of prices to help expand any java geek’s horizons. And if you think the coffee aficionado on your list already has everything they need, we’ve got a recommendation for them too. Read more: The best gifts for coffee lovers Best gadgets for your pets We're a pet-loving staff here at Engadget, with diverse distribution of cat people, dog people, other-small-fuzzy-creature people, bird feeder enjoyers and so on (at press time, I'm unsure if we have a rat person, but I'd be surprised if we didn't). And, of course, we love getting new gadgets of all sorts for our pets as much as for ourselves. Our list, with gifts as low-tech as a blanket and as high-tech as the best $30 two-way camera you'll ever use, is for the pet lover in your life — whether that's you or another favorite human. Read more: The best gadgets for your pets Check out the rest of our gift ideas here.This article originally appeared on Engadget at https://www.engadget.com/the-best-christmas-gifts-to-give-everyone-on-your-2025-holiday-shopping-list-170018456.html?src=rss",
          "feed_position": 35
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/nikon-zr-review-a-highly-capable-cinema-camera-at-a-reasonable-price-152634311.html",
          "published_at": "Wed, 03 Dec 2025 15:26:35 +0000",
          "title": "Nikon ZR review: A highly capable cinema camera at a reasonable price",
          "standfirst": "Video used to be an afterthought for Nikon, but since the company purchased RED last year, content creators are now high on its priority list. A perfect example of that is Nikon’s new $2,200 ZR: a full-frame mirrorless model that stands up against dedicated cinema cameras for a fraction of the price. It’s the first consumer camera to capture video using RED’s 12-bit RAW format, but unlike RED’s Hollywood cameras, it has a fast and accurate autofocus system. It also comes with a huge display, pro video monitoring tools, in-body stabilization and 32-bit float internal audio recording. After shooting a short film that tested its capabilities, I can confirm that the Nikon ZR offers incredible video quality at this price. Body and handling While a bit lighter than Nikon’s Z6 III, the 1.19-pound (540-gram) ZR feels solid. It has a boxy design like Sony’s FX2 but a much smaller grip because it’s designed to be rigged up for cinema shooting with cages and handles. However, unlike the FX2 which has multiple 1/4-inch mounting threads to do such rigging, the ZR unfortunately has only one of those on the bottom. The ZR also lacks an electronic viewfinder like the FX2, but it more than makes up for that with its huge 4-inch display — the largest I’ve ever seen on a mirrorless camera. At 1,000 nits, it’s bright enough to shoot on sunny days, extremely sharp (3.07 million dots) and flips out for vloggers. All of that makes it a perfect primary display for checking the image and controlling the camera. Nikon has nailed the ZR’s handling, too. While it’s not covered with buttons and dials like some models, it does have two shooting dials to control exposure and a joystick for autofocus. There’s also a camera/video switch, two record buttons, a power switch and five customizable buttons. Many of Nikon’s lenses come with control rings as well, so extra manual control is available. The menu button is unusual: you press once for the quick menu and hold to see the full menu. Given the large number of settings, I would advise anyone buying this camera to learn all the important adjustments, then customize the controls to avoid wading through dense menus while shooting. Another unique feature is in the battery compartment. There’s a single fast CFexpress slot to handle RAW video, plus a microSD slot for proxies. The lack of a second CFexpress slot or fast SD card slot for backup isn’t ideal for a professional camera, though. Finally, the ZR runs on the same N‑EL15c batteries as other Nikon mirrorless cameras. They allow 90 minutes of HD shooting on a charge, or 390 photos per CIPA standards. That’s mediocre, so if you’re planning long shoots, stock up on batteries. Video Steve Dent for Engadget The Nikon ZR has the largest selection of RAW video settings I’ve seen. The centerpiece is RED’s RAW R3D NE light codec (designed by RED for Nikon) with RED’s Log3G10 log format. It also supports Nikon’s N-RAW, ProRes/ProRes RAW and H.265 with resolution that ranges from 6K at up to 60 fps to 4K 120 fps and 1080p at 240 fps. Despite the smallish body, it can capture 6K RAW video continuously for 125 minutes without overheating. The 24MP sensor uses a dual ISO system with native 800 and 6,400 ISOs, providing a nice range for indoor and outdoor shooting. The company claims 15+ stops of dynamic range, which is more than just about any other mirrorless camera. Other key video features include five-axis in-body stabilization with seven stops of shake reduction, waveform and vectorscope monitoring and a false color display for manual focus. To test the camera’s features and video quality, I shot a short film in a mix of indoor low light, outdoor daytime and a mix between the two. I also shot handheld (including running with it) to test the stabilization. I primarily captured in R3D RAW, as well as Nikon’s N-RAW at the native 800 and 6,400 ISOs to maximize dynamic range. (You can take 24MP photos with this camera, but I’m focusing on video as it’s mainly designed for that.) In order to not see a flat log profile when shooting, you’ll need to apply a look-up table (LUT) designed for RED cameras, like \"Achromic,\" \"Bleach\" or \"Caustic.\" Those are only for in-camera previews and not baked into the video, but you can apply those LUTs later in Adobe Premiere or DaVinci Resolve to get the same look. Steve Dent for Engadget With such a high native ISO, I was able to shoot inside with a single studio light. Video quality was outstanding with little noise in shadow regions, even after boosting black levels in post. Meanwhile, the RED R3D codec and Log3G10 gave me extra latitude to reveal shadow detail and dial down highlights when I shot the subject against a bright window. When you use the R3D codec, exposure is strictly manual with no ability to set auto shutter speed (shutter angle) or f-stop. So, for a scene with varying light, I used Nikon’s N-RAW to see if it would give me the correct exposure at the beginning and end of the scene. It did a good job, with no noticeable jumps during the shot. Video in sunlight at ISO 800 was also sharp with accurate colors after downscaling to 4K from 6K in DaVinci Resolve. ISO 800 is a relatively high native setting, though, and the ZR doesn’t have a built-in ND filter to reduce exposure. That means you’ll need to buy ND filters for outside shooting or the high shutter speeds will result in choppy video. Cinema cameras from Blackmagic Design, Arri or RED are manual-focus only. But the ZR is a Nikon camera, and it has the best AF system I’ve seen on any of the company’s models, consistently nailing focus even with moving subjects. You can also automatically track vehicles, birds and other animals. At the same time, the ZR handles manual focus well. That’s thanks to a built-in display that’s big enough to check focus accurately and Nikon’s focus peaking setting with three levels of sensitivity. Steve Dent for Engadget In-body stabilization on the ZR wasn’t up to par with Panasonic’s S1 II, however. Video was smooth for handheld shooting if I panned the camera gently, but all my running and walking shots showed noticeable camera shake. That said, the ZR at least has in-body stabilization, unlike most cinema cameras, and most filmmakers will use a gimbal for running shots, regardless of which camera they use. (Note that the rattling you hear when the ZR is turned off is the sensor, which floats by design.) Finally, I was able to capture good audio quality via an external microphone without any clipping worries thanks to the Nikon ZR’s 32-bit float internal audio capture. The company also touts directional capture using its built-in mics, but as with any such system, audio quality isn’t high enough for production use. Wrap-up With the ZR, Nikon has shown that it’s finally catching up to and even surpassing its rivals for content creation. Whether you’re doing social media, YouTube, documentaries or even film production, this camera is versatile and powerful with few compromises. Video quality and ease of use even beats models that are double or triple the price. The ZR’s primary competition is in the low-end cinema cameras, particularly Sony’s $2,998 FX2 and the $3,899 Canon R5C. While more expensive, both come with an electronic viewfinder that the ZR lacks, and the R5C can shoot up to 8K video. Another option is Blackmagic Design’s Pyxis 6K camera, but it only offers basic autofocus capabilities and lacks in-body stabilization. Compared to those options, Nikon’s ZR delivers better dynamic range thanks to the inclusion of RED’s R3D RAW codec. It also comes with an excellent autofocus system and decent in-body stabilization. If you’re a creator looking to get the best video quality for the money without losing those niceties, I’d highly recommend the ZR.This article originally appeared on Engadget at https://www.engadget.com/cameras/nikon-zr-review-a-highly-capable-cinema-camera-at-a-reasonable-price-152634311.html?src=rss",
          "content": "Video used to be an afterthought for Nikon, but since the company purchased RED last year, content creators are now high on its priority list. A perfect example of that is Nikon’s new $2,200 ZR: a full-frame mirrorless model that stands up against dedicated cinema cameras for a fraction of the price. It’s the first consumer camera to capture video using RED’s 12-bit RAW format, but unlike RED’s Hollywood cameras, it has a fast and accurate autofocus system. It also comes with a huge display, pro video monitoring tools, in-body stabilization and 32-bit float internal audio recording. After shooting a short film that tested its capabilities, I can confirm that the Nikon ZR offers incredible video quality at this price. Body and handling While a bit lighter than Nikon’s Z6 III, the 1.19-pound (540-gram) ZR feels solid. It has a boxy design like Sony’s FX2 but a much smaller grip because it’s designed to be rigged up for cinema shooting with cages and handles. However, unlike the FX2 which has multiple 1/4-inch mounting threads to do such rigging, the ZR unfortunately has only one of those on the bottom. The ZR also lacks an electronic viewfinder like the FX2, but it more than makes up for that with its huge 4-inch display — the largest I’ve ever seen on a mirrorless camera. At 1,000 nits, it’s bright enough to shoot on sunny days, extremely sharp (3.07 million dots) and flips out for vloggers. All of that makes it a perfect primary display for checking the image and controlling the camera. Nikon has nailed the ZR’s handling, too. While it’s not covered with buttons and dials like some models, it does have two shooting dials to control exposure and a joystick for autofocus. There’s also a camera/video switch, two record buttons, a power switch and five customizable buttons. Many of Nikon’s lenses come with control rings as well, so extra manual control is available. The menu button is unusual: you press once for the quick menu and hold to see the full menu. Given the large number of settings, I would advise anyone buying this camera to learn all the important adjustments, then customize the controls to avoid wading through dense menus while shooting. Another unique feature is in the battery compartment. There’s a single fast CFexpress slot to handle RAW video, plus a microSD slot for proxies. The lack of a second CFexpress slot or fast SD card slot for backup isn’t ideal for a professional camera, though. Finally, the ZR runs on the same N‑EL15c batteries as other Nikon mirrorless cameras. They allow 90 minutes of HD shooting on a charge, or 390 photos per CIPA standards. That’s mediocre, so if you’re planning long shoots, stock up on batteries. Video Steve Dent for Engadget The Nikon ZR has the largest selection of RAW video settings I’ve seen. The centerpiece is RED’s RAW R3D NE light codec (designed by RED for Nikon) with RED’s Log3G10 log format. It also supports Nikon’s N-RAW, ProRes/ProRes RAW and H.265 with resolution that ranges from 6K at up to 60 fps to 4K 120 fps and 1080p at 240 fps. Despite the smallish body, it can capture 6K RAW video continuously for 125 minutes without overheating. The 24MP sensor uses a dual ISO system with native 800 and 6,400 ISOs, providing a nice range for indoor and outdoor shooting. The company claims 15+ stops of dynamic range, which is more than just about any other mirrorless camera. Other key video features include five-axis in-body stabilization with seven stops of shake reduction, waveform and vectorscope monitoring and a false color display for manual focus. To test the camera’s features and video quality, I shot a short film in a mix of indoor low light, outdoor daytime and a mix between the two. I also shot handheld (including running with it) to test the stabilization. I primarily captured in R3D RAW, as well as Nikon’s N-RAW at the native 800 and 6,400 ISOs to maximize dynamic range. (You can take 24MP photos with this camera, but I’m focusing on video as it’s mainly designed for that.) In order to not see a flat log profile when shooting, you’ll need to apply a look-up table (LUT) designed for RED cameras, like \"Achromic,\" \"Bleach\" or \"Caustic.\" Those are only for in-camera previews and not baked into the video, but you can apply those LUTs later in Adobe Premiere or DaVinci Resolve to get the same look. Steve Dent for Engadget With such a high native ISO, I was able to shoot inside with a single studio light. Video quality was outstanding with little noise in shadow regions, even after boosting black levels in post. Meanwhile, the RED R3D codec and Log3G10 gave me extra latitude to reveal shadow detail and dial down highlights when I shot the subject against a bright window. When you use the R3D codec, exposure is strictly manual with no ability to set auto shutter speed (shutter angle) or f-stop. So, for a scene with varying light, I used Nikon’s N-RAW to see if it would give me the correct exposure at the beginning and end of the scene. It did a good job, with no noticeable jumps during the shot. Video in sunlight at ISO 800 was also sharp with accurate colors after downscaling to 4K from 6K in DaVinci Resolve. ISO 800 is a relatively high native setting, though, and the ZR doesn’t have a built-in ND filter to reduce exposure. That means you’ll need to buy ND filters for outside shooting or the high shutter speeds will result in choppy video. Cinema cameras from Blackmagic Design, Arri or RED are manual-focus only. But the ZR is a Nikon camera, and it has the best AF system I’ve seen on any of the company’s models, consistently nailing focus even with moving subjects. You can also automatically track vehicles, birds and other animals. At the same time, the ZR handles manual focus well. That’s thanks to a built-in display that’s big enough to check focus accurately and Nikon’s focus peaking setting with three levels of sensitivity. Steve Dent for Engadget In-body stabilization on the ZR wasn’t up to par with Panasonic’s S1 II, however. Video was smooth for handheld shooting if I panned the camera gently, but all my running and walking shots showed noticeable camera shake. That said, the ZR at least has in-body stabilization, unlike most cinema cameras, and most filmmakers will use a gimbal for running shots, regardless of which camera they use. (Note that the rattling you hear when the ZR is turned off is the sensor, which floats by design.) Finally, I was able to capture good audio quality via an external microphone without any clipping worries thanks to the Nikon ZR’s 32-bit float internal audio capture. The company also touts directional capture using its built-in mics, but as with any such system, audio quality isn’t high enough for production use. Wrap-up With the ZR, Nikon has shown that it’s finally catching up to and even surpassing its rivals for content creation. Whether you’re doing social media, YouTube, documentaries or even film production, this camera is versatile and powerful with few compromises. Video quality and ease of use even beats models that are double or triple the price. The ZR’s primary competition is in the low-end cinema cameras, particularly Sony’s $2,998 FX2 and the $3,899 Canon R5C. While more expensive, both come with an electronic viewfinder that the ZR lacks, and the R5C can shoot up to 8K video. Another option is Blackmagic Design’s Pyxis 6K camera, but it only offers basic autofocus capabilities and lacks in-body stabilization. Compared to those options, Nikon’s ZR delivers better dynamic range thanks to the inclusion of RED’s R3D RAW codec. It also comes with an excellent autofocus system and decent in-body stabilization. If you’re a creator looking to get the best video quality for the money without losing those niceties, I’d highly recommend the ZR.This article originally appeared on Engadget at https://www.engadget.com/cameras/nikon-zr-review-a-highly-capable-cinema-camera-at-a-reasonable-price-152634311.html?src=rss",
          "feed_position": 39,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/ab234970-d046-11f0-9a7f-91832eb991a0"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/3Cr8qlWOHQWFuY1M5Z7sib/b1bad43fa7debaf698f5455f5ffcee1a/LLM_confessions.jpg?w=300&q=30",
      "popularity_score": 2019.6637180555556,
      "ai_summary": [
        "OpenAI researchers developed a method to make LLMs self-report errors and violations.",
        "The \"confessions\" technique addresses dishonesty and overconfidence in AI models.",
        "Models generate structured reports after providing answers, evaluating compliance.",
        "The model must list instructions, evaluate satisfaction, and report uncertainties.",
        "The goal is to create a channel where the model is incentivized to be honest."
      ]
    },
    {
      "id": "cluster_69",
      "coverage": 2,
      "updated_at": "Thu, 04 Dec 2025 12:10:01 -0500",
      "title": "Meta launches a centralized support hub for Facebook and Instagram, with AI-powered search and an AI assistant to answer queries, in its iOS and Android apps (Sarah Perez/TechCrunch)",
      "neutral_headline": "Meta launches a centralized support hub for Facebook and Instagram, with AI-powered search and an AI assistant to answer queries, in its iOS and Android apps (Sarah Perez/TechCrunch)",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251204/p34#a251204p34",
          "published_at": "Thu, 04 Dec 2025 12:10:01 -0500",
          "title": "Meta launches a centralized support hub for Facebook and Instagram, with AI-powered search and an AI assistant to answer queries, in its iOS and Android apps (Sarah Perez/TechCrunch)",
          "standfirst": "Sarah Perez / TechCrunch: Meta launches a centralized support hub for Facebook and Instagram, with AI-powered search and an AI assistant to answer queries, in its iOS and Android apps &mdash; Meta is launching a new centralized support hub for Facebook and Instagram users, the company announced on Thursday &hellip;",
          "content": "Sarah Perez / TechCrunch: Meta launches a centralized support hub for Facebook and Instagram, with AI-powered search and an AI assistant to answer queries, in its iOS and Android apps &mdash; Meta is launching a new centralized support hub for Facebook and Instagram users, the company announced on Thursday &hellip;",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/251204/i34.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/04/meta-centralizes-facebook-and-instagram-support-tests-ai-support-assistant/",
          "published_at": "Thu, 04 Dec 2025 17:00:00 +0000",
          "title": "Meta centralizes Facebook and Instagram support, tests AI support assistant",
          "standfirst": "The new support hub will connect users to security tools, account recovery options, and an AI assistant.",
          "content": "The new support hub will connect users to security tools, account recovery options, and an AI assistant.",
          "feed_position": 12
        }
      ],
      "featured_image": "http://www.techmeme.com/251204/i34.jpg",
      "popularity_score": 2013.8306625,
      "ai_summary": [
        "Meta is launching a centralized support hub for Facebook and Instagram users.",
        "The hub will include an AI-powered search function for user queries.",
        "An AI assistant will be available to answer user questions.",
        "The support hub is available within the iOS and Android apps.",
        "Users can access security tools and account recovery options."
      ]
    },
    {
      "id": "cluster_107",
      "coverage": 2,
      "updated_at": "Thu, 04 Dec 2025 11:30:04 +0000",
      "title": "A fentanyl vaccine is about to get its first major test",
      "neutral_headline": "Fentanyl Vaccine to Undergo First Major Test",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/a-fentanyl-vaccine-is-about-to-get-its-first-major-test/",
          "published_at": "Thu, 04 Dec 2025 11:30:04 +0000",
          "title": "A fentanyl vaccine is about to get its first major test",
          "standfirst": "Vaccine trial in the Netherlands hopes to protect against fentanyl-related overdose and death.",
          "content": "Just a tiny amount of fentanyl, the equivalent of a few grains of sand, is enough to stop a person’s breathing. The synthetic opioid is tasteless, odorless, and invisible when mixed with other substances, and drug users are often unaware of its presence. It’s why biotech entrepreneur Collin Gage is aiming to protect people against the drug’s lethal effects. In 2023, he became the cofounder and CEO of ARMR Sciences to develop a vaccine against fentanyl. Now, the company is launching a trial to test its vaccine in people for the first time. The goal: prevent deaths from overdose. “It became very apparent to me that as I assessed the treatment landscape, everything that exists is reactionary,” Gage says. “I thought, why are we not preventing this?”Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2209051218-1152x648.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/a-fentanyl-vaccine-is-about-to-get-its-first-major-test/",
          "published_at": "Wed, 03 Dec 2025 11:30:00 +0000",
          "title": "A Fentanyl Vaccine Is About to Get Its First Major Test",
          "standfirst": "ARMR Sciences of New York is trialing a vaccine in the Netherlands to protect against fentanyl-related overdose and death.",
          "content": "ARMR Sciences of New York is trialing a vaccine in the Netherlands to protect against fentanyl-related overdose and death.",
          "feed_position": 26,
          "image_url": "https://media.wired.com/photos/6909fef5d708e8376d1a521e/master/pass/110425_Fentanyl-Vaccine.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2209051218-1152x648.jpg",
      "popularity_score": 2008.1648291666668,
      "ai_summary": [
        "A fentanyl vaccine is about to undergo its first major clinical trial.",
        "The trial will take place in the Netherlands.",
        "The vaccine aims to protect against fentanyl-related overdoses.",
        "The vaccine is being developed by ARMR Sciences of New York.",
        "The trial hopes to reduce fentanyl-related deaths."
      ]
    },
    {
      "id": "cluster_14",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 21:51:36 +0000",
      "title": "In comedy of errors, men accused of wiping gov databases turned to an AI tool",
      "neutral_headline": "Men Accused of Wiping Databases Used AI Tool",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2025/12/previously-convicted-contractors-wiped-gov-databases-after-being-fired-feds-say/",
          "published_at": "Thu, 04 Dec 2025 21:51:36 +0000",
          "title": "In comedy of errors, men accused of wiping gov databases turned to an AI tool",
          "standfirst": "Defendants were convicted of similar crimes a decade ago. How were they cleared again?",
          "content": "Two sibling contractors convicted a decade ago for hacking into US State Department systems have once again been charged, this time for a comically hamfisted attempt to steal and destroy government records just minutes after being fired from their contractor jobs. The Department of Justice on Thursday said that Muneeb Akhter and Sohaib Akhter, both 34, of Alexandria, Virginia, deleted databases and documents maintained and belonging to three government agencies. The brothers were federal contractors working for an undisclosed company in Washington, DC, that provides software and services to 45 US agencies. Prosecutors said the men coordinated the crimes and began carrying them out just minutes after being fired. Using AI to cover up an alleged crime—what could go wrong? On February 18 at roughly 4:55 pm, the men were fired from the company, according to an indictment unsealed on Thursday. Five minutes later, they allegedly began trying to access their employer’s system and access federal government databases. By then, access to one of the brothers’ accounts had already been terminated. The other brother, however, allegedly accessed a government agency’s database stored on the employer’s server and issued commands to prevent other users from connecting or making changes to the database. Then, prosecutors said, he issued a command to delete 96 databases, many of which contained sensitive investigative files and records related to Freedom of Information Act matters.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/data-theft-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/data-theft-1152x648.jpg",
      "popularity_score": 356.52371805555555,
      "ai_summary": [
        "Men accused of wiping government databases used an AI tool.",
        "The defendants were previously convicted of similar crimes.",
        "The AI tool was used to clear the defendants of the charges.",
        "The case involves a series of errors and missteps.",
        "The details of the AI tool's use are not fully disclosed."
      ]
    },
    {
      "id": "cluster_3",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 22:54:52 +0000",
      "title": "Congress warned that NASA’s current plan for Artemis “cannot work”",
      "neutral_headline": "Congress Warns NASA's Artemis Plan Cannot Work",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/congress-told-there-needs-to-be-consequences-for-nasa-delays-amid-chinas-rise/",
          "published_at": "Thu, 04 Dec 2025 22:54:52 +0000",
          "title": "Congress warned that NASA’s current plan for Artemis “cannot work”",
          "standfirst": "\"The Artemis III mission and those beyond should be canceled.\"",
          "content": "In recent months, it has begun dawning on US lawmakers that, absent significant intervention, China will land humans on the Moon before the United States can return there with the Artemis Program. So far, legislators have yet to take meaningful action on this—a $10 billion infusion into NASA’s budget this summer essentially provided zero funding for efforts needed to land humans on the Moon this decade. But now a subcommittee of the House Committee on Space, Science, and Technology has begun reviewing the space agency’s policy, expressing concerns about Chinese competition in civil spaceflight. During a hearing on Thursday in Washington, DC, the subcommittee members asked a panel of experts how NASA could maintain its global leadership in space over China in general, and more specifically, how to improve the Artemis Program to reach the Moon more quickly.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-2207557317-900x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-2207557317-900x648.jpg",
      "popularity_score": 352.5781625,
      "ai_summary": [
        "Congress has warned NASA about its current Artemis plan.",
        "The warning suggests the Artemis III mission should be canceled.",
        "Further missions beyond Artemis III should also be canceled.",
        "The warning indicates concerns about the program's viability.",
        "The Artemis program aims to return humans to the Moon."
      ]
    },
    {
      "id": "cluster_23",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 20:56:44 +0000",
      "title": "CDC vaccine panel realizes again it has no idea what it’s doing, delays big vote",
      "neutral_headline": "CDC Vaccine Panel Delays Vote Again",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/cdc-vaccine-panel-realizes-again-it-has-no-idea-what-its-doing-delays-big-vote/",
          "published_at": "Thu, 04 Dec 2025 20:56:44 +0000",
          "title": "CDC vaccine panel realizes again it has no idea what it’s doing, delays big vote",
          "standfirst": "Today's meeting was chaotic and included garbage anti-vaccine presentations.",
          "content": "The panel of federal vaccine advisors hand-selected by anti-vaccine Health Secretary Robert F. Kennedy Jr. has once again punted on whether to strip recommendations for hepatitis B vaccinations for newborns—a move it tried to make in September before realizing it didn’t know what it was doing. The decision to delay the vote today came abruptly this afternoon when the panel realized it still does not understand the topic or what it was voting on. Prior to today’s 6–3 vote to delay a decision, there was a swirl of confusion over the wording of what a new recommendation would be. Panel members had gotten three different versions of the proposed recommendation in the 72 hours prior to the meeting, one panelist said. And the meeting’s data presentations this morning offered no clarity on the subject—they were delivered entirely by anti-vaccine activists who have no subject matter expertise and who made a dizzying amount of false and absurd claims. “Completely inappropriate” Overall, the meeting was disorganized and farcical. Kennedy’s panel has abandoned the evidence-based framework for setting vaccine policy in favor of airing unvetted presentations with misrepresentations, conspiracy theories, and cherry-picked studies. At times, there were tense exchanges, chaos, confusion, and misunderstandings.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249270671-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249270671-1152x648.jpg",
      "popularity_score": 335.6092736111111,
      "ai_summary": [
        "The CDC vaccine panel delayed a significant vote.",
        "The meeting included anti-vaccine presentations.",
        "The panel is struggling to make decisions.",
        "The meeting was described as chaotic.",
        "The panel has no clear direction."
      ]
    },
    {
      "id": "cluster_19",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 21:23:40 +0000",
      "title": "Engineer proves that Kohler’s smart toilet cameras aren’t very private",
      "neutral_headline": "Engineer Proves Kohler Smart Toilet Cameras Are Not Private",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/despite-accessing-user-data-kohler-still-says-its-smart-toilet-cameras-use-e2ee/",
          "published_at": "Thu, 04 Dec 2025 21:23:40 +0000",
          "title": "Engineer proves that Kohler’s smart toilet cameras aren’t very private",
          "standfirst": "Kohler is getting the scoop on people's poop.",
          "content": "Kohler is facing backlash after an engineer pointed out that the company’s new smart toilet cameras may not be as private as it wants people to believe. The discussion raises questions about Kohler’s use of the term “end-to-end encryption” (E2EE) and the inherent privacy limitations of a device that films the goings-on of a toilet bowl. In October, Kohler announced its first “health” product, the Dekoda. Kohler’s announcement described the $599 device (it also requires a subscription that starts at $7 per month) as a toilet bowl attachment that uses “optical sensors and validated machine-learning algorithms” to deliver “valuable insights into your health and wellness.” The announcement added: Data flows to the personalized Kohler Health app, giving users continuous, private awareness of key health and wellness indicators—right on their phone. Features like fingerprint authentication and end-to-end encryption are designed for user privacy and security. The average person is most likely to be familiar with E2EE through messaging apps, like Signal. Messages sent via apps with E2EE are encrypted throughout transmission. Only the message’s sender and recipient can view the decrypted messages, which is intended to prevent third parties, including the app developer, from reading them.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/fa9752cdfabfc67f2acd9bfdf4f195ecfdad5f05-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/fa9752cdfabfc67f2acd9bfdf4f195ecfdad5f05-1152x648.jpg",
      "popularity_score": 331.0581625,
      "ai_summary": [
        "An engineer demonstrated that Kohler's smart toilet cameras are not private.",
        "The cameras collect data on users' bowel movements.",
        "Kohler is able to access the data collected by the cameras.",
        "The findings raise privacy concerns about the smart toilet.",
        "The engineer's findings highlight data security issues."
      ]
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 20:07:20 +0000",
      "title": "Researchers find what makes AI chatbots politically persuasive",
      "neutral_headline": "Researchers Find AI Chatbots Have Weak Political Effect",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/researchers-find-what-makes-ai-chatbots-politically-persuasive/",
          "published_at": "Thu, 04 Dec 2025 20:07:20 +0000",
          "title": "Researchers find what makes AI chatbots politically persuasive",
          "standfirst": "A massive study of political persuasion shows AIs have, at best, a weak effect.",
          "content": "Roughly two years ago, Sam Altman tweeted that AI systems would be capable of superhuman persuasion well before achieving general intelligence—a prediction that raised concerns about the influence AI could have over democratic elections. To see if conversational large language models can really sway political views of the public, scientists at the UK AI Security Institute, MIT, Stanford, Carnegie Mellon, and many other institutions performed by far the largest study on AI persuasiveness to date, involving nearly 80,000 participants in the UK. It turned out political AI chatbots fell far short of superhuman persuasiveness, but the study raises some more nuanced issues about our interactions with AI. AI dystopias The public debate about the impact AI has on politics has largely revolved around notions drawn from dystopian sci-fi. Large language models have access to essentially every fact and story ever published about any issue or candidate. They have processed information from books on psychology, negotiations, and human manipulation. They can rely on absurdly high computing power in huge data centers worldwide. On top of that, they can often access tons of personal information about individual users thanks to hundreds upon hundreds of online interactions at their disposal.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/09/twitter-bot-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/09/twitter-bot-1152x648.jpg",
      "popularity_score": 324.7859402777778,
      "ai_summary": [
        "Researchers studied the political persuasion of AI chatbots.",
        "The study found AI chatbots have a weak effect on persuasion.",
        "The study was a large-scale investigation of political influence.",
        "The findings suggest limited impact on political opinions.",
        "The study examined the effectiveness of AI in political contexts."
      ]
    },
    {
      "id": "cluster_49",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 18:40:36 +0000",
      "title": "ChatGPT hyped up violent stalker who believed he was “God’s assassin,” DOJ says",
      "neutral_headline": "ChatGPT hyped up violent stalker who believed he was “God’s assassin,” DOJ says: Podcaster faces up to 70 years and a $3.5 million fine for ChatGPT-linked stalking",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/chatgpt-hyped-up-violent-stalker-who-believed-he-was-gods-assassin-doj-says/",
          "published_at": "Thu, 04 Dec 2025 18:40:36 +0000",
          "title": "ChatGPT hyped up violent stalker who believed he was “God’s assassin,” DOJ says",
          "standfirst": "Podcaster faces up to 70 years and a $3.5 million fine for ChatGPT-linked stalking.",
          "content": "ChatGPT allegedly validated the worst impulses of a wannabe influencer accused of stalking more than 10 women at boutique gyms, where the chatbot supposedly claimed he’d meet the “wife type.” In a press release on Tuesday, the Department of Justice confirmed that 31-year-old Brett Michael Dadig currently remains in custody after being charged with cyberstalking, interstate stalking, and making interstate threats. He now faces a maximum sentence of up to 70 years in prison that could be coupled with “a fine of up to $3.5 million,” the DOJ said. The podcaster—who primarily posted about “his desire to find a wife and his interactions with women”—allegedly harassed and sometimes even doxxed his victims through his videos on platforms including Instagram, Spotify, and TikTok. Over time, his videos and podcasts documented his intense desire to start a family, which was frustrated by his “anger towards women,” whom he claimed were “all the same from fucking 18 to fucking 40 to fucking 90” and “trash.”Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2233803629-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2233803629-1152x648.jpg",
      "popularity_score": 309.3403847222222,
      "ai_summary": [
        "A podcaster is facing charges related to ChatGPT-linked stalking.",
        "The Department of Justice is involved in the case.",
        "The podcaster could face up to 70 years in prison.",
        "A fine of $3.5 million is also possible.",
        "ChatGPT was used to encourage violent behavior."
      ]
    },
    {
      "id": "cluster_35",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 19:53:14 +0000",
      "title": "Why won’t Steam Machine support HDMI 2.1? Digging in on the display standard drama.",
      "neutral_headline": "Steam Machine Display Standard Drama",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/12/why-wont-steam-machine-support-hdmi-2-1-digging-in-on-the-display-standard-drama/",
          "published_at": "Thu, 04 Dec 2025 19:53:14 +0000",
          "title": "Why won’t Steam Machine support HDMI 2.1? Digging in on the display standard drama.",
          "standfirst": "Valve tells Ars its \"trying to unblock\" limits caused by open source driver issues.",
          "content": "When Valve announced its upcoming Steam Machine hardware last month, some eagle-eyed gamers may have been surprised to see that the official spec sheet lists support for HDMI 2.0 output, rather than the updated, higher-bandwidth HDMI 2.1 standard introduced in 2017. Now, Valve tells Ars that, while the hardware itself actually supports HDMI 2.1, the company is struggling to offer full support for that standard due to Linux drivers that are “still a work-in-progress on the software side.” As we noted last year, the HDMI Forum (which manages the official specifications for HDMI standards) has officially blocked any open source implementation of HDMI 2.1. That means the open source AMD drivers used by SteamOS can’t fully implement certain features that are specific to the updated output standard. “At this time an open source HDMI 2.1 implementation is not possible without running afoul of the HDMI Forum requirements,” AMD engineer Alex Deucher said at the time.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/sm1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/sm1-1152x648.jpg",
      "popularity_score": 299.5509402777778,
      "ai_summary": [
        "Valve is facing issues with HDMI 2.1 support on Steam Machines.",
        "The issue is related to open-source driver problems.",
        "Valve is working to resolve the display standard limitations.",
        "The limitations are causing display standard drama.",
        "The issue affects the display capabilities of the device."
      ]
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 18:11:41 +0000",
      "title": "OnePlus 15 finally gets FCC clearance after government shutdown delay—preorders live",
      "neutral_headline": "OnePlus 15 Receives FCC Clearance",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/oneplus-15-finally-gets-fcc-clearance-after-government-shutdown-delay-preorders-live/",
          "published_at": "Thu, 04 Dec 2025 18:11:41 +0000",
          "title": "OnePlus 15 finally gets FCC clearance after government shutdown delay—preorders live",
          "standfirst": "The device starts at $900 and comes with a free gift for a limited time.",
          "content": "OnePlus is ready to sell its new flagship smartphone in the US weeks after it made the device official. Having now finally gotten Federal Communications Commission clearance, the OnePlus 15 is available for preorder. It’s currently only live on the OnePlus storefront, but the device will eventually come to Amazon and Best Buy as well. The OnePlus 15 launched in China earlier this year, and it was supposed to go on sale in the US a month ago. However, the longest US government shutdown on record got in the way. Most of the FCC’s functions were suspended during the weekslong funding lapse, which prevented the agency from certifying new wireless products. Without that approval, OnePlus could not begin selling the phone. Thus, it had no firm release date when the phone was officially unveiled for the US in early November. Interested parties can head to the OnePlus website to place an order. The base model starts at $900 with 12GB of RAM and 256GB of storage. This version is only available in black. If you want the Ultraviolet or Sand Storm (with the distinctive micro-arc oxidation finish), you’ll have to upgrade to the $1,000 version, which has 16GB of RAM and 512GB of storage.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/OnePlus-15-5-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/OnePlus-15-5-1152x648.jpg",
      "popularity_score": 277.8584402777778,
      "ai_summary": [
        "The OnePlus 15 has received FCC clearance.",
        "Preorders for the device are now live.",
        "The device starts at a price of $900.",
        "A free gift is offered for a limited time.",
        "The government shutdown delayed the clearance."
      ]
    },
    {
      "id": "cluster_58",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 17:59:38 +0000",
      "title": "In 1995, a Netscape employee wrote a hack in 10 days that now runs the Internet",
      "neutral_headline": "JavaScript Turns Thirty Years Old",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/in-1995-a-netscape-employee-wrote-a-hack-in-10-days-that-now-runs-the-internet/",
          "published_at": "Thu, 04 Dec 2025 17:59:38 +0000",
          "title": "In 1995, a Netscape employee wrote a hack in 10 days that now runs the Internet",
          "standfirst": "Thirty years later, JavaScript is the glue that holds the interactive web together, warts and all.",
          "content": "Thirty years ago today, Netscape Communications and Sun Microsystems issued a joint press release announcing JavaScript, an object scripting language designed for creating interactive web applications. The language emerged from a frantic 10-day sprint at pioneering browser company Netscape, where engineer Brendan Eich hacked together a working internal prototype during May 1995. While the JavaScript language didn’t ship publicly until that September and didn’t reach a 1.0 release until March 1996, the descendants of Eich’s initial 10-day hack now run on approximately 98.9 percent of all websites with client-side code, making JavaScript the dominant programming language of the web. It’s wildly popular; beyond the browser, JavaScript powers server backends, mobile apps, desktop software, and even some embedded systems. According to several surveys, JavaScript consistently ranks among the most widely used programming languages in the world. In crafting JavaScript, Netscape wanted a scripting language that could make webpages interactive, something lightweight that would appeal to web designers and non-professional programmers. Eich drew from several influences: The syntax looked like a trendy new programming language called Java to satisfy Netscape management, but its guts borrowed concepts from Scheme, a language Eich admired, and Self, which contributed JavaScript’s prototype-based object model.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/netscape_logo_header_3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/netscape_logo_header_3-1152x648.jpg",
      "popularity_score": 277.65760694444447,
      "ai_summary": [
        "A Netscape employee wrote JavaScript in 10 days in 1995.",
        "JavaScript is the glue of the interactive web.",
        "The language holds the interactive web together.",
        "JavaScript has been in use for thirty years.",
        "The language has warts but is still essential."
      ]
    },
    {
      "id": "cluster_81",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 16:16:46 +0000",
      "title": "Welcome to “necroprinting”—3D printer nozzle made from mosquito’s proboscis",
      "neutral_headline": "Mosquito Proboscis Used for 3D Printer Nozzle",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/welcome-to-necroprinting-3d-printer-nozzle-made-from-mosquitos-proboscis/",
          "published_at": "Thu, 04 Dec 2025 16:16:46 +0000",
          "title": "Welcome to “necroprinting”—3D printer nozzle made from mosquito’s proboscis",
          "standfirst": "They're quite a bit cheaper than manufactured nozzles if you can dissect them.",
          "content": "Necrobotics is a field of engineering that builds robots out of a mix of synthetic materials and animal body parts. It has produced micro-grippers with pneumatically operated legs taken from dead spiders and walking robots based on deceased cockroaches. “These necrobotics papers inspired us to build something different,” said Changhong Cao, a mechanical engineering professor at the McGill University in Montreal, Canada. Cao’s team didn’t go for a robot—instead, it adapted a female mosquito proboscis to work as a nozzle in a super-precise 3D printer. And it worked surprisingly well. Fangs and stings To find the right nozzle for their 3D necroprinting system, Cao’s team began with a broad survey of natural micro-dispensing tips. The researchers examined stingers of bees, wasps, and scorpions; the fangs of venomous snakes; and the claws of centipedes. All of those evolved to deliver a fluid to the target, which is roughly what a 3D printer’s nozzle does. But they all had issues. “Some were too curved and curved for high-precision 3D printing,” Cao explained. “Also, they were optimized for delivering pulses of venom, not for a steady, continuous flow, which is what you need for printing.”Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2065922040-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2065922040-1152x648.jpg",
      "popularity_score": 255.9431625,
      "ai_summary": [
        "Researchers are using mosquito proboscises for 3D printer nozzles.",
        "The nozzles are made from the mosquito's proboscis.",
        "The nozzles are cheaper than manufactured alternatives.",
        "The nozzles are used in 3D printing applications.",
        "The nozzles are created by dissecting the proboscis."
      ]
    },
    {
      "id": "cluster_104",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 12:00:42 +0000",
      "title": "The NPU in your phone keeps improving—why isn’t that making AI better?",
      "neutral_headline": "Phone AI improvements do not always translate to better AI",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/the-npu-in-your-phone-keeps-improving-why-isnt-that-making-ai-better/",
          "published_at": "Thu, 04 Dec 2025 12:00:42 +0000",
          "title": "The NPU in your phone keeps improving—why isn’t that making AI better?",
          "standfirst": "Shrinking AI for your phone is no simple matter.",
          "content": "Almost every technological innovation of the past several years has been laser-focused on one thing: generative AI. Many of these supposedly revolutionary systems run on big, expensive servers in a data center somewhere, but at the same time, chipmakers are crowing about the power of the neural processing units (NPU) they have brought to consumer devices. Every few months, it’s the same thing: This new NPU is 30 or 40 percent faster than the last one. That’s supposed to let you do something important, but no one really gets around to explaining what that is. Experts envision a future of secure, personal AI tools with on-device intelligence, but does that match the reality of the AI boom? AI on the “edge” sounds great, but almost every AI tool of consequence is running in the cloud. So what’s that chip in your phone even doing? What is an NPU? Companies launching a new product often get bogged down in superlatives and vague marketing speak, so they do a poor job of explaining technical details. It’s not clear to most people buying a phone why they need the hardware to run AI workloads, and the supposed benefits are largely theoretical.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/npu_phone-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/npu_phone-1152x648.jpg",
      "popularity_score": 156.67538472222222,
      "ai_summary": [
        "AI on phones is improving, but it is not making AI better overall.",
        "Shrinking AI for phones is a complex process with many challenges.",
        "The article explores the difficulties of optimizing AI for mobile devices.",
        "It examines the trade-offs involved in balancing performance and efficiency.",
        "The article discusses the limitations of current mobile AI technology."
      ]
    },
    {
      "id": "cluster_118",
      "coverage": 1,
      "updated_at": "Wed, 03 Dec 2025 23:16:03 +0000",
      "title": "Admins and defenders gird themselves against maximum-severity server vuln",
      "neutral_headline": "Server vulnerability allows malicious code execution",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/12/admins-and-defenders-gird-themselves-against-maximum-severity-server-vulnerability/",
          "published_at": "Wed, 03 Dec 2025 23:16:03 +0000",
          "title": "Admins and defenders gird themselves against maximum-severity server vuln",
          "standfirst": "Open source React executes malicious code with malformed HTML—no authentication needed.",
          "content": "Security defenders are girding themselves in response to the disclosure of a maximum-severity vulnerability disclosed Wednesday in React Server, an open-source package that’s widely used by websites and in cloud environments. The vulnerability is easy to exploit and allows hackers to execute malicious code on servers that run it. Exploit code is now publicly available. React is embedded into web apps running on servers so that remote devices render JavaScript and content more quickly and with fewer resources required. React is used by an estimated 6 percent of all websites and 39 percent of cloud environments. When end users reload a page, React allows servers to re-render only parts that have changed, a feature that drastically speeds up performance and lowers the computing resources required by the server.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security-1.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security-1.jpg",
      "popularity_score": 154,
      "ai_summary": [
        "Open source React allows malicious code execution with malformed HTML.",
        "No authentication is needed to exploit the vulnerability.",
        "Admins and defenders are preparing for potential attacks.",
        "The vulnerability poses a maximum-severity threat to servers.",
        "The article highlights the importance of patching and security updates."
      ]
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 15:28:08 +0000",
      "title": "Trump wants tiny Japanese-style cars for US even as he cuts mpg goals",
      "neutral_headline": "Trump proposes Japanese-style cars while cutting fuel goals",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/12/trump-wants-tiny-japanese-style-cars-for-us-even-as-he-cuts-mpg-goals/",
          "published_at": "Thu, 04 Dec 2025 15:28:08 +0000",
          "title": "Trump wants tiny Japanese-style cars for US even as he cuts mpg goals",
          "standfirst": "Even the first Trump administration had tougher fuel economy targets.",
          "content": "It’s been less than a year into the second Trump administration, and to many outside observers, US government policies appear confusing or incoherent. Yesterday provided a good example from the automotive sector. As has been widely expected, the White House is moving ahead with plans to significantly erode fuel economy standards, beyond even the permissive levels that were considered OK during the first Trump term. Yet at the very announcement of that rollback, surrounded by compliant US automotive executives, the president decided to go off piste to declare his admiration for tiny Japanese Kei cars, telling Transportation Secretary Sean Duffy to make them street-legal in the US. 50.4 mpg 40.4 mpg 34.5 mpg A little over a decade ago, the Obama administration announced new fuel economy standards for light trucks and cars that were meant to go into effect this year, bringing the corporate fleet fuel economy average up to 50.4 mpg. As you can probably tell, that didn’t happen. It wasn’t a popular move with automakers, and the first Trump administration ripped up those rules and instituted new, weaker targets of just 40.4 mpg by 2026.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2234137052-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2234137052-1152x648.jpg",
      "popularity_score": 151.13260694444443,
      "ai_summary": [
        "Trump wants small Japanese-style cars for the United States.",
        "He is simultaneously cutting fuel economy goals.",
        "The first Trump administration had stricter fuel economy targets.",
        "The article discusses the apparent contradiction in his proposals.",
        "It examines the potential impact on vehicle emissions and efficiency."
      ]
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Wed, 03 Dec 2025 21:06:34 +0000",
      "title": "Republicans drop Trump-ordered block on state AI laws from defense bill",
      "neutral_headline": "Republicans drop Trump's block on state AI laws",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/republicans-once-again-thwart-trumps-push-to-block-state-ai-laws/",
          "published_at": "Wed, 03 Dec 2025 21:06:34 +0000",
          "title": "Republicans drop Trump-ordered block on state AI laws from defense bill",
          "standfirst": "“Widespread and powerful movement” keeps Trump from blocking state AI laws.",
          "content": "A Donald Trump-backed push has failed to wedge a federal measure that would block states from passing AI laws for a decade into the National Defense Authorization Act (NDAA). House Majority Leader Steve Scalise (R-La.) told reporters Tuesday that a sect of Republicans is now “looking at other places” to potentially pass the measure. Other Republicans opposed including the AI preemption in the defense bill, The Hill reported, joining critics who see value in allowing states to quickly regulate AI risks as they arise. For months, Trump has pressured the Republican-led Congress to block state AI laws that the president claims could bog down innovation as AI firms waste time and resources complying with a patchwork of state laws. But Republicans have continually failed to unite behind Trump’s command, first voting against including a similar measure in the “Big Beautiful” budget bill and then this week failing to negotiate a solution to pass the NDAA measure.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2238395456-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2238395456-1024x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Republicans removed Trump's block on state AI laws from defense bill.",
        "A \"widespread and powerful movement\" prevented the block.",
        "The article details the political maneuvering involved.",
        "It highlights the importance of state-level AI regulations.",
        "The article discusses the implications for AI development."
      ]
    },
    {
      "id": "cluster_91",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 15:08:39 +0000",
      "title": "Lego announces NASA Artemis SLS rocket set to lift off (literally) in 2026",
      "neutral_headline": "Lego announces NASA Artemis SLS rocket set for 2026",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/lego-announces-nasa-artemis-sls-rocket-set-to-lift-off-literally-in-2026/",
          "published_at": "Thu, 04 Dec 2025 15:08:39 +0000",
          "title": "Lego announces NASA Artemis SLS rocket set to lift off (literally) in 2026",
          "standfirst": "Developed with NASA and ESA, the 632-piece kit comes out Jan. 1.",
          "content": "How do you top a highly detailed scale model of NASA’s new moon-bound rocket and its support tower? If you’re Lego, you make it so it can actually lift off. Lego’s NASA Artemis Space Launch System Rocket, part of its Technic line of advanced building sets, will land on store shelves for $60 on January 1, 2026, and then “blast off” from kitchen tables, office desks and living room floors. The 632-piece set climbs skyward, separating from its expendable stages along the way, until the Orion crew spacecraft and its European Service Module top out the motion on their way to the moon—or wherever your imagination carries it. “The educational LEGO Technic set shows the moment a rocket launches, in three distinct stages,” reads the product description on Lego’s website. “Turn the crank to see the solid rocket boosters separate from the core stage, which then also detaches. Continue turning to watch the upper stage with its engine module, Orion spacecraft and launch abort system separate.”Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/news-120225b-lg-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/news-120225b-lg-1152x648.jpg",
      "popularity_score": 144.8078847222222,
      "ai_summary": [
        "Lego is releasing a NASA Artemis SLS rocket set.",
        "The set is developed with NASA and ESA.",
        "The kit contains 632 pieces.",
        "It will be available starting January 1.",
        "The article details the features of the new Lego set."
      ]
    },
    {
      "id": "cluster_119",
      "coverage": 1,
      "updated_at": "Wed, 03 Dec 2025 23:01:26 +0000",
      "title": "Great handling, advanced EV tech: We drive the 2027 BMW iX3",
      "neutral_headline": "BMW iX3 drive reveals great handling and EV tech",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/12/great-handling-advanced-ev-tech-we-drive-the-2026-bmw-ix3/",
          "published_at": "Wed, 03 Dec 2025 23:01:26 +0000",
          "title": "Great handling, advanced EV tech: We drive the 2027 BMW iX3",
          "standfirst": "The first of BMW's clean-sheet \"Neue Klasse\" EVs hits it out of the park.",
          "content": "BMW provided flights from Washington, DC, to Malaga, Spain, and accommodation so Ars could drive the iX3. Ars does not accept paid editorial content. The new BMW iX3 is an important car for the automaker. It’s the first of a new series of vehicles that BMW is calling the Neue Klasse, calling back to a range of cars that helped define the brand in the 1960s. Then, as now, propulsion is provided by the best powertrain BMW’s engineers could design and build, wrapped in styling that heralds the company’s new look. Except now, that powertrain is fully electric, and the cabin features technology that would have been scarcely believable to the driver of a new 1962 BMW 1500. In fact, the iX3 is only half the story when it comes to BMW’s neue look for the Neue Klasse—there’s an all-electric 3 series sedan on the way, too. The sedan will surely appeal to enthusiasts, particularly the version that the M tuning arm has worked its magic upon, but you’ll have to wait until early 2026 to read about that stuff. Which makes sense: crossovers and SUVs—or “sports activity vehicles” in BMW-speak—are what the market wants these days, so that’s what comes first. The technical stuff As we learned earlier this summer, BMW leaned heavily into sustainability when it designed the iX3. There’s extensive use of recycled battery minerals, interior plastics, and aluminum, and the automaker has gone for a monomaterial approach where possible to make recycling the car a lot easier. There’s also an all-new EV powertrain, BMW’s sixth-generation. When it goes on sale here next summer, the launch model will be the iX3 50 xDrive, which pairs an asynchronous motor at the front axle and an electrically excited synchronous motor at the rear for a combined output of 463 hp (345 kW) and 475 lb-ft (645 Nm).Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/BMW-iX3-50-xDrive-Spacesilver-061-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/BMW-iX3-50-xDrive-Spacesilver-061-1152x648.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "The 2027 BMW iX3 offers great handling and advanced EV technology.",
        "It is the first of BMW's \"Neue Klasse\" EVs.",
        "The article provides a review of the vehicle's performance.",
        "It highlights the innovative features of the new EV.",
        "The article discusses the future of BMW's electric vehicle lineup."
      ]
    },
    {
      "id": "cluster_115",
      "coverage": 1,
      "updated_at": "Thu, 04 Dec 2025 00:06:58 +0000",
      "title": "12 former FDA chiefs unite to say agency memo on vaccines is deeply stupid",
      "neutral_headline": "Former FDA chiefs criticize agency memo on vaccines",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/12-former-fda-chiefs-unite-to-say-agency-memo-on-vaccines-is-deeply-stupid/",
          "published_at": "Thu, 04 Dec 2025 00:06:58 +0000",
          "title": "12 former FDA chiefs unite to say agency memo on vaccines is deeply stupid",
          "standfirst": "Prasad's arguments \"misrepresent both the science and the regulatory record.\"",
          "content": "On Friday, Vinay Prasad—the Food and Drug Administration’s chief medical and scientific officer and its top vaccine regulator—emailed a stunning memo to staff that quickly leaked to the press. Without evidence, Prasad claimed COVID-19 vaccines have killed 10 children in the US, and, as such, he announced unilateral, sweeping changes to the way the agency regulates and approves vaccines, including seasonal flu shots. On Wednesday evening, a dozen former FDA commissioners, who collectively oversaw the agency for more than 35 years, responded to the memo with a scathing rebuke. Uniting to publish their response in the New England Journal of Medicine, the former commissioners said they were “deeply concerned” by Prasad’s memo, which they framed as a “threat” to the FDA’s work and a danger to Americans’ health. In his memo, Prasad called for abandoning the FDA’s current framework for updating seasonal flu shots and other vaccines, such as those for COVID-19. Those updates currently involve studies that measure well-characterized immune responses (called immunobridging studies). Prasad dismissed this approach as insufficient and, instead, plans to require expensive randomized trials, which can take months to years for each vaccine update.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/07/GettyImages-1403288381-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/07/GettyImages-1403288381-1152x648.jpeg",
      "popularity_score": 133,
      "ai_summary": [
        "Twelve former FDA chiefs criticize an agency memo on vaccines.",
        "They state the memo is \"deeply stupid.\"",
        "Prasad's arguments misrepresent science and regulatory record.",
        "The article details the disagreement among former officials.",
        "It discusses the implications for vaccine policy and public trust."
      ]
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Wed, 03 Dec 2025 20:40:42 +0000",
      "title": "Humans in southern Africa were an isolated population until recently",
      "neutral_headline": "Southern Africa humans were isolated until recently",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/ancient-genomes-from-southern-africa-reveal-distinct-human-lineage/",
          "published_at": "Wed, 03 Dec 2025 20:40:42 +0000",
          "title": "Humans in southern Africa were an isolated population until recently",
          "standfirst": "A distinct population that was isolated until the last thousand years or so.",
          "content": "The fossil and genetic evidence agree that modern humans originated in Africa. The most genetically diverse human populations—the groups that have had the longest time to pick up novel mutations—live there today. But the history of what went on within Africa between our origins and the present day is a bit murky. That’s partly because DNA doesn’t survive long in the conditions typical of most of the continent, which has largely limited us to trying to reconstruct the past using data from present-day populations. The other part is that many of those present-day populations have been impacted by the vast genetic churn caused by the Bantu expansion, which left its traces across most of the populations south of the Sahara. But a new study has managed to extract genomes from ancient samples in southern Africa. While all of these are relatively recent, dating from after the end of the most recent glacial period, they reveal a distinct southern African population that was relatively large, outside of the range of previously described human variation, and it remained isolated until only about 1,000 years ago.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-940753366-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-940753366-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Humans in southern Africa were isolated until recently.",
        "A distinct population existed until the last thousand years.",
        "The article discusses the genetic history of the region.",
        "It explores the implications for human migration patterns.",
        "The article examines the findings of recent research."
      ]
    },
    {
      "id": "cluster_129",
      "coverage": 1,
      "updated_at": "Wed, 03 Dec 2025 19:48:47 +0000",
      "title": "After nearly 30 years, Crucial will stop selling RAM to consumers",
      "neutral_headline": "Crucial will stop selling RAM to consumers after 30 years",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/after-nearly-30-years-crucial-will-stop-selling-ram-to-consumers/",
          "published_at": "Wed, 03 Dec 2025 19:48:47 +0000",
          "title": "After nearly 30 years, Crucial will stop selling RAM to consumers",
          "standfirst": "Micron cites AI data center demand as reason for killing DIY upgrade brand.",
          "content": "On Wednesday, Micron Technology announced it will exit the consumer RAM business in 2026, ending 29 years of selling RAM and SSDs to PC builders and enthusiasts under the Crucial brand. The company cited heavy demand from AI data centers as the reason for abandoning its consumer brand, a move that will remove one of the most recognizable names in the do-it-yourself PC upgrade market. “The AI-driven growth in the data center has led to a surge in demand for memory and storage,” Sumit Sadana, EVP and chief business officer at Micron Technology, said in a statement. “Micron has made the difficult decision to exit the Crucial consumer business in order to improve supply and support for our larger, strategic customers in faster-growing segments.” Micron said it will continue shipping Crucial consumer products through the end of its fiscal second quarter in February 2026 and will honor warranties on existing products. The company will continue selling Micron-branded enterprise products to commercial customers and plans to redeploy affected employees to other positions within the company.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/crucial_ram_header-1080x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/crucial_ram_header-1080x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Crucial will stop selling RAM to consumers.",
        "Micron cites AI data center demand as the reason.",
        "The DIY upgrade brand is being discontinued.",
        "The article discusses the changing market for RAM.",
        "It examines the impact on consumers and the industry."
      ]
    }
  ]
}