{
  "updated_at": "2025-10-22T11:17:37.467Z",
  "clusters": [
    {
      "id": "cluster_66",
      "coverage": 3,
      "updated_at": "Tue, 21 Oct 2025 19:06:41 +0000",
      "title": "OpenAI’s Atlas Browser Takes Direct Aim at Google Chrome",
      "neutral_headline": "OpenAI’s Atlas Browser Takes Direct Aim at Google Chrome: The new ChatGPT-powered web browser is OpenAI’s boldest play yet to reinvent how people use the web",
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/openai-atlas-browser-chrome-agents-web-browsing/",
          "published_at": "Tue, 21 Oct 2025 19:06:41 +0000",
          "title": "OpenAI’s Atlas Browser Takes Direct Aim at Google Chrome",
          "standfirst": "The new ChatGPT-powered web browser is OpenAI’s boldest play yet to reinvent how people use the web.",
          "content": "The new ChatGPT-powered web browser is OpenAI’s boldest play yet to reinvent how people use the web.",
          "feed_position": 12,
          "image_url": "https://media.wired.com/photos/68f7cbcc6fc0dea09153cfd9/master/pass/business_openai_browser.jpg"
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/is-openais-atlas-browser-the-chrome-killer-weve-been-waiting-for-try-it-for-yourself/",
          "published_at": "Tue, 21 Oct 2025 18:10:00 GMT",
          "title": "Is OpenAI's Atlas browser the Chrome killer we've been waiting for? Try it for yourself",
          "standfirst": "Here's everything OpenAI's ChatGPT-powered browser can do, and how to access it.",
          "content": "Here's everything OpenAI's ChatGPT-powered browser can do, and how to access it.",
          "feed_position": 18
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/21/openai-launches-an-ai-powered-browser-chatgpt-atlas/",
          "published_at": "Tue, 21 Oct 2025 17:15:40 +0000",
          "title": "OpenAI launches an AI-powered browser: ChatGPT Atlas",
          "standfirst": "OpenAI is launching an AI-powered browser, its latest challenge to Google as the main way people find information online.",
          "content": "OpenAI is launching an AI-powered browser, its latest challenge to Google as the main way people find information online.",
          "feed_position": 12
        }
      ],
      "featured_image": "https://media.wired.com/photos/68f7cbcc6fc0dea09153cfd9/master/pass/business_openai_browser.jpg",
      "popularity_score": 3003.8176480555558,
      "ai_summary": [
        "OpenAI is launching an AI-powered browser called Atlas.",
        "The browser aims to challenge Google Chrome's dominance.",
        "Atlas is designed to reinvent web usage.",
        "The browser is powered by ChatGPT.",
        "This is OpenAI's latest challenge to Google."
      ]
    },
    {
      "id": "cluster_17",
      "coverage": 2,
      "updated_at": "Wed, 22 Oct 2025 09:30:32 GMT",
      "title": "The best Android VPN services of 2025: Expert tested and reviewed",
      "neutral_headline": "Best Android and Smart TV VPN Services Reviewed",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/best-android-vpn/",
          "published_at": "Wed, 22 Oct 2025 09:30:32 GMT",
          "title": "The best Android VPN services of 2025: Expert tested and reviewed",
          "standfirst": "Installing a VPN on your Android smartphone gives you more privacy and peace of mind. These are the best Android VPNs around.",
          "content": "Installing a VPN on your Android smartphone gives you more privacy and peace of mind. These are the best Android VPNs around.",
          "feed_position": 2
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/best-smart-tv-vpns/",
          "published_at": "Wed, 22 Oct 2025 09:00:46 GMT",
          "title": "The best smart TV VPNs of 2025: Expert tested and reviewed",
          "standfirst": "Ever considered using a VPN on your smart TV? There are plenty of benefits. Here's our top recommendations and why you should try them.",
          "content": "Ever considered using a VPN on your smart TV? There are plenty of benefits. Here's our top recommendations and why you should try them.",
          "feed_position": 4
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/gallery/best-vpn/",
          "published_at": "Mon, 20 Oct 2025 13:00:00 +0000",
          "title": "6 Best VPN Services (2025), Tested and Reviewed",
          "standfirst": "Every VPN says it’s the best, but only some of them are telling the truth.",
          "content": "Every VPN says it’s the best, but only some of them are telling the truth.",
          "feed_position": 35,
          "image_url": "https://media.wired.com/photos/68c88e3fadc88e6a8852f302/master/pass/nordvpn.png"
        }
      ],
      "featured_image": "https://media.wired.com/photos/68c88e3fadc88e6a8852f302/master/pass/nordvpn.png",
      "popularity_score": 2018.2151480555556,
      "ai_summary": [
        "ZDNet reviewed the best Android VPN services, focusing on privacy and security features.",
        "ZDNet also reviewed the best smart TV VPNs, highlighting their benefits and recommendations.",
        "Wired Tech provided a review of the best VPN services, testing and comparing various options.",
        "The reviews aim to help users choose VPNs that meet their specific needs and requirements.",
        "The articles offer expert insights and recommendations for choosing the right VPN."
      ]
    },
    {
      "id": "cluster_20",
      "coverage": 2,
      "updated_at": "Wed, 22 Oct 2025 09:00:37 +0000",
      "title": "The best wireless headphones for 2025: Bluetooth options for every budget",
      "neutral_headline": "Best Wireless Headphones for 2025: Bluetooth Options",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html",
          "published_at": "Wed, 22 Oct 2025 09:00:37 +0000",
          "title": "The best wireless headphones for 2025: Bluetooth options for every budget",
          "standfirst": "Wireless headphones have come a long way from the bulky designs of the past. Today’s models are lighter, smarter and packed with features that make them useful for everything from travel to long workdays at your desk. Many offer strong noise cancellation, quick pairing and reliable battery life — all of which makes them an easy upgrade if you want more freedom from your devices.Of course, not every listener has the same needs. Some people want portability, which is why our guide to the best earbuds is worth a look, while others want something more specialized like the best gaming headsets or the best budget earbuds. But if you’re after over-ear headphones that focus on comfort and immersive sound, this roundup of the best wireless headphones highlights the top choices we’ve tested. Table of contents Best wireless headphones for 2025 How to choose the best wireless headphones for you How we test over-ear headphones Other wireless headphones we tested Wireless headphones FAQs Best wireless headphones for 2025 How to choose the best wireless headphones for you When it comes to shopping for a good pair of wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of our buyer’s guide, we focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear designs are much more effective at blocking sound. Speaking of noise cancellation, you’ll want to determine early on if you even want that. If you frequently crank up the beats in noisy environments, you’ll want to not only make sure it’s there, but also make sure it’s good, preferably with adaptive ANC. If you plan to use your new headphones in quieter spaces, skipping ANC can save you some money. The next area to consider is features. We recommend trying to get the most bang for your buck, but as you’re shopping around you should determine which items are must-haves and what you can live without. And don’t take basic things like automatic pausing and Bluetooth multipoint connectivity for granted, as not all companies include them. We also suggest reading reviews to see how well a company’s more advanced features work. This will help you decide if those are something you’re willing to (likely) pay extra for. Keep an eye on better battery life estimates to avoid disappointment, as some manufacturers promise more hours than real-world testing delivers. And don’t be easily swayed by lofty promises about call quality without verifying them. Sound can be subjective, so we recommend trying before you buy if at all possible. We understand this isn’t easy at a time when we’re doing most of our shopping online. But trying on a set of headphones and listening to them for a few minutes can save you from an expensive case of buyer’s remorse. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all headphones support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you. If you plan to use your headphones for other media besides music, checking for latency is also a must — some delay can impact playback for things like movies or games, even if most true wireless headphones now offer minimal lag. How we test over-ear headphones The primary way we test wireless headphones is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for headphones can be 30 hours or more, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, we’ll typically power the headphones off several times and leave them during a review. This simulates real-world use and keeps us from having to constantly monitor the process for over 24 straight hours. To judge the best Bluetooth headphones, we focus on higher-quality audio by listening to a variety of genres and paying close attention to how each style sounds. We also test at both low and high volumes to check for consistency in the tuning. To assess the quality of phone calls, we’ll record audio samples with the headphones’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that we review. Other wireless headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancelation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor which is actually handy. All told, that’s not a lot in a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Sony WH-CH720N While the WH-CH720N are a great affordable option, we prefer the Audio-Technica in the budget category. Sony’s cans are lightweight with good sound quality, but ANC struggles at times and they’re made with a lot of plastic. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Bose QuietComfort Ultra headphones Bose’s latest flagship model has a lot to offer, but its trademark Immersive Audio feature can be inconsistent across different types of music. There’s still world-class ANC, excellent comfort and a clearer transparency mode, but for the price, the non-Ultra model is a better choice right now. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 are more expensive and not nearly as comfortable as the Px7 S2. Wireless headphones FAQs How can you tell the quality of wireless headphones? I typically look at three factors: design, sound quality and features. In terms of design, I’m usually looking to see if the build quality of the headphones feels cheap and plasticky. Plenty of companies use plastic, but they can do so in a way that doesn’t look or feel like budget models. For sound quality, I want to hear a nice, even tuning where highs, mids and lows are all well represented. No overly boomy bass or scooped out mids. I also want good clarity where you can pick up fine details and an open, immersive soundstage. Features is typically a distant third, but if a company doesn’t cover basic functionality (automatic pausing, transparency mode, multipoint Bluetooth, etc.) it can be an indication of overall quality. How do I choose the best quality wireless headphones? “Best” can be pretty subjective, but I always recommend going to a place where you can listen to the headphones you’re thinking about buying before you commit. Sometimes this isn’t possible, so you’ll want to check return policies. I also recommend doing some research to determine what your priorities are in a new set. Are you an audiophile who wants the best sound quality? Is powerful active noise cancellation (ANC) the most important? Would you rather have conveniences like automatic pausing? Which brand has the best wireless headphones? Sony consistently tops our list with its 1000X line. This is mostly due to the combination of sound quality, ANC performance and the truckload of features these headphones pack in. I’ll be the first to tell you that there are better sounding options and other companies, like Bose, offer more effective noise cancellation. But when you add everything up, no one comes close to the full slate of tools Sony puts in its premium headphone line. Do expensive wireless headphones sound better? Exorbitant price tags don’t mean better audio quality. Bowers & Wilkins’ headphones are on the high end for wireless noise-canceling models and they sound amazing. However, Audio-Technica’s M50xBT2 is much more affordable and doesn’t have ANC, but these headphones have a warm, natural sound profile that I find very inviting. At the end of the day, it will come down to personal preference, but you don’t need to spend a lot to find great headphones.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html?src=rss",
          "content": "Wireless headphones have come a long way from the bulky designs of the past. Today’s models are lighter, smarter and packed with features that make them useful for everything from travel to long workdays at your desk. Many offer strong noise cancellation, quick pairing and reliable battery life — all of which makes them an easy upgrade if you want more freedom from your devices.Of course, not every listener has the same needs. Some people want portability, which is why our guide to the best earbuds is worth a look, while others want something more specialized like the best gaming headsets or the best budget earbuds. But if you’re after over-ear headphones that focus on comfort and immersive sound, this roundup of the best wireless headphones highlights the top choices we’ve tested. Table of contents Best wireless headphones for 2025 How to choose the best wireless headphones for you How we test over-ear headphones Other wireless headphones we tested Wireless headphones FAQs Best wireless headphones for 2025 How to choose the best wireless headphones for you When it comes to shopping for a good pair of wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of our buyer’s guide, we focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear designs are much more effective at blocking sound. Speaking of noise cancellation, you’ll want to determine early on if you even want that. If you frequently crank up the beats in noisy environments, you’ll want to not only make sure it’s there, but also make sure it’s good, preferably with adaptive ANC. If you plan to use your new headphones in quieter spaces, skipping ANC can save you some money. The next area to consider is features. We recommend trying to get the most bang for your buck, but as you’re shopping around you should determine which items are must-haves and what you can live without. And don’t take basic things like automatic pausing and Bluetooth multipoint connectivity for granted, as not all companies include them. We also suggest reading reviews to see how well a company’s more advanced features work. This will help you decide if those are something you’re willing to (likely) pay extra for. Keep an eye on better battery life estimates to avoid disappointment, as some manufacturers promise more hours than real-world testing delivers. And don’t be easily swayed by lofty promises about call quality without verifying them. Sound can be subjective, so we recommend trying before you buy if at all possible. We understand this isn’t easy at a time when we’re doing most of our shopping online. But trying on a set of headphones and listening to them for a few minutes can save you from an expensive case of buyer’s remorse. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all headphones support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you. If you plan to use your headphones for other media besides music, checking for latency is also a must — some delay can impact playback for things like movies or games, even if most true wireless headphones now offer minimal lag. How we test over-ear headphones The primary way we test wireless headphones is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for headphones can be 30 hours or more, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, we’ll typically power the headphones off several times and leave them during a review. This simulates real-world use and keeps us from having to constantly monitor the process for over 24 straight hours. To judge the best Bluetooth headphones, we focus on higher-quality audio by listening to a variety of genres and paying close attention to how each style sounds. We also test at both low and high volumes to check for consistency in the tuning. To assess the quality of phone calls, we’ll record audio samples with the headphones’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that we review. Other wireless headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancelation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor which is actually handy. All told, that’s not a lot in a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Sony WH-CH720N While the WH-CH720N are a great affordable option, we prefer the Audio-Technica in the budget category. Sony’s cans are lightweight with good sound quality, but ANC struggles at times and they’re made with a lot of plastic. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Bose QuietComfort Ultra headphones Bose’s latest flagship model has a lot to offer, but its trademark Immersive Audio feature can be inconsistent across different types of music. There’s still world-class ANC, excellent comfort and a clearer transparency mode, but for the price, the non-Ultra model is a better choice right now. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 are more expensive and not nearly as comfortable as the Px7 S2. Wireless headphones FAQs How can you tell the quality of wireless headphones? I typically look at three factors: design, sound quality and features. In terms of design, I’m usually looking to see if the build quality of the headphones feels cheap and plasticky. Plenty of companies use plastic, but they can do so in a way that doesn’t look or feel like budget models. For sound quality, I want to hear a nice, even tuning where highs, mids and lows are all well represented. No overly boomy bass or scooped out mids. I also want good clarity where you can pick up fine details and an open, immersive soundstage. Features is typically a distant third, but if a company doesn’t cover basic functionality (automatic pausing, transparency mode, multipoint Bluetooth, etc.) it can be an indication of overall quality. How do I choose the best quality wireless headphones? “Best” can be pretty subjective, but I always recommend going to a place where you can listen to the headphones you’re thinking about buying before you commit. Sometimes this isn’t possible, so you’ll want to check return policies. I also recommend doing some research to determine what your priorities are in a new set. Are you an audiophile who wants the best sound quality? Is powerful active noise cancellation (ANC) the most important? Would you rather have conveniences like automatic pausing? Which brand has the best wireless headphones? Sony consistently tops our list with its 1000X line. This is mostly due to the combination of sound quality, ANC performance and the truckload of features these headphones pack in. I’ll be the first to tell you that there are better sounding options and other companies, like Bose, offer more effective noise cancellation. But when you add everything up, no one comes close to the full slate of tools Sony puts in its premium headphone line. Do expensive wireless headphones sound better? Exorbitant price tags don’t mean better audio quality. Bowers & Wilkins’ headphones are on the high end for wireless noise-canceling models and they sound amazing. However, Audio-Technica’s M50xBT2 is much more affordable and doesn’t have ANC, but these headphones have a warm, natural sound profile that I find very inviting. At the end of the day, it will come down to personal preference, but you don’t need to spend a lot to find great headphones.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-laptops-120008636.html",
          "published_at": "Wed, 22 Oct 2025 07:01:26 +0000",
          "title": "The best laptop you can buy in 2025",
          "standfirst": "Choosing the best laptop can be a bit of a challenge — there are so many models, sizes and specs out there that it’s easy to feel lost in the shuffle. But the good news is that modern laptops are better than ever. Whether you're looking for a powerful AI PC, a travel-ready ultrabook or an affordable machine that can handle everyday tasks, there's something out there for everyone. Today’s systems combine improved performance, longer battery life and smarter features in sleek, lightweight designs that are built to keep up with work, play and everything in between.Out of all of the notebooks we've tested and reviewed recently, we consider Apple's 13-inch MacBook Air M4 to be the best laptop for most people, and this is still the case for our top picks to start off the new year. It's powerful enough to handle most tasks (even light video editing); it has a great screen and built-in speakers; and its battery could last over 18hours (depending on what you're doing, of course). The MacBook Air M4 is also one of the lightest and thinnest systems we've reviewed, and it's dead silent, thanks to a fanless design.Of course, not everyone wants a MacBook, and there are excellent Windows laptops and Chromebooks out there, too. Windows systems offer a range of configurations, from budget to high-end UHD screens with stunning IPS panels that boast high nits for vivid brightness. Chromebooks, on the other hand, tend to be more affordable and are great for users who mostly work online. Whether you need a powerhouse for creative work, a compact system for note-taking, or a laptop that can handle family movie night, there’s something for everyone in today’s laptop market. Best laptops of 2025 Back to top Specs to look for in a new laptop Depending on the type of laptop you’re looking to buy, there are some specs we think you should look for to get a machine that’s powerful enough for your needs and future-proof for the next couple of years (at least). Here's a cheat sheet for you to use when you're shopping. MacBooks At least M2 processor At least 16GB of RAM At least 256GB of SSD storage Windows laptops The most recent generation processor available from Intel or AMD At least 16GB of RAM At least 256GB of SSD storage Chromebooks Intel Core i processor At least 8GB of RAM (4GB is the bare minimum for a basic Chromebook) At least 128GB of storage, preferably a SSD Gaming laptops At least AMD Ryzen 9000 series or Intel 14th Gen Core CPU At least 16GB of RAM (ideally 32GB if you can swing it) At least 1TB of SSD storage For GPU recommendations, check out our guide to buying the best GPU for your needs Budget laptops The most recent generation processor available from Intel or AMD At least 8GB of RAM At least 256GB of SSD storage Back to top How we test laptops Engadget has been reviewing laptops for two decades, and while the definition of what a portable PC is has changed considerably since, our obsession with testing their limits and serving up informative buying advice remains the same. Be it a hybrid tablet like Microsoft's Surface machines, a rotating 2-in-1 convertible like HP's Spectre x360s or a plain old clamshell notebook, our review process follows similar beats. How does it look and feel? How fast is it? Whether it’s a Windows device powered by an Intel Core i5 or higher, a MacBook or a Chromebook, we aim to answer the most important question: Is it actually worth your hard-earned cash? We also pay close attention to portability, webcam quality and display features, including IPS panels and nits of brightness, as they can make a big difference in daily use. Back to top Factors to consider when choosing a laptop Operating system: Apple, Windows or Chrome OS There's a good chance you've already committed to an operating system, but my advice is to be as flexible as possible. These days, most major software is compatible with both Macs and PCs. (Of course, it's another story if you've become dependent on an Apple-only app like Final Cut Pro.) Web-based apps, naturally, will work on any platform with an internet browser. If you're an Apple-loyalist, there aren't many reasons to consider Windows laptops (unless you want a secondary gaming machine). But for Windows users, macOS is becoming more tempting every year. Apple's MacBooks, powered by its M-series Silicon chips, are among the fastest and most efficient laptops we've ever seen. They're incredibly well-built and have outstanding battery life to boot. MacOS itself is also an easy platform to learn, especially if you're used to iOS and iPadOS. That brings up another point: iPhone users may want to consider Macs because of the seamless integration with Apple's other platforms. You can't respond to iMessage conversations easily or hop into FaceTime chats on Windows PCs, but doing so is simple on Macs. (Microsoft's Phone Link app lets you send iOS users individual texts, but not media or group chats.) Android users, meanwhile, may be better off with Windows, as Phone Link can make calls, synchronize all your texts and also access your phone's photos. If cloud gaming is your priority, Windows laptops with NVIDIA’s GeForce Now or Xbox Cloud Gaming compatibility may offer more flexibility and decent performance, especially when paired with fast internet speeds. Chromebooks also make a compelling case here as an affordable, lightweight solution for casual cloud gaming sessions. As for whether you’ll want a PC with a dedicated Copilot AI button on the keyboard, that depends on how often you see yourself using Microsoft’s generative tools. Given we’re only just seeing the first slate of AI PCs, it would be wiser to wait out the hype and see what improvements might come over time. And what about ChromeOS? Chromebooks are a smart and (typically) inexpensive way to do things like web browsing and hopping on a few video chats, but for most, they're not the best choice as a primary computer. There aren't many apps or games that work offline, and they also don't work with powerful software suites like Adobe's (you can use the stripped-down Adobe Express and Photoshop online tools, though). Chromebooks are great secondary machines to use alongside a more powerful Mac or PC, and they're popular in schools because they're cheap and easy for IT workers to manage. And if all you need is web browsing access, or a notebook for a kid, a Chromebook might be enough. If, for some reason, you’re looking for a powerful ChromeOS system, there are also Chromebook Plus models to consider. These machines sport faster processors and more RAM than typical Google notebooks, and they can also tap into a few of the company’s online AI features, like AI image generation and photo processing. Price You can expect to spend between $1,000 and $1,800 for a new laptop these days, depending on the configuration. If you're looking for more of a workhorse, that could cost you well over $2,000 for additional RAM, storage, as well as a beefier graphics card and CPU. But you can also find some good laptops under $1,000 if you're willing to overlook build quality (or buy a refurbished or previous generation machine, which we highly recommend). Systems with AMD chips tend to come in cheaper than their Intel counterparts, but the bulk of their cost will come down to other components like RAM and storage. I’ve included our favorite affordable model in this best laptop buying guide, but we have a list of the best budget laptops that you can check out as well. Laptop size and weight So how portable do you want your laptop to be? That's the ultimate question you need to ask when choosing between various screen sizes. 13-inch machines have become a solid starting point for most shoppers — it's enough real estate for the majority of tasks like emailing and writing, and it also helps keep machines relatively light (typically between two to three pounds). Thanks to manufacturing advancements, these dainty machines sometimes even come with larger screens (the smaller MacBook Air actually has a 13.6-inch display). If you have trouble seeing fine text, we’d recommend going for a display larger than 13 inches. ASUS’s Zephyrus G14 is a solid 14-inch option for gamers, and we’re also seeing more productivity-focused machines aim for that size, like the Dell 14 Premium and MacBook Pro. While 14-inch notebooks are a bit heavier than 13-inch models, coming in between three to four pounds, their screens are noticeably roomier. For artists, or anyone else who needs a large canvas, a 15-inch laptop may make the most sense. They typically weigh between 3.5 and 4.5 pounds, but that extra heft may be worth it to fit wider video editing timelines or Photoshop windows. And, as you'd expect, you'll also pay a bit more for a 15-inch notebook compared to smaller ones (the 15-inch MacBook Air starts at $1,199, while the smaller model goes for $999). PC makers are also replacing 15-inch systems with 16-inch versions, which will give you even more space to work. If you're in the market for a business laptop, size and portability might be key considerations. A lightweight yet powerful system with a long battery life can make a world of difference if you travel frequently for work. You can still find laptops with 17-inch or 18-inch screens, but those are typically gaming systems or souped-up workstations. They're not meant for mere computing mortals. Ports and connectivity These days, most laptops ship with a few USB-C ports, which can handle both charging and speedy data transfers. Apple's MacBooks also include a separate connection for MagSafe power, and you'll find custom power connections on some PCs like Microsoft's Surface. Older USB Type-A connections are less common now, but they still pop up in systems like HP's Spectre x360 14, as well as many models from ASUS. For gamers or creators who rely on discrete graphics, ensuring your laptop has the right ports for external monitors or GPUs is crucial. DisplayPort or HDMI connections can also ensure you’re ready for dual- or multi-screen setups for more immersive experiences. Similarly, if you want to save high-resolution files or install multiple games, you might need to consider additional hard drive space; external hard drives are pretty affordable, as long as you have a proper port to connect them. If you're a fan of wired headphones, it's worth keeping a close eye on headphone jack availability. They usually include a USB-C to 3.5mm adapter, but that's a clunky solution, and it also takes up a USB port. Sure, most people use wireless earbuds and cans today, but it's still helpful to have a wired one around for when those devices run out of juice. Most laptops today offer Wi-Fi 6 or 6E and Bluetooth 5.0 or later, which should mean faster and more stable connections if you have compatible routers and devices. While Wi-Fi 7 routers have started appearing, that spec hasn't made its way into laptops yet. As for cellular coverage, there are notebooks like the Surface Pro 9 and Samsung Galaxy Book models that offer integrated 5G. But from our testing, that feature may not be worth the cost of a separate data plan. Instead, you could tether to your smartphone or invest in a wireless hotspot that can keep multiple devices online. Battery life A laptop's battery life depends on several factors: The power draw from the screen and other hardware, the optimizations used to avoid unnecessary power drain, and, of course, the size of the actual battery. One of our previous favorite systems, the Dell XPS 13, lasted 13 hours and 15 minutes in the PCMark 10 battery benchmark. In real-world testing, I was able to use it for a day and a half without needing a recharge. The MacBook Air 13-inch, meanwhile, more than 18 hours in our benchmark and kept running for more than two work days of my typical workflow. In general, you should expect a modern laptop to last at least eight hours. If battery life is your absolute priority, I'd strongly suggest looking at Macs over Windows PCs. Apple's M-series chips are essentially mobile hardware, with all of the power efficiency you'd expect from something originally designed for phones. Qualcomm’s upcoming Snapdragon chips could help Windows PCs compete with Apple’s astonishing battery life, but we’ve yet to see those in action. Chromebooks also typically get decent battery life (as long as you don’t overstuff them with power-draining tabs). Refresh rate A laptop's refresh rate refers to the amount of times its screen is cycled every second. Modern displays like IPS LCDs and OLEDs support 60Hz refresh rates at a minimum, but we're seeing more devices offering 120Hz, 240Hz and beyond. The higher the number, the faster the screen is refreshed, which ultimately leads to a smoother experience while mousing around or scrolling through web pages. (If you want to get a sense of what a slow refresh rate looks like, just grab an e-reader like the Kindle and try to flip between book pages.) While high refresh rates used to be reserved for gaming laptops, nowadays we're seeing more mainstream machines like the Dell 14 Premium offer 120Hz (or variable rates that move between 60Hz and 120Hz). CPU and GPU If you’re buying a new laptop, you’ll want to make sure it’s powered by the latest CPUs. For Windows PCs, that includes Intel’s Core Ultra chips for thin-and-light machines or the 14th-gen HX chips for beefier systems. The Core Ultra series have NPUs for handling AI tasks, while the HX hardware does not – they’re based on Intel’s previous chip architecture, and they’re more focused on delivering raw horsepower. Intel's older 13th-gen and 12th-gen laptop chips also don't have NPUs, so keep that in mind if you're looking at used systems. You'll also see AMD's Ryzen 8000 and 9000 chips in plenty of new systems like the ASUS Zephyrus G14 and Razer Blade 14. Those CPUs mainly target gaming laptops and high performance systems, while you'll still find AMD’s older Ryzen 7000 chips in ultraportables. AMD's main advantage is that its chips also include Radeon graphics, which are far more capable than Intel's Arc hardware (though those are getting better). Qualcomm’s new Snapdragon X Elite and X Plus are also an option in Copilot+ PCs (more on those below). Since they’re based on mobile chip designs, they’re likely also more power efficient than AMD and Intel’s hardware. In the past, we’ve avoided recommending Snapdragon chips because they led to a slow and frustrating Windows experience. But Microsoft claims it’s rebuilt Windows 11 around Snapdragon’s Arm-based architecture, which should lead to far faster performance and better app compatibility. As for Apple's laptops, you'll be choosing between the M4 Pro, M4 Max and M5, each of which is progressively more powerful. On the graphics side of things, a GPU, or graphics processing unit, is the component that communicates directly with a laptop's display. Laptop CPUs all have some form of integrated GPU: Intel has either its standard graphics or beefier Arc hardware, while AMD's chips include fast Radeon mobile graphics. If you want to play demanding games at high speeds (measured in frames per second, or fps), or if you need some extra power for rendering video or 3D models, you can configure a laptop with a dedicated GPU like NVIDIA's RTX 40-series hardware or AMD's Radeon RX 7000. Just be sure to leave room in your budget if you want a powerful GPU, as they typically add $300 or more to the cost of a laptop. Apple's M-series chips, meanwhile, have GPU cores that can perform as well as NVIDIA’s and AMD's lower-end dedicated GPUs. That's quite the accomplishment for systems like this (especially the MacBook Air and 14-inch MacBook Pro), and it's another reason we highly recommend Apple's notebooks. AI PCs, NPUs and Copilot+ Simply put, an AI PC is a computer equipped with a neural processing unit (NPU), which is designed to handle AI-related tasks. Much like how GPUs tackle heavy-duty gaming and rendering workloads, NPUs are designed to handle the complex math necessary for AI workloads. They’re also far more power efficient than CPUs or GPUs, which could lead to better battery performance in laptops. While many factors go into NPU performance, for the most part we measure their potential speed by TOPS (tera operations per second). We were primed for AI PCs based on the chips Intel and AMD announced in 2023. Intel unveiled its \"Core Ultra\" CPUs in December, its first to include an NPU for AI work. AMD also announced its Ryzen 8040 AI mobile chips that month (and it couldn't help but say they were faster than Intel's new hardware). But in May, Microsoft announced its Copilot+ initiative, which is pushing major PC makers to deliver premium AI PCs with specifications including 16GB of RAM, 256GB SSDs and NPUs with at least 40 TOPS of AI performance. Copilot+ is more than just a marketing term: Microsoft is also launching AI-powered features in Windows 11 that take advantage of powerful NPUs. That includes Recall, which can help you locate anything you’ve done on your PC (whenever it finally launches), as well as Cocreator in Paint, which can generate AI images based on text prompts and doodles. If you buy an AI PC that isn’t Copilot+ certified, you’ll still be able to use some features like Windows Studio Effects, which can blur your background in video calls or keep you in frame. Developers like Adobe and Audacity are also building features into their apps that can take advantage of NPUs. At the time of this post, Chromebook Plus notebooks can also access a few of Google’s online AI features, like image generation and photo processing. Back to top Other laptops we tested Lenovo ThinkPad X9-14 Aura Edition The ThinkPad X9-14 Aura Edition is a great spiritual successor to the ThinkPad X1 Carbon, offering the best that business laptops have to offer. That includes long battery life packed into a thin and light chassis. This is an optimal ultraportable business laptop. While the price might give you some pause, we tested the lowest configuration, and found that the X9-14’s performance is excellent for casual business users. The only issue with quality is that the keyboard is lacking. It’s mushier than we’d like, which could get a bit tiresome throughout the day. You’ll still miss out on a USB Type-A port, so you may need to carry a Type-C hub with you. Where the ThinkPad X9-14 will win you over is its bold OLED screen. Combo that with its well-rounded audio, and the ThinkPad X9-14 makes for an excellent multimedia device in and out of the workplace. ASUS Zenbook 14 OLED Aside from its lovely OLED screen, the ASUS Zenbook 14 OLED doesn't stand out from the crowded laptop field in any way. It just looks dull and boring, especially compared to the strikingly beautiful ASUS Zephyrus G14, which also came out this year. While you can probably find the Zenbook 14 for a decent price, I'd recommend holding out for something with a bit more personality (and with a less wobbly screen hinge). Razer Blade 14 The Razer Blade has almost everything you'd want in a 14-inch gaming notebook, but it's far pricier than the Zephyrus G14 on this list, and it doesn’t even have an SD card reader. It would be a solid competitor once its price falls a bit, and it's certainly a great option if you just have to have a jet-black laptop. Framework Laptop 16 Framework gave its modularity magic to the Laptop 16, delivering a gaming notebook where almost every single component is user replaceable. But you'll have to pay a pretty penny to snag it with upgraded hardware, and its optional Radeon 7700S GPU was surprisingly slow. Alienware m16 R2 The Alienware m16 r2 has been revamped with a slimmer case, but it’s otherwise a fairly typical gaming laptop. It’s a solid option for Alienware fans, but you’ll find better hardware and deals elsewhere. ASUS Zenbook Duo (2024) The Zenbook Duo is a fascinating dual-screened notebook, and according to my colleague Sam Rutherford it’s the first of its kind that’s worth buying. But its unique hardware isn’t really meant for mainstream consumers, and Windows 11 still doesn’t support multi-screen setups well enough to make full use of the Zenbook Duo’s ample canvas. Dell XPS 16 Dell’s XPS 16 is big and beautiful, but it’s far too expensive compared to the competition. Plus, it uses a capacitive row of function keys that you basically can’t see under bright light and has too few ports for a machine of this size. See Also: Best Gaming Laptops for 2025 Best Cheap Windows Laptops Best 2-in-1 Laptops for 2025 Best Chromebooks Best Laptops for College Students Back to top Laptop FAQs What is the average battery life of a laptop per charge? It’s hard to come up with an average battery life for laptops, since that will ultimately depend on what you’re doing with them. An ultraportable like the MacBook Air that sips power can last around 20 hours in our battery benchmark, and around two full work days of real-world usage. But a gaming laptop may last only a few hours if you’re actively playing something while on battery. At this point, Macs are delivering far better battery life than PCs, thanks to Apple’s Silicon chips, but Microsoft claims Copilot+ systems with Qualcomm chips will also get over 20 hours of batter life. How much RAM do I really need? The more RAM you have, the more things your computer can do simultaneously. For that reason, we recommend buying PCs and Macs with at least 16GB of RAM. That gives you enough memory to have several applications open at once, as well as web browsers filled with RAM-hogging tabs. Many PC games also require at least 16GB of RAM. While you could use a system with 8GB of RAM for basic tasks, you’ll quickly run into slowdowns and error messages as your apps stack up. Many laptops, especially ultraportables, don’t let you upgrade RAM, too – so you’ll have to buy an entirely new computer if you didn’t equip enough memory at the start. If you’re a hardcore gamer, programmer or planning to render videos or 3D models, then you may want to go for 32GB of RAM or more. And if you just need a secondary laptop for lighter work – perhaps a no-frills system for writing – then you can probably get by with 8GB. Just be sure to keep those browser tabs in check. What is the best storage capacity for a laptop? There is no one-size-fits-all solution when it comes to laptop storage. You’ll typically find configurations between 256GB and 1TB SSDs (solid state drives) on most laptops, and I’d recommend most people get at least 512GB. That’ll be enough space for large apps, music and video files without stressing your system too much. If you’re a media hoarder, or want to play a ton of games, then it’s definitely worth getting a 1TB SSD. If you’ll mainly be streaming your shows and music, and would rather invest in RAM or other hardware, then 256GB of storage would be serviceable. I’d recommend staying away from any machine with 128GB of storage though. Most of that will be taken up by the operating system, and you’ll likely run into issues cramming in large apps after a few months. We recommend springing for extra built-in storage or investing in a portable SSD for backing up your most important files. It's also worth noting that Chromebooks tend to come with less built-in storage — 32GB, 64GB or 128GB — since ChromeOS encourages users to save their files in the cloud rather than on the device. In that case, 128GB is plenty. What's a good price range for a decent laptop in 2025? You can expect to spend between $1,000 and $1,800 for a typical 13-inch laptop today. As I explained above, you'll pay more if you want to stuff in more RAM or better GPU hardware. But you can also find deals below $1,000 if you look for refurbished or older-generation models. What’s the difference between macOS and Windows? Which is better? Simply put, macOS is the operating system in all of Apple's notebooks and desktops, while Windows powers the vast majority of PCs. You'll also find Chromebooks running Google's ChromeOS, but those are basically just web browsers running on top of Linux. Debating the differences between Windows and Macs is something PC nerds have been doing since the '80s, so we won't be declaring a winner here. There are some small, negligible distinctions, like using a Command versus a Control key, how file explorers work and concerns about viruses and security. For the most part, those are minor issues or have become moot thanks to better built-in security. But if you care more about playing the newest games, you'll want to have a Windows system. If you're more focused on creative apps, like Photoshop, Premiere and Final Cut Pro, then macOS may be a better fit (especially if you're running an iPhone). What are the best laptop brands? There is no single \"best\" laptop brand, but judging from this guide alone, we're generally impressed by notebooks from Apple, Dell and ASUS. They all offer fast, reliable and sturdy machines. HP also makes some eye-catching devices if you want an option that’s the most aesthetic. Those four brands, along with Lenovo and Acer, dominate laptop sales worldwide. We'd avoid systems from any retail store brands, or companies that don't have a major presence in the US. Back to top Recent updates October 2025: Updated to add the latest MacBook Pro. September 2025: Added a new \"specs to look for\" section. August 2025: Updated our top picks to include the Dell 14 Premium. May 2025: Updated to ensure top picks and details are still accurate. March 2025: Updated to include the M4-powered MacBook Air. November 2024: Updated to include the M4-powered MacBook Pros. August 2024: Updated to include the Lenovo ThinkPad X1 Carbon Gen 12. Back to topThis article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-laptops-120008636.html?src=rss",
          "content": "Choosing the best laptop can be a bit of a challenge — there are so many models, sizes and specs out there that it’s easy to feel lost in the shuffle. But the good news is that modern laptops are better than ever. Whether you're looking for a powerful AI PC, a travel-ready ultrabook or an affordable machine that can handle everyday tasks, there's something out there for everyone. Today’s systems combine improved performance, longer battery life and smarter features in sleek, lightweight designs that are built to keep up with work, play and everything in between.Out of all of the notebooks we've tested and reviewed recently, we consider Apple's 13-inch MacBook Air M4 to be the best laptop for most people, and this is still the case for our top picks to start off the new year. It's powerful enough to handle most tasks (even light video editing); it has a great screen and built-in speakers; and its battery could last over 18hours (depending on what you're doing, of course). The MacBook Air M4 is also one of the lightest and thinnest systems we've reviewed, and it's dead silent, thanks to a fanless design.Of course, not everyone wants a MacBook, and there are excellent Windows laptops and Chromebooks out there, too. Windows systems offer a range of configurations, from budget to high-end UHD screens with stunning IPS panels that boast high nits for vivid brightness. Chromebooks, on the other hand, tend to be more affordable and are great for users who mostly work online. Whether you need a powerhouse for creative work, a compact system for note-taking, or a laptop that can handle family movie night, there’s something for everyone in today’s laptop market. Best laptops of 2025 Back to top Specs to look for in a new laptop Depending on the type of laptop you’re looking to buy, there are some specs we think you should look for to get a machine that’s powerful enough for your needs and future-proof for the next couple of years (at least). Here's a cheat sheet for you to use when you're shopping. MacBooks At least M2 processor At least 16GB of RAM At least 256GB of SSD storage Windows laptops The most recent generation processor available from Intel or AMD At least 16GB of RAM At least 256GB of SSD storage Chromebooks Intel Core i processor At least 8GB of RAM (4GB is the bare minimum for a basic Chromebook) At least 128GB of storage, preferably a SSD Gaming laptops At least AMD Ryzen 9000 series or Intel 14th Gen Core CPU At least 16GB of RAM (ideally 32GB if you can swing it) At least 1TB of SSD storage For GPU recommendations, check out our guide to buying the best GPU for your needs Budget laptops The most recent generation processor available from Intel or AMD At least 8GB of RAM At least 256GB of SSD storage Back to top How we test laptops Engadget has been reviewing laptops for two decades, and while the definition of what a portable PC is has changed considerably since, our obsession with testing their limits and serving up informative buying advice remains the same. Be it a hybrid tablet like Microsoft's Surface machines, a rotating 2-in-1 convertible like HP's Spectre x360s or a plain old clamshell notebook, our review process follows similar beats. How does it look and feel? How fast is it? Whether it’s a Windows device powered by an Intel Core i5 or higher, a MacBook or a Chromebook, we aim to answer the most important question: Is it actually worth your hard-earned cash? We also pay close attention to portability, webcam quality and display features, including IPS panels and nits of brightness, as they can make a big difference in daily use. Back to top Factors to consider when choosing a laptop Operating system: Apple, Windows or Chrome OS There's a good chance you've already committed to an operating system, but my advice is to be as flexible as possible. These days, most major software is compatible with both Macs and PCs. (Of course, it's another story if you've become dependent on an Apple-only app like Final Cut Pro.) Web-based apps, naturally, will work on any platform with an internet browser. If you're an Apple-loyalist, there aren't many reasons to consider Windows laptops (unless you want a secondary gaming machine). But for Windows users, macOS is becoming more tempting every year. Apple's MacBooks, powered by its M-series Silicon chips, are among the fastest and most efficient laptops we've ever seen. They're incredibly well-built and have outstanding battery life to boot. MacOS itself is also an easy platform to learn, especially if you're used to iOS and iPadOS. That brings up another point: iPhone users may want to consider Macs because of the seamless integration with Apple's other platforms. You can't respond to iMessage conversations easily or hop into FaceTime chats on Windows PCs, but doing so is simple on Macs. (Microsoft's Phone Link app lets you send iOS users individual texts, but not media or group chats.) Android users, meanwhile, may be better off with Windows, as Phone Link can make calls, synchronize all your texts and also access your phone's photos. If cloud gaming is your priority, Windows laptops with NVIDIA’s GeForce Now or Xbox Cloud Gaming compatibility may offer more flexibility and decent performance, especially when paired with fast internet speeds. Chromebooks also make a compelling case here as an affordable, lightweight solution for casual cloud gaming sessions. As for whether you’ll want a PC with a dedicated Copilot AI button on the keyboard, that depends on how often you see yourself using Microsoft’s generative tools. Given we’re only just seeing the first slate of AI PCs, it would be wiser to wait out the hype and see what improvements might come over time. And what about ChromeOS? Chromebooks are a smart and (typically) inexpensive way to do things like web browsing and hopping on a few video chats, but for most, they're not the best choice as a primary computer. There aren't many apps or games that work offline, and they also don't work with powerful software suites like Adobe's (you can use the stripped-down Adobe Express and Photoshop online tools, though). Chromebooks are great secondary machines to use alongside a more powerful Mac or PC, and they're popular in schools because they're cheap and easy for IT workers to manage. And if all you need is web browsing access, or a notebook for a kid, a Chromebook might be enough. If, for some reason, you’re looking for a powerful ChromeOS system, there are also Chromebook Plus models to consider. These machines sport faster processors and more RAM than typical Google notebooks, and they can also tap into a few of the company’s online AI features, like AI image generation and photo processing. Price You can expect to spend between $1,000 and $1,800 for a new laptop these days, depending on the configuration. If you're looking for more of a workhorse, that could cost you well over $2,000 for additional RAM, storage, as well as a beefier graphics card and CPU. But you can also find some good laptops under $1,000 if you're willing to overlook build quality (or buy a refurbished or previous generation machine, which we highly recommend). Systems with AMD chips tend to come in cheaper than their Intel counterparts, but the bulk of their cost will come down to other components like RAM and storage. I’ve included our favorite affordable model in this best laptop buying guide, but we have a list of the best budget laptops that you can check out as well. Laptop size and weight So how portable do you want your laptop to be? That's the ultimate question you need to ask when choosing between various screen sizes. 13-inch machines have become a solid starting point for most shoppers — it's enough real estate for the majority of tasks like emailing and writing, and it also helps keep machines relatively light (typically between two to three pounds). Thanks to manufacturing advancements, these dainty machines sometimes even come with larger screens (the smaller MacBook Air actually has a 13.6-inch display). If you have trouble seeing fine text, we’d recommend going for a display larger than 13 inches. ASUS’s Zephyrus G14 is a solid 14-inch option for gamers, and we’re also seeing more productivity-focused machines aim for that size, like the Dell 14 Premium and MacBook Pro. While 14-inch notebooks are a bit heavier than 13-inch models, coming in between three to four pounds, their screens are noticeably roomier. For artists, or anyone else who needs a large canvas, a 15-inch laptop may make the most sense. They typically weigh between 3.5 and 4.5 pounds, but that extra heft may be worth it to fit wider video editing timelines or Photoshop windows. And, as you'd expect, you'll also pay a bit more for a 15-inch notebook compared to smaller ones (the 15-inch MacBook Air starts at $1,199, while the smaller model goes for $999). PC makers are also replacing 15-inch systems with 16-inch versions, which will give you even more space to work. If you're in the market for a business laptop, size and portability might be key considerations. A lightweight yet powerful system with a long battery life can make a world of difference if you travel frequently for work. You can still find laptops with 17-inch or 18-inch screens, but those are typically gaming systems or souped-up workstations. They're not meant for mere computing mortals. Ports and connectivity These days, most laptops ship with a few USB-C ports, which can handle both charging and speedy data transfers. Apple's MacBooks also include a separate connection for MagSafe power, and you'll find custom power connections on some PCs like Microsoft's Surface. Older USB Type-A connections are less common now, but they still pop up in systems like HP's Spectre x360 14, as well as many models from ASUS. For gamers or creators who rely on discrete graphics, ensuring your laptop has the right ports for external monitors or GPUs is crucial. DisplayPort or HDMI connections can also ensure you’re ready for dual- or multi-screen setups for more immersive experiences. Similarly, if you want to save high-resolution files or install multiple games, you might need to consider additional hard drive space; external hard drives are pretty affordable, as long as you have a proper port to connect them. If you're a fan of wired headphones, it's worth keeping a close eye on headphone jack availability. They usually include a USB-C to 3.5mm adapter, but that's a clunky solution, and it also takes up a USB port. Sure, most people use wireless earbuds and cans today, but it's still helpful to have a wired one around for when those devices run out of juice. Most laptops today offer Wi-Fi 6 or 6E and Bluetooth 5.0 or later, which should mean faster and more stable connections if you have compatible routers and devices. While Wi-Fi 7 routers have started appearing, that spec hasn't made its way into laptops yet. As for cellular coverage, there are notebooks like the Surface Pro 9 and Samsung Galaxy Book models that offer integrated 5G. But from our testing, that feature may not be worth the cost of a separate data plan. Instead, you could tether to your smartphone or invest in a wireless hotspot that can keep multiple devices online. Battery life A laptop's battery life depends on several factors: The power draw from the screen and other hardware, the optimizations used to avoid unnecessary power drain, and, of course, the size of the actual battery. One of our previous favorite systems, the Dell XPS 13, lasted 13 hours and 15 minutes in the PCMark 10 battery benchmark. In real-world testing, I was able to use it for a day and a half without needing a recharge. The MacBook Air 13-inch, meanwhile, more than 18 hours in our benchmark and kept running for more than two work days of my typical workflow. In general, you should expect a modern laptop to last at least eight hours. If battery life is your absolute priority, I'd strongly suggest looking at Macs over Windows PCs. Apple's M-series chips are essentially mobile hardware, with all of the power efficiency you'd expect from something originally designed for phones. Qualcomm’s upcoming Snapdragon chips could help Windows PCs compete with Apple’s astonishing battery life, but we’ve yet to see those in action. Chromebooks also typically get decent battery life (as long as you don’t overstuff them with power-draining tabs). Refresh rate A laptop's refresh rate refers to the amount of times its screen is cycled every second. Modern displays like IPS LCDs and OLEDs support 60Hz refresh rates at a minimum, but we're seeing more devices offering 120Hz, 240Hz and beyond. The higher the number, the faster the screen is refreshed, which ultimately leads to a smoother experience while mousing around or scrolling through web pages. (If you want to get a sense of what a slow refresh rate looks like, just grab an e-reader like the Kindle and try to flip between book pages.) While high refresh rates used to be reserved for gaming laptops, nowadays we're seeing more mainstream machines like the Dell 14 Premium offer 120Hz (or variable rates that move between 60Hz and 120Hz). CPU and GPU If you’re buying a new laptop, you’ll want to make sure it’s powered by the latest CPUs. For Windows PCs, that includes Intel’s Core Ultra chips for thin-and-light machines or the 14th-gen HX chips for beefier systems. The Core Ultra series have NPUs for handling AI tasks, while the HX hardware does not – they’re based on Intel’s previous chip architecture, and they’re more focused on delivering raw horsepower. Intel's older 13th-gen and 12th-gen laptop chips also don't have NPUs, so keep that in mind if you're looking at used systems. You'll also see AMD's Ryzen 8000 and 9000 chips in plenty of new systems like the ASUS Zephyrus G14 and Razer Blade 14. Those CPUs mainly target gaming laptops and high performance systems, while you'll still find AMD’s older Ryzen 7000 chips in ultraportables. AMD's main advantage is that its chips also include Radeon graphics, which are far more capable than Intel's Arc hardware (though those are getting better). Qualcomm’s new Snapdragon X Elite and X Plus are also an option in Copilot+ PCs (more on those below). Since they’re based on mobile chip designs, they’re likely also more power efficient than AMD and Intel’s hardware. In the past, we’ve avoided recommending Snapdragon chips because they led to a slow and frustrating Windows experience. But Microsoft claims it’s rebuilt Windows 11 around Snapdragon’s Arm-based architecture, which should lead to far faster performance and better app compatibility. As for Apple's laptops, you'll be choosing between the M4 Pro, M4 Max and M5, each of which is progressively more powerful. On the graphics side of things, a GPU, or graphics processing unit, is the component that communicates directly with a laptop's display. Laptop CPUs all have some form of integrated GPU: Intel has either its standard graphics or beefier Arc hardware, while AMD's chips include fast Radeon mobile graphics. If you want to play demanding games at high speeds (measured in frames per second, or fps), or if you need some extra power for rendering video or 3D models, you can configure a laptop with a dedicated GPU like NVIDIA's RTX 40-series hardware or AMD's Radeon RX 7000. Just be sure to leave room in your budget if you want a powerful GPU, as they typically add $300 or more to the cost of a laptop. Apple's M-series chips, meanwhile, have GPU cores that can perform as well as NVIDIA’s and AMD's lower-end dedicated GPUs. That's quite the accomplishment for systems like this (especially the MacBook Air and 14-inch MacBook Pro), and it's another reason we highly recommend Apple's notebooks. AI PCs, NPUs and Copilot+ Simply put, an AI PC is a computer equipped with a neural processing unit (NPU), which is designed to handle AI-related tasks. Much like how GPUs tackle heavy-duty gaming and rendering workloads, NPUs are designed to handle the complex math necessary for AI workloads. They’re also far more power efficient than CPUs or GPUs, which could lead to better battery performance in laptops. While many factors go into NPU performance, for the most part we measure their potential speed by TOPS (tera operations per second). We were primed for AI PCs based on the chips Intel and AMD announced in 2023. Intel unveiled its \"Core Ultra\" CPUs in December, its first to include an NPU for AI work. AMD also announced its Ryzen 8040 AI mobile chips that month (and it couldn't help but say they were faster than Intel's new hardware). But in May, Microsoft announced its Copilot+ initiative, which is pushing major PC makers to deliver premium AI PCs with specifications including 16GB of RAM, 256GB SSDs and NPUs with at least 40 TOPS of AI performance. Copilot+ is more than just a marketing term: Microsoft is also launching AI-powered features in Windows 11 that take advantage of powerful NPUs. That includes Recall, which can help you locate anything you’ve done on your PC (whenever it finally launches), as well as Cocreator in Paint, which can generate AI images based on text prompts and doodles. If you buy an AI PC that isn’t Copilot+ certified, you’ll still be able to use some features like Windows Studio Effects, which can blur your background in video calls or keep you in frame. Developers like Adobe and Audacity are also building features into their apps that can take advantage of NPUs. At the time of this post, Chromebook Plus notebooks can also access a few of Google’s online AI features, like image generation and photo processing. Back to top Other laptops we tested Lenovo ThinkPad X9-14 Aura Edition The ThinkPad X9-14 Aura Edition is a great spiritual successor to the ThinkPad X1 Carbon, offering the best that business laptops have to offer. That includes long battery life packed into a thin and light chassis. This is an optimal ultraportable business laptop. While the price might give you some pause, we tested the lowest configuration, and found that the X9-14’s performance is excellent for casual business users. The only issue with quality is that the keyboard is lacking. It’s mushier than we’d like, which could get a bit tiresome throughout the day. You’ll still miss out on a USB Type-A port, so you may need to carry a Type-C hub with you. Where the ThinkPad X9-14 will win you over is its bold OLED screen. Combo that with its well-rounded audio, and the ThinkPad X9-14 makes for an excellent multimedia device in and out of the workplace. ASUS Zenbook 14 OLED Aside from its lovely OLED screen, the ASUS Zenbook 14 OLED doesn't stand out from the crowded laptop field in any way. It just looks dull and boring, especially compared to the strikingly beautiful ASUS Zephyrus G14, which also came out this year. While you can probably find the Zenbook 14 for a decent price, I'd recommend holding out for something with a bit more personality (and with a less wobbly screen hinge). Razer Blade 14 The Razer Blade has almost everything you'd want in a 14-inch gaming notebook, but it's far pricier than the Zephyrus G14 on this list, and it doesn’t even have an SD card reader. It would be a solid competitor once its price falls a bit, and it's certainly a great option if you just have to have a jet-black laptop. Framework Laptop 16 Framework gave its modularity magic to the Laptop 16, delivering a gaming notebook where almost every single component is user replaceable. But you'll have to pay a pretty penny to snag it with upgraded hardware, and its optional Radeon 7700S GPU was surprisingly slow. Alienware m16 R2 The Alienware m16 r2 has been revamped with a slimmer case, but it’s otherwise a fairly typical gaming laptop. It’s a solid option for Alienware fans, but you’ll find better hardware and deals elsewhere. ASUS Zenbook Duo (2024) The Zenbook Duo is a fascinating dual-screened notebook, and according to my colleague Sam Rutherford it’s the first of its kind that’s worth buying. But its unique hardware isn’t really meant for mainstream consumers, and Windows 11 still doesn’t support multi-screen setups well enough to make full use of the Zenbook Duo’s ample canvas. Dell XPS 16 Dell’s XPS 16 is big and beautiful, but it’s far too expensive compared to the competition. Plus, it uses a capacitive row of function keys that you basically can’t see under bright light and has too few ports for a machine of this size. See Also: Best Gaming Laptops for 2025 Best Cheap Windows Laptops Best 2-in-1 Laptops for 2025 Best Chromebooks Best Laptops for College Students Back to top Laptop FAQs What is the average battery life of a laptop per charge? It’s hard to come up with an average battery life for laptops, since that will ultimately depend on what you’re doing with them. An ultraportable like the MacBook Air that sips power can last around 20 hours in our battery benchmark, and around two full work days of real-world usage. But a gaming laptop may last only a few hours if you’re actively playing something while on battery. At this point, Macs are delivering far better battery life than PCs, thanks to Apple’s Silicon chips, but Microsoft claims Copilot+ systems with Qualcomm chips will also get over 20 hours of batter life. How much RAM do I really need? The more RAM you have, the more things your computer can do simultaneously. For that reason, we recommend buying PCs and Macs with at least 16GB of RAM. That gives you enough memory to have several applications open at once, as well as web browsers filled with RAM-hogging tabs. Many PC games also require at least 16GB of RAM. While you could use a system with 8GB of RAM for basic tasks, you’ll quickly run into slowdowns and error messages as your apps stack up. Many laptops, especially ultraportables, don’t let you upgrade RAM, too – so you’ll have to buy an entirely new computer if you didn’t equip enough memory at the start. If you’re a hardcore gamer, programmer or planning to render videos or 3D models, then you may want to go for 32GB of RAM or more. And if you just need a secondary laptop for lighter work – perhaps a no-frills system for writing – then you can probably get by with 8GB. Just be sure to keep those browser tabs in check. What is the best storage capacity for a laptop? There is no one-size-fits-all solution when it comes to laptop storage. You’ll typically find configurations between 256GB and 1TB SSDs (solid state drives) on most laptops, and I’d recommend most people get at least 512GB. That’ll be enough space for large apps, music and video files without stressing your system too much. If you’re a media hoarder, or want to play a ton of games, then it’s definitely worth getting a 1TB SSD. If you’ll mainly be streaming your shows and music, and would rather invest in RAM or other hardware, then 256GB of storage would be serviceable. I’d recommend staying away from any machine with 128GB of storage though. Most of that will be taken up by the operating system, and you’ll likely run into issues cramming in large apps after a few months. We recommend springing for extra built-in storage or investing in a portable SSD for backing up your most important files. It's also worth noting that Chromebooks tend to come with less built-in storage — 32GB, 64GB or 128GB — since ChromeOS encourages users to save their files in the cloud rather than on the device. In that case, 128GB is plenty. What's a good price range for a decent laptop in 2025? You can expect to spend between $1,000 and $1,800 for a typical 13-inch laptop today. As I explained above, you'll pay more if you want to stuff in more RAM or better GPU hardware. But you can also find deals below $1,000 if you look for refurbished or older-generation models. What’s the difference between macOS and Windows? Which is better? Simply put, macOS is the operating system in all of Apple's notebooks and desktops, while Windows powers the vast majority of PCs. You'll also find Chromebooks running Google's ChromeOS, but those are basically just web browsers running on top of Linux. Debating the differences between Windows and Macs is something PC nerds have been doing since the '80s, so we won't be declaring a winner here. There are some small, negligible distinctions, like using a Command versus a Control key, how file explorers work and concerns about viruses and security. For the most part, those are minor issues or have become moot thanks to better built-in security. But if you care more about playing the newest games, you'll want to have a Windows system. If you're more focused on creative apps, like Photoshop, Premiere and Final Cut Pro, then macOS may be a better fit (especially if you're running an iPhone). What are the best laptop brands? There is no single \"best\" laptop brand, but judging from this guide alone, we're generally impressed by notebooks from Apple, Dell and ASUS. They all offer fast, reliable and sturdy machines. HP also makes some eye-catching devices if you want an option that’s the most aesthetic. Those four brands, along with Lenovo and Acer, dominate laptop sales worldwide. We'd avoid systems from any retail store brands, or companies that don't have a major presence in the US. Back to top Recent updates October 2025: Updated to add the latest MacBook Pro. September 2025: Added a new \"specs to look for\" section. August 2025: Updated our top picks to include the Dell 14 Premium. May 2025: Updated to ensure top picks and details are still accurate. March 2025: Updated to include the M4-powered MacBook Air. November 2024: Updated to include the M4-powered MacBook Pros. August 2024: Updated to include the Lenovo ThinkPad X1 Carbon Gen 12. Back to topThis article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-laptops-120008636.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/samsung-is-working-on-xr-smart-glasses-with-warby-parker-and-gentle-monster-042632170.html",
          "published_at": "Wed, 22 Oct 2025 04:26:32 +0000",
          "title": "Samsung is working on XR smart glasses with Warby Parker and Gentle Monster",
          "standfirst": "As part of its Galaxy XR headset presentation, Samsung also briefly teased another wearable product. It's working in collaboration with two eyewear companies, Warby Parker and Gentle Monster, on AI-powered smart glasses to go up against Meta's Ray-Ban models, Samsung's head of customer experience Jay Kim announced at the end of the livestream. \"We're also really excited about the AI glasses that we're currently building together with Google,\" Kim said. \"We're working with two of the most forward-thinking brands in eyewear, Warby Parker and Gentle Monster, to introduce new devices that fit into your lifestyle.\" Samsung will focus on two different markets with those brands, though both will include \"cutting-edge\" AI features co-developed with Google. With Gentle Monster, it's developing \"fashion-forward\" glasses that will likely be aimed at the higher end of the market. The Warby Parker collaboration, meanwhile, will yield eyewear designed for general consumers, probably at a lower price point. Samsung only said that the AI glasses will bring \"style, comfort and practicality\" to everyday life via Android's XR ecosystem. As we saw in May with Google's prototype XR smart glasses, it will likely employ a Gemini-powered display that will show notifications and small snippets of info from your apps, like the music you're listening to or turn-by-turn GPS directions. It should also have a built-in camera, of course, along with speakers and a microphone. Design and appearance will also be key, but Samsung has yet to show any images of the upcoming smart glasses and didn't reveal a release date. However, it will have a tough climb against Meta's lineup given the Ray-Ban branding and that company's head start on the technology. Last week, Meta introduced its Ray-Ban Display model that includes a screen for a true extended reality experience. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-is-working-on-xr-smart-glasses-with-warby-parker-and-gentle-monster-042632170.html?src=rss",
          "content": "As part of its Galaxy XR headset presentation, Samsung also briefly teased another wearable product. It's working in collaboration with two eyewear companies, Warby Parker and Gentle Monster, on AI-powered smart glasses to go up against Meta's Ray-Ban models, Samsung's head of customer experience Jay Kim announced at the end of the livestream. \"We're also really excited about the AI glasses that we're currently building together with Google,\" Kim said. \"We're working with two of the most forward-thinking brands in eyewear, Warby Parker and Gentle Monster, to introduce new devices that fit into your lifestyle.\" Samsung will focus on two different markets with those brands, though both will include \"cutting-edge\" AI features co-developed with Google. With Gentle Monster, it's developing \"fashion-forward\" glasses that will likely be aimed at the higher end of the market. The Warby Parker collaboration, meanwhile, will yield eyewear designed for general consumers, probably at a lower price point. Samsung only said that the AI glasses will bring \"style, comfort and practicality\" to everyday life via Android's XR ecosystem. As we saw in May with Google's prototype XR smart glasses, it will likely employ a Gemini-powered display that will show notifications and small snippets of info from your apps, like the music you're listening to or turn-by-turn GPS directions. It should also have a built-in camera, of course, along with speakers and a microphone. Design and appearance will also be key, but Samsung has yet to show any images of the upcoming smart glasses and didn't reveal a release date. However, it will have a tough climb against Meta's lineup given the Ray-Ban branding and that company's head start on the technology. Last week, Meta introduced its Ray-Ban Display model that includes a screen for a true extended reality experience. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-is-working-on-xr-smart-glasses-with-warby-parker-and-gentle-monster-042632170.html?src=rss",
          "feed_position": 2
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/simplifying-the-ai-stack-the-key-to-scalable-portable-intelligence-from",
          "published_at": "Wed, 22 Oct 2025 04:00:00 GMT",
          "title": "Simplifying the AI stack: The key to scalable, portable intelligence from cloud to edge",
          "standfirst": "Presented by ArmA simpler software stack is the key to portable, scalable AI across cloud and edge. AI is now powering real-world applications, yet fragmented software stacks are holding it back. Developers routinely rebuild the same models for different hardware targets, losing time to glue code instead of shipping features. The good news is that a shift is underway. Unified toolchains and optimized libraries are making it possible to deploy models across platforms without compromising performance.Yet one critical hurdle remains: software complexity. Disparate tools, hardware-specific optimizations, and layered tech stacks continue to bottleneck progress. To unlock the next wave of AI innovation, the industry must pivot decisively away from siloed development and toward streamlined, end-to-end platforms.This transformation is already taking shape. Major cloud providers, edge platform vendors, and open-source communities are converging on unified toolchains that simplify development and accelerate deployment, from cloud to edge. In this article, we’ll explore why simplification is the key to scalable AI, what’s driving this momentum, and how next-gen platforms are turning that vision into real-world results.The bottleneck: fragmentation, complexity, and inefficiencyThe issue isn’t just hardware variety; it’s duplicated effort across frameworks and targets that slows time-to-value.Diverse hardware targets: GPUs, NPUs, CPU-only devices, mobile SoCs, and custom accelerators.Tooling and framework fragmentation: TensorFlow, PyTorch, ONNX, MediaPipe, and others.Edge constraints: Devices require real-time, energy-efficient performance with minimal overhead.According to Gartner Research, these mismatches create a key hurdle: over 60% of AI initiatives stall before production, driven by integration complexity and performance variability. What software simplification looks likeSimplification is coalescing around five moves that cut re-engineering cost and risk:Cross-platform abstraction layers that minimize re-engineering when porting models.Performance-tuned libraries integrated into major ML frameworks.Unified architectural designs that scale from datacenter to mobile.Open standards and runtimes (e.g., ONNX, MLIR) reducing lock-in and improving compatibility.Developer-first ecosystems emphasizing speed, reproducibility, and scalability.These shifts are making AI more accessible, especially for startups and academic teams that previously lacked the resources for bespoke optimization. Projects like Hugging Face’s Optimum and MLPerf benchmarks are also helping standardize and validate cross-hardware performance.Ecosystem momentum and real-world signals Simplification is no longer aspirational; it’s happening now. Across the industry, software considerations are influencing decisions at the IP and silicon design level, resulting in solutions that are production-ready from day one. Major ecosystem players are driving this shift by aligning hardware and software development efforts, delivering tighter integration across the stack.A key catalyst is the rapid rise of edge inference, where AI models are deployed directly on devices rather than in the cloud. This has intensified demand for streamlined software stacks that support end-to-end optimization, from silicon to system to application. Companies like Arm are responding by enabling tighter coupling between their compute platforms and software toolchains, helping developers accelerate time-to-deployment without sacrificing performance or portability. The emergence of multi-modal and general-purpose foundation models (e.g., LLaMA, Gemini, Claude) has also added urgency. These models require flexible runtimes that can scale across cloud and edge environments. AI agents, which interact, adapt, and perform tasks autonomously, further drive the need for high-efficiency, cross-platform software.MLPerf Inference v3.1 included over 13,500 performance results from 26 submitters, validating multi-platform benchmarking of AI workloads. Results spanned both data center and edge devices, demonstrating the diversity of optimized deployments now being tested and shared.Taken together, these signals make clear that the market’s demand and incentives are aligning around a common set of priorities, including maximizing performance-per-watt, ensuring portability, minimizing latency, and delivering security and consistency at scale.What must happen for successful simplificationTo realize the promise of simplified AI platforms, several things must occur:Strong hardware/software co-design: hardware features that are exposed in software frameworks (e.g., matrix multipliers, accelerator instructions), and conversely, software that is designed to take advantage of underlying hardware.Consistent, robust toolchains and libraries: developers need reliable, well-documented libraries that work across devices. Performance portability is only useful if the tools are stable and well supported.Open ecosystem: hardware vendors, software framework maintainers, and model developers need to cooperate. Standards and shared projects help avoid re-inventing the wheel for every new device or use case.Abstractions that don’t obscure performance: while high-level abstraction helps developers, they must still allow tuning or visibility where needed. The right balance between abstraction and control is key.Security, privacy, and trust built in: especially as more compute shifts to devices (edge/mobile), issues like data protection, safe execution, model integrity, and privacy matter.Arm as one example of ecosystem-led simplification Simplifying AI at scale now hinges on system-wide design, where silicon, software, and developer tools evolve in lockstep. This approach enables AI workloads to run efficiently across diverse environments, from cloud inference clusters to battery-constrained edge devices. It also reduces the overhead of bespoke optimization, making it easier to bring new products to market faster. Arm (Nasdaq:Arm) is advancing this model with a platform-centric focus that pushes hardware-software optimizations up through the software stack. At COMPUTEX 2025, Arm demonstrated how its latest Arm9 CPUs, combined with AI-specific ISA extensions and the Kleidi libraries, enable tighter integration with widely used frameworks like PyTorch, ExecuTorch, ONNX Runtime, and MediaPipe. This alignment reduces the need for custom kernels or hand-tuned operators, allowing developers to unlock hardware performance without abandoning familiar toolchains. The real-world implications are significant. In the data center, Arm-based platforms are delivering improved performance-per-watt, critical for scaling AI workloads sustainably. On consumer devices, these optimizations enable ultra-responsive user experiences and background intelligence that’s always on, yet power efficient.More broadly, the industry is coalescing around simplification as a design imperative, embedding AI support directly into hardware roadmaps, optimizing for software portability, and standardizing support for mainstream AI runtimes. Arm’s approach illustrates how deep integration across the compute stack can make scalable AI a practical reality.Market validation and momentumIn 2025, nearly half of the compute shipped to major hyperscalers will run on Arm-based architectures, a milestone that underscores a significant shift in cloud infrastructure. As AI workloads become more resource-intensive, cloud providers are prioritizing architectures that deliver superior performance-per-watt and support seamless software portability. This evolution marks a strategic pivot toward energy-efficient, scalable infrastructure optimized for the performance and demands of modern AI.At the edge, Arm-compatible inference engines are enabling real-time experiences, such as live translation and always-on voice assistants, on battery-powered devices. These advancements bring powerful AI capabilities directly to users, without sacrificing energy efficiency.Developer momentum is accelerating as well. In a recent collaboration, GitHub and Arm introduced native Arm Linux and Windows runners for GitHub Actions, streamlining CI workflows for Arm-based platforms. These tools lower the barrier to entry for developers and enable more efficient, cross-platform development at scale. What comes nextSimplification doesn’t mean removing complexity entirely; it means managing it in ways that empower innovation. As the AI stack stabilizes, winners will be those who deliver seamless performance across a fragmented landscape.From a future-facing perspective, expect:Benchmarks as guardrails: MLPerf + OSS suites guide where to optimize next.More upstream, fewer forks: Hardware features land in mainstream tools, not custom branches.Convergence of research + production: Faster handoff from papers to product via shared runtimes.ConclusionAI’s next phase isn’t about exotic hardware; it’s also about software that travels well. When the same model lands efficiently on cloud, client, and edge, teams ship faster and spend less time rebuilding the stack.Ecosystem-wide simplification, not brand-led slogans, will separate the winners. The practical playbook is clear: unify platforms, upstream optimizations, and measure with open benchmarks. Explore how Arm AI software platforms are enabling this future — efficiently, securely, and at scale.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by ArmA simpler software stack is the key to portable, scalable AI across cloud and edge. AI is now powering real-world applications, yet fragmented software stacks are holding it back. Developers routinely rebuild the same models for different hardware targets, losing time to glue code instead of shipping features. The good news is that a shift is underway. Unified toolchains and optimized libraries are making it possible to deploy models across platforms without compromising performance.Yet one critical hurdle remains: software complexity. Disparate tools, hardware-specific optimizations, and layered tech stacks continue to bottleneck progress. To unlock the next wave of AI innovation, the industry must pivot decisively away from siloed development and toward streamlined, end-to-end platforms.This transformation is already taking shape. Major cloud providers, edge platform vendors, and open-source communities are converging on unified toolchains that simplify development and accelerate deployment, from cloud to edge. In this article, we’ll explore why simplification is the key to scalable AI, what’s driving this momentum, and how next-gen platforms are turning that vision into real-world results.The bottleneck: fragmentation, complexity, and inefficiencyThe issue isn’t just hardware variety; it’s duplicated effort across frameworks and targets that slows time-to-value.Diverse hardware targets: GPUs, NPUs, CPU-only devices, mobile SoCs, and custom accelerators.Tooling and framework fragmentation: TensorFlow, PyTorch, ONNX, MediaPipe, and others.Edge constraints: Devices require real-time, energy-efficient performance with minimal overhead.According to Gartner Research, these mismatches create a key hurdle: over 60% of AI initiatives stall before production, driven by integration complexity and performance variability. What software simplification looks likeSimplification is coalescing around five moves that cut re-engineering cost and risk:Cross-platform abstraction layers that minimize re-engineering when porting models.Performance-tuned libraries integrated into major ML frameworks.Unified architectural designs that scale from datacenter to mobile.Open standards and runtimes (e.g., ONNX, MLIR) reducing lock-in and improving compatibility.Developer-first ecosystems emphasizing speed, reproducibility, and scalability.These shifts are making AI more accessible, especially for startups and academic teams that previously lacked the resources for bespoke optimization. Projects like Hugging Face’s Optimum and MLPerf benchmarks are also helping standardize and validate cross-hardware performance.Ecosystem momentum and real-world signals Simplification is no longer aspirational; it’s happening now. Across the industry, software considerations are influencing decisions at the IP and silicon design level, resulting in solutions that are production-ready from day one. Major ecosystem players are driving this shift by aligning hardware and software development efforts, delivering tighter integration across the stack.A key catalyst is the rapid rise of edge inference, where AI models are deployed directly on devices rather than in the cloud. This has intensified demand for streamlined software stacks that support end-to-end optimization, from silicon to system to application. Companies like Arm are responding by enabling tighter coupling between their compute platforms and software toolchains, helping developers accelerate time-to-deployment without sacrificing performance or portability. The emergence of multi-modal and general-purpose foundation models (e.g., LLaMA, Gemini, Claude) has also added urgency. These models require flexible runtimes that can scale across cloud and edge environments. AI agents, which interact, adapt, and perform tasks autonomously, further drive the need for high-efficiency, cross-platform software.MLPerf Inference v3.1 included over 13,500 performance results from 26 submitters, validating multi-platform benchmarking of AI workloads. Results spanned both data center and edge devices, demonstrating the diversity of optimized deployments now being tested and shared.Taken together, these signals make clear that the market’s demand and incentives are aligning around a common set of priorities, including maximizing performance-per-watt, ensuring portability, minimizing latency, and delivering security and consistency at scale.What must happen for successful simplificationTo realize the promise of simplified AI platforms, several things must occur:Strong hardware/software co-design: hardware features that are exposed in software frameworks (e.g., matrix multipliers, accelerator instructions), and conversely, software that is designed to take advantage of underlying hardware.Consistent, robust toolchains and libraries: developers need reliable, well-documented libraries that work across devices. Performance portability is only useful if the tools are stable and well supported.Open ecosystem: hardware vendors, software framework maintainers, and model developers need to cooperate. Standards and shared projects help avoid re-inventing the wheel for every new device or use case.Abstractions that don’t obscure performance: while high-level abstraction helps developers, they must still allow tuning or visibility where needed. The right balance between abstraction and control is key.Security, privacy, and trust built in: especially as more compute shifts to devices (edge/mobile), issues like data protection, safe execution, model integrity, and privacy matter.Arm as one example of ecosystem-led simplification Simplifying AI at scale now hinges on system-wide design, where silicon, software, and developer tools evolve in lockstep. This approach enables AI workloads to run efficiently across diverse environments, from cloud inference clusters to battery-constrained edge devices. It also reduces the overhead of bespoke optimization, making it easier to bring new products to market faster. Arm (Nasdaq:Arm) is advancing this model with a platform-centric focus that pushes hardware-software optimizations up through the software stack. At COMPUTEX 2025, Arm demonstrated how its latest Arm9 CPUs, combined with AI-specific ISA extensions and the Kleidi libraries, enable tighter integration with widely used frameworks like PyTorch, ExecuTorch, ONNX Runtime, and MediaPipe. This alignment reduces the need for custom kernels or hand-tuned operators, allowing developers to unlock hardware performance without abandoning familiar toolchains. The real-world implications are significant. In the data center, Arm-based platforms are delivering improved performance-per-watt, critical for scaling AI workloads sustainably. On consumer devices, these optimizations enable ultra-responsive user experiences and background intelligence that’s always on, yet power efficient.More broadly, the industry is coalescing around simplification as a design imperative, embedding AI support directly into hardware roadmaps, optimizing for software portability, and standardizing support for mainstream AI runtimes. Arm’s approach illustrates how deep integration across the compute stack can make scalable AI a practical reality.Market validation and momentumIn 2025, nearly half of the compute shipped to major hyperscalers will run on Arm-based architectures, a milestone that underscores a significant shift in cloud infrastructure. As AI workloads become more resource-intensive, cloud providers are prioritizing architectures that deliver superior performance-per-watt and support seamless software portability. This evolution marks a strategic pivot toward energy-efficient, scalable infrastructure optimized for the performance and demands of modern AI.At the edge, Arm-compatible inference engines are enabling real-time experiences, such as live translation and always-on voice assistants, on battery-powered devices. These advancements bring powerful AI capabilities directly to users, without sacrificing energy efficiency.Developer momentum is accelerating as well. In a recent collaboration, GitHub and Arm introduced native Arm Linux and Windows runners for GitHub Actions, streamlining CI workflows for Arm-based platforms. These tools lower the barrier to entry for developers and enable more efficient, cross-platform development at scale. What comes nextSimplification doesn’t mean removing complexity entirely; it means managing it in ways that empower innovation. As the AI stack stabilizes, winners will be those who deliver seamless performance across a fragmented landscape.From a future-facing perspective, expect:Benchmarks as guardrails: MLPerf + OSS suites guide where to optimize next.More upstream, fewer forks: Hardware features land in mainstream tools, not custom branches.Convergence of research + production: Faster handoff from papers to product via shared runtimes.ConclusionAI’s next phase isn’t about exotic hardware; it’s also about software that travels well. When the same model lands efficiently on cloud, client, and edge, teams ship faster and spend less time rebuilding the stack.Ecosystem-wide simplification, not brand-led slogans, will separate the winners. The practical playbook is clear: unify platforms, upstream optimizations, and measure with open benchmarks. Explore how Arm AI software platforms are enabling this future — efficiently, securely, and at scale.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5NhML02FGAEkp2yOpsPkrx/b62d547d376660e631c01d70283f7946/AdobeStock_1243259614.jpeg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/how-to-watch-samsung-unveil-its-android-xr-headset-184820772.html",
          "published_at": "Wed, 22 Oct 2025 03:02:32 +0000",
          "title": "How to watch Samsung unveil its Android XR headset",
          "standfirst": "Editor's Note: Samsung has officially announced the $1,800 Galaxy XR headset. You can read our hands-on here and how to order the device here. Samsung is set to officially reveal its long-anticipated Android extended reality (XR) headset, which has been codenamed Project Moohan. The company has scheduled a livestream event for October 21 at 10PM ET. That's just a few hours away, which is pretty much nothing compared to the years of lead-up to this reveal since Samsung and its partners have been teasing this device. The event will be streamed live via the company's YouTube page and on the official Samsung Newsroom site. We don't know how long the stream will be, but Samsung promises that Project Moohan will open up the \"true potential\" of mixed-reality devices. You can bookmark this page and watch it right here. This isn't just a reveal for a mixed-reality headset. Moohan is the very first device that uses Google's new Android XR operating system, which has been specifically designed for XR, VR and AR devices like glasses and headsets. Google has also shown previews of the ecosystem at its I/O developer conference before, and while we've seen bits and pieces of the software (and hardware) before, the final pieces should be available with the keynote today. We don't have official specs about the headset itself, but there have been plenty of leaks and rumors that will be confirmed or refuted during the stream. Leaks have suggested it includes a high-end display, advanced tracking and Gemini integration. These same leaks indicate a potential price tag of $1,800 to $2,800, making it more of a rival to the Apple Vision Pro than Meta's new Ray-Ban Display glasses. Update, October 21 2025, 11:02PM ET This story has been updated with links to Samsung's announcement and to our hands-on of the Galaxy XR. Update, October 21 2025, 2:48PM ET: This story has been updated to point out the event is happening tonight in a few hours and talk about how Google has previously shown previews of its Android XR platform at its developer conference.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/how-to-watch-samsung-unveil-its-android-xr-headset-184820772.html?src=rss",
          "content": "Editor's Note: Samsung has officially announced the $1,800 Galaxy XR headset. You can read our hands-on here and how to order the device here. Samsung is set to officially reveal its long-anticipated Android extended reality (XR) headset, which has been codenamed Project Moohan. The company has scheduled a livestream event for October 21 at 10PM ET. That's just a few hours away, which is pretty much nothing compared to the years of lead-up to this reveal since Samsung and its partners have been teasing this device. The event will be streamed live via the company's YouTube page and on the official Samsung Newsroom site. We don't know how long the stream will be, but Samsung promises that Project Moohan will open up the \"true potential\" of mixed-reality devices. You can bookmark this page and watch it right here. This isn't just a reveal for a mixed-reality headset. Moohan is the very first device that uses Google's new Android XR operating system, which has been specifically designed for XR, VR and AR devices like glasses and headsets. Google has also shown previews of the ecosystem at its I/O developer conference before, and while we've seen bits and pieces of the software (and hardware) before, the final pieces should be available with the keynote today. We don't have official specs about the headset itself, but there have been plenty of leaks and rumors that will be confirmed or refuted during the stream. Leaks have suggested it includes a high-end display, advanced tracking and Gemini integration. These same leaks indicate a potential price tag of $1,800 to $2,800, making it more of a rival to the Apple Vision Pro than Meta's new Ray-Ban Display glasses. Update, October 21 2025, 11:02PM ET This story has been updated with links to Samsung's announcement and to our hands-on of the Galaxy XR. Update, October 21 2025, 2:48PM ET: This story has been updated to point out the event is happening tonight in a few hours and talk about how Google has previously shown previews of its Android XR platform at its developer conference.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/how-to-watch-samsung-unveil-its-android-xr-headset-184820772.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/why-the-samsung-galaxy-xr-can-support-almost-all-android-apps-021000889.html",
          "published_at": "Wed, 22 Oct 2025 02:10:00 +0000",
          "title": "Why the Samsung Galaxy XR can support 'almost all' Android apps",
          "standfirst": "The Samsung Galaxy XR is designed to be a showcase for Android XR, Google's new AR / VR operating system, but unlike competing mixed reality headsets, Google says there will be few limits on the apps the Galaxy XR will actually be able to run. In fact, a Google spokesperson tells Engadget that \"almost all Android apps will automatically be made available without any additional development effort.\"Obviously, Google and Samsung would love deliberately designed spatial experiences for their new hardware, but almost all existing Android apps, regardless if they were made for phones or not, will be considered \"Android XR compatible mobile apps\" once the headset launches. That means they'll run in a floating spatial panel that can be moved around the virtual space surrounding you, and per Google's Android XR developer guidelines, will automatically support core XR input methods like eye and hand tracking, along with the usual suspects like controllers, mice and keyboards. They should also run and look like they would on a smartphone or tablet. \"Apps that specify compact sizes show up accordingly and apps that allow for resizing can be resized in XR. These apps do not run in compatibility mode and won’t be letterboxed,\" Google says.The only apps that won't make the cut are ones that require features a given Android XR device doesn't support, like GPS. And in the case of apps that are already updated to work on large screens, or that are \"adaptive apps\" designed to reflow and change size depending on the Android device they're running on, things will be even smoother. Google says adaptive design will be expected to be the default going forward, an effort that started with this year's release of Android 16. “Many APIs restricting size will be ignored on larger screens (which includes Android XR),” Google’s spokesperson said, because the company ultimately wants Android apps to feel responsive whether they’re on a phone, an in-car display or an XR headset.Apple tried a similar, but more limited approach with the launch of visionOS and the Vision Pro by letting developers list their iOS and iPadOS apps in the visionOS App Store. The move produced mixed results, and a dearth of real visionOS apps. An app designed with a device in mind is better than one that's not, but Google does at least appear to have set Android developers up for a slightly smoother ride. Considering the Galaxy XR's cheaper price when compared to the Vision Pro, they might also have a bigger audience to make apps for, too.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/why-the-samsung-galaxy-xr-can-support-almost-all-android-apps-021000889.html?src=rss",
          "content": "The Samsung Galaxy XR is designed to be a showcase for Android XR, Google's new AR / VR operating system, but unlike competing mixed reality headsets, Google says there will be few limits on the apps the Galaxy XR will actually be able to run. In fact, a Google spokesperson tells Engadget that \"almost all Android apps will automatically be made available without any additional development effort.\"Obviously, Google and Samsung would love deliberately designed spatial experiences for their new hardware, but almost all existing Android apps, regardless if they were made for phones or not, will be considered \"Android XR compatible mobile apps\" once the headset launches. That means they'll run in a floating spatial panel that can be moved around the virtual space surrounding you, and per Google's Android XR developer guidelines, will automatically support core XR input methods like eye and hand tracking, along with the usual suspects like controllers, mice and keyboards. They should also run and look like they would on a smartphone or tablet. \"Apps that specify compact sizes show up accordingly and apps that allow for resizing can be resized in XR. These apps do not run in compatibility mode and won’t be letterboxed,\" Google says.The only apps that won't make the cut are ones that require features a given Android XR device doesn't support, like GPS. And in the case of apps that are already updated to work on large screens, or that are \"adaptive apps\" designed to reflow and change size depending on the Android device they're running on, things will be even smoother. Google says adaptive design will be expected to be the default going forward, an effort that started with this year's release of Android 16. “Many APIs restricting size will be ignored on larger screens (which includes Android XR),” Google’s spokesperson said, because the company ultimately wants Android apps to feel responsive whether they’re on a phone, an in-car display or an XR headset.Apple tried a similar, but more limited approach with the launch of visionOS and the Vision Pro by letting developers list their iOS and iPadOS apps in the visionOS App Store. The move produced mixed results, and a dearth of real visionOS apps. An app designed with a device in mind is better than one that's not, but Google does at least appear to have set Android developers up for a slightly smoother ride. Considering the Galaxy XR's cheaper price when compared to the Vision Pro, they might also have a bigger audience to make apps for, too.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/why-the-samsung-galaxy-xr-can-support-almost-all-android-apps-021000889.html?src=rss",
          "feed_position": 4
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/samsung-galaxy-xr-hands-on-a-smarter-more-open-take-on-apples-vision-pro-for-half-the-price-020044642.html",
          "published_at": "Wed, 22 Oct 2025 02:00:44 +0000",
          "title": "Samsung Galaxy XR hands-on: A smarter, more open take on Apple's Vision Pro for half the price",
          "standfirst": "Apple's Vision Pro was meant to usher in a new era for headsets. However, its high price and somewhat limited utility resulted in what may be the company's biggest flop in years. Now it's time for Samsung to give things a go with the Galaxy XR. It's a fresh take on modern mixed reality goggles developed through deep partnerships with Qualcomm and Google and it attempts to address some of the Vision Pro's biggest shortcomings. The hardware While both Apple and Samsung's headsets have a lot of similarities (like their basic design and support for features such as hand and eye tracking), there are also some very important differences. First, at $1,800, the Galaxy XR is essentially half the price of the Vision Pro (including the new M5-powered model). Second, instead of Apple’s homegrown OS, Samsung's headset is the first to run Google's new Android XR platform, which combines a lot of familiar elements from its mobile counterpart but with a bigger emphasis on AI and Gemini-based voice controls. And third, because Samsung relied more on partners like Google and Qualcomm, the Galaxy XR feels like it's built around a larger, more open ecosystem that plays nicely with a wider range of third-party devices and software. The Galaxy XR fundamentally doesn't look that much different from the Vision Pro. It features a large visor in front with an assortment of 13 different exterior sensors to support inside-out tracking, passthrough vision and hand recognition. There are some additional sensors inside for eye and face tracking. There's also a connector for the wire that leads to its external clip-on battery pack alongside built-in speakers with spatial audio. The one big departure is that unlike the Vision Pro, the Galaxy XR doesn't have an outward-facing display, so it won't be able to project your face onto the outside of the headset, which is just fine by me. Sam Rutherford for Engadget However, the devil is in the details because while the original Vision Pro weighed between 600 and 650 grams (around 1.3 to 1.4 pounds) depending on the configuration (not including its battery pack), the Galaxy XR is significantly lighter at 545 grams (1.2 pounds). And that's before you consider the new M5 Vision Pro, which has somehow gone backwards by being even heavier at 750-800 grams (around 1.6 pounds). Furthermore, it seems Samsung learned a lot from its rivals by including a much larger and thicker head cushion that helps distribute the weight of the headset more evenly. Granted, during a longer session, I still noticed a bit of pressure and felt relief after taking off the Galaxy XR, but it's nothing like the Vision Pro, which in my experience gets uncomfortable almost immediately. Finally, around back, there's a simple strap with a knob that you can twist to tighten or loosen the headband as necessary. So even without extra support running across the top of your head, getting in and out of the Galaxy XR is much easier and comfier than the Vision Pro. Sam Rutherford for Engadget On the inside, the Galaxy XR is powered by Qualcomm's Snapdragon XR2+ Gen 2 chip with dual micro OLED displays that deliver 4K resolution (3,552 x 3,840) to each eye at up to 90Hz. I wish Samsung was able to go up to a 120Hz refresh rate like on the Vision Pro, but considering the Galaxy XR's slightly higher overall resolution, I'm not that bothered. And I must say, the image quality from this headset is seriously sharp. It's even better than Apple's goggles and it might be the best I've ever used, particularly outside of $10,000+ enterprise-only setups. Once again, when you consider that this thing costs half the price of a Vision Pro, this headset feels like a real accomplishment by Samsung to the point where I wouldn't be surprised if the company is losing money on every unit it sells. In terms of longevity, Samsung says that for general use the Galaxy XR should last around two hours. If you're only watching videos though, that figure is more like two and a half. Thankfully, if you do need to be in mixed reality for longer, you can charge the headset while it's being used. As for security, the Galaxy XR uses iris recognition to skip traditional passwords, which is nice. The platform: Android XR Sometimes, trying out a new software platform can be a little jarring. But that's not really the case for Android XR, which shouldn't present much of a learning curve for anyone who has used other headsets or Google's ubiquitous mobile OS. After putting the goggles on, you can summon a home menu with an app launcher by facing your palm up and touching your index finger and thumb together. From there, you can open apps and menus by moving your hands and pinching icons or rearranging virtual windows by grabbing the anchor point along the bottom and putting them where you want. Sam Rutherford for Engadget Notably, while there is a growing number of new apps made specifically for XR, you still get access to all of your standard Android titles. Those include Google Photos, Google Maps and Youtube, all of which I got a chance to play around with during a 25-minute demo. In Photos, you can browse your pictures normally. However, to take advantage of the Galaxy XR's hardware, Google created a feature that allows the app to convert standard flat images (with help from the cloud) into immersive ones. While the effect isn't true 3D, it adds distinct foreground, midground and background layers to images in a way that makes viewing your photo roll just a bit more interesting. In Maps, you start out with a view of the world before using hand gestures to move and zoom in wherever you want or voice commands to laser in on a specific location. The neat new trick for this app is that if you find bubbles over things like restaurants and stores, you can click those to be transported inside those businesses, where Android XR will stitch together 2D photos to create a simulated 3D environment that you can move and walk around in. Granted, this doesn't have a ton of practical use for most folks unless you want to take a virtual tour of something like a wedding venue. But, the tech is impressive nonetheless. Sam Rutherford for Engadget Finally in the YouTube app, the Galaxy XR did a great job of making standard 360 videos look even better. While quality will always depend on the gear that captured the content, viewing spatial clips was a great way to show off its resolution and image quality. Google says it will also put a new tab on the app to make finding 360 videos easier, though you can always watch the billions of standard flat videos as well. Interestingly, you can use and navigate the Galaxy XR entirely with hand gestures, but voice commands (via Gemini) are also a major part of the Android XR platform. Because the goggles sit on your head, unlike with mobile devices, there's no need to use a wake word every time you want to do something. You just talk and Gemini listens (though you can choose to disable this behavior if you prefer), so this makes voice interactions feel a lot more natural. Because Gemini can also do things like adjust settings or organize all the apps you have open, in addition to answering questions, it feels like Google is starting to deliver on some of those Star Trek moments where you can simply ask the computer to do something and it just happens. Yes, it's still very early, but as a platform, Android XR feels much more like a virtual playground than VisionOS does at the moment. Other features Sam Rutherford for Engadget While I didn't get to test these out myself, there are some other important features worth mentioning. In addition to apps, you can also play your standard selection of Android games like Stardew Valley or connect the headset to your PC (like with Steam Link) to play full desktop titles. Furthermore, I was told that the Galaxy XR can be tethered to a computer and used like a traditional VR headset. And while Samsung is making optional wireless controllers for the Galaxy XR (and a big carrying case), you may not need them at all as you'll also have the ability to pair the goggles with typical Bluetooth-based gamepads along with wireless mice and keyboards. Google also says it's working on a new system called Likenesses that can create personalized avatars for use in video calls and meetings that use data from interior sensors to deliver more realistic expressions. Additionally, you'll be able to use tools like Veo3 to make AI-generated videos while providing prompts using your voice. But this is just scratching the surface of the Galaxy XR's capabilities and I want to use this thing more before offering a final verdict. Early thoughts Sam Rutherford for Engadget In many ways, the Galaxy XR looks and feels like a flagship mixed reality headset in the same vein as the Vision Pro, but for the Android crowd (and Windows users to some extent as well). On top of that, Google has done some interesting things with Android XR to make it feel like there's a much wider range of content and software to view and use. In many ways, the addition of a dedicated AI assistant in Gemini and voice controls feels much more impactful on goggles than a phone because you can't always count on having physical inputs like a mouse or keyboard. And with the Galaxy XR being half the price of the Vision Pro, Samsung and Google have done a lot to address some of the most glaring issues with Apple's rival. In case the price drop wasn't enough, it feels like all the companies involved are doing as much as possible to sweeten the deal. I actually started laughing when I first heard all the discounts and free subscriptions that come with the headset. That's because in addition to the goggles themselves, every Galaxy XR will come with what's being called the Explorer Pack: 12 months of access to Google AI Pro, 12 months of YouTube Premium (which itself includes YouTube Music), 12 months of Google Play Pass, 12 Months of NBA League Pass and a bundle of other custom XR content and apps. So on top of a slick design, top-tier optics and a new platform, Google and Samsung are basically tossing a kitchen sink of apps and memberships in with the headset. Sam Rutherford for Engadget My only reservation is that when it comes to mass adoption, I think smartglasses have supplanted headsets as the next big mainstream play. Granted, there is a lot of technology and software shared between both categories of devices (Google has already teased upcoming Android XR smartglasses) that should allow Samsung or Google to pivot more easily down the line. But the idea that in the future there will be a headset in every home seems less likely every day. Still, as a showcase for the potential of mixed reality and high-end optics, the Galaxy XR is an exciting piece of tech. The Samsung Galaxy XR is available now for $1,800 on Samsung.com. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-galaxy-xr-hands-on-a-smarter-more-open-take-on-apples-vision-pro-for-half-the-price-020044642.html?src=rss",
          "content": "Apple's Vision Pro was meant to usher in a new era for headsets. However, its high price and somewhat limited utility resulted in what may be the company's biggest flop in years. Now it's time for Samsung to give things a go with the Galaxy XR. It's a fresh take on modern mixed reality goggles developed through deep partnerships with Qualcomm and Google and it attempts to address some of the Vision Pro's biggest shortcomings. The hardware While both Apple and Samsung's headsets have a lot of similarities (like their basic design and support for features such as hand and eye tracking), there are also some very important differences. First, at $1,800, the Galaxy XR is essentially half the price of the Vision Pro (including the new M5-powered model). Second, instead of Apple’s homegrown OS, Samsung's headset is the first to run Google's new Android XR platform, which combines a lot of familiar elements from its mobile counterpart but with a bigger emphasis on AI and Gemini-based voice controls. And third, because Samsung relied more on partners like Google and Qualcomm, the Galaxy XR feels like it's built around a larger, more open ecosystem that plays nicely with a wider range of third-party devices and software. The Galaxy XR fundamentally doesn't look that much different from the Vision Pro. It features a large visor in front with an assortment of 13 different exterior sensors to support inside-out tracking, passthrough vision and hand recognition. There are some additional sensors inside for eye and face tracking. There's also a connector for the wire that leads to its external clip-on battery pack alongside built-in speakers with spatial audio. The one big departure is that unlike the Vision Pro, the Galaxy XR doesn't have an outward-facing display, so it won't be able to project your face onto the outside of the headset, which is just fine by me. Sam Rutherford for Engadget However, the devil is in the details because while the original Vision Pro weighed between 600 and 650 grams (around 1.3 to 1.4 pounds) depending on the configuration (not including its battery pack), the Galaxy XR is significantly lighter at 545 grams (1.2 pounds). And that's before you consider the new M5 Vision Pro, which has somehow gone backwards by being even heavier at 750-800 grams (around 1.6 pounds). Furthermore, it seems Samsung learned a lot from its rivals by including a much larger and thicker head cushion that helps distribute the weight of the headset more evenly. Granted, during a longer session, I still noticed a bit of pressure and felt relief after taking off the Galaxy XR, but it's nothing like the Vision Pro, which in my experience gets uncomfortable almost immediately. Finally, around back, there's a simple strap with a knob that you can twist to tighten or loosen the headband as necessary. So even without extra support running across the top of your head, getting in and out of the Galaxy XR is much easier and comfier than the Vision Pro. Sam Rutherford for Engadget On the inside, the Galaxy XR is powered by Qualcomm's Snapdragon XR2+ Gen 2 chip with dual micro OLED displays that deliver 4K resolution (3,552 x 3,840) to each eye at up to 90Hz. I wish Samsung was able to go up to a 120Hz refresh rate like on the Vision Pro, but considering the Galaxy XR's slightly higher overall resolution, I'm not that bothered. And I must say, the image quality from this headset is seriously sharp. It's even better than Apple's goggles and it might be the best I've ever used, particularly outside of $10,000+ enterprise-only setups. Once again, when you consider that this thing costs half the price of a Vision Pro, this headset feels like a real accomplishment by Samsung to the point where I wouldn't be surprised if the company is losing money on every unit it sells. In terms of longevity, Samsung says that for general use the Galaxy XR should last around two hours. If you're only watching videos though, that figure is more like two and a half. Thankfully, if you do need to be in mixed reality for longer, you can charge the headset while it's being used. As for security, the Galaxy XR uses iris recognition to skip traditional passwords, which is nice. The platform: Android XR Sometimes, trying out a new software platform can be a little jarring. But that's not really the case for Android XR, which shouldn't present much of a learning curve for anyone who has used other headsets or Google's ubiquitous mobile OS. After putting the goggles on, you can summon a home menu with an app launcher by facing your palm up and touching your index finger and thumb together. From there, you can open apps and menus by moving your hands and pinching icons or rearranging virtual windows by grabbing the anchor point along the bottom and putting them where you want. Sam Rutherford for Engadget Notably, while there is a growing number of new apps made specifically for XR, you still get access to all of your standard Android titles. Those include Google Photos, Google Maps and Youtube, all of which I got a chance to play around with during a 25-minute demo. In Photos, you can browse your pictures normally. However, to take advantage of the Galaxy XR's hardware, Google created a feature that allows the app to convert standard flat images (with help from the cloud) into immersive ones. While the effect isn't true 3D, it adds distinct foreground, midground and background layers to images in a way that makes viewing your photo roll just a bit more interesting. In Maps, you start out with a view of the world before using hand gestures to move and zoom in wherever you want or voice commands to laser in on a specific location. The neat new trick for this app is that if you find bubbles over things like restaurants and stores, you can click those to be transported inside those businesses, where Android XR will stitch together 2D photos to create a simulated 3D environment that you can move and walk around in. Granted, this doesn't have a ton of practical use for most folks unless you want to take a virtual tour of something like a wedding venue. But, the tech is impressive nonetheless. Sam Rutherford for Engadget Finally in the YouTube app, the Galaxy XR did a great job of making standard 360 videos look even better. While quality will always depend on the gear that captured the content, viewing spatial clips was a great way to show off its resolution and image quality. Google says it will also put a new tab on the app to make finding 360 videos easier, though you can always watch the billions of standard flat videos as well. Interestingly, you can use and navigate the Galaxy XR entirely with hand gestures, but voice commands (via Gemini) are also a major part of the Android XR platform. Because the goggles sit on your head, unlike with mobile devices, there's no need to use a wake word every time you want to do something. You just talk and Gemini listens (though you can choose to disable this behavior if you prefer), so this makes voice interactions feel a lot more natural. Because Gemini can also do things like adjust settings or organize all the apps you have open, in addition to answering questions, it feels like Google is starting to deliver on some of those Star Trek moments where you can simply ask the computer to do something and it just happens. Yes, it's still very early, but as a platform, Android XR feels much more like a virtual playground than VisionOS does at the moment. Other features Sam Rutherford for Engadget While I didn't get to test these out myself, there are some other important features worth mentioning. In addition to apps, you can also play your standard selection of Android games like Stardew Valley or connect the headset to your PC (like with Steam Link) to play full desktop titles. Furthermore, I was told that the Galaxy XR can be tethered to a computer and used like a traditional VR headset. And while Samsung is making optional wireless controllers for the Galaxy XR (and a big carrying case), you may not need them at all as you'll also have the ability to pair the goggles with typical Bluetooth-based gamepads along with wireless mice and keyboards. Google also says it's working on a new system called Likenesses that can create personalized avatars for use in video calls and meetings that use data from interior sensors to deliver more realistic expressions. Additionally, you'll be able to use tools like Veo3 to make AI-generated videos while providing prompts using your voice. But this is just scratching the surface of the Galaxy XR's capabilities and I want to use this thing more before offering a final verdict. Early thoughts Sam Rutherford for Engadget In many ways, the Galaxy XR looks and feels like a flagship mixed reality headset in the same vein as the Vision Pro, but for the Android crowd (and Windows users to some extent as well). On top of that, Google has done some interesting things with Android XR to make it feel like there's a much wider range of content and software to view and use. In many ways, the addition of a dedicated AI assistant in Gemini and voice controls feels much more impactful on goggles than a phone because you can't always count on having physical inputs like a mouse or keyboard. And with the Galaxy XR being half the price of the Vision Pro, Samsung and Google have done a lot to address some of the most glaring issues with Apple's rival. In case the price drop wasn't enough, it feels like all the companies involved are doing as much as possible to sweeten the deal. I actually started laughing when I first heard all the discounts and free subscriptions that come with the headset. That's because in addition to the goggles themselves, every Galaxy XR will come with what's being called the Explorer Pack: 12 months of access to Google AI Pro, 12 months of YouTube Premium (which itself includes YouTube Music), 12 months of Google Play Pass, 12 Months of NBA League Pass and a bundle of other custom XR content and apps. So on top of a slick design, top-tier optics and a new platform, Google and Samsung are basically tossing a kitchen sink of apps and memberships in with the headset. Sam Rutherford for Engadget My only reservation is that when it comes to mass adoption, I think smartglasses have supplanted headsets as the next big mainstream play. Granted, there is a lot of technology and software shared between both categories of devices (Google has already teased upcoming Android XR smartglasses) that should allow Samsung or Google to pivot more easily down the line. But the idea that in the future there will be a headset in every home seems less likely every day. Still, as a showcase for the potential of mixed reality and high-end optics, the Galaxy XR is an exciting piece of tech. The Samsung Galaxy XR is available now for $1,800 on Samsung.com. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/samsung-galaxy-xr-hands-on-a-smarter-more-open-take-on-apples-vision-pro-for-half-the-price-020044642.html?src=rss",
          "feed_position": 5,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/6635b790-aeb7-11f0-9bd7-4a2aefe1b25b"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/how-to-order-the-samsung-galaxy-xr-headset-020008173.html",
          "published_at": "Wed, 22 Oct 2025 02:00:08 +0000",
          "title": "How to order the Samsung Galaxy XR headset",
          "standfirst": "Samsung's take on the Vision Pro is here — and you can already order it. Costing just over half as much as Apple's reality machine, the Galaxy XR has a 4K micro-OLED screen and a 100-degree horizontal field of view. The $1,800 mixed reality headset is available now for pre-order on Samsung's website. The Galaxy XR isn't only a Samsung product. The company developed the long-rumored headset alongside Google and Qualcomm. It's the first Android XR product, a line that will eventually include AI glasses \"and beyond.\" You can read more about the headset and its ecosystem in Engadget's news coverage. Given Google's connection to the Galaxy XR, it isn't too surprising that the company has bonuses for early orders. If you buy the headset before the end of 2025, you'll get \"The Explorer Pack.\" That includes a year of access to Google AI Pro, YouTube Premium and Google Play Pass. Also included until the end of the year is the \"XR Pack.\" This adds three months of YouTube TV, a year of NBA League Pass, NFL Pro Era, Adobe's Project Pulsar, Asteroid and Calm. You can order the Galaxy XR now from Samsung's website and in Samsung Experience Stores. The headset costs $1,800. An optional Galaxy XR Controller costs $250. And somehow, the official Galaxy XR travel case also costs $250, which is — yikes — a lot. Perhaps consider waiting for third-party alternatives on the case front. Samsung is offering a 24-month financing plan for the headset ($75.01 monthly) on its website. Meanwhile, Samsung's stores have that plan as well as a 12-month one ($149 monthly).This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-order-the-samsung-galaxy-xr-headset-020008173.html?src=rss",
          "content": "Samsung's take on the Vision Pro is here — and you can already order it. Costing just over half as much as Apple's reality machine, the Galaxy XR has a 4K micro-OLED screen and a 100-degree horizontal field of view. The $1,800 mixed reality headset is available now for pre-order on Samsung's website. The Galaxy XR isn't only a Samsung product. The company developed the long-rumored headset alongside Google and Qualcomm. It's the first Android XR product, a line that will eventually include AI glasses \"and beyond.\" You can read more about the headset and its ecosystem in Engadget's news coverage. Given Google's connection to the Galaxy XR, it isn't too surprising that the company has bonuses for early orders. If you buy the headset before the end of 2025, you'll get \"The Explorer Pack.\" That includes a year of access to Google AI Pro, YouTube Premium and Google Play Pass. Also included until the end of the year is the \"XR Pack.\" This adds three months of YouTube TV, a year of NBA League Pass, NFL Pro Era, Adobe's Project Pulsar, Asteroid and Calm. You can order the Galaxy XR now from Samsung's website and in Samsung Experience Stores. The headset costs $1,800. An optional Galaxy XR Controller costs $250. And somehow, the official Galaxy XR travel case also costs $250, which is — yikes — a lot. Perhaps consider waiting for third-party alternatives on the case front. Samsung is offering a 24-month financing plan for the headset ($75.01 monthly) on its website. Meanwhile, Samsung's stores have that plan as well as a 12-month one ($149 monthly).This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-order-the-samsung-galaxy-xr-headset-020008173.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/google-and-samsungs-first-android-xr-headset-is-the-1800-galaxy-xr-020004449.html",
          "published_at": "Wed, 22 Oct 2025 02:00:04 +0000",
          "title": "Google and Samsung's first Android XR headset is the $1,800 Galaxy XR",
          "standfirst": "We've known for a while that the first extended reality (or XR) headset from Samsung and Google would debut in 2025. During an event on Tuesday night, Samsung at long last shared more details about the first Android XR device that you'll be able to purchase. The company got really wild and original with the headset's name. You're truly not going to believe what it's called... Actually, it's got the most unsurprising name of all time: Galaxy XR. What's more, you can buy the headset right now in the US and Korea for $1,800. That's just over half of what the Apple Vision Pro costs. Aside from an Android-powered headset that looks very much like an Apple Vision Pro, you might be wondering exactly what you'll be getting in return for forking over 1,800 smackeroos. As expected, Galaxy XR is powered by the Snapdragon XR2+ Gen 2 chipset. Qualcomm worked with Samsung and Google on the headset. The micro OLED display has 29 million pixels (6 million more than the Apple Vision Pro), a resolution of 3,552 x 3,840 and 96 percent of the DCI‑P3 color gamut — four percent more than the Vision Pro. Where Apple does have Samsung beat on the display front is with the refresh rate: the Galaxy XR tops out at 90Hz and the Vision Pro can hit 120Hz. Galaxy XR has dual high-res passthrough cameras to support mixed reality use, six other external cameras for tracking things in the environment and two eye-tracking sensors. The device supports iris recognition for unlocking the headset and entering passwords in some apps. As with the Vision Pro, you can capture 3D photos and video using the headset. Sam Rutherford for Engadget The cameras allow for hand tracking and gesture control, though it's possible to operate Galaxy XR with physical controllers as well. If you prefer, you can pair a keyboard and mouse to the headset or link it to your PC and access your desktop that way. The dual speakers support Dolby Atmos and there are six microphones built in. As for battery life, Samsung says you'll get up to two hours of general use and 2.5 hours of video playback on a charge. That matches the original battery life promises of the original Vision Pro, but Apple said its latest model (which has the new M5 chipset) offers an extra 30 minutes or so of usage. The interpupillary distance of the Galaxy XR's optics is 54~70mm, and it's possible to buy insertable prescription lenses if needed. As for connectivity, the headset supports Wi-Fi 7 and Bluetooth 5.4. Even with a forehead cushion attached, Galaxy XR weighs 545g (1.2lbs), while the latest Apple Vision Pro has a minimum weight of 750g (1.7lbs). The Galaxy XR's battery pack — as with competitor's offerings, the battery is external — weighs 302g (0.7lbs). Samsung claims the Galaxy XR was designed with comfort in mind. \"The headset’s ergonomically balanced frame distributes pressure across the forehead and the back of the head, minimizing facial discomfort while providing steady support,\" the company said in a press release. There's also a detachable light shield that you can employ to block out external light. Google/Unity What you can actually do with Galaxy XR There are no prizes for guessing that Google's generative AI chatbot Gemini is at the heart of Android XR. \"Android XR is the first Android platform built entirely for the Gemini era, and we are incredibly excited to take a significant leap forward today with the launch of Galaxy XR,\" Sameer Samat, Google's president of Android Ecosystem, said. Every Google Play Store app works out of the box on the headset, though of course Google has reworked some for mixed reality. You can use Gemini to navigate Google Maps and ask for personalized recommendations while checking out 3D visuals with Immersive View. Google Photos can bring an extra dimension to 2D photos and videos via auto spatialization. On YouTube, you can ask Gemini to find videos and tell you more details about what you're watching. And, while using the passthrough mode, you can look at any object in your environment and use Circle to Search to look up more info about it. Google has also made new versions of Google TV, Chrome and Meet (because what is mixed reality for if not conference calls?) for Android XR. Multitasking is a factor here as well. The operating system allows users to have multiple, resizable apps open at once. These can be arranged in a virtual space, or you can simply ask Gemini to do that for you. On the entertainment front, you'll be able to stream shows and movies in 4K in a virtual theater setting. You'll have access to a library of 180-degree and 360-degree VR content, and you can view 3D content via a \"spatial\" tab. Some streaming platforms have reworked their apps for Android XR, including Crunchyroll, HBO Max and Peacock. There's a multi-view option for watching sports, with apps from the likes of MLB and Fox Sports available. With Adobe's Project Pulsar (an immersive video editing app), you'll be able to add 3D depth to videos and seemingly place captions behind subjects with ease, if that's something you're interested in. Sam Rutherford for Engadget Galaxy XR has games too. NFL Pro Era — an NFL-licensed virtual reality title that's also on Meta Quest, PlayStation VR and Windows — is available for Android XR. So too is Inside [JOB] by Owlchemy Labs (Vacation Simulator, Job Simulator). For compatible games, Samsung says Gemini can offer real-time coaching, tips and \"enhanced gameplay experiences.\" The arrival of Galaxy XR is an important next step for Google and its grand vision of an Android XR ecosystem. But the company isn't stopping with headsets. It's also making smart glasses, a product category that Meta has been trying to conquer. Samsung and Google are working with Warby Parker on Android XR smart glasses. At I/O earlier this year, we got some hands-on time with a prototype of Google's Android XR glasses. Once again, Galaxy XR will run you $1,800, and Samsung is offering financing options. The Galaxy XR Travel Case and Galaxy XR Controller will each run you $250 — at those prices, they almost need financing options too. Ouch. Anyone who buys Galaxy XR by the end of this year will get an Explorer Pack at no extra cost. This includes 12 months of access to Google AI Pro, YouTube Premium and Google Play Pass. The NFL Pro Era, Project Pulsar, Calm and Asteroid apps are bundled in too. You'll also get NBA League Pass access for the 2025-26 season in the US or 12 months of the Coupang Play Sports Pass in Korea. Charging $1 for each of the first three months of YouTube TV seems a little cheap considering the outlay for Galaxy XR, but it's still a decent perk. YouTube TV typically costs $83 per month. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/google-and-samsungs-first-android-xr-headset-is-the-1800-galaxy-xr-020004449.html?src=rss",
          "content": "We've known for a while that the first extended reality (or XR) headset from Samsung and Google would debut in 2025. During an event on Tuesday night, Samsung at long last shared more details about the first Android XR device that you'll be able to purchase. The company got really wild and original with the headset's name. You're truly not going to believe what it's called... Actually, it's got the most unsurprising name of all time: Galaxy XR. What's more, you can buy the headset right now in the US and Korea for $1,800. That's just over half of what the Apple Vision Pro costs. Aside from an Android-powered headset that looks very much like an Apple Vision Pro, you might be wondering exactly what you'll be getting in return for forking over 1,800 smackeroos. As expected, Galaxy XR is powered by the Snapdragon XR2+ Gen 2 chipset. Qualcomm worked with Samsung and Google on the headset. The micro OLED display has 29 million pixels (6 million more than the Apple Vision Pro), a resolution of 3,552 x 3,840 and 96 percent of the DCI‑P3 color gamut — four percent more than the Vision Pro. Where Apple does have Samsung beat on the display front is with the refresh rate: the Galaxy XR tops out at 90Hz and the Vision Pro can hit 120Hz. Galaxy XR has dual high-res passthrough cameras to support mixed reality use, six other external cameras for tracking things in the environment and two eye-tracking sensors. The device supports iris recognition for unlocking the headset and entering passwords in some apps. As with the Vision Pro, you can capture 3D photos and video using the headset. Sam Rutherford for Engadget The cameras allow for hand tracking and gesture control, though it's possible to operate Galaxy XR with physical controllers as well. If you prefer, you can pair a keyboard and mouse to the headset or link it to your PC and access your desktop that way. The dual speakers support Dolby Atmos and there are six microphones built in. As for battery life, Samsung says you'll get up to two hours of general use and 2.5 hours of video playback on a charge. That matches the original battery life promises of the original Vision Pro, but Apple said its latest model (which has the new M5 chipset) offers an extra 30 minutes or so of usage. The interpupillary distance of the Galaxy XR's optics is 54~70mm, and it's possible to buy insertable prescription lenses if needed. As for connectivity, the headset supports Wi-Fi 7 and Bluetooth 5.4. Even with a forehead cushion attached, Galaxy XR weighs 545g (1.2lbs), while the latest Apple Vision Pro has a minimum weight of 750g (1.7lbs). The Galaxy XR's battery pack — as with competitor's offerings, the battery is external — weighs 302g (0.7lbs). Samsung claims the Galaxy XR was designed with comfort in mind. \"The headset’s ergonomically balanced frame distributes pressure across the forehead and the back of the head, minimizing facial discomfort while providing steady support,\" the company said in a press release. There's also a detachable light shield that you can employ to block out external light. Google/Unity What you can actually do with Galaxy XR There are no prizes for guessing that Google's generative AI chatbot Gemini is at the heart of Android XR. \"Android XR is the first Android platform built entirely for the Gemini era, and we are incredibly excited to take a significant leap forward today with the launch of Galaxy XR,\" Sameer Samat, Google's president of Android Ecosystem, said. Every Google Play Store app works out of the box on the headset, though of course Google has reworked some for mixed reality. You can use Gemini to navigate Google Maps and ask for personalized recommendations while checking out 3D visuals with Immersive View. Google Photos can bring an extra dimension to 2D photos and videos via auto spatialization. On YouTube, you can ask Gemini to find videos and tell you more details about what you're watching. And, while using the passthrough mode, you can look at any object in your environment and use Circle to Search to look up more info about it. Google has also made new versions of Google TV, Chrome and Meet (because what is mixed reality for if not conference calls?) for Android XR. Multitasking is a factor here as well. The operating system allows users to have multiple, resizable apps open at once. These can be arranged in a virtual space, or you can simply ask Gemini to do that for you. On the entertainment front, you'll be able to stream shows and movies in 4K in a virtual theater setting. You'll have access to a library of 180-degree and 360-degree VR content, and you can view 3D content via a \"spatial\" tab. Some streaming platforms have reworked their apps for Android XR, including Crunchyroll, HBO Max and Peacock. There's a multi-view option for watching sports, with apps from the likes of MLB and Fox Sports available. With Adobe's Project Pulsar (an immersive video editing app), you'll be able to add 3D depth to videos and seemingly place captions behind subjects with ease, if that's something you're interested in. Sam Rutherford for Engadget Galaxy XR has games too. NFL Pro Era — an NFL-licensed virtual reality title that's also on Meta Quest, PlayStation VR and Windows — is available for Android XR. So too is Inside [JOB] by Owlchemy Labs (Vacation Simulator, Job Simulator). For compatible games, Samsung says Gemini can offer real-time coaching, tips and \"enhanced gameplay experiences.\" The arrival of Galaxy XR is an important next step for Google and its grand vision of an Android XR ecosystem. But the company isn't stopping with headsets. It's also making smart glasses, a product category that Meta has been trying to conquer. Samsung and Google are working with Warby Parker on Android XR smart glasses. At I/O earlier this year, we got some hands-on time with a prototype of Google's Android XR glasses. Once again, Galaxy XR will run you $1,800, and Samsung is offering financing options. The Galaxy XR Travel Case and Galaxy XR Controller will each run you $250 — at those prices, they almost need financing options too. Ouch. Anyone who buys Galaxy XR by the end of this year will get an Explorer Pack at no extra cost. This includes 12 months of access to Google AI Pro, YouTube Premium and Google Play Pass. The NFL Pro Era, Project Pulsar, Calm and Asteroid apps are bundled in too. You'll also get NBA League Pass access for the 2025-26 season in the US or 12 months of the Coupang Play Sports Pass in Korea. Charging $1 for each of the first three months of YouTube TV seems a little cheap considering the outlay for Galaxy XR, but it's still a decent perk. YouTube TV typically costs $83 per month. This article originally appeared on Engadget at https://www.engadget.com/ar-vr/google-and-samsungs-first-android-xr-headset-is-the-1800-galaxy-xr-020004449.html?src=rss",
          "feed_position": 7,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/5bf711b0-aea9-11f0-b7fa-d4a3d3eb61e4"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/qwens-new-deep-research-update-lets-you-turn-its-reports-into-webpages",
          "published_at": "Tue, 21 Oct 2025 18:32:00 GMT",
          "title": "Qwen's new Deep Research update lets you turn its reports into webpages, podcasts in seconds",
          "standfirst": "Chinese e-commerce giant Alibaba’s famously prolific Qwen Team of AI model researchers and engineers has introduced a major expansion to its Qwen Deep Research tool, which is available as an optional modality the user can activate on the web-based Qwen Chat (a competitor to ChatGPT).The update lets users generate not only comprehensive research reports with well-organized citations, but also interactive web pages and multi-speaker podcasts — all within 1-2 clicks.This functionality is part of a proprietary release, distinct from many of Qwen’s previous open-source model offerings. While the feature relies on the open-source models Qwen3-Coder, Qwen-Image, and Qwen3-TTS to power its core capabilities, the end-to-end experience — including research execution, web deployment, and audio generation — is hosted and operated by Qwen. This means users benefit from a managed, integrated workflow without needing to configure infrastructure. That said, developers with access to the open-source models could theoretically replicate similar functionality on private or commercial systems.The update was announced via the team’s official X account (@Alibaba_Qwen) today, October 21, 2025, stating:“Qwen Deep Research just got a major upgrade. It now creates not only the report, but also a live webpage and a podcast — powered by Qwen3-Coder, Qwen-Image, and Qwen3-TTS. Your insights, now visual and audible.”Multi-Format Research OutputThe core workflow begins with a user request inside the Qwen Chat interface. From there, Qwen collaborates by asking clarifying questions to shape the research scope, pulls data from the web and official sources, and analyzes or resolves any inconsistencies it finds — even generating custom code when needed.A demo video posted by Qwen on X walks through this process on Qwen Chat using the U.S. SaaS market as an example. In it, Qwen retrieves data from multiple industry sources, identifies discrepancies in market size estimates (e.g., $206 billion vs. $253 billion), and highlights ambiguities in the U.S. share of global figures. The assistant comments on differences in scope between sources and calculates a compound annual growth rate (CAGR) of 19.8% from 2020 to 2023, providing contextual analysis to back up the raw numbers.Once the research is complete, users can click on the \"eyeball\" icon below the output result (see screenshot), which will bring up a PDF-style report in the right hand pane.Then, when viewing the report in the right-hand pane, the user can click the \"Create\" button in the upper-right hand corner and select from the following two options:\"Web Dev\" which produces a live, professional-grade web page, automatically deployed and hosted by Qwen, using Qwen3-Coder for structure and Qwen-Image for visuals.\"Podcast,\" which, as it states, produces an audio podcast, featuring dynamic, multi-speaker narration generated by Qwen3-TTS, also hosted by Qwen for easy sharing and playback.This enables users to quickly convert a single research project into multiple forms of content — written, visual, and audible — with minimal extra input.The website includes inline graphics generated by Qwen Image, making it suitable for use in public presentations, classrooms, or publishing. The podcast feature allows users to select between 17 different speaker names as the host and 7 as the co-host, though I wasn&#x27;t able to find a way to preview the voice outputs before selecting them. It appears designed for deep listening on the go. There was no way to change the language output that I could see, so mine came out in English, like my reports and initial prompts, though the Qwen LLMs are multi-modal. The voices were slightly more robotic than other AI tools I&#x27;ve used.Here&#x27;s an example of a web page I generated on commonalities in authoritarian regimes throughout history, another one on UFO or UAP sightings, and below this paragraph, a podcast on UFO or UAP sightings. While the website is hosted via a public link, the podcast must be downloaded by the user and can&#x27;t be linked to publicly, from what I could tell in my brief usage so far.Note the podcast is much different than the actual report — not just a straight read-through audio version of it, rather, a new format of two hosts discussing and bantering about the subject using the report as the jumping off point. The web page versions of the report also include new graphics not found in the PDF report.Comparisons to Google&#x27;s NotebookLMWhile the new capabilities have been well received by many early users, comparisons to other research assistants have surfaced — particularly Google’s NotebookLM, which recently exited beta.AI commentator and newsletter writer Chubby (@kimmonismus) noted on X:“I am really grateful that Qwen provides regular updates. That’s great.But the attempt to build a NotebookLM clone inside Qwen-3-max doesn’t sound very promising compared to Google’s version.”While NotebookLM is built around organizing and querying existing documents and web pages, Qwen Deep Research focuses more on generating new research content from scratch, aggregating sources from the open web, and presenting it across multiple modalities. The comparison suggests that while the two tools overlap in general concept — AI-assisted research — they diverge in approach and target user experience.AvailabilityQwen Deep Research is now live and available through the Qwen Chat app. The feature can be accessed with the following URL.No pricing details have been provided for Qwen3-Max or the specific Deep Research capabilities as of this writing.What&#x27;s Next For Qwen Deep Research?By combining research guidance, data analysis, and multi-format content creation into a single tool, Qwen Deep Research aims to streamline the path from idea to publishable output. The integration of code, visuals, and voice makes it especially attractive to content creators, educators, and independent analysts who want to scale their research into web- or podcast-friendly forms without switching platforms.Still, comparisons to more specialized offerings like NotebookLM raise questions about how Qwen’s generalized approach stacks up on depth, precision, and refinement. Whether the strength of its multi-format execution outweighs those concerns may come down to user priorities — and whether they value single-click publishing over tight integration with existing notes and materials.For now, Qwen is signaling that research doesn’t end with a document — it begins with one.Let me know if you want this repackaged into something shorter or tailored to a particular audience — newsletter, press-style blog, internal team explainer, etc.",
          "content": "Chinese e-commerce giant Alibaba’s famously prolific Qwen Team of AI model researchers and engineers has introduced a major expansion to its Qwen Deep Research tool, which is available as an optional modality the user can activate on the web-based Qwen Chat (a competitor to ChatGPT).The update lets users generate not only comprehensive research reports with well-organized citations, but also interactive web pages and multi-speaker podcasts — all within 1-2 clicks.This functionality is part of a proprietary release, distinct from many of Qwen’s previous open-source model offerings. While the feature relies on the open-source models Qwen3-Coder, Qwen-Image, and Qwen3-TTS to power its core capabilities, the end-to-end experience — including research execution, web deployment, and audio generation — is hosted and operated by Qwen. This means users benefit from a managed, integrated workflow without needing to configure infrastructure. That said, developers with access to the open-source models could theoretically replicate similar functionality on private or commercial systems.The update was announced via the team’s official X account (@Alibaba_Qwen) today, October 21, 2025, stating:“Qwen Deep Research just got a major upgrade. It now creates not only the report, but also a live webpage and a podcast — powered by Qwen3-Coder, Qwen-Image, and Qwen3-TTS. Your insights, now visual and audible.”Multi-Format Research OutputThe core workflow begins with a user request inside the Qwen Chat interface. From there, Qwen collaborates by asking clarifying questions to shape the research scope, pulls data from the web and official sources, and analyzes or resolves any inconsistencies it finds — even generating custom code when needed.A demo video posted by Qwen on X walks through this process on Qwen Chat using the U.S. SaaS market as an example. In it, Qwen retrieves data from multiple industry sources, identifies discrepancies in market size estimates (e.g., $206 billion vs. $253 billion), and highlights ambiguities in the U.S. share of global figures. The assistant comments on differences in scope between sources and calculates a compound annual growth rate (CAGR) of 19.8% from 2020 to 2023, providing contextual analysis to back up the raw numbers.Once the research is complete, users can click on the \"eyeball\" icon below the output result (see screenshot), which will bring up a PDF-style report in the right hand pane.Then, when viewing the report in the right-hand pane, the user can click the \"Create\" button in the upper-right hand corner and select from the following two options:\"Web Dev\" which produces a live, professional-grade web page, automatically deployed and hosted by Qwen, using Qwen3-Coder for structure and Qwen-Image for visuals.\"Podcast,\" which, as it states, produces an audio podcast, featuring dynamic, multi-speaker narration generated by Qwen3-TTS, also hosted by Qwen for easy sharing and playback.This enables users to quickly convert a single research project into multiple forms of content — written, visual, and audible — with minimal extra input.The website includes inline graphics generated by Qwen Image, making it suitable for use in public presentations, classrooms, or publishing. The podcast feature allows users to select between 17 different speaker names as the host and 7 as the co-host, though I wasn&#x27;t able to find a way to preview the voice outputs before selecting them. It appears designed for deep listening on the go. There was no way to change the language output that I could see, so mine came out in English, like my reports and initial prompts, though the Qwen LLMs are multi-modal. The voices were slightly more robotic than other AI tools I&#x27;ve used.Here&#x27;s an example of a web page I generated on commonalities in authoritarian regimes throughout history, another one on UFO or UAP sightings, and below this paragraph, a podcast on UFO or UAP sightings. While the website is hosted via a public link, the podcast must be downloaded by the user and can&#x27;t be linked to publicly, from what I could tell in my brief usage so far.Note the podcast is much different than the actual report — not just a straight read-through audio version of it, rather, a new format of two hosts discussing and bantering about the subject using the report as the jumping off point. The web page versions of the report also include new graphics not found in the PDF report.Comparisons to Google&#x27;s NotebookLMWhile the new capabilities have been well received by many early users, comparisons to other research assistants have surfaced — particularly Google’s NotebookLM, which recently exited beta.AI commentator and newsletter writer Chubby (@kimmonismus) noted on X:“I am really grateful that Qwen provides regular updates. That’s great.But the attempt to build a NotebookLM clone inside Qwen-3-max doesn’t sound very promising compared to Google’s version.”While NotebookLM is built around organizing and querying existing documents and web pages, Qwen Deep Research focuses more on generating new research content from scratch, aggregating sources from the open web, and presenting it across multiple modalities. The comparison suggests that while the two tools overlap in general concept — AI-assisted research — they diverge in approach and target user experience.AvailabilityQwen Deep Research is now live and available through the Qwen Chat app. The feature can be accessed with the following URL.No pricing details have been provided for Qwen3-Max or the specific Deep Research capabilities as of this writing.What&#x27;s Next For Qwen Deep Research?By combining research guidance, data analysis, and multi-format content creation into a single tool, Qwen Deep Research aims to streamline the path from idea to publishable output. The integration of code, visuals, and voice makes it especially attractive to content creators, educators, and independent analysts who want to scale their research into web- or podcast-friendly forms without switching platforms.Still, comparisons to more specialized offerings like NotebookLM raise questions about how Qwen’s generalized approach stacks up on depth, precision, and refinement. Whether the strength of its multi-format execution outweighs those concerns may come down to user priorities — and whether they value single-click publishing over tight integration with existing notes and materials.For now, Qwen is signaling that research doesn’t end with a document — it begins with one.Let me know if you want this repackaged into something shorter or tailored to a particular audience — newsletter, press-style blog, internal team explainer, etc.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5Joxz8qhvStlvnHybvWBpG/5dcda997ed99a05e52cc929b825d01d5/cfr0z3n_realistic_graphic_novel_art_hyperdetailed_overhead_isom_7a652de4-81e1-4145-848c-4a9c6c0969e4.png"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/deepseek-drops-open-source-model-that-compresses-text-10x-through-images",
          "published_at": "Tue, 21 Oct 2025 18:30:00 GMT",
          "title": "DeepSeek drops open-source model that compresses text 10x through images, defying conventions",
          "standfirst": "DeepSeek, the Chinese artificial intelligence research company that has repeatedly challenged assumptions about AI development costs, has released a new model that fundamentally reimagines how large language models process information—and the implications extend far beyond its modest branding as an optical character recognition tool.The company&#x27;s DeepSeek-OCR model, released Monday with full open-source code and weights, achieves what researchers describe as a paradigm inversion: compressing text through visual representation up to 10 times more efficiently than traditional text tokens. The finding challenges a core assumption in AI development and could pave the way for language models with dramatically expanded context windows, potentially reaching tens of millions of tokens.\"We present DeepSeek-OCR as an initial investigation into the feasibility of compressing long contexts via optical 2D mapping,\" the research team wrote in their technical paper. \"Experiments show that when the number of text tokens is within 10 times that of vision tokens (i.e., a compression ratio < 10×), the model can achieve decoding (OCR) precision of 97%.\"The implications have resonated across the AI research community. Andrej Karpathy, co-founder of OpenAI and former director of AI at Tesla, said in a post that the work raises fundamental questions about how AI systems should process information. \"Maybe it makes more sense that all inputs to LLMs should only ever be images,\" Karpathy wrote. \"Even if you happen to have pure text input, maybe you&#x27;d prefer to render it and then feed that in.\"How DeepSeek achieved 10x compression by treating text as imagesWhile DeepSeek marketed the release as an OCR model — a technology for converting images of text into digital characters — the research paper reveals more ambitious goals. The model demonstrates that visual representations can serve as a superior compression medium for textual information, inverting the conventional hierarchy where text tokens were considered more efficient than vision tokens.\"Traditionally, vision LLM tokens almost seemed like an afterthought or &#x27;bolt on&#x27; to the LLM paradigm,\" wrote Jeffrey Emanuel, an AI researcher, in a detailed analysis of the paper. \"And 10k words of English would take up far more space in a multimodal LLM when expressed as intelligible pixels than when expressed as tokens...But that gets inverted now from the ideas in this paper.\"The model&#x27;s architecture consists of two primary components: DeepEncoder, a novel 380-million-parameter vision encoder, and a 3-billion-parameter mixture-of-experts language decoder with 570 million activated parameters. DeepEncoder combines Meta&#x27;s Segment Anything Model (SAM) for local visual perception with OpenAI&#x27;s CLIP model for global visual understanding, connected through a 16x compression module.To validate their compression claims, DeepSeek researchers tested the model on the Fox benchmark, a dataset of diverse document layouts. The results were striking: using just 100 vision tokens, the model achieved 97.3% accuracy on documents containing 700-800 text tokens — representing an effective compression ratio of 7.5x. Even at compression ratios approaching 20x, accuracy remained around 60%.The practical impact: Processing 200,000 pages per day on a single GPUThe efficiency gains translate directly to production capabilities. According to the company, a single Nvidia A100-40G GPU can process more than 200,000 pages per day using DeepSeek-OCR. Scaling to a cluster of 20 servers with eight GPUs each, throughput reaches 33 million pages daily — sufficient to rapidly construct training datasets for other AI models.On OmniDocBench, a comprehensive document parsing benchmark, DeepSeek-OCR outperformed GOT-OCR2.0 (which uses 256 tokens per page) while using only 100 vision tokens. More dramatically, it surpassed MinerU2.0 — which requires more than 6,000 tokens per page on average — while using fewer than 800 vision tokens.DeepSeek designed the model to support five distinct resolution modes, each optimized for different compression ratios and use cases. The \"Tiny\" mode operates at 512×512 resolution with just 64 vision tokens, while \"Gundam\" mode combines multiple resolutions dynamically for complex documents. \"Gundam mode consists of n×640×640 tiles (local views) and a 1024×1024 global view,\" the researchers wrote.Why this breakthrough could unlock 10 million token context windowsThe compression breakthrough has immediate implications for one of the most pressing challenges in AI development: expanding the context windows that determine how much information language models can actively consider. Current state-of-the-art models typically handle context windows measured in hundreds of thousands of tokens. DeepSeek&#x27;s approach suggests a path to windows ten times larger.\"The potential of getting a frontier LLM with a 10 or 20 million token context window is pretty exciting,\" Emanuel wrote. \"You could basically cram all of a company&#x27;s key internal documents into a prompt preamble and cache this with OpenAI and then just add your specific query or prompt on top of that and not have to deal with search tools and still have it be fast and cost-effective.\"The researchers explicitly frame their work in terms of context compression for language models. \"Through DeepSeek-OCR, we demonstrate that vision-text compression can achieve significant token reduction (7-20×) for different historical context stages, offering a promising direction for addressing long-context challenges in large language models,\" they wrote.The paper includes a speculative but intriguing diagram illustrating how the approach could implement memory decay mechanisms similar to human cognition. Older conversation rounds could be progressively downsampled to lower resolutions, consuming fewer tokens while maintaining key information — a form of computational forgetting that mirrors biological memory.How visual processing could eliminate the &#x27;ugly&#x27; tokenizer problemBeyond compression, Karpathy highlighted how the approach challenges fundamental assumptions about how language models should process text. Traditional tokenizers—the systems that break text into units for processing—have long been criticized for their complexity and limitations.\"I already ranted about how much I dislike the tokenizer,\" Karpathy wrote. \"Tokenizers are ugly, separate, not end-to-end stage. It &#x27;imports&#x27; all the ugliness of Unicode, byte encodings, it inherits a lot of historical baggage, security/jailbreak risk (e.g. continuation bytes). It makes two characters that look identical to the eye look as two completely different tokens internally in the network.\"Visual processing of text could eliminate these issues while enabling new capabilities. The approach naturally handles formatting information lost in pure text representations: bold text, colors, layout, embedded images. \"Input can now be processed with bidirectional attention easily and as default, not autoregressive attention - a lot more powerful,\" Karpathy noted.The implications resonate with human cognitive science. Emanuel drew a parallel to Hans Bethe, the renowned physicist who memorized vast amounts of reference data: \"Having vast amounts of task-specific knowledge in your working memory is extremely useful. This seems like a very clever and additive approach to potentially expanding that memory bank by 10x or more.\"The model&#x27;s training: 30 million PDF pages across 100 languagesThe model&#x27;s capabilities rest on an extensive training regimen using diverse data sources. DeepSeek collected 30 million PDF pages covering approximately 100 languages, with Chinese and English accounting for 25 million pages. The training data spans nine document types — academic papers, financial reports, textbooks, newspapers, handwritten notes, and others.Beyond document OCR, the training incorporated what the researchers call \"OCR 2.0\" data: 10 million synthetic charts, 5 million chemical formulas, and 1 million geometric figures. The model also received 20% general vision data for tasks like image captioning and object detection, plus 10% text-only data to maintain language capabilities.The training process employed pipeline parallelism across 160 Nvidia A100-40G GPUs (20 nodes with 8 GPUs each), with the vision encoder divided between two pipeline stages and the language model split across two others. \"For multimodal data, the training speed is 70B tokens/day,\" the researchers reported.Open source release accelerates research and raises competitive questionsTrue to DeepSeek&#x27;s pattern of open development, the company released the complete model weights, training code, and inference scripts on GitHub and Hugging Face. The GitHub repository gained over 4,000 stars within 24 hours of release, according to Dataconomy.The breakthrough raises questions about whether other AI labs have developed similar techniques but kept them proprietary. Emanuel speculated that Google&#x27;s Gemini models, which feature large context windows and strong OCR performance, might employ comparable approaches. \"For all we know, Google could have already figured out something like this, which could explain why Gemini has such a huge context size and is so good and fast at OCR tasks,\" Emanuel wrote.Google&#x27;s Gemini 2.5 Pro offers a 1-million-token context window, with plans to expand to 2 million, though the company has not publicly detailed the technical approaches enabling this capability. OpenAI&#x27;s GPT-5 supports 400,000 tokens, while Anthropic&#x27;s Claude 4.5 offers 200,000 tokens, with a 1-million-token window available in beta for eligible organizations.The unanswered question: Can AI reason over compressed visual tokens?While the compression results are impressive, researchers acknowledge important open questions. \"It&#x27;s not clear how exactly this interacts with the other downstream cognitive functioning of an LLM,\" Emanuel noted. \"Can the model reason as intelligently over those compressed visual tokens as it can using regular text tokens? Does it make the model less articulate by forcing it into a more vision-oriented modality?\"The DeepSeek paper focuses primarily on the compression-decompression capability, measured through OCR accuracy, rather than downstream reasoning performance. This leaves open whether language models could reason effectively over large contexts represented primarily as compressed visual tokens.The researchers acknowledge their work represents \"an initial exploration into the boundaries of vision-text compression.\" They note that \"OCR alone is insufficient to fully validate true context optical compression\" and plan future work including \"digital-optical text interleaved pretraining, needle-in-a-haystack testing, and other evaluations.\"DeepSeek has established a pattern of achieving competitive results with dramatically lower computational resources than Western AI labs. The company&#x27;s earlier DeepSeek-V3 model reportedly cost just $5.6 million to train—though this figure represents only the final training run and excludes R&D and infrastructure costs—compared to hundreds of millions for comparable models from OpenAI and Anthropic.Industry analysts have questioned the $5.6 million figure, with some estimates placing the company&#x27;s total infrastructure and operational costs closer to $1.3 billion, though still lower than American competitors&#x27; spending.The bigger picture: Should language models process text as images?DeepSeek-OCR poses a fundamental question for AI development: should language models process text as text, or as images of text? The research demonstrates that, at least for compression purposes, visual representation offers significant advantages. Whether this translates to effective reasoning over vast contexts remains to be determined.\"From another perspective, optical contexts compression still offers substantial room for research and improvement, representing a promising new direction,\" the researchers concluded in their paper.For the AI industry, the work adds another dimension to the race for longer context windows — a competition that has intensified as language models are applied to increasingly complex tasks requiring vast amounts of information. The open-source release ensures the technique will be widely explored, tested, and potentially integrated into future AI systems.As Karpathy framed the deeper implication: \"OCR is just one of many useful vision -> text tasks. And text -> text tasks can be made to be vision ->text tasks. Not vice versa.\" In other words, the path forward for AI might not run through better tokenizers — it might bypass text tokens altogether.",
          "content": "DeepSeek, the Chinese artificial intelligence research company that has repeatedly challenged assumptions about AI development costs, has released a new model that fundamentally reimagines how large language models process information—and the implications extend far beyond its modest branding as an optical character recognition tool.The company&#x27;s DeepSeek-OCR model, released Monday with full open-source code and weights, achieves what researchers describe as a paradigm inversion: compressing text through visual representation up to 10 times more efficiently than traditional text tokens. The finding challenges a core assumption in AI development and could pave the way for language models with dramatically expanded context windows, potentially reaching tens of millions of tokens.\"We present DeepSeek-OCR as an initial investigation into the feasibility of compressing long contexts via optical 2D mapping,\" the research team wrote in their technical paper. \"Experiments show that when the number of text tokens is within 10 times that of vision tokens (i.e., a compression ratio < 10×), the model can achieve decoding (OCR) precision of 97%.\"The implications have resonated across the AI research community. Andrej Karpathy, co-founder of OpenAI and former director of AI at Tesla, said in a post that the work raises fundamental questions about how AI systems should process information. \"Maybe it makes more sense that all inputs to LLMs should only ever be images,\" Karpathy wrote. \"Even if you happen to have pure text input, maybe you&#x27;d prefer to render it and then feed that in.\"How DeepSeek achieved 10x compression by treating text as imagesWhile DeepSeek marketed the release as an OCR model — a technology for converting images of text into digital characters — the research paper reveals more ambitious goals. The model demonstrates that visual representations can serve as a superior compression medium for textual information, inverting the conventional hierarchy where text tokens were considered more efficient than vision tokens.\"Traditionally, vision LLM tokens almost seemed like an afterthought or &#x27;bolt on&#x27; to the LLM paradigm,\" wrote Jeffrey Emanuel, an AI researcher, in a detailed analysis of the paper. \"And 10k words of English would take up far more space in a multimodal LLM when expressed as intelligible pixels than when expressed as tokens...But that gets inverted now from the ideas in this paper.\"The model&#x27;s architecture consists of two primary components: DeepEncoder, a novel 380-million-parameter vision encoder, and a 3-billion-parameter mixture-of-experts language decoder with 570 million activated parameters. DeepEncoder combines Meta&#x27;s Segment Anything Model (SAM) for local visual perception with OpenAI&#x27;s CLIP model for global visual understanding, connected through a 16x compression module.To validate their compression claims, DeepSeek researchers tested the model on the Fox benchmark, a dataset of diverse document layouts. The results were striking: using just 100 vision tokens, the model achieved 97.3% accuracy on documents containing 700-800 text tokens — representing an effective compression ratio of 7.5x. Even at compression ratios approaching 20x, accuracy remained around 60%.The practical impact: Processing 200,000 pages per day on a single GPUThe efficiency gains translate directly to production capabilities. According to the company, a single Nvidia A100-40G GPU can process more than 200,000 pages per day using DeepSeek-OCR. Scaling to a cluster of 20 servers with eight GPUs each, throughput reaches 33 million pages daily — sufficient to rapidly construct training datasets for other AI models.On OmniDocBench, a comprehensive document parsing benchmark, DeepSeek-OCR outperformed GOT-OCR2.0 (which uses 256 tokens per page) while using only 100 vision tokens. More dramatically, it surpassed MinerU2.0 — which requires more than 6,000 tokens per page on average — while using fewer than 800 vision tokens.DeepSeek designed the model to support five distinct resolution modes, each optimized for different compression ratios and use cases. The \"Tiny\" mode operates at 512×512 resolution with just 64 vision tokens, while \"Gundam\" mode combines multiple resolutions dynamically for complex documents. \"Gundam mode consists of n×640×640 tiles (local views) and a 1024×1024 global view,\" the researchers wrote.Why this breakthrough could unlock 10 million token context windowsThe compression breakthrough has immediate implications for one of the most pressing challenges in AI development: expanding the context windows that determine how much information language models can actively consider. Current state-of-the-art models typically handle context windows measured in hundreds of thousands of tokens. DeepSeek&#x27;s approach suggests a path to windows ten times larger.\"The potential of getting a frontier LLM with a 10 or 20 million token context window is pretty exciting,\" Emanuel wrote. \"You could basically cram all of a company&#x27;s key internal documents into a prompt preamble and cache this with OpenAI and then just add your specific query or prompt on top of that and not have to deal with search tools and still have it be fast and cost-effective.\"The researchers explicitly frame their work in terms of context compression for language models. \"Through DeepSeek-OCR, we demonstrate that vision-text compression can achieve significant token reduction (7-20×) for different historical context stages, offering a promising direction for addressing long-context challenges in large language models,\" they wrote.The paper includes a speculative but intriguing diagram illustrating how the approach could implement memory decay mechanisms similar to human cognition. Older conversation rounds could be progressively downsampled to lower resolutions, consuming fewer tokens while maintaining key information — a form of computational forgetting that mirrors biological memory.How visual processing could eliminate the &#x27;ugly&#x27; tokenizer problemBeyond compression, Karpathy highlighted how the approach challenges fundamental assumptions about how language models should process text. Traditional tokenizers—the systems that break text into units for processing—have long been criticized for their complexity and limitations.\"I already ranted about how much I dislike the tokenizer,\" Karpathy wrote. \"Tokenizers are ugly, separate, not end-to-end stage. It &#x27;imports&#x27; all the ugliness of Unicode, byte encodings, it inherits a lot of historical baggage, security/jailbreak risk (e.g. continuation bytes). It makes two characters that look identical to the eye look as two completely different tokens internally in the network.\"Visual processing of text could eliminate these issues while enabling new capabilities. The approach naturally handles formatting information lost in pure text representations: bold text, colors, layout, embedded images. \"Input can now be processed with bidirectional attention easily and as default, not autoregressive attention - a lot more powerful,\" Karpathy noted.The implications resonate with human cognitive science. Emanuel drew a parallel to Hans Bethe, the renowned physicist who memorized vast amounts of reference data: \"Having vast amounts of task-specific knowledge in your working memory is extremely useful. This seems like a very clever and additive approach to potentially expanding that memory bank by 10x or more.\"The model&#x27;s training: 30 million PDF pages across 100 languagesThe model&#x27;s capabilities rest on an extensive training regimen using diverse data sources. DeepSeek collected 30 million PDF pages covering approximately 100 languages, with Chinese and English accounting for 25 million pages. The training data spans nine document types — academic papers, financial reports, textbooks, newspapers, handwritten notes, and others.Beyond document OCR, the training incorporated what the researchers call \"OCR 2.0\" data: 10 million synthetic charts, 5 million chemical formulas, and 1 million geometric figures. The model also received 20% general vision data for tasks like image captioning and object detection, plus 10% text-only data to maintain language capabilities.The training process employed pipeline parallelism across 160 Nvidia A100-40G GPUs (20 nodes with 8 GPUs each), with the vision encoder divided between two pipeline stages and the language model split across two others. \"For multimodal data, the training speed is 70B tokens/day,\" the researchers reported.Open source release accelerates research and raises competitive questionsTrue to DeepSeek&#x27;s pattern of open development, the company released the complete model weights, training code, and inference scripts on GitHub and Hugging Face. The GitHub repository gained over 4,000 stars within 24 hours of release, according to Dataconomy.The breakthrough raises questions about whether other AI labs have developed similar techniques but kept them proprietary. Emanuel speculated that Google&#x27;s Gemini models, which feature large context windows and strong OCR performance, might employ comparable approaches. \"For all we know, Google could have already figured out something like this, which could explain why Gemini has such a huge context size and is so good and fast at OCR tasks,\" Emanuel wrote.Google&#x27;s Gemini 2.5 Pro offers a 1-million-token context window, with plans to expand to 2 million, though the company has not publicly detailed the technical approaches enabling this capability. OpenAI&#x27;s GPT-5 supports 400,000 tokens, while Anthropic&#x27;s Claude 4.5 offers 200,000 tokens, with a 1-million-token window available in beta for eligible organizations.The unanswered question: Can AI reason over compressed visual tokens?While the compression results are impressive, researchers acknowledge important open questions. \"It&#x27;s not clear how exactly this interacts with the other downstream cognitive functioning of an LLM,\" Emanuel noted. \"Can the model reason as intelligently over those compressed visual tokens as it can using regular text tokens? Does it make the model less articulate by forcing it into a more vision-oriented modality?\"The DeepSeek paper focuses primarily on the compression-decompression capability, measured through OCR accuracy, rather than downstream reasoning performance. This leaves open whether language models could reason effectively over large contexts represented primarily as compressed visual tokens.The researchers acknowledge their work represents \"an initial exploration into the boundaries of vision-text compression.\" They note that \"OCR alone is insufficient to fully validate true context optical compression\" and plan future work including \"digital-optical text interleaved pretraining, needle-in-a-haystack testing, and other evaluations.\"DeepSeek has established a pattern of achieving competitive results with dramatically lower computational resources than Western AI labs. The company&#x27;s earlier DeepSeek-V3 model reportedly cost just $5.6 million to train—though this figure represents only the final training run and excludes R&D and infrastructure costs—compared to hundreds of millions for comparable models from OpenAI and Anthropic.Industry analysts have questioned the $5.6 million figure, with some estimates placing the company&#x27;s total infrastructure and operational costs closer to $1.3 billion, though still lower than American competitors&#x27; spending.The bigger picture: Should language models process text as images?DeepSeek-OCR poses a fundamental question for AI development: should language models process text as text, or as images of text? The research demonstrates that, at least for compression purposes, visual representation offers significant advantages. Whether this translates to effective reasoning over vast contexts remains to be determined.\"From another perspective, optical contexts compression still offers substantial room for research and improvement, representing a promising new direction,\" the researchers concluded in their paper.For the AI industry, the work adds another dimension to the race for longer context windows — a competition that has intensified as language models are applied to increasingly complex tasks requiring vast amounts of information. The open-source release ensures the technique will be widely explored, tested, and potentially integrated into future AI systems.As Karpathy framed the deeper implication: \"OCR is just one of many useful vision -> text tasks. And text -> text tasks can be made to be vision ->text tasks. Not vice versa.\" In other words, the path forward for AI might not run through better tokenizers — it might bypass text tokens altogether.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5e39eq2QQIBDorTJB70Tw8/4a8d11981b981c2e3cf3b504304d424c/nuneybits_Vector_art_of_whale_surfing_data_streams_932353ff-5fc4-4cc9-bb53-0b9658f59281.webp"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/googles-new-vibe-coding-ai-studio-experience-lets-anyone-build-deploy-apps",
          "published_at": "Tue, 21 Oct 2025 17:45:00 GMT",
          "title": "Google's new vibe coding AI Studio experience lets anyone build, deploy apps live in minutes",
          "standfirst": "Google AI Studio has gotten a big vibe coding upgrade with a new interface, buttons, suggestions and community features that allow anyone with an idea for an app — even complete novices, laypeople, or non-developers like yours truly — to bring it into existence and deploy it live, on the web, for anyone to use, within minutes.The updated Build tab is available now at ai.studio/build, and it’s free to start. Users can experiment with building applications without needing to enter payment information upfront, though certain advanced features like Veo 3.1 and Cloud Run deployment require a paid API key.The new features appear to me to make Google&#x27;s AI models and offerings even more competitive, perhaps preferred, for many general users to dedicated AI startup rivals like Anthropic&#x27;s Claude Code and OpenAI&#x27;s Codex, respectively, two \"vibe coding\" focused products that are beloved by developers — but seem to have a higher barrier to entry or may require more technical know-how.A Fresh Start: Redesigned Build ModeThe updated Build tab serves as the entry point to vibe coding. It introduces a new layout and workflow where users can select from Google’s suite of AI models and features to power their applications. The default is Gemini 2.5 Pro, which is great for most cases.Once selections are made, users simply describe what they want to build, and the system automatically assembles the necessary components using Gemini’s APIs.This mode supports mixing capabilities like Nano Banana (a lightweight AI model), Veo (for video understanding), Imagine (for image generation), Flashlight (for performance-optimized inference), and Google Search.Patrick Löber, Developer Relations at Google DeepMind, highlighted that the experience is meant to help users “supercharge your apps with AI” using a simple prompt-to-app pipeline.In a video demo he posted on X and LinedIn, he showed how just a few clicks led to the automatic generation of a garden planning assistant app, complete with layouts, visuals, and a conversational interface.From Prompt to Production: Building and Editing in Real TimeOnce an app is generated, users land in a fully interactive editor. On the left, there’s a traditional code-assist interface where developers can chat with the AI model for help or suggestions. On the right, a code editor displays the full source of the app.Each component—such as React entry points, API calls, or styling files—can be edited directly. Tooltips help users understand what each file does, which is especially useful for those less familiar with TypeScript or frontend frameworks.Apps can be saved to GitHub, downloaded locally, or shared directly. Deployment is possible within the Studio environment or via Cloud Run if advanced scaling or hosting is needed.Inspiration on Demand: The ‘I’m Feeling Lucky’ ButtonOne standout feature in this update is the “I’m Feeling Lucky” button. Designed for users who need a creative jumpstart, it generates randomized app concepts and configures the app setup accordingly. Each press yields a different idea, complete with suggested AI features and components.Examples produced during demos include:An interactive map-based chatbot powered by Google Search and conversational AI.A dream garden designer using image generation and advanced planning tools.A trivia game app with an AI host whose personality users can define, integrating both Imagine and Flashlight with Gemini 2.5 Pro for conversation and reasoning.Logan Kilpatrick, Lead of Product for Google AI Studio and Gemini AI, noted in a demo video of his own that this feature encourages discovery and experimentation. “You get some really, really cool, different experiences,” he said, emphasizing its role in helping users find novel ideas quickly.Hands-On Test: From Prompt to App in 65 SecondsTo test the new workflow, I prompted Gemini with:A randomized dice rolling web application where the user can select between common dice sizes (6 sides, 10 sides, etc) and then see an animated die rolling and choose the color of their die as well.Within 65 seconds (just over a minute) AI Studio returned a fully working web app featuring:Dice size selector (d4, d6, d8, d10, d12, d20)Color customization options for the dieAnimated rolling effect with randomized resultsClean, modern UI built with React, TypeScript, and Tailwind CSSThe platform also generated a complete set of structured files, including App.tsx, constants.ts, and separate components for dice logic and controls. After generation, it was easy to iterate: adding sound effects for each interaction (rolling, choosing a die, changing color) required only a single follow-up prompt to the built-in assistant. This was also suggested by Gemini, too, by the way. From there, the app can be previewed live or exported using built-in controls to:Save to GitHubDownload the full codebaseCopy the project for remixingDeploy via integrated toolsMy brief, hands-on test showed just how quickly even small utility apps can go from idea to interactive prototype—without leaving the browser or writing boilerplate code manually.AI-Suggested Enhancements and Feature RefinementIn addition to code generation, Google AI Studio now offers context-aware feature suggestions. These recommendations, generated by Gemini’s Flashlight capability, analyze the current app and propose relevant improvements.In one example, the system suggested implementing a feature that displays the history of previously generated images in an image studio tab. These iterative enhancements allow builders to expand app functionality over time without starting from scratch.Kilpatrick emphasized that users can continue to refine their projects as they go, combining both automatic generation and manual adjustments. “You can go in and continue to edit and sort of refine the experience that you want iteratively,” he said.Free to Start, Flexible to GrowThe new experience is available at no cost for users who want to experiment, prototype, or build lightweight apps. There’s no requirement to enter credit card information to begin using vibe coding.However, more powerful capabilities — such as using models like Veo 3.1 or deploying through Cloud Run — do require switching to a paid API key.This pricing structure is intended to lower the barrier to entry for experimentation while providing a clear path to scale when needed.Built for All Skill LevelsOne of the central goals of the vibe coding launch is to make AI app development accessible to more people. The system supports both high-level visual builders and low-level code editing, creating a workflow that works for developers across experience levels.Kilpatrick mentioned that while he’s more familiar with Python than TypeScript, he still found the editor useful because of the helpful file descriptions and intuitive layout. This focus on usability could make AI Studio a compelling option for developers exploring AI for the first time.More to Come: A Week of LaunchesThe launch of vibe coding is the first in a series of announcements expected throughout the week. While specific future features haven’t been revealed yet, both Kilpatrick and Löber hinted that additional updates are on the way.With this update, Google AI Studio positions itself as a flexible, user-friendly environment for building AI-powered applications—whether for fun, prototyping, or production deployment. The focus is clear: make the power of Gemini’s APIs accessible without unnecessary complexity.",
          "content": "Google AI Studio has gotten a big vibe coding upgrade with a new interface, buttons, suggestions and community features that allow anyone with an idea for an app — even complete novices, laypeople, or non-developers like yours truly — to bring it into existence and deploy it live, on the web, for anyone to use, within minutes.The updated Build tab is available now at ai.studio/build, and it’s free to start. Users can experiment with building applications without needing to enter payment information upfront, though certain advanced features like Veo 3.1 and Cloud Run deployment require a paid API key.The new features appear to me to make Google&#x27;s AI models and offerings even more competitive, perhaps preferred, for many general users to dedicated AI startup rivals like Anthropic&#x27;s Claude Code and OpenAI&#x27;s Codex, respectively, two \"vibe coding\" focused products that are beloved by developers — but seem to have a higher barrier to entry or may require more technical know-how.A Fresh Start: Redesigned Build ModeThe updated Build tab serves as the entry point to vibe coding. It introduces a new layout and workflow where users can select from Google’s suite of AI models and features to power their applications. The default is Gemini 2.5 Pro, which is great for most cases.Once selections are made, users simply describe what they want to build, and the system automatically assembles the necessary components using Gemini’s APIs.This mode supports mixing capabilities like Nano Banana (a lightweight AI model), Veo (for video understanding), Imagine (for image generation), Flashlight (for performance-optimized inference), and Google Search.Patrick Löber, Developer Relations at Google DeepMind, highlighted that the experience is meant to help users “supercharge your apps with AI” using a simple prompt-to-app pipeline.In a video demo he posted on X and LinedIn, he showed how just a few clicks led to the automatic generation of a garden planning assistant app, complete with layouts, visuals, and a conversational interface.From Prompt to Production: Building and Editing in Real TimeOnce an app is generated, users land in a fully interactive editor. On the left, there’s a traditional code-assist interface where developers can chat with the AI model for help or suggestions. On the right, a code editor displays the full source of the app.Each component—such as React entry points, API calls, or styling files—can be edited directly. Tooltips help users understand what each file does, which is especially useful for those less familiar with TypeScript or frontend frameworks.Apps can be saved to GitHub, downloaded locally, or shared directly. Deployment is possible within the Studio environment or via Cloud Run if advanced scaling or hosting is needed.Inspiration on Demand: The ‘I’m Feeling Lucky’ ButtonOne standout feature in this update is the “I’m Feeling Lucky” button. Designed for users who need a creative jumpstart, it generates randomized app concepts and configures the app setup accordingly. Each press yields a different idea, complete with suggested AI features and components.Examples produced during demos include:An interactive map-based chatbot powered by Google Search and conversational AI.A dream garden designer using image generation and advanced planning tools.A trivia game app with an AI host whose personality users can define, integrating both Imagine and Flashlight with Gemini 2.5 Pro for conversation and reasoning.Logan Kilpatrick, Lead of Product for Google AI Studio and Gemini AI, noted in a demo video of his own that this feature encourages discovery and experimentation. “You get some really, really cool, different experiences,” he said, emphasizing its role in helping users find novel ideas quickly.Hands-On Test: From Prompt to App in 65 SecondsTo test the new workflow, I prompted Gemini with:A randomized dice rolling web application where the user can select between common dice sizes (6 sides, 10 sides, etc) and then see an animated die rolling and choose the color of their die as well.Within 65 seconds (just over a minute) AI Studio returned a fully working web app featuring:Dice size selector (d4, d6, d8, d10, d12, d20)Color customization options for the dieAnimated rolling effect with randomized resultsClean, modern UI built with React, TypeScript, and Tailwind CSSThe platform also generated a complete set of structured files, including App.tsx, constants.ts, and separate components for dice logic and controls. After generation, it was easy to iterate: adding sound effects for each interaction (rolling, choosing a die, changing color) required only a single follow-up prompt to the built-in assistant. This was also suggested by Gemini, too, by the way. From there, the app can be previewed live or exported using built-in controls to:Save to GitHubDownload the full codebaseCopy the project for remixingDeploy via integrated toolsMy brief, hands-on test showed just how quickly even small utility apps can go from idea to interactive prototype—without leaving the browser or writing boilerplate code manually.AI-Suggested Enhancements and Feature RefinementIn addition to code generation, Google AI Studio now offers context-aware feature suggestions. These recommendations, generated by Gemini’s Flashlight capability, analyze the current app and propose relevant improvements.In one example, the system suggested implementing a feature that displays the history of previously generated images in an image studio tab. These iterative enhancements allow builders to expand app functionality over time without starting from scratch.Kilpatrick emphasized that users can continue to refine their projects as they go, combining both automatic generation and manual adjustments. “You can go in and continue to edit and sort of refine the experience that you want iteratively,” he said.Free to Start, Flexible to GrowThe new experience is available at no cost for users who want to experiment, prototype, or build lightweight apps. There’s no requirement to enter credit card information to begin using vibe coding.However, more powerful capabilities — such as using models like Veo 3.1 or deploying through Cloud Run — do require switching to a paid API key.This pricing structure is intended to lower the barrier to entry for experimentation while providing a clear path to scale when needed.Built for All Skill LevelsOne of the central goals of the vibe coding launch is to make AI app development accessible to more people. The system supports both high-level visual builders and low-level code editing, creating a workflow that works for developers across experience levels.Kilpatrick mentioned that while he’s more familiar with Python than TypeScript, he still found the editor useful because of the helpful file descriptions and intuitive layout. This focus on usability could make AI Studio a compelling option for developers exploring AI for the first time.More to Come: A Week of LaunchesThe launch of vibe coding is the first in a series of announcements expected throughout the week. While specific future features haven’t been revealed yet, both Kilpatrick and Löber hinted that additional updates are on the way.With this update, Google AI Studio positions itself as a flexible, user-friendly environment for building AI-powered applications—whether for fun, prototyping, or production deployment. The focus is clear: make the power of Gemini’s APIs accessible without unnecessary complexity.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4kXCoAPJEcNYeIiP3L6Oyd/e2ced747533b5cf5f7b84e9fc7578ace/cfr0z3n_fix_hand_--chaos_35_--ar_9151_--raw_--profile_h57q96c_u_79d5871e-80b7-4587-8fc5-cd2407d695ac.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openais-ai-powered-browser-chatgpt-atlas-launches-on-macos-today-170735742.html",
          "published_at": "Tue, 21 Oct 2025 17:07:35 +0000",
          "title": "OpenAI's AI-powered browser, ChatGPT Atlas, launches on macOS today",
          "standfirst": "OpenAI's long-rumored browser has a name, and you can try it out today — provided you're an Apple user. ChatGPT Atlas is available to download on macOS, with the company promising to bring it to Windows, Android and iOS soon. Atlas integrates ChatGPT directly within the browser interface, allowing users to engage with the chatbot while they're surfing the web — no need to jump between different tabs or copy and paste content. When you select a text field, an icon will appear that allows you to prompt ChatGPT. OpenAI demoed this feature in Gmail where an employee asked the chatbot to polish an email he was writing to a colleague. Naturally, a prompt bar will also appear when you open a new tab, and you can open a sidebar where you can converse with ChatGPT at any time. The more you use Atlas, the more ChatGPT will \"remember\" about your preferences. One of the benefits of this is that you'll be able to more easily filter through your search history. For instance, you can write \"re-open the shoes I looked at yesterday,\" and ChatGPT will know the specific website you want to look at again. Browser memories are optional, and if you decide to enable the feature, you can manage them through the settings menu, and just like any other browser, you can delete your history or go surf the web using an incognito mode. OpenAI also says it won't use the content users browse to train its future models. Atlas also includes an agent mode where ChatGPT can surf the web for you and complete tasks. The feature builds on the Operator tech debuted at the start of the year, and is currently available as a preview within the browser that Plus, Pro and Business accounts can try out. \"It can help you book reservations or flights or even just edit a document that you’re working on,” said Adam Fry, product lead for ChatGPT Search, during the livestream where OpenAI announced Atlas. \"Tabs are great but we haven't seen a lot of browser innovation since then,\" OpenAI CEO Sam Altman at the start of the livestream. “This is just a great browser all-around — it’s smooth, it’s quick, it’s really nice to use.” Rumors that OpenAI was working on its own web browser first surfaced in July. With today's announcement, the company joins an already competitive market. A number of companies, including Opera and Perplexity, released their own \"agentic\" browsers earlier this year. Of course, then there's also Google, which plans to integrate its Gemini AI assistant more deeply into Chrome, the world's most popular browser, over the coming months. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-ai-powered-browser-chatgpt-atlas-launches-on-macos-today-170735742.html?src=rss",
          "content": "OpenAI's long-rumored browser has a name, and you can try it out today — provided you're an Apple user. ChatGPT Atlas is available to download on macOS, with the company promising to bring it to Windows, Android and iOS soon. Atlas integrates ChatGPT directly within the browser interface, allowing users to engage with the chatbot while they're surfing the web — no need to jump between different tabs or copy and paste content. When you select a text field, an icon will appear that allows you to prompt ChatGPT. OpenAI demoed this feature in Gmail where an employee asked the chatbot to polish an email he was writing to a colleague. Naturally, a prompt bar will also appear when you open a new tab, and you can open a sidebar where you can converse with ChatGPT at any time. The more you use Atlas, the more ChatGPT will \"remember\" about your preferences. One of the benefits of this is that you'll be able to more easily filter through your search history. For instance, you can write \"re-open the shoes I looked at yesterday,\" and ChatGPT will know the specific website you want to look at again. Browser memories are optional, and if you decide to enable the feature, you can manage them through the settings menu, and just like any other browser, you can delete your history or go surf the web using an incognito mode. OpenAI also says it won't use the content users browse to train its future models. Atlas also includes an agent mode where ChatGPT can surf the web for you and complete tasks. The feature builds on the Operator tech debuted at the start of the year, and is currently available as a preview within the browser that Plus, Pro and Business accounts can try out. \"It can help you book reservations or flights or even just edit a document that you’re working on,” said Adam Fry, product lead for ChatGPT Search, during the livestream where OpenAI announced Atlas. \"Tabs are great but we haven't seen a lot of browser innovation since then,\" OpenAI CEO Sam Altman at the start of the livestream. “This is just a great browser all-around — it’s smooth, it’s quick, it’s really nice to use.” Rumors that OpenAI was working on its own web browser first surfaced in July. With today's announcement, the company joins an already competitive market. A number of companies, including Opera and Perplexity, released their own \"agentic\" browsers earlier this year. Of course, then there's also Google, which plans to integrate its Gemini AI assistant more deeply into Chrome, the world's most popular browser, over the coming months. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-ai-powered-browser-chatgpt-atlas-launches-on-macos-today-170735742.html?src=rss",
          "feed_position": 15
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/google-fi-will-start-using-ai-to-make-calls-sound-better-170025805.html",
          "published_at": "Tue, 21 Oct 2025 17:00:25 +0000",
          "title": "Google Fi will start using AI to make calls sound better",
          "standfirst": "Google just announced several updates for its digital telecom provider, Google Fi. It's introducing AI-enhanced audio for better sound quality during calls. The company says this will ensure \"optimized audio quality for every call, so you can confidently take calls from a windy park or busy cafe.\" This feature rolls out sometime in November. Google Fi is getting HD/HD+ calling, which should also improve the overall audio quality. The service will soon automatically connect to Wi-Fi when available, with the company touting \"seamless, secure switching.\" As for security, each call and text goes through a VPN. There's no extra cost for this service and it doesn't count against the pre-existing data allocation. The platform will also soon let users make calls and send texts from any web browser. This is coming in December and will feature a new interface with full RCS support, allowing folks to add hi-res photos and videos to message threads. Finally, Google is integrating Gemini into the platform to create an AI-powered billing summary. The company says this offers \"simple, easy explanations of all your billing statements.\" The feature has been in a beta for a while and Google says users have given it \"high positive sentiment.\" These tools are accompanied by a limited-time promo for new subscribers, amounting to 50 percent off for 15 months when bringing in a phone. The discount is only available for the Unlimited Premium and Unlimited Standard plans.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/google-fi-will-start-using-ai-to-make-calls-sound-better-170025805.html?src=rss",
          "content": "Google just announced several updates for its digital telecom provider, Google Fi. It's introducing AI-enhanced audio for better sound quality during calls. The company says this will ensure \"optimized audio quality for every call, so you can confidently take calls from a windy park or busy cafe.\" This feature rolls out sometime in November. Google Fi is getting HD/HD+ calling, which should also improve the overall audio quality. The service will soon automatically connect to Wi-Fi when available, with the company touting \"seamless, secure switching.\" As for security, each call and text goes through a VPN. There's no extra cost for this service and it doesn't count against the pre-existing data allocation. The platform will also soon let users make calls and send texts from any web browser. This is coming in December and will feature a new interface with full RCS support, allowing folks to add hi-res photos and videos to message threads. Finally, Google is integrating Gemini into the platform to create an AI-powered billing summary. The company says this offers \"simple, easy explanations of all your billing statements.\" The feature has been in a beta for a while and Google says users have given it \"high positive sentiment.\" These tools are accompanied by a limited-time promo for new subscribers, amounting to 50 percent off for 15 months when bringing in a phone. The discount is only available for the Unlimited Premium and Unlimited Standard plans.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/google-fi-will-start-using-ai-to-make-calls-sound-better-170025805.html?src=rss",
          "feed_position": 16
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/apple-macbook-pro-m5-14-inch-review-a-huge-graphics-upgrade-for-creators-and-gamers-170009179.html",
          "published_at": "Tue, 21 Oct 2025 17:00:09 +0000",
          "title": "Apple MacBook Pro M5 14-inch review: A huge graphics upgrade for creators and gamers",
          "standfirst": "There was no massive event announcing the M5 MacBook Pro, not even a short promotional video for social media. Instead, Apple dumped all of its new M5 devices on us with a few press releases, a clear sign that there's not much to celebrate this year. But while the new 14-inch MacBook Pro appears to be more of the same on the surface, it also features an impressive graphics upgrade that makes it a decent choice for gaming. And it retains everything I already love about the MacBook Pro: It's still a well-designed machine that's sturdy, fast and offers tons of battery life. What's new in the M5 MacBook Pro The star of the show is Apple's new M5 chip, which sports a 10-core CPU, 10-core GPU and 16 Neural Engine cores. While the company claims it's 20 percent faster than the M4 for multi-threaded applications, the biggest upgrade is the GPU, which is up to 60 percent faster when it comes to games and professional apps. The M4 was no slouch when it came to gaming and media rendering, but the M5 is a more tempting upgrade for anyone using an M1 MacBook Pro or older. Otherwise, it's like I said: more of the same. There's the 14.2-inch Liquid Retina XDR display which offers up to 1,000 nits of full-screen brightness and 1,600 nits of HDR, as well as ProMotion’s smooth 120Hz refresh rate. (Unfortunately, we’ll likely have to wait until next year for an OLED option.) The aluminum case is still rock solid, and the excellent keyboard and trackpad haven't changed a bit. Last year's 12MP Center Stage webcam also makes a return, along with the superb six-speaker sound system. The port situation is also solid. On top of the MagSafe 3 charging connection, there are three Thunderbolt 4 USB-C ports, a full-sized SDXC card reader, HDMI and a headphone jack. (It would be nice to see a gigabit Ethernet port though. That's the one accessory I still regularly connect to almost every laptop.) Devindra Hardawar for Engadget In use: The best gets even better Before I get to the benchmarks and other performance metrics, it's worth pointing out just how pleasant the 14-inch MacBook is to use. Its aluminum frame is smooth to the touch, its screen is bright enough to use in direct sunlight and it always feels blazing fast. While its 3.4-pound frame is noticeably heavier than the 2.7-pound MacBook Air, it's still easy to travel with. And you can certainly tell that the additional weight translates into raw power, especially as you start to stress the MacBook Pro and hear its fans gently spin up. While the MacBook Air is built to be as thin as possible, the MacBook Pro is built to get work done (and look good while doing so). Based on my testing with popular benchmarks and a few games, the M5 MacBook Pro is noticeably faster than the M4 model in tasks that rely on the GPU and NPU. Otherwise, though, it's hard to tell a difference when it comes to basic tasks like booting into macOS, browsing the web and dealing with email. My review unit was equipped with 32GB of RAM, so it had a bit more breathing room than the base model with 16GB of memory. (Pro tip: If you're planning to keep the MacBook Pro for four years or more, it makes sense to get at least 32GB of RAM. You can't upgrade the memory down the line like older laptops, since it's baked directly into the M5 chip.) Computer Geekbench 6 Geekbench 6 GPU Cinebench 2024 Apple MacBook Pro 14-inch (M5, 2025) 4,310/18,003 48,840 197/1,034 | GPU: 6,143 Apple MacBook Pro 14-inch (M4, 2024) 3,797/14,571 37,869 172/979 GPU: 3,770 Apple MacBook Pro 16-inch (M4 Pro, 2024) 3,925/22,456 70,197 178/1,689 GPU 9,295 Apple MacBook Pro 16-inch (M3 Max, 2024) 3,202/21,312 92,344 143/1,686 GPU 13,182 In Geekbench 6, the M5 MacBook Pro was around 500 points faster than the M4 model in single-threaded tasks, and nearly 3,500 points faster for complex multi-threaded work like video rendering. Thanks to the M5's new graphics hardware, it also tested far better in the Geekbench 6 GPU test, reaching around 11,00 points faster than the M4. I noticed a similar result in Cinebench 2024: The M5 MacBook Pro's CPU scores were slightly better than before, but the GPU score was nearly twice as fast as the M4. For real-world gaming performance, I turned to Lies of P, which also surprised me with some major leaps. With the M4 MacBook Pro, I could only get a steady 60 fps with the highest graphics settings in 1080p. With this M5 model, I was able to play at the highest resolution (3024 by 1890) between 70 and 75 fps. It was even smoother as I scaled down the resolution: The MacBook Pro hit 85 to 95 fps in 1,440p and up to 140 fps in 1080p. Those results are in line with what I'd expect from a gaming notebook that costs well over $2,000, which is in line with the $2,200 retail cost of our review unit. Devindra Hardawar for Engadget I still wouldn't recommend a MacBook Pro for anyone who wants to play tons of games, but it's heartening to see Apple making progress on that front. There are more new AAA games hitting the app store, and the M-series chips are fast enough to run most of them well. But the M5 is the first time I'd consider Apple's hardware equivalent to a PC running a video card like NVIDIA's RTX 5070. The M5 MacBook Pro retains the impressive battery life from the previous model, reaching 34 hours and 30 minutes while looping an HD video. I could also use it for more than two full days of work with nothing much stressing the GPU. And once again, the MacBook Pro never feels very hot, even under an intensive workload. The fans are audible, but they don’t get as annoying as the helicopter-like fans from the old Intel MacBook Pros. Devindra Hardawar for Engadget Should you buy the M5 MacBook Pro? If you're looking for a powerful laptop that can handle most heavy-duty workloads, the MacBook Pro will certainly suit your needs. But the difficult choice now is deciding between this 14-inch M5 model, the existing M4 Pro and Max systems, or waiting a few months for the upcoming M5 Pro and M5 Max chips. If you're rendering video and 3D content all day, you're likely better off working with Pro and Max chips, but you'll have to wait several months to see the new M5 options. If you absolutely need a workhorse MacBook Pro today, you'll have to settle for the M4 Pro and M4 Max (which are still far faster than the base M5 chip). But for most creatives, the M5 MacBook Pro offers an impressive balance of power and portability.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apple-macbook-pro-m5-14-inch-review-a-huge-graphics-upgrade-for-creators-and-gamers-170009179.html?src=rss",
          "content": "There was no massive event announcing the M5 MacBook Pro, not even a short promotional video for social media. Instead, Apple dumped all of its new M5 devices on us with a few press releases, a clear sign that there's not much to celebrate this year. But while the new 14-inch MacBook Pro appears to be more of the same on the surface, it also features an impressive graphics upgrade that makes it a decent choice for gaming. And it retains everything I already love about the MacBook Pro: It's still a well-designed machine that's sturdy, fast and offers tons of battery life. What's new in the M5 MacBook Pro The star of the show is Apple's new M5 chip, which sports a 10-core CPU, 10-core GPU and 16 Neural Engine cores. While the company claims it's 20 percent faster than the M4 for multi-threaded applications, the biggest upgrade is the GPU, which is up to 60 percent faster when it comes to games and professional apps. The M4 was no slouch when it came to gaming and media rendering, but the M5 is a more tempting upgrade for anyone using an M1 MacBook Pro or older. Otherwise, it's like I said: more of the same. There's the 14.2-inch Liquid Retina XDR display which offers up to 1,000 nits of full-screen brightness and 1,600 nits of HDR, as well as ProMotion’s smooth 120Hz refresh rate. (Unfortunately, we’ll likely have to wait until next year for an OLED option.) The aluminum case is still rock solid, and the excellent keyboard and trackpad haven't changed a bit. Last year's 12MP Center Stage webcam also makes a return, along with the superb six-speaker sound system. The port situation is also solid. On top of the MagSafe 3 charging connection, there are three Thunderbolt 4 USB-C ports, a full-sized SDXC card reader, HDMI and a headphone jack. (It would be nice to see a gigabit Ethernet port though. That's the one accessory I still regularly connect to almost every laptop.) Devindra Hardawar for Engadget In use: The best gets even better Before I get to the benchmarks and other performance metrics, it's worth pointing out just how pleasant the 14-inch MacBook is to use. Its aluminum frame is smooth to the touch, its screen is bright enough to use in direct sunlight and it always feels blazing fast. While its 3.4-pound frame is noticeably heavier than the 2.7-pound MacBook Air, it's still easy to travel with. And you can certainly tell that the additional weight translates into raw power, especially as you start to stress the MacBook Pro and hear its fans gently spin up. While the MacBook Air is built to be as thin as possible, the MacBook Pro is built to get work done (and look good while doing so). Based on my testing with popular benchmarks and a few games, the M5 MacBook Pro is noticeably faster than the M4 model in tasks that rely on the GPU and NPU. Otherwise, though, it's hard to tell a difference when it comes to basic tasks like booting into macOS, browsing the web and dealing with email. My review unit was equipped with 32GB of RAM, so it had a bit more breathing room than the base model with 16GB of memory. (Pro tip: If you're planning to keep the MacBook Pro for four years or more, it makes sense to get at least 32GB of RAM. You can't upgrade the memory down the line like older laptops, since it's baked directly into the M5 chip.) Computer Geekbench 6 Geekbench 6 GPU Cinebench 2024 Apple MacBook Pro 14-inch (M5, 2025) 4,310/18,003 48,840 197/1,034 | GPU: 6,143 Apple MacBook Pro 14-inch (M4, 2024) 3,797/14,571 37,869 172/979 GPU: 3,770 Apple MacBook Pro 16-inch (M4 Pro, 2024) 3,925/22,456 70,197 178/1,689 GPU 9,295 Apple MacBook Pro 16-inch (M3 Max, 2024) 3,202/21,312 92,344 143/1,686 GPU 13,182 In Geekbench 6, the M5 MacBook Pro was around 500 points faster than the M4 model in single-threaded tasks, and nearly 3,500 points faster for complex multi-threaded work like video rendering. Thanks to the M5's new graphics hardware, it also tested far better in the Geekbench 6 GPU test, reaching around 11,00 points faster than the M4. I noticed a similar result in Cinebench 2024: The M5 MacBook Pro's CPU scores were slightly better than before, but the GPU score was nearly twice as fast as the M4. For real-world gaming performance, I turned to Lies of P, which also surprised me with some major leaps. With the M4 MacBook Pro, I could only get a steady 60 fps with the highest graphics settings in 1080p. With this M5 model, I was able to play at the highest resolution (3024 by 1890) between 70 and 75 fps. It was even smoother as I scaled down the resolution: The MacBook Pro hit 85 to 95 fps in 1,440p and up to 140 fps in 1080p. Those results are in line with what I'd expect from a gaming notebook that costs well over $2,000, which is in line with the $2,200 retail cost of our review unit. Devindra Hardawar for Engadget I still wouldn't recommend a MacBook Pro for anyone who wants to play tons of games, but it's heartening to see Apple making progress on that front. There are more new AAA games hitting the app store, and the M-series chips are fast enough to run most of them well. But the M5 is the first time I'd consider Apple's hardware equivalent to a PC running a video card like NVIDIA's RTX 5070. The M5 MacBook Pro retains the impressive battery life from the previous model, reaching 34 hours and 30 minutes while looping an HD video. I could also use it for more than two full days of work with nothing much stressing the GPU. And once again, the MacBook Pro never feels very hot, even under an intensive workload. The fans are audible, but they don’t get as annoying as the helicopter-like fans from the old Intel MacBook Pros. Devindra Hardawar for Engadget Should you buy the M5 MacBook Pro? If you're looking for a powerful laptop that can handle most heavy-duty workloads, the MacBook Pro will certainly suit your needs. But the difficult choice now is deciding between this 14-inch M5 model, the existing M4 Pro and Max systems, or waiting a few months for the upcoming M5 Pro and M5 Max chips. If you're rendering video and 3D content all day, you're likely better off working with Pro and Max chips, but you'll have to wait several months to see the new M5 options. If you absolutely need a workhorse MacBook Pro today, you'll have to settle for the M4 Pro and M4 Max (which are still far faster than the base M5 chip). But for most creatives, the M5 MacBook Pro offers an impressive balance of power and portability.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apple-macbook-pro-m5-14-inch-review-a-huge-graphics-upgrade-for-creators-and-gamers-170009179.html?src=rss",
          "feed_position": 17,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/01d16580-aded-11f0-a7fe-9a2d2eb17ce5"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/amazons-aws-outage-has-knocked-services-like-alexa-snapchat-fortnite-venmo-and-more-offline-142935812.html",
          "published_at": "Tue, 21 Oct 2025 15:18:46 +0000",
          "title": "Amazon's AWS outage on October 20 knocked services like Alexa, Snapchat, Fortnite, Venmo and more offline for hours",
          "standfirst": "It felt like half of the internet was dealing with a severe hangover on October 20. A severe Amazon Web Services outage took out many, many websites, apps, games and other services that rely on Amazon’s cloud division to stay up and running. That included a long list of popular software like Venmo, Snapchat, Canva and Fortnite. Even Amazon's own assistant Alexa stuttered, and if you were wondering why the internet seemed to be against you — you weren't imagining it. The good news is that, Amazon announced by 6:53PM ET on October 20 that it resolved the \"increased error rates and latencies for AWS Services.\" The company said it \"identified the trigger of the event as DNS resolution issues for the regional DynamoDB service endpoints.\" It ran into more problems as it tried to solve the outage, but it was eventually able to fix everything. \"By 3:01 PM [PT], all AWS services returned to normal operations,\" it said. At about 4:30PM ET on October 20, things seemed to be returning back to normal. Apps like Venmo and Lyft, which were either slow to respond or completely nonresponsive before, were appearing to behave smoothly. As of 1:15PM ET on October 20, multiple services were unavailable, including asking Alexa for the weather or to turn off lights in your home. The Lyft app was also slower to respond than usual, and Venmo transactions were not completing. According to the AWS service health page at the time, Amazon was looking into \"increased error rates and latencies for multiple AWS services\" in the US-EAST-1 region (i.e. data centers in Northern Virginia) as of 3:11AM ET on Monday. By 5:01AM, AWS had figured out that a DNS resolution issue with its DynamoDB API was the cause of the outage. DynamoDB is a database that holds info for AWS clients. At about 12:08PM ET, the company posted a small statement that reiterated the above and added that the \"underlying DNS issue was fully mitigated at 2:24 AM PDT.\" According to the notice, some Amazon \"customers still continue to experience increased error rates with AWS services in the N. Virginia (us-east-1) Region due to issues with launching new EC2 instances.\" Amazon also said Amazon.com and Amazon subsidiaries, as well as AWS customer service support operations have been impacted. “Amazon had the data safely stored, but nobody else could find it for several hours, leaving apps temporarily separated from their data,” Mike Chapple, a teaching professor of IT, analytics and operations at University of Notre Dame, told CNN. “It’s as if large portions of the internet suffered temporary amnesia.” As of 6:35AM, AWS said it had fully mitigated the DNS issue and that \"most AWS Service operations are succeeding normally now.\" However, the knock-on effect caused issues with other AWS services, including EC2, a virtual machine service on which many companies build online applications. At 8:48AM, AWS said it was \"making progress on resolving the issue with new EC2 instance launches in the US-EAST-1 Region.\" It recommended that clients not tie new deployments to specific Availability Zones (i.e. one or more data centers in a given region) \"so that EC2 has flexibility\" in picking a zone that may be a better option. At 9:42AM, Amazon noted on the status page that although it had applied \"multiple mitigations\" across several Availability Zones in US-EAST-1, it was \"still experiencing elevated errors for new EC2 instance launches.\" As such, AWS was \"rate limiting new instance launches to aid recovery.\" The company added at 10:14AM that it was seeing \"significant API errors and connectivity issues across multiple services in the US-EAST-1 Region.\" Even once all the issues are resolved, AWS will have a significant backlog of requests and other factors to process, so it'll take some time for everything to recover. Many, many, many companies use US-EAST-1 for their AWS deployments, which is why it felt like half of the internet was knocked offline on Monday morning. As of mid-morning, tons of websites and other services were sluggish or offering up error messages. Outage reports for a broad swathe of services spiked on Down Detector. Along with Amazon's own services, users reported issues with the likes of banks, airlines, Disney+, Snapchat, Reddit, Lyft, Apple Music, Pinterest, Fortnite, Roblox and The New York Times — sorry to anyone whose Wordle streaks may be at risk. Sites like Reddit have posted their own status updates, and though they don't explicitly mention AWS, it's possible that the services' paths may cross somewhere in the pipelines. AWS offers a lot of useful features to clients, such as the ability for websites and apps to automatically scale compute and server capacity up and down as needed to handle ebbs and flows in traffic. It also has data centers around the world. That kind of infrastructure is attractive to companies that serve a global audience and need to stay online around the clock. As of mid-2025, it was estimated that AWS' share of the worldwide cloud infrastructure market was 30 percent. But incidents such as this highlight that relying on just a few providers to be the backbone of much of the internet is a bit of a problem. Websites affected by Amazon Web Services outage Sites and services that were affected by the AWS outage include: Amazon Amazon Alexa Bank of America Snapchat Reddit Lyft Apple Music Apple TV Pinterest Fortnite Roblox The New York Times Disney+ Venmo Doordash Hulu Grubhub PlayStation Zoom Update, Oct 20 2025, 10:57AM ET: This story has been updated to include a short list of services affected in the intro. Update, Oct 20 2025, 11:17AM ET: This story has been updated to include a reference to Reddit's own status update website. Update, Oct 20 2025, 1:15PM ET: This story has been updated to include a paragraph reflecting the status of popular services like Lyft, Venmo and Alexa, based on our editors' personal experiences as of this time. Update, Oct 20 2025, 3:15PM ET: This story has been updated to include a short statement from Amazon describing a timeline of events, when the underlying issue was mitigated and what parts of Amazon have been impacted. Update, Oct 20 2025, 4:30PM ET: This story has been updated to reflect the status of services like Venmo and Lyft as of Monday afternoon. Update October 20, 2025, 9:21PM ET: This story has been updated with Amazon's latest update that says the issue has been resolved. Update, Oct 21, 2025, 11:18AM ET: Added a list of sites and services confirmed to have been affected by the AWS outage. This article originally appeared on Engadget at https://www.engadget.com/big-tech/amazons-aws-outage-has-knocked-services-like-alexa-snapchat-fortnite-venmo-and-more-offline-142935812.html?src=rss",
          "content": "It felt like half of the internet was dealing with a severe hangover on October 20. A severe Amazon Web Services outage took out many, many websites, apps, games and other services that rely on Amazon’s cloud division to stay up and running. That included a long list of popular software like Venmo, Snapchat, Canva and Fortnite. Even Amazon's own assistant Alexa stuttered, and if you were wondering why the internet seemed to be against you — you weren't imagining it. The good news is that, Amazon announced by 6:53PM ET on October 20 that it resolved the \"increased error rates and latencies for AWS Services.\" The company said it \"identified the trigger of the event as DNS resolution issues for the regional DynamoDB service endpoints.\" It ran into more problems as it tried to solve the outage, but it was eventually able to fix everything. \"By 3:01 PM [PT], all AWS services returned to normal operations,\" it said. At about 4:30PM ET on October 20, things seemed to be returning back to normal. Apps like Venmo and Lyft, which were either slow to respond or completely nonresponsive before, were appearing to behave smoothly. As of 1:15PM ET on October 20, multiple services were unavailable, including asking Alexa for the weather or to turn off lights in your home. The Lyft app was also slower to respond than usual, and Venmo transactions were not completing. According to the AWS service health page at the time, Amazon was looking into \"increased error rates and latencies for multiple AWS services\" in the US-EAST-1 region (i.e. data centers in Northern Virginia) as of 3:11AM ET on Monday. By 5:01AM, AWS had figured out that a DNS resolution issue with its DynamoDB API was the cause of the outage. DynamoDB is a database that holds info for AWS clients. At about 12:08PM ET, the company posted a small statement that reiterated the above and added that the \"underlying DNS issue was fully mitigated at 2:24 AM PDT.\" According to the notice, some Amazon \"customers still continue to experience increased error rates with AWS services in the N. Virginia (us-east-1) Region due to issues with launching new EC2 instances.\" Amazon also said Amazon.com and Amazon subsidiaries, as well as AWS customer service support operations have been impacted. “Amazon had the data safely stored, but nobody else could find it for several hours, leaving apps temporarily separated from their data,” Mike Chapple, a teaching professor of IT, analytics and operations at University of Notre Dame, told CNN. “It’s as if large portions of the internet suffered temporary amnesia.” As of 6:35AM, AWS said it had fully mitigated the DNS issue and that \"most AWS Service operations are succeeding normally now.\" However, the knock-on effect caused issues with other AWS services, including EC2, a virtual machine service on which many companies build online applications. At 8:48AM, AWS said it was \"making progress on resolving the issue with new EC2 instance launches in the US-EAST-1 Region.\" It recommended that clients not tie new deployments to specific Availability Zones (i.e. one or more data centers in a given region) \"so that EC2 has flexibility\" in picking a zone that may be a better option. At 9:42AM, Amazon noted on the status page that although it had applied \"multiple mitigations\" across several Availability Zones in US-EAST-1, it was \"still experiencing elevated errors for new EC2 instance launches.\" As such, AWS was \"rate limiting new instance launches to aid recovery.\" The company added at 10:14AM that it was seeing \"significant API errors and connectivity issues across multiple services in the US-EAST-1 Region.\" Even once all the issues are resolved, AWS will have a significant backlog of requests and other factors to process, so it'll take some time for everything to recover. Many, many, many companies use US-EAST-1 for their AWS deployments, which is why it felt like half of the internet was knocked offline on Monday morning. As of mid-morning, tons of websites and other services were sluggish or offering up error messages. Outage reports for a broad swathe of services spiked on Down Detector. Along with Amazon's own services, users reported issues with the likes of banks, airlines, Disney+, Snapchat, Reddit, Lyft, Apple Music, Pinterest, Fortnite, Roblox and The New York Times — sorry to anyone whose Wordle streaks may be at risk. Sites like Reddit have posted their own status updates, and though they don't explicitly mention AWS, it's possible that the services' paths may cross somewhere in the pipelines. AWS offers a lot of useful features to clients, such as the ability for websites and apps to automatically scale compute and server capacity up and down as needed to handle ebbs and flows in traffic. It also has data centers around the world. That kind of infrastructure is attractive to companies that serve a global audience and need to stay online around the clock. As of mid-2025, it was estimated that AWS' share of the worldwide cloud infrastructure market was 30 percent. But incidents such as this highlight that relying on just a few providers to be the backbone of much of the internet is a bit of a problem. Websites affected by Amazon Web Services outage Sites and services that were affected by the AWS outage include: Amazon Amazon Alexa Bank of America Snapchat Reddit Lyft Apple Music Apple TV Pinterest Fortnite Roblox The New York Times Disney+ Venmo Doordash Hulu Grubhub PlayStation Zoom Update, Oct 20 2025, 10:57AM ET: This story has been updated to include a short list of services affected in the intro. Update, Oct 20 2025, 11:17AM ET: This story has been updated to include a reference to Reddit's own status update website. Update, Oct 20 2025, 1:15PM ET: This story has been updated to include a paragraph reflecting the status of popular services like Lyft, Venmo and Alexa, based on our editors' personal experiences as of this time. Update, Oct 20 2025, 3:15PM ET: This story has been updated to include a short statement from Amazon describing a timeline of events, when the underlying issue was mitigated and what parts of Amazon have been impacted. Update, Oct 20 2025, 4:30PM ET: This story has been updated to reflect the status of services like Venmo and Lyft as of Monday afternoon. Update October 20, 2025, 9:21PM ET: This story has been updated with Amazon's latest update that says the issue has been resolved. Update, Oct 21, 2025, 11:18AM ET: Added a list of sites and services confirmed to have been affected by the AWS outage. This article originally appeared on Engadget at https://www.engadget.com/big-tech/amazons-aws-outage-has-knocked-services-like-alexa-snapchat-fortnite-venmo-and-more-offline-142935812.html?src=rss",
          "feed_position": 20
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/hbo-max-is-getting-even-more-expensive-starting-today-143939446.html",
          "published_at": "Tue, 21 Oct 2025 14:39:39 +0000",
          "title": "HBO Max is getting even more expensive starting today",
          "standfirst": "Yet another streaming platform is asking people to dig deeper into their wallets and pay more to keep using the service. Warner Bros. Discovery (WBD) has jacked up the prices of all HBO Max plans, 16 months after the last increase to the ad-free offerings. The entry-level, ad-supported plan is now $11 per month (an extra $1) or $110 per year ($10 more). HBO Max Standard will run you an extra $1.50 per month at $18.49 or $15 per year at $185 for the annual plan. As for the HBO Max Premium option, subscribers will now have to pay $23 per month (up by $2) or $230 for an annual plan (an increase of $20).The new prices kick in immediately for newcomers. Existing monthly subscribers will start paying more as of November 20 (whenever their next billing cycle starts on or after that date). Yearly subscribers will be notified about the price changes 30 days before their plan renews.WBD CEO David Zaslav suggested in September that price increases were on the way, along with a stricter crackdown on password sharing. \"The fact that this is quality — and that’s true across our company, motion picture, TV production and streaming quality — we all think that gives us a chance to raise prices,\" Zaslav said. \"We think we’re way underpriced.\"The company announced the price increases on the same day that Disney is making several Disney+ plans more expensive. As it happens, some of the Disney+ bundles that are going up in price include HBO Max. News of the price hikes comes just as WBD sticks a For Sale sign out on its lawn. It was reported this month that the company turned down an acquisition offer from Paramount Skydance for being too low. WBD has now confirmed that \"multiple parties\" have expressed interest in buying some or all of the company, and that it's now conducting \"a review of strategic alternatives to maximize shareholder value.\"In June, WBD announced plans to split into two companies. As things stand, Warner Bros. will retain the namesake film, TV and game studios, as well as New Line Cinema, DC Studios, HBO and HBO Max. Discovery Global will have all of the other live cable channels, such as CNN, HGTV, Cartoon Network, Discovery and TLC (it will also be saddled with the lion's share of WBD's debt). That split is slated to take place by mid-2026, but WBD said on Tuesday it would consider other options. \"The Warner Bros. Discovery Board will evaluate a broad range of strategic options, which will include continuing to advance the company's planned separation to completion by mid-2026, a transaction for the entire company or separate transactions for its Warner Bros. and/or Discovery Global businesses,\" WBD said in a press release. \"As part of the review, the company will also consider an alternative separation structure that would enable a merger of Warner Bros. and spin-off of Discovery Global to our shareholders.\" WBD hasn't set a deadline or timetable for completing this review. But given the whole HBO Max naming debacle, it might take the board quite a while to make its mind up.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/hbo-max-is-getting-even-more-expensive-starting-today-143939446.html?src=rss",
          "content": "Yet another streaming platform is asking people to dig deeper into their wallets and pay more to keep using the service. Warner Bros. Discovery (WBD) has jacked up the prices of all HBO Max plans, 16 months after the last increase to the ad-free offerings. The entry-level, ad-supported plan is now $11 per month (an extra $1) or $110 per year ($10 more). HBO Max Standard will run you an extra $1.50 per month at $18.49 or $15 per year at $185 for the annual plan. As for the HBO Max Premium option, subscribers will now have to pay $23 per month (up by $2) or $230 for an annual plan (an increase of $20).The new prices kick in immediately for newcomers. Existing monthly subscribers will start paying more as of November 20 (whenever their next billing cycle starts on or after that date). Yearly subscribers will be notified about the price changes 30 days before their plan renews.WBD CEO David Zaslav suggested in September that price increases were on the way, along with a stricter crackdown on password sharing. \"The fact that this is quality — and that’s true across our company, motion picture, TV production and streaming quality — we all think that gives us a chance to raise prices,\" Zaslav said. \"We think we’re way underpriced.\"The company announced the price increases on the same day that Disney is making several Disney+ plans more expensive. As it happens, some of the Disney+ bundles that are going up in price include HBO Max. News of the price hikes comes just as WBD sticks a For Sale sign out on its lawn. It was reported this month that the company turned down an acquisition offer from Paramount Skydance for being too low. WBD has now confirmed that \"multiple parties\" have expressed interest in buying some or all of the company, and that it's now conducting \"a review of strategic alternatives to maximize shareholder value.\"In June, WBD announced plans to split into two companies. As things stand, Warner Bros. will retain the namesake film, TV and game studios, as well as New Line Cinema, DC Studios, HBO and HBO Max. Discovery Global will have all of the other live cable channels, such as CNN, HGTV, Cartoon Network, Discovery and TLC (it will also be saddled with the lion's share of WBD's debt). That split is slated to take place by mid-2026, but WBD said on Tuesday it would consider other options. \"The Warner Bros. Discovery Board will evaluate a broad range of strategic options, which will include continuing to advance the company's planned separation to completion by mid-2026, a transaction for the entire company or separate transactions for its Warner Bros. and/or Discovery Global businesses,\" WBD said in a press release. \"As part of the review, the company will also consider an alternative separation structure that would enable a merger of Warner Bros. and spin-off of Discovery Global to our shareholders.\" WBD hasn't set a deadline or timetable for completing this review. But given the whole HBO Max naming debacle, it might take the board quite a while to make its mind up.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/hbo-max-is-getting-even-more-expensive-starting-today-143939446.html?src=rss",
          "feed_position": 24
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/perplexity-made-a-tv-app-and-its-coming-to-samsung-sets-143000479.html",
          "published_at": "Tue, 21 Oct 2025 14:30:00 +0000",
          "title": "Perplexity made a TV app and it’s coming to Samsung sets",
          "standfirst": "Samsung is partnering with Perplexity to bring the startup’s AI Search engine to its smart TVs. If you own a 2025 Samsung TV, you can start using the app today. The company will bring the software to older 2024 and 2023 sets later this year via an OTA update. As part of today’s announcement, Perplexity is also offering free 12-month subscriptions to its Pro plan. To redeem the offer, you’ll need to scan the QR code that appears within the new app. As mentioned, Perplexity is an AI search engine. Before OpenAI, Anthropic and others added similar capabilities to their chatbots, Perplexity’s offering was novel, giving users a way to search the web more deeply than even Google allowed at the time. Things have gotten even more competitive in recent months, with Google going all in on AI Mode in Search. Still, if you want to try different, it’s worth seeing what Perplexity has to offer. The company’s Samsung TV app allows users to both type and use their voice to ask questions. No matter how you slice it, this is a curious partnership. Perplexity doesn’t have a great reputation, even when you consider the broader AI industry. In August, Cloudflare accused the company of scraping websites it wasn’t supposed to be. Later that same month, two of Japan’s largest media companies sued the company for copyright infringement, alleging it not only stole information from them but also attributed falsehoods to them. And just last month, Merriam-Webster sued Perplexity as well, again alleging copyright infringement. This article originally appeared on Engadget at https://www.engadget.com/ai/perplexity-made-a-tv-app-and-its-coming-to-samsung-sets-143000479.html?src=rss",
          "content": "Samsung is partnering with Perplexity to bring the startup’s AI Search engine to its smart TVs. If you own a 2025 Samsung TV, you can start using the app today. The company will bring the software to older 2024 and 2023 sets later this year via an OTA update. As part of today’s announcement, Perplexity is also offering free 12-month subscriptions to its Pro plan. To redeem the offer, you’ll need to scan the QR code that appears within the new app. As mentioned, Perplexity is an AI search engine. Before OpenAI, Anthropic and others added similar capabilities to their chatbots, Perplexity’s offering was novel, giving users a way to search the web more deeply than even Google allowed at the time. Things have gotten even more competitive in recent months, with Google going all in on AI Mode in Search. Still, if you want to try different, it’s worth seeing what Perplexity has to offer. The company’s Samsung TV app allows users to both type and use their voice to ask questions. No matter how you slice it, this is a curious partnership. Perplexity doesn’t have a great reputation, even when you consider the broader AI industry. In August, Cloudflare accused the company of scraping websites it wasn’t supposed to be. Later that same month, two of Japan’s largest media companies sued the company for copyright infringement, alleging it not only stole information from them but also attributed falsehoods to them. And just last month, Merriam-Webster sued Perplexity as well, again alleging copyright infringement. This article originally appeared on Engadget at https://www.engadget.com/ai/perplexity-made-a-tv-app-and-its-coming-to-samsung-sets-143000479.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/ipad-pro-m5-review-speed-boost-130046249.html",
          "published_at": "Tue, 21 Oct 2025 13:00:46 +0000",
          "title": "iPad Pro M5 review: Speed boost",
          "standfirst": "Apple is back with the latest version of the iPad Pro, and like the iPad Air earlier this year the surface-level changes are minimal. Like that iPad Air, there’s a new chip on board here. It’s the M5, which was also added to the 14-inch MacBook Pro and Vision Pro. There are new Apple-designed networking chips: the N1 handles Wi-Fi 7, Bluetooth 6 and Thread, while the C1X handles 5G connectivity. Both of those chips debuted in the iPhone Air last month, so this is the first time they’re in an iPad. Finally, the iPad Pro supports fast charging for the first time; you can get to a 50 percent charge in about 30 minutes using a 60W power adaptor. Compared to the redesign Apple introduced with the M4 iPad Pro in 2024, this is very much a minor spec bump. It makes sense for Apple to ensure the iPad Pro has its most performant chips as soon as they are released. If you’re charging customers upwards of $1,000 for an iPad Pro, it had better be on the bleeding edge. (The 13-inch iPad Pro I'm testing with 1TB of storage and 5G connectivity costs $2,099, plus the $349 Magic Keyboard.) As such, the iPad Pro M5 is fairly easy to understand. Want a new iPad Pro? You’re now getting exactly what Apple offered a week ago, plus some impressive performance gains for specific tasks. Almost no one who bought an M4 iPad Pro should upgrade to this one, but anyone using an older model will find a ton to appreciate here. And while the hardware hasn’t radically changed, iPadOS has. The recent iPadOS 26 release introduced an entirely new multitasking system, a significantly improved Files app and more support for background processes, to name just a few of the highlights. Those things are best appreciated on a powerful device with a large screen like the 13-inch iPad Pro M5 I’m reviewing here. For years, the question that has dogged the iPad Pro is when its software would match up to its undeniably impressive hardware. I think the combo of iPadOS 26 paired with this hardware is a winner, but as always the price is going to be a sticking point. M5 As mentioned, the M5 chip is the big change for the iPad Pro, and if you’re coming from a device older than last year’s M4 model you can expect a big performance increase when you start pushing the envelope of what you can do. Before getting into the nitty gritty, here’s a rundown of what’s different from last year. Probably the most significant change is that the M5’s GPU now includes a “neural accelerator” on each of its 10 cores, an architectural tweak that’ll unsurprisingly give the chip more muscle when using the GPU for AI-related tasks. Beyond the neural accelerators, the GPU is also up to 30 percent faster in graphics performance, and the third-generation ray-tracing engine here is up to 45 percent faster in apps using ray tracing. Nathan Ingraham for Engadget The standard CPU cores (four performance, six efficiency) are also faster than last year’s model, though less dramatically so. That’s not a surprise, as each successive M-series chip has gotten similar modest performance gains over the years. (Note that the iPad Pros with 256GB or 512GB of storage only get three performance cores. They also come with 12GB of RAM compared to the 16GB in configurations with more storage, but that’s more than the 8GB of RAM in the last generation’s equivalent options.) The Neural Engine has been upgraded, as well. Apple is also promising big gains in memory bandwidth, which now hits 153GB/s (nearly 30 percent higher than on the M4). Finally, read/write speeds to storage are up to two times faster than in last year’s model. Doing some benchmarking with the Geekbench 6 and Geekbench AI apps show the expected major gains for GPU and AI performance. Single-core and multi-core CPU tests with Geekbench 6 come in at about 15 percent and 10 percent better than the iPad Pro M4, but GPU performance has increased more than 32 percent. Things are more dramatic when you look specifically at the Geekbench AI results. The app offers three scores (single precision, half precision and quantized) and can be run on three different chip backends (CPU, GPU and Neural Engine). When running the CPU- and Neural Engine-based benchmarks, the M5 only bested the M4 by single-digit percentages. But when using the GPU, the M5’s single-precision score was 22.4 percent better than the M4. Half precision and quantized performance was even more impressive — the M5 scored 85 percent and 101 percent better than the M4, respectively. The story this tells is that unless you’re hitting your GPU hard with AI tasks, the M5 isn’t massively better than the M4. Not a huge surprise, and most people who shelled out for an iPad Pro in the last 18 months should still be plenty happy with their purchases. But those GPU scores show off exactly where the M5 can stretch its wings compared to its predecessor. As I’ve only had the iPad Pro M5 for less than a week, I’m still comparing the M4 to M5 iPad Pro on specific AI-focused tasks and in certain apps and will update this review with more details later this week. The caveat with all of this is that while the M5 is incredibly powerful, it’s also overkill for most things that people are going to use an iPad for. An iPad Pro with the M2 chip from 2022 still feels plenty responsive for most standard tasks that don’t require exceptional speed or power. Yes, there are definitely people buying an iPad Pro and maxing out its impressive capabilities, and those who do so will appreciate the performance here. But for everyone else, the M5 alone isn’t going to change how you use the iPad Pro on a day-to-day basis. Apple's 13-inch iPad Pro M5 is on the left; the 11-inch iPad Pro M4 is on the right. Nathan Ingraham for Engadget Hardware and display are still stunning Anyone upgrading from an iPad Pro older than last year’s M4 model is in for a treat far beyond sheer performance. The iPad Pro M5 is physically identical to the prior one, but that doesn’t matter because I think this is still the single most impressive device Apple makes. I went deep into the many changes Apple made last year in my review of the iPad Pro M4, and everything I said there still applies. But to recap, the iPad Pro is extremely portable despite its performance chops. Apple made it about 20 percent thinner and about a quarter-pound lighter than the iPad Pro models Apple sold from 2018 through 2023. This radically improves the experience of using it. If you’re holding it like a tablet, the 13-inch model is now light and thin enough to be comfortable for extended use without having to put it down. Doing anything with the on-screen keyboard while holding it is still pretty awkward and the 11-inch option still feels like the best size for hand-held tasks. But the 13-inch iPad Pro I’m reviewing is noticeably easier to hold than the iPad Air because of its reduced weight and slimmer profile. The only complaint I might have about that thinness is it prevents Apple from shoving a bigger battery in here. The iPad Pro M5 gets the same 10-hour battery life rating (for surfing the web or watching videos) that every iPad has gotten since the tablet was released in 2010. But in recent years, Apple has, to some degree, stopped focusing on making every device as thin as possible at the potential expense of things like performance or battery life. Clearly, performance isn’t an issue here. But the same people who value extended battery life in a thicker device when using things like the MacBook Pro might feel the same here. Nathan Ingraham for Engadget That’s a valid opinion, but a tablet is meant to be held in your hands and carried around with you even more so than a laptop, so I understand why Apple values portability over extending the iPad Pro’s battery life. Plus, the iPad Pro M5’s fast-charging capabilities make it pretty easy to extend its life. Using Apple's new 40W Dynamic Charger that can automatically step up to 60W, I got from 23 percent to 70 percent in 35 minutes. That’s a tad slower than the 50 percent charge in 30 minutes Apple claims, but we’re well within the “close enough” range. One thing I didn’t get to test last year with the iPad Pro M4 was its durability. The tablet’s extremely thin design reminded people of past Apple devices that had had some issues with flexing. After over a year with the previous iPad Pro, I’m not at all worried about this one. I’ve taken an iPad Pro M4 all around the US and internationally with no issues. Granted, it’s usually in its keyboard case, but I’ve also traveled with it in the basic Smart Folio Apple sells and have seen no evidence of bending. I also don’t remember seeing any reports about durability issues from owners over the last 18 months, so I wouldn’t worry about its long-term durability. I don’t have a great read on how long the iPad Pro M5 lasts away from its charger just yet — in the first few days with a new device it’s often downloading a lot of data from backups and doing some optimizing, thus not giving you a great feel for how long it’ll usually last. But so far, performance seems similar to the iPad Air M3 and iPad Pro M4 I’ve reviewed recently. I was getting between seven and eight hours while using the Magic Keyboard, and I’m guessing that I’ll blow past the 10-hour estimate when watching locally-stored video. More details on that to come. Nathan Ingraham for Engadget Performance, check. Design, check. The third thing that continues to impress me about the iPad Pro is its screen. It quite simply has the nicest display I have ever seen on a portable device, be it a laptop, phone or tablet. Apple’s tandem OLED display (two OLED panels layered on top of each other) is the same in all respects as it was last year. That means the 13-inch screen has a 2,752 x 2,064 resolution (264 ppi) and standard brightness that can hit 1,000 nits, or up to 1,600 nits peak for HDR content. Aside from the OLED display, the only display improvements the iPad Pro has that the iPad Air doesn’t is ProMotion support for 120Hz refresh rates as well as a nano-texture glass option for the 1TB and 2TB models. To be clear, though, the iPad Pro’s screen is in a completely different ballpark than the one on the iPad Air. Between the much faster refresh rate, high brightness levels, completely dark blacks and wonderful contrast, there’s no question this screen far surpasses what you’ll find on any other iPad. Professionals who do detailed work in video, photography, drawing with the Apple Pencil Pro or graphic design will appreciate all of these features. But it also makes something like kicking back on a plane to watch a movie more enjoyable. Nathan Ingraham for Engadget iPadOS 26 In last year’s iPad Pro M4 review, I wrote: “Apple has shown no indication it’s going to make iPadOS more like a Mac.” As such, I recommended people not buy an iPad Pro unless they were happy with the limitations that have been inherent to iPadOS for a long time. It took Apple until this summer, but its latest updates rendered my earlier words invalid. With iPadOS 26, Apple pretty much said “screw it” and addressed nearly every big software complaint users have had. As a quick refresher: apps still open in full screen by default, but you can now grab the corner and resize it to any shape you see fit; you can then stack up as many windows as you want in that view. Apps are also much better at remembering their size and position on your screen than ever before. If you swipe up and dismiss all the apps you’re working with and then re-open one, it’s right in the same place you left it. If you want to throw something back in full-screen, the familiar “stoplight” controls from the Mac are available for easy window management. You can swipe up and hold for a second from the bottom of the screen to enter Expose, which shows every open window in your view. Swiping right shows all the full-screen apps you have open. If you have an app in full screen, you can switch back to a windowed app that’ll just float on top of what you’re working in. There’s also a menu bar at the top of the screen that makes it easy to access advanced controls for whatever you’re using. As I said when I first started testing out iPadOS 26 in the summer, the end result of all these changes is that your iPad (no matter which kind) will feel significantly more capable with this software update. And there are other features that power users will appreciate, like a significantly improved Files app. Since it’s easier to have multiple windows, moving things around or dragging and dropping things into apps is a lot simpler. And there are improved sorting options as well, while PDFs finally open in the new Preview app rather than within Files . Background task capabilities have also been significantly expanded. For example, Final Cut Pro can now render video in the background, whereas before, switching to a different app would put the lengthy and intensive process on pause. And developers can tap into this API to use it for their own apps, too. I can’t say for sure that this will answer all the complaints of various iPad Pro owners out there, but I think Apple has gotten about as close as it can without just putting macOS on the device and calling it a day. Even with the big updates to iPadOS, an iPad Pro isn’t for everyone. Plenty of people will still choose a traditional laptop. But the iPad has always offered a pretty unique blend of power and portability, and with better software it’s a more viable option than ever. Nathan Ingraham for Engadget Wrap-up My viewpoint on the iPad Pro hasn’t changed since last year. I still find it a wildly impressive device that is unlike much else you can buy. Just like the last model, it has Apple’s newest chip, the best display Apple has made (aside from its $5,000 Pro XDR monitor) and a physical design that feels almost impossible given how much technology is crammed inside. It’s truly delightful, and it’s even more capable than before thanks to the combination of iPadOS 26 and the M5 chip. However, I still can’t stomach that price. $1,299 for a 13-inch iPad with 256GB of storage, no 5G connectivity and no Magic Keyboard is a lot of money, even if it is as capable as a similarly-priced laptop. Given the incredible technology inside of the iPad Pro, I can understand why it’s so expensive. And it's powerful enough that some buyers will be able to use it for three, four, even five years before they feel the need to update, which makes the up-front investment a little less burdensome. It's not the kind of device you need to replace annually, that's for sure. But unless you are going to use it as your main computer — all day, every day — and know exactly what benefits you’ll get from the iPad over a more traditional laptop, you’re probably better off buying an iPad Air and saving yourself a lot of money.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/ipad-pro-m5-review-speed-boost-130046249.html?src=rss",
          "content": "Apple is back with the latest version of the iPad Pro, and like the iPad Air earlier this year the surface-level changes are minimal. Like that iPad Air, there’s a new chip on board here. It’s the M5, which was also added to the 14-inch MacBook Pro and Vision Pro. There are new Apple-designed networking chips: the N1 handles Wi-Fi 7, Bluetooth 6 and Thread, while the C1X handles 5G connectivity. Both of those chips debuted in the iPhone Air last month, so this is the first time they’re in an iPad. Finally, the iPad Pro supports fast charging for the first time; you can get to a 50 percent charge in about 30 minutes using a 60W power adaptor. Compared to the redesign Apple introduced with the M4 iPad Pro in 2024, this is very much a minor spec bump. It makes sense for Apple to ensure the iPad Pro has its most performant chips as soon as they are released. If you’re charging customers upwards of $1,000 for an iPad Pro, it had better be on the bleeding edge. (The 13-inch iPad Pro I'm testing with 1TB of storage and 5G connectivity costs $2,099, plus the $349 Magic Keyboard.) As such, the iPad Pro M5 is fairly easy to understand. Want a new iPad Pro? You’re now getting exactly what Apple offered a week ago, plus some impressive performance gains for specific tasks. Almost no one who bought an M4 iPad Pro should upgrade to this one, but anyone using an older model will find a ton to appreciate here. And while the hardware hasn’t radically changed, iPadOS has. The recent iPadOS 26 release introduced an entirely new multitasking system, a significantly improved Files app and more support for background processes, to name just a few of the highlights. Those things are best appreciated on a powerful device with a large screen like the 13-inch iPad Pro M5 I’m reviewing here. For years, the question that has dogged the iPad Pro is when its software would match up to its undeniably impressive hardware. I think the combo of iPadOS 26 paired with this hardware is a winner, but as always the price is going to be a sticking point. M5 As mentioned, the M5 chip is the big change for the iPad Pro, and if you’re coming from a device older than last year’s M4 model you can expect a big performance increase when you start pushing the envelope of what you can do. Before getting into the nitty gritty, here’s a rundown of what’s different from last year. Probably the most significant change is that the M5’s GPU now includes a “neural accelerator” on each of its 10 cores, an architectural tweak that’ll unsurprisingly give the chip more muscle when using the GPU for AI-related tasks. Beyond the neural accelerators, the GPU is also up to 30 percent faster in graphics performance, and the third-generation ray-tracing engine here is up to 45 percent faster in apps using ray tracing. Nathan Ingraham for Engadget The standard CPU cores (four performance, six efficiency) are also faster than last year’s model, though less dramatically so. That’s not a surprise, as each successive M-series chip has gotten similar modest performance gains over the years. (Note that the iPad Pros with 256GB or 512GB of storage only get three performance cores. They also come with 12GB of RAM compared to the 16GB in configurations with more storage, but that’s more than the 8GB of RAM in the last generation’s equivalent options.) The Neural Engine has been upgraded, as well. Apple is also promising big gains in memory bandwidth, which now hits 153GB/s (nearly 30 percent higher than on the M4). Finally, read/write speeds to storage are up to two times faster than in last year’s model. Doing some benchmarking with the Geekbench 6 and Geekbench AI apps show the expected major gains for GPU and AI performance. Single-core and multi-core CPU tests with Geekbench 6 come in at about 15 percent and 10 percent better than the iPad Pro M4, but GPU performance has increased more than 32 percent. Things are more dramatic when you look specifically at the Geekbench AI results. The app offers three scores (single precision, half precision and quantized) and can be run on three different chip backends (CPU, GPU and Neural Engine). When running the CPU- and Neural Engine-based benchmarks, the M5 only bested the M4 by single-digit percentages. But when using the GPU, the M5’s single-precision score was 22.4 percent better than the M4. Half precision and quantized performance was even more impressive — the M5 scored 85 percent and 101 percent better than the M4, respectively. The story this tells is that unless you’re hitting your GPU hard with AI tasks, the M5 isn’t massively better than the M4. Not a huge surprise, and most people who shelled out for an iPad Pro in the last 18 months should still be plenty happy with their purchases. But those GPU scores show off exactly where the M5 can stretch its wings compared to its predecessor. As I’ve only had the iPad Pro M5 for less than a week, I’m still comparing the M4 to M5 iPad Pro on specific AI-focused tasks and in certain apps and will update this review with more details later this week. The caveat with all of this is that while the M5 is incredibly powerful, it’s also overkill for most things that people are going to use an iPad for. An iPad Pro with the M2 chip from 2022 still feels plenty responsive for most standard tasks that don’t require exceptional speed or power. Yes, there are definitely people buying an iPad Pro and maxing out its impressive capabilities, and those who do so will appreciate the performance here. But for everyone else, the M5 alone isn’t going to change how you use the iPad Pro on a day-to-day basis. Apple's 13-inch iPad Pro M5 is on the left; the 11-inch iPad Pro M4 is on the right. Nathan Ingraham for Engadget Hardware and display are still stunning Anyone upgrading from an iPad Pro older than last year’s M4 model is in for a treat far beyond sheer performance. The iPad Pro M5 is physically identical to the prior one, but that doesn’t matter because I think this is still the single most impressive device Apple makes. I went deep into the many changes Apple made last year in my review of the iPad Pro M4, and everything I said there still applies. But to recap, the iPad Pro is extremely portable despite its performance chops. Apple made it about 20 percent thinner and about a quarter-pound lighter than the iPad Pro models Apple sold from 2018 through 2023. This radically improves the experience of using it. If you’re holding it like a tablet, the 13-inch model is now light and thin enough to be comfortable for extended use without having to put it down. Doing anything with the on-screen keyboard while holding it is still pretty awkward and the 11-inch option still feels like the best size for hand-held tasks. But the 13-inch iPad Pro I’m reviewing is noticeably easier to hold than the iPad Air because of its reduced weight and slimmer profile. The only complaint I might have about that thinness is it prevents Apple from shoving a bigger battery in here. The iPad Pro M5 gets the same 10-hour battery life rating (for surfing the web or watching videos) that every iPad has gotten since the tablet was released in 2010. But in recent years, Apple has, to some degree, stopped focusing on making every device as thin as possible at the potential expense of things like performance or battery life. Clearly, performance isn’t an issue here. But the same people who value extended battery life in a thicker device when using things like the MacBook Pro might feel the same here. Nathan Ingraham for Engadget That’s a valid opinion, but a tablet is meant to be held in your hands and carried around with you even more so than a laptop, so I understand why Apple values portability over extending the iPad Pro’s battery life. Plus, the iPad Pro M5’s fast-charging capabilities make it pretty easy to extend its life. Using Apple's new 40W Dynamic Charger that can automatically step up to 60W, I got from 23 percent to 70 percent in 35 minutes. That’s a tad slower than the 50 percent charge in 30 minutes Apple claims, but we’re well within the “close enough” range. One thing I didn’t get to test last year with the iPad Pro M4 was its durability. The tablet’s extremely thin design reminded people of past Apple devices that had had some issues with flexing. After over a year with the previous iPad Pro, I’m not at all worried about this one. I’ve taken an iPad Pro M4 all around the US and internationally with no issues. Granted, it’s usually in its keyboard case, but I’ve also traveled with it in the basic Smart Folio Apple sells and have seen no evidence of bending. I also don’t remember seeing any reports about durability issues from owners over the last 18 months, so I wouldn’t worry about its long-term durability. I don’t have a great read on how long the iPad Pro M5 lasts away from its charger just yet — in the first few days with a new device it’s often downloading a lot of data from backups and doing some optimizing, thus not giving you a great feel for how long it’ll usually last. But so far, performance seems similar to the iPad Air M3 and iPad Pro M4 I’ve reviewed recently. I was getting between seven and eight hours while using the Magic Keyboard, and I’m guessing that I’ll blow past the 10-hour estimate when watching locally-stored video. More details on that to come. Nathan Ingraham for Engadget Performance, check. Design, check. The third thing that continues to impress me about the iPad Pro is its screen. It quite simply has the nicest display I have ever seen on a portable device, be it a laptop, phone or tablet. Apple’s tandem OLED display (two OLED panels layered on top of each other) is the same in all respects as it was last year. That means the 13-inch screen has a 2,752 x 2,064 resolution (264 ppi) and standard brightness that can hit 1,000 nits, or up to 1,600 nits peak for HDR content. Aside from the OLED display, the only display improvements the iPad Pro has that the iPad Air doesn’t is ProMotion support for 120Hz refresh rates as well as a nano-texture glass option for the 1TB and 2TB models. To be clear, though, the iPad Pro’s screen is in a completely different ballpark than the one on the iPad Air. Between the much faster refresh rate, high brightness levels, completely dark blacks and wonderful contrast, there’s no question this screen far surpasses what you’ll find on any other iPad. Professionals who do detailed work in video, photography, drawing with the Apple Pencil Pro or graphic design will appreciate all of these features. But it also makes something like kicking back on a plane to watch a movie more enjoyable. Nathan Ingraham for Engadget iPadOS 26 In last year’s iPad Pro M4 review, I wrote: “Apple has shown no indication it’s going to make iPadOS more like a Mac.” As such, I recommended people not buy an iPad Pro unless they were happy with the limitations that have been inherent to iPadOS for a long time. It took Apple until this summer, but its latest updates rendered my earlier words invalid. With iPadOS 26, Apple pretty much said “screw it” and addressed nearly every big software complaint users have had. As a quick refresher: apps still open in full screen by default, but you can now grab the corner and resize it to any shape you see fit; you can then stack up as many windows as you want in that view. Apps are also much better at remembering their size and position on your screen than ever before. If you swipe up and dismiss all the apps you’re working with and then re-open one, it’s right in the same place you left it. If you want to throw something back in full-screen, the familiar “stoplight” controls from the Mac are available for easy window management. You can swipe up and hold for a second from the bottom of the screen to enter Expose, which shows every open window in your view. Swiping right shows all the full-screen apps you have open. If you have an app in full screen, you can switch back to a windowed app that’ll just float on top of what you’re working in. There’s also a menu bar at the top of the screen that makes it easy to access advanced controls for whatever you’re using. As I said when I first started testing out iPadOS 26 in the summer, the end result of all these changes is that your iPad (no matter which kind) will feel significantly more capable with this software update. And there are other features that power users will appreciate, like a significantly improved Files app. Since it’s easier to have multiple windows, moving things around or dragging and dropping things into apps is a lot simpler. And there are improved sorting options as well, while PDFs finally open in the new Preview app rather than within Files . Background task capabilities have also been significantly expanded. For example, Final Cut Pro can now render video in the background, whereas before, switching to a different app would put the lengthy and intensive process on pause. And developers can tap into this API to use it for their own apps, too. I can’t say for sure that this will answer all the complaints of various iPad Pro owners out there, but I think Apple has gotten about as close as it can without just putting macOS on the device and calling it a day. Even with the big updates to iPadOS, an iPad Pro isn’t for everyone. Plenty of people will still choose a traditional laptop. But the iPad has always offered a pretty unique blend of power and portability, and with better software it’s a more viable option than ever. Nathan Ingraham for Engadget Wrap-up My viewpoint on the iPad Pro hasn’t changed since last year. I still find it a wildly impressive device that is unlike much else you can buy. Just like the last model, it has Apple’s newest chip, the best display Apple has made (aside from its $5,000 Pro XDR monitor) and a physical design that feels almost impossible given how much technology is crammed inside. It’s truly delightful, and it’s even more capable than before thanks to the combination of iPadOS 26 and the M5 chip. However, I still can’t stomach that price. $1,299 for a 13-inch iPad with 256GB of storage, no 5G connectivity and no Magic Keyboard is a lot of money, even if it is as capable as a similarly-priced laptop. Given the incredible technology inside of the iPad Pro, I can understand why it’s so expensive. And it's powerful enough that some buyers will be able to use it for three, four, even five years before they feel the need to update, which makes the up-front investment a little less burdensome. It's not the kind of device you need to replace annually, that's for sure. But unless you are going to use it as your main computer — all day, every day — and know exactly what benefits you’ll get from the iPad over a more traditional laptop, you’re probably better off buying an iPad Air and saving yourself a lot of money.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/ipad-pro-m5-review-speed-boost-130046249.html?src=rss",
          "feed_position": 26,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/d1c1d911-ae0f-11f0-adf6-237a61d04241"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-111553740.html",
          "published_at": "Tue, 21 Oct 2025 11:15:53 +0000",
          "title": "The Morning After: Amazon broke the internet (for a bit)",
          "standfirst": "A decent-sized chunk of the internet stopped working after a fairly massive Amazon Web Services (AWS) outage. This included Venmo, Snapchat, Canva and Fortnite — even Amazon’s own products went on the fritz. Your humble narrator’s Ring Chimes started turning their night lights on and off entirely at random, with no prompting from yours truly. The company has already fixed the DNS issue that caused the outage, but a failure like this, which knocks out so damn much of the internet, should serve as a reminder. After all, having so many critical systems in the same basket means that when something goes wrong, a lot of the internet stops working. All at once. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Atari just announced the Intellivision Spirit, a revamp of the iconic 1980s gaming consoleComplete with games you’ll probably try once then never again. 8BitDo drops an NES-inspired collection for the console’s 40th anniversaryIncluding our favorite Switch controller. China claims the NSA conducted cyberattacks on its national time centerThis is fine, honestly, totally fine. Meta Ray-Ban Display review: Chunky frames with impressive abilities The next generation of smart glasses has arrived. Karissa Bell for Engadget It’s teeth-grindingly frustrating that Meta seems to be the company that has worked out how to make a truly transformative pair of smart glasses. Karissa Bell has reviewed its new Ray-Ban Display and has plenty of praise for so much of what it can do. You should read her exhaustive review to learn more, but the biggest barriers to adoption are size and price. But you can bet your bottom dollar the second or third generation of these are going to be a smash hit. At least until Meta gets rocked by another scandal that prompts people to deactivate their accounts. Continue Reading. Amazon reveals what one of the US’ first modular nuclear reactors will look like It’s an anonymous-looking warehouse. Amazon Last year, Amazon announced it would bankroll construction of a small nuclear reactor (SMR) plant in Washington state. Now, the company is showing off renders of the Hanford facility, which look like any other anonymous-looking modern warehouse. If you’re curious, the SMRs in question will use high-temperature gas-cooled reactors, each one with a maximum output of 80 megawatts. Continue Reading. Beats Powerbeats Fit review: Déjà vu, in a good way A few small tweaks add up to a nicer package. Valentina Palladino for Engadget Apple has updated the Beats Fit Pro with more flexible wingtips, a smaller charging case and the added benefits of Apple’s H1 chip. Valentina Palladino has been testing them out and can tell you the good, the bad and the ugly about these updated earbuds. And, if I’m honest, there’s not much that’s bad or ugly about them. Maybe the battery life could be a bit longer. Continue Reading. Apple is the new home for F1 in the US starting in 2026 It’s a pretty sweet deal given what’s thrown in. Apple In what can only be described as the least surprising sports rights streaming TV deal ever, Apple TV is the new home of F1 in the US. The five-year pact starts next year, with every practice, qualifying, sprint and race streaming live on Apple TV. Even better is that F1’s own excellent streaming platform, F1 TV Premium, will be a free perk for Apple TV subscribers. Continue Reading. Bose QuietComfort Ultra Headphones (2nd gen) review: Impactful upgrades to a familiar formula Sony finally has a worthy rival. Billy Steele for Engadget Bose opted for evolution over revolution for its 2025 series of QuietComfort Ultra products and is garnering rave reviews. Billy Steele is effusive with praise, calling them “the best noise canceling headphones you can buy right now.” It looks as if someone has finally been able to lay a finger on Sony’s previously imperious XM series, even if Bose’s glossy finish is a bit much. Continue Reading. Samsung Galaxy S25 FE review: Iterative to a fault A swing and a miss for Samsung. Igor Bonafacic for Engadget Samsung follows each flagship phone launch with a Fan Edition, which trims the spec list to get the price down. Igor Bonifacic has reviewed the S25 FE and found a phone designed for an older paradigm, before cheaper rivals like the Nothing 3a Pro and Pixel 10 came along. His recommendation? Buy last year’s full-fat model during a sale and swerve the compromises. Continue Reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111553740.html?src=rss",
          "content": "A decent-sized chunk of the internet stopped working after a fairly massive Amazon Web Services (AWS) outage. This included Venmo, Snapchat, Canva and Fortnite — even Amazon’s own products went on the fritz. Your humble narrator’s Ring Chimes started turning their night lights on and off entirely at random, with no prompting from yours truly. The company has already fixed the DNS issue that caused the outage, but a failure like this, which knocks out so damn much of the internet, should serve as a reminder. After all, having so many critical systems in the same basket means that when something goes wrong, a lot of the internet stops working. All at once. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Atari just announced the Intellivision Spirit, a revamp of the iconic 1980s gaming consoleComplete with games you’ll probably try once then never again. 8BitDo drops an NES-inspired collection for the console’s 40th anniversaryIncluding our favorite Switch controller. China claims the NSA conducted cyberattacks on its national time centerThis is fine, honestly, totally fine. Meta Ray-Ban Display review: Chunky frames with impressive abilities The next generation of smart glasses has arrived. Karissa Bell for Engadget It’s teeth-grindingly frustrating that Meta seems to be the company that has worked out how to make a truly transformative pair of smart glasses. Karissa Bell has reviewed its new Ray-Ban Display and has plenty of praise for so much of what it can do. You should read her exhaustive review to learn more, but the biggest barriers to adoption are size and price. But you can bet your bottom dollar the second or third generation of these are going to be a smash hit. At least until Meta gets rocked by another scandal that prompts people to deactivate their accounts. Continue Reading. Amazon reveals what one of the US’ first modular nuclear reactors will look like It’s an anonymous-looking warehouse. Amazon Last year, Amazon announced it would bankroll construction of a small nuclear reactor (SMR) plant in Washington state. Now, the company is showing off renders of the Hanford facility, which look like any other anonymous-looking modern warehouse. If you’re curious, the SMRs in question will use high-temperature gas-cooled reactors, each one with a maximum output of 80 megawatts. Continue Reading. Beats Powerbeats Fit review: Déjà vu, in a good way A few small tweaks add up to a nicer package. Valentina Palladino for Engadget Apple has updated the Beats Fit Pro with more flexible wingtips, a smaller charging case and the added benefits of Apple’s H1 chip. Valentina Palladino has been testing them out and can tell you the good, the bad and the ugly about these updated earbuds. And, if I’m honest, there’s not much that’s bad or ugly about them. Maybe the battery life could be a bit longer. Continue Reading. Apple is the new home for F1 in the US starting in 2026 It’s a pretty sweet deal given what’s thrown in. Apple In what can only be described as the least surprising sports rights streaming TV deal ever, Apple TV is the new home of F1 in the US. The five-year pact starts next year, with every practice, qualifying, sprint and race streaming live on Apple TV. Even better is that F1’s own excellent streaming platform, F1 TV Premium, will be a free perk for Apple TV subscribers. Continue Reading. Bose QuietComfort Ultra Headphones (2nd gen) review: Impactful upgrades to a familiar formula Sony finally has a worthy rival. Billy Steele for Engadget Bose opted for evolution over revolution for its 2025 series of QuietComfort Ultra products and is garnering rave reviews. Billy Steele is effusive with praise, calling them “the best noise canceling headphones you can buy right now.” It looks as if someone has finally been able to lay a finger on Sony’s previously imperious XM series, even if Bose’s glossy finish is a bit much. Continue Reading. Samsung Galaxy S25 FE review: Iterative to a fault A swing and a miss for Samsung. Igor Bonafacic for Engadget Samsung follows each flagship phone launch with a Fan Edition, which trims the spec list to get the price down. Igor Bonifacic has reviewed the S25 FE and found a phone designed for an older paradigm, before cheaper rivals like the Nothing 3a Pro and Pixel 10 came along. His recommendation? Buy last year’s full-fat model during a sale and swerve the compromises. Continue Reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111553740.html?src=rss",
          "feed_position": 29,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/97b73640-ae62-11f0-8df9-30df1506b776"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/yelp-is-getting-more-ai-including-an-upgraded-chatbot-110051320.html",
          "published_at": "Tue, 21 Oct 2025 11:00:51 +0000",
          "title": "Yelp is getting more AI, including an upgraded chatbot",
          "standfirst": "AI is the star of Yelp's fall product update. The review site has updated Yelp Assistant, its chatbot to answer users' questions, rolling the tool out for all business categories. Its responses will draw on information from the business' website as well as posts by other Yelp users. The chatbot will also remember past queries and preferences when it's used for finding services. Saved information can be managed in the Yelp app under Yelp Assistant memory settings. Yelp has been pushing more artificial intelligence into its platform, adding Review Insights in December and announcing calling features in April. The AI-powered calling is rolling out in the company's fall update as Yelp Host and Yelp Receptionist. Yelp Host is specifically for table-service restaurants, and promises the ability to take reservations, change bookings and capture special requests. It is available now starting at $149 a month, or $99 a month for customers with a Yelp Guest Manager plan. Yelp Receptionist can manage calls for any \"eligible local businesses.\" Subscriptions to this AI-powered service start at $99 a month and will begin rolling out this week. There are several other updates from Yelp, but one of the more interesting ones is Menu Vision. With this resource, pointing your camera at a restaurant's menu will show photos of the dish in question along with reviews about that particular item. Menu Vision will arrive on the iOS and Android apps this week.This article originally appeared on Engadget at https://www.engadget.com/ai/yelp-is-getting-more-ai-including-an-upgraded-chatbot-110051320.html?src=rss",
          "content": "AI is the star of Yelp's fall product update. The review site has updated Yelp Assistant, its chatbot to answer users' questions, rolling the tool out for all business categories. Its responses will draw on information from the business' website as well as posts by other Yelp users. The chatbot will also remember past queries and preferences when it's used for finding services. Saved information can be managed in the Yelp app under Yelp Assistant memory settings. Yelp has been pushing more artificial intelligence into its platform, adding Review Insights in December and announcing calling features in April. The AI-powered calling is rolling out in the company's fall update as Yelp Host and Yelp Receptionist. Yelp Host is specifically for table-service restaurants, and promises the ability to take reservations, change bookings and capture special requests. It is available now starting at $149 a month, or $99 a month for customers with a Yelp Guest Manager plan. Yelp Receptionist can manage calls for any \"eligible local businesses.\" Subscriptions to this AI-powered service start at $99 a month and will begin rolling out this week. There are several other updates from Yelp, but one of the more interesting ones is Menu Vision. With this resource, pointing your camera at a restaurant's menu will show photos of the dish in question along with reviews about that particular item. Menu Vision will arrive on the iOS and Android apps this week.This article originally appeared on Engadget at https://www.engadget.com/ai/yelp-is-getting-more-ai-including-an-upgraded-chatbot-110051320.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/best-action-camera-130017459.html",
          "published_at": "Tue, 21 Oct 2025 09:00:35 +0000",
          "title": "The best action cameras for 2025",
          "standfirst": "Whether you’re into adventure sports or just want to log your day-to-day activities, an action camera is the way to go. On top of regular models from the likes of GoPro, DJI and Insta360, you can film your adventures with 360-degree models and a new class of tiny cams that can even be attached to kids or pets. In other words, there are more options than ever for types of action shooting or vlogging.With all the new choices, which have the best features for your personal exploits? Engadget has been testing action cameras for more than 16 years and with that experience, we can help you find the right model for your budget and needs. Best action cameras for 2025 What to consider before choosing an action camera Action cameras have certain traits that separate them from regular cameras or smartphones. The most important is ruggedness that makes them resistant to water, dust and shocks. Most models are now waterproof without the need for a separate enclosure. At the same time, you can purchase housing accessories to make them waterproof to even greater depths. Video quality is also key. Every model we recommend goes to at least 4K 60fps, but some models like GoPro’s latest Hero 13 boost resolution up to 5.3K 60fps, or even 8K 30fps with the Insta360 Ace Pro 2. That allows you to crop in on shots and capture vertical video at higher resolutions for social media. And for slow-mo, you’ll want at least 120 fps video, preferably at 4K or at least 2.7K. Another nice feature is log video that improves dynamic range when filming on sunny, contrasty days. And if you film in dim environments, you’ll want the largest sensor possible for the best low-light performance. Next is the question of flat versus 360 video. 360 cams have become incredibly popular lately because they capture video all around the camera, even above and below. Then, you can reframe the shots in post, cutting from a cool bike trick to your reaction, for example. Or, you can post the entire 360 video online and let the audience choose which angle they want to see. For activities with bumps and jolts like mountain biking, stabilization is incredibly important. You want your video to look smooth, but still convey the thrill and speed of the action. Cameras from DJI, GoPro and Insta360 are all good in this regard, but GoPro’s Hero 13 still tops the list. Some action cameras are easier to handle and use, so take that into account as well. You’ll want bright and colorful displays both front and back, buttons you won’t have to fumble to find and easy-to-use menus. Remote control is another factor that can ease operation. And you’ll want to check which software is available to improve stabilization, edit video, remove selfie sticks and more. Size has also become a factor, with tiny cameras having become an all-new category recently. Mini sized models like Insta360’s Go 3S and Go Ultra, along with DJI’s new Osmo Nano, let you separate the camera from the display for maximum portability. Whether it’s mounted on a hat or your chest, you’ll barely notice it’s there. Then there are accessories. Do you need helmet or chest mounts, waterproof housings or battery charger? GoPro has the largest number as it’s been around the longest, but DJI and Insta360 now have a solid accessory lineup and both make handy wireless mics that connect directly with their cameras. And of course, battery life is critical for action shooting as it’s hard to change one when you’re out surfing.This article originally appeared on Engadget at https://www.engadget.com/cameras/best-action-camera-130017459.html?src=rss",
          "content": "Whether you’re into adventure sports or just want to log your day-to-day activities, an action camera is the way to go. On top of regular models from the likes of GoPro, DJI and Insta360, you can film your adventures with 360-degree models and a new class of tiny cams that can even be attached to kids or pets. In other words, there are more options than ever for types of action shooting or vlogging.With all the new choices, which have the best features for your personal exploits? Engadget has been testing action cameras for more than 16 years and with that experience, we can help you find the right model for your budget and needs. Best action cameras for 2025 What to consider before choosing an action camera Action cameras have certain traits that separate them from regular cameras or smartphones. The most important is ruggedness that makes them resistant to water, dust and shocks. Most models are now waterproof without the need for a separate enclosure. At the same time, you can purchase housing accessories to make them waterproof to even greater depths. Video quality is also key. Every model we recommend goes to at least 4K 60fps, but some models like GoPro’s latest Hero 13 boost resolution up to 5.3K 60fps, or even 8K 30fps with the Insta360 Ace Pro 2. That allows you to crop in on shots and capture vertical video at higher resolutions for social media. And for slow-mo, you’ll want at least 120 fps video, preferably at 4K or at least 2.7K. Another nice feature is log video that improves dynamic range when filming on sunny, contrasty days. And if you film in dim environments, you’ll want the largest sensor possible for the best low-light performance. Next is the question of flat versus 360 video. 360 cams have become incredibly popular lately because they capture video all around the camera, even above and below. Then, you can reframe the shots in post, cutting from a cool bike trick to your reaction, for example. Or, you can post the entire 360 video online and let the audience choose which angle they want to see. For activities with bumps and jolts like mountain biking, stabilization is incredibly important. You want your video to look smooth, but still convey the thrill and speed of the action. Cameras from DJI, GoPro and Insta360 are all good in this regard, but GoPro’s Hero 13 still tops the list. Some action cameras are easier to handle and use, so take that into account as well. You’ll want bright and colorful displays both front and back, buttons you won’t have to fumble to find and easy-to-use menus. Remote control is another factor that can ease operation. And you’ll want to check which software is available to improve stabilization, edit video, remove selfie sticks and more. Size has also become a factor, with tiny cameras having become an all-new category recently. Mini sized models like Insta360’s Go 3S and Go Ultra, along with DJI’s new Osmo Nano, let you separate the camera from the display for maximum portability. Whether it’s mounted on a hat or your chest, you’ll barely notice it’s there. Then there are accessories. Do you need helmet or chest mounts, waterproof housings or battery charger? GoPro has the largest number as it’s been around the longest, but DJI and Insta360 now have a solid accessory lineup and both make handy wireless mics that connect directly with their cameras. And of course, battery life is critical for action shooting as it’s hard to change one when you’re out surfing.This article originally appeared on Engadget at https://www.engadget.com/cameras/best-action-camera-130017459.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/new-markovian-thinking-technique-unlocks-a-path-to-million-token-ai",
          "published_at": "Tue, 21 Oct 2025 05:12:00 GMT",
          "title": "New 'Markovian Thinking' technique unlocks a path to million-token AI reasoning",
          "standfirst": "Researchers at Mila have proposed a new technique that makes large language models (LLMs) vastly more efficient when performing complex reasoning. Called Markovian Thinking, the approach allows LLMs to engage in lengthy reasoning without incurring the prohibitive computational costs that currently limit such tasks.The team’s implementation, an environment named Delethink, structures the reasoning chain into fixed-size chunks, breaking the scaling problem that plagues very long LLM responses. Initial estimates show that for a 1.5B parameter model, this method can cut the costs of training by more than two-thirds compared to standard approaches.The quadratic curse of long-chain reasoningFor an LLM to solve a complex problem, it often needs to generate a long series of intermediate “thinking” tokens, often referred to as chain-of-thought (CoT). In recent years, researchers have found that using reinforcement learning (RL) to train models to produce longer CoTs (sometimes referred to as LongCoT) has significantly improved their reasoning capabilities.However, the standard method for this has a critical flaw: The AI&#x27;s \"state\" (the prompt plus all the reasoning tokens it has generated thus far in its processing) grows with every new reasoning token. For modern transformer-based models, this means the computational cost explodes quadratically as the reasoning chain gets longer, making it prohibitively expensive to train models for very complex tasks.Most current attempts to manage this cost focus on limiting how much thinking the model does, implicitly preferring shorter solutions or terminating the process early. While these methods offer some relief, the Mila researchers still operate within the LongCoT framework and are thus fundamentally bound by its quadratic nature.Instead of trying to control the computational growth, Mila created an RL environment that avoids the quadratic problem altogether. As co-author Amirhossein Kazemnejad explained, the goal is to enable capabilities like multi-week reasoning and scientific discovery. \"That regime (and the RL needed to enable such capabilities) is not supported by the current LongCoT paradigm, because of quadratic compute cost,\" he said.Thinking in chunks with DelethinkThe researchers&#x27; solution is a paradigm they call the \"Markovian Thinker,\" where the model reasons while keeping the size of its reasoning context window constant. The core idea is to change the RL setup to separate \"how long the model thinks\" from \"how much context it must process.\" If done correctly, a Markovian Thinker turns the quadratic growth problem into linear compute and fixed memory requirements for LLM reasoning.The researchers put this paradigm into practice through Delethink, which forces the model to reason in a sequence of fixed-size chunks, such as 8,000 tokens at a time. Within each chunk, the model reasons as it normally would, using the classic attention mechanism. But when it reaches the limit of the chunk, the environment resets the context, creating a new prompt that includes the original query plus a short \"carryover\" from the previous chunk. For example, the carryover could be the last few tokens of the previous chunk of CoT or a summary of the most important results.This rearrangement of the problem forces the model to learn how to embed a summary of its progress, or a \"textual Markovian state,\" into this carryover to continue its reasoning in the next chunk. This addresses the common concern of whether the model can remember important details from earlier steps. According to Kazemnejad, the model learns what to remember. \"With training... the model is forced to learn to carry forward the task-critical state,\" he explained. He added crucial clarification for practical use: The original input prompt is not modified, including the documents or contextual data added to it. “Our approach is aimed at the reasoning phase and does not modify the prompt,\" he said.Delethink in actionTo test their approach, the researchers trained R1-Distill-1.5B with Delethink on a dataset of competition-level math problems, then evaluated it against several benchmarks. The model was trained to reason for up to 24,000 tokens but with fixed 8,000-token chunks. The researchers compared this to models trained with the standard LongCoT-RL method. Their findings indicate that the model trained with Delethink could reason up to 24,000 tokens, and matched or surpassed a LongCoT model trained with the same 24,000-token budget on math benchmarks. On other tasks like coding and PhD-level questions, Delethink also matched or slightly beat its LongCoT counterpart. “Overall, these results indicate that Delethink uses its thinking tokens as effectively as LongCoT-RL with reduced compute,” the researchers write.The benefits become even more pronounced when scaling beyond the training budget. While models trained with LongCoT quickly plateaued at their training limits, the Delethink-trained model continued to improve its performance. For instance, some math problems were only solved after the model reasoned for up to 140,000 tokens, far beyond its 24,000-token training budget. This linear compute advantage is substantial for enterprise applications. The researchers estimate that training a model to an average thinking length of 96,000 tokens would require 27 H100-GPU-months with LongCoT, versus just 7 with Delethink.This efficiency extends directly to inference, the primary operational cost for most enterprises. \"Models trained in Markovian Thinking use the same inference style (delethink-tracing) during test time, which provides the same advantages of linear compute and constant memory after training,\" said Kazemnejad. He offered a practical example: An AI agent could \"debug a large codebase and think for a long time... which of course reduces the cost significantly compared to the conventional LongCoT approach.\"Interestingly, the researchers found that off-the-shelf reasoning models, even without any specific training, already exhibit some ability to think in a Markovian way. This finding has immediate practical implications for developers. \"In practice, this means that — without Delethink-RL— these models can already run a delethink-tracing wrapper and perform competitively with LongCoT on our benchmarked tasks,\" Kazemnejad said.Their experiments with larger models such as GPT-OSS 120B showed robust performance with Delethink across a range of complex tasks. This latent ability provides a strong starting point for RL training, helping explain why the method is so effective. “Together, these results suggest that Delethink is compatible and scales with state-of-the-art models,” the researchers conclude.The success of Markovian Thinking shows it may be possible for \"next-generation reasoning models to think for millions of tokens,\" the researchers note. This opens the door to fundamentally new AI capabilities, moving beyond current constraints. \"Markovian Thinking... opens the path for models that can &#x27;think&#x27; for very long horizons, which we view as a necessary step toward eventual scientific discovery,\" Kazemnejad said. \"Our approach removes a key bottleneck and can allow training for much longer horizon tasks, which enables next-gen capabilities.\"",
          "content": "Researchers at Mila have proposed a new technique that makes large language models (LLMs) vastly more efficient when performing complex reasoning. Called Markovian Thinking, the approach allows LLMs to engage in lengthy reasoning without incurring the prohibitive computational costs that currently limit such tasks.The team’s implementation, an environment named Delethink, structures the reasoning chain into fixed-size chunks, breaking the scaling problem that plagues very long LLM responses. Initial estimates show that for a 1.5B parameter model, this method can cut the costs of training by more than two-thirds compared to standard approaches.The quadratic curse of long-chain reasoningFor an LLM to solve a complex problem, it often needs to generate a long series of intermediate “thinking” tokens, often referred to as chain-of-thought (CoT). In recent years, researchers have found that using reinforcement learning (RL) to train models to produce longer CoTs (sometimes referred to as LongCoT) has significantly improved their reasoning capabilities.However, the standard method for this has a critical flaw: The AI&#x27;s \"state\" (the prompt plus all the reasoning tokens it has generated thus far in its processing) grows with every new reasoning token. For modern transformer-based models, this means the computational cost explodes quadratically as the reasoning chain gets longer, making it prohibitively expensive to train models for very complex tasks.Most current attempts to manage this cost focus on limiting how much thinking the model does, implicitly preferring shorter solutions or terminating the process early. While these methods offer some relief, the Mila researchers still operate within the LongCoT framework and are thus fundamentally bound by its quadratic nature.Instead of trying to control the computational growth, Mila created an RL environment that avoids the quadratic problem altogether. As co-author Amirhossein Kazemnejad explained, the goal is to enable capabilities like multi-week reasoning and scientific discovery. \"That regime (and the RL needed to enable such capabilities) is not supported by the current LongCoT paradigm, because of quadratic compute cost,\" he said.Thinking in chunks with DelethinkThe researchers&#x27; solution is a paradigm they call the \"Markovian Thinker,\" where the model reasons while keeping the size of its reasoning context window constant. The core idea is to change the RL setup to separate \"how long the model thinks\" from \"how much context it must process.\" If done correctly, a Markovian Thinker turns the quadratic growth problem into linear compute and fixed memory requirements for LLM reasoning.The researchers put this paradigm into practice through Delethink, which forces the model to reason in a sequence of fixed-size chunks, such as 8,000 tokens at a time. Within each chunk, the model reasons as it normally would, using the classic attention mechanism. But when it reaches the limit of the chunk, the environment resets the context, creating a new prompt that includes the original query plus a short \"carryover\" from the previous chunk. For example, the carryover could be the last few tokens of the previous chunk of CoT or a summary of the most important results.This rearrangement of the problem forces the model to learn how to embed a summary of its progress, or a \"textual Markovian state,\" into this carryover to continue its reasoning in the next chunk. This addresses the common concern of whether the model can remember important details from earlier steps. According to Kazemnejad, the model learns what to remember. \"With training... the model is forced to learn to carry forward the task-critical state,\" he explained. He added crucial clarification for practical use: The original input prompt is not modified, including the documents or contextual data added to it. “Our approach is aimed at the reasoning phase and does not modify the prompt,\" he said.Delethink in actionTo test their approach, the researchers trained R1-Distill-1.5B with Delethink on a dataset of competition-level math problems, then evaluated it against several benchmarks. The model was trained to reason for up to 24,000 tokens but with fixed 8,000-token chunks. The researchers compared this to models trained with the standard LongCoT-RL method. Their findings indicate that the model trained with Delethink could reason up to 24,000 tokens, and matched or surpassed a LongCoT model trained with the same 24,000-token budget on math benchmarks. On other tasks like coding and PhD-level questions, Delethink also matched or slightly beat its LongCoT counterpart. “Overall, these results indicate that Delethink uses its thinking tokens as effectively as LongCoT-RL with reduced compute,” the researchers write.The benefits become even more pronounced when scaling beyond the training budget. While models trained with LongCoT quickly plateaued at their training limits, the Delethink-trained model continued to improve its performance. For instance, some math problems were only solved after the model reasoned for up to 140,000 tokens, far beyond its 24,000-token training budget. This linear compute advantage is substantial for enterprise applications. The researchers estimate that training a model to an average thinking length of 96,000 tokens would require 27 H100-GPU-months with LongCoT, versus just 7 with Delethink.This efficiency extends directly to inference, the primary operational cost for most enterprises. \"Models trained in Markovian Thinking use the same inference style (delethink-tracing) during test time, which provides the same advantages of linear compute and constant memory after training,\" said Kazemnejad. He offered a practical example: An AI agent could \"debug a large codebase and think for a long time... which of course reduces the cost significantly compared to the conventional LongCoT approach.\"Interestingly, the researchers found that off-the-shelf reasoning models, even without any specific training, already exhibit some ability to think in a Markovian way. This finding has immediate practical implications for developers. \"In practice, this means that — without Delethink-RL— these models can already run a delethink-tracing wrapper and perform competitively with LongCoT on our benchmarked tasks,\" Kazemnejad said.Their experiments with larger models such as GPT-OSS 120B showed robust performance with Delethink across a range of complex tasks. This latent ability provides a strong starting point for RL training, helping explain why the method is so effective. “Together, these results suggest that Delethink is compatible and scales with state-of-the-art models,” the researchers conclude.The success of Markovian Thinking shows it may be possible for \"next-generation reasoning models to think for millions of tokens,\" the researchers note. This opens the door to fundamentally new AI capabilities, moving beyond current constraints. \"Markovian Thinking... opens the path for models that can &#x27;think&#x27; for very long horizons, which we view as a necessary step toward eventual scientific discovery,\" Kazemnejad said. \"Our approach removes a key bottleneck and can allow training for much longer horizon tasks, which enables next-gen capabilities.\"",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1Nt9gogMKGFRD9qvf1lziG/bd8cf13e043d0d9341611055b70556e0/Markovian_thinking.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/the-unexpected-benefits-of-ai-pcs-why-creativity-could-be-the-new",
          "published_at": "Tue, 21 Oct 2025 04:00:00 GMT",
          "title": "The unexpected benefits of AI PCs: why creativity could be the new productivity",
          "standfirst": "Presented by HPCreativity is quickly becoming the new measure of productivity. While AI is often framed as a tool for efficiency and automation, new research from MIT Sloan School of Management shows that generative AI enhances human creativity — when employees have the right tools and skills to use it effectively. That’s where AI PCs come in. These next-generation laptops combine local AI processing with powerful Neural Processing Units (NPUs), delivering the speed and security that knowledge workers expect while also unlocking new creative possibilities. By handling AI tasks directly on the device, AI PCs minimize latency, protect sensitive data, and lower energy consumption.Teams are already proving the impact. Marketing teams are using AI PCs to generate campaign assets in hours instead of weeks. Engineers are shortening design and prototyping cycles. Sales reps are creating personalized proposals onsite, even without cloud access. In each case, AI PCs are not just accelerating workflows — they’re sparking fresh ideas, faster iteration, and more engaged teams.The payoff is clear: creativity that translates into measurable business outcomes, from faster time-to-market and stronger compliance to deeper customer engagement. Still, adoption is uneven, and the benefits aren’t yet reaching the wider workforce.Early creative benefits, but a divide remainsNew Morning Consult and HP research shows nearly half of IT decision makers (45%) already use AI PCs for creative assistance, with almost a third (29%) using them for tasks like image generation and editing. That’s not just about efficiency — it’s about bringing imagination into everyday workflows.According to HP’s 2025 Work Relationship Index, fulfillment is the single biggest driver of a healthy work relationship, outranking even leadership. Give employees tools that let them create, not just execute tasks, and you unlock productivity, satisfaction, retention, and optimism. The same instinct that drives workers to build outside the office is the one companies can harness inside it.The challenge is that among broader knowledge workers, adoption is still low, just 29% for creative assistance and just 19% for image generation. This creative divide means the full potential of AI PCs hasn’t reached the wider workforce. For CIOs, the opportunity isn’t just deploying faster machines — it’s fostering a workplace culture where creativity drives measurable business value. Creative benefits of AI PCsSo when you put AI PCs in front of the employees who embrace the possibilities, what does that look like in practice? Early adopters are already seeing AI PCs reshape how creative work gets done. Teams dream up fresh ideas, faster. AI PCs can spark new perspectives and out-of-the-box solutions, enhancing human creativity rather than replacing it. With dedicated NPUs handling AI workloads, employees stay in flow without interruptions. Battery life is extended, latency drops, and performance improves — allowing teams to focus on ideas, not wait times.On-device AI is opening new creative mediums, from visual design to video production to music editing, and videos, photos, and presentations that can be generated, edited, and refined in real time. Plus, AI workloads like summarization, transcription, and code generation run instantly without relying on cloud APIs. That means employees can work productively in low-bandwidth or disconnected environments, removing downtime risks, especially for mobile workforces and global deployments.And across the organization, AI PCs mean real-world, measurable business outcomes. Marketing: AI PCs enable creative teams to generate ad variations, social content, and campaign assets in minutes instead of days, reducing dependence on external agencies. And that leads to faster campaign launches, reduced external vendor spend, and increased pipeline velocity.Product and engineering: Designers/engineers can prototype in CAD, generate 3D mockups, or run simulations locally with on-device AI accelerators, shortening feedback loops. That means reduced iteration cycles, faster prototyping, and faster time-to-market.Sales/customer engagement: Reps can use AI PCs to generate real-time proposals, personalized presentations, or analyze contracts offline at client sites, even without cloud connection. This generates faster deal cycles, higher client engagement, and a shorter sales turnaround.From efficiency to fulfillmentAI PCs are more than just a performance upgrade. They’re reshaping how people approach and experience work. By giving employees tools that spark creativity as well as productivity, organizations can unlock faster innovation, deeper engagement, and stronger retention. For CIOs, the opportunity goes beyond efficiency gains. The true value of AI PCs won’t be measured in speed or specs, but in how they open new possibilities for creation, collaboration, and competition — helping teams not just work faster, but work more creatively and productively.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by HPCreativity is quickly becoming the new measure of productivity. While AI is often framed as a tool for efficiency and automation, new research from MIT Sloan School of Management shows that generative AI enhances human creativity — when employees have the right tools and skills to use it effectively. That’s where AI PCs come in. These next-generation laptops combine local AI processing with powerful Neural Processing Units (NPUs), delivering the speed and security that knowledge workers expect while also unlocking new creative possibilities. By handling AI tasks directly on the device, AI PCs minimize latency, protect sensitive data, and lower energy consumption.Teams are already proving the impact. Marketing teams are using AI PCs to generate campaign assets in hours instead of weeks. Engineers are shortening design and prototyping cycles. Sales reps are creating personalized proposals onsite, even without cloud access. In each case, AI PCs are not just accelerating workflows — they’re sparking fresh ideas, faster iteration, and more engaged teams.The payoff is clear: creativity that translates into measurable business outcomes, from faster time-to-market and stronger compliance to deeper customer engagement. Still, adoption is uneven, and the benefits aren’t yet reaching the wider workforce.Early creative benefits, but a divide remainsNew Morning Consult and HP research shows nearly half of IT decision makers (45%) already use AI PCs for creative assistance, with almost a third (29%) using them for tasks like image generation and editing. That’s not just about efficiency — it’s about bringing imagination into everyday workflows.According to HP’s 2025 Work Relationship Index, fulfillment is the single biggest driver of a healthy work relationship, outranking even leadership. Give employees tools that let them create, not just execute tasks, and you unlock productivity, satisfaction, retention, and optimism. The same instinct that drives workers to build outside the office is the one companies can harness inside it.The challenge is that among broader knowledge workers, adoption is still low, just 29% for creative assistance and just 19% for image generation. This creative divide means the full potential of AI PCs hasn’t reached the wider workforce. For CIOs, the opportunity isn’t just deploying faster machines — it’s fostering a workplace culture where creativity drives measurable business value. Creative benefits of AI PCsSo when you put AI PCs in front of the employees who embrace the possibilities, what does that look like in practice? Early adopters are already seeing AI PCs reshape how creative work gets done. Teams dream up fresh ideas, faster. AI PCs can spark new perspectives and out-of-the-box solutions, enhancing human creativity rather than replacing it. With dedicated NPUs handling AI workloads, employees stay in flow without interruptions. Battery life is extended, latency drops, and performance improves — allowing teams to focus on ideas, not wait times.On-device AI is opening new creative mediums, from visual design to video production to music editing, and videos, photos, and presentations that can be generated, edited, and refined in real time. Plus, AI workloads like summarization, transcription, and code generation run instantly without relying on cloud APIs. That means employees can work productively in low-bandwidth or disconnected environments, removing downtime risks, especially for mobile workforces and global deployments.And across the organization, AI PCs mean real-world, measurable business outcomes. Marketing: AI PCs enable creative teams to generate ad variations, social content, and campaign assets in minutes instead of days, reducing dependence on external agencies. And that leads to faster campaign launches, reduced external vendor spend, and increased pipeline velocity.Product and engineering: Designers/engineers can prototype in CAD, generate 3D mockups, or run simulations locally with on-device AI accelerators, shortening feedback loops. That means reduced iteration cycles, faster prototyping, and faster time-to-market.Sales/customer engagement: Reps can use AI PCs to generate real-time proposals, personalized presentations, or analyze contracts offline at client sites, even without cloud connection. This generates faster deal cycles, higher client engagement, and a shorter sales turnaround.From efficiency to fulfillmentAI PCs are more than just a performance upgrade. They’re reshaping how people approach and experience work. By giving employees tools that spark creativity as well as productivity, organizations can unlock faster innovation, deeper engagement, and stronger retention. For CIOs, the opportunity goes beyond efficiency gains. The true value of AI PCs won’t be measured in speed or specs, but in how they open new possibilities for creation, collaboration, and competition — helping teams not just work faster, but work more creatively and productively.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7mR1kld6Y3tDOhKAT0kylM/0aa331e0105f915b2bc3bcf96001101d/FY25C2_HP_EliteBook_X_Flip_G1i_14_inch_Notebook_Next_Gen_AI_PC_MasadaNX_14_Silver_FEATURE1_Killer_Claim_2000x1400_4204007__1.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/openai-releases-chatgpt-atlas-an-ai-enabled-web-browser-to-challenge-google",
          "published_at": "Tue, 21 Oct 2025 04:00:00 GMT",
          "title": "OpenAI announces ChatGPT Atlas, an AI-enabled web browser to challenge Google Chrome",
          "standfirst": "OpenAI is entering the browser world with the launch of ChatGPT Atlas, an AI-enabled browser. Atlas, now available globally, can be accessed through Apple’s macOS, with support for Windows, iOS and Android coming soon. The announcement comes several months after rumors in July that OpenAI would release a web browser that would challenge the dominance of Google’s Chrome. In a livestream, CEO Sam Altman said he hopes Atlas will help bring about a new way of interacting with and using the web, one where people chat with the browser rather than typing a URL. “We think AI represents a rare once-in-a-decade opportunity to rethink what a browser can be about and how to use one, and how to most productively and pleasantly use the web,” Altman said. “Tabs were great, but we haven’t seen a lot of innovation since then, so we got very excited to really rethink what this could be.” Atlas is meant to offer users a more seamless way to browse the web and ask chat agents questions. It invites users to either search for information via a prompt or question, or just type a URL. Part of Atlas’s value proposition is the ability to call on agents to do tasks directly in the browser. However, agents will only be available to ChatGPT Business, Plus and Pro users for now. Users can download Atlas from its dedicated site, but must log in to their ChatGPT account to begin using it. Chatting with a browser about your memoriesAtlas differentiates itself from browsers like Chrome or Apple’s Safari with its chat feature. The home page essentially is ChatGPT, with a prompt box and several suggested questions. During the livestream, OpenAI said that the more people use Atlas, the more personalized the suggestions will be. The chat box “follows” the user, meaning people can chat with ChatGPT on any website. The model will read what’s on the browser and answer any questions users might have. When you first open Atlas, it prompts you to import data from other browsers you may be using. When I set up mine, it only asked me for Chrome or Safari, the two browsers I mainly use. Importing browser data creates a memory base for Atlas that ChatGPT will reference. So far, Atlas’s memory is hit or miss. I connected my Chrome history, and when I asked about a recent travel destination search I did (and have been searching for every day for a month), Atlas claimed I had never searched for that information.The in-browser chat also reduces the copy-pasting that users often resort to when, say, writing an email. People can open their Gmail, then ask ChatGPT in the browser to help tidy up the message. Of course, Gmail or any other Google Workspace product already offers Gemini-powered capabilities, such as email rewriting. OpenAI CEO of Applications, Fidji Simo, said in a blog post that users can toggle browser memory on or off and control what it can see.Agent mode on the browserIn the past few months, OpenAI has shored up its agent infrastructure in the expectation that individuals and enterprises will rely more and more on agents. Agents on Atlas can use the browser if needed to accomplish a task. For example, you could be looking at a recipe and ask chat to build a grocery list. The agent can then begin shopping on your preferred grocery site. OpenAI has already added a buy button to ChatGPT and proposed an agentic commerce protocol, which could be helpful for Atlas. However, during the demo, OpenAI staff opted not to let the agent proceed to purchase products. Having the agent directly in the browser moves a step beyond point A, where the browser uses an agent in Chrome. Ideally, it already knows what you were looking at and has the information it needs to access and execute on the browser.A new browser warWith more people using AI models and chat platforms for web searches, launching an AI-enabled browser has become another battleground for model providers. Of course, as Chrome has become more popular, it has slowly added AI capabilities thanks to Google&#x27;s Gemini models. Google has also been experimenting with other AI-powered search capabilities, such as generative image search. But, companies like Perplexity, with its Comet browser, is hoping to take on Chrome. Opera, long a Chrome competitor, also repositioned itself as an AI-powered browser by embedding AI features into its platform. For some, Atlas represents a fresh new way to use a web browser. However, many pointed out that Atlas does not exactly reinvent the wheel, as it shares some features with Comet. What is interesting about Atlas is how familiar it is. It looks just like ChatGPT, but it also has tabs like Chrome. OpenAI emphasized that this is the first version of Atlas, implying that this may not be its final form. What is for sure is that Atlas is OpenAI’s first volley in the AI browser wars.",
          "content": "OpenAI is entering the browser world with the launch of ChatGPT Atlas, an AI-enabled browser. Atlas, now available globally, can be accessed through Apple’s macOS, with support for Windows, iOS and Android coming soon. The announcement comes several months after rumors in July that OpenAI would release a web browser that would challenge the dominance of Google’s Chrome. In a livestream, CEO Sam Altman said he hopes Atlas will help bring about a new way of interacting with and using the web, one where people chat with the browser rather than typing a URL. “We think AI represents a rare once-in-a-decade opportunity to rethink what a browser can be about and how to use one, and how to most productively and pleasantly use the web,” Altman said. “Tabs were great, but we haven’t seen a lot of innovation since then, so we got very excited to really rethink what this could be.” Atlas is meant to offer users a more seamless way to browse the web and ask chat agents questions. It invites users to either search for information via a prompt or question, or just type a URL. Part of Atlas’s value proposition is the ability to call on agents to do tasks directly in the browser. However, agents will only be available to ChatGPT Business, Plus and Pro users for now. Users can download Atlas from its dedicated site, but must log in to their ChatGPT account to begin using it. Chatting with a browser about your memoriesAtlas differentiates itself from browsers like Chrome or Apple’s Safari with its chat feature. The home page essentially is ChatGPT, with a prompt box and several suggested questions. During the livestream, OpenAI said that the more people use Atlas, the more personalized the suggestions will be. The chat box “follows” the user, meaning people can chat with ChatGPT on any website. The model will read what’s on the browser and answer any questions users might have. When you first open Atlas, it prompts you to import data from other browsers you may be using. When I set up mine, it only asked me for Chrome or Safari, the two browsers I mainly use. Importing browser data creates a memory base for Atlas that ChatGPT will reference. So far, Atlas’s memory is hit or miss. I connected my Chrome history, and when I asked about a recent travel destination search I did (and have been searching for every day for a month), Atlas claimed I had never searched for that information.The in-browser chat also reduces the copy-pasting that users often resort to when, say, writing an email. People can open their Gmail, then ask ChatGPT in the browser to help tidy up the message. Of course, Gmail or any other Google Workspace product already offers Gemini-powered capabilities, such as email rewriting. OpenAI CEO of Applications, Fidji Simo, said in a blog post that users can toggle browser memory on or off and control what it can see.Agent mode on the browserIn the past few months, OpenAI has shored up its agent infrastructure in the expectation that individuals and enterprises will rely more and more on agents. Agents on Atlas can use the browser if needed to accomplish a task. For example, you could be looking at a recipe and ask chat to build a grocery list. The agent can then begin shopping on your preferred grocery site. OpenAI has already added a buy button to ChatGPT and proposed an agentic commerce protocol, which could be helpful for Atlas. However, during the demo, OpenAI staff opted not to let the agent proceed to purchase products. Having the agent directly in the browser moves a step beyond point A, where the browser uses an agent in Chrome. Ideally, it already knows what you were looking at and has the information it needs to access and execute on the browser.A new browser warWith more people using AI models and chat platforms for web searches, launching an AI-enabled browser has become another battleground for model providers. Of course, as Chrome has become more popular, it has slowly added AI capabilities thanks to Google&#x27;s Gemini models. Google has also been experimenting with other AI-powered search capabilities, such as generative image search. But, companies like Perplexity, with its Comet browser, is hoping to take on Chrome. Opera, long a Chrome competitor, also repositioned itself as an AI-powered browser by embedding AI features into its platform. For some, Atlas represents a fresh new way to use a web browser. However, many pointed out that Atlas does not exactly reinvent the wheel, as it shares some features with Comet. What is interesting about Atlas is how familiar it is. It looks just like ChatGPT, but it also has tabs like Chrome. OpenAI emphasized that this is the first version of Atlas, implying that this may not be its final form. What is for sure is that Atlas is OpenAI’s first volley in the AI browser wars.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4EJUoAdNGN4myXdb69GnMD/f8ab6aaf2305a72ad84dcc5e4afb1beb/agentic_context_engineering.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ais-financial-blind-spot-why-long-term-success-depends-on-cost-transparency",
          "published_at": "Tue, 21 Oct 2025 04:00:00 GMT",
          "title": "AI’s financial blind spot: Why long-term success depends on cost transparency",
          "standfirst": "Presented by Apptio, an IBM companyWhen a technology with revolutionary potential comes on the scene, it’s easy for companies to let enthusiasm outpace fiscal discipline. Bean counting can seem short-sighted in the face of exciting opportunities for business transformation and competitive dominance. But money is always an object. And when the tech is AI, those beans can add up fast.AI’s value is becoming evident in areas like operational efficiency, worker productivity, and customer satisfaction. However, this comes at a cost. The key to long-term success is understanding the relationship between the two — so you can ensure that the potential of AI translates into real, positive impact for your business. The AI acceleration paradoxWhile AI is helping to transform business operations, its own financial footprint often remains obscure. If you can’t connect costs to impact, how can you be sure your AI investments will drive meaningful ROI? This uncertainty makes it no surprise that in the 2025 Gartner® Hype Cycle™ for Artificial Intelligence, GenAI has moved into the “Trough of Disillusionment” . Effective strategic planning depends on clarity. In its absence, decision-making falls back on guesswork and gut instinct. And there’s a lot riding on these decisions. According to Apptio research, 68% of technology leaders surveyed expect to increase their AI budgets, and 39% believe AI will be their departments’ biggest driver of future budget growth. But bigger budgets don’t guarantee better outcomes. Gartner® also reveals that “despite an average spend of $1.9 million on GenAI initiatives in 2024, fewer than 30% of AI leaders say their CEOs are satisfied with the return on investment.” If there’s no clear link between cost and outcome, organizations risk scaling investments without scaling the value they’re meant to create.To move forward with well-founded confidence, business leaders in finance, IT, and tech must collaborate to gain visibility into AI’s financial blind spot.The hidden financial risks of AIThe runaway costs of AI can give IT leaders flashbacks to the early days of public cloud. When it’s easy for DevOps teams and business units to procure their own resources on an OpEx basis, costs and inefficiencies can quickly spiral. In fact, AI projects are avid consumers of cloud infrastructure — while incurring additional costs for data platforms and engineering resources. And that’s on top of the tokens used for each query. The decentralized nature of these costs makes them particularly difficult to attribute to business outcomes. As with the cloud, the ease of AI procurement quickly leads to AI sprawl. And finite budgets mean that every dollar spent represents an unconscious tradeoff with other needs. People worry that AI will take their job. But it’s just as likely that AI will take their department’s budget. Meanwhile, according to Gartner®, “Over 40% of agentic AI projects will be canceled by end of 2027, due to escalating costs, unclear business value or inadequate rish controls”. But are those the right projects to cancel? Lacking a way to connect investment to impact, how can business leaders know whether those rising costs are justified by proportionally greater ROI? ? Without transparency into AI costs, companies risk overspending, under-delivering, and missing out on better opportunities to drive value. Why traditional financial planning can&#x27;t handle AIAs we learned with cloud, we see that traditional static budget models are poorly suited for dynamic workloads and rapidly scaling resources. The key to cloud cost management has been tagging and telemetry, which help companies attribute each dollar of cloud spend to specific business outcomes. AI cost management will require similar practices. But the scope of the challenge goes much further. On top of costs for storage, compute, and data transfer, each AI project brings its own set of requirements — from prompt optimization and model routing to data preparation, regulatory compliance, security, and personnel.This complex mix of ever-shifting factors makes it understandable that finance and business teams lack granular visibility into AI-related spend — and IT teams struggle to reconcile usage with business outcomes. But it’s impossible to precisely and accurately track ROI without these connections.The strategic value of cost transparencyCost transparency empowers smarter decisions — from resource allocation to talent deployment. Connecting specific AI resources with the projects that they support helps technology decision-makers ensure that the most high-value projects are given what they need to succeed. Setting the right priorities is especially critical when top talent is in short supply. If your highly compensated engineers and data scientists are spread across too many interesting but unessential pilots, it’ll be hard to staff the next strategic — and perhaps pressing — pivot.FinOps best practices apply equally to AI. Cost insights can surface opportunities to optimize infrastructure and address waste whether by right-sizing performance and latency to match workload requirements, or by selecting a smaller, more cost-effective model instead of defaulting to the latest large language model (LLM). As work proceeds, tracking can flag rising costs so leaders can pivot quickly in more-promising directions as needed. A project that makes sense at X cost might not be worthwhile at 2X cost. Companies that adopt a structured, transparent, and well-governed approach to AI costs are more likely to spend the right money in the right ways and see optimal ROI from their investment. TBM: An enterprise framework for AI cost managementTransparency and control over AI costs depend on three practices:IT financial management (ITFM): Managing IT costs and investments in alignment with business prioritiesFinOps: Optimizing cloud costs and ROI through financial accountability and operational efficiency Strategic portfolio management (SPM): Prioritizing and managing projects to better ensure they deliver maximum value for the businessCollectively, these three disciplines make up Technology Business Management (TBM) — a structured framework that helps technology, business, and finance leaders connect technology investments to business outcomes for better financial transparency and decision-making. Most companies are already on the road to TBM, whether they realize it or not. They may have adopted some form of FinOps or cloud cost management. Or they might be developing strong financial expertise for IT. Or they may rely on Enterprise Agile Planning or Strategic Portfolio Management project management to deliver initiatives more successfully. AI can draw on — and impact — all of these areas. By unifying them under one umbrella with a common model and vocabulary, TBM brings essential clarity to AI costs and the business impact they enable.AI success depends on value — not just velocity. The cost transparency that TBM provides offers a road map that can help business and IT leaders make the right investments, deliver them cost-effectively, scale them responsibly, and turn AI from a costly mistake into a measurable business asset and strategic driver. Sources : Gartner® Press Release, Gartner® Predicts Over 40% of Agentic AI Projects Will Be Canceled by End of 2027, June 25, 2025 https://www.Gartner®.com/en/newsroom/press-releases/2025-06-25-Gartner®-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027 GARTNER® is a registered trademark and service mark of Gartner®, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.Ajay Patel is General Manager, Apptio and IT Automation at IBM.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Apptio, an IBM companyWhen a technology with revolutionary potential comes on the scene, it’s easy for companies to let enthusiasm outpace fiscal discipline. Bean counting can seem short-sighted in the face of exciting opportunities for business transformation and competitive dominance. But money is always an object. And when the tech is AI, those beans can add up fast.AI’s value is becoming evident in areas like operational efficiency, worker productivity, and customer satisfaction. However, this comes at a cost. The key to long-term success is understanding the relationship between the two — so you can ensure that the potential of AI translates into real, positive impact for your business. The AI acceleration paradoxWhile AI is helping to transform business operations, its own financial footprint often remains obscure. If you can’t connect costs to impact, how can you be sure your AI investments will drive meaningful ROI? This uncertainty makes it no surprise that in the 2025 Gartner® Hype Cycle™ for Artificial Intelligence, GenAI has moved into the “Trough of Disillusionment” . Effective strategic planning depends on clarity. In its absence, decision-making falls back on guesswork and gut instinct. And there’s a lot riding on these decisions. According to Apptio research, 68% of technology leaders surveyed expect to increase their AI budgets, and 39% believe AI will be their departments’ biggest driver of future budget growth. But bigger budgets don’t guarantee better outcomes. Gartner® also reveals that “despite an average spend of $1.9 million on GenAI initiatives in 2024, fewer than 30% of AI leaders say their CEOs are satisfied with the return on investment.” If there’s no clear link between cost and outcome, organizations risk scaling investments without scaling the value they’re meant to create.To move forward with well-founded confidence, business leaders in finance, IT, and tech must collaborate to gain visibility into AI’s financial blind spot.The hidden financial risks of AIThe runaway costs of AI can give IT leaders flashbacks to the early days of public cloud. When it’s easy for DevOps teams and business units to procure their own resources on an OpEx basis, costs and inefficiencies can quickly spiral. In fact, AI projects are avid consumers of cloud infrastructure — while incurring additional costs for data platforms and engineering resources. And that’s on top of the tokens used for each query. The decentralized nature of these costs makes them particularly difficult to attribute to business outcomes. As with the cloud, the ease of AI procurement quickly leads to AI sprawl. And finite budgets mean that every dollar spent represents an unconscious tradeoff with other needs. People worry that AI will take their job. But it’s just as likely that AI will take their department’s budget. Meanwhile, according to Gartner®, “Over 40% of agentic AI projects will be canceled by end of 2027, due to escalating costs, unclear business value or inadequate rish controls”. But are those the right projects to cancel? Lacking a way to connect investment to impact, how can business leaders know whether those rising costs are justified by proportionally greater ROI? ? Without transparency into AI costs, companies risk overspending, under-delivering, and missing out on better opportunities to drive value. Why traditional financial planning can&#x27;t handle AIAs we learned with cloud, we see that traditional static budget models are poorly suited for dynamic workloads and rapidly scaling resources. The key to cloud cost management has been tagging and telemetry, which help companies attribute each dollar of cloud spend to specific business outcomes. AI cost management will require similar practices. But the scope of the challenge goes much further. On top of costs for storage, compute, and data transfer, each AI project brings its own set of requirements — from prompt optimization and model routing to data preparation, regulatory compliance, security, and personnel.This complex mix of ever-shifting factors makes it understandable that finance and business teams lack granular visibility into AI-related spend — and IT teams struggle to reconcile usage with business outcomes. But it’s impossible to precisely and accurately track ROI without these connections.The strategic value of cost transparencyCost transparency empowers smarter decisions — from resource allocation to talent deployment. Connecting specific AI resources with the projects that they support helps technology decision-makers ensure that the most high-value projects are given what they need to succeed. Setting the right priorities is especially critical when top talent is in short supply. If your highly compensated engineers and data scientists are spread across too many interesting but unessential pilots, it’ll be hard to staff the next strategic — and perhaps pressing — pivot.FinOps best practices apply equally to AI. Cost insights can surface opportunities to optimize infrastructure and address waste whether by right-sizing performance and latency to match workload requirements, or by selecting a smaller, more cost-effective model instead of defaulting to the latest large language model (LLM). As work proceeds, tracking can flag rising costs so leaders can pivot quickly in more-promising directions as needed. A project that makes sense at X cost might not be worthwhile at 2X cost. Companies that adopt a structured, transparent, and well-governed approach to AI costs are more likely to spend the right money in the right ways and see optimal ROI from their investment. TBM: An enterprise framework for AI cost managementTransparency and control over AI costs depend on three practices:IT financial management (ITFM): Managing IT costs and investments in alignment with business prioritiesFinOps: Optimizing cloud costs and ROI through financial accountability and operational efficiency Strategic portfolio management (SPM): Prioritizing and managing projects to better ensure they deliver maximum value for the businessCollectively, these three disciplines make up Technology Business Management (TBM) — a structured framework that helps technology, business, and finance leaders connect technology investments to business outcomes for better financial transparency and decision-making. Most companies are already on the road to TBM, whether they realize it or not. They may have adopted some form of FinOps or cloud cost management. Or they might be developing strong financial expertise for IT. Or they may rely on Enterprise Agile Planning or Strategic Portfolio Management project management to deliver initiatives more successfully. AI can draw on — and impact — all of these areas. By unifying them under one umbrella with a common model and vocabulary, TBM brings essential clarity to AI costs and the business impact they enable.AI success depends on value — not just velocity. The cost transparency that TBM provides offers a road map that can help business and IT leaders make the right investments, deliver them cost-effectively, scale them responsibly, and turn AI from a costly mistake into a measurable business asset and strategic driver. Sources : Gartner® Press Release, Gartner® Predicts Over 40% of Agentic AI Projects Will Be Canceled by End of 2027, June 25, 2025 https://www.Gartner®.com/en/newsroom/press-releases/2025-06-25-Gartner®-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027 GARTNER® is a registered trademark and service mark of Gartner®, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.Ajay Patel is General Manager, Apptio and IT Automation at IBM.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 7,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2GoMirWsXnSuZjapMQusnu/8efdafab45e1ad3f5c233f53b35287b2/AdobeStock_1726411808.jpeg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/xs-handle-marketplace-will-sell-some-rare-usernames-for-millions-of-dollars-224852740.html",
          "published_at": "Mon, 20 Oct 2025 22:48:52 +0000",
          "title": "X's handle marketplace will sell some 'rare' usernames for millions of dollars",
          "standfirst": "X is finally following through on its long-rumored plans to sell old user handles, and some of the most sought-after usernames could fetch millions of dollars. The company shared more details about and opened a waitlist for its \"handle marketplace,\" that will enable paying subscribers to request and buy \"inactive\" handles. According to the company, X will make two types of \"inactive' handles available: \"priority\" usernames that may include \"full names, multi-word phrases, or alphanumeric combinations\" and \"rare\" handles that consist of \"short, generic, or culturally significant names.\" Subscribers to X's Premium+ and Premium Business tiers will eventually be able to request some \"priority\" handles as part of their subscription. The company says @PizzaEater and @GabrielJones are possible examples of such handles. Notably, this process requires what essentially amounts to an indefinite subscription to X Premium, as the company says it will revoke priority handles if an account's subscription lapses. The X Handle Marketplace is our industry-first solution to redistribute handles that are no longer in use. Eligible Premium subscribers will be able to search and make requests, with both complimentary and paid options available.— Handle Marketplace (@XHandles) October 19, 2025 The process for acquiring a \"rare\" handle is a lot less clear. X says that it will offer some rare handles through \"public drops\" and that those will be given away for free \"based on merit\" and that multiple users will be able to apply. X will take a user's engagement and \"past contributions\" to the platform into account when deciding who gets these handles. The company will also make some handles available for sale via an invitation-only process. These prices will be \"fixed\" and \"determined by a number of factors including popularity of word, character length, and cultural significance.\" These usernames could include common one-word usernames like @one, @fly or @compute, according to examples provided by X. They could also be incredibly expensive. \"Some handles are included with a Premium+ or Premium Business subscription,\" X wrote in an FAQ. \"Others – especially Rare handles – may be priced anywhere from $2,500 to over seven figures, depending on demand and uniqueness.\" People who buy a supposedly rare handle will need to have a Premium+ or Premium Business subscription in order to start the process, but won't be required to maintain one in order to keep the handle. In a separate \"handle transfer agreement,\" X describes its handle-buying scheme as an \"evolving initiative\" that it hopes will be adopted by other social media companies in the future. \"We are establishing a new standard for social media handles—a framework we hope the broader industry will adopt, similar to how Community Notes has influenced online transparency,\" the company wrote. Andrew Allemann, the publisher of Domain Name Wire, a publication that tracks the domain name industry, says that there are some similarities between X's plan to sell handles and the marketplace for expired domains. \"For a long time, people have been buying and selling handles off of X, and X hasn't been getting a cut of that,\" he told Engadget. \"So in some ways, I think this will get some of the better handles to be more used on the platform.\" But he said he would have concerns about some of the terms in X's policies, which allow it to \"reclaim'' handles if they become inactive. The company's current \"inactive account policy\" defines an inactive account as one that hasn't been logged into for 30 days. \"I would definitely want a firmer contract if I were to pay money for a handle,\" Allemann says. \"I would want some rights baked into a contract that says it can't just be taken away. I certainly want a longer period of inactivity before it can be taken away.\" X also has a history of commandeering desirable handles from users that were actively using them. The company took the @X handle from a San Francisco photographer in 2023 without compensating him, though he was offered \"merch\" and a tour of X's headquarters. That same year, it also took the @music handle from a longtime user with more than a half million followers. Last year, the company swiped the @America handle from a reported Donald Trump critic. The handle is now used by Musk's super PAC. X's plan to give away handles based on \"merit\" raises additional questions about who the platform could decide to reward and penalize. The company didn't immediately respond to a request for comment. Allemann says that all social media users should remember they don't own any of the content they publish on company platforms. \"If you create your website, you control it, and people can always come to it. On social media, the single billionaire owner of it could decide they don't like you, and it's pretty much within their rights to kick you off, or demote you, or change the algorithm to impact you as well.\" Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/social-media/xs-handle-marketplace-will-sell-some-rare-usernames-for-millions-of-dollars-224852740.html?src=rss",
          "content": "X is finally following through on its long-rumored plans to sell old user handles, and some of the most sought-after usernames could fetch millions of dollars. The company shared more details about and opened a waitlist for its \"handle marketplace,\" that will enable paying subscribers to request and buy \"inactive\" handles. According to the company, X will make two types of \"inactive' handles available: \"priority\" usernames that may include \"full names, multi-word phrases, or alphanumeric combinations\" and \"rare\" handles that consist of \"short, generic, or culturally significant names.\" Subscribers to X's Premium+ and Premium Business tiers will eventually be able to request some \"priority\" handles as part of their subscription. The company says @PizzaEater and @GabrielJones are possible examples of such handles. Notably, this process requires what essentially amounts to an indefinite subscription to X Premium, as the company says it will revoke priority handles if an account's subscription lapses. The X Handle Marketplace is our industry-first solution to redistribute handles that are no longer in use. Eligible Premium subscribers will be able to search and make requests, with both complimentary and paid options available.— Handle Marketplace (@XHandles) October 19, 2025 The process for acquiring a \"rare\" handle is a lot less clear. X says that it will offer some rare handles through \"public drops\" and that those will be given away for free \"based on merit\" and that multiple users will be able to apply. X will take a user's engagement and \"past contributions\" to the platform into account when deciding who gets these handles. The company will also make some handles available for sale via an invitation-only process. These prices will be \"fixed\" and \"determined by a number of factors including popularity of word, character length, and cultural significance.\" These usernames could include common one-word usernames like @one, @fly or @compute, according to examples provided by X. They could also be incredibly expensive. \"Some handles are included with a Premium+ or Premium Business subscription,\" X wrote in an FAQ. \"Others – especially Rare handles – may be priced anywhere from $2,500 to over seven figures, depending on demand and uniqueness.\" People who buy a supposedly rare handle will need to have a Premium+ or Premium Business subscription in order to start the process, but won't be required to maintain one in order to keep the handle. In a separate \"handle transfer agreement,\" X describes its handle-buying scheme as an \"evolving initiative\" that it hopes will be adopted by other social media companies in the future. \"We are establishing a new standard for social media handles—a framework we hope the broader industry will adopt, similar to how Community Notes has influenced online transparency,\" the company wrote. Andrew Allemann, the publisher of Domain Name Wire, a publication that tracks the domain name industry, says that there are some similarities between X's plan to sell handles and the marketplace for expired domains. \"For a long time, people have been buying and selling handles off of X, and X hasn't been getting a cut of that,\" he told Engadget. \"So in some ways, I think this will get some of the better handles to be more used on the platform.\" But he said he would have concerns about some of the terms in X's policies, which allow it to \"reclaim'' handles if they become inactive. The company's current \"inactive account policy\" defines an inactive account as one that hasn't been logged into for 30 days. \"I would definitely want a firmer contract if I were to pay money for a handle,\" Allemann says. \"I would want some rights baked into a contract that says it can't just be taken away. I certainly want a longer period of inactivity before it can be taken away.\" X also has a history of commandeering desirable handles from users that were actively using them. The company took the @X handle from a San Francisco photographer in 2023 without compensating him, though he was offered \"merch\" and a tour of X's headquarters. That same year, it also took the @music handle from a longtime user with more than a half million followers. Last year, the company swiped the @America handle from a reported Donald Trump critic. The handle is now used by Musk's super PAC. X's plan to give away handles based on \"merit\" raises additional questions about who the platform could decide to reward and penalize. The company didn't immediately respond to a request for comment. Allemann says that all social media users should remember they don't own any of the content they publish on company platforms. \"If you create your website, you control it, and people can always come to it. On social media, the single billionaire owner of it could decide they don't like you, and it's pretty much within their rights to kick you off, or demote you, or change the algorithm to impact you as well.\" Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/social-media/xs-handle-marketplace-will-sell-some-rare-usernames-for-millions-of-dollars-224852740.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/microsoft-has-ended-windows-10-support-but-heres-how-to-get-an-extra-year-for-free-125118044.html",
          "published_at": "Mon, 20 Oct 2025 18:54:24 +0000",
          "title": "Microsoft has ended Windows 10 support, but here's how to get an extra year for free",
          "standfirst": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) Are you still using Windows 10 on your desktop or laptop? If so, you need to know this: As of October 14, Microsoft moved the software to its \"end of life\" phase. What that means is that while Windows 10 PCs will continue to work, they'll stop getting important security updates by default. That leaves you with three options to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. The third option is easier than it sounds — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to use your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/microsoft-has-ended-windows-10-support-but-heres-how-to-get-an-extra-year-for-free-125118044.html?src=rss",
          "content": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) Are you still using Windows 10 on your desktop or laptop? If so, you need to know this: As of October 14, Microsoft moved the software to its \"end of life\" phase. What that means is that while Windows 10 PCs will continue to work, they'll stop getting important security updates by default. That leaves you with three options to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. The third option is easier than it sounds — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to use your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/microsoft-has-ended-windows-10-support-but-heres-how-to-get-an-extra-year-for-free-125118044.html?src=rss",
          "feed_position": 35,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c836b6e0-a60d-11f0-aff0-71a091f199fd"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-s25-fe-review-iterative-to-a-fault-183026577.html",
          "published_at": "Mon, 20 Oct 2025 18:30:26 +0000",
          "title": "Samsung Galaxy S25 FE review: Iterative to a fault",
          "standfirst": "Five years after the release of the Galaxy S20 FE, Samsung has settled into a predictable pattern with its \"Fan Edition\" line of phones. Each new phone doesn't offer much new or different from its immediate predecessor, with the company opting to offer iterative updates instead. That might have been fine before, but with the arrival of the Nothing Phone 3a Pro and Pixel 10 — devices that changed the value proposition in their respective categories — the S25 FE feels woefully out of touch with a market that's changing to meet people's demands. There's not much here that makes the new Galaxy S25 FE stand out, and any \"upgrades\" aren't substantive. Hardware and display Igor Bonifacic for Engadget When I first took the S25 FE out of the box, I thought Samsung had played a cruel trick on me. The phone looks identical to its predecessor, sporting the same brushed aluminum frame that's been the company's go-to for years now. I had to dig the S24 FE out of my gadgets drawer to compare the two phones before I confirmed they were in fact different devices. The physical differences are minor. Samsung has tweaked the dimensions of the new phone, making it slightly shorter, wider and thinner. Specifically, the S25 FE measures in at 6.35 x 3.02 x 0.29 inches, while its predecessor was 6.38 x 3.04 x 0.31 inches. The new phone is also protected by Samsung's \"enhanced Armor\" aluminum frame. More noticeable is that the S25 FE is lighter than last year's model, coming in at 6.7 ounces, down from 7.51 ounces. This is despite the fact the new device has a higher-capacity 4,900mAh battery. Together, these changes don't make the S25 FE easier to hold if you have small hands (just ask my girlfriend), but it does feel better balanced than its predecessor. One issue with the size of the S25 FE is the placement of the in-display fingerprint sensor. It's right at the bottom of the screen. I found this made it awkward to unlock the phone with my thumb — and I'm someone with big hands. Another slight difference is the finish on the back of the phone. This time around, Samsung has gone with a matte coating, instead of the glossy finish it used on the S24 FE. It's a welcome change since it makes the new model less prone to smudging and attracting fingerprints. I just wish Samsung had decided to offer the S25 FE in more fun colors. At release, it's available in four colorways: white, icy blue, jet black and navy (pictured). So, if you don't like blue, I'm sorry. Amid the slight design tweaks, Samsung has gone with the same screen it did last year. The S25 FE has a 6.7-inch AMOLED display, with a panel that offers a 120Hz refresh rate and 1080p resolution. The S24 FE's vibrant screen was one of the best parts of last year's model, and it's the same with S25 FE. It's easy to see the screen in bright sunlight, thanks to the fact it can push 1,900 nits of peak brightness. It's also vibrant, and with HDR10 support included, great for watching videos on YouTube, Netflix and elsewhere. Cameras Igor Bonifacic for Engadget Samsung made a single tweak to the Galaxy S25 FE's camera hardware. Like last year's model, the new phone has a 50-megapixel main camera with optical image stabilization (OIS) and a fast f/1.8 aperture lens. Once again, it also has an 8MP telephoto camera with a 3x optical zoom and a 12MP ultrawide angle that offers a 123-degree field of view. The one addition is a higher resolution 12MP front-facing camera with a faster f/2.2 aperture lens. For selfies, the S24 FE made do with a 10MP sensor and f/2.4 lens. If the new front-facing camera included phase detection autofocus (PDAF), it would be the same one that's available on the Galaxy S25. Unfortunately, it doesn't and that's a shame because PDAF greatly increases the likelihood your photos will come out sharp and in focus. It's also a shame Samsung decided not to update the FE's telephoto camera. Before the Nothing 3a Pro, that was one of the features that made the S24 FE stand out in its price range. In 2025, however, the S25 FE's telephoto feels outdated. It doesn't offer the 5x optical zoom of the Pixel 10 nor the 50MP of resolution and periscope zoom you get with the 3a Pro. Coming from the former, the FE's telephoto camera felt limiting. With only 8MP of resolution, trying to snap a photo at anything beyond 5x zoom was pointless; it would just turn out a blurry mess. As for FE's other cameras, they're decent if uninspiring. The 50MP camera is the best of the bunch, capable of capturing detailed, good-looking photos even in low light. The ultrawide, meanwhile, is mostly forgettable. It does an okay job of capturing big scenes, but it's lacking in dynamic range and detail. The selfie camera is a noticeable upgrade from the one that came with last year's model, and produces pleasing photos that are on par with what you can expect from the S25's front-facing camera. Otherwise, snapping pictures with the S25 FE feels like using a flagship phone from a few years ago. The one thing that saves it from being a complete blast from the past is the inclusion of Samsung's generative photo editing software, which you can use to remove distracting objects from photos. Of the AI photo apps I've tested, Samsung's is among the best at editing out objects without smearing the background. You can also use the generative edit to add things to a photo, but as you might expect, this doesn't work as well as removing them. Performance and battery life Igor Bonifacic for Engadget On paper, the S25 FE should offer better performance than its predecessor, thanks to Samsung's decision to equip the phone with its Exynos 2400 chipset over the cut-down Exynos 2400e it used on last year's model. In practice the two are about on par with one another. On Geekbench's processor test, the Exynos 2400 delivered a 2,144 single-core score and a 7,059 multi-core score. That's not much better than the 2,140 and 6,690 I recorded last fall on the S24 FE. Still, it's a more impressive showing than either the Pixel 9a and Nothing 3a Pro had when my colleague Sam Rutherford and I put their Tensor G4 and Snapdragon 7s Gen 3 chips through Geekbench earlier this year. For comparison, the former delivered a modest 1,665 on single-core performance and 4,294 on multi-core performance. The latter scored an even less impressive 1,115 and 3,082 respectively. In real-world use, the Exynos 2400 feels snappy. Scrolling is fast and fluid, as is opening apps and switching between them. Gaming performance is also impressive, with the chip able to handle the 60 fps modes in graphically demanding games like Diablo Immortal and League of Legends: Wild Rift without dropping frames. Last year, Samsung said it redesigned the S24 FE's vapor chamber to make it bigger and improve cooling. With the S25 FE, that component is an additional 10 percent larger. However, if the new vapor chamber made a difference to the phone's thermals, I had a hard time telling. Both the S25 FE and S24 FE got warm after about 15 to 20 minutes of gaming. The new phone never got hot to the point I couldn't hold it anymore, but it also didn't feel noticeably cooler than the S24 FE running the same games. As mentioned at the top, the S25 FE has a larger 4,900mAh battery. That's about four percent more capacity than the S24 FE offered. As a result, any difference in battery life is minimal. I'm sure there are some scenarios the S25 FE may last longer than its predecessor, but in my testing the two phones were equal in terms of longevity. With three to four hours of active screentime, I managed to get a full day of battery life from the S25 FE, with enough power left over to get the phone through the night before charging it in the morning. That's similar to the experience I had last year. Speaking of charging, the S24 FE, with a 25 watt wired limit, was painfully slow at it. Going into this review, my hope was the S25 FE would do better and I had good reason to be hopeful. Samsung lists the new phone as capable of charging at 45 watts. However, in my testing the S25 FE was only slightly faster than its predecessor. Plugged into a 130 watt Razer GaN charger, it took the phone about an hour and 14 minutes to charge to full from a battery at 10 percent life. When I replicated that same test with a 25 watt charger, it took the S25 FE just over an hour-and-a-half to charge back up. Either way, if battery life is important to you, the Nothing 3a Pro and Pixel 9a are better bets. Both come with bigger batteries (5,000 and 5,100mAh, respectively), and with the former, you also get 50 watt charging. Software Igor Bonifacic for Engadget The S25 FE ships with Android 16 and Samsung's One UI 8 out of the box. Samsung has promised to support the phone with at least seven generations of platform updates, so it should stay current with Google's yearly release schedule up until at least Android 23 in 2032. Notably, this means the S25 FE may end up on a more recent version of Android than the S25, S25 Edge and S25 Ultra, all of which released with Android 15. With One UI 8, the S25 FE has access to all of the latest AI features from both Samsung and Google. Some of these tools are useful; others replicate functionality that has been present in Android for a long time. For example, Google's Circle to Search is great. It makes it easy to do a visual search of anything on the phone's screen. On the other hand, I could do without Samsung's Now Brief, which offers much of the same utility you'll find on Android's Discover page (a feature that comes standard on every Android phone). Each S25 FE also comes with six months of free access to Google AI Pro. Normally priced at $20 per month, the service gives you access to some of the company's best models, including Gemini 2.5 Pro, inside of the Gemini app. Within Flow, Google's AI filmmaking app, you also get limited access to Veo 3.1, Google's latest video generation system. Some other perks include 2TB of cloud storage and higher rate limits when using NotebookLM. Wrap-up Igor Bonifacic for Engadget With changes that amount to window dressing, I can't recommend anyone buy the S25 FE at full price. There's just enough here to justify spending $650 on a phone that is barely an upgrade over its predecessor. If you're a Samsung fan, I'm sure the S25 FE will be frequently discounted, but why reward the company for a lazy effort? Besides, the S25, following a $200 discount for Prime Day, was only $10 more than the FE earlier this month. Over the past few years, Google and Nothing have shown midrange phones don't need to be boring, iterative affairs. For Samsung, I think it's time to rethink its FE strategy. If these phones offered something different — say actual fan favorite features like a headphone jack — there could be compelling reasons to recommend them. But as things stand, there's just no reason to buy a new FE phone when the company's flagships see steep price discounts within months of their release.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s25-fe-review-iterative-to-a-fault-183026577.html?src=rss",
          "content": "Five years after the release of the Galaxy S20 FE, Samsung has settled into a predictable pattern with its \"Fan Edition\" line of phones. Each new phone doesn't offer much new or different from its immediate predecessor, with the company opting to offer iterative updates instead. That might have been fine before, but with the arrival of the Nothing Phone 3a Pro and Pixel 10 — devices that changed the value proposition in their respective categories — the S25 FE feels woefully out of touch with a market that's changing to meet people's demands. There's not much here that makes the new Galaxy S25 FE stand out, and any \"upgrades\" aren't substantive. Hardware and display Igor Bonifacic for Engadget When I first took the S25 FE out of the box, I thought Samsung had played a cruel trick on me. The phone looks identical to its predecessor, sporting the same brushed aluminum frame that's been the company's go-to for years now. I had to dig the S24 FE out of my gadgets drawer to compare the two phones before I confirmed they were in fact different devices. The physical differences are minor. Samsung has tweaked the dimensions of the new phone, making it slightly shorter, wider and thinner. Specifically, the S25 FE measures in at 6.35 x 3.02 x 0.29 inches, while its predecessor was 6.38 x 3.04 x 0.31 inches. The new phone is also protected by Samsung's \"enhanced Armor\" aluminum frame. More noticeable is that the S25 FE is lighter than last year's model, coming in at 6.7 ounces, down from 7.51 ounces. This is despite the fact the new device has a higher-capacity 4,900mAh battery. Together, these changes don't make the S25 FE easier to hold if you have small hands (just ask my girlfriend), but it does feel better balanced than its predecessor. One issue with the size of the S25 FE is the placement of the in-display fingerprint sensor. It's right at the bottom of the screen. I found this made it awkward to unlock the phone with my thumb — and I'm someone with big hands. Another slight difference is the finish on the back of the phone. This time around, Samsung has gone with a matte coating, instead of the glossy finish it used on the S24 FE. It's a welcome change since it makes the new model less prone to smudging and attracting fingerprints. I just wish Samsung had decided to offer the S25 FE in more fun colors. At release, it's available in four colorways: white, icy blue, jet black and navy (pictured). So, if you don't like blue, I'm sorry. Amid the slight design tweaks, Samsung has gone with the same screen it did last year. The S25 FE has a 6.7-inch AMOLED display, with a panel that offers a 120Hz refresh rate and 1080p resolution. The S24 FE's vibrant screen was one of the best parts of last year's model, and it's the same with S25 FE. It's easy to see the screen in bright sunlight, thanks to the fact it can push 1,900 nits of peak brightness. It's also vibrant, and with HDR10 support included, great for watching videos on YouTube, Netflix and elsewhere. Cameras Igor Bonifacic for Engadget Samsung made a single tweak to the Galaxy S25 FE's camera hardware. Like last year's model, the new phone has a 50-megapixel main camera with optical image stabilization (OIS) and a fast f/1.8 aperture lens. Once again, it also has an 8MP telephoto camera with a 3x optical zoom and a 12MP ultrawide angle that offers a 123-degree field of view. The one addition is a higher resolution 12MP front-facing camera with a faster f/2.2 aperture lens. For selfies, the S24 FE made do with a 10MP sensor and f/2.4 lens. If the new front-facing camera included phase detection autofocus (PDAF), it would be the same one that's available on the Galaxy S25. Unfortunately, it doesn't and that's a shame because PDAF greatly increases the likelihood your photos will come out sharp and in focus. It's also a shame Samsung decided not to update the FE's telephoto camera. Before the Nothing 3a Pro, that was one of the features that made the S24 FE stand out in its price range. In 2025, however, the S25 FE's telephoto feels outdated. It doesn't offer the 5x optical zoom of the Pixel 10 nor the 50MP of resolution and periscope zoom you get with the 3a Pro. Coming from the former, the FE's telephoto camera felt limiting. With only 8MP of resolution, trying to snap a photo at anything beyond 5x zoom was pointless; it would just turn out a blurry mess. As for FE's other cameras, they're decent if uninspiring. The 50MP camera is the best of the bunch, capable of capturing detailed, good-looking photos even in low light. The ultrawide, meanwhile, is mostly forgettable. It does an okay job of capturing big scenes, but it's lacking in dynamic range and detail. The selfie camera is a noticeable upgrade from the one that came with last year's model, and produces pleasing photos that are on par with what you can expect from the S25's front-facing camera. Otherwise, snapping pictures with the S25 FE feels like using a flagship phone from a few years ago. The one thing that saves it from being a complete blast from the past is the inclusion of Samsung's generative photo editing software, which you can use to remove distracting objects from photos. Of the AI photo apps I've tested, Samsung's is among the best at editing out objects without smearing the background. You can also use the generative edit to add things to a photo, but as you might expect, this doesn't work as well as removing them. Performance and battery life Igor Bonifacic for Engadget On paper, the S25 FE should offer better performance than its predecessor, thanks to Samsung's decision to equip the phone with its Exynos 2400 chipset over the cut-down Exynos 2400e it used on last year's model. In practice the two are about on par with one another. On Geekbench's processor test, the Exynos 2400 delivered a 2,144 single-core score and a 7,059 multi-core score. That's not much better than the 2,140 and 6,690 I recorded last fall on the S24 FE. Still, it's a more impressive showing than either the Pixel 9a and Nothing 3a Pro had when my colleague Sam Rutherford and I put their Tensor G4 and Snapdragon 7s Gen 3 chips through Geekbench earlier this year. For comparison, the former delivered a modest 1,665 on single-core performance and 4,294 on multi-core performance. The latter scored an even less impressive 1,115 and 3,082 respectively. In real-world use, the Exynos 2400 feels snappy. Scrolling is fast and fluid, as is opening apps and switching between them. Gaming performance is also impressive, with the chip able to handle the 60 fps modes in graphically demanding games like Diablo Immortal and League of Legends: Wild Rift without dropping frames. Last year, Samsung said it redesigned the S24 FE's vapor chamber to make it bigger and improve cooling. With the S25 FE, that component is an additional 10 percent larger. However, if the new vapor chamber made a difference to the phone's thermals, I had a hard time telling. Both the S25 FE and S24 FE got warm after about 15 to 20 minutes of gaming. The new phone never got hot to the point I couldn't hold it anymore, but it also didn't feel noticeably cooler than the S24 FE running the same games. As mentioned at the top, the S25 FE has a larger 4,900mAh battery. That's about four percent more capacity than the S24 FE offered. As a result, any difference in battery life is minimal. I'm sure there are some scenarios the S25 FE may last longer than its predecessor, but in my testing the two phones were equal in terms of longevity. With three to four hours of active screentime, I managed to get a full day of battery life from the S25 FE, with enough power left over to get the phone through the night before charging it in the morning. That's similar to the experience I had last year. Speaking of charging, the S24 FE, with a 25 watt wired limit, was painfully slow at it. Going into this review, my hope was the S25 FE would do better and I had good reason to be hopeful. Samsung lists the new phone as capable of charging at 45 watts. However, in my testing the S25 FE was only slightly faster than its predecessor. Plugged into a 130 watt Razer GaN charger, it took the phone about an hour and 14 minutes to charge to full from a battery at 10 percent life. When I replicated that same test with a 25 watt charger, it took the S25 FE just over an hour-and-a-half to charge back up. Either way, if battery life is important to you, the Nothing 3a Pro and Pixel 9a are better bets. Both come with bigger batteries (5,000 and 5,100mAh, respectively), and with the former, you also get 50 watt charging. Software Igor Bonifacic for Engadget The S25 FE ships with Android 16 and Samsung's One UI 8 out of the box. Samsung has promised to support the phone with at least seven generations of platform updates, so it should stay current with Google's yearly release schedule up until at least Android 23 in 2032. Notably, this means the S25 FE may end up on a more recent version of Android than the S25, S25 Edge and S25 Ultra, all of which released with Android 15. With One UI 8, the S25 FE has access to all of the latest AI features from both Samsung and Google. Some of these tools are useful; others replicate functionality that has been present in Android for a long time. For example, Google's Circle to Search is great. It makes it easy to do a visual search of anything on the phone's screen. On the other hand, I could do without Samsung's Now Brief, which offers much of the same utility you'll find on Android's Discover page (a feature that comes standard on every Android phone). Each S25 FE also comes with six months of free access to Google AI Pro. Normally priced at $20 per month, the service gives you access to some of the company's best models, including Gemini 2.5 Pro, inside of the Gemini app. Within Flow, Google's AI filmmaking app, you also get limited access to Veo 3.1, Google's latest video generation system. Some other perks include 2TB of cloud storage and higher rate limits when using NotebookLM. Wrap-up Igor Bonifacic for Engadget With changes that amount to window dressing, I can't recommend anyone buy the S25 FE at full price. There's just enough here to justify spending $650 on a phone that is barely an upgrade over its predecessor. If you're a Samsung fan, I'm sure the S25 FE will be frequently discounted, but why reward the company for a lazy effort? Besides, the S25, following a $200 discount for Prime Day, was only $10 more than the FE earlier this month. Over the past few years, Google and Nothing have shown midrange phones don't need to be boring, iterative affairs. For Samsung, I think it's time to rethink its FE strategy. If these phones offered something different — say actual fan favorite features like a headphone jack — there could be compelling reasons to recommend them. But as things stand, there's just no reason to buy a new FE phone when the company's flagships see steep price discounts within months of their release.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s25-fe-review-iterative-to-a-fault-183026577.html?src=rss",
          "feed_position": 36,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/adf88820-add9-11f0-a6f7-9b48f1e9c328"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/claude-code-comes-to-web-and-mobile-letting-devs-launch-parallel-jobs-on",
          "published_at": "Mon, 20 Oct 2025 18:15:00 GMT",
          "title": "Claude Code comes to web and mobile, letting devs launch parallel jobs on Anthropic’s managed infra",
          "standfirst": "Vibe coding is evolving and with it are the leading AI-powered coding services and tools, including Anthropic’s Claude Code. As of today, the service will be available via the web and, in preview, on the Claude iOS app, giving developers access to additional asynchronous capabilities. Previously, it was available through the terminal on developers&#x27; PCs with support for Git, Docker, Kubernetes, npm, pip, AWS CLI, etc., and as an extension for Microsoft&#x27;s open source VS Code editor and other JetBrains-powered integrated development environments (IDEs) via Claude Agent. “Claude Code on the web lets you kick off coding sessions without opening your terminal,” Anthropic said in a blog post. “Connect your GitHub repositories, describe what you need, and Claude handles the implementation. Each session runs in its own isolated environment with real-time progress tracking, and you can actively steer Claude to adjust course as it’s working through tasks.”This allows users to run coding projects asynchronously, a trend that many enterprises are looking for. The web version of Claude Code, currently in research preview, will be available to Pro and Max users. However, web Claude Code will be subject to the same rate limits as other versions. Anthropic throttled rate limits to Claude and Claude Code after the unexpected popularity of the coding tool in July, which enabled some users to run Claude Code overnight. Anthropic is now ensuring Claude Code comes closer to matching the availability of rival OpenAI&#x27;s Codex AI coding platform, powered by a variant of GPT-5, which launches on mobile and the web back in mid September 2025.Parallel usageAnthropic said running Claude Code in the cloud means teams can “now run multiple tasks in parallel across different repositories from a single interface and ship faster with automatic PR creation and clear change summaries.”One of the big draws of coding agents is giving developers the ability to run multiple coding projects, such as bugfixes, at the same time. Google’s two coding agents, Jules and Code Assist, both offer asynchronous code generation and checks. Codex from OpenAI also lets people work in parallel. Anthropic said bringing Claude Code to the web won’t disrupt workflows, but noted running tasks in the cloud work best for tasks such as answering questions around projects and how repositories are mapped, bugfixes and for routine, well-defined tasks, and backend changes to verify any adjustments. While most developers will likely prefer to use Claude Code on a desktop, Anthropic said the mobile version could encourage more users to “explore coding with Claude on the go.”Isolated environments Anthropic insisted that Claude Code tasks on the cloud will have the same level of security as the earlier version. It runs on an “isolated sandbox environment with network and filesystem restrictions.” Interactions go through a secure proxy service, which the company said ensures the model only accesses authorized repositories.Enterprise users can customize which domains Claude Code can connect to. Claude Code is powered by Claude Sonnet 4.5, which Anthropic claims is the best coding model around. The company recently made Claude Haiku 4.5, a smaller version of Claude that also has strong coding capabilities, available to all Claude subscribers, including free users.",
          "content": "Vibe coding is evolving and with it are the leading AI-powered coding services and tools, including Anthropic’s Claude Code. As of today, the service will be available via the web and, in preview, on the Claude iOS app, giving developers access to additional asynchronous capabilities. Previously, it was available through the terminal on developers&#x27; PCs with support for Git, Docker, Kubernetes, npm, pip, AWS CLI, etc., and as an extension for Microsoft&#x27;s open source VS Code editor and other JetBrains-powered integrated development environments (IDEs) via Claude Agent. “Claude Code on the web lets you kick off coding sessions without opening your terminal,” Anthropic said in a blog post. “Connect your GitHub repositories, describe what you need, and Claude handles the implementation. Each session runs in its own isolated environment with real-time progress tracking, and you can actively steer Claude to adjust course as it’s working through tasks.”This allows users to run coding projects asynchronously, a trend that many enterprises are looking for. The web version of Claude Code, currently in research preview, will be available to Pro and Max users. However, web Claude Code will be subject to the same rate limits as other versions. Anthropic throttled rate limits to Claude and Claude Code after the unexpected popularity of the coding tool in July, which enabled some users to run Claude Code overnight. Anthropic is now ensuring Claude Code comes closer to matching the availability of rival OpenAI&#x27;s Codex AI coding platform, powered by a variant of GPT-5, which launches on mobile and the web back in mid September 2025.Parallel usageAnthropic said running Claude Code in the cloud means teams can “now run multiple tasks in parallel across different repositories from a single interface and ship faster with automatic PR creation and clear change summaries.”One of the big draws of coding agents is giving developers the ability to run multiple coding projects, such as bugfixes, at the same time. Google’s two coding agents, Jules and Code Assist, both offer asynchronous code generation and checks. Codex from OpenAI also lets people work in parallel. Anthropic said bringing Claude Code to the web won’t disrupt workflows, but noted running tasks in the cloud work best for tasks such as answering questions around projects and how repositories are mapped, bugfixes and for routine, well-defined tasks, and backend changes to verify any adjustments. While most developers will likely prefer to use Claude Code on a desktop, Anthropic said the mobile version could encourage more users to “explore coding with Claude on the go.”Isolated environments Anthropic insisted that Claude Code tasks on the cloud will have the same level of security as the earlier version. It runs on an “isolated sandbox environment with network and filesystem restrictions.” Interactions go through a secure proxy service, which the company said ensures the model only accesses authorized repositories.Enterprise users can customize which domains Claude Code can connect to. Claude Code is powered by Claude Sonnet 4.5, which Anthropic claims is the best coding model around. The company recently made Claude Haiku 4.5, a smaller version of Claude that also has strong coding capabilities, available to all Claude subscribers, including free users.",
          "feed_position": 8,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/479x9yR2m3sOxcfXEPnxI/dd6f7e7281ced692395996331a3b5646/crimedy7_illustration_of_a_robot_coding_a_program_--ar_169_--_7dafd9d4-817a-4c5c-abbe-fb9112e639c7_0.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/anthropic-brings-claude-code-to-ios-and-the-web-180023611.html",
          "published_at": "Mon, 20 Oct 2025 18:00:23 +0000",
          "title": "Anthropic brings Claude Code to iOS and the web",
          "standfirst": "At the end of February, Anthropic announced Claude Code. In the eight months since then, the coding agent has arguably become the company's most important product, helping it carve out a niche for itself in the highly competitive AI market. Now, Anthropic is making it easier for developers to use Claude Code in more places with a new web interface for accessing the agent. To get started, you'll need connect Claude to your GitHub repositories. From there, the process of using the agent is the same as if it had direct terminal access. Describe what you need from it, and the agent will take it from there. Claude will provide progress updates while it works, and you can even steer it in real-time with additional prompts. Through the web interface, it's also possible to assign Claude multiple coding tasks to run in parallel. \"Every Claude Code task runs in an isolated sandbox environment with network and filesystem restrictions. Git interactions are handled through a secure proxy service that ensures Claude can only access authorized repositories — helping keep your code and credentials protected throughout the entire workflow,\" said Anthropic. In addition to making Claude Code available on the web, Anthropic is releasing a preview of the agent inside of its iOS app. The company warns the integration is early, and that it hopes \"to quickly refine the mobile experience based on your feedback.\" Pro and Max users can start using Claude Code on the web today. Anthropic notes any cloud sessions share the same rate limits with all other Claude Code usage. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-brings-claude-code-to-ios-and-the-web-180023611.html?src=rss",
          "content": "At the end of February, Anthropic announced Claude Code. In the eight months since then, the coding agent has arguably become the company's most important product, helping it carve out a niche for itself in the highly competitive AI market. Now, Anthropic is making it easier for developers to use Claude Code in more places with a new web interface for accessing the agent. To get started, you'll need connect Claude to your GitHub repositories. From there, the process of using the agent is the same as if it had direct terminal access. Describe what you need from it, and the agent will take it from there. Claude will provide progress updates while it works, and you can even steer it in real-time with additional prompts. Through the web interface, it's also possible to assign Claude multiple coding tasks to run in parallel. \"Every Claude Code task runs in an isolated sandbox environment with network and filesystem restrictions. Git interactions are handled through a secure proxy service that ensures Claude can only access authorized repositories — helping keep your code and credentials protected throughout the entire workflow,\" said Anthropic. In addition to making Claude Code available on the web, Anthropic is releasing a preview of the agent inside of its iOS app. The company warns the integration is early, and that it hopes \"to quickly refine the mobile experience based on your feedback.\" Pro and Max users can start using Claude Code on the web today. Anthropic notes any cloud sessions share the same rate limits with all other Claude Code usage. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-brings-claude-code-to-ios-and-the-web-180023611.html?src=rss",
          "feed_position": 37
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-cancel-nordvpn-and-get-your-money-back-173008588.html",
          "published_at": "Mon, 20 Oct 2025 17:30:08 +0000",
          "title": "How to cancel NordVPN and get your money back",
          "standfirst": "There's a lot to like about NordVPN, as I covered in my full NordVPN review. It's one of the fastest among the best VPNs, and it's got a bunch of cool, specialized servers for various VPN tasks. But the apps can be frustrating, and beyond that, no VPN is perfect for everyone. If you've decided NordVPN isn't for you, here's how to cancel your subscription and get your money back. How to turn off auto-renewal on NordVPN Even though you've decided to part ways with NordVPN, you may want to keep your subscription active while you pick out a replacement service. If that's the case, you can simply cancel automatic renewal and let your subscription expire at the end of the billing period. If you change your mind before then, you can turn auto-renew back on. Here's how to do it. Go to my.nordaccount.com. Click Log in to Nord Account and enter your email address and password. You'll arrive at the account overview page. In the left-hand column, click on Billing. On the list of subscriptions that appears, find NordVPN. Find the line that says \"Auto-renewal: ON,\" and click the Cancel link next to it. A warning message will appear. Click Cancel auto-renewal at the bottom-right. Sam Chapman for Engadget This will turn auto-renewal off. If you decide to turn it back on, just go back to the billing tab of your Nord account overview, find your NordVPN subscription and click Enable auto-renewal. How to cancel if you subscribed through an app store If you paid for NordVPN on a mobile device through Google Play or the Apple app store, you'll need to go to the relevant app store to cancel the subscription. On Android, sign in to Google Play, touch your profile picture, tap Payments & subscriptions and tap Subscriptions. Scroll until you find NordVPN, tap it and hit Cancel subscription. If you want a refund, follow the instructions in \"How to get a refund from NordVPN\" below. On iOS, open the settings app, touch your profile picture, then tap Subscription. Scroll down to NordVPN, tap it and hit Cancel subscription. To get a refund for an Apple purchase, contact the Apple support team instead of the NordVPN team. How to delete your NordVPN account On the other hand, if you're sick of NordVPN and already have another VPN lined up, you can cancel immediately by deleting your Nord account altogether. This will also cut you off from any other Nord Security products you might be using, including NordPass and NordLocker. Go to my.nordaccount.com, click Log in to Nord Account and enter your credentials. At the top-right of the account overview page, click your email address. In the dropdown menu, click Account settings. Look at the bottom of the page to find the account deletion controls. Click Delete account. Nord will send an authentication code to your account's email address. Enter it. Follow the onscreen prompts to confirm deletion. Sam Chapman for Engadget How to get a refund from NordVPN NordVPN has a standard 30-day money-back guarantee. As long as you bought your subscription in the last 30 days, you can get a full refund. To do so, you'll need to first cancel auto-renewal on your plan as described above, then contact support to ask for the refund. You can reach NordVPN support by going to the help center at support.nordvpn.com. To reach the live chat and email ticket options, you'll need to work your way down to a bottom-level help center article, then scroll down until you reach the section titled \"Still having issues?\" It's frustrating, but you can get there by just clicking the first link on every page (or just follow this link and scroll down). Sam Chapman for Engadget Once you've found the buttons, either start a live chat or open the email form. Whichever you choose, explain that you've cancelled your subscription and would like a refund. Make sure not to end the interaction until you've received confirmation that your refund will be processed. Afterwards, it'll take up to 10 business days for your reimbursement to go through. NordVPN alternatives With NordVPN cancelled, you may be in the market for another VPN. I've collected several on my best VPN list (linked at the start of the article), but here's a few specific recommendations: Proton VPN is the best overall, Surfshark is the fastest and ExpressVPN is good for beginners and great at streaming. Good luck in your quest for a VPN that meets your needs.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-nordvpn-and-get-your-money-back-173008588.html?src=rss",
          "content": "There's a lot to like about NordVPN, as I covered in my full NordVPN review. It's one of the fastest among the best VPNs, and it's got a bunch of cool, specialized servers for various VPN tasks. But the apps can be frustrating, and beyond that, no VPN is perfect for everyone. If you've decided NordVPN isn't for you, here's how to cancel your subscription and get your money back. How to turn off auto-renewal on NordVPN Even though you've decided to part ways with NordVPN, you may want to keep your subscription active while you pick out a replacement service. If that's the case, you can simply cancel automatic renewal and let your subscription expire at the end of the billing period. If you change your mind before then, you can turn auto-renew back on. Here's how to do it. Go to my.nordaccount.com. Click Log in to Nord Account and enter your email address and password. You'll arrive at the account overview page. In the left-hand column, click on Billing. On the list of subscriptions that appears, find NordVPN. Find the line that says \"Auto-renewal: ON,\" and click the Cancel link next to it. A warning message will appear. Click Cancel auto-renewal at the bottom-right. Sam Chapman for Engadget This will turn auto-renewal off. If you decide to turn it back on, just go back to the billing tab of your Nord account overview, find your NordVPN subscription and click Enable auto-renewal. How to cancel if you subscribed through an app store If you paid for NordVPN on a mobile device through Google Play or the Apple app store, you'll need to go to the relevant app store to cancel the subscription. On Android, sign in to Google Play, touch your profile picture, tap Payments & subscriptions and tap Subscriptions. Scroll until you find NordVPN, tap it and hit Cancel subscription. If you want a refund, follow the instructions in \"How to get a refund from NordVPN\" below. On iOS, open the settings app, touch your profile picture, then tap Subscription. Scroll down to NordVPN, tap it and hit Cancel subscription. To get a refund for an Apple purchase, contact the Apple support team instead of the NordVPN team. How to delete your NordVPN account On the other hand, if you're sick of NordVPN and already have another VPN lined up, you can cancel immediately by deleting your Nord account altogether. This will also cut you off from any other Nord Security products you might be using, including NordPass and NordLocker. Go to my.nordaccount.com, click Log in to Nord Account and enter your credentials. At the top-right of the account overview page, click your email address. In the dropdown menu, click Account settings. Look at the bottom of the page to find the account deletion controls. Click Delete account. Nord will send an authentication code to your account's email address. Enter it. Follow the onscreen prompts to confirm deletion. Sam Chapman for Engadget How to get a refund from NordVPN NordVPN has a standard 30-day money-back guarantee. As long as you bought your subscription in the last 30 days, you can get a full refund. To do so, you'll need to first cancel auto-renewal on your plan as described above, then contact support to ask for the refund. You can reach NordVPN support by going to the help center at support.nordvpn.com. To reach the live chat and email ticket options, you'll need to work your way down to a bottom-level help center article, then scroll down until you reach the section titled \"Still having issues?\" It's frustrating, but you can get there by just clicking the first link on every page (or just follow this link and scroll down). Sam Chapman for Engadget Once you've found the buttons, either start a live chat or open the email form. Whichever you choose, explain that you've cancelled your subscription and would like a refund. Make sure not to end the interaction until you've received confirmation that your refund will be processed. Afterwards, it'll take up to 10 business days for your reimbursement to go through. NordVPN alternatives With NordVPN cancelled, you may be in the market for another VPN. I've collected several on my best VPN list (linked at the start of the article), but here's a few specific recommendations: Proton VPN is the best overall, Surfshark is the fastest and ExpressVPN is good for beginners and great at streaming. Good luck in your quest for a VPN that meets your needs.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-nordvpn-and-get-your-money-back-173008588.html?src=rss",
          "feed_position": 39,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/813933f0-ab92-11f0-befe-8b86b84e993e"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/the-best-new-computers-to-replace-your-old-windows-10-pc-134500000.html",
          "published_at": "Mon, 20 Oct 2025 14:24:36 +0000",
          "title": "The best new computers to replace your old Windows 10 PC",
          "standfirst": "It’s official: Microsoft has officially ended support for Windows 10. Thankfully, there’s a free and easy way to get another year’s worth of Extended Security Updates (which will take you to mid-October 2026). But even if your computer meets the minimum system requirements for a free Windows 11 upgrade, anything older than a year won't be able to take advantage of Microsoft's Copilot+ AI PC features, like Windows Recall or Studio Effects for video chats. So if you've already been feeling that your current aging PC is on the verge of dying — slow performance, whining fans, batteries that barely keep a charge — it's probably time to consider replacing it with a new system. We've already done the legwork of researching and selecting new hardware in our best laptop and best Windows notebook guides (we've also covered more powerful gaming and schoolwork systems), but here are some suggestions if you're just looking to snap up something quickly. The best Windows 10 laptop replacements Surface Laptop 13.8-inch In many ways, the Snapdragon-powered Surface Laptop is emblematic of where Windows PCs are headed. It's incredibly light, surprisingly powerful for something with a mobile chip and its battery lasted over 17-and-a-half hours in our testing. While you may run into some compatibility issues if you're running ancient Windows programs, for most people the Surface Laptop is one of the best PC experiences they can have today. If you're looking for something smaller and cheaper, there's also a $700 13-inch model, and the $1,200 15-inch version is worth it if you need a bigger screen. (Check out our full review of the Surface Laptop 13.8-inch.) Dell 14 Premium laptop Sam Rutherford for Engadget Dell 14 Premium We loved last year's XPS 14, and now that it’s been renamed as the Dell 14 Premium, it’s still a fantastic machine. It looks and feels luxurious, and it has one of the best screens around. You may just need some time getting used to its invisible trackpad (which is blended into the palm rest), and its capacitive function key row. (Check out our full Editor’s Choice review of the Dell 14 Premium.) ASUS ZenBook S 14 The ZenBook S14 wowed us with its powerful hardware, excellent battery life (of over 16 hours) and solid construction. It's a sign of how far ASUS has come from simply copying Apple. The S14 is also lighter than the MacBook Air, and it includes more useful ports (two USB-C, one USB-A, HDMI and a headphone jack). Its Ceraluminum case (a unique ceramic material) also feels surprisingly polished, and its OLED screen looks simply amazing. (Check out our full review of the ASUS ZenBook S 14.) Apple MacBook Air Don't yell at me — Apple's new computers are so good that Windows users should seriously consider jumping ship to Macs. While the software may take some getting used to, it's worth the struggle for the speed and incredible battery life from Apple's M-series chips. The MacBook Air remains one of the best computers around, with an incredibly thin and fan-less case and far more power than you'd think. And if you're an iPhone user, you'll also have access to features like phone mirroring that are tough to replicate on Windows. (Check out our full review of the M4 MacBook Air.) Dell Slim Desktop Dell The best Windows 10 desktop replacements Dell Slim desktop If you're just looking for a basic desktop replacement, it's hard to go wrong with the Dell Slim. While we haven't reviewed this specific model, the specs on even the entry-level configuration have all of the power you need for basic computing, despite housing everything in a frame that's notably smaller than older tower PCs. And if you need a bit more performance, consider the slightly more expensive Dell Pro, which can squeeze in up to 32GB of RAM and a handful of dedicated graphics cards. Apple Mac Mini Apple's Mac mini is one of the most powerful mini-desktops around, it's adorably small and it starts at just $599 (look for the frequent sales that drop the price by as much as $100). Just as I argued above for the MacBook Air, it's worth considering the jump to MacOS simply because Apple's hardware is so impressive now. And don't worry, you can connect any monitor to it, and you won't have to replace your existing PC keyboard and mouse. Geekom A6 Mini While I haven't tested the Geekom A6 Mini yet, it's widely considered one of the best Windows mini-desktops around $400 to $500. The A6 Mini features a very capable AMD Ryzen 7 6800H processor with a bit of gaming power, 16GB of RAM and a 512GB SSD. You honestly don't need much more for basic productivity work. Frequently Asked Questions Do I need to upgrade to a new computer if my current Windows 10 PC still works fine for me? Your computer will still continue to run following the Microsoft’s termination of default support for Windows 10 on October 15, 2025, but that’s not a wise longterm strategy. The free Extended Security Updates will buy you another year, but that's effectively a limited life support: After that, Windows 10 PCs won’t receive security updates or any sort of improvements, so they’ll be vulnerable to hacking and malware. And if you’ve still got an old Windows 10 machine, there’s a good chance that its components may wear out soon. If you choose to continue using a Windows 10 PC, be sure to back up your important data and try not to rely on it for critical tasks. Can a Mac run native Windows software? Virtualization software like VMWare and Parallels can let you run Windows apps inside of macOS, but be aware that also involves buying a copy of Windows and dedicating a large chunk of disk space for it. These days, most major apps are available across both platforms, so be sure to check if there’s a Mac version of your favorite Windows app. Can a Chromebook or iPad replace a Windows 10 PC? Chromebooks and iPads both have very specific purposes: Chromebooks are great budget-friendly machines for accessing the web and running online apps. iPads are a handy way to upgrade your mobile internet experiences, since their large screens are better for browsing the web, running apps and watching media. But neither are ideal replacements for a Windows 10 PC, which can access the full breadth of Windows software in addition to the web. If either one works for you, great; but we think the options listed above are better full-service PC replacements. I have a ton of PC games. What's my best upgrade option? It’s easy to find a decent gaming desktop from a reliable computer maker these days, just make sure you’re equipped with at least 32GB of RAM (new titles can be pretty memory intensive), and an NVIDIA RTX 40-series or AMD Radeon RX 9000-series GPU. As for CPUs, I’d recommend sticking with Intel’s 13th-gen chips or AMD’s Ryzen 8000-series processors at a minimum. Don’t count out gaming laptops either, as they’ve come a long way over the last decade. It’s not hard to find a gaming notebook that’s powerful, portable and useful for multimedia and productivity work as well. Update, October 20 2025, 9:30AM ET: This story has been updated to reflect that the Windows 10 end of support date has now passed, and we’ve included a link to an explainer on how to extend support for another year for free. This article originally appeared on Engadget at https://www.engadget.com/computing/the-best-new-computers-to-replace-your-old-windows-10-pc-134500000.html?src=rss",
          "content": "It’s official: Microsoft has officially ended support for Windows 10. Thankfully, there’s a free and easy way to get another year’s worth of Extended Security Updates (which will take you to mid-October 2026). But even if your computer meets the minimum system requirements for a free Windows 11 upgrade, anything older than a year won't be able to take advantage of Microsoft's Copilot+ AI PC features, like Windows Recall or Studio Effects for video chats. So if you've already been feeling that your current aging PC is on the verge of dying — slow performance, whining fans, batteries that barely keep a charge — it's probably time to consider replacing it with a new system. We've already done the legwork of researching and selecting new hardware in our best laptop and best Windows notebook guides (we've also covered more powerful gaming and schoolwork systems), but here are some suggestions if you're just looking to snap up something quickly. The best Windows 10 laptop replacements Surface Laptop 13.8-inch In many ways, the Snapdragon-powered Surface Laptop is emblematic of where Windows PCs are headed. It's incredibly light, surprisingly powerful for something with a mobile chip and its battery lasted over 17-and-a-half hours in our testing. While you may run into some compatibility issues if you're running ancient Windows programs, for most people the Surface Laptop is one of the best PC experiences they can have today. If you're looking for something smaller and cheaper, there's also a $700 13-inch model, and the $1,200 15-inch version is worth it if you need a bigger screen. (Check out our full review of the Surface Laptop 13.8-inch.) Dell 14 Premium laptop Sam Rutherford for Engadget Dell 14 Premium We loved last year's XPS 14, and now that it’s been renamed as the Dell 14 Premium, it’s still a fantastic machine. It looks and feels luxurious, and it has one of the best screens around. You may just need some time getting used to its invisible trackpad (which is blended into the palm rest), and its capacitive function key row. (Check out our full Editor’s Choice review of the Dell 14 Premium.) ASUS ZenBook S 14 The ZenBook S14 wowed us with its powerful hardware, excellent battery life (of over 16 hours) and solid construction. It's a sign of how far ASUS has come from simply copying Apple. The S14 is also lighter than the MacBook Air, and it includes more useful ports (two USB-C, one USB-A, HDMI and a headphone jack). Its Ceraluminum case (a unique ceramic material) also feels surprisingly polished, and its OLED screen looks simply amazing. (Check out our full review of the ASUS ZenBook S 14.) Apple MacBook Air Don't yell at me — Apple's new computers are so good that Windows users should seriously consider jumping ship to Macs. While the software may take some getting used to, it's worth the struggle for the speed and incredible battery life from Apple's M-series chips. The MacBook Air remains one of the best computers around, with an incredibly thin and fan-less case and far more power than you'd think. And if you're an iPhone user, you'll also have access to features like phone mirroring that are tough to replicate on Windows. (Check out our full review of the M4 MacBook Air.) Dell Slim Desktop Dell The best Windows 10 desktop replacements Dell Slim desktop If you're just looking for a basic desktop replacement, it's hard to go wrong with the Dell Slim. While we haven't reviewed this specific model, the specs on even the entry-level configuration have all of the power you need for basic computing, despite housing everything in a frame that's notably smaller than older tower PCs. And if you need a bit more performance, consider the slightly more expensive Dell Pro, which can squeeze in up to 32GB of RAM and a handful of dedicated graphics cards. Apple Mac Mini Apple's Mac mini is one of the most powerful mini-desktops around, it's adorably small and it starts at just $599 (look for the frequent sales that drop the price by as much as $100). Just as I argued above for the MacBook Air, it's worth considering the jump to MacOS simply because Apple's hardware is so impressive now. And don't worry, you can connect any monitor to it, and you won't have to replace your existing PC keyboard and mouse. Geekom A6 Mini While I haven't tested the Geekom A6 Mini yet, it's widely considered one of the best Windows mini-desktops around $400 to $500. The A6 Mini features a very capable AMD Ryzen 7 6800H processor with a bit of gaming power, 16GB of RAM and a 512GB SSD. You honestly don't need much more for basic productivity work. Frequently Asked Questions Do I need to upgrade to a new computer if my current Windows 10 PC still works fine for me? Your computer will still continue to run following the Microsoft’s termination of default support for Windows 10 on October 15, 2025, but that’s not a wise longterm strategy. The free Extended Security Updates will buy you another year, but that's effectively a limited life support: After that, Windows 10 PCs won’t receive security updates or any sort of improvements, so they’ll be vulnerable to hacking and malware. And if you’ve still got an old Windows 10 machine, there’s a good chance that its components may wear out soon. If you choose to continue using a Windows 10 PC, be sure to back up your important data and try not to rely on it for critical tasks. Can a Mac run native Windows software? Virtualization software like VMWare and Parallels can let you run Windows apps inside of macOS, but be aware that also involves buying a copy of Windows and dedicating a large chunk of disk space for it. These days, most major apps are available across both platforms, so be sure to check if there’s a Mac version of your favorite Windows app. Can a Chromebook or iPad replace a Windows 10 PC? Chromebooks and iPads both have very specific purposes: Chromebooks are great budget-friendly machines for accessing the web and running online apps. iPads are a handy way to upgrade your mobile internet experiences, since their large screens are better for browsing the web, running apps and watching media. But neither are ideal replacements for a Windows 10 PC, which can access the full breadth of Windows software in addition to the web. If either one works for you, great; but we think the options listed above are better full-service PC replacements. I have a ton of PC games. What's my best upgrade option? It’s easy to find a decent gaming desktop from a reliable computer maker these days, just make sure you’re equipped with at least 32GB of RAM (new titles can be pretty memory intensive), and an NVIDIA RTX 40-series or AMD Radeon RX 9000-series GPU. As for CPUs, I’d recommend sticking with Intel’s 13th-gen chips or AMD’s Ryzen 8000-series processors at a minimum. Don’t count out gaming laptops either, as they’ve come a long way over the last decade. It’s not hard to find a gaming notebook that’s powerful, portable and useful for multimedia and productivity work as well. Update, October 20 2025, 9:30AM ET: This story has been updated to reflect that the Windows 10 end of support date has now passed, and we’ve included a link to an explainer on how to extend support for another year for free. This article originally appeared on Engadget at https://www.engadget.com/computing/the-best-new-computers-to-replace-your-old-windows-10-pc-134500000.html?src=rss",
          "feed_position": 42,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/99233ff0-7236-11f0-babc-58c1851dbde8.jpeg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/adobe-foundry-wants-to-rebuild-firefly-for-your-brand-not-just-tweak-it",
          "published_at": "Mon, 20 Oct 2025 13:00:00 GMT",
          "title": "Adobe Foundry wants to rebuild Firefly for your brand — not just tweak it",
          "standfirst": "Hoping to attract more enterprise teams to its ecosystem, Adobe launched a new model customization service called Adobe AI Foundry, which would create bespoke versions of its flagship AI model, Firefly.Adobe AI Foundry will work with enterprise customers to rearchitect and retrain Firefly models specific to the client. AI Foundry version models are different from custom Firefly models in that Foundry models understand multiple concepts compared to custom models with only a single concept. These models will also be multimodal, offering a wider use case than custom Firefly models, which can only ingest and respond with images. Adobe AI Foundry models, with Firefly at its base, will know a company’s brand tone, image and video style, products and services and all its IP. The models will generate content based on this information for any use case the company wants. Hannah Elsakr, vice president, GenAI New Business Ventures at Adobe, told VentureBeat that the idea to set up AI Foundry came because enterprise customers wanted more sophisticated custom versions of Firefly. But with how complex the needs of enterprises are, Adobe will be doing the rearchitecting rather than handing the reins over to customers. “We will retrain our own Firefly commercially safe models with the enterprise IP. We keep that IP separate. We never take that back into the base model, and the enterprise itself owns that output,” Elsakr said. Adobe will deploy the Foundry version of Firefly through its API solution, Firefly Services. Elsakr likened AI Foundry to an advisory service, since Adobe will have teams working directly with enterprise customers to retrain the model. Deep tuningElsakr refers to Foundry as a deep tuning method because it goes further than simply fine-tuning a model.“The way we think about it, maybe more layman&#x27;s terms, is that we&#x27;re surgically reopening the Firefly-based models,” Elsakr said. “So you get the benefit of all the world&#x27;s knowledge from our image model or a video model. We&#x27;re going back in time and are bringing in the IP from the enterprise, like a brand. It could be footage from a shot style, whatever they have a license to contribute. We then retrain. We call this continuous pre-training, where we overweigh the model to dial some things differently. So we&#x27;re literally retraining our base model, and that&#x27;s why we call it deep tuning instead of fine-tuning.”Part of the training pipeline involves Adobe’s embedded teams working with the company to identify the data they would need. Then the data is securely transferred and ingested before being tagged. It is fed to the base model, and then Adobe begins a pre-training model run. Elsakr maintains the Foundry versions of Firefly will not be small or distilled models. Often, the additional data from companies expands the parameters of Firefly.Two early customers of Adobe AI Foundry are Home Depot and Walt Disney Imagineering, the research and development arm of Disney for its theme parks. “We are always exploring innovative ways to enhance our customer experience and streamline our creative workflows. Adobe’s AI Foundry represents an exciting step forward in embracing cutting-edge technologies to deepen customer engagement and deliver impactful content across our digital channels,” said Molly Battin, senior vice president and chief marketing officer at The Home Depot.More customizationEnterprises often turn to fine-tuning and model customization to bring large language models with their vast external knowledge closer to their company’s needs. Fine-tuning also enables enterprise users to utilize models only in the context of their organization’s data, so the model doesn’t respond with text wholly unrelated to the business.Most organizations, however, do the fine-tuning themselves. They connect to the model’s API and begin retraining it to answer based on their ground truth or their preferences. Several methods for fine-tuning exist, including some that can be done with just a prompt. Other model providers also try to make it easier for their customers to fine-tune models, such as OpenAI with its o4-mini reasoning model. Elsakr said she expects some companies will have three versions of Firefly: the Foundry version for most projects, a custom Firefly for specific single-concept use cases, and the base Firefly because some teams want a model less encumbered by corporate knowledge.",
          "content": "Hoping to attract more enterprise teams to its ecosystem, Adobe launched a new model customization service called Adobe AI Foundry, which would create bespoke versions of its flagship AI model, Firefly.Adobe AI Foundry will work with enterprise customers to rearchitect and retrain Firefly models specific to the client. AI Foundry version models are different from custom Firefly models in that Foundry models understand multiple concepts compared to custom models with only a single concept. These models will also be multimodal, offering a wider use case than custom Firefly models, which can only ingest and respond with images. Adobe AI Foundry models, with Firefly at its base, will know a company’s brand tone, image and video style, products and services and all its IP. The models will generate content based on this information for any use case the company wants. Hannah Elsakr, vice president, GenAI New Business Ventures at Adobe, told VentureBeat that the idea to set up AI Foundry came because enterprise customers wanted more sophisticated custom versions of Firefly. But with how complex the needs of enterprises are, Adobe will be doing the rearchitecting rather than handing the reins over to customers. “We will retrain our own Firefly commercially safe models with the enterprise IP. We keep that IP separate. We never take that back into the base model, and the enterprise itself owns that output,” Elsakr said. Adobe will deploy the Foundry version of Firefly through its API solution, Firefly Services. Elsakr likened AI Foundry to an advisory service, since Adobe will have teams working directly with enterprise customers to retrain the model. Deep tuningElsakr refers to Foundry as a deep tuning method because it goes further than simply fine-tuning a model.“The way we think about it, maybe more layman&#x27;s terms, is that we&#x27;re surgically reopening the Firefly-based models,” Elsakr said. “So you get the benefit of all the world&#x27;s knowledge from our image model or a video model. We&#x27;re going back in time and are bringing in the IP from the enterprise, like a brand. It could be footage from a shot style, whatever they have a license to contribute. We then retrain. We call this continuous pre-training, where we overweigh the model to dial some things differently. So we&#x27;re literally retraining our base model, and that&#x27;s why we call it deep tuning instead of fine-tuning.”Part of the training pipeline involves Adobe’s embedded teams working with the company to identify the data they would need. Then the data is securely transferred and ingested before being tagged. It is fed to the base model, and then Adobe begins a pre-training model run. Elsakr maintains the Foundry versions of Firefly will not be small or distilled models. Often, the additional data from companies expands the parameters of Firefly.Two early customers of Adobe AI Foundry are Home Depot and Walt Disney Imagineering, the research and development arm of Disney for its theme parks. “We are always exploring innovative ways to enhance our customer experience and streamline our creative workflows. Adobe’s AI Foundry represents an exciting step forward in embracing cutting-edge technologies to deepen customer engagement and deliver impactful content across our digital channels,” said Molly Battin, senior vice president and chief marketing officer at The Home Depot.More customizationEnterprises often turn to fine-tuning and model customization to bring large language models with their vast external knowledge closer to their company’s needs. Fine-tuning also enables enterprise users to utilize models only in the context of their organization’s data, so the model doesn’t respond with text wholly unrelated to the business.Most organizations, however, do the fine-tuning themselves. They connect to the model’s API and begin retraining it to answer based on their ground truth or their preferences. Several methods for fine-tuning exist, including some that can be done with just a prompt. Other model providers also try to make it easier for their customers to fine-tune models, such as OpenAI with its o4-mini reasoning model. Elsakr said she expects some companies will have three versions of Firefly: the Foundry version for most projects, a custom Firefly for specific single-concept use cases, and the base Firefly because some teams want a model less encumbered by corporate knowledge.",
          "feed_position": 9,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1Hg97nt1wacQ4K8pE0NfX7/5dba45daa25b361ac777c18695b45898/crimedy7_illustration_of_a_sculptor_creating_a_robot_from_a_p_501bf165-0b44-4bb1-9608-1025a42400b7_2.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/tv-movies/the-new-apple-tv-and-peacock-streaming-bundle-is-officially-available-170403587.html",
          "published_at": "Mon, 20 Oct 2025 12:18:26 +0000",
          "title": "The new Apple TV and Peacock streaming bundle is officially available",
          "standfirst": "There's yet another streaming bundle in town, and it will be ideal for fans of Ted Lasso and The Office. Apple and Peacock have teamed up to provide both of their streaming services together in a bundle starting at $15 per month. The new Apple TV + Peacock bundle is officially available now for $15 monthly for the ad-supported tier. This is a mighty fine deal, given that Apple TV recently changed both its name and price. The platform costs $13 per month now on its own. Peacock starts at $11 per month. In other words, this is a discount of around $9 each month. In this economy, we'll take any savings we can get. As mentioned previously, the only caveat is that the base tier includes ads. The subscription shoots up to $20 per month for an ad-free version. However, a standalone subscription to ad-free Peacock is $17 on its own. Additionally, Apple One subscribers will get a 35 percent discount on Peacock Premium Plus plans. It's always nice when two lonely corporations find friendship, isn't it? For the uninitiated, Apple TV is the company's big-wig streaming platform. It's primarily known for sci-fi like Severance, For All Mankind and the upcoming Pluribus. The platform is also host to plenty of comedy, like The Studio, Shrinking and Ted Lasso. Peacock is NBC's streaming service. It streams old-school network programming like The Office, Grimm and Superstore. The service features a stable of original programming like Poker Face, Twisted Metal and the underrated Mrs. Davis. The platform also recently premiered a little show called The Paper, which is a spinoff of The Office. Against all odds, this is actually a great little sitcom and a worthy successor to the original. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/the-new-apple-tv-and-peacock-streaming-bundle-is-officially-available-170403587.html?src=rss",
          "content": "There's yet another streaming bundle in town, and it will be ideal for fans of Ted Lasso and The Office. Apple and Peacock have teamed up to provide both of their streaming services together in a bundle starting at $15 per month. The new Apple TV + Peacock bundle is officially available now for $15 monthly for the ad-supported tier. This is a mighty fine deal, given that Apple TV recently changed both its name and price. The platform costs $13 per month now on its own. Peacock starts at $11 per month. In other words, this is a discount of around $9 each month. In this economy, we'll take any savings we can get. As mentioned previously, the only caveat is that the base tier includes ads. The subscription shoots up to $20 per month for an ad-free version. However, a standalone subscription to ad-free Peacock is $17 on its own. Additionally, Apple One subscribers will get a 35 percent discount on Peacock Premium Plus plans. It's always nice when two lonely corporations find friendship, isn't it? For the uninitiated, Apple TV is the company's big-wig streaming platform. It's primarily known for sci-fi like Severance, For All Mankind and the upcoming Pluribus. The platform is also host to plenty of comedy, like The Studio, Shrinking and Ted Lasso. Peacock is NBC's streaming service. It streams old-school network programming like The Office, Grimm and Superstore. The service features a stable of original programming like Poker Face, Twisted Metal and the underrated Mrs. Davis. The platform also recently premiered a little show called The Paper, which is a spinoff of The Office. Against all odds, this is actually a great little sitcom and a worthy successor to the original. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/the-new-apple-tv-and-peacock-streaming-bundle-is-officially-available-170403587.html?src=rss",
          "feed_position": 44
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/beats-powerbeats-fit-review-deja-vu-in-a-good-way-120058332.html",
          "published_at": "Mon, 20 Oct 2025 12:00:58 +0000",
          "title": "Beats Powerbeats Fit review: Déjà vu, in a good way",
          "standfirst": "Beats devices have been the more colorful, full-of-personality complements to Apple’s clean-and-minimal gear ever since Apple bought the company back in 2014. Beats earbuds and speakers are the more flexible alternatives to things like AirPods and HomePods, and the new Beats Powerbeats Fit keep that tradition alive. Some six months after the Powerbeats Pro 2 debuted earlier this year, Beats now has an updated version of the Fit Pro to offer folks looking for many of the conveniences of an Apple device in something with slightly more character and versatility. Rather than reinventing the wheel, Beats made small changes on the Powerbeats Fit that ultimately make for a more polished version of its predecessor. What’s new If you’re familiar with the Beats Fit Pro, you’ll be familiar with the Powerbeats Fit. Beats kept much of what worked with its previous $200 earbuds here (including the price), making very minor changes to improve the comfort and the overall design. The new buds have 20 percent more flexible wingtips and the charging case is 17 percent more compact than that of the Beats Fit Pro. More on the wingtips in a moment, but first I have to commend Beats for making the charging case feel ever so slightly more premium this time around — and since it’s smaller than before, it’s less cumbersome to tuck in your back pocket. The buds also fit snugly into the charging case with a satisfying snap every time; they always align properly to recharge, something I cannot say about past pairs of the AirPods Pro I’ve owned. When it comes to the wingtips on the Powerbeats Fit, they appear to be a hair shorter than those on the Beats Fit Pro, and certainly more malleable. I felt the biggest difference in flexibility at the base of the wingtip where it meets the earbud — those on the Powerbeats Fit have a bit more give than those on its predecessor. These small changes make it easy to pop the Powerbeats Fit into your ears and really not fuss with the wingtips at all. They’re present just to provide a more secure fit during intense workouts, and they do just that. I wore them during strength training, 5K runs and leisurely walks and I didn’t have to adjust them at all once I popped them in. When Beats announced these new buds, the company claimed its design tweaks would also make the Powerbeats Fit more comfortable to wear all day long, not just during workouts. I’ll admit that I didn’t find the previous Beats Fit Pro uncomfortable to wear when not at the gym or on the trail. Yes, the Powerbeats Fit are marginally more comfortable now and the wingtips are more supple, but the change is subtle. If you jibe with the wingtip design to begin with, you’ll safely be able to use the Powerbeats Fit as daily drivers in addition to workout companions. Notably, the Powerbeats Fit come with one extra pair of eartips in the box (four instead of the previous three), so once you find the eartips that are your best fit, you’ll be off to the races. There are also two new bold colors to choose from, orange and pink, in addition to gray and black. Valentina Palladino for Engadget What’s the same Thankfully, Beats didn’t mess with all of the good things about the Fit Pro when developing the Powerbeats Fit. The new buds have an IPX4 water resistance rating, which isn’t the highest level of protection out there, but more than enough to withstand your sweatiest training sessions. Onboard controls in the form of physical buttons remain the same, although I didn’t accidentally trigger the buttons on the Powerbeats Fit nearly as much as I did with the Fit Pro. That might be because all the small changes Beats made in the design paid off — I didn’t fuss with the new buds in my ears as much as before, therefore I didn’t accidentally press the buttons as much. The Powerbeats Fit also have Apple’s H1 chip inside, which enables features like hands-free Siri, automatic switching between devices, Adaptive EQ, Audio Sharing and Personalized Spatial Audio with dynamic head tracking. Transparency mode returns here as well, and it remains one of the standout features of any Apple-associated wireless earbuds. And if you do decide to wear the Powerbeats Fit all day long, you’ll likely make even more use of transparency mode as you need to jump in and out of conversations happening around you. In addition, you can keep track of the new earbuds in Apple’s Find My app. Beats didn’t bill any improvements in sound quality on the Powerbeats Fit, and after listening to them alongside the Beats Fit Pro, I can say they sound almost identical. While listening to some tracks with the Powerbeats Fit, I noticed an almost imperceptible increase in the clarity of vocals, but that’s about it. Bass remains punchy and strong, and the buds get decently loud. Active noise cancellation (ANC) is also the same on the new buds: strong enough to block out ambient noise around you and people’s voices. While running outside, I still heard the loudest disturbances like passing trucks and oddly sonorous cackling of nearby wildlife, but that’s arguably for the best. If you’re exercising outside, be it in a park or on city streets, you should be at least somewhat aware of your surroundings. Valentina Palladino for Engadget Battery life is consistent here as well, with Beats promising up to seven hours on a single charge (or six with ANC turned on) and up to 30 hours total when employing the Powerbeats Fit charging case. Anecdotally, after a week of using the Powerbeats Fit for an average of one hour each day, the charging case still had 75 percent battery left. If you’re using these all day, every day, you’ll obviously need to power it up more frequently. But if these are primarily your workout companions, you could get a week or two before needing to plug them in. Wrap-up The Powerbeats Fit are a fitting update to the Beats Fit Pro. The latter was one of the best devices in the Beats lineup to begin with, and the latest model only improves upon the winning formula. They offer a solid balance of a comfortable, secure design, good sound quality and ANC and handy additional features at a decent price. The latter is arguably just as important as the buds’ ability to withstand a sweaty training session: folks looking for many of the conveniences found in AirPods will find them here in an alternative design, and in a pair of buds that also works just as well with Android devices. If you’re willing to pay more, you could shell out $250 for either the Powerbeats Pro 2 to get that full over-ear hook style, or AirPods Pro 3 — both of which have built-in heart rate tracking But that feature in particular will be more of a nice-to-have than a necessity for most.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/beats-powerbeats-fit-review-deja-vu-in-a-good-way-120058332.html?src=rss",
          "content": "Beats devices have been the more colorful, full-of-personality complements to Apple’s clean-and-minimal gear ever since Apple bought the company back in 2014. Beats earbuds and speakers are the more flexible alternatives to things like AirPods and HomePods, and the new Beats Powerbeats Fit keep that tradition alive. Some six months after the Powerbeats Pro 2 debuted earlier this year, Beats now has an updated version of the Fit Pro to offer folks looking for many of the conveniences of an Apple device in something with slightly more character and versatility. Rather than reinventing the wheel, Beats made small changes on the Powerbeats Fit that ultimately make for a more polished version of its predecessor. What’s new If you’re familiar with the Beats Fit Pro, you’ll be familiar with the Powerbeats Fit. Beats kept much of what worked with its previous $200 earbuds here (including the price), making very minor changes to improve the comfort and the overall design. The new buds have 20 percent more flexible wingtips and the charging case is 17 percent more compact than that of the Beats Fit Pro. More on the wingtips in a moment, but first I have to commend Beats for making the charging case feel ever so slightly more premium this time around — and since it’s smaller than before, it’s less cumbersome to tuck in your back pocket. The buds also fit snugly into the charging case with a satisfying snap every time; they always align properly to recharge, something I cannot say about past pairs of the AirPods Pro I’ve owned. When it comes to the wingtips on the Powerbeats Fit, they appear to be a hair shorter than those on the Beats Fit Pro, and certainly more malleable. I felt the biggest difference in flexibility at the base of the wingtip where it meets the earbud — those on the Powerbeats Fit have a bit more give than those on its predecessor. These small changes make it easy to pop the Powerbeats Fit into your ears and really not fuss with the wingtips at all. They’re present just to provide a more secure fit during intense workouts, and they do just that. I wore them during strength training, 5K runs and leisurely walks and I didn’t have to adjust them at all once I popped them in. When Beats announced these new buds, the company claimed its design tweaks would also make the Powerbeats Fit more comfortable to wear all day long, not just during workouts. I’ll admit that I didn’t find the previous Beats Fit Pro uncomfortable to wear when not at the gym or on the trail. Yes, the Powerbeats Fit are marginally more comfortable now and the wingtips are more supple, but the change is subtle. If you jibe with the wingtip design to begin with, you’ll safely be able to use the Powerbeats Fit as daily drivers in addition to workout companions. Notably, the Powerbeats Fit come with one extra pair of eartips in the box (four instead of the previous three), so once you find the eartips that are your best fit, you’ll be off to the races. There are also two new bold colors to choose from, orange and pink, in addition to gray and black. Valentina Palladino for Engadget What’s the same Thankfully, Beats didn’t mess with all of the good things about the Fit Pro when developing the Powerbeats Fit. The new buds have an IPX4 water resistance rating, which isn’t the highest level of protection out there, but more than enough to withstand your sweatiest training sessions. Onboard controls in the form of physical buttons remain the same, although I didn’t accidentally trigger the buttons on the Powerbeats Fit nearly as much as I did with the Fit Pro. That might be because all the small changes Beats made in the design paid off — I didn’t fuss with the new buds in my ears as much as before, therefore I didn’t accidentally press the buttons as much. The Powerbeats Fit also have Apple’s H1 chip inside, which enables features like hands-free Siri, automatic switching between devices, Adaptive EQ, Audio Sharing and Personalized Spatial Audio with dynamic head tracking. Transparency mode returns here as well, and it remains one of the standout features of any Apple-associated wireless earbuds. And if you do decide to wear the Powerbeats Fit all day long, you’ll likely make even more use of transparency mode as you need to jump in and out of conversations happening around you. In addition, you can keep track of the new earbuds in Apple’s Find My app. Beats didn’t bill any improvements in sound quality on the Powerbeats Fit, and after listening to them alongside the Beats Fit Pro, I can say they sound almost identical. While listening to some tracks with the Powerbeats Fit, I noticed an almost imperceptible increase in the clarity of vocals, but that’s about it. Bass remains punchy and strong, and the buds get decently loud. Active noise cancellation (ANC) is also the same on the new buds: strong enough to block out ambient noise around you and people’s voices. While running outside, I still heard the loudest disturbances like passing trucks and oddly sonorous cackling of nearby wildlife, but that’s arguably for the best. If you’re exercising outside, be it in a park or on city streets, you should be at least somewhat aware of your surroundings. Valentina Palladino for Engadget Battery life is consistent here as well, with Beats promising up to seven hours on a single charge (or six with ANC turned on) and up to 30 hours total when employing the Powerbeats Fit charging case. Anecdotally, after a week of using the Powerbeats Fit for an average of one hour each day, the charging case still had 75 percent battery left. If you’re using these all day, every day, you’ll obviously need to power it up more frequently. But if these are primarily your workout companions, you could get a week or two before needing to plug them in. Wrap-up The Powerbeats Fit are a fitting update to the Beats Fit Pro. The latter was one of the best devices in the Beats lineup to begin with, and the latest model only improves upon the winning formula. They offer a solid balance of a comfortable, secure design, good sound quality and ANC and handy additional features at a decent price. The latter is arguably just as important as the buds’ ability to withstand a sweaty training session: folks looking for many of the conveniences found in AirPods will find them here in an alternative design, and in a pair of buds that also works just as well with Android devices. If you’re willing to pay more, you could shell out $250 for either the Powerbeats Pro 2 to get that full over-ear hook style, or AirPods Pro 3 — both of which have built-in heart rate tracking But that feature in particular will be more of a nice-to-have than a necessity for most.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/beats-powerbeats-fit-review-deja-vu-in-a-good-way-120058332.html?src=rss",
          "feed_position": 46,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/7c269cf0-ab64-11f0-ac9b-105ce8eedd80"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/5NhML02FGAEkp2yOpsPkrx/b62d547d376660e631c01d70283f7946/AdobeStock_1243259614.jpeg",
      "popularity_score": 2017.7165369444444,
      "ai_summary": [
        "Engadget reviewed the best wireless headphones, focusing on over-ear models.",
        "The guide helps users choose headphones based on wear style and noise cancellation needs.",
        "The review considers features like adaptive ANC and budget options for various users.",
        "The article provides information on how to choose the best wireless headphones.",
        "The review also includes FAQs and details on how the headphones were tested."
      ]
    },
    {
      "id": "cluster_28",
      "coverage": 2,
      "updated_at": "Wed, 22 Oct 2025 03:10:00 -0400",
      "title": "Sources: Fal.ai, which hosts multimodal AI models for developers, raised ~$250M at a $4B+ valuation, less than three months after announcing a $125M Series C (Marina Temkin/TechCrunch)",
      "neutral_headline": "Fal.ai Raises $250M at $4B+ Valuation",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251022/p7#a251022p7",
          "published_at": "Wed, 22 Oct 2025 03:10:00 -0400",
          "title": "Sources: Fal.ai, which hosts multimodal AI models for developers, raised ~$250M at a $4B+ valuation, less than three months after announcing a $125M Series C (Marina Temkin/TechCrunch)",
          "standfirst": "Marina Temkin / TechCrunch: Sources: Fal.ai, which hosts multimodal AI models for developers, raised ~$250M at a $4B+ valuation, less than three months after announcing a $125M Series C &mdash; Fal.ai, a startup that hosts image, video, and audio AI models for developers, has closed a new round valuing the company at over $4 billion &hellip;",
          "content": "Marina Temkin / TechCrunch: Sources: Fal.ai, which hosts multimodal AI models for developers, raised ~$250M at a $4B+ valuation, less than three months after announcing a $125M Series C &mdash; Fal.ai, a startup that hosts image, video, and audio AI models for developers, has closed a new round valuing the company at over $4 billion &hellip;",
          "feed_position": 14,
          "image_url": "http://www.techmeme.com/251022/i7.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/21/sources-multimodal-ai-startup-fal-ai-already-raised-at-4b-valuation/",
          "published_at": "Tue, 21 Oct 2025 20:12:41 +0000",
          "title": "Sources: Multimodal AI startup Fal AI already raised at $4B+ valuation",
          "standfirst": "Fal provides developers with over 600 image, video, audio, and 3D models, it says, and boasts that its cloud has thousands of Nvidia H100 and H200 GPUs and is fine-tuned for speedy inference.",
          "content": "Fal provides developers with over 600 image, video, audio, and 3D models, it says, and boasts that its cloud has thousands of Nvidia H100 and H200 GPUs and is fine-tuned for speedy inference.",
          "feed_position": 5
        }
      ],
      "featured_image": "http://www.techmeme.com/251022/i7.jpg",
      "popularity_score": 2015.8729258333333,
      "ai_summary": [
        "Fal.ai, a multimodal AI model host, raised approximately $250 million.",
        "The funding round valued the company at over $4 billion.",
        "This new round occurred less than three months after a $125 million Series C.",
        "Fal.ai provides developers with over 600 AI models for various media types.",
        "The company's cloud infrastructure includes thousands of Nvidia GPUs."
      ]
    },
    {
      "id": "cluster_54",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 20:08:42 +0000",
      "title": "FDA slows down on drug reviews, approvals amid Trump admin chaos",
      "neutral_headline": "FDA Slows Drug Reviews Amid Shutdown",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/fda-slows-down-on-drug-reviews-approvals-amid-trump-admin-chaos/",
          "published_at": "Tue, 21 Oct 2025 20:08:42 +0000",
          "title": "FDA slows down on drug reviews, approvals amid Trump admin chaos",
          "standfirst": "The ongoing shutdown also means no new drug submissions are being accepted.",
          "content": "Amid the chaos of the Trump administration’s haphazard job cuts and a mass exodus of leadership, the Food and Drug Administration is experiencing a slowdown of drug reviews and approvals, according to an analysis reported by Stat News. An assessment of metrics by RBC Capital Markets analysts found that FDA drug approvals dropped 14 percentage points in the third quarter compared to the average of the six previous quarters—falling from an average of 87 percent to 73 percent this past quarter. In line with that finding, analysts noted that the delay rate in meeting deadlines for drug application reviews rose from an average of 4 percent to 11 percent. The FDA also rejected more applications than normal, going from a historical average of 10 percent to 15 percent in the third quarter. A growing number of rejections relate to problems at manufacturing plants, which in turn could suggest problems with the FDA’s inspection and auditing processes.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2019/05/GettyImages-496532228-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2019/05/GettyImages-496532228-1152x648.jpg",
      "popularity_score": 348.8512591666667,
      "ai_summary": [
        "The FDA is slowing down drug reviews and approvals.",
        "This slowdown is due to ongoing government shutdown.",
        "No new drug submissions are currently being accepted.",
        "The shutdown is causing chaos within the FDA.",
        "The situation impacts the drug approval process."
      ]
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 19:58:37 +0000",
      "title": "It’s troll vs. troll in Netflix’s Troll 2 trailer",
      "neutral_headline": "Netflix Releases Trailer for Troll 2",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/troll-2-trailer-is-a-godzilla-inspired-monster-mash/",
          "published_at": "Tue, 21 Oct 2025 19:58:37 +0000",
          "title": "It’s troll vs. troll in Netflix’s Troll 2 trailer",
          "standfirst": "Norwegian director Roar Uthaug's sequel to his 2022 film Troll knows to not take itself too seriously.",
          "content": "Netflix’s international offerings include some entertaining Norwegian fare, such as the series Ragnarok (2020–2023), a surprisingly engaging reworking of Norse mythology brought into the 21st century that ran for three seasons. Another enjoyable offering was a 2022 monster movie called Troll, essentially a Norwegian take on the classic Godzilla formula. Netflix just dropped a trailer for the sequel, Troll 2, which looks to be very much in the same vein as its predecessor. (Spoilers for the first Troll movie below.) Don’t confuse the Netflix franchise with 2010’s Trollhunter, shot in the style of a found footage mockumentary. A group of college students sets off into the wilds of the fjordland to make a documentary about a suspected bear poacher named Hans. They discover that Hans is actually hunting down trolls and decide to document those endeavors instead, but soon realize they are very much out of their depth.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/troll1-1152x648-1761073850.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/troll1-1152x648-1761073850.jpg",
      "popularity_score": 339.68320361111114,
      "ai_summary": [
        "Netflix released a trailer for the film Troll 2.",
        "The film is a sequel to the 2022 film Troll.",
        "The director is Norwegian director Roar Uthaug.",
        "The film does not take itself too seriously.",
        "The trailer provides a preview of the film's content."
      ]
    },
    {
      "id": "cluster_69",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 19:02:10 +0000",
      "title": "OpenAI looks for its “Google Chrome” moment with new Atlas web browser",
      "neutral_headline": "OpenAI Launches Atlas Web Browser",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/openais-new-atlas-web-browser-wants-to-let-you-chat-with-a-page/",
          "published_at": "Tue, 21 Oct 2025 19:02:10 +0000",
          "title": "OpenAI looks for its “Google Chrome” moment with new Atlas web browser",
          "standfirst": "MacOS version launches today, includes Agent Mode preview to \"use the Internet for you.\"",
          "content": "Back in 2008, Google launched the Chrome browser to help better integrate its industry-leading search engine into the web-browsing experience. Today, OpenAI announced the Atlas browser that it hopes will do something similar for its ChatGPT large language model, answering the question “What if I could chat with a browser?” as the OpenAI team put it. OpenAI Founder and CEO Sam Altman said in a live stream announcement that Atlas will let users “chat with a page,” helping ChatGPT become a core way that users interact with the place where “a ton of work and life happens” online. “The way that we hope people will use the Internet in the future… is that the chat experience and a web browser can be a great analogue,” he said. The new browser is available for download now on macOS, and Altman promised Windows and mobile versions would be rolled out “as quick as we can.”Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo.jpg",
      "popularity_score": 323.74237027777775,
      "ai_summary": [
        "OpenAI is launching a new web browser called Atlas.",
        "The MacOS version launches today.",
        "It includes an Agent Mode preview.",
        "Agent Mode is designed to use the Internet for users.",
        "OpenAI aims for a \"Google Chrome\" moment."
      ]
    },
    {
      "id": "cluster_58",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 19:45:32 +0000",
      "title": "Elon Musk just declared war on NASA’s acting administrator, apparently",
      "neutral_headline": "Elon Musk Declares War on NASA Administrator",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/elon-musk-just-declared-war-on-nasas-acting-administrator-apparently/",
          "published_at": "Tue, 21 Oct 2025 19:45:32 +0000",
          "title": "Elon Musk just declared war on NASA’s acting administrator, apparently",
          "standfirst": "\"Sean said that NASA might benefit from being part of the Cabinet.\"",
          "content": "The clock just ticked past noon here in Houston, so it’s acceptable to have a drink, right? Because after another turbulent morning of closely following the rough-and-tumble contest to become the next NASA administrator, I sure could use one. What has happened now? Why, it was only SpaceX founder Elon Musk, who is NASA’s most important contractor, referring to the interim head of the space agency, Sean Duffy, as “Sean Dummy” and suggesting Duffy was trying to kill NASA. Musk later added, “The person responsible for America’s space program can’t have a 2 digit IQ.”Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/54441425446_25b87f0fd0_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/54441425446_25b87f0fd0_k-1152x648.jpg",
      "popularity_score": 317.4651480555556,
      "ai_summary": [
        "Elon Musk has apparently declared war on NASA's acting administrator.",
        "The administrator is named Sean.",
        "Musk's statement was in response to a comment by Sean.",
        "Sean suggested NASA might benefit from being part of the Cabinet.",
        "The statement reflects a disagreement between Musk and NASA."
      ]
    },
    {
      "id": "cluster_65",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 19:12:30 +0000",
      "title": "Upcoming iOS and macOS 26.1 update will let you fog up your Liquid Glass",
      "neutral_headline": "iOS and macOS Update to Include Liquid Glass",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/new-ios-and-macos-betas-add-tinted-toggle-to-tone-down-liquid-glass/",
          "published_at": "Tue, 21 Oct 2025 19:12:30 +0000",
          "title": "Upcoming iOS and macOS 26.1 update will let you fog up your Liquid Glass",
          "standfirst": "Apple backs down from some aspects of Liquid Glass, but not others.",
          "content": "Apple’s new Liquid Glass user interface design was one of the most noticeable and divisive features of its major software updates this year. It added additional fluidity and translucency throughout iOS, iPadOS, macOS, and Apple’s other operating systems, and as we noted in our reviews, the default settings weren’t always great for readability. The upcoming 26.1 update for all of those OSes is taking a step toward addressing some of the complaints, though not by changing things about the default look of Liquid Glass. Rather, the update is adding a new toggle that will let users choose between a Clear and Tinted look for Liquid Glass, with Clear representing the default look and Tinted cranking up the opacity and contrast. The default glassy look of the notifications in iOS 26. The Tinted toggle fogs up the glass, preserving a hint of translucency. Credit: Andrew Cunningham The toggle behaved less consistently in macOS 26.1, but here's an example of the glassy look in the Photos app. Credit: Andrew Cunningham And the same UI with the Tinted toggle turned on. Credit: Andrew Cunningham The new toggle adds a half-step between the default visual settings and the “reduce transparency” setting, which, aside from changing a bunch of other things about the look and feel of the operating system, is buried further down inside the Accessibility options. The Tinted toggle does make colors and vague shapes visible beneath the glass panes, preserving the general look of Liquid Glass while also erring on the side of contrast and visibility, where the “reduce transparency” setting is more of an all-or-nothing blunt instrument.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6225-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6225-1152x648.jpg",
      "popularity_score": 306.9145925,
      "ai_summary": [
        "The upcoming iOS and macOS 26.1 update will include Liquid Glass.",
        "Apple is backing down from some aspects of Liquid Glass.",
        "The update will affect the user experience.",
        "The update is coming soon.",
        "The update will change some features."
      ]
    },
    {
      "id": "cluster_75",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:46:42 +0000",
      "title": "YouTube’s likeness detection has arrived to help stop AI doppelgängers",
      "neutral_headline": "YouTube Introduces Likeness Detection",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/10/youtube-rolls-out-likeness-detection-to-help-creators-combat-ai-fakes/",
          "published_at": "Tue, 21 Oct 2025 18:46:42 +0000",
          "title": "YouTube’s likeness detection has arrived to help stop AI doppelgängers",
          "standfirst": "Likeness detection will flag possible AI fakes, but Google doesn't guarantee removal.",
          "content": "AI content has proliferated across the Internet over the past few years, but those early confabulations with mutated hands have evolved into synthetic images and videos that can be hard to differentiate from reality. Having helped to create this problem, Google has some responsibility to keep AI video in check on YouTube. To that end, the company has started rolling out its promised likeness detection system for creators. Google’s powerful and freely available AI models have helped fuel the rise of AI content, some of which is aimed at spreading misinformation and harassing individuals. Creators and influencers fear their brands could be tainted by a flood of AI videos that show them saying and doing things that never happened—even lawmakers are fretting about this. Google has placed a large bet on the value of AI content, so banning AI from YouTube, as many want, simply isn’t happening. Earlier this year, YouTube promised tools that would flag face-stealing AI content on the platform. The likeness detection tool, which is similar to the site’s copyright detection system, has now expanded beyond the initial small group of testers. YouTube says the first batch of eligible creators have been notified that they can use likeness detection, but interested parties will need to hand Google even more personal information to get protection from AI fakes.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg",
      "popularity_score": 301.4845925,
      "ai_summary": [
        "YouTube is introducing likeness detection to identify AI doppelgängers.",
        "The feature will flag possible AI fakes.",
        "Google does not guarantee removal of flagged content.",
        "The feature aims to combat AI-generated content.",
        "The feature is designed to protect creators' likenesses."
      ]
    },
    {
      "id": "cluster_79",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:30:11 +0000",
      "title": "Satellite operators will soon join airlines in using Starlink in-flight Wi-Fi",
      "neutral_headline": "Starlink to Provide In-Flight Wi-Fi",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/satellite-operators-will-soon-join-airlines-in-using-starlink-in-flight-wi-fi/",
          "published_at": "Tue, 21 Oct 2025 18:30:11 +0000",
          "title": "Satellite operators will soon join airlines in using Starlink in-flight Wi-Fi",
          "standfirst": "\"This starts to enable a whole new category of capabilities.\"",
          "content": "A little over a year ago, one of SpaceX’s Crew Dragon spacecraft flew a team of four private astronauts to orbit on a mission that made history with the first fully commercial spacewalk. Jared Isaacman and Sarah Gillis briefly floated out the door of the Dragon capsule, wearing SpaceX-built pressure suits to protect them against the hostile environment of space. It was the first time anyone ventured outside of their spacecraft without the involvement of a government space agency. The mission, named Polaris Dawn, made an important contribution in another area. It was the first space mission to connect with SpaceX’s Starlink broadband network, using laser links between the Dragon spacecraft and Starlink satellites to communicate with the Earth.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink_laser-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink_laser-1152x648.jpg",
      "popularity_score": 291.20931472222225,
      "ai_summary": [
        "Satellite operators will soon use Starlink for in-flight Wi-Fi.",
        "Airlines will be among the first to use the service.",
        "This will enable a new category of capabilities.",
        "The service will improve in-flight connectivity.",
        "The service will be available soon."
      ]
    },
    {
      "id": "cluster_84",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:02:36 +0000",
      "title": "Cards Against Humanity lawsuit forced SpaceX to vacate land on US/Mexico border",
      "neutral_headline": "SpaceX Forced to Vacate Land",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/cards-against-humanity-gets-settlement-from-spacex-plans-pack-of-elon-musk-cards/",
          "published_at": "Tue, 21 Oct 2025 18:02:36 +0000",
          "title": "Cards Against Humanity lawsuit forced SpaceX to vacate land on US/Mexico border",
          "standfirst": "CAH: Trespassing lawsuit forced SpaceX to \"pack up the space garbage\" and leave.",
          "content": "A year after suing SpaceX for “invading” a plot of land on the US/Mexico border, Cards Against Humanity says it has obtained a settlement and will provide supporters with a new pack of cards about Elon Musk. The party-game company bought the land in 2017 in an attempt to stymie President Trump’s wall-building project, but alleged that SpaceX illegally took over the land and filled it with construction equipment and materials. A September 2024 lawsuit filed against SpaceX in Cameron County District Court in Texas sought up to $15 million to cover the cost of restoring the property and other damages. Cards Against Humanity, which bought the property with donations from supporters, told Ars today that “we’ve been in negotiations with SpaceX for much of the last year. We held out for the best settlement we could get—almost until the trial was supposed to start—and unfortunately part of that negotiation was that we’re not allowed to discuss specific settlement terms. They did admit to trespassing during the discovery phase, which was very validating.”Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/cards-against-elon-musk-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/cards-against-elon-musk-1152x648.jpg",
      "popularity_score": 278.7495925,
      "ai_summary": [
        "A Cards Against Humanity lawsuit forced SpaceX to vacate land.",
        "The land was located on the US/Mexico border.",
        "The lawsuit was for trespassing.",
        "SpaceX was forced to leave the area.",
        "SpaceX had to remove equipment."
      ]
    },
    {
      "id": "cluster_82",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:12:07 +0000",
      "title": "“Butt breathing” might soon be a real medical treatment",
      "neutral_headline": "Butt Breathing\" May Become Medical Treatment",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/butt-breathing-might-soon-be-a-real-medical-treatment/",
          "published_at": "Tue, 21 Oct 2025 18:12:07 +0000",
          "title": "“Butt breathing” might soon be a real medical treatment",
          "standfirst": "Ig Nobel-winning research could one day be used to treat people with blocked airways or clogged lungs.",
          "content": "Last year, a group of researchers won the 2024 Ig Nobel Prize in Physiology for discovering that many mammals are capable of breathing through their anus. But as with many Ig Nobel awards, there is a serious side to the seeming silliness. The same group has conducted a new study on the feasibility of adapting this method to treat people with blocked airways or clogged lungs, with promising results that bring rectal oxygen delivery one step closer to medical reality. As previously reported, this is perhaps one of the more unusual research developments to come out of the COVID-19 pandemic and its associated shortages of ventilators and artificial lungs to assist patients’ breathing and prevent respiratory failure. The Cincinnati Children’s Hospital Medical Center team took their inspiration from the humble loach, a freshwater bottom-dwelling fish found throughout Eurasia and northern Africa. The loach (along with sea cucumbers) employs intestinal breathing (i.e., through the anus) rather than gills to survive under hypoxic conditions, thanks to having lots of capillary vessels in its intestine. The technical term is enteral ventilation via anus (EVA). Would such a novel breathing method work in mammals? The team thought it might be possible and undertook experiments with mice and micro-pigs to test that hypothesis. They drew upon earlier research by Leland Clark, also of Cincinnati Children’s Hospital, who invented a perfluorocarbon liquid called Oxycyte as a possible form of artificial blood. That vision never materialized, although it did provide a handy plot point for the 1989 film The Abyss, in which a rat is able to “breathe” in a similar liquid.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/ignobel3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/ignobel3-1152x648.jpg",
      "popularity_score": 265.9082036111111,
      "ai_summary": [
        "\"Butt breathing\" research may become a medical treatment.",
        "The research won an Ig Nobel prize.",
        "It could treat people with blocked airways.",
        "It could treat people with clogged lungs.",
        "The treatment is still in development."
      ]
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 17:52:42 +0000",
      "title": "M5 iPad Pro tested: Stop me if you’ve heard this one before",
      "neutral_headline": "M5 iPad Pro Tested: Processing Power Questioned",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/testing-apples-m5-ipad-pro-future-proofing-for-apples-perennial-overkill-tablet/",
          "published_at": "Tue, 21 Oct 2025 17:52:42 +0000",
          "title": "M5 iPad Pro tested: Stop me if you’ve heard this one before",
          "standfirst": "It's a gorgeous tablet, but what does an iPad need with more processing power?",
          "content": "This year’s iPad Pro is what you might call a “chip refresh” or an “internal refresh.” These refreshes are what Apple generally does for its products for one or two or more years after making a larger external design change. Leaving the physical design alone preserves compatibility with the accessory ecosystem. For the Mac, chip refreshes are still pretty exciting to me, because many people who use a Mac will, very occasionally, assign it some kind of task where they need it to work as hard and fast as it can, for an extended period of time. You could be a developer compiling a large and complex app, or you could be a podcaster or streamer editing or exporting an audio or video file, or maybe you’re just playing a game. The power and flexibility of the operating system, and first- and third-party apps made to take advantage of that power and flexibility, mean that “more speed” is still exciting, even if it takes a few years for that speed to add up to something users will consistently notice and appreciate. And then there’s the iPad Pro. Especially since Apple shifted to using the same M-series chips that it uses in Macs, most iPad Pro reviews contain some version of “this is great hardware that is much faster than it needs to be for anything the iPad does.” To wit, our review of the M4 iPad Pro from May 2024:Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6198-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6198-1152x648.jpeg",
      "popularity_score": 250.58459249999999,
      "ai_summary": [
        "The M5 iPad Pro has been tested.",
        "The review calls the tablet gorgeous.",
        "The review questions the need for more processing power.",
        "The iPad Pro has a powerful processor.",
        "The review is about the new iPad Pro."
      ]
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 17:00:13 +0000",
      "title": "Google Fi is getting enhanced web calls and messaging, AI bill summaries",
      "neutral_headline": "Google Fi Enhances Web Calls and Messaging",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/google-fi-is-getting-enhanced-web-calls-and-messaging-ai-bill-summaries/",
          "published_at": "Tue, 21 Oct 2025 17:00:13 +0000",
          "title": "Google Fi is getting enhanced web calls and messaging, AI bill summaries",
          "standfirst": "Google's MVNO gets better web support, clearer audio, and yes, more AI.",
          "content": "Google’s Fi cellular service is getting an upgrade, and since this is 2025, there’s plenty of AI involved. You’ll be able to ask Google AI questions about your bill, and a different variation of AI will improve call quality. AI haters need not despair—there are also some upgrades to connectivity and Fi web features. As part of this update, a new Gemini-powered chatbot will soon be turned loose on your billing statements. The idea is that you can get bill summaries and ask specific questions of the robot without waiting for a real person. Google claims that testers have had positive experiences with the AI billing bot, so it’s rolling the feature out widely. Next month, Google also plans to flip the switch on an AI audio enhancement. The new “optimized audio” will use AI to filter out background sounds like wind or crowd noise. If you’re using a Pixel, you already have a similar feature for your end of the call. However, this update will reduce background noise on the other end as well. Google’s MVNO has also added support for HD and HD+ calling on supported connections.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2019/09/Google-Fi-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2019/09/Google-Fi-1152x648.png",
      "popularity_score": 161.70987027777778,
      "ai_summary": [
        "Google Fi is getting enhanced web calls and messaging.",
        "The enhancements include AI bill summaries.",
        "Google Fi is Google's MVNO service.",
        "The updates improve web support and audio quality.",
        "The updates include more AI features."
      ]
    },
    {
      "id": "cluster_92",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 17:00:45 +0000",
      "title": "MacBook Pro review: Apple’s most awkward laptop is the first to show off Apple M5",
      "neutral_headline": "MacBook Pro Review: Apple M5 Chip",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/m5-macbook-pro-review-fifth-generation-apple-silicon-in-a-familiar-wrapper/",
          "published_at": "Tue, 21 Oct 2025 17:00:45 +0000",
          "title": "MacBook Pro review: Apple’s most awkward laptop is the first to show off Apple M5",
          "standfirst": "Apple M5 trades blows with Pro and Max chips from older generations.",
          "content": "When I’m asked to recommend a Mac laptop for people, Apple’s low-end 14-inch MacBook Pro usually gets lost in the shuffle. It competes with the 13- and 15-inch MacBook Air, significantly cheaper computers that meet or exceed the “good enough” boundary for the vast majority of computer users. The basic MacBook Pro also doesn’t have the benefit of Apple’s Pro or Max-series chips, which come with many more CPU cores, substantially better graphics performance, and higher memory capacity for true professionals and power users. But the low-end Pro makes sense for a certain type of power user. At $1,599, it’s the cheapest way to get Apple’s best laptop screen, with mini LED technology, a higher 120 Hz ProMotion refresh rate for smoother scrolling and animations, and the optional but lovely nano-texture (read: matte) finish. Unlike the MacBook Air, it comes with a cooling fan, which has historically meant meaningfully better sustained performance and less performance throttling. And it’s also Apple’s cheapest laptop with three Thunderbolt ports, an HDMI port, and an SD card slot, all genuinely useful for people who want to plug lots of things in without having multiple dongles or a bulky dock competing for the Air’s two available ports. If you don’t find any of those arguments in the basic MacBook Pro’s favor convincing, that’s fine. The new M5 version makes almost no changes to the laptop other than the chip, so it’s unlikely to change your calculus if you already looked at the M3 or M4 version and passed it up. But it is the first Mac to ship with the M5, the first chip in Apple’s fifth-generation chip family and a preview of what’s to come for (almost?) every other Mac in the lineup. So you can at least be interested in the 14-inch MacBook Pro as a showcase for a new processor, if not as a retail product in and of itself.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6215-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6215-1152x648.jpeg",
      "popularity_score": 157.71875916666667,
      "ai_summary": [
        "A MacBook Pro review is available.",
        "The review focuses on the Apple M5 chip.",
        "The M5 chip trades blows with older Pro and Max chips.",
        "The laptop is the first to show off the Apple M5.",
        "The review assesses the performance of the new chip."
      ]
    },
    {
      "id": "cluster_128",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 02:54:29 +0000",
      "title": "It wasn’t space debris that struck a United Airlines plane—it was a weather balloon",
      "neutral_headline": "Weather Balloon Caused United Airlines Plane Incident, Not Space Debris",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/the-mystery-object-that-struck-a-plane-in-flight-it-was-probably-a-weather-balloon/",
          "published_at": "Tue, 21 Oct 2025 02:54:29 +0000",
          "title": "It wasn’t space debris that struck a United Airlines plane—it was a weather balloon",
          "standfirst": "WindBorne says its balloons are compliant with all applicable airspace regulations.",
          "content": "The mysterious impact of a United Airlines aircraft in flight last week has sparked plenty of theories as to its cause, from space debris to high-flying birds. However the question of what happened to flight 1093, and its severely damaged front window, appears to be answered in the form of a weather balloon. “I think this was a WindBorne balloon,” Kai Marshland, co-founder of the weather prediction company WindBorne Systems, told Ars in an email on Monday evening. “We learned about UA1093 and the potential that it was related to one of our balloons at 11 pm PT on Sunday and immediately looked into it. At 6 am PT, we sent our preliminary investigation to both NTSB and FAA, and are working with both of them to investigate further.”Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/68a6ba53499bdd827f510e35_54fca9353dfe2c2a33bb46167c61cd64_payload-block3-957x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/68a6ba53499bdd827f510e35_54fca9353dfe2c2a33bb46167c61cd64_payload-block3-957x648.png",
      "popularity_score": 151,
      "ai_summary": [
        "WindBorne confirmed its balloons are compliant with all airspace regulations.",
        "The incident involved a United Airlines plane, not space debris as initially thought.",
        "The cause was a weather balloon, according to WindBorne's statement.",
        "WindBorne's balloons are designed to operate within established regulations.",
        "The incident highlights the importance of identifying the correct cause."
      ]
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 14:43:20 +0000",
      "title": "Even with protections, wolves still fear humans",
      "neutral_headline": "Wolves Exhibit Fear of Humans, Even With Protections",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/even-with-protections-wolves-still-fear-humans/",
          "published_at": "Tue, 21 Oct 2025 14:43:20 +0000",
          "title": "Even with protections, wolves still fear humans",
          "standfirst": "European wolves flee human conversation faster than dogs' barking.",
          "content": "In May 2025, the European Parliament changed the status of wolves in the EU from “strictly protected” to “protected,” which opened the way for its member states to allow hunting under certain conditions, such as protecting livestock. One of the arguments behind this change was that the “tolerance of modern society towards wolves” led to the emergence of “fearless wolves” that are no longer afraid of people. “Regulators made it clear, though, that there is no scientific evidence to back this up,” says Michael Clinchy, a zoologist at Western University in London, Canada. “So we did the first-of-its-kind study to find out if wolves have really lost their fear of humans. We proved there is no such thing as a fearless wolf.” Red riding hood The big bad wolf trope is found in plenty of our myths and fables, with Little Red Riding Hood being probably the most famous example. This mythical fear of wolves, combined with real damage to livestock, led to extensive hunting. By the mid-20th century, we’d pushed wolves to the verge of extinction in Western and Central Europe. Human-wolf encounters became very rare, and the big bad wolf myth faded away. But starting in the 1970s, wolves became a protected species across Europe and North America, which caused wolf populations to bounce back and reoccupy some of their old habitats.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2206876894-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2206876894-1024x648.jpg",
      "popularity_score": 136,
      "ai_summary": [
        "European wolves show fear of humans, even with protections in place.",
        "Wolves flee human conversation faster than dogs react to barking.",
        "The study highlights the continued impact of humans on wolf behavior.",
        "The research was conducted on European wolves.",
        "The findings suggest a persistent fear of humans among wolves."
      ]
    },
    {
      "id": "cluster_97",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 16:21:12 +0000",
      "title": "Amazon’s DNS problem knocked out half the web, likely costing billions",
      "neutral_headline": "Amazon DNS Outage Caused Web Downtime, Resulting in Billions Lost",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/amazons-dns-problem-knocked-out-half-the-web-likely-costing-billions/",
          "published_at": "Tue, 21 Oct 2025 16:21:12 +0000",
          "title": "Amazon’s DNS problem knocked out half the web, likely costing billions",
          "standfirst": "Amazon’s outage is over. But backlash over billions in losses has just started.",
          "content": "On Monday afternoon, Amazon confirmed that an outage affecting Amazon Web Services’ cloud hosting, which had impacted millions across the Internet, had been resolved. Considered the worst outage since last year’s CrowdStrike chaos, Amazon’s outage caused “global turmoil,” Reuters reported. AWS is the world’s largest cloud provider and, therefore, the “backbone of much of the Internet,” ZDNet noted. Ultimately, more than 28 AWS services were disrupted, causing perhaps billions in damages, one analyst estimated for CNN. Popular apps like Snapchat, Signal, and Reddit went dark. Flights got delayed. Banks and financial services went down. Massive games like Fortnite could not be accessed. Some of Amazon’s own services were hit, too, including its e-commerce platform, Alexa, and Prime Video. Ultimately, millions of businesses simply stopped operating, unable to log employees into their systems or accept payments for their goods.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2241879469-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2241879469-1024x648.jpg",
      "popularity_score": 134.0595925,
      "ai_summary": [
        "Amazon's DNS problem caused a significant outage affecting half the web.",
        "The outage is over, but the financial repercussions are just beginning.",
        "The outage likely resulted in billions of dollars in losses for businesses.",
        "The incident highlights the critical role of Amazon's DNS services.",
        "Backlash is expected due to the widespread impact of the outage."
      ]
    },
    {
      "id": "cluster_114",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 13:11:27 +0000",
      "title": "Big Tech may fall short of green energy targets due to proposed rule changes",
      "neutral_headline": "Big Tech May Struggle to Meet Green Energy Goals",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/big-tech-may-fall-short-of-green-energy-targets-due-to-proposed-rule-changes/",
          "published_at": "Tue, 21 Oct 2025 13:11:27 +0000",
          "title": "Big Tech may fall short of green energy targets due to proposed rule changes",
          "standfirst": "Goal is to create a \"credible link\" between companies and power they invest in.",
          "content": "The world’s leading authority on carbon accounting has proposed stricter disclosure rules that are set to make it more challenging for large power users such as Amazon and Meta to hit their climate targets. The EU, California, and the International Financial Reporting Standards all draw on the voluntary Greenhouse Gas Protocol oversight body in their guidelines on how companies should disclose their carbon footprints. This week, the Protocol proposed the first update in a decade to how it measures power-sector emissions, in a move that would upend the way many tech, industrial, and utilities groups account for clean energy investments.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bigtechgreen-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bigtechgreen-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Big Tech companies may fall short of green energy targets.",
        "Proposed rule changes could hinder companies' progress.",
        "The goal is to create a \"credible link\" between companies and power.",
        "The changes could impact investments in renewable energy sources.",
        "The rules aim to ensure accountability for green energy claims."
      ]
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 22:18:22 +0000",
      "title": "NSO permanently barred from targeting WhatsApp users with Pegasus spyware",
      "neutral_headline": "NSO Barred From Targeting WhatsApp Users With Pegasus Spyware",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/nso-permanently-barred-from-targeting-whatsapp-users-with-pegasus-spyware/",
          "published_at": "Mon, 20 Oct 2025 22:18:22 +0000",
          "title": "NSO permanently barred from targeting WhatsApp users with Pegasus spyware",
          "standfirst": "Ruling holds that defeating end-to-end encryption in WhatsApp harms Meta's business.",
          "content": "A federal judge has ordered spyware maker NSO to stop using its Pegasus app to target or infect users of WhatsApp. The ruling, issued Friday by Phyllis J. Hamilton of the US District Court of the District of Northern California, grants a permanent injunction sought by WhatsApp owner Meta in a case it brought against NSO in 2019. The lawsuit alleged that Meta caught NSO trying to surreptitiously infect about 1,400 mobile phones—many belonging to attorneys, journalists, human-rights activists, political dissidents, diplomats, and senior foreign government officials—with Pegasus. As part of the campaign, NSO created fake WhatsApp accounts and targeted Meta infrastructure. The suit sought monetary awards and an injunction against the practice. Setting a precedent Friday’s ruling ordered NSO to permanently cease targeting WhatsApp users, attempting to infect their devices, or intercepting WhatsApp messages, which are end-to-end encrypted using the open source Signal Protocol. Hamilton also ruled that NSO must delete any data it obtained when targeting the WhatsApp users.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/whatsapp-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/whatsapp-1024x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "NSO is permanently barred from targeting WhatsApp users.",
        "The ruling concerns the use of Pegasus spyware.",
        "Defeating end-to-end encryption harms Meta's business.",
        "The ruling protects the privacy of WhatsApp users.",
        "The decision has implications for cybersecurity and privacy."
      ]
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 21:53:54 +0000",
      "title": "Why did NASA’s chief just shake up the agency’s plans to land on the Moon?",
      "neutral_headline": "NASA Chief Changes Moon Landing Plans",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/nasas-acting-leader-seeks-to-keep-his-job-with-new-lunar-lander-announcement/",
          "published_at": "Mon, 20 Oct 2025 21:53:54 +0000",
          "title": "Why did NASA’s chief just shake up the agency’s plans to land on the Moon?",
          "standfirst": "\"The president wants to make sure we beat the Chinese.\"",
          "content": "NASA acting Administrator Sean Duffy made two television appearances on Monday morning in which he shook up the space agency’s plans to return humans to the Moon. Speaking on Fox News, where the secretary of transportation frequently appears in his acting role as NASA chief, Duffy said SpaceX has fallen behind in its efforts to develop the Starship vehicle as a lunar lander. Duffy also indirectly acknowledged that NASA’s projected target of a 2027 crewed lunar landing is no longer achievable. Accordingly, he said he intended to expand the competition to develop a lander capable of carrying humans down to the Moon from lunar orbit and back. “They’re behind schedule, and so the President wants to make sure we beat the Chinese,” Duffy said of SpaceX. “He wants to get there in his term. So I’m in the process of opening that contract up. I think we’ll see companies like Blue [Origin] get involved, and maybe others. We’re going to have a space race in regard to American companies competing to see who can actually lead us back to the Moon first.”Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/NHQ202507310028medium-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/NHQ202507310028medium-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "NASA's chief has altered the agency's plans for Moon landings.",
        "The changes are influenced by the president's desire to compete.",
        "The goal is to beat China in the race to the Moon.",
        "The changes may affect the timeline and approach to the mission.",
        "The president's directive is a key factor in the decision."
      ]
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 20:45:26 +0000",
      "title": "Claude Code gets a web version—but it’s the new sandboxing that really matters",
      "neutral_headline": "Claude Code Gets Web Version, Sandboxing Is Significant",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/",
          "published_at": "Mon, 20 Oct 2025 20:45:26 +0000",
          "title": "Claude Code gets a web version—but it’s the new sandboxing that really matters",
          "standfirst": "Sandboxing lessens hassle, but fire-and-forget agentic tools still pose risks.",
          "content": "Anthropic has added web and mobile interfaces for Claude Code, its immensely popular command-line interface (CLI) agentic AI coding tool. The web interface appears to be well-baked at launch, but the mobile version is limited to iOS and is in an earlier stage of development. The web version of Claude Code can be given access to a GitHub repository. Once that’s done, developers can give it general marching orders like “add real-time inventory tracking to the dashboard.” As with the CLI version, it gets to work, with updates along the way approximating where it’s at and what it’s doing. The web interface supports the recently implemented Claude Code capability to take suggestions or requested changes while it’s in the middle of working on a task. (Previously, if you saw it doing something wrong or missing something, you often had to cancel and start over.)Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-3.36.24-PM.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-3.36.24-PM.png",
      "popularity_score": 133,
      "ai_summary": [
        "Claude Code now has a web version available for users.",
        "Sandboxing is a key feature of the new web version.",
        "Sandboxing reduces the hassle associated with the tool.",
        "Agentic tools still pose risks despite the new features.",
        "The new features aim to improve user experience and security."
      ]
    },
    {
      "id": "cluster_90",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 17:20:10 +0000",
      "title": "HBO Max prices increase by up to $20 today",
      "neutral_headline": "HBO Max Subscription Prices Increase",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/warner-bros-discovery-raises-hbo-max-prices-as-it-puts-itself-up-for-sale/",
          "published_at": "Tue, 21 Oct 2025 17:20:10 +0000",
          "title": "HBO Max prices increase by up to $20 today",
          "standfirst": "HBO Max subscription fees have risen every year for the past three years.",
          "content": "HBO Max subscriptions are getting up to 10 percent more expensive, owner Warner Bros. Discovery (WBD) revealed today. HBO Max’s ad plan is going from $10 per month to $11/month. The ad-free plan is going from $17/month to $18.49/month. And the premium ad-free plan (which adds 4K support, Dolby Atmos, and the ability to download more content) is increasing from $21 to $23. Meanwhile, prices for HBO Max’s annual plans are increasing from $100 to $110 with ads, $170 to $185 without ads, and $210 to $230 for the premium tier.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/02/peacemakerTOP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/02/peacemakerTOP-1152x648.jpg",
      "popularity_score": 132.04237027777776,
      "ai_summary": [
        "HBO Max subscription prices are increasing.",
        "The price increase is up to $20.",
        "This is the third consecutive year of price increases.",
        "The price changes affect the cost of subscriptions.",
        "The increases reflect changes in the streaming market."
      ]
    }
  ]
}