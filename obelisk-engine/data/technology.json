{
  "updated_at": "2026-01-26T19:23:47.383Z",
  "clusters": [
    {
      "id": "cluster_9",
      "coverage": 2,
      "updated_at": "Mon, 26 Jan 2026 13:20:01 -0500",
      "title": "Anthropic rolls out a new extension to MCP to let users interact with apps directly inside the Claude chatbot, with support for Asana, Figma, Slack, and others (Robert Hart/The Verge)",
      "neutral_headline": "MCP unites Claude chat with apps like Slack, Figma, and Canva",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260126/p32#a260126p32",
          "published_at": "Mon, 26 Jan 2026 13:20:01 -0500",
          "title": "Anthropic rolls out a new extension to MCP to let users interact with apps directly inside the Claude chatbot, with support for Asana, Figma, Slack, and others (Robert Hart/The Verge)",
          "standfirst": "Robert Hart / The Verge: Anthropic rolls out a new extension to MCP to let users interact with apps directly inside the Claude chatbot, with support for Asana, Figma, Slack, and others &mdash; &#65279;Anthropic's one step closer to having an everything app. &hellip; Anthropic's Claude got a bit livelier today thanks &hellip;",
          "content": "Robert Hart / The Verge: Anthropic rolls out a new extension to MCP to let users interact with apps directly inside the Claude chatbot, with support for Asana, Figma, Slack, and others &mdash; &#65279;Anthropic's one step closer to having an everything app. &hellip; Anthropic's Claude got a bit livelier today thanks &hellip;",
          "feed_position": 2,
          "image_url": "http://www.techmeme.com/260126/i32.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/867673/claude-mcp-app-interactive-slack-figma-canva",
          "published_at": "2026-01-26T13:00:00-05:00",
          "title": "MCP unites Claude chat with apps like Slack, Figma, and Canva",
          "standfirst": "Anthropic's Claude got a bit livelier today thanks to a new extension to MCP, the open-source protocol that allows AI agents to easily access tools and data across the internet. Users will now be able to interact with apps directly inside the Claude chatbot, letting you draft and format Slack messages to colleagues and create [&#8230;]",
          "content": "Anthropic's Claude got a bit livelier today thanks to a new extension to MCP, the open-source protocol that allows AI agents to easily access tools and data across the internet. Users will now be able to interact with apps directly inside the Claude chatbot, letting you draft and format Slack messages to colleagues and create presentations for clients in Canva without having to switch tabs. As of today, Anthropic said tools like Asana, Figma, Slack, and Canva will \"open as interactive apps right inside of chat.\" While users could previously connect tools like Slack and Asana to the AI assistant, doing so meant getting text back. The company ‚Ä¶ Read the full story at The Verge.",
          "feed_position": 2
        }
      ],
      "featured_image": "http://www.techmeme.com/260126/i32.jpg",
      "popularity_score": 2018.9371158333333
    },
    {
      "id": "cluster_12",
      "coverage": 2,
      "updated_at": "Mon, 26 Jan 2026 18:05:00 +0000",
      "title": "How to generate AI images using ChatGPT",
      "neutral_headline": "How to generate AI images using ChatGPT",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/how-to-generate-ai-images-using-chatgpt-120000560.html",
          "published_at": "Mon, 26 Jan 2026 18:05:00 +0000",
          "title": "How to generate AI images using ChatGPT",
          "standfirst": "Since March 2025, ChatGPT has been capable of generating images. Following a period where it briefly wasn't available to free users, you now don't even pay for one of OpenAI's subscriptions to use this feature. And while making images inside of ChatGPT is easy, there are some nuances worth explaining. For example, did you know you can ask ChatGPT to edit photos you've taken? It's more powerful than you might think. Here‚Äôs everything you need to know about generating AI images with ChatGPT. How to create images with ChatGPT using text prompts To begin making an image in ChatGPT, you can start by typing in the prompt bar. Igor Bonifacic for EngadgetYou can start generating images in ChatGPT simply by typing in the prompt bar what you want to see. There's no need to overthink things; as long as you have some version of \"generate an image\" followed by a description of your idea, ChatGPT will do the rest. Depending on the complexity of the prompt and whether you pay for ChatGPT, it may take a minute or two for the chatbot to complete your image request. Sometimes the process can take longer if OpenAI's servers are experiencing greater traffic than usual.At the end of last year, OpenAI updated the model powering image generation to make it faster, as well as better at rendering text and following instructions. At the same time, it added a dedicated \"Images\" section to ChatGPT's sidebar. Here you can see all the images you've made, alongside sample prompts and suggestions for styles to try out, making it a great place to start if you've never used an image generator before. How to create images with ChatGPT using existing photosYou can also upload images to ChatGPT.Igor Bonifacic for EngadgetIn addition to generating images from text prompts, ChatGPT can modify existing photos or images you upload. This is my preferred way of making images with ChatGPT; I don't need to describe the composition, I can use an existing one to guide the chatbot. To use an existing image as a starting point for a new generation, follow these steps: Tap the \"+\" icon, located to the left of the prompt bar. Select Add photos & files. Select the image you want ChatGPT to edit. If uploading an image from your phone, you'll first need to grant ChatGPT access to your camera roll. Write a prompt describing the changes you want. If generating from the Images section, tap \"Add photos\" instead.Keep in mind any photos you upload to OpenAI's servers may be used by the company to train future models. You can opt out of allowing your data to be used for training by following these steps: Open the sidebar menu. On mobile, tap the two lines on the top left of the interface; on desktop, click instead on the OpenAI logo.Tap your name to access account settings. Tap Data controls.Toggle off Improve the model for everyone. How to edit the images ChatGPT generatesChatGPT gives you a few different ways to edit images.Igor Bonifacic for EngadgetIf you're unhappy with ChatGPT's output, you have two options. You can either prompt it to create an entirely new image, or edit parts of the picture it just generated. As always, the process for both involves simply typing what you want in the prompt bar. On mobile, OpenAI gives users a few different ways of accomplishing the same task.To generate an entirely new image: Tap the three dots icon below the image ChatGPT created. Select Retry. To edit part of an existing image generation: Tap the image ChatGPT created. Tap Select area.Use your finger to mask the section of the image you want ChatGPT to tweak. The slider on the left allows you to adjust the size of the masking brush. On desktop, masking is also available if you click on an image and then click on the paintbrush icon on the top right. Describe what you want ChatGPT to add, remove or replace through the prompt bar.ChatGPT can also blend one of your photos with an image it has generated. To do this: Tap an image ChatGPT created.Tap Blend in a photo.Upload the photo you wish Like all AI systems, ChatGPT is non-deterministic, meaning even if you prompt it in the same way multiple times, it won't generate the exact same response each time. Tips to create better images with ChatGPTThe best advice I can offer is to be specific when prompting ChatGPT. The more detail you can provide when describing what you want from it, the better the results. And remember: ChatGPT can hallucinate ‚Äî as you may have noticed from one of the example pictures I included above. In the image of the tortoiseshell cat, not only is the tortie not sitting on the window sill as instructed, it's sitting on a table that doesn't make much sense. So, most of all, be patient. Prompting an AI model is not exact science, and it can take a few tries before it creates the result you want. FAQsHow do you access ChatGPT?ChatGPT is available on the web, desktop and mobile. To access it on your computer, open your preferred browser and navigate to chatgpt.com. OpenAI also offers dedicated Mac and Windows apps you can download from the company's website. On iOS and Android, you'll need to download the ChatGPT app from either the App Store or Google Play before you can start using the chatbot. Since ChatGPT runs on OpenAI's servers, as long as you can access the chatbot, you'll be able to use it to create images no matter the age of your phone or computer. Can ChatGPT generate images for free? Yes, ChatGPT can generate images for free, as long as you create an OpenAI account. However, there is a daily rate cap and GPT-5 will take longer to make a free image. Following March 27, 2025, OpenAI briefly limited free users to three image generations per day. The company has since relaxed that restriction, though it doesn't list a specific limit on its website. In my experience, you'll be able to generate about six to seven images every 24 hours.OpenAI offers three different subscription plans, each with their own set of image generation perks. ChatGPT Go, which costs $8 per month, offers \"more image creation.\" ChatGPT Plus, which costs $20 per month, offers \"expanded and faster image creation.\"ChatGPT Pro, which costs $200 per month, offers \"unlimited and faster image creation.\" Note: ChatGPT Go will be included in OpenAI's forthcoming ads pilot, which will see the company display sponsored content alongside organic responses from ChatGPT. The company does not plan to display ads to Plus and Pro users. Can ChatGPT generate an existing photo? No. For copyright reasons, ChatGPT can't replicate photos or exact real world events. For example, when I asked it to recreate the photo of Zinedine Zidane's iconic 2006 World Cup headbutt, ChatGPT refused. \"I can make an artistic reinterpretation inspired by the emotion or energy of that moment ‚Äî for example, a stylized painting showing the tension and intensity of competition, without depicting real individuals,\" it told me. This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-generate-ai-images-using-chatgpt-120000560.html?src=rss",
          "content": "Since March 2025, ChatGPT has been capable of generating images. Following a period where it briefly wasn't available to free users, you now don't even pay for one of OpenAI's subscriptions to use this feature. And while making images inside of ChatGPT is easy, there are some nuances worth explaining. For example, did you know you can ask ChatGPT to edit photos you've taken? It's more powerful than you might think. Here‚Äôs everything you need to know about generating AI images with ChatGPT. How to create images with ChatGPT using text prompts To begin making an image in ChatGPT, you can start by typing in the prompt bar. Igor Bonifacic for EngadgetYou can start generating images in ChatGPT simply by typing in the prompt bar what you want to see. There's no need to overthink things; as long as you have some version of \"generate an image\" followed by a description of your idea, ChatGPT will do the rest. Depending on the complexity of the prompt and whether you pay for ChatGPT, it may take a minute or two for the chatbot to complete your image request. Sometimes the process can take longer if OpenAI's servers are experiencing greater traffic than usual.At the end of last year, OpenAI updated the model powering image generation to make it faster, as well as better at rendering text and following instructions. At the same time, it added a dedicated \"Images\" section to ChatGPT's sidebar. Here you can see all the images you've made, alongside sample prompts and suggestions for styles to try out, making it a great place to start if you've never used an image generator before. How to create images with ChatGPT using existing photosYou can also upload images to ChatGPT.Igor Bonifacic for EngadgetIn addition to generating images from text prompts, ChatGPT can modify existing photos or images you upload. This is my preferred way of making images with ChatGPT; I don't need to describe the composition, I can use an existing one to guide the chatbot. To use an existing image as a starting point for a new generation, follow these steps: Tap the \"+\" icon, located to the left of the prompt bar. Select Add photos & files. Select the image you want ChatGPT to edit. If uploading an image from your phone, you'll first need to grant ChatGPT access to your camera roll. Write a prompt describing the changes you want. If generating from the Images section, tap \"Add photos\" instead.Keep in mind any photos you upload to OpenAI's servers may be used by the company to train future models. You can opt out of allowing your data to be used for training by following these steps: Open the sidebar menu. On mobile, tap the two lines on the top left of the interface; on desktop, click instead on the OpenAI logo.Tap your name to access account settings. Tap Data controls.Toggle off Improve the model for everyone. How to edit the images ChatGPT generatesChatGPT gives you a few different ways to edit images.Igor Bonifacic for EngadgetIf you're unhappy with ChatGPT's output, you have two options. You can either prompt it to create an entirely new image, or edit parts of the picture it just generated. As always, the process for both involves simply typing what you want in the prompt bar. On mobile, OpenAI gives users a few different ways of accomplishing the same task.To generate an entirely new image: Tap the three dots icon below the image ChatGPT created. Select Retry. To edit part of an existing image generation: Tap the image ChatGPT created. Tap Select area.Use your finger to mask the section of the image you want ChatGPT to tweak. The slider on the left allows you to adjust the size of the masking brush. On desktop, masking is also available if you click on an image and then click on the paintbrush icon on the top right. Describe what you want ChatGPT to add, remove or replace through the prompt bar.ChatGPT can also blend one of your photos with an image it has generated. To do this: Tap an image ChatGPT created.Tap Blend in a photo.Upload the photo you wish Like all AI systems, ChatGPT is non-deterministic, meaning even if you prompt it in the same way multiple times, it won't generate the exact same response each time. Tips to create better images with ChatGPTThe best advice I can offer is to be specific when prompting ChatGPT. The more detail you can provide when describing what you want from it, the better the results. And remember: ChatGPT can hallucinate ‚Äî as you may have noticed from one of the example pictures I included above. In the image of the tortoiseshell cat, not only is the tortie not sitting on the window sill as instructed, it's sitting on a table that doesn't make much sense. So, most of all, be patient. Prompting an AI model is not exact science, and it can take a few tries before it creates the result you want. FAQsHow do you access ChatGPT?ChatGPT is available on the web, desktop and mobile. To access it on your computer, open your preferred browser and navigate to chatgpt.com. OpenAI also offers dedicated Mac and Windows apps you can download from the company's website. On iOS and Android, you'll need to download the ChatGPT app from either the App Store or Google Play before you can start using the chatbot. Since ChatGPT runs on OpenAI's servers, as long as you can access the chatbot, you'll be able to use it to create images no matter the age of your phone or computer. Can ChatGPT generate images for free? Yes, ChatGPT can generate images for free, as long as you create an OpenAI account. However, there is a daily rate cap and GPT-5 will take longer to make a free image. Following March 27, 2025, OpenAI briefly limited free users to three image generations per day. The company has since relaxed that restriction, though it doesn't list a specific limit on its website. In my experience, you'll be able to generate about six to seven images every 24 hours.OpenAI offers three different subscription plans, each with their own set of image generation perks. ChatGPT Go, which costs $8 per month, offers \"more image creation.\" ChatGPT Plus, which costs $20 per month, offers \"expanded and faster image creation.\"ChatGPT Pro, which costs $200 per month, offers \"unlimited and faster image creation.\" Note: ChatGPT Go will be included in OpenAI's forthcoming ads pilot, which will see the company display sponsored content alongside organic responses from ChatGPT. The company does not plan to display ads to Plus and Pro users. Can ChatGPT generate an existing photo? No. For copyright reasons, ChatGPT can't replicate photos or exact real world events. For example, when I asked it to recreate the photo of Zinedine Zidane's iconic 2006 World Cup headbutt, ChatGPT refused. \"I can make an artistic reinterpretation inspired by the emotion or energy of that moment ‚Äî for example, a stylized painting showing the tension and intensity of competition, without depicting real individuals,\" it told me. This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-generate-ai-images-using-chatgpt-120000560.html?src=rss",
          "feed_position": 0,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/chatgpt-how-to-3.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/anthropic-embeds-slack-figma-and-asana-inside-claude-turning-ai-chat-into-a",
          "published_at": "Mon, 26 Jan 2026 18:00:00 GMT",
          "title": "Anthropic embeds Slack, Figma and Asana inside Claude, turning AI chat into a workplace command center",
          "standfirst": "Anthropic announced Monday that users can now open and interact with popular business applications directly inside Claude, the company&#x27;s AI assistant‚Äîa significant expansion that transforms the chatbot from a conversational tool into an integrated workspace where employees can build project timelines, draft Slack messages, create presentations, and visualize data without switching browser tabs.The rollout, which goes live today, includes integrations with Amplitude, Asana, Box, Canva, Clay, Figma, Hex, Monday.com, and Slack. Salesforce integration is coming soon. The feature marks a new chapter in Anthropic&#x27;s aggressive push to dominate enterprise AI, arriving just days after the company&#x27;s CEO made headlines at Davos with bold predictions about AI replacing white-collar workers.\"MCP Apps are an extension to the core MCP protocol and are part of the open source MCP ecosystem,\" Sean Strong, Anthropic&#x27;s product manager for MCP Apps, told VentureBeat in an exclusive interview. \"Within Claude.ai, connectors require a paid Claude plan ‚Äî Pro, Max, Team, or Enterprise ‚Äî but there is no additional charge associated with using connectors.\"That pricing decision is notable. Rather than monetizing integrations separately or charging partners for distribution, Anthropic is bundling interactive tools into existing subscription tiers ‚Äî a strategy designed to accelerate adoption and deepen Claude&#x27;s foothold in corporate environments where the company reportedly already leads OpenAI.Inside MCP Apps, the open-source technology that lets Claude control your favorite work toolsThe technical foundation is what Anthropic calls \"MCP Apps,\" a new extension to the Model Context Protocol, the open standard for connecting external tools to AI applications that Anthropic open-sourced last year. MCP Apps allow any MCP server to deliver an interactive user interface within any supporting AI product‚Äîmeaning the technology isn&#x27;t limited to Claude.In practice, the integrations allow for surprisingly granular control. Users can build analytics charts in Amplitude and adjust parameters interactively to explore trends. They can turn conversations into Asana projects with tasks and timelines that sync automatically. They can prompt Claude to generate flowcharts or Gantt charts in Figma&#x27;s collaborative whiteboard tool, FigJam. They can draft Slack messages, preview formatting, and review before posting.The Hex integration may prove particularly valuable for data teams: users can ask data questions in natural language and receive answers complete with interactive charts, tables, and citations ‚Äî effectively turning Claude into a business intelligence interface.\"We open sourced MCP to give the ecosystem a universal way to connect tools to AI,\" the company said in its announcement blog. \"Now we&#x27;re extending MCP further so developers can build interactive UI on top of it, wherever their users are.\"What happens when AI can send messages and create projects on your behalfWith AI systems increasingly capable of taking real-world actions ‚Äî sending messages, creating projects, publishing content ‚Äî the question of guardrails becomes critical. Can an employee accidentally send an unreviewed Slack message or publish an incomplete Canva presentation?Strong addressed this directly. \"Most major MCP clients, including Claude, provide consent prompts that help users determine if they want to take an action via a MCP server,\" he said.For enterprise deployments, IT administrators retain control. \"Team and Enterprise admins have the ability to control which MCP servers users in their organizations have the ability to use,\" Strong explained.The consent-prompt approach is a middle ground between full autonomy and cumbersome approval workflows. But it also places significant responsibility on individual users to review actions before confirming them ‚Äî a design choice that may draw scrutiny as AI agents become capable of more consequential decisions.The security concerns are not hypothetical. As Fortune reported last week, Anthropic&#x27;s Claude Code product faces vulnerabilities including \"prompt injections,\" where attackers hide malicious instructions in web content to manipulate AI behavior. The company has implemented multiple security layers, including running some features in virtual machines and adding deletion protection after users accidentally removed files. \"Agent safety‚Äîthat is, the task of securing Claude&#x27;s real-world actions‚Äîis still an active area of development in the industry,\" Anthropic has acknowledged.Claude Code&#x27;s viral success set the stage for Anthropic&#x27;s enterprise ambitionsThe interactive tools announcement arrives at a moment of unusual momentum for Anthropic. Claude Code, the company&#x27;s coding assistant released in February 2024, has become a viral hit that has captured attention far beyond its intended developer audience.Originally built for software developers, Claude Code has captured attention far beyond its intended audience. Non-programmers have deployed it to book theater tickets, file taxes, and monitor tomato plants. Nvidia CEO Jensen Huang called it \"incredible.\" Even Microsoft, which sells the competing GitHub Copilot, has widely adopted Claude Code internally, with non-developers reportedly encouraged to use it.Boris Cherny, Anthropic&#x27;s head of Claude Code, told Fortune that his team built Cowork ‚Äî a user-friendly version of the coding product for non-programmers ‚Äî in approximately a week and a half, largely using Claude Code itself. \"Engineers just feel unshackled, that they don&#x27;t have to work on all the tedious stuff anymore,\" Cherny said.Claude Code is now used by Uber, Netflix, Spotify, Salesforce, Accenture, and Snowflake, according to Anthropic. Claude&#x27;s total web audience has more than doubled since December 2024, and daily unique visitors on desktop are up 12% globally year-to-date, according to data from Similarweb and Sensor Tower published by The Wall Street Journal.The company is also reportedly planning a $10 billion fundraising round that would value Anthropic at $350 billion ‚Äî a staggering figure that reflects investor confidence in the company&#x27;s enterprise traction.Anthropic&#x27;s CEO stirred controversy at Davos with predictions about AI replacing workersThe interactive tools launch also arrives against a backdrop of intense debate about AI&#x27;s impact on employment ‚Äî a debate that Anthropic&#x27;s own CEO helped intensify at the World Economic Forum in Davos last week.Dario Amodei told a Davos audience that AI models would replace the work of all software developers within a year and would reach \"Nobel-level\" scientific research in multiple fields within two years. He predicted that 50% of white-collar jobs would disappear within five years.\"I have engineers within Anthropic who say &#x27;I don&#x27;t write any code anymore. I just let the model write the code, I edit it,&#x27;\" Amodei said. \"We might be six to 12 months away from when the model is doing most, maybe all of what software engineers do end-to-end.\"Not everyone agrees with that timeline. Demis Hassabis, the Nobel Prize-winning CEO of Google DeepMind, said at the same conference that today&#x27;s AI systems are \"nowhere near\" human-level artificial general intelligence. Yann LeCun, the Turing Award-winning AI pioneer who recently left Meta to found Advanced Machine Intelligence Labs, went further, arguing that large language models \"will never be able to achieve humanlike intelligence\" and that a completely different approach is needed.Why embedding AI into daily workflows could create powerful lock-in for enterprisesAnthropic&#x27;s integration strategy reflects a broader shift in enterprise AI competition. The battleground is moving from model benchmarks and capability demonstrations toward workflow integration ‚Äî the degree to which AI systems become embedded in how companies actually operate.By making Claude the interface through which employees interact with Asana, Slack, Figma, and other daily tools, Anthropic is positioning itself not merely as an AI provider but as a workflow orchestration layer. The more actions that flow through Claude, the harder it becomes for enterprises to switch to a competitor.This approach mirrors strategies that proved successful for earlier generations of enterprise software. Salesforce built its dominance partly by becoming the system of record for customer data. Slack grew by centralizing workplace communication. Anthropic appears to be betting that AI assistants can occupy a similar position ‚Äî the default starting point for work itself.The open-source foundation of MCP may accelerate this strategy. By making the protocol available to any developer, Anthropic encourages a broad ecosystem of integrations that all funnel through MCP-compatible clients ‚Äî of which Claude is the most prominent. The company benefits from network effects even as it maintains the standard is open.The race to become the operating system for AI-powered work is just getting startedThe launch notably excludes some major enterprise platforms. Salesforce integration is listed as \"coming soon,\" and there&#x27;s no mention of Microsoft 365, Google Workspace, or other productivity suites that dominate corporate environments. Those gaps may limit initial adoption in organizations heavily invested in those ecosystems.The feature is available on web and desktop for paid Claude plans, with support for Claude Cowork ‚Äî the file management agent launched last week ‚Äî coming later. Mobile support was not mentioned in the announcement.For enterprises evaluating Claude against OpenAI&#x27;s offerings and other competitors, the interactive integrations represent a tangible differentiator. The ability to take action within business tools ‚Äî rather than simply generating text that users must copy elsewhere ‚Äî addresses a persistent friction point in AI adoption.Whether that advantage proves durable depends on how quickly competitors respond. OpenAI has its own enterprise ambitions and partnerships. Google is integrating Gemini across its productivity suite. Microsoft continues to deepen Copilot&#x27;s presence in Office applications.But the larger significance may be what today&#x27;s announcement signals about where enterprise software is headed. For decades, the default unit of work has been the application ‚Äî the spreadsheet, the project tracker, the messaging platform. Anthropic is wagering that the future belongs to the AI layer that sits above them all.If the company is right, the question for every enterprise software vendor becomes uncomfortably simple: Do you want to be the tool, or the thing that controls the tools?",
          "content": "Anthropic announced Monday that users can now open and interact with popular business applications directly inside Claude, the company&#x27;s AI assistant‚Äîa significant expansion that transforms the chatbot from a conversational tool into an integrated workspace where employees can build project timelines, draft Slack messages, create presentations, and visualize data without switching browser tabs.The rollout, which goes live today, includes integrations with Amplitude, Asana, Box, Canva, Clay, Figma, Hex, Monday.com, and Slack. Salesforce integration is coming soon. The feature marks a new chapter in Anthropic&#x27;s aggressive push to dominate enterprise AI, arriving just days after the company&#x27;s CEO made headlines at Davos with bold predictions about AI replacing white-collar workers.\"MCP Apps are an extension to the core MCP protocol and are part of the open source MCP ecosystem,\" Sean Strong, Anthropic&#x27;s product manager for MCP Apps, told VentureBeat in an exclusive interview. \"Within Claude.ai, connectors require a paid Claude plan ‚Äî Pro, Max, Team, or Enterprise ‚Äî but there is no additional charge associated with using connectors.\"That pricing decision is notable. Rather than monetizing integrations separately or charging partners for distribution, Anthropic is bundling interactive tools into existing subscription tiers ‚Äî a strategy designed to accelerate adoption and deepen Claude&#x27;s foothold in corporate environments where the company reportedly already leads OpenAI.Inside MCP Apps, the open-source technology that lets Claude control your favorite work toolsThe technical foundation is what Anthropic calls \"MCP Apps,\" a new extension to the Model Context Protocol, the open standard for connecting external tools to AI applications that Anthropic open-sourced last year. MCP Apps allow any MCP server to deliver an interactive user interface within any supporting AI product‚Äîmeaning the technology isn&#x27;t limited to Claude.In practice, the integrations allow for surprisingly granular control. Users can build analytics charts in Amplitude and adjust parameters interactively to explore trends. They can turn conversations into Asana projects with tasks and timelines that sync automatically. They can prompt Claude to generate flowcharts or Gantt charts in Figma&#x27;s collaborative whiteboard tool, FigJam. They can draft Slack messages, preview formatting, and review before posting.The Hex integration may prove particularly valuable for data teams: users can ask data questions in natural language and receive answers complete with interactive charts, tables, and citations ‚Äî effectively turning Claude into a business intelligence interface.\"We open sourced MCP to give the ecosystem a universal way to connect tools to AI,\" the company said in its announcement blog. \"Now we&#x27;re extending MCP further so developers can build interactive UI on top of it, wherever their users are.\"What happens when AI can send messages and create projects on your behalfWith AI systems increasingly capable of taking real-world actions ‚Äî sending messages, creating projects, publishing content ‚Äî the question of guardrails becomes critical. Can an employee accidentally send an unreviewed Slack message or publish an incomplete Canva presentation?Strong addressed this directly. \"Most major MCP clients, including Claude, provide consent prompts that help users determine if they want to take an action via a MCP server,\" he said.For enterprise deployments, IT administrators retain control. \"Team and Enterprise admins have the ability to control which MCP servers users in their organizations have the ability to use,\" Strong explained.The consent-prompt approach is a middle ground between full autonomy and cumbersome approval workflows. But it also places significant responsibility on individual users to review actions before confirming them ‚Äî a design choice that may draw scrutiny as AI agents become capable of more consequential decisions.The security concerns are not hypothetical. As Fortune reported last week, Anthropic&#x27;s Claude Code product faces vulnerabilities including \"prompt injections,\" where attackers hide malicious instructions in web content to manipulate AI behavior. The company has implemented multiple security layers, including running some features in virtual machines and adding deletion protection after users accidentally removed files. \"Agent safety‚Äîthat is, the task of securing Claude&#x27;s real-world actions‚Äîis still an active area of development in the industry,\" Anthropic has acknowledged.Claude Code&#x27;s viral success set the stage for Anthropic&#x27;s enterprise ambitionsThe interactive tools announcement arrives at a moment of unusual momentum for Anthropic. Claude Code, the company&#x27;s coding assistant released in February 2024, has become a viral hit that has captured attention far beyond its intended developer audience.Originally built for software developers, Claude Code has captured attention far beyond its intended audience. Non-programmers have deployed it to book theater tickets, file taxes, and monitor tomato plants. Nvidia CEO Jensen Huang called it \"incredible.\" Even Microsoft, which sells the competing GitHub Copilot, has widely adopted Claude Code internally, with non-developers reportedly encouraged to use it.Boris Cherny, Anthropic&#x27;s head of Claude Code, told Fortune that his team built Cowork ‚Äî a user-friendly version of the coding product for non-programmers ‚Äî in approximately a week and a half, largely using Claude Code itself. \"Engineers just feel unshackled, that they don&#x27;t have to work on all the tedious stuff anymore,\" Cherny said.Claude Code is now used by Uber, Netflix, Spotify, Salesforce, Accenture, and Snowflake, according to Anthropic. Claude&#x27;s total web audience has more than doubled since December 2024, and daily unique visitors on desktop are up 12% globally year-to-date, according to data from Similarweb and Sensor Tower published by The Wall Street Journal.The company is also reportedly planning a $10 billion fundraising round that would value Anthropic at $350 billion ‚Äî a staggering figure that reflects investor confidence in the company&#x27;s enterprise traction.Anthropic&#x27;s CEO stirred controversy at Davos with predictions about AI replacing workersThe interactive tools launch also arrives against a backdrop of intense debate about AI&#x27;s impact on employment ‚Äî a debate that Anthropic&#x27;s own CEO helped intensify at the World Economic Forum in Davos last week.Dario Amodei told a Davos audience that AI models would replace the work of all software developers within a year and would reach \"Nobel-level\" scientific research in multiple fields within two years. He predicted that 50% of white-collar jobs would disappear within five years.\"I have engineers within Anthropic who say &#x27;I don&#x27;t write any code anymore. I just let the model write the code, I edit it,&#x27;\" Amodei said. \"We might be six to 12 months away from when the model is doing most, maybe all of what software engineers do end-to-end.\"Not everyone agrees with that timeline. Demis Hassabis, the Nobel Prize-winning CEO of Google DeepMind, said at the same conference that today&#x27;s AI systems are \"nowhere near\" human-level artificial general intelligence. Yann LeCun, the Turing Award-winning AI pioneer who recently left Meta to found Advanced Machine Intelligence Labs, went further, arguing that large language models \"will never be able to achieve humanlike intelligence\" and that a completely different approach is needed.Why embedding AI into daily workflows could create powerful lock-in for enterprisesAnthropic&#x27;s integration strategy reflects a broader shift in enterprise AI competition. The battleground is moving from model benchmarks and capability demonstrations toward workflow integration ‚Äî the degree to which AI systems become embedded in how companies actually operate.By making Claude the interface through which employees interact with Asana, Slack, Figma, and other daily tools, Anthropic is positioning itself not merely as an AI provider but as a workflow orchestration layer. The more actions that flow through Claude, the harder it becomes for enterprises to switch to a competitor.This approach mirrors strategies that proved successful for earlier generations of enterprise software. Salesforce built its dominance partly by becoming the system of record for customer data. Slack grew by centralizing workplace communication. Anthropic appears to be betting that AI assistants can occupy a similar position ‚Äî the default starting point for work itself.The open-source foundation of MCP may accelerate this strategy. By making the protocol available to any developer, Anthropic encourages a broad ecosystem of integrations that all funnel through MCP-compatible clients ‚Äî of which Claude is the most prominent. The company benefits from network effects even as it maintains the standard is open.The race to become the operating system for AI-powered work is just getting startedThe launch notably excludes some major enterprise platforms. Salesforce integration is listed as \"coming soon,\" and there&#x27;s no mention of Microsoft 365, Google Workspace, or other productivity suites that dominate corporate environments. Those gaps may limit initial adoption in organizations heavily invested in those ecosystems.The feature is available on web and desktop for paid Claude plans, with support for Claude Cowork ‚Äî the file management agent launched last week ‚Äî coming later. Mobile support was not mentioned in the announcement.For enterprises evaluating Claude against OpenAI&#x27;s offerings and other competitors, the interactive integrations represent a tangible differentiator. The ability to take action within business tools ‚Äî rather than simply generating text that users must copy elsewhere ‚Äî addresses a persistent friction point in AI adoption.Whether that advantage proves durable depends on how quickly competitors respond. OpenAI has its own enterprise ambitions and partnerships. Google is integrating Gemini across its productivity suite. Microsoft continues to deepen Copilot&#x27;s presence in Office applications.But the larger significance may be what today&#x27;s announcement signals about where enterprise software is headed. For decades, the default unit of work has been the application ‚Äî the spreadsheet, the project tracker, the messaging platform. Anthropic is wagering that the future belongs to the AI layer that sits above them all.If the company is right, the question for every enterprise software vendor becomes uncomfortably simple: Do you want to be the tool, or the thing that controls the tools?",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1p8ftZpSuS4Melgo35eWGo/c8a0c84c233a5c28bf4e49321e2602e0/nuneybits_Vector_art_of_a_glowing_burnt_orange_orb_at_center_wi_838c3333-89a8-4df4-b2bd-8d6a829836b2.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/trump-admin-reportedly-plans-to-use-ai-to-write-federal-regulations-175155111.html",
          "published_at": "Mon, 26 Jan 2026 17:51:56 +0000",
          "title": "Trump admin reportedly plans to use AI to write federal regulations",
          "standfirst": "The Trump administration is planning on using Google Gemini to draft important federal regulations, as reported by ProPublica. This is starting with the Department of Transportation, according to interviews with agency staffers. Regulations created by the DOT help keep us safe when traveling. The plan was initially presented to DOT staffers last month, with agency attorney Daniel Cohen writing to colleagues about AI's \"potential to revolutionize the way we draft rulemakings.\" Gregory Zerzan, the agency's general counsel, has indicated that President Donald Trump is \"very excited by this initiative\" and that DOT will be \"the first agency that is fully enabled to use AI to draft rules.\" This does suggest a pilot program of sorts, with eventual plans to bring AI to other departments. NEW: The Trump administration is planning to use AI to write federal regulations despite the risk of hallucinations.‚ÄúWe don't even need a very good rule,‚Äù @USDOT‚Äôs top lawyer said of the plan, per meeting notes reviewed by ProPublica. ‚ÄúWe want good enough.‚Äù üßµ pic.twitter.com/YKGvmlkMCt‚Äî Jesse Coburn (@Jesse_Coburn) January 26, 2026 Oddly, Zerzan doesn't seem that interested in high-quality regulations. ProPublica received transcripts of a meeting in which he declared that \"we don't need the perfect rule on XYZ. We don't even need a very good rule on XYZ.\" He went on to say that \"we want good enough\" and that \"we're flooding the zone.\" Let me remind you that DOT regulates the safety standards of commercial aircraft, along with rules involving the transport of hazardous materials and driver qualifications. The agency's rules touch on every aspect of transportation safety. Why would the federal government rely on a new technology that's notorious for making mistakes? AI ‚Äúhallucinations‚Äù eg false/made-up info now becoming a problem in scientific publications. Kudos to @alexcdot et al on building an AI hallucination detector and finding that certain journals/authors have used LLMs to generate papers that also made it through peer review. Here‚Äôs‚Ä¶ pic.twitter.com/i4Be1lS8xq‚Äî Daphne Zohar (@daphnezohar) January 22, 2026 The answer is speed. Writing and revising complex federal regulations can take months, but Google Gemini can spit something out in minutes. A DOT employee giving a presentation on the program suggested that many parts of these regulations are just \"word salad\" anyways, so AI should be able to do just fine. \"It shouldn‚Äôt take you more than 20 minutes to get a draft rule out of Gemini,\" Zerzan said. The plan is to compress the timeline in which transportation regulations are written and reviewed. The department has already used AI to draft an unpublished Federal Aviation Administration rule. Federal agencies have used AI for years, but not to actually write regulations. It's primarily been used for the purpose of translating documents, analyzing data and categorizing public comments. Trump, however, is a huge proponent of the technology. He has released multiple executive orders in support of AI and once shared an AI-created video in which he flew a fighter jet and dropped what appears to be feces on American citizens. Skeptics say that large language models like Gemini shouldn't be in charge of drafting complicated and consequential regulations that impact millions of everyday Americans. Mistakes could lead to lawsuits and even injuries and deaths. Mike Horton, DOT‚Äôs former acting chief artificial intelligence officer, said using Gemini to draft regulations was like ‚Äúhaving a high school intern that‚Äôs doing your rulemaking.‚Äù He also said that agency leaders under Trump \"want to go fast and break things, but going fast and breaking things means people are going to get hurt.\" \"Just because these tools can produce a lot of words doesn‚Äôt mean that those words add up to a high-quality government decision,‚Äù said Bridget Dooling, a professor at Ohio State University who studies administrative law. ‚ÄúIt‚Äôs so tempting to try to figure out how to use these tools, and I think it would make sense to try. But I think it should be done with a lot of skepticism.\" DOT has experienced a net loss of more than 4,000 employees since Trump started his second term. This includes over 100 attorneys.This article originally appeared on Engadget at https://www.engadget.com/ai/trump-admin-reportedly-plans-to-use-ai-to-write-federal-regulations-175155111.html?src=rss",
          "content": "The Trump administration is planning on using Google Gemini to draft important federal regulations, as reported by ProPublica. This is starting with the Department of Transportation, according to interviews with agency staffers. Regulations created by the DOT help keep us safe when traveling. The plan was initially presented to DOT staffers last month, with agency attorney Daniel Cohen writing to colleagues about AI's \"potential to revolutionize the way we draft rulemakings.\" Gregory Zerzan, the agency's general counsel, has indicated that President Donald Trump is \"very excited by this initiative\" and that DOT will be \"the first agency that is fully enabled to use AI to draft rules.\" This does suggest a pilot program of sorts, with eventual plans to bring AI to other departments. NEW: The Trump administration is planning to use AI to write federal regulations despite the risk of hallucinations.‚ÄúWe don't even need a very good rule,‚Äù @USDOT‚Äôs top lawyer said of the plan, per meeting notes reviewed by ProPublica. ‚ÄúWe want good enough.‚Äù üßµ pic.twitter.com/YKGvmlkMCt‚Äî Jesse Coburn (@Jesse_Coburn) January 26, 2026 Oddly, Zerzan doesn't seem that interested in high-quality regulations. ProPublica received transcripts of a meeting in which he declared that \"we don't need the perfect rule on XYZ. We don't even need a very good rule on XYZ.\" He went on to say that \"we want good enough\" and that \"we're flooding the zone.\" Let me remind you that DOT regulates the safety standards of commercial aircraft, along with rules involving the transport of hazardous materials and driver qualifications. The agency's rules touch on every aspect of transportation safety. Why would the federal government rely on a new technology that's notorious for making mistakes? AI ‚Äúhallucinations‚Äù eg false/made-up info now becoming a problem in scientific publications. Kudos to @alexcdot et al on building an AI hallucination detector and finding that certain journals/authors have used LLMs to generate papers that also made it through peer review. Here‚Äôs‚Ä¶ pic.twitter.com/i4Be1lS8xq‚Äî Daphne Zohar (@daphnezohar) January 22, 2026 The answer is speed. Writing and revising complex federal regulations can take months, but Google Gemini can spit something out in minutes. A DOT employee giving a presentation on the program suggested that many parts of these regulations are just \"word salad\" anyways, so AI should be able to do just fine. \"It shouldn‚Äôt take you more than 20 minutes to get a draft rule out of Gemini,\" Zerzan said. The plan is to compress the timeline in which transportation regulations are written and reviewed. The department has already used AI to draft an unpublished Federal Aviation Administration rule. Federal agencies have used AI for years, but not to actually write regulations. It's primarily been used for the purpose of translating documents, analyzing data and categorizing public comments. Trump, however, is a huge proponent of the technology. He has released multiple executive orders in support of AI and once shared an AI-created video in which he flew a fighter jet and dropped what appears to be feces on American citizens. Skeptics say that large language models like Gemini shouldn't be in charge of drafting complicated and consequential regulations that impact millions of everyday Americans. Mistakes could lead to lawsuits and even injuries and deaths. Mike Horton, DOT‚Äôs former acting chief artificial intelligence officer, said using Gemini to draft regulations was like ‚Äúhaving a high school intern that‚Äôs doing your rulemaking.‚Äù He also said that agency leaders under Trump \"want to go fast and break things, but going fast and breaking things means people are going to get hurt.\" \"Just because these tools can produce a lot of words doesn‚Äôt mean that those words add up to a high-quality government decision,‚Äù said Bridget Dooling, a professor at Ohio State University who studies administrative law. ‚ÄúIt‚Äôs so tempting to try to figure out how to use these tools, and I think it would make sense to try. But I think it should be done with a lot of skepticism.\" DOT has experienced a net loss of more than 4,000 employees since Trump started his second term. This includes over 100 attorneys.This article originally appeared on Engadget at https://www.engadget.com/ai/trump-admin-reportedly-plans-to-use-ai-to-write-federal-regulations-175155111.html?src=rss",
          "feed_position": 2
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/browser-security-gap-ciso-enterprise-breaches",
          "published_at": "Mon, 26 Jan 2026 17:00:00 GMT",
          "title": "Browser-based attacks hit 95% of enterprises ‚Äî and traditional security tools never saw them coming",
          "standfirst": "Your web gateway can&#x27;t see it. Your cloud access broker can&#x27;t see it. Your endpoint protection can&#x27;t see it. And yet 95% of organizations experienced browser-based attacks last year, according to Omdia research conducted across more than 1,000 IT and security leaders.Still, three campaigns in 12 months are making the threat more concrete. ShadyPanda infected 4.3 million users through extensions that had been legitimate for seven years. Cyberhaven&#x27;s security extension was weaponized against 400,000 corporate customers on Christmas Eve. Trust Wallet lost $8.5 million from 2,520 wallets in 48 hours. None triggered traditional alerts.The pattern is consistent: Attackers aren‚Äôt exploiting zero-days or bypassing perimeter defenses. They‚Äôre operating inside trusted browser sessions ‚Äî where traditional security tools lose visibility after login.\"Let&#x27;s be honest, people are using a browser the majority of their day anyway,\" said Sam Evans, CISO of Clearwater Analytics. \"Having the major security component in the browser has made our lives very simple.\" That convenience is exactly what makes the browser the highest-risk execution environment enterprises still treat as infrastructure, not attack surface.VentureBeat recently spoke with Elia Zaitsev, CTO of CrowdStrike, about what&#x27;s driving these attacks. \"The browser has become a prime target because modern adversaries don&#x27;t break in, they log in,\" he said. He added that as work, communication, and AI usage move into the browser, attackers increasingly operate inside trusted sessions, abusing valid identities, tokens, and access. Traditional security controls were never designed to stop this kind of activity because they assume \"trust-once\" access is granted and lack visibility into what happens inside live browser sessions.What traditional security architectures missTraditional enterprise security stacks were built to inspect traffic before authentication, not behavior after access is granted. Interviews with CISOs already running browser-layer controls reveal six operational patterns that consistently reduce exposure ‚Äî assuming identity and endpoint foundations are in place.The Omdia research quantifies the gap: 64% of encrypted traffic goes uninspected, and 65% of organizations lack control over data shared in AI tools, according to the study. LayerX&#x27;s Enterprise Browser Extension Security Report 2025 found that 99% of enterprise users have at least one browser extension, 53% with high or critical permissions granting access to cookies, passwords, and page content. Another 17% come from non-official stores, and 26% were sideloaded without IT knowing.\"Traditional endpoint detection products were using some machine learning, and they would get to a probability of maybe 85%,\" Evans told VentureBeat. \"This could be a threat, but we&#x27;re not really sure. How do we take action? Should I pull the fire alarm?\"\"At the end of the day, it&#x27;s the device the person uses day in and day out that carries the highest risk,\" he said.\"For a long time, the browser was treated as a window, not an execution layer,\" Zaitsev said. \"It was designed for searches and static web access, not for running core business applications or autonomous AI workflows. That&#x27;s changed dramatically. Today, SaaS applications, cloud identities, AI tools, and agentic workflows all run through the browser, making it the first line of enterprise execution and defense.\"Browser isolation from Menlo Security, Cloudflare, and Symantec addresses rendering threats by executing web content in remote containers. But thousands of extensions now run locally with privileged access, GenAI tools create new exfiltration paths, and session-based attacks hijack authenticated tokens. Isolation protects users before authentication ‚Äî not after attackers inherit valid sessions, tokens, and extension privileges.Three attack patterns worth understandingTrust can be accumulated over years ‚Äî then weaponized overnight.The long game. ShadyPanda submitted clean extensions to Chrome and Edge stores in 2018, accumulated Google&#x27;s \"Featured\" and \"Verified\" badges, then weaponized them seven years later. Clean Master became a remote code execution backdoor running hourly JavaScript downloads ‚Äî not malware with a fixed function, but a backdoor letting attackers decide what comes next.The credential hijack. Browser auto-updates function as a software supply chain ‚Äî and inherit its risks. Cyberhaven attackers phished one developer&#x27;s credentials in 2024. The Chrome Web Store approved the malicious upload. Within 48 hours, 400,000 corporate customers had auto-updated to compromised code.The API key leak. Control planes are attack surfaces, not internal safeguards. Trust Wallet attackers used a leaked Chrome Web Store API key to push malicious updates, bypassing all internal release controls. Around $8.5 million had been drained from wallets by attackers within a couple days. No phishing required. No zero-days. Just the auto-update mechanism doing what it was designed to do.Why detection fails when attackers have valid credentials\"Nation-state actors typically exploit browser access for long-term, covert intelligence collection, while financially motivated e-crime groups prioritize speed, using browser-based attacks to harvest credentials, session tokens, and sensitive data for rapid monetization or resale,\" Zaitsev said. \"Despite different objectives, both rely on the same browser-layer blind spot to operate inside trusted sessions and bypass traditional detection.\"Session hijacking illustrates why this matters. The most important signals are behavioral and contextual, not credentials themselves. That includes how a user interacts with the browser in real-time, whether actions align with expected behavior, how data is being accessed or moved, and whether the session context suddenly changes in ways that indicate abuse.Once attackers capture a valid token, they replay it from anywhere. Authentication already happened, and MFA already passed. Zaitsev argues that detecting session hijacking early requires correlating in-session browser behavior with identity posture, endpoint signals, and threat intelligence. When those signals are unified, distinguishing a legitimate user from a hijacker becomes possible. That&#x27;s something siloed enterprise browsers and legacy security tools can&#x27;t see.When productivity tools become exfiltration pathsGenAI traffic surged 890% in 2024, with organizations now averaging 66 GenAI applications, according to Palo Alto Networks&#x27; State of Generative AI 2025 report. GenAI-related data loss incidents more than doubled, accounting for 14% of all data security incidents.Evans remembers the board conversation that started it all. \"In October 2023, they asked, &#x27;What are your thoughts on ChatGPT?&#x27; I said it&#x27;s an incredible productivity tool, however, I don&#x27;t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it or our source code.\"Legitimate GenAI use and data exfiltration look identical at the network level. Both are encrypted browser sessions sending data to approved SaaS endpoints, often involving copy-and-paste into browser-based tools. The distinction only becomes clear at the browser layer, where you can see what data is being pasted, whether the destination is approved, and whether the behavior matches normal work patterns.Evans found a balance. \"If somebody goes to chatgpt.com, we allow them to use it. They just can&#x27;t copy and paste anything into it. They can&#x27;t upload any files, but they can ask questions and compare answers with our corporate version.\" Employees get AI for research without risking customer data in model training.\"It seems like there&#x27;s a new one every five minutes,\" Evans said. \"Browser-layer controls maintain those categories, so if a new tool shows up, we can feel pretty good that employees won&#x27;t be able to copy and paste or upload our data.\"The billion-dollar browser betCrowdStrike acquired Seraphic Security and SGNL for a combined $1.16 billion in January 2026, signaling how seriously vendors are betting on the browser layer. Palo Alto Networks bought Talon in 2023. Two camps are emerging. Island wants enterprises to replace Chrome and Edge entirely with a purpose-built browser, and has reached a $4.8 billion valuation (March, 2025). Menlo Security bets most enterprises won&#x27;t switch browsers, so it layers protection on top of whatever employees already use. The tradeoff is real. Replacement browsers offer deeper control but require adoption. Security layers preserve user choice but see less. Both are winning deals.Zaitsev says neither approach works without tying browser activity to identity. Authentication tells you who logged in. It doesn&#x27;t tell you if that session gets hijacked 10 minutes later, or if the user starts exfiltrating data to an unauthorized GenAI tool. Catching that requires correlating browser behavior with endpoint and identity signals in real time ‚Äî something most enterprises can&#x27;t do yet.For buyers, the decision isn‚Äôt about vendors ‚Äî it‚Äôs about whether browser activity is tied into identity, endpoint, and SOC workflows, or left as a standalone control plane.Six patterns from productionSecuring the browser that employees actually use matters more than which enterprise browser to deploy. Today&#x27;s workforce moves across multiple browsers and managed and unmanaged devices. What matters is visibility and control inside live sessions without breaking how people work.Evans put it more simply: \"I wanted security closer to the end user, on the device they use every day. Having security in the browser made our lives simple. Road warriors dealing with hotel captive portals that normally get blocked by edge products? We don&#x27;t worry about that anymore.\"Based on interviews with CISOs running browser-layer controls in production, six patterns keep showing up. One caveat: These assume you already have mature identity and endpoint infrastructure. If you don&#x27;t, start there.Build a complete extension inventory. Use browser management APIs to enumerate every extension, flag anything requesting sensitive permissions, and cross-reference against known-malicious hashes.Break the auto-update kill chain. Fast patching reduces exposure to known vulnerabilities but creates supply chain risk. Implement version pinning with 48- to 72-hour delays. The Cyberhaven attack was detected in roughly 25 hours. A staged rollout would have contained it.Move data protection to where data moves. \"DLP is where we got the biggest win,\" Evans said. \"Customer data exfiltration can happen through social media, personal file shares, and web-based email. Being able to block copy-paste into certain site categories, block file uploads was incredibly powerful.\"Eliminate browser sprawl. \"It does no good to deploy an enterprise browser when someone can download Opera, or Frank&#x27;s browser of the month, and bypass all the controls,\" Evans said. Every unmanaged browser is a policy-free zone.Extend identity into sessions, treat GenAI as unvetted, feed signals to the SOC. Session hijackers inherit valid credentials but not normal behavior patterns. Watch for impossible travel, permission escalation, and bulk access anomalies. Evans found that browser-layer blocking surfaced shadow AI tools employees actually wanted, which IT could then enable properly. And browser telemetry should flow into existing SOC workflows. \"The AI does initial triage,\" Evans said, \"telling analysts where to look based on what we&#x27;ve seen before.\"Show the board a working demo. \"I didn&#x27;t just come with concerns,\" Evans said. \"I came with a solution. When I explained how enterprise browsers work, the board said, &#x27;Can you really do it?&#x27; At our July 2024 audit committee, they asked how it was going. I said, &#x27;Let me show you.&#x27; Pulled up a screenshot ‚Äî here I am on ChatGPT, tried to paste something, got: &#x27;Policy prevents this.&#x27; They said, &#x27;Wow.&#x27; That calmed their nerves.\"The bottom lineThe browser security gap is real. The fix isn&#x27;t necessarily a new platform purchase. Start by assessing what you have: inventory extensions, delay auto-updates, and enforce data policies at the browser layer with existing tools.\"No security tool is 100% perfect,\" Evans said. \"But with browser-layer controls deployed, we sleep a lot easier.\"Breach rates won‚Äôt improve by stacking more perimeter tools onto architectures that assume trust ends at login. Outcomes improve when you treat the browser as what it&#x27;s become: the primary execution environment for enterprise work.",
          "content": "Your web gateway can&#x27;t see it. Your cloud access broker can&#x27;t see it. Your endpoint protection can&#x27;t see it. And yet 95% of organizations experienced browser-based attacks last year, according to Omdia research conducted across more than 1,000 IT and security leaders.Still, three campaigns in 12 months are making the threat more concrete. ShadyPanda infected 4.3 million users through extensions that had been legitimate for seven years. Cyberhaven&#x27;s security extension was weaponized against 400,000 corporate customers on Christmas Eve. Trust Wallet lost $8.5 million from 2,520 wallets in 48 hours. None triggered traditional alerts.The pattern is consistent: Attackers aren‚Äôt exploiting zero-days or bypassing perimeter defenses. They‚Äôre operating inside trusted browser sessions ‚Äî where traditional security tools lose visibility after login.\"Let&#x27;s be honest, people are using a browser the majority of their day anyway,\" said Sam Evans, CISO of Clearwater Analytics. \"Having the major security component in the browser has made our lives very simple.\" That convenience is exactly what makes the browser the highest-risk execution environment enterprises still treat as infrastructure, not attack surface.VentureBeat recently spoke with Elia Zaitsev, CTO of CrowdStrike, about what&#x27;s driving these attacks. \"The browser has become a prime target because modern adversaries don&#x27;t break in, they log in,\" he said. He added that as work, communication, and AI usage move into the browser, attackers increasingly operate inside trusted sessions, abusing valid identities, tokens, and access. Traditional security controls were never designed to stop this kind of activity because they assume \"trust-once\" access is granted and lack visibility into what happens inside live browser sessions.What traditional security architectures missTraditional enterprise security stacks were built to inspect traffic before authentication, not behavior after access is granted. Interviews with CISOs already running browser-layer controls reveal six operational patterns that consistently reduce exposure ‚Äî assuming identity and endpoint foundations are in place.The Omdia research quantifies the gap: 64% of encrypted traffic goes uninspected, and 65% of organizations lack control over data shared in AI tools, according to the study. LayerX&#x27;s Enterprise Browser Extension Security Report 2025 found that 99% of enterprise users have at least one browser extension, 53% with high or critical permissions granting access to cookies, passwords, and page content. Another 17% come from non-official stores, and 26% were sideloaded without IT knowing.\"Traditional endpoint detection products were using some machine learning, and they would get to a probability of maybe 85%,\" Evans told VentureBeat. \"This could be a threat, but we&#x27;re not really sure. How do we take action? Should I pull the fire alarm?\"\"At the end of the day, it&#x27;s the device the person uses day in and day out that carries the highest risk,\" he said.\"For a long time, the browser was treated as a window, not an execution layer,\" Zaitsev said. \"It was designed for searches and static web access, not for running core business applications or autonomous AI workflows. That&#x27;s changed dramatically. Today, SaaS applications, cloud identities, AI tools, and agentic workflows all run through the browser, making it the first line of enterprise execution and defense.\"Browser isolation from Menlo Security, Cloudflare, and Symantec addresses rendering threats by executing web content in remote containers. But thousands of extensions now run locally with privileged access, GenAI tools create new exfiltration paths, and session-based attacks hijack authenticated tokens. Isolation protects users before authentication ‚Äî not after attackers inherit valid sessions, tokens, and extension privileges.Three attack patterns worth understandingTrust can be accumulated over years ‚Äî then weaponized overnight.The long game. ShadyPanda submitted clean extensions to Chrome and Edge stores in 2018, accumulated Google&#x27;s \"Featured\" and \"Verified\" badges, then weaponized them seven years later. Clean Master became a remote code execution backdoor running hourly JavaScript downloads ‚Äî not malware with a fixed function, but a backdoor letting attackers decide what comes next.The credential hijack. Browser auto-updates function as a software supply chain ‚Äî and inherit its risks. Cyberhaven attackers phished one developer&#x27;s credentials in 2024. The Chrome Web Store approved the malicious upload. Within 48 hours, 400,000 corporate customers had auto-updated to compromised code.The API key leak. Control planes are attack surfaces, not internal safeguards. Trust Wallet attackers used a leaked Chrome Web Store API key to push malicious updates, bypassing all internal release controls. Around $8.5 million had been drained from wallets by attackers within a couple days. No phishing required. No zero-days. Just the auto-update mechanism doing what it was designed to do.Why detection fails when attackers have valid credentials\"Nation-state actors typically exploit browser access for long-term, covert intelligence collection, while financially motivated e-crime groups prioritize speed, using browser-based attacks to harvest credentials, session tokens, and sensitive data for rapid monetization or resale,\" Zaitsev said. \"Despite different objectives, both rely on the same browser-layer blind spot to operate inside trusted sessions and bypass traditional detection.\"Session hijacking illustrates why this matters. The most important signals are behavioral and contextual, not credentials themselves. That includes how a user interacts with the browser in real-time, whether actions align with expected behavior, how data is being accessed or moved, and whether the session context suddenly changes in ways that indicate abuse.Once attackers capture a valid token, they replay it from anywhere. Authentication already happened, and MFA already passed. Zaitsev argues that detecting session hijacking early requires correlating in-session browser behavior with identity posture, endpoint signals, and threat intelligence. When those signals are unified, distinguishing a legitimate user from a hijacker becomes possible. That&#x27;s something siloed enterprise browsers and legacy security tools can&#x27;t see.When productivity tools become exfiltration pathsGenAI traffic surged 890% in 2024, with organizations now averaging 66 GenAI applications, according to Palo Alto Networks&#x27; State of Generative AI 2025 report. GenAI-related data loss incidents more than doubled, accounting for 14% of all data security incidents.Evans remembers the board conversation that started it all. \"In October 2023, they asked, &#x27;What are your thoughts on ChatGPT?&#x27; I said it&#x27;s an incredible productivity tool, however, I don&#x27;t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it or our source code.\"Legitimate GenAI use and data exfiltration look identical at the network level. Both are encrypted browser sessions sending data to approved SaaS endpoints, often involving copy-and-paste into browser-based tools. The distinction only becomes clear at the browser layer, where you can see what data is being pasted, whether the destination is approved, and whether the behavior matches normal work patterns.Evans found a balance. \"If somebody goes to chatgpt.com, we allow them to use it. They just can&#x27;t copy and paste anything into it. They can&#x27;t upload any files, but they can ask questions and compare answers with our corporate version.\" Employees get AI for research without risking customer data in model training.\"It seems like there&#x27;s a new one every five minutes,\" Evans said. \"Browser-layer controls maintain those categories, so if a new tool shows up, we can feel pretty good that employees won&#x27;t be able to copy and paste or upload our data.\"The billion-dollar browser betCrowdStrike acquired Seraphic Security and SGNL for a combined $1.16 billion in January 2026, signaling how seriously vendors are betting on the browser layer. Palo Alto Networks bought Talon in 2023. Two camps are emerging. Island wants enterprises to replace Chrome and Edge entirely with a purpose-built browser, and has reached a $4.8 billion valuation (March, 2025). Menlo Security bets most enterprises won&#x27;t switch browsers, so it layers protection on top of whatever employees already use. The tradeoff is real. Replacement browsers offer deeper control but require adoption. Security layers preserve user choice but see less. Both are winning deals.Zaitsev says neither approach works without tying browser activity to identity. Authentication tells you who logged in. It doesn&#x27;t tell you if that session gets hijacked 10 minutes later, or if the user starts exfiltrating data to an unauthorized GenAI tool. Catching that requires correlating browser behavior with endpoint and identity signals in real time ‚Äî something most enterprises can&#x27;t do yet.For buyers, the decision isn‚Äôt about vendors ‚Äî it‚Äôs about whether browser activity is tied into identity, endpoint, and SOC workflows, or left as a standalone control plane.Six patterns from productionSecuring the browser that employees actually use matters more than which enterprise browser to deploy. Today&#x27;s workforce moves across multiple browsers and managed and unmanaged devices. What matters is visibility and control inside live sessions without breaking how people work.Evans put it more simply: \"I wanted security closer to the end user, on the device they use every day. Having security in the browser made our lives simple. Road warriors dealing with hotel captive portals that normally get blocked by edge products? We don&#x27;t worry about that anymore.\"Based on interviews with CISOs running browser-layer controls in production, six patterns keep showing up. One caveat: These assume you already have mature identity and endpoint infrastructure. If you don&#x27;t, start there.Build a complete extension inventory. Use browser management APIs to enumerate every extension, flag anything requesting sensitive permissions, and cross-reference against known-malicious hashes.Break the auto-update kill chain. Fast patching reduces exposure to known vulnerabilities but creates supply chain risk. Implement version pinning with 48- to 72-hour delays. The Cyberhaven attack was detected in roughly 25 hours. A staged rollout would have contained it.Move data protection to where data moves. \"DLP is where we got the biggest win,\" Evans said. \"Customer data exfiltration can happen through social media, personal file shares, and web-based email. Being able to block copy-paste into certain site categories, block file uploads was incredibly powerful.\"Eliminate browser sprawl. \"It does no good to deploy an enterprise browser when someone can download Opera, or Frank&#x27;s browser of the month, and bypass all the controls,\" Evans said. Every unmanaged browser is a policy-free zone.Extend identity into sessions, treat GenAI as unvetted, feed signals to the SOC. Session hijackers inherit valid credentials but not normal behavior patterns. Watch for impossible travel, permission escalation, and bulk access anomalies. Evans found that browser-layer blocking surfaced shadow AI tools employees actually wanted, which IT could then enable properly. And browser telemetry should flow into existing SOC workflows. \"The AI does initial triage,\" Evans said, \"telling analysts where to look based on what we&#x27;ve seen before.\"Show the board a working demo. \"I didn&#x27;t just come with concerns,\" Evans said. \"I came with a solution. When I explained how enterprise browsers work, the board said, &#x27;Can you really do it?&#x27; At our July 2024 audit committee, they asked how it was going. I said, &#x27;Let me show you.&#x27; Pulled up a screenshot ‚Äî here I am on ChatGPT, tried to paste something, got: &#x27;Policy prevents this.&#x27; They said, &#x27;Wow.&#x27; That calmed their nerves.\"The bottom lineThe browser security gap is real. The fix isn&#x27;t necessarily a new platform purchase. Start by assessing what you have: inventory extensions, delay auto-updates, and enforce data policies at the browser layer with existing tools.\"No security tool is 100% perfect,\" Evans said. \"But with browser-layer controls deployed, we sleep a lot easier.\"Breach rates won‚Äôt improve by stacking more perimeter tools onto architectures that assume trust ends at login. Outcomes improve when you treat the browser as what it&#x27;s become: the primary execution environment for enterprise work.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5L4OH5idEk7QcVSOUFllsM/8d834f158372e78f94c6f12fca684d7f/hero_image_95-_of_Enterprises_Got_Breached_Through_Their_Browsers_And_Their_Security_Stacks_Never_Saw_It_2.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/resident-evil-requiem-preview-150000849.html",
          "published_at": "Mon, 26 Jan 2026 15:00:00 +0000",
          "title": "Resident Evil Requiem gives series fans the best of both action and survival horror",
          "standfirst": "The ninth mainline Resident Evil is trying to split the difference between the series‚Äô action-heavy entries and the stress-inducing hide-and-seek episodes. During a four-hour playthrough of some early parts of Resident Evil Requiem, I spent time with both of the two main characters, Grace and series mainstay Leon. They offer distinctly different playstyles, talents, strengths, and weaknesses. While it isn't an entirely new premise for the survival horror series (in the original, playing as Chris Redfield offered more challenge than playing as Jill Valentine) it‚Äôs never been this pronounced. I started playing as Leon, entering a medical facility he seemed to have been invited to. With a cavernous main hall, it feels like yet another iconic Resident Evil hub, immediately reminding me of Raccoon City's Police Precinct and even the original's cavernous manor. Wings to explore? Check. Suspiciously quiet and empty central area that will almost definitely get overrun by zombies at some point? Probably.Both Grace and Leon‚Äôs parts can be played in either third- or first-person perspective, though Leon‚Äôs segments seem better suited to the third-person view, since there's just a lot more shooting. Grace's segments were tense and demanded my full attention, more akin to Resident Evil 7. During this early part of the game, there is a lot of hiding, plenty of ammo conservation and a lot more learning from dumb mistakes. The parts of the game I played with Leon reminded me more of Resident Evil 4 (or 5 or 6 ‚Äì but let‚Äôs gloss over those).Once you take control of him, Leon is immediately attacked and has to fend off roughly 15 infected doctors, nurses and patients. It‚Äôs a significant tone shift from Grace skulking around the facility, hiding behind plants and sometimes just hoping for the best. Leon faces off against a chainsaw-wielding doctor zombie. Best cut that arm off.CapcomLeon, fortunately, arrives with several weapons, including a new melee option, a hatchet. Using this, he can make targeted attacks to lop off limbs and aim at the head to deliver more damage. At least on these basic zombies, I found relentless slashing more effective than more targeted efforts ‚Äì I‚Äôm sure future enemies will demand more‚Ä¶ nuanced approaches. A later enemy must be decapitated to kill it. After a set number of swings, you will need to retreat and sharpen the blade, which adds to the jeopardy while not disrupting the chaos. The hatchet can even be used to parry attacks ‚Äì if you get the timing down. Leon even gets to wield a chainsaw during this initial encounter, but only after claiming it from one particularly industrious zombie that seemed to find it inside a hospital. It was crucial to both disarm this zombie and grab the chainsaw before another corpse could take a turn on it. However, just because the chainsaw gets dropped doesn‚Äôt mean it‚Äôs turned off. I suffered significant damage when I repeatedly rushed into the spinning power tool. The zombies in Requiem are also a little more nuanced compared to previous games ‚Äì if a zombie can have nuance. While nearly all of the zombies will attack you on sight, they can be distracted or delayed based on the person they were before they turned. For example, the chef zombie (a hardy, bigger zombie than the ones you‚Äôve come across until that point) will only chase you around his kitchen. Step out into the corridor and he‚Äôll leave you alone. Elsewhere, a zombie (attached to an IV, cute) has his eyes bandaged and will react aggressively to any noise. I used this to my advantage, hurling an empty bottle at another zombie who stood nearby. The IV zombie killed him immediately. Another time, a senior exec who‚Äôs been turned is firing an employee of his‚Ä¶ by killing them, moaning ‚ÄúYou‚Äôre fired‚Äù as he does so. This little vignette gave me enough time to dim the lights and hide when he left his office. In Requiem, players are expected to exploit individual zombie behaviors to outmaneuver them. It‚Äôs also a welcome dose of humor to the survival horror series, reminding me a little of the camp moments in Dead Rising, another zombie-centric Capcom series. Leon doesn‚Äôt have to strategize quite as much, arriving with a particularly powerful handgun, the Requiem, that he eventually passes over to Grace. This is capable of stopping pretty much (but not all) enemies you come across, although it initially comes with only a single bullet, so you really have to make it count. During a set-piece battle against a towering, swollen former patient, I got to test Requiem‚Äôs action-horror controls under pressure. Leon finds a shotgun and has to flank (and outrun) his ‚Äúhungry‚Äù attacker. The environment in the rafters of the building is designed so it‚Äôs easy to figure out where you need to go and how to stop the giant zombie from cornering you. Ammo, at least during this fight, was scattered around, which was a relief after struggling to find bullets during Grace‚Äôs segment.Despite the lack of traditional weapons, Grace eventually finds a blood injector (and its companion blood analysis system). These turn into Requiem‚Äôs crafting system. Powered by literal buckets and puddles of blood (you have to draw up infected blood from certain parts of the environment and enemies), samples can be combined with scraps, herbs and more to create high-powered first-aid shots, injectable explosive blood, ammunition and a lot of other things. Analysing different blood types (and solving some light puzzles) adds further crafting options. Oh he's not going to help you.CapcomDuring the preview, the infected blood injector was exclusively for Grace‚Äôs use. It‚Äôll be intriguing if only one character gets to benefit from the crafting system, although Capcom teased customizable weapons for Leon, which might better suit his playstyle. Grace might also be handicapped by the typewriter save system popularized in the first few RE games. This could mean you‚Äôll only be able to save if you have an ink ribbon on you, a very stressful part of inventory management early on in the series ‚Äî she really can‚Äôt catch a break. However, it appears to be adjustable in difficulty settings. According to Capcom‚Äôs Resident Evil showcase last week, infected blood will apparently play a strong role in Requiem, touching on both Leon‚Äôs past (he‚Äôs apparently suffering from a mystery ailment) and the circumstances surrounding the death of Grace's mother. And it wouldn‚Äôt be a Resident Evil game with mystery, buckets of blood, and a pulpy villain. Capcom has primed another fascinating villain with Requiem‚Äôs Dr. Gideon, a former Umbrella virologist who was seemingly written for an actor to go full camp baddie ‚Äì if the doctor‚Äôs hooded snakeskin trenchcoat wasn‚Äôt a giveaway. Resident Evil Requiem will be released on February 27, 2026 for PC, PS5 and Xbox Series X|S.This article originally appeared on Engadget at https://www.engadget.com/gaming/resident-evil-requiem-preview-150000849.html?src=rss",
          "content": "The ninth mainline Resident Evil is trying to split the difference between the series‚Äô action-heavy entries and the stress-inducing hide-and-seek episodes. During a four-hour playthrough of some early parts of Resident Evil Requiem, I spent time with both of the two main characters, Grace and series mainstay Leon. They offer distinctly different playstyles, talents, strengths, and weaknesses. While it isn't an entirely new premise for the survival horror series (in the original, playing as Chris Redfield offered more challenge than playing as Jill Valentine) it‚Äôs never been this pronounced. I started playing as Leon, entering a medical facility he seemed to have been invited to. With a cavernous main hall, it feels like yet another iconic Resident Evil hub, immediately reminding me of Raccoon City's Police Precinct and even the original's cavernous manor. Wings to explore? Check. Suspiciously quiet and empty central area that will almost definitely get overrun by zombies at some point? Probably.Both Grace and Leon‚Äôs parts can be played in either third- or first-person perspective, though Leon‚Äôs segments seem better suited to the third-person view, since there's just a lot more shooting. Grace's segments were tense and demanded my full attention, more akin to Resident Evil 7. During this early part of the game, there is a lot of hiding, plenty of ammo conservation and a lot more learning from dumb mistakes. The parts of the game I played with Leon reminded me more of Resident Evil 4 (or 5 or 6 ‚Äì but let‚Äôs gloss over those).Once you take control of him, Leon is immediately attacked and has to fend off roughly 15 infected doctors, nurses and patients. It‚Äôs a significant tone shift from Grace skulking around the facility, hiding behind plants and sometimes just hoping for the best. Leon faces off against a chainsaw-wielding doctor zombie. Best cut that arm off.CapcomLeon, fortunately, arrives with several weapons, including a new melee option, a hatchet. Using this, he can make targeted attacks to lop off limbs and aim at the head to deliver more damage. At least on these basic zombies, I found relentless slashing more effective than more targeted efforts ‚Äì I‚Äôm sure future enemies will demand more‚Ä¶ nuanced approaches. A later enemy must be decapitated to kill it. After a set number of swings, you will need to retreat and sharpen the blade, which adds to the jeopardy while not disrupting the chaos. The hatchet can even be used to parry attacks ‚Äì if you get the timing down. Leon even gets to wield a chainsaw during this initial encounter, but only after claiming it from one particularly industrious zombie that seemed to find it inside a hospital. It was crucial to both disarm this zombie and grab the chainsaw before another corpse could take a turn on it. However, just because the chainsaw gets dropped doesn‚Äôt mean it‚Äôs turned off. I suffered significant damage when I repeatedly rushed into the spinning power tool. The zombies in Requiem are also a little more nuanced compared to previous games ‚Äì if a zombie can have nuance. While nearly all of the zombies will attack you on sight, they can be distracted or delayed based on the person they were before they turned. For example, the chef zombie (a hardy, bigger zombie than the ones you‚Äôve come across until that point) will only chase you around his kitchen. Step out into the corridor and he‚Äôll leave you alone. Elsewhere, a zombie (attached to an IV, cute) has his eyes bandaged and will react aggressively to any noise. I used this to my advantage, hurling an empty bottle at another zombie who stood nearby. The IV zombie killed him immediately. Another time, a senior exec who‚Äôs been turned is firing an employee of his‚Ä¶ by killing them, moaning ‚ÄúYou‚Äôre fired‚Äù as he does so. This little vignette gave me enough time to dim the lights and hide when he left his office. In Requiem, players are expected to exploit individual zombie behaviors to outmaneuver them. It‚Äôs also a welcome dose of humor to the survival horror series, reminding me a little of the camp moments in Dead Rising, another zombie-centric Capcom series. Leon doesn‚Äôt have to strategize quite as much, arriving with a particularly powerful handgun, the Requiem, that he eventually passes over to Grace. This is capable of stopping pretty much (but not all) enemies you come across, although it initially comes with only a single bullet, so you really have to make it count. During a set-piece battle against a towering, swollen former patient, I got to test Requiem‚Äôs action-horror controls under pressure. Leon finds a shotgun and has to flank (and outrun) his ‚Äúhungry‚Äù attacker. The environment in the rafters of the building is designed so it‚Äôs easy to figure out where you need to go and how to stop the giant zombie from cornering you. Ammo, at least during this fight, was scattered around, which was a relief after struggling to find bullets during Grace‚Äôs segment.Despite the lack of traditional weapons, Grace eventually finds a blood injector (and its companion blood analysis system). These turn into Requiem‚Äôs crafting system. Powered by literal buckets and puddles of blood (you have to draw up infected blood from certain parts of the environment and enemies), samples can be combined with scraps, herbs and more to create high-powered first-aid shots, injectable explosive blood, ammunition and a lot of other things. Analysing different blood types (and solving some light puzzles) adds further crafting options. Oh he's not going to help you.CapcomDuring the preview, the infected blood injector was exclusively for Grace‚Äôs use. It‚Äôll be intriguing if only one character gets to benefit from the crafting system, although Capcom teased customizable weapons for Leon, which might better suit his playstyle. Grace might also be handicapped by the typewriter save system popularized in the first few RE games. This could mean you‚Äôll only be able to save if you have an ink ribbon on you, a very stressful part of inventory management early on in the series ‚Äî she really can‚Äôt catch a break. However, it appears to be adjustable in difficulty settings. According to Capcom‚Äôs Resident Evil showcase last week, infected blood will apparently play a strong role in Requiem, touching on both Leon‚Äôs past (he‚Äôs apparently suffering from a mystery ailment) and the circumstances surrounding the death of Grace's mother. And it wouldn‚Äôt be a Resident Evil game with mystery, buckets of blood, and a pulpy villain. Capcom has primed another fascinating villain with Requiem‚Äôs Dr. Gideon, a former Umbrella virologist who was seemingly written for an actor to go full camp baddie ‚Äì if the doctor‚Äôs hooded snakeskin trenchcoat wasn‚Äôt a giveaway. Resident Evil Requiem will be released on February 27, 2026 for PC, PS5 and Xbox Series X|S.This article originally appeared on Engadget at https://www.engadget.com/gaming/resident-evil-requiem-preview-150000849.html?src=rss",
          "feed_position": 10,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/requiem1_2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/outside-parties-is-the-creepiest-playdate-game-yet-and-im-kind-of-obsessed-213142541.html",
          "published_at": "Sun, 25 Jan 2026 21:31:42 +0000",
          "title": "Outside Parties is the creepiest Playdate game yet, and I'm kind of obsessed",
          "standfirst": "Never underestimate the chilling powers of grainy grayscale imagery and ethereal whooshing sounds. Outside Parties asks, \"What if I Spy, but in an alien hell dimension?\", and it is impressively unnerving despite the fact that nothing's really happening at any given time. It goes all in on atmosphere, to great effect. This is the Playdate horror game that I've been waiting for. Adams Immersive's Outside Parties is a sort of scavenger hunt across a massive image of a realm called the Outside, which can only be visited by astral travel, according to the lore. There are lots of unknowns about what or where it really is, though explorers have mapped it fairly extensively through out-of-body excursions and they've encountered thousands of different entities there, including the spirits of the dead. As the player, you have come across a Hellscryer K5 ‚Äî the communication device, psychic camera and recorder used for these trips ‚Äî and now you're combing through the mission logs, getting sucked into the mystery of it all. Think of the K5 as your Playdate, except powered by blood and runes. At the center of Outside Parties is a 1.44 gigapixel, 360-degree panoramic HDR image which has dozens of eerie scenes hidden within it: skeletons of human, animal and paranormal origin; scary robed figures and occult symbols etched all around; what appear to be fountains and rivers of blood; a Stonehenge of teeth. These are the targets you're meant to track down, and as you hone in and check them off your list, voice signals attached to each one will reveal more and more of the explorer's spellbinding story. But this isn't a straightforward \"find the object\" puzzle game by any means. When you first look at the zoomed-out photo, it's akin to a strip of TV static with some heavily shadowed areas throughout. You can zoom to up to 64 times magnification to get a better look at specific zones, but you also have to adjust the image brightness using the crank to improve the clarity of the objects. Making it brighter or darker will reveal more objects in certain spots while simultaneously obscuring others. There are 150 targets according to the developer, which should take players somewhere from 10-20 hours to complete. I've been at it for hours and still have plenty left to find. (If you're stuck, you can turn to the helpful target lookup page, which provides hints with varying degrees of specificity.) All the while as you're hunched over your Playdate, laser-focused on the screen to find targets that are buried in a sea of fuzz, unsettling audio transmissions are cutting in and out, disturbing images are flashing on-screen at random and a constant atmospheric whooshing is playing in your ear. The sound design of this game is seriously brilliant ‚Äî it's worth playing for that alone, not to mention all the other cool stuff. From the startup page to the menus where you'll find bits of a background story, to the creepy clips of people wailing and ominously reciting numbers, the sounds of Outside Parties make for a truly immersive, disconcerting experience that I previously wouldn't have thought possible on a Playdate. It's really something special. Outside Parties also comes with a screensaver that once again makes me yearn for the Playdate Stereo Dock. Pop on the Void Monitor, sit back, and enjoy the horrifying sights and sounds of the Outside. This article originally appeared on Engadget at https://www.engadget.com/gaming/outside-parties-is-the-creepiest-playdate-game-yet-and-im-kind-of-obsessed-213142541.html?src=rss",
          "content": "Never underestimate the chilling powers of grainy grayscale imagery and ethereal whooshing sounds. Outside Parties asks, \"What if I Spy, but in an alien hell dimension?\", and it is impressively unnerving despite the fact that nothing's really happening at any given time. It goes all in on atmosphere, to great effect. This is the Playdate horror game that I've been waiting for. Adams Immersive's Outside Parties is a sort of scavenger hunt across a massive image of a realm called the Outside, which can only be visited by astral travel, according to the lore. There are lots of unknowns about what or where it really is, though explorers have mapped it fairly extensively through out-of-body excursions and they've encountered thousands of different entities there, including the spirits of the dead. As the player, you have come across a Hellscryer K5 ‚Äî the communication device, psychic camera and recorder used for these trips ‚Äî and now you're combing through the mission logs, getting sucked into the mystery of it all. Think of the K5 as your Playdate, except powered by blood and runes. At the center of Outside Parties is a 1.44 gigapixel, 360-degree panoramic HDR image which has dozens of eerie scenes hidden within it: skeletons of human, animal and paranormal origin; scary robed figures and occult symbols etched all around; what appear to be fountains and rivers of blood; a Stonehenge of teeth. These are the targets you're meant to track down, and as you hone in and check them off your list, voice signals attached to each one will reveal more and more of the explorer's spellbinding story. But this isn't a straightforward \"find the object\" puzzle game by any means. When you first look at the zoomed-out photo, it's akin to a strip of TV static with some heavily shadowed areas throughout. You can zoom to up to 64 times magnification to get a better look at specific zones, but you also have to adjust the image brightness using the crank to improve the clarity of the objects. Making it brighter or darker will reveal more objects in certain spots while simultaneously obscuring others. There are 150 targets according to the developer, which should take players somewhere from 10-20 hours to complete. I've been at it for hours and still have plenty left to find. (If you're stuck, you can turn to the helpful target lookup page, which provides hints with varying degrees of specificity.) All the while as you're hunched over your Playdate, laser-focused on the screen to find targets that are buried in a sea of fuzz, unsettling audio transmissions are cutting in and out, disturbing images are flashing on-screen at random and a constant atmospheric whooshing is playing in your ear. The sound design of this game is seriously brilliant ‚Äî it's worth playing for that alone, not to mention all the other cool stuff. From the startup page to the menus where you'll find bits of a background story, to the creepy clips of people wailing and ominously reciting numbers, the sounds of Outside Parties make for a truly immersive, disconcerting experience that I previously wouldn't have thought possible on a Playdate. It's really something special. Outside Parties also comes with a screensaver that once again makes me yearn for the Playdate Stereo Dock. Pop on the Void Monitor, sit back, and enjoy the horrifying sights and sounds of the Outside. This article originally appeared on Engadget at https://www.engadget.com/gaming/outside-parties-is-the-creepiest-playdate-game-yet-and-im-kind-of-obsessed-213142541.html?src=rss",
          "feed_position": 19
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/the-era-of-agentic-ai-demands-a-data-constitution-not-better-prompts",
          "published_at": "Sun, 25 Jan 2026 21:00:00 GMT",
          "title": "The era of agentic AI demands a data constitution, not better prompts",
          "standfirst": "The industry consensus is that 2026 will be the year of \"agentic AI.\" We are rapidly moving past chatbots that simply summarize text. We are entering the era of autonomous agents that execute tasks. We expect them to book flights, diagnose system outages, manage cloud infrastructure and personalize media streams in real-time.As a technology executive overseeing platforms that serve 30 million concurrent users during massive global events like the Olympics and the Super Bowl, I have seen the unsexy reality behind the hype: Agents are incredibly fragile.Executives and VCs obsess over model benchmarks. They debate Llama 3 versus GPT-4. They focus on maximizing context window sizes. Yet they are ignoring the actual failure point. The primary reason autonomous agents fail in production is often due to data hygiene issues.In the previous era of \"human-in-the-loop\" analytics, data quality was a manageable nuisance. If an ETL pipeline experiences an issue, a dashboard may display an incorrect revenue number. A human analyst would spot the anomaly, flag it and fix it. The blast radius was contained.In the new world of autonomous agents, that safety net is gone.If a data pipeline drifts today, an agent doesn&#x27;t just report the wrong number. It takes the wrong action. It provisions the wrong server type. It recommends a horror movie to a user watching cartoons. It hallucinates a customer service answer based on corrupted vector embeddings.To run AI at the scale of the NFL or the Olympics, I realized that standard data cleaning is insufficient. We cannot just \"monitor\" data. We must legislate it.A solution to this specific problem could be in the form of a ‚Äòdata quality ‚Äì creed‚Äô framework. It functions as a &#x27;data constitution.&#x27; It enforces thousands of automated rules before a single byte of data is allowed to touch an AI model. While I applied this specifically to the streaming architecture at NBCUniversal, the methodology is universal for any enterprise looking to operationalize AI agents.Here is why \"defensive data engineering\" and the Creed philosophy are the only ways to survive the Agentic era.The vector database trapThe core problem with AI Agents is that they trust the context you give them implicitly. If you are using RAG, your vector database is the agent‚Äôs long-term memory.Standard data quality issues are catastrophic for vector databases. In traditional SQL databases, a null value is just a null value. In a vector database, a null value or a schema mismatch can warp the semantic meaning of the entire embedding.Consider a scenario where metadata drifts. Suppose your pipeline ingests video metadata, but a race condition causes the \"genre\" tag to slip. Your metadata might tag a video as \"live sports,\" but the embedding was generated from a \"news clip.\" When an agent queries the database for \"touchdown highlights,\" it retrieves the news clip because the vector similarity search is operating on a corrupted signal. The agent then serves that clip to millions of users.At scale, you cannot rely on downstream monitoring to catch this. By the time an anomaly alarm goes off, the agent has already made thousands of bad decisions. Quality controls must shift to the absolute \"left\" of the pipeline.The \"Creed\" framework: 3 principles for survivalThe Creed framework is expected to act as a gatekeeper. It is a multi-tenant quality architecture that sits between ingestion sources and AI models.For technology leaders looking to build their own \"constitution,\" here are the three non-negotiable principles I recommend.1. The \"quarantine\" pattern is mandatory: In many modern data organizations, engineers favor the \"ELT\" approach. They dump raw data into a lake and clean it up later. For AI Agents, this is unacceptable. You cannot let an agent drink from a polluted lake.The Creed methodology enforces a strict \"dead letter queue.\" If a data packet violates a contract, it is immediately quarantined. It never reaches the vector database. It is far better for an agent to say \"I don&#x27;t know\" due to missing data than to confidently lie due to bad data. This \"circuit breaker\" pattern is essential for preventing high-profile hallucinations.2. Schema is law: For years, the industry moved toward \"schemaless\" flexibility to move fast. We must reverse that trend for core AI pipelines. We must enforce strict typing and referential integrity.In my experience, a robust system requires scale. The implementation I oversee currently enforces more than 1,000 active rules running across real-time streams. These aren&#x27;t just checking for nulls. They check for business logic consistency.Example: Does the \"user_segment\" in the event stream match the active taxonomy in the feature store? If not, block it.Example: Is the timestamp within the acceptable latency window for real-time inference? If not, drop it.3. Vector consistency checks This is the new frontier for SREs. We must implement automated checks to ensure that the text chunks stored in a vector database actually match the embedding vectors associated with them. \"Silent\" failures in an embedding model API often leave you with vectors that point to nothing. This causes agents to retrieve pure noise.The culture war: Engineers vs. governanceImplementing a framework like Creed is not just a technical challenge. It is a cultural one.Engineers generally hate guardrails. They view strict schemas and data contracts as bureaucratic hurdles that slow down deployment velocity. When introducing a data constitution, leaders often face pushback. Teams feel they are returning to the \"waterfall\" era of rigid database administration.To succeed, you must flip the incentive structure. We demonstrated that Creed was actually an accelerator. By guaranteeing the purity of the input data, we eliminated the weeks data scientists used to spend debugging model hallucinations. We turned data governance from a compliance task into a \"quality of service\" guarantee.The lesson for data decision makersIf you are building an AI strategy for 2026, stop buying more GPUs. Stop worrying about which foundation model is slightly higher on the leaderboard this week.Start auditing your data contracts.An AI Agent is only as autonomous as its data is reliable. Without a strict, automated data constitution like the Creed framework, your agents will eventually go rogue. In an SRE‚Äôs world, a rogue agent is far worse than a broken dashboard. It is a silent killer of trust, revenue, and customer experience.Manoj Yerrasani is a senior technology executive.",
          "content": "The industry consensus is that 2026 will be the year of \"agentic AI.\" We are rapidly moving past chatbots that simply summarize text. We are entering the era of autonomous agents that execute tasks. We expect them to book flights, diagnose system outages, manage cloud infrastructure and personalize media streams in real-time.As a technology executive overseeing platforms that serve 30 million concurrent users during massive global events like the Olympics and the Super Bowl, I have seen the unsexy reality behind the hype: Agents are incredibly fragile.Executives and VCs obsess over model benchmarks. They debate Llama 3 versus GPT-4. They focus on maximizing context window sizes. Yet they are ignoring the actual failure point. The primary reason autonomous agents fail in production is often due to data hygiene issues.In the previous era of \"human-in-the-loop\" analytics, data quality was a manageable nuisance. If an ETL pipeline experiences an issue, a dashboard may display an incorrect revenue number. A human analyst would spot the anomaly, flag it and fix it. The blast radius was contained.In the new world of autonomous agents, that safety net is gone.If a data pipeline drifts today, an agent doesn&#x27;t just report the wrong number. It takes the wrong action. It provisions the wrong server type. It recommends a horror movie to a user watching cartoons. It hallucinates a customer service answer based on corrupted vector embeddings.To run AI at the scale of the NFL or the Olympics, I realized that standard data cleaning is insufficient. We cannot just \"monitor\" data. We must legislate it.A solution to this specific problem could be in the form of a ‚Äòdata quality ‚Äì creed‚Äô framework. It functions as a &#x27;data constitution.&#x27; It enforces thousands of automated rules before a single byte of data is allowed to touch an AI model. While I applied this specifically to the streaming architecture at NBCUniversal, the methodology is universal for any enterprise looking to operationalize AI agents.Here is why \"defensive data engineering\" and the Creed philosophy are the only ways to survive the Agentic era.The vector database trapThe core problem with AI Agents is that they trust the context you give them implicitly. If you are using RAG, your vector database is the agent‚Äôs long-term memory.Standard data quality issues are catastrophic for vector databases. In traditional SQL databases, a null value is just a null value. In a vector database, a null value or a schema mismatch can warp the semantic meaning of the entire embedding.Consider a scenario where metadata drifts. Suppose your pipeline ingests video metadata, but a race condition causes the \"genre\" tag to slip. Your metadata might tag a video as \"live sports,\" but the embedding was generated from a \"news clip.\" When an agent queries the database for \"touchdown highlights,\" it retrieves the news clip because the vector similarity search is operating on a corrupted signal. The agent then serves that clip to millions of users.At scale, you cannot rely on downstream monitoring to catch this. By the time an anomaly alarm goes off, the agent has already made thousands of bad decisions. Quality controls must shift to the absolute \"left\" of the pipeline.The \"Creed\" framework: 3 principles for survivalThe Creed framework is expected to act as a gatekeeper. It is a multi-tenant quality architecture that sits between ingestion sources and AI models.For technology leaders looking to build their own \"constitution,\" here are the three non-negotiable principles I recommend.1. The \"quarantine\" pattern is mandatory: In many modern data organizations, engineers favor the \"ELT\" approach. They dump raw data into a lake and clean it up later. For AI Agents, this is unacceptable. You cannot let an agent drink from a polluted lake.The Creed methodology enforces a strict \"dead letter queue.\" If a data packet violates a contract, it is immediately quarantined. It never reaches the vector database. It is far better for an agent to say \"I don&#x27;t know\" due to missing data than to confidently lie due to bad data. This \"circuit breaker\" pattern is essential for preventing high-profile hallucinations.2. Schema is law: For years, the industry moved toward \"schemaless\" flexibility to move fast. We must reverse that trend for core AI pipelines. We must enforce strict typing and referential integrity.In my experience, a robust system requires scale. The implementation I oversee currently enforces more than 1,000 active rules running across real-time streams. These aren&#x27;t just checking for nulls. They check for business logic consistency.Example: Does the \"user_segment\" in the event stream match the active taxonomy in the feature store? If not, block it.Example: Is the timestamp within the acceptable latency window for real-time inference? If not, drop it.3. Vector consistency checks This is the new frontier for SREs. We must implement automated checks to ensure that the text chunks stored in a vector database actually match the embedding vectors associated with them. \"Silent\" failures in an embedding model API often leave you with vectors that point to nothing. This causes agents to retrieve pure noise.The culture war: Engineers vs. governanceImplementing a framework like Creed is not just a technical challenge. It is a cultural one.Engineers generally hate guardrails. They view strict schemas and data contracts as bureaucratic hurdles that slow down deployment velocity. When introducing a data constitution, leaders often face pushback. Teams feel they are returning to the \"waterfall\" era of rigid database administration.To succeed, you must flip the incentive structure. We demonstrated that Creed was actually an accelerator. By guaranteeing the purity of the input data, we eliminated the weeks data scientists used to spend debugging model hallucinations. We turned data governance from a compliance task into a \"quality of service\" guarantee.The lesson for data decision makersIf you are building an AI strategy for 2026, stop buying more GPUs. Stop worrying about which foundation model is slightly higher on the leaderboard this week.Start auditing your data contracts.An AI Agent is only as autonomous as its data is reliable. Without a strict, automated data constitution like the Creed framework, your agents will eventually go rogue. In an SRE‚Äôs world, a rogue agent is far worse than a broken dashboard. It is a silent killer of trust, revenue, and customer experience.Manoj Yerrasani is a senior technology executive.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/51ivtIwaFfeOn1BNlUNuBg/27e59afbbbc17bed9aac28d1c3d6aa98/image2.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/conversational-ai-doesnt-understand-users-intent-first-architecture-does",
          "published_at": "Sun, 25 Jan 2026 18:00:00 GMT",
          "title": "Conversational AI doesn‚Äôt understand users ‚Äî 'Intent First' architecture does",
          "standfirst": "The modern customer has just one need that matters: Getting the thing they want when they want it. The old standard RAG model embed+retrieve+LLM misunderstands intent, overloads context and misses freshness, repeatedly sending customers down the wrong paths. Instead, intent-first architecture uses a lightweight language model to parse the query for intent and context, before delivering to the most relevant content sources (documents, APIs, people).Enterprise AI is a speeding train headed for a cliff. Organizations are deploying LLM-powered search applications at a record pace, while a fundamental architectural issue is setting most up for failure.A recent Coveo study revealed that 72% of enterprise search queries fail to deliver meaningful results on the first attempt, while Gartner also predicts that the majority of conversational AI deployments have been falling short of enterprise expectations.The problem isn‚Äôt the underlying models. It‚Äôs the architecture around them.After designing and running live AI-driven customer interaction platforms at scale, serving millions of customer and citizen users at some of the world‚Äôs largest telecommunications and healthcare organizations, I‚Äôve come to see a pattern. It‚Äôs the difference between successful AI-powered interaction deployments and multi-million-dollar failures.It‚Äôs a cloud-native architecture pattern that I call Intent-First. And it‚Äôs reshaping the way enterprises build AI-powered experiences.The $36 pillion problem Gartner projects the global conversational AI market will balloon to $36 billion by 2032. Enterprises are scrambling to get a slice. The demos are irresistible. Plug your LLM into your knowledge base, and suddenly it can answer customer questions in natural language.Magic. Then production happens. A major telecommunications provider I work with rolled out a RAG system with the expectation of driving down the support call rate. Instead, the rate increased. Callers tried AI-powered search, were provided incorrect answers with a high degree of confidence and called customer support angrier than before.This pattern is repeated over and over. In healthcare, customer-facing AI assistants are providing patients with formulary information that‚Äôs outdated by weeks or months. Financial services chatbots are spitting out answers from both retail and institutional product content. Retailers are seeing discontinued products surface in product searches.The issue isn‚Äôt a failure of AI technology. It‚Äôs a failure of architectureWhy standard RAG architectures fail The standard RAG pattern ‚Äî embedding the query, retrieving semantically similar content, passing to an LLM ‚Äîworks beautifully in demos and proof of concepts. But it falls apart in production use cases for three systematic reasons:1. The intent gapIntent is not context. But standard RAG architectures don‚Äôt account for this.Say a customer types ‚ÄúI want to cancel‚Äù What does that mean? Cancel a service? Cancel an order? Cancel an appointment? During our telecommunications deployment, we found that 65% of queries for ‚Äúcancel‚Äù were actually about orders or appointments, not service cancellation. The RAG system had no way of understanding this intent, so it consistently returned service cancellation documents.Intent matters. In healthcare, if a patient is typing ‚ÄúI need to cancel‚Äù because they&#x27;re trying to cancel an appointment, a prescription refill or a procedure, routing them to medication content from scheduling is not only frustrating ‚Äî it&#x27;s also dangerous.2. Context flood Enterprise knowledge and experience is vast, spanning dozens of sources such as product catalogs, billing, support articles, policies, promotions and account data. Standard RAG models treat all of it the same, searching all for every query.When a customer asks ‚ÄúHow do I activate my new phone,‚Äù they don‚Äôt care about billing FAQs, store locations or network status updates. But a standard RAG model retrieves semantically similar content from every source, returning search results that are a half-steps off the mark.3. Freshness blindspot Vector space is timeblind. Semantically, last quarter‚Äôs promotion is identical to this quarter‚Äôs. But presenting customers with outdated offers shatters trust. We linked a significant percentage of customer complaints to search results that surfaced expired products, offers, or features.The Intent-First architecture pattern The Intent-First architecture pattern is the mirror image of the standard RAG deployment. In the RAG model, you retrieve, then route. In the Intent-First model, you classify before you route or retrieve. Intent-First architectures use a lightweight language model to parse a query for intent and context, before dispatching to the most relevant content sources (documents, APIs, agents).Comparison: Intent-first vs standard RAGCloud-native implementationThe Intent-First pattern is designed for cloud-native deployment, leveraging microservices, containerization and elastic scaling to handle enterprise traffic patterns.Intent classification serviceThe classifier determines user intent before any retrieval occurs:ALGORITHM: Intent ClassificationINPUT: user_query (string)OUTPUT: intent_result (object)1. PREPROCESS query (normalize, expand contractions)2. CLASSIFY using transformer model: - primary_intent ‚Üê model.predict(query) - confidence ‚Üê model.confidence_score()3. IF confidence < 0.70 THEN - RETURN { requires_clarification: true, suggested_question: generate_clarifying_question(query) }4. EXTRACT sub_intent based on primary_intent: - IF primary = \"ACCOUNT\" ‚Üí check for ORDER_STATUS, PROFILE, etc. - IF primary = \"SUPPORT\" ‚Üí check for DEVICE_ISSUE, NETWORK, etc. - IF primary = \"BILLING\" ‚Üí check for PAYMENT, DISPUTE, etc.5. DETERMINE target_sources based on intent mapping: - ORDER_STATUS ‚Üí [orders_db, order_faq] - DEVICE_ISSUE ‚Üí [troubleshooting_kb, device_guides] - MEDICATION ‚Üí [formulary, clinical_docs] (healthcare)6. RETURN { primary_intent, sub_intent, confidence, target_sources, requires_personalization: true/false }Context-aware retrieval serviceOnce intent is classified, retrieval becomes targeted:ALGORITHM: Context-Aware RetrievalINPUT: query, intent_result, user_contextOUTPUT: ranked_documents1. GET source_config for intent_result.sub_intent: - primary_sources ‚Üê sources to search - excluded_sources ‚Üê sources to skip - freshness_days ‚Üê max content age2. IF intent requires personalization AND user is authenticated: - FETCH account_context from Account Service - IF intent = ORDER_STATUS: - FETCH recent_orders (last 60 days) - ADD to results3. BUILD search filters: - content_types ‚Üê primary_sources only - max_age ‚Üê freshness_days - user_context ‚Üê account_context (if available)4. FOR EACH source IN primary_sources: - documents ‚Üê vector_search(query, source, filters) - ADD documents to results5. SCORE each document: - relevance_score ‚Üê vector_similarity √ó 0.40 - recency_score ‚Üê freshness_weight √ó 0.20 - personalization_score ‚Üê user_match √ó 0.25 - intent_match_score ‚Üê type_match √ó 0.15 - total_score ‚Üê SUM of above6. RANK by total_score descending7. RETURN top 10 documentsHealthcare-specific considerationsIn healthcare deployments, the Intent-First pattern includes additional safeguards:Healthcare intent categories:Clinical: Medication questions, symptoms, care instructionsCoverage: Benefits, prior authorization, formularyScheduling: Appointments, provider availabilityBilling: Claims, payments, statementsAccount: Profile, dependents, ID cardsCritical safeguard: Clinical queries always include disclaimers and never replace professional medical advice. The system routes complex clinical questions to human support.Handling edge casesThe edge cases are where systems fail. The Intent-First pattern includes specific handlers:Frustration detection keywords:Anger: \"terrible,\" \"worst,\" \"hate,\" \"ridiculous\"Time: \"hours,\" \"days,\" \"still waiting\"Failure: \"useless,\" \"no help,\" \"doesn&#x27;t work\"Escalation: \"speak to human,\" \"real person,\" \"manager\"When frustration is detected, skip search entirely and route to human support.Cross-industry applicationsThe Intent-First pattern applies wherever enterprises deploy conversational AI over heterogeneous content:IndustryIntent categoriesKey benefitTelecommunicationsSales, Support, Billing, Account, RetentionPrevents \"cancel\" misclassificationHealthcareClinical, Coverage, Scheduling, BillingSeparates clinical from administrativeFinancial servicesRetail, Institutional, Lending, InsurancePrevents context mixingRetailProduct, Orders, Returns, LoyaltyEnsures promotional freshnessResultsAfter implementing Intent-First architecture across telecommunications and healthcare platforms:MetricImpactQuery success rateNearly doubledSupport escalationsReduced by more than halfTime to resolutionReduced approximately 70%User satisfactionImproved roughly 50%Return user rateMore than doubledThe return user rate proved most significant. When search works, users come back. When it fails, they abandon the channel entirely, increasing costs across all other support channels.The strategic imperativeThe conversational AI market will continue to experience hyper growth.But enterprises that build and deploy typical RAG architectures will continue to fail ‚Ä¶ repeatedly.AI will confidently give wrong answers, users will abandon digital channels out of frustration and support costs will go up instead of down.Intent-First is a fundamental shift in how enterprises need to architect and build AI-powered customer conversations. It‚Äôs not about better models or more data. It‚Äôs about understanding what a user wants before you try to help them.The sooner an organization realizes this as an architectural imperative, the sooner they will be able to capture the efficiency gains this technology is supposed to enable. Those that don‚Äôt will be debugging why their AI investments haven‚Äôt been producing expected business outcomes for many years to come.The demo is easy. Production is hard. But the pattern for production success is clear: Intent First.Sreenivasa Reddy Hulebeedu Reddy is a lead software engineer and enterprise architect",
          "content": "The modern customer has just one need that matters: Getting the thing they want when they want it. The old standard RAG model embed+retrieve+LLM misunderstands intent, overloads context and misses freshness, repeatedly sending customers down the wrong paths. Instead, intent-first architecture uses a lightweight language model to parse the query for intent and context, before delivering to the most relevant content sources (documents, APIs, people).Enterprise AI is a speeding train headed for a cliff. Organizations are deploying LLM-powered search applications at a record pace, while a fundamental architectural issue is setting most up for failure.A recent Coveo study revealed that 72% of enterprise search queries fail to deliver meaningful results on the first attempt, while Gartner also predicts that the majority of conversational AI deployments have been falling short of enterprise expectations.The problem isn‚Äôt the underlying models. It‚Äôs the architecture around them.After designing and running live AI-driven customer interaction platforms at scale, serving millions of customer and citizen users at some of the world‚Äôs largest telecommunications and healthcare organizations, I‚Äôve come to see a pattern. It‚Äôs the difference between successful AI-powered interaction deployments and multi-million-dollar failures.It‚Äôs a cloud-native architecture pattern that I call Intent-First. And it‚Äôs reshaping the way enterprises build AI-powered experiences.The $36 pillion problem Gartner projects the global conversational AI market will balloon to $36 billion by 2032. Enterprises are scrambling to get a slice. The demos are irresistible. Plug your LLM into your knowledge base, and suddenly it can answer customer questions in natural language.Magic. Then production happens. A major telecommunications provider I work with rolled out a RAG system with the expectation of driving down the support call rate. Instead, the rate increased. Callers tried AI-powered search, were provided incorrect answers with a high degree of confidence and called customer support angrier than before.This pattern is repeated over and over. In healthcare, customer-facing AI assistants are providing patients with formulary information that‚Äôs outdated by weeks or months. Financial services chatbots are spitting out answers from both retail and institutional product content. Retailers are seeing discontinued products surface in product searches.The issue isn‚Äôt a failure of AI technology. It‚Äôs a failure of architectureWhy standard RAG architectures fail The standard RAG pattern ‚Äî embedding the query, retrieving semantically similar content, passing to an LLM ‚Äîworks beautifully in demos and proof of concepts. But it falls apart in production use cases for three systematic reasons:1. The intent gapIntent is not context. But standard RAG architectures don‚Äôt account for this.Say a customer types ‚ÄúI want to cancel‚Äù What does that mean? Cancel a service? Cancel an order? Cancel an appointment? During our telecommunications deployment, we found that 65% of queries for ‚Äúcancel‚Äù were actually about orders or appointments, not service cancellation. The RAG system had no way of understanding this intent, so it consistently returned service cancellation documents.Intent matters. In healthcare, if a patient is typing ‚ÄúI need to cancel‚Äù because they&#x27;re trying to cancel an appointment, a prescription refill or a procedure, routing them to medication content from scheduling is not only frustrating ‚Äî it&#x27;s also dangerous.2. Context flood Enterprise knowledge and experience is vast, spanning dozens of sources such as product catalogs, billing, support articles, policies, promotions and account data. Standard RAG models treat all of it the same, searching all for every query.When a customer asks ‚ÄúHow do I activate my new phone,‚Äù they don‚Äôt care about billing FAQs, store locations or network status updates. But a standard RAG model retrieves semantically similar content from every source, returning search results that are a half-steps off the mark.3. Freshness blindspot Vector space is timeblind. Semantically, last quarter‚Äôs promotion is identical to this quarter‚Äôs. But presenting customers with outdated offers shatters trust. We linked a significant percentage of customer complaints to search results that surfaced expired products, offers, or features.The Intent-First architecture pattern The Intent-First architecture pattern is the mirror image of the standard RAG deployment. In the RAG model, you retrieve, then route. In the Intent-First model, you classify before you route or retrieve. Intent-First architectures use a lightweight language model to parse a query for intent and context, before dispatching to the most relevant content sources (documents, APIs, agents).Comparison: Intent-first vs standard RAGCloud-native implementationThe Intent-First pattern is designed for cloud-native deployment, leveraging microservices, containerization and elastic scaling to handle enterprise traffic patterns.Intent classification serviceThe classifier determines user intent before any retrieval occurs:ALGORITHM: Intent ClassificationINPUT: user_query (string)OUTPUT: intent_result (object)1. PREPROCESS query (normalize, expand contractions)2. CLASSIFY using transformer model: - primary_intent ‚Üê model.predict(query) - confidence ‚Üê model.confidence_score()3. IF confidence < 0.70 THEN - RETURN { requires_clarification: true, suggested_question: generate_clarifying_question(query) }4. EXTRACT sub_intent based on primary_intent: - IF primary = \"ACCOUNT\" ‚Üí check for ORDER_STATUS, PROFILE, etc. - IF primary = \"SUPPORT\" ‚Üí check for DEVICE_ISSUE, NETWORK, etc. - IF primary = \"BILLING\" ‚Üí check for PAYMENT, DISPUTE, etc.5. DETERMINE target_sources based on intent mapping: - ORDER_STATUS ‚Üí [orders_db, order_faq] - DEVICE_ISSUE ‚Üí [troubleshooting_kb, device_guides] - MEDICATION ‚Üí [formulary, clinical_docs] (healthcare)6. RETURN { primary_intent, sub_intent, confidence, target_sources, requires_personalization: true/false }Context-aware retrieval serviceOnce intent is classified, retrieval becomes targeted:ALGORITHM: Context-Aware RetrievalINPUT: query, intent_result, user_contextOUTPUT: ranked_documents1. GET source_config for intent_result.sub_intent: - primary_sources ‚Üê sources to search - excluded_sources ‚Üê sources to skip - freshness_days ‚Üê max content age2. IF intent requires personalization AND user is authenticated: - FETCH account_context from Account Service - IF intent = ORDER_STATUS: - FETCH recent_orders (last 60 days) - ADD to results3. BUILD search filters: - content_types ‚Üê primary_sources only - max_age ‚Üê freshness_days - user_context ‚Üê account_context (if available)4. FOR EACH source IN primary_sources: - documents ‚Üê vector_search(query, source, filters) - ADD documents to results5. SCORE each document: - relevance_score ‚Üê vector_similarity √ó 0.40 - recency_score ‚Üê freshness_weight √ó 0.20 - personalization_score ‚Üê user_match √ó 0.25 - intent_match_score ‚Üê type_match √ó 0.15 - total_score ‚Üê SUM of above6. RANK by total_score descending7. RETURN top 10 documentsHealthcare-specific considerationsIn healthcare deployments, the Intent-First pattern includes additional safeguards:Healthcare intent categories:Clinical: Medication questions, symptoms, care instructionsCoverage: Benefits, prior authorization, formularyScheduling: Appointments, provider availabilityBilling: Claims, payments, statementsAccount: Profile, dependents, ID cardsCritical safeguard: Clinical queries always include disclaimers and never replace professional medical advice. The system routes complex clinical questions to human support.Handling edge casesThe edge cases are where systems fail. The Intent-First pattern includes specific handlers:Frustration detection keywords:Anger: \"terrible,\" \"worst,\" \"hate,\" \"ridiculous\"Time: \"hours,\" \"days,\" \"still waiting\"Failure: \"useless,\" \"no help,\" \"doesn&#x27;t work\"Escalation: \"speak to human,\" \"real person,\" \"manager\"When frustration is detected, skip search entirely and route to human support.Cross-industry applicationsThe Intent-First pattern applies wherever enterprises deploy conversational AI over heterogeneous content:IndustryIntent categoriesKey benefitTelecommunicationsSales, Support, Billing, Account, RetentionPrevents \"cancel\" misclassificationHealthcareClinical, Coverage, Scheduling, BillingSeparates clinical from administrativeFinancial servicesRetail, Institutional, Lending, InsurancePrevents context mixingRetailProduct, Orders, Returns, LoyaltyEnsures promotional freshnessResultsAfter implementing Intent-First architecture across telecommunications and healthcare platforms:MetricImpactQuery success rateNearly doubledSupport escalationsReduced by more than halfTime to resolutionReduced approximately 70%User satisfactionImproved roughly 50%Return user rateMore than doubledThe return user rate proved most significant. When search works, users come back. When it fails, they abandon the channel entirely, increasing costs across all other support channels.The strategic imperativeThe conversational AI market will continue to experience hyper growth.But enterprises that build and deploy typical RAG architectures will continue to fail ‚Ä¶ repeatedly.AI will confidently give wrong answers, users will abandon digital channels out of frustration and support costs will go up instead of down.Intent-First is a fundamental shift in how enterprises need to architect and build AI-powered customer conversations. It‚Äôs not about better models or more data. It‚Äôs about understanding what a user wants before you try to help them.The sooner an organization realizes this as an architectural imperative, the sooner they will be able to capture the efficiency gains this technology is supposed to enable. Those that don‚Äôt will be debugging why their AI investments haven‚Äôt been producing expected business outcomes for many years to come.The demo is easy. Production is hard. But the pattern for production success is clear: Intent First.Sreenivasa Reddy Hulebeedu Reddy is a lead software engineer and enterprise architect",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4RG14xD3FBupJCjwyfXnRQ/189358d225f858df792c92c95ee93bd1/Conversational_AI.webp?w=300&q=30"
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/chatgpt-how-to-3.jpg",
      "popularity_score": 2018.6868380555557
    },
    {
      "id": "cluster_46",
      "coverage": 2,
      "updated_at": "Mon, 26 Jan 2026 11:10:01 -0500",
      "title": "Microsoft unveils the Maia 200, its 2nd-generation AI accelerator built on TSMC's 3nm process, deploying today in its Azure US Central data center region (Tom Warren/The Verge)",
      "neutral_headline": "Microsoft‚Äôs latest AI chip goes head-to-head with Amazon and Google",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260126/p26#a260126p26",
          "published_at": "Mon, 26 Jan 2026 11:10:01 -0500",
          "title": "Microsoft unveils the Maia 200, its 2nd-generation AI accelerator built on TSMC's 3nm process, deploying today in its Azure US Central data center region (Tom Warren/The Verge)",
          "standfirst": "Tom Warren / The Verge: Microsoft unveils the Maia 200, its 2nd-generation AI accelerator built on TSMC's 3nm process, deploying today in its Azure US Central data center region &mdash; The Maia 200 chip is starting to roll out to Microsoft's data centers today. &hellip; Microsoft is announcing a successor to its first in-house AI chip today, the Maia 200.",
          "content": "Tom Warren / The Verge: Microsoft unveils the Maia 200, its 2nd-generation AI accelerator built on TSMC's 3nm process, deploying today in its Azure US Central data center region &mdash; The Maia 200 chip is starting to roll out to Microsoft's data centers today. &hellip; Microsoft is announcing a successor to its first in-house AI chip today, the Maia 200.",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/260126/i26.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/867670/microsoft-maia-200-ai-chip-announcement",
          "published_at": "2026-01-26T11:00:00-05:00",
          "title": "Microsoft‚Äôs latest AI chip goes head-to-head with Amazon and Google",
          "standfirst": "Microsoft is announcing a successor to its first in-house AI chip today, the Maia 200. Built on TSMC's 3nm process, Microsoft says its Maia 200 AI accelerator \"delivers 3 times the FP4 performance of the third generation Amazon Trainium, and FP8 performance above Google's seventh generation TPU.\" Each Maia 200 chip has more than 100 [&#8230;]",
          "content": "Microsoft is announcing a successor to its first in-house AI chip today, the Maia 200. Built on TSMC's 3nm process, Microsoft says its Maia 200 AI accelerator \"delivers 3 times the FP4 performance of the third generation Amazon Trainium, and FP8 performance above Google's seventh generation TPU.\" Each Maia 200 chip has more than 100 billion transistors, which are all designed to handle large-scale AI workloads. \"Maia 200 can effortlessly run today's largest models, with plenty of headroom for even bigger models in the future,\" says Scott Guthrie, executive vice president of Microsoft's Cloud and AI division. Microsoft will use Maia 200 to ‚Ä¶ Read the full story at The Verge.",
          "feed_position": 9
        }
      ],
      "featured_image": "http://www.techmeme.com/260126/i26.jpg",
      "popularity_score": 2016.7704491666666
    },
    {
      "id": "cluster_6",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 18:29:08 +0000",
      "title": "How to encrypt your PC's disk without giving the keys to Microsoft",
      "neutral_headline": "How to encrypt your PC's disk without giving the keys to Microsoft",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/how-to-encrypt-your-pcs-disk-without-giving-the-keys-to-microsoft/",
          "published_at": "Mon, 26 Jan 2026 18:29:08 +0000",
          "title": "How to encrypt your PC's disk without giving the keys to Microsoft",
          "standfirst": "Storing recovery keys with Microsoft allows the company to unlock your disk.",
          "content": "In early 2025, Forbes reports, investigators at the FBI served Microsoft with a warrant seeking the BitLocker encryption recovery keys for several laptops it believed held evidence of fraud in Guam's COVID-19 unemployment assistance program. And Microsoft complied with the FBI's request. BitLocker is the name of the full-disk encryption technology that has been part of Windows for nearly two decades. Though initially only available to owners of the Pro editions of Windows who turned it on manually, during the Windows 8 era Microsoft began using BitLocker to encrypt local disks automatically for all Windows 11 Home and Pro PCs that signed in with a Microsoft account. Using BitLocker in this way also uploads a recovery key for your device to Microsoft's servers‚Äîthis makes it possible to unlock your disk so you don't lose data if something goes wrong with your system, or if you install a CPU upgrade or some other hardware change that breaks BitLocker. But it also (apparently) makes it possible for Microsoft to unlock your disk, too. A Microsoft rep said that the company handled \"around 20\" similar BitLocker recovery key requests from government authorities per year, and that these requests often fail because users haven't stored their recovery keys on Microsoft's servers. Microsoft and other tech companies have generally refused requests to install universal encryption backdoors for law enforcement purposes, and some companies (like Apple) claim to store device encryption keys using another layer of encryption that renders the keys inaccessible to the company.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/win11-pc-2023-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/win11-pc-2023-1152x648.jpeg",
      "popularity_score": 364.0890602777778
    },
    {
      "id": "cluster_11",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 18:05:50 +0000",
      "title": "The brothers meet Yoshi in Super Mario Galaxy Movie trailer",
      "neutral_headline": "The brothers meet Yoshi in Super Mario Galaxy Movie trailer",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/yoshi-joins-the-fun-in-latest-super-mario-galaxy-movie-trailer/",
          "published_at": "Mon, 26 Jan 2026 18:05:50 +0000",
          "title": "The brothers meet Yoshi in Super Mario Galaxy Movie trailer",
          "standfirst": "Toad: \"So some dinosaur just shows up and he's now part of the group. Cool.\"",
          "content": "Universal Pictures and Illumination dropped a new trailer for the upcoming Super Mario Galaxy Movie, and gaming fans will no doubt be delighted at the news that Yoshi, the little green dinosaur, features prominently, along with plenty of other Easter eggs for sharp-eyed fans. As previously reported, the first attempt at a Super Mario movie adaptation in 1993 was notoriously a dismal failure, although it still has its ‚Äô90s-nostalgic fans. But 2023‚Äôs Super Mario Bros. Movie won over gaming fans who were skeptical about another adaptation‚Äîincluding Ars Senior Gaming Editor Kyle Orland. The 2023 film reintroduced Mario and Luigi, two tight-knit but struggling Brooklyn plumbers who got separated when they unexpectedly fell into the fantastical Mushroom Kingdom. Mario sought Princess Peach‚Äôs help to rescue his brother from the evil clutches of Bowser, ruler of the Dark Lands, who was keen to marry Peach and threatened to destroy the Mushroom Kingdom with a Super Star if she refused him. So Peach led Mario on a quest to recruit allies and stop Bowser for good. They succeeded, shrinking Bowser and imprisoning him in a jar. Mario and Luigi moved to the Mushroom Kingdom and continued their plumbing work there.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/mario2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/mario2-1152x648.jpg",
      "popularity_score": 356.70072694444445
    },
    {
      "id": "cluster_45",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 16:13:22 +0000",
      "title": "How to get Doom running on a pair of earbuds",
      "neutral_headline": "How to get Doom running on a pair of earbuds",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/how-to-get-doom-running-on-a-pair-of-earbuds/",
          "published_at": "Mon, 26 Jan 2026 16:13:22 +0000",
          "title": "How to get Doom running on a pair of earbuds",
          "standfirst": "No display? No problem for the UART-to-web-server \"Doombuds\" project.",
          "content": "Over the years, hackers and modders at large have made it their mission to port classic first-person shooter Doom to practically anything with a display. Recently, though, coder Arin Sarkisan has taken the \"Can it Run Doom?\" idea in an unlikely direction: wireless earbuds that aren't designed to output graphics at all. To be clear, this hack doesn't apply to any generic set of earbuds. The \"Doombuds\" project is designed specifically for the PineBuds Pro, which are unique in featuring completely open source firmware and a community-maintained SDK. That means Sarkisan was able to code up a JavaScript interface that uses the earbuds' UART contact pads to send a heavily compressed MJPEG video stream to a web server (via a serial server). The 2.4 MB/s data stream from the UART connection can put out about 22 to 27 frames per second in this format, which is more than enough for a CPU that can only run the game at a maximum of 18 fps anyway.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/PineBuds-Pro-4-1152x648-1769443386.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/PineBuds-Pro-4-1152x648-1769443386.jpg",
      "popularity_score": 331.8262825
    },
    {
      "id": "cluster_42",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 16:23:48 +0000",
      "title": "Data center power outage took out TikTok first weekend under US ownership",
      "neutral_headline": "Data center power outage took out TikTok first weekend under US ownership",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/tiktok-glitches-caused-by-data-center-power-outage-us-joint-venture-says/",
          "published_at": "Mon, 26 Jan 2026 16:23:48 +0000",
          "title": "Data center power outage took out TikTok first weekend under US ownership",
          "standfirst": "US TikTok users experienced a wide range of errors, sparking conspiracies.",
          "content": "TikTok has been glitching for US users since Sunday, and TikTok's new US owners have finally confirmed the cause: a power outage at a US data center. \"Since yesterday we‚Äôve been working to restore our services following a power outage at a US data center impacting TikTok and other apps we operate,\" the TikTok USDS Joint Venture posted on X on Monday morning. \"We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.\" A DownDetector report tracking outages showed problems began early Sunday morning, with the majority of problems seemingly resolved by early Monday. However, The Verge reported that some US users continue to experience issues, including issues logging in, long delays uploading videos, generic content flooding For You pages, problems accessing comments, and other issues.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2257704765-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2257704765-1024x648.jpg",
      "popularity_score": 330.0001713888889
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 14:17:46 +0000",
      "title": "EU launches formal investigation of xAI over Grok's sexualized deepfakes",
      "neutral_headline": "EU launches formal investigation of xAI over Grok's sexualized deepfakes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/eu-launches-formal-investigation-of-xai-over-groks-sexualized-deepfakes/",
          "published_at": "Mon, 26 Jan 2026 14:17:46 +0000",
          "title": "EU launches formal investigation of xAI over Grok's sexualized deepfakes",
          "standfirst": "Elon Musk's company faces fines of up to 6 percent of its daily turnover.",
          "content": "The EU has launched a formal investigation into Elon Musk‚Äôs xAI following a public outcry over how its Grok chatbot spread sexualized images of women and children. The billionaire entrepreneur has come under scrutiny from regulators around the world this month after people began using Grok to generate deepfakes of people without consent. The images were posted on the X social network as well as the separate Grok app, both of which are run by xAI. The probe, announced on Monday under the EU‚Äôs Digital Services Act, will assess if xAI tried to mitigate the risks of deploying Grok‚Äôs tools on X and the proliferation of content that ‚Äúmay amount to child sexual abuse material.‚ÄùRead full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/xai-grok-1152x648-1752596823.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/xai-grok-1152x648-1752596823.jpg",
      "popularity_score": 322.8996158333333
    },
    {
      "id": "cluster_78",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 12:00:57 +0000",
      "title": "Former astronaut on lunar spacesuits: \"I don't think they're great right now\"",
      "neutral_headline": "Former astronaut on lunar spacesuits: \"I don't think they're great right now\"",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/former-astronaut-on-lunar-spacesuits-i-dont-think-theyre-great-right-now/",
          "published_at": "Mon, 26 Jan 2026 12:00:57 +0000",
          "title": "Former astronaut on lunar spacesuits: \"I don't think they're great right now\"",
          "standfirst": "\"These are just the difficulties of designing a spacesuit for the lunar environment.\"",
          "content": "Crew members traveling to the lunar surface on NASA's Artemis missions should be gearing up for a grind. They will wear heavier spacesuits than those worn by the Apollo astronauts, and NASA will ask them to do more than the first Moonwalkers did more than 50 years ago. The Moonwalking experience will amount to an \"extreme physical event\" for crews selected for the Artemis program's first lunar landings, a former NASA astronaut told a panel of researchers, physicians, and engineers convened by the National Academies. Kate Rubins, who retired from the space agency last year, presented the committee with her views on the health risks for astronauts on lunar missions. She outlined the concerns NASA officials often talk about: radiation exposure, muscle and bone atrophy, reduced cardiovascular and immune function, and other adverse medical effects of spaceflight.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/jsc2025e077725-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/jsc2025e077725-1152x648.jpg",
      "popularity_score": 303.61933805555554
    },
    {
      "id": "cluster_100",
      "coverage": 1,
      "updated_at": "Sun, 25 Jan 2026 12:00:25 +0000",
      "title": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
      "neutral_headline": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/a-decade-of-star-trek-themed-fart-jokes-the-greatest-generation-podcast-turns-10/",
          "published_at": "Sun, 25 Jan 2026 12:00:25 +0000",
          "title": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
          "standfirst": "How two podcasters turned a Star Trek side project into a full-time career.",
          "content": "A decade is a long time for a TV series; no single iteration of Star Trek has made it that far. But ‚Äúa Star Trek podcast by two guys just a little bit embarrassed to have a Star Trek podcast‚Äù has now passed the milestone. January 25, 2026, marks a full decade since The Greatest Generation, my favorite podcast, debuted. Like a bottle of Ch√¢teau Picard, the show has only improved with age. (I interviewed the guys behind the show back in 2016 when they were just getting started.) The podcast helped me rediscover, and appreciate more fully, Star Trek: The Next Generation‚Äîwhich is also my favorite TV show. The Greatest Generation continues to delight with its irreverent humor, its celebration of the most minor of characters, and its technical fascination with how a given episode was made.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ADAM_BEN_L1560319-1152x648-1769205900.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ADAM_BEN_L1560319-1152x648-1769205900.jpg",
      "popularity_score": 278
    }
  ]
}