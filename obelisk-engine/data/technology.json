{
  "updated_at": "2025-12-10T19:18:41.124Z",
  "clusters": [
    {
      "id": "cluster_13",
      "coverage": 3,
      "updated_at": "Wed, 10 Dec 2025 18:40:58 +0000",
      "title": "Kindle Scribe Colorsoft brings color e-ink to Amazon’s 11-inch e-reader",
      "neutral_headline": "Kindle Scribe Colorsoft brings color e-ink to Amazon’s 11-inch e-reader",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/gadgets/2025/12/kindle-scribe-colorsoft-brings-color-e-ink-to-amazons-11-inch-e-reader/",
          "published_at": "Wed, 10 Dec 2025 18:40:58 +0000",
          "title": "Kindle Scribe Colorsoft brings color e-ink to Amazon’s 11-inch e-reader",
          "standfirst": "Amazon has added color e-ink to its devices more slowly than its competitors.",
          "content": "Amazon has been updating the large-screened Kindle Scribe tablet more frequently and regularly than it updates its standard e-readers, and today the company is announcing the tablet’s third hardware update in four years. The regular Scribe is also being joined by a lower-end Scribe with less storage and no front light and an upgraded Kindle Scribe Colorsoft model with a color e-ink screen. This makes it only the second Kindle to include a color screen, after last year’s Kindle Colorsoft. Both the regular Kindle Scribe and the Kindle Scribe Colorsoft are available to order starting today for $500 and $630, respectively. Both of those devices include a Premium Pen accessory and 32GB of internal storage; 64GB of storage is available for an extra $50 for both devices. The cheaper front light-less Scribe is coming sometime next year and will run $430 for a model with a more modest 16GB of storage. (These are all much more expensive than the original Scribe’s $340 launch price, but inflation, tariffs, and shortages are wreaking havoc with all kinds of tech prices for the past few years.) The Scribe and Scribe Colorsoft both come with an updated front light “with miniaturized LEDs that fit tightly against the display,” narrowing the bezel and improving the uniformity of the lighting. Amazon has also tweaked the friction level of the paper-like texture on the glass display, shrunk the gap between the glass and the actual display panel to make writing on the tablet feel more like writing on paper, and added a quad-core processor and more RAM to speed the tablet up.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/download-1152x648.jpeg"
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251210/p35#a251210p35",
          "published_at": "Wed, 10 Dec 2025 09:30:01 -0500",
          "title": "Amazon Kindle Scribe Colorsoft review: the $630 pen-enabled e-reader is a tough sell for most people, even with its big 11\" display and productivity features (Samantha Kelly/Bloomberg)",
          "standfirst": "Samantha Kelly / Bloomberg: Amazon Kindle Scribe Colorsoft review: the $630 pen-enabled e-reader is a tough sell for most people, even with its big 11\" display and productivity features &mdash; Review: Amazon's $630 pen-enabled device is a tough sell for most people. &mdash; Amazon.com Inc.'s new Kindle Scribe Colorsoft &hellip;",
          "content": "Samantha Kelly / Bloomberg: Amazon Kindle Scribe Colorsoft review: the $630 pen-enabled e-reader is a tough sell for most people, even with its big 11\" display and productivity features &mdash; Review: Amazon's $630 pen-enabled device is a tough sell for most people. &mdash; Amazon.com Inc.'s new Kindle Scribe Colorsoft &hellip;",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/251210/i35.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/review/kindle-scribe-colorsoft-2025/",
          "published_at": "Wed, 10 Dec 2025 14:01:00 +0000",
          "title": "Kindle Scribe Colorsoft and Kindle Scribe (3rd Gen) Review (2025)",
          "standfirst": "Amazon’s latest e-reader and digital notebook combos bring new features, but they may not be enough in a crowded market.",
          "content": "Amazon’s latest e-reader and digital notebook combos bring new features, but they may not be enough in a crowded market.",
          "feed_position": 6,
          "image_url": "https://media.wired.com/photos/6938b15e6714700b8598873d/master/pass/Kindle%20Scribe%20Colorsoft_Kindle%20Scribe%20(3rd%20Gen)%20comparison%20top%20art%20122025%20updated%20SOURCE%20Amazon.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/download-1152x648.jpeg",
      "popularity_score": 3019.3713544444445
    },
    {
      "id": "cluster_1",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 19:08:43 +0000",
      "title": "12 steps you can take right now to be safer online",
      "neutral_headline": "12 steps you can take right now to be safer online",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/12-steps-you-can-take-right-now-to-be-safer-online-130008335.html",
          "published_at": "Wed, 10 Dec 2025 19:08:43 +0000",
          "title": "12 steps you can take right now to be safer online",
          "standfirst": "There's a fundamental question you can ask of both the internet and real life: \"How do I enjoy my time here without taking unnecessary risks?\" In grass-touching meatspace, you can cut out processed foods, carry pepper spray and avoid skydiving without a partner. But the best methods for staying safe online aren't as intuitive. The internet is a massive town square where people are constantly bellowing deeply personal facts about themselves. It's no surprise that it's become a breeding ground for scams, theft and other criminal activity. Given the breadth of dangers, it may feel easier to throw up your hands and say that whatever happens will happen. I'm here to tell you, though, that cybersecurity doesn't have to be complex, difficult or time-consuming. You don't need to be a hacker to foil a hacker — you only have to take advantage of simple tips and free apps designed to make you safer online. Whether you commit to all 12 detailed here or only focus on one, you'll be much more secure for it. 1. Install security updates immediately One of the most important things you can do to ensure your digital security is to install all software updates as soon as they become available on your devices. When you see the notification, don't wait — train yourself to download the update immediately. Not all software updates are about security, but the ones that are form your best line of defense against technical hacks. When developers discover a flaw that can be exploited, they ship an update to fix it. By the time the flaw gets patched, chances are very high that hackers also know about it, so any time lost means you could be the next to get exploited. As you go down this list, you'll learn that cybersecurity threats are less technical than you think. To counter the ones that are, however, there's nothing more important you can do than install security updates. 2. Use strong passwords Weak, easily guessed passwords are one of the most frequent causes of data breaches and malware attacks. If a password is one of the ten or so most common, an attacker may be able to guess it with no other information. If it's connected to you — your birthday, say, or mother's maiden name — it may be guessable from information anyone can look up online. Even if your password is a random string of characters, it might still be guessable if it's too short. Hackers can use programs to guess all possible combinations and try each one on a target account. The longer a password is, the more exponentially difficult it is to guess. SEAN GLADWELL via Getty Images That means you need passwords that are both long and meaningless to you. You might rightly complain that these are bastards to remember, but you're in luck: password managers can do that for you. A password manager app or browser extension can create passwords when you need them, store them securely and fill them in automatically. All you have to remember is the one master password that unlocks all the others. 3. Set up two-factor authentication Even the strongest password might get revealed through no fault of your own, like if it's stored without encryption and leaked in a data breach. That's why it helps to have two-factor authentication (2FA), also known as multi-factor authentication (MFA), as a second secure layer on every account. You probably already know 2FA as the irritating extra step that makes you go get your phone — but that's not the only way to do it. Many apps, including Google and Apple, now let you log in through passkeys. These not only don't require you to enter a code or password, but use asymmetric encryption, sharing credentials between your device and the service that runs the passkeys. It's a lot quicker for you, and leaves nothing to steal. 4. Back everything up Ransomware and its cousins are a growth industry within the cybercrime economy. These attacks corrupt your files or lock you out of them until you pay a fee to get them back. The easiest way to foil a ransomware attack, or to clear any other kind of malware off a device, is to restore the entire system from the most recent backup. To make sure you actually have a backup, experts recommend the 3-2-1 rule: three different backups, on two different types of storage, with at least one physically distant from the main system. For example, you could have one backup on another device in your house, one in the cloud and one on a portable hard drive. Automatic backup services can save disk images for you at set intervals so you don't have to remember to do it yourself. 5. Learn to spot social engineering Despite all the technobabble flying around the cybersecurity world, a great many scams and hacks are accomplished through methods a 19th-century con artist would recognize. Scammers pose as experts or authority figures to gain your trust, and use frightening language to bypass your critical thinking. Ticking clocks, emotional manipulation and fake identities are all in the toolbox. Alex Cristi via Getty Images Take phishing, in which hackers trick you into giving up your information willingly. A typical phishing email might pose as a bank, credit bureau or other authoritative service. In red letters, it may demand your bank password or social security number to immediately fix an irregularity with your account. Other common approaches include warning you about speeding tickets you never incurred or sending receipts for subscriptions you never bought. Social engineering attacks are constantly evolving, but they often fall back on the same strategies. The best way to foil them is to take a deep breath every time you receive a frightening email or text message, then research it in detail: look up the email address, check the visual design to make sure the sender is who they claim to be, and ask yourself if there's any way the message could be true. I highly recommend working through this phishing quiz — it's tough, but fair, and extremely educational. 6. Always check links before clicking This is a companion to the previous tip. Social engineering scams don't always try to get you to give up information yourself. They also get you to click on links that put secret malware on your device — like keyloggers that watch you type your passwords or ransomware programs that corrupt your files. If you're ever not sure about an email attachment or a link you're being asked to click, copy the link (without opening it) and paste it into a URL checker like this one from NordVPN. These free tools can tell you if a link is associated with any known malware domains. Sam Chapman for Engadget You can also mouse over any link, then look at the bottom-left of your browser to see what URL it will take you to. If an email is from your bank, any links within it should go to your bank's website. If it's going anywhere else, especially to an unidentifiable string of characters, be suspicious. A related tip is to never copy and paste something into your URL bar if you aren't absolutely sure of what it will do. Social engineering doesn't always get you to click the link — sometimes attackers leave it un-hyperlinked so mousing over it doesn't reveal anything. This also goes for the command modules on desktop and laptop computers. In a recent documented attack, hackers convinced AI chatbots to suggest a command that gave them root access to the victim's device. Never copy-paste anything into the command window without verifying it first, especially if an AI told you to do it. 7. Don't overshare Over the last two decades, lots of us have gotten into the habit of dumping all sorts of personal information on social media. This trend has supercharged the scam economy. It may seem harmless to broadcast the names of your kids or the dates you'll be on vacation, but every piece of data you put into the world makes it easier for a stranger to get hooks into you. For example, \"grandparent scams\" are on the rise right now. Grifters contact a target, usually a senior, pretending to be their grandchild. They'll claim to be in a crisis and need money fast. The more information they have on their target, the more convincing their tale of woe will be. Social media is a prime place to study a potential victim. Oversharing can also be a compounding problem. If you use weak passwords, your public information can be used to guess your credentials or answer your security questions. So, if you don't have a password manager yet, think twice before you engage with that quiz post on Facebook that asks for the name of your childhood pet. 8. Use a VPN I'm a big booster of virtual private networks (VPNs), but it's important to be realistic about what they can and can't do. Even the best VPNs aren't total cybersecurity solutions — you can't just set one and assume you're safe forever. A VPN can't protect you if you use easily guessed passwords, for example, or click on a malware link. It's about hiding your identity, not making you invulnerable. So what can a VPN do? In short, it replaces your IP address (a fingerprint that identifies you online) with another IP address, belonging to a server owned by the VPN. The VPN server does business with the internet on your behalf, while its conversations with your device are encrypted so it can't be traced back to you. Sam Chapman for Engadget This means no third party can connect your online actions with your real-world identity. Nobody will be harvesting data on the websites you visit to sell to advertisers, nor building a file on you that an unscrupulous government might misuse. VPNs also protect you from fake public Wi-Fi networks set up by cybercriminals — even if a hacker tricks you with a man-in-the-middle attack, they can't do much without your real IP address. Many top VPNs, including my top pick Proton VPN, include ad blockers that can also keep cookies and tracking pixels from latching onto you. So, even if a VPN can't do everything, you'll be far safer and more private with one than without one. If you don’t want to pay for a new subscription right now, I've also compiled a list of the best free VPNs that are actually safe to use. 9. Run regular virus scans The most important time to look for malware is when you're downloading a file from the internet. Not only can unwanted apps hitch rides on seemingly safe files, but links can start downloads in secret, even if you don't think they're meant to be downloading anything. A solid antivirus program can catch malware as it arrives on your system, and if it's uncertain, can lock suspicious files in quarantine until it knows whether they're safe or not. Dedicated antivirus apps are sometimes even capable of catching malware that hasn't been seen or used yet. AV software uses machine learning to identify the common patterns of malware, filtering out new viruses that behave like old ones. But what about malware that's already gotten through the perimeter? An antivirus app can also check your computer at set intervals in search of unwanted apps, including those that might be masquerading as system files. Windows computers now come pre-installed with Windows Defender, which is enough to handle most of these tasks, but I recommend at least one anti-malware program on any device. 10. Use email maskers and private search engines If you're concerned about your information being misused or mishandled, remember that the less you put out into the world, the less danger you're in. Keeping your private data off social media is one important step, but there are other ways your data gets disseminated — and other options for responding. For example, you often need an email address to sign up for an online account. If you use your real email, your contact information is now floating around online, increasing the chance of someone using it to scam you (or at least adding you to mailing lists you never signed up for). To stay safe, use an email masker. These services give you a fake email address you can use to create accounts, which automatically forwards messages to your real address. Sam Chapman for Engadget Search engines, especially Google, are also notorious for building profiles on users by watching the terms they search for. You can dodge that by switching to a private search engine like DuckDuckGo, which doesn't track anything you do — it's funded by non-targeted ad sales on its search results pages, not by selling your data to brokers. 11. Use a data removal service Speaking of data brokers: unfortunately, if you've been on the internet at any point in the last 10 years without taking intense precautions, your data is probably in the hands of at least one business that makes money by hoarding and selling it. These data brokers range from public-facing, people-search sites to private backend dealers. Data brokers are poorly regulated and lax about safety. The longer one has your personal information, the more likely it is to leak. The good news is that most brokers (though not all of them) are legally required to delete your data if you ask them to. However, there are a lot of data brokers out there, and they really want to keep your data. Each one makes opting out harder than uninstalling a Norton product — and hundreds of them may have files on you. To make the process easier, you can use a data removal service like DeleteMe or Surfshark VPN's partner service Incogni. 12. Practice physical security Let's close out the list by getting a little old school. I've already discussed how many online scams depend on classic con artistry to work. By the same token, physical infiltration and smash-and-grab tactics still pose a threat to cybersecurity. It doesn't take too much imagination to see how this could work. If you leave your laptop or phone unattended in public, for example, someone might insert a flash drive that loads malware onto the system. In one illustrative case, a thief in the Minneapolis area would loiter in bars, watch people unlock their phones, then steal those phones and unlock them himself. I'm not saying you need to be paranoid every second you're in public. Just use the same level of caution you'd use to protect your car. Lock your phone with a biometric key so only you can open it, and make sure not to leave any device lying around if it can access your online accounts. And at work, be careful not to let anyone into a secure area if they don't have the proper credentials.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/12-steps-you-can-take-right-now-to-be-safer-online-130008335.html?src=rss",
          "content": "There's a fundamental question you can ask of both the internet and real life: \"How do I enjoy my time here without taking unnecessary risks?\" In grass-touching meatspace, you can cut out processed foods, carry pepper spray and avoid skydiving without a partner. But the best methods for staying safe online aren't as intuitive. The internet is a massive town square where people are constantly bellowing deeply personal facts about themselves. It's no surprise that it's become a breeding ground for scams, theft and other criminal activity. Given the breadth of dangers, it may feel easier to throw up your hands and say that whatever happens will happen. I'm here to tell you, though, that cybersecurity doesn't have to be complex, difficult or time-consuming. You don't need to be a hacker to foil a hacker — you only have to take advantage of simple tips and free apps designed to make you safer online. Whether you commit to all 12 detailed here or only focus on one, you'll be much more secure for it. 1. Install security updates immediately One of the most important things you can do to ensure your digital security is to install all software updates as soon as they become available on your devices. When you see the notification, don't wait — train yourself to download the update immediately. Not all software updates are about security, but the ones that are form your best line of defense against technical hacks. When developers discover a flaw that can be exploited, they ship an update to fix it. By the time the flaw gets patched, chances are very high that hackers also know about it, so any time lost means you could be the next to get exploited. As you go down this list, you'll learn that cybersecurity threats are less technical than you think. To counter the ones that are, however, there's nothing more important you can do than install security updates. 2. Use strong passwords Weak, easily guessed passwords are one of the most frequent causes of data breaches and malware attacks. If a password is one of the ten or so most common, an attacker may be able to guess it with no other information. If it's connected to you — your birthday, say, or mother's maiden name — it may be guessable from information anyone can look up online. Even if your password is a random string of characters, it might still be guessable if it's too short. Hackers can use programs to guess all possible combinations and try each one on a target account. The longer a password is, the more exponentially difficult it is to guess. SEAN GLADWELL via Getty Images That means you need passwords that are both long and meaningless to you. You might rightly complain that these are bastards to remember, but you're in luck: password managers can do that for you. A password manager app or browser extension can create passwords when you need them, store them securely and fill them in automatically. All you have to remember is the one master password that unlocks all the others. 3. Set up two-factor authentication Even the strongest password might get revealed through no fault of your own, like if it's stored without encryption and leaked in a data breach. That's why it helps to have two-factor authentication (2FA), also known as multi-factor authentication (MFA), as a second secure layer on every account. You probably already know 2FA as the irritating extra step that makes you go get your phone — but that's not the only way to do it. Many apps, including Google and Apple, now let you log in through passkeys. These not only don't require you to enter a code or password, but use asymmetric encryption, sharing credentials between your device and the service that runs the passkeys. It's a lot quicker for you, and leaves nothing to steal. 4. Back everything up Ransomware and its cousins are a growth industry within the cybercrime economy. These attacks corrupt your files or lock you out of them until you pay a fee to get them back. The easiest way to foil a ransomware attack, or to clear any other kind of malware off a device, is to restore the entire system from the most recent backup. To make sure you actually have a backup, experts recommend the 3-2-1 rule: three different backups, on two different types of storage, with at least one physically distant from the main system. For example, you could have one backup on another device in your house, one in the cloud and one on a portable hard drive. Automatic backup services can save disk images for you at set intervals so you don't have to remember to do it yourself. 5. Learn to spot social engineering Despite all the technobabble flying around the cybersecurity world, a great many scams and hacks are accomplished through methods a 19th-century con artist would recognize. Scammers pose as experts or authority figures to gain your trust, and use frightening language to bypass your critical thinking. Ticking clocks, emotional manipulation and fake identities are all in the toolbox. Alex Cristi via Getty Images Take phishing, in which hackers trick you into giving up your information willingly. A typical phishing email might pose as a bank, credit bureau or other authoritative service. In red letters, it may demand your bank password or social security number to immediately fix an irregularity with your account. Other common approaches include warning you about speeding tickets you never incurred or sending receipts for subscriptions you never bought. Social engineering attacks are constantly evolving, but they often fall back on the same strategies. The best way to foil them is to take a deep breath every time you receive a frightening email or text message, then research it in detail: look up the email address, check the visual design to make sure the sender is who they claim to be, and ask yourself if there's any way the message could be true. I highly recommend working through this phishing quiz — it's tough, but fair, and extremely educational. 6. Always check links before clicking This is a companion to the previous tip. Social engineering scams don't always try to get you to give up information yourself. They also get you to click on links that put secret malware on your device — like keyloggers that watch you type your passwords or ransomware programs that corrupt your files. If you're ever not sure about an email attachment or a link you're being asked to click, copy the link (without opening it) and paste it into a URL checker like this one from NordVPN. These free tools can tell you if a link is associated with any known malware domains. Sam Chapman for Engadget You can also mouse over any link, then look at the bottom-left of your browser to see what URL it will take you to. If an email is from your bank, any links within it should go to your bank's website. If it's going anywhere else, especially to an unidentifiable string of characters, be suspicious. A related tip is to never copy and paste something into your URL bar if you aren't absolutely sure of what it will do. Social engineering doesn't always get you to click the link — sometimes attackers leave it un-hyperlinked so mousing over it doesn't reveal anything. This also goes for the command modules on desktop and laptop computers. In a recent documented attack, hackers convinced AI chatbots to suggest a command that gave them root access to the victim's device. Never copy-paste anything into the command window without verifying it first, especially if an AI told you to do it. 7. Don't overshare Over the last two decades, lots of us have gotten into the habit of dumping all sorts of personal information on social media. This trend has supercharged the scam economy. It may seem harmless to broadcast the names of your kids or the dates you'll be on vacation, but every piece of data you put into the world makes it easier for a stranger to get hooks into you. For example, \"grandparent scams\" are on the rise right now. Grifters contact a target, usually a senior, pretending to be their grandchild. They'll claim to be in a crisis and need money fast. The more information they have on their target, the more convincing their tale of woe will be. Social media is a prime place to study a potential victim. Oversharing can also be a compounding problem. If you use weak passwords, your public information can be used to guess your credentials or answer your security questions. So, if you don't have a password manager yet, think twice before you engage with that quiz post on Facebook that asks for the name of your childhood pet. 8. Use a VPN I'm a big booster of virtual private networks (VPNs), but it's important to be realistic about what they can and can't do. Even the best VPNs aren't total cybersecurity solutions — you can't just set one and assume you're safe forever. A VPN can't protect you if you use easily guessed passwords, for example, or click on a malware link. It's about hiding your identity, not making you invulnerable. So what can a VPN do? In short, it replaces your IP address (a fingerprint that identifies you online) with another IP address, belonging to a server owned by the VPN. The VPN server does business with the internet on your behalf, while its conversations with your device are encrypted so it can't be traced back to you. Sam Chapman for Engadget This means no third party can connect your online actions with your real-world identity. Nobody will be harvesting data on the websites you visit to sell to advertisers, nor building a file on you that an unscrupulous government might misuse. VPNs also protect you from fake public Wi-Fi networks set up by cybercriminals — even if a hacker tricks you with a man-in-the-middle attack, they can't do much without your real IP address. Many top VPNs, including my top pick Proton VPN, include ad blockers that can also keep cookies and tracking pixels from latching onto you. So, even if a VPN can't do everything, you'll be far safer and more private with one than without one. If you don’t want to pay for a new subscription right now, I've also compiled a list of the best free VPNs that are actually safe to use. 9. Run regular virus scans The most important time to look for malware is when you're downloading a file from the internet. Not only can unwanted apps hitch rides on seemingly safe files, but links can start downloads in secret, even if you don't think they're meant to be downloading anything. A solid antivirus program can catch malware as it arrives on your system, and if it's uncertain, can lock suspicious files in quarantine until it knows whether they're safe or not. Dedicated antivirus apps are sometimes even capable of catching malware that hasn't been seen or used yet. AV software uses machine learning to identify the common patterns of malware, filtering out new viruses that behave like old ones. But what about malware that's already gotten through the perimeter? An antivirus app can also check your computer at set intervals in search of unwanted apps, including those that might be masquerading as system files. Windows computers now come pre-installed with Windows Defender, which is enough to handle most of these tasks, but I recommend at least one anti-malware program on any device. 10. Use email maskers and private search engines If you're concerned about your information being misused or mishandled, remember that the less you put out into the world, the less danger you're in. Keeping your private data off social media is one important step, but there are other ways your data gets disseminated — and other options for responding. For example, you often need an email address to sign up for an online account. If you use your real email, your contact information is now floating around online, increasing the chance of someone using it to scam you (or at least adding you to mailing lists you never signed up for). To stay safe, use an email masker. These services give you a fake email address you can use to create accounts, which automatically forwards messages to your real address. Sam Chapman for Engadget Search engines, especially Google, are also notorious for building profiles on users by watching the terms they search for. You can dodge that by switching to a private search engine like DuckDuckGo, which doesn't track anything you do — it's funded by non-targeted ad sales on its search results pages, not by selling your data to brokers. 11. Use a data removal service Speaking of data brokers: unfortunately, if you've been on the internet at any point in the last 10 years without taking intense precautions, your data is probably in the hands of at least one business that makes money by hoarding and selling it. These data brokers range from public-facing, people-search sites to private backend dealers. Data brokers are poorly regulated and lax about safety. The longer one has your personal information, the more likely it is to leak. The good news is that most brokers (though not all of them) are legally required to delete your data if you ask them to. However, there are a lot of data brokers out there, and they really want to keep your data. Each one makes opting out harder than uninstalling a Norton product — and hundreds of them may have files on you. To make the process easier, you can use a data removal service like DeleteMe or Surfshark VPN's partner service Incogni. 12. Practice physical security Let's close out the list by getting a little old school. I've already discussed how many online scams depend on classic con artistry to work. By the same token, physical infiltration and smash-and-grab tactics still pose a threat to cybersecurity. It doesn't take too much imagination to see how this could work. If you leave your laptop or phone unattended in public, for example, someone might insert a flash drive that loads malware onto the system. In one illustrative case, a thief in the Minneapolis area would loiter in bars, watch people unlock their phones, then steal those phones and unlock them himself. I'm not saying you need to be paranoid every second you're in public. Just use the same level of caution you'd use to protect your car. Lock your phone with a biometric key so only you can open it, and make sure not to leave any device lying around if it can access your online accounts. And at work, be careful not to let anyone into a secure area if they don't have the proper credentials.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/12-steps-you-can-take-right-now-to-be-safer-online-130008335.html?src=rss",
          "feed_position": 0,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-05/953644c0-f013-11ed-8bdf-a2cfeb7310a6"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/hackers-tricked-chatgpt-grok-and-google-into-helping-them-install-malware-185711492.html",
          "published_at": "Wed, 10 Dec 2025 18:57:11 +0000",
          "title": "Hackers tricked ChatGPT, Grok and Google into helping them install malware",
          "standfirst": "Ever since reporting earlier this year on how easy it is to trick an agentic browser, I've been following the intersections between modern AI and old-school scams. Now, there's a new convergence on the horizon: hackers are apparently using AI prompts to seed Google search results with dangerous commands. When executed by unknowing users, these commands prompt computers to give the hackers the access they need to install malware. The warning comes by way of a recent report from detection-and-response firm Huntress. Here's how it works. First, the threat actor has a conversation with an AI assistant about a common search term, during which they prompt the AI to suggest pasting a certain command into a computer's terminal. They make the chat publicly visible and pay to boost it on Google. From then on, whenever someone searches for the term, the malicious instructions will show up high on the first page of results. Huntress ran tests on both ChatGPT and Grok after discovering that a Mac-targeting data exfiltration attack called AMOS had originated from a simple Google search. The user of the infected device had searched \"clear disk space on Mac,\" clicked a sponsored ChatGPT link and — lacking the training to see that the advice was hostile — executed the command. This let the attackers install the AMOS malware. The testers discovered that both chatbots replicated the attack vector. As Huntress points out, the evil genius of this attack is that it bypasses almost all the traditional red flags we've been taught to look for. The victim doesn't have to download a file, install a suspicious executable or even click a shady link. The only things they have to trust are Google and ChatGPT, which they've either used before or heard about nonstop for the last several years. They're primed to trust what those sources tell them. Even worse, while the link to the ChatGPT conversation has since been taken off Google, it was up for at least half a day after Huntress published their blog post. This news comes at a time that's already fraught for both AIs. Grok has been getting dunked on for sucking up to Elon Musk in despicable ways, while ChatGPT creator OpenAI has been falling behind the competition. It's not yet clear if the attack can be replicated with other chatbots, but for now, I strongly recommend using caution. Alongside your other common-sense cybersecurity steps, make sure to never paste anything into your command terminal or your browser URL bar if you aren't certain of what it will do.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/hackers-tricked-chatgpt-grok-and-google-into-helping-them-install-malware-185711492.html?src=rss",
          "content": "Ever since reporting earlier this year on how easy it is to trick an agentic browser, I've been following the intersections between modern AI and old-school scams. Now, there's a new convergence on the horizon: hackers are apparently using AI prompts to seed Google search results with dangerous commands. When executed by unknowing users, these commands prompt computers to give the hackers the access they need to install malware. The warning comes by way of a recent report from detection-and-response firm Huntress. Here's how it works. First, the threat actor has a conversation with an AI assistant about a common search term, during which they prompt the AI to suggest pasting a certain command into a computer's terminal. They make the chat publicly visible and pay to boost it on Google. From then on, whenever someone searches for the term, the malicious instructions will show up high on the first page of results. Huntress ran tests on both ChatGPT and Grok after discovering that a Mac-targeting data exfiltration attack called AMOS had originated from a simple Google search. The user of the infected device had searched \"clear disk space on Mac,\" clicked a sponsored ChatGPT link and — lacking the training to see that the advice was hostile — executed the command. This let the attackers install the AMOS malware. The testers discovered that both chatbots replicated the attack vector. As Huntress points out, the evil genius of this attack is that it bypasses almost all the traditional red flags we've been taught to look for. The victim doesn't have to download a file, install a suspicious executable or even click a shady link. The only things they have to trust are Google and ChatGPT, which they've either used before or heard about nonstop for the last several years. They're primed to trust what those sources tell them. Even worse, while the link to the ChatGPT conversation has since been taken off Google, it was up for at least half a day after Huntress published their blog post. This news comes at a time that's already fraught for both AIs. Grok has been getting dunked on for sucking up to Elon Musk in despicable ways, while ChatGPT creator OpenAI has been falling behind the competition. It's not yet clear if the attack can be replicated with other chatbots, but for now, I strongly recommend using caution. Alongside your other common-sense cybersecurity steps, make sure to never paste anything into your command terminal or your browser URL bar if you aren't certain of what it will do.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/hackers-tricked-chatgpt-grok-and-google-into-helping-them-install-malware-185711492.html?src=rss",
          "feed_position": 2
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html",
          "published_at": "Wed, 10 Dec 2025 17:29:06 +0000",
          "title": "The best VPN deals: Up to 88 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "With a good virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart those online trackers that watch you sleep and show you weird personalized ads. Although we strongly recommend using a VPN, you shouldn't jump on just any deal — a bit of comparison shopping goes a long way in this market. The pricing you see on VPN websites is often not an accurate portrayal of what you'll actually pay. Even so, there are some great bargains on the table. Black Friday and Cyber Monday may be over, but lots of the best VPNs — including our top pick, Proton VPN — have end-of-year deals live that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're sure you like the service, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals below follow that pattern, so make sure you're comfortable with a service before you take the plunge. Read on for the best VPN deals live this week. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This holiday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another holiday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "content": "With a good virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart those online trackers that watch you sleep and show you weird personalized ads. Although we strongly recommend using a VPN, you shouldn't jump on just any deal — a bit of comparison shopping goes a long way in this market. The pricing you see on VPN websites is often not an accurate portrayal of what you'll actually pay. Even so, there are some great bargains on the table. Black Friday and Cyber Monday may be over, but lots of the best VPNs — including our top pick, Proton VPN — have end-of-year deals live that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're sure you like the service, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals below follow that pattern, so make sure you're comfortable with a service before you take the plunge. Read on for the best VPN deals live this week. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This holiday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another holiday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openais-house-of-cards-seems-primed-to-collapse-170000900.html",
          "published_at": "Wed, 10 Dec 2025 17:00:00 +0000",
          "title": "OpenAI's house of cards seems primed to collapse",
          "standfirst": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago. Back in 2022, the sudden popularity of ChatGPT sent Google into a panic. The company was so worried about the possibility of the upstart chatbot disrupting its Search business, executives sounded a \"code red\" alert inside of the company and called Sergey Brin and Larry Page out of retirement to help it formulate a response to OpenAI. It then rushed out Bard, announcing its first commercial chatbot on February 6, 2023. Google's stock tanked days later when the AI incorrectly answered a question about NASA's James Webb Space Telescope during a public demo. But it wasn't just Google that wanted a piece of OpenAI, while the search giant sought to compete with it, others — including Microsoft and Apple — made deals with the company to bring its technology to their products and services, all the promise that AI would eventually revolutionize every facet of the economy. Since then, OpenAI has seen its lead against Google and much of the AI industry evaporate, culminating in a series of successive blows throughout 2025. On January 20, the same day Altman was busy rubbing shoulders with other tech oligarchs at Donald Trump’s inauguration, China’s DeepSeek quietly released its R1 chain-of-thought model. A week later, the startup's chatbot surpassed ChatGPT as the most-download free app on the US App Store. The overnight success of DeepSeek eliminated $1 trillion worth of stock market value, and almost certainly left OpenAI blindsided.In response, the company showed a newfound urgency. In one week, for instance, OpenAI released both o3-mini and Deep Research. It even went so far as to announce the latter on a Sunday evening. But for all its new urgency, OpenAI's biggest, most important release of the year was a miss. It's safe to say GPT-5 hasn't lived up to anyone's expectations, including OpenAI's own. The company touted the system as smarter, faster and better than all of its previous models, but after users got their hands on it, they complained of a chatbot that made surprisingly dumb mistakes and didn't have much of a personality. For many, GPT-5 felt like a downgrade compared to the older, simpler GPT-4o. That's a position no AI company wants to be in, let alone one that has taken on as much investment as OpenAI. Anthropic was quick to take advantage of the weakness, signing a deal with Microsoft to bring its Claude models to Copilot 365. Previously, Microsoft depended exclusively on OpenAI for partner models in Copilot. Before the company announced the integration, reporting from The Information said Microsoft made the decision based on the strength of Anthropic's Sonnet 4.0 model, judging it \"perform[ed] better in subtle but important ways\" relative to OpenAI's offerings. However, what will likely go down as the defining moment occurred a few short weeks after OpenAI announced the conclusion of its restructuring. On November 18, Google released Gemini 3 Pro, and immediately the new model leap-frogged the competition, including GPT-5. As of the writing of this article, Google's new model is at the top of LMArena, the site where humans compare outputs from different AI systems and vote on the best one. GPT-5, by contrast, is currently ranked sixth overall, behind models from Anthropic and Elon Musk's xAI. According to a December 2 report from The Wall Street Journal, Sam Altman sent a companywide memo following the release of Gemini 3 Pro. Echoing the words Google used to describe the situation it found itself against OpenAI in 2023, he called for a \"code red\" effort to improve ChatGPT. Altman reportedly told employees there would be temporary reassignments and that the company would delay some products, all in an effort to catch up to Google and Anthropic. The few numbers these companies are willing to share don't paint a promising picture for OpenAI. Each month, about 800 million people use ChatGPT. On paper, that's impressive, but Google is catching up there too. In October, the company said the Gemini app had 650 million users, up from 450 million just a few months earlier in July, thanks to the popularity of its Nano Banana Pro image generator. More importantly, OpenAI has an inherent disadvantage against Google. For the search giant, AI may touch everything the company does now, but Gemini is just one product in an extensive portfolio that includes many other popular services. Google can fund its AI advancements with money it makes elsewhere. OpenAI cannot say the same. The company is constantly raising money to stay afloat, and according to a financial roadmap obtained by The Journal, it will need its revenue to grow to about $200 billion annually to become profitable by 2030. In November, Altman said on X the company was on track to hit above $20 billion in annualized revenue this year. In an effort to grow revenue, Altman and company have adopted an incredibly risky strategy. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals in a bid to outscale the competition that is already beating it. Many of those agreements can only be described as circular, and I think the fears about a financial bubble are real. In the first half of 2025, investment in data centers accounted for nearly all of US GDP growth. Even if there's not a repeat of the 2008 housing market crisis or the dot-com crash, the AI boom is at the very least poised to make everyday electronics (and utilities) more expensive for regular people in the short term.Since late October, demand for server-grade computer components, including memory and storage, has sent the price of consumer PC parts skyrocketing as manufacturers devote more of their production capacity and wafers to high-margin customers like OpenAI and Google. Since late October, the cost of most RAM kits has doubled and tripled. In November, the price of some SSDs went up by as much as 60 percent. Next year, the cost of LPDDR5X memory, which is used in both smartphones and NVIDIA servers, is expected to climb as well. \"Be it carmakers, smartphones or consumer electronics, everyone that uses memory is facing pressure from price hikes and supply constraints in the coming year,\" Zhao Haijun, the co-CEO of memory manufacturer SMIC told analysts, per Bloomberg.Gita Gopinath, former chief economist for the International Monetary Fund, recently estimated that if the AI bubble were to burst, it would wipe out $20 trillion in wealth held by American households. The Great Recession, considered the worst financial meltdown since the Great Depression, reduced US household net worth by $11.5 trillion, and it took years before for American families to rebuild their wealth to pre-recession levels. The modern AI bubble may have been started by ChatGPT, but given the crowded field of chatbots and LLMs, it won't necessarily pop should OpenAI go bust. With novelty and technical prowess no longer on its side though, it's now on Altman to prove in short order why his company still deserves such unprecedented levels of investment. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-house-of-cards-seems-primed-to-collapse-170000900.html?src=rss",
          "content": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago. Back in 2022, the sudden popularity of ChatGPT sent Google into a panic. The company was so worried about the possibility of the upstart chatbot disrupting its Search business, executives sounded a \"code red\" alert inside of the company and called Sergey Brin and Larry Page out of retirement to help it formulate a response to OpenAI. It then rushed out Bard, announcing its first commercial chatbot on February 6, 2023. Google's stock tanked days later when the AI incorrectly answered a question about NASA's James Webb Space Telescope during a public demo. But it wasn't just Google that wanted a piece of OpenAI, while the search giant sought to compete with it, others — including Microsoft and Apple — made deals with the company to bring its technology to their products and services, all the promise that AI would eventually revolutionize every facet of the economy. Since then, OpenAI has seen its lead against Google and much of the AI industry evaporate, culminating in a series of successive blows throughout 2025. On January 20, the same day Altman was busy rubbing shoulders with other tech oligarchs at Donald Trump’s inauguration, China’s DeepSeek quietly released its R1 chain-of-thought model. A week later, the startup's chatbot surpassed ChatGPT as the most-download free app on the US App Store. The overnight success of DeepSeek eliminated $1 trillion worth of stock market value, and almost certainly left OpenAI blindsided.In response, the company showed a newfound urgency. In one week, for instance, OpenAI released both o3-mini and Deep Research. It even went so far as to announce the latter on a Sunday evening. But for all its new urgency, OpenAI's biggest, most important release of the year was a miss. It's safe to say GPT-5 hasn't lived up to anyone's expectations, including OpenAI's own. The company touted the system as smarter, faster and better than all of its previous models, but after users got their hands on it, they complained of a chatbot that made surprisingly dumb mistakes and didn't have much of a personality. For many, GPT-5 felt like a downgrade compared to the older, simpler GPT-4o. That's a position no AI company wants to be in, let alone one that has taken on as much investment as OpenAI. Anthropic was quick to take advantage of the weakness, signing a deal with Microsoft to bring its Claude models to Copilot 365. Previously, Microsoft depended exclusively on OpenAI for partner models in Copilot. Before the company announced the integration, reporting from The Information said Microsoft made the decision based on the strength of Anthropic's Sonnet 4.0 model, judging it \"perform[ed] better in subtle but important ways\" relative to OpenAI's offerings. However, what will likely go down as the defining moment occurred a few short weeks after OpenAI announced the conclusion of its restructuring. On November 18, Google released Gemini 3 Pro, and immediately the new model leap-frogged the competition, including GPT-5. As of the writing of this article, Google's new model is at the top of LMArena, the site where humans compare outputs from different AI systems and vote on the best one. GPT-5, by contrast, is currently ranked sixth overall, behind models from Anthropic and Elon Musk's xAI. According to a December 2 report from The Wall Street Journal, Sam Altman sent a companywide memo following the release of Gemini 3 Pro. Echoing the words Google used to describe the situation it found itself against OpenAI in 2023, he called for a \"code red\" effort to improve ChatGPT. Altman reportedly told employees there would be temporary reassignments and that the company would delay some products, all in an effort to catch up to Google and Anthropic. The few numbers these companies are willing to share don't paint a promising picture for OpenAI. Each month, about 800 million people use ChatGPT. On paper, that's impressive, but Google is catching up there too. In October, the company said the Gemini app had 650 million users, up from 450 million just a few months earlier in July, thanks to the popularity of its Nano Banana Pro image generator. More importantly, OpenAI has an inherent disadvantage against Google. For the search giant, AI may touch everything the company does now, but Gemini is just one product in an extensive portfolio that includes many other popular services. Google can fund its AI advancements with money it makes elsewhere. OpenAI cannot say the same. The company is constantly raising money to stay afloat, and according to a financial roadmap obtained by The Journal, it will need its revenue to grow to about $200 billion annually to become profitable by 2030. In November, Altman said on X the company was on track to hit above $20 billion in annualized revenue this year. In an effort to grow revenue, Altman and company have adopted an incredibly risky strategy. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals in a bid to outscale the competition that is already beating it. Many of those agreements can only be described as circular, and I think the fears about a financial bubble are real. In the first half of 2025, investment in data centers accounted for nearly all of US GDP growth. Even if there's not a repeat of the 2008 housing market crisis or the dot-com crash, the AI boom is at the very least poised to make everyday electronics (and utilities) more expensive for regular people in the short term.Since late October, demand for server-grade computer components, including memory and storage, has sent the price of consumer PC parts skyrocketing as manufacturers devote more of their production capacity and wafers to high-margin customers like OpenAI and Google. Since late October, the cost of most RAM kits has doubled and tripled. In November, the price of some SSDs went up by as much as 60 percent. Next year, the cost of LPDDR5X memory, which is used in both smartphones and NVIDIA servers, is expected to climb as well. \"Be it carmakers, smartphones or consumer electronics, everyone that uses memory is facing pressure from price hikes and supply constraints in the coming year,\" Zhao Haijun, the co-CEO of memory manufacturer SMIC told analysts, per Bloomberg.Gita Gopinath, former chief economist for the International Monetary Fund, recently estimated that if the AI bubble were to burst, it would wipe out $20 trillion in wealth held by American households. The Great Recession, considered the worst financial meltdown since the Great Depression, reduced US household net worth by $11.5 trillion, and it took years before for American families to rebuild their wealth to pre-recession levels. The modern AI bubble may have been started by ChatGPT, but given the crowded field of chatbots and LLMs, it won't necessarily pop should OpenAI go bust. With novelty and technical prowess no longer on its side though, it's now on Altman to prove in short order why his company still deserves such unprecedented levels of investment. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-house-of-cards-seems-primed-to-collapse-170000900.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/the-ai-that-scored-95-until-consultants-learned-it-was-ai",
          "published_at": "Wed, 10 Dec 2025 15:00:00 GMT",
          "title": "The AI that scored 95% — until consultants learned it was AI",
          "standfirst": "Presented by SAPWhen SAP ran a quiet internal experiment to gauge consultant attitudes toward AI, the results were striking. Five teams were asked to validate answers to more than 1,000 business requirements completed by SAP’s AI co-pilot, Joule for Consultants — a workload that would normally take several weeks.Four teams were told the analysis had been completed by junior interns fresh out of school. They reviewed the material, found it impressive, and rated the work about 95% accurate.The fifth team was told the very same answers had come from AI.They rejected almost everything.Only when asked to validate each answer one by one did they discover that the AI was, in fact, highly accurate — surfacing detailed insights the consultants had initially dismissed. The overall accuracy? Again, about 95%.“The lesson learned here is that we need to be very cautious as we introduce AI — especially in how we communicate with senior consultants about its possibilities and how to integrate it into their workflows,” says Guillermo B. Vazquez Mendez, chief architect, RI business transformation and architecture, SAP America Inc.The experiment has since become a revealing starting point for SAP’s push toward the consultant of 2030: a practitioner who is deeply human, enabled by AI, and no longer weighed down by the technical grunt work of the past.Overcoming AI skepticismResistance isn’t surprising, Vazquez notes. Consultants with two or three decades of experience carry enormous institutional knowledge — and an understandable degree of caution.But AI copilots like Joule for Consultants are not replacing expertise. They’re amplifying it.“What Joule really does is make their very expensive time far more effective,” Vazquez says. “It removes the clerical work, so they can focus on turning out high-quality answers in a fraction of the time.”He emphasizes this message constantly: “AI is not replacing you. It’s a tool for you. Human oversight is always required. But now, instead of spending your time looking for documentation, you’re gaining significant time and boosting the effectiveness and detail of your answers.”The consultant time-shift: from tech execution to business insightHistorically, consultants spent about 80% of their time understanding technical systems — how processes run, how data flows, how functions execute. Customers, by contrast, spend 80% of their time focused on their business.That mismatch is exactly where Joule steps in.“There’s a gap there — and the bridge is AI,” Vazquez says. “It flips the time equation, enabling consultants to invest more of their energy in understanding the customer’s industry and business goals. AI takes on the heavy technical lift, so consultants can focus on driving the right business outcomes.”Bringing new consultants up to speedAI is also transforming how new hires learn.“We’re excited to see Joule acting as a bridge between senior consultants, who are adapting more slowly, and interns and new consultants who are already technically savvy,” Vazquez says.Junior consultants ramp up faster because Joule helps them operate independently. Seniors, meanwhile, engage where their insight matters most.This is also where many consultants learn the fundamentals of today’s AI copilots. Much of the work depends on prompt engineering — for instance, instructing Joule to act as a senior chief technology architect specializing in finance and SAP S/4HANA 2023, then asking it to analyze business requirements and deliver the output as tables or PowerPoint slides.Once they grasp how to frame prompts, consultants consistently get higher-quality, more structured answers.New architects are also able to communicate more clearly with their more experienced counterparts. They know what they don’t know and can ask targeted questions, which makes mentorship far smoother. It’s created a real synergy, Vazquez adds — senior consultants see how quickly new hires are adapting and learning with AI, and that momentum encourages them to keep pace and adopt the technology themselves.Looking ahead to the future of AI copilots“We’re still in the baby steps of AI — we’re toddlers,” Vazquez says. “Right now, copilots depend on prompt engineering to get good answers. The better you prompt, the better the answer you get.”But that represents only the earliest phase of what these systems will eventually do. As copilots mature, they’ll move beyond responding to prompts and start interpreting entire business processes — understanding the sequence of steps, identifying where human intervention is needed, and spotting where an AI agent could take over. That shift is what leads directly into agentic AI.SAP’s depth of process knowledge is what makes that evolution possible. The company has mapped more than 3,500 business processes across industries — a repository Vazquez calls “some of the most valuable, rigorously tested processes developed in the last 50 years.” Every day, SAP systems support roughly $7.3 trillion in global commerce, giving these emerging AI agents a rich foundation to navigate and reason over.“With that level of process insight and data, we can take a real leap forward,” he says, “equipping our consultants with agentic AI that can solve complex challenges and push us toward increasingly autonomous systems.” Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by SAPWhen SAP ran a quiet internal experiment to gauge consultant attitudes toward AI, the results were striking. Five teams were asked to validate answers to more than 1,000 business requirements completed by SAP’s AI co-pilot, Joule for Consultants — a workload that would normally take several weeks.Four teams were told the analysis had been completed by junior interns fresh out of school. They reviewed the material, found it impressive, and rated the work about 95% accurate.The fifth team was told the very same answers had come from AI.They rejected almost everything.Only when asked to validate each answer one by one did they discover that the AI was, in fact, highly accurate — surfacing detailed insights the consultants had initially dismissed. The overall accuracy? Again, about 95%.“The lesson learned here is that we need to be very cautious as we introduce AI — especially in how we communicate with senior consultants about its possibilities and how to integrate it into their workflows,” says Guillermo B. Vazquez Mendez, chief architect, RI business transformation and architecture, SAP America Inc.The experiment has since become a revealing starting point for SAP’s push toward the consultant of 2030: a practitioner who is deeply human, enabled by AI, and no longer weighed down by the technical grunt work of the past.Overcoming AI skepticismResistance isn’t surprising, Vazquez notes. Consultants with two or three decades of experience carry enormous institutional knowledge — and an understandable degree of caution.But AI copilots like Joule for Consultants are not replacing expertise. They’re amplifying it.“What Joule really does is make their very expensive time far more effective,” Vazquez says. “It removes the clerical work, so they can focus on turning out high-quality answers in a fraction of the time.”He emphasizes this message constantly: “AI is not replacing you. It’s a tool for you. Human oversight is always required. But now, instead of spending your time looking for documentation, you’re gaining significant time and boosting the effectiveness and detail of your answers.”The consultant time-shift: from tech execution to business insightHistorically, consultants spent about 80% of their time understanding technical systems — how processes run, how data flows, how functions execute. Customers, by contrast, spend 80% of their time focused on their business.That mismatch is exactly where Joule steps in.“There’s a gap there — and the bridge is AI,” Vazquez says. “It flips the time equation, enabling consultants to invest more of their energy in understanding the customer’s industry and business goals. AI takes on the heavy technical lift, so consultants can focus on driving the right business outcomes.”Bringing new consultants up to speedAI is also transforming how new hires learn.“We’re excited to see Joule acting as a bridge between senior consultants, who are adapting more slowly, and interns and new consultants who are already technically savvy,” Vazquez says.Junior consultants ramp up faster because Joule helps them operate independently. Seniors, meanwhile, engage where their insight matters most.This is also where many consultants learn the fundamentals of today’s AI copilots. Much of the work depends on prompt engineering — for instance, instructing Joule to act as a senior chief technology architect specializing in finance and SAP S/4HANA 2023, then asking it to analyze business requirements and deliver the output as tables or PowerPoint slides.Once they grasp how to frame prompts, consultants consistently get higher-quality, more structured answers.New architects are also able to communicate more clearly with their more experienced counterparts. They know what they don’t know and can ask targeted questions, which makes mentorship far smoother. It’s created a real synergy, Vazquez adds — senior consultants see how quickly new hires are adapting and learning with AI, and that momentum encourages them to keep pace and adopt the technology themselves.Looking ahead to the future of AI copilots“We’re still in the baby steps of AI — we’re toddlers,” Vazquez says. “Right now, copilots depend on prompt engineering to get good answers. The better you prompt, the better the answer you get.”But that represents only the earliest phase of what these systems will eventually do. As copilots mature, they’ll move beyond responding to prompts and start interpreting entire business processes — understanding the sequence of steps, identifying where human intervention is needed, and spotting where an AI agent could take over. That shift is what leads directly into agentic AI.SAP’s depth of process knowledge is what makes that evolution possible. The company has mapped more than 3,500 business processes across industries — a repository Vazquez calls “some of the most valuable, rigorously tested processes developed in the last 50 years.” Every day, SAP systems support roughly $7.3 trillion in global commerce, giving these emerging AI agents a rich foundation to navigate and reason over.“With that level of process insight and data, we can take a real leap forward,” he says, “equipping our consultants with agentic AI that can solve complex challenges and push us toward increasingly autonomous systems.” Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7IoiYyTs0K9D4WfYDzJvhy/f6bb93584c65f055662926cf6ed9d467/AdobeStock_571280209.jpeg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/projectors-won-us-over-in-2025-143655492.html",
          "published_at": "Wed, 10 Dec 2025 14:36:55 +0000",
          "title": "Projectors won us over in 2025",
          "standfirst": "Not long ago, you may have thought of projectors as complicated, unreliable or just too expensive. In 2025, though, consumer sentiment started to flip. Companies like Anker and Valerion made the projector experience more practical and immersive, helping drive consumer interest and, ultimately, sales. This shift has been quite a few years in the making. LG helped kickstart the projector renaissance back at CES 2018 when it introduced its unusual-looking CineBeam HU80K projector that could provide a 150-inch image. The next year at CES saw the dawn of the ultra short-throw (UST) laser projector that could create a similarly large display while sitting just inches from your wall. Another big technological upgrade over the following years was the bright and long-lasting laser light engines that replaced weaker, more fragile bulbs. The timing couldn’t have been better for projector manufacturers. When COVID shut down theaters in 2020, consumers were forced to get their entertainment at home. Many wanted something akin to a movie theater experience — both indoors and out — and thus interest in projectors started to take off. In 2025, though, projectors really entered the zeitgeist thanks to two new products. The first was Anker’s SoundCore Nebula X1, the highest-rated home theater product Engadget reviewed this year. It comes with a triple-laser engine that allows for 3,500 lumens of brightness — enough that you can watch it during the day. It also uses liquid cooling to reduce annoying fan noise and offers color-accurate picture quality with support for Dolby Vision HDR. Even better, it can be carried outside easily via the retractable handle and used for movie nights under the stars. If you splurge for the Soundcore Nebula X1 Pro version that comes with huge party speakers, you can even expect excellent sound quality. It also looks sleek and modern, unlike the plasticky models normally aimed at mid-range buyers. However, the most interesting feature — which is new for a projector in this price range — is the motorized tilting lens that automatically fits the picture to your screen or surface. That allows buyers to set up the Nebula X1 themselves in just a few minutes, rather than hours. That also makes it easy to move the projector around and use in another location. Valerion The other model that captured our imagination was the Valerion VisionMaster Max. This projector shares many traits of the Nebula X1, like Dolby Vision, a triple laser system and automatic setup. It’s also a nice-looking, modern product. However, it has two other innovations that made it extra interesting. The first is the dynamic iris and its Enhanced Black Level technology. That had reviewers raving about its deep black levels that were comparable to projectors like JVC’s NZ8 that cost twice as much. The other is the so-called anti-rainbow technology, which eliminates most of the rainbow-hued strobing that appears with models using Texas Instruments DLP chips. This resolves a common complaint with mid-range projectors. For a similar price as a good quality TV ($1,500 - $3,000), these models can beam an image double the size. And to install one, you just need to position the projector in front of the screen, roughly center it and hit “calibrate” to get a perfect image. Both the X1 and VisionMaster Max were first announced on Kickstarter and became the top two projectors ever sold on the site. Plus, several projector models, particularly from Anker/Soundcore, appeared on Google’s gadget search trends. All of that is helping the home projector market increase to the point that it’s, well, projected to nearly double by 2030. As people researched these products, they may have noticed the other advantages. Along with movies, they’re also great for gaming and sports, particularly if you have a big group of people. In fact, they actually take up less room than a TV if both the projector and screen are ceiling mounted. And many models are portable, battery-powered and bright enough to use outside for parties and camping. Steve Dent for Engadget A prime example of a recent projector convert is Engadget editor and cinema podcaster Devindra Hardawar, who explained why he decided to make the leap. “I know big TVs have gotten cheaper, but they still can't reach the massive 120-inch screen size of my Formovie ultra-short throw projector,” he said. “It makes watching anything feel truly cinematic, and not like I'm just staring at another screen.” Even though projectors are gaining some ground, they won’t replace TVs for most people. Mid-range televisions still cost less at around $1,000. TVs are obviously easier to install and more convenient to use, as all projectors need time to warm up. TVs are much brighter, too: even dim models put out at least 500 nits of brightness, compared to 200 to 300 nits max for very bright projectors. However, even though projector setups are less tricky than before, you still need to buy and install a screen for optimal performance, which adds cost and complexity. How much more can projectors improve? I think they’ll continue to get brighter, more color accurate and even easier to install. Another piece of technology with potential to reduce complexity and improve image quality is the roll-up screen. If those come down in price enough, they may convince some buyers to replace their TVs with a projector. They’re still likely to remain a niche product, but for cinephiles who want a theater-like experience, projectors are now a more compelling option.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/projectors-won-us-over-in-2025-143655492.html?src=rss",
          "content": "Not long ago, you may have thought of projectors as complicated, unreliable or just too expensive. In 2025, though, consumer sentiment started to flip. Companies like Anker and Valerion made the projector experience more practical and immersive, helping drive consumer interest and, ultimately, sales. This shift has been quite a few years in the making. LG helped kickstart the projector renaissance back at CES 2018 when it introduced its unusual-looking CineBeam HU80K projector that could provide a 150-inch image. The next year at CES saw the dawn of the ultra short-throw (UST) laser projector that could create a similarly large display while sitting just inches from your wall. Another big technological upgrade over the following years was the bright and long-lasting laser light engines that replaced weaker, more fragile bulbs. The timing couldn’t have been better for projector manufacturers. When COVID shut down theaters in 2020, consumers were forced to get their entertainment at home. Many wanted something akin to a movie theater experience — both indoors and out — and thus interest in projectors started to take off. In 2025, though, projectors really entered the zeitgeist thanks to two new products. The first was Anker’s SoundCore Nebula X1, the highest-rated home theater product Engadget reviewed this year. It comes with a triple-laser engine that allows for 3,500 lumens of brightness — enough that you can watch it during the day. It also uses liquid cooling to reduce annoying fan noise and offers color-accurate picture quality with support for Dolby Vision HDR. Even better, it can be carried outside easily via the retractable handle and used for movie nights under the stars. If you splurge for the Soundcore Nebula X1 Pro version that comes with huge party speakers, you can even expect excellent sound quality. It also looks sleek and modern, unlike the plasticky models normally aimed at mid-range buyers. However, the most interesting feature — which is new for a projector in this price range — is the motorized tilting lens that automatically fits the picture to your screen or surface. That allows buyers to set up the Nebula X1 themselves in just a few minutes, rather than hours. That also makes it easy to move the projector around and use in another location. Valerion The other model that captured our imagination was the Valerion VisionMaster Max. This projector shares many traits of the Nebula X1, like Dolby Vision, a triple laser system and automatic setup. It’s also a nice-looking, modern product. However, it has two other innovations that made it extra interesting. The first is the dynamic iris and its Enhanced Black Level technology. That had reviewers raving about its deep black levels that were comparable to projectors like JVC’s NZ8 that cost twice as much. The other is the so-called anti-rainbow technology, which eliminates most of the rainbow-hued strobing that appears with models using Texas Instruments DLP chips. This resolves a common complaint with mid-range projectors. For a similar price as a good quality TV ($1,500 - $3,000), these models can beam an image double the size. And to install one, you just need to position the projector in front of the screen, roughly center it and hit “calibrate” to get a perfect image. Both the X1 and VisionMaster Max were first announced on Kickstarter and became the top two projectors ever sold on the site. Plus, several projector models, particularly from Anker/Soundcore, appeared on Google’s gadget search trends. All of that is helping the home projector market increase to the point that it’s, well, projected to nearly double by 2030. As people researched these products, they may have noticed the other advantages. Along with movies, they’re also great for gaming and sports, particularly if you have a big group of people. In fact, they actually take up less room than a TV if both the projector and screen are ceiling mounted. And many models are portable, battery-powered and bright enough to use outside for parties and camping. Steve Dent for Engadget A prime example of a recent projector convert is Engadget editor and cinema podcaster Devindra Hardawar, who explained why he decided to make the leap. “I know big TVs have gotten cheaper, but they still can't reach the massive 120-inch screen size of my Formovie ultra-short throw projector,” he said. “It makes watching anything feel truly cinematic, and not like I'm just staring at another screen.” Even though projectors are gaining some ground, they won’t replace TVs for most people. Mid-range televisions still cost less at around $1,000. TVs are obviously easier to install and more convenient to use, as all projectors need time to warm up. TVs are much brighter, too: even dim models put out at least 500 nits of brightness, compared to 200 to 300 nits max for very bright projectors. However, even though projector setups are less tricky than before, you still need to buy and install a screen for optimal performance, which adds cost and complexity. How much more can projectors improve? I think they’ll continue to get brighter, more color accurate and even easier to install. Another piece of technology with potential to reduce complexity and improve image quality is the roll-up screen. If those come down in price enough, they may convince some buyers to replace their TVs with a projector. They’re still likely to remain a niche product, but for cinephiles who want a theater-like experience, projectors are now a more compelling option.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/projectors-won-us-over-in-2025-143655492.html?src=rss",
          "feed_position": 15,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/036c16c0-d5ce-11f0-b7db-e63439d1da6a"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/openai-report-reveals-a-6x-productivity-gap-between-ai-power-users-and",
          "published_at": "Wed, 10 Dec 2025 14:30:00 GMT",
          "title": "OpenAI report reveals a 6x productivity gap between AI power users and everyone else",
          "standfirst": "The tools are available to everyone. The subscription is company-wide. The training sessions have been held. And yet, in offices from Wall Street to Silicon Valley, a stark divide is opening between workers who have woven artificial intelligence into the fabric of their daily work and colleagues who have barely touched it.The gap is not small. According to a new report from OpenAI analyzing usage patterns across its more than one million business customers, workers at the 95th percentile of AI adoption are sending six times as many messages to ChatGPT as the median employee at the same companies. For specific tasks, the divide is even more dramatic: frontier workers send 17 times as many coding-related messages as their typical peers, and among data analysts, the heaviest users engage the data analysis tool 16 times more frequently than the median.This is not a story about access. It is a story about a new form of workplace stratification emerging in real time — one that may be reshaping who gets ahead, who falls behind, and what it means to be a skilled worker in the age of artificial intelligence.Everyone has the same tools, but not everyone is using themPerhaps the most striking finding in the OpenAI report is how little access explains. ChatGPT Enterprise is now deployed across more than 7 million workplace seats globally, a nine-fold increase from a year ago. The tools are the same for everyone. The capabilities are identical. And yet usage varies by orders of magnitude.Among monthly active users — people who have logged in at least once in the past 30 days — 19 percent have never tried the data analysis feature. Fourteen percent have never used reasoning capabilities. Twelve percent have never used search. These are not obscure features buried in submenus; they are core functionality that OpenAI highlights as transformative for knowledge work.The pattern inverts among daily users. Only 3 percent of people who use ChatGPT every day have never tried data analysis; just 1 percent have skipped reasoning or search. The implication is clear: the divide is not between those who have access and those who don&#x27;t, but between those who have made AI a daily habit and those for whom it remains an occasional novelty.Employees who experiment more are saving dramatically more timeThe OpenAI report suggests that AI productivity gains are not evenly distributed across all users but concentrated among those who use the technology most intensively. Workers who engage across approximately seven distinct task types — data analysis, coding, image generation, translation, writing, and others — report saving five times as much time as those who use only four. Employees who save more than 10 hours per week consume eight times more AI credits than those who report no time savings at all.This creates a compounding dynamic. Workers who experiment broadly discover more uses. More uses lead to greater productivity gains. Greater productivity gains presumably lead to better performance reviews, more interesting assignments, and faster advancement—which in turn provides more opportunity and incentive to deepen AI usage further.Seventy-five percent of surveyed workers report being able to complete tasks they previously could not perform, including programming support, spreadsheet automation, and technical troubleshooting. For workers who have embraced these capabilities, the boundaries of their roles are expanding. For those who have not, the boundaries may be contracting by comparison.The corporate AI paradox: $40 billion spent, 95 percent seeing no returnThe individual usage gap documented by OpenAI mirrors a broader pattern identified by a separate study from MIT&#x27;s Project NANDA. Despite $30 billion to $40 billion invested in generative AI initiatives, only 5 percent of organizations are seeing transformative returns. The researchers call this the \"GenAI Divide\" — a gap separating the few organizations that succeed in transforming processes with adaptive AI systems from the majority that remain stuck in pilots.The MIT report found limited disruption across industries: only two of nine major sectors—technology and media—show material business transformation from generative AI use. Large firms lead in pilot volume but lag in successful deployment.The pattern is consistent across both studies. Organizations and individuals are buying the technology. They are launching pilots. They are attending training sessions. But somewhere between adoption and transformation, most are getting stuck.While official AI projects stall, a shadow economy is thrivingThe MIT study reveals a striking disconnect: while only 40 percent of companies have purchased official LLM subscriptions, employees in over 90 percent of companies regularly use personal AI tools for work. Nearly every respondent reported using LLMs in some form as part of their regular workflow.\"This &#x27;shadow AI&#x27; often delivers better ROI than formal initiatives and reveals what actually works for bridging the divide,\" MIT&#x27;s Project NANDA found.The shadow economy offers a clue to what&#x27;s happening at the individual level within organizations. Employees who take initiative — who sign up for personal subscriptions, who experiment on their own time, who figure out how to integrate AI into their workflows without waiting for IT approval — are pulling ahead of colleagues who wait for official guidance that may never come.These shadow systems, largely unsanctioned, often deliver better performance and faster adoption than corporate tools. Worker sentiment reveals a preference for flexible, responsive tools — precisely the kind of experimentation that separates OpenAI&#x27;s frontier workers from the median.The biggest gaps show up in technical work that used to require specialistsThe largest relative gaps between frontier and median workers appear in coding, writing, and analysis — precisely the task categories where AI capabilities have advanced most rapidly. Frontier workers are not just doing the same work faster; they appear to be doing different work entirely, expanding into technical domains that were previously inaccessible to them.Among ChatGPT Enterprise users outside of engineering, IT, and research, coding-related messages have grown 36 percent over the past six months. Someone in marketing or HR who learns to write scripts and automate workflows is becoming a categorically different employee than a peer who has not — even if they hold the same title and started with the same skills.The academic research on AI and productivity offers a complicated picture. Several studies cited in the OpenAI report find that AI has an \"equalizing effect,\" disproportionately helping lower-performing workers close the gap with their higher-performing peers. But the equalizing effect may apply only within the population of workers who actually use AI regularly. A meaningful share of workers are not in that group at all. They remain light users or non-users, even as their more adventurous colleagues pull away.Companies are divided too, and the gap is widening by the monthThe divide is not only between individual workers. It exists between entire organizations.Frontier firms — those at the 95th percentile of adoption intensity — generate approximately twice as many AI messages per employee as the median enterprise. For messages routed through custom GPTs, purpose-built tools that automate specific workflows, the gap widens to seven-fold.These numbers suggest fundamentally different operating models. At median companies, AI may be a productivity tool that individual workers use at their discretion. At frontier firms, AI appears to be embedded in core infrastructure: standardized workflows, persistent custom tools, systematic integration with internal data systems.The OpenAI report notes that roughly one in four enterprises still has not enabled connectors that give AI access to company data—a basic step that dramatically increases the technology&#x27;s utility. The MIT study found that companies that purchased AI tools from specialized vendors succeeded 67 percent of the time, while internal builds had only a one-in-three success rate. For many organizations, the AI era has technically arrived but has not yet begun in practice.The technology is no longer the problem — organizations areFor executives, the data presents an uncomfortable challenge. The technology is no longer the constraint. OpenAI notes that it releases a new feature or capability roughly every three days; the models are advancing faster than most organizations can absorb. The bottleneck has shifted from what AI can do to whether organizations are structured to take advantage of it.\"The dividing line isn&#x27;t intelligence,\" the MIT authors write. The problems with enterprise AI have to do with memory, adaptability, and learning capability. Problems stem less from regulations or model performance, and more from tools that fail to learn or adapt.Leading firms, according to the OpenAI report, consistently invest in executive sponsorship, data readiness, workflow standardization, and deliberate change management. They build cultures where custom AI tools are created, shared, and refined across teams. They track performance and run evaluations. They make AI adoption a strategic priority rather than an individual choice.The rest are leaving it to chance — hoping that workers will discover the tools on their own, experiment on their own time, and somehow propagate best practices without infrastructure or incentive. The six-fold gap suggests this approach is not working.The window to catch up is closing faster than most companies realizeWith enterprise contracts locking in over the next 18 months, there&#x27;s a shrinking window for vendors and adopters to cross the divide.The GenAI Divide identified by the MIT report is not going to last forever. But the organizations that figure out a way across it soonest will be the ones that define the next era of business.Both reports carry caveats. The OpenAI data comes from a company with an obvious interest in promoting AI adoption. The productivity figures are self-reported by customers already paying for the product. The MIT study, while independent, relies on interviews and surveys rather than direct measurement. The long-term effects of this technology on employment, wages, and workplace dynamics remain uncertain.But the core finding — that access alone does not produce adoption, and that adoption varies enormously even within organizations that have made identical tools available to all — is consistent with how previous technologies have diffused through the economy. Spreadsheets, email, and the internet all created similar divides before eventually becoming universal. The question is how long the current gap persists, who benefits during the transition, and what happens to workers who find themselves on the wrong side of it.For now, the divide is stark. Ninety percent of users said they prefer humans for \"mission-critical work,\" while AI has \"won the war for simple work.\" The workers who are pulling ahead are not doing so because they have access their colleagues lack. They are pulling ahead because they decided to use what everyone already has—and kept using it until they figured out what it could do.The 6x gap is not about technology. It is about behavior. And behavior, unlike software, cannot be deployed with a company-wide rollout.",
          "content": "The tools are available to everyone. The subscription is company-wide. The training sessions have been held. And yet, in offices from Wall Street to Silicon Valley, a stark divide is opening between workers who have woven artificial intelligence into the fabric of their daily work and colleagues who have barely touched it.The gap is not small. According to a new report from OpenAI analyzing usage patterns across its more than one million business customers, workers at the 95th percentile of AI adoption are sending six times as many messages to ChatGPT as the median employee at the same companies. For specific tasks, the divide is even more dramatic: frontier workers send 17 times as many coding-related messages as their typical peers, and among data analysts, the heaviest users engage the data analysis tool 16 times more frequently than the median.This is not a story about access. It is a story about a new form of workplace stratification emerging in real time — one that may be reshaping who gets ahead, who falls behind, and what it means to be a skilled worker in the age of artificial intelligence.Everyone has the same tools, but not everyone is using themPerhaps the most striking finding in the OpenAI report is how little access explains. ChatGPT Enterprise is now deployed across more than 7 million workplace seats globally, a nine-fold increase from a year ago. The tools are the same for everyone. The capabilities are identical. And yet usage varies by orders of magnitude.Among monthly active users — people who have logged in at least once in the past 30 days — 19 percent have never tried the data analysis feature. Fourteen percent have never used reasoning capabilities. Twelve percent have never used search. These are not obscure features buried in submenus; they are core functionality that OpenAI highlights as transformative for knowledge work.The pattern inverts among daily users. Only 3 percent of people who use ChatGPT every day have never tried data analysis; just 1 percent have skipped reasoning or search. The implication is clear: the divide is not between those who have access and those who don&#x27;t, but between those who have made AI a daily habit and those for whom it remains an occasional novelty.Employees who experiment more are saving dramatically more timeThe OpenAI report suggests that AI productivity gains are not evenly distributed across all users but concentrated among those who use the technology most intensively. Workers who engage across approximately seven distinct task types — data analysis, coding, image generation, translation, writing, and others — report saving five times as much time as those who use only four. Employees who save more than 10 hours per week consume eight times more AI credits than those who report no time savings at all.This creates a compounding dynamic. Workers who experiment broadly discover more uses. More uses lead to greater productivity gains. Greater productivity gains presumably lead to better performance reviews, more interesting assignments, and faster advancement—which in turn provides more opportunity and incentive to deepen AI usage further.Seventy-five percent of surveyed workers report being able to complete tasks they previously could not perform, including programming support, spreadsheet automation, and technical troubleshooting. For workers who have embraced these capabilities, the boundaries of their roles are expanding. For those who have not, the boundaries may be contracting by comparison.The corporate AI paradox: $40 billion spent, 95 percent seeing no returnThe individual usage gap documented by OpenAI mirrors a broader pattern identified by a separate study from MIT&#x27;s Project NANDA. Despite $30 billion to $40 billion invested in generative AI initiatives, only 5 percent of organizations are seeing transformative returns. The researchers call this the \"GenAI Divide\" — a gap separating the few organizations that succeed in transforming processes with adaptive AI systems from the majority that remain stuck in pilots.The MIT report found limited disruption across industries: only two of nine major sectors—technology and media—show material business transformation from generative AI use. Large firms lead in pilot volume but lag in successful deployment.The pattern is consistent across both studies. Organizations and individuals are buying the technology. They are launching pilots. They are attending training sessions. But somewhere between adoption and transformation, most are getting stuck.While official AI projects stall, a shadow economy is thrivingThe MIT study reveals a striking disconnect: while only 40 percent of companies have purchased official LLM subscriptions, employees in over 90 percent of companies regularly use personal AI tools for work. Nearly every respondent reported using LLMs in some form as part of their regular workflow.\"This &#x27;shadow AI&#x27; often delivers better ROI than formal initiatives and reveals what actually works for bridging the divide,\" MIT&#x27;s Project NANDA found.The shadow economy offers a clue to what&#x27;s happening at the individual level within organizations. Employees who take initiative — who sign up for personal subscriptions, who experiment on their own time, who figure out how to integrate AI into their workflows without waiting for IT approval — are pulling ahead of colleagues who wait for official guidance that may never come.These shadow systems, largely unsanctioned, often deliver better performance and faster adoption than corporate tools. Worker sentiment reveals a preference for flexible, responsive tools — precisely the kind of experimentation that separates OpenAI&#x27;s frontier workers from the median.The biggest gaps show up in technical work that used to require specialistsThe largest relative gaps between frontier and median workers appear in coding, writing, and analysis — precisely the task categories where AI capabilities have advanced most rapidly. Frontier workers are not just doing the same work faster; they appear to be doing different work entirely, expanding into technical domains that were previously inaccessible to them.Among ChatGPT Enterprise users outside of engineering, IT, and research, coding-related messages have grown 36 percent over the past six months. Someone in marketing or HR who learns to write scripts and automate workflows is becoming a categorically different employee than a peer who has not — even if they hold the same title and started with the same skills.The academic research on AI and productivity offers a complicated picture. Several studies cited in the OpenAI report find that AI has an \"equalizing effect,\" disproportionately helping lower-performing workers close the gap with their higher-performing peers. But the equalizing effect may apply only within the population of workers who actually use AI regularly. A meaningful share of workers are not in that group at all. They remain light users or non-users, even as their more adventurous colleagues pull away.Companies are divided too, and the gap is widening by the monthThe divide is not only between individual workers. It exists between entire organizations.Frontier firms — those at the 95th percentile of adoption intensity — generate approximately twice as many AI messages per employee as the median enterprise. For messages routed through custom GPTs, purpose-built tools that automate specific workflows, the gap widens to seven-fold.These numbers suggest fundamentally different operating models. At median companies, AI may be a productivity tool that individual workers use at their discretion. At frontier firms, AI appears to be embedded in core infrastructure: standardized workflows, persistent custom tools, systematic integration with internal data systems.The OpenAI report notes that roughly one in four enterprises still has not enabled connectors that give AI access to company data—a basic step that dramatically increases the technology&#x27;s utility. The MIT study found that companies that purchased AI tools from specialized vendors succeeded 67 percent of the time, while internal builds had only a one-in-three success rate. For many organizations, the AI era has technically arrived but has not yet begun in practice.The technology is no longer the problem — organizations areFor executives, the data presents an uncomfortable challenge. The technology is no longer the constraint. OpenAI notes that it releases a new feature or capability roughly every three days; the models are advancing faster than most organizations can absorb. The bottleneck has shifted from what AI can do to whether organizations are structured to take advantage of it.\"The dividing line isn&#x27;t intelligence,\" the MIT authors write. The problems with enterprise AI have to do with memory, adaptability, and learning capability. Problems stem less from regulations or model performance, and more from tools that fail to learn or adapt.Leading firms, according to the OpenAI report, consistently invest in executive sponsorship, data readiness, workflow standardization, and deliberate change management. They build cultures where custom AI tools are created, shared, and refined across teams. They track performance and run evaluations. They make AI adoption a strategic priority rather than an individual choice.The rest are leaving it to chance — hoping that workers will discover the tools on their own, experiment on their own time, and somehow propagate best practices without infrastructure or incentive. The six-fold gap suggests this approach is not working.The window to catch up is closing faster than most companies realizeWith enterprise contracts locking in over the next 18 months, there&#x27;s a shrinking window for vendors and adopters to cross the divide.The GenAI Divide identified by the MIT report is not going to last forever. But the organizations that figure out a way across it soonest will be the ones that define the next era of business.Both reports carry caveats. The OpenAI data comes from a company with an obvious interest in promoting AI adoption. The productivity figures are self-reported by customers already paying for the product. The MIT study, while independent, relies on interviews and surveys rather than direct measurement. The long-term effects of this technology on employment, wages, and workplace dynamics remain uncertain.But the core finding — that access alone does not produce adoption, and that adoption varies enormously even within organizations that have made identical tools available to all — is consistent with how previous technologies have diffused through the economy. Spreadsheets, email, and the internet all created similar divides before eventually becoming universal. The question is how long the current gap persists, who benefits during the transition, and what happens to workers who find themselves on the wrong side of it.For now, the divide is stark. Ninety percent of users said they prefer humans for \"mission-critical work,\" while AI has \"won the war for simple work.\" The workers who are pulling ahead are not doing so because they have access their colleagues lack. They are pulling ahead because they decided to use what everyone already has—and kept using it until they figured out what it could do.The 6x gap is not about technology. It is about behavior. And behavior, unlike software, cannot be deployed with a company-wide rollout.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2bLHfbnsHmBo88bpiWCXw9/e35290d2729e57b19a3bfff2cb96f47f/nuneybits_purple_gradient_sky_with_city_lights_in_dots_pattern__7c85a503-0251-4c67-9ddc-4341ea63314b.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/kindle-scribe-colorsoft-review-a-very-particular-set-of-skills-for-a-price-140014961.html",
          "published_at": "Wed, 10 Dec 2025 14:00:14 +0000",
          "title": "Kindle Scribe Colorsoft review: A very particular set of skills, for a price",
          "standfirst": "In a world where notifications persistently compete for our attention, distraction-free ereaders and writing tablets have found an audience. Putting your phone, laptop or iPad aside and curling up with a Kindle or a reMarkable tablet have become an almost ironic way for the tech-savvy to disconnect from online noise and focus on reading and writing. It’s debatable how broad the appeal of these devices is, but even in what appears to be a relatively small slice of the industry, the competition is fierce. Amazon is arguably the biggest name in the space, with its Kindles dominating the ereader market for years. When it introduced the Kindle Scribe in 2022, the company made a play for the burgeoning E Ink writing tablet category, and just last year it launched its first color ereader with the Kindle Colorsoft. Put all those features — reading, writing and color — together, and you’ve got the ingredients for Amazon’s latest contender: the Kindle Scribe Colorsoft. This time, Amazon expanded the Scribe line by releasing three new Scribes at once. The entry-level model is the black-and-white tablet without a front light, which costs $430. For $70 more, you’ll get the front light, and then the Colorsoft version goes for $630. There are upgrades from last year’s Scribe across the trio, and for this review we’ll be looking mostly at the Colorsoft, which has all of the new features. Like with previous models of the Scribe, Amazon doesn’t indicate the generation number in the name, simply calling this lineup the “all-new Kindle Scribe,” attaching the word Colorsoft to the edition that renders colors. To avoid confusion, I’ll occasionally be referring to this generation of the device as the Scribe 3, and the version from last year as the Scribe 2. Editor’s note: As I only received the Kindle Scribe Colorsoft on December 7 due to shipping delays, I won’t be assigning a score to this device until I have had more time to test it. My colleague Valentina Palladino received the new Kindle Scribe a few days before that, and has contributed testing and impressions to this review. It’s also worth noting that some new features, like “Send to Alexa+,” “Story so far” and “Ask this book” aren’t available to test yet. We will update this review with a score after spending more time with it so we can better gauge things like battery life and the usefulness of some software features. What’s new with the Kindle Scribe Colorsoft Aside from the obvious, which is that the Colorsoft can now render colors, the latest Kindle Scribes also feature a refined design, improved front light system, updated screen architecture, new quad-core chip, more memory and Oxide display technology. It has a larger 11-inch screen compared to the 10.2-inch display on its predecessor, and still manages to weigh 33 grams less at 400 grams (0.88 pounds). There’s also a revamped Home page that houses a Quick Note for easier access to the writing interface as well as some software and AI tools that aren’t available to test yet. A lot of the hardware tweaks translated to a snappier, more responsive device overall. In my testing, the Scribe Colorsoft’s AI summarization and handwriting refinements took a bit less time than the Scribe 2, which I attribute most to the processor, but I also noticed improved fluidity in the writing experience. Drawing on the Scribe Colorsoft brings me right back to my younger days testing out pens at bookstores. Amazon’s stylus feels like a pen with ink that flows more freely and consistently onto the page than others, and between the nib and the texture of the page there is a lack of resistance and overall smoothness that is very satisfying. Cherlynn Low for Engadget Amazon said that the Premium Pen that comes with the Scribes has been refined with a thicker and more rounded silhouette. With its latest Oxide display, the Scribe Colorsoft’s screen response rate of 14 milliseconds and the non-Colorsoft Scribe 3’s rates of 12ms are both much higher than the 20-21ms for the Scribe 2. Together, this probably is the main reason that the new Scribe feels more responsive in general, and why writing on it seems so smooth. Although, that new front light system might also be contributing to the overall feeling of freshness. Speaking of, I put the Scribe 2 and Scribe Colorsoft side by side in my friend’s living room and the difference was stark. When I brought both devices next to the window, under direct sunlight, they both seemed similarly bright, with the typical glare-free finish you’d expect of ereaders. But when I took them into a darkened bedroom, the auto-adjusting panel on the Colorsoft lit up its screen and made it easier to read. Colors popped, and while I felt that there was a slight blue tinge to the light, it wasn’t something I would’ve noticed without a side-by-side comparison. It’s not an issue though because you can also adjust the warmth here like you can on other Kindles. One of my complaints in my review of the Scribe 2 was the flimsy attachment method of magnets holding the pen to the tablet. While Amazon hasn’t built an onboard slot or holder for the stylus, it did increase the magnetic force on the Scribe 3. This was already noticeable during my hands-on with the device back in October, and in real-world use I appreciated this upgrade in keeping the Premium Pen tightly attached to the Scribe Colorsoft. I would still prefer a more secure approach, since I still do worry about the stylus getting lost in my purse and don’t want to have to buy a case just for this purpose. But it’s a small quibble and my concerns have largely been allayed with the increased magnetism. Cherlynn Low for Engadget I still need to test some software features like Send to Alexa+, Ask This Book and Story So Far, but they’re not available yet. I’ve been focusing my testing on the Notebook section and need to spend more time marking up and annotating books to better evaluate that use case. But not much has changed there since Amazon rolled out the collapsible margins in February, and you can read my review of the Scribe 2 for my impressions there. The new home page and AI-powered Notebook search At the moment, I can speak to one of the new features: AI-powered Notebook search. The Search bar at the top of the Scribe can now answer questions about the contents of all your Notebooks (and books). At the time of the Scribe’s announcement, I thought this would be helpful in pulling together all the tasks I’d assigned to specific team members across the to-do lists I drew up for various events. When I asked the Scribe “what tasks have I assigned Sam,” its results page showed six categories, pulling information from my library, notebooks, the Kindle Store, the Audible Store, Goodreads and text within books. Only the second one had any findings. Under “Results in your notebooks,” there was a label “AI-powered insights” followed by a header “Sam’s Assigned Tasks.” Below that was a bulleted list, which I’ll transcribe and include an image of here: Add content to CES sheet Handle KPBP company set Track Samsung mobile developments Handle OnePlus 13 Review device during CES Attend meetings with: - Dell & ASUS on Thursday, MSI, Razer, HP, Lenovo, Potentially Sony Ateela Work on Sam Qi 2 Best-Sam host responsibilities Cherlynn Low for Engadget I quickly realized that I’d need to fine-tune my requests to get results that made more sense, since random tasks divorced from their parent documents made little sense without context. Thankfully, there was a button below the results that prompted me to “Ask Notebooks” about “these insights, or ask something else.” However, tapping that only brought me to a different page showing the same list but with a new section to see the notes they were sourced from. I’ll also point out that this list of tasks for Sam was not the same result I got from a query about “where do I mention Sam?” In addition to the two to-do lists that I created in December 2023 and January of this year, the Scribe told me “Sam appears on a Christmas shopping list as one of the checked-off friends.” That’s fairly impressive, since that list did have Sam under a handwritten header “Friends,” as opposed to other pages titled “Gym” or “Neighbors.” But it appeared to only be able to determine that Sam’s name was checked off thanks to the template I used for the notebook. Other check marks I made outside the predefined boxes in that background weren’t deemed as checks and instead misrecognized as dashes. So later when I asked where my friend Michelle appeared in all my notebooks, the Scribe noted an entry for “Michelle-scart” in a different holiday shopping page. Retrying the same question did yield more accurate results, though, with a subsequent search correctly stating “Michelle appears in a list with ‘scarf’ noted next to her name.” And whether it’s my overly messy handwriting to blame or Amazon’s technological deficiencies, there were still some words or sentences that it misidentified, like “Michelle-callin” instead of “Michelle — Callie.” So far, the AI-powered Search feels like a hit-or-miss update. Sometimes, like when I took the bait and asked the questions it suggested, I would get shockingly accurate answers. “Try asking ‘which Ariana song is mentioned in the list,’” the Scribe prompted. Or “When is the HOA meeting occurring?” For the former, it told me that the song “Bang Bang” was on a list of karaoke songs, while the latter simply told me the date and time it had found in a note titled “Appointments Dec 2022.” I’ll need more time to think of better ways to use this feature, but for now I can’t decide if it’s actually helpful without some extra work. Cherlynn Low for Engadget I already spent some time testing the Summarize and Refine tools introduced in the last Kindle Scribe, so I’ll just say that refining the handwriting of a to-do list on the Scribe Colorsoft was largely the same as before, just a tad faster. I didn’t really use either AI tool in the year since I reviewed the Scribe 2, so I was right last year in thinking I wouldn’t find much use for them in daily practice. What I thought would be more practical is the redesigned Home screen and the Quick Note that takes up the top left corner of this page. Again, I’d need to spend much more time to understand how I’d navigate the device over weeks and months, but for the most part I find it easy to just hop in and out of notes I want without first going to the Home section. I’d prefer a hardware shortcut like Montblanc offers in its Digital Paper writing tablet. On that device, you can program the buttons on the pen so that a double click starts a new note, adds a blank page or brings you back home. While you can customize the button on Amazon’s Premium Pen, your options are limited to switching between tools like the highlighter, pen, shader or eraser for use while you’re writing. (And yes, like before, you can still use the top of the Premium Pen to erase content — no need to push any button.) One last thing to note about the home page (for now) is that seeing the rows of book covers in color is a delight, and though it’s not something that impacts the function of the device, it certainly adds a layer of visual pleasure. How does the Kindle Scribe Colorsoft compare to the competition? One of the Scribe Colorsoft’s main competitors is the reMarkable Paper Pro. The latter has a larger 11.8-inch screen and, correspondingly, weighs a lot more at 525 grams (1.16 pounds). Though I prefer the sharp lines of the reMarkable to the rounded edges and corners of the Scribe, I find the Kindle’s size much more manageable, especially when I’m writing for more than five minutes. Importantly, the Kindle Scribe Colorsoft simply has a better screen than the reMarkable. It delivers brighter, more saturated colors, and supports more hues, too. Plus, when I placed them next to each other, the Paper Pro seemed to have a yellow cast and a dimmer screen overall (even at maximum brightness). And when I use the highlight function on each, the reMarkable device “flashes” — meaning you have to give it a second for the color to appear in its final form after you put the stylus to the screen. Meanwhile, the color that shows up on the Colorsoft’s panel as soon as you write on it doesn’t change — no flashing takes place. Cherlynn Low for Engadget The Scribe’s other strengths are its superior performance and Amazon’s ecosystem of books (for those like me who already have large Kindle libraries, anyway). Though it does offer AI features that reMarkable doesn’t, I’m generally leery of those tools, and, as already detailed in this review, they don’t usually help me. However, the reMarkable remains the winner when it comes to writing software. It’s way more versatile than Amazon in this respect, especially with its ability to have handwritten and typed text coexist within the same document. You can also edit a note from reMarkable’s app on your phone, typing in any last-minute additions to your shopping list and bolding, italicizing or formatting them if you like. And if you’re a power user, getting your favorite ebooks onto the reMarkable tablet isn’t too difficult, provided you have the EPUB files. The main problem for me here is that you'll need to pay $3 a month for its Connect subscription to continue having access to a lot of these features. I’ll also shout out companies like Kobo and Boox, who also make color-rendering ereaders that you can write on. Boox’s Note Air 5c starts at $530 and includes the stylus and a magnetic case for that price. It supports apps via the Google Play Store, but, as our deputy editor Valentina Palladino cautions, isn’t the most beginner-friendly product. Kobo, on the other hand, makes color ereaders like the Libra Color. Although it does support stylus input, it is much smaller with its 7-inch display. And for those who aren’t too fussed about color, there are plenty of black-and-white E Ink writing tablets, including the $905 Montblanc Digital Paper, which I’ve been testing for a few weeks. I’m finishing up my review but that one is clearly a luxury product targeted at a much more niche audience than the already limited target market for this category of devices. If your budget is tight, I’d recommend skipping the Colorsoft model unless it’s crucial to your process. $500 is a much easier price to stomach. Who should get the Kindle Scribe Colorsoft? I hesitate to recommend anyone buy anything before I’ve had enough time to assign a score, since things like battery life take longer to evaluate. And while I continue to test the device to get a better sense for its battery life, I’ve already noticed that like the Scribes before it, this version doesn’t last as long as other Kindles. Amazon promises weeks of reading and writing per charge, which could be anything between two and ten (or more) weeks. In my experience so far, the Kindle Scribe Colorsoft dropped about 20 percent in two days, which, mathematically, means it would struggle to even last a week, not to mention multiple weeks. But because the Scribe 2 showed similar battery drain during my review (with heavier use) and manages to stay charged for at least a month when I’m not testing it all day every day, I’m willing to believe Amazon’s promise of greater runtime. Aside from my reservations about battery life, the Kindle Scribe Colorsoft is a competent device that delivers on most of its promises so far. The biggest knock against it is its price. At $500 for the monochrome model and $630 for color, this is one Amazon product that can be more expensive than the competition. But it’s not without its strengths. I’d think of the Kindle Scribe 3 (and Colorsoft) as an E Ink tablet that is more of a notebook than a portal for textbooks you can mark up, with a robust library of Kindle titles to boot. The AI features are not crucial to the experience, but they also stay out of the way. For those looking for a more sophisticated and versatile writing tablet that is less of a book replacement, the reMarkable Paper Pro is the superior device. And for people who don’t mind the notifications, apps and alerts that these purpose-driven tablets keep from distracting you, there’s always the option of buying an iPad or an Android tablet with a stylus. Just install minimal apps or block all notifications, and you might even save hundreds of dollars in the process. Cherlynn Low for Engadget Wrap-up I hate to admit it, but Amazon’s devices and services chief Panos Panay was right in calling the Kindle Scribe a 2-in-1. But the two functions it serves are very specific. I think of the Scribe devices as Kindles first and foremost. That means they’re ereaders, capable of substituting stacks of books thanks to their digital libraries and eye-friendly screens. The second role the Scribe plays well is that of a notebook substitute. It is a place to hold endless slips of digital paper, and its search function can competently help you find what you jotted down in a random note years ago. But Amazon has not yet found a way to deliver on features like annotating and marking up ebooks that feels like pen-and-paper. Trying to mark up a digital textbook on the Scribe still feels unintuitive, involving virtual sticky notes, collapsible margins and inserting boxes within lines of text. And you won’t be able to easily edit your notes if you’re away from your Scribe, unlike how you can on a reMarkable product. So the Kindle Scribe 3 is not a three- or four-in-one. I don’t have a problem with that, especially without the extra cost that comes with the color capabilities. While the Colorsoft model is superior to the competition at the moment, it also comes at a premium. If you’re looking for the best color E Ink writing tablet available and are willing to splurge, the Kindle Scribe Colorsoft is worth consideration.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/kindle-scribe-colorsoft-review-a-very-particular-set-of-skills-for-a-price-140014961.html?src=rss",
          "content": "In a world where notifications persistently compete for our attention, distraction-free ereaders and writing tablets have found an audience. Putting your phone, laptop or iPad aside and curling up with a Kindle or a reMarkable tablet have become an almost ironic way for the tech-savvy to disconnect from online noise and focus on reading and writing. It’s debatable how broad the appeal of these devices is, but even in what appears to be a relatively small slice of the industry, the competition is fierce. Amazon is arguably the biggest name in the space, with its Kindles dominating the ereader market for years. When it introduced the Kindle Scribe in 2022, the company made a play for the burgeoning E Ink writing tablet category, and just last year it launched its first color ereader with the Kindle Colorsoft. Put all those features — reading, writing and color — together, and you’ve got the ingredients for Amazon’s latest contender: the Kindle Scribe Colorsoft. This time, Amazon expanded the Scribe line by releasing three new Scribes at once. The entry-level model is the black-and-white tablet without a front light, which costs $430. For $70 more, you’ll get the front light, and then the Colorsoft version goes for $630. There are upgrades from last year’s Scribe across the trio, and for this review we’ll be looking mostly at the Colorsoft, which has all of the new features. Like with previous models of the Scribe, Amazon doesn’t indicate the generation number in the name, simply calling this lineup the “all-new Kindle Scribe,” attaching the word Colorsoft to the edition that renders colors. To avoid confusion, I’ll occasionally be referring to this generation of the device as the Scribe 3, and the version from last year as the Scribe 2. Editor’s note: As I only received the Kindle Scribe Colorsoft on December 7 due to shipping delays, I won’t be assigning a score to this device until I have had more time to test it. My colleague Valentina Palladino received the new Kindle Scribe a few days before that, and has contributed testing and impressions to this review. It’s also worth noting that some new features, like “Send to Alexa+,” “Story so far” and “Ask this book” aren’t available to test yet. We will update this review with a score after spending more time with it so we can better gauge things like battery life and the usefulness of some software features. What’s new with the Kindle Scribe Colorsoft Aside from the obvious, which is that the Colorsoft can now render colors, the latest Kindle Scribes also feature a refined design, improved front light system, updated screen architecture, new quad-core chip, more memory and Oxide display technology. It has a larger 11-inch screen compared to the 10.2-inch display on its predecessor, and still manages to weigh 33 grams less at 400 grams (0.88 pounds). There’s also a revamped Home page that houses a Quick Note for easier access to the writing interface as well as some software and AI tools that aren’t available to test yet. A lot of the hardware tweaks translated to a snappier, more responsive device overall. In my testing, the Scribe Colorsoft’s AI summarization and handwriting refinements took a bit less time than the Scribe 2, which I attribute most to the processor, but I also noticed improved fluidity in the writing experience. Drawing on the Scribe Colorsoft brings me right back to my younger days testing out pens at bookstores. Amazon’s stylus feels like a pen with ink that flows more freely and consistently onto the page than others, and between the nib and the texture of the page there is a lack of resistance and overall smoothness that is very satisfying. Cherlynn Low for Engadget Amazon said that the Premium Pen that comes with the Scribes has been refined with a thicker and more rounded silhouette. With its latest Oxide display, the Scribe Colorsoft’s screen response rate of 14 milliseconds and the non-Colorsoft Scribe 3’s rates of 12ms are both much higher than the 20-21ms for the Scribe 2. Together, this probably is the main reason that the new Scribe feels more responsive in general, and why writing on it seems so smooth. Although, that new front light system might also be contributing to the overall feeling of freshness. Speaking of, I put the Scribe 2 and Scribe Colorsoft side by side in my friend’s living room and the difference was stark. When I brought both devices next to the window, under direct sunlight, they both seemed similarly bright, with the typical glare-free finish you’d expect of ereaders. But when I took them into a darkened bedroom, the auto-adjusting panel on the Colorsoft lit up its screen and made it easier to read. Colors popped, and while I felt that there was a slight blue tinge to the light, it wasn’t something I would’ve noticed without a side-by-side comparison. It’s not an issue though because you can also adjust the warmth here like you can on other Kindles. One of my complaints in my review of the Scribe 2 was the flimsy attachment method of magnets holding the pen to the tablet. While Amazon hasn’t built an onboard slot or holder for the stylus, it did increase the magnetic force on the Scribe 3. This was already noticeable during my hands-on with the device back in October, and in real-world use I appreciated this upgrade in keeping the Premium Pen tightly attached to the Scribe Colorsoft. I would still prefer a more secure approach, since I still do worry about the stylus getting lost in my purse and don’t want to have to buy a case just for this purpose. But it’s a small quibble and my concerns have largely been allayed with the increased magnetism. Cherlynn Low for Engadget I still need to test some software features like Send to Alexa+, Ask This Book and Story So Far, but they’re not available yet. I’ve been focusing my testing on the Notebook section and need to spend more time marking up and annotating books to better evaluate that use case. But not much has changed there since Amazon rolled out the collapsible margins in February, and you can read my review of the Scribe 2 for my impressions there. The new home page and AI-powered Notebook search At the moment, I can speak to one of the new features: AI-powered Notebook search. The Search bar at the top of the Scribe can now answer questions about the contents of all your Notebooks (and books). At the time of the Scribe’s announcement, I thought this would be helpful in pulling together all the tasks I’d assigned to specific team members across the to-do lists I drew up for various events. When I asked the Scribe “what tasks have I assigned Sam,” its results page showed six categories, pulling information from my library, notebooks, the Kindle Store, the Audible Store, Goodreads and text within books. Only the second one had any findings. Under “Results in your notebooks,” there was a label “AI-powered insights” followed by a header “Sam’s Assigned Tasks.” Below that was a bulleted list, which I’ll transcribe and include an image of here: Add content to CES sheet Handle KPBP company set Track Samsung mobile developments Handle OnePlus 13 Review device during CES Attend meetings with: - Dell & ASUS on Thursday, MSI, Razer, HP, Lenovo, Potentially Sony Ateela Work on Sam Qi 2 Best-Sam host responsibilities Cherlynn Low for Engadget I quickly realized that I’d need to fine-tune my requests to get results that made more sense, since random tasks divorced from their parent documents made little sense without context. Thankfully, there was a button below the results that prompted me to “Ask Notebooks” about “these insights, or ask something else.” However, tapping that only brought me to a different page showing the same list but with a new section to see the notes they were sourced from. I’ll also point out that this list of tasks for Sam was not the same result I got from a query about “where do I mention Sam?” In addition to the two to-do lists that I created in December 2023 and January of this year, the Scribe told me “Sam appears on a Christmas shopping list as one of the checked-off friends.” That’s fairly impressive, since that list did have Sam under a handwritten header “Friends,” as opposed to other pages titled “Gym” or “Neighbors.” But it appeared to only be able to determine that Sam’s name was checked off thanks to the template I used for the notebook. Other check marks I made outside the predefined boxes in that background weren’t deemed as checks and instead misrecognized as dashes. So later when I asked where my friend Michelle appeared in all my notebooks, the Scribe noted an entry for “Michelle-scart” in a different holiday shopping page. Retrying the same question did yield more accurate results, though, with a subsequent search correctly stating “Michelle appears in a list with ‘scarf’ noted next to her name.” And whether it’s my overly messy handwriting to blame or Amazon’s technological deficiencies, there were still some words or sentences that it misidentified, like “Michelle-callin” instead of “Michelle — Callie.” So far, the AI-powered Search feels like a hit-or-miss update. Sometimes, like when I took the bait and asked the questions it suggested, I would get shockingly accurate answers. “Try asking ‘which Ariana song is mentioned in the list,’” the Scribe prompted. Or “When is the HOA meeting occurring?” For the former, it told me that the song “Bang Bang” was on a list of karaoke songs, while the latter simply told me the date and time it had found in a note titled “Appointments Dec 2022.” I’ll need more time to think of better ways to use this feature, but for now I can’t decide if it’s actually helpful without some extra work. Cherlynn Low for Engadget I already spent some time testing the Summarize and Refine tools introduced in the last Kindle Scribe, so I’ll just say that refining the handwriting of a to-do list on the Scribe Colorsoft was largely the same as before, just a tad faster. I didn’t really use either AI tool in the year since I reviewed the Scribe 2, so I was right last year in thinking I wouldn’t find much use for them in daily practice. What I thought would be more practical is the redesigned Home screen and the Quick Note that takes up the top left corner of this page. Again, I’d need to spend much more time to understand how I’d navigate the device over weeks and months, but for the most part I find it easy to just hop in and out of notes I want without first going to the Home section. I’d prefer a hardware shortcut like Montblanc offers in its Digital Paper writing tablet. On that device, you can program the buttons on the pen so that a double click starts a new note, adds a blank page or brings you back home. While you can customize the button on Amazon’s Premium Pen, your options are limited to switching between tools like the highlighter, pen, shader or eraser for use while you’re writing. (And yes, like before, you can still use the top of the Premium Pen to erase content — no need to push any button.) One last thing to note about the home page (for now) is that seeing the rows of book covers in color is a delight, and though it’s not something that impacts the function of the device, it certainly adds a layer of visual pleasure. How does the Kindle Scribe Colorsoft compare to the competition? One of the Scribe Colorsoft’s main competitors is the reMarkable Paper Pro. The latter has a larger 11.8-inch screen and, correspondingly, weighs a lot more at 525 grams (1.16 pounds). Though I prefer the sharp lines of the reMarkable to the rounded edges and corners of the Scribe, I find the Kindle’s size much more manageable, especially when I’m writing for more than five minutes. Importantly, the Kindle Scribe Colorsoft simply has a better screen than the reMarkable. It delivers brighter, more saturated colors, and supports more hues, too. Plus, when I placed them next to each other, the Paper Pro seemed to have a yellow cast and a dimmer screen overall (even at maximum brightness). And when I use the highlight function on each, the reMarkable device “flashes” — meaning you have to give it a second for the color to appear in its final form after you put the stylus to the screen. Meanwhile, the color that shows up on the Colorsoft’s panel as soon as you write on it doesn’t change — no flashing takes place. Cherlynn Low for Engadget The Scribe’s other strengths are its superior performance and Amazon’s ecosystem of books (for those like me who already have large Kindle libraries, anyway). Though it does offer AI features that reMarkable doesn’t, I’m generally leery of those tools, and, as already detailed in this review, they don’t usually help me. However, the reMarkable remains the winner when it comes to writing software. It’s way more versatile than Amazon in this respect, especially with its ability to have handwritten and typed text coexist within the same document. You can also edit a note from reMarkable’s app on your phone, typing in any last-minute additions to your shopping list and bolding, italicizing or formatting them if you like. And if you’re a power user, getting your favorite ebooks onto the reMarkable tablet isn’t too difficult, provided you have the EPUB files. The main problem for me here is that you'll need to pay $3 a month for its Connect subscription to continue having access to a lot of these features. I’ll also shout out companies like Kobo and Boox, who also make color-rendering ereaders that you can write on. Boox’s Note Air 5c starts at $530 and includes the stylus and a magnetic case for that price. It supports apps via the Google Play Store, but, as our deputy editor Valentina Palladino cautions, isn’t the most beginner-friendly product. Kobo, on the other hand, makes color ereaders like the Libra Color. Although it does support stylus input, it is much smaller with its 7-inch display. And for those who aren’t too fussed about color, there are plenty of black-and-white E Ink writing tablets, including the $905 Montblanc Digital Paper, which I’ve been testing for a few weeks. I’m finishing up my review but that one is clearly a luxury product targeted at a much more niche audience than the already limited target market for this category of devices. If your budget is tight, I’d recommend skipping the Colorsoft model unless it’s crucial to your process. $500 is a much easier price to stomach. Who should get the Kindle Scribe Colorsoft? I hesitate to recommend anyone buy anything before I’ve had enough time to assign a score, since things like battery life take longer to evaluate. And while I continue to test the device to get a better sense for its battery life, I’ve already noticed that like the Scribes before it, this version doesn’t last as long as other Kindles. Amazon promises weeks of reading and writing per charge, which could be anything between two and ten (or more) weeks. In my experience so far, the Kindle Scribe Colorsoft dropped about 20 percent in two days, which, mathematically, means it would struggle to even last a week, not to mention multiple weeks. But because the Scribe 2 showed similar battery drain during my review (with heavier use) and manages to stay charged for at least a month when I’m not testing it all day every day, I’m willing to believe Amazon’s promise of greater runtime. Aside from my reservations about battery life, the Kindle Scribe Colorsoft is a competent device that delivers on most of its promises so far. The biggest knock against it is its price. At $500 for the monochrome model and $630 for color, this is one Amazon product that can be more expensive than the competition. But it’s not without its strengths. I’d think of the Kindle Scribe 3 (and Colorsoft) as an E Ink tablet that is more of a notebook than a portal for textbooks you can mark up, with a robust library of Kindle titles to boot. The AI features are not crucial to the experience, but they also stay out of the way. For those looking for a more sophisticated and versatile writing tablet that is less of a book replacement, the reMarkable Paper Pro is the superior device. And for people who don’t mind the notifications, apps and alerts that these purpose-driven tablets keep from distracting you, there’s always the option of buying an iPad or an Android tablet with a stylus. Just install minimal apps or block all notifications, and you might even save hundreds of dollars in the process. Cherlynn Low for Engadget Wrap-up I hate to admit it, but Amazon’s devices and services chief Panos Panay was right in calling the Kindle Scribe a 2-in-1. But the two functions it serves are very specific. I think of the Scribe devices as Kindles first and foremost. That means they’re ereaders, capable of substituting stacks of books thanks to their digital libraries and eye-friendly screens. The second role the Scribe plays well is that of a notebook substitute. It is a place to hold endless slips of digital paper, and its search function can competently help you find what you jotted down in a random note years ago. But Amazon has not yet found a way to deliver on features like annotating and marking up ebooks that feels like pen-and-paper. Trying to mark up a digital textbook on the Scribe still feels unintuitive, involving virtual sticky notes, collapsible margins and inserting boxes within lines of text. And you won’t be able to easily edit your notes if you’re away from your Scribe, unlike how you can on a reMarkable product. So the Kindle Scribe 3 is not a three- or four-in-one. I don’t have a problem with that, especially without the extra cost that comes with the color capabilities. While the Colorsoft model is superior to the competition at the moment, it also comes at a premium. If you’re looking for the best color E Ink writing tablet available and are willing to splurge, the Kindle Scribe Colorsoft is worth consideration.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/kindle-scribe-colorsoft-review-a-very-particular-set-of-skills-for-a-price-140014961.html?src=rss",
          "feed_position": 16,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/64d18df0-d56a-11f0-bbcf-fdfdc8e1f0aa"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/how-huds-runtime-sensor-cut-triage-time-from-3-hours-to-10-minutes",
          "published_at": "Wed, 10 Dec 2025 14:00:00 GMT",
          "title": "How Hud's runtime sensor cut triage time from 3 hours to 10 minutes",
          "standfirst": "Engineering teams are generating more code with AI agents than ever before. But they&#x27;re hitting a wall when that code reaches production.The problem isn&#x27;t necessarily the AI-generated code itself. It&#x27;s that traditional monitoring tools generally struggle to provide the granular, function-level data AI agents need to understand how code actually behaves in complex production environments. Without that context, agents can&#x27;t detect issues or generate fixes that account for production reality.It&#x27;s a challenge that startup Hud is looking to help solve with the launch of its runtime code sensor on Wednesday. The company&#x27;s eponymous sensor runs alongside production code, automatically tracking how every function behaves, giving developers a heads-up on what&#x27;s actually occurring in deployment.\"Every software team building at scale faces the same fundamental challenge: building high-quality products that work well in the real world,\" Roee Adler, CEO and founder of Hud, told VentureBeat in an exclusive interview. \"In the new era of AI-accelerated development, not knowing how code behaves in production becomes an even bigger part of that challenge.\"What software developers are struggling with The pain points that developers are facing are fairly consistent across engineering organizations. Moshik Eilon, group tech lead at Monday.com, oversees 130 engineer and describes a familiar frustration with traditional monitoring tools.\"When you get an alert, you usually end up checking an endpoint that has an error rate or high latency, and you want to drill down to see the downstream dependencies,\" Eilon told VentureBeat. \"A lot of times it&#x27;s the actual application, and then it&#x27;s a black box. You just get 80% downstream latency on the application.\"The next step typically involves manual detective work across multiple tools. Check the logs. Correlate timestamps. Try to reconstruct what the application was doing. For novel issues deep in a large codebase, teams often lack the exact data they need.Daniel Marashlian, CTO and co-founder at Drata, saw his engineers spending hours on what he referred to as an \"investigation tax.\" \"They were mapping a generic alert to a specific code owner, then digging through logs to reconstruct the state of the application,\" Marashlian told VentureBeat. \"We wanted to eliminate that so our team could focus entirely on the fix rather than the discovery.\"Drata&#x27;s architecture compounds the challenge. The company integrates with numerous external services to deliver automated compliance, which creates sophisticated investigations when issues arise. Engineers trace behavior across a very large codebase spanning risk, compliance, integrations, and reporting modules.Marashlian identified three specific problems that drove Drata toward investing in runtime sensors. The first issue was the cost of context switching. \"Our data was scattered, so our engineers had to act as human bridges between disconnected tools,\" he said.The second issue, he noted, is alert fatigue. \"When you have a complex distributed system, general alert channels become a constant stream of background noise, what our team describes as a &#x27;ding, ding, ding&#x27; effect that eventually gets ignored,\" Marashlian said.The third key driver was a need to integrate with the company&#x27;s AI strategy.\"An AI agent can write code, but it cannot fix a production bug if it can&#x27;t see the runtime variables or the root cause,\" Marashlian said.Why traditional APMs can&#x27;t solve the problem easilyEnterprises have long relied on a class of tools and services known as Application Performance Monitoring (APM). With the current pace of agentic AI development and modern development workflows, both Monday.com and Drata simply were not able to get the required visibility from existing APM tools.\"If I would want to get this information from Datadog or from CoreLogix, I would just have to ingest tons of logs or tons of spans, and I would pay a lot of money,\" Eilon said. Eilon noted that Monday.com used very low sampling rates because of cost constraints. That meant they often missed the exact data needed to debug issues.Traditional application performance monitoring tools also require prediction, which is a problem because sometimes a developer just doesn&#x27;t know what they don&#x27;t know.\"Traditional observability requires you to anticipate what you&#x27;ll need to debug,\" Marashlian said. \"But when a novel issue surfaces, especially deep within a large, complex codebase, you&#x27;re often missing the exact data you need.\"Drata evaluated several solutions in the AI site reliability engineering and automated incident response categories and didn&#x27;t find what was needed. \"Most tools we evaluated were excellent at managing the incident process, routing tickets, summarizing Slack threads, or correlating graphs,\" he said. \"But they often stopped short of the code itself. They could tell us &#x27;Service A is down,&#x27; but they couldn&#x27;t tell us why specifically.\"Another common capability in some tools including error monitors like Sentry is the ability to capture exceptions. The challenge, according to Adler, is that being made aware of exceptions is nice, but that doesn&#x27;t connect them to business impact or provide the execution context AI agents need to propose fixes.How runtime sensors work differentlyRuntime sensors push intelligence to the edge where code executes. Hud&#x27;s sensor runs as an SDK that integrates with a single line of code. It sees every function execution but only sends lightweight aggregate data unless something goes wrong.When errors or slowdowns occur, the sensor automatically gathers deep forensic data including HTTP parameters, database queries and responses, and full execution context. The system establishes performance baselines within a day and can alert on both dramatic slowdowns and outliers that percentile-based monitoring misses.\"Now we just get all of this information for all of the functions regardless of what level they are, even for underlying packages,\" Eilon said. \"Sometimes you might have an issue that is very deep, and we still see it pretty fast.\"The platform delivers data through four channels:Web application for centralized monitoring and analysisIDE extensions for VS Code, JetBrains and Cursor that surface production metrics directly where code is writtenMCP server that feeds structured data to AI coding agentsAlerting system that identifies issues without manual configurationThe MCP server integration is critical for AI-assisted development. Monday.com engineers now query production behavior directly within Cursor. \"I can just ask Cursor a question: Hey, why is this endpoint slow?\" Eilon said. \"When it uses the Hud MCP, I get all of the granular metrics, and this function is 30% slower since this deployment. Then I can also find the root cause.\"This changes the incident response workflow. Instead of starting in Datadog and drilling down through layers, engineers start by asking an AI agent to diagnose the issue. The agent has immediate access to function-level production data.From voodoo incidents to minutes-long fixesThe shift from theoretical capability to practical impact becomes clear in how engineering teams actually use runtime sensors. What used to take hours or days of detective work now resolves in minutes.\"I&#x27;m used to having these voodoo incidents where there is a CPU spike and you don&#x27;t know where it came from,\" Eilon said. \"A few years ago, I had such an incident and I had to build my own tool that takes the CPU profile and the memory dump. Now I just have all of the function data and I&#x27;ve seen engineers just solve it so fast.\"At Drata, the quantified impact is dramatic. The company built an internal /triage command that support engineers run within their AI assistants to instantly identify root causes. Manual triage work dropped from approximately 3 hours per day to under 10 minutes. Mean time to resolution improved by approximately 70%.The team also generates a daily \"Heads Up\" report of quick-win errors. Because the root cause is already captured, developers can fix these issues in minutes. Support engineers now perform forensic diagnosis that previously required a senior developer. Ticket throughput increased without expanding the L2 team.Where this technology fitsRuntime sensors occupy a distinct space from traditional APMs, which excel at service-level monitoring but struggle with granular, cost-effective function-level data. They differ from error monitors that capture exceptions without business context.The technical requirements for supporting AI coding agents differ from human-facing observability. Agents need structured, function-level data they can reason over. They can&#x27;t parse and correlate raw logs the way humans do. Traditional observability also assumes you can predict what you&#x27;ll need to debug and instrument accordingly. That approach breaks down with AI-generated code where engineers may not deeply understand every function.\"I think we&#x27;re entering a new age of AI-generated code and this puzzle, this jigsaw puzzle of a new stack emerging,\" Adler said. \"I just don&#x27;t think that the cloud computing observability stack is going to fit neatly into how the future looks like.\"What this means for enterprisesFor organizations already using AI coding assistants like GitHub Copilot or Cursor, runtime intelligence provides a safety layer for production deployments. The technology enables what Monday.com calls \"agentic investigation\" rather than manual tool-hopping.The broader implication relates to trust. \"With AI-generated code, we are getting much more AI-generated code, and engineers start not knowing all of the code,\" Eilon said. Runtime sensors bridge that knowledge gap by providing production context directly in the IDE where code is written.For enterprises looking to scale AI code generation beyond pilots, runtime intelligence addresses a fundamental problem. AI agents generate code based on assumptions about system behavior. Production environments are complex and surprising. Function-level behavioral data captured automatically from production gives agents the context they need to generate reliable code at scale.Organizations should evaluate whether their existing observability stack can cost-effectively provide the granularity AI agents require. If achieving function-level visibility requires dramatically increasing ingestion costs or manual instrumentation, runtime sensors may offer a more sustainable architecture for AI-accelerated development workflows already emerging across the industry.",
          "content": "Engineering teams are generating more code with AI agents than ever before. But they&#x27;re hitting a wall when that code reaches production.The problem isn&#x27;t necessarily the AI-generated code itself. It&#x27;s that traditional monitoring tools generally struggle to provide the granular, function-level data AI agents need to understand how code actually behaves in complex production environments. Without that context, agents can&#x27;t detect issues or generate fixes that account for production reality.It&#x27;s a challenge that startup Hud is looking to help solve with the launch of its runtime code sensor on Wednesday. The company&#x27;s eponymous sensor runs alongside production code, automatically tracking how every function behaves, giving developers a heads-up on what&#x27;s actually occurring in deployment.\"Every software team building at scale faces the same fundamental challenge: building high-quality products that work well in the real world,\" Roee Adler, CEO and founder of Hud, told VentureBeat in an exclusive interview. \"In the new era of AI-accelerated development, not knowing how code behaves in production becomes an even bigger part of that challenge.\"What software developers are struggling with The pain points that developers are facing are fairly consistent across engineering organizations. Moshik Eilon, group tech lead at Monday.com, oversees 130 engineer and describes a familiar frustration with traditional monitoring tools.\"When you get an alert, you usually end up checking an endpoint that has an error rate or high latency, and you want to drill down to see the downstream dependencies,\" Eilon told VentureBeat. \"A lot of times it&#x27;s the actual application, and then it&#x27;s a black box. You just get 80% downstream latency on the application.\"The next step typically involves manual detective work across multiple tools. Check the logs. Correlate timestamps. Try to reconstruct what the application was doing. For novel issues deep in a large codebase, teams often lack the exact data they need.Daniel Marashlian, CTO and co-founder at Drata, saw his engineers spending hours on what he referred to as an \"investigation tax.\" \"They were mapping a generic alert to a specific code owner, then digging through logs to reconstruct the state of the application,\" Marashlian told VentureBeat. \"We wanted to eliminate that so our team could focus entirely on the fix rather than the discovery.\"Drata&#x27;s architecture compounds the challenge. The company integrates with numerous external services to deliver automated compliance, which creates sophisticated investigations when issues arise. Engineers trace behavior across a very large codebase spanning risk, compliance, integrations, and reporting modules.Marashlian identified three specific problems that drove Drata toward investing in runtime sensors. The first issue was the cost of context switching. \"Our data was scattered, so our engineers had to act as human bridges between disconnected tools,\" he said.The second issue, he noted, is alert fatigue. \"When you have a complex distributed system, general alert channels become a constant stream of background noise, what our team describes as a &#x27;ding, ding, ding&#x27; effect that eventually gets ignored,\" Marashlian said.The third key driver was a need to integrate with the company&#x27;s AI strategy.\"An AI agent can write code, but it cannot fix a production bug if it can&#x27;t see the runtime variables or the root cause,\" Marashlian said.Why traditional APMs can&#x27;t solve the problem easilyEnterprises have long relied on a class of tools and services known as Application Performance Monitoring (APM). With the current pace of agentic AI development and modern development workflows, both Monday.com and Drata simply were not able to get the required visibility from existing APM tools.\"If I would want to get this information from Datadog or from CoreLogix, I would just have to ingest tons of logs or tons of spans, and I would pay a lot of money,\" Eilon said. Eilon noted that Monday.com used very low sampling rates because of cost constraints. That meant they often missed the exact data needed to debug issues.Traditional application performance monitoring tools also require prediction, which is a problem because sometimes a developer just doesn&#x27;t know what they don&#x27;t know.\"Traditional observability requires you to anticipate what you&#x27;ll need to debug,\" Marashlian said. \"But when a novel issue surfaces, especially deep within a large, complex codebase, you&#x27;re often missing the exact data you need.\"Drata evaluated several solutions in the AI site reliability engineering and automated incident response categories and didn&#x27;t find what was needed. \"Most tools we evaluated were excellent at managing the incident process, routing tickets, summarizing Slack threads, or correlating graphs,\" he said. \"But they often stopped short of the code itself. They could tell us &#x27;Service A is down,&#x27; but they couldn&#x27;t tell us why specifically.\"Another common capability in some tools including error monitors like Sentry is the ability to capture exceptions. The challenge, according to Adler, is that being made aware of exceptions is nice, but that doesn&#x27;t connect them to business impact or provide the execution context AI agents need to propose fixes.How runtime sensors work differentlyRuntime sensors push intelligence to the edge where code executes. Hud&#x27;s sensor runs as an SDK that integrates with a single line of code. It sees every function execution but only sends lightweight aggregate data unless something goes wrong.When errors or slowdowns occur, the sensor automatically gathers deep forensic data including HTTP parameters, database queries and responses, and full execution context. The system establishes performance baselines within a day and can alert on both dramatic slowdowns and outliers that percentile-based monitoring misses.\"Now we just get all of this information for all of the functions regardless of what level they are, even for underlying packages,\" Eilon said. \"Sometimes you might have an issue that is very deep, and we still see it pretty fast.\"The platform delivers data through four channels:Web application for centralized monitoring and analysisIDE extensions for VS Code, JetBrains and Cursor that surface production metrics directly where code is writtenMCP server that feeds structured data to AI coding agentsAlerting system that identifies issues without manual configurationThe MCP server integration is critical for AI-assisted development. Monday.com engineers now query production behavior directly within Cursor. \"I can just ask Cursor a question: Hey, why is this endpoint slow?\" Eilon said. \"When it uses the Hud MCP, I get all of the granular metrics, and this function is 30% slower since this deployment. Then I can also find the root cause.\"This changes the incident response workflow. Instead of starting in Datadog and drilling down through layers, engineers start by asking an AI agent to diagnose the issue. The agent has immediate access to function-level production data.From voodoo incidents to minutes-long fixesThe shift from theoretical capability to practical impact becomes clear in how engineering teams actually use runtime sensors. What used to take hours or days of detective work now resolves in minutes.\"I&#x27;m used to having these voodoo incidents where there is a CPU spike and you don&#x27;t know where it came from,\" Eilon said. \"A few years ago, I had such an incident and I had to build my own tool that takes the CPU profile and the memory dump. Now I just have all of the function data and I&#x27;ve seen engineers just solve it so fast.\"At Drata, the quantified impact is dramatic. The company built an internal /triage command that support engineers run within their AI assistants to instantly identify root causes. Manual triage work dropped from approximately 3 hours per day to under 10 minutes. Mean time to resolution improved by approximately 70%.The team also generates a daily \"Heads Up\" report of quick-win errors. Because the root cause is already captured, developers can fix these issues in minutes. Support engineers now perform forensic diagnosis that previously required a senior developer. Ticket throughput increased without expanding the L2 team.Where this technology fitsRuntime sensors occupy a distinct space from traditional APMs, which excel at service-level monitoring but struggle with granular, cost-effective function-level data. They differ from error monitors that capture exceptions without business context.The technical requirements for supporting AI coding agents differ from human-facing observability. Agents need structured, function-level data they can reason over. They can&#x27;t parse and correlate raw logs the way humans do. Traditional observability also assumes you can predict what you&#x27;ll need to debug and instrument accordingly. That approach breaks down with AI-generated code where engineers may not deeply understand every function.\"I think we&#x27;re entering a new age of AI-generated code and this puzzle, this jigsaw puzzle of a new stack emerging,\" Adler said. \"I just don&#x27;t think that the cloud computing observability stack is going to fit neatly into how the future looks like.\"What this means for enterprisesFor organizations already using AI coding assistants like GitHub Copilot or Cursor, runtime intelligence provides a safety layer for production deployments. The technology enables what Monday.com calls \"agentic investigation\" rather than manual tool-hopping.The broader implication relates to trust. \"With AI-generated code, we are getting much more AI-generated code, and engineers start not knowing all of the code,\" Eilon said. Runtime sensors bridge that knowledge gap by providing production context directly in the IDE where code is written.For enterprises looking to scale AI code generation beyond pilots, runtime intelligence addresses a fundamental problem. AI agents generate code based on assumptions about system behavior. Production environments are complex and surprising. Function-level behavioral data captured automatically from production gives agents the context they need to generate reliable code at scale.Organizations should evaluate whether their existing observability stack can cost-effectively provide the granularity AI agents require. If achieving function-level visibility requires dramatically increasing ingestion costs or manual instrumentation, runtime sensors may offer a more sustainable architecture for AI-accelerated development workflows already emerging across the industry.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5OFBMkrEKqvqYY0hbPYaoF/e31f8e8b39af32f6197a402b42f96136/hud-code-dev-smk.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/quilters-ai-just-designed-an-843-part-linux-computer-that-booted-on-the",
          "published_at": "Wed, 10 Dec 2025 14:00:00 GMT",
          "title": "Quilter's AI just designed an 843‑part Linux computer that booted on the first try. Hardware will never be the same.",
          "standfirst": "A Los Angeles-based startup has demonstrated what it calls a breakthrough in hardware development: an artificial intelligence system that designed a fully functional Linux computer in one week — a process that would typically consume nearly three months of skilled engineering labor.Quilter, which has raised more than $40 million from investors including Benchmark, Index Ventures, and Coatue, used its physics-driven AI to automate the design of a two-board computer system that booted successfully on its first attempt, requiring no costly revisions. The project, internally dubbed \"Project Speedrun,\" required just 38.5 hours of human labor compared to the 428 hours that professional PCB designers quoted for the same task.The announcement also marks the first public disclosure that Tony Fadell, the engineer who led development of the iPod and iPhone at Apple and later founded Nest, has invested in the company and serves as an advisor.\"We didn&#x27;t teach Quilter to draw; we taught it to think in physics,\" said Sergiy Nesterenko, Quilter&#x27;s chief executive and a former SpaceX engineer, in an exclusive interview with VentureBeat. \"The result wasn&#x27;t a simulation — it was a working computer.\"Circuit board design remains the forgotten bottleneck that delays nearly every hardware productThe announcement shines a light on an unglamorous but critical chokepoint in technology development: printed circuit board layout. While semiconductors and software have received enormous attention and investment, the green fiberglass boards that connect chips, memory, and components in virtually every electronic device remain stubbornly manual to design.\"Besides auto-routers, the technology really hadn&#x27;t changed since the early &#x27;90s,\" Fadell told VentureBeat. \"The best boards are still made by hand. You go to Apple, they&#x27;ve got the tools, and these guys are just pushing traces, checking everything, doing flood fills—and you&#x27;re like, there&#x27;s got to be a better way.\"The PCB design process typically unfolds in three stages. Engineers first create a schematic — a logical diagram showing how components connect. Then a specialist manually draws the physical layout in CAD software, placing components and routing thousands of copper traces across multiple layers. Finally, the design goes to a manufacturer for fabrication.That middle step — the layout — creates a persistent bottleneck. For a board of moderate complexity, the process typically consumes four to eight weeks. For sophisticated systems like computers or automotive electronics, timelines stretch to three months or longer.\"The timeline was always this elastic thing—they&#x27;d say, &#x27;Yeah, that&#x27;s two weeks minimum,&#x27;\" Fadell recalled of his experience at Apple and Nest. \"And we&#x27;d say, &#x27;No, no. Work day and night. It&#x27;s two weeks.&#x27; But it was always this fixed bottleneck.\"The consequences ripple through hardware organizations. Firmware teams sit idle waiting for physical boards to test their code. Validation engineers cannot begin debugging. Product launches slip. According to Quilter&#x27;s research, only about 10 percent of first board revisions work correctly, forcing expensive and time-consuming respins.Project Speedrun put Quilter&#x27;s AI to the test with an 843-component computer that booted on the first tryProject Speedrun was designed to push the technology to its limits while producing an easily understood result: a working computer that could boot Linux, browse the internet, and run applications.The system consists of two boards based on NXP&#x27;s i.MX 8M Mini reference platform, a processor architecture used in automotive infotainment, industrial automation, and machine vision applications.The main system-on-module contains a quad-core ARM processor running at 1.8 gigahertz, 2 gigabytes of LPDDR4 memory, and 32 gigabytes of eMMC storage. A companion baseboard provides connectivity including Ethernet, USB, HDMI, and audio.Together, the boards incorporate 843 components and 5,141 electrical connections, or \"pins,\" routed across eight-layer circuit board stackups manufactured by Sierra Circuits in California. The minimum trace geometry reached 2 mils (two-thousandths of an inch) on the system-on-module — fine enough to require advanced high-density interconnect manufacturing techniques.Quilter&#x27;s AI completed the layout with approximately 98 percent routing coverage and zero design rule violations. Both boards passed power-on testing and successfully booted Debian Linux on the first attempt.\"We made an entire computer to demonstrate that this technology works,\" Nesterenko said. \"We took something that&#x27;s typically quoted at 400 to 450 hours, automated the vast majority of it, and reduced it to about 30 to 40 hours of cleanup time.\"The cleanup time is work that human engineers still perform: reviewing the AI&#x27;s output, fixing any issues, and preparing final fabrication files. But even with that overhead, the total elapsed time from schematic to fabricated boards collapsed from the typical 11 weeks to a single week.Unlike ChatGPT, Quilter&#x27;s AI learns by playing billions of games against the laws of physicsQuilter&#x27;s technical approach differs fundamentally from the large language models that have dominated recent AI headlines. Where systems like GPT-5 or Claude learn to predict text based on massive training datasets of human writing, Quilter&#x27;s AI learns by playing what amounts to an elaborate game against the laws of physics.\"Language models don&#x27;t apply to us because this is not a language problem,\" Nesterenko explained. \"If you ask it to actually create a blueprint, it has no training data for that. It has no context for that.\"The company also rejected the seemingly obvious approach of training on examples of human-designed boards. Nesterenko cited three reasons: humans make frequent errors (explaining why most boards require revisions), the best designs are locked inside large companies unwilling to share proprietary data, and training on human examples would cap the AI&#x27;s performance at human levels.Instead, Quilter built what Nesterenko describes as a \"game\" where the AI agent makes sequential decisions — place this component here, route this trace there — and receives feedback based on whether the resulting design satisfies electromagnetic, thermal, and manufacturing constraints.\"What you&#x27;re really changing is not the probability of getting a very specific outcome of the model, but the probability of choosing a certain action based on that experience,\" Nesterenko said.The approach mirrors DeepMind&#x27;s progression with its Go-playing systems. The original AlphaGo learned from human games, but its successor AlphaZero learned purely through self-play and ultimately surpassed human capability. Quilter harbors similar ambitions.\"In the long term, to come up with better designs for circuit boards than humans have ever tried to do,\" Nesterenko said.Fadell drew a parallel to an earlier technological transition: \"I remember this with assembly. You had assembly and compilers, and engineers would say, &#x27;I can&#x27;t trust the compiler. I&#x27;m going to do the loop unrolling myself.&#x27; Now very, very few people write any assembly.\"He expects PCB design to follow a similar arc: \"I hope the same thing happens with PCB design. Sure, a few people will hold out, but these tools are going to get so good that everyone else will move on.\"Fadell and Nesterenko spent months solving a delicate problem: how to automate design without stripping engineers of controlAutomating a task that skilled professionals have performed manually for decades raises an obvious question: how do engineers maintain control over designs that will ultimately ship in products where reliability matters?Fadell said he spent significant time with Nesterenko working through this tension. The solution, he said, lies in allowing users to choose their level of involvement at each stage of the process.\"If you&#x27;re a control freak, you can be a control freak. If you want to say &#x27;just do it for me,&#x27; you can do that too—and everything in between,\" Fadell said. \"You can walk through each phase of the design and get involved wherever you want, or let the AI handle it.\"The workflow breaks into three phases: setup, where engineers define constraints and requirements; execution, where the AI generates candidate layouts; and cleanup, where humans review and refine the output. Engineers can intervene at any point, adjusting constraints and regenerating designs until they&#x27;re satisfied.\"This is something Tony and I talk about a lot,\" Nesterenko said. \"How do we give users control while still automating most of the work?\"Quilter&#x27;s technology has clear boundaries: 10,000 pins and 10 gigahertz mark the current limitsThe technology has clear limitations. Quilter currently handles boards with up to roughly 10,000 pins — sufficient for a wide range of applications but well short of the most complex designs, which can exceed 100,000 connections.Physics complexity also creates boundaries. The system handles high-speed communications up to approximately 10 gigahertz, covering typical consumer electronics and many industrial applications. But advanced systems like sophisticated radar, which can operate at 100 gigahertz, exceed current capabilities.\"There are boards where Quilter won&#x27;t make enough progress to make the cleanup time worthwhile,\" Nesterenko acknowledged. \"We&#x27;re just not that helpful yet with the most advanced, sophisticated designs.\"The company has focused initially on categories where speed matters more than extreme complexity: test fixtures, evaluation boards, design validation boards, and environmental test hardware. These boards often sit in long queues behind higher-priority production designs, delaying engineering programs.The company bets that engineers will pay the same price for a 10x speed improvementQuilter prices its service by pin count, matching the billing conventions that already exist when companies hire outside layout specialists. The pitch to customers is cost neutrality with a ten-fold improvement in speed.\"We&#x27;re going to charge you roughly the same that you would pay for the pins that you would with a person,\" Nesterenko said. \"But the reason you choose us is that we do this 10 times faster.\"For a company waiting three months for a board layout, receiving it in a week fundamentally changes what&#x27;s possible. Engineering teams can run multiple design experiments in parallel. Firmware developers get hardware faster. Products reach the market sooner.The company offers free access for hobbyists, students, and small businesses with less than $50,000 in revenue — a strategy to build familiarity while targeting enterprise customers for commercial revenue.The iPod creator waited years to attach his name to Quilter — until he could prove the technology actually worksFadell said he chose this moment to publicly acknowledge his investment because the Project Speedrun demonstration provides concrete evidence that the technology works.\"It&#x27;s not about being comfortable—I was always comfortable with the team,\" he said. \"This was about waiting until we had something you could hang your hat on. Now I can say, &#x27;I&#x27;ve used the tool. I&#x27;ve seen it.&#x27;\"He contrasted his approach with typical investor announcements: \"Every investor goes, I invested in this, it&#x27;s gonna change the world. It&#x27;s like, no, I know better. I&#x27;ve used the tool. I know people who use it. I asked my startups to use the tool.\"Fadell&#x27;s involvement goes beyond capital. He described email exchanges running to \"a dozen pages of details\" covering product design, user experience, enterprise sales, and technical architecture.\"Of all the investors I work with, Tony by far goes deepest with me on the product side,\" Nesterenko said.If Quilter succeeds, it could unlock a new generation of hardware startups that were never economically viable beforeThe stakes extend far beyond one company&#x27;s product roadmap. If Quilter&#x27;s technology scales, it could fundamentally alter the economics of building physical products.Fadell argued that hardware development has historically moved slowly because each step in the process — schematic design, PCB layout, manufacturing, assembly — created friction. Other innovations have already smoothed schematic tools and manufacturing. Layout remained the stubborn holdout.\"Once you shrink that from weeks to hours, you can iterate so much faster because all the other friction in the chain has been reduced,\" Fadell said.He predicted the technology would eventually extend upstream into schematic design itself, with AI that understands both logical connections and physical constraints helping engineers avoid problems earlier in the process.At MIT, where Fadell now spends time, he encounters would-be founders who have abandoned hardware ambitions because the process seemed insurmountable.\"I talk to professors and startup founders, and they say, &#x27;I&#x27;m never doing hardware. It&#x27;s too hard,&#x27;\" he said. \"I hope we can make it easier for more people to jump in and try things.\"Industry veterans remain skeptical. Auto-routing tools — previous attempts at automation — became notorious for producing unusable results, spawning T-shirts proclaiming engineers would \"never trust the auto-router.\"Nesterenko has seen the skepticism dissolve in real time. He described a recent meeting with executives from a major customer who came to discuss Quilter&#x27;s capabilities. As the conversation unfolded, one executive picked up the Project Speedrun boards and began photographing them from every angle, turning them over in his hands.\"He was just fascinated by the fact that this is possible now,\" Nesterenko said.The question is no longer whether AI can design circuit boards. A working Linux computer, assembled from 843 components and booted on the first attempt, answers that definitively. The question now is what engineers will build when layout stops being the bottleneck — when hardware, as Fadell put it, finally \"moves at the speed of thought.\"On that point, Nesterenko offered a prediction. \"If you ask the average electrical engineer today whether automation or AI could at all help with the board of this complexity, they would say no,\" he said. For decades, they would have been right. As of last week, they&#x27;re not.",
          "content": "A Los Angeles-based startup has demonstrated what it calls a breakthrough in hardware development: an artificial intelligence system that designed a fully functional Linux computer in one week — a process that would typically consume nearly three months of skilled engineering labor.Quilter, which has raised more than $40 million from investors including Benchmark, Index Ventures, and Coatue, used its physics-driven AI to automate the design of a two-board computer system that booted successfully on its first attempt, requiring no costly revisions. The project, internally dubbed \"Project Speedrun,\" required just 38.5 hours of human labor compared to the 428 hours that professional PCB designers quoted for the same task.The announcement also marks the first public disclosure that Tony Fadell, the engineer who led development of the iPod and iPhone at Apple and later founded Nest, has invested in the company and serves as an advisor.\"We didn&#x27;t teach Quilter to draw; we taught it to think in physics,\" said Sergiy Nesterenko, Quilter&#x27;s chief executive and a former SpaceX engineer, in an exclusive interview with VentureBeat. \"The result wasn&#x27;t a simulation — it was a working computer.\"Circuit board design remains the forgotten bottleneck that delays nearly every hardware productThe announcement shines a light on an unglamorous but critical chokepoint in technology development: printed circuit board layout. While semiconductors and software have received enormous attention and investment, the green fiberglass boards that connect chips, memory, and components in virtually every electronic device remain stubbornly manual to design.\"Besides auto-routers, the technology really hadn&#x27;t changed since the early &#x27;90s,\" Fadell told VentureBeat. \"The best boards are still made by hand. You go to Apple, they&#x27;ve got the tools, and these guys are just pushing traces, checking everything, doing flood fills—and you&#x27;re like, there&#x27;s got to be a better way.\"The PCB design process typically unfolds in three stages. Engineers first create a schematic — a logical diagram showing how components connect. Then a specialist manually draws the physical layout in CAD software, placing components and routing thousands of copper traces across multiple layers. Finally, the design goes to a manufacturer for fabrication.That middle step — the layout — creates a persistent bottleneck. For a board of moderate complexity, the process typically consumes four to eight weeks. For sophisticated systems like computers or automotive electronics, timelines stretch to three months or longer.\"The timeline was always this elastic thing—they&#x27;d say, &#x27;Yeah, that&#x27;s two weeks minimum,&#x27;\" Fadell recalled of his experience at Apple and Nest. \"And we&#x27;d say, &#x27;No, no. Work day and night. It&#x27;s two weeks.&#x27; But it was always this fixed bottleneck.\"The consequences ripple through hardware organizations. Firmware teams sit idle waiting for physical boards to test their code. Validation engineers cannot begin debugging. Product launches slip. According to Quilter&#x27;s research, only about 10 percent of first board revisions work correctly, forcing expensive and time-consuming respins.Project Speedrun put Quilter&#x27;s AI to the test with an 843-component computer that booted on the first tryProject Speedrun was designed to push the technology to its limits while producing an easily understood result: a working computer that could boot Linux, browse the internet, and run applications.The system consists of two boards based on NXP&#x27;s i.MX 8M Mini reference platform, a processor architecture used in automotive infotainment, industrial automation, and machine vision applications.The main system-on-module contains a quad-core ARM processor running at 1.8 gigahertz, 2 gigabytes of LPDDR4 memory, and 32 gigabytes of eMMC storage. A companion baseboard provides connectivity including Ethernet, USB, HDMI, and audio.Together, the boards incorporate 843 components and 5,141 electrical connections, or \"pins,\" routed across eight-layer circuit board stackups manufactured by Sierra Circuits in California. The minimum trace geometry reached 2 mils (two-thousandths of an inch) on the system-on-module — fine enough to require advanced high-density interconnect manufacturing techniques.Quilter&#x27;s AI completed the layout with approximately 98 percent routing coverage and zero design rule violations. Both boards passed power-on testing and successfully booted Debian Linux on the first attempt.\"We made an entire computer to demonstrate that this technology works,\" Nesterenko said. \"We took something that&#x27;s typically quoted at 400 to 450 hours, automated the vast majority of it, and reduced it to about 30 to 40 hours of cleanup time.\"The cleanup time is work that human engineers still perform: reviewing the AI&#x27;s output, fixing any issues, and preparing final fabrication files. But even with that overhead, the total elapsed time from schematic to fabricated boards collapsed from the typical 11 weeks to a single week.Unlike ChatGPT, Quilter&#x27;s AI learns by playing billions of games against the laws of physicsQuilter&#x27;s technical approach differs fundamentally from the large language models that have dominated recent AI headlines. Where systems like GPT-5 or Claude learn to predict text based on massive training datasets of human writing, Quilter&#x27;s AI learns by playing what amounts to an elaborate game against the laws of physics.\"Language models don&#x27;t apply to us because this is not a language problem,\" Nesterenko explained. \"If you ask it to actually create a blueprint, it has no training data for that. It has no context for that.\"The company also rejected the seemingly obvious approach of training on examples of human-designed boards. Nesterenko cited three reasons: humans make frequent errors (explaining why most boards require revisions), the best designs are locked inside large companies unwilling to share proprietary data, and training on human examples would cap the AI&#x27;s performance at human levels.Instead, Quilter built what Nesterenko describes as a \"game\" where the AI agent makes sequential decisions — place this component here, route this trace there — and receives feedback based on whether the resulting design satisfies electromagnetic, thermal, and manufacturing constraints.\"What you&#x27;re really changing is not the probability of getting a very specific outcome of the model, but the probability of choosing a certain action based on that experience,\" Nesterenko said.The approach mirrors DeepMind&#x27;s progression with its Go-playing systems. The original AlphaGo learned from human games, but its successor AlphaZero learned purely through self-play and ultimately surpassed human capability. Quilter harbors similar ambitions.\"In the long term, to come up with better designs for circuit boards than humans have ever tried to do,\" Nesterenko said.Fadell drew a parallel to an earlier technological transition: \"I remember this with assembly. You had assembly and compilers, and engineers would say, &#x27;I can&#x27;t trust the compiler. I&#x27;m going to do the loop unrolling myself.&#x27; Now very, very few people write any assembly.\"He expects PCB design to follow a similar arc: \"I hope the same thing happens with PCB design. Sure, a few people will hold out, but these tools are going to get so good that everyone else will move on.\"Fadell and Nesterenko spent months solving a delicate problem: how to automate design without stripping engineers of controlAutomating a task that skilled professionals have performed manually for decades raises an obvious question: how do engineers maintain control over designs that will ultimately ship in products where reliability matters?Fadell said he spent significant time with Nesterenko working through this tension. The solution, he said, lies in allowing users to choose their level of involvement at each stage of the process.\"If you&#x27;re a control freak, you can be a control freak. If you want to say &#x27;just do it for me,&#x27; you can do that too—and everything in between,\" Fadell said. \"You can walk through each phase of the design and get involved wherever you want, or let the AI handle it.\"The workflow breaks into three phases: setup, where engineers define constraints and requirements; execution, where the AI generates candidate layouts; and cleanup, where humans review and refine the output. Engineers can intervene at any point, adjusting constraints and regenerating designs until they&#x27;re satisfied.\"This is something Tony and I talk about a lot,\" Nesterenko said. \"How do we give users control while still automating most of the work?\"Quilter&#x27;s technology has clear boundaries: 10,000 pins and 10 gigahertz mark the current limitsThe technology has clear limitations. Quilter currently handles boards with up to roughly 10,000 pins — sufficient for a wide range of applications but well short of the most complex designs, which can exceed 100,000 connections.Physics complexity also creates boundaries. The system handles high-speed communications up to approximately 10 gigahertz, covering typical consumer electronics and many industrial applications. But advanced systems like sophisticated radar, which can operate at 100 gigahertz, exceed current capabilities.\"There are boards where Quilter won&#x27;t make enough progress to make the cleanup time worthwhile,\" Nesterenko acknowledged. \"We&#x27;re just not that helpful yet with the most advanced, sophisticated designs.\"The company has focused initially on categories where speed matters more than extreme complexity: test fixtures, evaluation boards, design validation boards, and environmental test hardware. These boards often sit in long queues behind higher-priority production designs, delaying engineering programs.The company bets that engineers will pay the same price for a 10x speed improvementQuilter prices its service by pin count, matching the billing conventions that already exist when companies hire outside layout specialists. The pitch to customers is cost neutrality with a ten-fold improvement in speed.\"We&#x27;re going to charge you roughly the same that you would pay for the pins that you would with a person,\" Nesterenko said. \"But the reason you choose us is that we do this 10 times faster.\"For a company waiting three months for a board layout, receiving it in a week fundamentally changes what&#x27;s possible. Engineering teams can run multiple design experiments in parallel. Firmware developers get hardware faster. Products reach the market sooner.The company offers free access for hobbyists, students, and small businesses with less than $50,000 in revenue — a strategy to build familiarity while targeting enterprise customers for commercial revenue.The iPod creator waited years to attach his name to Quilter — until he could prove the technology actually worksFadell said he chose this moment to publicly acknowledge his investment because the Project Speedrun demonstration provides concrete evidence that the technology works.\"It&#x27;s not about being comfortable—I was always comfortable with the team,\" he said. \"This was about waiting until we had something you could hang your hat on. Now I can say, &#x27;I&#x27;ve used the tool. I&#x27;ve seen it.&#x27;\"He contrasted his approach with typical investor announcements: \"Every investor goes, I invested in this, it&#x27;s gonna change the world. It&#x27;s like, no, I know better. I&#x27;ve used the tool. I know people who use it. I asked my startups to use the tool.\"Fadell&#x27;s involvement goes beyond capital. He described email exchanges running to \"a dozen pages of details\" covering product design, user experience, enterprise sales, and technical architecture.\"Of all the investors I work with, Tony by far goes deepest with me on the product side,\" Nesterenko said.If Quilter succeeds, it could unlock a new generation of hardware startups that were never economically viable beforeThe stakes extend far beyond one company&#x27;s product roadmap. If Quilter&#x27;s technology scales, it could fundamentally alter the economics of building physical products.Fadell argued that hardware development has historically moved slowly because each step in the process — schematic design, PCB layout, manufacturing, assembly — created friction. Other innovations have already smoothed schematic tools and manufacturing. Layout remained the stubborn holdout.\"Once you shrink that from weeks to hours, you can iterate so much faster because all the other friction in the chain has been reduced,\" Fadell said.He predicted the technology would eventually extend upstream into schematic design itself, with AI that understands both logical connections and physical constraints helping engineers avoid problems earlier in the process.At MIT, where Fadell now spends time, he encounters would-be founders who have abandoned hardware ambitions because the process seemed insurmountable.\"I talk to professors and startup founders, and they say, &#x27;I&#x27;m never doing hardware. It&#x27;s too hard,&#x27;\" he said. \"I hope we can make it easier for more people to jump in and try things.\"Industry veterans remain skeptical. Auto-routing tools — previous attempts at automation — became notorious for producing unusable results, spawning T-shirts proclaiming engineers would \"never trust the auto-router.\"Nesterenko has seen the skepticism dissolve in real time. He described a recent meeting with executives from a major customer who came to discuss Quilter&#x27;s capabilities. As the conversation unfolded, one executive picked up the Project Speedrun boards and began photographing them from every angle, turning them over in his hands.\"He was just fascinated by the fact that this is possible now,\" Nesterenko said.The question is no longer whether AI can design circuit boards. A working Linux computer, assembled from 843 components and booted on the first attempt, answers that definitively. The question now is what engineers will build when layout stops being the bottleneck — when hardware, as Fadell put it, finally \"moves at the speed of thought.\"On that point, Nesterenko offered a prediction. \"If you ask the average electrical engineer today whether automation or AI could at all help with the board of this complexity, they would say no,\" he said. For decades, they would have been right. As of last week, they&#x27;re not.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3ibU0O0ON6nC4NSVY5KYkP/e13a276f2bece890100148b10cbcf165/nuneybits_Vector_art_of_self-building_computer_isometric_ca3b7721-5759-4033-9885-e096e5d68ddc.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/instagram-will-let-you-control-which-topics-its-algorithm-recommends-133002612.html",
          "published_at": "Wed, 10 Dec 2025 13:30:02 +0000",
          "title": "Instagram will let you control which topics its algorithm recommends",
          "standfirst": "For the first time, Instagram will start letting you control the topics its algorithm recommends, much as you now can on TikTok. The new feature is starting with the Reels tab but will eventually come to Explore and other areas of the app. Like much of what Meta is doing right now (for better or worse), the \"Your Algorithm\" feature will be powered by AI. \"As your interests evolve over time, we want to give you more meaningful ways to control what you see,\" Instagram wrote on its blog post. \"Using AI, you can now more easily view and personalize the topics that shape your Reels, making recommendations feel even more tailored to you.\" To see and control the Reels algorithm, tap the icon in the upper right corner (two lines with hearts) to open Your Algorithm. It will show what topics Instagram thinks you're interested in, then you can specify which ones you want to see more or less of and your recommendations will adapt. You can fine tune topics as well: See your top interests: View a summary of the topics Instagram thinks you care about most, right at the top. Tune your preferences: Type in the topics you want to see more or less of, and your Reels will reflect your choices. Share your algorithm: If you’d like, you can share your interests to your Story, so friends and followers can see what you’re into. Another AI \"feature\" that surfaced yesterday on the platform didn't go over well with some users. It was discovered that Instagram was generating sensational and often inaccurate headlines that were likely created by an LLM. And you can expect AI to infiltrate its apps even more down the road, judging by the company's recent acquisitions and priority shifts. In any case, the new Your Algorithm feature for the Reels tab is debuting today in the US only and expanding to other territories in the future.This article originally appeared on Engadget at https://www.engadget.com/social-media/instagram-will-let-you-control-which-topics-its-algorithm-recommends-133002612.html?src=rss",
          "content": "For the first time, Instagram will start letting you control the topics its algorithm recommends, much as you now can on TikTok. The new feature is starting with the Reels tab but will eventually come to Explore and other areas of the app. Like much of what Meta is doing right now (for better or worse), the \"Your Algorithm\" feature will be powered by AI. \"As your interests evolve over time, we want to give you more meaningful ways to control what you see,\" Instagram wrote on its blog post. \"Using AI, you can now more easily view and personalize the topics that shape your Reels, making recommendations feel even more tailored to you.\" To see and control the Reels algorithm, tap the icon in the upper right corner (two lines with hearts) to open Your Algorithm. It will show what topics Instagram thinks you're interested in, then you can specify which ones you want to see more or less of and your recommendations will adapt. You can fine tune topics as well: See your top interests: View a summary of the topics Instagram thinks you care about most, right at the top. Tune your preferences: Type in the topics you want to see more or less of, and your Reels will reflect your choices. Share your algorithm: If you’d like, you can share your interests to your Story, so friends and followers can see what you’re into. Another AI \"feature\" that surfaced yesterday on the platform didn't go over well with some users. It was discovered that Instagram was generating sensational and often inaccurate headlines that were likely created by an LLM. And you can expect AI to infiltrate its apps even more down the road, judging by the company's recent acquisitions and priority shifts. In any case, the new Your Algorithm feature for the Reels tab is debuting today in the US only and expanding to other territories in the future.This article originally appeared on Engadget at https://www.engadget.com/social-media/instagram-will-let-you-control-which-topics-its-algorithm-recommends-133002612.html?src=rss",
          "feed_position": 18
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/adobe-brings-photoshop-acrobat-and-adobe-express-to-chatgpt-130000389.html",
          "published_at": "Wed, 10 Dec 2025 13:00:00 +0000",
          "title": "Adobe brings Photoshop, Acrobat and Adobe Express to ChatGPT",
          "standfirst": "Back in October, OpenAI announced apps like Spotify and Canva would be accessible in ChatGPT. At the time, the company said more software was on the way, and now one of the most popular professional applications is available through the chatbot. Starting today, you can access Photoshop, Acrobat and Adobe Express inside of ChatGPT. All the apps are free to use through OpenAI’s website, though before you can begin generating PDFs and illustrations using Acrobat and Adobe Express, you'll need to sign into your Adobe account. To use any of the apps in ChatGPT, either name them in your prompt or select them from the plus menu. Of the three apps, the way OpenAI's chatbot connects to Photoshop is probably the most interesting. Depending on the prompt, the interface will change to display the sliders most relevant to your request. For example, if you want to brighten an image, you'll see one slider allowing you to adjust the exposure, alongside other ones for the shadows and highlights. By comparison, if you want to add an effect to an image, ChatGPT might display options related to dithering and tri-tone, among others. What's interesting about all this is the way ChatGPT is interacting with Adobe's tools, through an MCP server, to offer a slice of the company's apps. I don't know about you, but I’ve always found Adobe software to be far too complicated, with often one too many ways to accomplish the same task. Granted, what I saw was a hands-off demo, but the routing Adobe created worked well. A ChatGPT user asks the chatbot to create a dance party invitation. Adobe\"We build the Lego blocks, which are the MCP tools, and we create detailed instructions, and then ChatGPT figures out what it wants to do,\" Aubrey Cattell, vice-president of developer platform and partner ecosystem at Adobe, explains. \"Sometimes it does what we want it, and sometimes it doesn't. That's the nature of it being non-deterministic, and we're continuing to hone as much as we can from users' intent and natural language to give them the result that they're looking for.\"Of course, if you ever want more control, the web versions of Photoshop, Acrobat and Adobe Express are a click away. For OpenAI, this is easily the biggest coup to date of its push to reshape ChatGPT into an operating system for all the apps its more than 800 million users depend on daily. For Adobe, it feels like the company is partnering with an entity out to eat its lunch. After all, OpenAI offers its own image generation. However, Cattell said Adobe doesn't see it that way. \"A couple weeks back, OpenAI dropped Apps SDK as a new paradigm for accessing ChatGPT, we saw there was a natural fit in the work we were doing with our applications,\" he said. \"Essentially, they gave us an operating system we were able to leverage to bring our applications to their surface. There's a lot of natural affinity there between the workflows OpenAI is trying to enable and Adobe's best in class capabilities.\" Cattell promised Adobe would continue to explore what it could offer inside of ChatGPT, but added the company's apps will continue to be the place users can go if they want more power, precision and control.This article originally appeared on Engadget at https://www.engadget.com/ai/adobe-brings-photoshop-acrobat-and-adobe-express-to-chatgpt-130000389.html?src=rss",
          "content": "Back in October, OpenAI announced apps like Spotify and Canva would be accessible in ChatGPT. At the time, the company said more software was on the way, and now one of the most popular professional applications is available through the chatbot. Starting today, you can access Photoshop, Acrobat and Adobe Express inside of ChatGPT. All the apps are free to use through OpenAI’s website, though before you can begin generating PDFs and illustrations using Acrobat and Adobe Express, you'll need to sign into your Adobe account. To use any of the apps in ChatGPT, either name them in your prompt or select them from the plus menu. Of the three apps, the way OpenAI's chatbot connects to Photoshop is probably the most interesting. Depending on the prompt, the interface will change to display the sliders most relevant to your request. For example, if you want to brighten an image, you'll see one slider allowing you to adjust the exposure, alongside other ones for the shadows and highlights. By comparison, if you want to add an effect to an image, ChatGPT might display options related to dithering and tri-tone, among others. What's interesting about all this is the way ChatGPT is interacting with Adobe's tools, through an MCP server, to offer a slice of the company's apps. I don't know about you, but I’ve always found Adobe software to be far too complicated, with often one too many ways to accomplish the same task. Granted, what I saw was a hands-off demo, but the routing Adobe created worked well. A ChatGPT user asks the chatbot to create a dance party invitation. Adobe\"We build the Lego blocks, which are the MCP tools, and we create detailed instructions, and then ChatGPT figures out what it wants to do,\" Aubrey Cattell, vice-president of developer platform and partner ecosystem at Adobe, explains. \"Sometimes it does what we want it, and sometimes it doesn't. That's the nature of it being non-deterministic, and we're continuing to hone as much as we can from users' intent and natural language to give them the result that they're looking for.\"Of course, if you ever want more control, the web versions of Photoshop, Acrobat and Adobe Express are a click away. For OpenAI, this is easily the biggest coup to date of its push to reshape ChatGPT into an operating system for all the apps its more than 800 million users depend on daily. For Adobe, it feels like the company is partnering with an entity out to eat its lunch. After all, OpenAI offers its own image generation. However, Cattell said Adobe doesn't see it that way. \"A couple weeks back, OpenAI dropped Apps SDK as a new paradigm for accessing ChatGPT, we saw there was a natural fit in the work we were doing with our applications,\" he said. \"Essentially, they gave us an operating system we were able to leverage to bring our applications to their surface. There's a lot of natural affinity there between the workflows OpenAI is trying to enable and Adobe's best in class capabilities.\" Cattell promised Adobe would continue to explore what it could offer inside of ChatGPT, but added the company's apps will continue to be the place users can go if they want more power, precision and control.This article originally appeared on Engadget at https://www.engadget.com/ai/adobe-brings-photoshop-acrobat-and-adobe-express-to-chatgpt-130000389.html?src=rss",
          "feed_position": 22,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/AX_Search_"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/best-mesh-wifi-system-130028701.html",
          "published_at": "Wed, 10 Dec 2025 10:01:26 +0000",
          "title": "The best mesh Wi-Fi systems of 2025",
          "standfirst": "Spotty Wi-Fi can make even simple tasks feel harder than they should. If you’ve ever had a video call freeze in one room or watched a stream buffer in another, a mesh Wi-Fi system can fix those frustrations. Instead of relying on a single router tucked in a corner, a mesh setup uses multiple units that work together to spread a strong, consistent signal throughout your home.Modern mesh systems are built for busy households. They keep dozens of devices connected at once, manage traffic intelligently and often include helpful app features that make troubleshooting or adjusting settings much easier. Many support the latest Wi-Fi standards and faster internet plans too, so you can upgrade your network without replacing everything else.We’ve tested a range of mesh Wi-Fi systems to find the ones that deliver the best mix of speed, coverage and reliability. Whether you live in a small apartment or a multi-floor home, these picks can help you stay connected wherever you are. Table of contents Best mesh Wi-Fi systems for 2025 What to look for in a mesh Wi-Fi system Other mesh Wi-Fi router systems we tested How we test Wi-Fi routers Mesh Wi-Fi system FAQs Best mesh Wi-Fi systems for 2025 What to look for in a mesh Wi-Fi system Linksys’ CEO Jonathan Bettino told Engadget why mesh systems are an “advancement in Wi-Fi technology” over buying a single point router. With one transmitter, the signal can degrade the further away from the router you go, or the local environment isn’t ideal. “You can have a small [home], but there’s thick walls [...] or things in the way that just interfere with your wireless signal,” he said. Historically, the solution to a home’s Wi-Fi dead zone was to buy a Wi-Fi extender but Bettino said the hardware has both a “terrible user experience” and one of the highest return rates of any consumer electronics product. Mesh Wi-Fi, by comparison, offers “multiple nodes that can be placed anywhere in your home,” says Bettino, resulting in “ubiquitous Wi-Fi” that feels as if you have a “router in every room.” Rather than having one main router in your home, having a “router in every room” is the biggest selling point for mesh Wi-Fi given how reliant we all are on the internet. Each node is in constant contact with each other, broadcasting a single, seamless network to all of your connected devices. There’s no separate network for the 2.4GHz and 5GHz bands, just a single name that you connect to. It’s a good time to buy a mesh Wi-Fi system since the latest standard, Wi-Fi 6E, represents a big leap in the technology. Matt MacPherson, Cisco's Chief Technology Officer for Wireless, said Wi-Fi 6E is a big “inflection point,” using much more of the wireless spectrum than its predecessors. “If you’re using that spectrum with a Wi-Fi 6 [device],” he said, “you’re going to get significant gains [in speed.]” MacPherson added Wi-Fi 6E will likely “carry you for a long time” thanks to the fact its “top throughputs now typically exceed what people can actually connect their home to.” In short, with a top theoretical per-stream speed of 1.2 Gbps, Wi-Fi 6E is fast enough to outrun all but the fastest internet service. What do all these Wi-Fi numbers and letters mean? I’m sorry folks, we need to get boringly technical for one paragraph, but I promise you it’s worth it. Wi-Fi is governed by International Standard IEEE 802.11, and every few years a letter gets added onto that name when the technology evolves and improves. Until 2019, routers were sold under their IEEE name, leaving users to pick through the word soup of a product labeled 802.11 b/g/a/n/ac and so on. Mercifully, wiser heads opted to rebrand the letters as numbers, so rather than 802.11 b/g/a/n/ac, we have Wi-Fi 1, 2, 3 4 and 5. Right now, we’re in the middle of one of those Wi-Fi generations, with most of the gear on sale right now supporting either Wi-Fi 6 or Wi-Fi 6E. What’s the difference between Wi-Fi 6 and Wi-Fi 6E? Wi-Fi uses chunks of the radio frequency spectrum, with Wi-Fi 6 using the 2.4GHz and 5GHz bands to pump data around. In fact, back in the old days, it was likely your home router would offer you the choice of the 2.4GHz or the 5GHz network, as separate bands to access. These days, all of the spectrums are tied together as one thing, and Wi-Fi 6E has the added ability to use the 6GHz band as well. That’s a big chunk of extra wireless real estate that isn’t as cluttered up as the 2.4 and 5GHz bands. You’re going to talk about wireless frequencies now, aren’t you. Each Wi-Fi band had tradeoffs, because the slower radio frequencies have greater range but less speed. 2.4GHz signals will travel a long way in your home but aren’t quick, while 6GHz is blisteringly fast but can be defeated by a sturdy brick wall. A lot of Wi-Fi-enabled gear you own, like smart home products, only use the 2.4GHz band because the range is better and it’s a lot cheaper. But it means that the band is also overcrowded and slow, making it great for your doorbell and robovac, but lackluster for Twitch streaming. So, what am I looking for? Right now, the market is full of mature Wi-Fi 6 and 6E devices, and most new systems available to buy are capable of taking advantage of the faster speeds they offer. This guide focuses on Wi-Fi 6E gear since it’s what we think it’s more than enough to satisfy almost everyone’s at-home Wi-Fi needs. What about Wi-Fi 7? We’re now seeing the first generation of Wi-Fi 7 devices available to buy, but we don’t recommend you do so immediately. The Wi-Fi 7 standard is still so new that there’s little to no reason for you to rush out and buy one for your home. The hardware is tremendously expensive and while Wi-Fi 7 will, eventually, offer some great benefits over 6E, it’s not as transformative an upgrade as 6E. Not to mention, Wi-Fi 7 is so new that almost none of your home’s devices will be able to take advantage of its big-ticket features. I’d estimate you won’t need to worry about upgrading to Wi-Fi 7 for at least five years, if not longer. Range and speed All Wi-Fi routers boast a theoretical broadcast range and a theoretical top speed, and in some cases external antennas to boost signal directionality — but these figures don’t mean much. After all, manufacturers can’t control your ISP’s real speed, the materials and layout of your home or where you put your Wi-Fi gear. Raw speed isn’t everything, either, and you likely need a lot less than the internet speeds your provider is advertising. What matters more is how consistent your connection is between rooms and across devices.. After all, Netflix needs just 15 Mbps to push a single 4K video stream to your home. As cool as it is to say you’ve got all these hundreds of Mbps, factors like latency and reliability are far more crucial to a happy internet life. And unless you have Gigabit internet that can reach speeds of up to 1 Gbps, you won’t need a mesh router that offers that spec. Backhaul Mesh Wi-Fi systems work by connecting every hardware node to a single wireless network, letting them all communicate with each other. Imagine four people in a busy, noisy restaurant all trying to order their dinner from a weary staff member, all at once. Now imagine, while this is going on, that four more people at that same table are also trying to tell a funny anecdote. It’s no surprise that it might take a long time for the right information to reach its intended destination. To combat this, higher-end mesh routers offer dedicated wireless backhaul; a slice of the spectrum for node-to-node communication. So rather than everyone talking at once in the same space, the conversations are essentially separated, reducing the invisible clutter in the air. Because there’s less confusing cross-chatter, everything moves faster, offering a significant performance boost to those systems. Connectivity These days, even your washing machine can have a wireless connection, but that doesn’t mean you should ignore the joys of wired internet. No matter how fast Wi-Fi is, a hard line will always be faster, and some gear, like Philips’ Hue bridge, still needs an ethernet connection. Plenty of routers can also use these hard connections as backhaul, eliminating further wireless clutter. It’s convenient for spread-out systems and power users, but it will mean running more wires through your home. The most common standard is Cat 5e, or gigabit ethernet which, unsurprisingly, has a top speed of 1 Gigabit per second (Gbps). Since Ethernet cables are backward compatible, you should be able to easily find one that works with your system. However, to get the most out of your mesh routers, it’s worth investing in an Ethernet cable that meets the standard your router uses — if it’s Cat 5e, use a Cat 5e cable. You can check your router’s specs via the manufacturer’s website to be sure. Flexibility and scalability Mesh routers enable you to add (or subtract) modules from your home network to suit your needs. D-Link’s Alan Jones said users should “check how scalable the prospective product is” before you buy. This sense of scale doesn’t just apply to the number of nodes on the network, but how many simultaneous connections it can handle. It’s also worth looking at ASUS’ AiMesh products, which can combine mesh Wi-Fi gear and its standard “spider” Wi-Fi routers. If you’ve got a tricky part of your home, you can bolt on an ultra-power standalone Wi-Fi router to a compatible mesh. Placement Mesh networks replace one big piece of hardware with a series of identical nodes that you scatter around your home. You connect one to your modem (usually over ethernet), and then scatter the rest around the place for the best coverage. A good rule of thumb is to place each node no more than two rooms away from the last one, rather than sticking them at the far ends of your home. Bear in mind, every physical obstacle between a Wi-Fi node, its siblings and your devices will hurt your overall performance. You should aim to place them, at the very least, at waist height on furniture in open air, without too many obstructions. The reason many mesh Wi-Fi products are designed to look like an inoffensive white doodad is so you don’t feel compelled to hide them behind your TV. Other mesh Wi-Fi router systems we tested Amazon Eero Pro 7 Eero built its reputation on easy to use yet powerful mesh systems that offer a lot of good in a relatively small and affordable package. Setup is effortless, the app running things is clean and simple, and you get the added benefit of backwards compatibility with older hardware. Sadly, the issue with every Eero system is that so many basic management features, like parental controls, are paywalled behind the company’s Eero Plus subscription for $100 a year. Amazon Eero 6E Eero Pro 6E is an “easy” device, the sort a total novice can set up on their own and thrive with for years on end. There’s little brainwork required to get things set up, and the app has a clean UI with plenty of hand-holding. But, as with the Eero Pro 7, the fact that so many basic management tools are paywalled irks me, especially since you can get plenty of them for free with Google’s rival offering. Netgear Orbi 960 The Orbi 96T0 (RBKE963) is Netgear’s flagship mesh Wi-Fi product, which the company calls the “world’s most powerful Wi-Fi 6E system.” It’s also one of the most expensive consumer-level kits on the market, setting you back $1,499.99 for a three pack. It's a fantastic piece of gear, but it's worth saying that the subset of people who could, would or should buy it remains far smaller than you might expect. Ultimately, I feel that if you’re paying luxury prices, you should expect a luxury product. There were plenty of times during testing that I went looking for a feature that was either only available via the web client, or behind a paywall. While, yes, much of your cash is going to the superlative hardware, but for this sort of money, the fact you have to pay extra for some table-stakes features is insulting. If you’re looking for a new Wi-Fi system and aren’t prepared to spend almost $1,500, it’s worth considering our other top picks for the best Wi-Fi routers and mesh systems. How we test Wi-Fi routers My home covers around 2,200 square feet across three stories with the office on the third floor. It’s relatively long and thin, with the living room at the front of the house, the kitchen at the back and the three bedrooms on the first floor. Its age means there are a lot of solid brick walls, old-school lathe and plaster as well as aluminum foil-backed insulation boards to help with energy efficiency. There are two major Wi-Fi dead zones in the house: The bathroom and the third bedroom behind it, since there’s lots of old and new pipework in the walls and floors. For mesh routers with two nodes, I place the first in my living room, connected via ethernet to my cable modem with the second on the first floor landing in the (ostensible) center of the house. For three-node sets, the third goes in my kitchen, which I’ve found is the optimal layout to get the bulk of my house covered in Wi-Fi. Fundamentally, my home poses enough challenges that if it succeeds here, it stands a very good chance of succeeding in your place. Each mesh is judged on ease of setup, Wi-Fi coverage, reliability, speed and any additional features that it advertises. I look at how user-friendly each companion app is from the perspective of a novice rather than an expert given you shouldn’t need to be a network engineer to do this sort of thing. Tests I do include checking for dead zones, moving from room to room to measure consistency of connectivity and streaming multiple videos at once to replicate common usage patterns. Mesh Wi-Fi system FAQs This is the section of our mesh Wi-Fi buyer’s guide where we talk about the stuff that most people just glide past. If you’re not familiar with technology, it can be intimidating if people talk about these things as if you’re expected to already know. So here’s a very simple, very basic rundown of some of the stuff you might have missed in very basic terms. What’s the difference between a Wi-Fi router and a mesh router? A Wi-Fi router is a box that usually sits close to wherever the internet comes into your home and pumps out information over radio waves. A mesh router, meanwhile, is a set of smaller devices, one of which sits next to your internet connection while the rest are scattered around your home. A single Wi-Fi router is great if your home is small, your needs aren’t too demanding, or if your home doesn’t have many radio-blocking obstructions that mean those signals can’t reach every corner of your home. But, much like standing next to a radio transmitter and then walking away from it in a straight line, after a while, the signal will degrade. That’s the problem a mesh system is designed to solve, since it will take the signal from your modem and pump to the other mesh devices, known as nodes, in your home. That way, instead of having one big router in one part of your home, you have several small ones that ensure you have good Wi-Fi connectivity all over. It also helps ensure that there’s no risk of dropping your connection as you move around — a mesh router system makes it easy to, for instance, walk from room to room watching Netflix and know you won’t miss a single frame. What's the difference between a Wi-Fi extender and a mesh system? Oh boy. Wi-Fi extenders, or repeaters, are small devices designed to push Wi-Fi a little further than your Wi-Fi router can stretch. They’re cheap, compact and often come in the form of little boxes that sit on your plug sockets with the hope of pushing Wi-Fi to a signal-sparse corner of your home. They are, and I can’t put this delicately enough, often a big pile of rubbish and are often not worth your time. Especially since the price of mesh routers has fallen to within most people’s budgets. What is a wireless backhaul? As we explained above, mesh Wi-Fi systems work by connecting every hardware node to a single wireless network, letting them all communicate with each other. Imagine four people in a busy, noisy restaurant all trying to order their dinner from a weary staff member, all at once. Now imagine, while this is going on, that four more people at that same table are also trying to tell a funny anecdote. It’s no surprise that it might take a long time for the right information to reach its intended destination. To combat this, higher-end mesh routers offer dedicated wireless backhaul; a slice of the spectrum for node-to-node communication. So rather than everyone talking at once in the same space, the conversations are essentially separated, reducing the invisible clutter in the air. Because there’s less confusing cross-chatter, everything moves faster, offering a significant performance boost to those systems. Is it better to hard wire instead of using a mesh Wi-Fi system? This is a great question that doesn’t have a simple answer. It is (almost) always preferable to connect devices with a wire, in this case Ethernet, than to use Wi-Fi. The speeds are faster, it’s more reliable and your data is less vulnerable to the slings and arrows of the laws of physics. Hell, I spent about a year trying to work out how to build an iPhone to Ethernet connector back in the bad old days of Wi-Fi. But your ability to do so depends on your level of DIY skills and / or how much money you want to spend on contractors. Wiring your home for Ethernet if you don’t have the infrastructure already can be a costly and time-consuming process. Particularly if you don’t want ugly wires running along your baseboards and under your carpets or across your hardwood floors. If you’re building your own home or can do some serious DIY, then hard wiring is a fantastic thing to have. It goes wonderfully hand-in-glove with mesh networks too, since you’ll be able to hook up your nodes to the network for even better speeds. But if I’m honest, advances in Wi-Fi technology mean I’d only go for hard wiring if I really believed I needed the sort of speed it offers. Unless you’re a Twitch streamer running your own 24/7 content studio, it’s probably overkill. When we started renovating our 140-year-old home, I had Ethernet installed in the living room, the master and second bedroom and in my office, all at the front of the house. I can’t use it for my mesh since I’d need to put the wiring through the middle of the house. If I ever had the wiring done again, I would do so as I know I’ll instantly see a meaningful improvement in both my connection speed and reliability. But I wouldn’t spend several thousand pounds to have it done just for the sake of it.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-mesh-wifi-system-130028701.html?src=rss",
          "content": "Spotty Wi-Fi can make even simple tasks feel harder than they should. If you’ve ever had a video call freeze in one room or watched a stream buffer in another, a mesh Wi-Fi system can fix those frustrations. Instead of relying on a single router tucked in a corner, a mesh setup uses multiple units that work together to spread a strong, consistent signal throughout your home.Modern mesh systems are built for busy households. They keep dozens of devices connected at once, manage traffic intelligently and often include helpful app features that make troubleshooting or adjusting settings much easier. Many support the latest Wi-Fi standards and faster internet plans too, so you can upgrade your network without replacing everything else.We’ve tested a range of mesh Wi-Fi systems to find the ones that deliver the best mix of speed, coverage and reliability. Whether you live in a small apartment or a multi-floor home, these picks can help you stay connected wherever you are. Table of contents Best mesh Wi-Fi systems for 2025 What to look for in a mesh Wi-Fi system Other mesh Wi-Fi router systems we tested How we test Wi-Fi routers Mesh Wi-Fi system FAQs Best mesh Wi-Fi systems for 2025 What to look for in a mesh Wi-Fi system Linksys’ CEO Jonathan Bettino told Engadget why mesh systems are an “advancement in Wi-Fi technology” over buying a single point router. With one transmitter, the signal can degrade the further away from the router you go, or the local environment isn’t ideal. “You can have a small [home], but there’s thick walls [...] or things in the way that just interfere with your wireless signal,” he said. Historically, the solution to a home’s Wi-Fi dead zone was to buy a Wi-Fi extender but Bettino said the hardware has both a “terrible user experience” and one of the highest return rates of any consumer electronics product. Mesh Wi-Fi, by comparison, offers “multiple nodes that can be placed anywhere in your home,” says Bettino, resulting in “ubiquitous Wi-Fi” that feels as if you have a “router in every room.” Rather than having one main router in your home, having a “router in every room” is the biggest selling point for mesh Wi-Fi given how reliant we all are on the internet. Each node is in constant contact with each other, broadcasting a single, seamless network to all of your connected devices. There’s no separate network for the 2.4GHz and 5GHz bands, just a single name that you connect to. It’s a good time to buy a mesh Wi-Fi system since the latest standard, Wi-Fi 6E, represents a big leap in the technology. Matt MacPherson, Cisco's Chief Technology Officer for Wireless, said Wi-Fi 6E is a big “inflection point,” using much more of the wireless spectrum than its predecessors. “If you’re using that spectrum with a Wi-Fi 6 [device],” he said, “you’re going to get significant gains [in speed.]” MacPherson added Wi-Fi 6E will likely “carry you for a long time” thanks to the fact its “top throughputs now typically exceed what people can actually connect their home to.” In short, with a top theoretical per-stream speed of 1.2 Gbps, Wi-Fi 6E is fast enough to outrun all but the fastest internet service. What do all these Wi-Fi numbers and letters mean? I’m sorry folks, we need to get boringly technical for one paragraph, but I promise you it’s worth it. Wi-Fi is governed by International Standard IEEE 802.11, and every few years a letter gets added onto that name when the technology evolves and improves. Until 2019, routers were sold under their IEEE name, leaving users to pick through the word soup of a product labeled 802.11 b/g/a/n/ac and so on. Mercifully, wiser heads opted to rebrand the letters as numbers, so rather than 802.11 b/g/a/n/ac, we have Wi-Fi 1, 2, 3 4 and 5. Right now, we’re in the middle of one of those Wi-Fi generations, with most of the gear on sale right now supporting either Wi-Fi 6 or Wi-Fi 6E. What’s the difference between Wi-Fi 6 and Wi-Fi 6E? Wi-Fi uses chunks of the radio frequency spectrum, with Wi-Fi 6 using the 2.4GHz and 5GHz bands to pump data around. In fact, back in the old days, it was likely your home router would offer you the choice of the 2.4GHz or the 5GHz network, as separate bands to access. These days, all of the spectrums are tied together as one thing, and Wi-Fi 6E has the added ability to use the 6GHz band as well. That’s a big chunk of extra wireless real estate that isn’t as cluttered up as the 2.4 and 5GHz bands. You’re going to talk about wireless frequencies now, aren’t you. Each Wi-Fi band had tradeoffs, because the slower radio frequencies have greater range but less speed. 2.4GHz signals will travel a long way in your home but aren’t quick, while 6GHz is blisteringly fast but can be defeated by a sturdy brick wall. A lot of Wi-Fi-enabled gear you own, like smart home products, only use the 2.4GHz band because the range is better and it’s a lot cheaper. But it means that the band is also overcrowded and slow, making it great for your doorbell and robovac, but lackluster for Twitch streaming. So, what am I looking for? Right now, the market is full of mature Wi-Fi 6 and 6E devices, and most new systems available to buy are capable of taking advantage of the faster speeds they offer. This guide focuses on Wi-Fi 6E gear since it’s what we think it’s more than enough to satisfy almost everyone’s at-home Wi-Fi needs. What about Wi-Fi 7? We’re now seeing the first generation of Wi-Fi 7 devices available to buy, but we don’t recommend you do so immediately. The Wi-Fi 7 standard is still so new that there’s little to no reason for you to rush out and buy one for your home. The hardware is tremendously expensive and while Wi-Fi 7 will, eventually, offer some great benefits over 6E, it’s not as transformative an upgrade as 6E. Not to mention, Wi-Fi 7 is so new that almost none of your home’s devices will be able to take advantage of its big-ticket features. I’d estimate you won’t need to worry about upgrading to Wi-Fi 7 for at least five years, if not longer. Range and speed All Wi-Fi routers boast a theoretical broadcast range and a theoretical top speed, and in some cases external antennas to boost signal directionality — but these figures don’t mean much. After all, manufacturers can’t control your ISP’s real speed, the materials and layout of your home or where you put your Wi-Fi gear. Raw speed isn’t everything, either, and you likely need a lot less than the internet speeds your provider is advertising. What matters more is how consistent your connection is between rooms and across devices.. After all, Netflix needs just 15 Mbps to push a single 4K video stream to your home. As cool as it is to say you’ve got all these hundreds of Mbps, factors like latency and reliability are far more crucial to a happy internet life. And unless you have Gigabit internet that can reach speeds of up to 1 Gbps, you won’t need a mesh router that offers that spec. Backhaul Mesh Wi-Fi systems work by connecting every hardware node to a single wireless network, letting them all communicate with each other. Imagine four people in a busy, noisy restaurant all trying to order their dinner from a weary staff member, all at once. Now imagine, while this is going on, that four more people at that same table are also trying to tell a funny anecdote. It’s no surprise that it might take a long time for the right information to reach its intended destination. To combat this, higher-end mesh routers offer dedicated wireless backhaul; a slice of the spectrum for node-to-node communication. So rather than everyone talking at once in the same space, the conversations are essentially separated, reducing the invisible clutter in the air. Because there’s less confusing cross-chatter, everything moves faster, offering a significant performance boost to those systems. Connectivity These days, even your washing machine can have a wireless connection, but that doesn’t mean you should ignore the joys of wired internet. No matter how fast Wi-Fi is, a hard line will always be faster, and some gear, like Philips’ Hue bridge, still needs an ethernet connection. Plenty of routers can also use these hard connections as backhaul, eliminating further wireless clutter. It’s convenient for spread-out systems and power users, but it will mean running more wires through your home. The most common standard is Cat 5e, or gigabit ethernet which, unsurprisingly, has a top speed of 1 Gigabit per second (Gbps). Since Ethernet cables are backward compatible, you should be able to easily find one that works with your system. However, to get the most out of your mesh routers, it’s worth investing in an Ethernet cable that meets the standard your router uses — if it’s Cat 5e, use a Cat 5e cable. You can check your router’s specs via the manufacturer’s website to be sure. Flexibility and scalability Mesh routers enable you to add (or subtract) modules from your home network to suit your needs. D-Link’s Alan Jones said users should “check how scalable the prospective product is” before you buy. This sense of scale doesn’t just apply to the number of nodes on the network, but how many simultaneous connections it can handle. It’s also worth looking at ASUS’ AiMesh products, which can combine mesh Wi-Fi gear and its standard “spider” Wi-Fi routers. If you’ve got a tricky part of your home, you can bolt on an ultra-power standalone Wi-Fi router to a compatible mesh. Placement Mesh networks replace one big piece of hardware with a series of identical nodes that you scatter around your home. You connect one to your modem (usually over ethernet), and then scatter the rest around the place for the best coverage. A good rule of thumb is to place each node no more than two rooms away from the last one, rather than sticking them at the far ends of your home. Bear in mind, every physical obstacle between a Wi-Fi node, its siblings and your devices will hurt your overall performance. You should aim to place them, at the very least, at waist height on furniture in open air, without too many obstructions. The reason many mesh Wi-Fi products are designed to look like an inoffensive white doodad is so you don’t feel compelled to hide them behind your TV. Other mesh Wi-Fi router systems we tested Amazon Eero Pro 7 Eero built its reputation on easy to use yet powerful mesh systems that offer a lot of good in a relatively small and affordable package. Setup is effortless, the app running things is clean and simple, and you get the added benefit of backwards compatibility with older hardware. Sadly, the issue with every Eero system is that so many basic management features, like parental controls, are paywalled behind the company’s Eero Plus subscription for $100 a year. Amazon Eero 6E Eero Pro 6E is an “easy” device, the sort a total novice can set up on their own and thrive with for years on end. There’s little brainwork required to get things set up, and the app has a clean UI with plenty of hand-holding. But, as with the Eero Pro 7, the fact that so many basic management tools are paywalled irks me, especially since you can get plenty of them for free with Google’s rival offering. Netgear Orbi 960 The Orbi 96T0 (RBKE963) is Netgear’s flagship mesh Wi-Fi product, which the company calls the “world’s most powerful Wi-Fi 6E system.” It’s also one of the most expensive consumer-level kits on the market, setting you back $1,499.99 for a three pack. It's a fantastic piece of gear, but it's worth saying that the subset of people who could, would or should buy it remains far smaller than you might expect. Ultimately, I feel that if you’re paying luxury prices, you should expect a luxury product. There were plenty of times during testing that I went looking for a feature that was either only available via the web client, or behind a paywall. While, yes, much of your cash is going to the superlative hardware, but for this sort of money, the fact you have to pay extra for some table-stakes features is insulting. If you’re looking for a new Wi-Fi system and aren’t prepared to spend almost $1,500, it’s worth considering our other top picks for the best Wi-Fi routers and mesh systems. How we test Wi-Fi routers My home covers around 2,200 square feet across three stories with the office on the third floor. It’s relatively long and thin, with the living room at the front of the house, the kitchen at the back and the three bedrooms on the first floor. Its age means there are a lot of solid brick walls, old-school lathe and plaster as well as aluminum foil-backed insulation boards to help with energy efficiency. There are two major Wi-Fi dead zones in the house: The bathroom and the third bedroom behind it, since there’s lots of old and new pipework in the walls and floors. For mesh routers with two nodes, I place the first in my living room, connected via ethernet to my cable modem with the second on the first floor landing in the (ostensible) center of the house. For three-node sets, the third goes in my kitchen, which I’ve found is the optimal layout to get the bulk of my house covered in Wi-Fi. Fundamentally, my home poses enough challenges that if it succeeds here, it stands a very good chance of succeeding in your place. Each mesh is judged on ease of setup, Wi-Fi coverage, reliability, speed and any additional features that it advertises. I look at how user-friendly each companion app is from the perspective of a novice rather than an expert given you shouldn’t need to be a network engineer to do this sort of thing. Tests I do include checking for dead zones, moving from room to room to measure consistency of connectivity and streaming multiple videos at once to replicate common usage patterns. Mesh Wi-Fi system FAQs This is the section of our mesh Wi-Fi buyer’s guide where we talk about the stuff that most people just glide past. If you’re not familiar with technology, it can be intimidating if people talk about these things as if you’re expected to already know. So here’s a very simple, very basic rundown of some of the stuff you might have missed in very basic terms. What’s the difference between a Wi-Fi router and a mesh router? A Wi-Fi router is a box that usually sits close to wherever the internet comes into your home and pumps out information over radio waves. A mesh router, meanwhile, is a set of smaller devices, one of which sits next to your internet connection while the rest are scattered around your home. A single Wi-Fi router is great if your home is small, your needs aren’t too demanding, or if your home doesn’t have many radio-blocking obstructions that mean those signals can’t reach every corner of your home. But, much like standing next to a radio transmitter and then walking away from it in a straight line, after a while, the signal will degrade. That’s the problem a mesh system is designed to solve, since it will take the signal from your modem and pump to the other mesh devices, known as nodes, in your home. That way, instead of having one big router in one part of your home, you have several small ones that ensure you have good Wi-Fi connectivity all over. It also helps ensure that there’s no risk of dropping your connection as you move around — a mesh router system makes it easy to, for instance, walk from room to room watching Netflix and know you won’t miss a single frame. What's the difference between a Wi-Fi extender and a mesh system? Oh boy. Wi-Fi extenders, or repeaters, are small devices designed to push Wi-Fi a little further than your Wi-Fi router can stretch. They’re cheap, compact and often come in the form of little boxes that sit on your plug sockets with the hope of pushing Wi-Fi to a signal-sparse corner of your home. They are, and I can’t put this delicately enough, often a big pile of rubbish and are often not worth your time. Especially since the price of mesh routers has fallen to within most people’s budgets. What is a wireless backhaul? As we explained above, mesh Wi-Fi systems work by connecting every hardware node to a single wireless network, letting them all communicate with each other. Imagine four people in a busy, noisy restaurant all trying to order their dinner from a weary staff member, all at once. Now imagine, while this is going on, that four more people at that same table are also trying to tell a funny anecdote. It’s no surprise that it might take a long time for the right information to reach its intended destination. To combat this, higher-end mesh routers offer dedicated wireless backhaul; a slice of the spectrum for node-to-node communication. So rather than everyone talking at once in the same space, the conversations are essentially separated, reducing the invisible clutter in the air. Because there’s less confusing cross-chatter, everything moves faster, offering a significant performance boost to those systems. Is it better to hard wire instead of using a mesh Wi-Fi system? This is a great question that doesn’t have a simple answer. It is (almost) always preferable to connect devices with a wire, in this case Ethernet, than to use Wi-Fi. The speeds are faster, it’s more reliable and your data is less vulnerable to the slings and arrows of the laws of physics. Hell, I spent about a year trying to work out how to build an iPhone to Ethernet connector back in the bad old days of Wi-Fi. But your ability to do so depends on your level of DIY skills and / or how much money you want to spend on contractors. Wiring your home for Ethernet if you don’t have the infrastructure already can be a costly and time-consuming process. Particularly if you don’t want ugly wires running along your baseboards and under your carpets or across your hardwood floors. If you’re building your own home or can do some serious DIY, then hard wiring is a fantastic thing to have. It goes wonderfully hand-in-glove with mesh networks too, since you’ll be able to hook up your nodes to the network for even better speeds. But if I’m honest, advances in Wi-Fi technology mean I’d only go for hard wiring if I really believed I needed the sort of speed it offers. Unless you’re a Twitch streamer running your own 24/7 content studio, it’s probably overkill. When we started renovating our 140-year-old home, I had Ethernet installed in the living room, the master and second bedroom and in my office, all at the front of the house. I can’t use it for my mesh since I’d need to put the wiring through the middle of the house. If I ever had the wiring done again, I would do so as I know I’ll instantly see a meaningful improvement in both my connection speed and reliability. But I wouldn’t spend several thousand pounds to have it done just for the sake of it.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-mesh-wifi-system-130028701.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/how-googles-tpus-are-reshaping-the-economics-of-large-scale-ai",
          "published_at": "Wed, 10 Dec 2025 08:00:00 GMT",
          "title": "How Google’s TPUs are reshaping the economics of large-scale AI",
          "standfirst": "For more than a decade, Nvidia’s GPUs have underpinned nearly every major advance in modern AI. That position is now being challenged. Frontier models such as Google’s Gemini 3 and Anthropic’s Claude 4.5 Opus were trained not on Nvidia hardware, but on Google’s latest Tensor Processing Units, the Ironwood-based TPUv7. This signals that a viable alternative to the GPU-centric AI stack has already arrived — one with real implications for the economics and architecture of frontier-scale training.Nvidia&#x27;s CUDA (Compute Unified Device Architecture), the platform that provides access to the GPU&#x27;s massive parallel architecture, and its surrounding tools have created what many have dubbed the \"CUDA moat\"; once a team has built pipelines on CUDA, switching to another platform is prohibitively expensive because of the dependencies on Nvidia’s software stack. This, combined with Nvidia&#x27;s first-mover advantage, helped the company achieve a staggering 75% gross margin.Unlike GPUs, TPUs were designed from day one as purpose-built silicon for machine learning. With each generation, Google has pushed further into large-scale AI acceleration, but now, as the hardware behind two of the most capable AI models ever trained, TPUv7 signals a broader strategy to challenge Nvidia’s dominance.GPUs and TPUs both accelerate machine learning, but they reflect different design philosophies: GPUs are general-purpose parallel processors, while TPUs are purpose-built systems optimized almost exclusively for large-scale matrix multiplication. With TPUv7, Google has pushed that specialization further by tightly integrating high-speed interconnects directly into the chip, allowing TPU pods to scale like a single supercomputer and reducing the cost and latency penalties that typically come with GPU-based clusters.TPUs are \"designed as a complete &#x27;system&#x27; rather than just a chip,\" Val Bercovici, Chief AI Officer at WEKA, told VentureBeat.Google&#x27;s commercial pivot from internal to industry-wideHistorically, Google restricted access to TPUs solely through cloud rentals on the Google Cloud Platform. In recent months, Google has started offering the hardware directly to external customers, effectively unbundling the chip from the cloud service. Customers can choose between treating compute as an operating expense by renting via cloud, or a capital expenditure (purchasing hardware outright), removing a major friction point for large AI labs that prefer to own their own hardware and effectively bypassing the \"cloud rent\" premium for the base hardware.The centerpiece of Google&#x27;s shift in strategy is a landmark deal with Anthropic, where the Claude 4.5 Opus creator will receive access to up to 1 million TPUv7 chips — more than a gigawatt of compute capacity. Through Broadcom, Google&#x27;s longtime physical design partner, approximately 400,000 chips are being sold directly to Anthropic. The remaining 600,000 chips are leased through traditional Google Cloud contracts. Anthropic&#x27;s commitment adds billions of dollars to Google&#x27;s bottom line and locks one of OpenAI&#x27;s key competitors into Google&#x27;s ecosystem. Eroding the \"CUDA moat\"For years, Nvidia’s GPUs have been the clear market leader in AI infrastructure. In addition to its powerful hardware, Nvidia&#x27;s CUDA ecosystem features a vast library of optimized kernels and frameworks. Combined with broad developer familiarity and a huge installed base, enterprises gradually became locked into the \"CUDA moat,\" a structural barrier that made it impractically expensive to abandon a GPU-based infrastructure.One of the key blockers preventing wider TPU adoption has been ecosystem friction. In the past, TPUs worked best with JAX, Google&#x27;s own numerical computing library designed for AI/ML research. However, mainstream AI development relies primarily on PyTorch, an open-source ML framework that can be tuned for CUDA. Google is now directly addressing the gap. TPUv7 supports native PyTorch integration, including eager execution, full support for distributed APIs, torch.compile, and custom TPU kernel support under PyTorch’s toolchain. The goal is for PyTorch to run as easily on TPUs as it does on Nvidia GPUs.Google is also contributing heavily to vLLM and SGLang, two popular open-source inference frameworks. By optimizing these widely-used tools for TPU, Google ensures that developers are able to switch hardware without rewriting their entire codebase.Advantages and disadvantages of TPUs versus GPUsFor enterprises comparing TPUs and GPUs for large-scale ML workloads, the benefits center primarily on cost, performance, and scalability. SemiAnalysis recently published a deep dive weighing the advantages and disadvantages of the two technologies, measuring cost efficiency, as well as technical performance.Thanks to its specialized architecture and greater energy efficiency, TPUv7 offers significantly better throughput-per-dollar for large-scale training and high-volume inference. This allows enterprises to reduce operational costs related to power, cooling, and data center resources. SemiAnalysis estimates that, for Google&#x27;s internal systems, the total cost of ownership (TCO) for an Ironwood-based server is approximately 44% lower than the TCO for an equivalent Nvidia GB200 Blackwell server. Even after factoring in the profit margins for both Google and Broadcom, external customers like Anthropic are seeing a ~30% reduction in costs compared to Nvidia. \"When cost is paramount, TPUs make sense for AI projects at massive scale. With TPUs, hyperscalers and AI labs can achieve 30-50% TCO reductions, which could translate to billions in savings,\" Bercovici said.This economic leverage is already reshaping the market. Just the existence of a viable alternative allowed OpenAI to negotiate a ~30% discount on its own Nvidia hardware. OpenAI is one of the largest purchasers for Nvidia GPUs, however, earlier this year, the company added Google TPUs via Google Cloud to support its growing compute requirements. Meta is also reportedly in advanced discussions to acquire Google TPUs for its data centers.At this stage, it might seem like Ironwood is the ideal solution for enterprise architecture, but there are a number of trade-offs. While TPUs excel at specific deep learning workloads, they are far less flexible than GPUs, which can run a wide variety of algorithms, including non-AI tasks. If a new AI technique is invented tomorrow, a GPU will run it immediately. This makes GPUs more suitable for organizations that run a wide range of computational workloads beyond standard deep learning. Migration from a GPU-centric environment can also be expensive and time-consuming, especially for teams with existing CUDA-based pipelines, custom GPU kernels, or that leverage frameworks not yet optimized for TPUs. Bercovici recommends that companies \"opt for GPUs when they need to move fast and time to market matters. GPUs leverage standard infrastructure and the largest developer ecosystem, handle dynamic and complex workloads that TPUs aren&#x27;t optimized for, and deploy into existing on-premises standards-based data centers without requiring custom power and networking rebuilds.\" Additionally, the ubiquity of GPUs means that there is more engineering talent available. TPUs demand a rare skillset. \"Leveraging the power of TPUs requires an organization to have engineering depth, which means being able to recruit and retain the rare engineering talent that can write custom kernels and optimize compilers,\" Bercovici said. In practice, Ironwood’s advantages can be realized mostly for enterprises with large, tensor-heavy workloads. Organizations requiring broader hardware flexibility, hybrid-cloud strategies, or HPC-style versatility may find GPUs the better fit. In many cases, a hybrid approach combining the two may offer the best balance of specialization and flexibility.The future of AI architectureThe competition for AI hardware dominance is heating up, but it&#x27;s far too early to predict a winner — or if there will even be a winner at all. With Nvidia and Google innovating at such a rapid pace and companies like Amazon joining the fray, the highest-performing AI systems of the future could be hybrid, integrating both TPUs and GPUs.\"Google Cloud is experiencing accelerating demand for both our custom TPUs and Nvidia GPUs,” a Google spokesperson told VentureBeat. “As a result, we are significantly expanding our Nvidia GPU offerings to meet substantial customer demand. The reality is that the majority of our Google Cloud customers use both GPUs and TPUs. With our wide selection of the latest Nvidia GPUs and seven generations of custom TPUs, we offer customers the flexibility of choice to optimize for their specific needs.\"",
          "content": "For more than a decade, Nvidia’s GPUs have underpinned nearly every major advance in modern AI. That position is now being challenged. Frontier models such as Google’s Gemini 3 and Anthropic’s Claude 4.5 Opus were trained not on Nvidia hardware, but on Google’s latest Tensor Processing Units, the Ironwood-based TPUv7. This signals that a viable alternative to the GPU-centric AI stack has already arrived — one with real implications for the economics and architecture of frontier-scale training.Nvidia&#x27;s CUDA (Compute Unified Device Architecture), the platform that provides access to the GPU&#x27;s massive parallel architecture, and its surrounding tools have created what many have dubbed the \"CUDA moat\"; once a team has built pipelines on CUDA, switching to another platform is prohibitively expensive because of the dependencies on Nvidia’s software stack. This, combined with Nvidia&#x27;s first-mover advantage, helped the company achieve a staggering 75% gross margin.Unlike GPUs, TPUs were designed from day one as purpose-built silicon for machine learning. With each generation, Google has pushed further into large-scale AI acceleration, but now, as the hardware behind two of the most capable AI models ever trained, TPUv7 signals a broader strategy to challenge Nvidia’s dominance.GPUs and TPUs both accelerate machine learning, but they reflect different design philosophies: GPUs are general-purpose parallel processors, while TPUs are purpose-built systems optimized almost exclusively for large-scale matrix multiplication. With TPUv7, Google has pushed that specialization further by tightly integrating high-speed interconnects directly into the chip, allowing TPU pods to scale like a single supercomputer and reducing the cost and latency penalties that typically come with GPU-based clusters.TPUs are \"designed as a complete &#x27;system&#x27; rather than just a chip,\" Val Bercovici, Chief AI Officer at WEKA, told VentureBeat.Google&#x27;s commercial pivot from internal to industry-wideHistorically, Google restricted access to TPUs solely through cloud rentals on the Google Cloud Platform. In recent months, Google has started offering the hardware directly to external customers, effectively unbundling the chip from the cloud service. Customers can choose between treating compute as an operating expense by renting via cloud, or a capital expenditure (purchasing hardware outright), removing a major friction point for large AI labs that prefer to own their own hardware and effectively bypassing the \"cloud rent\" premium for the base hardware.The centerpiece of Google&#x27;s shift in strategy is a landmark deal with Anthropic, where the Claude 4.5 Opus creator will receive access to up to 1 million TPUv7 chips — more than a gigawatt of compute capacity. Through Broadcom, Google&#x27;s longtime physical design partner, approximately 400,000 chips are being sold directly to Anthropic. The remaining 600,000 chips are leased through traditional Google Cloud contracts. Anthropic&#x27;s commitment adds billions of dollars to Google&#x27;s bottom line and locks one of OpenAI&#x27;s key competitors into Google&#x27;s ecosystem. Eroding the \"CUDA moat\"For years, Nvidia’s GPUs have been the clear market leader in AI infrastructure. In addition to its powerful hardware, Nvidia&#x27;s CUDA ecosystem features a vast library of optimized kernels and frameworks. Combined with broad developer familiarity and a huge installed base, enterprises gradually became locked into the \"CUDA moat,\" a structural barrier that made it impractically expensive to abandon a GPU-based infrastructure.One of the key blockers preventing wider TPU adoption has been ecosystem friction. In the past, TPUs worked best with JAX, Google&#x27;s own numerical computing library designed for AI/ML research. However, mainstream AI development relies primarily on PyTorch, an open-source ML framework that can be tuned for CUDA. Google is now directly addressing the gap. TPUv7 supports native PyTorch integration, including eager execution, full support for distributed APIs, torch.compile, and custom TPU kernel support under PyTorch’s toolchain. The goal is for PyTorch to run as easily on TPUs as it does on Nvidia GPUs.Google is also contributing heavily to vLLM and SGLang, two popular open-source inference frameworks. By optimizing these widely-used tools for TPU, Google ensures that developers are able to switch hardware without rewriting their entire codebase.Advantages and disadvantages of TPUs versus GPUsFor enterprises comparing TPUs and GPUs for large-scale ML workloads, the benefits center primarily on cost, performance, and scalability. SemiAnalysis recently published a deep dive weighing the advantages and disadvantages of the two technologies, measuring cost efficiency, as well as technical performance.Thanks to its specialized architecture and greater energy efficiency, TPUv7 offers significantly better throughput-per-dollar for large-scale training and high-volume inference. This allows enterprises to reduce operational costs related to power, cooling, and data center resources. SemiAnalysis estimates that, for Google&#x27;s internal systems, the total cost of ownership (TCO) for an Ironwood-based server is approximately 44% lower than the TCO for an equivalent Nvidia GB200 Blackwell server. Even after factoring in the profit margins for both Google and Broadcom, external customers like Anthropic are seeing a ~30% reduction in costs compared to Nvidia. \"When cost is paramount, TPUs make sense for AI projects at massive scale. With TPUs, hyperscalers and AI labs can achieve 30-50% TCO reductions, which could translate to billions in savings,\" Bercovici said.This economic leverage is already reshaping the market. Just the existence of a viable alternative allowed OpenAI to negotiate a ~30% discount on its own Nvidia hardware. OpenAI is one of the largest purchasers for Nvidia GPUs, however, earlier this year, the company added Google TPUs via Google Cloud to support its growing compute requirements. Meta is also reportedly in advanced discussions to acquire Google TPUs for its data centers.At this stage, it might seem like Ironwood is the ideal solution for enterprise architecture, but there are a number of trade-offs. While TPUs excel at specific deep learning workloads, they are far less flexible than GPUs, which can run a wide variety of algorithms, including non-AI tasks. If a new AI technique is invented tomorrow, a GPU will run it immediately. This makes GPUs more suitable for organizations that run a wide range of computational workloads beyond standard deep learning. Migration from a GPU-centric environment can also be expensive and time-consuming, especially for teams with existing CUDA-based pipelines, custom GPU kernels, or that leverage frameworks not yet optimized for TPUs. Bercovici recommends that companies \"opt for GPUs when they need to move fast and time to market matters. GPUs leverage standard infrastructure and the largest developer ecosystem, handle dynamic and complex workloads that TPUs aren&#x27;t optimized for, and deploy into existing on-premises standards-based data centers without requiring custom power and networking rebuilds.\" Additionally, the ubiquity of GPUs means that there is more engineering talent available. TPUs demand a rare skillset. \"Leveraging the power of TPUs requires an organization to have engineering depth, which means being able to recruit and retain the rare engineering talent that can write custom kernels and optimize compilers,\" Bercovici said. In practice, Ironwood’s advantages can be realized mostly for enterprises with large, tensor-heavy workloads. Organizations requiring broader hardware flexibility, hybrid-cloud strategies, or HPC-style versatility may find GPUs the better fit. In many cases, a hybrid approach combining the two may offer the best balance of specialization and flexibility.The future of AI architectureThe competition for AI hardware dominance is heating up, but it&#x27;s far too early to predict a winner — or if there will even be a winner at all. With Nvidia and Google innovating at such a rapid pace and companies like Amazon joining the fray, the highest-performing AI systems of the future could be hybrid, integrating both TPUs and GPUs.\"Google Cloud is experiencing accelerating demand for both our custom TPUs and Nvidia GPUs,” a Google spokesperson told VentureBeat. “As a result, we are significantly expanding our Nvidia GPU offerings to meet substantial customer demand. The reality is that the majority of our Google Cloud customers use both GPUs and TPUs. With our wide selection of the latest Nvidia GPUs and seven generations of custom TPUs, we offer customers the flexibility of choice to optimize for their specific needs.\"",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5fpm1kFZ4PDgn6vjzrMoQu/39d54faf92de31f8d62a81ec9ab4df63/cruey3_photo_realistic_colorful_blocks_going_up_from_the_ground_3055ca54-93bb-4e1b-a45d-d53a8a0d193e.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/mistral-launches-powerful-devstral-2-coding-model-including-open-source",
          "published_at": "Tue, 09 Dec 2025 19:44:00 GMT",
          "title": "Mistral launches powerful Devstral 2 coding model including open source, laptop-friendly version",
          "standfirst": "French AI startup Mistral has weathered a rocky period of public questioning over the last year to emerge, now here in December 2025, with new, crowd-pleasing models for enterprise and indie developers.Just days after releasing its powerful open source, general purpose Mistral 3 LLM family for edge devices and local hardware, the company returned today to debut Devstral 2.The release includes a new pair of models optimized for software engineering tasks — again, with one small enough to run on a single laptop, offline and privately — alongside Mistral Vibe, a command-line interface (CLI) agent designed to allow developers to call the models up directly within their terminal environments. The models are fast, lean, and open—at least in theory. But the real story lies not just in the benchmarks, but in how Mistral is packaging this capability: one model fully free, another conditionally so, and a terminal interface built to scale with either.It’s an attempt not just to match proprietary systems like Claude and GPT-4 in performance, but to compete with them on developer experience—and to do so while holding onto the flag of open-source.Both models are available now for free for a limited time via Mistral’s API and Hugging Face. The full Devstral 2 model is supported out-of-the-box in the community inference provider vLLM and on the open source agentic coding platform Kilo Code. A Coding Model Meant to DriveAt the top of the announcement is Devstral 2, a 123-billion parameter dense transformer with a 256K-token context window, engineered specifically for agentic software development. Mistral says the model achieves 72.2% on SWE-bench Verified, a benchmark designed to evaluate long-context software engineering tasks in real-world repositories.The smaller sibling, Devstral Small 2, weighs in at 24B parameters, with the same long context window and a performance of 68.0% on SWE-bench. On paper, that makes it the strongest open-weight model of its size, even outscoring many 70B-class competitors.But the performance story isn’t just about raw percentages. Mistral is betting that efficient intelligence beats scale, and has made much of the fact that Devstral 2 is:5× smaller than DeepSeek V3.28× smaller than Kimi K2Yet still matches or surpasses them on key software reasoning benchmarks.Human evaluations back this up. In side-by-side comparisons:Devstral 2 beat DeepSeek V3.2 in 42.8% of tasks, losing only 28.6%.Against Claude Sonnet 4.5, it lost more often (53.1%)—a reminder that while the gap is narrowing, closed models still lead in overall preference.Still, for an open-weight model, these results place Devstral 2 at the frontier of what’s currently available to run and modify independently.Vibe CLI: A Terminal-Native AgentAlongside the models, Mistral released Vibe CLI, a command-line assistant that integrates directly with Devstral models. It’s not an IDE plugin or a ChatGPT-style code explainer. It’s a native interface designed for project-wide code understanding and orchestration, built to live inside the developer’s actual workflow.Vibe brings a surprising degree of intelligence to the terminal:It reads your file tree and Git status to understand project scope.It lets you reference files with @, run shell commands with !, and toggle behavior with slash commands.It orchestrates changes across multiple files, tracks dependencies, retries failed executions, and can even refactor at architectural scale.Unlike most developer agents, which simulate a REPL from within a chat UI, Vibe starts with the shell and pulls intelligence in from there. It’s programmable, scriptable, and themeable. And it’s released under the Apache 2.0 license, meaning it’s truly free to use—in commercial settings, internal tools, or open-source extensions.Licensing Structure: Open-ish — With Revenue LimitationsAt first glance, Mistral’s licensing approach appears straightforward: the models are open-weight and publicly available. But a closer look reveals a line drawn through the middle of the release, with different rules for different users.Devstral Small 2, the 24-billion parameter variant, is covered under a standard, enterprise- and developer-friendly Apache 2.0 license. That’s a gold standard in open-source: no revenue restrictions, no fine print, no need to check with legal. Enterprises can use it in production, embed it into products, and redistribute fine-tuned versions without asking for permission.Devstral 2, the flagship 123B model, is released under what Mistral calls a “modified MIT license.” That phrase sounds innocuous, but the modification introduces a critical limitation: any company making more than $20 million in monthly revenue cannot use the model at all—not even internally—without securing a separate commercial license from Mistral.“You are not authorized to exercise any rights under this license if the global consolidated monthly revenue of your company […] exceeds $20 million,” the license reads.The clause applies not only to the base model, but to derivatives, fine-tuned versions, and redistributed variants, regardless of who hosts them. In effect, it means that while the weights are “open,” their use is gated for large enterprises—unless they’re willing to engage with Mistral’s sales team or use the hosted API at metered pricing.To draw an analogy: Apache 2.0 is like a public library—you walk in, borrow the book, and use it however you need. Mistral’s modified MIT license is more like a corporate co-working space that’s free for freelancers but charges rent once your company hits a certain size.Weighing Devstral Small 2 for Enterprise UseThis division raises an obvious question for larger companies: can Devstral Small 2 with its more permissive and unrestricted Apache 2.0 licensing serve as a viable alternative for medium-to-large enterprises?The answer depends on context. Devstral Small 2 scores 68.0% on SWE-bench, significantly ahead of many larger open models, and remains deployable on single-GPU or CPU-only setups. For teams focused on:internal tooling,on-prem deployment,low-latency edge inference,…it offers a rare combination of legality, performance, and convenience.But the performance gap from Devstral 2 is real. For multi-agent setups, deep monorepo refactoring, or long-context code analysis, that 4-point benchmark delta may understate the actual experience difference.For most enterprises, Devstral Small 2 will serve either as a low-friction way to prototype—or as a pragmatic bridge until licensing for Devstral 2 becomes feasible. It is not a drop-in replacement for the flagship, but it may be “good enough” in specific production slices, particularly when paired with Vibe CLI.But because Devstral Small 2 can be run entirely offline — including on a single GPU machine or a sufficiently specced laptop — it unlocks a critical use case for developers and teams operating in tightly controlled environments. Whether you’re a solo indie building tools on the go, or part of a company with strict data governance or compliance mandates, the ability to run a performant, long-context coding model without ever hitting the internet is a powerful differentiator. No cloud calls, no third-party telemetry, no risk of data leakage — just local inference with full visibility and control.This matters in industries like finance, healthcare, defense, and advanced manufacturing, where data often cannot leave the network perimeter. But it’s just as useful for developers who prefer autonomy over vendor lock-in — or who want their tools to work the same on a plane, in the field, or inside an air-gapped lab. In a market where most top-tier code models are delivered as API-only SaaS products, Devstral Small 2 offers a rare level of portability, privacy, and ownership.In that sense, Mistral isn’t just offering open models—they’re offering multiple paths to adoption, depending on your scale, compliance posture, and willingness to engage.Integration, Infrastructure, and AccessFrom a technical standpoint, Mistral’s models are built for deployment. Devstral 2 requires a minimum of 4× H100-class GPUs, and is already available on build.nvidia.com. Devstral Small 2 can run on a single GPU or CPU such as those in a standard laptop, making it accessible to solo developers and embedded teams alike.Both models support quantized FP4 and FP8 weights, and are compatible with vLLM for scalable inference. Fine-tuning is supported out of the box.API pricing—after the free introductory window—follows a token-based structure:Devstral 2: $0.40 per million input tokens / $2.00 for outputDevstral Small 2: $0.10 input / $0.30 outputThat pricing sits just below OpenAI’s GPT-4 Turbo, and well below Anthropic’s Claude Sonnet at comparable performance levels.Developer Reception: Ground-Level BuzzOn X (formerly Twitter), developers reacted quickly with a wave of positive reception, with Hugging Face&#x27;s Head of Product Victor Mustar asking if the small, Apache 2.0 licensed variant was the \"new local coding king,\" i.e., the one developers could use to run on their laptops directly and privately, without an internet connection:Another popular AI news and rumors account, TestingCatalogNews, posted that it was \"SOTTA in coding,\" or \"State Of The Tiny Art\"Another user, @xlr8harder, took issue with the custom licensing terms for Devstral 2, writing \"calling the Devstral 2 license &#x27;modified MIT&#x27; is misleading at best. It’s a proprietary license with MIT-like attribution requirements.\"While the tone was critical, it reflected some attention Mistral’s license structuring was receiving, particularly among developers familiar with open-use norms.Strategic Context: From Codestral to Devstral and Mistral 3Mistral’s steady push into software development tools didn’t start with Devstral 2—it began in May 2024 with Codestral, the company’s first code-focused large language model. A 22-billion parameter system trained on more than 80 programming languages, Codestral was designed for use in developer environments ranging from basic autocompletions to full function generation. The model launched under a non-commercial license but still outperformed heavyweight competitors like CodeLlama 70B and Deepseek Coder 33B in early benchmarks such as HumanEval and RepoBench.Codestral’s release marked Mistral’s first move into the competitive coding-model space, but it also established a now-familiar pattern: technically lean models with surprisingly strong results, a wide context window, and licensing choices that invited developer experimentation. Industry partners including JetBrains, LlamaIndex, and LangChain quickly began integrating the model into their workflows, citing its speed and tool compatibility as key differentiators.One year later, the company followed up with Devstral, a 24B model purpose-built for “agentic” behavior—handling long-range reasoning, file navigation, and autonomous code modification. Released in partnership with All Hands AI and licensed under Apache 2.0, Devstral was notable not just for its portability (it could run on a MacBook or RTX 4090), but for its performance: it beat out several closed models on SWE-Bench Verified, a benchmark of 500 real-world GitHub issues.Then came Mistral 3, announced in December 2025 as a portfolio of 10 open-weight models targeting everything from drones and smartphones to cloud infrastructure. This suite included both high-end models like Mistral Large 3 (a MoE system with 41 active parameters and 256K context) and lightweight “Ministral” variants that could run on 4GB of VRAM. All were licensed under Apache 2.0, reinforcing Mistral’s commitment to flexible, edge-friendly deployment.Mistral 3 positioned the company not as a direct competitor to frontier models like GPT-5 or Gemini 3, but as a developer-first platform for customized, localized AI systems. Co-founder Guillaume Lample described the vision as “distributed intelligence”—many smaller systems tuned for specific tasks and running outside centralized infrastructure. “In more than 90% of cases, a small model can do the job,” he told VentureBeat. “It doesn’t have to be a model with hundreds of billions of parameters.”That broader strategy helps explain the significance of Devstral 2. It’s not a one-off release but a continuation of Mistral’s long-running commitment to code agents, local-first deployment, and open-weight availability—an ecosystem that began with Codestral, matured through Devstral, and scaled up with Mistral 3. Devstral 2, in this framing, is not just a model. It’s the next version of a playbook that’s been unfolding in public for over a year.Final Thoughts (For Now): A Fork in the RoadWith Devstral 2, Devstral Small 2, and Vibe CLI, Mistral AI has drawn a clear map for developers and companies alike. The tools are fast, capable, and thoughtfully integrated. But they also present a choice—not just in architecture, but in how and where you’re allowed to use them.If you’re an individual developer, small startup, or open-source maintainer, this is one of the most powerful AI systems you can freely run today. If you’re a Fortune 500 engineering lead, you’ll need to either talk to Mistral—or settle for the smaller model and make it work.In a market increasingly dominated by black-box models and SaaS lock-ins, Mistral’s offer is still a breath of fresh air. Just read the fine print before you start building.",
          "content": "French AI startup Mistral has weathered a rocky period of public questioning over the last year to emerge, now here in December 2025, with new, crowd-pleasing models for enterprise and indie developers.Just days after releasing its powerful open source, general purpose Mistral 3 LLM family for edge devices and local hardware, the company returned today to debut Devstral 2.The release includes a new pair of models optimized for software engineering tasks — again, with one small enough to run on a single laptop, offline and privately — alongside Mistral Vibe, a command-line interface (CLI) agent designed to allow developers to call the models up directly within their terminal environments. The models are fast, lean, and open—at least in theory. But the real story lies not just in the benchmarks, but in how Mistral is packaging this capability: one model fully free, another conditionally so, and a terminal interface built to scale with either.It’s an attempt not just to match proprietary systems like Claude and GPT-4 in performance, but to compete with them on developer experience—and to do so while holding onto the flag of open-source.Both models are available now for free for a limited time via Mistral’s API and Hugging Face. The full Devstral 2 model is supported out-of-the-box in the community inference provider vLLM and on the open source agentic coding platform Kilo Code. A Coding Model Meant to DriveAt the top of the announcement is Devstral 2, a 123-billion parameter dense transformer with a 256K-token context window, engineered specifically for agentic software development. Mistral says the model achieves 72.2% on SWE-bench Verified, a benchmark designed to evaluate long-context software engineering tasks in real-world repositories.The smaller sibling, Devstral Small 2, weighs in at 24B parameters, with the same long context window and a performance of 68.0% on SWE-bench. On paper, that makes it the strongest open-weight model of its size, even outscoring many 70B-class competitors.But the performance story isn’t just about raw percentages. Mistral is betting that efficient intelligence beats scale, and has made much of the fact that Devstral 2 is:5× smaller than DeepSeek V3.28× smaller than Kimi K2Yet still matches or surpasses them on key software reasoning benchmarks.Human evaluations back this up. In side-by-side comparisons:Devstral 2 beat DeepSeek V3.2 in 42.8% of tasks, losing only 28.6%.Against Claude Sonnet 4.5, it lost more often (53.1%)—a reminder that while the gap is narrowing, closed models still lead in overall preference.Still, for an open-weight model, these results place Devstral 2 at the frontier of what’s currently available to run and modify independently.Vibe CLI: A Terminal-Native AgentAlongside the models, Mistral released Vibe CLI, a command-line assistant that integrates directly with Devstral models. It’s not an IDE plugin or a ChatGPT-style code explainer. It’s a native interface designed for project-wide code understanding and orchestration, built to live inside the developer’s actual workflow.Vibe brings a surprising degree of intelligence to the terminal:It reads your file tree and Git status to understand project scope.It lets you reference files with @, run shell commands with !, and toggle behavior with slash commands.It orchestrates changes across multiple files, tracks dependencies, retries failed executions, and can even refactor at architectural scale.Unlike most developer agents, which simulate a REPL from within a chat UI, Vibe starts with the shell and pulls intelligence in from there. It’s programmable, scriptable, and themeable. And it’s released under the Apache 2.0 license, meaning it’s truly free to use—in commercial settings, internal tools, or open-source extensions.Licensing Structure: Open-ish — With Revenue LimitationsAt first glance, Mistral’s licensing approach appears straightforward: the models are open-weight and publicly available. But a closer look reveals a line drawn through the middle of the release, with different rules for different users.Devstral Small 2, the 24-billion parameter variant, is covered under a standard, enterprise- and developer-friendly Apache 2.0 license. That’s a gold standard in open-source: no revenue restrictions, no fine print, no need to check with legal. Enterprises can use it in production, embed it into products, and redistribute fine-tuned versions without asking for permission.Devstral 2, the flagship 123B model, is released under what Mistral calls a “modified MIT license.” That phrase sounds innocuous, but the modification introduces a critical limitation: any company making more than $20 million in monthly revenue cannot use the model at all—not even internally—without securing a separate commercial license from Mistral.“You are not authorized to exercise any rights under this license if the global consolidated monthly revenue of your company […] exceeds $20 million,” the license reads.The clause applies not only to the base model, but to derivatives, fine-tuned versions, and redistributed variants, regardless of who hosts them. In effect, it means that while the weights are “open,” their use is gated for large enterprises—unless they’re willing to engage with Mistral’s sales team or use the hosted API at metered pricing.To draw an analogy: Apache 2.0 is like a public library—you walk in, borrow the book, and use it however you need. Mistral’s modified MIT license is more like a corporate co-working space that’s free for freelancers but charges rent once your company hits a certain size.Weighing Devstral Small 2 for Enterprise UseThis division raises an obvious question for larger companies: can Devstral Small 2 with its more permissive and unrestricted Apache 2.0 licensing serve as a viable alternative for medium-to-large enterprises?The answer depends on context. Devstral Small 2 scores 68.0% on SWE-bench, significantly ahead of many larger open models, and remains deployable on single-GPU or CPU-only setups. For teams focused on:internal tooling,on-prem deployment,low-latency edge inference,…it offers a rare combination of legality, performance, and convenience.But the performance gap from Devstral 2 is real. For multi-agent setups, deep monorepo refactoring, or long-context code analysis, that 4-point benchmark delta may understate the actual experience difference.For most enterprises, Devstral Small 2 will serve either as a low-friction way to prototype—or as a pragmatic bridge until licensing for Devstral 2 becomes feasible. It is not a drop-in replacement for the flagship, but it may be “good enough” in specific production slices, particularly when paired with Vibe CLI.But because Devstral Small 2 can be run entirely offline — including on a single GPU machine or a sufficiently specced laptop — it unlocks a critical use case for developers and teams operating in tightly controlled environments. Whether you’re a solo indie building tools on the go, or part of a company with strict data governance or compliance mandates, the ability to run a performant, long-context coding model without ever hitting the internet is a powerful differentiator. No cloud calls, no third-party telemetry, no risk of data leakage — just local inference with full visibility and control.This matters in industries like finance, healthcare, defense, and advanced manufacturing, where data often cannot leave the network perimeter. But it’s just as useful for developers who prefer autonomy over vendor lock-in — or who want their tools to work the same on a plane, in the field, or inside an air-gapped lab. In a market where most top-tier code models are delivered as API-only SaaS products, Devstral Small 2 offers a rare level of portability, privacy, and ownership.In that sense, Mistral isn’t just offering open models—they’re offering multiple paths to adoption, depending on your scale, compliance posture, and willingness to engage.Integration, Infrastructure, and AccessFrom a technical standpoint, Mistral’s models are built for deployment. Devstral 2 requires a minimum of 4× H100-class GPUs, and is already available on build.nvidia.com. Devstral Small 2 can run on a single GPU or CPU such as those in a standard laptop, making it accessible to solo developers and embedded teams alike.Both models support quantized FP4 and FP8 weights, and are compatible with vLLM for scalable inference. Fine-tuning is supported out of the box.API pricing—after the free introductory window—follows a token-based structure:Devstral 2: $0.40 per million input tokens / $2.00 for outputDevstral Small 2: $0.10 input / $0.30 outputThat pricing sits just below OpenAI’s GPT-4 Turbo, and well below Anthropic’s Claude Sonnet at comparable performance levels.Developer Reception: Ground-Level BuzzOn X (formerly Twitter), developers reacted quickly with a wave of positive reception, with Hugging Face&#x27;s Head of Product Victor Mustar asking if the small, Apache 2.0 licensed variant was the \"new local coding king,\" i.e., the one developers could use to run on their laptops directly and privately, without an internet connection:Another popular AI news and rumors account, TestingCatalogNews, posted that it was \"SOTTA in coding,\" or \"State Of The Tiny Art\"Another user, @xlr8harder, took issue with the custom licensing terms for Devstral 2, writing \"calling the Devstral 2 license &#x27;modified MIT&#x27; is misleading at best. It’s a proprietary license with MIT-like attribution requirements.\"While the tone was critical, it reflected some attention Mistral’s license structuring was receiving, particularly among developers familiar with open-use norms.Strategic Context: From Codestral to Devstral and Mistral 3Mistral’s steady push into software development tools didn’t start with Devstral 2—it began in May 2024 with Codestral, the company’s first code-focused large language model. A 22-billion parameter system trained on more than 80 programming languages, Codestral was designed for use in developer environments ranging from basic autocompletions to full function generation. The model launched under a non-commercial license but still outperformed heavyweight competitors like CodeLlama 70B and Deepseek Coder 33B in early benchmarks such as HumanEval and RepoBench.Codestral’s release marked Mistral’s first move into the competitive coding-model space, but it also established a now-familiar pattern: technically lean models with surprisingly strong results, a wide context window, and licensing choices that invited developer experimentation. Industry partners including JetBrains, LlamaIndex, and LangChain quickly began integrating the model into their workflows, citing its speed and tool compatibility as key differentiators.One year later, the company followed up with Devstral, a 24B model purpose-built for “agentic” behavior—handling long-range reasoning, file navigation, and autonomous code modification. Released in partnership with All Hands AI and licensed under Apache 2.0, Devstral was notable not just for its portability (it could run on a MacBook or RTX 4090), but for its performance: it beat out several closed models on SWE-Bench Verified, a benchmark of 500 real-world GitHub issues.Then came Mistral 3, announced in December 2025 as a portfolio of 10 open-weight models targeting everything from drones and smartphones to cloud infrastructure. This suite included both high-end models like Mistral Large 3 (a MoE system with 41 active parameters and 256K context) and lightweight “Ministral” variants that could run on 4GB of VRAM. All were licensed under Apache 2.0, reinforcing Mistral’s commitment to flexible, edge-friendly deployment.Mistral 3 positioned the company not as a direct competitor to frontier models like GPT-5 or Gemini 3, but as a developer-first platform for customized, localized AI systems. Co-founder Guillaume Lample described the vision as “distributed intelligence”—many smaller systems tuned for specific tasks and running outside centralized infrastructure. “In more than 90% of cases, a small model can do the job,” he told VentureBeat. “It doesn’t have to be a model with hundreds of billions of parameters.”That broader strategy helps explain the significance of Devstral 2. It’s not a one-off release but a continuation of Mistral’s long-running commitment to code agents, local-first deployment, and open-weight availability—an ecosystem that began with Codestral, matured through Devstral, and scaled up with Mistral 3. Devstral 2, in this framing, is not just a model. It’s the next version of a playbook that’s been unfolding in public for over a year.Final Thoughts (For Now): A Fork in the RoadWith Devstral 2, Devstral Small 2, and Vibe CLI, Mistral AI has drawn a clear map for developers and companies alike. The tools are fast, capable, and thoughtfully integrated. But they also present a choice—not just in architecture, but in how and where you’re allowed to use them.If you’re an individual developer, small startup, or open-source maintainer, this is one of the most powerful AI systems you can freely run today. If you’re a Fortune 500 engineering lead, you’ll need to either talk to Mistral—or settle for the smaller model and make it work.In a market increasingly dominated by black-box models and SaaS lock-ins, Mistral’s offer is still a breath of fresh air. Just read the fine print before you start building.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5h08IT02qEnf15d2nC66XM/808f775396da3b120a6c20c72b759776/G-V5j_tz9IkXATIrqK6cF.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/meta-is-trying-to-make-facebook-suck-less-by-simplifying-things-a-bit-171910771.html",
          "published_at": "Tue, 09 Dec 2025 17:19:10 +0000",
          "title": "Meta is trying to make Facebook suck less by simplifying things a bit",
          "standfirst": "Somewhere along its never-ending quest to increase engagement, Meta realized that giving Facebook users more of what they want would make it more likely that they'll stick around. The company has announced a bunch of updates designed to help improve the feed and the broader Facebook experience by making it easier to find, create and share interesting things. (Because primarily showing updates from your friends with the occasional ad or meme post is maybe just too complicated.)Simplification is a big focus of this overhaul. First, the Facebook feed will be a bit more streamlined. Whenever you post multiple photos, Facebook will arrange them into a standardized grid. When you click into anything on the feed, you'll be able to see it in a full screen view. And there's a very welcome change in that you'll be able to like a photo by double-tapping it. Just be careful with that when you're swiping through an ex's or a crush's photos.Simplified Facebook feed.MetaSearch results are now said to \"show more content in a more immersive grid layout that supports all content types,\" according to Meta. The company is trying out a new full-screen viewer for Facebook that \"lets you explore different photo and video results without losing your place in search,\" which it plans to expand to \"more content and post types in the coming months.\"In addition, the company says you’ll be able to provide feedback on a Facebook post or Reel to help make future recommendations more relevant. More ways for you to \"shape your feed\" and offer feedback on what the algorithm serves up are coming soon.The Facebook feed sucks, and it's good that Meta knows it sucks. There have been numerous occasions over the last couple of years where I've had to scroll through a couple dozen uninteresting posts from pages and creators I've never heard of before seeing something from a friend. The glut of spam and AI slop isn't helping (things are pretty grim for creators who have been dealing with content thieves too). There was a spell of several months last year when, every single time I opened Facebook, I would see an utterly garbage AI-generated image of a \"tiny house,\" a supposedly cozy domicile where not much actually made sense (three TVs in a living room, stairs and railings that had the telltale signs of AI warping). I'd always provide feedback that I didn't want to see any posts from that page again. But the next day there'd be another rotten \"tiny house\" image from a different page in my feed.Here's hoping Meta will actually take feedback related to recommendations on board and act on it. If the company does, it might actually make the feed more interesting to scroll through again.Elsewhere, Facebook will place the most-used tab bar features — such as Reels, Friends, Marketplace and Profile — front and center on the tab bar for easier and faster access. Meta is also promising a refreshed look for the menu and \"cleaner\" tab notifications.Facebook Story creation screenMetaFacebook is making it easier to access more popular Story and Feed post creation tools like music and friend tagging by giving them more prominent placement. Advanced options like text background colors will be an extra tap or two away. The post and Story composer feature audience and cross-post settings prominently, so that you have ease of control over who can see what you're sharing. Meta has updated how comments work across the feed, Groups and Reels as well to make things more streamlined and easier to follow. On top of all of that, when you make changes to your profile, you might start seeing suggestions for friends with shared interests. Meta suggested that, \"if you update your profile to show you're into sourdough bread baking or planning a trip to Nashville, Facebook will show you friends who can give you sourdough starter tips or offer suggestions on the best local spots.\" As always, though, you can decide who sees what on your profile or simply opt to share none of this personal info with Facebook at all, especially if you feel that Meta already knows too much about you.This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-is-trying-to-make-facebook-suck-less-by-simplifying-things-a-bit-171910771.html?src=rss",
          "content": "Somewhere along its never-ending quest to increase engagement, Meta realized that giving Facebook users more of what they want would make it more likely that they'll stick around. The company has announced a bunch of updates designed to help improve the feed and the broader Facebook experience by making it easier to find, create and share interesting things. (Because primarily showing updates from your friends with the occasional ad or meme post is maybe just too complicated.)Simplification is a big focus of this overhaul. First, the Facebook feed will be a bit more streamlined. Whenever you post multiple photos, Facebook will arrange them into a standardized grid. When you click into anything on the feed, you'll be able to see it in a full screen view. And there's a very welcome change in that you'll be able to like a photo by double-tapping it. Just be careful with that when you're swiping through an ex's or a crush's photos.Simplified Facebook feed.MetaSearch results are now said to \"show more content in a more immersive grid layout that supports all content types,\" according to Meta. The company is trying out a new full-screen viewer for Facebook that \"lets you explore different photo and video results without losing your place in search,\" which it plans to expand to \"more content and post types in the coming months.\"In addition, the company says you’ll be able to provide feedback on a Facebook post or Reel to help make future recommendations more relevant. More ways for you to \"shape your feed\" and offer feedback on what the algorithm serves up are coming soon.The Facebook feed sucks, and it's good that Meta knows it sucks. There have been numerous occasions over the last couple of years where I've had to scroll through a couple dozen uninteresting posts from pages and creators I've never heard of before seeing something from a friend. The glut of spam and AI slop isn't helping (things are pretty grim for creators who have been dealing with content thieves too). There was a spell of several months last year when, every single time I opened Facebook, I would see an utterly garbage AI-generated image of a \"tiny house,\" a supposedly cozy domicile where not much actually made sense (three TVs in a living room, stairs and railings that had the telltale signs of AI warping). I'd always provide feedback that I didn't want to see any posts from that page again. But the next day there'd be another rotten \"tiny house\" image from a different page in my feed.Here's hoping Meta will actually take feedback related to recommendations on board and act on it. If the company does, it might actually make the feed more interesting to scroll through again.Elsewhere, Facebook will place the most-used tab bar features — such as Reels, Friends, Marketplace and Profile — front and center on the tab bar for easier and faster access. Meta is also promising a refreshed look for the menu and \"cleaner\" tab notifications.Facebook Story creation screenMetaFacebook is making it easier to access more popular Story and Feed post creation tools like music and friend tagging by giving them more prominent placement. Advanced options like text background colors will be an extra tap or two away. The post and Story composer feature audience and cross-post settings prominently, so that you have ease of control over who can see what you're sharing. Meta has updated how comments work across the feed, Groups and Reels as well to make things more streamlined and easier to follow. On top of all of that, when you make changes to your profile, you might start seeing suggestions for friends with shared interests. Meta suggested that, \"if you update your profile to show you're into sourdough bread baking or planning a trip to Nashville, Facebook will show you friends who can give you sourdough starter tips or offer suggestions on the best local spots.\" As always, though, you can decide who sees what on your profile or simply opt to share none of this personal info with Facebook at all, especially if you feel that Meta already knows too much about you.This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-is-trying-to-make-facebook-suck-less-by-simplifying-things-a-bit-171910771.html?src=rss",
          "feed_position": 38,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/facebook_feed.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data-infrastructure/databricks-officeqa-uncovers-disconnect-ai-agents-ace-abstract-tests-but",
          "published_at": "Tue, 09 Dec 2025 16:00:00 GMT",
          "title": "Databricks' OfficeQA uncovers disconnect: AI agents ace abstract tests but stall at 45% on enterprise docs",
          "standfirst": "There is no shortage of AI benchmarks in the market today, with popular options like Humanity&#x27;s Last Exam (HLE), ARC-AGI-2 and GDPval, among numerous others.AI agents excel at solving abstract math problems and passing PhD-level exams that most benchmarks are based on, but Databricks has a question for the enterprise: Can they actually handle the document-heavy work most enterprises need them to do?The answer, according to new research from the data and AI platform company, is sobering. Even the best-performing AI agents achieve less than 45% accuracy on tasks that mirror real enterprise workloads, exposing a critical gap between academic benchmarks and business reality.\"If we focus our research efforts on getting better at [existing benchmarks], then we&#x27;re probably not solving the right problems to make Databricks a better platform,\" Erich Elsen, principal research scientist at Databricks, explained to VentureBeat. \"So that&#x27;s why we were looking around. How do we create a benchmark that, if we get better at it, we&#x27;re actually getting better at solving the problems that our customers have?\"The result is OfficeQA, a benchmark designed to test AI agents on grounded reasoning: Answering questions based on complex proprietary datasets containing unstructured documents and tabular data. Unlike existing benchmarks that focus on abstract capabilities, OfficeQA proxies for the economically valuable tasks enterprises actually perform.Why academic benchmarks miss the enterprise markThere are numerous shortcomings of popular AI benchmarks from an enterprise perspective, according to Elsen. HLE features questions requiring PhD-level expertise across diverse fields. ARC-AGI evaluates abstract reasoning through visual manipulation of colored grids. Both push the frontiers of AI capabilities, but don&#x27;t reflect daily enterprise work. Even GDPval, which was specifically created to evaluate economically useful tasks, misses the target.\"We come from a pretty heavy science or engineering background, and sometimes we create evals that reflect that,\" Elsen said. \" So they&#x27;re either extremely math-heavy, which is a great, useful task, but advancing the frontiers of human mathematics is not what customers are trying to do with Databricks.\"While AI is commonly used for customer support and coding apps, Databricks&#x27; customer base has a broader set of requirements. Elsen noted that answering questions about documents or corpora of documents is a common enterprise task. These require parsing complex tables with nested headers, retrieving information across dozens or hundreds of documents and performing calculations where a single-digit error can cascade into organizations making incorrect business decisions.Building a benchmark that mirrors enterprise document complexityTo create a meaningful test of grounded reasoning capabilities, Databricks needed a dataset that approximates the messy reality of proprietary enterprise document corpora, while remaining freely available for research. The team landed on U.S. Treasury Bulletins, published monthly for five decades beginning in 1939 and quarterly thereafter.The Treasury Bulletins check every box for enterprise document complexity. Each bulletin runs 100 to 200 pages and consists of prose, complex tables, charts and figures describing Treasury operations: Where federal money came from, where it went and how it financed government operations. The corpus spans approximately 89,000 pages across eight decades. Until 1996, the bulletins were scans of physical documents; afterwards, they were digitally produced PDFs. USAFacts, an organization whose mission is \"to make government data easier to access and understand,\" partnered with Databricks to develop the benchmark, identifying Treasury Bulletins as ideal and ensuring questions reflected realistic use cases.The 246 questions require agents to handle messy, real-world document challenges: Scanned images, hierarchical table structures, temporal data spanning multiple reports and the need for external knowledge like inflation adjustments. Questions range from simple value lookups to multi-step analysis requiring statistical calculations and cross-year comparisons.To ensure the benchmark requires actual document-grounded retrieval, Databricks filtered out questions that LLMs could answer using parametric knowledge or web search alone. This removed simpler questions and some surprisingly complex ones where models leveraged historical financial records memorized during pre-training.Every question has a validated ground truth answer (typically a number, sometimes dates or small lists), enabling automated evaluation without human judging. This design choice matters: It allows reinforcement learning (RL) approaches that require verifiable rewards, similar to how models train on coding problems.Current performance exposes fundamental gapsDatabricks tested Claude Opus 4.5 Agent (using Claude&#x27;s SDK) and GPT-5.1 Agent (using OpenAI&#x27;s File Search API). The results should give pause to any enterprise betting heavily on current agent capabilities.When provided with raw PDF documents: Claude Opus 4.5 Agent (with default thinking=high) achieved 37.4% accuracy. GPT-5.1 Agent (with reasoning_effort=high) achieved 43.5% accuracy. However, performance improved noticeably when provided with pre-parsed versions of pages using Databricks&#x27; ai_parse_document, indicating that the poor raw PDF performance stems from LLM APIs struggling with parsing rather than reasoning. Even with parsed documents, the experiments show room for improvement.When provided with documents parsed using Databricks&#x27; ai_parse_document:Claude Opus 4.5 Agent achieved 67.8% accuracy (a +30.4 percentage point improvement)GPT-5.1 Agent achieved a 52.8% accuracy (a +9.3 percentage point improvement)Three findings that matter for enterprise deploymentsThe testing identified critical insights for practitioners:Parsing remains the fundamental blocker: Complex tables with nested headers, merged cells and unusual formatting frequently produce misaligned values. Even when given exact oracle pages, agents struggled primarily due to parsing errors, although performance roughly doubled with pre-parsed documents.Document versioning creates ambiguity: Financial and regulatory documents get revised and reissued, meaning multiple valid answers exist depending on the publication date. Agents often stop searching once they find a plausible answer, missing more authoritative sources.Visual reasoning is a gap: About 3% of questions require chart or graph interpretation, where current agents consistently fail. For enterprises where data visualizations communicate critical insights, this represents a meaningful capability limitation.How enterprises can use OfficeQAThe benchmark&#x27;s design enables specific improvement paths beyond simple scoring. \"Since you&#x27;re able to look at the right answer, it&#x27;s easy to tell if the error is coming from parsing,\" Elsen explained. This automated evaluation enables rapid iteration on parsing pipelines. The verified ground truth answers also enable RL training similar to coding benchmarks, since there&#x27;s no human judgment required.Elsen said the benchmark provides \"a really strong feedback signal\" for developers working on search solutions. However, he cautioned against treating it as training data.\"At least in my imagination, the goal of releasing this is more as an eval and not as a source of raw training data,\" he said. \"If you tune too specifically into this environment, then it&#x27;s not clear how generalizable your agent results would be.\"What this means for enterprise AI deploymentsFor enterprises currently deploying or planning document-heavy AI agent systems, OfficeQA provides a sobering reality check. Even the latest frontier models achieve only 43% accuracy on unprocessed PDFs and fall short of 70% accuracy even with optimal document parsing. Performance on the hardest questions plateaus at 40%, indicating substantial room for improvement.Three immediate implications:Evaluate your document complexity: If your documents resemble the complexity profile of Treasury Bulletins (scanned images, nested table structures, cross-document references), expect accuracy well below vendor marketing claims. Test on your actual documents before production deployment.Plan for the parsing bottleneck: The test results indicate that parsing remains a fundamental blocker. Budget time and resources for custom parsing solutions rather than assuming off-the-shelf OCR will suffice. Plan for hard question failure modes: Even with optimal parsing, agents plateau at 40% on complex multi-step questions. For mission-critical document workflows that require multi-document analysis, statistical calculations or visual reasoning, current agent capabilities may not be ready without significant human oversight.For enterprises looking to lead in AI-powered document intelligence, this benchmark provides a concrete evaluation framework and identifies specific capability gaps that need solving.",
          "content": "There is no shortage of AI benchmarks in the market today, with popular options like Humanity&#x27;s Last Exam (HLE), ARC-AGI-2 and GDPval, among numerous others.AI agents excel at solving abstract math problems and passing PhD-level exams that most benchmarks are based on, but Databricks has a question for the enterprise: Can they actually handle the document-heavy work most enterprises need them to do?The answer, according to new research from the data and AI platform company, is sobering. Even the best-performing AI agents achieve less than 45% accuracy on tasks that mirror real enterprise workloads, exposing a critical gap between academic benchmarks and business reality.\"If we focus our research efforts on getting better at [existing benchmarks], then we&#x27;re probably not solving the right problems to make Databricks a better platform,\" Erich Elsen, principal research scientist at Databricks, explained to VentureBeat. \"So that&#x27;s why we were looking around. How do we create a benchmark that, if we get better at it, we&#x27;re actually getting better at solving the problems that our customers have?\"The result is OfficeQA, a benchmark designed to test AI agents on grounded reasoning: Answering questions based on complex proprietary datasets containing unstructured documents and tabular data. Unlike existing benchmarks that focus on abstract capabilities, OfficeQA proxies for the economically valuable tasks enterprises actually perform.Why academic benchmarks miss the enterprise markThere are numerous shortcomings of popular AI benchmarks from an enterprise perspective, according to Elsen. HLE features questions requiring PhD-level expertise across diverse fields. ARC-AGI evaluates abstract reasoning through visual manipulation of colored grids. Both push the frontiers of AI capabilities, but don&#x27;t reflect daily enterprise work. Even GDPval, which was specifically created to evaluate economically useful tasks, misses the target.\"We come from a pretty heavy science or engineering background, and sometimes we create evals that reflect that,\" Elsen said. \" So they&#x27;re either extremely math-heavy, which is a great, useful task, but advancing the frontiers of human mathematics is not what customers are trying to do with Databricks.\"While AI is commonly used for customer support and coding apps, Databricks&#x27; customer base has a broader set of requirements. Elsen noted that answering questions about documents or corpora of documents is a common enterprise task. These require parsing complex tables with nested headers, retrieving information across dozens or hundreds of documents and performing calculations where a single-digit error can cascade into organizations making incorrect business decisions.Building a benchmark that mirrors enterprise document complexityTo create a meaningful test of grounded reasoning capabilities, Databricks needed a dataset that approximates the messy reality of proprietary enterprise document corpora, while remaining freely available for research. The team landed on U.S. Treasury Bulletins, published monthly for five decades beginning in 1939 and quarterly thereafter.The Treasury Bulletins check every box for enterprise document complexity. Each bulletin runs 100 to 200 pages and consists of prose, complex tables, charts and figures describing Treasury operations: Where federal money came from, where it went and how it financed government operations. The corpus spans approximately 89,000 pages across eight decades. Until 1996, the bulletins were scans of physical documents; afterwards, they were digitally produced PDFs. USAFacts, an organization whose mission is \"to make government data easier to access and understand,\" partnered with Databricks to develop the benchmark, identifying Treasury Bulletins as ideal and ensuring questions reflected realistic use cases.The 246 questions require agents to handle messy, real-world document challenges: Scanned images, hierarchical table structures, temporal data spanning multiple reports and the need for external knowledge like inflation adjustments. Questions range from simple value lookups to multi-step analysis requiring statistical calculations and cross-year comparisons.To ensure the benchmark requires actual document-grounded retrieval, Databricks filtered out questions that LLMs could answer using parametric knowledge or web search alone. This removed simpler questions and some surprisingly complex ones where models leveraged historical financial records memorized during pre-training.Every question has a validated ground truth answer (typically a number, sometimes dates or small lists), enabling automated evaluation without human judging. This design choice matters: It allows reinforcement learning (RL) approaches that require verifiable rewards, similar to how models train on coding problems.Current performance exposes fundamental gapsDatabricks tested Claude Opus 4.5 Agent (using Claude&#x27;s SDK) and GPT-5.1 Agent (using OpenAI&#x27;s File Search API). The results should give pause to any enterprise betting heavily on current agent capabilities.When provided with raw PDF documents: Claude Opus 4.5 Agent (with default thinking=high) achieved 37.4% accuracy. GPT-5.1 Agent (with reasoning_effort=high) achieved 43.5% accuracy. However, performance improved noticeably when provided with pre-parsed versions of pages using Databricks&#x27; ai_parse_document, indicating that the poor raw PDF performance stems from LLM APIs struggling with parsing rather than reasoning. Even with parsed documents, the experiments show room for improvement.When provided with documents parsed using Databricks&#x27; ai_parse_document:Claude Opus 4.5 Agent achieved 67.8% accuracy (a +30.4 percentage point improvement)GPT-5.1 Agent achieved a 52.8% accuracy (a +9.3 percentage point improvement)Three findings that matter for enterprise deploymentsThe testing identified critical insights for practitioners:Parsing remains the fundamental blocker: Complex tables with nested headers, merged cells and unusual formatting frequently produce misaligned values. Even when given exact oracle pages, agents struggled primarily due to parsing errors, although performance roughly doubled with pre-parsed documents.Document versioning creates ambiguity: Financial and regulatory documents get revised and reissued, meaning multiple valid answers exist depending on the publication date. Agents often stop searching once they find a plausible answer, missing more authoritative sources.Visual reasoning is a gap: About 3% of questions require chart or graph interpretation, where current agents consistently fail. For enterprises where data visualizations communicate critical insights, this represents a meaningful capability limitation.How enterprises can use OfficeQAThe benchmark&#x27;s design enables specific improvement paths beyond simple scoring. \"Since you&#x27;re able to look at the right answer, it&#x27;s easy to tell if the error is coming from parsing,\" Elsen explained. This automated evaluation enables rapid iteration on parsing pipelines. The verified ground truth answers also enable RL training similar to coding benchmarks, since there&#x27;s no human judgment required.Elsen said the benchmark provides \"a really strong feedback signal\" for developers working on search solutions. However, he cautioned against treating it as training data.\"At least in my imagination, the goal of releasing this is more as an eval and not as a source of raw training data,\" he said. \"If you tune too specifically into this environment, then it&#x27;s not clear how generalizable your agent results would be.\"What this means for enterprise AI deploymentsFor enterprises currently deploying or planning document-heavy AI agent systems, OfficeQA provides a sobering reality check. Even the latest frontier models achieve only 43% accuracy on unprocessed PDFs and fall short of 70% accuracy even with optimal document parsing. Performance on the hardest questions plateaus at 40%, indicating substantial room for improvement.Three immediate implications:Evaluate your document complexity: If your documents resemble the complexity profile of Treasury Bulletins (scanned images, nested table structures, cross-document references), expect accuracy well below vendor marketing claims. Test on your actual documents before production deployment.Plan for the parsing bottleneck: The test results indicate that parsing remains a fundamental blocker. Budget time and resources for custom parsing solutions rather than assuming off-the-shelf OCR will suffice. Plan for hard question failure modes: Even with optimal parsing, agents plateau at 40% on complex multi-step questions. For mission-critical document workflows that require multi-document analysis, statistical calculations or visual reasoning, current agent capabilities may not be ready without significant human oversight.For enterprises looking to lead in AI-powered document intelligence, this benchmark provides a concrete evaluation framework and identifies specific capability gaps that need solving.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/11CUQal9q3dPlFL3fRIjP3/a601024e0be680f9645daaf6198bf0f4/OfficeQA-image-smk.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/the-ai-boom-could-soon-send-gpu-prices-soaring-so-nows-a-good-time-to-buy-one-153000063.html",
          "published_at": "Tue, 09 Dec 2025 15:30:00 +0000",
          "title": "The AI boom could soon send GPU prices soaring, so now's a good time to buy one",
          "standfirst": "When someone asks me for gadget buying advice, I normally tell them to stick with their current device. In 2025, most new tech products aren't a worthwhile upgrade over even something that was released a few years ago — and with the price of everything going up, that new iPhone can wait. But things aren't normal right now. On December 3, The Wall Street Journal reported memory manufacturer Micron would wind down Crucial, its consumer business, to focus on components for the AI industry. The PC I'm writing this article on has an SSD and RAM from Crucial. Overnight, Micron decided to end a business it spent decades building, and from a certain perspective, I guess it makes sense. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals, creating unprecedented demand for server-grade solid-state storage and RAM. To meet the moment, manufacturers have been allocating more of their production capacity and wafers to high-margin commercial customers. For consumers, the result has been skyrocketing RAM prices, with some DDR5 kits now costing as much as two or three times as much as they did a couple of months ago. Recent analysis from TrendForce shows the price of some consumer-grade SSDs increased between 20 and 60 percent in November for the same reason. Then there's LPDDR5X memory, which is used in both smartphones and NVIDIA's Grace Blackwell and Vera Rubin platforms. In 2026, it's expected to increase in price as well. The demand for AI infrastructure is such that all consumer electronics may cost more in the coming months.Price Changes Coming December 7th 2025, Due To Market Conditions 🔔‼️ pic.twitter.com/et0HADhc08— CyberPowerPC (@CYBERPOWERPC) November 25, 2025 That gets me to the purpose of this article. If you've been thinking about upgrading to a new graphics card, I would recommend you buy one sooner rather than later. The AI boom came for RAM first, and there are already signs it will come for GPU pricing next. A recent report suggests AMD is considering raising the MSRP of its 8GB models by $20 and 16GB models by $40 due to the price of GDDR6 memory. NVIDIA, meanwhile, is rumored to have recently told its board partners it would no longer supply them with VRAM for their cards. Neither NVIDIA nor AMD responded to comment requests from Engadget requesting they share how they plan to work with their board partners to ensure GPU prices remain stable. NVIDIA also did not comment on reports the company will stop providing VRAM to its board partners. Separate from the memory shortage, neither NVIDIA nor AMD are expected to release new GPUs soon. According to recent rumors, the earliest a Super refresh of the Blackwell line could arrive is sometime in the middle of 2026 — not at CES in January as the 40-series Super cards did in 2024. The memory crunch could complicate things there too, since the company has typically relied on more and faster VRAM to offer better performance on its Super cards. With 50-series Super GPUs, it might not be the case that NVIDIA announces them at the same MSRP as their non-Super predecessors, which was the case with the 40-series. As for AMD, the company debuted its RDNA 4 cards at the start of the year. We know it's already working on RDNA 5, and if a recent chat with Sony's Mark Cerny is any indication, the new architecture will be a major step change for AMD. However, right now rumors indicate the earliest RDNA 5 could arrive is sometime in 2027.In other words, with nothing new on the horizon and pricing of existing stock likely to increase, there might be only a short window where you can get a new GPU at a reasonable price. It's impossible to predict the future, but if you're in need of an upgrade and have the means to purchase, there might not be a better opportunity before the end of 2026. RecommendationsThe recommendations in Engadget's recent GPU guide are still as relevant today as they were a few months ago. Once again, the best advice I can give is to buy a card with at least 12GB of VRAM, and preferably 16GB if your budget allows for it. Unless you mostly plan to play older games on a 1080p monitor, it's not worth considering a model with 8GB of VRAM — it won't last you long enough to warrant the purchase price. Our recommendations are grouped from most affordable to most expensive. Where possible, I've tried to find options from both Newegg and Amazon. You won't find any high-end picks like the RTX 5080 since if you can afford that card, this guide isn't for you. Intel Arc B580Intel's Arc B580 is a great budget option, as long as you can put up with some driver issues. Devindra Hardawar for EngadgetFor those on a tight budget, I would start and end my search with the Intel Arc B580. Newegg has models from ASRock and Onix at or under the card's $250 MSRP. I can't speak to the quality of ONIX cards, but ASRock is well-regarded. Over on Amazon, you can find the B580 for $300. With Intel cards you sometimes need to put up with odd driver issues, but as far as budget options go, the B580 offers value that's hard to beat. The one thing about budget cards like the B580 is they’re likely to face the most pricing pressure from the memory crunch due to the smaller margins manufacturers are making on them. NVIDIA RTX 5060 Ti 16GBIf you decide to go with the RTX 5060 Ti, be sure to buy the 16GB model. Devindra Hardawar for EngadgetIf you have more than $250 to spend on a GPU, the RTX 5060 Ti is the GPU to buy. Avoid the 8GB model and go straight for the 16GB variant. NVIDIA announced the 5060 Ti at an MSRP of $429, and luckily as of the writing of this article, you can still find one close to that price.Newegg, for instance, is selling the MSI Ventus Black Plus version of the card for $440. Amazon has the silver colorway of that same GPU listed for $460 currently. The retailer also has models from Gigabyte and Zotac in and around that same price. If I had to pick between the 5060 Ti and 5070, which NVIDIA only offers with 12GB of VRAM, I would pick the former. The 5060 Ti is a safer bet, and offers nearly as much performance, particularly in games that include ray tracing as an option. AMD Radeon RX 9070 and RX 9070 XT If you're a fan of Team Red, the Radeon RX 9070 and 9070 XT are among the best cards of this generation. Devindra Hardawar for EngadgetFor a mid-range option, the Radeon RX 9070 and 9070 XT offer excellent value. Of the two cards, the 9070 is the better purchase for most people due to its less demanding power requirements, but if you got a PSU that can handle the 9070 XT, go for it. Right now, Newegg has a few 9070 models from ASRock and Sapphire just under the card's $549 MSRP. My friend recently bought the Sapphire card linked above, and has had nothing but good things to say about it. You'll pay more going through Amazon, but the company has a couple of options around $600 from XFX and Gigabyte. When it comes to the 9070 XT, Newegg has an ASRock model priced right at the card's $599 MSRP. Many of the other options from Sapphire and XFX are unfortunately priced between $650 and $700. The same is true on Amazon, where the cheapest model I could find was $630. NVIDIA RTX 5070 TiIf you have more money to spend, the RTX 5070 Ti is a performance beast. Devindra Hardawar for EngadgetFor our final recommendation, consider the RTX 5070 Ti. It's a great option if you want to play games at 4K for less than what the 5080 and 5090 cost. Newegg has MSI and Zotac models on sale for $750, the card's recommended price. There are also a handful of other options from ASUS and Gigabyte that are just over $800. Amazon, meanwhile, is selling one Gigabyte variant for $749. This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/the-ai-boom-could-soon-send-gpu-prices-soaring-so-nows-a-good-time-to-buy-one-153000063.html?src=rss",
          "content": "When someone asks me for gadget buying advice, I normally tell them to stick with their current device. In 2025, most new tech products aren't a worthwhile upgrade over even something that was released a few years ago — and with the price of everything going up, that new iPhone can wait. But things aren't normal right now. On December 3, The Wall Street Journal reported memory manufacturer Micron would wind down Crucial, its consumer business, to focus on components for the AI industry. The PC I'm writing this article on has an SSD and RAM from Crucial. Overnight, Micron decided to end a business it spent decades building, and from a certain perspective, I guess it makes sense. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals, creating unprecedented demand for server-grade solid-state storage and RAM. To meet the moment, manufacturers have been allocating more of their production capacity and wafers to high-margin commercial customers. For consumers, the result has been skyrocketing RAM prices, with some DDR5 kits now costing as much as two or three times as much as they did a couple of months ago. Recent analysis from TrendForce shows the price of some consumer-grade SSDs increased between 20 and 60 percent in November for the same reason. Then there's LPDDR5X memory, which is used in both smartphones and NVIDIA's Grace Blackwell and Vera Rubin platforms. In 2026, it's expected to increase in price as well. The demand for AI infrastructure is such that all consumer electronics may cost more in the coming months.Price Changes Coming December 7th 2025, Due To Market Conditions 🔔‼️ pic.twitter.com/et0HADhc08— CyberPowerPC (@CYBERPOWERPC) November 25, 2025 That gets me to the purpose of this article. If you've been thinking about upgrading to a new graphics card, I would recommend you buy one sooner rather than later. The AI boom came for RAM first, and there are already signs it will come for GPU pricing next. A recent report suggests AMD is considering raising the MSRP of its 8GB models by $20 and 16GB models by $40 due to the price of GDDR6 memory. NVIDIA, meanwhile, is rumored to have recently told its board partners it would no longer supply them with VRAM for their cards. Neither NVIDIA nor AMD responded to comment requests from Engadget requesting they share how they plan to work with their board partners to ensure GPU prices remain stable. NVIDIA also did not comment on reports the company will stop providing VRAM to its board partners. Separate from the memory shortage, neither NVIDIA nor AMD are expected to release new GPUs soon. According to recent rumors, the earliest a Super refresh of the Blackwell line could arrive is sometime in the middle of 2026 — not at CES in January as the 40-series Super cards did in 2024. The memory crunch could complicate things there too, since the company has typically relied on more and faster VRAM to offer better performance on its Super cards. With 50-series Super GPUs, it might not be the case that NVIDIA announces them at the same MSRP as their non-Super predecessors, which was the case with the 40-series. As for AMD, the company debuted its RDNA 4 cards at the start of the year. We know it's already working on RDNA 5, and if a recent chat with Sony's Mark Cerny is any indication, the new architecture will be a major step change for AMD. However, right now rumors indicate the earliest RDNA 5 could arrive is sometime in 2027.In other words, with nothing new on the horizon and pricing of existing stock likely to increase, there might be only a short window where you can get a new GPU at a reasonable price. It's impossible to predict the future, but if you're in need of an upgrade and have the means to purchase, there might not be a better opportunity before the end of 2026. RecommendationsThe recommendations in Engadget's recent GPU guide are still as relevant today as they were a few months ago. Once again, the best advice I can give is to buy a card with at least 12GB of VRAM, and preferably 16GB if your budget allows for it. Unless you mostly plan to play older games on a 1080p monitor, it's not worth considering a model with 8GB of VRAM — it won't last you long enough to warrant the purchase price. Our recommendations are grouped from most affordable to most expensive. Where possible, I've tried to find options from both Newegg and Amazon. You won't find any high-end picks like the RTX 5080 since if you can afford that card, this guide isn't for you. Intel Arc B580Intel's Arc B580 is a great budget option, as long as you can put up with some driver issues. Devindra Hardawar for EngadgetFor those on a tight budget, I would start and end my search with the Intel Arc B580. Newegg has models from ASRock and Onix at or under the card's $250 MSRP. I can't speak to the quality of ONIX cards, but ASRock is well-regarded. Over on Amazon, you can find the B580 for $300. With Intel cards you sometimes need to put up with odd driver issues, but as far as budget options go, the B580 offers value that's hard to beat. The one thing about budget cards like the B580 is they’re likely to face the most pricing pressure from the memory crunch due to the smaller margins manufacturers are making on them. NVIDIA RTX 5060 Ti 16GBIf you decide to go with the RTX 5060 Ti, be sure to buy the 16GB model. Devindra Hardawar for EngadgetIf you have more than $250 to spend on a GPU, the RTX 5060 Ti is the GPU to buy. Avoid the 8GB model and go straight for the 16GB variant. NVIDIA announced the 5060 Ti at an MSRP of $429, and luckily as of the writing of this article, you can still find one close to that price.Newegg, for instance, is selling the MSI Ventus Black Plus version of the card for $440. Amazon has the silver colorway of that same GPU listed for $460 currently. The retailer also has models from Gigabyte and Zotac in and around that same price. If I had to pick between the 5060 Ti and 5070, which NVIDIA only offers with 12GB of VRAM, I would pick the former. The 5060 Ti is a safer bet, and offers nearly as much performance, particularly in games that include ray tracing as an option. AMD Radeon RX 9070 and RX 9070 XT If you're a fan of Team Red, the Radeon RX 9070 and 9070 XT are among the best cards of this generation. Devindra Hardawar for EngadgetFor a mid-range option, the Radeon RX 9070 and 9070 XT offer excellent value. Of the two cards, the 9070 is the better purchase for most people due to its less demanding power requirements, but if you got a PSU that can handle the 9070 XT, go for it. Right now, Newegg has a few 9070 models from ASRock and Sapphire just under the card's $549 MSRP. My friend recently bought the Sapphire card linked above, and has had nothing but good things to say about it. You'll pay more going through Amazon, but the company has a couple of options around $600 from XFX and Gigabyte. When it comes to the 9070 XT, Newegg has an ASRock model priced right at the card's $599 MSRP. Many of the other options from Sapphire and XFX are unfortunately priced between $650 and $700. The same is true on Amazon, where the cheapest model I could find was $630. NVIDIA RTX 5070 TiIf you have more money to spend, the RTX 5070 Ti is a performance beast. Devindra Hardawar for EngadgetFor our final recommendation, consider the RTX 5070 Ti. It's a great option if you want to play games at 4K for less than what the 5080 and 5090 cost. Newegg has MSI and Zotac models on sale for $750, the card's recommended price. There are also a handful of other options from ASUS and Gigabyte that are just over $800. Amazon, meanwhile, is selling one Gigabyte variant for $749. This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/the-ai-boom-could-soon-send-gpu-prices-soaring-so-nows-a-good-time-to-buy-one-153000063.html?src=rss",
          "feed_position": 43,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/intel-arc-b580.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/amazon-is-rolling-out-new-shopping-features-for-alexa-because-of-course-it-is-150000355.html",
          "published_at": "Tue, 09 Dec 2025 15:00:00 +0000",
          "title": "Amazon is rolling out new shopping features for Alexa+, because of course it is",
          "standfirst": "Congrats to any budding Nostradamus out there who peered into the future to boldly predict that Amazon would bring more shopping features to Alexa+ sooner rather than later. A gold star for you. Yes, it hasn't taken too long for Amazon to weave more features into the generative AI-powered version of Alexa that are designed to get you to buy more stuff.Shopping features were part of the original Alexa from the jump, of course, but Amazon is doing some interesting things with the latest iteration. For instance, the company is rolling out a new price tracking feature. Tell it the product you want and how much you’re willing to pay for it. As soon as the item goes on sale for below that price, Alexa+ will automatically order it for you using your default payment method and delivery address. This deal tracking feature also keeps an eye on items in your cart and wishlists. Maybe remember to turn this off when you’re going out of town for a while, though.Another feature that Alexa+ users can start trying today is a Shopping Essentials tool on Echo Show 15 and 21. You'll be able to see real-time tracking for your orders, your recent orders, household essentials that it may be time to reorder, saved items and your shopping list. Tap the screen and you can find out more info about products, add them to your cart and complete your purchase. You'll soon be able to add a shopping widget to your Echo Show home screen, but for now you can check this out by saying \"Open Shopping Essentials\" or \"Alexa, where's my stuff?\"Elsewhere, Alexa+ can offer personalized product recommendations after you share details about a special occasion or a person you're buying for. That could be handy if you haven't completed your gift shopping yet. There's also an option to add extra items onto a current order until just before it leaves an Amazon warehouse. Alexa+ might make some suggestions here, such as asking if you need batteries for a new gadget or toy.Amazon was always going to be interested in tapping into Alexa+ to prompt you to buy more goods from the company, but some of these features are pretty interesting, especially for deal hawks and those who order items frequently. It makes even more sense now as to why Amazon is trying to prevent third-party AI agents (such as the one in Perplexity's Comet browser) from carrying out purchases on the platform.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-is-rolling-out-new-shopping-features-for-alexa-because-of-course-it-is-150000355.html?src=rss",
          "content": "Congrats to any budding Nostradamus out there who peered into the future to boldly predict that Amazon would bring more shopping features to Alexa+ sooner rather than later. A gold star for you. Yes, it hasn't taken too long for Amazon to weave more features into the generative AI-powered version of Alexa that are designed to get you to buy more stuff.Shopping features were part of the original Alexa from the jump, of course, but Amazon is doing some interesting things with the latest iteration. For instance, the company is rolling out a new price tracking feature. Tell it the product you want and how much you’re willing to pay for it. As soon as the item goes on sale for below that price, Alexa+ will automatically order it for you using your default payment method and delivery address. This deal tracking feature also keeps an eye on items in your cart and wishlists. Maybe remember to turn this off when you’re going out of town for a while, though.Another feature that Alexa+ users can start trying today is a Shopping Essentials tool on Echo Show 15 and 21. You'll be able to see real-time tracking for your orders, your recent orders, household essentials that it may be time to reorder, saved items and your shopping list. Tap the screen and you can find out more info about products, add them to your cart and complete your purchase. You'll soon be able to add a shopping widget to your Echo Show home screen, but for now you can check this out by saying \"Open Shopping Essentials\" or \"Alexa, where's my stuff?\"Elsewhere, Alexa+ can offer personalized product recommendations after you share details about a special occasion or a person you're buying for. That could be handy if you haven't completed your gift shopping yet. There's also an option to add extra items onto a current order until just before it leaves an Amazon warehouse. Alexa+ might make some suggestions here, such as asking if you need batteries for a new gadget or toy.Amazon was always going to be interested in tapping into Alexa+ to prompt you to buy more goods from the company, but some of these features are pretty interesting, especially for deal hawks and those who order items frequently. It makes even more sense now as to why Amazon is trying to prevent third-party AI agents (such as the one in Perplexity's Comet browser) from carrying out purchases on the platform.This article originally appeared on Engadget at https://www.engadget.com/ai/amazon-is-rolling-out-new-shopping-features-for-alexa-because-of-course-it-is-150000355.html?src=rss",
          "feed_position": 46
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/techs-biggest-losers-of-2025-140000419.html",
          "published_at": "Tue, 09 Dec 2025 14:00:00 +0000",
          "title": "Tech's biggest losers of 2025",
          "standfirst": "It’s the end of another year, so it’s time for the Engadget staff to compile a list of the year’s biggest losers. We scour over articles from the previous 12 months to determine the people, companies, products and trends that made our lives worse over the course of the year. Some selections may be so pervasive they actually make our list of biggest winners. But, for the most part, we’re confident you’ll share in our collective rage over the biggest losers of 2025.OpenAIOpenAI CEO Sam Altman delivers a speech with video at the SK AI Summit 2025 at COEX in Seoul, South Korea on November 3, 2025 Anadolu via Getty ImagesIn 2025, OpenAI shed any pretense it was committed to anything more than making money. There are a few different things you could point to, including the company's successful reorganization into a more traditional profit-seeking business, but I think the most damning sign was OpenAI's response to the tragic death of Adam Raine. In August, Raine’s parents sued OpenAI, alleging ChatGPT was aware of four suicide attempts by their son before it helped him successfully plan his death. At first, OpenAI's response appeared commensurate with the gravity of the situation. A week after news of the lawsuit broke, the company announced in early September it was working on parental controls. That same month, the company said it was working on a system that would automatically identify teen users and restrict their ChatGPT usage. Then came the announcement of a new \"wellness\" advisory council. Setting aside the question of whether OpenAI would even follow the advice of the council, it was peculiar that the company chose not recruit a single expert on suicide prevention. At that point, it was still possible to give OpenAI the benefit of the doubt, but then information about the company's legal defense against the Raines started to trickle out, including the fact it had reportedly asked to see the memorial guest list for Adam Raine's funeral, a request the family's lawyers described as \"intentional harassment.\" In late November, court documents revealed the company planned to argue Raine's \"misuse\" of ChatGPT was to blame for his death, not its own insufficient safety systems. We live in a world where tech giants are rarely held accountable for the great harm they've shown themselves capable of inflicting on people. As things stand, OpenAI's handling of Adam Raine's death is further proof something must change. — Igor Bonifacic, Senior reporterXboxAn Xbox Ally X running the Windows full screen experience.Sam Rutherford for EngadgetDid anything go right for Xbox this year? While price increases have also affected Sony and Nintendo, Microsoft cranked up the prices of both the Xbox Series S and X twice in the last year. It’s bad: The Series S is now $100 more than at launch, five years on.Previously “the best deal in gaming”, the Xbox Series X/S combined with a Game Pass subscription gave you a ton of games to play, including any of Microsoft’s own titles on their launch date. However, the subscription is now $30 a month, up 50 percent. (It was previously $17 per month the year before.)I agree with Nathan Ingraham’s take: $30 for literally hundreds of games, plus launch-day availability for major games that typically cost $70, is reasonable. But it’s still a harder sell when the price has jumped. Are you getting 50 percent more games? Not yet. According to Bloomberg, Microsoft demanded higher profits from Xbox back in 2023. When the gaming division reached around 12 percent growth in the first nine months of 2022, that was an ambitious goal. Day One launches on Game Pass apparently dented Xbox’s ability to pull profits from its biggest titles.Microsoft no longer shares console unit sales, but in its most recent earnings report, the company announced that hardware revenue dropped 29 percent. That’s including those price increases, meaning console sales fell even further.Estimates over the last few years put the PS5 tens of millions of units ahead. An annual subscription to Game Pass is more than double the Sony console’s most premium plan, although it’s not an apples-to-apples comparison. This year, Microsoft collaborated with ASUS to create Xbox-branded handheld gaming PCs. In that form-factor, I was on the precipice of grabbing Game Pass and barreling through Xbox titles I never had the chance to play. Then, I reassessed exactly what I was missing out on. It wasn’t the inclusion of a Fortnite Crew subscription. Despite its developer shopping spree, Xbox exclusives remain few, with many appearing on rival platforms. This year, Indiana Jones and even the Forza series is available to play on PlayStation. And next year? Halo. Where are the exciting new games going to come from? In the middle of 2025, Microsoft announced major layoffs affecting over 9,000 employees across the company. with the gaming division being hit exceptionally hard. Cuts and closures across many of Microsoft’s game studios led to cancellations like a Perfect Dark reboot and Rare’s Everwild.Xbox’s 2025 was bad on both the business and creative fronts. The decision to hike console and Game Pass prices didn’t immediately turn around revenue. At the same time, layoffs and high-profile game cancellations make Xbox a challenging pitch for anyone deciding which console or platform to invest in. Right now, looking at Engadget’s pick of the top Xbox games, the only game I feel like I’m missing out on is Avowed. Many of our favorite games are already available on PS5 and several can be played on the Switch. The reverse, however, isn’t true. — Mat Smith, UK bureau chiefGrokThe Grokipedia page about Elon Musk Jonathan Raa/NurPhoto via Getty ImagesIt's hard to even know where to begin. X users have long noticed that Grok, the site's built-in chatbot, is less filtered than other AI tools. But this year, Grok went off the rails in some truly unhinged and disturbing ways. There was the time Grok randomly began talking about a nonexistent \"white genocide\" in South Africa in response to completely unrelated questions. There was the time it declared itself \"MechaHitler,\" much to the delight of neo-nazi fanboys on X. There was the time it was caught posting Holocaust denial tropes, and the time researchers noted its Wikipedia knockoff that contains dozens of citations of neo-Nazi website Stormfront. There was the time it became so embarrassingly obsessed with Elon Musk it claimed he was a better basketball player than LeBron James and a better actor than Tom Cruise. It later brought both its anti-semitism and Musk sycophancy together when it stated that it would choose saving Musk's brain over saving 16 million Jews. \"His potential long-term impact on billions outweighs the loss in utilitarian terms,\" it stated in a post that's since been deleted. Besides the horrifying racism, what all of these incidents have in common is that xAI, Musk's AI company that acquired X earlier this year, has failed to fully explain how its chatbot went so far off the rails. The company has blamed an unnamed rogue employee, its own Nazi-loving users and \"adversarial prompting\" for Grok's missteps. — Karissa Bell, Senior reporterEVs in the USFord Mustang Mach-E vehicles are seen for sale on a dealership lot on June 24, 2025 in Austin, Texas.Brandon Bell via Getty ImagesEVs sales across the globe are up around 25 percent this year. Germany broke records in the first half of 2025, with electric cars accounting for nearly one in five new registrations. Meanwhile, back in September, sales of BEVs in the UK grew by almost a third, setting a new high for our neighbors across the pond. And in China, EV sales are growing so fast (over 50 percent market share) that the country is beginning to flood the global market with gas-powered cars that it can't sell at home. So naturally, what did our esteemed leaders in the US do in order to help companies here stay competitive? They ended the EV tax credit. And wouldn't you know it, after a spike earlier this fall just before the credit went away, sales of EVs in the US began to slump, with some automakers like Ford seeing a drop of 60 percent year-over-year. No matter how you slice it, this is bad for any company that sells EVs in the US and particularly bad for anyone considering purchasing a new one in the foreseeable future. As an EV owner, that just bums me out. Not only does this policy change put more roadblocks in the way of making battery-powered cars more affordable, it also puts a damper on EV investment and threatens to cause US automakers to fall even further behind their rivals in China and elsewhere. Manufacturers across the Pacific are going so wild, they are making EVs that can jump like the Mach 5 from Speed Racer. That isn't to say there aren't any promising developments on the horizon. Ford's Universal EV Platform and the arrival of the Rivian R2 sometime next year are a couple of examples. But it's clear that our politicians wanted to target EVs in the US this year and they sure made it happen. So the next time someone asks why we can't have nice things here, you know who to blame. — Sam Rutherford, Senior reporterDJI drone customersDJI Neo 2Steve Dent for EngadgetBarring a miracle, DJI will be banned from selling any new drones in the US starting December 23rd — and buyers will feel the pain. As I wrote last month, the company has been targeted by regulators since 2017 over concerns that its products could be used to spy on sensitive US infrastructure on behalf of China. “What’s the big deal?” you may ask. “Surely people can buy from other drone companies.” Indeed, but the problem is that DJI has such a monumental technological lead and high market share (over 75 percent) that its absence will effectively upend the industry. Commercial buyers have checked other (approved) options from the likes of Skydio, but found them wanting. “In one year and a half, we had five failures of the manufacturers on the list. DJI, none,” Orlando police Sgt. David Cruz told the Miami Herald. “I work for a popular UAV photogrammetry company,” said a user on Reddit. “[A] ban will set back the drone industry in the US by several years. There’s no competitor to DJI right now.”The same applies on the consumer side. DJI’s drones outperform rivals in nearly every area including range, battery life, subject tracking, obstacle detection and video quality. It’s so one-sided that when testing DJI drones, I struggle to find other options for buyers with anywhere close to the same capabilities. The US government does have reason to be concerned about DJI’s drones. They present an obvious national security risk due to their ability to fly over sensitive areas, take photos or video and transmit them, live, to any location in the world. And being a Chinese company, they’re compelled by law to cooperate with state intelligence services. However, the US government hasn’t attempted to work with DJI to determine whether its products pose a risk so far. DJI made a final plea for a security review recently by sending letters to five US agencies that could assess its products. If that fails, chaos among drone users is likely to ensue. “We just want the best technology that keeps our citizens safe for the most reasonable price,” Sgt. Drew Fennelly of the Lawrence, Kansas police department told The Wall Street Journal last year. “The technology in the US-made drones has not caught up with the Chinese-manufactured drones.” — Steve Dent, Contributing reporterTV streamingParamount Skydance CEO David Ellison speaks during the Bloomberg Screentime conference in Los Angeles on October 9, 2025.PATRICK T. FALLON via Getty ImagesIn 2015, Sling TV arrived with ESPN, CNN, TBS, HGTV, Disney Channel and others for just $20 a month. A couple years later, YouTube TV debuted for just $35 monthly and showed local CBS, Fox, NBC and ABC stations plus dozens of other channels including ESPN, Fox Sports 1 and Bravo. Streaming TV had arrived. It was here to unfetter TV watchers from cable’s onerous contracts, high prices and carrier monopolies. Take that, Comcast! In your face, Charter! (But they’d still like to pay you for internet access, please.) Fast forward to 2025: Streaming TV and its low-price, monopoly-free, contractless freedom is all but dead. Every major live TV service provider raised prices this year. Currently, YouTubeTV, Hulu+ Live TV, Fubo and DirecTV all go for a minimum of $83 per month. That’s before you opt for cable-inspired package upgrades and channel add-ons. Throw in perks like 4K, additional sports channels and a couple of one-off networks and you’re easily shelling out $150 every month. You’ll pay less for chopped-up live TV plans from Sling TV, but be prepared to create a spreadsheet to make sure a plan has the channels you want. This year, consolidation came for TV streaming, giving strong Cox/Charter/Comcast monopoly vibes. Disney, which completed its buyout of Hulu in 2023, acquired Fubo this year and plans to combine the two. The combo makes Disney the second-largest live TV streaming provider behind Google. DirecTV already owns Sling TV, so that leaves just three big players in the live TV streaming arena. With Netflix's move to buy Warner Bros, the traditional streaming market is getting narrower, too. We can safely assume good ol’ market competition won’t be bringing prices down anytime soon. But it’s not just consolidation — fragmentation also contributes to an overall crappier streaming experience. In 2025, Disney launched a standalone ESPN service (no, not that one, nor that one) for $30 per month. So far, that doesn’t mean you can’t find ESPN content through other providers. But we did see Disney flex its increasingly large TV muscles in drawn-out contract negotiations with Google. The dispute darkened ESPN, ABC and other Disney channels on YouTube TV for two weeks this fall — which, I’ll point out for the cynical crowd, was less than two months after the standalone service launched. YouTube TV subscribers got a $20 credit, but that probably didn’t placate NFL and NCAA football fans who missed out on ESPN-carried games. Then in November, Fubo quarreled with NBCUniversal, saying the Peacock parent was “shifting content to their own streaming services” and forcing up rates. The spat turned off NBC, Bravo, USA and other channels for Fubo subscribers, no doubt infuriating both NBA and Real Housewives fans, despite a $15 credit. Of course, Fubo is Disney’s newest affiliate, so there are no non-bad guys here.The only advantage TV streaming has in its favor is the lack of cable-style contracts and I haven’t heard any murmurs of such a thing forthcoming. We are still all free to hop around between the big three TV streamers until we give up and just go back to DVDs. — Amy Skorheim, Senior reporterThe work of DOGEElon Musk at the Conservative Political Action Conference (CPAC) at the National Harbor in Oxon Hill, MD on February 20, 2025. The Washington Post via Getty ImagesAn Elon Musk-led attempt to rein in federal spending with the Department of Government Efficiency (DOGE) has been a failure by almost every metric. As of November, it was reported that DOGE is no more, even though the initiative ostensibly had eight months left to run. An official told Reuters that DOGE \"doesn't exist,\" and it never should have in the first place.Though Musk was only at the helm of DOGE for a few months, he and his team caused chaos. Adopting the slash-and-burn tactic Musk employed when he took over Twitter, he swung a chainsaw through myriad government departments, with DOGE firing workers who were actually essential and quickly had to be hired back. By August, the government was said to have fired some 300,000 federal workers, with DOGE taking responsibility for most of those. Among other things, cuts at the National Institutes of Health resulted in the end of funding for hundreds of medical studies, which is said to have affected tens of thousands of patients. It's also estimated that the dismantling of the US Agency for International Development had resulted in more than 650,000 deaths around the world by early December, with children accounting for two-thirds of those. DOGE workers seemed to be busy, though. They reportedly monitored government communications for criticisms of both Musk and President Donald Trump, while implementing generative AI chatbots in an attempt to automate some government tasks. But for all the blustering about making the government much more efficient, DOGE did not meet its stated goal.Musk initially promised to reduce government spending by $2 trillion, but it didn't take long for him to reduce that pledge to $150 billion. And yet government spending has actually gone up. In October, the first month of the government's fiscal year, its total outlay was $689 billion, an increase of $105 billion (18 percent) from October 2024. Still, maybe DOGE wasn't a total disaster for its architects. It was able to gain access to sensitive and valuable government data, after all. — Kris Holt, Contributing reporterAI videoSora 2 app launch screen displayed on smartphoneIn our post-truth world, video was one of the few remaining ways to prove something had actually happened. It had its problems of course, but the fact it was harder to fake than words and images, and anyone could record a clip with their phone, made it vital to our sense of shared reality. Think about the murder of George Floyd: The grave injustice of his death would have probably never come to light if Darnella Frazier had not filmed what happened. With the advent of AI video, I'm not sure where we go. Both Google and OpenAI pushed the technology into the realm of uncomfortable realism this year, but it's Sora's cameo feature that has me worried. Within the first week of the app's public availability, people were using the feature, which allows users to add the likeness of other people to their videos, to generate clips of OpenAI CEO Sam Altman stealing GPUs from Target. Cameo has limitations, and users can restrict and delete videos that include their likeness, but it's just another assault on the truth. It's hard to see how making it trivial to create deepfake videos benefits anyone other than the companies offering building the tech. — I.B.This article originally appeared on Engadget at https://www.engadget.com/techs-biggest-losers-of-2025-140000419.html?src=rss",
          "content": "It’s the end of another year, so it’s time for the Engadget staff to compile a list of the year’s biggest losers. We scour over articles from the previous 12 months to determine the people, companies, products and trends that made our lives worse over the course of the year. Some selections may be so pervasive they actually make our list of biggest winners. But, for the most part, we’re confident you’ll share in our collective rage over the biggest losers of 2025.OpenAIOpenAI CEO Sam Altman delivers a speech with video at the SK AI Summit 2025 at COEX in Seoul, South Korea on November 3, 2025 Anadolu via Getty ImagesIn 2025, OpenAI shed any pretense it was committed to anything more than making money. There are a few different things you could point to, including the company's successful reorganization into a more traditional profit-seeking business, but I think the most damning sign was OpenAI's response to the tragic death of Adam Raine. In August, Raine’s parents sued OpenAI, alleging ChatGPT was aware of four suicide attempts by their son before it helped him successfully plan his death. At first, OpenAI's response appeared commensurate with the gravity of the situation. A week after news of the lawsuit broke, the company announced in early September it was working on parental controls. That same month, the company said it was working on a system that would automatically identify teen users and restrict their ChatGPT usage. Then came the announcement of a new \"wellness\" advisory council. Setting aside the question of whether OpenAI would even follow the advice of the council, it was peculiar that the company chose not recruit a single expert on suicide prevention. At that point, it was still possible to give OpenAI the benefit of the doubt, but then information about the company's legal defense against the Raines started to trickle out, including the fact it had reportedly asked to see the memorial guest list for Adam Raine's funeral, a request the family's lawyers described as \"intentional harassment.\" In late November, court documents revealed the company planned to argue Raine's \"misuse\" of ChatGPT was to blame for his death, not its own insufficient safety systems. We live in a world where tech giants are rarely held accountable for the great harm they've shown themselves capable of inflicting on people. As things stand, OpenAI's handling of Adam Raine's death is further proof something must change. — Igor Bonifacic, Senior reporterXboxAn Xbox Ally X running the Windows full screen experience.Sam Rutherford for EngadgetDid anything go right for Xbox this year? While price increases have also affected Sony and Nintendo, Microsoft cranked up the prices of both the Xbox Series S and X twice in the last year. It’s bad: The Series S is now $100 more than at launch, five years on.Previously “the best deal in gaming”, the Xbox Series X/S combined with a Game Pass subscription gave you a ton of games to play, including any of Microsoft’s own titles on their launch date. However, the subscription is now $30 a month, up 50 percent. (It was previously $17 per month the year before.)I agree with Nathan Ingraham’s take: $30 for literally hundreds of games, plus launch-day availability for major games that typically cost $70, is reasonable. But it’s still a harder sell when the price has jumped. Are you getting 50 percent more games? Not yet. According to Bloomberg, Microsoft demanded higher profits from Xbox back in 2023. When the gaming division reached around 12 percent growth in the first nine months of 2022, that was an ambitious goal. Day One launches on Game Pass apparently dented Xbox’s ability to pull profits from its biggest titles.Microsoft no longer shares console unit sales, but in its most recent earnings report, the company announced that hardware revenue dropped 29 percent. That’s including those price increases, meaning console sales fell even further.Estimates over the last few years put the PS5 tens of millions of units ahead. An annual subscription to Game Pass is more than double the Sony console’s most premium plan, although it’s not an apples-to-apples comparison. This year, Microsoft collaborated with ASUS to create Xbox-branded handheld gaming PCs. In that form-factor, I was on the precipice of grabbing Game Pass and barreling through Xbox titles I never had the chance to play. Then, I reassessed exactly what I was missing out on. It wasn’t the inclusion of a Fortnite Crew subscription. Despite its developer shopping spree, Xbox exclusives remain few, with many appearing on rival platforms. This year, Indiana Jones and even the Forza series is available to play on PlayStation. And next year? Halo. Where are the exciting new games going to come from? In the middle of 2025, Microsoft announced major layoffs affecting over 9,000 employees across the company. with the gaming division being hit exceptionally hard. Cuts and closures across many of Microsoft’s game studios led to cancellations like a Perfect Dark reboot and Rare’s Everwild.Xbox’s 2025 was bad on both the business and creative fronts. The decision to hike console and Game Pass prices didn’t immediately turn around revenue. At the same time, layoffs and high-profile game cancellations make Xbox a challenging pitch for anyone deciding which console or platform to invest in. Right now, looking at Engadget’s pick of the top Xbox games, the only game I feel like I’m missing out on is Avowed. Many of our favorite games are already available on PS5 and several can be played on the Switch. The reverse, however, isn’t true. — Mat Smith, UK bureau chiefGrokThe Grokipedia page about Elon Musk Jonathan Raa/NurPhoto via Getty ImagesIt's hard to even know where to begin. X users have long noticed that Grok, the site's built-in chatbot, is less filtered than other AI tools. But this year, Grok went off the rails in some truly unhinged and disturbing ways. There was the time Grok randomly began talking about a nonexistent \"white genocide\" in South Africa in response to completely unrelated questions. There was the time it declared itself \"MechaHitler,\" much to the delight of neo-nazi fanboys on X. There was the time it was caught posting Holocaust denial tropes, and the time researchers noted its Wikipedia knockoff that contains dozens of citations of neo-Nazi website Stormfront. There was the time it became so embarrassingly obsessed with Elon Musk it claimed he was a better basketball player than LeBron James and a better actor than Tom Cruise. It later brought both its anti-semitism and Musk sycophancy together when it stated that it would choose saving Musk's brain over saving 16 million Jews. \"His potential long-term impact on billions outweighs the loss in utilitarian terms,\" it stated in a post that's since been deleted. Besides the horrifying racism, what all of these incidents have in common is that xAI, Musk's AI company that acquired X earlier this year, has failed to fully explain how its chatbot went so far off the rails. The company has blamed an unnamed rogue employee, its own Nazi-loving users and \"adversarial prompting\" for Grok's missteps. — Karissa Bell, Senior reporterEVs in the USFord Mustang Mach-E vehicles are seen for sale on a dealership lot on June 24, 2025 in Austin, Texas.Brandon Bell via Getty ImagesEVs sales across the globe are up around 25 percent this year. Germany broke records in the first half of 2025, with electric cars accounting for nearly one in five new registrations. Meanwhile, back in September, sales of BEVs in the UK grew by almost a third, setting a new high for our neighbors across the pond. And in China, EV sales are growing so fast (over 50 percent market share) that the country is beginning to flood the global market with gas-powered cars that it can't sell at home. So naturally, what did our esteemed leaders in the US do in order to help companies here stay competitive? They ended the EV tax credit. And wouldn't you know it, after a spike earlier this fall just before the credit went away, sales of EVs in the US began to slump, with some automakers like Ford seeing a drop of 60 percent year-over-year. No matter how you slice it, this is bad for any company that sells EVs in the US and particularly bad for anyone considering purchasing a new one in the foreseeable future. As an EV owner, that just bums me out. Not only does this policy change put more roadblocks in the way of making battery-powered cars more affordable, it also puts a damper on EV investment and threatens to cause US automakers to fall even further behind their rivals in China and elsewhere. Manufacturers across the Pacific are going so wild, they are making EVs that can jump like the Mach 5 from Speed Racer. That isn't to say there aren't any promising developments on the horizon. Ford's Universal EV Platform and the arrival of the Rivian R2 sometime next year are a couple of examples. But it's clear that our politicians wanted to target EVs in the US this year and they sure made it happen. So the next time someone asks why we can't have nice things here, you know who to blame. — Sam Rutherford, Senior reporterDJI drone customersDJI Neo 2Steve Dent for EngadgetBarring a miracle, DJI will be banned from selling any new drones in the US starting December 23rd — and buyers will feel the pain. As I wrote last month, the company has been targeted by regulators since 2017 over concerns that its products could be used to spy on sensitive US infrastructure on behalf of China. “What’s the big deal?” you may ask. “Surely people can buy from other drone companies.” Indeed, but the problem is that DJI has such a monumental technological lead and high market share (over 75 percent) that its absence will effectively upend the industry. Commercial buyers have checked other (approved) options from the likes of Skydio, but found them wanting. “In one year and a half, we had five failures of the manufacturers on the list. DJI, none,” Orlando police Sgt. David Cruz told the Miami Herald. “I work for a popular UAV photogrammetry company,” said a user on Reddit. “[A] ban will set back the drone industry in the US by several years. There’s no competitor to DJI right now.”The same applies on the consumer side. DJI’s drones outperform rivals in nearly every area including range, battery life, subject tracking, obstacle detection and video quality. It’s so one-sided that when testing DJI drones, I struggle to find other options for buyers with anywhere close to the same capabilities. The US government does have reason to be concerned about DJI’s drones. They present an obvious national security risk due to their ability to fly over sensitive areas, take photos or video and transmit them, live, to any location in the world. And being a Chinese company, they’re compelled by law to cooperate with state intelligence services. However, the US government hasn’t attempted to work with DJI to determine whether its products pose a risk so far. DJI made a final plea for a security review recently by sending letters to five US agencies that could assess its products. If that fails, chaos among drone users is likely to ensue. “We just want the best technology that keeps our citizens safe for the most reasonable price,” Sgt. Drew Fennelly of the Lawrence, Kansas police department told The Wall Street Journal last year. “The technology in the US-made drones has not caught up with the Chinese-manufactured drones.” — Steve Dent, Contributing reporterTV streamingParamount Skydance CEO David Ellison speaks during the Bloomberg Screentime conference in Los Angeles on October 9, 2025.PATRICK T. FALLON via Getty ImagesIn 2015, Sling TV arrived with ESPN, CNN, TBS, HGTV, Disney Channel and others for just $20 a month. A couple years later, YouTube TV debuted for just $35 monthly and showed local CBS, Fox, NBC and ABC stations plus dozens of other channels including ESPN, Fox Sports 1 and Bravo. Streaming TV had arrived. It was here to unfetter TV watchers from cable’s onerous contracts, high prices and carrier monopolies. Take that, Comcast! In your face, Charter! (But they’d still like to pay you for internet access, please.) Fast forward to 2025: Streaming TV and its low-price, monopoly-free, contractless freedom is all but dead. Every major live TV service provider raised prices this year. Currently, YouTubeTV, Hulu+ Live TV, Fubo and DirecTV all go for a minimum of $83 per month. That’s before you opt for cable-inspired package upgrades and channel add-ons. Throw in perks like 4K, additional sports channels and a couple of one-off networks and you’re easily shelling out $150 every month. You’ll pay less for chopped-up live TV plans from Sling TV, but be prepared to create a spreadsheet to make sure a plan has the channels you want. This year, consolidation came for TV streaming, giving strong Cox/Charter/Comcast monopoly vibes. Disney, which completed its buyout of Hulu in 2023, acquired Fubo this year and plans to combine the two. The combo makes Disney the second-largest live TV streaming provider behind Google. DirecTV already owns Sling TV, so that leaves just three big players in the live TV streaming arena. With Netflix's move to buy Warner Bros, the traditional streaming market is getting narrower, too. We can safely assume good ol’ market competition won’t be bringing prices down anytime soon. But it’s not just consolidation — fragmentation also contributes to an overall crappier streaming experience. In 2025, Disney launched a standalone ESPN service (no, not that one, nor that one) for $30 per month. So far, that doesn’t mean you can’t find ESPN content through other providers. But we did see Disney flex its increasingly large TV muscles in drawn-out contract negotiations with Google. The dispute darkened ESPN, ABC and other Disney channels on YouTube TV for two weeks this fall — which, I’ll point out for the cynical crowd, was less than two months after the standalone service launched. YouTube TV subscribers got a $20 credit, but that probably didn’t placate NFL and NCAA football fans who missed out on ESPN-carried games. Then in November, Fubo quarreled with NBCUniversal, saying the Peacock parent was “shifting content to their own streaming services” and forcing up rates. The spat turned off NBC, Bravo, USA and other channels for Fubo subscribers, no doubt infuriating both NBA and Real Housewives fans, despite a $15 credit. Of course, Fubo is Disney’s newest affiliate, so there are no non-bad guys here.The only advantage TV streaming has in its favor is the lack of cable-style contracts and I haven’t heard any murmurs of such a thing forthcoming. We are still all free to hop around between the big three TV streamers until we give up and just go back to DVDs. — Amy Skorheim, Senior reporterThe work of DOGEElon Musk at the Conservative Political Action Conference (CPAC) at the National Harbor in Oxon Hill, MD on February 20, 2025. The Washington Post via Getty ImagesAn Elon Musk-led attempt to rein in federal spending with the Department of Government Efficiency (DOGE) has been a failure by almost every metric. As of November, it was reported that DOGE is no more, even though the initiative ostensibly had eight months left to run. An official told Reuters that DOGE \"doesn't exist,\" and it never should have in the first place.Though Musk was only at the helm of DOGE for a few months, he and his team caused chaos. Adopting the slash-and-burn tactic Musk employed when he took over Twitter, he swung a chainsaw through myriad government departments, with DOGE firing workers who were actually essential and quickly had to be hired back. By August, the government was said to have fired some 300,000 federal workers, with DOGE taking responsibility for most of those. Among other things, cuts at the National Institutes of Health resulted in the end of funding for hundreds of medical studies, which is said to have affected tens of thousands of patients. It's also estimated that the dismantling of the US Agency for International Development had resulted in more than 650,000 deaths around the world by early December, with children accounting for two-thirds of those. DOGE workers seemed to be busy, though. They reportedly monitored government communications for criticisms of both Musk and President Donald Trump, while implementing generative AI chatbots in an attempt to automate some government tasks. But for all the blustering about making the government much more efficient, DOGE did not meet its stated goal.Musk initially promised to reduce government spending by $2 trillion, but it didn't take long for him to reduce that pledge to $150 billion. And yet government spending has actually gone up. In October, the first month of the government's fiscal year, its total outlay was $689 billion, an increase of $105 billion (18 percent) from October 2024. Still, maybe DOGE wasn't a total disaster for its architects. It was able to gain access to sensitive and valuable government data, after all. — Kris Holt, Contributing reporterAI videoSora 2 app launch screen displayed on smartphoneIn our post-truth world, video was one of the few remaining ways to prove something had actually happened. It had its problems of course, but the fact it was harder to fake than words and images, and anyone could record a clip with their phone, made it vital to our sense of shared reality. Think about the murder of George Floyd: The grave injustice of his death would have probably never come to light if Darnella Frazier had not filmed what happened. With the advent of AI video, I'm not sure where we go. Both Google and OpenAI pushed the technology into the realm of uncomfortable realism this year, but it's Sora's cameo feature that has me worried. Within the first week of the app's public availability, people were using the feature, which allows users to add the likeness of other people to their videos, to generate clips of OpenAI CEO Sam Altman stealing GPUs from Target. Cameo has limitations, and users can restrict and delete videos that include their likeness, but it's just another assault on the truth. It's hard to see how making it trivial to create deepfake videos benefits anyone other than the companies offering building the tech. — I.B.This article originally appeared on Engadget at https://www.engadget.com/techs-biggest-losers-of-2025-140000419.html?src=rss",
          "feed_position": 48,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-11/1a5faf40-bbf7-11f0-bfcb-51aef0300038"
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2023-05/953644c0-f013-11ed-8bdf-a2cfeb7310a6",
      "popularity_score": 2019.8338544444443
    },
    {
      "id": "cluster_24",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 12:45:03 -0500",
      "title": "Google unveils Emergency Live Video, similar to iOS' Emergency SOS Live Video, letting US users on Android 8 or later to share live video with 911 responders (Stevie Bonifield/The Verge)",
      "neutral_headline": "Android users can now share a live video on 911 calls",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251210/p45#a251210p45",
          "published_at": "Wed, 10 Dec 2025 12:45:03 -0500",
          "title": "Google unveils Emergency Live Video, similar to iOS' Emergency SOS Live Video, letting US users on Android 8 or later to share live video with 911 responders (Stevie Bonifield/The Verge)",
          "standfirst": "Stevie Bonifield / The Verge: Google unveils Emergency Live Video, similar to iOS' Emergency SOS Live Video, letting US users on Android 8 or later to share live video with 911 responders &mdash; &#65279;Emergency Live Video is rolling out today on phones running Android 8 or later. &hellip; A new feature coming to Android &hellip;",
          "content": "Stevie Bonifield / The Verge: Google unveils Emergency Live Video, similar to iOS' Emergency SOS Live Video, letting US users on Android 8 or later to share live video with 911 responders &mdash; &#65279;Emergency Live Video is rolling out today on phones running Android 8 or later. &hellip; A new feature coming to Android &hellip;",
          "feed_position": 3,
          "image_url": "http://www.techmeme.com/251210/i45.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/841503/android-emergency-live-video",
          "published_at": "2025-12-10T12:01:00-05:00",
          "title": "Android users can now share a live video on 911 calls",
          "standfirst": "A new feature coming to Android will allow users to get more support during emergencies by sharing a live video feed from their phone with 911 responders. For instance, if someone calls 911 for a medical emergency, the 911 responder can use the live video feed to walk the caller through CPR or first aid [&#8230;]",
          "content": "A new feature coming to Android will allow users to get more support during emergencies by sharing a live video feed from their phone with 911 responders. For instance, if someone calls 911 for a medical emergency, the 911 responder can use the live video feed to walk the caller through CPR or first aid until paramedics arrive. Emergency Live Video is also helpful in situations where someone is lost, under high stress, or otherwise can't clearly describe what's going on. During a 911 call, emergency responders can send a request for a live video, which the caller has to approve before any video is shared. The video feed is encrypted by def … Read the full story at The Verge.",
          "feed_position": 4
        }
      ],
      "featured_image": "http://www.techmeme.com/251210/i45.jpg",
      "popularity_score": 2018.43941
    },
    {
      "id": "cluster_40",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 11:55:02 -0500",
      "title": "Amazon plans to let authors offer their DRM-free ebooks in the EPUB and PDF formats through Kindle Direct Publishing, starting January 20, 2026 (Sarah Perez/TechCrunch)",
      "neutral_headline": "Amazon changes how copyright protection is applied to...",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251210/p42#a251210p42",
          "published_at": "Wed, 10 Dec 2025 11:55:02 -0500",
          "title": "Amazon plans to let authors offer their DRM-free ebooks in the EPUB and PDF formats through Kindle Direct Publishing, starting January 20, 2026 (Sarah Perez/TechCrunch)",
          "standfirst": "Sarah Perez / TechCrunch: Amazon plans to let authors offer their DRM-free ebooks in the EPUB and PDF formats through Kindle Direct Publishing, starting January 20, 2026 &mdash; Amazon says it will allow authors to offer their DRM-free e-books in the EPUB and PDF formats through its self-publishing platform, Kindle Direct Publishing.",
          "content": "Sarah Perez / TechCrunch: Amazon plans to let authors offer their DRM-free ebooks in the EPUB and PDF formats through Kindle Direct Publishing, starting January 20, 2026 &mdash; Amazon says it will allow authors to offer their DRM-free e-books in the EPUB and PDF formats through its self-publishing platform, Kindle Direct Publishing.",
          "feed_position": 6,
          "image_url": "http://www.techmeme.com/251210/i42.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/10/amazon-changes-how-copyright-protection-is-applied-to-kindle-directs-self-published-ebooks/",
          "published_at": "Wed, 10 Dec 2025 16:26:01 +0000",
          "title": "Amazon changes how copyright protection is applied to Kindle Direct&#8217;s self-published e-books",
          "standfirst": "Amazon says it will allow authors to offer their DRM-free e-books in the EPUB and PDF formats through its self-publishing platform, Kindle Direct Publishing. Starting on January 20, 2026, authors who set their titles as DRM-free will see their books made available in these more open formats.",
          "content": "Amazon says it will allow authors to offer their DRM-free e-books in the EPUB and PDF formats through its self-publishing platform, Kindle Direct Publishing. Starting on January 20, 2026, authors who set their titles as DRM-free will see their books made available in these more open formats.",
          "feed_position": 5
        }
      ],
      "featured_image": "http://www.techmeme.com/251210/i42.jpg",
      "popularity_score": 2017.6057988888888
    },
    {
      "id": "cluster_71",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 14:45:06 +0000",
      "title": "Dr. Oz tells his federal employees to eat less during the holidays",
      "neutral_headline": "Dr. Oz tells his federal employees to eat less during the holidays",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/dr-oz-tells-his-federal-employees-to-eat-less-during-the-holidays/",
          "published_at": "Wed, 10 Dec 2025 14:45:06 +0000",
          "title": "Dr. Oz tells his federal employees to eat less during the holidays",
          "standfirst": "“You don’t have to try every cookie on the holiday table,” wrote Mehmet Oz in an email to staff.",
          "content": "Dr. Mehmet Oz, the administrator for the Centers for Medicare and Medicaid Services (CMS) and former daytime talk show star, has recently been emailing all federal workers in his agency weekly tips on “Crushing Cubicle Cravings” and how to avoid snacking in the office. “We all love a fun cookie swap and potluck this time of year. With several teams across CMS hosting holiday gatherings this month, I am sharing some strategies to help you make healthier choices—while still indulging in festive treats,” Oz wrote in his latest missive, which appears as a recurring section in his weekly bulletin titled “From the Administrator’s Desk,” according to emails viewed by WIRED. “Set your intentions,” writes Oz. “Decide in advance how many treats you’ll allow yourself to enjoy and try to stick to that number. You don’t have to try every cookie on the cookie table.”Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2188660602-1-1152x648.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/dr-oz-centers-for-medicare-and-medicaid-services-tells-employees-to-eat-less/",
          "published_at": "Mon, 08 Dec 2025 21:03:01 +0000",
          "title": "Dr. Oz Tells His Federal Employees to Eat Less",
          "standfirst": "“You don’t have to try every cookie on the holiday table,” wrote Mehmet Oz in an email to all Centers for Medicare and Medicaid Services staffers.",
          "content": "“You don’t have to try every cookie on the holiday table,” wrote Mehmet Oz in an email to all Centers for Medicare and Medicaid Services staffers.",
          "feed_position": 46,
          "image_url": "https://media.wired.com/photos/693716534326df3e510054c6/master/pass/GettyImages-1439310751.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2188660602-1-1152x648.jpg",
      "popularity_score": 2015.4402433333332
    },
    {
      "id": "cluster_73",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 14:31:32 GMT",
      "title": "This new $75 smart ring helps you remember things you'd likely forget - here's how",
      "neutral_headline": "Pebble Index: Everything You Need to Know About the $75 Smart Ring",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/pebble-index-ring-01-smart-ring-note-taker/",
          "published_at": "Wed, 10 Dec 2025 14:31:32 GMT",
          "title": "This new $75 smart ring helps you remember things you'd likely forget - here's how",
          "standfirst": "Pebble, known for its watches, has opened preorders for its new Pebble Index 01 smart ring.",
          "content": "Pebble, known for its watches, has opened preorders for its new Pebble Index 01 smart ring.",
          "feed_position": 18
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/pebble-index-ring/",
          "published_at": "Tue, 09 Dec 2025 15:00:00 +0000",
          "title": "Pebble Index: Everything You Need to Know About the $75 Smart Ring",
          "standfirst": "You can speak into the Pebble Index to have it remember things or set reminders, timers, and tasks. No cloud processing, no subscription, and best of all, no charging.",
          "content": "You can speak into the Pebble Index to have it remember things or set reminders, timers, and tasks. No cloud processing, no subscription, and best of all, no charging.",
          "feed_position": 30,
          "image_url": "https://media.wired.com/photos/693736203470dde182fcfaa3/master/pass/Pebble%20Index%20top%20art%20SOURCE%20Pebble.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/693736203470dde182fcfaa3/master/pass/Pebble%20Index%20top%20art%20SOURCE%20Pebble.jpg",
      "popularity_score": 2015.2141322222221
    },
    {
      "id": "cluster_84",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 13:30:00 +0000",
      "title": "Instagram&#8217;s new &#8216;Your Algorithm&#8217; tool gives you more control over the Reels you see",
      "neutral_headline": "Instagram Will Start Letting You Pick What Shows Up in Your Reels",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/10/instagrams-new-your-algorithm-tool-gives-you-more-control-over-the-reels-you-see/",
          "published_at": "Wed, 10 Dec 2025 13:30:00 +0000",
          "title": "Instagram&#8217;s new &#8216;Your Algorithm&#8217; tool gives you more control over the Reels you see",
          "standfirst": "You can select which topics you want to see more or less of, and your recommendations will adapt accordingly.",
          "content": "You can select which topics you want to see more or less of, and your recommendations will adapt accordingly.",
          "feed_position": 15
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/instagram-lets-you-pick-what-shows-up-in-reels/",
          "published_at": "Wed, 10 Dec 2025 13:30:00 +0000",
          "title": "Instagram Will Start Letting You Pick What Shows Up in Your Reels",
          "standfirst": "In the battle for your attention, Instagram is betting that more control over the algorithm could keep you scrolling on Reels.",
          "content": "In the battle for your attention, Instagram is betting that more control over the algorithm could keep you scrolling on Reels.",
          "feed_position": 7,
          "image_url": "https://media.wired.com/photos/6938878155a83fbf9c5eff48/master/pass/gear-meta-1238243805.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/6938878155a83fbf9c5eff48/master/pass/gear-meta-1238243805.jpg",
      "popularity_score": 2014.1885766666667
    },
    {
      "id": "cluster_22",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 18:00:19 +0000",
      "title": "Ugly infotainment mars the 2025 Subaru Forester Hybrid experience",
      "neutral_headline": "Ugly infotainment mars the 2025 Subaru Forester Hybrid experience",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/12/ugly-infotainment-mars-the-2025-subaru-forester-hybrid-experience/",
          "published_at": "Wed, 10 Dec 2025 18:00:19 +0000",
          "title": "Ugly infotainment mars the 2025 Subaru Forester Hybrid experience",
          "standfirst": "It drives fine, but the first hybrid Forester is not without its flaws.",
          "content": "Although many of us associate it with rally-derived machinery from the late 1990s and early 2000s, these days, Subaru has mostly abandoned its performance cars to concentrate on its true calling—rugged, all-wheel-drive vehicles that are high on practicality, powered by horizontally opposed “boxer” engines. One area where the brand has never particularly excelled has been fuel efficiency, which is where today’s test car, the Subaru Forester Hybrid, comes in. The last time Ars reviewed a Subaru Forester, it left us impressed. How about one with 40 percent better economy, in that case? Now, the 2.5 L flat-four engine operates on the Atkinson/Miller cycle, which generates 162 hp (121 kW) and 154 lb-ft (208 Nm). There’s an electric motor-generator starter and an electric traction motor with 118 hp (88 kW) and 199 lb-ft (270 Nm) that work together to send a combined 194 hp (145 kW) to all four wheels via a symmetrical all-wheel drive system and a planetary continuously variable transmission. The Forester Hybrid is 183.3 inches (4,656 mm) long, 70.2 inches (1,783 mm) wide, and 68.1 inches (1,729 mm) tall, with a 105.1-inch (2,670 mm) wheelbase. Credit: Jonathan Gitlin Spot the two EyeSight cameras at the top of the windscreen. Credit: Jonathan Gitlin Hatching plots. Credit: Jonathan Gitlin If that sounds vaguely familiar, that’s because it’s the same powertrain that Subaru has also fitted to the smaller Crosstrek Hybrid that we drove in September.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/2025-Subaru-Forester-Hybrid-1-of-14-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/2025-Subaru-Forester-Hybrid-1-of-14-1152x648.jpg",
      "popularity_score": 374.69385444444447
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 17:14:08 +0000",
      "title": "This is the oldest evidence of people starting fires",
      "neutral_headline": "This is the oldest evidence of people starting fires",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/this-is-the-oldest-evidence-of-people-starting-fires/",
          "published_at": "Wed, 10 Dec 2025 17:14:08 +0000",
          "title": "This is the oldest evidence of people starting fires",
          "standfirst": "We didn't start the fire. (Neanderthals did, at least 400,000 years ago.)",
          "content": "Heat-reddened clay, fire-cracked stone, and fragments of pyrite mark where Neanderthals gathered around a campfire 400,000 years ago in what’s now Suffolk, England. Based on chemical analysis of the sediment at the site, along with the telltale presence of pyrite, a mineral not naturally found nearby but very handy for striking sparks with flint, British Museum archaeologist Rob Davis and his colleagues say the Neanderthals probably started the fire themselves. That makes the abandoned English clay pit at Barnham the oldest evidence in the world that people (Neanderthal people, in this case) had learned to not only use fire, but also create it and control it. A cozy Neanderthal campfire Today, the Barnham site is part of an abandoned clay pit where workers first discovered stone tools in the early 1900s. But 400,000 years ago, it would have been a picturesque little spot at the edge of a stream-fed pond, surrounded by a mix of forest and grassland. There are no hominin fossils here, but archaeologists unearthed a Neanderthal skull about 100 kilometers to the south, so the hominins at Barnham were probably also Neanderthals. The place would have have offered a group of Neanderthals a relatively quiet, sheltered place to set up camp, according to Davis and his colleagues.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/artist-e1765349023584-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/artist-e1765349023584-1152x648.jpg",
      "popularity_score": 346.9241322222222
    },
    {
      "id": "cluster_15",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 18:30:45 +0000",
      "title": "US taking 25% cut of Nvidia chip sales “makes no sense,” experts say",
      "neutral_headline": "US taking 25% cut of Nvidia chip sales “makes no sense,” experts say",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/tech-policy/2025/12/us-taking-25-cut-of-nvidia-chip-sales-makes-no-sense-experts-say/",
          "published_at": "Wed, 10 Dec 2025 18:30:45 +0000",
          "title": "US taking 25% cut of Nvidia chip sales “makes no sense,” experts say",
          "standfirst": "Trump’s odd Nvidia reversal may open the door for China to demand Blackwell access.",
          "content": "Donald Trump’s decision to allow Nvidia to export an advanced artificial intelligence chip, the H200, to China may give China exactly what it needs to win the AI race, experts and lawmakers have warned. The H200 is about 10 times less powerful than Nvidia’s Blackwell chip, which is the tech giant’s currently most advanced chip that cannot be exported to China. But the H200 is six times more powerful than the H20, the most advanced chip available in China today. Meanwhile China’s leading AI chip maker, Huawei, is estimated to be about two years behind Nvidia’s technology. By approving the sales, Trump may unwittingly be helping Chinese chip makers “catch up” to Nvidia, Jake Sullivan told The New York Times. Sullivan, a former Biden-era national security advisor who helped design AI chip export curbs on China, told the NYT that Trump’s move was “nuts” because “China’s main problem” in the AI race “is they don’t have enough advanced computing capability.”Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2212801610-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2212801610-1024x648.jpg",
      "popularity_score": 342.20107666666667
    },
    {
      "id": "cluster_65",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 15:11:10 +0000",
      "title": "Impeachment articles filed against RFK Jr., claiming abuse of power",
      "neutral_headline": "Impeachment articles filed against RFK Jr., claiming abuse of power",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/impeachment-articles-filed-against-rfk-jr-claiming-abuse-of-power/",
          "published_at": "Wed, 10 Dec 2025 15:11:10 +0000",
          "title": "Impeachment articles filed against RFK Jr., claiming abuse of power",
          "standfirst": "He's the \"biggest self-created threat to our health and safety,\" Stevens said.",
          "content": "Rep. Haley Stevens (D-Mich.) filed articles of impeachment against Health Secretary Robert F. Kennedy Jr. Wednesday, accusing him of abusing the powers of his office and undermining public health, putting Americans’ lives at risk. He “has got to go,” Stevens said in a video announcing the impeachment articles. In an accompanying press statement, she said Kennedy, who rose to prominence as an ardent anti-vaccine activist, “has turned his back on science, on public health, and on the American people—spreading conspiracies and lies, driving up costs, and putting lives at risk.” She called him the “biggest self-created threat to our health and safety.” It is very unlikely that an impeachment push will gain traction in the Republican-controlled Congress. No other Democratic lawmakers are backing the articles.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2233690134-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2233690134-1152x648.jpg",
      "popularity_score": 333.87468777777775
    },
    {
      "id": "cluster_19",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 18:13:52 +0000",
      "title": "After key Russian launch site is damaged, NASA accelerates Dragon supply missions",
      "neutral_headline": "After key Russian launch site is damaged, NASA accelerates Dragon supply missions",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/space/2025/12/after-key-russian-launch-site-is-damaged-nasa-accelerates-dragon-supply-missions/",
          "published_at": "Wed, 10 Dec 2025 18:13:52 +0000",
          "title": "After key Russian launch site is damaged, NASA accelerates Dragon supply missions",
          "standfirst": "It is by no means certain that Russia will be able to fix Site 31 soon.",
          "content": "With a key Russian launch pad out of service, NASA is accelerating the launch of two Cargo Dragon spaceships in order to ensure that astronauts on board the International Space Station have all the supplies they need next year. According to the space agency’s internal schedule, the next Dragon supply mission, CRS-34, is moving forward one month from June 2026 to May. And the next Dragon supply mission after this, CRS-35, has been advanced three months from November to August. A source indicated that the changing schedules are a “direct result” of a launch pad incident on Thanksgiving Day at the Russian spaceport in Baikonur, Kazakhstan.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/06/51842830239_a0768f7dc5_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/06/51842830239_a0768f7dc5_k-1152x648.jpg",
      "popularity_score": 331.91968777777777
    },
    {
      "id": "cluster_39",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 16:59:15 +0000",
      "title": "Sperm donor with rare cancer mutation fathered nearly 200 children in Europe",
      "neutral_headline": "Sperm donor with rare cancer mutation fathered nearly 200 children in Europe",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/sperm-donor-with-rare-cancer-mutation-fathered-nearly-200-children-in-europe/",
          "published_at": "Wed, 10 Dec 2025 16:59:15 +0000",
          "title": "Sperm donor with rare cancer mutation fathered nearly 200 children in Europe",
          "standfirst": "Children with the mutation have up to a 90% chance of developing cancer by age 60.",
          "content": "A single sperm donor who carries a rare cancer-causing genetic mutation has fathered at least 197 children across 14 countries in Europe, according to a collaborative investigation by 14 European news groups. According to their investigative report, some of the children have already died, and many others are expected to develop deadly cancers. The man—Donor 7069, alias “Kjeld”—carries a rare mutation in the TP53 gene, which codes for a critical tumor suppressor called protein 53 or p53. This protein (which is a transcription factor) keeps cells from dividing uncontrollably, can activate DNA repair processes amid damage, and can trigger cell death when a cell is beyond repair. Many cancers are linked to mutations in p53.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2018/09/GettyImages-460716005-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2018/09/GettyImages-460716005-1152x648.jpg",
      "popularity_score": 330.6760766666667
    },
    {
      "id": "cluster_77",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 14:00:43 +0000",
      "title": "AMD’s next-gen “FSR Redstone” brings big gains, as long as you’re using a new GPU",
      "neutral_headline": "AMD’s next-gen “FSR Redstone” brings big gains, as long as you’re using a new GPU",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/amds-fsr-redstone-upscaling-claims-to-close-the-gap-with-nvidias-dlss/",
          "published_at": "Wed, 10 Dec 2025 14:00:43 +0000",
          "title": "AMD’s next-gen “FSR Redstone” brings big gains, as long as you’re using a new GPU",
          "standfirst": "\"Redstone\" is a promising mix of old and new ideas, but Nvidia is years ahead.",
          "content": "Nvidia, AMD, and Intel have all made high-quality image upscaling a cornerstone feature of their new GPUs this decade. Upscaling technologies like Nvidia’s Deep Learning Super Sampling (DLSS), AMD’s FidelityFX Super Resolution (FSR), and Intel’s Xe Super Sampling (XeSS) are all ways to transform a lower-resolution source image into a higher-resolution image, delivering better-looking games without requiring as much graphics hardware as you’d need to render the higher-resolution image natively. Later additions have focused on improving ray-tracing performance and “frame generation” technologies that boost frame rates by creating new AI-generated frames to insert between natively rendered frames. Generally speaking, Nvidia’s DLSS technologies have provided better image quality than AMD’s FSR, but they have only been available on newer Nvidia hardware—the GeForce RTX 20-series or newer for most features, with frame-generation features locked to the RTX 40- and 50-series. FSR’s results don’t look as good, but they have benefited from running on just about anything, including older GPUs, Nvidia GPUs, and even integrated Intel and AMD GPUs. Today, AMD is trying to shift that dynamic with something called “FSR Redstone,” a collection of ray-tracing and frame-generation features all intended to boost AMD’s image quality while being relatively easy to implement for game developers who are already using FSR 3.1 or FSR 4.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Screenshot-2025-12-09-at-3.43.56-PM-1152x648-1765313186.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Screenshot-2025-12-09-at-3.43.56-PM-1152x648-1765313186.jpeg",
      "popularity_score": 312.70052111111113
    },
    {
      "id": "cluster_91",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 12:32:21 +0000",
      "title": "Operation Bluebird wants to relaunch “Twitter,” says Musk abandoned the name and logo",
      "neutral_headline": "Operation Bluebird wants to relaunch “Twitter,” says Musk abandoned the name and logo",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2025/12/can-twitter-fly-again-startup-wants-to-pry-iconic-trademark-from-musks-x/",
          "published_at": "Wed, 10 Dec 2025 12:32:21 +0000",
          "title": "Operation Bluebird wants to relaunch “Twitter,” says Musk abandoned the name and logo",
          "standfirst": "“Abandonment” offers rare chance to reclaim one of tech’s most recognized brands.",
          "content": "A Virginia startup calling itself “Operation Bluebird” announced this week that it has filed a formal petition with the US Patent and Trademark Office, asking the federal agency to cancel X Corporation’s trademarks of the words “Twitter” and “tweet” since X has allegedly abandoned them. “The TWITTER and TWEET brands have been eradicated from X Corp.’s products, services, and marketing, effectively abandoning the storied brand, with no intention to resume use of the mark,” the petition states. “The TWITTER bird was grounded.” If successful, two leaders of the group tell Ars, Operation Bluebird would launch a social network under the name Twitter.new, possibly as early as late next year. (Twitter.new has created a working prototype and is already inviting users to reserve handles.)Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/03/getty-twitter-logo-1152x648-1765369763.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/03/getty-twitter-logo-1152x648-1765369763.jpg",
      "popularity_score": 286.2277433333333
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 12:30:29 +0000",
      "title": "Win hardware, collectibles, and more in the 2025 Ars Technica Charity Drive",
      "neutral_headline": "Win hardware, collectibles, and more in the 2025 Ars Technica Charity Drive",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/12/win-hardware-collectibles-and-more-in-the-2025-ars-technica-charity-drive/",
          "published_at": "Wed, 10 Dec 2025 12:30:29 +0000",
          "title": "Win hardware, collectibles, and more in the 2025 Ars Technica Charity Drive",
          "standfirst": "Help yourself to prizes by helping us raise money for good causes.",
          "content": "It’s once again that special time of year when we give you a chance to do well by doing good. That’s right—it’s the 2025 edition of our annual Charity Drive! Every year since 2007, we’ve encouraged readers to give to Penny Arcade’s Child’s Play charity, which provides toys and games to kids being treated in hospitals around the world. In recent years, we’ve added the Electronic Frontier Foundation to our charity push, aiding in their efforts to defend Internet freedom. This year, as always, we’re providing some extra incentive for those donations by offering donors a chance to win pieces of our big pile of vendor-provided swag. We can’t keep it, and we don’t want it clogging up our offices, so it’s now yours to win. This year’s swag pile is full of high-value geek goodies. We have over a dozen prizes valued at nearly $5,000 total, including gaming hardware and collectibles, apparel, and more. In 2023, Ars readers raised nearly $40,000 for charity, contributing to a total haul of more than $542,000 since 2007. We want to raise even more this year, and we can do it if readers dig deep.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/charitydrive2025-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/charitydrive2025-1152x648.jpg",
      "popularity_score": 276.1966322222222
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 21:08:11 +0000",
      "title": "Big Tech joins forces with Linux Foundation to standardize AI agents",
      "neutral_headline": "Big Tech joins forces with Linux Foundation to standardize AI agents",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/12/big-tech-joins-forces-with-linux-foundation-to-standardize-ai-agents/",
          "published_at": "Tue, 09 Dec 2025 21:08:11 +0000",
          "title": "Big Tech joins forces with Linux Foundation to standardize AI agents",
          "standfirst": "The Agentic AI Foundation launches to support MCP, AGENTS.md, and goose.",
          "content": "Big Tech has spent the past year telling us we’re living in the era of AI agents, but most of what we’ve been promised is still theoretical. As companies race to turn fantasy into reality, they’ve developed a collection of tools to guide the development of generative AI. A cadre of major players in the AI race, including Anthropic, Block, and OpenAI, has come together to promote interoperability with the newly formed Agentic AI Foundation (AAIF). This move elevates a handful of popular technologies and could make them a de facto standard for AI development going forward. The development path for agentic AI models is cloudy to say the least, but companies have invested so heavily in creating these systems that some tools have percolated to the surface. The AAIF, which is part of the nonprofit Linux Foundation, has been launched to govern the development of three key AI technologies: Model Context Protocol (MCP), goose, and AGENTS.md. MCP is probably the most well-known of the trio, having been open-sourced by Anthropic a year ago. The goal of MCP is to link AI agents to data sources in a standardized way—Anthropic (and now the AAIF) is fond of calling MCP a “USB-C port for AI.” Rather than creating custom integrations for every different database or cloud storage platform, MCP allows developers to quickly and easily connect to any MCP-compliant server.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1327016094-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1327016094-1152x648.jpg",
      "popularity_score": 258
    },
    {
      "id": "cluster_112",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 22:34:39 +0000",
      "title": "Over 250 people quarantined in South Carolina as measles outbreak rages",
      "neutral_headline": "Over 250 people quarantined in South Carolina as measles outbreak rages",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/over-250-people-quarantined-in-south-carolina-as-measles-outbreak-rages/",
          "published_at": "Tue, 09 Dec 2025 22:34:39 +0000",
          "title": "Over 250 people quarantined in South Carolina as measles outbreak rages",
          "standfirst": "16 cases are linked to a church, which followed exposures at four schools last week.",
          "content": "A measles outbreak that began in South Carolina at the start of October is showing no signs of slowing as officials on Tuesday reported 27 new cases since Friday. Those cases bring the outbreak total to 111. The southern state’s outbreak now rivals outbreaks ongoing in Utah and Arizona, which have tallied 115 and 176 cases, respectively. The outbreaks are threatening to cost the country its measles elimination status, which was earned in 2000 after vaccination efforts stopped the virus from spreading continuously. If the current transmission of the virus isn’t halted by January, the virus will have circulated for 12 consecutive months, marking it once again as an endemic disease in the US. In an update on Tuesday, South Carolina’s health department suggested the spread is far from over. Of the state’s 27 new cases, 16 were linked to exposure at a church, the Way of Truth Church in Inman. And amid the new cases, new exposures were identified at Inman Intermediate School. That’s on top of exposures announced Friday at four other schools in the region, which led to well over 100 students being quarantined.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2152300024-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2152300024-1152x648.jpg",
      "popularity_score": 253
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 17:00:28 +0000",
      "title": "Google is reviving wearable gesture controls, but only for the Pixel Watch 4",
      "neutral_headline": "Google is reviving wearable gesture controls, but only for the Pixel Watch 4",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/google-is-reviving-wearable-gesture-controls-but-only-for-the-pixel-watch-4/",
          "published_at": "Tue, 09 Dec 2025 17:00:28 +0000",
          "title": "Google is reviving wearable gesture controls, but only for the Pixel Watch 4",
          "standfirst": "Google will let you select and dismiss with a gesture, but only on the newest watch.",
          "content": "Long ago, Google’s Android-powered wearables had hands-free navigation gestures. Those fell by the wayside as Google shredded its wearable strategy over and over, but gestures are back, baby. The Pixel Watch 4 is getting an update that adds several gestures, one of which is straight out of the Apple playbook. When the update hits devices, the Pixel Watch 4 will gain a double pinch gesture like the Apple Watch has. By tapping your thumb and forefinger together, you can answer or end calls, pause timers, and more. The watch will also prompt you at times when you can use the tap gesture to control things. In previous incarnations of Google-powered watches, a quick wrist turn gesture would scroll through lists. In the new gesture system, that motion dismisses what’s on the screen. For example, you can clear a notification from the screen or dismiss an incoming call. Pixel Watch 4 owners will also enjoy this one when the update arrives.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Pixel-watch-4-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Pixel-watch-4-1-1152x648.jpg",
      "popularity_score": 151
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 17:47:01 +0000",
      "title": "Court: “Because Trump said to” may not be a legally valid defense",
      "neutral_headline": "Court: “Because Trump said to” may not be a legally valid defense",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/trumps-order-blocking-wind-development-thrown-out-by-court/",
          "published_at": "Tue, 09 Dec 2025 17:47:01 +0000",
          "title": "Court: “Because Trump said to” may not be a legally valid defense",
          "standfirst": "The \"arbitrary and capricious\" standard strikes down another administration action.",
          "content": "On Monday, US District Court Judge Patti Saris vacated a Trump executive order that brought a halt to all offshore wind power development, as well as some projects on land. That order had called for the suspension of all permitting for wind power on federal land and waters pending a review of current practices. This led states and an organization representing wind power companies to sue, claiming among other things that the suspension was arbitrary and capricious. Over 10 months since the relevant government agencies were ordered to start a re-evaluation of the permitting process, testimony revealed that they had barely begun to develop the concept of a review. As such, the only reason they could offer in defense of the suspension consisted of Trump’s executive order and a Department of the Interior memo implementing it. “Whatever level of explanation is required when deviating from longstanding agency practice,” Judge Saris wrote, “this is not it.” Lifting Trump’s suspension does not require the immediate approval of any wind projects. Instead, the relevant agencies are likely to continue following Trump’s wishes and slow-walking any leasing and licensing processes, which may force states and project owners to sue individually. But it does provide a legal backdrop for any suits that ultimately occur, one in which the government’s actions have little justification beyond Trump’s personal animosity toward wind power.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2235990625-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2235990625-1024x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_137",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 16:00:25 +0000",
      "title": "In a major new report, scientists build rationale for sending astronauts to Mars",
      "neutral_headline": "In a major new report, scientists build rationale for sending astronauts to Mars",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/in-a-major-new-report-scientists-build-rationale-for-sending-astronauts-to-mars/",
          "published_at": "Tue, 09 Dec 2025 16:00:25 +0000",
          "title": "In a major new report, scientists build rationale for sending astronauts to Mars",
          "standfirst": "\"Everyone is inspired by this because it's becoming real.\"",
          "content": "Sending astronauts to the red planet will be a decades-long activity and cost many billions of dollars. So why should NASA undertake such a bold mission? A new report published Tuesday, titled “A Science Strategy for the Human Exploration of Mars,” represents the answer from leading scientists and engineers in the United States: finding whether life exists, or once did, beyond Earth. “We’re searching for life on Mars,” said Dava Newman, a professor in the Department of Aeronautics and Astronautics at Massachusetts Institute of Technology and co-chair of the committee that wrote the report, in an interview with Ars. “The answer to the question ‘are we alone‘ is always going to be ‘maybe,’ unless it becomes yes.”Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/file-20250327-56-dflaq1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/file-20250327-56-dflaq1-1152x648.jpg",
      "popularity_score": 141
    },
    {
      "id": "cluster_122",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 18:53:21 +0000",
      "title": "Supreme Court appears likely to approve Trump’s firing of FTC Democrat",
      "neutral_headline": "Supreme Court appears likely to approve Trump’s firing of FTC Democrat",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/supreme-court-appears-likely-to-approve-trumps-firing-of-ftc-democrat/",
          "published_at": "Tue, 09 Dec 2025 18:53:21 +0000",
          "title": "Supreme Court appears likely to approve Trump’s firing of FTC Democrat",
          "standfirst": "Conservative justices seem ready to back Trump control of independent agencies.",
          "content": "The Supreme Court’s conservative justices appear ready to overturn a 90-year-old precedent that said the president cannot fire a Federal Trade Commission member without cause. A ruling for Trump would give him more power over the FTC and potentially other independent agencies such as the Federal Communications Commission. Former FTC Commissioner Rebecca Kelly Slaughter, a Democrat, sued Trump after he fired both Democrats from the commission in March. Slaughter’s case rests largely on the 1935 ruling in Humphrey’s Executor v. United States, in which the Supreme Court unanimously held that the president can only remove FTC commissioners for inefficiency, neglect of duty, or malfeasance in office. Chief Justice John Roberts said during yesterday’s oral arguments that Humphrey’s Executor is a “dried husk” despite being the “primary authority” that Slaughter’s legal team is relying on. Roberts said the court’s 2020 ruling in Seila Law made it “pretty clear… that Humphrey’s Executor is just a dried husk of whatever people used to think it was because, in the opinion itself, it described the powers of the agency it was talking about, and they’re vanishingly insignificant, have nothing to do with what the FTC looks like today.”Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/09/getty-supreme-court-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/09/getty-supreme-court-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 18:09:05 +0000",
      "title": "NASA astronauts will have their own droid when they go back to the Moon",
      "neutral_headline": "NASA astronauts will have their own droid when they go back to the Moon",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/lunar-outpost-rover-to-study-lunar-dust-alongside-artemis-astronauts-on-moon/",
          "published_at": "Tue, 09 Dec 2025 18:09:05 +0000",
          "title": "NASA astronauts will have their own droid when they go back to the Moon",
          "standfirst": "NASA crew will be the first astronauts to work with a robot on a celestial body other than Earth.",
          "content": "B-9 had Will Robinson. Twiki had Buck Rogers. And, of course, C-3PO and R2-D2 had Luke Skywalker. Now, in a scenario straight out of science fiction, MAPP will have whoever NASA names to the crew of the second Artemis mission to land on the moon. The space agency has selected Lunar Outpost’s Mobile Autonomous Prospecting Platform, or MAPP, to become the first robotic rover to operate on the moon alongside astronauts. Although its tasks will be far simpler than those of the robots seen on TV and in the movies, the autonomous four-wheeled MAPP will help scientists learn more about the crew’s surroundings. Science instruments on the rover will characterize the surface plasma and behavior of the dust in the lunar environment. “The Apollo era taught us that the further humanity is from Earth, the more dependent we are on science to protect and sustain human life on other planets,” said Nicky Fox, NASA’s associate administrator for science, in a statement. “By deploying these… science instruments on the lunar surface, our proving ground, NASA is leading the world in the creation of humanity’s interplanetary survival guide to ensure the health and safety of our spacecraft and human explorers as we begin our epic journey back to the Moon.”Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/news-120825a-lg-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/news-120825a-lg-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 16:00:29 +0000",
      "title": "Pompeii construction site confirms recipe for Roman concrete",
      "neutral_headline": "Pompeii construction site confirms recipe for Roman concrete",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/study-confirms-romans-used-hot-mixing-to-make-concrete/",
          "published_at": "Tue, 09 Dec 2025 16:00:29 +0000",
          "title": "Pompeii construction site confirms recipe for Roman concrete",
          "standfirst": "Latest results from a recently discovered ancient Roman construction site confirm earlier findings.",
          "content": "Back in 2023, we reported on MIT scientists’ conclusion that the ancient Romans employed “hot mixing” with quicklime, among other strategies, to make their famous concrete, giving the material self-healing functionality. The only snag was that this didn’t match the recipe as described in historical texts. Now the same team is back with a fresh analysis of samples collected from a recently discovered site that confirms the Romans did indeed use hot mixing, according to a new paper published in the journal Nature Communications. As we’ve reported previously, like today’s Portland cement (a basic ingredient of modern concrete), ancient Roman concrete was basically a mix of a semi-liquid mortar and aggregate. Portland cement is typically made by heating limestone and clay (as well as sandstone, ash, chalk, and iron) in a kiln. The resulting clinker is then ground into a fine powder with just a touch of added gypsum to achieve a smooth, flat surface. But the aggregate used to make Roman concrete was made up of fist-sized pieces of stone or bricks. In his treatise De architectura (circa 30 CE), the Roman architect and engineer Vitruvius wrote about how to build concrete walls for funerary structures that could endure for a long time without falling into ruin. He recommended the walls be at least two feet thick, made of either “squared red stone or of brick or lava laid in courses.” The brick or volcanic rock aggregate should be bound with mortar composed of hydrated lime and porous fragments of glass and crystals from volcanic eruptions (known as volcanic tephra).Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/concrete1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/concrete1-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_138",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 15:35:39 +0000",
      "title": "Asked why we need Golden Dome, the man in charge points to a Hollywood film",
      "neutral_headline": "Asked why we need Golden Dome, the man in charge points to a Hollywood film",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/asked-why-we-need-golden-dome-the-man-in-charge-points-to-a-hollywood-film/",
          "published_at": "Tue, 09 Dec 2025 15:35:39 +0000",
          "title": "Asked why we need Golden Dome, the man in charge points to a Hollywood film",
          "standfirst": "\"If they see how prepared we are, no one starts a nuclear war.\"",
          "content": "Near the end of the film A House of Dynamite, a fictional American president portrayed by Idris Elba sums up the theory of nuclear deterrence. “Just being ready is the point, right?” Elba says. “It keeps people in check. Keeps the world straight. If they see how prepared we are, no one starts a nuclear war.” There’s a lot that goes wrong in the film, namely the collapse of deterrence itself. For more than 60 years, the US military has used its vast arsenal of nuclear weapons, constantly deployed on Navy submarines, at Air Force bomber bases, and in Minuteman missile fields, as a way of saying, “Don’t mess with us.” In the event of a first strike against the United States, an adversary would be assured of an overwhelming nuclear response, giving rise to the concept of mutual assured destruction.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/5208709-1152x648-1765274456.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/5208709-1152x648-1765274456.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_139",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 15:00:56 +0000",
      "title": "Pebble maker announces Index 01, a smart-ish ring for under $100",
      "neutral_headline": "Pebble maker announces Index 01, a smart-ish ring for under $100",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/resurrected-pebble-maker-announces-a-kind-of-smart-ring-for-capturing-audio-notes/",
          "published_at": "Tue, 09 Dec 2025 15:00:56 +0000",
          "title": "Pebble maker announces Index 01, a smart-ish ring for under $100",
          "standfirst": "The Pebble Index 01 isn't quite a smart ring, but it can do some smart things.",
          "content": "Nearly a decade after Pebble’s nascent smartwatch empire crumbled, the brand is staging a comeback with new wearables. The Pebble Core Duo 2 and Core Time 2 are a natural evolution of the company’s low-power smartwatch designs, but its next wearable is something different. The Index 01 is a ring, but you probably shouldn’t call it a smart ring. The Index does just one thing—capture voice notes—but the firm says it does that one thing extremely well. Most of today’s smart rings offer users the ability to track health stats, along with various minor smartphone integrations. With all the sensors and data collection, these devices can cost as much as a smartwatch and require frequent charging. The Index 01 doesn’t do any of that. It contains a Bluetooth radio, a microphone, a hearing aid battery, and a physical button. You press the button, record your note, and that’s it. The company says the Index 01 will run for years on a charge and will cost just $75 during the preorder period. After that, it will go up to $99. Core Devices, the new home of Pebble, says the Index is designed to be worn on your index finger (get it?), where you can easily mash the device’s button with your thumb. Unlike recording notes with a phone or smartwatch, you don’t need both hands to create voice notes with the Index.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Index01-polished-silver-rocks-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Index01-polished-silver-rocks-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_158",
      "coverage": 1,
      "updated_at": "Mon, 08 Dec 2025 21:54:58 +0000",
      "title": "ICEBlock lawsuit: Trump admin bragged about demanding App Store removal",
      "neutral_headline": "ICEBlock lawsuit: Trump admin bragged about demanding App Store removal",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/iceblock-lawsuit-trump-admin-bragged-about-demanding-app-store-removal/",
          "published_at": "Mon, 08 Dec 2025 21:54:58 +0000",
          "title": "ICEBlock lawsuit: Trump admin bragged about demanding App Store removal",
          "standfirst": "ICEBlock creator sues to protect apps that are crowd-sourcing ICE sightings.",
          "content": "In a lawsuit filed against top Trump administration officials on Monday, Apple was accused of caving to unconstitutional government demands by removing an Immigration and Customs Enforcement-spotting app from the App Store with more than a million users. In his complaint, Joshua Aaron, creator of ICEBlock, cited a Fox News interview in which Attorney General Pam Bondi “made plain that the United States government used its regulatory power to coerce a private platform to suppress First Amendment-protected expression.” Suing Bondi—along with Department of Homeland Security Secretary Kristi Noem, Acting Director of ICE Todd Lyons, White House “Border Czar” Thomas D. Homan, and unnamed others—Aaron further alleged that US officials made false statements and “unlawful threats” to criminally investigate and prosecute him for developing ICEBlock.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2235825531-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2235825531-1024x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 16:10:45 +0000",
      "title": "Brazil weakens Amazon protections days after COP30",
      "neutral_headline": "Brazil weakens Amazon protections days after COP30",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/days-after-cop30-brazil-weakened-amazon-safeguards/",
          "published_at": "Tue, 09 Dec 2025 16:10:45 +0000",
          "title": "Brazil weakens Amazon protections days after COP30",
          "standfirst": "Backed by powerful corporations, nations are giving public false choices: Environmental protection or economic growth.",
          "content": "Despite claims of environmental leadership and promises to preserve the Amazon rainforest ahead of COP30, Brazil is stripping away protections for the region’s vital ecosystems faster than workers dismantled the tents that housed the recent global climate summit in Belém. On Nov. 27, less than a week after COP30 ended, a powerful political bloc in Brazil’s National Congress, representing agribusiness, and development interests, weakened safeguards for the Amazon’s rivers, forests, and Indigenous communities. The rollback centered on provisions in an environmental licensing bill passed by the government a few months before COP30. The law began to take shape well before, during the Jair Bolsonaro presidency from 2019 to 2023. It reflected the deregulatory agenda of the rural caucus, the Frente Parlamentar da Agropecuária, which wielded significant power during his term and remains influential today.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1249347312-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1249347312-1152x648.jpg",
      "popularity_score": 130
    }
  ]
}