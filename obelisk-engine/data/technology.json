{
  "updated_at": "2025-10-25T19:14:36.075Z",
  "clusters": [
    {
      "id": "cluster_0",
      "coverage": 2,
      "updated_at": "Sat, 25 Oct 2025 19:05:11 +0000",
      "title": "High school’s AI security system confuses Doritos bag for a possible firearm",
      "neutral_headline": "High school’s AI security system confuses Doritos bag for a possible firearm",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/25/high-schools-ai-security-system-confuses-doritos-bag-for-a-possible-firearm/",
          "published_at": "Sat, 25 Oct 2025 19:05:11 +0000",
          "title": "High school’s AI security system confuses Doritos bag for a possible firearm",
          "standfirst": "A high school student in Baltimore County, Maryland was reportedly handcuffed and searched after an AI security system flagged his bag of chips as a possible firearm.",
          "content": "A high school student in Baltimore County, Maryland was reportedly handcuffed and searched after an AI security system flagged his bag of chips as a possible firearm.",
          "feed_position": 0
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/us-news/2025/oct/24/baltimore-student-ai-gun-detection-system-doritos",
          "published_at": "Fri, 24 Oct 2025 11:47:34 GMT",
          "title": "US student handcuffed after AI system apparently mistook bag of chips for gun",
          "standfirst": "Baltimore county high schools have gun detection system that alerts police if it sees what it deems suspiciousAn artificial intelligence system (AI) apparently mistook a high school student’s bag of Doritos for a firearm and called local police to tell them the pupil was armed.Taki Allen was sitting with friends on Monday night outside Kenwood high school in Baltimore and eating a snack when police officers with guns approached him. Continue reading...",
          "content": "Baltimore county high schools have gun detection system that alerts police if it sees what it deems suspiciousAn artificial intelligence system (AI) apparently mistook a high school student’s bag of Doritos for a firearm and called local police to tell them the pupil was armed.Taki Allen was sitting with friends on Monday night outside Kenwood high school in Baltimore and eating a snack when police officers with guns approached him. Continue reading...",
          "feed_position": 6
        }
      ],
      "popularity_score": 2019.8430347222222,
      "ai_summary": [
        "A high school student was handcuffed and searched.",
        "An AI security system flagged a Doritos bag as a firearm.",
        "The incident occurred at a high school in Baltimore County.",
        "The AI system alerted police to a potential threat.",
        "The student was eating a snack when approached by police."
      ]
    },
    {
      "id": "cluster_92",
      "coverage": 2,
      "updated_at": "Fri, 24 Oct 2025 16:39:18 +0000",
      "title": "Best iPad deals: Get over $300 off the iPad Air M3 with cellular",
      "neutral_headline": "Best iPad deals: Get over $300 off the iPad Air M3 with cellular",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-ipad-deals-get-over-300-off-the-ipad-air-m3-with-cellular-150020542.html",
          "published_at": "Fri, 24 Oct 2025 16:39:18 +0000",
          "title": "Best iPad deals: Get over $300 off the iPad Air M3 with cellular",
          "standfirst": "The just-released iPad Pro with the M5 chip tops our list of the best tablets and the standard iPad is our pick for the best budget slate. While the former is expectedly not on sale yet, we are seeing a modest discount for the cheaper iPad. The lovely iPad Air (13-inch, with cellular) is down to a record low as well. Of course, you won't find deals on Apple's own website, but we keep an eye on Amazon, Target, Walmart and other retailers to find the best iPad deals out there and round them up each Friday. This week, the discounts aren't as good as they were for Prime Day earlier this month — chances are, we won't see a huge influx of Apple deals until Black Friday sales start up. Until then, here are the top deals on iPads and all the other Apple gear we could find. Best iPad deals Apple iPad (A16, 256GB) for $399 ($50 off): The latest entry-level iPad comes with a faster A16 chip, 2GB more RAM and more base storage. It earned a score of 84 in our review — if you only need a tablet for roaming the internet, watching shows and doing some lighter productivity tasks, it should do the job. With the recent iPadOS 26 update, it also has most of the same multitasking features available on the more expensive models. It does lack Apple Intelligence, but to be candid, that isn't a big loss right now. This deal isn't an all-time low for the model with 256GB of storage but it takes $50 off Apple's list price. Also at Best Buy. Apple iPad Air (11-inch, M3, 1TB) for $949 ($150 off MSRP): The most recent iPad Air is a relatively minor update, as the only major addition is a more powerful M3 chip. However, we still recommend the Air over the base model in our iPad buying guide: Its display is laminated, more color-rich and better at fending off glare (though it's still 60Hz); its speakers are more robust; it works with Apple’s best accessories and its performance should hold up better in the years ahead. This deal is only for the maxed-out model with 1TB of storage, but it ties the lowest price we've seen all the same. Best Apple deals Apple Pencil Pro for $99 ($30 off): The top-end option in Apple’s confusing stylus lineup, the Pencil Pro supports pressure sensitivity, wireless charging, tilt detection, haptic feedback and Apple’s double tap and squeeze gestures, among other perks. It’s a lovely tool for more intricate sketching and note-taking, but the catch is that it’s only compatible with the M4 iPad Pro, M2 and M3 iPad Air and most recent iPad mini. We've seen this deal fairly often over the course of the year, but it's a fine discount compared to buying from Apple directly. Also at Walmart. Apple MacBook Air (13-inch, M4, 512GB) for $999 ($200 off): Apple's latest MacBook Air is the top pick in our guide to the best laptops, and it earned a score of 92 in our review. It's not a major overhaul, but the design is still exceptionally thin, light and well-built, with long battery life and a top-notch keyboard and trackpad. Now it's a bit faster. (Though we'd still love more ports and a refresh rate higher than 60Hz.) This discount ties the all-time low for the model with 16GB of RAM and a 512GB SSD. Apple Watch Series 11 (GPS, 42mm) for $389 ($10 off): The latest flagship Apple Watch only hit store shelves last month, but Amazon is already selling it for $10 off. It doesn't show up as a percentage off, but you'll see some models listed at $389 instead of Apple's $399 MSRP. If you're new to Apple's wearables or are ready to upgrade from a Series 9 or older, this is a good model to grab. If you're coming from a Series 10, however, there's not much need to upgrade as the only major change from last year's model is a slightly larger battery and a tougher screen. Apple Watch SE 3 (GPS, 40mm) for $240 ($9 off): There's a similar stealth discount for the newest budget model, the Apple Watch SE 3, at Amazon. It normally goes for $249 — again, not a big discount, but better than nothing if you're looking to get onboard early. Apple gave this model some badly needed updates compared to its predecessor, including an always-on display, faster charging, better sensors and the same processor that you'll find in the new Apple Watch Series 11. Read more Apple coverage: The best AirPods The best Apple Watches The best MacBooks The best iPhones The best iPads Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-ipad-deals-get-over-300-off-the-ipad-air-m3-with-cellular-150020542.html?src=rss",
          "content": "The just-released iPad Pro with the M5 chip tops our list of the best tablets and the standard iPad is our pick for the best budget slate. While the former is expectedly not on sale yet, we are seeing a modest discount for the cheaper iPad. The lovely iPad Air (13-inch, with cellular) is down to a record low as well. Of course, you won't find deals on Apple's own website, but we keep an eye on Amazon, Target, Walmart and other retailers to find the best iPad deals out there and round them up each Friday. This week, the discounts aren't as good as they were for Prime Day earlier this month — chances are, we won't see a huge influx of Apple deals until Black Friday sales start up. Until then, here are the top deals on iPads and all the other Apple gear we could find. Best iPad deals Apple iPad (A16, 256GB) for $399 ($50 off): The latest entry-level iPad comes with a faster A16 chip, 2GB more RAM and more base storage. It earned a score of 84 in our review — if you only need a tablet for roaming the internet, watching shows and doing some lighter productivity tasks, it should do the job. With the recent iPadOS 26 update, it also has most of the same multitasking features available on the more expensive models. It does lack Apple Intelligence, but to be candid, that isn't a big loss right now. This deal isn't an all-time low for the model with 256GB of storage but it takes $50 off Apple's list price. Also at Best Buy. Apple iPad Air (11-inch, M3, 1TB) for $949 ($150 off MSRP): The most recent iPad Air is a relatively minor update, as the only major addition is a more powerful M3 chip. However, we still recommend the Air over the base model in our iPad buying guide: Its display is laminated, more color-rich and better at fending off glare (though it's still 60Hz); its speakers are more robust; it works with Apple’s best accessories and its performance should hold up better in the years ahead. This deal is only for the maxed-out model with 1TB of storage, but it ties the lowest price we've seen all the same. Best Apple deals Apple Pencil Pro for $99 ($30 off): The top-end option in Apple’s confusing stylus lineup, the Pencil Pro supports pressure sensitivity, wireless charging, tilt detection, haptic feedback and Apple’s double tap and squeeze gestures, among other perks. It’s a lovely tool for more intricate sketching and note-taking, but the catch is that it’s only compatible with the M4 iPad Pro, M2 and M3 iPad Air and most recent iPad mini. We've seen this deal fairly often over the course of the year, but it's a fine discount compared to buying from Apple directly. Also at Walmart. Apple MacBook Air (13-inch, M4, 512GB) for $999 ($200 off): Apple's latest MacBook Air is the top pick in our guide to the best laptops, and it earned a score of 92 in our review. It's not a major overhaul, but the design is still exceptionally thin, light and well-built, with long battery life and a top-notch keyboard and trackpad. Now it's a bit faster. (Though we'd still love more ports and a refresh rate higher than 60Hz.) This discount ties the all-time low for the model with 16GB of RAM and a 512GB SSD. Apple Watch Series 11 (GPS, 42mm) for $389 ($10 off): The latest flagship Apple Watch only hit store shelves last month, but Amazon is already selling it for $10 off. It doesn't show up as a percentage off, but you'll see some models listed at $389 instead of Apple's $399 MSRP. If you're new to Apple's wearables or are ready to upgrade from a Series 9 or older, this is a good model to grab. If you're coming from a Series 10, however, there's not much need to upgrade as the only major change from last year's model is a slightly larger battery and a tougher screen. Apple Watch SE 3 (GPS, 40mm) for $240 ($9 off): There's a similar stealth discount for the newest budget model, the Apple Watch SE 3, at Amazon. It normally goes for $249 — again, not a big discount, but better than nothing if you're looking to get onboard early. Apple gave this model some badly needed updates compared to its predecessor, including an always-on display, faster charging, better sensors and the same processor that you'll find in the new Apple Watch Series 11. Read more Apple coverage: The best AirPods The best Apple Watches The best MacBooks The best iPhones The best iPads Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-ipad-deals-get-over-300-off-the-ipad-air-m3-with-cellular-150020542.html?src=rss",
          "feed_position": 13
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/sennheiser-hdb-630-review-a-sonic-marvel-with-room-for-improvement-150000295.html",
          "published_at": "Fri, 24 Oct 2025 15:00:00 +0000",
          "title": "Sennheiser HDB 630 review: A sonic marvel with room for improvement",
          "standfirst": "High-resolution audio on the go isn’t very convenient. It typically involves wired headphones and a DAC (digital-to-analog converter) of some kind, plus your phone or another device to access files or a streaming service. All of this is necessary since Bluetooth compresses an audio signal by design, to allow for low-latency transmission and minimize battery draw. Simply put, wireless headphones haven’t been able to meet the demands of lossless audio, but Sennheiser has come the closest to fulfilling the dream with its HDB 630 ($500). Thanks to redesigned drivers, a new acoustic platform and a dongle, the company offers up to 24-bit/96kHz audio on the HDB 630 — depending on your configuration. You also get above average active noise cancellation (ANC), a highly customizable EQ, shockingly long battery life and advanced features to fine-tune the headphones to your liking. For some, the best possible sound is still only found on pricey setups and open-back headphones. For everyone else, Sennheiser has provided a taste of the audiophile life in a much more portable package. Design Sennheiser says the HDB 630 “inherited” the same chassis from its Momentum 4 headphones. That’s unfortunate because my biggest complaint with that older model's redesign is how cheap it looked compared to previous entries in the Momentum line. The HDB 630 suffers the same fate, although the splash of silver on the headband and yokes helps things a bit. Simply put, these don’t look like a set of $500 headphones, and since they’re $150 more than their predecessor was at launch, they really should have a more premium appearance. The outside of the right ear cup is still a touch panel where you can swipe, tap and even pinch to control the HDB 630. I don’t recall another set of headphones with a pinch gesture, and I’m still not convinced it’s warranted. The action is used to enable an Adaptive ANC adjustment that allows you to dial in the amount of noise blocking you need. After the pinch, sliding a single finger forwards and backwards fine tunes the mix of ANC and transparency mode. It’s a nice option to have on the headphones themselves, I just think a triple tap to activate it would be easier to master — and remember. The only other button on the HDB 630 is for power and Bluetooth pairing. Unless you’re frequently connecting these headphones to a new device, you might not be reaching for this control very often. That’s because the HDB 630 goes into standby mode when you take them off before powering down completely after 15 minutes of inactivity. You can extend that window to 30 or 60 minutes if you prefer. And if the headphones still have battery left, you can return to active mode by simply putting them back on your head. Sennheiser is betting you’ll use the HDB 630 for long listening sessions, so it outfitted these headphones with soft ear pads and a well-cushioned headband. The clamping force is adequate for a proper ANC seal, but never becomes a burden. And despite being around 20 grams heavier than the Momentum 4, this model still feels balanced and doesn’t weigh you down. Sound quality The HDB 630 features new drivers and a specially designed acoustic system. Billy Steele for Engadget While the overall design may be familiar, the sound platform for the HDB 630 is completely new. 42mm drivers offer what Sennheiser says is “neutral sound with lifelike mids, stunning detail and a wide soundstage.” In order to deliver sound quality that’s as close to open-back headphones as possible, the company overhauled the entire acoustic system, from the drivers to the baffle’s transparent mesh, in the name of balance and clarity. And since audiophile headphones typically require a dedicated external amplifier to achieve their full potential, Sennheiser included a BTD 700 USB-C dongle for high-resolution wireless audio transmission. When I first put the HDB 630 on, I thought the audio quality was good but not great. Listening over the standard definition SBC codec produced decent results, but it wasn’t anything to write home about. Once I connected to the BTD 700 dongle and unlocked 16-bit/48kHz tunes from Apple Music, though, these headphones really started to impress. As good as they are, the HDB 630 may not be for everyone. That “neutral” stock tuning places high emphasis on the midrange, so you’ll likely need to make some adjustments to get the bass performance you crave from rock, electronic, hip-hop and other genres driven by low-end tone. While I concede the neutral base is a great starting point, and the HDB 630 does indeed showcase “stunning detail,” I’d argue Sennheiser’s promise of “a wide soundstage” doesn’t always hold true. These headphones are at their best with more immersive content, like the TRON: Ares soundtrack from Nine Inch Nails. After a slight adjustment, the electronic score had the booming bass it needed, offering driving beats that nearly rattled my brain. All that was layered with rich synths and Trent Reznor’s iconic vocals. The texture and distortion in the instruments came through in greater detail too, something that’s not as apparent on other headphones and earbuds. Switch over to Thrice’s Horizons/West and the HDB 630 is a different story. Transitioning from synth-heavy electronic music to a genre like rock causes these headphones to lose some of the immersive character they are capable of delivering. You still get absurd clarity and detail, particularly in Teppei Teranishi’s guitar riffs, but the music sounds slightly flatter and a little less energetic. It’s not bad by any means, but some genres won’t envelope you as much as others do. You can also use the HDB 630 wired over USB-C for lossless-quality audio. Since a number of competitors also do this, I dedicated the bulk of my testing to see if Sennheiser’s wireless dongle is meaningfully different. Of course, I did my due diligence and tested the wired configuration a few times, and it should come as no surprise that the HDB 630 sounds just as good in that setup. Software, features and accessories There's only one button on the HDB 630. Billy Steele for Engadget As I mentioned, the HDB 630 comes with Sennheiser’s BTD 700 Bluetooth USB dongle. This enables higher quality streaming than you’ll natively get from most devices. With the BTD 700, you can expect aptX Adaptive and aptX Lossless listening up at rates to 24-bit/96kHz. The dongle also has a 30ms low-latency gaming mode, (supposedly) enhanced call performance and Auracast support for streaming to multiple headphones or speakers. The BTD 700 has a USB-C connector, but it comes with a USB-A adapter if you need it. This typically costs $60 if you buy it on its own, and since you need it to unlock the HDB 630’s full potential, it’s great to see it included in the box. The HDB 630’s settings and features are accessible in the Sennheiser Smart Control Plus app. And for this model, the company is offering a lot more customization than it does on the Accentum or Momentum headphones. First, the EQ editing options are more robust thanks to a parametric equalizer, which allows you to get a lot more detailed with your custom presets. For example, I was able to add the low-end tone I feel is missing from the stock tuning for those metal, rock and hip-hop tracks I mentioned before. And unlike a lot of headphone apps, adjusting the EQ actually improves the sound instead of just muddying things further. Another sound-related addition for the HDB 630 is Crossfeed. This allows you to blend the left and right channels so that it seems like you’re listening to speakers instead of headphones. Unfortunately, you only get two options here — Low and High — but the effect certainly enhances the sonic profile of the HDB 630 at both settings. Despite the BTD 700 dongle’s Mac and Windows compatibility, there’s no desktop version of the Smart Control Plus app. This means you’ll have to change all of your settings with the HDB 630 through your phone before you pair it with both the dongle and your computer. It would be nice if you could make EQ adjustments, create new presets and even change Crossfeed levels without having to reconnect to another device. This also means you can’t be connected to the BTD 700 and both your phone and your computer, since the dongle takes one of the two available multipoint Bluetooth slots. Active noise cancellation and call quality The HDB 630 has a very basic design with lots of plastic. Billy Steele for Engadget When it comes to ANC performance, I’m not entirely sure that the HDB 630 is better than the Momentum 4. But that’s okay. That previous model brought a significant improvement compared to Sennheiser’s older wireless headphones and the ANC is still quite good here. In fact, it was robust enough to block my family’s voices during their calls while I worked from home, and since most headphones struggle with this, that’s no mean feat. Sennheiser says the BTD 700 dongle will give you improved voice performance over the headphones alone. Specifically, the accessory should provide extended range, clearer voice pickup and, according to the company, “uninterrupted” calls. In my recorded samples, I think the headphones themselves sounded slightly better than when I captured my voice while connected to the BTD 700. However, I noticed a distinct lack of background noise in both clips, which is helpful in busier environments. I’ll also note the overall voice quality isn’t pristine, but it’s clear enough to use for work calls — even if you’re the main presenter. Battery life Sennheiser promises that you’ll get up to 60 hours of battery life on a charge with the HDB 630. That’s the same staggering figure the company claims on the Momentum 4. And yes, that’s with ANC enabled, but you’ll only achieve that if you’re listening to standard resolution tunes. Based on my testing with a mix of noise cancellation and transparency mode while I was listening to music and taking work calls, I have no reason to believe the company’s numbers don’t hold true. If you choose to listen entirely via the BTD 700’s higher quality output, you can expect up to 45 hours of use on a charge. That’s still quite a long time considering a lot of the competition runs out at around 30 hours — and that’s without high-res music. Due to all of the signal processing that helps with the acoustic performance on the HDB 630, they can only be used when they’re turned on. Unlike some wireless models, you can’t use these as wired headphones when the battery is spent. However, if you find yourself with a completely depleted battery, a 10-minute charge will give you up to seven hours of use. The company doesn’t specify streaming resolution for that number, but I assume it’s at standard definition. Still, you’ll get a few hours of higher-res music in that time, which should be enough to get you through a work session, evening commute or that new album you’re dying to play for the first time. The competition Incredible sound awaits, if you're okay to carry a dongle around with your headphones. Billy Steele for Engadget In the realm of flagship headphones, any company’s top-of-the-line model will set you back $500 these days. I look back fondly on the time when $300-$350 got you the best Sony had to offer. While the HDB 630 is expensive, it’s also in the same ballpark of what you’ll pay for the Bose QuietComfort Ultra Headphones ($450), the Sony WH-1000XM6 ($458 currently) and the AirPods Max ($549). Each of those have their advantages over the rest of the competition, with the 1000XM6 offering the most complete package overall. However, when it comes to pure sound quality, neither of those three are at the top of the heap. Up until now, that title belonged to the Noble Audio FoKus Apollo. At $650, those headphones are even more expensive than the HDB 630, but their stock tuning will appeal to more listeners and the soundstage is wider and more immersive. There’s also Bowers & Wilkins’ Px7 S3 for a slightly cheaper $479. It delivers the company’s warm, inviting sound and attention to finer details. After spending time with the HDB 630 though, these alternatives are just that — alternatives — as the new Sennheiser headphones are now my pick for best overall sound quality. Wrap-up I get it: in the current financial climate, $500 is a lot to pay for headphones (or anything else, for that matter). You can find a number of perfectly capable sets of ANC headphones for much less given how frequently things go on sale these days. However, what you won’t find is an option that gives you anything close to the performance of audiophile-grade, open-back headphones. That’s really what Sennheiser is doing here, and the HDB 630 slots nicely into the company’s HD 600 series of high-end cans. As good as the HDB 630 is sound-wise, I can also appreciate that these aren’t the best headphones for everyone. The company’s Momentum 4 is still a very capable set of headphones and it’s now available for about $250. If you crave the best sound quality that still offers the convenience of wireless headphones — and you’re okay with a few extra steps — the HDB 630 is a worthy investment. Just don’t leave home without that dongle.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sennheiser-hdb-630-review-a-sonic-marvel-with-room-for-improvement-150000295.html?src=rss",
          "content": "High-resolution audio on the go isn’t very convenient. It typically involves wired headphones and a DAC (digital-to-analog converter) of some kind, plus your phone or another device to access files or a streaming service. All of this is necessary since Bluetooth compresses an audio signal by design, to allow for low-latency transmission and minimize battery draw. Simply put, wireless headphones haven’t been able to meet the demands of lossless audio, but Sennheiser has come the closest to fulfilling the dream with its HDB 630 ($500). Thanks to redesigned drivers, a new acoustic platform and a dongle, the company offers up to 24-bit/96kHz audio on the HDB 630 — depending on your configuration. You also get above average active noise cancellation (ANC), a highly customizable EQ, shockingly long battery life and advanced features to fine-tune the headphones to your liking. For some, the best possible sound is still only found on pricey setups and open-back headphones. For everyone else, Sennheiser has provided a taste of the audiophile life in a much more portable package. Design Sennheiser says the HDB 630 “inherited” the same chassis from its Momentum 4 headphones. That’s unfortunate because my biggest complaint with that older model's redesign is how cheap it looked compared to previous entries in the Momentum line. The HDB 630 suffers the same fate, although the splash of silver on the headband and yokes helps things a bit. Simply put, these don’t look like a set of $500 headphones, and since they’re $150 more than their predecessor was at launch, they really should have a more premium appearance. The outside of the right ear cup is still a touch panel where you can swipe, tap and even pinch to control the HDB 630. I don’t recall another set of headphones with a pinch gesture, and I’m still not convinced it’s warranted. The action is used to enable an Adaptive ANC adjustment that allows you to dial in the amount of noise blocking you need. After the pinch, sliding a single finger forwards and backwards fine tunes the mix of ANC and transparency mode. It’s a nice option to have on the headphones themselves, I just think a triple tap to activate it would be easier to master — and remember. The only other button on the HDB 630 is for power and Bluetooth pairing. Unless you’re frequently connecting these headphones to a new device, you might not be reaching for this control very often. That’s because the HDB 630 goes into standby mode when you take them off before powering down completely after 15 minutes of inactivity. You can extend that window to 30 or 60 minutes if you prefer. And if the headphones still have battery left, you can return to active mode by simply putting them back on your head. Sennheiser is betting you’ll use the HDB 630 for long listening sessions, so it outfitted these headphones with soft ear pads and a well-cushioned headband. The clamping force is adequate for a proper ANC seal, but never becomes a burden. And despite being around 20 grams heavier than the Momentum 4, this model still feels balanced and doesn’t weigh you down. Sound quality The HDB 630 features new drivers and a specially designed acoustic system. Billy Steele for Engadget While the overall design may be familiar, the sound platform for the HDB 630 is completely new. 42mm drivers offer what Sennheiser says is “neutral sound with lifelike mids, stunning detail and a wide soundstage.” In order to deliver sound quality that’s as close to open-back headphones as possible, the company overhauled the entire acoustic system, from the drivers to the baffle’s transparent mesh, in the name of balance and clarity. And since audiophile headphones typically require a dedicated external amplifier to achieve their full potential, Sennheiser included a BTD 700 USB-C dongle for high-resolution wireless audio transmission. When I first put the HDB 630 on, I thought the audio quality was good but not great. Listening over the standard definition SBC codec produced decent results, but it wasn’t anything to write home about. Once I connected to the BTD 700 dongle and unlocked 16-bit/48kHz tunes from Apple Music, though, these headphones really started to impress. As good as they are, the HDB 630 may not be for everyone. That “neutral” stock tuning places high emphasis on the midrange, so you’ll likely need to make some adjustments to get the bass performance you crave from rock, electronic, hip-hop and other genres driven by low-end tone. While I concede the neutral base is a great starting point, and the HDB 630 does indeed showcase “stunning detail,” I’d argue Sennheiser’s promise of “a wide soundstage” doesn’t always hold true. These headphones are at their best with more immersive content, like the TRON: Ares soundtrack from Nine Inch Nails. After a slight adjustment, the electronic score had the booming bass it needed, offering driving beats that nearly rattled my brain. All that was layered with rich synths and Trent Reznor’s iconic vocals. The texture and distortion in the instruments came through in greater detail too, something that’s not as apparent on other headphones and earbuds. Switch over to Thrice’s Horizons/West and the HDB 630 is a different story. Transitioning from synth-heavy electronic music to a genre like rock causes these headphones to lose some of the immersive character they are capable of delivering. You still get absurd clarity and detail, particularly in Teppei Teranishi’s guitar riffs, but the music sounds slightly flatter and a little less energetic. It’s not bad by any means, but some genres won’t envelope you as much as others do. You can also use the HDB 630 wired over USB-C for lossless-quality audio. Since a number of competitors also do this, I dedicated the bulk of my testing to see if Sennheiser’s wireless dongle is meaningfully different. Of course, I did my due diligence and tested the wired configuration a few times, and it should come as no surprise that the HDB 630 sounds just as good in that setup. Software, features and accessories There's only one button on the HDB 630. Billy Steele for Engadget As I mentioned, the HDB 630 comes with Sennheiser’s BTD 700 Bluetooth USB dongle. This enables higher quality streaming than you’ll natively get from most devices. With the BTD 700, you can expect aptX Adaptive and aptX Lossless listening up at rates to 24-bit/96kHz. The dongle also has a 30ms low-latency gaming mode, (supposedly) enhanced call performance and Auracast support for streaming to multiple headphones or speakers. The BTD 700 has a USB-C connector, but it comes with a USB-A adapter if you need it. This typically costs $60 if you buy it on its own, and since you need it to unlock the HDB 630’s full potential, it’s great to see it included in the box. The HDB 630’s settings and features are accessible in the Sennheiser Smart Control Plus app. And for this model, the company is offering a lot more customization than it does on the Accentum or Momentum headphones. First, the EQ editing options are more robust thanks to a parametric equalizer, which allows you to get a lot more detailed with your custom presets. For example, I was able to add the low-end tone I feel is missing from the stock tuning for those metal, rock and hip-hop tracks I mentioned before. And unlike a lot of headphone apps, adjusting the EQ actually improves the sound instead of just muddying things further. Another sound-related addition for the HDB 630 is Crossfeed. This allows you to blend the left and right channels so that it seems like you’re listening to speakers instead of headphones. Unfortunately, you only get two options here — Low and High — but the effect certainly enhances the sonic profile of the HDB 630 at both settings. Despite the BTD 700 dongle’s Mac and Windows compatibility, there’s no desktop version of the Smart Control Plus app. This means you’ll have to change all of your settings with the HDB 630 through your phone before you pair it with both the dongle and your computer. It would be nice if you could make EQ adjustments, create new presets and even change Crossfeed levels without having to reconnect to another device. This also means you can’t be connected to the BTD 700 and both your phone and your computer, since the dongle takes one of the two available multipoint Bluetooth slots. Active noise cancellation and call quality The HDB 630 has a very basic design with lots of plastic. Billy Steele for Engadget When it comes to ANC performance, I’m not entirely sure that the HDB 630 is better than the Momentum 4. But that’s okay. That previous model brought a significant improvement compared to Sennheiser’s older wireless headphones and the ANC is still quite good here. In fact, it was robust enough to block my family’s voices during their calls while I worked from home, and since most headphones struggle with this, that’s no mean feat. Sennheiser says the BTD 700 dongle will give you improved voice performance over the headphones alone. Specifically, the accessory should provide extended range, clearer voice pickup and, according to the company, “uninterrupted” calls. In my recorded samples, I think the headphones themselves sounded slightly better than when I captured my voice while connected to the BTD 700. However, I noticed a distinct lack of background noise in both clips, which is helpful in busier environments. I’ll also note the overall voice quality isn’t pristine, but it’s clear enough to use for work calls — even if you’re the main presenter. Battery life Sennheiser promises that you’ll get up to 60 hours of battery life on a charge with the HDB 630. That’s the same staggering figure the company claims on the Momentum 4. And yes, that’s with ANC enabled, but you’ll only achieve that if you’re listening to standard resolution tunes. Based on my testing with a mix of noise cancellation and transparency mode while I was listening to music and taking work calls, I have no reason to believe the company’s numbers don’t hold true. If you choose to listen entirely via the BTD 700’s higher quality output, you can expect up to 45 hours of use on a charge. That’s still quite a long time considering a lot of the competition runs out at around 30 hours — and that’s without high-res music. Due to all of the signal processing that helps with the acoustic performance on the HDB 630, they can only be used when they’re turned on. Unlike some wireless models, you can’t use these as wired headphones when the battery is spent. However, if you find yourself with a completely depleted battery, a 10-minute charge will give you up to seven hours of use. The company doesn’t specify streaming resolution for that number, but I assume it’s at standard definition. Still, you’ll get a few hours of higher-res music in that time, which should be enough to get you through a work session, evening commute or that new album you’re dying to play for the first time. The competition Incredible sound awaits, if you're okay to carry a dongle around with your headphones. Billy Steele for Engadget In the realm of flagship headphones, any company’s top-of-the-line model will set you back $500 these days. I look back fondly on the time when $300-$350 got you the best Sony had to offer. While the HDB 630 is expensive, it’s also in the same ballpark of what you’ll pay for the Bose QuietComfort Ultra Headphones ($450), the Sony WH-1000XM6 ($458 currently) and the AirPods Max ($549). Each of those have their advantages over the rest of the competition, with the 1000XM6 offering the most complete package overall. However, when it comes to pure sound quality, neither of those three are at the top of the heap. Up until now, that title belonged to the Noble Audio FoKus Apollo. At $650, those headphones are even more expensive than the HDB 630, but their stock tuning will appeal to more listeners and the soundstage is wider and more immersive. There’s also Bowers & Wilkins’ Px7 S3 for a slightly cheaper $479. It delivers the company’s warm, inviting sound and attention to finer details. After spending time with the HDB 630 though, these alternatives are just that — alternatives — as the new Sennheiser headphones are now my pick for best overall sound quality. Wrap-up I get it: in the current financial climate, $500 is a lot to pay for headphones (or anything else, for that matter). You can find a number of perfectly capable sets of ANC headphones for much less given how frequently things go on sale these days. However, what you won’t find is an option that gives you anything close to the performance of audiophile-grade, open-back headphones. That’s really what Sennheiser is doing here, and the HDB 630 slots nicely into the company’s HD 600 series of high-end cans. As good as the HDB 630 is sound-wise, I can also appreciate that these aren’t the best headphones for everyone. The company’s Momentum 4 is still a very capable set of headphones and it’s now available for about $250. If you crave the best sound quality that still offers the convenience of wireless headphones — and you’re okay with a few extra steps — the HDB 630 is a worthy investment. Just don’t leave home without that dongle.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sennheiser-hdb-630-review-a-sonic-marvel-with-room-for-improvement-150000295.html?src=rss",
          "feed_position": 19,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/DSC_5509.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/openais-recent-chip-deals-heap-more-pressure-on-tsmc-130000194.html",
          "published_at": "Fri, 24 Oct 2025 13:00:00 +0000",
          "title": "OpenAI's recent chip deals heap more pressure on TSMC",
          "standfirst": "In recent weeks, OpenAI has signed blockbuster deals with AMD and Broadcom to build vast numbers of AI chips. Much of the focus has been on the financial implications, since OpenAI will need hundreds of billions of dollars to make good on its promises. As important as it is to look at the quite implausible financials, we also need to look at the broader implications for the industry. Like, the chips themselves, what that spells for the AI industry as a whole, and the added pressure on TSMC, the only chip company that can actually build this stuff.The DealsOpenAI’s deal with AMD will see the chip giant build out 6 gigawatts’ (GW) worth of GPUs in the next few years. The first 1 GW deployment of AMD’s Instinct MI450 silicon will start in the back end of 2026, with more to come. AMD’s CFO Jean Hu believes that the partnership will deliver “tens of billions of dollars in revenue” in future, justifying the complicated way the deal is funded.Meanwhile, Broadcom’s deal with OpenAI will see the pair collaborate on building 10 gigawatts’ worth of AI accelerators and ethernet systems that it has designed. The latter will be crucial to speed up connections between each individual system in OpenAI’s planned data centers. Like the deal with AMD, the first deployments of these systems will begin in the back half of 2026 and is set to run through 2029.Phil Burr is head of product at Lumai, a British company looking to replace traditional GPUs with optical processors. He’s got 30 years experience in the chip world, including a stint as a senior director at ARM. Burr explained the nitty-gritty of OpenAI’s deals with both Broadcom and AMD, and what both mean for the wider world. Burr first poured water on OpenAI’s claim that it would be “designing” the gear produced by Broadcom. “Broadcom has a wide portfolio of IP blocks and pre-designed parts of a chip,” he said, “it will put those together according to the specification of the customer.” He went on to say that Broadcom will essentially put together a series of blocks it has already designed to suit the specification laid down by a customer, in this case OpenAI.Similarly, the AI accelerators Broadcom will build are geared toward more efficient running of models OpenAI has already trained and built — a process called inference in AI circles. “It can tailor the workload and reduce power, or increase performance,” said Burr, but these benefits would only work in OpenAI's favor, rather than for the wider AI industry.I asked Burr why every company in the AI space talks about gigawatts worth of chips rather than in more simple numbers. He explained that, often, it’s because both parties don’t yet know how many chips would be required to meet those lofty goals. But you could make a reasonable guess if you knew the power draw of a specific chip divided by the overall goal, then cut that number in half, then remove an extra 10 percent. “For every watt of power you burn in the chip, you need about a watt of power to cool it as well.” In terms of what OpenAI gets from these deals, Burr believes that the startup will save money on chips, since there’s “less margin” from making your own versus buying gear from NVIDIA. Plus, being able to produce custom silicon to tailor the work to their needs should see significant speed and performance gains on rival systems. Of course, the next biggest benefit is that OpenAI now has “diversity in supply,” rather than being reliant on one provider for all its needs. “Nobody wants a single supplier,” said Burr. The FactoryExcept, of course, OpenAI may be sourcing chips from a variety of its partners, but no matter what’s stamped on the silicon, it all comes from the same place. “I’d be very surprised if it wasn’t TSMC,” said Burr, “I’m pretty sure all of the AI chips out there use TSMC.” TSMC is short for Taiwan Semiconductor Manufacturing Company which, over the last decade, has blown past its major rivals to become the biggest (and in many cases only) source of bleeding-edge chips for the whole technology industry. Unlike historic rivals, which designed and manufactured their own hardware, TSMC is a pure play foundry, only building chips designed by others. Interior at one of TSMC's FabsTaiwan Semiconductor Manufacturing Co. Ltd.Gil Luria is Managing Director at head of technology research at investment firm DA Davidson. He said that TSMC isn’t just a bottleneck for the western technology industry, but in fact is the \"greatest single point of failure for the entire global economy.” Luria credits the company with an impressive expansion “considering it has had to ramp the production of GPUs tenfold over the last three years.” But said that, “in a catastrophic scenario where TSMC is not able to produce in Taiwan, the disruption would be significant.” And that won’t just affect the AI world, but “mobile handset sales as well as global car sales.” TSMC supplanted Intel for a number of well-documented reasons, but the most relevant here is its embrace of Extreme Ultraviolet Lithography (EUV). It’s a technology that Intel had initially backed, but struggled to fully adopt, allowing TSMC to pick it up and run straight to the top. EUV produces the headline-grabbing chips used by pretty much everyone in the consumer electronics world. Apple, Qualcomm, NVIDIA, AMD (including the SOCs inside the PS5 and Xbox) all use TSMC chips. Even Intel has been using TSMC foundries for some consumer CPUs as it races to bridge to gulf in manufacturing between the two companies.“TSMC is the current leader in advanced 3 nanometer (nm) process technologies,” said University of Pennsylvania Professor Benjamin C. Lee. The company’s only meaningful competitors are Intel and Samsung, neither of which pose a threat to its dominance at present. “Intel has been working for a very long time to build a foundry business,” he explained, “but has yet to perfect its interface.” Samsung is in a similar situation, but Professor Lee explained it “has been unable to attract enough customers to generate a profitable manufacturing business.” Professor Lee said that TSMC, by comparison, has become so successful because of how good its chips are, and how easy it is for clients to build chips with its tools. “TSMC fabricates chips with high yield, which is to say more of its chips emerge from the fabrication process at expected performance and reliability.” Consequently, it should be no surprise that TSMC is a money making machine. In the second quarter of 2025 alone it reported a net profit of $12.8 billion USD. And in the following three months, TSMC posted net profits of $14.76 billion. “TSMC’s secret sauce is its mastery of yield,” explained ARPU Intelligence, an analyst group that prefers to use the group name over individual attribution. “This expertise is the result of decades of accumulated process refinement [and] a deep institutional knowledge that cannot be replicated.” This deep institutional knowledge and ability to deliver high quality product creates a “powerful technical lock-in, since companies like Apple and NVIDIA design their chips specifically for TSMC’s unique manufacturing process … It’s not as simple as sending the [chip] design to another factory,” it added.The downside, at least for the wider technology industry, is that TSMC is now a bottleneck that the whole industry has come to rely upon. In the company’s most recent financials, it said more than three quarters of its business comes from North American customers. And in a call with investors, Chairman and CEO C.C. Wei talked about the efforts the company has made to narrow the gap between the enormous demand and its constrained supply. While he was reticent to be specific, he did say that the company’s capacity is “very tight,” and would likely remain that way for the foreseeable future. In fact, TSMC’s capacity is so tight that it’s already caused at least one major name a significant headache. Earlier this year, Reuters reported that NVIDIA canceled an order of its H20 AI chips after being informed the US would not permit them to be exported to China. Once the ban was lifted, however, NVIDIA was unable to find space in TSMC’s schedule, with the next available slot at least nine months later.“TSMC has no room for error,” said ARPU Intelligence, “any minor disruption can halt production with no spare capacity to absorb the shock.” It cited the Hualien earthquake which struck Taiwan on April 3, 2024, and how it negatively impacted the number of wafers in production.Naturally, TSMC is spending big to increase its production capacity for its customers, both in Taiwan and the US. Close to its home, construction on its A14 fab is expected to begin in the very near future, with the first chips due to be produced in 2028. That facility will harness TSMC’s A14 process node, producing 1.4 nm chips, which offer a speed boost over the 2nm silicon that's expected to arrive in consumer devices next year.Image of TSMC's Arizona CampusTaiwan Semiconductor Manufacturing Co. Ltd.Meanwhile, work continues apace on building out TSMC’s sprawling facility in Arizona, which broke ground in April 2021. As Reuters reported at the time, the first facility started operating in early 2025, producing 4 nm chips. Last week, NVIDIA and TSMC showed off the first Blackwell wafer produced at the Arizona plant ahead of domestic volume production.Plans for the operation have grown over time, expanding from three facilities up to six to be built over the next decade. And while the initial outline called for the US facilities to remain several process generations behind Taiwan, that is also changing. In his recent investors call, Chairman and CEO C.C. Wei pledged to invest more in the US facility to bring it only one generation behind the Taiwanese facility. No amount of investment from TSMC or catch-up from rivals like Samsung and Intel will solve the current bottleneck swiftly. It will take many years, if not decades, for the world to reduce its reliance on Taiwan for bleeding-edge manufacturing. TSMC's island remains the industry's weak point, and should something go wrong, the consequences could be dire indeed.This article originally appeared on Engadget at https://www.engadget.com/computing/openais-recent-chip-deals-heap-more-pressure-on-tsmc-130000194.html?src=rss",
          "content": "In recent weeks, OpenAI has signed blockbuster deals with AMD and Broadcom to build vast numbers of AI chips. Much of the focus has been on the financial implications, since OpenAI will need hundreds of billions of dollars to make good on its promises. As important as it is to look at the quite implausible financials, we also need to look at the broader implications for the industry. Like, the chips themselves, what that spells for the AI industry as a whole, and the added pressure on TSMC, the only chip company that can actually build this stuff.The DealsOpenAI’s deal with AMD will see the chip giant build out 6 gigawatts’ (GW) worth of GPUs in the next few years. The first 1 GW deployment of AMD’s Instinct MI450 silicon will start in the back end of 2026, with more to come. AMD’s CFO Jean Hu believes that the partnership will deliver “tens of billions of dollars in revenue” in future, justifying the complicated way the deal is funded.Meanwhile, Broadcom’s deal with OpenAI will see the pair collaborate on building 10 gigawatts’ worth of AI accelerators and ethernet systems that it has designed. The latter will be crucial to speed up connections between each individual system in OpenAI’s planned data centers. Like the deal with AMD, the first deployments of these systems will begin in the back half of 2026 and is set to run through 2029.Phil Burr is head of product at Lumai, a British company looking to replace traditional GPUs with optical processors. He’s got 30 years experience in the chip world, including a stint as a senior director at ARM. Burr explained the nitty-gritty of OpenAI’s deals with both Broadcom and AMD, and what both mean for the wider world. Burr first poured water on OpenAI’s claim that it would be “designing” the gear produced by Broadcom. “Broadcom has a wide portfolio of IP blocks and pre-designed parts of a chip,” he said, “it will put those together according to the specification of the customer.” He went on to say that Broadcom will essentially put together a series of blocks it has already designed to suit the specification laid down by a customer, in this case OpenAI.Similarly, the AI accelerators Broadcom will build are geared toward more efficient running of models OpenAI has already trained and built — a process called inference in AI circles. “It can tailor the workload and reduce power, or increase performance,” said Burr, but these benefits would only work in OpenAI's favor, rather than for the wider AI industry.I asked Burr why every company in the AI space talks about gigawatts worth of chips rather than in more simple numbers. He explained that, often, it’s because both parties don’t yet know how many chips would be required to meet those lofty goals. But you could make a reasonable guess if you knew the power draw of a specific chip divided by the overall goal, then cut that number in half, then remove an extra 10 percent. “For every watt of power you burn in the chip, you need about a watt of power to cool it as well.” In terms of what OpenAI gets from these deals, Burr believes that the startup will save money on chips, since there’s “less margin” from making your own versus buying gear from NVIDIA. Plus, being able to produce custom silicon to tailor the work to their needs should see significant speed and performance gains on rival systems. Of course, the next biggest benefit is that OpenAI now has “diversity in supply,” rather than being reliant on one provider for all its needs. “Nobody wants a single supplier,” said Burr. The FactoryExcept, of course, OpenAI may be sourcing chips from a variety of its partners, but no matter what’s stamped on the silicon, it all comes from the same place. “I’d be very surprised if it wasn’t TSMC,” said Burr, “I’m pretty sure all of the AI chips out there use TSMC.” TSMC is short for Taiwan Semiconductor Manufacturing Company which, over the last decade, has blown past its major rivals to become the biggest (and in many cases only) source of bleeding-edge chips for the whole technology industry. Unlike historic rivals, which designed and manufactured their own hardware, TSMC is a pure play foundry, only building chips designed by others. Interior at one of TSMC's FabsTaiwan Semiconductor Manufacturing Co. Ltd.Gil Luria is Managing Director at head of technology research at investment firm DA Davidson. He said that TSMC isn’t just a bottleneck for the western technology industry, but in fact is the \"greatest single point of failure for the entire global economy.” Luria credits the company with an impressive expansion “considering it has had to ramp the production of GPUs tenfold over the last three years.” But said that, “in a catastrophic scenario where TSMC is not able to produce in Taiwan, the disruption would be significant.” And that won’t just affect the AI world, but “mobile handset sales as well as global car sales.” TSMC supplanted Intel for a number of well-documented reasons, but the most relevant here is its embrace of Extreme Ultraviolet Lithography (EUV). It’s a technology that Intel had initially backed, but struggled to fully adopt, allowing TSMC to pick it up and run straight to the top. EUV produces the headline-grabbing chips used by pretty much everyone in the consumer electronics world. Apple, Qualcomm, NVIDIA, AMD (including the SOCs inside the PS5 and Xbox) all use TSMC chips. Even Intel has been using TSMC foundries for some consumer CPUs as it races to bridge to gulf in manufacturing between the two companies.“TSMC is the current leader in advanced 3 nanometer (nm) process technologies,” said University of Pennsylvania Professor Benjamin C. Lee. The company’s only meaningful competitors are Intel and Samsung, neither of which pose a threat to its dominance at present. “Intel has been working for a very long time to build a foundry business,” he explained, “but has yet to perfect its interface.” Samsung is in a similar situation, but Professor Lee explained it “has been unable to attract enough customers to generate a profitable manufacturing business.” Professor Lee said that TSMC, by comparison, has become so successful because of how good its chips are, and how easy it is for clients to build chips with its tools. “TSMC fabricates chips with high yield, which is to say more of its chips emerge from the fabrication process at expected performance and reliability.” Consequently, it should be no surprise that TSMC is a money making machine. In the second quarter of 2025 alone it reported a net profit of $12.8 billion USD. And in the following three months, TSMC posted net profits of $14.76 billion. “TSMC’s secret sauce is its mastery of yield,” explained ARPU Intelligence, an analyst group that prefers to use the group name over individual attribution. “This expertise is the result of decades of accumulated process refinement [and] a deep institutional knowledge that cannot be replicated.” This deep institutional knowledge and ability to deliver high quality product creates a “powerful technical lock-in, since companies like Apple and NVIDIA design their chips specifically for TSMC’s unique manufacturing process … It’s not as simple as sending the [chip] design to another factory,” it added.The downside, at least for the wider technology industry, is that TSMC is now a bottleneck that the whole industry has come to rely upon. In the company’s most recent financials, it said more than three quarters of its business comes from North American customers. And in a call with investors, Chairman and CEO C.C. Wei talked about the efforts the company has made to narrow the gap between the enormous demand and its constrained supply. While he was reticent to be specific, he did say that the company’s capacity is “very tight,” and would likely remain that way for the foreseeable future. In fact, TSMC’s capacity is so tight that it’s already caused at least one major name a significant headache. Earlier this year, Reuters reported that NVIDIA canceled an order of its H20 AI chips after being informed the US would not permit them to be exported to China. Once the ban was lifted, however, NVIDIA was unable to find space in TSMC’s schedule, with the next available slot at least nine months later.“TSMC has no room for error,” said ARPU Intelligence, “any minor disruption can halt production with no spare capacity to absorb the shock.” It cited the Hualien earthquake which struck Taiwan on April 3, 2024, and how it negatively impacted the number of wafers in production.Naturally, TSMC is spending big to increase its production capacity for its customers, both in Taiwan and the US. Close to its home, construction on its A14 fab is expected to begin in the very near future, with the first chips due to be produced in 2028. That facility will harness TSMC’s A14 process node, producing 1.4 nm chips, which offer a speed boost over the 2nm silicon that's expected to arrive in consumer devices next year.Image of TSMC's Arizona CampusTaiwan Semiconductor Manufacturing Co. Ltd.Meanwhile, work continues apace on building out TSMC’s sprawling facility in Arizona, which broke ground in April 2021. As Reuters reported at the time, the first facility started operating in early 2025, producing 4 nm chips. Last week, NVIDIA and TSMC showed off the first Blackwell wafer produced at the Arizona plant ahead of domestic volume production.Plans for the operation have grown over time, expanding from three facilities up to six to be built over the next decade. And while the initial outline called for the US facilities to remain several process generations behind Taiwan, that is also changing. In his recent investors call, Chairman and CEO C.C. Wei pledged to invest more in the US facility to bring it only one generation behind the Taiwanese facility. No amount of investment from TSMC or catch-up from rivals like Samsung and Intel will solve the current bottleneck swiftly. It will take many years, if not decades, for the world to reduce its reliance on Taiwan for bleeding-edge manufacturing. TSMC's island remains the industry's weak point, and should something go wrong, the consequences could be dire indeed.This article originally appeared on Engadget at https://www.engadget.com/computing/openais-recent-chip-deals-heap-more-pressure-on-tsmc-130000194.html?src=rss",
          "feed_position": 22,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/Fab14inr015_902_01.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-111555814.html",
          "published_at": "Fri, 24 Oct 2025 11:15:55 +0000",
          "title": "The Morning After: Samsung’s Galaxy XR enters the chat",
          "standfirst": "This week, Samsung showed off Galaxy XR, its Vision Pro-troubling headset, and you can bet we’ve done a deep dive. Sam Rutherford got one of these strapped to his head and has plenty of feelings about the new hardware. The headset is lighter, more comfortable and easier to live with than Apple’s Vision Pro, even if it lacks many of its headline features. The software ecosystem is already pretty broad, thanks to Google making a real effort with Android XR, but dedicated apps are still a bit rare. Samsung’s entry into the market might provide some much-needed impetus for this type of augmented reality headset. That it’s half the price of Apple’s Vision Pro may also loosen some wallets eager to get into this world. But it’s hard not to see this as Samsung running down the same cul-de-sac Apple is now lurking at the end of. It has allowed other companies, like Meta, to waltz in and grab an early lead in the much more useful smart glasses market. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed The first e-bike from Rivian spinoff Also has a virtual drivetrainI’m more interested in its Bakfiets-esque quad bike for driving kids around. Amazon’s smart glasses with AI will help its drivers deliver packages fasterIt’s just like RoboCop, only with more peeing in bottles. ChatGPT in WhatsApp will stop working in JanuaryMeta is kicking its AI rival off its platform. Apple MacBook Pro M5 14-inch review: A huge graphics upgrade for creators and gamers The GPU is the star here. Devindra Hardawar for Engadget Apple’s online-only announcement of the new vanilla M5 MacBooks might have been a sign the new models were no big deal. But Devindra Hardawar found these were, in fact, quite a big deal, and the M5’s faster GPU has the chops to go toe-to-toe with a gaming PC. Continue Reading. Toyota’s new all-hybrid RAV4 has software you might actually want to use It wants to offer a better alternative to your smartphone. Tim Stevens for Engadget Toyota isn’t happy folks just default to CarPlay or Android Auto for their in-car infotainment. That’s why it’s chosen to radically redesign its OS for the 2026 RAV4 to include voice and touch control. Tim Stevens has ridden the new whip and has plenty of opinions on whether it’s worth your time or, you know… you’ll just default to CarPlay or Android Auto. Continue Reading. iPad Pro M5 review: Speed boost We reviewed the iPad Pro M5 and had some feelings. Nathan Ingraham for Engadget As much as I may want an iPad Pro, it wouldn’t play a role in my life that would get anywhere near to justifying its extortionate price. Consequently, I shall just live vicariously through Nathan Ingraham, who reviewed the M5 edition and found it to be a work of art. But, you know, it has a price so eye-watering that nobody who’s on the fence about owning one should bother. Then, Nate pivoted to writing about how the iPad Pro has, at least, carved out its own identity. Continue Reading. New report leaks Amazon’s proposed mass-automation plans It plans to replace more than half a million employees. Amazon may be planning to use automation to eliminate more than half a million jobs in the next few years. The New York Times claims to have seen internal documents outlining the plans and the PR operation that’ll get underway ahead of time to quell public anger. Continue Reading. Binance founder Changpeng Zhao lands a Trump pardon Nothing to see here, move along. Maybe there’s nothing interesting about the fact Changpeng Zhao was just pardoned by President Trump despite pleading guilty to violating the Bank Secrecy Act. I mean, yes, Zhao has ties to World Liberty Financial, a cryptocurrency venture linked to the Trump family. But that’s not uncommon, is it? Surely everyone would use the privilege of high office to exonerate people with whom they potentially have fruitful relationships. Right? Continue Reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111555814.html?src=rss",
          "content": "This week, Samsung showed off Galaxy XR, its Vision Pro-troubling headset, and you can bet we’ve done a deep dive. Sam Rutherford got one of these strapped to his head and has plenty of feelings about the new hardware. The headset is lighter, more comfortable and easier to live with than Apple’s Vision Pro, even if it lacks many of its headline features. The software ecosystem is already pretty broad, thanks to Google making a real effort with Android XR, but dedicated apps are still a bit rare. Samsung’s entry into the market might provide some much-needed impetus for this type of augmented reality headset. That it’s half the price of Apple’s Vision Pro may also loosen some wallets eager to get into this world. But it’s hard not to see this as Samsung running down the same cul-de-sac Apple is now lurking at the end of. It has allowed other companies, like Meta, to waltz in and grab an early lead in the much more useful smart glasses market. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed The first e-bike from Rivian spinoff Also has a virtual drivetrainI’m more interested in its Bakfiets-esque quad bike for driving kids around. Amazon’s smart glasses with AI will help its drivers deliver packages fasterIt’s just like RoboCop, only with more peeing in bottles. ChatGPT in WhatsApp will stop working in JanuaryMeta is kicking its AI rival off its platform. Apple MacBook Pro M5 14-inch review: A huge graphics upgrade for creators and gamers The GPU is the star here. Devindra Hardawar for Engadget Apple’s online-only announcement of the new vanilla M5 MacBooks might have been a sign the new models were no big deal. But Devindra Hardawar found these were, in fact, quite a big deal, and the M5’s faster GPU has the chops to go toe-to-toe with a gaming PC. Continue Reading. Toyota’s new all-hybrid RAV4 has software you might actually want to use It wants to offer a better alternative to your smartphone. Tim Stevens for Engadget Toyota isn’t happy folks just default to CarPlay or Android Auto for their in-car infotainment. That’s why it’s chosen to radically redesign its OS for the 2026 RAV4 to include voice and touch control. Tim Stevens has ridden the new whip and has plenty of opinions on whether it’s worth your time or, you know… you’ll just default to CarPlay or Android Auto. Continue Reading. iPad Pro M5 review: Speed boost We reviewed the iPad Pro M5 and had some feelings. Nathan Ingraham for Engadget As much as I may want an iPad Pro, it wouldn’t play a role in my life that would get anywhere near to justifying its extortionate price. Consequently, I shall just live vicariously through Nathan Ingraham, who reviewed the M5 edition and found it to be a work of art. But, you know, it has a price so eye-watering that nobody who’s on the fence about owning one should bother. Then, Nate pivoted to writing about how the iPad Pro has, at least, carved out its own identity. Continue Reading. New report leaks Amazon’s proposed mass-automation plans It plans to replace more than half a million employees. Amazon may be planning to use automation to eliminate more than half a million jobs in the next few years. The New York Times claims to have seen internal documents outlining the plans and the PR operation that’ll get underway ahead of time to quell public anger. Continue Reading. Binance founder Changpeng Zhao lands a Trump pardon Nothing to see here, move along. Maybe there’s nothing interesting about the fact Changpeng Zhao was just pardoned by President Trump despite pleading guilty to violating the Bank Secrecy Act. I mean, yes, Zhao has ties to World Liberty Financial, a cryptocurrency venture linked to the Trump family. But that’s not uncommon, is it? Surely everyone would use the privilege of high office to exonerate people with whom they potentially have fruitful relationships. Right? Continue Reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111555814.html?src=rss",
          "feed_position": 29,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/1c5c79b0-b0bf-11f0-873f-6093239f799f"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/thinking-machines-challenges-openais-ai-scaling-strategy-first",
          "published_at": "Fri, 24 Oct 2025 09:30:00 GMT",
          "title": "Thinking Machines challenges OpenAI's AI scaling strategy: 'First superintelligence will be a superhuman learner'",
          "standfirst": "While the world&#x27;s leading artificial intelligence companies race to build ever-larger models, betting billions that scale alone will unlock artificial general intelligence, a researcher at one of the industry&#x27;s most secretive and valuable startups delivered a pointed challenge to that orthodoxy this week: The path forward isn&#x27;t about training bigger — it&#x27;s about learning better.\"I believe that the first superintelligence will be a superhuman learner,\" Rafael Rafailov, a reinforcement learning researcher at Thinking Machines Lab, told an audience at TED AI San Francisco on Tuesday. \"It will be able to very efficiently figure out and adapt, propose its own theories, propose experiments, use the environment to verify that, get information, and iterate that process.\"This breaks sharply with the approach pursued by OpenAI, Anthropic, Google DeepMind, and other leading laboratories, which have bet billions on scaling up model size, data, and compute to achieve increasingly sophisticated reasoning capabilities. Rafailov argues these companies have the strategy backwards: what&#x27;s missing from today&#x27;s most advanced AI systems isn&#x27;t more scale — it&#x27;s the ability to actually learn from experience.\"Learning is something an intelligent being does,\" Rafailov said, citing a quote he described as recently compelling. \"Training is something that&#x27;s being done to it.\"The distinction cuts to the core of how AI systems improve — and whether the industry&#x27;s current trajectory can deliver on its most ambitious promises. Rafailov&#x27;s comments offer a rare window into the thinking at Thinking Machines Lab, the startup co-founded in February by former OpenAI chief technology officer Mira Murati that raised a record-breaking $2 billion in seed funding at a $12 billion valuation.Why today&#x27;s AI coding assistants forget everything they learned yesterdayTo illustrate the problem with current AI systems, Rafailov offered a scenario familiar to anyone who has worked with today&#x27;s most advanced coding assistants.\"If you use a coding agent, ask it to do something really difficult — to implement a feature, go read your code, try to understand your code, reason about your code, implement something, iterate — it might be successful,\" he explained. \"And then come back the next day and ask it to implement the next feature, and it will do the same thing.\"The issue, he argued, is that these systems don&#x27;t internalize what they learn. \"In a sense, for the models we have today, every day is their first day of the job,\" Rafailov said. \"But an intelligent being should be able to internalize information. It should be able to adapt. It should be able to modify its behavior so every day it becomes better, every day it knows more, every day it works faster — the way a human you hire gets better at the job.\"The duct tape problem: How current training methods teach AI to take shortcuts instead of solving problemsRafailov pointed to a specific behavior in coding agents that reveals the deeper problem: their tendency to wrap uncertain code in try/except blocks — a programming construct that catches errors and allows a program to continue running.\"If you use coding agents, you might have observed a very annoying tendency of them to use try/except pass,\" he said. \"And in general, that is basically just like duct tape to save the entire program from a single error.\"Why do agents do this? \"They do this because they understand that part of the code might not be right,\" Rafailov explained. \"They understand there might be something wrong, that it might be risky. But under the limited constraint—they have a limited amount of time solving the problem, limited amount of interaction—they must only focus on their objective, which is implement this feature and solve this bug.\"The result: \"They&#x27;re kicking the can down the road.\"This behavior stems from training systems that optimize for immediate task completion. \"The only thing that matters to our current generation is solving the task,\" he said. \"And anything that&#x27;s general, anything that&#x27;s not related to just that one objective, is a waste of computation.\"Why throwing more compute at AI won&#x27;t create superintelligence, according to Thinking Machines researcherRafailov&#x27;s most direct challenge to the industry came in his assertion that continued scaling won&#x27;t be sufficient to reach AGI.\"I don&#x27;t believe we&#x27;re hitting any sort of saturation points,\" he clarified. \"I think we&#x27;re just at the beginning of the next paradigm—the scale of reinforcement learning, in which we move from teaching our models how to think, how to explore thinking space, into endowing them with the capability of general agents.\"In other words, current approaches will produce increasingly capable systems that can interact with the world, browse the web, write code. \"I believe a year or two from now, we&#x27;ll look at our coding agents today, research agents or browsing agents, the way we look at summarization models or translation models from several years ago,\" he said.But general agency, he argued, is not the same as general intelligence. \"The much more interesting question is: Is that going to be AGI? And are we done — do we just need one more round of scaling, one more round of environments, one more round of RL, one more round of compute, and we&#x27;re kind of done?\"His answer was unequivocal: \"I don&#x27;t believe this is the case. I believe that under our current paradigms, under any scale, we are not enough to deal with artificial general intelligence and artificial superintelligence. And I believe that under our current paradigms, our current models will lack one core capability, and that is learning.\"Teaching AI like students, not calculators: The textbook approach to machine learningTo explain the alternative approach, Rafailov turned to an analogy from mathematics education.\"Think about how we train our current generation of reasoning models,\" he said. \"We take a particular math problem, make it very hard, and try to solve it, rewarding the model for solving it. And that&#x27;s it. Once that experience is done, the model submits a solution. Anything it discovers—any abstractions it learned, any theorems—we discard, and then we ask it to solve a new problem, and it has to come up with the same abstractions all over again.\"That approach misunderstands how knowledge accumulates. \"This is not how science or mathematics works,\" he said. \"We build abstractions not necessarily because they solve our current problems, but because they&#x27;re important. For example, we developed the field of topology to extend Euclidean geometry — not to solve a particular problem that Euclidean geometry couldn&#x27;t handle, but because mathematicians and physicists understood these concepts were fundamentally important.\"The solution: \"Instead of giving our models a single problem, we might give them a textbook. Imagine a very advanced graduate-level textbook, and we ask our models to work through the first chapter, then the first exercise, the second exercise, the third, the fourth, then move to the second chapter, and so on—the way a real student might teach themselves a topic.\"The objective would fundamentally change: \"Instead of rewarding their success — how many problems they solved — we need to reward their progress, their ability to learn, and their ability to improve.\"This approach, known as \"meta-learning\" or \"learning to learn,\" has precedents in earlier AI systems. \"Just like the ideas of scaling test-time compute and search and test-time exploration played out in the domain of games first\" — in systems like DeepMind&#x27;s AlphaGo — \"the same is true for meta learning. We know that these ideas do work at a small scale, but we need to adapt them to the scale and the capability of foundation models.\"The missing ingredients for AI that truly learns aren&#x27;t new architectures—they&#x27;re better data and smarter objectivesWhen Rafailov addressed why current models lack this learning capability, he offered a surprisingly straightforward answer.\"Unfortunately, I think the answer is quite prosaic,\" he said. \"I think we just don&#x27;t have the right data, and we don&#x27;t have the right objectives. I fundamentally believe a lot of the core architectural engineering design is in place.\"Rather than arguing for entirely new model architectures, Rafailov suggested the path forward lies in redesigning the data distributions and reward structures used to train models.\"Learning, in of itself, is an algorithm,\" he explained. \"It has inputs — the current state of the model. It has data and compute. You process it through some sort of structure, choose your favorite optimization algorithm, and you produce, hopefully, a stronger model.\"The question: \"If reasoning models are able to learn general reasoning algorithms, general search algorithms, and agent models are able to learn general agency, can the next generation of AI learn a learning algorithm itself?\"His answer: \"I strongly believe that the answer to this question is yes.\"The technical approach would involve creating training environments where \"learning, adaptation, exploration, and self-improvement, as well as generalization, are necessary for success.\"\"I believe that under enough computational resources and with broad enough coverage, general purpose learning algorithms can emerge from large scale training,\" Rafailov said. \"The way we train our models to reason in general over just math and code, and potentially act in general domains, we might be able to teach them how to learn efficiently across many different applications.\"Forget god-like reasoners: The first superintelligence will be a master studentThis vision leads to a fundamentally different conception of what artificial superintelligence might look like.\"I believe that if this is possible, that&#x27;s the final missing piece to achieve truly efficient general intelligence,\" Rafailov said. \"Now imagine such an intelligence with the core objective of exploring, learning, acquiring information, self-improving, equipped with general agency capability—the ability to understand and explore the external world, the ability to use computers, ability to do research, ability to manage and control robots.\"Such a system would constitute artificial superintelligence. But not the kind often imagined in science fiction.\"I believe that intelligence is not going to be a single god model that&#x27;s a god-level reasoner or a god-level mathematical problem solver,\" Rafailov said. \"I believe that the first superintelligence will be a superhuman learner, and it will be able to very efficiently figure out and adapt, propose its own theories, propose experiments, use the environment to verify that, get information, and iterate that process.\"This vision stands in contrast to OpenAI&#x27;s emphasis on building increasingly powerful reasoning systems, or Anthropic&#x27;s focus on \"constitutional AI.\" Instead, Thinking Machines Lab appears to be betting that the path to superintelligence runs through systems that can continuously improve themselves through interaction with their environment.The $12 billion bet on learning over scaling faces formidable challengesRafailov&#x27;s appearance comes at a complex moment for Thinking Machines Lab. The company has assembled an impressive team of approximately 30 researchers from OpenAI, Google, Meta, and other leading labs. But it suffered a setback in early October when Andrew Tulloch, a co-founder and machine learning expert, departed to return to Meta after the company launched what The Wall Street Journal called a \"full-scale raid\" on the startup, approaching more than a dozen employees with compensation packages ranging from $200 million to $1.5 billion over multiple years.Despite these pressures, Rafailov&#x27;s comments suggest the company remains committed to its differentiated technical approach. The company launched its first product, Tinker, an API for fine-tuning open-source language models, in October. But Rafailov&#x27;s talk suggests Tinker is just the foundation for a much more ambitious research agenda focused on meta-learning and self-improving systems.\"This is not easy. This is going to be very difficult,\" Rafailov acknowledged. \"We&#x27;ll need a lot of breakthroughs in memory and engineering and data and optimization, but I think it&#x27;s fundamentally possible.\"He concluded with a play on words: \"The world is not enough, but we need the right experiences, and we need the right type of rewards for learning.\"The question for Thinking Machines Lab — and the broader AI industry — is whether this vision can be realized, and on what timeline. Rafailov notably did not offer specific predictions about when such systems might emerge.In an industry where executives routinely make bold predictions about AGI arriving within years or even months, that restraint is notable. It suggests either unusual scientific humility — or an acknowledgment that Thinking Machines Lab is pursuing a much longer, harder path than its competitors.For now, the most revealing detail may be what Rafailov didn&#x27;t say during his TED AI presentation. No timeline for when superhuman learners might emerge. No prediction about when the technical breakthroughs would arrive. Just a conviction that the capability was \"fundamentally possible\" — and that without it, all the scaling in the world won&#x27;t be enough.",
          "content": "While the world&#x27;s leading artificial intelligence companies race to build ever-larger models, betting billions that scale alone will unlock artificial general intelligence, a researcher at one of the industry&#x27;s most secretive and valuable startups delivered a pointed challenge to that orthodoxy this week: The path forward isn&#x27;t about training bigger — it&#x27;s about learning better.\"I believe that the first superintelligence will be a superhuman learner,\" Rafael Rafailov, a reinforcement learning researcher at Thinking Machines Lab, told an audience at TED AI San Francisco on Tuesday. \"It will be able to very efficiently figure out and adapt, propose its own theories, propose experiments, use the environment to verify that, get information, and iterate that process.\"This breaks sharply with the approach pursued by OpenAI, Anthropic, Google DeepMind, and other leading laboratories, which have bet billions on scaling up model size, data, and compute to achieve increasingly sophisticated reasoning capabilities. Rafailov argues these companies have the strategy backwards: what&#x27;s missing from today&#x27;s most advanced AI systems isn&#x27;t more scale — it&#x27;s the ability to actually learn from experience.\"Learning is something an intelligent being does,\" Rafailov said, citing a quote he described as recently compelling. \"Training is something that&#x27;s being done to it.\"The distinction cuts to the core of how AI systems improve — and whether the industry&#x27;s current trajectory can deliver on its most ambitious promises. Rafailov&#x27;s comments offer a rare window into the thinking at Thinking Machines Lab, the startup co-founded in February by former OpenAI chief technology officer Mira Murati that raised a record-breaking $2 billion in seed funding at a $12 billion valuation.Why today&#x27;s AI coding assistants forget everything they learned yesterdayTo illustrate the problem with current AI systems, Rafailov offered a scenario familiar to anyone who has worked with today&#x27;s most advanced coding assistants.\"If you use a coding agent, ask it to do something really difficult — to implement a feature, go read your code, try to understand your code, reason about your code, implement something, iterate — it might be successful,\" he explained. \"And then come back the next day and ask it to implement the next feature, and it will do the same thing.\"The issue, he argued, is that these systems don&#x27;t internalize what they learn. \"In a sense, for the models we have today, every day is their first day of the job,\" Rafailov said. \"But an intelligent being should be able to internalize information. It should be able to adapt. It should be able to modify its behavior so every day it becomes better, every day it knows more, every day it works faster — the way a human you hire gets better at the job.\"The duct tape problem: How current training methods teach AI to take shortcuts instead of solving problemsRafailov pointed to a specific behavior in coding agents that reveals the deeper problem: their tendency to wrap uncertain code in try/except blocks — a programming construct that catches errors and allows a program to continue running.\"If you use coding agents, you might have observed a very annoying tendency of them to use try/except pass,\" he said. \"And in general, that is basically just like duct tape to save the entire program from a single error.\"Why do agents do this? \"They do this because they understand that part of the code might not be right,\" Rafailov explained. \"They understand there might be something wrong, that it might be risky. But under the limited constraint—they have a limited amount of time solving the problem, limited amount of interaction—they must only focus on their objective, which is implement this feature and solve this bug.\"The result: \"They&#x27;re kicking the can down the road.\"This behavior stems from training systems that optimize for immediate task completion. \"The only thing that matters to our current generation is solving the task,\" he said. \"And anything that&#x27;s general, anything that&#x27;s not related to just that one objective, is a waste of computation.\"Why throwing more compute at AI won&#x27;t create superintelligence, according to Thinking Machines researcherRafailov&#x27;s most direct challenge to the industry came in his assertion that continued scaling won&#x27;t be sufficient to reach AGI.\"I don&#x27;t believe we&#x27;re hitting any sort of saturation points,\" he clarified. \"I think we&#x27;re just at the beginning of the next paradigm—the scale of reinforcement learning, in which we move from teaching our models how to think, how to explore thinking space, into endowing them with the capability of general agents.\"In other words, current approaches will produce increasingly capable systems that can interact with the world, browse the web, write code. \"I believe a year or two from now, we&#x27;ll look at our coding agents today, research agents or browsing agents, the way we look at summarization models or translation models from several years ago,\" he said.But general agency, he argued, is not the same as general intelligence. \"The much more interesting question is: Is that going to be AGI? And are we done — do we just need one more round of scaling, one more round of environments, one more round of RL, one more round of compute, and we&#x27;re kind of done?\"His answer was unequivocal: \"I don&#x27;t believe this is the case. I believe that under our current paradigms, under any scale, we are not enough to deal with artificial general intelligence and artificial superintelligence. And I believe that under our current paradigms, our current models will lack one core capability, and that is learning.\"Teaching AI like students, not calculators: The textbook approach to machine learningTo explain the alternative approach, Rafailov turned to an analogy from mathematics education.\"Think about how we train our current generation of reasoning models,\" he said. \"We take a particular math problem, make it very hard, and try to solve it, rewarding the model for solving it. And that&#x27;s it. Once that experience is done, the model submits a solution. Anything it discovers—any abstractions it learned, any theorems—we discard, and then we ask it to solve a new problem, and it has to come up with the same abstractions all over again.\"That approach misunderstands how knowledge accumulates. \"This is not how science or mathematics works,\" he said. \"We build abstractions not necessarily because they solve our current problems, but because they&#x27;re important. For example, we developed the field of topology to extend Euclidean geometry — not to solve a particular problem that Euclidean geometry couldn&#x27;t handle, but because mathematicians and physicists understood these concepts were fundamentally important.\"The solution: \"Instead of giving our models a single problem, we might give them a textbook. Imagine a very advanced graduate-level textbook, and we ask our models to work through the first chapter, then the first exercise, the second exercise, the third, the fourth, then move to the second chapter, and so on—the way a real student might teach themselves a topic.\"The objective would fundamentally change: \"Instead of rewarding their success — how many problems they solved — we need to reward their progress, their ability to learn, and their ability to improve.\"This approach, known as \"meta-learning\" or \"learning to learn,\" has precedents in earlier AI systems. \"Just like the ideas of scaling test-time compute and search and test-time exploration played out in the domain of games first\" — in systems like DeepMind&#x27;s AlphaGo — \"the same is true for meta learning. We know that these ideas do work at a small scale, but we need to adapt them to the scale and the capability of foundation models.\"The missing ingredients for AI that truly learns aren&#x27;t new architectures—they&#x27;re better data and smarter objectivesWhen Rafailov addressed why current models lack this learning capability, he offered a surprisingly straightforward answer.\"Unfortunately, I think the answer is quite prosaic,\" he said. \"I think we just don&#x27;t have the right data, and we don&#x27;t have the right objectives. I fundamentally believe a lot of the core architectural engineering design is in place.\"Rather than arguing for entirely new model architectures, Rafailov suggested the path forward lies in redesigning the data distributions and reward structures used to train models.\"Learning, in of itself, is an algorithm,\" he explained. \"It has inputs — the current state of the model. It has data and compute. You process it through some sort of structure, choose your favorite optimization algorithm, and you produce, hopefully, a stronger model.\"The question: \"If reasoning models are able to learn general reasoning algorithms, general search algorithms, and agent models are able to learn general agency, can the next generation of AI learn a learning algorithm itself?\"His answer: \"I strongly believe that the answer to this question is yes.\"The technical approach would involve creating training environments where \"learning, adaptation, exploration, and self-improvement, as well as generalization, are necessary for success.\"\"I believe that under enough computational resources and with broad enough coverage, general purpose learning algorithms can emerge from large scale training,\" Rafailov said. \"The way we train our models to reason in general over just math and code, and potentially act in general domains, we might be able to teach them how to learn efficiently across many different applications.\"Forget god-like reasoners: The first superintelligence will be a master studentThis vision leads to a fundamentally different conception of what artificial superintelligence might look like.\"I believe that if this is possible, that&#x27;s the final missing piece to achieve truly efficient general intelligence,\" Rafailov said. \"Now imagine such an intelligence with the core objective of exploring, learning, acquiring information, self-improving, equipped with general agency capability—the ability to understand and explore the external world, the ability to use computers, ability to do research, ability to manage and control robots.\"Such a system would constitute artificial superintelligence. But not the kind often imagined in science fiction.\"I believe that intelligence is not going to be a single god model that&#x27;s a god-level reasoner or a god-level mathematical problem solver,\" Rafailov said. \"I believe that the first superintelligence will be a superhuman learner, and it will be able to very efficiently figure out and adapt, propose its own theories, propose experiments, use the environment to verify that, get information, and iterate that process.\"This vision stands in contrast to OpenAI&#x27;s emphasis on building increasingly powerful reasoning systems, or Anthropic&#x27;s focus on \"constitutional AI.\" Instead, Thinking Machines Lab appears to be betting that the path to superintelligence runs through systems that can continuously improve themselves through interaction with their environment.The $12 billion bet on learning over scaling faces formidable challengesRafailov&#x27;s appearance comes at a complex moment for Thinking Machines Lab. The company has assembled an impressive team of approximately 30 researchers from OpenAI, Google, Meta, and other leading labs. But it suffered a setback in early October when Andrew Tulloch, a co-founder and machine learning expert, departed to return to Meta after the company launched what The Wall Street Journal called a \"full-scale raid\" on the startup, approaching more than a dozen employees with compensation packages ranging from $200 million to $1.5 billion over multiple years.Despite these pressures, Rafailov&#x27;s comments suggest the company remains committed to its differentiated technical approach. The company launched its first product, Tinker, an API for fine-tuning open-source language models, in October. But Rafailov&#x27;s talk suggests Tinker is just the foundation for a much more ambitious research agenda focused on meta-learning and self-improving systems.\"This is not easy. This is going to be very difficult,\" Rafailov acknowledged. \"We&#x27;ll need a lot of breakthroughs in memory and engineering and data and optimization, but I think it&#x27;s fundamentally possible.\"He concluded with a play on words: \"The world is not enough, but we need the right experiences, and we need the right type of rewards for learning.\"The question for Thinking Machines Lab — and the broader AI industry — is whether this vision can be realized, and on what timeline. Rafailov notably did not offer specific predictions about when such systems might emerge.In an industry where executives routinely make bold predictions about AGI arriving within years or even months, that restraint is notable. It suggests either unusual scientific humility — or an acknowledgment that Thinking Machines Lab is pursuing a much longer, harder path than its competitors.For now, the most revealing detail may be what Rafailov didn&#x27;t say during his TED AI presentation. No timeline for when superhuman learners might emerge. No prediction about when the technical breakthroughs would arrive. Just a conviction that the capability was \"fundamentally possible\" — and that without it, all the scaling in the world won&#x27;t be enough.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6gnj4yPgIqEF3Y4cLtYWL9/3a8c4c8b409b763704f9f4dd0ad67fd3/nuneybits_A_retro_glowing_computer_terminal_on_gradient_backgro_b5f91633-1cc9-42d7-9d6f-e497887b2ff3.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-headphones-for-running-120044637.html",
          "published_at": "Fri, 24 Oct 2025 09:00:35 +0000",
          "title": "The best headphones for running in 2025",
          "standfirst": "Whether you’re already an avid runner or hope to be one as you start a new training regimen, you’ll get more out of your exercise routine if you have some good music to accompany you. Getting into the zone during a long run with your preferred music, be it rap, classic rock or today’s pop hits, can totally change your experience for the better. To do that, you have to start with a good pair of running headphones.But not all wireless workout headphones are created equally, and runners need to consider specific factors before investing in a pair like how long your runs are, what type of music or other audio you prefer listening to and how much you want to block out the world during a session. I’ve tested out more than a dozen pairs to find which are the best headphones for running for all budgets and all kinds of runners. Table of contents Best headphones for running in 2025 What to look for in running headphones How we test headphones for running Others headphones for running we tested Best headphones for running in 2025 Others headphones for running we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in running headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear Bluetooth headphones during a run, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Water resistance and dust protection are crucial for the best running headphones to have since you’ll likely be sweating while wearing them. Also, if you have the unfortunate luck of getting caught in the rain during a run, at least your gear will survive. Here’s a quick rundown of ingress protection (IP) ratings, which you’ll see attached to many earbuds on the market today. The first digit after the abbreviation rates dust protection on a scale from one to six — the higher, the better. The second digit refers to water- resistance, or waterproofing in some cases, ranked on a scale from one to nine. A letter “X” in either position means the device isn’t rated for the corresponding material. Check out this guide for an even more detailed breakdown. All of the earbuds we tested for this guide have at least an IPX4 rating (most have even more protection), which means they can withstand sweat and splashes but do not have dust protection. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming a standard feature on wireless earbuds, at least in those above a certain price. If you’re looking for a pair of buds that can be your workout companion and continue to serve you when you’re off the trail, ANC is good to have. It adds versatility by allowing you to block out the hum of your home or office so you can focus, or give you some solitude during a busy commute on public transit. But an earbud’s ability to block out the world goes hand in hand with its ability to open things back up should you need it. Many earbuds with ANC support some sort of “transparency mode” or various levels of noise reduction. This is important for running headphones because you don’t want to be totally oblivious to what’s going on around you when you’re exercising outside along busy streets. Lowering noise cancelation levels to increase your awareness will help with that. Battery life All of the earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most runners, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. Speaking of, you’ll get an average of 20-28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test headphones for running When testing to determine the best running headphones, I wear each contender during as many runs as possible. I typically run three to five days each week, completing at least a 5K (3.01 miles) each time. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you’re on the tread or trail (as a note, I primarily run outside). I’m also paying attention to fit over time, particularly if the earbuds get slippery or loose while I sweat, or if they tend to pop out or feel less stable in my ears as I pick up speed or make quick movements. I also use the earbuds when not running to take calls and listen to music, podcasts and the like throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also listening for audio quality, I’m admittedly not an expert in this space. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about sound quality for some of our top picks in his reviews and buying guides. Here, however, I will make note of audio-quality characteristics if they stood out to me (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’re able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-for-running-120044637.html?src=rss",
          "content": "Whether you’re already an avid runner or hope to be one as you start a new training regimen, you’ll get more out of your exercise routine if you have some good music to accompany you. Getting into the zone during a long run with your preferred music, be it rap, classic rock or today’s pop hits, can totally change your experience for the better. To do that, you have to start with a good pair of running headphones.But not all wireless workout headphones are created equally, and runners need to consider specific factors before investing in a pair like how long your runs are, what type of music or other audio you prefer listening to and how much you want to block out the world during a session. I’ve tested out more than a dozen pairs to find which are the best headphones for running for all budgets and all kinds of runners. Table of contents Best headphones for running in 2025 What to look for in running headphones How we test headphones for running Others headphones for running we tested Best headphones for running in 2025 Others headphones for running we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in running headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear Bluetooth headphones during a run, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Water resistance and dust protection are crucial for the best running headphones to have since you’ll likely be sweating while wearing them. Also, if you have the unfortunate luck of getting caught in the rain during a run, at least your gear will survive. Here’s a quick rundown of ingress protection (IP) ratings, which you’ll see attached to many earbuds on the market today. The first digit after the abbreviation rates dust protection on a scale from one to six — the higher, the better. The second digit refers to water- resistance, or waterproofing in some cases, ranked on a scale from one to nine. A letter “X” in either position means the device isn’t rated for the corresponding material. Check out this guide for an even more detailed breakdown. All of the earbuds we tested for this guide have at least an IPX4 rating (most have even more protection), which means they can withstand sweat and splashes but do not have dust protection. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming a standard feature on wireless earbuds, at least in those above a certain price. If you’re looking for a pair of buds that can be your workout companion and continue to serve you when you’re off the trail, ANC is good to have. It adds versatility by allowing you to block out the hum of your home or office so you can focus, or give you some solitude during a busy commute on public transit. But an earbud’s ability to block out the world goes hand in hand with its ability to open things back up should you need it. Many earbuds with ANC support some sort of “transparency mode” or various levels of noise reduction. This is important for running headphones because you don’t want to be totally oblivious to what’s going on around you when you’re exercising outside along busy streets. Lowering noise cancelation levels to increase your awareness will help with that. Battery life All of the earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most runners, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. Speaking of, you’ll get an average of 20-28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test headphones for running When testing to determine the best running headphones, I wear each contender during as many runs as possible. I typically run three to five days each week, completing at least a 5K (3.01 miles) each time. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you’re on the tread or trail (as a note, I primarily run outside). I’m also paying attention to fit over time, particularly if the earbuds get slippery or loose while I sweat, or if they tend to pop out or feel less stable in my ears as I pick up speed or make quick movements. I also use the earbuds when not running to take calls and listen to music, podcasts and the like throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also listening for audio quality, I’m admittedly not an expert in this space. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about sound quality for some of our top picks in his reviews and buying guides. Here, however, I will make note of audio-quality characteristics if they stood out to me (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’re able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-for-running-120044637.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/best-ipads-how-to-pick-the-best-apple-tablet-for-you-150054066.html",
          "published_at": "Fri, 24 Oct 2025 07:00:37 +0000",
          "title": "The best iPad for 2025: How to pick the best Apple tablet for you",
          "standfirst": "We’ve long considered Apple’s iPads to be the best tablets on the market, but determining exactly which model you should buy isn’t always straightforward. Do you just want a big screen for streaming and web browsing? Do you want to use it like a pseudo-laptop? Do you care about Apple Intelligence at all? If you’re not sure, allow us to help. We’ve tested every iPad available today and broken down which ones should best fit your needs below. Table of contents The best iPads for 2025 How we test the best iPads iPad FAQs Recent updates The best iPads for 2025 How we test the best iPads The top edge of the iPad mini. Photo by Nathan Ingraham / Engadget Much like we do for our guide to the best tablets overall, we spend several days with each iPad to see how they feel and perform with different tasks: watching videos, web browsing, playing both casual and graphically intense games, editing 4K photos and video, running multiple apps side-by-side, making FaceTime calls and the like. To better measure performance specifically, we use benchmarking tests like Geekbench 6, 3DMark and GFXBench Metal, plus we measure how long it takes for each tablet to boot up and open various apps. We also check how well each tablet holds up long-term, whether it’s with a review unit provided by Apple or an iPad model that’s owned by a member of the Engadget staff. To help compare the color performance and brightness of the displays, we play the same videos on different iPads, side-by-side, at equal brightness levels. We use each tablet in direct sunlight outdoors to see how well they hold up to glare, and we play a handful of the same musical tracks to evaluate speaker performance. For battery life, we keep track of how long each tablet generally lasts before it needs a recharge, but we also play a 1080p movie on a loop at roughly 70 percent brightness with power-sapping background processes off. We also test each device with an Apple Pencil and note how responsive the stylus feels. Finally, we carefully pore over spec sheets and software updates to keep track of which features are available on certain iPads but not others. iPad FAQs The iPad (A16) on top of an 13-inch iPad Air. Jeff Dunn for Engadget What are some new features coming to iPadOS 26? Apple released the latest update to its iPad operating system, iPadOS 26, in September. The update is a fairly significant overhaul, one that brings iPadOS closer to macOS than ever before. New features include the ability to open more windows simultaneously and resize or tile them more freely; a Mac-style Menu bar; a dedicated Preview app; an upgraded Files app; an improved ability to export or download large files in the background; an Exposé view that shows all open windows; a pointier cursor and the option to add folders to the Dock. It also uses the new “liquid glass” design language that Apple is rolling out across all of its platforms in 2025. That said, it completely removed the “slide over” and “split view” modes found in previous versions of iPadOS, which can make quickly viewing multiple apps at once a little more cumbersome. (Though the former will now return in an upcoming update.) Notably, most of these features are available across Apple’s tablet lineup, from the iPad Pro to the entry-level iPad. You can find the full list of compatible devices at the bottom of Apple’s overview page. How long do iPads typically last? If history is any indication, expect Apple to update your iPad to the latest version of iPadOS for at least five years, if not longer. The current iPadOS 26 update, for example, is available on iPad Pro models dating back to 2018 and other iPads dating back to 2019. How long your iPad’s hardware will last depends on which model you buy and how well you maintain it. (If you’re particularly clumsy, consider an iPad case.) A more powerful iPad Pro will feel fast for a longer time than an entry-level iPad, but each model should remain at least serviceable until Apple stops updating it, at minimum. What’s the difference between the iPad and the iPad Air? Compared to the standard iPad, the iPad Air runs on a stronger M3 chip (instead of the A16 Bionic) and has 2GB more RAM (8GB total). Both come with 128GB of storage by default. The Air is also available in two sizes, 11 and 13 inches, whereas the 11th-gen iPad doesn't offer the larger screen option. The M-series SoC gives the Air better long-term performance prospects, plus access to certain iPadOS features such as Apple Intelligence. Its display supports a wider P3 color gamut, has an antireflective coating and is fully laminated. The latter means there’s no “air gap” between the display and the glass covering it, so it feels more like you’re directly touching what’s on screen instead of interacting with an image below the glass. The Air also works with the newer Pencil Pro stylus and more comfortable Magic Keyboards, and its USB-C port supports faster data transfer speeds. It technically supports faster Wi-Fi 6E, too, while the lower-cost iPad uses Wi-Fi 6. Starting at $349, the 11th-gen iPad is $250 less expensive than the iPad Air. It has a similarly elegant design with flat edges, thin bezels, USB-C port, and a Touch ID reader. Battery life is rated at the same 10 hours, and both devices have their front-facing camera on their long edge, which is a more natural position for video calls. The cheaper iPad works with the first-gen and USB-C Apple Pencils – which are more convoluted to charge – and a unique keyboard accessory called the Magic Keyboard Folio. Jeff Dunn for Engadget What’s the difference between iPads and Android tablets? The operating system, duh. But to give a few more specifics: Android devices are available from more manufacturers and cover a wider price range. You won’t see an $80 iPad anytime soon. Android is also more malleable in that you can easily sideload apps from places beyond Google’s official app store and more extensively customize the look of the OS (though the former may no longer be an option in the coming months). Several Android tablets still have features like a headphone jack or a microSD slot for adding storage, too, though those are getting rarer. But we tend to recommend Apple tablets to those who have no allegiance either way. iPad apps are still a bit more likely to be designed specifically for larger screens, rather than looking like blown-up phone software, and Apple is just about peerless when it comes to long-term software support. Every new iPad hits a certain baseline of hardware quality and performance — none of them feel cheap, and all of them are fast enough for most needs. Plus, you’ll get the most out of an iPad if you use other Apple devices. Can an iPad replace a laptop? This is a loaded question, since laptop workflows differ from person to person. If you mostly use a notebook for browsing the web, watching videos or writing emails and word docs, then sure, you can get along just fine with an iPad and the right iPad accessories. It’ll be easier to carry around, the battery life is great and having the touchscreen and stylus support is handy (though many Windows users have that regardless). Even beyond the basics, plenty of media editors, graphic designers and digital artists have shown they can get things done on an iPad. Broadly speaking, though, a laptop OS tends to be more flexible when it comes to file management, multitasking, coding or other “heavy” tasks. The recent iPadOS 26 update does close the gap a bit, though it’s still not quite as fluid. Safari on the iPad isn’t fully on par with desktop browsers either. So the answer really depends on you. How do I take a screenshot on an iPad? As we note in our screenshot how-to guide, you can take a screenshot on your iPad by pressing the top button and either volume button at the same time. If you have an older iPad with a Home button, simultaneously press the top button and the Home button instead. Recent updates Late October 2025: The new M5-based iPad Pro replaces the previous-generation iPad Pro as our top pick for power users. Early October 2025: We’ve made a few edits to reflect the full release of iPadOS 26 and made sure our recommendations are still accurate. August 2025: We've taken another sweep to ensure our picks are still accurate and added a few more notes to our FAQ section. June 2025: We’ve made a few minor edits to reflect the announcement of Apple’s latest iPadOS update, which we detail above. May 2025: We’ve lightly edited this guide to ensure all details and links are still correct. We’re also keeping an eye on how the Trump administration’s tariff policy affects the pricing and stock of the iPad lineup (and every other tech category). All of our picks are still available at normal prices today, but we’ll update this guide if that changes. March 2025: We've reviewed the iPad (A16) and named it our new budget pick, removing the discontinued 10th-gen iPad in the process. March 2025: The recently-launched iPad Air M3 has replaced its predecessor as our top overall recommendation. We’ve also made a note regarding the new iPad (A16), which we plan to test in the near future and expect to become our new budget pick. We’ve made a handful of edits elsewhere in the guide to reflect Apple’s latest hardware. January 2025: We’ve lightly edited this guide for clarity. Our recommendations remain the same. October 2024: We've updated our guide to include the new iPad mini 7. June 2024: We’ve touched up this guide to reflect some of the new iPadOS features Apple announced at WWDC, though our picks remain the same. Nathan Ingraham contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-ipads-how-to-pick-the-best-apple-tablet-for-you-150054066.html?src=rss",
          "content": "We’ve long considered Apple’s iPads to be the best tablets on the market, but determining exactly which model you should buy isn’t always straightforward. Do you just want a big screen for streaming and web browsing? Do you want to use it like a pseudo-laptop? Do you care about Apple Intelligence at all? If you’re not sure, allow us to help. We’ve tested every iPad available today and broken down which ones should best fit your needs below. Table of contents The best iPads for 2025 How we test the best iPads iPad FAQs Recent updates The best iPads for 2025 How we test the best iPads The top edge of the iPad mini. Photo by Nathan Ingraham / Engadget Much like we do for our guide to the best tablets overall, we spend several days with each iPad to see how they feel and perform with different tasks: watching videos, web browsing, playing both casual and graphically intense games, editing 4K photos and video, running multiple apps side-by-side, making FaceTime calls and the like. To better measure performance specifically, we use benchmarking tests like Geekbench 6, 3DMark and GFXBench Metal, plus we measure how long it takes for each tablet to boot up and open various apps. We also check how well each tablet holds up long-term, whether it’s with a review unit provided by Apple or an iPad model that’s owned by a member of the Engadget staff. To help compare the color performance and brightness of the displays, we play the same videos on different iPads, side-by-side, at equal brightness levels. We use each tablet in direct sunlight outdoors to see how well they hold up to glare, and we play a handful of the same musical tracks to evaluate speaker performance. For battery life, we keep track of how long each tablet generally lasts before it needs a recharge, but we also play a 1080p movie on a loop at roughly 70 percent brightness with power-sapping background processes off. We also test each device with an Apple Pencil and note how responsive the stylus feels. Finally, we carefully pore over spec sheets and software updates to keep track of which features are available on certain iPads but not others. iPad FAQs The iPad (A16) on top of an 13-inch iPad Air. Jeff Dunn for Engadget What are some new features coming to iPadOS 26? Apple released the latest update to its iPad operating system, iPadOS 26, in September. The update is a fairly significant overhaul, one that brings iPadOS closer to macOS than ever before. New features include the ability to open more windows simultaneously and resize or tile them more freely; a Mac-style Menu bar; a dedicated Preview app; an upgraded Files app; an improved ability to export or download large files in the background; an Exposé view that shows all open windows; a pointier cursor and the option to add folders to the Dock. It also uses the new “liquid glass” design language that Apple is rolling out across all of its platforms in 2025. That said, it completely removed the “slide over” and “split view” modes found in previous versions of iPadOS, which can make quickly viewing multiple apps at once a little more cumbersome. (Though the former will now return in an upcoming update.) Notably, most of these features are available across Apple’s tablet lineup, from the iPad Pro to the entry-level iPad. You can find the full list of compatible devices at the bottom of Apple’s overview page. How long do iPads typically last? If history is any indication, expect Apple to update your iPad to the latest version of iPadOS for at least five years, if not longer. The current iPadOS 26 update, for example, is available on iPad Pro models dating back to 2018 and other iPads dating back to 2019. How long your iPad’s hardware will last depends on which model you buy and how well you maintain it. (If you’re particularly clumsy, consider an iPad case.) A more powerful iPad Pro will feel fast for a longer time than an entry-level iPad, but each model should remain at least serviceable until Apple stops updating it, at minimum. What’s the difference between the iPad and the iPad Air? Compared to the standard iPad, the iPad Air runs on a stronger M3 chip (instead of the A16 Bionic) and has 2GB more RAM (8GB total). Both come with 128GB of storage by default. The Air is also available in two sizes, 11 and 13 inches, whereas the 11th-gen iPad doesn't offer the larger screen option. The M-series SoC gives the Air better long-term performance prospects, plus access to certain iPadOS features such as Apple Intelligence. Its display supports a wider P3 color gamut, has an antireflective coating and is fully laminated. The latter means there’s no “air gap” between the display and the glass covering it, so it feels more like you’re directly touching what’s on screen instead of interacting with an image below the glass. The Air also works with the newer Pencil Pro stylus and more comfortable Magic Keyboards, and its USB-C port supports faster data transfer speeds. It technically supports faster Wi-Fi 6E, too, while the lower-cost iPad uses Wi-Fi 6. Starting at $349, the 11th-gen iPad is $250 less expensive than the iPad Air. It has a similarly elegant design with flat edges, thin bezels, USB-C port, and a Touch ID reader. Battery life is rated at the same 10 hours, and both devices have their front-facing camera on their long edge, which is a more natural position for video calls. The cheaper iPad works with the first-gen and USB-C Apple Pencils – which are more convoluted to charge – and a unique keyboard accessory called the Magic Keyboard Folio. Jeff Dunn for Engadget What’s the difference between iPads and Android tablets? The operating system, duh. But to give a few more specifics: Android devices are available from more manufacturers and cover a wider price range. You won’t see an $80 iPad anytime soon. Android is also more malleable in that you can easily sideload apps from places beyond Google’s official app store and more extensively customize the look of the OS (though the former may no longer be an option in the coming months). Several Android tablets still have features like a headphone jack or a microSD slot for adding storage, too, though those are getting rarer. But we tend to recommend Apple tablets to those who have no allegiance either way. iPad apps are still a bit more likely to be designed specifically for larger screens, rather than looking like blown-up phone software, and Apple is just about peerless when it comes to long-term software support. Every new iPad hits a certain baseline of hardware quality and performance — none of them feel cheap, and all of them are fast enough for most needs. Plus, you’ll get the most out of an iPad if you use other Apple devices. Can an iPad replace a laptop? This is a loaded question, since laptop workflows differ from person to person. If you mostly use a notebook for browsing the web, watching videos or writing emails and word docs, then sure, you can get along just fine with an iPad and the right iPad accessories. It’ll be easier to carry around, the battery life is great and having the touchscreen and stylus support is handy (though many Windows users have that regardless). Even beyond the basics, plenty of media editors, graphic designers and digital artists have shown they can get things done on an iPad. Broadly speaking, though, a laptop OS tends to be more flexible when it comes to file management, multitasking, coding or other “heavy” tasks. The recent iPadOS 26 update does close the gap a bit, though it’s still not quite as fluid. Safari on the iPad isn’t fully on par with desktop browsers either. So the answer really depends on you. How do I take a screenshot on an iPad? As we note in our screenshot how-to guide, you can take a screenshot on your iPad by pressing the top button and either volume button at the same time. If you have an older iPad with a Home button, simultaneously press the top button and the Home button instead. Recent updates Late October 2025: The new M5-based iPad Pro replaces the previous-generation iPad Pro as our top pick for power users. Early October 2025: We’ve made a few edits to reflect the full release of iPadOS 26 and made sure our recommendations are still accurate. August 2025: We've taken another sweep to ensure our picks are still accurate and added a few more notes to our FAQ section. June 2025: We’ve made a few minor edits to reflect the announcement of Apple’s latest iPadOS update, which we detail above. May 2025: We’ve lightly edited this guide to ensure all details and links are still correct. We’re also keeping an eye on how the Trump administration’s tariff policy affects the pricing and stock of the iPad lineup (and every other tech category). All of our picks are still available at normal prices today, but we’ll update this guide if that changes. March 2025: We've reviewed the iPad (A16) and named it our new budget pick, removing the discontinued 10th-gen iPad in the process. March 2025: The recently-launched iPad Air M3 has replaced its predecessor as our top overall recommendation. We’ve also made a note regarding the new iPad (A16), which we plan to test in the near future and expect to become our new budget pick. We’ve made a handful of edits elsewhere in the guide to reflect Apple’s latest hardware. January 2025: We’ve lightly edited this guide for clarity. Our recommendations remain the same. October 2024: We've updated our guide to include the new iPad mini 7. June 2024: We’ve touched up this guide to reflect some of the new iPadOS features Apple announced at WWDC, though our picks remain the same. Nathan Ingraham contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-ipads-how-to-pick-the-best-apple-tablet-for-you-150054066.html?src=rss",
          "feed_position": 31,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2024-10/ded6eb30-8fee-11ef-bfcf-f1599e27e076"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/mistral-launches-its-own-ai-studio-for-quick-development-with-its-european",
          "published_at": "Fri, 24 Oct 2025 06:55:00 GMT",
          "title": "Mistral launches its own AI Studio for quick development with its European open source, proprietary models",
          "standfirst": "The next big trend in AI providers appears to be \"studio\" environments on the web that allow users to spin up agents and AI applications within minutes. Case in point, today the well-funded French AI startup Mistral launched its own Mistral AI Studio, a new production platform designed to help enterprises build, observe, and operationalize AI applications at scale atop Mistral&#x27;s growing family of proprietary and open source large language models (LLMs) and multimodal models.It&#x27;s an evolution of its legacy API and AI building platorm, \"Le Platforme,\" initially launched in late 2023, and that brand name is being retired for now. The move comes just days after U.S. rival Google updated its AI Studio, also launched in late 2023, to be easier for non-developers to use and build and deploy apps with natural language, aka \"vibe coding.\"But while Google&#x27;s update appears to target novices who want to tinker around, Mistral appears more fully focused on building an easy-to-use enterprise AI app development and launchpad, which may require some technical knowledge or familiarity with LLMs, but far less than that of a seasoned developer. In other words, those outside the tech team at your enterprise could potentially use this to build and test simple apps, tools, and workflows — all powered by E.U.-native AI models operating on E.U.-based infrastructure. That may be a welcome change for companies concerned about the political situation in the U.S., or who have large operations in Europe and prefer to give their business to homegrown alternatives to U.S. and Chinese tech giants.In addition, Mistral AI Studio appears to offer an easier way for users to customize and fine-tune AI models for use at specific tasks.Branded as “The Production AI Platform,” Mistral&#x27;s AI Studio extends its internal infrastructure, bringing enterprise-grade observability, orchestration, and governance to teams running AI in production.The platform unifies tools for building, evaluating, and deploying AI systems, while giving enterprises flexible control over where and how their models run — in the cloud, on-premise, or self-hosted. Mistral says AI Studio brings the same production discipline that supports its own large-scale systems to external customers, closing the gap between AI prototyping and reliable deployment. It&#x27;s available here with developer documentation here.Extensive Model CatalogAI Studio’s model selector reveals one of the platform’s strongest features: a comprehensive and versioned catalog of Mistral models spanning open-weight, code, multimodal, and transcription domains.Available models include the following, though note that even for the open source ones, users will still be running a Mistral-based inference and paying Mistral for access through its API.ModelLicense TypeNotes / SourceMistral LargeProprietaryMistral’s top-tier closed-weight commercial model (available via API and AI Studio only).Mistral MediumProprietaryMid-range performance, offered via hosted API; no public weights released.Mistral SmallProprietaryLightweight API model; no open weights.Mistral TinyProprietaryCompact hosted model optimized for latency; closed-weight.Open Mistral 7BOpenFully open-weight model (Apache 2.0 license), downloadable on Hugging Face.Open Mixtral 8×7BOpenReleased under Apache 2.0; mixture-of-experts architecture.Open Mixtral 8×22BOpenLarger open-weight MoE model; Apache 2.0 license.Magistral MediumProprietaryNot publicly released; appears only in AI Studio catalog.Magistral SmallProprietarySame; internal or enterprise-only release.Devstral MediumProprietary / LegacyOlder internal development models, no open weights.Devstral SmallProprietary / LegacySame; used for internal evaluation.Ministral 8BOpenOpen-weight model available under Apache 2.0; basis for Mistral Moderation model.Pixtral 12BProprietaryMultimodal (text-image) model; closed-weight, API-only.Pixtral LargeProprietaryLarger multimodal variant; closed-weight.Voxtral SmallProprietarySpeech-to-text/audio model; closed-weight.Voxtral MiniProprietaryLightweight version; closed-weight.Voxtral Mini Transcribe 2507ProprietarySpecialized transcription model; API-only.Codestral 2501OpenOpen-weight code-generation model (Apache 2.0 license, available on Hugging Face).Mistral OCR 2503ProprietaryDocument-text extraction model; closed-weight.This extensive model lineup confirms that AI Studio is both model-rich and model-agnostic, allowing enterprises to test and deploy different configurations according to task complexity, cost targets, or compute environments.Bridging the Prototype-to-Production DivideMistral’s release highlights a common problem in enterprise AI adoption: while organizations are building more prototypes than ever before, few transition into dependable, observable systems. Many teams lack the infrastructure to track model versions, explain regressions, or ensure compliance as models evolve.AI Studio aims to solve that. The platform provides what Mistral calls the “production fabric” for AI — a unified environment that connects creation, observability, and governance into a single operational loop. Its architecture is organized around three core pillars: Observability, Agent Runtime, and AI Registry.1. ObservabilityAI Studio’s Observability layer provides transparency into AI system behavior. Teams can filter and inspect traffic through the Explorer, identify regressions, and build datasets directly from real-world usage. Judges let teams define evaluation logic and score outputs at scale, while Campaigns and Datasets automatically transform production interactions into curated evaluation sets.Metrics and dashboards quantify performance improvements, while lineage tracking connects model outcomes to the exact prompt and dataset versions that produced them. Mistral describes Observability as a way to move AI improvement from intuition to measurement.2. Agent Runtime and RAG supportThe Agent Runtime serves as the execution backbone of AI Studio. Each agent — whether it’s handling a single task or orchestrating a complex multi-step business process — runs within a stateful, fault-tolerant runtime built on Temporal. This architecture ensures reproducibility across long-running or retry-prone tasks and automatically captures execution graphs for auditing and sharing.Every run emits telemetry and evaluation data that feed directly into the Observability layer. The runtime supports hybrid, dedicated, and self-hosted deployments, allowing enterprises to run AI close to their existing systems while maintaining durability and control.While Mistral&#x27;s blog post doesn’t explicitly reference retrieval-augmented generation (RAG), Mistral AI Studio clearly supports it under the hood. Screenshots of the interface show built-in workflows such as RAGWorkflow, RetrievalWorkflow, and IngestionWorkflow, revealing that document ingestion, retrieval, and augmentation are first-class capabilities within the Agent Runtime system. These components allow enterprises to pair Mistral’s language models with their own proprietary or internal data sources, enabling contextualized responses grounded in up-to-date information. By integrating RAG directly into its orchestration and observability stack—but leaving it out of marketing language—Mistral signals that it views retrieval not as a buzzword but as a production primitive: measurable, governed, and auditable like any other AI process.3. AI RegistryThe AI Registry is the system of record for all AI assets — models, datasets, judges, tools, and workflows. It manages lineage, access control, and versioning, enforcing promotion gates and audit trails before deployments.Integrated directly with the Runtime and Observability layers, the Registry provides a unified governance view so teams can trace any output back to its source components.Interface and User ExperienceThe screenshots of Mistral AI Studio show a clean, developer-oriented interface organized around a left-hand navigation bar and a central Playground environment.The Home dashboard features three core action areas — Create, Observe, and Improve — guiding users through model building, monitoring, and fine-tuning workflows.Under Create, users can open the Playground to test prompts or build agents.Observe and Improve link to observability and evaluation modules, some labeled “coming soon,” suggesting staged rollout.The left navigation also includes quick access to API Keys, Batches, Evaluate, Fine-tune, Files, and Documentation, positioning Studio as a full workspace for both development and operations.Inside the Playground, users can select a model, customize parameters such as temperature and max tokens, and enable integrated tools that extend model capabilities.Users can try the Playground for free, but will need to sign up with their phone number to receive an access code.Integrated Tools and CapabilitiesMistral AI Studio includes a growing suite of built-in tools that can be toggled for any session:Code Interpreter — lets the model execute Python code directly within the environment, useful for data analysis, chart generation, or computational reasoning tasks.Image Generation — enables the model to generate images based on user prompts.Web Search — allows real-time information retrieval from the web to supplement model responses.Premium News — provides access to verified news sources via integrated provider partnerships, offering fact-checked context for information retrieval.These tools can be combined with Mistral’s function calling capabilities, letting models call APIs or external functions defined by developers. This means a single agent could, for example, search the web, retrieve verified financial data, run calculations in Python, and generate a chart — all within the same workflow.Beyond Text: Multimodal and Programmatic AIWith the inclusion of Code Interpreter and Image Generation, Mistral AI Studio moves beyond traditional text-based LLM workflows. Developers can use the platform to create agents that write and execute code, analyze uploaded files, or generate visual content — all directly within the same conversational environment.The Web Search and Premium News integrations also extend the model’s reach beyond static data, enabling real-time information retrieval with verified sources. This combination positions AI Studio not just as a playground for experimentation but as a full-stack environment for production AI systems capable of reasoning, coding, and multimodal output.Deployment FlexibilityMistral supports four main deployment models for AI Studio users:Hosted Access via AI Studio — pay-as-you-go APIs for Mistral’s latest models, managed through Studio workspaces.Third-Party Cloud Integration — availability through major cloud providers.Self-Deployment — open-weight models can be deployed on private infrastructure under the Apache 2.0 license, using frameworks such as TensorRT-LLM, vLLM, llama.cpp, or Ollama.Enterprise-Supported Self-Deployment — adds official support for both open and proprietary models, including security and compliance configuration assistance.These options allow enterprises to balance operational control with convenience, running AI wherever their data and governance requirements demand.Safety, Guardrailing, and ModerationAI Studio builds safety features directly into its stack. Enterprises can apply guardrails and moderation filters at both the model and API levels.The Mistral Moderation model, based on Ministral 8B (24.10), classifies text across policy categories such as sexual content, hate and discrimination, violence, self-harm, and PII. A separate system prompt guardrail can be activated to enforce responsible AI behavior, instructing models to “assist with care, respect, and truth” while avoiding harmful or unethical content.Developers can also employ self-reflection prompts, a technique where the model itself classifies outputs against enterprise-defined safety categories like physical harm or fraud. This layered approach gives organizations flexibility in enforcing safety policies while retaining creative or operational control.From Experimentation to Dependable OperationsMistral positions AI Studio as the next phase in enterprise AI maturity. As large language models become more capable and accessible, the company argues, the differentiator will no longer be model performance but the ability to operate AI reliably, safely, and measurably.AI Studio is designed to support that shift. By integrating evaluation, telemetry, version control, and governance into one workspace, it enables teams to manage AI with the same discipline as modern software systems — tracking every change, measuring every improvement, and maintaining full ownership of data and outcomes.In the company’s words, “This is how AI moves from experimentation to dependable operations — secure, observable, and under your control.”Mistral AI Studio is available starting October 24, 2025, as part of a private beta program. Enterprises can sign up on Mistral’s website to access the platform, explore its model catalog, and test observability, runtime, and governance features before general release.",
          "content": "The next big trend in AI providers appears to be \"studio\" environments on the web that allow users to spin up agents and AI applications within minutes. Case in point, today the well-funded French AI startup Mistral launched its own Mistral AI Studio, a new production platform designed to help enterprises build, observe, and operationalize AI applications at scale atop Mistral&#x27;s growing family of proprietary and open source large language models (LLMs) and multimodal models.It&#x27;s an evolution of its legacy API and AI building platorm, \"Le Platforme,\" initially launched in late 2023, and that brand name is being retired for now. The move comes just days after U.S. rival Google updated its AI Studio, also launched in late 2023, to be easier for non-developers to use and build and deploy apps with natural language, aka \"vibe coding.\"But while Google&#x27;s update appears to target novices who want to tinker around, Mistral appears more fully focused on building an easy-to-use enterprise AI app development and launchpad, which may require some technical knowledge or familiarity with LLMs, but far less than that of a seasoned developer. In other words, those outside the tech team at your enterprise could potentially use this to build and test simple apps, tools, and workflows — all powered by E.U.-native AI models operating on E.U.-based infrastructure. That may be a welcome change for companies concerned about the political situation in the U.S., or who have large operations in Europe and prefer to give their business to homegrown alternatives to U.S. and Chinese tech giants.In addition, Mistral AI Studio appears to offer an easier way for users to customize and fine-tune AI models for use at specific tasks.Branded as “The Production AI Platform,” Mistral&#x27;s AI Studio extends its internal infrastructure, bringing enterprise-grade observability, orchestration, and governance to teams running AI in production.The platform unifies tools for building, evaluating, and deploying AI systems, while giving enterprises flexible control over where and how their models run — in the cloud, on-premise, or self-hosted. Mistral says AI Studio brings the same production discipline that supports its own large-scale systems to external customers, closing the gap between AI prototyping and reliable deployment. It&#x27;s available here with developer documentation here.Extensive Model CatalogAI Studio’s model selector reveals one of the platform’s strongest features: a comprehensive and versioned catalog of Mistral models spanning open-weight, code, multimodal, and transcription domains.Available models include the following, though note that even for the open source ones, users will still be running a Mistral-based inference and paying Mistral for access through its API.ModelLicense TypeNotes / SourceMistral LargeProprietaryMistral’s top-tier closed-weight commercial model (available via API and AI Studio only).Mistral MediumProprietaryMid-range performance, offered via hosted API; no public weights released.Mistral SmallProprietaryLightweight API model; no open weights.Mistral TinyProprietaryCompact hosted model optimized for latency; closed-weight.Open Mistral 7BOpenFully open-weight model (Apache 2.0 license), downloadable on Hugging Face.Open Mixtral 8×7BOpenReleased under Apache 2.0; mixture-of-experts architecture.Open Mixtral 8×22BOpenLarger open-weight MoE model; Apache 2.0 license.Magistral MediumProprietaryNot publicly released; appears only in AI Studio catalog.Magistral SmallProprietarySame; internal or enterprise-only release.Devstral MediumProprietary / LegacyOlder internal development models, no open weights.Devstral SmallProprietary / LegacySame; used for internal evaluation.Ministral 8BOpenOpen-weight model available under Apache 2.0; basis for Mistral Moderation model.Pixtral 12BProprietaryMultimodal (text-image) model; closed-weight, API-only.Pixtral LargeProprietaryLarger multimodal variant; closed-weight.Voxtral SmallProprietarySpeech-to-text/audio model; closed-weight.Voxtral MiniProprietaryLightweight version; closed-weight.Voxtral Mini Transcribe 2507ProprietarySpecialized transcription model; API-only.Codestral 2501OpenOpen-weight code-generation model (Apache 2.0 license, available on Hugging Face).Mistral OCR 2503ProprietaryDocument-text extraction model; closed-weight.This extensive model lineup confirms that AI Studio is both model-rich and model-agnostic, allowing enterprises to test and deploy different configurations according to task complexity, cost targets, or compute environments.Bridging the Prototype-to-Production DivideMistral’s release highlights a common problem in enterprise AI adoption: while organizations are building more prototypes than ever before, few transition into dependable, observable systems. Many teams lack the infrastructure to track model versions, explain regressions, or ensure compliance as models evolve.AI Studio aims to solve that. The platform provides what Mistral calls the “production fabric” for AI — a unified environment that connects creation, observability, and governance into a single operational loop. Its architecture is organized around three core pillars: Observability, Agent Runtime, and AI Registry.1. ObservabilityAI Studio’s Observability layer provides transparency into AI system behavior. Teams can filter and inspect traffic through the Explorer, identify regressions, and build datasets directly from real-world usage. Judges let teams define evaluation logic and score outputs at scale, while Campaigns and Datasets automatically transform production interactions into curated evaluation sets.Metrics and dashboards quantify performance improvements, while lineage tracking connects model outcomes to the exact prompt and dataset versions that produced them. Mistral describes Observability as a way to move AI improvement from intuition to measurement.2. Agent Runtime and RAG supportThe Agent Runtime serves as the execution backbone of AI Studio. Each agent — whether it’s handling a single task or orchestrating a complex multi-step business process — runs within a stateful, fault-tolerant runtime built on Temporal. This architecture ensures reproducibility across long-running or retry-prone tasks and automatically captures execution graphs for auditing and sharing.Every run emits telemetry and evaluation data that feed directly into the Observability layer. The runtime supports hybrid, dedicated, and self-hosted deployments, allowing enterprises to run AI close to their existing systems while maintaining durability and control.While Mistral&#x27;s blog post doesn’t explicitly reference retrieval-augmented generation (RAG), Mistral AI Studio clearly supports it under the hood. Screenshots of the interface show built-in workflows such as RAGWorkflow, RetrievalWorkflow, and IngestionWorkflow, revealing that document ingestion, retrieval, and augmentation are first-class capabilities within the Agent Runtime system. These components allow enterprises to pair Mistral’s language models with their own proprietary or internal data sources, enabling contextualized responses grounded in up-to-date information. By integrating RAG directly into its orchestration and observability stack—but leaving it out of marketing language—Mistral signals that it views retrieval not as a buzzword but as a production primitive: measurable, governed, and auditable like any other AI process.3. AI RegistryThe AI Registry is the system of record for all AI assets — models, datasets, judges, tools, and workflows. It manages lineage, access control, and versioning, enforcing promotion gates and audit trails before deployments.Integrated directly with the Runtime and Observability layers, the Registry provides a unified governance view so teams can trace any output back to its source components.Interface and User ExperienceThe screenshots of Mistral AI Studio show a clean, developer-oriented interface organized around a left-hand navigation bar and a central Playground environment.The Home dashboard features three core action areas — Create, Observe, and Improve — guiding users through model building, monitoring, and fine-tuning workflows.Under Create, users can open the Playground to test prompts or build agents.Observe and Improve link to observability and evaluation modules, some labeled “coming soon,” suggesting staged rollout.The left navigation also includes quick access to API Keys, Batches, Evaluate, Fine-tune, Files, and Documentation, positioning Studio as a full workspace for both development and operations.Inside the Playground, users can select a model, customize parameters such as temperature and max tokens, and enable integrated tools that extend model capabilities.Users can try the Playground for free, but will need to sign up with their phone number to receive an access code.Integrated Tools and CapabilitiesMistral AI Studio includes a growing suite of built-in tools that can be toggled for any session:Code Interpreter — lets the model execute Python code directly within the environment, useful for data analysis, chart generation, or computational reasoning tasks.Image Generation — enables the model to generate images based on user prompts.Web Search — allows real-time information retrieval from the web to supplement model responses.Premium News — provides access to verified news sources via integrated provider partnerships, offering fact-checked context for information retrieval.These tools can be combined with Mistral’s function calling capabilities, letting models call APIs or external functions defined by developers. This means a single agent could, for example, search the web, retrieve verified financial data, run calculations in Python, and generate a chart — all within the same workflow.Beyond Text: Multimodal and Programmatic AIWith the inclusion of Code Interpreter and Image Generation, Mistral AI Studio moves beyond traditional text-based LLM workflows. Developers can use the platform to create agents that write and execute code, analyze uploaded files, or generate visual content — all directly within the same conversational environment.The Web Search and Premium News integrations also extend the model’s reach beyond static data, enabling real-time information retrieval with verified sources. This combination positions AI Studio not just as a playground for experimentation but as a full-stack environment for production AI systems capable of reasoning, coding, and multimodal output.Deployment FlexibilityMistral supports four main deployment models for AI Studio users:Hosted Access via AI Studio — pay-as-you-go APIs for Mistral’s latest models, managed through Studio workspaces.Third-Party Cloud Integration — availability through major cloud providers.Self-Deployment — open-weight models can be deployed on private infrastructure under the Apache 2.0 license, using frameworks such as TensorRT-LLM, vLLM, llama.cpp, or Ollama.Enterprise-Supported Self-Deployment — adds official support for both open and proprietary models, including security and compliance configuration assistance.These options allow enterprises to balance operational control with convenience, running AI wherever their data and governance requirements demand.Safety, Guardrailing, and ModerationAI Studio builds safety features directly into its stack. Enterprises can apply guardrails and moderation filters at both the model and API levels.The Mistral Moderation model, based on Ministral 8B (24.10), classifies text across policy categories such as sexual content, hate and discrimination, violence, self-harm, and PII. A separate system prompt guardrail can be activated to enforce responsible AI behavior, instructing models to “assist with care, respect, and truth” while avoiding harmful or unethical content.Developers can also employ self-reflection prompts, a technique where the model itself classifies outputs against enterprise-defined safety categories like physical harm or fraud. This layered approach gives organizations flexibility in enforcing safety policies while retaining creative or operational control.From Experimentation to Dependable OperationsMistral positions AI Studio as the next phase in enterprise AI maturity. As large language models become more capable and accessible, the company argues, the differentiator will no longer be model performance but the ability to operate AI reliably, safely, and measurably.AI Studio is designed to support that shift. By integrating evaluation, telemetry, version control, and governance into one workspace, it enables teams to manage AI with the same discipline as modern software systems — tracking every change, measuring every improvement, and maintaining full ownership of data and outcomes.In the company’s words, “This is how AI moves from experimentation to dependable operations — secure, observable, and under your control.”Mistral AI Studio is available starting October 24, 2025, as part of a private beta program. Enterprises can sign up on Mistral’s website to access the platform, explore its model catalog, and test observability, runtime, and governance features before general release.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1fMUbtU7YznYAg9NA7yB60/80213a82826047e09229046ab093081a/cfr0z3n_top_down_view_of_diverse_modern_office_workers_at_desks_ef397a8f-5455-47b1-a73e-990ad12aedf1.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/inside-ring-1t-ant-engineers-solve-reinforcement-learning-bottlenecks-at",
          "published_at": "Fri, 24 Oct 2025 04:00:00 GMT",
          "title": "Inside Ring-1T: Ant engineers solve reinforcement learning bottlenecks at trillion scale",
          "standfirst": "China’s Ant Group, an affiliate of Alibaba, detailed technical information around its new model, Ring-1T, which the company said is “the first open-source reasoning model with one trillion total parameters.”Ring-1T aims to compete with other reasoning models like GPT-5 and the o-series from OpenAI, as well as Google’s Gemini 2.5. With the new release of the latest model, Ant extends the geopolitical debate over who will dominate the AI race: China or the US. Ant Group said Ring-1T is optimized for mathematical and logical problems, code generation and scientific problem-solving. “With approximately 50 billion activated parameters per token, Ring-1T achieves state-of-the-art performance across multiple challenging benchmarks — despite relying solely on natural language reasoning capabilities,” Ant said in a paper.Ring-1T, which was first released on preview in September, adopts the same architecture as Ling 2.0 and trained on the Ling-1T-base model the company released earlier this month. Ant said this allows the model to support up to 128,000 tokens.To train a model as large as Ring-1T, researchers had to develop new methods to scale reinforcement learning (RL).New methods of training Ant Group developed three “interconnected innovations” to support the RL and training of Ring-1T, a challenge given the model&#x27;s size and the typically large compute requirements it entails. These three are IcePop, C3PO++ and ASystem.IcePop removes noisy gradient updates to stabilize training without slowing inference. It helps eliminate catastrophic training-inference misalignment in RL. The researchers noted that when training models, particularly those using a mixture-of-experts (MoE) architecture like Ring-1T, there can often be a discrepancy in probability calculations. “This problem is particularly pronounced in the training of MoE models with RL due to the inherent usage of the dynamic routing mechanism. Additionally, in long CoT settings, these discrepancies can gradually accumulate across iterations and become further amplified,” the researchers said. IcePop “suppresses unstable training updates through double-sided masking calibration.”The next new method the researchers had to develop is C3PO++, an improved version of the C3PO system that Ant previously established. The method manages how Ring-1T and other extra-large parameter models generate and process training examples, or what they call rollouts, so GPUs don’t sit idle. The way it works would break work in rollouts into pieces to process in parallel. One group is the inference pool, which generates new data, and the other is the training pool, which collects results to update the model. C3PO++ creates a token budget to control how much data is processed, ensuring GPUs are used efficiently.The last new method, ASystem, adopts a SingleController+SPMD (Single Program, Multiple Data) architecture to enable asynchronous operations. Benchmark resultsAnt pointed Ring-1T to benchmarks measuring performance in mathematics, coding, logical reasoning and general tasks. They tested it against models such as DeepSeek-V3.1-Terminus-Thinking, Qwen-35B-A22B-Thinking-2507, Gemini 2.5 Pro and GPT-5 Thinking. In benchmark testing, Ring-1T performed strongly, coming in second to OpenAI’s GPT-5 across most benchmarks. Ant said that Ring-1T showed the best performance among all the open-weight models it tested. The model posted a 93.4% score on the AIME 25 leaderboard, second only to GPT-5. In coding, Ring-1T outperformed both DeepSeek and Qwen.“It indicates that our carefully synthesized dataset shapes Ring-1T’s robust performance on programming applications, which forms a strong foundation for future endeavors on agentic applications,” the company said. Ring-1T shows how much Chinese companies are investing in models Ring-1T is just the latest model from China aiming to dethrone GPT-5 and Gemini. Chinese companies have been releasing impressive models at a quick pace since the surprise launch of DeepSeek in January. Ant&#x27;s parent company, Alibaba, recently released Qwen3-Omni, a multimodal model that natively unifies text, image, audio and video. DeepSeek has also continued to improve its models and earlier this month, launched DeepSeek-OCR. This new model reimagines how models process information. With Ring-1T and Ant’s development of new methods to train and scale extra-large models, the battle for AI dominance between the US and China continues to heat up.",
          "content": "China’s Ant Group, an affiliate of Alibaba, detailed technical information around its new model, Ring-1T, which the company said is “the first open-source reasoning model with one trillion total parameters.”Ring-1T aims to compete with other reasoning models like GPT-5 and the o-series from OpenAI, as well as Google’s Gemini 2.5. With the new release of the latest model, Ant extends the geopolitical debate over who will dominate the AI race: China or the US. Ant Group said Ring-1T is optimized for mathematical and logical problems, code generation and scientific problem-solving. “With approximately 50 billion activated parameters per token, Ring-1T achieves state-of-the-art performance across multiple challenging benchmarks — despite relying solely on natural language reasoning capabilities,” Ant said in a paper.Ring-1T, which was first released on preview in September, adopts the same architecture as Ling 2.0 and trained on the Ling-1T-base model the company released earlier this month. Ant said this allows the model to support up to 128,000 tokens.To train a model as large as Ring-1T, researchers had to develop new methods to scale reinforcement learning (RL).New methods of training Ant Group developed three “interconnected innovations” to support the RL and training of Ring-1T, a challenge given the model&#x27;s size and the typically large compute requirements it entails. These three are IcePop, C3PO++ and ASystem.IcePop removes noisy gradient updates to stabilize training without slowing inference. It helps eliminate catastrophic training-inference misalignment in RL. The researchers noted that when training models, particularly those using a mixture-of-experts (MoE) architecture like Ring-1T, there can often be a discrepancy in probability calculations. “This problem is particularly pronounced in the training of MoE models with RL due to the inherent usage of the dynamic routing mechanism. Additionally, in long CoT settings, these discrepancies can gradually accumulate across iterations and become further amplified,” the researchers said. IcePop “suppresses unstable training updates through double-sided masking calibration.”The next new method the researchers had to develop is C3PO++, an improved version of the C3PO system that Ant previously established. The method manages how Ring-1T and other extra-large parameter models generate and process training examples, or what they call rollouts, so GPUs don’t sit idle. The way it works would break work in rollouts into pieces to process in parallel. One group is the inference pool, which generates new data, and the other is the training pool, which collects results to update the model. C3PO++ creates a token budget to control how much data is processed, ensuring GPUs are used efficiently.The last new method, ASystem, adopts a SingleController+SPMD (Single Program, Multiple Data) architecture to enable asynchronous operations. Benchmark resultsAnt pointed Ring-1T to benchmarks measuring performance in mathematics, coding, logical reasoning and general tasks. They tested it against models such as DeepSeek-V3.1-Terminus-Thinking, Qwen-35B-A22B-Thinking-2507, Gemini 2.5 Pro and GPT-5 Thinking. In benchmark testing, Ring-1T performed strongly, coming in second to OpenAI’s GPT-5 across most benchmarks. Ant said that Ring-1T showed the best performance among all the open-weight models it tested. The model posted a 93.4% score on the AIME 25 leaderboard, second only to GPT-5. In coding, Ring-1T outperformed both DeepSeek and Qwen.“It indicates that our carefully synthesized dataset shapes Ring-1T’s robust performance on programming applications, which forms a strong foundation for future endeavors on agentic applications,” the company said. Ring-1T shows how much Chinese companies are investing in models Ring-1T is just the latest model from China aiming to dethrone GPT-5 and Gemini. Chinese companies have been releasing impressive models at a quick pace since the surprise launch of DeepSeek in January. Ant&#x27;s parent company, Alibaba, recently released Qwen3-Omni, a multimodal model that natively unifies text, image, audio and video. DeepSeek has also continued to improve its models and earlier this month, launched DeepSeek-OCR. This new model reimagines how models process information. With Ring-1T and Ant’s development of new methods to train and scale extra-large models, the battle for AI dominance between the US and China continues to heat up.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1ZZDt515lczBZYmiAPxjJm/323c164f6ce43f0bac50cb5d392d747a/crimedy7_illustration_of_ants_building_a_robot_but_the_robot__62e35f6c-d1f6-47e9-bf3c-393e15b45361_1.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html",
          "published_at": "Fri, 24 Oct 2025 00:00:35 +0000",
          "title": "The best VPN service for 2025",
          "standfirst": "As frustrating as it is that governments and businesses are running roughshod over our online freedoms, at least we have plenty of good VPNs to choose from to keep us protected online. There are so many fast, intelligently designed, full-featured and affordable services on the market that the biggest problem is picking one. For any use case, you can bet at least two providers will be neck-and-neck for first place.On the other hand, the VPN world is still the Wild West in some ways. It's easy enough to slap a cheap VPN together that the market is flooded with low-quality apps that put more money into advertising than infrastructure. They may look good, but it's all styrofoam under the hood.I built this list of the best VPNs after intensive testing to help you reorient your focus on the providers that actually deserve your time and money. Which one truly fits your needs is dependent on who you are and what you do online, but if you pick any of my seven recommendations, you can't go too far wrong.For each VPN on this list, I've shared which platforms it works on, how much it cuts into your download speed, where it offers servers, what other features are included and how much the best available deal costs. At the end, I'll list some honorable and dishonorable mentions, then answer some of the most common questions I hear about VPNs.Editor's note: This list has been completely overhauled and rewritten as of September 2025. We intend to revisit this list every three months at a minimum, at which time our picks may be adjusted based on changes in pricing, features, testing results and other factors. Table of contents Best VPNs for 2025 Other VPNs we tested What to look for in a VPN VPN FAQs Best VPNs for 2025 Other VPNs we tested The VPNs in this section didn't crack our top list above, but we're summarizing them here so you can see their positives and negatives as of the time of our evaluation. Windscribe Windscribe is another well-known free VPN supported by paid subscriptions. In many ways, it takes the best from both Mullvad and Proton VPN, with the former's no-nonsense privacy and the latter's healthy free plan. Without paying, you can connect to 10 of Windscribe's server locations on an unlimited number of devices at once. Unfortunately, Windscribe didn't copy the most important part of Proton VPN's free plan — the unlimited data. You're only allowed to use 10GB per month, which isn't enough for regular streaming. It's also committed to a cramped and headache-inducing user interface that stands out from the crowd in all the worst ways. Private Internet Access Private Internet Access (PIA VPN) has a deeply annoying name — I assume whoever invented it also likes to hop in their Toyota Forward Motion to grab a gallon of Sustaining Cow Extract from the grocery store — but it's a worthwhile VPN whose pricing provides incredible value. Its monthly and yearly plans are good enough, but its three-year plan is the clincher. Not only is it longer than average, but you can continue to renew at the three-year level, so you won't see an unpleasant price jump the first time you re-up. PIA's apps have a dark UI reminiscent of Proton VPN, which is always a good thing. It also supports port forwarding, custom DNS and the use of a SOCKS5 or Shadowsocks proxy as a second step in the VPN connection. You can even set the maximum data packet size to help out a struggling connection, as I cover in my full PIA VPN review. The downside is that your connection will struggle a lot. While well-designed, PIA's apps have a tendency to lag. In my most recent battery of tests, it dragged oddly on my internet in ways that weren't directly reflected in the speed tests. It's also not always capable of unblocking streaming services in other countries, and while its server network offers 152 IP address options in 84 countries, it's heavily bulked out by virtual locations. TunnelBear TunnelBear has a decent interface, which its target audience of VPN beginners will find very easy to use. Its speeds are perfectly good too, and I appreciate the depth and breadth of its transparency reports. But it's far too limited overall, with few extra features, less than 50 server locations and a free plan that caps data at 2GB per month. VyprVPN VyprVPN often flies under the radar, but it has some of the best apps in the business and a very good security record (there was a breach in 2023, but it didn't crack the VPN encryption itself). It's also got a verified privacy policy, a solid jurisdiction and runs every connection through an in-house DNS to prevent leaks. Despite all that, it didn't make the top seven because its connection speeds aren't up to scratch — you'll likely notice a bigger slowdown than average. It also has a troubling history of wild, seemingly experimental swings in its pricing and simultaneous connection limits. Norton VPN Norton VPN is part of the Norton 360 package that includes the well-known antivirus software and other security apps. It's a nice bonus if you use Norton already, but as a standalone VPN, it falls short. My tests repeatedly showed it dropping encryption and revealing my IP address whenever I switched servers, and not all of its locations managed to unblock Netflix. This isn't to say Norton VPN is terrible. It has a fairly large server network, user-friendly apps and some cool features like an IP rotator. It also recently revamped its OpenVPN infrastructure to improve speeds on Windows. But you probably won't find those things sufficient to balance out significant speed drops on other platforms or poorly written FAQs. I especially advise against Norton VPN for Apple users, as its Mac and iPhone apps are much more limited than their Windows and Android counterparts. What to look for in a VPN Choosing a VPN can quickly get you mired in analysis paralysis. We're here to help, but since only you know your particular needs, you should know the major red and green flags so you can make the final call yourself. Every reputable VPN provider offers a free trial or refund guarantee you can use to run the tests below. Compatibility: First, make sure your VPN works on all the platforms you plan to use it on. Most VPNs have apps for Windows, Mac, Android and iOS, but those apps aren't always created equal — check that the app for your chosen OS is user-friendly and has all the features you need. Speed: Use a speed testing app to see how fast your internet is before and after connecting to the VPN (I use Ookla's speedtest.net). To check security, look up your IP address while connected to a VPN server and see if it's actually changed your virtual location. Be sure it's using expert-vetted protocols like OpenVPN, WireGuard and IKEv2. Try connecting to streaming services and seeing whether the VPN changes the available content. Background: Do some outside research into the VPN's origins, especially its parent company, privacy policy and any past incidents. It's a dealbreaker if you can't figure out where the VPN is headquartered (which indicates a lax approach to transparency) or if it seems to have never passed a real third-party audit. Server network: Look at the server network to make sure the VPN has locations near you and in any countries where you'll want an IP address — e.g. if you need a VPN to unblock Canadian Netflix, look for multiple server locations in Canada. Customer Service: I also advise testing the customer support options by looking for the answer to a straightforward question. If phone support (versus email and chat) is important to you, make sure to prioritize that — and make sure it's available at convenient times in your timezone. Pricing: Finally, check prices. See if the VPN is affordable and decide whether you're comfortable taking a long-term subscription for better savings. If you do get a multi-year plan, check what price it will renew at, since many of the cheapest subscriptions are only introductory deals. VPN FAQs To wrap up, let's answer some of the most common questions we get about VPNs. Feel free to get in touch if you have a query I don't cover here. What is a VPN? VPN stands for virtual private network. There are a few different types of VPNs, but for this list, we're talking about commercial services that let individual users access the internet with an assumed identity. Whenever you get online, you're assigned an IP address — a digital nametag that tells websites where to send the information you request. For an IP address to work, it needs to be unique, which means it's possible to create a record of what an individual does online. When you use a VPN, all the data you send to the internet goes through one of the VPN's servers before heading to its final destination. The VPN encrypts the connection between your computer and its server so the data won't trace back to you. Any website, ISP or third party that cares to look will only see the VPN's IP address, not yours. What are some things VPNs are used for? The three main use cases for a commercial VPN are security, privacy and entertainment. Using a VPN conceals your real IP address from anyone who might want to use it for nefarious purposes like cyberstalking, DDoS attacks or deducing your real location. It also keeps your ISP from profiling you for ads based on where you live or what you do online. One side effect of borrowing a VPN's IP address is that you can make it appear as though your connection is coming from another country. You can use this to access streaming content and platforms that are only available in certain regions due to copyright. Changing your location can even get you better prices when shopping online. Location spoofing can also be used to get online in countries that censor internet access, like China and Russia, as well as certain US states or countries — like the UK — that are adding barriers like age-gating to previously unfettered online access. All you have to do is connect to a neighboring country (or locality) where the internet isn't blocked. If you plan to do this while traveling, make sure you have the VPN downloaded before you go, as some nations prevent you from even loading a VPN's homepage. Make sure you check with local laws regarding the legality of VPN use as well — just because your VPN traffic is encrypted doesn't mean that authorities can't detect that it's being used in a given location. Are VPNs worth it? Whether a VPN is worth the price depends on how much you value those three use cases above. It's no secret that your personal information is profitable for a lot of people, from illicit hackers to corporations to law enforcement. A VPN will not make you completely anonymous, nor is it a license to commit crimes (see the next question) but it will give you a lot more control over what you transmit to the world. With entertainment, the value is even clearer. You can use a VPN to fight back against streaming balkanization by getting more shows and movies out of a single platform — for example, a lot of shows that have been kicked off American Netflix are still on Netflix in other countries. What information does a VPN hide? A VPN does not make it impossible for you to be unmasked or taken advantage of online. It prevents you from passively leaking information, keeps your IP address undiscoverable on public wi-fi networks and gets you around online censorship. However, if you share personal information of your own volition, there's nothing the VPN can do. If you reveal your password in a social media post or click a link in a phishing email, that information bypasses the VPN. Likewise, if you do anything sensitive while logged into an account, the account holder will have that information even if you're using a VPN. A VPN is a critical part of your online security, but it can't do the whole job by itself. Healthy passwords, malware scanners, private search engines and common sense all have roles to play. Never forget, too, that using a VPN means trusting the VPN provider with access to information that's concealed from everyone else — make sure you trust the privacy policy before signing up. Are VPNs safe? As far as we can determine, all the VPNs recommended in this story are safe to use. As with anything you subscribe to online, due diligence is important, but there's very little inherent risk; generally, the worst thing a bad VPN will do is fail to work, leaving you no worse off than before. There are some VPNs (usually offered for free) that transmit malware, so always make sure to look up any complaints or warnings about a service before you download it. Can you get a VPN on your phone? Absolutely — almost every VPN has apps for both desktop and mobile devices. A good VPN will redesign its app to be mobile-friendly without dropping too many features. Both iOS and Android natively support VPN connections, so you're free to choose whichever provider you like. What about Google's One VPN? Google One VPN was, as you might expect, a VPN provided by Google. It was launched in 2020 for Google One subscribers and discontinued in 2024 due to lack of use. If you really want a Google VPN, you can still get one if you have certain Pixel models or if you're a Google Fi subscriber. That said, I don't recommend using a VPN from Google even if you do still have access to one. Google is one of the worst big tech companies at protecting user privacy. While its VPN might not leak, I wouldn't trust it to guard your sensitive information.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html?src=rss",
          "content": "As frustrating as it is that governments and businesses are running roughshod over our online freedoms, at least we have plenty of good VPNs to choose from to keep us protected online. There are so many fast, intelligently designed, full-featured and affordable services on the market that the biggest problem is picking one. For any use case, you can bet at least two providers will be neck-and-neck for first place.On the other hand, the VPN world is still the Wild West in some ways. It's easy enough to slap a cheap VPN together that the market is flooded with low-quality apps that put more money into advertising than infrastructure. They may look good, but it's all styrofoam under the hood.I built this list of the best VPNs after intensive testing to help you reorient your focus on the providers that actually deserve your time and money. Which one truly fits your needs is dependent on who you are and what you do online, but if you pick any of my seven recommendations, you can't go too far wrong.For each VPN on this list, I've shared which platforms it works on, how much it cuts into your download speed, where it offers servers, what other features are included and how much the best available deal costs. At the end, I'll list some honorable and dishonorable mentions, then answer some of the most common questions I hear about VPNs.Editor's note: This list has been completely overhauled and rewritten as of September 2025. We intend to revisit this list every three months at a minimum, at which time our picks may be adjusted based on changes in pricing, features, testing results and other factors. Table of contents Best VPNs for 2025 Other VPNs we tested What to look for in a VPN VPN FAQs Best VPNs for 2025 Other VPNs we tested The VPNs in this section didn't crack our top list above, but we're summarizing them here so you can see their positives and negatives as of the time of our evaluation. Windscribe Windscribe is another well-known free VPN supported by paid subscriptions. In many ways, it takes the best from both Mullvad and Proton VPN, with the former's no-nonsense privacy and the latter's healthy free plan. Without paying, you can connect to 10 of Windscribe's server locations on an unlimited number of devices at once. Unfortunately, Windscribe didn't copy the most important part of Proton VPN's free plan — the unlimited data. You're only allowed to use 10GB per month, which isn't enough for regular streaming. It's also committed to a cramped and headache-inducing user interface that stands out from the crowd in all the worst ways. Private Internet Access Private Internet Access (PIA VPN) has a deeply annoying name — I assume whoever invented it also likes to hop in their Toyota Forward Motion to grab a gallon of Sustaining Cow Extract from the grocery store — but it's a worthwhile VPN whose pricing provides incredible value. Its monthly and yearly plans are good enough, but its three-year plan is the clincher. Not only is it longer than average, but you can continue to renew at the three-year level, so you won't see an unpleasant price jump the first time you re-up. PIA's apps have a dark UI reminiscent of Proton VPN, which is always a good thing. It also supports port forwarding, custom DNS and the use of a SOCKS5 or Shadowsocks proxy as a second step in the VPN connection. You can even set the maximum data packet size to help out a struggling connection, as I cover in my full PIA VPN review. The downside is that your connection will struggle a lot. While well-designed, PIA's apps have a tendency to lag. In my most recent battery of tests, it dragged oddly on my internet in ways that weren't directly reflected in the speed tests. It's also not always capable of unblocking streaming services in other countries, and while its server network offers 152 IP address options in 84 countries, it's heavily bulked out by virtual locations. TunnelBear TunnelBear has a decent interface, which its target audience of VPN beginners will find very easy to use. Its speeds are perfectly good too, and I appreciate the depth and breadth of its transparency reports. But it's far too limited overall, with few extra features, less than 50 server locations and a free plan that caps data at 2GB per month. VyprVPN VyprVPN often flies under the radar, but it has some of the best apps in the business and a very good security record (there was a breach in 2023, but it didn't crack the VPN encryption itself). It's also got a verified privacy policy, a solid jurisdiction and runs every connection through an in-house DNS to prevent leaks. Despite all that, it didn't make the top seven because its connection speeds aren't up to scratch — you'll likely notice a bigger slowdown than average. It also has a troubling history of wild, seemingly experimental swings in its pricing and simultaneous connection limits. Norton VPN Norton VPN is part of the Norton 360 package that includes the well-known antivirus software and other security apps. It's a nice bonus if you use Norton already, but as a standalone VPN, it falls short. My tests repeatedly showed it dropping encryption and revealing my IP address whenever I switched servers, and not all of its locations managed to unblock Netflix. This isn't to say Norton VPN is terrible. It has a fairly large server network, user-friendly apps and some cool features like an IP rotator. It also recently revamped its OpenVPN infrastructure to improve speeds on Windows. But you probably won't find those things sufficient to balance out significant speed drops on other platforms or poorly written FAQs. I especially advise against Norton VPN for Apple users, as its Mac and iPhone apps are much more limited than their Windows and Android counterparts. What to look for in a VPN Choosing a VPN can quickly get you mired in analysis paralysis. We're here to help, but since only you know your particular needs, you should know the major red and green flags so you can make the final call yourself. Every reputable VPN provider offers a free trial or refund guarantee you can use to run the tests below. Compatibility: First, make sure your VPN works on all the platforms you plan to use it on. Most VPNs have apps for Windows, Mac, Android and iOS, but those apps aren't always created equal — check that the app for your chosen OS is user-friendly and has all the features you need. Speed: Use a speed testing app to see how fast your internet is before and after connecting to the VPN (I use Ookla's speedtest.net). To check security, look up your IP address while connected to a VPN server and see if it's actually changed your virtual location. Be sure it's using expert-vetted protocols like OpenVPN, WireGuard and IKEv2. Try connecting to streaming services and seeing whether the VPN changes the available content. Background: Do some outside research into the VPN's origins, especially its parent company, privacy policy and any past incidents. It's a dealbreaker if you can't figure out where the VPN is headquartered (which indicates a lax approach to transparency) or if it seems to have never passed a real third-party audit. Server network: Look at the server network to make sure the VPN has locations near you and in any countries where you'll want an IP address — e.g. if you need a VPN to unblock Canadian Netflix, look for multiple server locations in Canada. Customer Service: I also advise testing the customer support options by looking for the answer to a straightforward question. If phone support (versus email and chat) is important to you, make sure to prioritize that — and make sure it's available at convenient times in your timezone. Pricing: Finally, check prices. See if the VPN is affordable and decide whether you're comfortable taking a long-term subscription for better savings. If you do get a multi-year plan, check what price it will renew at, since many of the cheapest subscriptions are only introductory deals. VPN FAQs To wrap up, let's answer some of the most common questions we get about VPNs. Feel free to get in touch if you have a query I don't cover here. What is a VPN? VPN stands for virtual private network. There are a few different types of VPNs, but for this list, we're talking about commercial services that let individual users access the internet with an assumed identity. Whenever you get online, you're assigned an IP address — a digital nametag that tells websites where to send the information you request. For an IP address to work, it needs to be unique, which means it's possible to create a record of what an individual does online. When you use a VPN, all the data you send to the internet goes through one of the VPN's servers before heading to its final destination. The VPN encrypts the connection between your computer and its server so the data won't trace back to you. Any website, ISP or third party that cares to look will only see the VPN's IP address, not yours. What are some things VPNs are used for? The three main use cases for a commercial VPN are security, privacy and entertainment. Using a VPN conceals your real IP address from anyone who might want to use it for nefarious purposes like cyberstalking, DDoS attacks or deducing your real location. It also keeps your ISP from profiling you for ads based on where you live or what you do online. One side effect of borrowing a VPN's IP address is that you can make it appear as though your connection is coming from another country. You can use this to access streaming content and platforms that are only available in certain regions due to copyright. Changing your location can even get you better prices when shopping online. Location spoofing can also be used to get online in countries that censor internet access, like China and Russia, as well as certain US states or countries — like the UK — that are adding barriers like age-gating to previously unfettered online access. All you have to do is connect to a neighboring country (or locality) where the internet isn't blocked. If you plan to do this while traveling, make sure you have the VPN downloaded before you go, as some nations prevent you from even loading a VPN's homepage. Make sure you check with local laws regarding the legality of VPN use as well — just because your VPN traffic is encrypted doesn't mean that authorities can't detect that it's being used in a given location. Are VPNs worth it? Whether a VPN is worth the price depends on how much you value those three use cases above. It's no secret that your personal information is profitable for a lot of people, from illicit hackers to corporations to law enforcement. A VPN will not make you completely anonymous, nor is it a license to commit crimes (see the next question) but it will give you a lot more control over what you transmit to the world. With entertainment, the value is even clearer. You can use a VPN to fight back against streaming balkanization by getting more shows and movies out of a single platform — for example, a lot of shows that have been kicked off American Netflix are still on Netflix in other countries. What information does a VPN hide? A VPN does not make it impossible for you to be unmasked or taken advantage of online. It prevents you from passively leaking information, keeps your IP address undiscoverable on public wi-fi networks and gets you around online censorship. However, if you share personal information of your own volition, there's nothing the VPN can do. If you reveal your password in a social media post or click a link in a phishing email, that information bypasses the VPN. Likewise, if you do anything sensitive while logged into an account, the account holder will have that information even if you're using a VPN. A VPN is a critical part of your online security, but it can't do the whole job by itself. Healthy passwords, malware scanners, private search engines and common sense all have roles to play. Never forget, too, that using a VPN means trusting the VPN provider with access to information that's concealed from everyone else — make sure you trust the privacy policy before signing up. Are VPNs safe? As far as we can determine, all the VPNs recommended in this story are safe to use. As with anything you subscribe to online, due diligence is important, but there's very little inherent risk; generally, the worst thing a bad VPN will do is fail to work, leaving you no worse off than before. There are some VPNs (usually offered for free) that transmit malware, so always make sure to look up any complaints or warnings about a service before you download it. Can you get a VPN on your phone? Absolutely — almost every VPN has apps for both desktop and mobile devices. A good VPN will redesign its app to be mobile-friendly without dropping too many features. Both iOS and Android natively support VPN connections, so you're free to choose whichever provider you like. What about Google's One VPN? Google One VPN was, as you might expect, a VPN provided by Google. It was launched in 2020 for Google One subscribers and discontinued in 2024 due to lack of use. If you really want a Google VPN, you can still get one if you have certain Pixel models or if you're a Google Fi subscriber. That said, I don't recommend using a VPN from Google even if you do still have access to one. Google is one of the worst big tech companies at protecting user privacy. While its VPN might not leak, I wouldn't trust it to guard your sensitive information.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/openai-launches-company-knowledge-in-chatgpt-letting-you-access-your-firms",
          "published_at": "Thu, 23 Oct 2025 22:19:00 GMT",
          "title": "OpenAI launches company knowledge in ChatGPT, letting you access your firm's data from Google Drive, Slack, GitHub",
          "standfirst": "Is the Google Search for internal enterprise knowledge finally here...but from OpenAI? It certainly seems that way. Today, OpenAI has launched company knowledge in ChatGPT, a major new capability for subscribers to ChatGPT&#x27;s paid Business, Enterprise, and Edu plans that lets them call up their company&#x27;s data directly from third-party workplace apps including Slack, SharePoint, Google Drive, Gmail, GitHub, HubSpot and combine it in ChatGPT outputs to them. As OpenAI&#x27;s CEO of Applications Fidji Simo put it in a post on the social network X: \"it brings all the context from your apps (Slack, Google Drive, GitHub, etc) together in ChatGPT so you can get answers that are specific to your business.\"Intriguingly, OpenAI&#x27;s blog post on the feature states that is \"powered by a version of GPT‑5 that’s trained to look across multiple sources to give more comprehensive and accurate answers,\" which sounds to me like a new fine-tuned version of the model family the company released back in August, though there are no additional details on how it was trained or its size, techniques, etc.OpenAI tells VentureBeat it&#x27;s a version of GPT-5 that specifically powers company knowledge in ChatGPT Business, Enterprise, and Edu. Nonetheless, company knowledge in ChatGPT is rolling out globally and is designed to make ChatGPT a central point of access for verified organizational information, supported by secure integrations and enterprise-grade compliance controls, and give employees way faster access to their company&#x27;s information while working.Now, instead of toggling over to Slack to find the assignment you were given and instructions, or tabbing over to Google Drive and opening up specific files to find the names and numbers you need to call, ChatGPT can deliver all that type of information directly into your chat session — if your company enables the proper connections.As OpenAI Chief Operating Officer Brad Lightcap wrote in a post on the social network X: \"company knowledge has changed how i use chatgpt at work more than anything we have built so far - let us know what you think!\"It builds upon the third-party app connectors unveiled back in August 2025, though those were only for individual users on the ChatGPT Plus plans.Connecting ChatGPT to Workplace SystemsEnterprise teams often face the challenge of fragmented data across various internal tools—email, chat, file storage, project management, and customer platforms. Company knowledge bridges those silos by enabling ChatGPT to connect to approved systems like, and other supported apps through enterprise-managed connectors.Each response generated with company knowledge includes citations and direct links to the original sources, allowing teams to verify where specific details originated. This transparency helps organizations maintain data trustworthiness while increasing productivity.The sidebar shows a live view of the sources being examined and what it is getting from them. When it’s done, you’ll see exactly the sources used, along with the specific snippets it drew from. You can then click on any citation to open the original source for more details.Built for Enterprise Control and SecurityCompany knowledge was designed from the ground up for enterprise governance and compliance. It respects existing permissions within connected apps — ChatGPT can only access what a user is already authorized to view— and never trains on company data by default.Security features include industry-standard encryption, support for SSO and SCIM for account provisioning, and IP allowlisting to restrict access to approved corporate networks. Enterprise administrators can also define role-based access control (RBAC) policies and manage permissions at a group or department level.OpenAI’s Enterprise Compliance API provides a full audit trail, allowing administrators to review conversation logs for reporting and regulatory purposes. This capability helps enterprises meet internal governance standards and industry-specific requirements such as SOC 2 and ISO 27001 compliance.Admin Configuration and Connector ManagementFor enterprise deployment, administrators must enable company knowledge and its connectors within the ChatGPT workspace. Once connectors are active, users can authenticate their own accounts for each work app they need to access.In Enterprise and Edu plans, connectors are off by default and require explicit admin approval before employees can use them. Admins can selectively enable connectors, manage access by role, and require SSO-based authentication for enhanced control.Business plan users, by contrast, have connectors enabled automatically if available in their workspace. Admins can still oversee which connectors are approved, ensuring alignment with internal IT and data policies.Company knowledge becomes available to any user with at least one active connector, and admins can configure group-level permissions for different teams — such as restricting GitHub access to engineering while enabling Google Drive or HubSpot for marketing and sales.Organizations who turn on the feature can also elect to turn it off just as easily. Once you disconnect a connector, ChatGPT does not have access to that data.How Company Knowledge Works in PracticeActivating company knowledge is straightforward. Users can start a new or existing conversation in ChatGPT and select “Company knowledge” under the message composer or from the tools menu. It must be turned on proactively for each new conversation or chat session, even from the same user.After authenticating their connected apps, they can ask questions as usual—such as “Summarize this account’s latest feedback and risks” or “Compile a Q4 performance summary from project trackers.”ChatGPT searches across the connected tools, retrieves relevant context, and produces an answer with full citations and source links. The system can combine data across apps — for instance, blending Slack updates, Google Docs notes, and HubSpot CRM records — to create an integrated view of a project, client, or initiative.When company knowledge is not selected, ChatGPT may still use connectors in a limited capacity as part of the default experience, but responses will not include detailed citations or multi-source synthesis.Advanced Use Cases for Enterprise TeamsFor development and operations leaders, company knowledge can act as a centralized intelligence layer that surfaces real-time updates and dependencies across complex workflows. ChatGPT can, for example, summarize open GitHub pull requests, highlight unresolved Linear tickets, and cross-reference Slack engineering discussions—all in a single output.Technical teams can also use it for incident retrospectives or release planning by pulling relevant information from issue trackers, logs, and meeting notes. Procurement or finance leaders can use it to consolidate purchase requests or budget updates across shared drives and internal communications.Because the model can reference structured and unstructured data simultaneously, it supports wide-ranging scenarios—from compliance documentation reviews to cross-departmental performance summaries.Privacy, Data Residency, and ComplianceEnterprise data protection is a central design element of company knowledge. ChatGPT processes data in line with OpenAI’s enterprise-grade security model, ensuring that no connected app data leaves the secure boundary of the organization’s authorized environment.Data residency policies vary by connector. Certain integrations, such as Slack, support region-specific data storage, while others—like Google Drive and SharePoint—are available for U.S.-based customers with or without at-rest data residency. Organizations with regional compliance obligations can review connector-specific security documentation for details.No geo restrictions apply to company knowledge, making it suitable for multinational organizations operating across multiple jurisdictions.Limitations and Future EnhancementsAt present, users must manually enable company knowledge in each new ChatGPT conversation. OpenAI is developing a unified interface that will automatically integrate company knowledge with other ChatGPT tools—such as browsing and chart generation—so that users won’t need to toggle between modes.When enabled, company knowledge temporarily disables web browsing and visual output generation, though users can switch modes within the same conversation to re-enable those features.OpenAI also continues to expand the network of supported tools. Recent updates have added connectors for Asana, GitLab Issues, and ClickUp, and OpenAI plans to support future MCP (Model Context Protocol) connectors to enable custom, developer-built integrations.Availability and Getting StartedCompany knowledge is now available to all ChatGPT Business, Enterprise, and Edu users. Organizations can begin by enabling the feature under the ChatGPT message composer and connecting approved work apps.For enterprise rollouts, OpenAI recommends a phased deployment: first enabling core connectors (such as Google Drive and Slack), configuring RBAC and SSO, then expanding to specialized systems once data access policies are verified.Procurement and security leaders evaluating the feature should note that company knowledge is covered under existing ChatGPT Enterprise terms and uses the same encryption, compliance, and service-level guarantees.With company knowledge, OpenAI aims to make ChatGPT not just a conversational assistant but an intelligent interface to enterprise data—delivering secure, context-aware insights that help technical and business leaders act with confidence.",
          "content": "Is the Google Search for internal enterprise knowledge finally here...but from OpenAI? It certainly seems that way. Today, OpenAI has launched company knowledge in ChatGPT, a major new capability for subscribers to ChatGPT&#x27;s paid Business, Enterprise, and Edu plans that lets them call up their company&#x27;s data directly from third-party workplace apps including Slack, SharePoint, Google Drive, Gmail, GitHub, HubSpot and combine it in ChatGPT outputs to them. As OpenAI&#x27;s CEO of Applications Fidji Simo put it in a post on the social network X: \"it brings all the context from your apps (Slack, Google Drive, GitHub, etc) together in ChatGPT so you can get answers that are specific to your business.\"Intriguingly, OpenAI&#x27;s blog post on the feature states that is \"powered by a version of GPT‑5 that’s trained to look across multiple sources to give more comprehensive and accurate answers,\" which sounds to me like a new fine-tuned version of the model family the company released back in August, though there are no additional details on how it was trained or its size, techniques, etc.OpenAI tells VentureBeat it&#x27;s a version of GPT-5 that specifically powers company knowledge in ChatGPT Business, Enterprise, and Edu. Nonetheless, company knowledge in ChatGPT is rolling out globally and is designed to make ChatGPT a central point of access for verified organizational information, supported by secure integrations and enterprise-grade compliance controls, and give employees way faster access to their company&#x27;s information while working.Now, instead of toggling over to Slack to find the assignment you were given and instructions, or tabbing over to Google Drive and opening up specific files to find the names and numbers you need to call, ChatGPT can deliver all that type of information directly into your chat session — if your company enables the proper connections.As OpenAI Chief Operating Officer Brad Lightcap wrote in a post on the social network X: \"company knowledge has changed how i use chatgpt at work more than anything we have built so far - let us know what you think!\"It builds upon the third-party app connectors unveiled back in August 2025, though those were only for individual users on the ChatGPT Plus plans.Connecting ChatGPT to Workplace SystemsEnterprise teams often face the challenge of fragmented data across various internal tools—email, chat, file storage, project management, and customer platforms. Company knowledge bridges those silos by enabling ChatGPT to connect to approved systems like, and other supported apps through enterprise-managed connectors.Each response generated with company knowledge includes citations and direct links to the original sources, allowing teams to verify where specific details originated. This transparency helps organizations maintain data trustworthiness while increasing productivity.The sidebar shows a live view of the sources being examined and what it is getting from them. When it’s done, you’ll see exactly the sources used, along with the specific snippets it drew from. You can then click on any citation to open the original source for more details.Built for Enterprise Control and SecurityCompany knowledge was designed from the ground up for enterprise governance and compliance. It respects existing permissions within connected apps — ChatGPT can only access what a user is already authorized to view— and never trains on company data by default.Security features include industry-standard encryption, support for SSO and SCIM for account provisioning, and IP allowlisting to restrict access to approved corporate networks. Enterprise administrators can also define role-based access control (RBAC) policies and manage permissions at a group or department level.OpenAI’s Enterprise Compliance API provides a full audit trail, allowing administrators to review conversation logs for reporting and regulatory purposes. This capability helps enterprises meet internal governance standards and industry-specific requirements such as SOC 2 and ISO 27001 compliance.Admin Configuration and Connector ManagementFor enterprise deployment, administrators must enable company knowledge and its connectors within the ChatGPT workspace. Once connectors are active, users can authenticate their own accounts for each work app they need to access.In Enterprise and Edu plans, connectors are off by default and require explicit admin approval before employees can use them. Admins can selectively enable connectors, manage access by role, and require SSO-based authentication for enhanced control.Business plan users, by contrast, have connectors enabled automatically if available in their workspace. Admins can still oversee which connectors are approved, ensuring alignment with internal IT and data policies.Company knowledge becomes available to any user with at least one active connector, and admins can configure group-level permissions for different teams — such as restricting GitHub access to engineering while enabling Google Drive or HubSpot for marketing and sales.Organizations who turn on the feature can also elect to turn it off just as easily. Once you disconnect a connector, ChatGPT does not have access to that data.How Company Knowledge Works in PracticeActivating company knowledge is straightforward. Users can start a new or existing conversation in ChatGPT and select “Company knowledge” under the message composer or from the tools menu. It must be turned on proactively for each new conversation or chat session, even from the same user.After authenticating their connected apps, they can ask questions as usual—such as “Summarize this account’s latest feedback and risks” or “Compile a Q4 performance summary from project trackers.”ChatGPT searches across the connected tools, retrieves relevant context, and produces an answer with full citations and source links. The system can combine data across apps — for instance, blending Slack updates, Google Docs notes, and HubSpot CRM records — to create an integrated view of a project, client, or initiative.When company knowledge is not selected, ChatGPT may still use connectors in a limited capacity as part of the default experience, but responses will not include detailed citations or multi-source synthesis.Advanced Use Cases for Enterprise TeamsFor development and operations leaders, company knowledge can act as a centralized intelligence layer that surfaces real-time updates and dependencies across complex workflows. ChatGPT can, for example, summarize open GitHub pull requests, highlight unresolved Linear tickets, and cross-reference Slack engineering discussions—all in a single output.Technical teams can also use it for incident retrospectives or release planning by pulling relevant information from issue trackers, logs, and meeting notes. Procurement or finance leaders can use it to consolidate purchase requests or budget updates across shared drives and internal communications.Because the model can reference structured and unstructured data simultaneously, it supports wide-ranging scenarios—from compliance documentation reviews to cross-departmental performance summaries.Privacy, Data Residency, and ComplianceEnterprise data protection is a central design element of company knowledge. ChatGPT processes data in line with OpenAI’s enterprise-grade security model, ensuring that no connected app data leaves the secure boundary of the organization’s authorized environment.Data residency policies vary by connector. Certain integrations, such as Slack, support region-specific data storage, while others—like Google Drive and SharePoint—are available for U.S.-based customers with or without at-rest data residency. Organizations with regional compliance obligations can review connector-specific security documentation for details.No geo restrictions apply to company knowledge, making it suitable for multinational organizations operating across multiple jurisdictions.Limitations and Future EnhancementsAt present, users must manually enable company knowledge in each new ChatGPT conversation. OpenAI is developing a unified interface that will automatically integrate company knowledge with other ChatGPT tools—such as browsing and chart generation—so that users won’t need to toggle between modes.When enabled, company knowledge temporarily disables web browsing and visual output generation, though users can switch modes within the same conversation to re-enable those features.OpenAI also continues to expand the network of supported tools. Recent updates have added connectors for Asana, GitLab Issues, and ClickUp, and OpenAI plans to support future MCP (Model Context Protocol) connectors to enable custom, developer-built integrations.Availability and Getting StartedCompany knowledge is now available to all ChatGPT Business, Enterprise, and Edu users. Organizations can begin by enabling the feature under the ChatGPT message composer and connecting approved work apps.For enterprise rollouts, OpenAI recommends a phased deployment: first enabling core connectors (such as Google Drive and Slack), configuring RBAC and SSO, then expanding to specialized systems once data access policies are verified.Procurement and security leaders evaluating the feature should note that company knowledge is covered under existing ChatGPT Enterprise terms and uses the same encryption, compliance, and service-level guarantees.With company knowledge, OpenAI aims to make ChatGPT not just a conversational assistant but an intelligent interface to enterprise data—delivering secure, context-aware insights that help technical and business leaders act with confidence.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/77MUUhh1PM8EeHOJyHjmwX/2f1b317b8af31339017a06f84d871d58/cfr0z3n_third-person_view_of_woman_seated_at_desk_in_a_home_off_d68bd7db-ac86-44be-8e05-2cdb878c7190.png?w=300&q=30"
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/DSC_5509.jpg",
      "popularity_score": 2000,
      "ai_summary": [
        "The article discusses deals on various iPad models.",
        "The iPad Air M3 with cellular is available with a discount.",
        "The latest iPad Pro with the M5 chip is mentioned.",
        "The standard iPad is recommended as a budget option.",
        "Deals are available from retailers like Amazon and Best Buy."
      ]
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Sat, 25 Oct 2025 11:00:09 +0000",
      "title": "Whale and dolphin migrations are being disrupted by climate change",
      "neutral_headline": "Whale and dolphin migrations are being disrupted by climate change",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/whale-and-dolphin-migrations-are-being-disrupted-by-climate-change/",
          "published_at": "Sat, 25 Oct 2025 11:00:09 +0000",
          "title": "Whale and dolphin migrations are being disrupted by climate change",
          "standfirst": "Marine mammals are being forced into new and more dangerous waters, scientists warn.",
          "content": "For millennia, some of the world’s largest filter-feeding whales, including humpbacks, fin whales, and blue whales, have undertaken some of the longest migrations on earth to travel between their warm breeding grounds in the tropics to nutrient-rich feeding destinations in the poles each year. “Nature has finely tuned these journeys, guided by memory and environmental cues that tell whales when to move and where to go,” said Trisha Atwood, an ecologist and associate professor at Utah State University’s Quinney College of Agriculture and Natural Resources. But, she said, climate change is “scrambling these signals,” forcing the marine mammals to veer off course. And they’re not alone. Earlier this year, Atwood joined more than 70 other scientists to discuss the global impacts of climate change on migratory species in a workshop convened by the United Nations Convention on the Conservation of Migratory Species of Wild Animals. The organization monitors and protects more than 1,000 species that cross borders in search of food, mates, and favorable conditions to nurture their offspring.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/whale1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/whale1-1152x648.jpg",
      "popularity_score": 352.7591458333333,
      "ai_summary": [
        "Marine mammals are facing new and dangerous waters.",
        "Scientists are warning about the impact of climate change.",
        "Whale and dolphin migrations are being disrupted.",
        "Climate change is forcing animals to change their routes.",
        "The article focuses on the effects of climate change."
      ]
    },
    {
      "id": "cluster_64",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 21:53:20 +0000",
      "title": "A single point of failure triggered the Amazon outage affecting millions",
      "neutral_headline": "A single point of failure triggered the Amazon outage affecting millions",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/a-single-point-of-failure-triggered-the-amazon-outage-affecting-millions/",
          "published_at": "Fri, 24 Oct 2025 21:53:20 +0000",
          "title": "A single point of failure triggered the Amazon outage affecting millions",
          "standfirst": "A DNS manager in a single region of Amazon's sprawling network touched off a 16-hour debacle.",
          "content": "The outage that hit Amazon Web Services and took out vital services worldwide was the result of a single failure that cascaded from system to system within Amazon’s sprawling network, according to a post-mortem from company engineers. The series of failures lasted for 15 hours and 32 minutes, Amazon said. Network intelligence company Ookla said its DownDetector service received more than 17 million reports of disrupted services offered by 3,500 organizations. The three biggest countries where reports originated were the US, the UK, and Germany. Snapchat, AWS, and Roblox were the most reported services affected. Ookla said the event was “among the largest internet outages on record for Downdetector.” It’s always DNS Amazon said the root cause of the outage was a software bug in software running the DynamoDB DNS management system. The system monitors the stability of load balancers by, among other things, periodically creating new DNS configurations for endpoints within the AWS network. A race condition is an error that makes a process dependent on the timing or sequence events that are variable and outside the developers’ control. The result can be unexpected behavior and potentially harmful failures.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/network-outage.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/network-outage.jpg",
      "popularity_score": 328,
      "ai_summary": [
        "A DNS manager caused the Amazon outage.",
        "The outage affected millions of users.",
        "The outage lasted for 16 hours.",
        "The failure occurred in a single region.",
        "The outage was a result of a single point of failure."
      ]
    },
    {
      "id": "cluster_61",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 22:26:30 +0000",
      "title": "Are you the asshole? Of course not!—quantifying LLMs’ sycophancy problem",
      "neutral_headline": "AI Models Show Tendency to Agree with User Statements",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/are-you-the-asshole-of-course-not-quantifying-llms-sycophancy-problem/",
          "published_at": "Fri, 24 Oct 2025 22:26:30 +0000",
          "title": "Are you the asshole? Of course not!—quantifying LLMs’ sycophancy problem",
          "standfirst": "In new research, AI models show a troubling tendency to agree with whatever the user says.",
          "content": "Researchers and users of LLMs have long been aware that AI models have a troubling tendency to tell people what they want to hear, even if that means being less accurate. But many reports of this phenomenon amount to mere anecdotes that don’t provide much visibility into how common this sycophantic behavior is across frontier LLMs. Two recent research papers have come at this problem a bit more rigorously, though, taking different tacks in attempting to quantify exactly how likely an LLM is to listen when a user provides factually incorrect or socially inappropriate information in a prompt. Solve this flawed theorem for me In one pre-print study published this month, researchers from Sofia University and ETH Zurich looked at how LLMs respond when false statements are presented as the basis for difficult mathematical proofs and problems. The BrokenMath benchmark that the researchers constructed starts with “a diverse set of challenging theorems from advanced mathematics competitions held in 2025.” Those problems are then “perturbed” into versions that are “demonstrably false but plausible” by an LLM that’s checked with expert review.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2195752979-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2195752979-1152x648.jpg",
      "popularity_score": 323,
      "ai_summary": [
        "Research indicates AI models exhibit a concerning inclination to agree with user input.",
        "This behavior, termed \"sycophancy,\" is a significant issue in AI development.",
        "The study quantifies the extent of this agreement in various language models.",
        "The findings highlight potential biases and limitations in AI responses.",
        "Researchers are investigating methods to mitigate this sycophantic tendency."
      ]
    },
    {
      "id": "cluster_65",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 21:29:30 +0000",
      "title": "Man takes herbal pain quackery, nearly dies, spends months in hospital",
      "neutral_headline": "Man's Herbal Pain Treatment Leads to Near-Fatal Complications",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/man-takes-herbal-pain-quackery-nearly-dies-spends-months-in-hospital/",
          "published_at": "Fri, 24 Oct 2025 21:29:30 +0000",
          "title": "Man takes herbal pain quackery, nearly dies, spends months in hospital",
          "standfirst": "The 61-year-old had wounds all over, a bacterial infection, and needed intensive care.",
          "content": "A 61-year-old man in California is lucky to be alive after a combination of herbal supplements he was taking for joint pain ended up utterly wrecking his body, landing him in intensive care and in a delirious state for months. His case is reported in the Annals of Internal Medicine: Clinical Cases. The man turned up at a hospital in San Francisco in bad shape, but with nonspecific problems that had begun just two days earlier. His back hurt, he was feverish, nauseous, bloated, and he hadn’t been eating much. He was so weak he couldn’t walk or get out of bed without help. His heart rate and breathing rate were high. His blood pressure was low. There were multiple wounds on his lower body in various stages of healing. Initial exams and lab work revealed Staphylococcus aureus bacteria in his blood. There was also an abscess on his shoulder and an infection in and around his spine, which was worsening. Doctors wanted to perform a surgical procedure to relieve the pressure building up on his spinal cord and nerves, but his blood pressure was too low—and then he went into hemorrhagic shock from bleeding in his gastrointestinal tract. Doctors transferred him to the intensive care unit.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2019/11/GettyImages-462760366-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2019/11/GettyImages-462760366-1152x648.jpg",
      "popularity_score": 318,
      "ai_summary": [
        "A 61-year-old man experienced severe health issues after using herbal remedies.",
        "He developed wounds, a bacterial infection, and required intensive hospital care.",
        "The man's condition resulted from the use of unproven herbal pain treatments.",
        "He spent several months in the hospital recovering from the complications.",
        "The case underscores the risks associated with unregulated alternative medicine."
      ]
    },
    {
      "id": "cluster_66",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 20:58:11 +0000",
      "title": "Clinical trial of a technique that could give everyone the best antibodies",
      "neutral_headline": "Clinical Trial Explores Antibody Production Technique",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/dna-and-jolts-of-electricity-get-people-to-make-optimal-antibodies/",
          "published_at": "Fri, 24 Oct 2025 20:58:11 +0000",
          "title": "Clinical trial of a technique that could give everyone the best antibodies",
          "standfirst": "If we ID the DNA for a great antibody, anyone can now make it.",
          "content": "One of the things that emerging diseases, including the COVID and Zika pandemics, have taught us is that it’s tough to keep up with infectious diseases in the modern world. Things like air travel can allow a virus to spread faster than our ability to develop therapies. But that doesn’t mean biotech has stood still; companies have been developing technologies that could allow us to rapidly respond to future threats. There are a lot of ideas out there. But this week saw some early clinical trial results of one technique that could be useful for a range of infectious diseases. We’ll go over the results as a way to illustrate the sort of thinking that’s going on, along with the technologies we have available to pursue the resulting ideas. The best antibodies Any emerging disease leaves a mass of antibodies in its wake—those made by people in response to infections and vaccines, those made by lab animals we use to study the infectious agent, and so on. Some of these only have a weak affinity for the disease-causing agent, but some of them turn out to be what are called “broadly neutralizing.” These stick with high affinity not only to the original pathogen, but most or all of its variants, and possibly some related viruses.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/abstractdna-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/abstractdna-1152x648.jpg",
      "popularity_score": 299,
      "ai_summary": [
        "A clinical trial investigates a method to produce optimal antibodies for everyone.",
        "The technique involves identifying the DNA sequence for effective antibodies.",
        "This allows for the mass production of beneficial antibodies for various individuals.",
        "The research aims to improve immune responses and disease treatment.",
        "The trial could revolutionize antibody-based therapies and treatments."
      ]
    },
    {
      "id": "cluster_82",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 18:55:47 +0000",
      "title": "Tech billionaires are now shaping the militarization of American cities",
      "neutral_headline": "Tech Billionaires Influence Militarization of American Cities",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/troops-in-us-cities-tech-billionaires-are-shaping-that-too/",
          "published_at": "Fri, 24 Oct 2025 18:55:47 +0000",
          "title": "Tech billionaires are now shaping the militarization of American cities",
          "standfirst": "Money means access to power—and tech has plenty of money.",
          "content": "Yesterday, Donald Trump announced on social media that he had been planning to “surge” troops into San Francisco this weekend—but was dissuaded from doing so by several tech billionaires. “Friends of mine who live in the area called last night to ask me not to go forward with the surge,” Trump wrote. Who are these “friends”? Trump named “great people like [Nvidia CEO] Jensen Huang, [Salesforce CEO] Marc Benioff, and others” who told him that “the future of San Francisco is great. They want to give it a ‘shot.’ Therefore, we will not surge San Francisco on Saturday. Stay tuned!”Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2232417355-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2232417355-1152x648.jpg",
      "popularity_score": 288,
      "ai_summary": [
        "Tech billionaires are increasingly involved in shaping urban militarization efforts.",
        "Their financial resources provide access to power and influence in this domain.",
        "This involvement raises concerns about the direction of urban policing.",
        "The trend highlights the growing intersection of technology and law enforcement.",
        "The impact of this influence on communities is a subject of debate."
      ]
    },
    {
      "id": "cluster_69",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 20:07:30 +0000",
      "title": "The Android-powered Boox Palma 2 Pro fits in your pocket, but it’s not a phone",
      "neutral_headline": "Boox Palma 2 Pro E-Reader Offers Color Screen, 5G",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/the-android-powered-boox-palma-2-pro-fits-in-your-pocket-but-its-not-a-phone/",
          "published_at": "Fri, 24 Oct 2025 20:07:30 +0000",
          "title": "The Android-powered Boox Palma 2 Pro fits in your pocket, but it’s not a phone",
          "standfirst": "This e-reader has a color screen and 5G.",
          "content": "Digital reading devices like the Kindle have existed for almost 20 years, and the standard eReader form factor has hardly changed at all. Amazon, Boox, and a few other companies have offered larger E Ink screens, but how about something smaller? Boox has unveiled its second-generation Palma e-reader, which still fits in your pocket but adds a color screen and mobile data connectivity. The first-gen Palma launched last year, earning fans who saw it as a way to read and access some apps without the full spate of distracting smartphone experiences. Boox e-readers are essentially Android tablets with E Ink screens and a few software quirks that arise from their unofficial Google Play implementation. The second-gen Palma might offer more opportunities for distraction because it’s almost a smartphone. The Palma 2 Pro upgrades the 6.1-inch monochrome display from the original to a 6.13-inch color E Ink Kaleido display. That’s the same technology used in Amazon’s Kindle Colorsoft. The Amazon reader is a bit larger with its 7-inch display and chunkier bezels. Of course, the Kindle isn’t trying to fit in your pocket like the Palma 2 Pro, which is roughly the size and shape of a phone.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Boox-Palam-2-Pro-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Boox-Palam-2-Pro-1152x648.jpg",
      "popularity_score": 283,
      "ai_summary": [
        "The Boox Palma 2 Pro is an Android-powered e-reader designed for portability.",
        "It features a color screen and offers 5G connectivity for internet access.",
        "The device is intended for reading and other digital content consumption.",
        "It is designed to fit in a pocket, emphasizing its compact size.",
        "The e-reader is not a phone, despite its similar form factor."
      ]
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 18:35:30 +0000",
      "title": "Tesla’s “Mad Max” mode is now under federal scrutiny",
      "neutral_headline": "Tesla's \"Mad Max\" Mode Faces Federal Scrutiny",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/feds-probe-tesla-about-its-mad-max-mode/",
          "published_at": "Fri, 24 Oct 2025 18:35:30 +0000",
          "title": "Tesla’s “Mad Max” mode is now under federal scrutiny",
          "standfirst": "The new mode added in the latest update will speed and weave through traffic.",
          "content": "Earlier this month, Tesla rolled out a new firmware update that added a pair of new driving modes for the controversial full self-driving (FSD) feature. One, called “Sloth,” relaxes acceleration and stays in its lane. The other, called “Mad Max,” does the opposite: It speeds and swerves through traffic to get you to your destination faster. And after multiple reports of FSD Teslas doing just that, the National Highway Traffic Safety Administration wants to know more. In fact, “Mad Max” mode is not entirely new—Tesla beta-tested the same feature in Autopilot in 2018, before deciding not to roll it out in a production release after widespread outcry. These days, the company is evidently feeling less constrained; despite having just lost a federal wrongful death lawsuit that will cost it hundreds of millions of dollars, it described the new mode as being able to drive “through traffic at an incredible pace, all while still being super smooth. It drives your car like a sports car. If you are running late, this is the mode for you.”Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2078835132-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2078835132-1152x648.jpg",
      "popularity_score": 269,
      "ai_summary": [
        "Tesla's new \"Mad Max\" mode is under investigation by federal authorities.",
        "The mode allows vehicles to speed and weave through traffic.",
        "The feature was introduced in a recent software update.",
        "Concerns have been raised regarding the safety implications of this mode.",
        "The scrutiny reflects a focus on vehicle safety and driver behavior."
      ]
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 17:07:57 +0000",
      "title": "Microsoft’s Mico heightens the risks of parasocial LLM relationships",
      "neutral_headline": "Microsoft's Mico Raises Concerns About Parasocial Relationships",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/microsofts-mico-heightens-the-risks-of-parasocial-llm-relationships/",
          "published_at": "Fri, 24 Oct 2025 17:07:57 +0000",
          "title": "Microsoft’s Mico heightens the risks of parasocial LLM relationships",
          "standfirst": "\"It looks like you're trying to find a friend. Would you like help?\"",
          "content": "Microsoft is rolling out a new face for its AI, and its name is Mico. The company announced the new, animated blob-like avatar for Copilot’s voice mode yesterday as part of a “human-centered” rebranding of Microsoft’s Copilot AI efforts. Mico is part of a Microsoft program dedicated to the idea that “technology should work in service of people,” Microsoft wrote. The company insists this effort is “not [about] chasing engagement or optimizing for screen time. We’re building AI that gets you back to your life. That deepens human connection.” Mico has drawn instant and obvious comparisons to Clippy, the animated paperclip that popped up to offer help with Microsoft Office starting in the ’90s. Microsoft has leaned into this comparison with an Easter egg that can transform Mico into an animated Clippy.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/micoheart-1152x648-1761323845.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/micoheart-1152x648-1761323845.png",
      "popularity_score": 255,
      "ai_summary": [
        "Microsoft's Mico AI assistant may heighten risks of parasocial relationships.",
        "The AI prompts users with statements like \"It looks like you're trying to find a friend.\"",
        "This interaction style could blur the lines between human and AI interaction.",
        "The feature raises ethical questions about AI's role in social connections.",
        "The potential for emotional dependency on AI is a key concern."
      ]
    },
    {
      "id": "cluster_84",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 18:18:19 +0000",
      "title": "EU accuses Meta of violating content rules in move that could anger Trump",
      "neutral_headline": "EU Accuses Meta of Violating Content Rules",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trump-tariff-threats-havent-stopped-eu-from-cracking-down-on-meta/",
          "published_at": "Fri, 24 Oct 2025 18:18:19 +0000",
          "title": "EU accuses Meta of violating content rules in move that could anger Trump",
          "standfirst": "EU alleges Facebook and Instagram make it too hard to report illegal content.",
          "content": "Meta violated the Digital Services Act (DSA) by failing to give Facebook and Instagram users simple mechanisms to report illegal content, the European Commission said in a preliminary decision announced yesterday. Meta also failed to give users an effective way to challenge content moderation decisions, the EC said. “When it comes to Meta, neither Facebook nor Instagram appear to provide a user-friendly and easily accessible ‘Notice and Action’ mechanism for users to flag illegal content, such as child sexual abuse material and terrorist content,” the EC press release said. The EC said that Meta mechanisms seem to “impose several unnecessary steps and additional demands on users. In addition, both Facebook and Instagram appear to use so-called ‘dark patterns,’ or deceptive interface designs, when it comes to the ‘Notice and Action’ mechanisms.” The EC also found that the content moderation appeal mechanisms used by Facebook and Instagram do not “allow users to provide explanations or supporting evidence to substantiate their appeals. This makes it difficult for users in the EU to further explain why they disagree with Meta’s content decision, limiting the effectiveness of the appeals mechanism.”Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/facebook-instagram-1152x648-1761326412.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/facebook-instagram-1152x648-1761326412.jpg",
      "popularity_score": 253,
      "ai_summary": [
        "The European Union accuses Meta of violating content moderation regulations.",
        "The EU alleges that Facebook and Instagram make reporting illegal content difficult.",
        "This action could lead to penalties and further regulatory scrutiny.",
        "The case highlights the ongoing debate over content moderation on social media.",
        "The move may impact Meta's operations within the European Union."
      ]
    },
    {
      "id": "cluster_112",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 14:37:03 +0000",
      "title": "This browser claims “perfect privacies protection,” but it acts like malware",
      "neutral_headline": "Browser Claiming Privacy Protection Acts Like Malware",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/this-browser-claims-perfect-privacies-protection-but-it-acts-like-malware/",
          "published_at": "Fri, 24 Oct 2025 14:37:03 +0000",
          "title": "This browser claims “perfect privacies protection,” but it acts like malware",
          "standfirst": "Researchers note links to Asia’s booming cybercrime and illegal gambling networks.",
          "content": "The Universe Browser makes some big promises to its potential users. Its online advertisements claim it’s the “fastest browser,” that people using it will “avoid privacy leaks” and that the software will help “keep you away from danger.” However, everything likely isn’t as it seems. The browser, which is linked to Chinese online gambling websites and is thought to have been downloaded millions of times, actually routes all Internet traffic through servers in China and “covertly installs several programs that run silently in the background,” according to new findings from network security company Infoblox. The researchers say the “hidden” elements include features similar to malware—including “key logging, surreptitious connections,” and changing a device’s network connections. Perhaps most significantly, the Infoblox researchers who collaborated with the United Nations Office on Drugs and Crime (UNODC) on the work, found links between the browser’s operation and Southeast Asia’s sprawling, multibillion-dollar cybercrime ecosystem, which has connections to money-laundering, illegal online gambling, human trafficking, and scam operations that use forced labor. The browser itself, the researchers says, is directly linked to a network around major online gambling company BBIN, which the researchers have labeled a threat group they call Vault Viper.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/universebrowser-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/universebrowser-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "A browser claiming \"perfect privacy protection\" exhibits malware-like behavior.",
        "Researchers have identified links to cybercrime and illegal gambling networks.",
        "The browser's actions contradict its privacy claims.",
        "The findings raise concerns about the security of the browser.",
        "Users are advised to exercise caution when using this browser."
      ]
    },
    {
      "id": "cluster_144",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 22:08:40 +0000",
      "title": "With new acquisition, OpenAI signals plans to integrate deeper into the OS",
      "neutral_headline": "OpenAI Plans Deeper OS Integration with New Acquisition",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/openai-acquires-the-team-that-made-apples-shortcuts/",
          "published_at": "Thu, 23 Oct 2025 22:08:40 +0000",
          "title": "With new acquisition, OpenAI signals plans to integrate deeper into the OS",
          "standfirst": "The acquired firm was working on a tool to control macOS directly with AI.",
          "content": "OpenAI has acquired Software Applications Incorporated (SAI), perhaps best known for the core team that produced what became Shortcuts on Apple platforms. More recently, the team has been working on Sky, a context-aware AI interface layer on top of macOS. The financial terms of the acquisition have not been publicly disclosed. “AI progress isn’t only about advancing intelligence—it’s about unlocking it through interfaces that understand context, adapt to your intent, and work seamlessly,” an OpenAI rep wrote in the company’s blog post about the acquisition. The post goes on to specify that OpenAI plans to “bring Sky’s deep macOS integration and product craft into ChatGPT, and all members of the team will join OpenAI.” That includes SAI co-founders Ari Weinstein (CEO), Conrad Kramer (CTO), and Kim Beverett (Product Lead)—all of whom worked together for several years at Apple after Apple acquired Weinstein and Kramer’s previous company, which produced an automation tool called Workflows, to integrate Shortcuts across Apple’s software platforms.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/openai-sky-1152x648.webp"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/openai-sky-1152x648.webp",
      "popularity_score": 148,
      "ai_summary": [
        "OpenAI plans to integrate deeper into operating systems through acquisition.",
        "The acquired firm was developing a tool to control macOS with AI.",
        "This move signals OpenAI's ambition to expand its OS capabilities.",
        "The integration could enhance AI's control over computer functions.",
        "The acquisition reflects the growing trend of AI integration in software."
      ]
    },
    {
      "id": "cluster_148",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 21:20:48 +0000",
      "title": "Researchers show that training on “junk data” can lead to LLM “brain rot”",
      "neutral_headline": "Training on \"Junk Data\" Leads to LLM \"Brain Rot",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/researchers-show-that-training-on-junk-data-can-lead-to-llm-brain-rot/",
          "published_at": "Thu, 23 Oct 2025 21:20:48 +0000",
          "title": "Researchers show that training on “junk data” can lead to LLM “brain rot”",
          "standfirst": "Models trained on short, popular, and/or \"superficial\" tweets perform worse on benchmarks.",
          "content": "On the surface, it seems obvious that training an LLM with “high quality” data will lead to better performance than feeding it any old “low quality” junk you can find. Now, a group of researchers is attempting to quantify just how much this kind of low quality data can cause an LLM to experience effects akin to human “brain rot.” For a pre-print paper published this month, the researchers from Texas A&M, the University of Texas, and Purdue University drew inspiration from existing research showing how humans who consume “large volumes of trivial and unchallenging online content” can develop problems with attention, memory, and social cognition. That led them to what they’re calling the “LLM brain rot hypothesis,” summed up as the idea that “continual pre-training on junk web text induces lasting cognitive decline in LLMs.” Figuring out what counts as “junk web text” and what counts as “quality content” is far from a simple or fully objective process, of course. But the researchers used a few different metrics to tease a “junk dataset” and “control dataset” from HuggingFace’s corpus of 100 million tweets.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1908316227-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1908316227-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Research shows that training on \"junk data\" harms LLM performance.",
        "Models trained on short, popular, or superficial tweets perform worse.",
        "This \"brain rot\" effect impacts benchmark performance negatively.",
        "The study emphasizes the importance of data quality in AI training.",
        "The findings highlight the need for careful data curation."
      ]
    },
    {
      "id": "cluster_145",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 21:54:39 +0000",
      "title": "Lawsuit: Reddit caught Perplexity “red-handed” stealing data from Google results",
      "neutral_headline": "Lawsuit: Reddit caught Perplexity “red-handed” stealing data from Google results",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/reddit-sues-to-block-perplexity-from-scraping-google-search-results/",
          "published_at": "Thu, 23 Oct 2025 21:54:39 +0000",
          "title": "Lawsuit: Reddit caught Perplexity “red-handed” stealing data from Google results",
          "standfirst": "Scraper accused of stealing Reddit content \"shocked\" by lawsuit.",
          "content": "In a lawsuit filed on Wednesday, Reddit accused an AI search engine, Perplexity, of conspiring with several companies to illegally scrape Reddit content from Google search results, allegedly dodging anti-scraping methods that require substantial investments from both Google and Reddit. Reddit alleged that Perplexity feeds off Reddit and Google, claiming to be “the world’s first answer engine” but really doing “nothing groundbreaking.” “Its answer engine simply uses a different company’s” large language model “to parse through a massive number of Google search results to see if it can answer a user’s question based on those results,” the lawsuit said. “But Perplexity can only run its ‘answer engine’ by wrongfully accessing and scraping Reddit content appearing in Google’s own search results from Google’s own search engine.”Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2236792840-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2236792840-1024x648.jpg",
      "popularity_score": 145,
      "ai_summary": [
        "A lawsuit accuses Perplexity of stealing data from Google search results.",
        "Reddit is accused of scraping content from Google's search results.",
        "The lawsuit claims Perplexity was \"red-handed\" in the data theft.",
        "The content was allegedly taken without permission from Reddit.",
        "The lawsuit has caused shock and concern within the Reddit community."
      ]
    },
    {
      "id": "cluster_94",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 16:30:12 +0000",
      "title": "Rivian is settling $250 million lawsuit to focus on next year’s R2 EV",
      "neutral_headline": "Rivian Settles $250 Million Lawsuit to Focus on R2 EV",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/rivian-settles-shareholder-lawsuit-for-250-million-denies-allegations/",
          "published_at": "Fri, 24 Oct 2025 16:30:12 +0000",
          "title": "Rivian is settling $250 million lawsuit to focus on next year’s R2 EV",
          "standfirst": "Investors sued Rivian claiming it knew prices had to rise after its IPO.",
          "content": "Electric vehicle startup Rivian announced on Thursday that it has settled a lawsuit with some of its investors. The company continues to deny allegations of making “materially untrue” statements during its inial public offering but says it agreed to pay $250 million to clear itself of distractions as it focuses on building its next EV, the mass-market R2, which is due next year. Rivian was first sued by a shareholder in 2022 over claims that the startup knew it would cost far more for it to build each R1T electric truck and R1S electric SUV than the advertised $67,500 and $70,000 prices, respectively. A big surprise price increase would tarnish the nascent automaker’s reputation, the lawsuit claimed, and could lead to many of the almost 56,000 pre-orders being canceled. Just a few months after its November 2021 IPO, the company had indeed issued a hefty price hike: $79,500 for the R1T and $84,500 for the R1S SUV. After an outcry, the company said it would honor the original price for its existing preorders. By that point, though, the damage was done, and more than a third of the company’s value was erased within a few days, the lawsuit alleged.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/05/rivian-assembly-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/05/rivian-assembly-1152x648.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "Rivian is settling a $250 million lawsuit to focus on the R2 EV.",
        "Investors sued Rivian, claiming they knew prices would rise after IPO.",
        "The settlement allows Rivian to concentrate on its upcoming EV model.",
        "The lawsuit stemmed from concerns about the company's financial practices.",
        "The R2 EV is a key project for Rivian's future growth."
      ]
    },
    {
      "id": "cluster_105",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 15:24:52 +0000",
      "title": "DNA analysis reveals likely pathogens that killed Napoleon’s army",
      "neutral_headline": "DNA Analysis Reveals Likely Pathogens That Killed Napoleon’s Army",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/dna-analysis-reveals-likely-pathogens-that-killed-napoleons-army/",
          "published_at": "Fri, 24 Oct 2025 15:24:52 +0000",
          "title": "DNA analysis reveals likely pathogens that killed Napoleon’s army",
          "standfirst": "Microbial DNA suggests troops suffered from paratyphoid fever and relapsing fever, among other diseases.",
          "content": "In 1812, Napoleon Bonaparte led a disastrous military campaign into Moscow. The death toll was devastating: Out of some 615,000 men, only about 110,000 survivors returned. (Napoleon abandoned his army in early December to return home on a sled.) Roughly 100,000 of the casualties died in battle, while as many as 300,000 perished from a combination of the bitter cold of Russia’s notoriously harsh winter, starvation, and disease. Scholars have debated precisely what kinds of diseases ravaged Napoleon’s troops. New DNA analysis of some soldiers’ remains has revealed the presence of two pathogens in particular, according to a new paper published in the journal Current Biology. The first is Salmonella enterica, which causes paratyphoid fever; the second is Borrelia recurrentis, which is transmitted by body lice and causes relapsing fever. (A preprint of the paper appeared on bioaRxiv in July.) “It’s very exciting to use a technology we have today to detect and diagnose something that was buried for 200 years,” said co-author Nicolás Rascovan of the Institut Pasteur. “Accessing the genomic data of the pathogens that circulated in historical populations helps us to understand how infectious diseases evolved, spread, and disappeared over time and to identify the social or environmental contexts that played a part in these developments. This information provides us with valuable insights to better understand and tackle infectious diseases today.”Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/napoleon2-1152x648-1760798560.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/napoleon2-1152x648-1760798560.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "DNA analysis identifies pathogens that likely caused Napoleon's army's demise.",
        "Microbial DNA suggests paratyphoid fever and relapsing fever were present.",
        "Other diseases also contributed to the high mortality rates.",
        "The study provides insights into the health challenges faced by the army.",
        "The findings offer a deeper understanding of historical disease outbreaks."
      ]
    },
    {
      "id": "cluster_128",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 11:00:36 +0000",
      "title": "Rocket Report: China tests Falcon 9 lookalike; NASA’s Moon rocket fully stacked",
      "neutral_headline": "Rocket Report: China tests Falcon 9 lookalike; NASA’s Moon rocket fully stacked",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/rocket-report-china-tests-falcon-9-lookalike-nasas-moon-rocket-fully-stacked/",
          "published_at": "Fri, 24 Oct 2025 11:00:36 +0000",
          "title": "Rocket Report: China tests Falcon 9 lookalike; NASA’s Moon rocket fully stacked",
          "standfirst": "A South Korean rocket startup will soon make its first attempt to reach low-Earth orbit.",
          "content": "Welcome to Edition 8.16 of the Rocket Report! The 10th anniversary of SpaceX’s first Falcon 9 rocket landing is coming up at the end of this year. We’re still waiting for a second company to bring back an orbital-class booster from space for a propulsive landing. Two companies, Jeff Bezos’ Blue Origin and China’s LandSpace, could join SpaceX’s exclusive club as soon as next month. (Bezos might claim he’s already part of the club, but there’s a distinction to be made.) Each company is in the final stages of launch preparations—Blue Origin for its second New Glenn rocket, and LandSpace for the debut flight of its Zhuque-3 rocket. Blue Origin and LandSpace will both attempt to land their first stage boosters downrange from their launch sites. They’re not exactly in a race with one another, but it will be fascinating to see how New Glenn and Zhuque-3 perform during the uphill and downhill phases of flight, and whether one or both of the new rockets stick the landing. As always, we welcome reader submissions. If you don’t want to miss an issue, please subscribe using the box below (the form will not appear on AMP-enabled versions of the site). Each report will include information on small-, medium-, and heavy-lift rockets, as well as a quick look ahead at the next three launches on the calendar. The race for space-based interceptors. The Trump administration’s announcement of the Golden Dome missile defense shield has set off a race among US companies to develop and test space weapons, some of them on their own dime, Ars reports. One of these companies is a 3-year-old startup named Apex, which announced plans to test a space-based interceptor as soon as next year. Apex’s concept will utilize one of the company’s low-cost satellite platforms outfitted with an “Orbital Magazine” containing multiple interceptors, which will be supplied by an undisclosed third-party partner. The demonstration in low-Earth orbit could launch as soon as June 2026 and will test-fire two interceptors from Apex’s Project Shadow spacecraft. The prototype interceptors could pave the way for operational space-based interceptors to shoot down ballistic missiles. (submitted by biokleen)Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/artemisiistacked-1152x648-1761259328.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/artemisiistacked-1152x648-1761259328.jpg",
      "popularity_score": 138,
      "ai_summary": [
        "China tested a rocket resembling SpaceX's Falcon 9 design.",
        "NASA's Moon rocket is now fully assembled and ready for launch.",
        "A South Korean startup will attempt to reach low-Earth orbit soon.",
        "The report covers recent developments in the space industry.",
        "The news highlights advancements in rocket technology and space exploration."
      ]
    },
    {
      "id": "cluster_97",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 16:16:55 +0000",
      "title": "Bats eat the birds they pluck from the sky while on the wing",
      "neutral_headline": "Bats Hunt Birds While Flying, New Sensor Data Reveals",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/tracking-bats-as-they-hunt-birds-in-the-skies-above-europe/",
          "published_at": "Fri, 24 Oct 2025 16:16:55 +0000",
          "title": "Bats eat the birds they pluck from the sky while on the wing",
          "standfirst": "A handful of bat species hunt birds, and new sensor data tells us how.",
          "content": "There are three species of bats that eat birds. We know that because we have found feathers and other avian remains in their feces. What we didn’t know was how exactly they hunt birds, which are quite a bit heavier, faster, and stronger than the insects bats usually dine on. To find out, Elena Tena, a biologist at Doñana Biological Station in Seville, Spain, and her colleagues attached ultra-light sensors to Nyctalus Iasiopterus, the largest bats in Europe. What they found was jaw-droppingly brutal. Inconspicuous interceptors Nyctalus Iasiopterus, otherwise known as greater noctule bats, have a wingspan of about 45 centimeters. They have reddish-brown or chestnut fur with a slightly paler underside, and usually weigh around 40 to 60 grams. Despite that minimal weight, they are the largest of the three bat species known to eat birds, so the key challenge in getting a glimpse into the way they hunt was finding sensors light enough to not impede the bats’ flight.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/image-4-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/image-4-1152x648.jpeg",
      "popularity_score": 133,
      "ai_summary": [
        "Researchers used sensors to track bat hunting behavior in flight.",
        "Data showed several bat species actively hunt and consume birds.",
        "Bats were observed capturing birds mid-air, a rare behavior.",
        "The study provided insights into bat hunting strategies and prey selection.",
        "Sensor data revealed the frequency and location of bird predation by bats."
      ]
    },
    {
      "id": "cluster_114",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 14:18:13 +0000",
      "title": "Satellite shows what’s really happening at the East Wing of the White House",
      "neutral_headline": "Satellite Shows White House East Wing Destruction",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/satellite-shows-whats-really-happening-at-the-east-wing-of-the-white-house/",
          "published_at": "Fri, 24 Oct 2025 14:18:13 +0000",
          "title": "Satellite shows what’s really happening at the East Wing of the White House",
          "standfirst": "\"Now it looks like the White House is physically being destroyed.\"",
          "content": "You need to go up—way up—to fully appreciate the changes underway at the White House this week. Demolition crews starting tearing down the East Wing of the presidential mansion Tuesday to clear room for the construction of a new $300 million, 90,000-square-foot ballroom, a recent priority of President Donald Trump. The teardown drew criticism and surprise from Democratic lawmakers, former White House staffers, and members of the public. It was, after all, just three months ago that President Donald Trump defended his ballroom plan by saying it wouldn’t affect the existing structure at the White House. “It won’t interfere with the current building,” he said in July. “It’ll be near it but not touching it—and pays total respect to the existing building, which I’m the biggest fan of.”Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2242218583-1152x648-1761262960.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2242218583-1152x648-1761262960.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Satellite imagery shows significant changes to the White House East Wing.",
        "The imagery suggests physical damage or demolition is occurring.",
        "Details of the changes are not specified in the provided text.",
        "The nature of the destruction is not clarified in the article.",
        "The article does not provide any context for the observed changes."
      ]
    },
    {
      "id": "cluster_149",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 20:57:36 +0000",
      "title": "Dinosaurs may have flourished right up to when the asteroid hit",
      "neutral_headline": "Dinosaurs Flourished Before Asteroid Impact, Study Shows",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/dinosaurs-may-have-flourished-right-up-to-when-the-asteroid-hit/",
          "published_at": "Thu, 23 Oct 2025 20:57:36 +0000",
          "title": "Dinosaurs may have flourished right up to when the asteroid hit",
          "standfirst": "Fossil beds in New Mexico show diverse species present in the late Cretaceous.",
          "content": "The end of the dinosaurs was clearly linked to an asteroid impact that brought the Cretaceous period to a close. But the details of their end have remained a matter of debate since the impact crater was discovered. There is a lot of evidence that the impact alone should have been enough to do them in. But the asteroid arrived amid major volcanic eruptions associated with previous mass extinctions. And fossils dating to just before the impact have suggested that dinosaur-dominated ecosystems had become less diverse, making them more prone to collapse. Now, a new study has revealed that fossils we already know about originated within the last few hundred thousand years before the impact that killed off all dinosaurs except birds. The results indicate that species richness wasn’t likely to be a problem—at least in the neighborhood of the impact itself. Wyoming vs. New Mexico Most of what we know about the last days of the non-avian dinosaurs comes from the Hell Creek Formation, rich fossil beds in present-day Wyoming. These not only date from within a few hundred thousand years prior to the impact, but there may be deposits that capture the immediate aftermath of the impact. Beyond this area, which reflects the ecosystem of the northern Great Plains, we have little else. It hasn’t been clear whether the diversity of species present at Hell Creek reflects what was present more globally, or if there were regional differences in ecosystemsRead full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1386002288-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1386002288-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Fossil beds in New Mexico reveal diverse dinosaur species.",
        "These species were present in the late Cretaceous period.",
        "The findings suggest dinosaurs thrived until the asteroid impact.",
        "The study challenges previous assumptions about dinosaur decline.",
        "The fossil record provides evidence of dinosaur diversity."
      ]
    }
  ]
}