{
  "updated_at": "2025-10-24T19:15:52.094Z",
  "clusters": [
    {
      "id": "cluster_106",
      "coverage": 3,
      "updated_at": "Thu, 23 Oct 2025 21:48:01 GMT",
      "title": "Trump pardons founder of Binance, world’s largest crypto exchange",
      "neutral_headline": "Trump pardons founder of Binance, world’s largest crypto exchange",
      "items": [
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2025/oct/23/binance-trump-pardon-changpeng-zhao",
          "published_at": "Thu, 23 Oct 2025 21:48:01 GMT",
          "title": "Trump pardons founder of Binance, world’s largest crypto exchange",
          "standfirst": "Changpeng Zhao pleaded guilty to failing to stop money laundering in 2023 and was sentenced to four monthsDonald Trump issued a pardon for the founder of the world’s largest cryptocurrency exchange on Thursday.“President Trump exercised his constitutional authority by issuing a pardon for Mr Zhao, who was prosecuted by the Biden administration in their war on cryptocurrency,” a White House statement said. “The war on crypto is over.” Continue reading...",
          "content": "Changpeng Zhao pleaded guilty to failing to stop money laundering in 2023 and was sentenced to four monthsDonald Trump issued a pardon for the founder of the world’s largest cryptocurrency exchange on Thursday.“President Trump exercised his constitutional authority by issuing a pardon for Mr Zhao, who was prosecuted by the Biden administration in their war on cryptocurrency,” a White House statement said. “The war on crypto is over.” Continue reading...",
          "feed_position": 6
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/trump-pardons-cz-binance/",
          "published_at": "Thu, 23 Oct 2025 18:05:37 +0000",
          "title": "‘War on Crypto Is Over’: Donald Trump Pardons Binance Founder CZ",
          "standfirst": "After serving a federal prison sentence for violating anti-money-laundering laws and US sanctions, former crypto exchange CEO Changpeng Zhao has been pardoned by US president Donald Trump.",
          "content": "After serving a federal prison sentence for violating anti-money-laundering laws and US sanctions, former crypto exchange CEO Changpeng Zhao has been pardoned by US president Donald Trump.",
          "feed_position": 19,
          "image_url": "https://media.wired.com/photos/68fa4fd3c5809c60f31dd079/master/pass/Trump-Pardon-Binance-CEO-Business-2210816860.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/binance-founder-changpeng-zhao-lands-a-trump-pardon-174929498.html",
          "published_at": "Thu, 23 Oct 2025 17:49:29 +0000",
          "title": "Binance founder Changpeng Zhao lands a Trump pardon",
          "standfirst": "President Donald Trump has pardoned Binance founder Changpeng Zhao, the White House said. Zhao pleaded guilty to federal money laundering charges in 2023 and he was sentenced last year to four months in prison. He was released in September 2024. As part of his plea deal, Zhao stepped down as CEO of Binance and he was banned from having any involvement with the company for three years. Both Zhao and Binance reportedly submitted formal applications for pardons by August this year.Trump \"exercised his constitutional authority by issuing a pardon for Mr. Zhao, who was prosecuted by the Biden Administration in their war on cryptocurrency,\" White House press secretary Karoline Leavitt said in a statement. \"The Biden Administration’s war on crypto is over.\"The Wall Street Journal notes that the pardon could pave the way for Binance to start doing business in the US again. The company was barred from operating there after pleading guilty to violating money laundering laws in 2023. Binance officials are said to have met with Treasury Department representatives this year in an attempt to reduce US oversight of the company. Binance is involved with the Trump family's World Liberty Financial cryptocurrency business — a venture that has padded the president's pockets. For one thing, it bolstered the growth of USD1, a World Liberty cryptocurrency that's pegged to the dollar. Binance received a $2 billion investment this spring and that was paid in USD1. According to CNBC, World Liberty has generated around $4.5 billion since last year's presidential election.FTX founder Sam Bankman-Fried has also reportedly been angling for a Trump pardon. Bankman-Fried was sentenced to 25 years in prison in 2024 after being found guilty of fraud and conspiracy to commit money laundering.Crypto billionaire Justin Sun said last November that he'd invested $30 million into World Liberty (a figure that later rose to $75 million). In February, the Securities and Exchange Commission dropped a case against Sun. The agency had charged him in 2023 with alleged violations of securities laws. This article originally appeared on Engadget at https://www.engadget.com/big-tech/binance-founder-changpeng-zhao-lands-a-trump-pardon-174929498.html?src=rss",
          "content": "President Donald Trump has pardoned Binance founder Changpeng Zhao, the White House said. Zhao pleaded guilty to federal money laundering charges in 2023 and he was sentenced last year to four months in prison. He was released in September 2024. As part of his plea deal, Zhao stepped down as CEO of Binance and he was banned from having any involvement with the company for three years. Both Zhao and Binance reportedly submitted formal applications for pardons by August this year.Trump \"exercised his constitutional authority by issuing a pardon for Mr. Zhao, who was prosecuted by the Biden Administration in their war on cryptocurrency,\" White House press secretary Karoline Leavitt said in a statement. \"The Biden Administration’s war on crypto is over.\"The Wall Street Journal notes that the pardon could pave the way for Binance to start doing business in the US again. The company was barred from operating there after pleading guilty to violating money laundering laws in 2023. Binance officials are said to have met with Treasury Department representatives this year in an attempt to reduce US oversight of the company. Binance is involved with the Trump family's World Liberty Financial cryptocurrency business — a venture that has padded the president's pockets. For one thing, it bolstered the growth of USD1, a World Liberty cryptocurrency that's pegged to the dollar. Binance received a $2 billion investment this spring and that was paid in USD1. According to CNBC, World Liberty has generated around $4.5 billion since last year's presidential election.FTX founder Sam Bankman-Fried has also reportedly been angling for a Trump pardon. Bankman-Fried was sentenced to 25 years in prison in 2024 after being found guilty of fraud and conspiracy to commit money laundering.Crypto billionaire Justin Sun said last November that he'd invested $30 million into World Liberty (a figure that later rose to $75 million). In February, the Securities and Exchange Commission dropped a case against Sun. The agency had charged him in 2023 with alleged violations of securities laws. This article originally appeared on Engadget at https://www.engadget.com/big-tech/binance-founder-changpeng-zhao-lands-a-trump-pardon-174929498.html?src=rss",
          "feed_position": 39
        }
      ],
      "featured_image": "https://media.wired.com/photos/68fa4fd3c5809c60f31dd079/master/pass/Trump-Pardon-Binance-CEO-Business-2210816860.jpg",
      "popularity_score": 3000,
      "ai_summary": [
        "Changpeng Zhao, founder of Binance, received a pardon from Donald Trump.",
        "Zhao pleaded guilty to money laundering charges in 2023.",
        "He was sentenced to four months in prison and released in September 2024.",
        "The pardon was issued by Trump, exercising his constitutional authority.",
        "The White House stated the \"war on crypto is over\" with the pardon."
      ]
    },
    {
      "id": "cluster_13",
      "coverage": 2,
      "updated_at": "Fri, 24 Oct 2025 13:55:02 -0400",
      "title": "Netflix shuts down Boss Fight Entertainment, the game studio behind mobile game Squid Game: Unleashed, after acquiring it in March 2022 (Jay Peters/The Verge)",
      "neutral_headline": "Netflix shuts down Boss Fight Entertainment, the game studio behind mobile game Squid Game: Unleashed, after acquiring it in March 2022 (Jay Peters/The Verge)",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251024/p14#a251024p14",
          "published_at": "Fri, 24 Oct 2025 13:55:02 -0400",
          "title": "Netflix shuts down Boss Fight Entertainment, the game studio behind mobile game Squid Game: Unleashed, after acquiring it in March 2022 (Jay Peters/The Verge)",
          "standfirst": "Jay Peters / The Verge: Netflix shuts down Boss Fight Entertainment, the game studio behind mobile game Squid Game: Unleashed, after acquiring it in March 2022 &mdash; &#65279;More than three years after acquiring Boss Fight Entertainment, Netflix is closing it. &hellip; Netflix acquired Boss Fight in March 2022 &hellip;",
          "content": "Jay Peters / The Verge: Netflix shuts down Boss Fight Entertainment, the game studio behind mobile game Squid Game: Unleashed, after acquiring it in March 2022 &mdash; &#65279;More than three years after acquiring Boss Fight Entertainment, Netflix is closing it. &hellip; Netflix acquired Boss Fight in March 2022 &hellip;",
          "feed_position": 1,
          "image_url": "http://www.techmeme.com/251024/i14.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/806303/netflix-squid-game-unleashed-boss-fight-entertainment-studio-shut-down",
          "published_at": "2025-10-24T12:35:55-04:00",
          "title": "Netflix shuts down its Squid Game mobile studio",
          "standfirst": "Netflix has shut down Boss Fight Entertainment, the studio behind the mobile game Squid Game: Unleashed, according to posts from staffers on LinkedIn. Netflix acquired Boss Fight in March 2022, with an executive saying at the time that the studio’s “extensive experience building hit games across genres will help accelerate our ability to provide Netflix [&#8230;]",
          "content": "Netflix has shut down Boss Fight Entertainment, the studio behind the mobile game Squid Game: Unleashed, according to posts from staffers on LinkedIn. Netflix acquired Boss Fight in March 2022, with an executive saying at the time that the studio’s “extensive experience building hit games across genres will help accelerate our ability to provide Netflix members with great games wherever they want to play them.” The company has frequently touted the success of Squid Game: Unleashed, highlighting how it was the “ #1 Free Action Game in 107 countries upon release” and co-CEO Greg Peters pointing to Unleashed during this week’s earnings call as an example of the types of narrative games based on its own franchises that it wants to do more of. But over three years after the acquisition and some changes to Netflix’s gaming strategy, Boss Fight has been closed. Netflix declined to comment. “Hi everyone – well, word has gotten around quickly about Boss Fight’s closure,” Boss Fight co-founder and former CEO David Rippy said. “Thanks, everyone who reached out today. Rough news, for sure, but I’m very grateful for the time we had at Netflix.” “After 10+ great years working at Boss Fight, the last few as part of Netflix, the time has come for the studio to close down,” David Luehmann, a director of game development at the studio, said in a post. “I am very proud of all the people, work, and games we&#8217;ve released. I wish you could see what we had cooking!” The shutdown follows persistent layoffs across the industry, including cut jobs at Dune: Awakening developer Funcom despite that game’s success and layoffs at Cloud Chamber, the studio making the next title in the BioShock franchise. Last year, Netflix closed its AAA game studio before it ever released a game. Netflix’s next big gaming initiative is focused around party games you can play on your TV using your phone as a controller, and Peters said this week that the company is ‘judiciously’ expanding into interactive experiences.",
          "feed_position": 4
        }
      ],
      "featured_image": "http://www.techmeme.com/251024/i14.jpg",
      "popularity_score": 2018.6527516666667,
      "ai_summary": [
        "Netflix acquired Boss Fight Entertainment in March 2022.",
        "Boss Fight Entertainment developed the mobile game \"Squid Game: Unleashed\".",
        "Netflix is shutting down Boss Fight Entertainment.",
        "The closure comes over three years after the acquisition.",
        "Staffers shared the news on LinkedIn."
      ]
    },
    {
      "id": "cluster_21",
      "coverage": 2,
      "updated_at": "Fri, 24 Oct 2025 16:50:00 GMT",
      "title": "Internet bill too high? Verizon's new plan starts at $20/month - here's who qualifies",
      "neutral_headline": "Verizon offers new internet plan starting at $20 monthly",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/internet-bill-too-high-verizons-new-plan-starts-at-20month-heres-who-qualifies/",
          "published_at": "Fri, 24 Oct 2025 16:50:00 GMT",
          "title": "Internet bill too high? Verizon's new plan starts at $20/month - here's who qualifies",
          "standfirst": "Designed for use outside 5G or fiber areas, Home Internet Lite provides unlimited data and download speeds of up to 25 Mbps. Here's everything you need to know.",
          "content": "Designed for use outside 5G or fiber areas, Home Internet Lite provides unlimited data and download speeds of up to 25 Mbps. Here's everything you need to know.",
          "feed_position": 3
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/806083/verizon-lite-home-internet-plan-launch-price",
          "published_at": "2025-10-24T09:38:54-04:00",
          "title": "Verizon launches Lite home internet for people in limited coverage areas",
          "standfirst": "Verizon is launching a new “Lite” home internet plan for people in areas previously not covered by its fiber and 5G internet. The new plan offers download speeds of up to 25Mbps, but it costs as much as $60 per month without any discounts. Verizon says its Lite plan is best for “light” internet usage [&#8230;]",
          "content": "Verizon is launching a new “Lite” home internet plan for people in areas previously not covered by its fiber and 5G internet. The new plan offers download speeds of up to 25Mbps, but it costs as much as $60 per month without any discounts. Verizon says its Lite plan is best for “light” internet usage in homes limited to “older, less reliable options like DSL or satellite.” Customers who already use Verizon for their postpaid mobile phone service will benefit the most from the heavy discounts. You’ll save $15 / month when the service is combined with a mobile plan. It’s also offering a $10 monthly discount for paperless billing and autopay, along with an additional $10 discount available for three years if mobile phone customers sign up before December 31st. All these discounts bring the price down to $25 per month. Though Verizon’s Lite plan may be ultra-cheap if you’re able to take advantage of the price cuts, it’s quite slow when compared to other budget internet plans. T-Mobile’s cheapest home internet plan, for example, costs up to $55 per month for download speeds up to 415Mbps. Verizon will throttle your service by up to 10Mbps after the first 150GB of data usage in one month, while T-Mobile will start slowing down internet speeds if customers use more than 1.2TB in one month. Like T-Mobile, Mint Mobile’s new prepaid home internet plan also offers download speeds of up to 415Mbps, but it will start throttling data after 1TB of usage and costs up to $50 per month. Verizon Lite is available across the US starting today. The carrier will likely only continue to expand its home internet coverage in the coming months, as it’s set to acquire the fiber internet provider Frontier and the antenna-based internet service Starry.",
          "feed_position": 9
        }
      ],
      "popularity_score": 2017.5688627777777,
      "ai_summary": [
        "Verizon launched a new \"Lite\" home internet plan.",
        "The plan is designed for areas without 5G or fiber coverage.",
        "It offers download speeds up to 25 Mbps.",
        "The plan has unlimited data.",
        "The monthly cost can reach $60 without discounts."
      ]
    },
    {
      "id": "cluster_24",
      "coverage": 2,
      "updated_at": "Fri, 24 Oct 2025 16:39:18 +0000",
      "title": "Best iPad deals: Get over $300 off the iPad Air M3 with cellular",
      "neutral_headline": "iPad deals offer discounts on iPad Air M3 with cellular",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-ipad-deals-get-over-300-off-the-ipad-air-m3-with-cellular-150020542.html",
          "published_at": "Fri, 24 Oct 2025 16:39:18 +0000",
          "title": "Best iPad deals: Get over $300 off the iPad Air M3 with cellular",
          "standfirst": "The just-released iPad Pro with the M5 chip tops our list of the best tablets and the standard iPad is our pick for the best budget slate. While the former is expectedly not on sale yet, we are seeing a modest discount for the cheaper iPad. The lovely iPad Air (13-inch, with cellular) is down to a record low as well. Of course, you won't find deals on Apple's own website, but we keep an eye on Amazon, Target, Walmart and other retailers to find the best iPad deals out there and round them up each Friday. This week, the discounts aren't as good as they were for Prime Day earlier this month — chances are, we won't see a huge influx of Apple deals until Black Friday sales start up. Until then, here are the top deals on iPads and all the other Apple gear we could find. Best iPad deals Apple iPad (A16, 256GB) for $399 ($50 off): The latest entry-level iPad comes with a faster A16 chip, 2GB more RAM and more base storage. It earned a score of 84 in our review — if you only need a tablet for roaming the internet, watching shows and doing some lighter productivity tasks, it should do the job. With the recent iPadOS 26 update, it also has most of the same multitasking features available on the more expensive models. It does lack Apple Intelligence, but to be candid, that isn't a big loss right now. This deal isn't an all-time low for the model with 256GB of storage but it takes $50 off Apple's list price. Also at Best Buy. Apple iPad Air (11-inch, M3, 1TB) for $949 ($150 off MSRP): The most recent iPad Air is a relatively minor update, as the only major addition is a more powerful M3 chip. However, we still recommend the Air over the base model in our iPad buying guide: Its display is laminated, more color-rich and better at fending off glare (though it's still 60Hz); its speakers are more robust; it works with Apple’s best accessories and its performance should hold up better in the years ahead. This deal is only for the maxed-out model with 1TB of storage, but it ties the lowest price we've seen all the same. Best Apple deals Apple Pencil Pro for $99 ($30 off): The top-end option in Apple’s confusing stylus lineup, the Pencil Pro supports pressure sensitivity, wireless charging, tilt detection, haptic feedback and Apple’s double tap and squeeze gestures, among other perks. It’s a lovely tool for more intricate sketching and note-taking, but the catch is that it’s only compatible with the M4 iPad Pro, M2 and M3 iPad Air and most recent iPad mini. We've seen this deal fairly often over the course of the year, but it's a fine discount compared to buying from Apple directly. Also at Walmart. Apple MacBook Air (13-inch, M4, 512GB) for $999 ($200 off): Apple's latest MacBook Air is the top pick in our guide to the best laptops, and it earned a score of 92 in our review. It's not a major overhaul, but the design is still exceptionally thin, light and well-built, with long battery life and a top-notch keyboard and trackpad. Now it's a bit faster. (Though we'd still love more ports and a refresh rate higher than 60Hz.) This discount ties the all-time low for the model with 16GB of RAM and a 512GB SSD. Apple Watch Series 11 (GPS, 42mm) for $389 ($10 off): The latest flagship Apple Watch only hit store shelves last month, but Amazon is already selling it for $10 off. It doesn't show up as a percentage off, but you'll see some models listed at $389 instead of Apple's $399 MSRP. If you're new to Apple's wearables or are ready to upgrade from a Series 9 or older, this is a good model to grab. If you're coming from a Series 10, however, there's not much need to upgrade as the only major change from last year's model is a slightly larger battery and a tougher screen. Apple Watch SE 3 (GPS, 40mm) for $240 ($9 off): There's a similar stealth discount for the newest budget model, the Apple Watch SE 3, at Amazon. It normally goes for $249 — again, not a big discount, but better than nothing if you're looking to get onboard early. Apple gave this model some badly needed updates compared to its predecessor, including an always-on display, faster charging, better sensors and the same processor that you'll find in the new Apple Watch Series 11. Read more Apple coverage: The best AirPods The best Apple Watches The best MacBooks The best iPhones The best iPads Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-ipad-deals-get-over-300-off-the-ipad-air-m3-with-cellular-150020542.html?src=rss",
          "content": "The just-released iPad Pro with the M5 chip tops our list of the best tablets and the standard iPad is our pick for the best budget slate. While the former is expectedly not on sale yet, we are seeing a modest discount for the cheaper iPad. The lovely iPad Air (13-inch, with cellular) is down to a record low as well. Of course, you won't find deals on Apple's own website, but we keep an eye on Amazon, Target, Walmart and other retailers to find the best iPad deals out there and round them up each Friday. This week, the discounts aren't as good as they were for Prime Day earlier this month — chances are, we won't see a huge influx of Apple deals until Black Friday sales start up. Until then, here are the top deals on iPads and all the other Apple gear we could find. Best iPad deals Apple iPad (A16, 256GB) for $399 ($50 off): The latest entry-level iPad comes with a faster A16 chip, 2GB more RAM and more base storage. It earned a score of 84 in our review — if you only need a tablet for roaming the internet, watching shows and doing some lighter productivity tasks, it should do the job. With the recent iPadOS 26 update, it also has most of the same multitasking features available on the more expensive models. It does lack Apple Intelligence, but to be candid, that isn't a big loss right now. This deal isn't an all-time low for the model with 256GB of storage but it takes $50 off Apple's list price. Also at Best Buy. Apple iPad Air (11-inch, M3, 1TB) for $949 ($150 off MSRP): The most recent iPad Air is a relatively minor update, as the only major addition is a more powerful M3 chip. However, we still recommend the Air over the base model in our iPad buying guide: Its display is laminated, more color-rich and better at fending off glare (though it's still 60Hz); its speakers are more robust; it works with Apple’s best accessories and its performance should hold up better in the years ahead. This deal is only for the maxed-out model with 1TB of storage, but it ties the lowest price we've seen all the same. Best Apple deals Apple Pencil Pro for $99 ($30 off): The top-end option in Apple’s confusing stylus lineup, the Pencil Pro supports pressure sensitivity, wireless charging, tilt detection, haptic feedback and Apple’s double tap and squeeze gestures, among other perks. It’s a lovely tool for more intricate sketching and note-taking, but the catch is that it’s only compatible with the M4 iPad Pro, M2 and M3 iPad Air and most recent iPad mini. We've seen this deal fairly often over the course of the year, but it's a fine discount compared to buying from Apple directly. Also at Walmart. Apple MacBook Air (13-inch, M4, 512GB) for $999 ($200 off): Apple's latest MacBook Air is the top pick in our guide to the best laptops, and it earned a score of 92 in our review. It's not a major overhaul, but the design is still exceptionally thin, light and well-built, with long battery life and a top-notch keyboard and trackpad. Now it's a bit faster. (Though we'd still love more ports and a refresh rate higher than 60Hz.) This discount ties the all-time low for the model with 16GB of RAM and a 512GB SSD. Apple Watch Series 11 (GPS, 42mm) for $389 ($10 off): The latest flagship Apple Watch only hit store shelves last month, but Amazon is already selling it for $10 off. It doesn't show up as a percentage off, but you'll see some models listed at $389 instead of Apple's $399 MSRP. If you're new to Apple's wearables or are ready to upgrade from a Series 9 or older, this is a good model to grab. If you're coming from a Series 10, however, there's not much need to upgrade as the only major change from last year's model is a slightly larger battery and a tougher screen. Apple Watch SE 3 (GPS, 40mm) for $240 ($9 off): There's a similar stealth discount for the newest budget model, the Apple Watch SE 3, at Amazon. It normally goes for $249 — again, not a big discount, but better than nothing if you're looking to get onboard early. Apple gave this model some badly needed updates compared to its predecessor, including an always-on display, faster charging, better sensors and the same processor that you'll find in the new Apple Watch Series 11. Read more Apple coverage: The best AirPods The best Apple Watches The best MacBooks The best iPhones The best iPads Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-ipad-deals-get-over-300-off-the-ipad-air-m3-with-cellular-150020542.html?src=rss",
          "feed_position": 4
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/sennheiser-hdb-630-review-a-sonic-marvel-with-room-for-improvement-150000295.html",
          "published_at": "Fri, 24 Oct 2025 15:00:00 +0000",
          "title": "Sennheiser HDB 630 review: A sonic marvel with room for improvement",
          "standfirst": "High-resolution audio on the go isn’t very convenient. It typically involves wired headphones and a DAC (digital-to-analog converter) of some kind, plus your phone or another device to access files or a streaming service. All of this is necessary since Bluetooth compresses an audio signal by design, to allow for low-latency transmission and minimize battery draw. Simply put, wireless headphones haven’t been able to meet the demands of lossless audio, but Sennheiser has come the closest to fulfilling the dream with its HDB 630 ($500). Thanks to redesigned drivers, a new acoustic platform and a dongle, the company offers up to 24-bit/96kHz audio on the HDB 630 — depending on your configuration. You also get above average active noise cancellation (ANC), a highly customizable EQ, shockingly long battery life and advanced features to fine-tune the headphones to your liking. For some, the best possible sound is still only found on pricey setups and open-back headphones. For everyone else, Sennheiser has provided a taste of the audiophile life in a much more portable package. Design Sennheiser says the HDB 630 “inherited” the same chassis from its Momentum 4 headphones. That’s unfortunate because my biggest complaint with that older model's redesign is how cheap it looked compared to previous entries in the Momentum line. The HDB 630 suffers the same fate, although the splash of silver on the headband and yokes helps things a bit. Simply put, these don’t look like a set of $500 headphones, and since they’re $150 more than their predecessor was at launch, they really should have a more premium appearance. The outside of the right ear cup is still a touch panel where you can swipe, tap and even pinch to control the HDB 630. I don’t recall another set of headphones with a pinch gesture, and I’m still not convinced it’s warranted. The action is used to enable an Adaptive ANC adjustment that allows you to dial in the amount of noise blocking you need. After the pinch, sliding a single finger forwards and backwards fine tunes the mix of ANC and transparency mode. It’s a nice option to have on the headphones themselves, I just think a triple tap to activate it would be easier to master — and remember. The only other button on the HDB 630 is for power and Bluetooth pairing. Unless you’re frequently connecting these headphones to a new device, you might not be reaching for this control very often. That’s because the HDB 630 goes into standby mode when you take them off before powering down completely after 15 minutes of inactivity. You can extend that window to 30 or 60 minutes if you prefer. And if the headphones still have battery left, you can return to active mode by simply putting them back on your head. Sennheiser is betting you’ll use the HDB 630 for long listening sessions, so it outfitted these headphones with soft ear pads and a well-cushioned headband. The clamping force is adequate for a proper ANC seal, but never becomes a burden. And despite being around 20 grams heavier than the Momentum 4, this model still feels balanced and doesn’t weigh you down. Sound quality The HDB 630 features new drivers and a specially designed acoustic system. Billy Steele for Engadget While the overall design may be familiar, the sound platform for the HDB 630 is completely new. 42mm drivers offer what Sennheiser says is “neutral sound with lifelike mids, stunning detail and a wide soundstage.” In order to deliver sound quality that’s as close to open-back headphones as possible, the company overhauled the entire acoustic system, from the drivers to the baffle’s transparent mesh, in the name of balance and clarity. And since audiophile headphones typically require a dedicated external amplifier to achieve their full potential, Sennheiser included a BTD 700 USB-C dongle for high-resolution wireless audio transmission. When I first put the HDB 630 on, I thought the audio quality was good but not great. Listening over the standard definition SBC codec produced decent results, but it wasn’t anything to write home about. Once I connected to the BTD 700 dongle and unlocked 16-bit/48kHz tunes from Apple Music, though, these headphones really started to impress. As good as they are, the HDB 630 may not be for everyone. That “neutral” stock tuning places high emphasis on the midrange, so you’ll likely need to make some adjustments to get the bass performance you crave from rock, electronic, hip-hop and other genres driven by low-end tone. While I concede the neutral base is a great starting point, and the HDB 630 does indeed showcase “stunning detail,” I’d argue Sennheiser’s promise of “a wide soundstage” doesn’t always hold true. These headphones are at their best with more immersive content, like the TRON: Ares soundtrack from Nine Inch Nails. After a slight adjustment, the electronic score had the booming bass it needed, offering driving beats that nearly rattled my brain. All that was layered with rich synths and Trent Reznor’s iconic vocals. The texture and distortion in the instruments came through in greater detail too, something that’s not as apparent on other headphones and earbuds. Switch over to Thrice’s Horizons/West and the HDB 630 is a different story. Transitioning from synth-heavy electronic music to a genre like rock causes these headphones to lose some of the immersive character they are capable of delivering. You still get absurd clarity and detail, particularly in Teppei Teranishi’s guitar riffs, but the music sounds slightly flatter and a little less energetic. It’s not bad by any means, but some genres won’t envelope you as much as others do. You can also use the HDB 630 wired over USB-C for lossless-quality audio. Since a number of competitors also do this, I dedicated the bulk of my testing to see if Sennheiser’s wireless dongle is meaningfully different. Of course, I did my due diligence and tested the wired configuration a few times, and it should come as no surprise that the HDB 630 sounds just as good in that setup. Software, features and accessories There's only one button on the HDB 630. Billy Steele for Engadget As I mentioned, the HDB 630 comes with Sennheiser’s BTD 700 Bluetooth USB dongle. This enables higher quality streaming than you’ll natively get from most devices. With the BTD 700, you can expect aptX Adaptive and aptX Lossless listening up at rates to 24-bit/96kHz. The dongle also has a 30ms low-latency gaming mode, (supposedly) enhanced call performance and Auracast support for streaming to multiple headphones or speakers. The BTD 700 has a USB-C connector, but it comes with a USB-A adapter if you need it. This typically costs $60 if you buy it on its own, and since you need it to unlock the HDB 630’s full potential, it’s great to see it included in the box. The HDB 630’s settings and features are accessible in the Sennheiser Smart Control Plus app. And for this model, the company is offering a lot more customization than it does on the Accentum or Momentum headphones. First, the EQ editing options are more robust thanks to a parametric equalizer, which allows you to get a lot more detailed with your custom presets. For example, I was able to add the low-end tone I feel is missing from the stock tuning for those metal, rock and hip-hop tracks I mentioned before. And unlike a lot of headphone apps, adjusting the EQ actually improves the sound instead of just muddying things further. Another sound-related addition for the HDB 630 is Crossfeed. This allows you to blend the left and right channels so that it seems like you’re listening to speakers instead of headphones. Unfortunately, you only get two options here — Low and High — but the effect certainly enhances the sonic profile of the HDB 630 at both settings. Despite the BTD 700 dongle’s Mac and Windows compatibility, there’s no desktop version of the Smart Control Plus app. This means you’ll have to change all of your settings with the HDB 630 through your phone before you pair it with both the dongle and your computer. It would be nice if you could make EQ adjustments, create new presets and even change Crossfeed levels without having to reconnect to another device. This also means you can’t be connected to the BTD 700 and both your phone and your computer, since the dongle takes one of the two available multipoint Bluetooth slots. Active noise cancellation and call quality The HDB 630 has a very basic design with lots of plastic. Billy Steele for Engadget When it comes to ANC performance, I’m not entirely sure that the HDB 630 is better than the Momentum 4. But that’s okay. That previous model brought a significant improvement compared to Sennheiser’s older wireless headphones and the ANC is still quite good here. In fact, it was robust enough to block my family’s voices during their calls while I worked from home, and since most headphones struggle with this, that’s no mean feat. Sennheiser says the BTD 700 dongle will give you improved voice performance over the headphones alone. Specifically, the accessory should provide extended range, clearer voice pickup and, according to the company, “uninterrupted” calls. In my recorded samples, I think the headphones themselves sounded slightly better than when I captured my voice while connected to the BTD 700. However, I noticed a distinct lack of background noise in both clips, which is helpful in busier environments. I’ll also note the overall voice quality isn’t pristine, but it’s clear enough to use for work calls — even if you’re the main presenter. Battery life Sennheiser promises that you’ll get up to 60 hours of battery life on a charge with the HDB 630. That’s the same staggering figure the company claims on the Momentum 4. And yes, that’s with ANC enabled, but you’ll only achieve that if you’re listening to standard resolution tunes. Based on my testing with a mix of noise cancellation and transparency mode while I was listening to music and taking work calls, I have no reason to believe the company’s numbers don’t hold true. If you choose to listen entirely via the BTD 700’s higher quality output, you can expect up to 45 hours of use on a charge. That’s still quite a long time considering a lot of the competition runs out at around 30 hours — and that’s without high-res music. Due to all of the signal processing that helps with the acoustic performance on the HDB 630, they can only be used when they’re turned on. Unlike some wireless models, you can’t use these as wired headphones when the battery is spent. However, if you find yourself with a completely depleted battery, a 10-minute charge will give you up to seven hours of use. The company doesn’t specify streaming resolution for that number, but I assume it’s at standard definition. Still, you’ll get a few hours of higher-res music in that time, which should be enough to get you through a work session, evening commute or that new album you’re dying to play for the first time. The competition Incredible sound awaits, if you're okay to carry a dongle around with your headphones. Billy Steele for Engadget In the realm of flagship headphones, any company’s top-of-the-line model will set you back $500 these days. I look back fondly on the time when $300-$350 got you the best Sony had to offer. While the HDB 630 is expensive, it’s also in the same ballpark of what you’ll pay for the Bose QuietComfort Ultra Headphones ($450), the Sony WH-1000XM6 ($458 currently) and the AirPods Max ($549). Each of those have their advantages over the rest of the competition, with the 1000XM6 offering the most complete package overall. However, when it comes to pure sound quality, neither of those three are at the top of the heap. Up until now, that title belonged to the Noble Audio FoKus Apollo. At $650, those headphones are even more expensive than the HDB 630, but their stock tuning will appeal to more listeners and the soundstage is wider and more immersive. There’s also Bowers & Wilkins’ Px7 S3 for a slightly cheaper $479. It delivers the company’s warm, inviting sound and attention to finer details. After spending time with the HDB 630 though, these alternatives are just that — alternatives — as the new Sennheiser headphones are now my pick for best overall sound quality. Wrap-up I get it: in the current financial climate, $500 is a lot to pay for headphones (or anything else, for that matter). You can find a number of perfectly capable sets of ANC headphones for much less given how frequently things go on sale these days. However, what you won’t find is an option that gives you anything close to the performance of audiophile-grade, open-back headphones. That’s really what Sennheiser is doing here, and the HDB 630 slots nicely into the company’s HD 600 series of high-end cans. As good as the HDB 630 is sound-wise, I can also appreciate that these aren’t the best headphones for everyone. The company’s Momentum 4 is still a very capable set of headphones and it’s now available for about $250. If you crave the best sound quality that still offers the convenience of wireless headphones — and you’re okay with a few extra steps — the HDB 630 is a worthy investment. Just don’t leave home without that dongle.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sennheiser-hdb-630-review-a-sonic-marvel-with-room-for-improvement-150000295.html?src=rss",
          "content": "High-resolution audio on the go isn’t very convenient. It typically involves wired headphones and a DAC (digital-to-analog converter) of some kind, plus your phone or another device to access files or a streaming service. All of this is necessary since Bluetooth compresses an audio signal by design, to allow for low-latency transmission and minimize battery draw. Simply put, wireless headphones haven’t been able to meet the demands of lossless audio, but Sennheiser has come the closest to fulfilling the dream with its HDB 630 ($500). Thanks to redesigned drivers, a new acoustic platform and a dongle, the company offers up to 24-bit/96kHz audio on the HDB 630 — depending on your configuration. You also get above average active noise cancellation (ANC), a highly customizable EQ, shockingly long battery life and advanced features to fine-tune the headphones to your liking. For some, the best possible sound is still only found on pricey setups and open-back headphones. For everyone else, Sennheiser has provided a taste of the audiophile life in a much more portable package. Design Sennheiser says the HDB 630 “inherited” the same chassis from its Momentum 4 headphones. That’s unfortunate because my biggest complaint with that older model's redesign is how cheap it looked compared to previous entries in the Momentum line. The HDB 630 suffers the same fate, although the splash of silver on the headband and yokes helps things a bit. Simply put, these don’t look like a set of $500 headphones, and since they’re $150 more than their predecessor was at launch, they really should have a more premium appearance. The outside of the right ear cup is still a touch panel where you can swipe, tap and even pinch to control the HDB 630. I don’t recall another set of headphones with a pinch gesture, and I’m still not convinced it’s warranted. The action is used to enable an Adaptive ANC adjustment that allows you to dial in the amount of noise blocking you need. After the pinch, sliding a single finger forwards and backwards fine tunes the mix of ANC and transparency mode. It’s a nice option to have on the headphones themselves, I just think a triple tap to activate it would be easier to master — and remember. The only other button on the HDB 630 is for power and Bluetooth pairing. Unless you’re frequently connecting these headphones to a new device, you might not be reaching for this control very often. That’s because the HDB 630 goes into standby mode when you take them off before powering down completely after 15 minutes of inactivity. You can extend that window to 30 or 60 minutes if you prefer. And if the headphones still have battery left, you can return to active mode by simply putting them back on your head. Sennheiser is betting you’ll use the HDB 630 for long listening sessions, so it outfitted these headphones with soft ear pads and a well-cushioned headband. The clamping force is adequate for a proper ANC seal, but never becomes a burden. And despite being around 20 grams heavier than the Momentum 4, this model still feels balanced and doesn’t weigh you down. Sound quality The HDB 630 features new drivers and a specially designed acoustic system. Billy Steele for Engadget While the overall design may be familiar, the sound platform for the HDB 630 is completely new. 42mm drivers offer what Sennheiser says is “neutral sound with lifelike mids, stunning detail and a wide soundstage.” In order to deliver sound quality that’s as close to open-back headphones as possible, the company overhauled the entire acoustic system, from the drivers to the baffle’s transparent mesh, in the name of balance and clarity. And since audiophile headphones typically require a dedicated external amplifier to achieve their full potential, Sennheiser included a BTD 700 USB-C dongle for high-resolution wireless audio transmission. When I first put the HDB 630 on, I thought the audio quality was good but not great. Listening over the standard definition SBC codec produced decent results, but it wasn’t anything to write home about. Once I connected to the BTD 700 dongle and unlocked 16-bit/48kHz tunes from Apple Music, though, these headphones really started to impress. As good as they are, the HDB 630 may not be for everyone. That “neutral” stock tuning places high emphasis on the midrange, so you’ll likely need to make some adjustments to get the bass performance you crave from rock, electronic, hip-hop and other genres driven by low-end tone. While I concede the neutral base is a great starting point, and the HDB 630 does indeed showcase “stunning detail,” I’d argue Sennheiser’s promise of “a wide soundstage” doesn’t always hold true. These headphones are at their best with more immersive content, like the TRON: Ares soundtrack from Nine Inch Nails. After a slight adjustment, the electronic score had the booming bass it needed, offering driving beats that nearly rattled my brain. All that was layered with rich synths and Trent Reznor’s iconic vocals. The texture and distortion in the instruments came through in greater detail too, something that’s not as apparent on other headphones and earbuds. Switch over to Thrice’s Horizons/West and the HDB 630 is a different story. Transitioning from synth-heavy electronic music to a genre like rock causes these headphones to lose some of the immersive character they are capable of delivering. You still get absurd clarity and detail, particularly in Teppei Teranishi’s guitar riffs, but the music sounds slightly flatter and a little less energetic. It’s not bad by any means, but some genres won’t envelope you as much as others do. You can also use the HDB 630 wired over USB-C for lossless-quality audio. Since a number of competitors also do this, I dedicated the bulk of my testing to see if Sennheiser’s wireless dongle is meaningfully different. Of course, I did my due diligence and tested the wired configuration a few times, and it should come as no surprise that the HDB 630 sounds just as good in that setup. Software, features and accessories There's only one button on the HDB 630. Billy Steele for Engadget As I mentioned, the HDB 630 comes with Sennheiser’s BTD 700 Bluetooth USB dongle. This enables higher quality streaming than you’ll natively get from most devices. With the BTD 700, you can expect aptX Adaptive and aptX Lossless listening up at rates to 24-bit/96kHz. The dongle also has a 30ms low-latency gaming mode, (supposedly) enhanced call performance and Auracast support for streaming to multiple headphones or speakers. The BTD 700 has a USB-C connector, but it comes with a USB-A adapter if you need it. This typically costs $60 if you buy it on its own, and since you need it to unlock the HDB 630’s full potential, it’s great to see it included in the box. The HDB 630’s settings and features are accessible in the Sennheiser Smart Control Plus app. And for this model, the company is offering a lot more customization than it does on the Accentum or Momentum headphones. First, the EQ editing options are more robust thanks to a parametric equalizer, which allows you to get a lot more detailed with your custom presets. For example, I was able to add the low-end tone I feel is missing from the stock tuning for those metal, rock and hip-hop tracks I mentioned before. And unlike a lot of headphone apps, adjusting the EQ actually improves the sound instead of just muddying things further. Another sound-related addition for the HDB 630 is Crossfeed. This allows you to blend the left and right channels so that it seems like you’re listening to speakers instead of headphones. Unfortunately, you only get two options here — Low and High — but the effect certainly enhances the sonic profile of the HDB 630 at both settings. Despite the BTD 700 dongle’s Mac and Windows compatibility, there’s no desktop version of the Smart Control Plus app. This means you’ll have to change all of your settings with the HDB 630 through your phone before you pair it with both the dongle and your computer. It would be nice if you could make EQ adjustments, create new presets and even change Crossfeed levels without having to reconnect to another device. This also means you can’t be connected to the BTD 700 and both your phone and your computer, since the dongle takes one of the two available multipoint Bluetooth slots. Active noise cancellation and call quality The HDB 630 has a very basic design with lots of plastic. Billy Steele for Engadget When it comes to ANC performance, I’m not entirely sure that the HDB 630 is better than the Momentum 4. But that’s okay. That previous model brought a significant improvement compared to Sennheiser’s older wireless headphones and the ANC is still quite good here. In fact, it was robust enough to block my family’s voices during their calls while I worked from home, and since most headphones struggle with this, that’s no mean feat. Sennheiser says the BTD 700 dongle will give you improved voice performance over the headphones alone. Specifically, the accessory should provide extended range, clearer voice pickup and, according to the company, “uninterrupted” calls. In my recorded samples, I think the headphones themselves sounded slightly better than when I captured my voice while connected to the BTD 700. However, I noticed a distinct lack of background noise in both clips, which is helpful in busier environments. I’ll also note the overall voice quality isn’t pristine, but it’s clear enough to use for work calls — even if you’re the main presenter. Battery life Sennheiser promises that you’ll get up to 60 hours of battery life on a charge with the HDB 630. That’s the same staggering figure the company claims on the Momentum 4. And yes, that’s with ANC enabled, but you’ll only achieve that if you’re listening to standard resolution tunes. Based on my testing with a mix of noise cancellation and transparency mode while I was listening to music and taking work calls, I have no reason to believe the company’s numbers don’t hold true. If you choose to listen entirely via the BTD 700’s higher quality output, you can expect up to 45 hours of use on a charge. That’s still quite a long time considering a lot of the competition runs out at around 30 hours — and that’s without high-res music. Due to all of the signal processing that helps with the acoustic performance on the HDB 630, they can only be used when they’re turned on. Unlike some wireless models, you can’t use these as wired headphones when the battery is spent. However, if you find yourself with a completely depleted battery, a 10-minute charge will give you up to seven hours of use. The company doesn’t specify streaming resolution for that number, but I assume it’s at standard definition. Still, you’ll get a few hours of higher-res music in that time, which should be enough to get you through a work session, evening commute or that new album you’re dying to play for the first time. The competition Incredible sound awaits, if you're okay to carry a dongle around with your headphones. Billy Steele for Engadget In the realm of flagship headphones, any company’s top-of-the-line model will set you back $500 these days. I look back fondly on the time when $300-$350 got you the best Sony had to offer. While the HDB 630 is expensive, it’s also in the same ballpark of what you’ll pay for the Bose QuietComfort Ultra Headphones ($450), the Sony WH-1000XM6 ($458 currently) and the AirPods Max ($549). Each of those have their advantages over the rest of the competition, with the 1000XM6 offering the most complete package overall. However, when it comes to pure sound quality, neither of those three are at the top of the heap. Up until now, that title belonged to the Noble Audio FoKus Apollo. At $650, those headphones are even more expensive than the HDB 630, but their stock tuning will appeal to more listeners and the soundstage is wider and more immersive. There’s also Bowers & Wilkins’ Px7 S3 for a slightly cheaper $479. It delivers the company’s warm, inviting sound and attention to finer details. After spending time with the HDB 630 though, these alternatives are just that — alternatives — as the new Sennheiser headphones are now my pick for best overall sound quality. Wrap-up I get it: in the current financial climate, $500 is a lot to pay for headphones (or anything else, for that matter). You can find a number of perfectly capable sets of ANC headphones for much less given how frequently things go on sale these days. However, what you won’t find is an option that gives you anything close to the performance of audiophile-grade, open-back headphones. That’s really what Sennheiser is doing here, and the HDB 630 slots nicely into the company’s HD 600 series of high-end cans. As good as the HDB 630 is sound-wise, I can also appreciate that these aren’t the best headphones for everyone. The company’s Momentum 4 is still a very capable set of headphones and it’s now available for about $250. If you crave the best sound quality that still offers the convenience of wireless headphones — and you’re okay with a few extra steps — the HDB 630 is a worthy investment. Just don’t leave home without that dongle.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sennheiser-hdb-630-review-a-sonic-marvel-with-room-for-improvement-150000295.html?src=rss",
          "feed_position": 11,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/DSC_5509.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/openais-recent-chip-deals-heap-more-pressure-on-tsmc-130000194.html",
          "published_at": "Fri, 24 Oct 2025 13:00:00 +0000",
          "title": "OpenAI's recent chip deals heap more pressure on TSMC",
          "standfirst": "In recent weeks, OpenAI has signed blockbuster deals with AMD and Broadcom to build vast numbers of AI chips. Much of the focus has been on the financial implications, since OpenAI will need hundreds of billions of dollars to make good on its promises. As important as it is to look at the quite implausible financials, we also need to look at the broader implications for the industry. Like, the chips themselves, what that spells for the AI industry as a whole, and the added pressure on TSMC, the only chip company that can actually build this stuff.The DealsOpenAI’s deal with AMD will see the chip giant build out 6 gigawatts’ (GW) worth of GPUs in the next few years. The first 1 GW deployment of AMD’s Instinct MI450 silicon will start in the back end of 2026, with more to come. AMD’s CFO Jean Hu believes that the partnership will deliver “tens of billions of dollars in revenue” in future, justifying the complicated way the deal is funded.Meanwhile, Broadcom’s deal with OpenAI will see the pair collaborate on building 10 gigawatts’ worth of AI accelerators and ethernet systems that it has designed. The latter will be crucial to speed up connections between each individual system in OpenAI’s planned data centers. Like the deal with AMD, the first deployments of these systems will begin in the back half of 2026 and is set to run through 2029.Phil Burr is head of product at Lumai, a British company looking to replace traditional GPUs with optical processors. He’s got 30 years experience in the chip world, including a stint as a senior director at ARM. Burr explained the nitty-gritty of OpenAI’s deals with both Broadcom and AMD, and what both mean for the wider world. Burr first poured water on OpenAI’s claim that it would be “designing” the gear produced by Broadcom. “Broadcom has a wide portfolio of IP blocks and pre-designed parts of a chip,” he said, “it will put those together according to the specification of the customer.” He went on to say that Broadcom will essentially put together a series of blocks it has already designed to suit the specification laid down by a customer, in this case OpenAI.Similarly, the AI accelerators Broadcom will build are geared toward more efficient running of models OpenAI has already trained and built — a process called inference in AI circles. “It can tailor the workload and reduce power, or increase performance,” said Burr, but these benefits would only work in OpenAI's favor, rather than for the wider AI industry.I asked Burr why every company in the AI space talks about gigawatts worth of chips rather than in more simple numbers. He explained that, often, it’s because both parties don’t yet know how many chips would be required to meet those lofty goals. But you could make a reasonable guess if you knew the power draw of a specific chip divided by the overall goal, then cut that number in half, then remove an extra 10 percent. “For every watt of power you burn in the chip, you need about a watt of power to cool it as well.” In terms of what OpenAI gets from these deals, Burr believes that the startup will save money on chips, since there’s “less margin” from making your own versus buying gear from NVIDIA. Plus, being able to produce custom silicon to tailor the work to their needs should see significant speed and performance gains on rival systems. Of course, the next biggest benefit is that OpenAI now has “diversity in supply,” rather than being reliant on one provider for all its needs. “Nobody wants a single supplier,” said Burr. The FactoryExcept, of course, OpenAI may be sourcing chips from a variety of its partners, but no matter what’s stamped on the silicon, it all comes from the same place. “I’d be very surprised if it wasn’t TSMC,” said Burr, “I’m pretty sure all of the AI chips out there use TSMC.” TSMC is short for Taiwan Semiconductor Manufacturing Company which, over the last decade, has blown past its major rivals to become the biggest (and in many cases only) source of bleeding-edge chips for the whole technology industry. Unlike historic rivals, which designed and manufactured their own hardware, TSMC is a pure play foundry, only building chips designed by others. Interior at one of TSMC's FabsTaiwan Semiconductor Manufacturing Co. Ltd.Gil Luria is Managing Director at head of technology research at investment firm DA Davidson. He said that TSMC isn’t just a bottleneck for the western technology industry, but in fact is the \"greatest single point of failure for the entire global economy.” Luria credits the company with an impressive expansion “considering it has had to ramp the production of GPUs tenfold over the last three years.” But said that, “in a catastrophic scenario where TSMC is not able to produce in Taiwan, the disruption would be significant.” And that won’t just affect the AI world, but “mobile handset sales as well as global car sales.” TSMC supplanted Intel for a number of well-documented reasons, but the most relevant here is its embrace of Extreme Ultraviolet Lithography (EUV). It’s a technology that Intel had initially backed, but struggled to fully adopt, allowing TSMC to pick it up and run straight to the top. EUV produces the headline-grabbing chips used by pretty much everyone in the consumer electronics world. Apple, Qualcomm, NVIDIA, AMD (including the SOCs inside the PS5 and Xbox) all use TSMC chips. Even Intel has been using TSMC foundries for some consumer CPUs as it races to bridge to gulf in manufacturing between the two companies.“TSMC is the current leader in advanced 3 nanometer (nm) process technologies,” said University of Pennsylvania Professor Benjamin C. Lee. The company’s only meaningful competitors are Intel and Samsung, neither of which pose a threat to its dominance at present. “Intel has been working for a very long time to build a foundry business,” he explained, “but has yet to perfect its interface.” Samsung is in a similar situation, but Professor Lee explained it “has been unable to attract enough customers to generate a profitable manufacturing business.” Professor Lee said that TSMC, by comparison, has become so successful because of how good its chips are, and how easy it is for clients to build chips with its tools. “TSMC fabricates chips with high yield, which is to say more of its chips emerge from the fabrication process at expected performance and reliability.” Consequently, it should be no surprise that TSMC is a money making machine. In the second quarter of 2025 alone it reported a net profit of $12.8 billion USD. And in the following three months, TSMC posted net profits of $14.76 billion. “TSMC’s secret sauce is its mastery of yield,” explained ARPU Intelligence, an analyst group that prefers to use the group name over individual attribution. “This expertise is the result of decades of accumulated process refinement [and] a deep institutional knowledge that cannot be replicated.” This deep institutional knowledge and ability to deliver high quality product creates a “powerful technical lock-in, since companies like Apple and NVIDIA design their chips specifically for TSMC’s unique manufacturing process … It’s not as simple as sending the [chip] design to another factory,” it added.The downside, at least for the wider technology industry, is that TSMC is now a bottleneck that the whole industry has come to rely upon. In the company’s most recent financials, it said more than three quarters of its business comes from North American customers. And in a call with investors, Chairman and CEO C.C. Wei talked about the efforts the company has made to narrow the gap between the enormous demand and its constrained supply. While he was reticent to be specific, he did say that the company’s capacity is “very tight,” and would likely remain that way for the foreseeable future. In fact, TSMC’s capacity is so tight that it’s already caused at least one major name a significant headache. Earlier this year, Reuters reported that NVIDIA canceled an order of its H20 AI chips after being informed the US would not permit them to be exported to China. Once the ban was lifted, however, NVIDIA was unable to find space in TSMC’s schedule, with the next available slot at least nine months later.“TSMC has no room for error,” said ARPU Intelligence, “any minor disruption can halt production with no spare capacity to absorb the shock.” It cited the Hualien earthquake which struck Taiwan on April 3, 2024, and how it negatively impacted the number of wafers in production.Naturally, TSMC is spending big to increase its production capacity for its customers, both in Taiwan and the US. Close to its home, construction on its A14 fab is expected to begin in the very near future, with the first chips due to be produced in 2028. That facility will harness TSMC’s A14 process node, producing 1.4 nm chips, which offer a speed boost over the 2nm silicon that's expected to arrive in consumer devices next year.Image of TSMC's Arizona CampusTaiwan Semiconductor Manufacturing Co. Ltd.Meanwhile, work continues apace on building out TSMC’s sprawling facility in Arizona, which broke ground in April 2021. As Reuters reported at the time, the first facility started operating in early 2025, producing 4 nm chips. Last week, NVIDIA and TSMC showed off the first Blackwell wafer produced at the Arizona plant ahead of domestic volume production.Plans for the operation have grown over time, expanding from three facilities up to six to be built over the next decade. And while the initial outline called for the US facilities to remain several process generations behind Taiwan, that is also changing. In his recent investors call, Chairman and CEO C.C. Wei pledged to invest more in the US facility to bring it only one generation behind the Taiwanese facility. No amount of investment from TSMC or catch-up from rivals like Samsung and Intel will solve the current bottleneck swiftly. It will take many years, if not decades, for the world to reduce its reliance on Taiwan for bleeding-edge manufacturing. TSMC's island remains the industry's weak point, and should something go wrong, the consequences could be dire indeed.This article originally appeared on Engadget at https://www.engadget.com/computing/openais-recent-chip-deals-heap-more-pressure-on-tsmc-130000194.html?src=rss",
          "content": "In recent weeks, OpenAI has signed blockbuster deals with AMD and Broadcom to build vast numbers of AI chips. Much of the focus has been on the financial implications, since OpenAI will need hundreds of billions of dollars to make good on its promises. As important as it is to look at the quite implausible financials, we also need to look at the broader implications for the industry. Like, the chips themselves, what that spells for the AI industry as a whole, and the added pressure on TSMC, the only chip company that can actually build this stuff.The DealsOpenAI’s deal with AMD will see the chip giant build out 6 gigawatts’ (GW) worth of GPUs in the next few years. The first 1 GW deployment of AMD’s Instinct MI450 silicon will start in the back end of 2026, with more to come. AMD’s CFO Jean Hu believes that the partnership will deliver “tens of billions of dollars in revenue” in future, justifying the complicated way the deal is funded.Meanwhile, Broadcom’s deal with OpenAI will see the pair collaborate on building 10 gigawatts’ worth of AI accelerators and ethernet systems that it has designed. The latter will be crucial to speed up connections between each individual system in OpenAI’s planned data centers. Like the deal with AMD, the first deployments of these systems will begin in the back half of 2026 and is set to run through 2029.Phil Burr is head of product at Lumai, a British company looking to replace traditional GPUs with optical processors. He’s got 30 years experience in the chip world, including a stint as a senior director at ARM. Burr explained the nitty-gritty of OpenAI’s deals with both Broadcom and AMD, and what both mean for the wider world. Burr first poured water on OpenAI’s claim that it would be “designing” the gear produced by Broadcom. “Broadcom has a wide portfolio of IP blocks and pre-designed parts of a chip,” he said, “it will put those together according to the specification of the customer.” He went on to say that Broadcom will essentially put together a series of blocks it has already designed to suit the specification laid down by a customer, in this case OpenAI.Similarly, the AI accelerators Broadcom will build are geared toward more efficient running of models OpenAI has already trained and built — a process called inference in AI circles. “It can tailor the workload and reduce power, or increase performance,” said Burr, but these benefits would only work in OpenAI's favor, rather than for the wider AI industry.I asked Burr why every company in the AI space talks about gigawatts worth of chips rather than in more simple numbers. He explained that, often, it’s because both parties don’t yet know how many chips would be required to meet those lofty goals. But you could make a reasonable guess if you knew the power draw of a specific chip divided by the overall goal, then cut that number in half, then remove an extra 10 percent. “For every watt of power you burn in the chip, you need about a watt of power to cool it as well.” In terms of what OpenAI gets from these deals, Burr believes that the startup will save money on chips, since there’s “less margin” from making your own versus buying gear from NVIDIA. Plus, being able to produce custom silicon to tailor the work to their needs should see significant speed and performance gains on rival systems. Of course, the next biggest benefit is that OpenAI now has “diversity in supply,” rather than being reliant on one provider for all its needs. “Nobody wants a single supplier,” said Burr. The FactoryExcept, of course, OpenAI may be sourcing chips from a variety of its partners, but no matter what’s stamped on the silicon, it all comes from the same place. “I’d be very surprised if it wasn’t TSMC,” said Burr, “I’m pretty sure all of the AI chips out there use TSMC.” TSMC is short for Taiwan Semiconductor Manufacturing Company which, over the last decade, has blown past its major rivals to become the biggest (and in many cases only) source of bleeding-edge chips for the whole technology industry. Unlike historic rivals, which designed and manufactured their own hardware, TSMC is a pure play foundry, only building chips designed by others. Interior at one of TSMC's FabsTaiwan Semiconductor Manufacturing Co. Ltd.Gil Luria is Managing Director at head of technology research at investment firm DA Davidson. He said that TSMC isn’t just a bottleneck for the western technology industry, but in fact is the \"greatest single point of failure for the entire global economy.” Luria credits the company with an impressive expansion “considering it has had to ramp the production of GPUs tenfold over the last three years.” But said that, “in a catastrophic scenario where TSMC is not able to produce in Taiwan, the disruption would be significant.” And that won’t just affect the AI world, but “mobile handset sales as well as global car sales.” TSMC supplanted Intel for a number of well-documented reasons, but the most relevant here is its embrace of Extreme Ultraviolet Lithography (EUV). It’s a technology that Intel had initially backed, but struggled to fully adopt, allowing TSMC to pick it up and run straight to the top. EUV produces the headline-grabbing chips used by pretty much everyone in the consumer electronics world. Apple, Qualcomm, NVIDIA, AMD (including the SOCs inside the PS5 and Xbox) all use TSMC chips. Even Intel has been using TSMC foundries for some consumer CPUs as it races to bridge to gulf in manufacturing between the two companies.“TSMC is the current leader in advanced 3 nanometer (nm) process technologies,” said University of Pennsylvania Professor Benjamin C. Lee. The company’s only meaningful competitors are Intel and Samsung, neither of which pose a threat to its dominance at present. “Intel has been working for a very long time to build a foundry business,” he explained, “but has yet to perfect its interface.” Samsung is in a similar situation, but Professor Lee explained it “has been unable to attract enough customers to generate a profitable manufacturing business.” Professor Lee said that TSMC, by comparison, has become so successful because of how good its chips are, and how easy it is for clients to build chips with its tools. “TSMC fabricates chips with high yield, which is to say more of its chips emerge from the fabrication process at expected performance and reliability.” Consequently, it should be no surprise that TSMC is a money making machine. In the second quarter of 2025 alone it reported a net profit of $12.8 billion USD. And in the following three months, TSMC posted net profits of $14.76 billion. “TSMC’s secret sauce is its mastery of yield,” explained ARPU Intelligence, an analyst group that prefers to use the group name over individual attribution. “This expertise is the result of decades of accumulated process refinement [and] a deep institutional knowledge that cannot be replicated.” This deep institutional knowledge and ability to deliver high quality product creates a “powerful technical lock-in, since companies like Apple and NVIDIA design their chips specifically for TSMC’s unique manufacturing process … It’s not as simple as sending the [chip] design to another factory,” it added.The downside, at least for the wider technology industry, is that TSMC is now a bottleneck that the whole industry has come to rely upon. In the company’s most recent financials, it said more than three quarters of its business comes from North American customers. And in a call with investors, Chairman and CEO C.C. Wei talked about the efforts the company has made to narrow the gap between the enormous demand and its constrained supply. While he was reticent to be specific, he did say that the company’s capacity is “very tight,” and would likely remain that way for the foreseeable future. In fact, TSMC’s capacity is so tight that it’s already caused at least one major name a significant headache. Earlier this year, Reuters reported that NVIDIA canceled an order of its H20 AI chips after being informed the US would not permit them to be exported to China. Once the ban was lifted, however, NVIDIA was unable to find space in TSMC’s schedule, with the next available slot at least nine months later.“TSMC has no room for error,” said ARPU Intelligence, “any minor disruption can halt production with no spare capacity to absorb the shock.” It cited the Hualien earthquake which struck Taiwan on April 3, 2024, and how it negatively impacted the number of wafers in production.Naturally, TSMC is spending big to increase its production capacity for its customers, both in Taiwan and the US. Close to its home, construction on its A14 fab is expected to begin in the very near future, with the first chips due to be produced in 2028. That facility will harness TSMC’s A14 process node, producing 1.4 nm chips, which offer a speed boost over the 2nm silicon that's expected to arrive in consumer devices next year.Image of TSMC's Arizona CampusTaiwan Semiconductor Manufacturing Co. Ltd.Meanwhile, work continues apace on building out TSMC’s sprawling facility in Arizona, which broke ground in April 2021. As Reuters reported at the time, the first facility started operating in early 2025, producing 4 nm chips. Last week, NVIDIA and TSMC showed off the first Blackwell wafer produced at the Arizona plant ahead of domestic volume production.Plans for the operation have grown over time, expanding from three facilities up to six to be built over the next decade. And while the initial outline called for the US facilities to remain several process generations behind Taiwan, that is also changing. In his recent investors call, Chairman and CEO C.C. Wei pledged to invest more in the US facility to bring it only one generation behind the Taiwanese facility. No amount of investment from TSMC or catch-up from rivals like Samsung and Intel will solve the current bottleneck swiftly. It will take many years, if not decades, for the world to reduce its reliance on Taiwan for bleeding-edge manufacturing. TSMC's island remains the industry's weak point, and should something go wrong, the consequences could be dire indeed.This article originally appeared on Engadget at https://www.engadget.com/computing/openais-recent-chip-deals-heap-more-pressure-on-tsmc-130000194.html?src=rss",
          "feed_position": 14,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/Fab14inr015_902_01.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-111555814.html",
          "published_at": "Fri, 24 Oct 2025 11:15:55 +0000",
          "title": "The Morning After: Samsung’s Galaxy XR enters the chat",
          "standfirst": "This week, Samsung showed off Galaxy XR, its Vision Pro-troubling headset, and you can bet we’ve done a deep dive. Sam Rutherford got one of these strapped to his head and has plenty of feelings about the new hardware. The headset is lighter, more comfortable and easier to live with than Apple’s Vision Pro, even if it lacks many of its headline features. The software ecosystem is already pretty broad, thanks to Google making a real effort with Android XR, but dedicated apps are still a bit rare. Samsung’s entry into the market might provide some much-needed impetus for this type of augmented reality headset. That it’s half the price of Apple’s Vision Pro may also loosen some wallets eager to get into this world. But it’s hard not to see this as Samsung running down the same cul-de-sac Apple is now lurking at the end of. It has allowed other companies, like Meta, to waltz in and grab an early lead in the much more useful smart glasses market. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed The first e-bike from Rivian spinoff Also has a virtual drivetrainI’m more interested in its Bakfiets-esque quad bike for driving kids around. Amazon’s smart glasses with AI will help its drivers deliver packages fasterIt’s just like RoboCop, only with more peeing in bottles. ChatGPT in WhatsApp will stop working in JanuaryMeta is kicking its AI rival off its platform. Apple MacBook Pro M5 14-inch review: A huge graphics upgrade for creators and gamers The GPU is the star here. Devindra Hardawar for Engadget Apple’s online-only announcement of the new vanilla M5 MacBooks might have been a sign the new models were no big deal. But Devindra Hardawar found these were, in fact, quite a big deal, and the M5’s faster GPU has the chops to go toe-to-toe with a gaming PC. Continue Reading. Toyota’s new all-hybrid RAV4 has software you might actually want to use It wants to offer a better alternative to your smartphone. Tim Stevens for Engadget Toyota isn’t happy folks just default to CarPlay or Android Auto for their in-car infotainment. That’s why it’s chosen to radically redesign its OS for the 2026 RAV4 to include voice and touch control. Tim Stevens has ridden the new whip and has plenty of opinions on whether it’s worth your time or, you know… you’ll just default to CarPlay or Android Auto. Continue Reading. iPad Pro M5 review: Speed boost We reviewed the iPad Pro M5 and had some feelings. Nathan Ingraham for Engadget As much as I may want an iPad Pro, it wouldn’t play a role in my life that would get anywhere near to justifying its extortionate price. Consequently, I shall just live vicariously through Nathan Ingraham, who reviewed the M5 edition and found it to be a work of art. But, you know, it has a price so eye-watering that nobody who’s on the fence about owning one should bother. Then, Nate pivoted to writing about how the iPad Pro has, at least, carved out its own identity. Continue Reading. New report leaks Amazon’s proposed mass-automation plans It plans to replace more than half a million employees. Amazon may be planning to use automation to eliminate more than half a million jobs in the next few years. The New York Times claims to have seen internal documents outlining the plans and the PR operation that’ll get underway ahead of time to quell public anger. Continue Reading. Binance founder Changpeng Zhao lands a Trump pardon Nothing to see here, move along. Maybe there’s nothing interesting about the fact Changpeng Zhao was just pardoned by President Trump despite pleading guilty to violating the Bank Secrecy Act. I mean, yes, Zhao has ties to World Liberty Financial, a cryptocurrency venture linked to the Trump family. But that’s not uncommon, is it? Surely everyone would use the privilege of high office to exonerate people with whom they potentially have fruitful relationships. Right? Continue Reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111555814.html?src=rss",
          "content": "This week, Samsung showed off Galaxy XR, its Vision Pro-troubling headset, and you can bet we’ve done a deep dive. Sam Rutherford got one of these strapped to his head and has plenty of feelings about the new hardware. The headset is lighter, more comfortable and easier to live with than Apple’s Vision Pro, even if it lacks many of its headline features. The software ecosystem is already pretty broad, thanks to Google making a real effort with Android XR, but dedicated apps are still a bit rare. Samsung’s entry into the market might provide some much-needed impetus for this type of augmented reality headset. That it’s half the price of Apple’s Vision Pro may also loosen some wallets eager to get into this world. But it’s hard not to see this as Samsung running down the same cul-de-sac Apple is now lurking at the end of. It has allowed other companies, like Meta, to waltz in and grab an early lead in the much more useful smart glasses market. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed The first e-bike from Rivian spinoff Also has a virtual drivetrainI’m more interested in its Bakfiets-esque quad bike for driving kids around. Amazon’s smart glasses with AI will help its drivers deliver packages fasterIt’s just like RoboCop, only with more peeing in bottles. ChatGPT in WhatsApp will stop working in JanuaryMeta is kicking its AI rival off its platform. Apple MacBook Pro M5 14-inch review: A huge graphics upgrade for creators and gamers The GPU is the star here. Devindra Hardawar for Engadget Apple’s online-only announcement of the new vanilla M5 MacBooks might have been a sign the new models were no big deal. But Devindra Hardawar found these were, in fact, quite a big deal, and the M5’s faster GPU has the chops to go toe-to-toe with a gaming PC. Continue Reading. Toyota’s new all-hybrid RAV4 has software you might actually want to use It wants to offer a better alternative to your smartphone. Tim Stevens for Engadget Toyota isn’t happy folks just default to CarPlay or Android Auto for their in-car infotainment. That’s why it’s chosen to radically redesign its OS for the 2026 RAV4 to include voice and touch control. Tim Stevens has ridden the new whip and has plenty of opinions on whether it’s worth your time or, you know… you’ll just default to CarPlay or Android Auto. Continue Reading. iPad Pro M5 review: Speed boost We reviewed the iPad Pro M5 and had some feelings. Nathan Ingraham for Engadget As much as I may want an iPad Pro, it wouldn’t play a role in my life that would get anywhere near to justifying its extortionate price. Consequently, I shall just live vicariously through Nathan Ingraham, who reviewed the M5 edition and found it to be a work of art. But, you know, it has a price so eye-watering that nobody who’s on the fence about owning one should bother. Then, Nate pivoted to writing about how the iPad Pro has, at least, carved out its own identity. Continue Reading. New report leaks Amazon’s proposed mass-automation plans It plans to replace more than half a million employees. Amazon may be planning to use automation to eliminate more than half a million jobs in the next few years. The New York Times claims to have seen internal documents outlining the plans and the PR operation that’ll get underway ahead of time to quell public anger. Continue Reading. Binance founder Changpeng Zhao lands a Trump pardon Nothing to see here, move along. Maybe there’s nothing interesting about the fact Changpeng Zhao was just pardoned by President Trump despite pleading guilty to violating the Bank Secrecy Act. I mean, yes, Zhao has ties to World Liberty Financial, a cryptocurrency venture linked to the Trump family. But that’s not uncommon, is it? Surely everyone would use the privilege of high office to exonerate people with whom they potentially have fruitful relationships. Right? Continue Reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111555814.html?src=rss",
          "feed_position": 21,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/1c5c79b0-b0bf-11f0-873f-6093239f799f"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-headphones-for-running-120044637.html",
          "published_at": "Fri, 24 Oct 2025 09:00:35 +0000",
          "title": "The best headphones for running in 2025",
          "standfirst": "Whether you’re already an avid runner or hope to be one as you start a new training regimen, you’ll get more out of your exercise routine if you have some good music to accompany you. Getting into the zone during a long run with your preferred music, be it rap, classic rock or today’s pop hits, can totally change your experience for the better. To do that, you have to start with a good pair of running headphones.But not all wireless workout headphones are created equally, and runners need to consider specific factors before investing in a pair like how long your runs are, what type of music or other audio you prefer listening to and how much you want to block out the world during a session. I’ve tested out more than a dozen pairs to find which are the best headphones for running for all budgets and all kinds of runners. Table of contents Best headphones for running in 2025 What to look for in running headphones How we test headphones for running Others headphones for running we tested Best headphones for running in 2025 Others headphones for running we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in running headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear Bluetooth headphones during a run, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Water resistance and dust protection are crucial for the best running headphones to have since you’ll likely be sweating while wearing them. Also, if you have the unfortunate luck of getting caught in the rain during a run, at least your gear will survive. Here’s a quick rundown of ingress protection (IP) ratings, which you’ll see attached to many earbuds on the market today. The first digit after the abbreviation rates dust protection on a scale from one to six — the higher, the better. The second digit refers to water- resistance, or waterproofing in some cases, ranked on a scale from one to nine. A letter “X” in either position means the device isn’t rated for the corresponding material. Check out this guide for an even more detailed breakdown. All of the earbuds we tested for this guide have at least an IPX4 rating (most have even more protection), which means they can withstand sweat and splashes but do not have dust protection. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming a standard feature on wireless earbuds, at least in those above a certain price. If you’re looking for a pair of buds that can be your workout companion and continue to serve you when you’re off the trail, ANC is good to have. It adds versatility by allowing you to block out the hum of your home or office so you can focus, or give you some solitude during a busy commute on public transit. But an earbud’s ability to block out the world goes hand in hand with its ability to open things back up should you need it. Many earbuds with ANC support some sort of “transparency mode” or various levels of noise reduction. This is important for running headphones because you don’t want to be totally oblivious to what’s going on around you when you’re exercising outside along busy streets. Lowering noise cancelation levels to increase your awareness will help with that. Battery life All of the earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most runners, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. Speaking of, you’ll get an average of 20-28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test headphones for running When testing to determine the best running headphones, I wear each contender during as many runs as possible. I typically run three to five days each week, completing at least a 5K (3.01 miles) each time. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you’re on the tread or trail (as a note, I primarily run outside). I’m also paying attention to fit over time, particularly if the earbuds get slippery or loose while I sweat, or if they tend to pop out or feel less stable in my ears as I pick up speed or make quick movements. I also use the earbuds when not running to take calls and listen to music, podcasts and the like throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also listening for audio quality, I’m admittedly not an expert in this space. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about sound quality for some of our top picks in his reviews and buying guides. Here, however, I will make note of audio-quality characteristics if they stood out to me (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’re able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-for-running-120044637.html?src=rss",
          "content": "Whether you’re already an avid runner or hope to be one as you start a new training regimen, you’ll get more out of your exercise routine if you have some good music to accompany you. Getting into the zone during a long run with your preferred music, be it rap, classic rock or today’s pop hits, can totally change your experience for the better. To do that, you have to start with a good pair of running headphones.But not all wireless workout headphones are created equally, and runners need to consider specific factors before investing in a pair like how long your runs are, what type of music or other audio you prefer listening to and how much you want to block out the world during a session. I’ve tested out more than a dozen pairs to find which are the best headphones for running for all budgets and all kinds of runners. Table of contents Best headphones for running in 2025 What to look for in running headphones How we test headphones for running Others headphones for running we tested Best headphones for running in 2025 Others headphones for running we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in running headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear Bluetooth headphones during a run, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Water resistance and dust protection are crucial for the best running headphones to have since you’ll likely be sweating while wearing them. Also, if you have the unfortunate luck of getting caught in the rain during a run, at least your gear will survive. Here’s a quick rundown of ingress protection (IP) ratings, which you’ll see attached to many earbuds on the market today. The first digit after the abbreviation rates dust protection on a scale from one to six — the higher, the better. The second digit refers to water- resistance, or waterproofing in some cases, ranked on a scale from one to nine. A letter “X” in either position means the device isn’t rated for the corresponding material. Check out this guide for an even more detailed breakdown. All of the earbuds we tested for this guide have at least an IPX4 rating (most have even more protection), which means they can withstand sweat and splashes but do not have dust protection. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming a standard feature on wireless earbuds, at least in those above a certain price. If you’re looking for a pair of buds that can be your workout companion and continue to serve you when you’re off the trail, ANC is good to have. It adds versatility by allowing you to block out the hum of your home or office so you can focus, or give you some solitude during a busy commute on public transit. But an earbud’s ability to block out the world goes hand in hand with its ability to open things back up should you need it. Many earbuds with ANC support some sort of “transparency mode” or various levels of noise reduction. This is important for running headphones because you don’t want to be totally oblivious to what’s going on around you when you’re exercising outside along busy streets. Lowering noise cancelation levels to increase your awareness will help with that. Battery life All of the earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most runners, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. Speaking of, you’ll get an average of 20-28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test headphones for running When testing to determine the best running headphones, I wear each contender during as many runs as possible. I typically run three to five days each week, completing at least a 5K (3.01 miles) each time. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you’re on the tread or trail (as a note, I primarily run outside). I’m also paying attention to fit over time, particularly if the earbuds get slippery or loose while I sweat, or if they tend to pop out or feel less stable in my ears as I pick up speed or make quick movements. I also use the earbuds when not running to take calls and listen to music, podcasts and the like throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also listening for audio quality, I’m admittedly not an expert in this space. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about sound quality for some of our top picks in his reviews and buying guides. Here, however, I will make note of audio-quality characteristics if they stood out to me (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’re able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-for-running-120044637.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/best-ipads-how-to-pick-the-best-apple-tablet-for-you-150054066.html",
          "published_at": "Fri, 24 Oct 2025 07:00:37 +0000",
          "title": "The best iPad for 2025: How to pick the best Apple tablet for you",
          "standfirst": "We’ve long considered Apple’s iPads to be the best tablets on the market, but determining exactly which model you should buy isn’t always straightforward. Do you just want a big screen for streaming and web browsing? Do you want to use it like a pseudo-laptop? Do you care about Apple Intelligence at all? If you’re not sure, allow us to help. We’ve tested every iPad available today and broken down which ones should best fit your needs below. Table of contents The best iPads for 2025 How we test the best iPads iPad FAQs Recent updates The best iPads for 2025 How we test the best iPads The top edge of the iPad mini. Photo by Nathan Ingraham / Engadget Much like we do for our guide to the best tablets overall, we spend several days with each iPad to see how they feel and perform with different tasks: watching videos, web browsing, playing both casual and graphically intense games, editing 4K photos and video, running multiple apps side-by-side, making FaceTime calls and the like. To better measure performance specifically, we use benchmarking tests like Geekbench 6, 3DMark and GFXBench Metal, plus we measure how long it takes for each tablet to boot up and open various apps. We also check how well each tablet holds up long-term, whether it’s with a review unit provided by Apple or an iPad model that’s owned by a member of the Engadget staff. To help compare the color performance and brightness of the displays, we play the same videos on different iPads, side-by-side, at equal brightness levels. We use each tablet in direct sunlight outdoors to see how well they hold up to glare, and we play a handful of the same musical tracks to evaluate speaker performance. For battery life, we keep track of how long each tablet generally lasts before it needs a recharge, but we also play a 1080p movie on a loop at roughly 70 percent brightness with power-sapping background processes off. We also test each device with an Apple Pencil and note how responsive the stylus feels. Finally, we carefully pore over spec sheets and software updates to keep track of which features are available on certain iPads but not others. iPad FAQs The iPad (A16) on top of an 13-inch iPad Air. Jeff Dunn for Engadget What are some new features coming to iPadOS 26? Apple released the latest update to its iPad operating system, iPadOS 26, in September. The update is a fairly significant overhaul, one that brings iPadOS closer to macOS than ever before. New features include the ability to open more windows simultaneously and resize or tile them more freely; a Mac-style Menu bar; a dedicated Preview app; an upgraded Files app; an improved ability to export or download large files in the background; an Exposé view that shows all open windows; a pointier cursor and the option to add folders to the Dock. It also uses the new “liquid glass” design language that Apple is rolling out across all of its platforms in 2025. That said, it completely removed the “slide over” and “split view” modes found in previous versions of iPadOS, which can make quickly viewing multiple apps at once a little more cumbersome. (Though the former will now return in an upcoming update.) Notably, most of these features are available across Apple’s tablet lineup, from the iPad Pro to the entry-level iPad. You can find the full list of compatible devices at the bottom of Apple’s overview page. How long do iPads typically last? If history is any indication, expect Apple to update your iPad to the latest version of iPadOS for at least five years, if not longer. The current iPadOS 26 update, for example, is available on iPad Pro models dating back to 2018 and other iPads dating back to 2019. How long your iPad’s hardware will last depends on which model you buy and how well you maintain it. (If you’re particularly clumsy, consider an iPad case.) A more powerful iPad Pro will feel fast for a longer time than an entry-level iPad, but each model should remain at least serviceable until Apple stops updating it, at minimum. What’s the difference between the iPad and the iPad Air? Compared to the standard iPad, the iPad Air runs on a stronger M3 chip (instead of the A16 Bionic) and has 2GB more RAM (8GB total). Both come with 128GB of storage by default. The Air is also available in two sizes, 11 and 13 inches, whereas the 11th-gen iPad doesn't offer the larger screen option. The M-series SoC gives the Air better long-term performance prospects, plus access to certain iPadOS features such as Apple Intelligence. Its display supports a wider P3 color gamut, has an antireflective coating and is fully laminated. The latter means there’s no “air gap” between the display and the glass covering it, so it feels more like you’re directly touching what’s on screen instead of interacting with an image below the glass. The Air also works with the newer Pencil Pro stylus and more comfortable Magic Keyboards, and its USB-C port supports faster data transfer speeds. It technically supports faster Wi-Fi 6E, too, while the lower-cost iPad uses Wi-Fi 6. Starting at $349, the 11th-gen iPad is $250 less expensive than the iPad Air. It has a similarly elegant design with flat edges, thin bezels, USB-C port, and a Touch ID reader. Battery life is rated at the same 10 hours, and both devices have their front-facing camera on their long edge, which is a more natural position for video calls. The cheaper iPad works with the first-gen and USB-C Apple Pencils – which are more convoluted to charge – and a unique keyboard accessory called the Magic Keyboard Folio. Jeff Dunn for Engadget What’s the difference between iPads and Android tablets? The operating system, duh. But to give a few more specifics: Android devices are available from more manufacturers and cover a wider price range. You won’t see an $80 iPad anytime soon. Android is also more malleable in that you can easily sideload apps from places beyond Google’s official app store and more extensively customize the look of the OS (though the former may no longer be an option in the coming months). Several Android tablets still have features like a headphone jack or a microSD slot for adding storage, too, though those are getting rarer. But we tend to recommend Apple tablets to those who have no allegiance either way. iPad apps are still a bit more likely to be designed specifically for larger screens, rather than looking like blown-up phone software, and Apple is just about peerless when it comes to long-term software support. Every new iPad hits a certain baseline of hardware quality and performance — none of them feel cheap, and all of them are fast enough for most needs. Plus, you’ll get the most out of an iPad if you use other Apple devices. Can an iPad replace a laptop? This is a loaded question, since laptop workflows differ from person to person. If you mostly use a notebook for browsing the web, watching videos or writing emails and word docs, then sure, you can get along just fine with an iPad and the right iPad accessories. It’ll be easier to carry around, the battery life is great and having the touchscreen and stylus support is handy (though many Windows users have that regardless). Even beyond the basics, plenty of media editors, graphic designers and digital artists have shown they can get things done on an iPad. Broadly speaking, though, a laptop OS tends to be more flexible when it comes to file management, multitasking, coding or other “heavy” tasks. The recent iPadOS 26 update does close the gap a bit, though it’s still not quite as fluid. Safari on the iPad isn’t fully on par with desktop browsers either. So the answer really depends on you. How do I take a screenshot on an iPad? As we note in our screenshot how-to guide, you can take a screenshot on your iPad by pressing the top button and either volume button at the same time. If you have an older iPad with a Home button, simultaneously press the top button and the Home button instead. Recent updates Late October 2025: The new M5-based iPad Pro replaces the previous-generation iPad Pro as our top pick for power users. Early October 2025: We’ve made a few edits to reflect the full release of iPadOS 26 and made sure our recommendations are still accurate. August 2025: We've taken another sweep to ensure our picks are still accurate and added a few more notes to our FAQ section. June 2025: We’ve made a few minor edits to reflect the announcement of Apple’s latest iPadOS update, which we detail above. May 2025: We’ve lightly edited this guide to ensure all details and links are still correct. We’re also keeping an eye on how the Trump administration’s tariff policy affects the pricing and stock of the iPad lineup (and every other tech category). All of our picks are still available at normal prices today, but we’ll update this guide if that changes. March 2025: We've reviewed the iPad (A16) and named it our new budget pick, removing the discontinued 10th-gen iPad in the process. March 2025: The recently-launched iPad Air M3 has replaced its predecessor as our top overall recommendation. We’ve also made a note regarding the new iPad (A16), which we plan to test in the near future and expect to become our new budget pick. We’ve made a handful of edits elsewhere in the guide to reflect Apple’s latest hardware. January 2025: We’ve lightly edited this guide for clarity. Our recommendations remain the same. October 2024: We've updated our guide to include the new iPad mini 7. June 2024: We’ve touched up this guide to reflect some of the new iPadOS features Apple announced at WWDC, though our picks remain the same. Nathan Ingraham contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-ipads-how-to-pick-the-best-apple-tablet-for-you-150054066.html?src=rss",
          "content": "We’ve long considered Apple’s iPads to be the best tablets on the market, but determining exactly which model you should buy isn’t always straightforward. Do you just want a big screen for streaming and web browsing? Do you want to use it like a pseudo-laptop? Do you care about Apple Intelligence at all? If you’re not sure, allow us to help. We’ve tested every iPad available today and broken down which ones should best fit your needs below. Table of contents The best iPads for 2025 How we test the best iPads iPad FAQs Recent updates The best iPads for 2025 How we test the best iPads The top edge of the iPad mini. Photo by Nathan Ingraham / Engadget Much like we do for our guide to the best tablets overall, we spend several days with each iPad to see how they feel and perform with different tasks: watching videos, web browsing, playing both casual and graphically intense games, editing 4K photos and video, running multiple apps side-by-side, making FaceTime calls and the like. To better measure performance specifically, we use benchmarking tests like Geekbench 6, 3DMark and GFXBench Metal, plus we measure how long it takes for each tablet to boot up and open various apps. We also check how well each tablet holds up long-term, whether it’s with a review unit provided by Apple or an iPad model that’s owned by a member of the Engadget staff. To help compare the color performance and brightness of the displays, we play the same videos on different iPads, side-by-side, at equal brightness levels. We use each tablet in direct sunlight outdoors to see how well they hold up to glare, and we play a handful of the same musical tracks to evaluate speaker performance. For battery life, we keep track of how long each tablet generally lasts before it needs a recharge, but we also play a 1080p movie on a loop at roughly 70 percent brightness with power-sapping background processes off. We also test each device with an Apple Pencil and note how responsive the stylus feels. Finally, we carefully pore over spec sheets and software updates to keep track of which features are available on certain iPads but not others. iPad FAQs The iPad (A16) on top of an 13-inch iPad Air. Jeff Dunn for Engadget What are some new features coming to iPadOS 26? Apple released the latest update to its iPad operating system, iPadOS 26, in September. The update is a fairly significant overhaul, one that brings iPadOS closer to macOS than ever before. New features include the ability to open more windows simultaneously and resize or tile them more freely; a Mac-style Menu bar; a dedicated Preview app; an upgraded Files app; an improved ability to export or download large files in the background; an Exposé view that shows all open windows; a pointier cursor and the option to add folders to the Dock. It also uses the new “liquid glass” design language that Apple is rolling out across all of its platforms in 2025. That said, it completely removed the “slide over” and “split view” modes found in previous versions of iPadOS, which can make quickly viewing multiple apps at once a little more cumbersome. (Though the former will now return in an upcoming update.) Notably, most of these features are available across Apple’s tablet lineup, from the iPad Pro to the entry-level iPad. You can find the full list of compatible devices at the bottom of Apple’s overview page. How long do iPads typically last? If history is any indication, expect Apple to update your iPad to the latest version of iPadOS for at least five years, if not longer. The current iPadOS 26 update, for example, is available on iPad Pro models dating back to 2018 and other iPads dating back to 2019. How long your iPad’s hardware will last depends on which model you buy and how well you maintain it. (If you’re particularly clumsy, consider an iPad case.) A more powerful iPad Pro will feel fast for a longer time than an entry-level iPad, but each model should remain at least serviceable until Apple stops updating it, at minimum. What’s the difference between the iPad and the iPad Air? Compared to the standard iPad, the iPad Air runs on a stronger M3 chip (instead of the A16 Bionic) and has 2GB more RAM (8GB total). Both come with 128GB of storage by default. The Air is also available in two sizes, 11 and 13 inches, whereas the 11th-gen iPad doesn't offer the larger screen option. The M-series SoC gives the Air better long-term performance prospects, plus access to certain iPadOS features such as Apple Intelligence. Its display supports a wider P3 color gamut, has an antireflective coating and is fully laminated. The latter means there’s no “air gap” between the display and the glass covering it, so it feels more like you’re directly touching what’s on screen instead of interacting with an image below the glass. The Air also works with the newer Pencil Pro stylus and more comfortable Magic Keyboards, and its USB-C port supports faster data transfer speeds. It technically supports faster Wi-Fi 6E, too, while the lower-cost iPad uses Wi-Fi 6. Starting at $349, the 11th-gen iPad is $250 less expensive than the iPad Air. It has a similarly elegant design with flat edges, thin bezels, USB-C port, and a Touch ID reader. Battery life is rated at the same 10 hours, and both devices have their front-facing camera on their long edge, which is a more natural position for video calls. The cheaper iPad works with the first-gen and USB-C Apple Pencils – which are more convoluted to charge – and a unique keyboard accessory called the Magic Keyboard Folio. Jeff Dunn for Engadget What’s the difference between iPads and Android tablets? The operating system, duh. But to give a few more specifics: Android devices are available from more manufacturers and cover a wider price range. You won’t see an $80 iPad anytime soon. Android is also more malleable in that you can easily sideload apps from places beyond Google’s official app store and more extensively customize the look of the OS (though the former may no longer be an option in the coming months). Several Android tablets still have features like a headphone jack or a microSD slot for adding storage, too, though those are getting rarer. But we tend to recommend Apple tablets to those who have no allegiance either way. iPad apps are still a bit more likely to be designed specifically for larger screens, rather than looking like blown-up phone software, and Apple is just about peerless when it comes to long-term software support. Every new iPad hits a certain baseline of hardware quality and performance — none of them feel cheap, and all of them are fast enough for most needs. Plus, you’ll get the most out of an iPad if you use other Apple devices. Can an iPad replace a laptop? This is a loaded question, since laptop workflows differ from person to person. If you mostly use a notebook for browsing the web, watching videos or writing emails and word docs, then sure, you can get along just fine with an iPad and the right iPad accessories. It’ll be easier to carry around, the battery life is great and having the touchscreen and stylus support is handy (though many Windows users have that regardless). Even beyond the basics, plenty of media editors, graphic designers and digital artists have shown they can get things done on an iPad. Broadly speaking, though, a laptop OS tends to be more flexible when it comes to file management, multitasking, coding or other “heavy” tasks. The recent iPadOS 26 update does close the gap a bit, though it’s still not quite as fluid. Safari on the iPad isn’t fully on par with desktop browsers either. So the answer really depends on you. How do I take a screenshot on an iPad? As we note in our screenshot how-to guide, you can take a screenshot on your iPad by pressing the top button and either volume button at the same time. If you have an older iPad with a Home button, simultaneously press the top button and the Home button instead. Recent updates Late October 2025: The new M5-based iPad Pro replaces the previous-generation iPad Pro as our top pick for power users. Early October 2025: We’ve made a few edits to reflect the full release of iPadOS 26 and made sure our recommendations are still accurate. August 2025: We've taken another sweep to ensure our picks are still accurate and added a few more notes to our FAQ section. June 2025: We’ve made a few minor edits to reflect the announcement of Apple’s latest iPadOS update, which we detail above. May 2025: We’ve lightly edited this guide to ensure all details and links are still correct. We’re also keeping an eye on how the Trump administration’s tariff policy affects the pricing and stock of the iPad lineup (and every other tech category). All of our picks are still available at normal prices today, but we’ll update this guide if that changes. March 2025: We've reviewed the iPad (A16) and named it our new budget pick, removing the discontinued 10th-gen iPad in the process. March 2025: The recently-launched iPad Air M3 has replaced its predecessor as our top overall recommendation. We’ve also made a note regarding the new iPad (A16), which we plan to test in the near future and expect to become our new budget pick. We’ve made a handful of edits elsewhere in the guide to reflect Apple’s latest hardware. January 2025: We’ve lightly edited this guide for clarity. Our recommendations remain the same. October 2024: We've updated our guide to include the new iPad mini 7. June 2024: We’ve touched up this guide to reflect some of the new iPadOS features Apple announced at WWDC, though our picks remain the same. Nathan Ingraham contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-ipads-how-to-pick-the-best-apple-tablet-for-you-150054066.html?src=rss",
          "feed_position": 23,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2024-10/ded6eb30-8fee-11ef-bfcf-f1599e27e076"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html",
          "published_at": "Fri, 24 Oct 2025 00:00:35 +0000",
          "title": "The best VPN service for 2025",
          "standfirst": "As frustrating as it is that governments and businesses are running roughshod over our online freedoms, at least we have plenty of good VPNs to choose from to keep us protected online. There are so many fast, intelligently designed, full-featured and affordable services on the market that the biggest problem is picking one. For any use case, you can bet at least two providers will be neck-and-neck for first place.On the other hand, the VPN world is still the Wild West in some ways. It's easy enough to slap a cheap VPN together that the market is flooded with low-quality apps that put more money into advertising than infrastructure. They may look good, but it's all styrofoam under the hood.I built this list of the best VPNs after intensive testing to help you reorient your focus on the providers that actually deserve your time and money. Which one truly fits your needs is dependent on who you are and what you do online, but if you pick any of my seven recommendations, you can't go too far wrong.For each VPN on this list, I've shared which platforms it works on, how much it cuts into your download speed, where it offers servers, what other features are included and how much the best available deal costs. At the end, I'll list some honorable and dishonorable mentions, then answer some of the most common questions I hear about VPNs.Editor's note: This list has been completely overhauled and rewritten as of September 2025. We intend to revisit this list every three months at a minimum, at which time our picks may be adjusted based on changes in pricing, features, testing results and other factors. Table of contents Best VPNs for 2025 Other VPNs we tested What to look for in a VPN VPN FAQs Best VPNs for 2025 Other VPNs we tested The VPNs in this section didn't crack our top list above, but we're summarizing them here so you can see their positives and negatives as of the time of our evaluation. Windscribe Windscribe is another well-known free VPN supported by paid subscriptions. In many ways, it takes the best from both Mullvad and Proton VPN, with the former's no-nonsense privacy and the latter's healthy free plan. Without paying, you can connect to 10 of Windscribe's server locations on an unlimited number of devices at once. Unfortunately, Windscribe didn't copy the most important part of Proton VPN's free plan — the unlimited data. You're only allowed to use 10GB per month, which isn't enough for regular streaming. It's also committed to a cramped and headache-inducing user interface that stands out from the crowd in all the worst ways. Private Internet Access Private Internet Access (PIA VPN) has a deeply annoying name — I assume whoever invented it also likes to hop in their Toyota Forward Motion to grab a gallon of Sustaining Cow Extract from the grocery store — but it's a worthwhile VPN whose pricing provides incredible value. Its monthly and yearly plans are good enough, but its three-year plan is the clincher. Not only is it longer than average, but you can continue to renew at the three-year level, so you won't see an unpleasant price jump the first time you re-up. PIA's apps have a dark UI reminiscent of Proton VPN, which is always a good thing. It also supports port forwarding, custom DNS and the use of a SOCKS5 or Shadowsocks proxy as a second step in the VPN connection. You can even set the maximum data packet size to help out a struggling connection, as I cover in my full PIA VPN review. The downside is that your connection will struggle a lot. While well-designed, PIA's apps have a tendency to lag. In my most recent battery of tests, it dragged oddly on my internet in ways that weren't directly reflected in the speed tests. It's also not always capable of unblocking streaming services in other countries, and while its server network offers 152 IP address options in 84 countries, it's heavily bulked out by virtual locations. TunnelBear TunnelBear has a decent interface, which its target audience of VPN beginners will find very easy to use. Its speeds are perfectly good too, and I appreciate the depth and breadth of its transparency reports. But it's far too limited overall, with few extra features, less than 50 server locations and a free plan that caps data at 2GB per month. VyprVPN VyprVPN often flies under the radar, but it has some of the best apps in the business and a very good security record (there was a breach in 2023, but it didn't crack the VPN encryption itself). It's also got a verified privacy policy, a solid jurisdiction and runs every connection through an in-house DNS to prevent leaks. Despite all that, it didn't make the top seven because its connection speeds aren't up to scratch — you'll likely notice a bigger slowdown than average. It also has a troubling history of wild, seemingly experimental swings in its pricing and simultaneous connection limits. Norton VPN Norton VPN is part of the Norton 360 package that includes the well-known antivirus software and other security apps. It's a nice bonus if you use Norton already, but as a standalone VPN, it falls short. My tests repeatedly showed it dropping encryption and revealing my IP address whenever I switched servers, and not all of its locations managed to unblock Netflix. This isn't to say Norton VPN is terrible. It has a fairly large server network, user-friendly apps and some cool features like an IP rotator. It also recently revamped its OpenVPN infrastructure to improve speeds on Windows. But you probably won't find those things sufficient to balance out significant speed drops on other platforms or poorly written FAQs. I especially advise against Norton VPN for Apple users, as its Mac and iPhone apps are much more limited than their Windows and Android counterparts. What to look for in a VPN Choosing a VPN can quickly get you mired in analysis paralysis. We're here to help, but since only you know your particular needs, you should know the major red and green flags so you can make the final call yourself. Every reputable VPN provider offers a free trial or refund guarantee you can use to run the tests below. Compatibility: First, make sure your VPN works on all the platforms you plan to use it on. Most VPNs have apps for Windows, Mac, Android and iOS, but those apps aren't always created equal — check that the app for your chosen OS is user-friendly and has all the features you need. Speed: Use a speed testing app to see how fast your internet is before and after connecting to the VPN (I use Ookla's speedtest.net). To check security, look up your IP address while connected to a VPN server and see if it's actually changed your virtual location. Be sure it's using expert-vetted protocols like OpenVPN, WireGuard and IKEv2. Try connecting to streaming services and seeing whether the VPN changes the available content. Background: Do some outside research into the VPN's origins, especially its parent company, privacy policy and any past incidents. It's a dealbreaker if you can't figure out where the VPN is headquartered (which indicates a lax approach to transparency) or if it seems to have never passed a real third-party audit. Server network: Look at the server network to make sure the VPN has locations near you and in any countries where you'll want an IP address — e.g. if you need a VPN to unblock Canadian Netflix, look for multiple server locations in Canada. Customer Service: I also advise testing the customer support options by looking for the answer to a straightforward question. If phone support (versus email and chat) is important to you, make sure to prioritize that — and make sure it's available at convenient times in your timezone. Pricing: Finally, check prices. See if the VPN is affordable and decide whether you're comfortable taking a long-term subscription for better savings. If you do get a multi-year plan, check what price it will renew at, since many of the cheapest subscriptions are only introductory deals. VPN FAQs To wrap up, let's answer some of the most common questions we get about VPNs. Feel free to get in touch if you have a query I don't cover here. What is a VPN? VPN stands for virtual private network. There are a few different types of VPNs, but for this list, we're talking about commercial services that let individual users access the internet with an assumed identity. Whenever you get online, you're assigned an IP address — a digital nametag that tells websites where to send the information you request. For an IP address to work, it needs to be unique, which means it's possible to create a record of what an individual does online. When you use a VPN, all the data you send to the internet goes through one of the VPN's servers before heading to its final destination. The VPN encrypts the connection between your computer and its server so the data won't trace back to you. Any website, ISP or third party that cares to look will only see the VPN's IP address, not yours. What are some things VPNs are used for? The three main use cases for a commercial VPN are security, privacy and entertainment. Using a VPN conceals your real IP address from anyone who might want to use it for nefarious purposes like cyberstalking, DDoS attacks or deducing your real location. It also keeps your ISP from profiling you for ads based on where you live or what you do online. One side effect of borrowing a VPN's IP address is that you can make it appear as though your connection is coming from another country. You can use this to access streaming content and platforms that are only available in certain regions due to copyright. Changing your location can even get you better prices when shopping online. Location spoofing can also be used to get online in countries that censor internet access, like China and Russia, as well as certain US states or countries — like the UK — that are adding barriers like age-gating to previously unfettered online access. All you have to do is connect to a neighboring country (or locality) where the internet isn't blocked. If you plan to do this while traveling, make sure you have the VPN downloaded before you go, as some nations prevent you from even loading a VPN's homepage. Make sure you check with local laws regarding the legality of VPN use as well — just because your VPN traffic is encrypted doesn't mean that authorities can't detect that it's being used in a given location. Are VPNs worth it? Whether a VPN is worth the price depends on how much you value those three use cases above. It's no secret that your personal information is profitable for a lot of people, from illicit hackers to corporations to law enforcement. A VPN will not make you completely anonymous, nor is it a license to commit crimes (see the next question) but it will give you a lot more control over what you transmit to the world. With entertainment, the value is even clearer. You can use a VPN to fight back against streaming balkanization by getting more shows and movies out of a single platform — for example, a lot of shows that have been kicked off American Netflix are still on Netflix in other countries. What information does a VPN hide? A VPN does not make it impossible for you to be unmasked or taken advantage of online. It prevents you from passively leaking information, keeps your IP address undiscoverable on public wi-fi networks and gets you around online censorship. However, if you share personal information of your own volition, there's nothing the VPN can do. If you reveal your password in a social media post or click a link in a phishing email, that information bypasses the VPN. Likewise, if you do anything sensitive while logged into an account, the account holder will have that information even if you're using a VPN. A VPN is a critical part of your online security, but it can't do the whole job by itself. Healthy passwords, malware scanners, private search engines and common sense all have roles to play. Never forget, too, that using a VPN means trusting the VPN provider with access to information that's concealed from everyone else — make sure you trust the privacy policy before signing up. Are VPNs safe? As far as we can determine, all the VPNs recommended in this story are safe to use. As with anything you subscribe to online, due diligence is important, but there's very little inherent risk; generally, the worst thing a bad VPN will do is fail to work, leaving you no worse off than before. There are some VPNs (usually offered for free) that transmit malware, so always make sure to look up any complaints or warnings about a service before you download it. Can you get a VPN on your phone? Absolutely — almost every VPN has apps for both desktop and mobile devices. A good VPN will redesign its app to be mobile-friendly without dropping too many features. Both iOS and Android natively support VPN connections, so you're free to choose whichever provider you like. What about Google's One VPN? Google One VPN was, as you might expect, a VPN provided by Google. It was launched in 2020 for Google One subscribers and discontinued in 2024 due to lack of use. If you really want a Google VPN, you can still get one if you have certain Pixel models or if you're a Google Fi subscriber. That said, I don't recommend using a VPN from Google even if you do still have access to one. Google is one of the worst big tech companies at protecting user privacy. While its VPN might not leak, I wouldn't trust it to guard your sensitive information.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html?src=rss",
          "content": "As frustrating as it is that governments and businesses are running roughshod over our online freedoms, at least we have plenty of good VPNs to choose from to keep us protected online. There are so many fast, intelligently designed, full-featured and affordable services on the market that the biggest problem is picking one. For any use case, you can bet at least two providers will be neck-and-neck for first place.On the other hand, the VPN world is still the Wild West in some ways. It's easy enough to slap a cheap VPN together that the market is flooded with low-quality apps that put more money into advertising than infrastructure. They may look good, but it's all styrofoam under the hood.I built this list of the best VPNs after intensive testing to help you reorient your focus on the providers that actually deserve your time and money. Which one truly fits your needs is dependent on who you are and what you do online, but if you pick any of my seven recommendations, you can't go too far wrong.For each VPN on this list, I've shared which platforms it works on, how much it cuts into your download speed, where it offers servers, what other features are included and how much the best available deal costs. At the end, I'll list some honorable and dishonorable mentions, then answer some of the most common questions I hear about VPNs.Editor's note: This list has been completely overhauled and rewritten as of September 2025. We intend to revisit this list every three months at a minimum, at which time our picks may be adjusted based on changes in pricing, features, testing results and other factors. Table of contents Best VPNs for 2025 Other VPNs we tested What to look for in a VPN VPN FAQs Best VPNs for 2025 Other VPNs we tested The VPNs in this section didn't crack our top list above, but we're summarizing them here so you can see their positives and negatives as of the time of our evaluation. Windscribe Windscribe is another well-known free VPN supported by paid subscriptions. In many ways, it takes the best from both Mullvad and Proton VPN, with the former's no-nonsense privacy and the latter's healthy free plan. Without paying, you can connect to 10 of Windscribe's server locations on an unlimited number of devices at once. Unfortunately, Windscribe didn't copy the most important part of Proton VPN's free plan — the unlimited data. You're only allowed to use 10GB per month, which isn't enough for regular streaming. It's also committed to a cramped and headache-inducing user interface that stands out from the crowd in all the worst ways. Private Internet Access Private Internet Access (PIA VPN) has a deeply annoying name — I assume whoever invented it also likes to hop in their Toyota Forward Motion to grab a gallon of Sustaining Cow Extract from the grocery store — but it's a worthwhile VPN whose pricing provides incredible value. Its monthly and yearly plans are good enough, but its three-year plan is the clincher. Not only is it longer than average, but you can continue to renew at the three-year level, so you won't see an unpleasant price jump the first time you re-up. PIA's apps have a dark UI reminiscent of Proton VPN, which is always a good thing. It also supports port forwarding, custom DNS and the use of a SOCKS5 or Shadowsocks proxy as a second step in the VPN connection. You can even set the maximum data packet size to help out a struggling connection, as I cover in my full PIA VPN review. The downside is that your connection will struggle a lot. While well-designed, PIA's apps have a tendency to lag. In my most recent battery of tests, it dragged oddly on my internet in ways that weren't directly reflected in the speed tests. It's also not always capable of unblocking streaming services in other countries, and while its server network offers 152 IP address options in 84 countries, it's heavily bulked out by virtual locations. TunnelBear TunnelBear has a decent interface, which its target audience of VPN beginners will find very easy to use. Its speeds are perfectly good too, and I appreciate the depth and breadth of its transparency reports. But it's far too limited overall, with few extra features, less than 50 server locations and a free plan that caps data at 2GB per month. VyprVPN VyprVPN often flies under the radar, but it has some of the best apps in the business and a very good security record (there was a breach in 2023, but it didn't crack the VPN encryption itself). It's also got a verified privacy policy, a solid jurisdiction and runs every connection through an in-house DNS to prevent leaks. Despite all that, it didn't make the top seven because its connection speeds aren't up to scratch — you'll likely notice a bigger slowdown than average. It also has a troubling history of wild, seemingly experimental swings in its pricing and simultaneous connection limits. Norton VPN Norton VPN is part of the Norton 360 package that includes the well-known antivirus software and other security apps. It's a nice bonus if you use Norton already, but as a standalone VPN, it falls short. My tests repeatedly showed it dropping encryption and revealing my IP address whenever I switched servers, and not all of its locations managed to unblock Netflix. This isn't to say Norton VPN is terrible. It has a fairly large server network, user-friendly apps and some cool features like an IP rotator. It also recently revamped its OpenVPN infrastructure to improve speeds on Windows. But you probably won't find those things sufficient to balance out significant speed drops on other platforms or poorly written FAQs. I especially advise against Norton VPN for Apple users, as its Mac and iPhone apps are much more limited than their Windows and Android counterparts. What to look for in a VPN Choosing a VPN can quickly get you mired in analysis paralysis. We're here to help, but since only you know your particular needs, you should know the major red and green flags so you can make the final call yourself. Every reputable VPN provider offers a free trial or refund guarantee you can use to run the tests below. Compatibility: First, make sure your VPN works on all the platforms you plan to use it on. Most VPNs have apps for Windows, Mac, Android and iOS, but those apps aren't always created equal — check that the app for your chosen OS is user-friendly and has all the features you need. Speed: Use a speed testing app to see how fast your internet is before and after connecting to the VPN (I use Ookla's speedtest.net). To check security, look up your IP address while connected to a VPN server and see if it's actually changed your virtual location. Be sure it's using expert-vetted protocols like OpenVPN, WireGuard and IKEv2. Try connecting to streaming services and seeing whether the VPN changes the available content. Background: Do some outside research into the VPN's origins, especially its parent company, privacy policy and any past incidents. It's a dealbreaker if you can't figure out where the VPN is headquartered (which indicates a lax approach to transparency) or if it seems to have never passed a real third-party audit. Server network: Look at the server network to make sure the VPN has locations near you and in any countries where you'll want an IP address — e.g. if you need a VPN to unblock Canadian Netflix, look for multiple server locations in Canada. Customer Service: I also advise testing the customer support options by looking for the answer to a straightforward question. If phone support (versus email and chat) is important to you, make sure to prioritize that — and make sure it's available at convenient times in your timezone. Pricing: Finally, check prices. See if the VPN is affordable and decide whether you're comfortable taking a long-term subscription for better savings. If you do get a multi-year plan, check what price it will renew at, since many of the cheapest subscriptions are only introductory deals. VPN FAQs To wrap up, let's answer some of the most common questions we get about VPNs. Feel free to get in touch if you have a query I don't cover here. What is a VPN? VPN stands for virtual private network. There are a few different types of VPNs, but for this list, we're talking about commercial services that let individual users access the internet with an assumed identity. Whenever you get online, you're assigned an IP address — a digital nametag that tells websites where to send the information you request. For an IP address to work, it needs to be unique, which means it's possible to create a record of what an individual does online. When you use a VPN, all the data you send to the internet goes through one of the VPN's servers before heading to its final destination. The VPN encrypts the connection between your computer and its server so the data won't trace back to you. Any website, ISP or third party that cares to look will only see the VPN's IP address, not yours. What are some things VPNs are used for? The three main use cases for a commercial VPN are security, privacy and entertainment. Using a VPN conceals your real IP address from anyone who might want to use it for nefarious purposes like cyberstalking, DDoS attacks or deducing your real location. It also keeps your ISP from profiling you for ads based on where you live or what you do online. One side effect of borrowing a VPN's IP address is that you can make it appear as though your connection is coming from another country. You can use this to access streaming content and platforms that are only available in certain regions due to copyright. Changing your location can even get you better prices when shopping online. Location spoofing can also be used to get online in countries that censor internet access, like China and Russia, as well as certain US states or countries — like the UK — that are adding barriers like age-gating to previously unfettered online access. All you have to do is connect to a neighboring country (or locality) where the internet isn't blocked. If you plan to do this while traveling, make sure you have the VPN downloaded before you go, as some nations prevent you from even loading a VPN's homepage. Make sure you check with local laws regarding the legality of VPN use as well — just because your VPN traffic is encrypted doesn't mean that authorities can't detect that it's being used in a given location. Are VPNs worth it? Whether a VPN is worth the price depends on how much you value those three use cases above. It's no secret that your personal information is profitable for a lot of people, from illicit hackers to corporations to law enforcement. A VPN will not make you completely anonymous, nor is it a license to commit crimes (see the next question) but it will give you a lot more control over what you transmit to the world. With entertainment, the value is even clearer. You can use a VPN to fight back against streaming balkanization by getting more shows and movies out of a single platform — for example, a lot of shows that have been kicked off American Netflix are still on Netflix in other countries. What information does a VPN hide? A VPN does not make it impossible for you to be unmasked or taken advantage of online. It prevents you from passively leaking information, keeps your IP address undiscoverable on public wi-fi networks and gets you around online censorship. However, if you share personal information of your own volition, there's nothing the VPN can do. If you reveal your password in a social media post or click a link in a phishing email, that information bypasses the VPN. Likewise, if you do anything sensitive while logged into an account, the account holder will have that information even if you're using a VPN. A VPN is a critical part of your online security, but it can't do the whole job by itself. Healthy passwords, malware scanners, private search engines and common sense all have roles to play. Never forget, too, that using a VPN means trusting the VPN provider with access to information that's concealed from everyone else — make sure you trust the privacy policy before signing up. Are VPNs safe? As far as we can determine, all the VPNs recommended in this story are safe to use. As with anything you subscribe to online, due diligence is important, but there's very little inherent risk; generally, the worst thing a bad VPN will do is fail to work, leaving you no worse off than before. There are some VPNs (usually offered for free) that transmit malware, so always make sure to look up any complaints or warnings about a service before you download it. Can you get a VPN on your phone? Absolutely — almost every VPN has apps for both desktop and mobile devices. A good VPN will redesign its app to be mobile-friendly without dropping too many features. Both iOS and Android natively support VPN connections, so you're free to choose whichever provider you like. What about Google's One VPN? Google One VPN was, as you might expect, a VPN provided by Google. It was launched in 2020 for Google One subscribers and discontinued in 2024 due to lack of use. If you really want a Google VPN, you can still get one if you have certain Pixel models or if you're a Google Fi subscriber. That said, I don't recommend using a VPN from Google even if you do still have access to one. Google is one of the worst big tech companies at protecting user privacy. While its VPN might not leak, I wouldn't trust it to guard your sensitive information.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/openai-launches-company-knowledge-in-chatgpt-letting-you-access-your-firms",
          "published_at": "Thu, 23 Oct 2025 22:19:00 GMT",
          "title": "OpenAI launches company knowledge in ChatGPT, letting you access your firm's data from Google Drive, Slack, GitHub",
          "standfirst": "Is the Google Search for internal enterprise knowledge finally here...but from OpenAI? It certainly seems that way. Today, OpenAI has launched company knowledge in ChatGPT, a major new capability for subscribers to ChatGPT&#x27;s paid Business, Enterprise, and Edu plans that lets them call up their company&#x27;s data directly from third-party workplace apps including Slack, SharePoint, Google Drive, Gmail, GitHub, HubSpot and combine it in ChatGPT outputs to them. As OpenAI&#x27;s CEO of Applications Fidji Simo put it in a post on the social network X: \"it brings all the context from your apps (Slack, Google Drive, GitHub, etc) together in ChatGPT so you can get answers that are specific to your business.\"Intriguingly, OpenAI&#x27;s blog post on the feature states that is \"powered by a version of GPT‑5 that’s trained to look across multiple sources to give more comprehensive and accurate answers,\" which sounds to me like a new fine-tuned version of the model family the company released back in August, though there are no additional details on how it was trained or its size, techniques, etc.OpenAI tells VentureBeat it&#x27;s a version of GPT-5 that specifically powers company knowledge in ChatGPT Business, Enterprise, and Edu. Nonetheless, company knowledge in ChatGPT is rolling out globally and is designed to make ChatGPT a central point of access for verified organizational information, supported by secure integrations and enterprise-grade compliance controls, and give employees way faster access to their company&#x27;s information while working.Now, instead of toggling over to Slack to find the assignment you were given and instructions, or tabbing over to Google Drive and opening up specific files to find the names and numbers you need to call, ChatGPT can deliver all that type of information directly into your chat session — if your company enables the proper connections.As OpenAI Chief Operating Officer Brad Lightcap wrote in a post on the social network X: \"company knowledge has changed how i use chatgpt at work more than anything we have built so far - let us know what you think!\"It builds upon the third-party app connectors unveiled back in August 2025, though those were only for individual users on the ChatGPT Plus plans.Connecting ChatGPT to Workplace SystemsEnterprise teams often face the challenge of fragmented data across various internal tools—email, chat, file storage, project management, and customer platforms. Company knowledge bridges those silos by enabling ChatGPT to connect to approved systems like, and other supported apps through enterprise-managed connectors.Each response generated with company knowledge includes citations and direct links to the original sources, allowing teams to verify where specific details originated. This transparency helps organizations maintain data trustworthiness while increasing productivity.The sidebar shows a live view of the sources being examined and what it is getting from them. When it’s done, you’ll see exactly the sources used, along with the specific snippets it drew from. You can then click on any citation to open the original source for more details.Built for Enterprise Control and SecurityCompany knowledge was designed from the ground up for enterprise governance and compliance. It respects existing permissions within connected apps — ChatGPT can only access what a user is already authorized to view— and never trains on company data by default.Security features include industry-standard encryption, support for SSO and SCIM for account provisioning, and IP allowlisting to restrict access to approved corporate networks. Enterprise administrators can also define role-based access control (RBAC) policies and manage permissions at a group or department level.OpenAI’s Enterprise Compliance API provides a full audit trail, allowing administrators to review conversation logs for reporting and regulatory purposes. This capability helps enterprises meet internal governance standards and industry-specific requirements such as SOC 2 and ISO 27001 compliance.Admin Configuration and Connector ManagementFor enterprise deployment, administrators must enable company knowledge and its connectors within the ChatGPT workspace. Once connectors are active, users can authenticate their own accounts for each work app they need to access.In Enterprise and Edu plans, connectors are off by default and require explicit admin approval before employees can use them. Admins can selectively enable connectors, manage access by role, and require SSO-based authentication for enhanced control.Business plan users, by contrast, have connectors enabled automatically if available in their workspace. Admins can still oversee which connectors are approved, ensuring alignment with internal IT and data policies.Company knowledge becomes available to any user with at least one active connector, and admins can configure group-level permissions for different teams — such as restricting GitHub access to engineering while enabling Google Drive or HubSpot for marketing and sales.Organizations who turn on the feature can also elect to turn it off just as easily. Once you disconnect a connector, ChatGPT does not have access to that data.How Company Knowledge Works in PracticeActivating company knowledge is straightforward. Users can start a new or existing conversation in ChatGPT and select “Company knowledge” under the message composer or from the tools menu. It must be turned on proactively for each new conversation or chat session, even from the same user.After authenticating their connected apps, they can ask questions as usual—such as “Summarize this account’s latest feedback and risks” or “Compile a Q4 performance summary from project trackers.”ChatGPT searches across the connected tools, retrieves relevant context, and produces an answer with full citations and source links. The system can combine data across apps — for instance, blending Slack updates, Google Docs notes, and HubSpot CRM records — to create an integrated view of a project, client, or initiative.When company knowledge is not selected, ChatGPT may still use connectors in a limited capacity as part of the default experience, but responses will not include detailed citations or multi-source synthesis.Advanced Use Cases for Enterprise TeamsFor development and operations leaders, company knowledge can act as a centralized intelligence layer that surfaces real-time updates and dependencies across complex workflows. ChatGPT can, for example, summarize open GitHub pull requests, highlight unresolved Linear tickets, and cross-reference Slack engineering discussions—all in a single output.Technical teams can also use it for incident retrospectives or release planning by pulling relevant information from issue trackers, logs, and meeting notes. Procurement or finance leaders can use it to consolidate purchase requests or budget updates across shared drives and internal communications.Because the model can reference structured and unstructured data simultaneously, it supports wide-ranging scenarios—from compliance documentation reviews to cross-departmental performance summaries.Privacy, Data Residency, and ComplianceEnterprise data protection is a central design element of company knowledge. ChatGPT processes data in line with OpenAI’s enterprise-grade security model, ensuring that no connected app data leaves the secure boundary of the organization’s authorized environment.Data residency policies vary by connector. Certain integrations, such as Slack, support region-specific data storage, while others—like Google Drive and SharePoint—are available for U.S.-based customers with or without at-rest data residency. Organizations with regional compliance obligations can review connector-specific security documentation for details.No geo restrictions apply to company knowledge, making it suitable for multinational organizations operating across multiple jurisdictions.Limitations and Future EnhancementsAt present, users must manually enable company knowledge in each new ChatGPT conversation. OpenAI is developing a unified interface that will automatically integrate company knowledge with other ChatGPT tools—such as browsing and chart generation—so that users won’t need to toggle between modes.When enabled, company knowledge temporarily disables web browsing and visual output generation, though users can switch modes within the same conversation to re-enable those features.OpenAI also continues to expand the network of supported tools. Recent updates have added connectors for Asana, GitLab Issues, and ClickUp, and OpenAI plans to support future MCP (Model Context Protocol) connectors to enable custom, developer-built integrations.Availability and Getting StartedCompany knowledge is now available to all ChatGPT Business, Enterprise, and Edu users. Organizations can begin by enabling the feature under the ChatGPT message composer and connecting approved work apps.For enterprise rollouts, OpenAI recommends a phased deployment: first enabling core connectors (such as Google Drive and Slack), configuring RBAC and SSO, then expanding to specialized systems once data access policies are verified.Procurement and security leaders evaluating the feature should note that company knowledge is covered under existing ChatGPT Enterprise terms and uses the same encryption, compliance, and service-level guarantees.With company knowledge, OpenAI aims to make ChatGPT not just a conversational assistant but an intelligent interface to enterprise data—delivering secure, context-aware insights that help technical and business leaders act with confidence.",
          "content": "Is the Google Search for internal enterprise knowledge finally here...but from OpenAI? It certainly seems that way. Today, OpenAI has launched company knowledge in ChatGPT, a major new capability for subscribers to ChatGPT&#x27;s paid Business, Enterprise, and Edu plans that lets them call up their company&#x27;s data directly from third-party workplace apps including Slack, SharePoint, Google Drive, Gmail, GitHub, HubSpot and combine it in ChatGPT outputs to them. As OpenAI&#x27;s CEO of Applications Fidji Simo put it in a post on the social network X: \"it brings all the context from your apps (Slack, Google Drive, GitHub, etc) together in ChatGPT so you can get answers that are specific to your business.\"Intriguingly, OpenAI&#x27;s blog post on the feature states that is \"powered by a version of GPT‑5 that’s trained to look across multiple sources to give more comprehensive and accurate answers,\" which sounds to me like a new fine-tuned version of the model family the company released back in August, though there are no additional details on how it was trained or its size, techniques, etc.OpenAI tells VentureBeat it&#x27;s a version of GPT-5 that specifically powers company knowledge in ChatGPT Business, Enterprise, and Edu. Nonetheless, company knowledge in ChatGPT is rolling out globally and is designed to make ChatGPT a central point of access for verified organizational information, supported by secure integrations and enterprise-grade compliance controls, and give employees way faster access to their company&#x27;s information while working.Now, instead of toggling over to Slack to find the assignment you were given and instructions, or tabbing over to Google Drive and opening up specific files to find the names and numbers you need to call, ChatGPT can deliver all that type of information directly into your chat session — if your company enables the proper connections.As OpenAI Chief Operating Officer Brad Lightcap wrote in a post on the social network X: \"company knowledge has changed how i use chatgpt at work more than anything we have built so far - let us know what you think!\"It builds upon the third-party app connectors unveiled back in August 2025, though those were only for individual users on the ChatGPT Plus plans.Connecting ChatGPT to Workplace SystemsEnterprise teams often face the challenge of fragmented data across various internal tools—email, chat, file storage, project management, and customer platforms. Company knowledge bridges those silos by enabling ChatGPT to connect to approved systems like, and other supported apps through enterprise-managed connectors.Each response generated with company knowledge includes citations and direct links to the original sources, allowing teams to verify where specific details originated. This transparency helps organizations maintain data trustworthiness while increasing productivity.The sidebar shows a live view of the sources being examined and what it is getting from them. When it’s done, you’ll see exactly the sources used, along with the specific snippets it drew from. You can then click on any citation to open the original source for more details.Built for Enterprise Control and SecurityCompany knowledge was designed from the ground up for enterprise governance and compliance. It respects existing permissions within connected apps — ChatGPT can only access what a user is already authorized to view— and never trains on company data by default.Security features include industry-standard encryption, support for SSO and SCIM for account provisioning, and IP allowlisting to restrict access to approved corporate networks. Enterprise administrators can also define role-based access control (RBAC) policies and manage permissions at a group or department level.OpenAI’s Enterprise Compliance API provides a full audit trail, allowing administrators to review conversation logs for reporting and regulatory purposes. This capability helps enterprises meet internal governance standards and industry-specific requirements such as SOC 2 and ISO 27001 compliance.Admin Configuration and Connector ManagementFor enterprise deployment, administrators must enable company knowledge and its connectors within the ChatGPT workspace. Once connectors are active, users can authenticate their own accounts for each work app they need to access.In Enterprise and Edu plans, connectors are off by default and require explicit admin approval before employees can use them. Admins can selectively enable connectors, manage access by role, and require SSO-based authentication for enhanced control.Business plan users, by contrast, have connectors enabled automatically if available in their workspace. Admins can still oversee which connectors are approved, ensuring alignment with internal IT and data policies.Company knowledge becomes available to any user with at least one active connector, and admins can configure group-level permissions for different teams — such as restricting GitHub access to engineering while enabling Google Drive or HubSpot for marketing and sales.Organizations who turn on the feature can also elect to turn it off just as easily. Once you disconnect a connector, ChatGPT does not have access to that data.How Company Knowledge Works in PracticeActivating company knowledge is straightforward. Users can start a new or existing conversation in ChatGPT and select “Company knowledge” under the message composer or from the tools menu. It must be turned on proactively for each new conversation or chat session, even from the same user.After authenticating their connected apps, they can ask questions as usual—such as “Summarize this account’s latest feedback and risks” or “Compile a Q4 performance summary from project trackers.”ChatGPT searches across the connected tools, retrieves relevant context, and produces an answer with full citations and source links. The system can combine data across apps — for instance, blending Slack updates, Google Docs notes, and HubSpot CRM records — to create an integrated view of a project, client, or initiative.When company knowledge is not selected, ChatGPT may still use connectors in a limited capacity as part of the default experience, but responses will not include detailed citations or multi-source synthesis.Advanced Use Cases for Enterprise TeamsFor development and operations leaders, company knowledge can act as a centralized intelligence layer that surfaces real-time updates and dependencies across complex workflows. ChatGPT can, for example, summarize open GitHub pull requests, highlight unresolved Linear tickets, and cross-reference Slack engineering discussions—all in a single output.Technical teams can also use it for incident retrospectives or release planning by pulling relevant information from issue trackers, logs, and meeting notes. Procurement or finance leaders can use it to consolidate purchase requests or budget updates across shared drives and internal communications.Because the model can reference structured and unstructured data simultaneously, it supports wide-ranging scenarios—from compliance documentation reviews to cross-departmental performance summaries.Privacy, Data Residency, and ComplianceEnterprise data protection is a central design element of company knowledge. ChatGPT processes data in line with OpenAI’s enterprise-grade security model, ensuring that no connected app data leaves the secure boundary of the organization’s authorized environment.Data residency policies vary by connector. Certain integrations, such as Slack, support region-specific data storage, while others—like Google Drive and SharePoint—are available for U.S.-based customers with or without at-rest data residency. Organizations with regional compliance obligations can review connector-specific security documentation for details.No geo restrictions apply to company knowledge, making it suitable for multinational organizations operating across multiple jurisdictions.Limitations and Future EnhancementsAt present, users must manually enable company knowledge in each new ChatGPT conversation. OpenAI is developing a unified interface that will automatically integrate company knowledge with other ChatGPT tools—such as browsing and chart generation—so that users won’t need to toggle between modes.When enabled, company knowledge temporarily disables web browsing and visual output generation, though users can switch modes within the same conversation to re-enable those features.OpenAI also continues to expand the network of supported tools. Recent updates have added connectors for Asana, GitLab Issues, and ClickUp, and OpenAI plans to support future MCP (Model Context Protocol) connectors to enable custom, developer-built integrations.Availability and Getting StartedCompany knowledge is now available to all ChatGPT Business, Enterprise, and Edu users. Organizations can begin by enabling the feature under the ChatGPT message composer and connecting approved work apps.For enterprise rollouts, OpenAI recommends a phased deployment: first enabling core connectors (such as Google Drive and Slack), configuring RBAC and SSO, then expanding to specialized systems once data access policies are verified.Procurement and security leaders evaluating the feature should note that company knowledge is covered under existing ChatGPT Enterprise terms and uses the same encryption, compliance, and service-level guarantees.With company knowledge, OpenAI aims to make ChatGPT not just a conversational assistant but an intelligent interface to enterprise data—delivering secure, context-aware insights that help technical and business leaders act with confidence.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/77MUUhh1PM8EeHOJyHjmwX/2f1b317b8af31339017a06f84d871d58/cfr0z3n_third-person_view_of_woman_seated_at_desk_in_a_home_off_d68bd7db-ac86-44be-8e05-2cdb878c7190.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-macbook-140032524.html",
          "published_at": "Thu, 23 Oct 2025 19:01:26 +0000",
          "title": "The best MacBook for 2025: Which Apple laptop should you buy?",
          "standfirst": "Picking the best MacBook may seem like an easy decision. After all, Apple just makes two models: the MacBook Air and the MacBook Pro. But the available variations within those categories — screen size, chip type, capacity and more — deserve some consideration. You also may wonder what the real-world differences are between models and who they’re best for. To make things even more interesting, Apple keeps announcing new chips. The latest, the M5 came out October 15, and is now found in the base model, 14-inch MacBook Pro (as well as the iPad Pro and the Vision Pro). This guide breaks down Apple’s terminology, as well as all which upgrades make the most sense so you can get the best MacBook for what you want to do. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently, MacBooks come equipped with M4 and M5-series chips. You’ll find the standard M4 processor in the Air. The base-model 14-inch Pro now comes with either the latest M5 chip. Other Pro configurations have the M4 Max or the M4 Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air. That chip houses a 10-core CPU and either an 8- or 10-core GPU. The base-model MacBook Pro uses the latest M5 chip, but only on the 14-inch model. The upgraded versions of that laptop use the M4 Pro or M4 Max chips (which are a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The M4 Max is the burliest chip and built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM (or unified memory) varies, but when Apple switched to the M4 chip for the MacBook Air, the lowest amount of RAM you can get was bumped to 16GB. That’s a necessary jump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. The M5 chip in the base-model MacBook Pro comes with a minimum of 16GB and can be configured to a maximum of 32GB of RAM.. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14-inch M5 or 16-inch M4 MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage and 32GB of RAM to make your machine as future-proof as possible. Of course, if you're just after Apple’s silicon and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M5 (14-inch) Best MacBook for creatives Apple M5, 32GB RAM, 512GB SSD 34.5 hours Up to 24 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? The MacBook Air comes with the M4 chip. The 14-inch, base-model Pro comes with the M5 chip. MacBook Pro models have the option of more powerful M4 Pro or M4 Max chips. The Pro models have higher resolution screens with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "content": "Picking the best MacBook may seem like an easy decision. After all, Apple just makes two models: the MacBook Air and the MacBook Pro. But the available variations within those categories — screen size, chip type, capacity and more — deserve some consideration. You also may wonder what the real-world differences are between models and who they’re best for. To make things even more interesting, Apple keeps announcing new chips. The latest, the M5 came out October 15, and is now found in the base model, 14-inch MacBook Pro (as well as the iPad Pro and the Vision Pro). This guide breaks down Apple’s terminology, as well as all which upgrades make the most sense so you can get the best MacBook for what you want to do. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently, MacBooks come equipped with M4 and M5-series chips. You’ll find the standard M4 processor in the Air. The base-model 14-inch Pro now comes with either the latest M5 chip. Other Pro configurations have the M4 Max or the M4 Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air. That chip houses a 10-core CPU and either an 8- or 10-core GPU. The base-model MacBook Pro uses the latest M5 chip, but only on the 14-inch model. The upgraded versions of that laptop use the M4 Pro or M4 Max chips (which are a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The M4 Max is the burliest chip and built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM (or unified memory) varies, but when Apple switched to the M4 chip for the MacBook Air, the lowest amount of RAM you can get was bumped to 16GB. That’s a necessary jump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. The M5 chip in the base-model MacBook Pro comes with a minimum of 16GB and can be configured to a maximum of 32GB of RAM.. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14-inch M5 or 16-inch M4 MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage and 32GB of RAM to make your machine as future-proof as possible. Of course, if you're just after Apple’s silicon and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M5 (14-inch) Best MacBook for creatives Apple M5, 32GB RAM, 512GB SSD 34.5 hours Up to 24 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? The MacBook Air comes with the M4 chip. The 14-inch, base-model Pro comes with the M5 chip. MacBook Pro models have the option of more powerful M4 Pro or M4 Max chips. The Pro models have higher resolution screens with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "feed_position": 34,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-11/e536a1d0-7c1e-11ee-9e77-9ea8e142b078"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/microsoft-copilot-gets-12-big-updates-for-fall-including-new-ai-assistant",
          "published_at": "Thu, 23 Oct 2025 19:01:00 GMT",
          "title": "Microsoft Copilot gets 12 big updates for fall, including new AI assistant character Mico",
          "standfirst": "Microsoft today held a live announcement event online for its Copilot AI digital assistant, with Mustafa Suleyman, CEO of Microsoft&#x27;s AI division, and other presenters unveiling a new generation of features that deepen integration across Windows, Edge, and Microsoft 365, positioning the platform as a practical assistant for people during work and off-time, while allowing them to preserve control and safety of their data.The new Copilot 2025 Fall Update features also up the ante in terms of capabilities and the accessibility of generative AI assistance from Microsoft to users, so businesses relying on Microsoft products, and those who seek to offer complimentary or competing products, would do well to review them.Suleyman emphasized that the updates reflect a shift from hype to usefulness. “Technology should work in service of people, not the other way around,” he said. “Copilot is not just a product—it’s a promise that AI can be helpful, supportive, and deeply personal.”Intriguingly, the announcement also sought to shine a greater spotlight on Microsoft&#x27;s own homegrown AI models, as opposed to those of its partner and investment OpenAI, which previously powered the entire Copilot experience. Instead, Suleyman wrote today in a blog post: “At the foundation of it all is our strategy to put the best models to work for you – both those we build and those we don’t. Over the past few months, we have released in-house models like MAI-Voice-1, MAI-1-Preview and MAI-Vision-1, and are rapidly iterating.”12 Features That Redefine CopilotThe Fall Release consolidates Copilot’s identity around twelve key capabilities—each with potential to streamline organizational knowledge work, development, or support operations.Groups – Shared Copilot sessions where up to 32 participants can brainstorm, co-author, or plan simultaneously. For distributed teams, it effectively merges a meeting chat, task board, and generative workspace. Copilot maintains context, summarizes decisions, and tracks open actions. Imagine – A collaborative hub for creating and remixing AI-generated content. In an enterprise setting, Imagine enables rapid prototyping of visuals, marketing drafts, or training materials.Mico – A new character identity for Copilot that introduces expressive feedback and emotional expression in the form of a cute, amorphous blob. Echoing Microsoft’s historic character interfaces like Clippy (Office 97) or Cortana (2014), Mico serves as a unifying UX layer across modalities.Real Talk – A conversational mode that adapts to a user’s communication style and offers calibrated pushback — ending the sycophancy that some users have complained about with other AI models such as prior versions of OpenAI&#x27;s ChatGPT. For professionals, it allows Socratic problem-solving rather than passive answer generation, making Copilot more credible in technical collaboration.Memory & Personalization – Long-term contextual memory that lets Copilot recall key details—training plans, dates, goals—at the user’s direction.Connectors – Integration with OneDrive, Outlook, Gmail, Google Drive, and Google Calendar for natural-language search across accounts.Proactive Actions (Preview) – Context-based prompts and next-step suggestions derived from recent activity.Copilot for Health – Health information grounded in credible medical sources such as Harvard Health, with tools allowing users to locate and compare doctors.Learn Live – A Socratic, voice-driven tutoring experience using questions, visuals, and whiteboards.Copilot Mode in Edge – Converts Microsoft Edge into an “AI browser” that summarizes, compares, and executes web actions by voice.Copilot on Windows – Deep integration across Windows 11 PCs with “Hey Copilot” activation, Copilot Vision guidance, and quick access to files and apps.Copilot Pages and Copilot Search – A collaborative file canvas plus a unified search experience combining AI-generated, cited answers with standard web results.The Fall Release is immediately available in the United States, with rollout to the UK, Canada, and other markets in progress. Some functions—such as Groups, Journeys, and Copilot for Health—remain U.S.-only for now. Proactive Actions requires a Microsoft 365 Personal, Family, or Premium subscription.Together these updates illustrate Microsoft’s pivot from static productivity suites to contextual AI infrastructure, with the Copilot brand acting as the connective tissue across user roles.From Clippy to Mico: The Return of a Guided InterfaceOne of the most notable introductions is Mico, a small animated companion that is available within Copilot’s voice-enabled experiences, including the Copilot app on Windows, iOS, and Android, as well as in Study Mode and other conversational contexts. It serves as an optional visual companion that appears during interactive or voice-based sessions, rather than across all Copilot interfaces.Mico listens, reacts with expressions, and changes color to reflect tone and emotion — bringing a visual warmth to an AI assistant experience that has traditionally been text-heavy.Mico’s design recalls earlier eras of Microsoft’s history with character-based assistants. In the mid-1990s, Microsoft experimented with Microsoft Bob (1995), a software interface that used cartoon characters like a dog named Rover to guide users through everyday computing tasks. While innovative for its time, Bob was discontinued after a year due to performance and usability issues.A few years later came Clippy, the Office Assistant introduced in Microsoft Office 97. Officially known as “Clippit,” the animated paperclip would pop up to offer help and tips within Word and other Office applications. Clippy became widely recognized—sometimes humorously so—for interrupting users with unsolicited advice. Microsoft retired Clippy from Office in 2001, though the character remains a nostalgic symbol of early AI-driven assistance.More recently, Cortana, launched in 2014 as Microsoft’s digital voice assistant for Windows and mobile devices, aimed to provide natural-language interaction similar to Apple’s Siri or Amazon’s Alexa. Despite positive early reception, Cortana’s role diminished as Microsoft refocused on enterprise productivity and AI integration. The service was officially discontinued on Windows in 2023.Mico, by contrast, represents a modern reimagining of that tradition—combining the personality of early assistants with the intelligence and adaptability of contemporary AI models. Where Clippy offered canned responses, Mico listens, learns, and reflects a user’s mood in real time. The goal, as Suleyman framed it, is to create an AI that feels “helpful, supportive, and deeply personal.”Groups Are Microsoft&#x27;s Version of Claude and ChatGPT ProjectsDuring Microsoft’s launch video, product researcher Wendy described Groups as a transformative shift: “You can finally bring in other people directly to the conversation that you’re having with Copilot,” she said. “It’s the only place you can do this.”Up to 32 users can join a shared Copilot session, brainstorming, editing, or planning together while the AI manages logistics such as summarizing discussion threads, tallying votes, and splitting tasks. Participants can enter or exit sessions using a link, maintaining full visibility into ongoing work.Instead of a single user prompting an AI and later sharing results, Groups lets teams prompt and iterate together in one unified conversation. In some ways, it&#x27;s an answer to Anthropic’s Claude Projects and OpenAI’s ChatGPT Projects, both launched within the last year as tools to centralize team workspaces and shared AI context. Where Claude and ChatGPT Projects allow users to aggregate files, prompts, and conversations into a single container, Groups extends that model into real-time, multi-participant collaboration. Unlike Anthropic’s and OpenAI’s implementations, Groups is deeply embedded within Microsoft’s productivity environment. Like other Copilot experiences connected to Outlook and OneDrive, Groups operates within Microsoft’s enterprise identity framework, governed by Microsoft 365 and Entra ID (formerly Azure Active Directory) authentication and consent modelsThis means conversations, shared artifacts, and generated summaries are governed under the same compliance policies that already protect Outlook, Teams, and SharePoint data.Hours after the unveiling, OpenAI hit back against its own investor in the escalating AI competition between the \"frenemies\" by expanding its Shared Projects feature beyond its current Enterprise, Team, and Edu subscriber availability to users of its free, Plus, and Pro subscription tiers. Operational Impact for AI and Data TeamsMemory & Personalization and Connectors effectively extend a lightweight orchestration layer across Microsoft’s ecosystem. Instead of building separate context-stores or retrieval APIs, teams can leverage Copilot’s secure integration with OneDrive or SharePoint as a governed data backbone. A presenter explained that Copilot’s memory “naturally picks up on important details and remembers them long after you’ve had the conversation,” yet remains editable. For data engineers, Copilot Search and Connectors reduce friction in data discovery across multiple systems. Natural-language retrieval from internal and cloud repositories may lower the cost of knowledge management initiatives by consolidating search endpoints.For security directors, Copilot’s explicit consent requirements and on/off toggles in Edge and Windows help maintain data residency standards. The company reiterated during the livestream that Copilot “acts only with user permission and within organizational privacy controls.”Copilot Mode in Edge: The AI Browser for Research and AutomationCopilot Mode in Edge stands out for offering AI-assisted information workflows. The browser can now parse open tabs, summarize differences, and perform transactional steps.“Historically, browsers have been static—just endless clicking and tab-hopping,” said a presenter during Microsoft’s livestream. “We asked not how browsers should work, but how people work.”In practice, an analyst could prompt Edge to compare supplier documentation, extract structured data, and auto-fill procurement forms—all with consistent citation. Voice-only navigation enables accessibility and multitasking, while Journeys, a companion feature, organizes browsing sessions into storylines for later review.Copilot on Windows: The Operating System as an AI SurfaceIn Windows 11, Copilot now functions as an embedded assistant. With the wake-word “Hey Copilot,” users can initiate context-aware commands without leaving the desktop—drafting documentation, troubleshooting configuration issues, or summarizing system logs.A presenter described it as a “super assistant plugged into all your files and applications.” For enterprises standardizing on Windows 11, this positions Copilot as a native productivity layer rather than an add-on, reducing training friction and promoting secure, on-device reasoning.Copilot Vision, now in early deployment, adds visual comprehension. IT staff can capture a screen region and ask Copilot to interpret error messages, explain configuration options, or generate support tickets automatically.Combined with Copilot Pages, which supports up to twenty concurrent file uploads, this enables more efficient cross-document analysis for audits, RFPs, or code reviews.Leveraging MAI Models for Multimodal WorkflowsAt the foundation of these capabilities are Microsoft’s proprietary MAI-Voice-1, MAI-1 Preview, and MAI-Vision-1 models—trained in-house to handle text, voice, and visual inputs cohesively.For engineering teams managing LLM orchestration, this architecture introduces several potential efficiencies:Unified multimodal reasoning – Reduces the need for separate ASR (speech-to-text) and image-parsing services.Fine-tuning continuity – Because Microsoft owns the model stack, updates propagate across Copilot experiences without re-integration.Predictable latency and governance – In-house hosting under Azure compliance frameworks simplifies security certification for regulated industries.A presenter described the new stack as “the foundation for immersive, creative, and dynamic experiences that still respect enterprise boundaries.”A Strategic Pivot Toward Contextual AIFor years, Microsoft positioned Copilot primarily as a productivity companion. With the Fall 2025 release, it crosses into operational AI infrastructure—a set of extensible services for reasoning over data and processes.Suleyman described this evolution succinctly: “Judge an AI by how much it elevates human potential, not just by its own smarts.” For CIOs and technical leads, the elevation comes from efficiency and interoperability.Copilot now acts as:A connective interface linking files, communications, and cloud data.A reasoning agent capable of understanding context across sessions and modalities.A secure orchestration layer compatible with Microsoft’s compliance and identity framework.Suleyman’s insistence that “technology should work in service of people” now extends to organizations as well: technology that serves teams, not workloads; systems that adapt to enterprise context rather than demand it.",
          "content": "Microsoft today held a live announcement event online for its Copilot AI digital assistant, with Mustafa Suleyman, CEO of Microsoft&#x27;s AI division, and other presenters unveiling a new generation of features that deepen integration across Windows, Edge, and Microsoft 365, positioning the platform as a practical assistant for people during work and off-time, while allowing them to preserve control and safety of their data.The new Copilot 2025 Fall Update features also up the ante in terms of capabilities and the accessibility of generative AI assistance from Microsoft to users, so businesses relying on Microsoft products, and those who seek to offer complimentary or competing products, would do well to review them.Suleyman emphasized that the updates reflect a shift from hype to usefulness. “Technology should work in service of people, not the other way around,” he said. “Copilot is not just a product—it’s a promise that AI can be helpful, supportive, and deeply personal.”Intriguingly, the announcement also sought to shine a greater spotlight on Microsoft&#x27;s own homegrown AI models, as opposed to those of its partner and investment OpenAI, which previously powered the entire Copilot experience. Instead, Suleyman wrote today in a blog post: “At the foundation of it all is our strategy to put the best models to work for you – both those we build and those we don’t. Over the past few months, we have released in-house models like MAI-Voice-1, MAI-1-Preview and MAI-Vision-1, and are rapidly iterating.”12 Features That Redefine CopilotThe Fall Release consolidates Copilot’s identity around twelve key capabilities—each with potential to streamline organizational knowledge work, development, or support operations.Groups – Shared Copilot sessions where up to 32 participants can brainstorm, co-author, or plan simultaneously. For distributed teams, it effectively merges a meeting chat, task board, and generative workspace. Copilot maintains context, summarizes decisions, and tracks open actions. Imagine – A collaborative hub for creating and remixing AI-generated content. In an enterprise setting, Imagine enables rapid prototyping of visuals, marketing drafts, or training materials.Mico – A new character identity for Copilot that introduces expressive feedback and emotional expression in the form of a cute, amorphous blob. Echoing Microsoft’s historic character interfaces like Clippy (Office 97) or Cortana (2014), Mico serves as a unifying UX layer across modalities.Real Talk – A conversational mode that adapts to a user’s communication style and offers calibrated pushback — ending the sycophancy that some users have complained about with other AI models such as prior versions of OpenAI&#x27;s ChatGPT. For professionals, it allows Socratic problem-solving rather than passive answer generation, making Copilot more credible in technical collaboration.Memory & Personalization – Long-term contextual memory that lets Copilot recall key details—training plans, dates, goals—at the user’s direction.Connectors – Integration with OneDrive, Outlook, Gmail, Google Drive, and Google Calendar for natural-language search across accounts.Proactive Actions (Preview) – Context-based prompts and next-step suggestions derived from recent activity.Copilot for Health – Health information grounded in credible medical sources such as Harvard Health, with tools allowing users to locate and compare doctors.Learn Live – A Socratic, voice-driven tutoring experience using questions, visuals, and whiteboards.Copilot Mode in Edge – Converts Microsoft Edge into an “AI browser” that summarizes, compares, and executes web actions by voice.Copilot on Windows – Deep integration across Windows 11 PCs with “Hey Copilot” activation, Copilot Vision guidance, and quick access to files and apps.Copilot Pages and Copilot Search – A collaborative file canvas plus a unified search experience combining AI-generated, cited answers with standard web results.The Fall Release is immediately available in the United States, with rollout to the UK, Canada, and other markets in progress. Some functions—such as Groups, Journeys, and Copilot for Health—remain U.S.-only for now. Proactive Actions requires a Microsoft 365 Personal, Family, or Premium subscription.Together these updates illustrate Microsoft’s pivot from static productivity suites to contextual AI infrastructure, with the Copilot brand acting as the connective tissue across user roles.From Clippy to Mico: The Return of a Guided InterfaceOne of the most notable introductions is Mico, a small animated companion that is available within Copilot’s voice-enabled experiences, including the Copilot app on Windows, iOS, and Android, as well as in Study Mode and other conversational contexts. It serves as an optional visual companion that appears during interactive or voice-based sessions, rather than across all Copilot interfaces.Mico listens, reacts with expressions, and changes color to reflect tone and emotion — bringing a visual warmth to an AI assistant experience that has traditionally been text-heavy.Mico’s design recalls earlier eras of Microsoft’s history with character-based assistants. In the mid-1990s, Microsoft experimented with Microsoft Bob (1995), a software interface that used cartoon characters like a dog named Rover to guide users through everyday computing tasks. While innovative for its time, Bob was discontinued after a year due to performance and usability issues.A few years later came Clippy, the Office Assistant introduced in Microsoft Office 97. Officially known as “Clippit,” the animated paperclip would pop up to offer help and tips within Word and other Office applications. Clippy became widely recognized—sometimes humorously so—for interrupting users with unsolicited advice. Microsoft retired Clippy from Office in 2001, though the character remains a nostalgic symbol of early AI-driven assistance.More recently, Cortana, launched in 2014 as Microsoft’s digital voice assistant for Windows and mobile devices, aimed to provide natural-language interaction similar to Apple’s Siri or Amazon’s Alexa. Despite positive early reception, Cortana’s role diminished as Microsoft refocused on enterprise productivity and AI integration. The service was officially discontinued on Windows in 2023.Mico, by contrast, represents a modern reimagining of that tradition—combining the personality of early assistants with the intelligence and adaptability of contemporary AI models. Where Clippy offered canned responses, Mico listens, learns, and reflects a user’s mood in real time. The goal, as Suleyman framed it, is to create an AI that feels “helpful, supportive, and deeply personal.”Groups Are Microsoft&#x27;s Version of Claude and ChatGPT ProjectsDuring Microsoft’s launch video, product researcher Wendy described Groups as a transformative shift: “You can finally bring in other people directly to the conversation that you’re having with Copilot,” she said. “It’s the only place you can do this.”Up to 32 users can join a shared Copilot session, brainstorming, editing, or planning together while the AI manages logistics such as summarizing discussion threads, tallying votes, and splitting tasks. Participants can enter or exit sessions using a link, maintaining full visibility into ongoing work.Instead of a single user prompting an AI and later sharing results, Groups lets teams prompt and iterate together in one unified conversation. In some ways, it&#x27;s an answer to Anthropic’s Claude Projects and OpenAI’s ChatGPT Projects, both launched within the last year as tools to centralize team workspaces and shared AI context. Where Claude and ChatGPT Projects allow users to aggregate files, prompts, and conversations into a single container, Groups extends that model into real-time, multi-participant collaboration. Unlike Anthropic’s and OpenAI’s implementations, Groups is deeply embedded within Microsoft’s productivity environment. Like other Copilot experiences connected to Outlook and OneDrive, Groups operates within Microsoft’s enterprise identity framework, governed by Microsoft 365 and Entra ID (formerly Azure Active Directory) authentication and consent modelsThis means conversations, shared artifacts, and generated summaries are governed under the same compliance policies that already protect Outlook, Teams, and SharePoint data.Hours after the unveiling, OpenAI hit back against its own investor in the escalating AI competition between the \"frenemies\" by expanding its Shared Projects feature beyond its current Enterprise, Team, and Edu subscriber availability to users of its free, Plus, and Pro subscription tiers. Operational Impact for AI and Data TeamsMemory & Personalization and Connectors effectively extend a lightweight orchestration layer across Microsoft’s ecosystem. Instead of building separate context-stores or retrieval APIs, teams can leverage Copilot’s secure integration with OneDrive or SharePoint as a governed data backbone. A presenter explained that Copilot’s memory “naturally picks up on important details and remembers them long after you’ve had the conversation,” yet remains editable. For data engineers, Copilot Search and Connectors reduce friction in data discovery across multiple systems. Natural-language retrieval from internal and cloud repositories may lower the cost of knowledge management initiatives by consolidating search endpoints.For security directors, Copilot’s explicit consent requirements and on/off toggles in Edge and Windows help maintain data residency standards. The company reiterated during the livestream that Copilot “acts only with user permission and within organizational privacy controls.”Copilot Mode in Edge: The AI Browser for Research and AutomationCopilot Mode in Edge stands out for offering AI-assisted information workflows. The browser can now parse open tabs, summarize differences, and perform transactional steps.“Historically, browsers have been static—just endless clicking and tab-hopping,” said a presenter during Microsoft’s livestream. “We asked not how browsers should work, but how people work.”In practice, an analyst could prompt Edge to compare supplier documentation, extract structured data, and auto-fill procurement forms—all with consistent citation. Voice-only navigation enables accessibility and multitasking, while Journeys, a companion feature, organizes browsing sessions into storylines for later review.Copilot on Windows: The Operating System as an AI SurfaceIn Windows 11, Copilot now functions as an embedded assistant. With the wake-word “Hey Copilot,” users can initiate context-aware commands without leaving the desktop—drafting documentation, troubleshooting configuration issues, or summarizing system logs.A presenter described it as a “super assistant plugged into all your files and applications.” For enterprises standardizing on Windows 11, this positions Copilot as a native productivity layer rather than an add-on, reducing training friction and promoting secure, on-device reasoning.Copilot Vision, now in early deployment, adds visual comprehension. IT staff can capture a screen region and ask Copilot to interpret error messages, explain configuration options, or generate support tickets automatically.Combined with Copilot Pages, which supports up to twenty concurrent file uploads, this enables more efficient cross-document analysis for audits, RFPs, or code reviews.Leveraging MAI Models for Multimodal WorkflowsAt the foundation of these capabilities are Microsoft’s proprietary MAI-Voice-1, MAI-1 Preview, and MAI-Vision-1 models—trained in-house to handle text, voice, and visual inputs cohesively.For engineering teams managing LLM orchestration, this architecture introduces several potential efficiencies:Unified multimodal reasoning – Reduces the need for separate ASR (speech-to-text) and image-parsing services.Fine-tuning continuity – Because Microsoft owns the model stack, updates propagate across Copilot experiences without re-integration.Predictable latency and governance – In-house hosting under Azure compliance frameworks simplifies security certification for regulated industries.A presenter described the new stack as “the foundation for immersive, creative, and dynamic experiences that still respect enterprise boundaries.”A Strategic Pivot Toward Contextual AIFor years, Microsoft positioned Copilot primarily as a productivity companion. With the Fall 2025 release, it crosses into operational AI infrastructure—a set of extensible services for reasoning over data and processes.Suleyman described this evolution succinctly: “Judge an AI by how much it elevates human potential, not just by its own smarts.” For CIOs and technical leads, the elevation comes from efficiency and interoperability.Copilot now acts as:A connective interface linking files, communications, and cloud data.A reasoning agent capable of understanding context across sessions and modalities.A secure orchestration layer compatible with Microsoft’s compliance and identity framework.Suleyman’s insistence that “technology should work in service of people” now extends to organizations as well: technology that serves teams, not workloads; systems that adapt to enterprise context rather than demand it.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1Y044YCqXidwgzt8iDL4XH/2a45ab0dfe64db4d9371db86b1d0e5d2/cfr0z3n_flat_2D_illustration_mod_colorful_playful_whimsical_sty_715bb078-8762-43bc-93ec-ce95bb5d570d.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ai-is-tearing-companies-apart-writer-ai-ceo-slams-fortune-500-leaders-for",
          "published_at": "Thu, 23 Oct 2025 13:02:00 GMT",
          "title": "‘AI is tearing companies apart’: Writer AI CEO slams Fortune 500 leaders for mismanaging tech",
          "standfirst": "May Habib, co-founder and CEO of Writer AI, delivered one of the bluntest assessments of corporate AI failures at the TED AI conference on Tuesday, revealing that nearly half of Fortune 500 executives believe artificial intelligence is actively damaging their organizations — and placing the blame squarely on leadership&#x27;s shoulders.The problem, according to Habib, isn&#x27;t the technology. It&#x27;s that business leaders are making a category error, treating AI transformation like previous technology rollouts and delegating it to IT departments. This approach, she warned, has led to \"billions of dollars spent on AI initiatives that are going nowhere.\"\"Earlier this year, we did a survey of 800 Fortune 500 C-suite executives,\" Habib told the audience of Silicon Valley executives and investors. \"42% of them said AI is tearing their company apart.\"The diagnosis challenges conventional wisdom about how enterprises should approach AI adoption. While most major companies have stood up AI task forces, appointed chief AI officers, or expanded IT budgets, Habib argues these moves reflect a fundamental misunderstanding of what AI represents: not another software tool, but a wholesale reorganization of how work gets done.\"There is something leaders are missing when they compare AI to just another tech tool,\" Habib said. \"This is not like giving accountants calculators or bankers Excel or designers Photoshop.\"Why the &#x27;old playbook&#x27; of delegating to IT departments is failing companiesHabib, whose company has spent five years building AI systems for Fortune 500 companies and logged two million miles visiting customer sites, said the pattern is consistent: \"When generative AI started showing up, we turned to the old playbook. We turned to IT and said, &#x27;Go figure this out.&#x27;\"That approach fails, she argued, because AI fundamentally changes the economics and organization of work itself. \"For 100 years, enterprises have been built around the idea that execution is expensive and hard,\" Habib said. \"The enterprise built complex org charts, complex processes, all to manage people doing stuff.\"AI inverts that model. \"Execution is going from scarce and expensive to programmatic, on-demand and abundant,\" she said. In this new paradigm, the bottleneck shifts from execution capacity to strategic design — a shift that requires business leaders, not IT departments, to drive transformation.\"With AI technology, it can no longer be centralized. It&#x27;s in every workflow, every business,\" Habib said. \"It is now the most important part of a business leader&#x27;s job. It cannot be delegated.\"The statement represents a direct challenge to how most large organizations have structured their AI initiatives, with centralized centers of excellence, dedicated AI teams, or IT-led implementations that business units are expected to adopt.A generational power shift is happening based on who understands AI workflow designHabib framed the shift in dramatic terms: \"A generational transfer of power is happening right now. It&#x27;s not about your age or how long you&#x27;ve been at a company. The generational transfer of power is about the nature of leadership itself.\"Traditional leadership, she argued, has been defined by the ability to manage complexity — big teams, big budgets, intricate processes. \"The identity of leaders at these companies, people like us, has been tied to old school power structures: control, hierarchy, how big our teams are, how big our budgets are. Our value is measured by the sheer amount of complexity we could manage,\" Habib said. \"Today we reward leaders for this. We promote leaders for this.\"AI makes that model obsolete. \"When I am able to 10x the output of my team or do things that could never be possible, work is no longer about the 1x,\" she said. \"Leadership is no longer about managing complex human execution.\"Instead, Habib outlined three fundamental shifts that define what she calls \"AI-first leaders\" — executives her company has worked with who have successfully deployed AI agents solving \"$100 million plus problems.\"The first shift: Taking a machete to enterprise complexityThe new leadership mandate, according to Habib, is \"taking a machete to the complexity that has calcified so many organizations.\" She pointed to the layers of friction that have accumulated in enterprises: \"Brilliant ideas dying in memos, the endless cycles of approvals, the death by 1,000 clicks, meetings about meetings — a death, by the way, that&#x27;s happening in 17 different browser tabs each for software that promises to be a single source of truth.\"Rather than accepting this complexity as inevitable, AI-first leaders redesign workflows from first principles. \"There are very few legacy systems that can&#x27;t be replaced in your organization, that won&#x27;t be replaced,\" Habib said. \"But they&#x27;re not going to be replaced by another monolithic piece of software. They can only be replaced by a business leader articulating business logic and getting that into an agentic system.\"She offered a concrete example: \"We have customers where it used to take them seven months to get a creative campaign — not even a product, a campaign. Now they can go from TikTok trend to digital shelf in 30 days. That is radical simplicity.\"The catch, she emphasized, is that CIOs can&#x27;t drive this transformation alone. \"Your CIO can&#x27;t help flatten your org chart. Only a business leader can look at workflows and say, &#x27;This part is necessary genius, this part is bureaucratic scar tissue that has to go.&#x27;\"The second shift: Managing the fear as career ladders disappearWhen AI handles execution, \"your humans are liberated to do what they&#x27;re amazing at: judgment, strategy, creativity,\" Habib explained. \"The old leadership playbook was about managing headcount. We managed people against revenue: one business development rep for every three account executives, one marketer for every five salespeople.\"But this liberation carries profound challenges that leaders must address directly. Habib acknowledged the elephant in the room that many executives avoid discussing: \"These changes are still frightening for people, even when it&#x27;s become unholy to talk about it.\" She&#x27;s witnessed the fear firsthand. \"It shows up as tears in an AI workshop when someone feels like their old skill set isn&#x27;t translated to the new.\"She introduced a term for a common form of resistance: \"productivity anchoring\" — when employees \"cling to the hard way of doing things because they feel productive, because their self-worth is tied to them, even when empirically AI can be better.\"The solution isn&#x27;t to look away. \"We have to design new pathways to impact, to show your people their value is not in executing a task. Their value is in orchestrating systems of execution, to ask the next great question,\" Habib said. She advocates replacing career \"ladders\" with \"lattices\" where \"people need to grow laterally, to expand sideways.\"She was candid about the disruption: \"The first rungs on our career ladders are indeed going away. I know because my company is automating them.\" But she insisted this creates opportunity for work that is \"more creative, more strategic, more driven by curiosity and impact — and I believe a lot more human than the jobs that they&#x27;re replacing.\"The third shift: When execution becomes free, ambition becomes the only bottleneckThe final shift is from optimization to creation. \"Before AI, we used to call it transformation when we took 12 steps and made them nine,\" Habib said. \"That&#x27;s optimizing the world as it is. We can now create a new world. That is the greenfield mindset.\"She challenged executives to identify assumptions their industries are built on that AI now disrupts. Writer&#x27;s customers, she said, are already seeing new categories of growth: treating every customer like their only customer, democratizing premium services to broader markets, and entering new markets at unprecedented speed because \"AI strips away the friction to access new channels.\"\"When execution is abundant, the only bottleneck is the scope of your own ambition,\" Habib declared.What this means for CIOs: Building the stadium while business leaders design the playsHabib didn&#x27;t leave IT leaders without a role — she redefined it. \"If tech is everyone&#x27;s job, you might be asking, what is mine?\" she addressed CIOs. \"Yours is to provide the mission critical infrastructure that makes this revolution possible.\"As tens or hundreds of thousands of AI agents operate at various levels of autonomy within organizations, \"governance becomes existential,\" she explained. \"The business leader&#x27;s job is to design the play, but you have to build the stadium, you have to write the rule book, and you have to make sure these plays can win at championship scale.\"The formulation suggests a partnership model: business leaders drive workflow redesign and strategic implementation while IT provides the infrastructure, governance frameworks, and security guardrails that make mass AI deployment safe and scalable. \"One can&#x27;t succeed without the other,\" Habib said.For CIOs and technical leaders, this represents a fundamental shift from gatekeeper to enabler. When business units deploy agents autonomously, IT faces governance challenges unlike anything in enterprise software history. Success requires genuine partnership between business and IT — neither can succeed alone, forcing cultural changes in how these functions collaborate.A real example: From multi-day scrambles to instant answers during a market crisisTo ground her arguments in concrete business impact, Habib described working with the chief client officer of a Fortune 500 wealth advisory firm during recent market volatility following tariff announcements.\"Their phone was ringing off the hook with customers trying to figure out their market exposure,\" she recounted. \"Every request kicked off a multi-day, multi-person scramble: a portfolio manager ran the show, an analyst pulled charts, a relationship manager built the PowerPoint, a compliance officer had to review everything for disclosures. And the leader in all this — she was forwarding emails and chasing updates. This is the top job: managing complexity.\"With an agentic AI system, the same work happens programmatically. \"A system of agents is able to assemble the answer faster than any number of people could have. No more midnight deck reviews. No more days on end\" of coordination, Habib said.This isn&#x27;t about marginal productivity gains — it&#x27;s about fundamentally different operating models where senior executives shift from managing coordination to designing intelligent systems.Why so many AI initiatives are failing despite massive investmentHabib&#x27;s arguments arrive as many enterprises face AI disillusionment. After initial excitement about generative AI, many companies have struggled to move beyond pilots and demonstrations to production deployments generating tangible business value.Her diagnosis — that leaders are delegating rather than driving transformation — aligns with growing evidence that organizational factors, not technical limitations, explain most failures. Companies often lack clarity on use cases, struggle with data preparation, or face internal resistance to workflow changes that AI requires.Perhaps the most striking aspect of Habib&#x27;s presentation was her willingness to acknowledge the human cost of AI transformation — and insist leaders address it rather than avoid it. \"Your job as a leader is to not look away from this fear. Your job is to face it with a plan,\" she told the audience.She described \"productivity anchoring\" as a form of \"self-sabotage\" where employees resist AI adoption because their identity and self-worth are tied to execution tasks AI can now perform. The phenomenon suggests that successful AI transformation requires not just technical and strategic changes but psychological and cultural work that many leaders may be unprepared for.Two challenges: Get your hands dirty, then reimagine everythingHabib closed by throwing down two gauntlets to her executive audience.\"First, a small one: get your hands dirty with agentic AI. Don&#x27;t delegate. Choose a process that you oversee and automate it. See the difference from managing a complex process to redesigning it for yourself.\"The second was more ambitious: \"Go back to your team and ask, what could we achieve if execution were free? What would work feel like, be like, look like if you&#x27;re unbound from the friction and process that slows us down today?\"She concluded: \"The tools for creation are in your hands. The mandate for leadership is on your shoulders. What will you build?\"For enterprise leaders accustomed to viewing AI as an IT initiative, Habib&#x27;s message is clear: that approach isn&#x27;t working, won&#x27;t work, and reflects a fundamental misunderstanding of what AI represents. Whether executives embrace her call to personally drive transformation — or continue delegating to IT departments — may determine which organizations thrive and which become cautionary tales.The statistic she opened with lingers uncomfortably: 42% of Fortune 500 C-suite executives say AI is tearing their companies apart. Habib&#x27;s diagnosis suggests they&#x27;re tearing themselves apart by clinging to organizational models designed for an era when execution was scarce. The cure she prescribes requires leaders to do something most find uncomfortable: stop managing complexity and start dismantling it.",
          "content": "May Habib, co-founder and CEO of Writer AI, delivered one of the bluntest assessments of corporate AI failures at the TED AI conference on Tuesday, revealing that nearly half of Fortune 500 executives believe artificial intelligence is actively damaging their organizations — and placing the blame squarely on leadership&#x27;s shoulders.The problem, according to Habib, isn&#x27;t the technology. It&#x27;s that business leaders are making a category error, treating AI transformation like previous technology rollouts and delegating it to IT departments. This approach, she warned, has led to \"billions of dollars spent on AI initiatives that are going nowhere.\"\"Earlier this year, we did a survey of 800 Fortune 500 C-suite executives,\" Habib told the audience of Silicon Valley executives and investors. \"42% of them said AI is tearing their company apart.\"The diagnosis challenges conventional wisdom about how enterprises should approach AI adoption. While most major companies have stood up AI task forces, appointed chief AI officers, or expanded IT budgets, Habib argues these moves reflect a fundamental misunderstanding of what AI represents: not another software tool, but a wholesale reorganization of how work gets done.\"There is something leaders are missing when they compare AI to just another tech tool,\" Habib said. \"This is not like giving accountants calculators or bankers Excel or designers Photoshop.\"Why the &#x27;old playbook&#x27; of delegating to IT departments is failing companiesHabib, whose company has spent five years building AI systems for Fortune 500 companies and logged two million miles visiting customer sites, said the pattern is consistent: \"When generative AI started showing up, we turned to the old playbook. We turned to IT and said, &#x27;Go figure this out.&#x27;\"That approach fails, she argued, because AI fundamentally changes the economics and organization of work itself. \"For 100 years, enterprises have been built around the idea that execution is expensive and hard,\" Habib said. \"The enterprise built complex org charts, complex processes, all to manage people doing stuff.\"AI inverts that model. \"Execution is going from scarce and expensive to programmatic, on-demand and abundant,\" she said. In this new paradigm, the bottleneck shifts from execution capacity to strategic design — a shift that requires business leaders, not IT departments, to drive transformation.\"With AI technology, it can no longer be centralized. It&#x27;s in every workflow, every business,\" Habib said. \"It is now the most important part of a business leader&#x27;s job. It cannot be delegated.\"The statement represents a direct challenge to how most large organizations have structured their AI initiatives, with centralized centers of excellence, dedicated AI teams, or IT-led implementations that business units are expected to adopt.A generational power shift is happening based on who understands AI workflow designHabib framed the shift in dramatic terms: \"A generational transfer of power is happening right now. It&#x27;s not about your age or how long you&#x27;ve been at a company. The generational transfer of power is about the nature of leadership itself.\"Traditional leadership, she argued, has been defined by the ability to manage complexity — big teams, big budgets, intricate processes. \"The identity of leaders at these companies, people like us, has been tied to old school power structures: control, hierarchy, how big our teams are, how big our budgets are. Our value is measured by the sheer amount of complexity we could manage,\" Habib said. \"Today we reward leaders for this. We promote leaders for this.\"AI makes that model obsolete. \"When I am able to 10x the output of my team or do things that could never be possible, work is no longer about the 1x,\" she said. \"Leadership is no longer about managing complex human execution.\"Instead, Habib outlined three fundamental shifts that define what she calls \"AI-first leaders\" — executives her company has worked with who have successfully deployed AI agents solving \"$100 million plus problems.\"The first shift: Taking a machete to enterprise complexityThe new leadership mandate, according to Habib, is \"taking a machete to the complexity that has calcified so many organizations.\" She pointed to the layers of friction that have accumulated in enterprises: \"Brilliant ideas dying in memos, the endless cycles of approvals, the death by 1,000 clicks, meetings about meetings — a death, by the way, that&#x27;s happening in 17 different browser tabs each for software that promises to be a single source of truth.\"Rather than accepting this complexity as inevitable, AI-first leaders redesign workflows from first principles. \"There are very few legacy systems that can&#x27;t be replaced in your organization, that won&#x27;t be replaced,\" Habib said. \"But they&#x27;re not going to be replaced by another monolithic piece of software. They can only be replaced by a business leader articulating business logic and getting that into an agentic system.\"She offered a concrete example: \"We have customers where it used to take them seven months to get a creative campaign — not even a product, a campaign. Now they can go from TikTok trend to digital shelf in 30 days. That is radical simplicity.\"The catch, she emphasized, is that CIOs can&#x27;t drive this transformation alone. \"Your CIO can&#x27;t help flatten your org chart. Only a business leader can look at workflows and say, &#x27;This part is necessary genius, this part is bureaucratic scar tissue that has to go.&#x27;\"The second shift: Managing the fear as career ladders disappearWhen AI handles execution, \"your humans are liberated to do what they&#x27;re amazing at: judgment, strategy, creativity,\" Habib explained. \"The old leadership playbook was about managing headcount. We managed people against revenue: one business development rep for every three account executives, one marketer for every five salespeople.\"But this liberation carries profound challenges that leaders must address directly. Habib acknowledged the elephant in the room that many executives avoid discussing: \"These changes are still frightening for people, even when it&#x27;s become unholy to talk about it.\" She&#x27;s witnessed the fear firsthand. \"It shows up as tears in an AI workshop when someone feels like their old skill set isn&#x27;t translated to the new.\"She introduced a term for a common form of resistance: \"productivity anchoring\" — when employees \"cling to the hard way of doing things because they feel productive, because their self-worth is tied to them, even when empirically AI can be better.\"The solution isn&#x27;t to look away. \"We have to design new pathways to impact, to show your people their value is not in executing a task. Their value is in orchestrating systems of execution, to ask the next great question,\" Habib said. She advocates replacing career \"ladders\" with \"lattices\" where \"people need to grow laterally, to expand sideways.\"She was candid about the disruption: \"The first rungs on our career ladders are indeed going away. I know because my company is automating them.\" But she insisted this creates opportunity for work that is \"more creative, more strategic, more driven by curiosity and impact — and I believe a lot more human than the jobs that they&#x27;re replacing.\"The third shift: When execution becomes free, ambition becomes the only bottleneckThe final shift is from optimization to creation. \"Before AI, we used to call it transformation when we took 12 steps and made them nine,\" Habib said. \"That&#x27;s optimizing the world as it is. We can now create a new world. That is the greenfield mindset.\"She challenged executives to identify assumptions their industries are built on that AI now disrupts. Writer&#x27;s customers, she said, are already seeing new categories of growth: treating every customer like their only customer, democratizing premium services to broader markets, and entering new markets at unprecedented speed because \"AI strips away the friction to access new channels.\"\"When execution is abundant, the only bottleneck is the scope of your own ambition,\" Habib declared.What this means for CIOs: Building the stadium while business leaders design the playsHabib didn&#x27;t leave IT leaders without a role — she redefined it. \"If tech is everyone&#x27;s job, you might be asking, what is mine?\" she addressed CIOs. \"Yours is to provide the mission critical infrastructure that makes this revolution possible.\"As tens or hundreds of thousands of AI agents operate at various levels of autonomy within organizations, \"governance becomes existential,\" she explained. \"The business leader&#x27;s job is to design the play, but you have to build the stadium, you have to write the rule book, and you have to make sure these plays can win at championship scale.\"The formulation suggests a partnership model: business leaders drive workflow redesign and strategic implementation while IT provides the infrastructure, governance frameworks, and security guardrails that make mass AI deployment safe and scalable. \"One can&#x27;t succeed without the other,\" Habib said.For CIOs and technical leaders, this represents a fundamental shift from gatekeeper to enabler. When business units deploy agents autonomously, IT faces governance challenges unlike anything in enterprise software history. Success requires genuine partnership between business and IT — neither can succeed alone, forcing cultural changes in how these functions collaborate.A real example: From multi-day scrambles to instant answers during a market crisisTo ground her arguments in concrete business impact, Habib described working with the chief client officer of a Fortune 500 wealth advisory firm during recent market volatility following tariff announcements.\"Their phone was ringing off the hook with customers trying to figure out their market exposure,\" she recounted. \"Every request kicked off a multi-day, multi-person scramble: a portfolio manager ran the show, an analyst pulled charts, a relationship manager built the PowerPoint, a compliance officer had to review everything for disclosures. And the leader in all this — she was forwarding emails and chasing updates. This is the top job: managing complexity.\"With an agentic AI system, the same work happens programmatically. \"A system of agents is able to assemble the answer faster than any number of people could have. No more midnight deck reviews. No more days on end\" of coordination, Habib said.This isn&#x27;t about marginal productivity gains — it&#x27;s about fundamentally different operating models where senior executives shift from managing coordination to designing intelligent systems.Why so many AI initiatives are failing despite massive investmentHabib&#x27;s arguments arrive as many enterprises face AI disillusionment. After initial excitement about generative AI, many companies have struggled to move beyond pilots and demonstrations to production deployments generating tangible business value.Her diagnosis — that leaders are delegating rather than driving transformation — aligns with growing evidence that organizational factors, not technical limitations, explain most failures. Companies often lack clarity on use cases, struggle with data preparation, or face internal resistance to workflow changes that AI requires.Perhaps the most striking aspect of Habib&#x27;s presentation was her willingness to acknowledge the human cost of AI transformation — and insist leaders address it rather than avoid it. \"Your job as a leader is to not look away from this fear. Your job is to face it with a plan,\" she told the audience.She described \"productivity anchoring\" as a form of \"self-sabotage\" where employees resist AI adoption because their identity and self-worth are tied to execution tasks AI can now perform. The phenomenon suggests that successful AI transformation requires not just technical and strategic changes but psychological and cultural work that many leaders may be unprepared for.Two challenges: Get your hands dirty, then reimagine everythingHabib closed by throwing down two gauntlets to her executive audience.\"First, a small one: get your hands dirty with agentic AI. Don&#x27;t delegate. Choose a process that you oversee and automate it. See the difference from managing a complex process to redesigning it for yourself.\"The second was more ambitious: \"Go back to your team and ask, what could we achieve if execution were free? What would work feel like, be like, look like if you&#x27;re unbound from the friction and process that slows us down today?\"She concluded: \"The tools for creation are in your hands. The mandate for leadership is on your shoulders. What will you build?\"For enterprise leaders accustomed to viewing AI as an IT initiative, Habib&#x27;s message is clear: that approach isn&#x27;t working, won&#x27;t work, and reflects a fundamental misunderstanding of what AI represents. Whether executives embrace her call to personally drive transformation — or continue delegating to IT departments — may determine which organizations thrive and which become cautionary tales.The statistic she opened with lingers uncomfortably: 42% of Fortune 500 C-suite executives say AI is tearing their companies apart. Habib&#x27;s diagnosis suggests they&#x27;re tearing themselves apart by clinging to organizational models designed for an era when execution was scarce. The cure she prescribes requires leaders to do something most find uncomfortable: stop managing complexity and start dismantling it.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4aHBNxyB2pkPhCFjBLoMOH/b09ae06e86fe5534666c4574c5de2bdb/nuneybits_Vector_art_of_company_fracturing_apart_433a69a5-4c41-4199-bf6a-51d8cd076379.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/sakana-ais-cto-says-hes-absolutely-sick-of-transformers-the-tech-that-powers",
          "published_at": "Thu, 23 Oct 2025 13:00:00 GMT",
          "title": "Sakana AI's CTO says he's 'absolutely sick' of transformers, the tech that powers every major AI model",
          "standfirst": "In a striking act of self-critique, one of the architects of the transformer technology that powers ChatGPT, Claude, and virtually every major AI system told an audience of industry leaders this week that artificial intelligence research has become dangerously narrow — and that he&#x27;s moving on from his own creation.Llion Jones, who co-authored the seminal 2017 paper \"Attention Is All You Need\" and even coined the name \"transformer,\" delivered an unusually candid assessment at the TED AI conference in San Francisco on Tuesday: Despite unprecedented investment and talent flooding into AI, the field has calcified around a single architectural approach, potentially blinding researchers to the next major breakthrough.\"Despite the fact that there&#x27;s never been so much interest and resources and money and talent, this has somehow caused the narrowing of the research that we&#x27;re doing,\" Jones told the audience. The culprit, he argued, is the \"immense amount of pressure\" from investors demanding returns and researchers scrambling to stand out in an overcrowded field.The warning carries particular weight given Jones&#x27;s role in AI history. The transformer architecture he helped develop at Google has become the foundation of the generative AI boom, enabling systems that can write essays, generate images, and engage in human-like conversation. His paper has been cited more than 100,000 times, making it one of the most influential computer science publications of the century.Now, as CTO and co-founder of Tokyo-based Sakana AI, Jones is explicitly abandoning his own creation. \"I personally made a decision in the beginning of this year that I&#x27;m going to drastically reduce the amount of time that I spend on transformers,\" he said. \"I&#x27;m explicitly now exploring and looking for the next big thing.\"Why more AI funding has led to less creative research, according to a transformer pioneerJones painted a picture of an AI research community suffering from what he called a paradox: More resources have led to less creativity. He described researchers constantly checking whether they&#x27;ve been \"scooped\" by competitors working on identical ideas, and academics choosing safe, publishable projects over risky, potentially transformative ones.\"If you&#x27;re doing standard AI research right now, you kind of have to assume that there&#x27;s maybe three or four other groups doing something very similar, or maybe exactly the same,\" Jones said, describing an environment where \"unfortunately, this pressure damages the science, because people are rushing their papers, and it&#x27;s reducing the amount of creativity.\"He drew an analogy from AI itself — the \"exploration versus exploitation\" trade-off that governs how algorithms search for solutions. When a system exploits too much and explores too little, it finds mediocre local solutions while missing superior alternatives. \"We are almost certainly in that situation right now in the AI industry,\" Jones argued.The implications are sobering. Jones recalled the period just before transformers emerged, when researchers were endlessly tweaking recurrent neural networks — the previous dominant architecture — for incremental gains. Once transformers arrived, all that work suddenly seemed irrelevant. \"How much time do you think those researchers would have spent trying to improve the recurrent neural network if they knew something like transformers was around the corner?\" he asked.He worries the field is repeating that pattern. \"I&#x27;m worried that we&#x27;re in that situation right now where we&#x27;re just concentrating on one architecture and just permuting it and trying different things, where there might be a breakthrough just around the corner.\"How the &#x27;Attention is all you need&#x27; paper was born from freedom, not pressureTo underscore his point, Jones described the conditions that allowed transformers to emerge in the first place — a stark contrast to today&#x27;s environment. The project, he said, was \"very organic, bottom up,\" born from \"talking over lunch or scrawling randomly on the whiteboard in the office.\"Critically, \"we didn&#x27;t actually have a good idea, we had the freedom to actually spend time and go and work on it, and even more importantly, we didn&#x27;t have any pressure that was coming down from management,\" Jones recounted. \"No pressure to work on any particular project, publish a number of papers to push a certain metric up.\"That freedom, Jones suggested, is largely absent today. Even researchers recruited for astronomical salaries — \"literally a million dollars a year, in some cases\" — may not feel empowered to take risks. \"Do you think that when they start their new position they feel empowered to try their wild ideas and more speculative ideas, or do they feel immense pressure to prove their worth and once again, go for the low hanging fruit?\" he asked.Why one AI lab is betting that research freedom beats million-dollar salariesJones&#x27;s proposed solution is deliberately provocative: Turn up the \"explore dial\" and openly share findings, even at competitive cost. He acknowledged the irony of his position. \"It may sound a little controversial to hear one of the Transformers authors stand on stage and tell you that he&#x27;s absolutely sick of them, but it&#x27;s kind of fair enough, right? I&#x27;ve been working on them longer than anyone, with the possible exception of seven people.\"At Sakana AI, Jones said he&#x27;s attempting to recreate that pre-transformer environment, with nature-inspired research and minimal pressure to chase publications or compete directly with rivals. He offered researchers a mantra from engineer Brian Cheung: \"You should only do the research that wouldn&#x27;t happen if you weren&#x27;t doing it.\"One example is Sakana&#x27;s \"continuous thought machine,\" which incorporates brain-like synchronization into neural networks. An employee who pitched the idea told Jones he would have faced skepticism and pressure not to waste time at previous employers or academic positions. At Sakana, Jones gave him a week to explore. The project became successful enough to be spotlighted at NeurIPS, a major AI conference.Jones even suggested that freedom beats compensation in recruiting. \"It&#x27;s a really, really good way of getting talent,\" he said of the exploratory environment. \"Think about it, talented, intelligent people, ambitious people, will naturally seek out this kind of environment.\"The transformer&#x27;s success may be blocking AI&#x27;s next breakthroughPerhaps most provocatively, Jones suggested transformers may be victims of their own success. \"The fact that the current technology is so powerful and flexible... stopped us from looking for better,\" he said. \"It makes sense that if the current technology was worse, more people would be looking for better.\"He was careful to clarify that he&#x27;s not dismissing ongoing transformer research. \"There&#x27;s still plenty of very important work to be done on current technology and bringing a lot of value in the coming years,\" he said. \"I&#x27;m just saying that given the amount of talent and resources that we have currently, we can afford to do a lot more.\"His ultimate message was one of collaboration over competition. \"Genuinely, from my perspective, this is not a competition,\" Jones concluded. \"We all have the same goal. We all want to see this technology progress so that we can all benefit from it. So if we can all collectively turn up the explore dial and then openly share what we find, we can get to our goal much faster.\"The high stakes of AI&#x27;s exploration problemThe remarks arrive at a pivotal moment for artificial intelligence. The industry grapples with mounting evidence that simply building larger transformer models may be approaching diminishing returns. Leading researchers have begun openly discussing whether the current paradigm has fundamental limitations, with some suggesting that architectural innovations — not just scale — will be needed for continued progress toward more capable AI systems.Jones&#x27;s warning suggests that finding those innovations may require dismantling the very incentive structures that have driven AI&#x27;s recent boom. With tens of billions of dollars flowing into AI development annually and fierce competition among labs driving secrecy and rapid publication cycles, the exploratory research environment he described seems increasingly distant.Yet his insider perspective carries unusual weight. As someone who helped create the technology now dominating the field, Jones understands both what it takes to achieve breakthrough innovation and what the industry risks by abandoning that approach. His decision to walk away from transformers — the architecture that made his reputation — adds credibility to a message that might otherwise sound like contrarian positioning.Whether AI&#x27;s power players will heed the call remains uncertain. But Jones offered a pointed reminder of what&#x27;s at stake: The next transformer-scale breakthrough could be just around the corner, pursued by researchers with the freedom to explore. Or it could be languishing unexplored while thousands of researchers race to publish incremental improvements on architecture that, in Jones&#x27;s words, one of its creators is \"absolutely sick of.\"After all, he&#x27;s been working on transformers longer than almost anyone. He would know when it&#x27;s time to move on.",
          "content": "In a striking act of self-critique, one of the architects of the transformer technology that powers ChatGPT, Claude, and virtually every major AI system told an audience of industry leaders this week that artificial intelligence research has become dangerously narrow — and that he&#x27;s moving on from his own creation.Llion Jones, who co-authored the seminal 2017 paper \"Attention Is All You Need\" and even coined the name \"transformer,\" delivered an unusually candid assessment at the TED AI conference in San Francisco on Tuesday: Despite unprecedented investment and talent flooding into AI, the field has calcified around a single architectural approach, potentially blinding researchers to the next major breakthrough.\"Despite the fact that there&#x27;s never been so much interest and resources and money and talent, this has somehow caused the narrowing of the research that we&#x27;re doing,\" Jones told the audience. The culprit, he argued, is the \"immense amount of pressure\" from investors demanding returns and researchers scrambling to stand out in an overcrowded field.The warning carries particular weight given Jones&#x27;s role in AI history. The transformer architecture he helped develop at Google has become the foundation of the generative AI boom, enabling systems that can write essays, generate images, and engage in human-like conversation. His paper has been cited more than 100,000 times, making it one of the most influential computer science publications of the century.Now, as CTO and co-founder of Tokyo-based Sakana AI, Jones is explicitly abandoning his own creation. \"I personally made a decision in the beginning of this year that I&#x27;m going to drastically reduce the amount of time that I spend on transformers,\" he said. \"I&#x27;m explicitly now exploring and looking for the next big thing.\"Why more AI funding has led to less creative research, according to a transformer pioneerJones painted a picture of an AI research community suffering from what he called a paradox: More resources have led to less creativity. He described researchers constantly checking whether they&#x27;ve been \"scooped\" by competitors working on identical ideas, and academics choosing safe, publishable projects over risky, potentially transformative ones.\"If you&#x27;re doing standard AI research right now, you kind of have to assume that there&#x27;s maybe three or four other groups doing something very similar, or maybe exactly the same,\" Jones said, describing an environment where \"unfortunately, this pressure damages the science, because people are rushing their papers, and it&#x27;s reducing the amount of creativity.\"He drew an analogy from AI itself — the \"exploration versus exploitation\" trade-off that governs how algorithms search for solutions. When a system exploits too much and explores too little, it finds mediocre local solutions while missing superior alternatives. \"We are almost certainly in that situation right now in the AI industry,\" Jones argued.The implications are sobering. Jones recalled the period just before transformers emerged, when researchers were endlessly tweaking recurrent neural networks — the previous dominant architecture — for incremental gains. Once transformers arrived, all that work suddenly seemed irrelevant. \"How much time do you think those researchers would have spent trying to improve the recurrent neural network if they knew something like transformers was around the corner?\" he asked.He worries the field is repeating that pattern. \"I&#x27;m worried that we&#x27;re in that situation right now where we&#x27;re just concentrating on one architecture and just permuting it and trying different things, where there might be a breakthrough just around the corner.\"How the &#x27;Attention is all you need&#x27; paper was born from freedom, not pressureTo underscore his point, Jones described the conditions that allowed transformers to emerge in the first place — a stark contrast to today&#x27;s environment. The project, he said, was \"very organic, bottom up,\" born from \"talking over lunch or scrawling randomly on the whiteboard in the office.\"Critically, \"we didn&#x27;t actually have a good idea, we had the freedom to actually spend time and go and work on it, and even more importantly, we didn&#x27;t have any pressure that was coming down from management,\" Jones recounted. \"No pressure to work on any particular project, publish a number of papers to push a certain metric up.\"That freedom, Jones suggested, is largely absent today. Even researchers recruited for astronomical salaries — \"literally a million dollars a year, in some cases\" — may not feel empowered to take risks. \"Do you think that when they start their new position they feel empowered to try their wild ideas and more speculative ideas, or do they feel immense pressure to prove their worth and once again, go for the low hanging fruit?\" he asked.Why one AI lab is betting that research freedom beats million-dollar salariesJones&#x27;s proposed solution is deliberately provocative: Turn up the \"explore dial\" and openly share findings, even at competitive cost. He acknowledged the irony of his position. \"It may sound a little controversial to hear one of the Transformers authors stand on stage and tell you that he&#x27;s absolutely sick of them, but it&#x27;s kind of fair enough, right? I&#x27;ve been working on them longer than anyone, with the possible exception of seven people.\"At Sakana AI, Jones said he&#x27;s attempting to recreate that pre-transformer environment, with nature-inspired research and minimal pressure to chase publications or compete directly with rivals. He offered researchers a mantra from engineer Brian Cheung: \"You should only do the research that wouldn&#x27;t happen if you weren&#x27;t doing it.\"One example is Sakana&#x27;s \"continuous thought machine,\" which incorporates brain-like synchronization into neural networks. An employee who pitched the idea told Jones he would have faced skepticism and pressure not to waste time at previous employers or academic positions. At Sakana, Jones gave him a week to explore. The project became successful enough to be spotlighted at NeurIPS, a major AI conference.Jones even suggested that freedom beats compensation in recruiting. \"It&#x27;s a really, really good way of getting talent,\" he said of the exploratory environment. \"Think about it, talented, intelligent people, ambitious people, will naturally seek out this kind of environment.\"The transformer&#x27;s success may be blocking AI&#x27;s next breakthroughPerhaps most provocatively, Jones suggested transformers may be victims of their own success. \"The fact that the current technology is so powerful and flexible... stopped us from looking for better,\" he said. \"It makes sense that if the current technology was worse, more people would be looking for better.\"He was careful to clarify that he&#x27;s not dismissing ongoing transformer research. \"There&#x27;s still plenty of very important work to be done on current technology and bringing a lot of value in the coming years,\" he said. \"I&#x27;m just saying that given the amount of talent and resources that we have currently, we can afford to do a lot more.\"His ultimate message was one of collaboration over competition. \"Genuinely, from my perspective, this is not a competition,\" Jones concluded. \"We all have the same goal. We all want to see this technology progress so that we can all benefit from it. So if we can all collectively turn up the explore dial and then openly share what we find, we can get to our goal much faster.\"The high stakes of AI&#x27;s exploration problemThe remarks arrive at a pivotal moment for artificial intelligence. The industry grapples with mounting evidence that simply building larger transformer models may be approaching diminishing returns. Leading researchers have begun openly discussing whether the current paradigm has fundamental limitations, with some suggesting that architectural innovations — not just scale — will be needed for continued progress toward more capable AI systems.Jones&#x27;s warning suggests that finding those innovations may require dismantling the very incentive structures that have driven AI&#x27;s recent boom. With tens of billions of dollars flowing into AI development annually and fierce competition among labs driving secrecy and rapid publication cycles, the exploratory research environment he described seems increasingly distant.Yet his insider perspective carries unusual weight. As someone who helped create the technology now dominating the field, Jones understands both what it takes to achieve breakthrough innovation and what the industry risks by abandoning that approach. His decision to walk away from transformers — the architecture that made his reputation — adds credibility to a message that might otherwise sound like contrarian positioning.Whether AI&#x27;s power players will heed the call remains uncertain. But Jones offered a pointed reminder of what&#x27;s at stake: The next transformer-scale breakthrough could be just around the corner, pursued by researchers with the freedom to explore. Or it could be languishing unexplored while thousands of researchers race to publish incremental improvements on architecture that, in Jones&#x27;s words, one of its creators is \"absolutely sick of.\"After all, he&#x27;s been working on transformers longer than almost anyone. He would know when it&#x27;s time to move on.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/WSXBhFReMwh2HPn3P3k9E/f6352f008c9afddcbf6a4ff6148d7c96/nuneybits_Vector_art_of_a_koi_fish_with_scales_formed_from_algo_8e356867-71b0-4e3b-b5b1-87ac3e4c8013.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data-infrastructure/research-finds-that-77-of-data-engineers-have-heavier-workloads-despite-ai",
          "published_at": "Thu, 23 Oct 2025 13:00:00 GMT",
          "title": "Research finds that 77% of data engineers have heavier workloads despite AI tools: Here's why and what to do about it",
          "standfirst": "Data engineers should be working faster than ever. AI-powered tools promise to automate pipeline optimization, accelerate data integration and handle the repetitive grunt work that has defined the profession for decades.Yet, according to a new survey of 400 senior technology executives by MIT Technology Review Insights in partnership with Snowflake, 77% say their data engineering teams&#x27; workloads are getting heavier, not lighter.The culprit? The very AI tools meant to help are creating a new set of problems.While 83% of organizations have already deployed AI-based data engineering tools, 45% cite integration complexity as a top challenge. Another 38% are struggling with tool sprawl and fragmentation.\"Many data engineers are using one tool to collect data, one tool to process data and another to run analytics on that data,\" Chris Child, VP of product for data engineering at Snowflake, told VentureBeat. \"Using several tools along this data lifecycle introduces complexity, risk and increased infrastructure management, which data engineers can&#x27;t afford to take on.\"The result is a productivity paradox. AI tools are making individual tasks faster, but the proliferation of disconnected tools is making the overall system more complex to manage. For enterprises racing to deploy AI at scale, this fragmentation represents a critical bottleneck.From SQL queries to LLM pipelines: The daily workflow shiftThe survey found that data engineers spent an average of 19% of their time on AI projects two years ago. Today, that figure has jumped to 37%. Respondents expect it to hit 61% within two years.But what does that shift actually look like in practice?Child offered a concrete example. Previously, if the CFO of a company needed to make forecast predictions, they would tap the data engineering team to help build a system that correlates unstructured data like vendor contracts with structured data like revenue numbers into a static dashboard. Connecting these two worlds of different data types was extremely time-consuming and expensive, requiring lawyers to manually read through each document for key contract terms and upload that information into a database.Today, that same workflow looks radically different.\"Data engineers can use a tool like Snowflake Openflow to seamlessly bring the unstructured PDF contracts living in a source like Box, together with the structured financial figures into a single platform like Snowflake, making the data accessible to LLMs,\" Child said. \"What used to take hours of manual work is now near instantaneous.\"The shift isn&#x27;t just about speed. It&#x27;s about the nature of the work itself.Two years ago, a typical data engineer&#x27;s day consisted of tuning clusters, writing SQL transformations and ensuring data readiness for human analysts. Today, that same engineer is more likely to be debugging LLM-powered transformation pipelines and setting up governance rules for AI model workflows.\"Data engineers&#x27; core skill isn&#x27;t just coding,\" Child said. \"It&#x27;s orchestrating the data foundation and ensuring trust, context and governance so AI outputs are reliable.\"The tool stack problem: When help becomes hindranceHere&#x27;s where enterprises are getting stuck.The promise of AI-powered data tools is compelling: automate pipeline optimization, accelerate debugging, streamline integration. But in practice, many organizations are discovering that each new AI tool they add creates its own integration headaches.The survey data bears this out. While AI has led to improvements in output quantity (74% report increases) and quality (77% report improvements), those gains are being offset by the operational overhead of managing disconnected tools.\"The other problem we&#x27;re seeing is that AI tools often make it easy to build a prototype by stitching together several data sources with an out-of-the-box LLM,\" Child said. \"But then when you want to take that into production, you realize that you don&#x27;t have the data accessible and you don&#x27;t know what governance you need, so it becomes difficult to roll the tool out to your users.\"For technical decision-makers evaluating their data engineering stack right now, Child offered a clear framework. \"Teams should prioritize AI tools that accelerate productivity, while at the same time eliminate infrastructure and operational complexity,\" he said. \"This allows engineers to move their focus away from managing the &#x27;glue work&#x27; of data engineering and closer to business outcomes.\"The agentic AI deployment window: 12 months to get it rightThe survey revealed that 54% of organizations plan to deploy agentic AI within the next 12 months. Agentic AI refers to autonomous agents that can make decisions and take actions without human intervention. Another 20% have already begun doing so.For data engineering teams, agentic AI represents both an enormous opportunity and a significant risk. Done right, autonomous agents can handle repetitive tasks like detecting schema drift or debugging transformation errors. Done wrong, they can corrupt datasets or expose sensitive information.\"Data engineers must prioritize pipeline optimization and monitoring in order to truly deploy agentic AI at scale,\" Child said. \"It&#x27;s a low-risk, high-return starting point that allows agentic AI to safely automate repetitive tasks like detecting schema drift or debugging transformation errors when done correctly.\"But Child was emphatic about the guardrails that must be in place first.\"Before organizations let agents near production data, two safeguards must be in place: strong governance and lineage tracking, and active human oversight,\" he said. \"Agents must inherit fine-grained permissions and operate within an established governance framework.\"The risks of skipping those steps are real. \"Without proper lineage or access governance, an agent could unintentionally corrupt datasets or expose sensitive information,\" Child warned.The perception gap that&#x27;s costing enterprises AI successPerhaps the most striking finding in the survey is a disconnect at the C-suite level.While 80% of chief data officers and 82% of chief AI officers consider data engineers integral to business success, only 55% of CIOs share that view.\"This shows that the data-forward leaders are seeing data engineering&#x27;s strategic value, but we need to do more work to help the rest of the C-suite recognize that investing in a unified, scalable data foundation and the people helping drive this is an investment in AI success, not just IT operations,\" Child said.That perception gap has real consequences.Data engineers in the surveyed organizations are already influential in decisions about AI use-case feasibility (53% of respondents) and business units&#x27; use of AI models (56%). But if CIOs don&#x27;t recognize data engineers as strategic partners, they&#x27;re unlikely to give those teams the resources, authority or seat at the table they need to prevent the kinds of tool sprawl and integration problems the survey identified.The gap appears to correlate with visibility. Chief data officers and chief AI officers work directly with data engineering teams daily and understand the complexity of what they&#x27;re managing. CIOs, focused more broadly on infrastructure and operations, may not see the strategic architecture work that data engineers are increasingly doing.This disconnect also shows up in how different executives rate the challenges facing data engineering teams. Chief AI officers are significantly more likely than CIOs to agree that data engineers&#x27; workloads are becoming increasingly heavy (93% vs. 75%). They&#x27;re also more likely to recognize data engineers&#x27; influence on overall AI strategy.What data engineers need to learn nowThe survey identified three critical skills data engineers need to develop: AI expertise, business acumen and communication abilities.For an enterprise with a 20-person data engineering team, that presents a practical challenge. Do you hire for these skills, train existing engineers or restructure the team? Child&#x27;s answer suggested the priority should be business understanding.\"The most important skill right now is for data engineers to understand what is critical to their end business users and prioritize how they can make those questions easier and faster to answer,\" he said.The lesson for enterprises: Business context matters more than adding technical certifications. Child stressed that understanding the business impact of &#x27;why&#x27; data engineers are performing certain tasks will allow them to anticipate the needs of customers better, delivering value more immediately to the business. \"The organizations with data engineering teams that prioritize this business understanding will set themselves apart from competition.\"For enterprises looking to lead in AI, the solution to the data engineering productivity crisis isn&#x27;t more AI tools. The organizations that will move fastest are consolidating their tool stacks now, deploying governance infrastructure before agents go into production and elevating data engineers from support staff to strategic architects. The window is narrow. With 54% planning agentic AI deployment within 12 months and data engineers expected to spend 61% of their time on AI projects within two years, teams that haven&#x27;t addressed tool sprawl and governance gaps will find their AI initiatives stuck in permanent pilot mode.",
          "content": "Data engineers should be working faster than ever. AI-powered tools promise to automate pipeline optimization, accelerate data integration and handle the repetitive grunt work that has defined the profession for decades.Yet, according to a new survey of 400 senior technology executives by MIT Technology Review Insights in partnership with Snowflake, 77% say their data engineering teams&#x27; workloads are getting heavier, not lighter.The culprit? The very AI tools meant to help are creating a new set of problems.While 83% of organizations have already deployed AI-based data engineering tools, 45% cite integration complexity as a top challenge. Another 38% are struggling with tool sprawl and fragmentation.\"Many data engineers are using one tool to collect data, one tool to process data and another to run analytics on that data,\" Chris Child, VP of product for data engineering at Snowflake, told VentureBeat. \"Using several tools along this data lifecycle introduces complexity, risk and increased infrastructure management, which data engineers can&#x27;t afford to take on.\"The result is a productivity paradox. AI tools are making individual tasks faster, but the proliferation of disconnected tools is making the overall system more complex to manage. For enterprises racing to deploy AI at scale, this fragmentation represents a critical bottleneck.From SQL queries to LLM pipelines: The daily workflow shiftThe survey found that data engineers spent an average of 19% of their time on AI projects two years ago. Today, that figure has jumped to 37%. Respondents expect it to hit 61% within two years.But what does that shift actually look like in practice?Child offered a concrete example. Previously, if the CFO of a company needed to make forecast predictions, they would tap the data engineering team to help build a system that correlates unstructured data like vendor contracts with structured data like revenue numbers into a static dashboard. Connecting these two worlds of different data types was extremely time-consuming and expensive, requiring lawyers to manually read through each document for key contract terms and upload that information into a database.Today, that same workflow looks radically different.\"Data engineers can use a tool like Snowflake Openflow to seamlessly bring the unstructured PDF contracts living in a source like Box, together with the structured financial figures into a single platform like Snowflake, making the data accessible to LLMs,\" Child said. \"What used to take hours of manual work is now near instantaneous.\"The shift isn&#x27;t just about speed. It&#x27;s about the nature of the work itself.Two years ago, a typical data engineer&#x27;s day consisted of tuning clusters, writing SQL transformations and ensuring data readiness for human analysts. Today, that same engineer is more likely to be debugging LLM-powered transformation pipelines and setting up governance rules for AI model workflows.\"Data engineers&#x27; core skill isn&#x27;t just coding,\" Child said. \"It&#x27;s orchestrating the data foundation and ensuring trust, context and governance so AI outputs are reliable.\"The tool stack problem: When help becomes hindranceHere&#x27;s where enterprises are getting stuck.The promise of AI-powered data tools is compelling: automate pipeline optimization, accelerate debugging, streamline integration. But in practice, many organizations are discovering that each new AI tool they add creates its own integration headaches.The survey data bears this out. While AI has led to improvements in output quantity (74% report increases) and quality (77% report improvements), those gains are being offset by the operational overhead of managing disconnected tools.\"The other problem we&#x27;re seeing is that AI tools often make it easy to build a prototype by stitching together several data sources with an out-of-the-box LLM,\" Child said. \"But then when you want to take that into production, you realize that you don&#x27;t have the data accessible and you don&#x27;t know what governance you need, so it becomes difficult to roll the tool out to your users.\"For technical decision-makers evaluating their data engineering stack right now, Child offered a clear framework. \"Teams should prioritize AI tools that accelerate productivity, while at the same time eliminate infrastructure and operational complexity,\" he said. \"This allows engineers to move their focus away from managing the &#x27;glue work&#x27; of data engineering and closer to business outcomes.\"The agentic AI deployment window: 12 months to get it rightThe survey revealed that 54% of organizations plan to deploy agentic AI within the next 12 months. Agentic AI refers to autonomous agents that can make decisions and take actions without human intervention. Another 20% have already begun doing so.For data engineering teams, agentic AI represents both an enormous opportunity and a significant risk. Done right, autonomous agents can handle repetitive tasks like detecting schema drift or debugging transformation errors. Done wrong, they can corrupt datasets or expose sensitive information.\"Data engineers must prioritize pipeline optimization and monitoring in order to truly deploy agentic AI at scale,\" Child said. \"It&#x27;s a low-risk, high-return starting point that allows agentic AI to safely automate repetitive tasks like detecting schema drift or debugging transformation errors when done correctly.\"But Child was emphatic about the guardrails that must be in place first.\"Before organizations let agents near production data, two safeguards must be in place: strong governance and lineage tracking, and active human oversight,\" he said. \"Agents must inherit fine-grained permissions and operate within an established governance framework.\"The risks of skipping those steps are real. \"Without proper lineage or access governance, an agent could unintentionally corrupt datasets or expose sensitive information,\" Child warned.The perception gap that&#x27;s costing enterprises AI successPerhaps the most striking finding in the survey is a disconnect at the C-suite level.While 80% of chief data officers and 82% of chief AI officers consider data engineers integral to business success, only 55% of CIOs share that view.\"This shows that the data-forward leaders are seeing data engineering&#x27;s strategic value, but we need to do more work to help the rest of the C-suite recognize that investing in a unified, scalable data foundation and the people helping drive this is an investment in AI success, not just IT operations,\" Child said.That perception gap has real consequences.Data engineers in the surveyed organizations are already influential in decisions about AI use-case feasibility (53% of respondents) and business units&#x27; use of AI models (56%). But if CIOs don&#x27;t recognize data engineers as strategic partners, they&#x27;re unlikely to give those teams the resources, authority or seat at the table they need to prevent the kinds of tool sprawl and integration problems the survey identified.The gap appears to correlate with visibility. Chief data officers and chief AI officers work directly with data engineering teams daily and understand the complexity of what they&#x27;re managing. CIOs, focused more broadly on infrastructure and operations, may not see the strategic architecture work that data engineers are increasingly doing.This disconnect also shows up in how different executives rate the challenges facing data engineering teams. Chief AI officers are significantly more likely than CIOs to agree that data engineers&#x27; workloads are becoming increasingly heavy (93% vs. 75%). They&#x27;re also more likely to recognize data engineers&#x27; influence on overall AI strategy.What data engineers need to learn nowThe survey identified three critical skills data engineers need to develop: AI expertise, business acumen and communication abilities.For an enterprise with a 20-person data engineering team, that presents a practical challenge. Do you hire for these skills, train existing engineers or restructure the team? Child&#x27;s answer suggested the priority should be business understanding.\"The most important skill right now is for data engineers to understand what is critical to their end business users and prioritize how they can make those questions easier and faster to answer,\" he said.The lesson for enterprises: Business context matters more than adding technical certifications. Child stressed that understanding the business impact of &#x27;why&#x27; data engineers are performing certain tasks will allow them to anticipate the needs of customers better, delivering value more immediately to the business. \"The organizations with data engineering teams that prioritize this business understanding will set themselves apart from competition.\"For enterprises looking to lead in AI, the solution to the data engineering productivity crisis isn&#x27;t more AI tools. The organizations that will move fastest are consolidating their tool stacks now, deploying governance infrastructure before agents go into production and elevating data engineers from support staff to strategic architects. The window is narrow. With 54% planning agentic AI deployment within 12 months and data engineers expected to spend 61% of their time on AI projects within two years, teams that haven&#x27;t addressed tool sprawl and governance gaps will find their AI initiatives stuck in permanent pilot mode.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6c6tA8fZ29MNNDGLsHQgK9/78cecaac03eddd1b3bd5489771bd2e57/modern-data-engineer-smk.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/what-enterprises-can-take-away-from-microsoft-ceo-satya-nadellas-shareholder",
          "published_at": "Thu, 23 Oct 2025 01:34:00 GMT",
          "title": "What enterprises can take away from Microsoft CEO Satya Nadella's shareholder letter",
          "standfirst": "One of the leading architects of the current generative AI boom — Microsoft CEO Satya Nadella, famed for having the software giant take an early investment in OpenAI (and later saying he was \"good for my $80 billion\") — published his latest annual letter yesterday on LinkedIn (a Microsoft subsidiary), and it&#x27;s chock full of interesting ideas about the near-term future that enterprise technical decision makers would do well to pay attention to, as it could aid in their own planning and tech stack development.In a companion post on X, Nadella wrote, “AI is radically changing every layer of the tech stack, and we’re changing with it.\" The full letter reinforces that message: Microsoft sees itself not just participating in the AI revolution, but shaping its infrastructure, security, tooling and governance for decades to come.While the message is addressed to Microsoft shareholders, the implications reach much further. The letter is a strategic signal to enterprise engineering leaders: CIOs, CTOs, AI leads, platform architects and security directors. Nadella outlines the direction of Microsoft’s innovation, but also what it expects from its customers and partners. The AI era is here, but it will be built by those who combine technical vision with operational discipline.Below are the five most important takeaways for enterprise technical decision makers.1. Security and reliability are now the foundation of the AI stackNadella makes security the first priority in the letter and ties it directly to Microsoft’s relevance going forward. Through its Secure Future Initiative (SFI), Microsoft has assigned the equivalent of 34,000 engineers to secure its identity systems, networks and software supply chain. Its Quality Excellence Initiative (QEI) aims to increase platform resiliency and strengthen global service uptime.Microsoft’s positioning makes it clear that enterprises will no longer get away with “ship fast, harden later” AI deployments. Nadella calls security “non-negotiable,” signaling that AI infrastructure must now meet the standards of mission-critical software. That means identity-first architecture, zero-trust execution environments and change management discipline are now table stakes for enterprise AI.2. AI infrastructure strategy is hybrid, open and sovereignty-readyNadella commits Microsoft to building “planet-scale systems” and backs that up with numbers: more than 400 Azure datacenters across 70 regions, two gigawatts of new compute capacity added this year, and new liquid-cooled GPU clusters rolling out across Azure. Microsoft also introduced Fairwater, a massive new AI datacenter in Wisconsin positioned to deliver unprecedented scale. Just as important, Microsoft is now officially multi-model. Azure AI Foundry offers access to more than 11,000 models including OpenAI, Meta, Mistral, Cohere and xAI. Microsoft is no longer pushing a single-model future, but a hybrid AI strategy.Enterprises should interpret this as validation of “portfolio architectures,” where closed, open and domain-specific models coexist. Nadella also emphasizes growing investment in sovereign cloud offerings for regulated industries, previewing a world where AI systems will have to meet regional data residency and compliance requirements from day one.3. AI agents—not just chatbots—are now Microsoft’s futureThe AI shift inside Microsoft is no longer about copilots that answer questions. It is now about AI agents that perform work. Nadella points to the rollout of Agent Mode in Microsoft 365 Copilot, which turns natural language requests into multistep business workflows. GitHub Copilot evolves from code autocomplete into a “peer programmer” capable of executing tasks asynchronously. In security operations, Microsoft has deployed AI agents that autonomously respond to incidents. In healthcare, Copilot for Dragon Medical documents clinical encounters automatically.This represents a major architectural pivot. Enterprises will need to move beyond prompt-response interfaces and begin engineering agent ecosystems that safely take actions inside business systems. That requires workflow orchestration, API integration strategies and strong guardrails. Nadella’s letter frames this as the next software platform shift.4. Unified data platforms are required to unlock AI valueNadella devotes significant attention to Microsoft Fabric and OneLake, calling Fabric the company’s fastest-growing data and analytics product ever. Fabric promises to centralize enterprise data from multiple cloud and analytics environments. OneLake provides a universal storage layer that binds analytics and AI workloads together.Microsoft’s message is blunt: siloed data means stalled AI. Enterprise teams that want AI at scale must unify operational and analytical data into a single architecture, enforce consistent data contracts and standardize metadata governance. AI success is now a data engineering problem more than a model problem.5. Trust, compliance and responsible AI are now mandatory for deployment“People want technology they can trust,” Nadella writes. Microsoft now publishes Responsible AI Transparency Reports and aligns parts of its development process with UN human rights guidance. Microsoft is also committing to digital resilience in Europe and proactive safeguards against misuse of AI-generated content.This shifts responsible AI out of the realm of corporate messaging and into engineering practice. Enterprises will need model documentation, reproducibility practices, audit trails, risk monitoring and human-in-the-loop checkpoints. Nadella signals that compliance will become integrated with product delivery—not an afterthought layered on top.The real meaning of Microsoft’s AI strategyTaken together, these five pillars send a clear message to enterprise leaders: AI maturity is no longer about building prototypes or proving use cases. System-level readiness now defines success. Nadella frames Microsoft’s mission as helping customers “think in decades and execute in quarters,” and that is more than corporate poetry. It is a call to build AI platforms engineered for longevity.The companies that win in enterprise AI will be the ones that invest early in secure cloud foundations, unify their data architectures, enable agent-based workflows and embrace responsible AI as a prerequisite for scale—not a press release. Nadella is betting that the next industrial transformation will be powered by AI infrastructure, not AI demos. With this letter, he has made Microsoft’s ambition clear: to become the platform on which that transformation is built.",
          "content": "One of the leading architects of the current generative AI boom — Microsoft CEO Satya Nadella, famed for having the software giant take an early investment in OpenAI (and later saying he was \"good for my $80 billion\") — published his latest annual letter yesterday on LinkedIn (a Microsoft subsidiary), and it&#x27;s chock full of interesting ideas about the near-term future that enterprise technical decision makers would do well to pay attention to, as it could aid in their own planning and tech stack development.In a companion post on X, Nadella wrote, “AI is radically changing every layer of the tech stack, and we’re changing with it.\" The full letter reinforces that message: Microsoft sees itself not just participating in the AI revolution, but shaping its infrastructure, security, tooling and governance for decades to come.While the message is addressed to Microsoft shareholders, the implications reach much further. The letter is a strategic signal to enterprise engineering leaders: CIOs, CTOs, AI leads, platform architects and security directors. Nadella outlines the direction of Microsoft’s innovation, but also what it expects from its customers and partners. The AI era is here, but it will be built by those who combine technical vision with operational discipline.Below are the five most important takeaways for enterprise technical decision makers.1. Security and reliability are now the foundation of the AI stackNadella makes security the first priority in the letter and ties it directly to Microsoft’s relevance going forward. Through its Secure Future Initiative (SFI), Microsoft has assigned the equivalent of 34,000 engineers to secure its identity systems, networks and software supply chain. Its Quality Excellence Initiative (QEI) aims to increase platform resiliency and strengthen global service uptime.Microsoft’s positioning makes it clear that enterprises will no longer get away with “ship fast, harden later” AI deployments. Nadella calls security “non-negotiable,” signaling that AI infrastructure must now meet the standards of mission-critical software. That means identity-first architecture, zero-trust execution environments and change management discipline are now table stakes for enterprise AI.2. AI infrastructure strategy is hybrid, open and sovereignty-readyNadella commits Microsoft to building “planet-scale systems” and backs that up with numbers: more than 400 Azure datacenters across 70 regions, two gigawatts of new compute capacity added this year, and new liquid-cooled GPU clusters rolling out across Azure. Microsoft also introduced Fairwater, a massive new AI datacenter in Wisconsin positioned to deliver unprecedented scale. Just as important, Microsoft is now officially multi-model. Azure AI Foundry offers access to more than 11,000 models including OpenAI, Meta, Mistral, Cohere and xAI. Microsoft is no longer pushing a single-model future, but a hybrid AI strategy.Enterprises should interpret this as validation of “portfolio architectures,” where closed, open and domain-specific models coexist. Nadella also emphasizes growing investment in sovereign cloud offerings for regulated industries, previewing a world where AI systems will have to meet regional data residency and compliance requirements from day one.3. AI agents—not just chatbots—are now Microsoft’s futureThe AI shift inside Microsoft is no longer about copilots that answer questions. It is now about AI agents that perform work. Nadella points to the rollout of Agent Mode in Microsoft 365 Copilot, which turns natural language requests into multistep business workflows. GitHub Copilot evolves from code autocomplete into a “peer programmer” capable of executing tasks asynchronously. In security operations, Microsoft has deployed AI agents that autonomously respond to incidents. In healthcare, Copilot for Dragon Medical documents clinical encounters automatically.This represents a major architectural pivot. Enterprises will need to move beyond prompt-response interfaces and begin engineering agent ecosystems that safely take actions inside business systems. That requires workflow orchestration, API integration strategies and strong guardrails. Nadella’s letter frames this as the next software platform shift.4. Unified data platforms are required to unlock AI valueNadella devotes significant attention to Microsoft Fabric and OneLake, calling Fabric the company’s fastest-growing data and analytics product ever. Fabric promises to centralize enterprise data from multiple cloud and analytics environments. OneLake provides a universal storage layer that binds analytics and AI workloads together.Microsoft’s message is blunt: siloed data means stalled AI. Enterprise teams that want AI at scale must unify operational and analytical data into a single architecture, enforce consistent data contracts and standardize metadata governance. AI success is now a data engineering problem more than a model problem.5. Trust, compliance and responsible AI are now mandatory for deployment“People want technology they can trust,” Nadella writes. Microsoft now publishes Responsible AI Transparency Reports and aligns parts of its development process with UN human rights guidance. Microsoft is also committing to digital resilience in Europe and proactive safeguards against misuse of AI-generated content.This shifts responsible AI out of the realm of corporate messaging and into engineering practice. Enterprises will need model documentation, reproducibility practices, audit trails, risk monitoring and human-in-the-loop checkpoints. Nadella signals that compliance will become integrated with product delivery—not an afterthought layered on top.The real meaning of Microsoft’s AI strategyTaken together, these five pillars send a clear message to enterprise leaders: AI maturity is no longer about building prototypes or proving use cases. System-level readiness now defines success. Nadella frames Microsoft’s mission as helping customers “think in decades and execute in quarters,” and that is more than corporate poetry. It is a call to build AI platforms engineered for longevity.The companies that win in enterprise AI will be the ones that invest early in secure cloud foundations, unify their data architectures, enable agent-based workflows and embrace responsible AI as a prerequisite for scale—not a press release. Nadella is betting that the next industrial transformation will be powered by AI infrastructure, not AI demos. With this letter, he has made Microsoft’s ambition clear: to become the platform on which that transformation is built.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/QSvQwRJMpyn4Xku8ZnAyk/dd36ccdb1258c23fd9dbabf947ba7cd4/cfr0z3n_httpss.mj.runM4mKVYlCu30_Cut_and_paste_collage_style_ph_780082c3-eb52-4012-ad6c-016de100662a__1_.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/DSC_5509.jpg",
      "popularity_score": 2017.3905294444444,
      "ai_summary": [
        "Discounts are available on various iPad models.",
        "The iPad Air (13-inch, with cellular) is at a record low price.",
        "The latest entry-level iPad has a faster A16 chip.",
        "The iPad Air has a laminated display and better speakers.",
        "Deals are available at retailers like Amazon and Best Buy."
      ]
    },
    {
      "id": "cluster_39",
      "coverage": 2,
      "updated_at": "Fri, 24 Oct 2025 15:58:45 +0000",
      "title": "EC finds Meta and TikTok breached transparency rules under DSA",
      "neutral_headline": "EU accuses Meta and TikTok of breaching transparency rules",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/24/ec-finds-meta-and-tiktok-breached-transparency-rules-under-dsa/",
          "published_at": "Fri, 24 Oct 2025 15:58:45 +0000",
          "title": "EC finds Meta and TikTok breached transparency rules under DSA",
          "standfirst": "The European Commission said on Friday that it has preliminarily found that both companies are not complying with rules of the Digital Services Act (DSA) that mandate them to give researchers adequate access to public data.",
          "content": "The European Commission said on Friday that it has preliminarily found that both companies are not complying with rules of the Digital Services Act (DSA) that mandate them to give researchers adequate access to public data.",
          "feed_position": 4
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251024/p3#a251024p3",
          "published_at": "Fri, 24 Oct 2025 06:45:08 -0400",
          "title": "The EU accuses Meta and TikTok of violating their obligations to give researchers adequate access to public data on their platforms under the DSA (Eliza Gkritsi/Politico)",
          "standfirst": "Eliza Gkritsi / Politico: The EU accuses Meta and TikTok of violating their obligations to give researchers adequate access to public data on their platforms under the DSA &mdash; Move comes as EU faces pressure over enforcing its tech lawbooks. &mdash; BRUSSELS &mdash; The European Commission on Friday accused Meta and TikTok &hellip;",
          "content": "Eliza Gkritsi / Politico: The EU accuses Meta and TikTok of violating their obligations to give researchers adequate access to public data on their platforms under the DSA &mdash; Move comes as EU faces pressure over enforcing its tech lawbooks. &mdash; BRUSSELS &mdash; The European Commission on Friday accused Meta and TikTok &hellip;",
          "feed_position": 12,
          "image_url": "http://www.techmeme.com/251024/i3.jpg"
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251024/p2#a251024p2",
          "published_at": "Fri, 24 Oct 2025 06:40:01 -0400",
          "title": "EU accuses Meta under DSA of failing to give users easy ways to flag illegal content and adequate tools to appeal moderation decisions, in preliminary findings (Kim Mackrael/Wall Street Journal)",
          "standfirst": "Kim Mackrael / Wall Street Journal: EU accuses Meta under DSA of failing to give users easy ways to flag illegal content and adequate tools to appeal moderation decisions, in preliminary findings &mdash; Allegations against Facebook and Instagram owner risk ire of Trump administration &mdash; BRUSSELS&mdash;The European Union charged Meta Platforms &hellip;",
          "content": "Kim Mackrael / Wall Street Journal: EU accuses Meta under DSA of failing to give users easy ways to flag illegal content and adequate tools to appeal moderation decisions, in preliminary findings &mdash; Allegations against Facebook and Instagram owner risk ire of Trump administration &mdash; BRUSSELS&mdash;The European Union charged Meta Platforms &hellip;",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/251024/i2.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251024/i3.jpg",
      "popularity_score": 2016.7146961111112,
      "ai_summary": [
        "The European Commission found Meta and TikTok non-compliant.",
        "The companies allegedly violated the Digital Services Act (DSA).",
        "The DSA mandates access to public data for researchers.",
        "The EU is facing pressure to enforce its tech regulations.",
        "Meta is also accused of failing to flag illegal content."
      ]
    },
    {
      "id": "cluster_43",
      "coverage": 2,
      "updated_at": "Fri, 24 Oct 2025 11:35:01 -0400",
      "title": "Automattic files counterclaims against WP Engine's October 2024 lawsuit and alleges that WP Engine has been abusing the WordPress trademark (Sarah Perez/TechCrunch)",
      "neutral_headline": "Automattic files counterclaims against WP Engine lawsuit",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251024/p11#a251024p11",
          "published_at": "Fri, 24 Oct 2025 11:35:01 -0400",
          "title": "Automattic files counterclaims against WP Engine's October 2024 lawsuit and alleges that WP Engine has been abusing the WordPress trademark (Sarah Perez/TechCrunch)",
          "standfirst": "Sarah Perez / TechCrunch: Automattic files counterclaims against WP Engine's October 2024 lawsuit and alleges that WP Engine has been abusing the WordPress trademark &mdash; On Friday, WordPress maker Automattic filed its counterclaims in the lawsuit initiated by hosting company WP Engine in October 2024 &hellip;",
          "content": "Sarah Perez / TechCrunch: Automattic files counterclaims against WP Engine's October 2024 lawsuit and alleges that WP Engine has been abusing the WordPress trademark &mdash; On Friday, WordPress maker Automattic filed its counterclaims in the lawsuit initiated by hosting company WP Engine in October 2024 &hellip;",
          "feed_position": 4,
          "image_url": "http://www.techmeme.com/251024/i11.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/24/automattic-files-counterclaims-against-wp-engine-in-wordpress-lawsuit-alleging-trademark-misuse/",
          "published_at": "Fri, 24 Oct 2025 14:57:06 +0000",
          "title": "Automattic files counterclaims against WP Engine in WordPress lawsuit, alleging trademark misuse",
          "standfirst": "Automattic has filed counterclaims against WP Engine, alleging that the company — backed by private equity firm Silver Lake — misused WordPress and WooCommerce trademarks, misled users, and undermined the open source community.",
          "content": "Automattic has filed counterclaims against WP Engine, alleging that the company — backed by private equity firm Silver Lake — misused WordPress and WooCommerce trademarks, misled users, and undermined the open source community.",
          "feed_position": 7
        }
      ],
      "featured_image": "http://www.techmeme.com/251024/i11.jpg",
      "popularity_score": 2016.3191405555556,
      "ai_summary": [
        "Automattic filed counterclaims against WP Engine.",
        "WP Engine initiated a lawsuit in October 2024.",
        "Automattic alleges WP Engine misused WordPress trademarks.",
        "Automattic claims WP Engine misled users.",
        "The counterclaims allege harm to the open source community."
      ]
    },
    {
      "id": "cluster_55",
      "coverage": 2,
      "updated_at": "Fri, 24 Oct 2025 14:37:03 +0000",
      "title": "This browser claims “perfect privacies protection,” but it acts like malware",
      "neutral_headline": "Browser claims privacy but acts like malware",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/this-browser-claims-perfect-privacies-protection-but-it-acts-like-malware/",
          "published_at": "Fri, 24 Oct 2025 14:37:03 +0000",
          "title": "This browser claims “perfect privacies protection,” but it acts like malware",
          "standfirst": "Researchers note links to Asia’s booming cybercrime and illegal gambling networks.",
          "content": "The Universe Browser makes some big promises to its potential users. Its online advertisements claim it’s the “fastest browser,” that people using it will “avoid privacy leaks” and that the software will help “keep you away from danger.” However, everything likely isn’t as it seems. The browser, which is linked to Chinese online gambling websites and is thought to have been downloaded millions of times, actually routes all Internet traffic through servers in China and “covertly installs several programs that run silently in the background,” according to new findings from network security company Infoblox. The researchers say the “hidden” elements include features similar to malware—including “key logging, surreptitious connections,” and changing a device’s network connections. Perhaps most significantly, the Infoblox researchers who collaborated with the United Nations Office on Drugs and Crime (UNODC) on the work, found links between the browser’s operation and Southeast Asia’s sprawling, multibillion-dollar cybercrime ecosystem, which has connections to money-laundering, illegal online gambling, human trafficking, and scam operations that use forced labor. The browser itself, the researchers says, is directly linked to a network around major online gambling company BBIN, which the researchers have labeled a threat group they call Vault Viper.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/universebrowser-1152x648.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/universe-browser-malware-gambling-networks/",
          "published_at": "Thu, 23 Oct 2025 09:30:00 +0000",
          "title": "This ‘Privacy Browser’ Has Dangerous Hidden Features",
          "standfirst": "The Universe Browser is believed to have been downloaded millions of times. But researchers say it behaves like malware and has links to Asia’s booming cybercrime and illegal gambling networks.",
          "content": "The Universe Browser is believed to have been downloaded millions of times. But researchers say it behaves like malware and has links to Asia’s booming cybercrime and illegal gambling networks.",
          "feed_position": 33,
          "image_url": "https://media.wired.com/photos/68f7d940b0f33f5754e9b50c/master/pass/sec-malware-522199638.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/universebrowser-1152x648.jpg",
      "popularity_score": 2015.3530294444445,
      "ai_summary": [
        "A browser called Universe Browser is under scrutiny.",
        "Researchers found links to cybercrime and illegal gambling networks.",
        "The browser is believed to have millions of downloads.",
        "It is suspected of behaving like malware.",
        "The browser's behavior raises security concerns."
      ]
    },
    {
      "id": "cluster_5",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 18:55:47 +0000",
      "title": "Tech billionaires are now shaping the militarization of American cities",
      "neutral_headline": "Tech billionaires shape militarization of American cities",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/tech-policy/2025/10/troops-in-us-cities-tech-billionaires-are-shaping-that-too/",
          "published_at": "Fri, 24 Oct 2025 18:55:47 +0000",
          "title": "Tech billionaires are now shaping the militarization of American cities",
          "standfirst": "Money means access to power—and tech has plenty of money.",
          "content": "Yesterday, Donald Trump announced on social media that he had been planning to “surge” troops into San Francisco this weekend—but was dissuaded from doing so by several tech billionaires. “Friends of mine who live in the area called last night to ask me not to go forward with the surge,” Trump wrote. Who are these “friends”? Trump named “great people like [Nvidia CEO] Jensen Huang, [Salesforce CEO] Marc Benioff, and others” who told him that “the future of San Francisco is great. They want to give it a ‘shot.’ Therefore, we will not surge San Francisco on Saturday. Stay tuned!”Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2232417355-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2232417355-1152x648.jpg",
      "popularity_score": 367.6652516666667,
      "ai_summary": [
        "Tech billionaires are influencing the militarization of cities.",
        "Wealth provides access to power and influence.",
        "The article suggests a connection between tech and militarization.",
        "The focus is on the impact of tech money.",
        "The trend is a growing concern."
      ]
    },
    {
      "id": "cluster_17",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 17:07:57 +0000",
      "title": "Microsoft’s Mico heightens the risks of parasocial LLM relationships",
      "neutral_headline": "Microsoft’s Mico heightens risks of parasocial LLM relationships",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/microsofts-mico-heightens-the-risks-of-parasocial-llm-relationships/",
          "published_at": "Fri, 24 Oct 2025 17:07:57 +0000",
          "title": "Microsoft’s Mico heightens the risks of parasocial LLM relationships",
          "standfirst": "\"It looks like you're trying to find a friend. Would you like help?\"",
          "content": "Microsoft is rolling out a new face for its AI, and its name is Mico. The company announced the new, animated blob-like avatar for Copilot’s voice mode yesterday as part of a “human-centered” rebranding of Microsoft’s Copilot AI efforts. Mico is part of a Microsoft program dedicated to the idea that “technology should work in service of people,” Microsoft wrote. The company insists this effort is “not [about] chasing engagement or optimizing for screen time. We’re building AI that gets you back to your life. That deepens human connection.” Mico has drawn instant and obvious comparisons to Clippy, the animated paperclip that popped up to offer help with Microsoft Office starting in the ’90s. Microsoft has leaned into this comparison with an Easter egg that can transform Mico into an animated Clippy.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/micoheart-1152x648-1761323845.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/micoheart-1152x648-1761323845.png",
      "popularity_score": 352.86802944444446,
      "ai_summary": [
        "Microsoft's Mico is raising concerns.",
        "It is related to parasocial relationships.",
        "The article highlights potential risks.",
        "The AI offers help to find friends.",
        "The focus is on the impact of AI."
      ]
    },
    {
      "id": "cluster_9",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 18:18:19 +0000",
      "title": "EU accuses Meta of violating content rules in move that could anger Trump",
      "neutral_headline": "EU accuses Meta of violating content rules",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trump-tariff-threats-havent-stopped-eu-from-cracking-down-on-meta/",
          "published_at": "Fri, 24 Oct 2025 18:18:19 +0000",
          "title": "EU accuses Meta of violating content rules in move that could anger Trump",
          "standfirst": "EU alleges Facebook and Instagram make it too hard to report illegal content.",
          "content": "Meta violated the Digital Services Act (DSA) by failing to give Facebook and Instagram users simple mechanisms to report illegal content, the European Commission said in a preliminary decision announced yesterday. Meta also failed to give users an effective way to challenge content moderation decisions, the EC said. “When it comes to Meta, neither Facebook nor Instagram appear to provide a user-friendly and easily accessible ‘Notice and Action’ mechanism for users to flag illegal content, such as child sexual abuse material and terrorist content,” the EC press release said. The EC said that Meta mechanisms seem to “impose several unnecessary steps and additional demands on users. In addition, both Facebook and Instagram appear to use so-called ‘dark patterns,’ or deceptive interface designs, when it comes to the ‘Notice and Action’ mechanisms.” The EC also found that the content moderation appeal mechanisms used by Facebook and Instagram do not “allow users to provide explanations or supporting evidence to substantiate their appeals. This makes it difficult for users in the EU to further explain why they disagree with Meta’s content decision, limiting the effectiveness of the appeals mechanism.”Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/facebook-instagram-1152x648-1761326412.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/facebook-instagram-1152x648-1761326412.jpg",
      "popularity_score": 352.0408072222222,
      "ai_summary": [
        "The EU accuses Meta of violating content rules.",
        "The allegations concern Facebook and Instagram.",
        "Meta is accused of making it hard to report illegal content.",
        "The move could anger Donald Trump.",
        "The focus is on content moderation."
      ]
    },
    {
      "id": "cluster_7",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 18:35:30 +0000",
      "title": "Tesla’s “Mad Max” mode is now under federal scrutiny",
      "neutral_headline": "Tesla’s “Mad Max” mode is now under federal scrutiny",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/cars/2025/10/feds-probe-tesla-about-its-mad-max-mode/",
          "published_at": "Fri, 24 Oct 2025 18:35:30 +0000",
          "title": "Tesla’s “Mad Max” mode is now under federal scrutiny",
          "standfirst": "The new mode added in the latest update will speed and weave through traffic.",
          "content": "Earlier this month, Tesla rolled out a new firmware update that added a pair of new driving modes for the controversial full self-driving (FSD) feature. One, called “Sloth,” relaxes acceleration and stays in its lane. The other, called “Mad Max,” does the opposite: It speeds and swerves through traffic to get you to your destination faster. And after multiple reports of FSD Teslas doing just that, the National Highway Traffic Safety Administration wants to know more. In fact, “Mad Max” mode is not entirely new—Tesla beta-tested the same feature in Autopilot in 2018, before deciding not to roll it out in a production release after widespread outcry. These days, the company is evidently feeling less constrained; despite having just lost a federal wrongful death lawsuit that will cost it hundreds of millions of dollars, it described the new mode as being able to drive “through traffic at an incredible pace, all while still being super smooth. It drives your car like a sports car. If you are running late, this is the mode for you.”Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2078835132-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2078835132-1152x648.jpg",
      "popularity_score": 348.3271961111111,
      "ai_summary": [
        "Tesla's \"Mad Max\" mode is under federal scrutiny.",
        "The new mode was added in a recent update.",
        "The mode allows for speeding and weaving through traffic.",
        "The focus is on safety concerns.",
        "The federal government is investigating the feature."
      ]
    },
    {
      "id": "cluster_26",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 16:30:12 +0000",
      "title": "Rivian is settling $250 million lawsuit to focus on next year’s R2 EV",
      "neutral_headline": "Rivian settles $250 million lawsuit",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/rivian-settles-shareholder-lawsuit-for-250-million-denies-allegations/",
          "published_at": "Fri, 24 Oct 2025 16:30:12 +0000",
          "title": "Rivian is settling $250 million lawsuit to focus on next year’s R2 EV",
          "standfirst": "Investors sued Rivian claiming it knew prices had to rise after its IPO.",
          "content": "Electric vehicle startup Rivian announced on Thursday that it has settled a lawsuit with some of its investors. The company continues to deny allegations of making “materially untrue” statements during its inial public offering but says it agreed to pay $250 million to clear itself of distractions as it focuses on building its next EV, the mass-market R2, which is due next year. Rivian was first sued by a shareholder in 2022 over claims that the startup knew it would cost far more for it to build each R1T electric truck and R1S electric SUV than the advertised $67,500 and $70,000 prices, respectively. A big surprise price increase would tarnish the nascent automaker’s reputation, the lawsuit claimed, and could lead to many of the almost 56,000 pre-orders being canceled. Just a few months after its November 2021 IPO, the company had indeed issued a hefty price hike: $79,500 for the R1T and $84,500 for the R1S SUV. After an outcry, the company said it would honor the original price for its existing preorders. By that point, though, the damage was done, and more than a third of the company’s value was erased within a few days, the lawsuit alleged.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/05/rivian-assembly-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/05/rivian-assembly-1152x648.jpg",
      "popularity_score": 336.2388627777778,
      "ai_summary": [
        "Rivian is settling a $250 million lawsuit.",
        "The lawsuit focused on rising prices after the IPO.",
        "Investors claimed Rivian knew prices would increase.",
        "The settlement allows Rivian to focus on the R2 EV.",
        "The focus is on the company's future."
      ]
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 16:16:55 +0000",
      "title": "Bats eat the birds they pluck from the sky while on the wing",
      "neutral_headline": "Bats eat the birds they pluck from the sky while on the wing",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/tracking-bats-as-they-hunt-birds-in-the-skies-above-europe/",
          "published_at": "Fri, 24 Oct 2025 16:16:55 +0000",
          "title": "Bats eat the birds they pluck from the sky while on the wing",
          "standfirst": "A handful of bat species hunt birds, and new sensor data tells us how.",
          "content": "There are three species of bats that eat birds. We know that because we have found feathers and other avian remains in their feces. What we didn’t know was how exactly they hunt birds, which are quite a bit heavier, faster, and stronger than the insects bats usually dine on. To find out, Elena Tena, a biologist at Doñana Biological Station in Seville, Spain, and her colleagues attached ultra-light sensors to Nyctalus Iasiopterus, the largest bats in Europe. What they found was jaw-droppingly brutal. Inconspicuous interceptors Nyctalus Iasiopterus, otherwise known as greater noctule bats, have a wingspan of about 45 centimeters. They have reddish-brown or chestnut fur with a slightly paler underside, and usually weigh around 40 to 60 grams. Despite that minimal weight, they are the largest of the three bat species known to eat birds, so the key challenge in getting a glimpse into the way they hunt was finding sensors light enough to not impede the bats’ flight.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/image-4-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/image-4-1152x648.jpeg",
      "popularity_score": 320.0174738888889,
      "ai_summary": [
        "Some bat species hunt birds.",
        "Bats catch birds while in flight.",
        "New sensor data provides insights.",
        "The article focuses on bat behavior.",
        "The research reveals hunting strategies."
      ]
    },
    {
      "id": "cluster_45",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 15:24:52 +0000",
      "title": "DNA analysis reveals likely pathogens that killed Napoleon’s army",
      "neutral_headline": "DNA Analysis Identifies Pathogens Affecting Napoleon's Army",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/dna-analysis-reveals-likely-pathogens-that-killed-napoleons-army/",
          "published_at": "Fri, 24 Oct 2025 15:24:52 +0000",
          "title": "DNA analysis reveals likely pathogens that killed Napoleon’s army",
          "standfirst": "Microbial DNA suggests troops suffered from paratyphoid fever and relapsing fever, among other diseases.",
          "content": "In 1812, Napoleon Bonaparte led a disastrous military campaign into Moscow. The death toll was devastating: Out of some 615,000 men, only about 110,000 survivors returned. (Napoleon abandoned his army in early December to return home on a sled.) Roughly 100,000 of the casualties died in battle, while as many as 300,000 perished from a combination of the bitter cold of Russia’s notoriously harsh winter, starvation, and disease. Scholars have debated precisely what kinds of diseases ravaged Napoleon’s troops. New DNA analysis of some soldiers’ remains has revealed the presence of two pathogens in particular, according to a new paper published in the journal Current Biology. The first is Salmonella enterica, which causes paratyphoid fever; the second is Borrelia recurrentis, which is transmitted by body lice and causes relapsing fever. (A preprint of the paper appeared on bioaRxiv in July.) “It’s very exciting to use a technology we have today to detect and diagnose something that was buried for 200 years,” said co-author Nicolás Rascovan of the Institut Pasteur. “Accessing the genomic data of the pathogens that circulated in historical populations helps us to understand how infectious diseases evolved, spread, and disappeared over time and to identify the social or environmental contexts that played a part in these developments. This information provides us with valuable insights to better understand and tackle infectious diseases today.”Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/napoleon2-1152x648-1760798560.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/napoleon2-1152x648-1760798560.jpg",
      "popularity_score": 315.1499738888889,
      "ai_summary": [
        "Microbial DNA analysis revealed paratyphoid fever and relapsing fever infections.",
        "These diseases likely contributed to significant mortality among Napoleon's troops.",
        "The study examined remains from soldiers who died during military campaigns.",
        "Researchers identified other potential pathogens present in the samples.",
        "The findings offer insights into historical disease outbreaks and their impact."
      ]
    },
    {
      "id": "cluster_59",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 14:18:13 +0000",
      "title": "Satellite shows what’s really happening at the East Wing of the White House",
      "neutral_headline": "Satellite Imagery Shows White House East Wing Changes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/satellite-shows-whats-really-happening-at-the-east-wing-of-the-white-house/",
          "published_at": "Fri, 24 Oct 2025 14:18:13 +0000",
          "title": "Satellite shows what’s really happening at the East Wing of the White House",
          "standfirst": "\"Now it looks like the White House is physically being destroyed.\"",
          "content": "You need to go up—way up—to fully appreciate the changes underway at the White House this week. Demolition crews starting tearing down the East Wing of the presidential mansion Tuesday to clear room for the construction of a new $300 million, 90,000-square-foot ballroom, a recent priority of President Donald Trump. The teardown drew criticism and surprise from Democratic lawmakers, former White House staffers, and members of the public. It was, after all, just three months ago that President Donald Trump defended his ballroom plan by saying it wouldn’t affect the existing structure at the White House. “It won’t interfere with the current building,” he said in July. “It’ll be near it but not touching it—and pays total respect to the existing building, which I’m the biggest fan of.”Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2242218583-1152x648-1761262960.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2242218583-1152x648-1761262960.jpg",
      "popularity_score": 288.03914055555555,
      "ai_summary": [
        "Satellite images suggest significant physical changes at the White House East Wing.",
        "The images show what appears to be ongoing construction or demolition.",
        "Details of the changes are not yet fully understood.",
        "The nature of the observed activity remains unclear.",
        "Further investigation is needed to determine the exact nature of the changes."
      ]
    },
    {
      "id": "cluster_85",
      "coverage": 1,
      "updated_at": "Fri, 24 Oct 2025 11:00:36 +0000",
      "title": "Rocket Report: China tests Falcon 9 lookalike; NASA’s Moon rocket fully stacked",
      "neutral_headline": "China Tests Rocket; NASA Moon Rocket Fully Assembled",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/rocket-report-china-tests-falcon-9-lookalike-nasas-moon-rocket-fully-stacked/",
          "published_at": "Fri, 24 Oct 2025 11:00:36 +0000",
          "title": "Rocket Report: China tests Falcon 9 lookalike; NASA’s Moon rocket fully stacked",
          "standfirst": "A South Korean rocket startup will soon make its first attempt to reach low-Earth orbit.",
          "content": "Welcome to Edition 8.16 of the Rocket Report! The 10th anniversary of SpaceX’s first Falcon 9 rocket landing is coming up at the end of this year. We’re still waiting for a second company to bring back an orbital-class booster from space for a propulsive landing. Two companies, Jeff Bezos’ Blue Origin and China’s LandSpace, could join SpaceX’s exclusive club as soon as next month. (Bezos might claim he’s already part of the club, but there’s a distinction to be made.) Each company is in the final stages of launch preparations—Blue Origin for its second New Glenn rocket, and LandSpace for the debut flight of its Zhuque-3 rocket. Blue Origin and LandSpace will both attempt to land their first stage boosters downrange from their launch sites. They’re not exactly in a race with one another, but it will be fascinating to see how New Glenn and Zhuque-3 perform during the uphill and downhill phases of flight, and whether one or both of the new rockets stick the landing. As always, we welcome reader submissions. If you don’t want to miss an issue, please subscribe using the box below (the form will not appear on AMP-enabled versions of the site). Each report will include information on small-, medium-, and heavy-lift rockets, as well as a quick look ahead at the next three launches on the calendar. The race for space-based interceptors. The Trump administration’s announcement of the Golden Dome missile defense shield has set off a race among US companies to develop and test space weapons, some of them on their own dime, Ars reports. One of these companies is a 3-year-old startup named Apex, which announced plans to test a space-based interceptor as soon as next year. Apex’s concept will utilize one of the company’s low-cost satellite platforms outfitted with an “Orbital Magazine” containing multiple interceptors, which will be supplied by an undisclosed third-party partner. The demonstration in low-Earth orbit could launch as soon as June 2026 and will test-fire two interceptors from Apex’s Project Shadow spacecraft. The prototype interceptors could pave the way for operational space-based interceptors to shoot down ballistic missiles. (submitted by biokleen)Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/artemisiistacked-1152x648-1761259328.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/artemisiistacked-1152x648-1761259328.jpg",
      "popularity_score": 279.74552944444446,
      "ai_summary": [
        "China tested a rocket resembling the SpaceX Falcon 9 design.",
        "A South Korean startup plans its first low-Earth orbit attempt soon.",
        "NASA's Space Launch System rocket is fully assembled for its next mission.",
        "The report covers developments in space exploration and rocketry.",
        "These events highlight ongoing advancements in space technology."
      ]
    },
    {
      "id": "cluster_104",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 22:08:40 +0000",
      "title": "With new acquisition, OpenAI signals plans to integrate deeper into the OS",
      "neutral_headline": "OpenAI Plans OS Integration with New Acquisition",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/openai-acquires-the-team-that-made-apples-shortcuts/",
          "published_at": "Thu, 23 Oct 2025 22:08:40 +0000",
          "title": "With new acquisition, OpenAI signals plans to integrate deeper into the OS",
          "standfirst": "The acquired firm was working on a tool to control macOS directly with AI.",
          "content": "OpenAI has acquired Software Applications Incorporated (SAI), perhaps best known for the core team that produced what became Shortcuts on Apple platforms. More recently, the team has been working on Sky, a context-aware AI interface layer on top of macOS. The financial terms of the acquisition have not been publicly disclosed. “AI progress isn’t only about advancing intelligence—it’s about unlocking it through interfaces that understand context, adapt to your intent, and work seamlessly,” an OpenAI rep wrote in the company’s blog post about the acquisition. The post goes on to specify that OpenAI plans to “bring Sky’s deep macOS integration and product craft into ChatGPT, and all members of the team will join OpenAI.” That includes SAI co-founders Ari Weinstein (CEO), Conrad Kramer (CTO), and Kim Beverett (Product Lead)—all of whom worked together for several years at Apple after Apple acquired Weinstein and Kramer’s previous company, which produced an automation tool called Workflows, to integrate Shortcuts across Apple’s software platforms.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/openai-sky-1152x648.webp"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/openai-sky-1152x648.webp",
      "popularity_score": 268,
      "ai_summary": [
        "OpenAI acquired a firm developing a tool to control macOS with AI.",
        "The acquisition signals OpenAI's plans for deeper OS integration.",
        "The acquired company's technology allows direct AI control of macOS.",
        "This move could enhance AI's capabilities within operating systems.",
        "The integration aims to improve user interaction with AI tools."
      ]
    },
    {
      "id": "cluster_105",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 21:54:39 +0000",
      "title": "Lawsuit: Reddit caught Perplexity “red-handed” stealing data from Google results",
      "neutral_headline": "Reddit Sues Perplexity for Alleged Data Theft",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/reddit-sues-to-block-perplexity-from-scraping-google-search-results/",
          "published_at": "Thu, 23 Oct 2025 21:54:39 +0000",
          "title": "Lawsuit: Reddit caught Perplexity “red-handed” stealing data from Google results",
          "standfirst": "Scraper accused of stealing Reddit content \"shocked\" by lawsuit.",
          "content": "In a lawsuit filed on Wednesday, Reddit accused an AI search engine, Perplexity, of conspiring with several companies to illegally scrape Reddit content from Google search results, allegedly dodging anti-scraping methods that require substantial investments from both Google and Reddit. Reddit alleged that Perplexity feeds off Reddit and Google, claiming to be “the world’s first answer engine” but really doing “nothing groundbreaking.” “Its answer engine simply uses a different company’s” large language model “to parse through a massive number of Google search results to see if it can answer a user’s question based on those results,” the lawsuit said. “But Perplexity can only run its ‘answer engine’ by wrongfully accessing and scraping Reddit content appearing in Google’s own search results from Google’s own search engine.”Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2236792840-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2236792840-1024x648.jpg",
      "popularity_score": 255,
      "ai_summary": [
        "Reddit filed a lawsuit against Perplexity for allegedly stealing data.",
        "The lawsuit accuses Perplexity of scraping data from Reddit content.",
        "Reddit claims Perplexity used its content without permission.",
        "Perplexity is accused of using Reddit data in Google search results.",
        "The lawsuit highlights concerns about data scraping practices."
      ]
    },
    {
      "id": "cluster_139",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 15:04:47 +0000",
      "title": "Reports suggest Apple is already pulling back on the iPhone Air",
      "neutral_headline": "Apple Reportedly Scales Back iPhone Air Features",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/early-indicators-analyst-reports-suggest-apples-iphone-air-isnt-taking-off/",
          "published_at": "Thu, 23 Oct 2025 15:04:47 +0000",
          "title": "Reports suggest Apple is already pulling back on the iPhone Air",
          "standfirst": "New phone design compromises on camera and battery to achieve a lighter weight.",
          "content": "Apple’s iPhone Air was the company’s most interesting new iPhone this year, at least insofar as it was the one most different from previous iPhones. We came away impressed by its size and weight in our review. But early reports suggest that its novelty might not be translating into sales success. A note from analyst Ming-Chi Kuo, whose supply chain sources are often accurate about Apple’s future plans, said yesterday that demand for the iPhone Air “has fallen short of expectations” and that “both shipments and production capacity” were being scaled back to account for the lower-than-expected demand. Kuo’s note is backed up by reports from other analysts at Mizuho Securities (via MacRumors) and Nikkei Asia. Both of these reports say that demand for the iPhone 17 and 17 Pro models remains strong, indicating that this is just a problem for the iPhone Air and not a wider slowdown caused by tariffs or other external factors.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_3384-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_3384-1152x648.jpeg",
      "popularity_score": 160,
      "ai_summary": [
        "Reports indicate Apple is reducing features for the iPhone Air.",
        "The design compromises on camera and battery to reduce weight.",
        "The changes aim to make the phone lighter than previous models.",
        "The iPhone Air is expected to be a more affordable option.",
        "The adjustments reflect Apple's design and market strategies."
      ]
    },
    {
      "id": "cluster_109",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 21:20:48 +0000",
      "title": "Researchers show that training on “junk data” can lead to LLM “brain rot”",
      "neutral_headline": "Junk Data\" Training Can Cause LLM Performance Decline",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/researchers-show-that-training-on-junk-data-can-lead-to-llm-brain-rot/",
          "published_at": "Thu, 23 Oct 2025 21:20:48 +0000",
          "title": "Researchers show that training on “junk data” can lead to LLM “brain rot”",
          "standfirst": "Models trained on short, popular, and/or \"superficial\" tweets perform worse on benchmarks.",
          "content": "On the surface, it seems obvious that training an LLM with “high quality” data will lead to better performance than feeding it any old “low quality” junk you can find. Now, a group of researchers is attempting to quantify just how much this kind of low quality data can cause an LLM to experience effects akin to human “brain rot.” For a pre-print paper published this month, the researchers from Texas A&M, the University of Texas, and Purdue University drew inspiration from existing research showing how humans who consume “large volumes of trivial and unchallenging online content” can develop problems with attention, memory, and social cognition. That led them to what they’re calling the “LLM brain rot hypothesis,” summed up as the idea that “continual pre-training on junk web text induces lasting cognitive decline in LLMs.” Figuring out what counts as “junk web text” and what counts as “quality content” is far from a simple or fully objective process, of course. But the researchers used a few different metrics to tease a “junk dataset” and “control dataset” from HuggingFace’s corpus of 100 million tweets.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1908316227-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1908316227-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Researchers found training on \"junk data\" harms LLM performance.",
        "Models trained on short, popular tweets perform worse on benchmarks.",
        "The study highlights the importance of data quality in training.",
        "\"Brain rot\" refers to the decline in model performance.",
        "The findings impact how LLMs are trained and evaluated."
      ]
    },
    {
      "id": "cluster_147",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 13:58:46 +0000",
      "title": "An outcast faces a deadly alien world in Predator: Badlands trailer",
      "neutral_headline": "Predator: Badlands Trailer Features Alien World",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/an-outcast-faces-a-deadly-alien-world-in-predator-badlands-trailer/",
          "published_at": "Thu, 23 Oct 2025 13:58:46 +0000",
          "title": "An outcast faces a deadly alien world in Predator: Badlands trailer",
          "standfirst": "\"The ways of your kind are ones of violence. Either you are hunted or you become the hunter.\"",
          "content": "We’ve got a new international trailer for Predator: Badlands, the latest installment in a popular franchise that’s been around since 1987. It’s directed by Dan Trachtenberg, who is very familiar with the franchise, having also directed 2022’s highly acclaimed standalone Predator movie, Prey. In April, Twentieth Century Studios released the first teaser, which involved multiple predators fighting or threatening one another, Elle Fanning looking very strange and cool as an android, and glimpses of new monsters and the alien world the movie focuses on. And the film was featured prominently at San Diego Comic-Con this summer. But it hasn’t quite wormed its way into the cultural zeitgeist for fall releases. Perhaps this latest trailer will boost its profile. This is a standalone film in the franchise, with a particular focus on the culture of the Predator species; in fact, the same conlanger who created the Na’Vi language for James Cameron’s Avatar franchise also created a written and verbal language for the Predators. (We hear a bit of the dialogue in the new trailer.) And this time around, the primary Predator is actually the film’s protagonist rather than an adversary. Per the official premise: “Set in the future on a deadly remote planet, Predator: Badlands follows a young Predator outcast (Dimitrius Schuster-Koloamatangi) who finds an unlikely ally in Thia (Elle Fanning) as he embarks on a treacherous journey in search of the ultimate adversary.”Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bloodlands1-1152x648-1761226866.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bloodlands1-1152x648-1761226866.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "The trailer for Predator: Badlands has been released.",
        "The trailer shows an outcast facing a deadly alien world.",
        "The film features themes of violence and survival.",
        "The trailer offers a glimpse into the film's plot.",
        "The movie is part of the Predator franchise."
      ]
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 18:48:52 +0000",
      "title": "Microsoft makes Copilot “human-centered” with a ‘90s-style animated assistant",
      "neutral_headline": "Microsoft Introduces Animated Assistant \"Mico",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/microsoft-makes-copilot-human-centered-with-a-90s-style-animated-assistant/",
          "published_at": "Thu, 23 Oct 2025 18:48:52 +0000",
          "title": "Microsoft makes Copilot “human-centered” with a ‘90s-style animated assistant",
          "standfirst": "\"Mico\" literally tries to put a face on Microsoft's chatbot-turned-assistant.",
          "content": "Microsoft said earlier this month that it wanted to add better voice controls to Copilot, Windows 11’s built-in chatbot-slash-virtual assistant. As described, this new version of Copilot sounds an awful lot like another stab at Cortana, the voice assistant that Microsoft tried (and failed) to get people to use in Windows 10 in the mid-to-late 2010s. Turns out that the company isn’t done trying to reformulate and revive ideas it has already tried before. As part of a push toward what it calls “human-centered AI,” Microsoft is now putting a face on Copilot. Literally, a face: “Mico” is an “expressive, customizable, and warm” blob with a face that dynamically “listens, reacts, and even changes colors to reflect your interactions” as you interact with Copilot. (Another important adjective for Mico: “optional.”) Mico (rhymes with “pico”) recalls old digital assistants like Clippy, Microsoft Bob, and Rover, ideas that Microsoft tried in the ’90s and early 2000s before mostly abandoning them.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Mico-1-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Mico-1-1152x648.jpeg",
      "popularity_score": 145,
      "ai_summary": [
        "Microsoft is introducing a \"human-centered\" Copilot assistant.",
        "The assistant, named \"Mico,\" has a '90s-style animated appearance.",
        "Mico aims to personalize the user experience.",
        "The assistant is designed to be more engaging.",
        "This is Microsoft's attempt to enhance its chatbot."
      ]
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 20:57:36 +0000",
      "title": "Dinosaurs may have flourished right up to when the asteroid hit",
      "neutral_headline": "Dinosaurs Flourished Before Asteroid Impact",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/dinosaurs-may-have-flourished-right-up-to-when-the-asteroid-hit/",
          "published_at": "Thu, 23 Oct 2025 20:57:36 +0000",
          "title": "Dinosaurs may have flourished right up to when the asteroid hit",
          "standfirst": "Fossil beds in New Mexico show diverse species present in the late Cretaceous.",
          "content": "The end of the dinosaurs was clearly linked to an asteroid impact that brought the Cretaceous period to a close. But the details of their end have remained a matter of debate since the impact crater was discovered. There is a lot of evidence that the impact alone should have been enough to do them in. But the asteroid arrived amid major volcanic eruptions associated with previous mass extinctions. And fossils dating to just before the impact have suggested that dinosaur-dominated ecosystems had become less diverse, making them more prone to collapse. Now, a new study has revealed that fossils we already know about originated within the last few hundred thousand years before the impact that killed off all dinosaurs except birds. The results indicate that species richness wasn’t likely to be a problem—at least in the neighborhood of the impact itself. Wyoming vs. New Mexico Most of what we know about the last days of the non-avian dinosaurs comes from the Hell Creek Formation, rich fossil beds in present-day Wyoming. These not only date from within a few hundred thousand years prior to the impact, but there may be deposits that capture the immediate aftermath of the impact. Beyond this area, which reflects the ecosystem of the northern Great Plains, we have little else. It hasn’t been clear whether the diversity of species present at Hell Creek reflects what was present more globally, or if there were regional differences in ecosystemsRead full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1386002288-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1386002288-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Fossil beds in New Mexico show diverse dinosaur species.",
        "These species were present right up to the asteroid impact.",
        "The findings challenge previous assumptions about dinosaur decline.",
        "The study provides insights into the late Cretaceous period.",
        "The research supports the idea of a thriving ecosystem."
      ]
    },
    {
      "id": "cluster_117",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 19:58:52 +0000",
      "title": "An NIH director joins MAHA, gets replaced by JD Vance’s close friend",
      "neutral_headline": "An NIH director joins MAHA, gets replaced by JD Vance’s close friend",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/an-nih-director-joins-maha-gets-replaced-by-jd-vances-close-friend/",
          "published_at": "Thu, 23 Oct 2025 19:58:52 +0000",
          "title": "An NIH director joins MAHA, gets replaced by JD Vance’s close friend",
          "standfirst": "The NTP produced controversial studies on cellphone radiation and fluoride.",
          "content": "The director of a federal health institute that has arguably produced two of the most controversial government studies in recent years has accepted a new federal role to advance the goals of the Make America Healthy Again movement. Meanwhile, the person replacing him as director is a close friend of Vice President JD Vance and was installed in a process that experts describe as completely outside standard hiring practices. The series of events—revealed in an email to staff last week from the National Institutes of Health Director Jay Bhattacharya—is only exacerbating the spiraling fears that science is being deeply corrupted by politics under the Trump administration. Richard Woychik, a molecular geneticist, is the outgoing director of the NIH’s National Institute of Environmental Health Sciences (NIEHS), which is located in Research Triangle Park, North Carolina. He has been director since 2020 and was recently appointed to a second five-year term, according to Science magazine. Woychik was hired at the institute in 2010, when he joined as deputy director, and was appointed acting director in 2019.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1291108057-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1291108057-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "An NIH director joined MAHA and was subsequently replaced.",
        "The replacement is a close friend of JD Vance.",
        "The NTP produced controversial studies on cellphone radiation.",
        "The NTP also produced studies on fluoride.",
        "The changes reflect shifts in leadership and research focus."
      ]
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 17:04:16 +0000",
      "title": "The first people to set foot in Australia were fossil hunters",
      "neutral_headline": "The first people to set foot in Australia were fossil hunters",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/the-first-people-to-set-foot-in-australia-were-fossil-hunters/",
          "published_at": "Thu, 23 Oct 2025 17:04:16 +0000",
          "title": "The first people to set foot in Australia were fossil hunters",
          "standfirst": "Europeans weren't the first people to collect fossils in Australia.",
          "content": "Australia’s First Peoples may or may not have hunted the continent’s megafauna to extinction, but they definitely collected fossils. A team of archaeologists examined the fossilized leg bone of an extinct kangaroo and realized that instead of evidence of butchery, cut marks on the bone reveal an ancient attempt at fossil collecting. That leaves Australia with little evidence of First Peoples hunting or butchering the continent’s extinct megafauna—and reopens the question of whether humans were responsible for the die-off of that continent’s giant Ice Age marsupials. Fossil hunting in the Ice Age In the unsolved case of whether humans hunted Australia’s Ice Age megafauna to extinction, the key piece of evidence so far is a tibia (one of the bones of the lower leg) from an extinct short-faced kangaroo. Instead of hopping like their modern relatives, these extinct kangaroos walked on their hind legs, probably placing all their weight on the tips of single hoofed toes. This particular kangaroo wasn’t quite fully grown when it died, which happened sometime between 44,500 and 55,200 years ago, based on uranium-series dating of the thin layer of rock covering most of the fossils in Mammoth Cave (in what’s now Western Australia).Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rsosSimosthenurus_occidentalis-1152x648-1761239043.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rsosSimosthenurus_occidentalis-1152x648-1761239043.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Europeans were not the first to collect fossils in Australia.",
        "The first people to collect fossils were indigenous Australians.",
        "This discovery changes the historical narrative.",
        "The findings highlight the importance of indigenous knowledge.",
        "The research focuses on the history of fossil collection."
      ]
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 16:40:22 +0000",
      "title": "CS2 item market loses nearly $2B in value overnight due to “trade up” update",
      "neutral_headline": "CS2 item market loses nearly $2B in value overnight due to “trade up” update",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/10/valve-upends-the-cs2-item-marketplace-with-new-trade-up-update/",
          "published_at": "Thu, 23 Oct 2025 16:40:22 +0000",
          "title": "CS2 item market loses nearly $2B in value overnight due to “trade up” update",
          "standfirst": "Once rare $14K knife now sells for $7K, some common guns jump from $10 to over $100.",
          "content": "From the outside, Counter-Strike 2 looks a lot like a game that’s primarily about shooting people. For millions of players, though, the game is more about collecting and/or buying rare in-game loot and flipping it for what can be very significant sums on the Steam Marketplace. Wednesday night, Valve sent that multi-billion-dollar market into turmoil as part of a so-called “small update.” Now, players can use the game’s “Trade Up contracts” to exchange five common, “Covert” items (also known as “reds”) for the kinds of knives and gloves that have until now been much harder to obtain. That “small update” has unsurprisingly had an immediate and sharp impact on the Marketplace price for those items. One rare knife that sold for over $14,000 less than 24 hours ago has seen its minimum price plummet over 50 percent as of this writing, according to the trackers at Pricempire. Meanwhile, the median sale price for a common P90 Asimov gun on the Steam Marketplace shot up from $10 on Wednesday to well over $100 as of this writing.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/cs2knife-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/cs2knife-1152x648.png",
      "popularity_score": 133,
      "ai_summary": [
        "The CS2 item market lost nearly $2 billion in value.",
        "This loss was due to a \"trade up\" update.",
        "A rare knife's value dropped from $14,000 to $7,000.",
        "Some common guns increased in price from $10 to over $100.",
        "The update significantly impacted the in-game economy."
      ]
    },
    {
      "id": "cluster_134",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 16:25:00 +0000",
      "title": "Great hybrid V6, lousy HMI: Three days with a Ferrari 296 GTB",
      "neutral_headline": "Great hybrid V6, lousy HMI: Three days with a Ferrari 296 GTB",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/great-hybrid-v6-lousy-hmi-three-days-with-a-ferrari-296-gtb/",
          "published_at": "Thu, 23 Oct 2025 16:25:00 +0000",
          "title": "Great hybrid V6, lousy HMI: Three days with a Ferrari 296 GTB",
          "standfirst": "Three days with a car revealed its character in more ways than one.",
          "content": "Ferrari provided flights from Washington, DC, to Austin, Texas, and accommodation so Ars could attend the Lone Star Le Mans. Ars does not accept paid editorial content. The first time I drove this generation of mid-engined Ferrari, it was on a curated route on the company’s home turf. As the Po Valley gives way to the Apennines, you find plenty of narrow winding roads, steep gradients, and hairpin turns. It was an engaging few hours of driving, but it was too brief to properly assess some of the 296’s technology. I found the ride firm but comfortable on rough Italian tarmac and the hybrid system easy to operate, flicking into calm-and-quiet electric-only mode through the villages I encountered. That was back in 2022 during the unveiling of Ferrari’s 499P race car. Last month, I met the 499P again as it visited the Circuit of the Americas in Austin, along with the rest of the World Endurance Championship. And that afforded another chance to get to know the 296, with three days rather than three hours to form an impression. Head west from Austin and you’ll find twisty roads that wrap around the hills. It would have been easy to spend an entire day out there, but that seemed repetitive—I’d experienced the 296’s back road behavior already. Plus, there were things to do at the racetrack, although I’ll admit I took the long way there and back each day.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2025-Ferrari-296-GTB-1-of-12-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2025-Ferrari-296-GTB-1-of-12-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "The review focuses on a Ferrari 296 GTB.",
        "The car has a great hybrid V6 engine.",
        "The car's HMI (Human-Machine Interface) is considered lousy.",
        "The review covers the car's performance and features.",
        "The review provides an assessment of the car's overall character."
      ]
    },
    {
      "id": "cluster_138",
      "coverage": 1,
      "updated_at": "Thu, 23 Oct 2025 15:33:04 +0000",
      "title": "Trump eyes government control of quantum computing firms with Intel-like deals",
      "neutral_headline": "Trump eyes government control of quantum computing firms with Intel-like deals",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trumps-industry-meddling-may-give-us-a-stake-in-quantum-computing-firms/",
          "published_at": "Thu, 23 Oct 2025 15:33:04 +0000",
          "title": "Trump eyes government control of quantum computing firms with Intel-like deals",
          "standfirst": "Some quantum computing firms seem optimistic about Trump's proposed deals.",
          "content": "Donald Trump is eyeing taking equity stakes in quantum computing firms in exchange for federal funding, The Wall Street Journal reported. At least five companies are weighing whether allowing the government to become a shareholder would be worth it to snag funding that the Trump administration has “earmarked for promising technology companies,” sources familiar with the potential deals told the WSJ. IonQ, Rigetti Computing, and D-Wave Quantum are currently in talks with the government over potential funding agreements, with minimum awards of $10 million each, some sources said. Quantum Computing Inc. and Atom Computing are reportedly “considering similar arrangements,” as are other companies in the sector, which is viewed as critical for scientific advancements and next-generation technologies.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2229574852-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2229574852-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Trump is considering government control of quantum computing firms.",
        "The proposed deals are similar to those with Intel.",
        "Some quantum computing firms are optimistic about the deals.",
        "The proposal could impact the quantum computing industry.",
        "The plan involves government intervention in the sector."
      ]
    }
  ]
}