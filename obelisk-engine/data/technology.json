{
  "updated_at": "2025-10-13T19:14:35.054Z",
  "clusters": [
    {
      "id": "cluster_18",
      "coverage": 3,
      "updated_at": "2025-10-13T13:12:12-04:00",
      "title": "New California law requires AI to tell you it’s AI",
      "neutral_headline": "California law requires AI to tell you it’s AI",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/798875/california-just-passed-a-new-law-requiring-ai-to-tell-you-its-ai",
          "published_at": "2025-10-13T13:12:12-04:00",
          "title": "New California law requires AI to tell you it’s AI",
          "standfirst": "A bill attempting to regulate the ever-growing industry of companion AI chatbots is now law in California, as of October 13th. California Gov. Gavin Newsom signed into law Senate Bill 243, billed as “first-in-the-nation AI chatbot safeguards” by state senator Anthony Padilla. The new law requires that companion chatbot developers implement new safeguards —&#160;for instance, [&#8230;]",
          "content": "A bill attempting to regulate the ever-growing industry of companion AI chatbots is now law in California, as of October 13th. California Gov. Gavin Newsom signed into law Senate Bill 243, billed as “first-in-the-nation AI chatbot safeguards” by state senator Anthony Padilla. The new law requires that companion chatbot developers implement new safeguards — for instance, “if a reasonable person interacting with a companion chatbot would be misled to believe that the person is interacting with a human,” then the new law requires the chatbot maker to “issue a clear and conspicuous notification” that the product is strictly AI and not human. Starting next year, the legislation would require some companion chatbot operators to make annual reports to the Office of Suicide Prevention about safeguards they’ve put in place “to detect, remove, and respond to instances of suicidal ideation by users,” and the Office would need to post such data on its website. “Emerging technology like chatbots and social media can inspire, educate, and connect – but without real guardrails, technology can also exploit, mislead, and endanger our kids,” Newsom said in a statement on signing the bill, along with several other pieces of legislation aimed at improving online safety for children, including new age-gating requirements for hardware. “We can continue to lead in AI and technology, but we must do it responsibly — protecting our children every step of the way. Our children’s safety is not for sale.” The news comes after Governor Newsom officially signed Senate Bill 53, the landmark AI transparency bill that divided AI companies and made headlines for months, into law in California.",
          "feed_position": 1
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251013/p24#a251013p24",
          "published_at": "Mon, 13 Oct 2025 11:15:00 -0400",
          "title": "California Governor Gavin Newsom signs SB 243, which mandates safety protocols for AI chatbot companions, the first US state law to regulate such AI chatbots (Rebecca Bellan/TechCrunch)",
          "standfirst": "Rebecca Bellan / TechCrunch: California Governor Gavin Newsom signs SB 243, which mandates safety protocols for AI chatbot companions, the first US state law to regulate such AI chatbots &mdash; California Governor Gavin Newsom signed a landmark bill on Monday that regulates AI companion chatbots, making it the first state &hellip;",
          "content": "Rebecca Bellan / TechCrunch: California Governor Gavin Newsom signs SB 243, which mandates safety protocols for AI chatbot companions, the first US state law to regulate such AI chatbots &mdash; California Governor Gavin Newsom signed a landmark bill on Monday that regulates AI companion chatbots, making it the first state &hellip;",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/251013/i24.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/13/california-becomes-first-state-to-regulate-ai-companion-chatbots/",
          "published_at": "Mon, 13 Oct 2025 14:50:53 +0000",
          "title": "California becomes first state to regulate AI companion chatbots",
          "standfirst": "SB 243 is designed to protect children and vulnerable users from harms associated with use of AI companion chatbots.",
          "content": "SB 243 is designed to protect children and vulnerable users from harms associated with use of AI companion chatbots.",
          "feed_position": 1
        }
      ],
      "featured_image": "http://www.techmeme.com/251013/i24.jpg",
      "popularity_score": 3017.9602627777776,
      "ai_summary": [
        "California Governor Newsom signed SB 243 into law.",
        "The law mandates safety protocols for AI chatbots.",
        "It is the first US state law to regulate such AI.",
        "The law aims to protect children and vulnerable users.",
        "The law requires AI to disclose its identity."
      ]
    },
    {
      "id": "cluster_24",
      "coverage": 2,
      "updated_at": "2025-10-13T12:38:44-04:00",
      "title": "Apple TV Plus is being rebranded to… Apple TV",
      "neutral_headline": "Apple says that its Apple TV+ streaming service has been renamed Apple TV, \"with a vibrant new identity",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/798857/apple-tv-plus-rebrand-streaming-service",
          "published_at": "2025-10-13T12:38:44-04:00",
          "title": "Apple TV Plus is being rebranded to… Apple TV",
          "standfirst": "The Apple TV Plus streaming service is being rebranded with a “vibrant new identity,” according to the Cupertino company, and is “now simply Apple TV.” The announcement was briefly mentioned at the bottom of Apple’s latest press release regarding the December 12th streaming debut of F1 The Movie. At the time of writing, no changes [&#8230;]",
          "content": "The plus symbol in the current logo is still present across Apple’s website. The Apple TV Plus streaming service is being rebranded with a “vibrant new identity,” according to the Cupertino company, and is “now simply Apple TV.” The announcement was briefly mentioned at the bottom of Apple’s latest press release regarding the December 12th streaming debut of F1 The Movie. At the time of writing, no changes have been made to the current Apple TV Plus branding across Apple’s website or press portal. The change is likely to cause some confusion, given that the new name is already used by the Apple TV app that allows users to buy or rent movies, and hardware like the Apple TV 4K. Even the wording on Apple’s own announcement highlights the muddled branding, saying that F1 is available to purchase on Apple TV “ahead of its global streaming debut on Apple TV,” and that “Apple TV is available on the Apple TV app” on devices like… you got it, Apple TV. Apple hasn’t shared any other details about the new branding for its streaming service, so it&#8217;s unclear if it will be introducing an updated logo, or finding other ways to distinguish it from existing products. We’ve asked Apple if any changes will be made to the Apple TV app and Apple TV hardware, and will update if we hear back.",
          "feed_position": 3
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251013/p26#a251013p26",
          "published_at": "Mon, 13 Oct 2025 11:40:00 -0400",
          "title": "Apple says that its Apple TV+ streaming service has been renamed Apple TV, \"with a vibrant new identity\" (Eric Slivka/MacRumors)",
          "standfirst": "Eric Slivka / MacRumors: Apple says that its Apple TV+ streaming service has been renamed Apple TV, &ldquo;with a vibrant new identity&rdquo; &mdash; Buried in its announcement about &ldquo;F1: The Movie&rdquo; making its streaming debut on December 12, Apple has also announced that Apple TV+ is being rebranded as simply Apple TV.",
          "content": "Eric Slivka / MacRumors: Apple says that its Apple TV+ streaming service has been renamed Apple TV, &ldquo;with a vibrant new identity&rdquo; &mdash; Buried in its announcement about &ldquo;F1: The Movie&rdquo; making its streaming debut on December 12, Apple has also announced that Apple TV+ is being rebranded as simply Apple TV.",
          "feed_position": 6,
          "image_url": "http://www.techmeme.com/251013/i26.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251013/i26.jpg",
      "popularity_score": 2017.402485,
      "ai_summary": [
        "Apple TV+ is being rebranded as simply Apple TV.",
        "The change is mentioned in a press release.",
        "The press release concerns the debut of F1 The Movie.",
        "The rebranding includes a \"vibrant new identity\".",
        "The change was announced by Apple."
      ]
    },
    {
      "id": "cluster_46",
      "coverage": 2,
      "updated_at": "Mon, 13 Oct 2025 14:25:30 +0000",
      "title": "Windows 10 support ends tomorrow, but here's how to get an extra year for free",
      "neutral_headline": "Windows 10 support ends tomorrow, but here's how to get an extra year for free",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/windows-10-support-ends-tomorrow-but-heres-how-to-get-an-extra-year-for-free-125118505.html",
          "published_at": "Mon, 13 Oct 2025 14:25:30 +0000",
          "title": "Windows 10 support ends tomorrow, but here's how to get an extra year for free",
          "standfirst": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) Are you still running Windows 10 on your PC? Starting tomorrow, October 14, Microsoft is moving the software to \"end of life\" status. What does that mean for you? While Windows 10 PCs will continue to work after that date, they'll stop getting important security updates by default. That leaves you with three choices if you want to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. The last one is easy — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to be using your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/windows-10-support-ends-tomorrow-but-heres-how-to-get-an-extra-year-for-free-125118505.html?src=rss",
          "content": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) Are you still running Windows 10 on your PC? Starting tomorrow, October 14, Microsoft is moving the software to \"end of life\" status. What does that mean for you? While Windows 10 PCs will continue to work after that date, they'll stop getting important security updates by default. That leaves you with three choices if you want to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. The last one is easy — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to be using your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/windows-10-support-ends-tomorrow-but-heres-how-to-get-an-extra-year-for-free-125118505.html?src=rss",
          "feed_position": 5,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c836b6e0-a60d-11f0-aff0-71a091f199fd"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/this-new-ai-technique-creates-digital-twin-consumers-and-it-could-kill-the",
          "published_at": "Mon, 13 Oct 2025 13:00:00 GMT",
          "title": "This new AI technique creates ‘digital twin’ consumers, and it could kill the traditional survey industry",
          "standfirst": "A new research paper quietly published last week outlines a breakthrough method that allows large language models (LLMs) to simulate human consumer behavior with startling accuracy, a development that could reshape the multi-billion-dollar market research industry. The technique promises to create armies of synthetic consumers who can provide not just realistic product ratings, but also the qualitative reasoning behind them, at a scale and speed currently unattainable.For years, companies have sought to use AI for market research, but have been stymied by a fundamental flaw: when asked to provide a numerical rating on a scale of 1 to 5, LLMs produce unrealistic and poorly distributed responses. A new paper, \"LLMs Reproduce Human Purchase Intent via Semantic Similarity Elicitation of Likert Ratings,\" submitted to the pre-print server arXiv on October 9th proposes an elegant solution that sidesteps this problem entirely.The international team of researchers, led by Benjamin F. Maier, developed a method they call semantic similarity rating (SSR). Instead of asking an LLM for a number, SSR prompts the model for a rich, textual opinion on a product. This text is then converted into a numerical vector — an \"embedding\" — and its similarity is measured against a set of pre-defined reference statements. For example, a response of \"I would absolutely buy this, it&#x27;s exactly what I&#x27;m looking for\" would be semantically closer to the reference statement for a \"5\" rating than to the statement for a \"1.\"The results are striking. Tested against a massive real-world dataset from a leading personal care corporation — comprising 57 product surveys and 9,300 human responses — the SSR method achieved 90% of human test-retest reliability. Crucially, the distribution of AI-generated ratings was statistically almost indistinguishable from the human panel. The authors state, \"This framework enables scalable consumer research simulations while preserving traditional survey metrics and interpretability.\"A timely solution as AI threatens survey integrityThis development arrives at a critical time, as the integrity of traditional online survey panels is increasingly under threat from AI. A 2024 analysis from the Stanford Graduate School of Business highlighted a growing problem of human survey-takers using chatbots to generate their answers. These AI-generated responses were found to be \"suspiciously nice,\" overly verbose, and lacking the \"snark\" and authenticity of genuine human feedback, leading to what researchers called a \"homogenization\" of data that could mask serious issues like discrimination or product flaws.Maier&#x27;s research offers a starkly different approach: instead of fighting to purge contaminated data, it creates a controlled environment for generating high-fidelity synthetic data from the ground up.\"What we&#x27;re seeing is a pivot from defense to offense,\" said one analyst not affiliated with the study. \"The Stanford paper showed the chaos of uncontrolled AI polluting human datasets. This new paper shows the order and utility of controlled AI creating its own datasets. For a Chief Data Officer, this is the difference between cleaning a contaminated well and tapping into a fresh spring.\"From text to intent: The technical leap behind the synthetic consumerThe technical validity of the new method hinges on the quality of the text embeddings, a concept explored in a 2022 paper in EPJ Data Science. That research argued for a rigorous \"construct validity\" framework to ensure that text embeddings — the numerical representations of text — truly \"measure what they are supposed to.\" The success of the SSR method suggests its embeddings effectively capture the nuances of purchase intent. For this new technique to be widely adopted, enterprises will need to be confident that the underlying models are not just generating plausible text, but are mapping that text to scores in a way that is robust and meaningful.The approach also represents a significant leap from prior research, which has largely focused on using text embeddings to analyze and predict ratings from existing online reviews. A 2022 study, for example, evaluated the performance of models like BERT and word2vec in predicting review scores on retail sites, finding that newer models like BERT performed better for general use. The new research moves beyond analyzing existing data to generating novel, predictive insights before a product even hits the market.The dawn of the digital focus groupFor technical decision-makers, the implications are profound. The ability to spin up a \"digital twin\" of a target consumer segment and test product concepts, ad copy, or packaging variations in a matter of hours could drastically accelerate innovation cycles. As the paper notes, these synthetic respondents also provide \"rich qualitative feedback explaining their ratings,\" offering a treasure trove of data for product development that is both scalable and interpretable. While the era of human-only focus groups is far from over, this research provides the most compelling evidence yet that their synthetic counterparts are ready for business.But the business case extends beyond speed and scale. Consider the economics: a traditional survey panel for a national product launch might cost tens of thousands of dollars and take weeks to field. An SSR-based simulation could deliver comparable insights in a fraction of the time, at a fraction of the cost, and with the ability to iterate instantly based on findings. For companies in fast-moving consumer goods categories — where the window between concept and shelf can determine market leadership — this velocity advantage could be decisive.There are, of course, caveats. The method was validated on personal care products; its performance on complex B2B purchasing decisions, luxury goods, or culturally specific products remains unproven. And while the paper demonstrates that SSR can replicate aggregate human behavior, it does not claim to predict individual consumer choices. The technique works at the population level, not the person level — a distinction that matters greatly for applications like personalized marketing.Yet even with these limitations, the research is a watershed. While the era of human-only focus groups is far from over, this paper provides the most compelling evidence yet that their synthetic counterparts are ready for business. The question is no longer whether AI can simulate consumer sentiment, but whether enterprises can move fast enough to capitalize on it before their competitors do.",
          "content": "A new research paper quietly published last week outlines a breakthrough method that allows large language models (LLMs) to simulate human consumer behavior with startling accuracy, a development that could reshape the multi-billion-dollar market research industry. The technique promises to create armies of synthetic consumers who can provide not just realistic product ratings, but also the qualitative reasoning behind them, at a scale and speed currently unattainable.For years, companies have sought to use AI for market research, but have been stymied by a fundamental flaw: when asked to provide a numerical rating on a scale of 1 to 5, LLMs produce unrealistic and poorly distributed responses. A new paper, \"LLMs Reproduce Human Purchase Intent via Semantic Similarity Elicitation of Likert Ratings,\" submitted to the pre-print server arXiv on October 9th proposes an elegant solution that sidesteps this problem entirely.The international team of researchers, led by Benjamin F. Maier, developed a method they call semantic similarity rating (SSR). Instead of asking an LLM for a number, SSR prompts the model for a rich, textual opinion on a product. This text is then converted into a numerical vector — an \"embedding\" — and its similarity is measured against a set of pre-defined reference statements. For example, a response of \"I would absolutely buy this, it&#x27;s exactly what I&#x27;m looking for\" would be semantically closer to the reference statement for a \"5\" rating than to the statement for a \"1.\"The results are striking. Tested against a massive real-world dataset from a leading personal care corporation — comprising 57 product surveys and 9,300 human responses — the SSR method achieved 90% of human test-retest reliability. Crucially, the distribution of AI-generated ratings was statistically almost indistinguishable from the human panel. The authors state, \"This framework enables scalable consumer research simulations while preserving traditional survey metrics and interpretability.\"A timely solution as AI threatens survey integrityThis development arrives at a critical time, as the integrity of traditional online survey panels is increasingly under threat from AI. A 2024 analysis from the Stanford Graduate School of Business highlighted a growing problem of human survey-takers using chatbots to generate their answers. These AI-generated responses were found to be \"suspiciously nice,\" overly verbose, and lacking the \"snark\" and authenticity of genuine human feedback, leading to what researchers called a \"homogenization\" of data that could mask serious issues like discrimination or product flaws.Maier&#x27;s research offers a starkly different approach: instead of fighting to purge contaminated data, it creates a controlled environment for generating high-fidelity synthetic data from the ground up.\"What we&#x27;re seeing is a pivot from defense to offense,\" said one analyst not affiliated with the study. \"The Stanford paper showed the chaos of uncontrolled AI polluting human datasets. This new paper shows the order and utility of controlled AI creating its own datasets. For a Chief Data Officer, this is the difference between cleaning a contaminated well and tapping into a fresh spring.\"From text to intent: The technical leap behind the synthetic consumerThe technical validity of the new method hinges on the quality of the text embeddings, a concept explored in a 2022 paper in EPJ Data Science. That research argued for a rigorous \"construct validity\" framework to ensure that text embeddings — the numerical representations of text — truly \"measure what they are supposed to.\" The success of the SSR method suggests its embeddings effectively capture the nuances of purchase intent. For this new technique to be widely adopted, enterprises will need to be confident that the underlying models are not just generating plausible text, but are mapping that text to scores in a way that is robust and meaningful.The approach also represents a significant leap from prior research, which has largely focused on using text embeddings to analyze and predict ratings from existing online reviews. A 2022 study, for example, evaluated the performance of models like BERT and word2vec in predicting review scores on retail sites, finding that newer models like BERT performed better for general use. The new research moves beyond analyzing existing data to generating novel, predictive insights before a product even hits the market.The dawn of the digital focus groupFor technical decision-makers, the implications are profound. The ability to spin up a \"digital twin\" of a target consumer segment and test product concepts, ad copy, or packaging variations in a matter of hours could drastically accelerate innovation cycles. As the paper notes, these synthetic respondents also provide \"rich qualitative feedback explaining their ratings,\" offering a treasure trove of data for product development that is both scalable and interpretable. While the era of human-only focus groups is far from over, this research provides the most compelling evidence yet that their synthetic counterparts are ready for business.But the business case extends beyond speed and scale. Consider the economics: a traditional survey panel for a national product launch might cost tens of thousands of dollars and take weeks to field. An SSR-based simulation could deliver comparable insights in a fraction of the time, at a fraction of the cost, and with the ability to iterate instantly based on findings. For companies in fast-moving consumer goods categories — where the window between concept and shelf can determine market leadership — this velocity advantage could be decisive.There are, of course, caveats. The method was validated on personal care products; its performance on complex B2B purchasing decisions, luxury goods, or culturally specific products remains unproven. And while the paper demonstrates that SSR can replicate aggregate human behavior, it does not claim to predict individual consumer choices. The technique works at the population level, not the person level — a distinction that matters greatly for applications like personalized marketing.Yet even with these limitations, the research is a watershed. While the era of human-only focus groups is far from over, this paper provides the most compelling evidence yet that their synthetic counterparts are ready for business. The question is no longer whether AI can simulate consumer sentiment, but whether enterprises can move fast enough to capitalize on it before their competitors do.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/51ORdJ4l6mg6ZSTkJpGFOw/85fa4483c879359d1872778236f4fc20/nuneybits_Vector_art_of_AI_shopper_silhouette_e82a806b-f70d-4b1d-9418-71b2ffd65ea4.webp"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/salesforce-bets-on-ai-agents-to-fix-what-it-calls-a-usd7-billion-problem-in",
          "published_at": "Mon, 13 Oct 2025 12:00:00 GMT",
          "title": "Salesforce bets on AI 'agents' to fix what it calls a $7 billion problem in enterprise software",
          "standfirst": "As 50,000 attendees descend on Salesforce&#x27;s Dreamforce conference this week, the enterprise software giant is making its most aggressive bet yet on artificial intelligence agents, positioning itself as the antidote to what it calls an industry-wide \"pilot purgatory\" where 95% of enterprise AI projects never reach production.The company on Monday launched Agentforce 360, a sweeping reimagination of its entire product portfolio designed to transform businesses into what it calls \"agentic enterprises\" — organizations where AI agents work alongside humans to handle up to 40% of work across sales, service, marketing, and operations.\"We are truly in the agentic AI era, and I think it&#x27;s probably the biggest revolution, the biggest transition in technology I&#x27;ve ever experienced in my career,\" said Parker Harris, Salesforce&#x27;s co-founder and chief technology officer, during a recent press briefing. \"In the future, 40% of the work in the Fortune 1000 is probably going to be done by AI, and it&#x27;s going to be humans and AI actually working together.\"The announcement comes at a pivotal moment for Salesforce, which has deployed more than 12,000 AI agent implementations over the past year while building what Harris called a \"$7 billion business\" around its AI platform. Yet the launch also arrives amid unusual turbulence, as CEO Marc Benioff faces fierce backlash for recent comments supporting President Trump and suggesting National Guard troops should patrol San Francisco streets.Why 95% of enterprise AI projects never launchThe stakes are enormous. While companies have rushed to experiment with AI following ChatGPT&#x27;s emergence two years ago, most enterprise deployments have stalled before reaching production, according to recent MIT research that Salesforce executives cited extensively.\"Customers have invested a lot in AI, but they&#x27;re not getting the value,\" said Srini Tallapragada, Salesforce&#x27;s president and chief engineering and customer success officer. \"95% of enterprise AI pilots fail before production. It&#x27;s not because of lack of intent. People want to do this. Everybody understands the power of the technology. But why is it so hard?\"The answer, according to Tallapragada, is that AI tools remain disconnected from enterprise workflows, data, and governance systems. \"You&#x27;re writing prompts, prompts, you&#x27;re getting frustrated because the context is not there,\" he said, describing what he called a \"prompt doom loop.\"Salesforce&#x27;s solution is a deeply integrated platform connecting what it calls four ingredients: the Agentforce 360 agent platform, Data 360 for unified data access, Customer 360 apps containing business logic, and Slack as the \"conversational interface\" where humans and agents collaborate.Slack becomes the front door to SalesforcePerhaps the most significant strategic shift is the elevation of Slack — acquired by Salesforce in 2019 for $27.7 billion — as the primary interface for Salesforce itself. The company is effectively reimagining its traditional Lightning interface around Slack channels, where sales deals, service cases, and data insights will surface conversationally rather than through forms and dashboards.\"Imagine that you maybe don&#x27;t log into Salesforce, you don&#x27;t see Salesforce, but it&#x27;s there. It&#x27;s coming to you in Slack, because that&#x27;s where you&#x27;re getting your work done,\" Harris explained.The strategy includes embedding Salesforce&#x27;s Agentforce agents for sales, IT service, HR service, and analytics directly into Slack, alongside a completely rebuilt Slackbot that acts as a personal AI companion. The company is also launching \"Channel Expert,\" an always-on agent that provides instant answers from channel conversations.To enable third-party AI tools to access Slack&#x27;s conversational data, Salesforce is releasing a Real-Time Search API and Model Context Protocol server. Partners including OpenAI, Anthropic, Google, Perplexity, Writer, Dropbox, Notion, and Cursor are building agents that will live natively in Slack.\"The best way to see the power of the platform is through the AI apps and agents already being built,\" Rob Seaman, a Salesforce executive, said during a technical briefing, citing examples of startups \"achieving tens of thousands of customers that have it installed in 120 days or less.\"Voice and IT service take aim at new marketsBeyond Slack integration, Salesforce announced major expansions into voice-based interactions and employee service. Agentforce Voice, now generally available, transforms traditional IVR systems into natural conversations that can update CRM records, trigger workflows, and seamlessly hand off to human agents.The IT Service offering represents Salesforce&#x27;s most direct challenge to ServiceNow, the market leader. Mudhu Sudhakar, who joined Salesforce two months ago as senior vice president for IT and HR Service, positioned the product as a fundamental reimagining of employee support.\"Legacy IT service management is very portals, forms, tickets focused, manual process,\" Sudhakar said. \"What we had a few key tenets: conversation first and agent first, really focused on having a conversational experience for the people requesting the support and for the people providing the support.\"The IT Service platform includes what Salesforce describes as 25+ specialized agents and 100+ pre-built workflows and connectors that can handle everything from password resets to complex incident management.Early customers report dramatic efficiency gainsCustomer results suggest the approach is gaining traction. Reddit reduced average support resolution time from 8.9 minutes to 1.4 minutes — an 84% improvement — while deflecting 46% of cases entirely to AI agents. \"This efficiency has allowed us to provide on-demand help for complex tasks and boost advertiser satisfaction scores by 20%,\" said John Thompson, Reddit&#x27;s VP of sales strategy and operations, in a statement.Engine, a travel management company, reduced average handle time by 15%, saving over $2 million annually. OpenTable resolved 70% of restaurant and diner inquiries autonomously. And 1-800Accountant achieved a 90% case deflection rate during the critical tax week period.Salesforce&#x27;s own internal deployments may be most telling. Tallapragada&#x27;s customer success organization now handles 1.8 million AI-powered conversations weekly, with metrics published at help.salesforce.com showing how many agents answer versus escalating to humans.Even more significantly, Salesforce has deployed AI-powered sales development representatives to follow up on leads that would previously have gone uncontacted due to cost constraints. \"Now, Agentforce has an SDR which is doing thousands of leads following up,\" Tallapragada explained. The company also increased proactive customer outreach by 40% by shifting staff from reactive support.The trust layer problem enterprises can&#x27;t ignoreGiven enterprise concerns about AI reliability, Salesforce has invested heavily in what it calls the \"trust layer\" — audit trails, compliance checks, and observability tools that let organizations monitor agent behavior at scale.\"You should think of an agent as a human. Digital labor. You need to manage performance just like a human. And you need these audit trails,\" Tallapragada explained.The company encountered this challenge firsthand when its own agent deployment scaled. \"When we started at Agentforce at Salesforce, we would track every message, which is great until 1,000, 3,000,\" Tallapragada said. \"Once you have a million chats, there&#x27;s no human, we cannot do it.\"The platform now includes \"Agentforce Grid\" for searching across millions of conversations to identify and fix problematic patterns. The company also introduced Agent Script, a new scripting language that allows developers to define precise guardrails and deterministic controls for agent behavior.Data infrastructure gets a major upgradeUnderlying the agent capabilities is significant infrastructure investment. Salesforce&#x27;s Data 360 includes \"Intelligent Context,\" which automatically extracts structured information from unstructured content like PDFs, diagrams, and flowcharts using what the company describes as \"AI-powered unstructured data pipelines.\"The company is also collaborating with Databricks, dbt Labs, and Snowflake on the \"Universal Semantic Interchange,\" an attempt to standardize how different platforms define business metrics. The pending $8 billion acquisition of Informatica, expected to close soon, will expand metadata management capabilities across the enterprise.The competitive landscape keeps intensifyingSalesforce&#x27;s aggressive AI agent push comes as virtually every major enterprise software vendor pursues similar strategies. Microsoft has embedded Copilot across its product line, Google offers agent capabilities through Vertex AI and Gemini, and ServiceNow has launched its own agentic offerings.When asked how Salesforce&#x27;s announcement compared to OpenAI&#x27;s recent releases, Tallapragada emphasized that customers will use multiple AI tools simultaneously. \"Most of the time I&#x27;m seeing they&#x27;re using OpenAI, they&#x27;re using Gemini, they&#x27;re using Anthropic, just like Salesforce, we use all three,\" he said.The real differentiation, executives argued, lies not in the AI models but in the integration with business processes and data. Harris framed the competition in terms familiar from Salesforce&#x27;s founding: \"26 years ago, we just said, let&#x27;s make Salesforce automation as easy as buying a book on Amazon.com. We&#x27;re doing that same thing. We want to make agentic AI as easy as buying a book on Amazon.\"The company&#x27;s customer success stories are impressive but remain a small fraction of its customer base. With 150,000 Salesforce customers and one million Slack customers, the 12,000 Agentforce deployments represent roughly 8% penetration — strong for a one-year-old product line, but hardly ubiquitous.The company&#x27;s stock, down roughly 28% year to date with a Relative Strength rating of just 15, suggests investors remain skeptical. This week&#x27;s Dreamforce demonstrations — and the months of customer deployments that follow — will begin to provide answers to whether Salesforce can finally move enterprise AI from pilots to production at scale, or whether the \"$7 billion business\" remains more aspiration than reality.",
          "content": "As 50,000 attendees descend on Salesforce&#x27;s Dreamforce conference this week, the enterprise software giant is making its most aggressive bet yet on artificial intelligence agents, positioning itself as the antidote to what it calls an industry-wide \"pilot purgatory\" where 95% of enterprise AI projects never reach production.The company on Monday launched Agentforce 360, a sweeping reimagination of its entire product portfolio designed to transform businesses into what it calls \"agentic enterprises\" — organizations where AI agents work alongside humans to handle up to 40% of work across sales, service, marketing, and operations.\"We are truly in the agentic AI era, and I think it&#x27;s probably the biggest revolution, the biggest transition in technology I&#x27;ve ever experienced in my career,\" said Parker Harris, Salesforce&#x27;s co-founder and chief technology officer, during a recent press briefing. \"In the future, 40% of the work in the Fortune 1000 is probably going to be done by AI, and it&#x27;s going to be humans and AI actually working together.\"The announcement comes at a pivotal moment for Salesforce, which has deployed more than 12,000 AI agent implementations over the past year while building what Harris called a \"$7 billion business\" around its AI platform. Yet the launch also arrives amid unusual turbulence, as CEO Marc Benioff faces fierce backlash for recent comments supporting President Trump and suggesting National Guard troops should patrol San Francisco streets.Why 95% of enterprise AI projects never launchThe stakes are enormous. While companies have rushed to experiment with AI following ChatGPT&#x27;s emergence two years ago, most enterprise deployments have stalled before reaching production, according to recent MIT research that Salesforce executives cited extensively.\"Customers have invested a lot in AI, but they&#x27;re not getting the value,\" said Srini Tallapragada, Salesforce&#x27;s president and chief engineering and customer success officer. \"95% of enterprise AI pilots fail before production. It&#x27;s not because of lack of intent. People want to do this. Everybody understands the power of the technology. But why is it so hard?\"The answer, according to Tallapragada, is that AI tools remain disconnected from enterprise workflows, data, and governance systems. \"You&#x27;re writing prompts, prompts, you&#x27;re getting frustrated because the context is not there,\" he said, describing what he called a \"prompt doom loop.\"Salesforce&#x27;s solution is a deeply integrated platform connecting what it calls four ingredients: the Agentforce 360 agent platform, Data 360 for unified data access, Customer 360 apps containing business logic, and Slack as the \"conversational interface\" where humans and agents collaborate.Slack becomes the front door to SalesforcePerhaps the most significant strategic shift is the elevation of Slack — acquired by Salesforce in 2019 for $27.7 billion — as the primary interface for Salesforce itself. The company is effectively reimagining its traditional Lightning interface around Slack channels, where sales deals, service cases, and data insights will surface conversationally rather than through forms and dashboards.\"Imagine that you maybe don&#x27;t log into Salesforce, you don&#x27;t see Salesforce, but it&#x27;s there. It&#x27;s coming to you in Slack, because that&#x27;s where you&#x27;re getting your work done,\" Harris explained.The strategy includes embedding Salesforce&#x27;s Agentforce agents for sales, IT service, HR service, and analytics directly into Slack, alongside a completely rebuilt Slackbot that acts as a personal AI companion. The company is also launching \"Channel Expert,\" an always-on agent that provides instant answers from channel conversations.To enable third-party AI tools to access Slack&#x27;s conversational data, Salesforce is releasing a Real-Time Search API and Model Context Protocol server. Partners including OpenAI, Anthropic, Google, Perplexity, Writer, Dropbox, Notion, and Cursor are building agents that will live natively in Slack.\"The best way to see the power of the platform is through the AI apps and agents already being built,\" Rob Seaman, a Salesforce executive, said during a technical briefing, citing examples of startups \"achieving tens of thousands of customers that have it installed in 120 days or less.\"Voice and IT service take aim at new marketsBeyond Slack integration, Salesforce announced major expansions into voice-based interactions and employee service. Agentforce Voice, now generally available, transforms traditional IVR systems into natural conversations that can update CRM records, trigger workflows, and seamlessly hand off to human agents.The IT Service offering represents Salesforce&#x27;s most direct challenge to ServiceNow, the market leader. Mudhu Sudhakar, who joined Salesforce two months ago as senior vice president for IT and HR Service, positioned the product as a fundamental reimagining of employee support.\"Legacy IT service management is very portals, forms, tickets focused, manual process,\" Sudhakar said. \"What we had a few key tenets: conversation first and agent first, really focused on having a conversational experience for the people requesting the support and for the people providing the support.\"The IT Service platform includes what Salesforce describes as 25+ specialized agents and 100+ pre-built workflows and connectors that can handle everything from password resets to complex incident management.Early customers report dramatic efficiency gainsCustomer results suggest the approach is gaining traction. Reddit reduced average support resolution time from 8.9 minutes to 1.4 minutes — an 84% improvement — while deflecting 46% of cases entirely to AI agents. \"This efficiency has allowed us to provide on-demand help for complex tasks and boost advertiser satisfaction scores by 20%,\" said John Thompson, Reddit&#x27;s VP of sales strategy and operations, in a statement.Engine, a travel management company, reduced average handle time by 15%, saving over $2 million annually. OpenTable resolved 70% of restaurant and diner inquiries autonomously. And 1-800Accountant achieved a 90% case deflection rate during the critical tax week period.Salesforce&#x27;s own internal deployments may be most telling. Tallapragada&#x27;s customer success organization now handles 1.8 million AI-powered conversations weekly, with metrics published at help.salesforce.com showing how many agents answer versus escalating to humans.Even more significantly, Salesforce has deployed AI-powered sales development representatives to follow up on leads that would previously have gone uncontacted due to cost constraints. \"Now, Agentforce has an SDR which is doing thousands of leads following up,\" Tallapragada explained. The company also increased proactive customer outreach by 40% by shifting staff from reactive support.The trust layer problem enterprises can&#x27;t ignoreGiven enterprise concerns about AI reliability, Salesforce has invested heavily in what it calls the \"trust layer\" — audit trails, compliance checks, and observability tools that let organizations monitor agent behavior at scale.\"You should think of an agent as a human. Digital labor. You need to manage performance just like a human. And you need these audit trails,\" Tallapragada explained.The company encountered this challenge firsthand when its own agent deployment scaled. \"When we started at Agentforce at Salesforce, we would track every message, which is great until 1,000, 3,000,\" Tallapragada said. \"Once you have a million chats, there&#x27;s no human, we cannot do it.\"The platform now includes \"Agentforce Grid\" for searching across millions of conversations to identify and fix problematic patterns. The company also introduced Agent Script, a new scripting language that allows developers to define precise guardrails and deterministic controls for agent behavior.Data infrastructure gets a major upgradeUnderlying the agent capabilities is significant infrastructure investment. Salesforce&#x27;s Data 360 includes \"Intelligent Context,\" which automatically extracts structured information from unstructured content like PDFs, diagrams, and flowcharts using what the company describes as \"AI-powered unstructured data pipelines.\"The company is also collaborating with Databricks, dbt Labs, and Snowflake on the \"Universal Semantic Interchange,\" an attempt to standardize how different platforms define business metrics. The pending $8 billion acquisition of Informatica, expected to close soon, will expand metadata management capabilities across the enterprise.The competitive landscape keeps intensifyingSalesforce&#x27;s aggressive AI agent push comes as virtually every major enterprise software vendor pursues similar strategies. Microsoft has embedded Copilot across its product line, Google offers agent capabilities through Vertex AI and Gemini, and ServiceNow has launched its own agentic offerings.When asked how Salesforce&#x27;s announcement compared to OpenAI&#x27;s recent releases, Tallapragada emphasized that customers will use multiple AI tools simultaneously. \"Most of the time I&#x27;m seeing they&#x27;re using OpenAI, they&#x27;re using Gemini, they&#x27;re using Anthropic, just like Salesforce, we use all three,\" he said.The real differentiation, executives argued, lies not in the AI models but in the integration with business processes and data. Harris framed the competition in terms familiar from Salesforce&#x27;s founding: \"26 years ago, we just said, let&#x27;s make Salesforce automation as easy as buying a book on Amazon.com. We&#x27;re doing that same thing. We want to make agentic AI as easy as buying a book on Amazon.\"The company&#x27;s customer success stories are impressive but remain a small fraction of its customer base. With 150,000 Salesforce customers and one million Slack customers, the 12,000 Agentforce deployments represent roughly 8% penetration — strong for a one-year-old product line, but hardly ubiquitous.The company&#x27;s stock, down roughly 28% year to date with a Relative Strength rating of just 15, suggests investors remain skeptical. This week&#x27;s Dreamforce demonstrations — and the months of customer deployments that follow — will begin to provide answers to whether Salesforce can finally move enterprise AI from pilots to production at scale, or whether the \"$7 billion business\" remains more aspiration than reality.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4ElJnVoqNF5EdTdQ2qbc94/6c61cde31557a66a34fdfbbfaa9e57ed/nuneybits_Vector_art_of_businessperson_guiding_robot_f1c9b0fc-59ad-455c-b635-5551c598aa7b.webp"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/best-smart-led-light-bulbs-143022856.html",
          "published_at": "Mon, 13 Oct 2025 09:00:36 +0000",
          "title": "The best smart LED light bulbs for 2025",
          "standfirst": "Smart LED light bulbs are one of the easiest ways to get into the IoT space. These smart lighting solutions let you control your home’s illumination from your phone and other connected devices, and in addition to that practicality, they also inject some fun into your space. Color-changing bulbs have a plethora of RGB options for you to customize the lighting mood for your next movie night, date night or game day, or you can opt for cozy warm white light when you need to unwind at the end of a long day.It goes without saying that many of these smart LED light bulbs work with Amazon’s Alexa and the Google Assistant, so if you already have a smart home setup in the works, you can find one that fits into your chosen ecosystem. And arguably the best thing about these devices is that they can fit into any budget; affordable and advanced options have flooded the space over the past few years. We’ve tested out a bunch of smart lights over the years, and these are our current favorites. Table of contents Best smart lights for 2025 Other smart bulbs we tested What to look for in smart light bulbs Smart light bulb FAQs Best smart lights for 2025 Other smart bulbs we’ve tested Nanoleaf Smarter Kit While we’ve recommended Nanoleaf’s Smarter Kits in guides in the past, they’re a bit more niche than other smart lights on this list. They’re best for adding flare to your living room or game-streaming setup as they come in different shapes like hexagons and triangles and can sync with music. In addition to different colors, light animations and schedules, Nanoleaf’s Smart Kits also support Amazon Alexa and Google Assistant voice commands. What to look for in smart light bulbs Connectivity (To hub or not to hub) One of the biggest appeals of smart lighting solutions is being able to control them from your phone. Most of them are able to do so by connecting to it via Wi-Fi or Bluetooth, or via an external hub, which handles the connection for them. Bluetooth connectivity limits the range in which you’ll be able to control the light, so it’s only best for a limited number of bulbs and ones you don’t expect to control when you’re away. Wi-Fi color-changing bulbs are easy to set up and can be cheaper overall since they don’t require a hub to connect them. However, having something like a central Zigbee hub can make your whole system more reliable since its connection is separate from your home’s network. For that reason, hub-based bulbs tend to be more expandable, so we mainly recommend those if you want to eventually have dozens of smart lights around your home. White or color? Most color-changing bulbs you’ll find today are “white and color” bulbs, meaning they can glow in vibrant RGB color-options like blues, pinks, greens and everything in between, as well as shine with different temperatures of white. But there are some white-only bulbs out there, and they are often a bit more affordable than their color counterparts. While we recommend springing for the white-and-color devices, if you’d prefer white only, make sure you’re getting a bulb that can span the color temperature spectrum (typically from about 2000 to 5000 Kelvin), offering you various levels of cool and warm white light. App features One of the perks of smart lighting solutions is the amount of control you have over them thanks to their various app-control capabilities. Most companion apps let you do things like set lighting schedules and timers, group individual lights into room designations and create your own custom light “scenes” with different RGB options. But we have seen other features that aren’t as ubiquitous like vacation mode for automatically turning lights on and off to enhance your home security, and sync with media, which changes the colors of lights depending on the music you’re listening to or the game you’re currently live-streaming. Smart home compatibility If you use a smart assistant like Amazon’s Alexa or the Google Assistant regularly, make sure the smart lights or smart switches work with your favorite. All of the bulbs we tested supported both Amazon’s and Google’s virtual assistants, allowing you to use voice commands to turn lights on and off, dim them with a virtual dimmer and more. The wildcard here is Siri and Apple’s HomeKit; while numerous smart bulbs have added HomeKit support, not all lights are compatible with Apple’s smart home system. Expandability We alluded to this above, but you’ll want to consider how many smart lights you eventually want in your home. Some brands and lighting systems are easier to expand than others, and we generally recommend going for hub-based bulbs if you plan on putting smart lights in every room in your home. If you’re only looking to deck out your home office or living room with some fancy color-changing bulbs, Wi-Fi options should serve you well. Thankfully, these are some of the most affordable smart home devices you can get, so even if you don’t have a clear answer to this question now, you can reconsider your options down the line if you do decide to outfit your home with multiple smart bulbs. Smart light bulb FAQs What’s the best smart light bulb for Alexa? There is no best smart light bulb for Alexa. Amazon doesn’t make its own smart bulbs (like it does for smart plugs and thermostats), but rather there are dozens of smart lights made by third-parties that work with Alexa — including all of the ones we tested. Before picking the best smart light bulb for you, make sure to check the voice assistants that the contenders support. You’ll find that most smart light bulbs available today work with Amazon’s Alexa and the Google Assistant, and plenty of them also have support for Apple’s Siri and HomeKit. Can you put a smart bulb in any lamp? Smart light bulbs can go into most modern light fixtures — but just like regular bulbs, they need to be the right shape/size for the fixture. A standard A19 smart light bulb should work properly in most table, floor and other lamps. If you have a fixture that takes a specific type of bulb, look for smart bulbs that will fit properly. Do smart light bulbs use electricity when off? Smart light bulbs do use a negligible amount of electricity when their fixtures are turned off. This is due to the fact that the smart bulb needs to stay in constant contact with your home’s internet connection or Bluetooth in order to work properly. However, their energy-saving benefits usually outweigh the small amount of power they consume even while turned off.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-smart-led-light-bulbs-143022856.html?src=rss",
          "content": "Smart LED light bulbs are one of the easiest ways to get into the IoT space. These smart lighting solutions let you control your home’s illumination from your phone and other connected devices, and in addition to that practicality, they also inject some fun into your space. Color-changing bulbs have a plethora of RGB options for you to customize the lighting mood for your next movie night, date night or game day, or you can opt for cozy warm white light when you need to unwind at the end of a long day.It goes without saying that many of these smart LED light bulbs work with Amazon’s Alexa and the Google Assistant, so if you already have a smart home setup in the works, you can find one that fits into your chosen ecosystem. And arguably the best thing about these devices is that they can fit into any budget; affordable and advanced options have flooded the space over the past few years. We’ve tested out a bunch of smart lights over the years, and these are our current favorites. Table of contents Best smart lights for 2025 Other smart bulbs we tested What to look for in smart light bulbs Smart light bulb FAQs Best smart lights for 2025 Other smart bulbs we’ve tested Nanoleaf Smarter Kit While we’ve recommended Nanoleaf’s Smarter Kits in guides in the past, they’re a bit more niche than other smart lights on this list. They’re best for adding flare to your living room or game-streaming setup as they come in different shapes like hexagons and triangles and can sync with music. In addition to different colors, light animations and schedules, Nanoleaf’s Smart Kits also support Amazon Alexa and Google Assistant voice commands. What to look for in smart light bulbs Connectivity (To hub or not to hub) One of the biggest appeals of smart lighting solutions is being able to control them from your phone. Most of them are able to do so by connecting to it via Wi-Fi or Bluetooth, or via an external hub, which handles the connection for them. Bluetooth connectivity limits the range in which you’ll be able to control the light, so it’s only best for a limited number of bulbs and ones you don’t expect to control when you’re away. Wi-Fi color-changing bulbs are easy to set up and can be cheaper overall since they don’t require a hub to connect them. However, having something like a central Zigbee hub can make your whole system more reliable since its connection is separate from your home’s network. For that reason, hub-based bulbs tend to be more expandable, so we mainly recommend those if you want to eventually have dozens of smart lights around your home. White or color? Most color-changing bulbs you’ll find today are “white and color” bulbs, meaning they can glow in vibrant RGB color-options like blues, pinks, greens and everything in between, as well as shine with different temperatures of white. But there are some white-only bulbs out there, and they are often a bit more affordable than their color counterparts. While we recommend springing for the white-and-color devices, if you’d prefer white only, make sure you’re getting a bulb that can span the color temperature spectrum (typically from about 2000 to 5000 Kelvin), offering you various levels of cool and warm white light. App features One of the perks of smart lighting solutions is the amount of control you have over them thanks to their various app-control capabilities. Most companion apps let you do things like set lighting schedules and timers, group individual lights into room designations and create your own custom light “scenes” with different RGB options. But we have seen other features that aren’t as ubiquitous like vacation mode for automatically turning lights on and off to enhance your home security, and sync with media, which changes the colors of lights depending on the music you’re listening to or the game you’re currently live-streaming. Smart home compatibility If you use a smart assistant like Amazon’s Alexa or the Google Assistant regularly, make sure the smart lights or smart switches work with your favorite. All of the bulbs we tested supported both Amazon’s and Google’s virtual assistants, allowing you to use voice commands to turn lights on and off, dim them with a virtual dimmer and more. The wildcard here is Siri and Apple’s HomeKit; while numerous smart bulbs have added HomeKit support, not all lights are compatible with Apple’s smart home system. Expandability We alluded to this above, but you’ll want to consider how many smart lights you eventually want in your home. Some brands and lighting systems are easier to expand than others, and we generally recommend going for hub-based bulbs if you plan on putting smart lights in every room in your home. If you’re only looking to deck out your home office or living room with some fancy color-changing bulbs, Wi-Fi options should serve you well. Thankfully, these are some of the most affordable smart home devices you can get, so even if you don’t have a clear answer to this question now, you can reconsider your options down the line if you do decide to outfit your home with multiple smart bulbs. Smart light bulb FAQs What’s the best smart light bulb for Alexa? There is no best smart light bulb for Alexa. Amazon doesn’t make its own smart bulbs (like it does for smart plugs and thermostats), but rather there are dozens of smart lights made by third-parties that work with Alexa — including all of the ones we tested. Before picking the best smart light bulb for you, make sure to check the voice assistants that the contenders support. You’ll find that most smart light bulbs available today work with Amazon’s Alexa and the Google Assistant, and plenty of them also have support for Apple’s Siri and HomeKit. Can you put a smart bulb in any lamp? Smart light bulbs can go into most modern light fixtures — but just like regular bulbs, they need to be the right shape/size for the fixture. A standard A19 smart light bulb should work properly in most table, floor and other lamps. If you have a fixture that takes a specific type of bulb, look for smart bulbs that will fit properly. Do smart light bulbs use electricity when off? Smart light bulbs do use a negligible amount of electricity when their fixtures are turned off. This is due to the fact that the smart bulb needs to stay in constant contact with your home’s internet connection or Bluetooth in order to work properly. However, their energy-saving benefits usually outweigh the small amount of power they consume even while turned off.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-smart-led-light-bulbs-143022856.html?src=rss",
          "feed_position": 10
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/breaking-the-bottleneck-why-ai-demands-an-ssd-first-future",
          "published_at": "Mon, 13 Oct 2025 04:00:00 GMT",
          "title": "Breaking the bottleneck: Why AI demands an SSD-first future",
          "standfirst": "Presented by SolidigmAs AI adoption surges, data centers face a critical bottleneck in storage — and traditional HDDs are at the center of it. Data that once sat idle as cold archives is now being pulled into frequent use to build more accurate models and deliver better inference results. This shift from cold data to warm data demands low-latency, high-throughput storage that can handle parallel computations. HDDs will remain the workhorse for low-cost cold storage, but without rethinking their role, the high-capacity storage layer risks becoming the weakest link in the AI factory.\"Modern AI workloads, combined with data center constraints, have created new challenges for HDDs,\" says Jeff Janukowicz, research vice president at IDC. \"While HDD suppliers are addressing data storage growth by offering larger drives, this often comes at the expense of slower performance. As a result, the concept of &#x27;nearline SSDs&#x27; is becoming an increasingly relevant topic of discussion within the industry.\" Today, AI operators need to maximize GPU utilization, manage network-attached storage efficiently, and scale compute — all while cutting costs on increasingly scarce power and space. In an environment where every watt and every square inch counts, says Roger Corell, senior director of AI and leadership marketing at Solidigm, success requires more than a technical refresh. It calls for a deeper realignment.“It speaks to the tectonic shift in the value of data for AI,” Corell says. “That’s where high-capacity SSDs come into play. Along with capacity, they bring performance and efficiency -- enabling exabyte-scale storage pipelines to keep pace with the relentless pace of data set size. All of that consumes power and space, so we need to do it as efficiently as possible to enable more GPU scale in this constrained environment.”High-capacity SSDs aren’t just displacing HDDs — they’re removing one of the biggest bottlenecks on the AI factory floor. By delivering massive gains in performance, efficiency, and density, SSDs free up the power and space needed to push GPU scale further. It’s less a storage upgrade than a structural shift in how data infrastructure is designed for the AI era.HDDs vs. SDDs: More than just a hardware refreshHDDs have impressive mechanical designs, but they&#x27;re made up of many moving parts that at scale use more energy, take up more space, and fail at a higher rate than solid state drives. The reliance on spinning platters and mechanical read/write heads inherently limits Input/Output Operations Per Second (IOPS), creating bottlenecks for AI workloads that demand low latency, high concurrency, and sustained throughput. HDDs also struggle with latency-sensitive tasks, as the physical act of seeking data introduces mechanical delays unsuited for real-time AI inference and training. Moreover, their power and cooling requirements increase significantly under frequent and intensive data access, reducing efficiency as data scales and warms.In contrast, the SSD-based VAST storage solution reduces energy usage by ~$1M a year, and in an AI environment where every watt matters, this is a huge advantage for SSDs. To demonstrate, Solidigm and VAST Data completed a study examining the economics of data storage at exabyte scale — a quadrillion bytes, or a billion gigabytes, with an analysis of storage power consumption versus HDDs over a 10-year period. As a starting reference point, you’d need four 30TB HDDs to equal the capacity of a single 122TB Solidigm SSD. After factoring in VAST’s data reduction techniques made possible by the superior performance of SSDs, the exabyte solution comprises 3,738 Solidigm SSDs vs over 40,000 high-capacity HDDs. The study found that the SSD-based VAST solution consumes 77% less storage energy. Minimizing data center footprints\"We’re shipping 122-terabyte drives to some of the top OEMs and leading AI cloud service providers in the world,\" Corell says. \"When you compare an all-122TB SSD to hybrid HDD + TLC SSD configuration, they&#x27;re getting a nine-to-one savings in data center footprint. And yes, it’s important in these massive data centers that are building their own nuclear reactors and signing hefty power purchase agreements with renewable energy providers, but it’s increasingly important as you get to the regional data centers, the local data centers, and all the way out to your edge deployments where space can come at a premium.\"That nine-to-one savings goes beyond space and power — it lets organizations fit infrastructure into previously unavailable spaces, expand GPU scale, or build smaller footprints.\"If you’re given X amount of land and Y amount of power, you’re going to use it. You’re AI\" Corell explains, “where every watt and square inch counts, so why not use it in the most efficient way? Get the most efficient storage possible on the planet and enable greater GPU scale within that envelope that you have to fit in. On an ongoing basis, it’s going to save you operational cost as well. You have 90 percent fewer storage bays to maintain, and the cost associated with that is gone.\"Another often-overlooked element, the (much) larger physical footprint of data stored on mechanical HDDs results in a greater construction materials footprint. Collectively, concrete and steel production accounts for over 15% of global greenhouse gas emissions. By reducing the physical footprint of storage, high-capacity SSDs can help reduce embodied concrete and steel-based emissions by more than 80% compared to HDDs. And in the last phase of the sustainability life cycle, which is drive end-of-life, there will be 90% percent fewer drives to disposition. . Reshaping cold and archival storage strategiesThe move to SDD isn&#x27;t just a storage upgrade; it&#x27;s a fundamental realignment of data infrastructure strategy in the AI era, and it&#x27;s picking up speed.\"Big hyperscalers are looking to wring the most out of their existing infrastructure, doing unnatural acts, if you will, with HDDs like overprovisioning them to near 90% to try to wring out as many IOPS per terabyte as possible, but they’re beginning to come around,\" Corell says. \"Once they turn to a modern all high-capacity storage infrastructure, the industry at large will be on that trajectory. Plus, we&#x27;re starting to see these lessons learned on the value of modern storage in AI applied to other segments as well, such as big data analytics, HPC, and many more.\"While all-flash solutions are being embraced almost universally, there will always be a place for HDDs, he adds. HDDs will persist in usages like archival, cold storage, and scenarios where pure cost per gigabyte concerns outweigh the need for real-time access. But as the token economy heats up and enterprises realize value in monetizing data, the warm and warming data segments will continue to grow. Solving power challenges of the futureNow in its 4th generation, with more than 122 cumulative exabytes shipped to date, Solidigm’s QLC (Quad-Level Cell) technology has led the industry in balancing higher drive capacities with cost efficiency.\"We don’t think of storage as just storing bits and bytes. We think about how we can develop these amazing drives that are able to deliver benefits at a solution level,\" Corell says. \"The shining star on that is our recently launched, E1.S, designed specifically for dense and efficient storage in direct attach storage configurations for the next-generation fanless GPU server.\"The Solidigm D7-PS1010 E1.S is a breakthrough, the industry’s first eSSD with single-sided direct-to-chip liquid cooling technology. Solidigm worked with NVIDIA to address the dual challenges of heat management and cost efficiency, while delivering the high performance required for demanding AI workloads. \"We’re rapidly moving to an environment where all critical IT components will be direct-to-chip liquid-cooled on the direct attach side,\" he says. \"I think the market needs to be looking at their approach to cooling, because power limitations, power challenges are not going to abate in my lifetime, at least. They need to be applying a neocloud mindset to how they’re architecting the most efficient infrastructure.\"Increasingly complex inference is pushing against a memory wall, which makes storage architecture a front-line design challenge, not an afterthought. High-capacity SSDs, paired with liquid cooling and efficient design, are emerging as the only path to meet AI’s escalating demands. The mandate now is to build infrastructure not just for efficiency, but for storage that can efficiently scale as data grows. The organizations that realign storage now will be the ones able to scale AI tomorrow.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by SolidigmAs AI adoption surges, data centers face a critical bottleneck in storage — and traditional HDDs are at the center of it. Data that once sat idle as cold archives is now being pulled into frequent use to build more accurate models and deliver better inference results. This shift from cold data to warm data demands low-latency, high-throughput storage that can handle parallel computations. HDDs will remain the workhorse for low-cost cold storage, but without rethinking their role, the high-capacity storage layer risks becoming the weakest link in the AI factory.\"Modern AI workloads, combined with data center constraints, have created new challenges for HDDs,\" says Jeff Janukowicz, research vice president at IDC. \"While HDD suppliers are addressing data storage growth by offering larger drives, this often comes at the expense of slower performance. As a result, the concept of &#x27;nearline SSDs&#x27; is becoming an increasingly relevant topic of discussion within the industry.\" Today, AI operators need to maximize GPU utilization, manage network-attached storage efficiently, and scale compute — all while cutting costs on increasingly scarce power and space. In an environment where every watt and every square inch counts, says Roger Corell, senior director of AI and leadership marketing at Solidigm, success requires more than a technical refresh. It calls for a deeper realignment.“It speaks to the tectonic shift in the value of data for AI,” Corell says. “That’s where high-capacity SSDs come into play. Along with capacity, they bring performance and efficiency -- enabling exabyte-scale storage pipelines to keep pace with the relentless pace of data set size. All of that consumes power and space, so we need to do it as efficiently as possible to enable more GPU scale in this constrained environment.”High-capacity SSDs aren’t just displacing HDDs — they’re removing one of the biggest bottlenecks on the AI factory floor. By delivering massive gains in performance, efficiency, and density, SSDs free up the power and space needed to push GPU scale further. It’s less a storage upgrade than a structural shift in how data infrastructure is designed for the AI era.HDDs vs. SDDs: More than just a hardware refreshHDDs have impressive mechanical designs, but they&#x27;re made up of many moving parts that at scale use more energy, take up more space, and fail at a higher rate than solid state drives. The reliance on spinning platters and mechanical read/write heads inherently limits Input/Output Operations Per Second (IOPS), creating bottlenecks for AI workloads that demand low latency, high concurrency, and sustained throughput. HDDs also struggle with latency-sensitive tasks, as the physical act of seeking data introduces mechanical delays unsuited for real-time AI inference and training. Moreover, their power and cooling requirements increase significantly under frequent and intensive data access, reducing efficiency as data scales and warms.In contrast, the SSD-based VAST storage solution reduces energy usage by ~$1M a year, and in an AI environment where every watt matters, this is a huge advantage for SSDs. To demonstrate, Solidigm and VAST Data completed a study examining the economics of data storage at exabyte scale — a quadrillion bytes, or a billion gigabytes, with an analysis of storage power consumption versus HDDs over a 10-year period. As a starting reference point, you’d need four 30TB HDDs to equal the capacity of a single 122TB Solidigm SSD. After factoring in VAST’s data reduction techniques made possible by the superior performance of SSDs, the exabyte solution comprises 3,738 Solidigm SSDs vs over 40,000 high-capacity HDDs. The study found that the SSD-based VAST solution consumes 77% less storage energy. Minimizing data center footprints\"We’re shipping 122-terabyte drives to some of the top OEMs and leading AI cloud service providers in the world,\" Corell says. \"When you compare an all-122TB SSD to hybrid HDD + TLC SSD configuration, they&#x27;re getting a nine-to-one savings in data center footprint. And yes, it’s important in these massive data centers that are building their own nuclear reactors and signing hefty power purchase agreements with renewable energy providers, but it’s increasingly important as you get to the regional data centers, the local data centers, and all the way out to your edge deployments where space can come at a premium.\"That nine-to-one savings goes beyond space and power — it lets organizations fit infrastructure into previously unavailable spaces, expand GPU scale, or build smaller footprints.\"If you’re given X amount of land and Y amount of power, you’re going to use it. You’re AI\" Corell explains, “where every watt and square inch counts, so why not use it in the most efficient way? Get the most efficient storage possible on the planet and enable greater GPU scale within that envelope that you have to fit in. On an ongoing basis, it’s going to save you operational cost as well. You have 90 percent fewer storage bays to maintain, and the cost associated with that is gone.\"Another often-overlooked element, the (much) larger physical footprint of data stored on mechanical HDDs results in a greater construction materials footprint. Collectively, concrete and steel production accounts for over 15% of global greenhouse gas emissions. By reducing the physical footprint of storage, high-capacity SSDs can help reduce embodied concrete and steel-based emissions by more than 80% compared to HDDs. And in the last phase of the sustainability life cycle, which is drive end-of-life, there will be 90% percent fewer drives to disposition. . Reshaping cold and archival storage strategiesThe move to SDD isn&#x27;t just a storage upgrade; it&#x27;s a fundamental realignment of data infrastructure strategy in the AI era, and it&#x27;s picking up speed.\"Big hyperscalers are looking to wring the most out of their existing infrastructure, doing unnatural acts, if you will, with HDDs like overprovisioning them to near 90% to try to wring out as many IOPS per terabyte as possible, but they’re beginning to come around,\" Corell says. \"Once they turn to a modern all high-capacity storage infrastructure, the industry at large will be on that trajectory. Plus, we&#x27;re starting to see these lessons learned on the value of modern storage in AI applied to other segments as well, such as big data analytics, HPC, and many more.\"While all-flash solutions are being embraced almost universally, there will always be a place for HDDs, he adds. HDDs will persist in usages like archival, cold storage, and scenarios where pure cost per gigabyte concerns outweigh the need for real-time access. But as the token economy heats up and enterprises realize value in monetizing data, the warm and warming data segments will continue to grow. Solving power challenges of the futureNow in its 4th generation, with more than 122 cumulative exabytes shipped to date, Solidigm’s QLC (Quad-Level Cell) technology has led the industry in balancing higher drive capacities with cost efficiency.\"We don’t think of storage as just storing bits and bytes. We think about how we can develop these amazing drives that are able to deliver benefits at a solution level,\" Corell says. \"The shining star on that is our recently launched, E1.S, designed specifically for dense and efficient storage in direct attach storage configurations for the next-generation fanless GPU server.\"The Solidigm D7-PS1010 E1.S is a breakthrough, the industry’s first eSSD with single-sided direct-to-chip liquid cooling technology. Solidigm worked with NVIDIA to address the dual challenges of heat management and cost efficiency, while delivering the high performance required for demanding AI workloads. \"We’re rapidly moving to an environment where all critical IT components will be direct-to-chip liquid-cooled on the direct attach side,\" he says. \"I think the market needs to be looking at their approach to cooling, because power limitations, power challenges are not going to abate in my lifetime, at least. They need to be applying a neocloud mindset to how they’re architecting the most efficient infrastructure.\"Increasingly complex inference is pushing against a memory wall, which makes storage architecture a front-line design challenge, not an afterthought. High-capacity SSDs, paired with liquid cooling and efficient design, are emerging as the only path to meet AI’s escalating demands. The mandate now is to build infrastructure not just for efficiency, but for storage that can efficiently scale as data grows. The organizations that realign storage now will be the ones able to scale AI tomorrow.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4rRjfWe1S9u2XgvoKASwHM/ddafa77e43acdade763516ae3aa9a5fe/Solidigm_2.png"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/we-keep-talking-about-ai-agents-but-do-we-ever-know-what-they-are",
          "published_at": "Sun, 12 Oct 2025 19:00:00 GMT",
          "title": "We keep talking about AI agents, but do we ever know what they are?",
          "standfirst": "Imagine you do two things on a Monday morning.First, you ask a chatbot to summarize your new emails. Next, you ask an AI tool to figure out why your top competitor grew so fast last quarter. The AI silently gets to work. It scours financial reports, news articles and social media sentiment. It cross-references that data with your internal sales numbers, drafts a strategy outlining three potential reasons for the competitor&#x27;s success and schedules a 30-minute meeting with your team to present its findings.We&#x27;re calling both of these \"AI agents,\" but they represent worlds of difference in intelligence, capability and the level of trust we place in them. This ambiguity creates a fog that makes it difficult to build, evaluate, and safely govern these powerful new tools. If we can&#x27;t agree on what we&#x27;re building, how can we know when we&#x27;ve succeeded?This post won&#x27;t try to sell you on yet another definitive framework. Instead, think of it as a survey of the current landscape of agent autonomy, a map to help us all navigate the terrain together.What are we even talking about? Defining an \"AI agent\"Before we can measure an agent&#x27;s autonomy, we need to agree on what an \"agent\" actually is. The most widely accepted starting point comes from the foundational textbook on AI, Stuart Russell and Peter Norvig’s “Artificial Intelligence: A Modern Approach.” They define an agent as anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators. A thermostat is a simple agent: Its sensor perceives the room temperature, and its actuator acts by turning the heat on or off.ReAct Model for AI Agents (Credit: Confluent) That classic definition provides a solid mental model. For today&#x27;s technology, we can translate it into four key components that make up a modern AI agent:Perception (the \"senses\"): This is how an agent takes in information about its digital or physical environment. It&#x27;s the input stream that allows the agent to understand the current state of the world relevant to its task.Reasoning engine (the \"brain\"): This is the core logic that processes the perceptions and decides what to do next. For modern agents, this is typically powered by a large language model (LLM). The engine is responsible for planning, breaking down large goals into smaller steps, handling errors and choosing the right tools for the job.Action (the \"hands\"): This is how an agent affects its environment to move closer to its goal. The ability to take action via tools is what gives an agent its power.Goal/objective: This is the overarching task or purpose that guides all of the agent&#x27;s actions. It is the \"why\" that turns a collection of tools into a purposeful system. The goal can be simple (\"Find the best price for this book\") or complex (\"Launch the marketing campaign for our new product\")Putting it all together, a true agent is a full-body system. The reasoning engine is the brain, but it’s useless without the senses (perception) to understand the world and the hands (actions) to change it. This complete system, all guided by a central goal, is what creates genuine agency.With these components in mind, the distinction we made earlier becomes clear. A standard chatbot isn&#x27;t a true agent. It perceives your question and acts by providing an answer, but it lacks an overarching goal and the ability to use external tools to accomplish it.An agent, on the other hand, is software that has agency. It has the capacity to act independently and dynamically toward a goal. And it&#x27;s this capacity that makes a discussion about the levels of autonomy so important.Learning from the past: How we learned to classify autonomyThe dizzying pace of AI can make it feel like we&#x27;re navigating uncharted territory. But when it comes to classifying autonomy, we’re not starting from scratch. Other industries have been working on this problem for decades, and their playbooks offer powerful lessons for the world of AI agents.The core challenge is always the same: How do you create a clear, shared language for the gradual handover of responsibility from a human to a machine?SAE levels of driving automationPerhaps the most successful framework comes from the automotive industry. The SAE J3016 standard defines six levels of driving automation, from Level 0 (fully manual) to Level 5 (fully autonomous).The SAE J3016 Levels of Driving Automation (Credit: SAE International) What makes this model so effective isn&#x27;t its technical detail, but its focus on two simple concepts:Dynamic driving task (DDT): This is everything involved in the real-time act of driving: steering, braking, accelerating and monitoring the road.Operational design domain (ODD): These are the specific conditions under which the system is designed to work. For example, \"only on divided highways\" or \"only in clear weather during the daytime.\"The question for each level is simple: Who is doing the DDT, and what is the ODD? At Level 2, the human must supervise at all times. At Level 3, the car handles the DDT within its ODD, but the human must be ready to take over. At Level 4, the car can handle everything within its ODD, and if it encounters a problem, it can safely pull over on its own.The key insight for AI agents: A robust framework isn&#x27;t about the sophistication of the AI \"brain.\" It&#x27;s about clearly defining the division of responsibility between human and machine under specific, well-defined conditions.Aviation&#x27;s 10 Levels of AutomationWhile the SAE’s six levels are great for broad classification, aviation offers a more granular model for systems designed for close human-machine collaboration. The Parasuraman, Sheridan, and Wickens model proposes a detailed 10-level spectrum of automation.Levels of Automation of Decision and Action Selection for Aviation (Credit: The MITRE Corporation)This framework is less about full autonomy and more about the nuances of interaction. For example:At Level 3, the computer \"narrows the selection down to a few\" for the human to choose from.At Level 6, the computer \"allows the human a restricted time to veto before it executes\" an action.At Level 9, the computer \"informs the human only if it, the computer, decides to.\"The key insight for AI agents: This model is perfect for describing the collaborative \"centaur\" systems we&#x27;re seeing today. Most AI agents won&#x27;t be fully autonomous (Level 10) but will exist somewhere on this spectrum, acting as a co-pilot that suggests, executes with approval or acts with a veto window.Robotics and unmanned systemsFinally, the world of robotics brings in another critical dimension: context. The National Institute of Standards and Technology&#x27;s (NIST) Autonomy Levels for Unmanned Systems (ALFUS) framework was designed for systems like drones and industrial robots.The Three-Axis Model for ALFUS (Credit: NIST) Its main contribution is adding context to the definition of autonomy, assessing it along three axes:Human independence: How much human supervision is required?Mission complexity: How difficult or unstructured is the task?Environmental complexity: How predictable and stable is the environment in which the agent operates?The key insight for AI agents: This framework reminds us that autonomy isn&#x27;t a single number. An agent performing a simple task in a stable, predictable digital environment (like sorting files in a single folder) is fundamentally less autonomous than an agent performing a complex task across the chaotic, unpredictable environment of the open internet, even if the level of human supervision is the same.The emerging frameworks for AI agentsHaving looked at the lessons from automotive, aviation and robotics, we can now examine the emerging frameworks designed for AI agents. While the field is still new and no single standard has won out, most proposals fall into three distinct, but often overlapping, categories based on the primary question they seek to answer.Category 1: The \"What can it do?\" frameworks (capability-focused)These frameworks classify agents based on their underlying technical architecture and what they are capable of achieving. They provide a roadmap for developers, outlining a progression of increasingly sophisticated technical milestones that often correspond directly to code patterns.A prime example of this developer-centric approach comes from Hugging Face. Their framework uses a star rating to show the gradual shift in control from human to AI:Five Levels of AI Agent Autonomy, as proposed by HuggingFace (Credit: Hugging Face) Zero stars (simple processor): The AI has no impact on the program&#x27;s flow. It simply processes information and its output is displayed, like a print statement. The human is in complete control.One star (router): The AI makes a basic decision that directs program flow, like choosing between two predefined paths (if/else). The human still defines how everything is done.Two stars (tool call): The AI chooses which predefined tool to use and what arguments to use with it. The human has defined the available tools, but the AI decides how to execute them.Three stars (multi-step agent): The AI now controls the iteration loop. It decides which tool to use, when to use it and whether to continue working on the task.Four stars (fully autonomous): The AI can generate and execute entirely new code to accomplish a goal, going beyond the predefined tools it was given.Strengths: This model is excellent for engineers. It&#x27;s concrete, maps directly to code and clearly benchmarks the transfer of executive control to the AI. Weaknesses: It is highly technical and less intuitive for non-developers trying to understand an agent&#x27;s real-world impact.Category 2: The \"How do we work together?\" frameworks (interaction-focused)This second category defines autonomy not by the agent’s internal skills, but by the nature of its relationship with the human user. The central question is: Who is in control, and how do we collaborate?This approach often mirrors the nuance we saw in the aviation models. For instance, a framework detailed in the paper Levels of Autonomy for AI Agents defines levels based on the user&#x27;s role:L1 - user as an operator: The human is in direct control (like a person using Photoshop with AI-assist features).L4 - user as an approver: The agent proposes a full plan or action, and the human must give a simple \"yes\" or \"no\" before it proceeds.L5 - user as an observer: The agent has full autonomy to pursue a goal and simply reports its progress and results back to the human.Levels of Autonomy for AI AgentsStrengths: These frameworks are highly intuitive and user-centric. They directly address the critical issues of control, trust, and oversight.Weaknesses: An agent with simple capabilities and one with highly advanced reasoning could both fall into the \"Approver\" level, so this approach can sometimes obscure the underlying technical sophistication.Category 3: The \"Who is responsible?\" frameworks (governance-focused)The final category is less concerned with how an agent works and more with what happens when it fails. These frameworks are designed to help answer crucial questions about law, safety and ethics.Think tanks like Germany&#x27;s Stiftung Neue VTrantwortung have analyzed AI agents through the lens of legal liability. Their work aims to classify agents in a way that helps regulators determine who is responsible for an agent&#x27;s actions: The user who deployed it, the developer who built it or the company that owns the platform it runs on?This perspective is essential for navigating complex regulations like the EU&#x27;s Artificial Intelligence Act, which will treat AI systems differently based on the level of risk they pose.Strengths: This approach is absolutely essential for real-world deployment. It forces the difficult but necessary conversations about accountability that build public trust.Weaknesses: It&#x27;s more of a legal or policy guide than a technical roadmap for developers.A comprehensive understanding requires looking at all three questions at once: An agent&#x27;s capabilities, how we interact with it and who is responsible for the outcome..Identifying the gaps and challengesLooking at the landscape of autonomy frameworks shows us that no single model is sufficient because the true challenges lie in the gaps between them, in areas that are incredibly difficult to define and measure.What is the \"Road\" for a digital agent?The SAE framework for self-driving cars gave us the powerful concept of an ODD, the specific conditions under which a system can operate safely. For a car, that might be \"divided highways, in clear weather, during the day.\" This is a great solution for a physical environment, but what’s the ODD for a digital agent?The \"road\" for an agent is the entire internet. An infinite, chaotic and constantly changing environment. Websites get redesigned overnight, APIs are deprecated and social norms in online communities shift. How do we define a \"safe\" operational boundary for an agent that can browse websites, access databases and interact with third-party services? Answering this is one of the biggest unsolved problems. Without a clear digital ODD, we can&#x27;t make the same safety guarantees that are becoming standard in the automotive world.This is why, for now, the most effective and reliable agents operate within well-defined, closed-world scenarios. As I argued in a recent VentureBeat article, forgetting the open-world fantasies and focusing on \"bounded problems\" is the key to real-world success. This means defining a clear, limited set of tools, data sources and potential actions. Beyond simple tool useToday&#x27;s agents are getting very good at executing straightforward plans. If you tell one to \"find the price of this item using Tool A, then book a meeting with Tool B,\" it can often succeed. But true autonomy requires much more. Many systems today hit a technical wall when faced with tasks that require:Long-term reasoning and planning: Agents struggle to create and adapt complex, multi-step plans in the face of uncertainty. They can follow a recipe, but they can&#x27;t yet invent one from scratch when things go wrong.Robust self-correction: What happens when an API call fails or a website returns an unexpected error? A truly autonomous agent needs the resilience to diagnose the problem, form a new hypothesis and try a different approach, all without a human stepping in.Composability: The future likely involves not one agent, but a team of specialized agents working together. Getting them to collaborate reliably, to pass information back and forth, delegate tasks and resolve conflicts is a monumental software engineering challenge that we are just beginning to tackle.The elephant in the room: Alignment and controlThis is the most critical challenge of all, because it&#x27;s not just technical, it&#x27;s deeply human. Alignment is the problem of ensuring an agent&#x27;s goals and actions are consistent with our intentions and values, even when those values are complex, unstated or nuanced.Imagine you give an agent the seemingly harmless goal of \"maximizing customer engagement for our new product.\" The agent might correctly determine that the most effective strategy is to send a dozen notifications a day to every user. The agent has achieved its literal goal perfectly, but it has violated the unstated, common-sense goal of \"don&#x27;t be incredibly annoying.\"This is a failure of alignment.The core difficulty, which organizations like the AI Alignment Forum are dedicated to studying, is that it is incredibly hard to specify fuzzy, complex human preferences in the precise, literal language of code. As agents become more powerful, ensuring they are not just capable but also safe, predictable and aligned with our true intent becomes the most important challenge we face.The future is agentic (and collaborative)The path forward for AI agents is not a single leap to a god-like super-intelligence, but a more practical and collaborative journey. The immense challenges of open-world reasoning and perfect alignment mean that the future is a team effort.We will see less of the single, all-powerful agent and more of an \"agentic mesh\" — a network of specialized agents, each operating within a bounded domain, working together to tackle complex problems. More importantly, they will work with us. The most valuable and safest applications will keep a human on the loop, casting them as a co-pilot or strategist to augment our intellect with the speed of machine execution. This \"centaur\" model will be the most effective and responsible path forward.The frameworks we&#x27;ve explored aren’t just theoretical. They’re practical tools for building trust, assigning responsibility and setting clear expectations. They help developers define limits and leaders shape vision, laying the groundwork for AI to become a dependable partner in our work and lives.Sean Falconer is Confluent&#x27;s AI entrepreneur in residence.",
          "content": "Imagine you do two things on a Monday morning.First, you ask a chatbot to summarize your new emails. Next, you ask an AI tool to figure out why your top competitor grew so fast last quarter. The AI silently gets to work. It scours financial reports, news articles and social media sentiment. It cross-references that data with your internal sales numbers, drafts a strategy outlining three potential reasons for the competitor&#x27;s success and schedules a 30-minute meeting with your team to present its findings.We&#x27;re calling both of these \"AI agents,\" but they represent worlds of difference in intelligence, capability and the level of trust we place in them. This ambiguity creates a fog that makes it difficult to build, evaluate, and safely govern these powerful new tools. If we can&#x27;t agree on what we&#x27;re building, how can we know when we&#x27;ve succeeded?This post won&#x27;t try to sell you on yet another definitive framework. Instead, think of it as a survey of the current landscape of agent autonomy, a map to help us all navigate the terrain together.What are we even talking about? Defining an \"AI agent\"Before we can measure an agent&#x27;s autonomy, we need to agree on what an \"agent\" actually is. The most widely accepted starting point comes from the foundational textbook on AI, Stuart Russell and Peter Norvig’s “Artificial Intelligence: A Modern Approach.” They define an agent as anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators. A thermostat is a simple agent: Its sensor perceives the room temperature, and its actuator acts by turning the heat on or off.ReAct Model for AI Agents (Credit: Confluent) That classic definition provides a solid mental model. For today&#x27;s technology, we can translate it into four key components that make up a modern AI agent:Perception (the \"senses\"): This is how an agent takes in information about its digital or physical environment. It&#x27;s the input stream that allows the agent to understand the current state of the world relevant to its task.Reasoning engine (the \"brain\"): This is the core logic that processes the perceptions and decides what to do next. For modern agents, this is typically powered by a large language model (LLM). The engine is responsible for planning, breaking down large goals into smaller steps, handling errors and choosing the right tools for the job.Action (the \"hands\"): This is how an agent affects its environment to move closer to its goal. The ability to take action via tools is what gives an agent its power.Goal/objective: This is the overarching task or purpose that guides all of the agent&#x27;s actions. It is the \"why\" that turns a collection of tools into a purposeful system. The goal can be simple (\"Find the best price for this book\") or complex (\"Launch the marketing campaign for our new product\")Putting it all together, a true agent is a full-body system. The reasoning engine is the brain, but it’s useless without the senses (perception) to understand the world and the hands (actions) to change it. This complete system, all guided by a central goal, is what creates genuine agency.With these components in mind, the distinction we made earlier becomes clear. A standard chatbot isn&#x27;t a true agent. It perceives your question and acts by providing an answer, but it lacks an overarching goal and the ability to use external tools to accomplish it.An agent, on the other hand, is software that has agency. It has the capacity to act independently and dynamically toward a goal. And it&#x27;s this capacity that makes a discussion about the levels of autonomy so important.Learning from the past: How we learned to classify autonomyThe dizzying pace of AI can make it feel like we&#x27;re navigating uncharted territory. But when it comes to classifying autonomy, we’re not starting from scratch. Other industries have been working on this problem for decades, and their playbooks offer powerful lessons for the world of AI agents.The core challenge is always the same: How do you create a clear, shared language for the gradual handover of responsibility from a human to a machine?SAE levels of driving automationPerhaps the most successful framework comes from the automotive industry. The SAE J3016 standard defines six levels of driving automation, from Level 0 (fully manual) to Level 5 (fully autonomous).The SAE J3016 Levels of Driving Automation (Credit: SAE International) What makes this model so effective isn&#x27;t its technical detail, but its focus on two simple concepts:Dynamic driving task (DDT): This is everything involved in the real-time act of driving: steering, braking, accelerating and monitoring the road.Operational design domain (ODD): These are the specific conditions under which the system is designed to work. For example, \"only on divided highways\" or \"only in clear weather during the daytime.\"The question for each level is simple: Who is doing the DDT, and what is the ODD? At Level 2, the human must supervise at all times. At Level 3, the car handles the DDT within its ODD, but the human must be ready to take over. At Level 4, the car can handle everything within its ODD, and if it encounters a problem, it can safely pull over on its own.The key insight for AI agents: A robust framework isn&#x27;t about the sophistication of the AI \"brain.\" It&#x27;s about clearly defining the division of responsibility between human and machine under specific, well-defined conditions.Aviation&#x27;s 10 Levels of AutomationWhile the SAE’s six levels are great for broad classification, aviation offers a more granular model for systems designed for close human-machine collaboration. The Parasuraman, Sheridan, and Wickens model proposes a detailed 10-level spectrum of automation.Levels of Automation of Decision and Action Selection for Aviation (Credit: The MITRE Corporation)This framework is less about full autonomy and more about the nuances of interaction. For example:At Level 3, the computer \"narrows the selection down to a few\" for the human to choose from.At Level 6, the computer \"allows the human a restricted time to veto before it executes\" an action.At Level 9, the computer \"informs the human only if it, the computer, decides to.\"The key insight for AI agents: This model is perfect for describing the collaborative \"centaur\" systems we&#x27;re seeing today. Most AI agents won&#x27;t be fully autonomous (Level 10) but will exist somewhere on this spectrum, acting as a co-pilot that suggests, executes with approval or acts with a veto window.Robotics and unmanned systemsFinally, the world of robotics brings in another critical dimension: context. The National Institute of Standards and Technology&#x27;s (NIST) Autonomy Levels for Unmanned Systems (ALFUS) framework was designed for systems like drones and industrial robots.The Three-Axis Model for ALFUS (Credit: NIST) Its main contribution is adding context to the definition of autonomy, assessing it along three axes:Human independence: How much human supervision is required?Mission complexity: How difficult or unstructured is the task?Environmental complexity: How predictable and stable is the environment in which the agent operates?The key insight for AI agents: This framework reminds us that autonomy isn&#x27;t a single number. An agent performing a simple task in a stable, predictable digital environment (like sorting files in a single folder) is fundamentally less autonomous than an agent performing a complex task across the chaotic, unpredictable environment of the open internet, even if the level of human supervision is the same.The emerging frameworks for AI agentsHaving looked at the lessons from automotive, aviation and robotics, we can now examine the emerging frameworks designed for AI agents. While the field is still new and no single standard has won out, most proposals fall into three distinct, but often overlapping, categories based on the primary question they seek to answer.Category 1: The \"What can it do?\" frameworks (capability-focused)These frameworks classify agents based on their underlying technical architecture and what they are capable of achieving. They provide a roadmap for developers, outlining a progression of increasingly sophisticated technical milestones that often correspond directly to code patterns.A prime example of this developer-centric approach comes from Hugging Face. Their framework uses a star rating to show the gradual shift in control from human to AI:Five Levels of AI Agent Autonomy, as proposed by HuggingFace (Credit: Hugging Face) Zero stars (simple processor): The AI has no impact on the program&#x27;s flow. It simply processes information and its output is displayed, like a print statement. The human is in complete control.One star (router): The AI makes a basic decision that directs program flow, like choosing between two predefined paths (if/else). The human still defines how everything is done.Two stars (tool call): The AI chooses which predefined tool to use and what arguments to use with it. The human has defined the available tools, but the AI decides how to execute them.Three stars (multi-step agent): The AI now controls the iteration loop. It decides which tool to use, when to use it and whether to continue working on the task.Four stars (fully autonomous): The AI can generate and execute entirely new code to accomplish a goal, going beyond the predefined tools it was given.Strengths: This model is excellent for engineers. It&#x27;s concrete, maps directly to code and clearly benchmarks the transfer of executive control to the AI. Weaknesses: It is highly technical and less intuitive for non-developers trying to understand an agent&#x27;s real-world impact.Category 2: The \"How do we work together?\" frameworks (interaction-focused)This second category defines autonomy not by the agent’s internal skills, but by the nature of its relationship with the human user. The central question is: Who is in control, and how do we collaborate?This approach often mirrors the nuance we saw in the aviation models. For instance, a framework detailed in the paper Levels of Autonomy for AI Agents defines levels based on the user&#x27;s role:L1 - user as an operator: The human is in direct control (like a person using Photoshop with AI-assist features).L4 - user as an approver: The agent proposes a full plan or action, and the human must give a simple \"yes\" or \"no\" before it proceeds.L5 - user as an observer: The agent has full autonomy to pursue a goal and simply reports its progress and results back to the human.Levels of Autonomy for AI AgentsStrengths: These frameworks are highly intuitive and user-centric. They directly address the critical issues of control, trust, and oversight.Weaknesses: An agent with simple capabilities and one with highly advanced reasoning could both fall into the \"Approver\" level, so this approach can sometimes obscure the underlying technical sophistication.Category 3: The \"Who is responsible?\" frameworks (governance-focused)The final category is less concerned with how an agent works and more with what happens when it fails. These frameworks are designed to help answer crucial questions about law, safety and ethics.Think tanks like Germany&#x27;s Stiftung Neue VTrantwortung have analyzed AI agents through the lens of legal liability. Their work aims to classify agents in a way that helps regulators determine who is responsible for an agent&#x27;s actions: The user who deployed it, the developer who built it or the company that owns the platform it runs on?This perspective is essential for navigating complex regulations like the EU&#x27;s Artificial Intelligence Act, which will treat AI systems differently based on the level of risk they pose.Strengths: This approach is absolutely essential for real-world deployment. It forces the difficult but necessary conversations about accountability that build public trust.Weaknesses: It&#x27;s more of a legal or policy guide than a technical roadmap for developers.A comprehensive understanding requires looking at all three questions at once: An agent&#x27;s capabilities, how we interact with it and who is responsible for the outcome..Identifying the gaps and challengesLooking at the landscape of autonomy frameworks shows us that no single model is sufficient because the true challenges lie in the gaps between them, in areas that are incredibly difficult to define and measure.What is the \"Road\" for a digital agent?The SAE framework for self-driving cars gave us the powerful concept of an ODD, the specific conditions under which a system can operate safely. For a car, that might be \"divided highways, in clear weather, during the day.\" This is a great solution for a physical environment, but what’s the ODD for a digital agent?The \"road\" for an agent is the entire internet. An infinite, chaotic and constantly changing environment. Websites get redesigned overnight, APIs are deprecated and social norms in online communities shift. How do we define a \"safe\" operational boundary for an agent that can browse websites, access databases and interact with third-party services? Answering this is one of the biggest unsolved problems. Without a clear digital ODD, we can&#x27;t make the same safety guarantees that are becoming standard in the automotive world.This is why, for now, the most effective and reliable agents operate within well-defined, closed-world scenarios. As I argued in a recent VentureBeat article, forgetting the open-world fantasies and focusing on \"bounded problems\" is the key to real-world success. This means defining a clear, limited set of tools, data sources and potential actions. Beyond simple tool useToday&#x27;s agents are getting very good at executing straightforward plans. If you tell one to \"find the price of this item using Tool A, then book a meeting with Tool B,\" it can often succeed. But true autonomy requires much more. Many systems today hit a technical wall when faced with tasks that require:Long-term reasoning and planning: Agents struggle to create and adapt complex, multi-step plans in the face of uncertainty. They can follow a recipe, but they can&#x27;t yet invent one from scratch when things go wrong.Robust self-correction: What happens when an API call fails or a website returns an unexpected error? A truly autonomous agent needs the resilience to diagnose the problem, form a new hypothesis and try a different approach, all without a human stepping in.Composability: The future likely involves not one agent, but a team of specialized agents working together. Getting them to collaborate reliably, to pass information back and forth, delegate tasks and resolve conflicts is a monumental software engineering challenge that we are just beginning to tackle.The elephant in the room: Alignment and controlThis is the most critical challenge of all, because it&#x27;s not just technical, it&#x27;s deeply human. Alignment is the problem of ensuring an agent&#x27;s goals and actions are consistent with our intentions and values, even when those values are complex, unstated or nuanced.Imagine you give an agent the seemingly harmless goal of \"maximizing customer engagement for our new product.\" The agent might correctly determine that the most effective strategy is to send a dozen notifications a day to every user. The agent has achieved its literal goal perfectly, but it has violated the unstated, common-sense goal of \"don&#x27;t be incredibly annoying.\"This is a failure of alignment.The core difficulty, which organizations like the AI Alignment Forum are dedicated to studying, is that it is incredibly hard to specify fuzzy, complex human preferences in the precise, literal language of code. As agents become more powerful, ensuring they are not just capable but also safe, predictable and aligned with our true intent becomes the most important challenge we face.The future is agentic (and collaborative)The path forward for AI agents is not a single leap to a god-like super-intelligence, but a more practical and collaborative journey. The immense challenges of open-world reasoning and perfect alignment mean that the future is a team effort.We will see less of the single, all-powerful agent and more of an \"agentic mesh\" — a network of specialized agents, each operating within a bounded domain, working together to tackle complex problems. More importantly, they will work with us. The most valuable and safest applications will keep a human on the loop, casting them as a co-pilot or strategist to augment our intellect with the speed of machine execution. This \"centaur\" model will be the most effective and responsible path forward.The frameworks we&#x27;ve explored aren’t just theoretical. They’re practical tools for building trust, assigning responsibility and setting clear expectations. They help developers define limits and leaders shape vision, laying the groundwork for AI to become a dependable partner in our work and lives.Sean Falconer is Confluent&#x27;s AI entrepreneur in residence.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5b0hTPUKh7PB9D7CfWwO22/3b31fdc3f95c670ce5096758d8760ccd/Agent_autonomy.png"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/heres-whats-slowing-down-your-ai-strategy-and-how-to-fix-it",
          "published_at": "Sun, 12 Oct 2025 07:00:00 GMT",
          "title": "Here's what's slowing down your AI strategy — and how to fix it",
          "standfirst": "Your best data science team just spent six months building a model that predicts customer churn with 90% accuracy. It’s sitting on a server, unused. Why? Because it’s been stuck in a risk review queue for a very long period of time, waiting for a committee that doesn’t understand stochastic models to sign off. This isn’t a hypothetical — it’s the daily reality in most large companies. In AI, the models move at internet speed. Enterprises don’t. Every few weeks, a new model family drops, open-source toolchains mutate and entire MLOps practices get rewritten. But in most companies, anything touching production AI has to pass through risk reviews, audit trails, change-management boards and model-risk sign-off. The result is a widening velocity gap: The research community accelerates; the enterprise stalls. This gap isn’t a headline problem like “AI will take your job.” It’s quieter and more expensive: missed productivity, shadow AI sprawl, duplicated spend and compliance drag that turns promising pilots into perpetual proofs-of-concept.The numbers say the quiet part out loudTwo trends collide. First, the pace of innovation: Industry is now the dominant force, producing the vast majority of notable AI models, according to Stanford&#x27;s 2024 AI Index Report. The core inputs for this innovation are compounding at a historic rate, with training compute needs doubling rapidly every few years. That pace all but guarantees rapid model churn and tool fragmentation. Second, enterprise adoption is accelerating. According to IBM&#x27;s, 42% of enterprise-scale companies have actively deployed AI, with many more actively exploring it. Yet the same surveys show governance roles are only now being formalized, leaving many companies to retrofit control after deployment. Layer on new regulation. The EU AI Act’s staged obligations are locked in — unacceptable-risk bans are already active and General Purpose AI (GPAI) transparency duties hit in mid-2025, with high-risk rules following. Brussels has made clear there’s no pause coming. If your governance isn’t ready, your roadmap will be.The real blocker isn&#x27;t modeling, it&#x27;s auditIn most enterprises, the slowest step isn’t fine-tuning a model; it’s proving your model follows certain guidelines. Three frictions dominate:Audit debt: Policies were written for static software, not stochastic models. You can ship a microservice with unit tests; you can’t “unit test” fairness drift without data access, lineage and ongoing monitoring. When controls don’t map, reviews balloon.. MRM overload: Model risk management (MRM), a discipline perfected in banking, is spreading beyond finance — often translated literally, not functionally. Explainability and data-governance checks make sense; forcing every retrieval-augmented chatbot through credit-risk style documentation does not.Shadow AI sprawl: Teams adopt vertical AI inside SaaS tools without central oversight. It feels fast — until the third audit asks who owns the prompts, where embeddings live and how to revoke data. Sprawl is speed’s illusion; integration and governance are the long-term velocity.Frameworks exist, but they&#x27;re not operational by defaultThe NIST AI Risk Management Framework is a solid north star: govern, map, measure, manage. It’s voluntary, adaptable and aligned with international standards. But it’s a blueprint, not a building. Companies still need concrete control catalogs, evidence templates and tooling that turn principles into repeatable reviews. Similarly, the EU AI Act sets deadlines and duties. It doesn’t install your model registry, wire your dataset lineage or resolve the age-old question of who signs off when accuracy and bias trade off. That’s on you soon.What winning enterprises are doing differentlyThe leaders I see closing the velocity gap aren’t chasing every model; they’re making the path to production routine. Five moves show up again and again:Ship a control plane, not a memo: Codify governance as code. Create a small library or service that enforces non-negotiables: Dataset lineage required, evaluation suite attached, risk tier chosen, PII scan passed, human-in-the-loop defined (if required). If a project can’t satisfy the checks, it can’t deploy.Pre-approve patterns: Approve reference architectures — “GPAI with retrieval augmented generation (RAG) on approved vector store,” “high-risk tabular model with feature store X and bias audit Y,” “vendor LLM via API with no data retention.” Pre-approval shifts review from bespoke debates to pattern conformance. (Your auditors will thank you.)Stage your governance by risk, not by team: Tie review depth to use-case criticality (safety, finance, regulated outcomes). A marketing copy assistant shouldn’t endure the same gauntlet as a loan adjudicator. Risk-proportionate review is both defensible and fast.Create an “evidence once, reuse everywhere” backbone: Centralize model cards, eval results, data sheets, prompt templates and vendor attestations. Every subsequent audit should start at 60% done because you’ve already proven the common pieces.Make audit a product: Give legal, risk and compliance a real roadmap. Instrument dashboards that show: Models in production by risk tier, upcoming re-evals, incidents and data-retention attestations. If audit can self-serve, engineering can ship.A pragmatic cadence for the next 12 monthsIf you’re serious about catching up, pick a 12-month governance sprint:Quarter 1: Stand up a minimal AI registry (models, datasets, prompts, evaluations). Draft risk-tiering and control mapping aligned to NIST AI RMF functions; publish two pre-approved patterns.Quarter 2: Turn controls into pipelines (CI checks for evals, data scans, model cards). Convert two fast-moving teams from shadow AI to platform AI by making the paved road easier than the side road.Quarter 3: Pilot a GxP-style review (a rigorous documentation standard from life sciences) for one high-risk use case; automate evidence capture. Start your EU AI Act gap analysis if you touch Europe; assign owners and deadlines.Quarter 4: Expand your pattern catalog (RAG, batch inference, streaming prediction). Roll out dashboards for risk/compliance. Bake governance SLAs into your OKRs. By this point, you haven’t slowed down innovation — you’ve standardized it. The research community can keep moving at light speed; you can keep shipping at enterprise speed — without the audit queue becoming your critical path.The competitive edge isn&#x27;t the next model — it&#x27;s the next mileIt’s tempting to chase each week’s leaderboard. But the durable advantage is the mile between a paper and production: The platform, the patterns, the proofs. That’s what your competitors can’t copy from GitHub, and it’s the only way to keep velocity without trading compliance for chaos. In other words: Make governance the grease, not the grit. Jayachander Reddy Kandakatla is senior machine learning operations (MLOps) engineer at Ford Motor Credit Company.",
          "content": "Your best data science team just spent six months building a model that predicts customer churn with 90% accuracy. It’s sitting on a server, unused. Why? Because it’s been stuck in a risk review queue for a very long period of time, waiting for a committee that doesn’t understand stochastic models to sign off. This isn’t a hypothetical — it’s the daily reality in most large companies. In AI, the models move at internet speed. Enterprises don’t. Every few weeks, a new model family drops, open-source toolchains mutate and entire MLOps practices get rewritten. But in most companies, anything touching production AI has to pass through risk reviews, audit trails, change-management boards and model-risk sign-off. The result is a widening velocity gap: The research community accelerates; the enterprise stalls. This gap isn’t a headline problem like “AI will take your job.” It’s quieter and more expensive: missed productivity, shadow AI sprawl, duplicated spend and compliance drag that turns promising pilots into perpetual proofs-of-concept.The numbers say the quiet part out loudTwo trends collide. First, the pace of innovation: Industry is now the dominant force, producing the vast majority of notable AI models, according to Stanford&#x27;s 2024 AI Index Report. The core inputs for this innovation are compounding at a historic rate, with training compute needs doubling rapidly every few years. That pace all but guarantees rapid model churn and tool fragmentation. Second, enterprise adoption is accelerating. According to IBM&#x27;s, 42% of enterprise-scale companies have actively deployed AI, with many more actively exploring it. Yet the same surveys show governance roles are only now being formalized, leaving many companies to retrofit control after deployment. Layer on new regulation. The EU AI Act’s staged obligations are locked in — unacceptable-risk bans are already active and General Purpose AI (GPAI) transparency duties hit in mid-2025, with high-risk rules following. Brussels has made clear there’s no pause coming. If your governance isn’t ready, your roadmap will be.The real blocker isn&#x27;t modeling, it&#x27;s auditIn most enterprises, the slowest step isn’t fine-tuning a model; it’s proving your model follows certain guidelines. Three frictions dominate:Audit debt: Policies were written for static software, not stochastic models. You can ship a microservice with unit tests; you can’t “unit test” fairness drift without data access, lineage and ongoing monitoring. When controls don’t map, reviews balloon.. MRM overload: Model risk management (MRM), a discipline perfected in banking, is spreading beyond finance — often translated literally, not functionally. Explainability and data-governance checks make sense; forcing every retrieval-augmented chatbot through credit-risk style documentation does not.Shadow AI sprawl: Teams adopt vertical AI inside SaaS tools without central oversight. It feels fast — until the third audit asks who owns the prompts, where embeddings live and how to revoke data. Sprawl is speed’s illusion; integration and governance are the long-term velocity.Frameworks exist, but they&#x27;re not operational by defaultThe NIST AI Risk Management Framework is a solid north star: govern, map, measure, manage. It’s voluntary, adaptable and aligned with international standards. But it’s a blueprint, not a building. Companies still need concrete control catalogs, evidence templates and tooling that turn principles into repeatable reviews. Similarly, the EU AI Act sets deadlines and duties. It doesn’t install your model registry, wire your dataset lineage or resolve the age-old question of who signs off when accuracy and bias trade off. That’s on you soon.What winning enterprises are doing differentlyThe leaders I see closing the velocity gap aren’t chasing every model; they’re making the path to production routine. Five moves show up again and again:Ship a control plane, not a memo: Codify governance as code. Create a small library or service that enforces non-negotiables: Dataset lineage required, evaluation suite attached, risk tier chosen, PII scan passed, human-in-the-loop defined (if required). If a project can’t satisfy the checks, it can’t deploy.Pre-approve patterns: Approve reference architectures — “GPAI with retrieval augmented generation (RAG) on approved vector store,” “high-risk tabular model with feature store X and bias audit Y,” “vendor LLM via API with no data retention.” Pre-approval shifts review from bespoke debates to pattern conformance. (Your auditors will thank you.)Stage your governance by risk, not by team: Tie review depth to use-case criticality (safety, finance, regulated outcomes). A marketing copy assistant shouldn’t endure the same gauntlet as a loan adjudicator. Risk-proportionate review is both defensible and fast.Create an “evidence once, reuse everywhere” backbone: Centralize model cards, eval results, data sheets, prompt templates and vendor attestations. Every subsequent audit should start at 60% done because you’ve already proven the common pieces.Make audit a product: Give legal, risk and compliance a real roadmap. Instrument dashboards that show: Models in production by risk tier, upcoming re-evals, incidents and data-retention attestations. If audit can self-serve, engineering can ship.A pragmatic cadence for the next 12 monthsIf you’re serious about catching up, pick a 12-month governance sprint:Quarter 1: Stand up a minimal AI registry (models, datasets, prompts, evaluations). Draft risk-tiering and control mapping aligned to NIST AI RMF functions; publish two pre-approved patterns.Quarter 2: Turn controls into pipelines (CI checks for evals, data scans, model cards). Convert two fast-moving teams from shadow AI to platform AI by making the paved road easier than the side road.Quarter 3: Pilot a GxP-style review (a rigorous documentation standard from life sciences) for one high-risk use case; automate evidence capture. Start your EU AI Act gap analysis if you touch Europe; assign owners and deadlines.Quarter 4: Expand your pattern catalog (RAG, batch inference, streaming prediction). Roll out dashboards for risk/compliance. Bake governance SLAs into your OKRs. By this point, you haven’t slowed down innovation — you’ve standardized it. The research community can keep moving at light speed; you can keep shipping at enterprise speed — without the audit queue becoming your critical path.The competitive edge isn&#x27;t the next model — it&#x27;s the next mileIt’s tempting to chase each week’s leaderboard. But the durable advantage is the mile between a paper and production: The platform, the patterns, the proofs. That’s what your competitors can’t copy from GitHub, and it’s the only way to keep velocity without trading compliance for chaos. In other words: Make governance the grease, not the grit. Jayachander Reddy Kandakatla is senior machine learning operations (MLOps) engineer at Ford Motor Credit Company.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/77WjI7ALpxOD2JSAUGMDRD/e938cb7b3827956c6043438c7af3f0d6/Velocity_gap.png"
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c836b6e0-a60d-11f0-aff0-71a091f199fd",
      "popularity_score": 2015.1819294444444,
      "ai_summary": [
        "Windows 10 support ends on October 14.",
        "Microsoft is moving Windows 10 to \"end of life\" status.",
        "Security updates will stop by default.",
        "Users can upgrade to Windows 11 for free.",
        "Extended Security Updates (ESU) offer an extra year."
      ]
    },
    {
      "id": "cluster_17",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 17:16:56 +0000",
      "title": "Apple’s streaming service gets harder to tell apart from its streaming app, box",
      "neutral_headline": "Apple’s streaming service gets harder to tell apart from its streaming app, box",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/apple/2025/10/apple-tv-streaming-service-is-renamed-to-just-apple-tv/",
          "published_at": "Mon, 13 Oct 2025 17:16:56 +0000",
          "title": "Apple’s streaming service gets harder to tell apart from its streaming app, box",
          "standfirst": "Apple unifies its remaining streaming offerings by dropping the \"+\".",
          "content": "Apple has lightly rebranded its video-on-demand streaming service. The Netflix rival that has brought us critically acclaimed shows and movies like Slow Horses and The Lost Bus has gone from Apple TV+ to Apple TV. Apple announced the name change today in a press release that was primarily about the film F1: The Movie coming to its streaming service on December 12. Unlike previous announcements, however, today’s release referred to the streaming service as Apple TV, instead of Apple TV+. The announcement reads: Apple TV+ is now simply Apple TV, with a vibrant new identity. Apple didn’t specify how its streaming service’s “identity” has changed at all. As of this writing, accessing Apple’s streaming service via a browser or smart TV app still shows the original Apple TV+ branding.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/12/sever2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/12/sever2-1152x648.jpg",
      "popularity_score": 363.03915166666667,
      "ai_summary": [
        "Apple is unifying its streaming offerings.",
        "The company is dropping the \"+\" from the name.",
        "The change simplifies the branding.",
        "The streaming service is now called Apple TV.",
        "The change affects the Apple TV+ service."
      ]
    },
    {
      "id": "cluster_5",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 18:52:06 +0000",
      "title": "To shield kids, California hikes fake nude fines to $250K max",
      "neutral_headline": "To shield kids, California hikes fake nude fines to $250K max",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/tech-policy/2025/10/to-shield-kids-california-hikes-fake-nude-fines-to-250k-max/",
          "published_at": "Mon, 13 Oct 2025 18:52:06 +0000",
          "title": "To shield kids, California hikes fake nude fines to $250K max",
          "standfirst": "California cracks down on AI as child safety concerns grow.",
          "content": "California is cracking down on AI technology deemed too harmful for kids, attacking two increasingly notorious child safety fronts: companion bots and deepfake pornography. On Monday, Governor Gavin Newsom signed the first-ever US law regulating companion bots after several teen suicides sparked lawsuits. Moving forward, California will require any companion bot platforms—including ChatGPT, Grok, Character.AI, and the like—to create and make public \"protocols to identify and address users’ suicidal ideation or expressions of self-harm.\"Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-1152x648.jpg",
      "popularity_score": 352.6252627777778,
      "ai_summary": [
        "California is increasing penalties for AI-generated child abuse.",
        "The maximum fine for creating fake nudes is $250,000.",
        "The state is responding to growing child safety concerns.",
        "The law addresses the use of AI.",
        "The focus is on protecting children."
      ]
    },
    {
      "id": "cluster_28",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 16:15:53 +0000",
      "title": "Why Signal’s post-quantum makeover is an amazing engineering achievement",
      "neutral_headline": "Why Signal’s post-quantum makeover is an amazing engineering achievement",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/why-signals-post-quantum-makeover-is-an-amazing-engineering-achievement/",
          "published_at": "Mon, 13 Oct 2025 16:15:53 +0000",
          "title": "Why Signal’s post-quantum makeover is an amazing engineering achievement",
          "standfirst": "New design sets a high standard for post-quantum readiness.",
          "content": "The encryption protecting communications against criminal and nation-state snooping is under threat. As private industry and governments get closer to building useful quantum computers, the algorithms protecting Bitcoin wallets, encrypted Web visits, and other sensitive secrets will be useless. No one doubts the day will come, but as the now-common joke in cryptography circles observes, experts have been forecasting this cryptocalypse will arrive in the next 15 to 30 years for the past 30 years. The uncertainty has created something of an existential dilemma: Should network architects spend the billions of dollars required to wean themselves off quantum-vulnerable algorithms now, or should they prioritize their limited security budgets fighting more immediate threats such as ransomware and espionage attacks? Given the expense and no clear deadline, it’s little wonder that less than half of all TLS connections made inside the Cloudflare network and only 18 percent of Fortune 500 networks support quantum-resistant TLS connections. It's all but certain that many fewer organizations still are supporting quantum-ready encryption in less prominent protocols. Triumph of the cypherpunks One exception to the industry-wide lethargy is the engineering team that designs the Signal Protocol, the open-source engine that powers the world’s most robust and resilient form of end-to-end encryption for multiple private chat apps, most notably the Signal Messenger. Eleven days ago, the nonprofit entity that develops the protocol, Signal Messenger LLC, published a 5,900-word write-up describing its latest updates that make Signal fully quantum-resistant.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/signal-quantum-security-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/signal-quantum-security-1152x648.jpg",
      "popularity_score": 346.0216516666667,
      "ai_summary": [
        "Signal has undergone a post-quantum makeover.",
        "The new design sets a high standard.",
        "The article discusses the engineering achievement.",
        "The focus is on post-quantum readiness.",
        "The changes are considered amazing."
      ]
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 15:33:42 +0000",
      "title": "Hans Koenigsmann, who investigated all of SpaceX’s rocket failures, is going to space",
      "neutral_headline": "Hans Koenigsmann, who investigated all of SpaceX’s rocket failures, is going to space",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/one-of-spacexs-earliest-employees-is-going-to-space-via-blue-origin/",
          "published_at": "Mon, 13 Oct 2025 15:33:42 +0000",
          "title": "Hans Koenigsmann, who investigated all of SpaceX’s rocket failures, is going to space",
          "standfirst": "\"I've always been interested to experience Max Q from the inside.\"",
          "content": "Hans Koenigsmann is one of SpaceX's earliest, longest-tenured, and most-revered employees. When Elon Musk started the company in 2002, he was joined by two other \"founding\" employees, Tom Mueller in propulsion and Chris Thompson in structures. Koenigsmann was the next hire, brought on to develop avionics for the Falcon 1 rocket. Koenigsmann remained at the company for two decades before leaving SpaceX in late 2021. During that time, he transitioned from avionics to lead mission assurance and safety while also spearheading every major failure investigation of the Falcon 9 rocket. He was a beloved leader and mentor for his employees within the company's demanding culture.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-621034912-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-621034912-1024x648.jpg",
      "popularity_score": 342.3185961111111,
      "ai_summary": [
        "Hans Koenigsmann is going to space.",
        "He investigated SpaceX's rocket failures.",
        "He is interested in experiencing Max Q.",
        "He has worked for SpaceX.",
        "He will experience space travel."
      ]
    },
    {
      "id": "cluster_29",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 15:49:12 +0000",
      "title": "4chan fined $26K for refusing to assess risks under UK Online Safety Act",
      "neutral_headline": "4chan fined $26K for refusing to assess risks under UK Online Safety Act",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/4chan-fined-26k-for-refusing-to-assess-risks-under-uk-online-safety-act/",
          "published_at": "Mon, 13 Oct 2025 15:49:12 +0000",
          "title": "4chan fined $26K for refusing to assess risks under UK Online Safety Act",
          "standfirst": "4chan fine may test if US will intervene to block UK’s Online Safety Act.",
          "content": "A battle over the United Kingdom's Online Safety Act (OSA) heated up Monday as UK regulator Ofcom fined the notorious image-hosting board 4chan about $26,000 for failing to provide a risk assessment detailing the potential harms of illegal content hosted on its forum. In a press release provided to Ars, Ofcom said 4chan refused to respond to two requests for information that the regulator considered \"routine.\" The first asked for the risk assessment and the second for 4chan's \"qualifying worldwide revenue.\" 4chan was anticipating the Monday fine, noting in a lawsuit—which was jointly filed with the online trolling forum Kiwi Farms in August and seeks to permanently enjoin Ofcom from enforcing OSA—that Ofcom had made it clear that because 4chan ignored Ofcom's emails, the fine was coming.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1814351886.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1814351886.jpg",
      "popularity_score": 329.57692944444443,
      "ai_summary": [
        "4chan was fined $26,000.",
        "The fine is for refusing to assess risks.",
        "The UK Online Safety Act is the basis for the fine.",
        "The fine may test US intervention.",
        "The US may block the UK's act."
      ]
    },
    {
      "id": "cluster_33",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 15:14:44 +0000",
      "title": "Layoffs, a “coding error,” chaos: Trump admin ravages the health dept.",
      "neutral_headline": "Trump administration actions impact the Department of Health",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/10/mass-firings-at-us-health-dept-partially-reversed-but-still-devastating/",
          "published_at": "Mon, 13 Oct 2025 15:14:44 +0000",
          "title": "Layoffs, a “coding error,” chaos: Trump admin ravages the health dept.",
          "standfirst": "Reports suggest the hardest hit is the CDC, which is already struggling to function.",
          "content": "Federal health agencies are reeling from mass layoffs on Friday that appear to have particularly devastated the Centers for Disease Control and Prevention, despite some terminations being rescinded on Saturday. Numbers are still sketchy, but reports from Friday indicate that more than 4,000 federal workers overall were initially targeted for layoffs. The Trump administration linked the firings to the ongoing government shutdown, which legal experts have suggested is illegal. Unions representing federal workers have already filed a lawsuit challenging the move. Of the reported 4,000 terminations, about 1,100 to 1,200 were among employees in the Department of Health and Human Services (HHS). HHS is a massive department that houses critical federal agencies, including the Centers for Disease Control and Prevention, the National Institutes of Health, the Food and Drug Administration, and the Centers for Medicare & Medicaid Services, among others. Before Trump's second term, the HHS workforce was about 82,000, but that was slashed to about 62,000 earlier this year amid initial cuts and efforts to push civil servants out.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2228551722-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2228551722-1152x648.jpg",
      "popularity_score": 309.002485,
      "ai_summary": [
        "Reports indicate the CDC is struggling to function due to the administration's actions.",
        "Layoffs and a coding error are contributing to the chaos within the department.",
        "The administration's actions are described as ravaging the health department.",
        "The CDC is reportedly the hardest hit by these issues.",
        "The situation is causing significant disruption within the health department."
      ]
    },
    {
      "id": "cluster_39",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 14:57:01 +0000",
      "title": "Keep losing your key fob? Ford’s new “Truckle” is the answer.",
      "neutral_headline": "Ford introduces \"Truckle\" for key fob management",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/keep-losing-your-key-fob-fords-new-truckle-is-the-answer/",
          "published_at": "Mon, 13 Oct 2025 14:57:01 +0000",
          "title": "Keep losing your key fob? Ford’s new “Truckle” is the answer.",
          "standfirst": "Keep your pants up and your F-150 unlocked at the same time.",
          "content": "I came across possibly one of the weirdest official automotive accessories this morning, courtesy of a friend's social media feed. It's called the \"Truckle,\" and it's a hand-crafted silver and bronze belt buckle that might be the envy of every other cowboy out there, since this one has a place to keep your F-150's key fob without ruining the lines of your jeans. The Truckle was designed by Utah-based A Cut Above Buckles, with a hand-engraved F-150 on the bump in the front. Behind the truck? Storage space for a Ford truck key fob, which should fit any F-150 from model year 2018 onward. \"You can put your key fob in the buckle—all your remote features work while it’s in the buckle,\" designer Andy Andrews told the Detroit Free Press. \"Once you have it in there, you're not going to lose that key fob. You’re not going to be scratching your head (wondering) where it’s at. It's right there with you in the Truckle.\"Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Truckle_7-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Truckle_7-1152x648.jpg",
      "popularity_score": 298.7072072222222,
      "ai_summary": [
        "Ford's \"Truckle\" aims to address the issue of lost key fobs.",
        "The system is designed to keep pants up and the F-150 unlocked.",
        "Details about the specific technology behind \"Truckle\" are not provided.",
        "The product is intended for Ford F-150 owners.",
        "The announcement focuses on convenience for truck owners."
      ]
    },
    {
      "id": "cluster_51",
      "coverage": 1,
      "updated_at": "Mon, 13 Oct 2025 14:10:25 +0000",
      "title": "Software update bricks some Jeep 4xe hybrids over the weekend",
      "neutral_headline": "Jeep 4xe hybrid software update causes issues",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/software-update-bricks-some-jeep-4xe-hybrids-over-the-weekend/",
          "published_at": "Mon, 13 Oct 2025 14:10:25 +0000",
          "title": "Software update bricks some Jeep 4xe hybrids over the weekend",
          "standfirst": "Jeep has pulled the update; owners are advised to ignore it if it already downloaded.",
          "content": "Owners of some Jeep Wrangler 4xe hybrids have been left stranded after installing an over-the-air software update this weekend. The automaker pushed out a telematics update for the Uconnect infotainment system that evidently wasn't ready, resulting in cars losing power while driving and then becoming stranded. Stranded Jeep owners have been detailing their experiences in forum and Reddit posts, as well as on YouTube. The buggy update doesn't appear to brick the car immediately. Instead, the failure appears to occur while driving—a far more serious problem. For some, this happened close to home and at low speed, but others claim to have experienced a powertrain failure at highway speeds. Jeep pulled the update after reports of problems, but the software had already downloaded to many owners' cars by then. A member of Stellantis' social engagement team told 4xe owners at a Jeep forum to ignore the update pop-up if they haven't installed it yet.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2024Wrangler4xe-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2024Wrangler4xe-1152x648.jpg",
      "popularity_score": 287.9305405555556,
      "ai_summary": [
        "A software update caused problems for some Jeep 4xe hybrid owners.",
        "The update has been pulled by Jeep due to the issues it caused.",
        "Owners are advised to avoid the update if they have not installed it.",
        "The update's problems occurred over the weekend.",
        "The specific nature of the software problems is not detailed."
      ]
    },
    {
      "id": "cluster_81",
      "coverage": 1,
      "updated_at": "Sun, 12 Oct 2025 20:50:35 +0000",
      "title": "New Starfleet Academy trailer debuts at NYCC",
      "neutral_headline": "New Star Trek Academy trailer released at NYCC",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/10/new-starfleet-academy-trailer-debuts-at-nycc/",
          "published_at": "Sun, 12 Oct 2025 20:50:35 +0000",
          "title": "New Starfleet Academy trailer debuts at NYCC",
          "standfirst": "Also: Our first look at S4 of Star Trek: Strange New Worlds.",
          "content": "The Star Trek universe panel at New York Comic Con (NYCC) this weekend concluded with a brand-new trailer for Star Trek: Starfleet Academy. The 10-episode series will follow the exploits of the first new crop of cadets in a century. Per the official premise: Star Trek: Starfleet Academy introduces viewers to a young group of cadets who come together to pursue a common dream of hope and optimism. Under the watchful and demanding eyes of their instructors, they discover what it takes to become Starfleet officers as they navigate blossoming friendships, explosive rivalries, first loves and a new enemy that threatens both the Academy and the Federation itself. The new cadets include Sandro Rosta as human orphan Caleb Mir; Karim Diané as a Klingon cadet, Jay-Den Kraag; Kerrice Brooks as Sam (Series Acclimation Mil), the first Kasquain to attend the Academy; George Hawkins as Darem Reymi, a Khionian cadet who wants to be a captain; Bella Shepard as Genesis Lythe, a Dar-Sha cadet; and Zoë Steiner as Tarima Sadal, daughter of the president of Betazed. In addition, Holly Hunter plays Academy chancellor Captain Nahla Ake; Gina Yashere plays Cadet Master Lura Thok; Becky Lynch plays a member of Starfleet bridge crew; and Paul Giamatti plays a half-Klingon, half-Tellarite character named Nus Braka, the series' chief villain.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/academy1-1152x648-1760302457.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/academy1-1152x648-1760302457.jpg",
      "popularity_score": 275,
      "ai_summary": [
        "A new trailer for Starfleet Academy was debuted at NYCC.",
        "The trailer provides a first look at the upcoming series.",
        "The event also featured a first look at Star Trek: Strange New Worlds Season 4.",
        "The announcement is related to the Star Trek franchise.",
        "The trailer's content is not described in detail."
      ]
    }
  ]
}