{
  "updated_at": "2025-10-15T19:15:31.711Z",
  "clusters": [
    {
      "id": "cluster_0",
      "coverage": 3,
      "updated_at": "Wed, 15 Oct 2025 18:53:00 +0000",
      "title": "Anthropic’s Claude Haiku 4.5 matches May’s frontier model at fraction of cost",
      "neutral_headline": "Anthropic’s Claude Haiku 4.5 matches May’s frontier model at fraction of cost: Tiny, fast model hits coding scores similar to GPT-5 and Sonnet 4",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/anthropics-claude-haiku-4-5-matches-mays-frontier-model-at-fraction-of-cost/",
          "published_at": "Wed, 15 Oct 2025 18:53:00 +0000",
          "title": "Anthropic’s Claude Haiku 4.5 matches May’s frontier model at fraction of cost",
          "standfirst": "Tiny, fast model hits coding scores similar to GPT-5 and Sonnet 4.",
          "content": "On Wednesday, Anthropic released Claude Haiku 4.5, a small AI language model that reportedly delivers performance similar to what its frontier model Claude Sonnet 4 achieved five months ago but at one-third the cost and more than twice the speed. The new model is available now to all Claude app, web, and API users. If the benchmarks for Haiku 4.5 reported by Anthropic hold up to independent testing, the fact that the company can match some capabilities of its cutting-edge coding model from only five months ago (and GPT-5 in coding) while providing a dramatic speed increase and cost cut is notable. As a recap, Anthropic ships the Claude family in three model sizes: Haiku (small), Sonnet (medium), and Opus (large). The larger models are based on larger neural networks and typically include deeper contextual knowledge but are slower and more expensive to run. Due to a technique called distillation, companies like Anthropic have been able to craft smaller-sized AI models that match the capability of larger, older models at functional tasks like coding, although it typically comes at the cost of omitting stored knowledge.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/haiku45_hero.jpg"
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251015/p41#a251015p41",
          "published_at": "Wed, 15 Oct 2025 13:10:04 -0400",
          "title": "Anthropic releases Claude Haiku 4.5, claiming it offers similar levels of coding performance to Sonnet 4 at \"one-third the cost and more than twice the speed\" (Russell Brandom/TechCrunch)",
          "standfirst": "Russell Brandom / TechCrunch: Anthropic releases Claude Haiku 4.5, claiming it offers similar levels of coding performance to Sonnet 4 at &ldquo;one-third the cost and more than twice the speed&rdquo; &mdash; On Wednesday, Anthropic released Claude Haiku 4.5, the newest version of its smallest model, billed as offering similar performance &hellip;",
          "content": "Russell Brandom / TechCrunch: Anthropic releases Claude Haiku 4.5, claiming it offers similar levels of coding performance to Sonnet 4 at &ldquo;one-third the cost and more than twice the speed&rdquo; &mdash; On Wednesday, Anthropic released Claude Haiku 4.5, the newest version of its smallest model, billed as offering similar performance &hellip;",
          "feed_position": 3,
          "image_url": "http://www.techmeme.com/251015/i41.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/15/anthropic-launches-new-version-of-scaled-down-haiku-model/",
          "published_at": "Wed, 15 Oct 2025 17:00:00 +0000",
          "title": "Anthropic launches new version of scaled-down &#8216;Haiku&#8217; model",
          "standfirst": "Anthropic has released Claude Haiku 4.5, the newest version of its smallest model, billed as offering similar performance to Sonnet 4 \"at one-third the cost and more than twice the speed.\"",
          "content": "Anthropic has released Claude Haiku 4.5, the newest version of its smallest model, billed as offering similar performance to Sonnet 4 \"at one-third the cost and more than twice the speed.\"",
          "feed_position": 1
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/haiku45_hero.jpg",
      "popularity_score": 3019.6245247222223,
      "ai_summary": [
        "Anthropic released Claude Haiku 4.5, its smallest model.",
        "The model offers similar coding performance to Sonnet 4.",
        "It is available at one-third the cost of Sonnet 4.",
        "Claude Haiku 4.5 is more than twice as fast as Sonnet 4.",
        "The model is designed for speed and efficiency."
      ]
    },
    {
      "id": "cluster_23",
      "coverage": 3,
      "updated_at": "Wed, 15 Oct 2025 16:49:00 GMT",
      "title": "Should you upgrade to M5 MacBook Pro from an M1? How the numbers add up",
      "neutral_headline": "Apple Announces New M5 Chip for Multiple Devices",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/should-you-upgrade-to-m5-macbook-pro-from-an-m1-how-the-numbers-add-up/",
          "published_at": "Wed, 15 Oct 2025 16:49:00 GMT",
          "title": "Should you upgrade to M5 MacBook Pro from an M1? How the numbers add up",
          "standfirst": "Apple's new M5 MacBook Pro advertises some impressive performance gains, but who are they relevant for? Let's break down the numbers.",
          "content": "Apple's new M5 MacBook Pro advertises some impressive performance gains, but who are they relevant for? Let's break down the numbers.",
          "feed_position": 4
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/15/apple-upgrades-ipad-pro-macbook-pro-and-vision-pro-with-new-m5-chip/",
          "published_at": "Wed, 15 Oct 2025 15:15:33 +0000",
          "title": "Apple upgrades iPad Pro, MacBook Pro, and Vision Pro with new M5 chip",
          "standfirst": "Apple announced its new M5 chip along with the new iPad Pro, MacBook Pro, and Vision Pro.",
          "content": "Apple announced its new M5 chip along with the new iPad Pro, MacBook Pro, and Vision Pro.",
          "feed_position": 10
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/apple-m5-powered-ipad-pro-macbook-pro-vision-pro-october-2025/",
          "published_at": "Wed, 15 Oct 2025 15:11:26 +0000",
          "title": "Apple Just Upgraded the iPad Pro, MacBook Pro, and Vision Pro With Its New M5 Chip",
          "standfirst": "The hardware largely remains the same, but performance gets a boost.",
          "content": "The hardware largely remains the same, but performance gets a boost.",
          "feed_position": 5,
          "image_url": "https://media.wired.com/photos/68efb698670b06a048487b72/master/pass/Apple%20iPad%20Pro%20M5%20SOURCE%20Apple.jpg"
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/apple-just-launched-an-m5-macbook-ipad-and-vision-pro-specs-prices-and-availability/",
          "published_at": "Wed, 15 Oct 2025 14:22:00 GMT",
          "title": "Apple just launched an M5 MacBook, iPad, and Vision Pro: Specs, prices, and availability",
          "standfirst": "Apple just announced three new Pro devices with an all-new chipset that focuses on AI compute performance. Here's what to know.",
          "content": "Apple just announced three new Pro devices with an all-new chipset that focuses on AI compute performance. Here's what to know.",
          "feed_position": 15
        }
      ],
      "featured_image": "https://media.wired.com/photos/68efb698670b06a048487b72/master/pass/Apple%20iPad%20Pro%20M5%20SOURCE%20Apple.jpg",
      "popularity_score": 3017.5578580555557,
      "ai_summary": [
        "Apple launched new M5 chip, upgrading iPad Pro, MacBook Pro, and Vision Pro models.",
        "The new chip focuses on AI compute performance, enhancing device capabilities.",
        "Hardware largely remains the same, but performance receives a significant boost.",
        "New devices include M5 MacBook, iPad, and Vision Pro, with updated specs and pricing.",
        "The M5 MacBook Pro advertises impressive performance gains, relevant for specific users."
      ]
    },
    {
      "id": "cluster_1",
      "coverage": 2,
      "updated_at": "Wed, 15 Oct 2025 18:50:00 GMT",
      "title": "Google releases new AI video model Veo 3.1 in Flow and API: what it means for enterprises",
      "neutral_headline": "Google Releases New AI Video Model Veo 3.1",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/google-releases-new-ai-video-model-veo-3-1-in-flow-and-api-what-it-means-for",
          "published_at": "Wed, 15 Oct 2025 18:50:00 GMT",
          "title": "Google releases new AI video model Veo 3.1 in Flow and API: what it means for enterprises",
          "standfirst": "As expected after days of leaks and rumors online, Google has unveiled Veo 3.1, its latest AI video generation model, bringing a suite of creative and technical upgrades aimed at improving narrative control, audio integration, and realism in AI-generated video. While the updates expand possibilities for hobbyists and content creators using Google’s online AI creation app, Flow, the release also signals a growing opportunity for enterprises, developers, and creative teams seeking scalable, customizable video tools.The quality is higher, the physics better, the pricing the same as before, and the control and editing features more robust and varied.My initial tests showed it to be a powerful and performant model that immediately delights with each generation. However, the look is more cinematic, polished and a little more \"artificial\" than by default than rivals such as OpenAI&#x27;s new Sora 2, released late last month, which may or may not be what a particular user is going after (Sora excels at handheld and \"candid\" style videos). Expanded Control Over Narrative and AudioVeo 3.1 builds on its predecessor, Veo 3 (released back in May 2025) with enhanced support for dialogue, ambient sound, and other audio effects. Native audio generation is now available across several key features in Flow, including “Frames to Video,” “Ingredients to Video,” and “Extend,\" which give users the ability to, respectively: turn still images into video; use items, characters and objects from multiple images in a single video; and generate longer clips than the initial 8 seconds, to more than 30 seconds or even 1+ plus when continuing from a prior clip&#x27;s final frame. Before, you had to add audio manually after using these features. This addition gives users greater command over tone, emotion, and storytelling — capabilities that have previously required post-production work.In enterprise contexts, this level of control may reduce the need for separate audio pipelines, offering an integrated way to create training content, marketing videos, or digital experiences with synchronized sound and visuals.Google noted in a blog post that the updates reflect user feedback calling for deeper artistic control and improved audio support. Gallegos emphasizes the importance of making edits and refinements possible directly in Flow, without reworking scenes from scratch.Richer Inputs and Editing CapabilitiesWith Veo 3.1, Google introduces support for multiple input types and more granular control over generated outputs. The model accepts text prompts, images, and video clips as input, and also supports:Reference images (up to three) to guide appearance and style in the final outputFirst and last frame interpolation to generate seamless scenes between fixed endpointsScene extension that continues a video’s action or motion beyond its current durationThese tools aim to give enterprise users a way to fine-tune the look and feel of their content—useful for brand consistency or adherence to creative briefs.Additional capabilities like “Insert” (add objects to scenes) and “Remove” (delete elements or characters) are also being introduced, though not all are immediately available through the Gemini API.Deployment Across PlatformsVeo 3.1 is accessible through several of Google’s existing AI services:Flow, Google’s own interface for AI-assisted filmmakingGemini API, targeted at developers building video capabilities into applicationsVertex AI, where enterprise integration will soon support Veo’s “Scene Extension” and other key featuresAvailability through these platforms allows enterprise customers to choose the right environment—GUI-based or programmatic—based on their teams and workflows.Pricing and AccessThe Veo 3.1 model is currently in preview and available only on the paid tier of the Gemini API. The cost structure is the same as Veo 3, the preceding generation of AI video models from Google.Standard model: $0.40 per second of videoFast model: $0.15 per secondThere is no free tier, and users are charged only if a video is successfully generated. This model is consistent with previous Veo versions and provides predictable pricing for budget-conscious enterprise teams.Technical Specs and Output ControlVeo 3.1 outputs video at 720p or 1080p resolution, with a 24 fps frame rate. Duration options include 4, 6, or 8 seconds from a text prompt or uploaded images, with the ability to extend videos up to 148 seconds (more than 2 and half minutes!) when using the “Extend” feature.New functionality also includes tighter control over subjects and environments. For example, enterprises can upload a product image or visual reference, and Veo 3.1 will generate scenes that preserve its appearance and stylistic cues across the video. This could streamline creative production pipelines for retail, advertising, and virtual content production teams.Initial ReactionsThe broader creator and developer community has responded to Veo 3.1’s launch with a mix of optimism and tempered critique—particularly when comparing it to rival models like OpenAI’s Sora 2.Matt Shumer, an AI founder of Otherside AI/Hyperwrite, and early adopter, described his initial reaction as “disappointment,” noting that Veo 3.1 is “noticeably worse than Sora 2” and also “quite a bit more expensive.”However, he acknowledged that Google’s tooling—such as support for references and scene extension—is a bright spot in the release.Travis Davids, a 3D digital artist and AI content creator, echoed some of that sentiment. While he noted improvements in audio quality, particularly in sound effects and dialogue, he raised concerns about limitations that remain in the system. These include the lack of custom voice support, an inability to select generated voices directly, and the continued cap at 8-second generations—despite some public claims about longer outputs.Davids also pointed out that character consistency across changing camera angles still requires careful prompting, whereas other models like Sora 2 handle this more automatically. He questioned the absence of 1080p resolution for users on paid tiers like Flow Pro and expressed skepticism over feature parity.On the more positive end, @kimmonismus, an AI newsletter writer, stated that “Veo 3.1 is amazing,” though still concluded that OpenAI’s latest model remains preferable overall.Collectively, these early impressions suggest that while Veo 3.1 delivers meaningful tooling enhancements and new creative control features, expectations have shifted as competitors raise the bar on both quality and usability.Adoption and ScaleSince launching Flow five months ago, Google says over 275 million videos have been generated across various Veo models. The pace of adoption suggests significant interest not only from individuals but also from developers and businesses experimenting with automated content creation.Thomas Iljic, Director of Product Management at Google Labs, highlights that Veo 3.1’s release brings capabilities closer to how human filmmakers plan and shoot. These include scene composition, continuity across shots, and coordinated audio—all areas that enterprises increasingly look to automate or streamline.Safety and Responsible AI UseVideos generated with Veo 3.1 are watermarked using Google’s SynthID technology, which embeds an imperceptible identifier to signal that the content is AI-generated. Google applies safety filters and moderation across its APIs to help minimize privacy and copyright risks. Generated content is stored temporarily and deleted after two days unless downloaded.For developers and enterprises, these features provide reassurance around provenance and compliance—critical in regulated or brand-sensitive industries.Where Veo 3.1 Stands Among a Crowded AI Video Model SpaceVeo 3.1 is not just an iteration on prior models—it represents a deeper integration of multimodal inputs, storytelling control, and enterprise-level tooling. While creative professionals may see immediate benefits in editing workflows and fidelity, businesses exploring automation in training, advertising, or virtual experiences may find even greater value in the model’s composability and API support.The early user feedback highlights that while Veo 3.1 offers valuable tooling, expectations around realism, voice control, and generation length are evolving rapidly. As Google expands access through Vertex AI and continues refining Veo, its competitive positioning in enterprise video generation will hinge on how quickly these user pain points are addressed.",
          "content": "As expected after days of leaks and rumors online, Google has unveiled Veo 3.1, its latest AI video generation model, bringing a suite of creative and technical upgrades aimed at improving narrative control, audio integration, and realism in AI-generated video. While the updates expand possibilities for hobbyists and content creators using Google’s online AI creation app, Flow, the release also signals a growing opportunity for enterprises, developers, and creative teams seeking scalable, customizable video tools.The quality is higher, the physics better, the pricing the same as before, and the control and editing features more robust and varied.My initial tests showed it to be a powerful and performant model that immediately delights with each generation. However, the look is more cinematic, polished and a little more \"artificial\" than by default than rivals such as OpenAI&#x27;s new Sora 2, released late last month, which may or may not be what a particular user is going after (Sora excels at handheld and \"candid\" style videos). Expanded Control Over Narrative and AudioVeo 3.1 builds on its predecessor, Veo 3 (released back in May 2025) with enhanced support for dialogue, ambient sound, and other audio effects. Native audio generation is now available across several key features in Flow, including “Frames to Video,” “Ingredients to Video,” and “Extend,\" which give users the ability to, respectively: turn still images into video; use items, characters and objects from multiple images in a single video; and generate longer clips than the initial 8 seconds, to more than 30 seconds or even 1+ plus when continuing from a prior clip&#x27;s final frame. Before, you had to add audio manually after using these features. This addition gives users greater command over tone, emotion, and storytelling — capabilities that have previously required post-production work.In enterprise contexts, this level of control may reduce the need for separate audio pipelines, offering an integrated way to create training content, marketing videos, or digital experiences with synchronized sound and visuals.Google noted in a blog post that the updates reflect user feedback calling for deeper artistic control and improved audio support. Gallegos emphasizes the importance of making edits and refinements possible directly in Flow, without reworking scenes from scratch.Richer Inputs and Editing CapabilitiesWith Veo 3.1, Google introduces support for multiple input types and more granular control over generated outputs. The model accepts text prompts, images, and video clips as input, and also supports:Reference images (up to three) to guide appearance and style in the final outputFirst and last frame interpolation to generate seamless scenes between fixed endpointsScene extension that continues a video’s action or motion beyond its current durationThese tools aim to give enterprise users a way to fine-tune the look and feel of their content—useful for brand consistency or adherence to creative briefs.Additional capabilities like “Insert” (add objects to scenes) and “Remove” (delete elements or characters) are also being introduced, though not all are immediately available through the Gemini API.Deployment Across PlatformsVeo 3.1 is accessible through several of Google’s existing AI services:Flow, Google’s own interface for AI-assisted filmmakingGemini API, targeted at developers building video capabilities into applicationsVertex AI, where enterprise integration will soon support Veo’s “Scene Extension” and other key featuresAvailability through these platforms allows enterprise customers to choose the right environment—GUI-based or programmatic—based on their teams and workflows.Pricing and AccessThe Veo 3.1 model is currently in preview and available only on the paid tier of the Gemini API. The cost structure is the same as Veo 3, the preceding generation of AI video models from Google.Standard model: $0.40 per second of videoFast model: $0.15 per secondThere is no free tier, and users are charged only if a video is successfully generated. This model is consistent with previous Veo versions and provides predictable pricing for budget-conscious enterprise teams.Technical Specs and Output ControlVeo 3.1 outputs video at 720p or 1080p resolution, with a 24 fps frame rate. Duration options include 4, 6, or 8 seconds from a text prompt or uploaded images, with the ability to extend videos up to 148 seconds (more than 2 and half minutes!) when using the “Extend” feature.New functionality also includes tighter control over subjects and environments. For example, enterprises can upload a product image or visual reference, and Veo 3.1 will generate scenes that preserve its appearance and stylistic cues across the video. This could streamline creative production pipelines for retail, advertising, and virtual content production teams.Initial ReactionsThe broader creator and developer community has responded to Veo 3.1’s launch with a mix of optimism and tempered critique—particularly when comparing it to rival models like OpenAI’s Sora 2.Matt Shumer, an AI founder of Otherside AI/Hyperwrite, and early adopter, described his initial reaction as “disappointment,” noting that Veo 3.1 is “noticeably worse than Sora 2” and also “quite a bit more expensive.”However, he acknowledged that Google’s tooling—such as support for references and scene extension—is a bright spot in the release.Travis Davids, a 3D digital artist and AI content creator, echoed some of that sentiment. While he noted improvements in audio quality, particularly in sound effects and dialogue, he raised concerns about limitations that remain in the system. These include the lack of custom voice support, an inability to select generated voices directly, and the continued cap at 8-second generations—despite some public claims about longer outputs.Davids also pointed out that character consistency across changing camera angles still requires careful prompting, whereas other models like Sora 2 handle this more automatically. He questioned the absence of 1080p resolution for users on paid tiers like Flow Pro and expressed skepticism over feature parity.On the more positive end, @kimmonismus, an AI newsletter writer, stated that “Veo 3.1 is amazing,” though still concluded that OpenAI’s latest model remains preferable overall.Collectively, these early impressions suggest that while Veo 3.1 delivers meaningful tooling enhancements and new creative control features, expectations have shifted as competitors raise the bar on both quality and usability.Adoption and ScaleSince launching Flow five months ago, Google says over 275 million videos have been generated across various Veo models. The pace of adoption suggests significant interest not only from individuals but also from developers and businesses experimenting with automated content creation.Thomas Iljic, Director of Product Management at Google Labs, highlights that Veo 3.1’s release brings capabilities closer to how human filmmakers plan and shoot. These include scene composition, continuity across shots, and coordinated audio—all areas that enterprises increasingly look to automate or streamline.Safety and Responsible AI UseVideos generated with Veo 3.1 are watermarked using Google’s SynthID technology, which embeds an imperceptible identifier to signal that the content is AI-generated. Google applies safety filters and moderation across its APIs to help minimize privacy and copyright risks. Generated content is stored temporarily and deleted after two days unless downloaded.For developers and enterprises, these features provide reassurance around provenance and compliance—critical in regulated or brand-sensitive industries.Where Veo 3.1 Stands Among a Crowded AI Video Model SpaceVeo 3.1 is not just an iteration on prior models—it represents a deeper integration of multimodal inputs, storytelling control, and enterprise-level tooling. While creative professionals may see immediate benefits in editing workflows and fidelity, businesses exploring automation in training, advertising, or virtual experiences may find even greater value in the model’s composability and API support.The early user feedback highlights that while Veo 3.1 offers valuable tooling, expectations around realism, voice control, and generation length are evolving rapidly. As Google expands access through Vertex AI and continues refining Veo, its competitive positioning in enterprise video generation will hinge on how quickly these user pain points are addressed.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4tvp7qfEbQOW0pucNGc3oW/21a8f215813133c934f9e71c0acff280/Screenshot_2025-10-15_at_2.53.23%C3%A2__PM.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html",
          "published_at": "Wed, 15 Oct 2025 17:13:14 +0000",
          "title": "The best VPN service for 2025",
          "standfirst": "As frustrating as it is that governments and businesses are running roughshod over our online freedoms, at least we have plenty of good VPNs to choose from to keep us protected online. There are so many fast, intelligently designed, full-featured and affordable services on the market that the biggest problem is picking one. For any use case, you can bet at least two providers will be neck-and-neck for first place.On the other hand, the VPN world is still the Wild West in some ways. It's easy enough to slap a cheap VPN together that the market is flooded with low-quality apps that put more money into advertising than infrastructure. They may look good, but it's all styrofoam under the hood.I built this list of the best VPNs after intensive testing to help you reorient your focus on the providers that actually deserve your time and money. Which one truly fits your needs is dependent on who you are and what you do online, but if you pick any of my seven recommendations, you can't go too far wrong.For each VPN on this list, I've shared which platforms it works on, how much it cuts into your download speed, where it offers servers, what other features are included and how much the best available deal costs. At the end, I'll list some honorable and dishonorable mentions, then answer some of the most common questions I hear about VPNs.Editor's note: This list has been completely overhauled and rewritten as of September 2025. We intend to revisit this list every three months at a minimum, at which time our picks may be adjusted based on changes in pricing, features, testing results and other factors. Table of contents Best VPNs for 2025 Other VPNs we tested What to look for in a VPN VPN FAQs Best VPNs for 2025 Other VPNs we tested The VPNs in this section didn't crack our top list above, but we're summarizing them here so you can see their positives and negatives as of the time of our evaluation. Windscribe Windscribe is another well-known free VPN supported by paid subscriptions. In many ways, it takes the best from both Mullvad and Proton VPN, with the former's no-nonsense privacy and the latter's healthy free plan. Without paying, you can connect to 10 of Windscribe's server locations on an unlimited number of devices at once. Unfortunately, Windscribe didn't copy the most important part of Proton VPN's free plan — the unlimited data. You're only allowed to use 10GB per month, which isn't enough for regular streaming. It's also committed to a cramped and headache-inducing user interface that stands out from the crowd in all the worst ways. CyberGhost There's a lot to recommend with CyberGhost. Its streaming-optimized servers meet a high standard for playback quality, it's pretty fast overall and its Smart Rules offer some of the deepest VPN automation on the market. The ad blocker works well, and the NoSpy servers are a neat idea — CyberGhost keeps them under lock and key near its Romania headquarters and carefully fine-tunes all their settings. On the other hand, its apps just aren't up to the standard set by our favorites on this list. I like the designs on paper, but there are too many snags in the experience, from laggy connections to an overactive kill switch that often blocks internet access even when the VPN is working perfectly. I also have some concerns about its commitment to data privacy, since its privacy policy retains the right to share your personal data with its entire corporate family. CyberGhost's parent company, Kape Technologies, also owns ExpressVPN and Private Internet Access, but neither of those VPNs have privacy policies quite so permissive. TunnelBear TunnelBear has a decent interface, which its target audience of VPN beginners will find very easy to use. Its speeds are perfectly good too, and I appreciate the depth and breadth of its transparency reports. But it's far too limited overall, with few extra features, less than 50 server locations and a free plan that caps data at 2GB per month. VyprVPN VyprVPN often flies under the radar, but it has some of the best apps in the business and a very good security record (there was a breach in 2023, but it didn't crack the VPN encryption itself). It's also got a verified privacy policy, a solid jurisdiction and runs every connection through an in-house DNS to prevent leaks. Despite all that, it didn't make the top seven because its connection speeds aren't up to scratch — you'll likely notice a bigger slowdown than average. It also has a troubling history of wild, seemingly experimental swings in its pricing and simultaneous connection limits. Norton VPN Norton VPN is part of the Norton 360 package that includes the well-known antivirus software and other security apps. It's a nice bonus if you use Norton already, but as a standalone VPN, it falls short. My tests repeatedly showed it dropping encryption and revealing my IP address whenever I switched servers, and not all of its locations managed to unblock Netflix. This isn't to say Norton VPN is terrible. It has a fairly large server network, user-friendly apps and some cool features like an IP rotator. It also recently revamped its OpenVPN infrastructure to improve speeds on Windows. But you probably won't find those things sufficient to balance out significant speed drops on other platforms or poorly written FAQs. I especially advise against Norton VPN for Apple users, as its Mac and iPhone apps are much more limited than their Windows and Android counterparts. What to look for in a VPN Choosing a VPN can quickly get you mired in analysis paralysis. We're here to help, but since only you know your particular needs, you should know the major red and green flags so you can make the final call yourself. Every reputable VPN provider offers a free trial or refund guarantee you can use to run the tests below. Compatibility: First, make sure your VPN works on all the platforms you plan to use it on. Most VPNs have apps for Windows, Mac, Android and iOS, but those apps aren't always created equal — check that the app for your chosen OS is user-friendly and has all the features you need. Speed: Use a speed testing app to see how fast your internet is before and after connecting to the VPN (I use Ookla's speedtest.net). To check security, look up your IP address while connected to a VPN server and see if it's actually changed your virtual location. Be sure it's using expert-vetted protocols like OpenVPN, WireGuard and IKEv2. Try connecting to streaming services and seeing whether the VPN changes the available content. Background: Do some outside research into the VPN's origins, especially its parent company, privacy policy and any past incidents. It's a dealbreaker if you can't figure out where the VPN is headquartered (which indicates a lax approach to transparency) or if it seems to have never passed a real third-party audit. Server network: Look at the server network to make sure the VPN has locations near you and in any countries where you'll want an IP address — e.g. if you need a VPN to unblock Canadian Netflix, look for multiple server locations in Canada. Customer Service: I also advise testing the customer support options by looking for the answer to a straightforward question. If phone support (versus email and chat) is important to you, make sure to prioritize that — and make sure it's available at convenient times in your timezone. Pricing: Finally, check prices. See if the VPN is affordable and decide whether you're comfortable taking a long-term subscription for better savings. If you do get a multi-year plan, check what price it will renew at, since many of the cheapest subscriptions are only introductory deals. VPN FAQs To wrap up, let's answer some of the most common questions we get about VPNs. Feel free to get in touch if you have a query I don't cover here. What is a VPN? VPN stands for virtual private network. There are a few different types of VPNs, but for this list, we're talking about commercial services that let individual users access the internet with an assumed identity. Whenever you get online, you're assigned an IP address — a digital nametag that tells websites where to send the information you request. For an IP address to work, it needs to be unique, which means it's possible to create a record of what an individual does online. When you use a VPN, all the data you send to the internet goes through one of the VPN's servers before heading to its final destination. The VPN encrypts the connection between your computer and its server so the data won't trace back to you. Any website, ISP or third party that cares to look will only see the VPN's IP address, not yours. What are some things VPNs are used for? The three main use cases for a commercial VPN are security, privacy and entertainment. Using a VPN conceals your real IP address from anyone who might want to use it for nefarious purposes like cyberstalking, DDoS attacks or deducing your real location. It also keeps your ISP from profiling you for ads based on where you live or what you do online. One side effect of borrowing a VPN's IP address is that you can make it appear as though your connection is coming from another country. You can use this to access streaming content and platforms that are only available in certain regions due to copyright. Changing your location can even get you better prices when shopping online. Location spoofing can also be used to get online in countries that censor internet access, like China and Russia, as well as certain US states or countries — like the UK — that are adding barriers like age-gating to previously unfettered online access. All you have to do is connect to a neighboring country (or locality) where the internet isn't blocked. If you plan to do this while traveling, make sure you have the VPN downloaded before you go, as some nations prevent you from even loading a VPN's homepage. Make sure you check with local laws regarding the legality of VPN use as well — just because your VPN traffic is encrypted doesn't mean that authorities can't detect that it's being used in a given location. Are VPNs worth it? Whether a VPN is worth the price depends on how much you value those three use cases above. It's no secret that your personal information is profitable for a lot of people, from illicit hackers to corporations to law enforcement. A VPN will not make you completely anonymous, nor is it a license to commit crimes (see the next question) but it will give you a lot more control over what you transmit to the world. With entertainment, the value is even clearer. You can use a VPN to fight back against streaming balkanization by getting more shows and movies out of a single platform — for example, a lot of shows that have been kicked off American Netflix are still on Netflix in other countries. What information does a VPN hide? A VPN does not make it impossible for you to be unmasked or taken advantage of online. It prevents you from passively leaking information, keeps your IP address undiscoverable on public wi-fi networks and gets you around online censorship. However, if you share personal information of your own volition, there's nothing the VPN can do. If you reveal your password in a social media post or click a link in a phishing email, that information bypasses the VPN. Likewise, if you do anything sensitive while logged into an account, the account holder will have that information even if you're using a VPN. A VPN is a critical part of your online security, but it can't do the whole job by itself. Healthy passwords, malware scanners, private search engines and common sense all have roles to play. Never forget, too, that using a VPN means trusting the VPN provider with access to information that's concealed from everyone else — make sure you trust the privacy policy before signing up. Are VPNs safe? As far as we can determine, all the VPNs recommended in this story are safe to use. As with anything you subscribe to online, due diligence is important, but there's very little inherent risk; generally, the worst thing a bad VPN will do is fail to work, leaving you no worse off than before. There are some VPNs (usually offered for free) that transmit malware, so always make sure to look up any complaints or warnings about a service before you download it. Can you get a VPN on your phone? Absolutely — almost every VPN has apps for both desktop and mobile devices. A good VPN will redesign its app to be mobile-friendly without dropping too many features. Both iOS and Android natively support VPN connections, so you're free to choose whichever provider you like. What about Google's One VPN? Google One VPN was, as you might expect, a VPN provided by Google. It was launched in 2020 for Google One subscribers and discontinued in 2024 due to lack of use. If you really want a Google VPN, you can still get one if you have certain Pixel models or if you're a Google Fi subscriber. That said, I don't recommend using a VPN from Google even if you do still have access to one. Google is one of the worst big tech companies at protecting user privacy. While its VPN might not leak, I wouldn't trust it to guard your sensitive information.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html?src=rss",
          "content": "As frustrating as it is that governments and businesses are running roughshod over our online freedoms, at least we have plenty of good VPNs to choose from to keep us protected online. There are so many fast, intelligently designed, full-featured and affordable services on the market that the biggest problem is picking one. For any use case, you can bet at least two providers will be neck-and-neck for first place.On the other hand, the VPN world is still the Wild West in some ways. It's easy enough to slap a cheap VPN together that the market is flooded with low-quality apps that put more money into advertising than infrastructure. They may look good, but it's all styrofoam under the hood.I built this list of the best VPNs after intensive testing to help you reorient your focus on the providers that actually deserve your time and money. Which one truly fits your needs is dependent on who you are and what you do online, but if you pick any of my seven recommendations, you can't go too far wrong.For each VPN on this list, I've shared which platforms it works on, how much it cuts into your download speed, where it offers servers, what other features are included and how much the best available deal costs. At the end, I'll list some honorable and dishonorable mentions, then answer some of the most common questions I hear about VPNs.Editor's note: This list has been completely overhauled and rewritten as of September 2025. We intend to revisit this list every three months at a minimum, at which time our picks may be adjusted based on changes in pricing, features, testing results and other factors. Table of contents Best VPNs for 2025 Other VPNs we tested What to look for in a VPN VPN FAQs Best VPNs for 2025 Other VPNs we tested The VPNs in this section didn't crack our top list above, but we're summarizing them here so you can see their positives and negatives as of the time of our evaluation. Windscribe Windscribe is another well-known free VPN supported by paid subscriptions. In many ways, it takes the best from both Mullvad and Proton VPN, with the former's no-nonsense privacy and the latter's healthy free plan. Without paying, you can connect to 10 of Windscribe's server locations on an unlimited number of devices at once. Unfortunately, Windscribe didn't copy the most important part of Proton VPN's free plan — the unlimited data. You're only allowed to use 10GB per month, which isn't enough for regular streaming. It's also committed to a cramped and headache-inducing user interface that stands out from the crowd in all the worst ways. CyberGhost There's a lot to recommend with CyberGhost. Its streaming-optimized servers meet a high standard for playback quality, it's pretty fast overall and its Smart Rules offer some of the deepest VPN automation on the market. The ad blocker works well, and the NoSpy servers are a neat idea — CyberGhost keeps them under lock and key near its Romania headquarters and carefully fine-tunes all their settings. On the other hand, its apps just aren't up to the standard set by our favorites on this list. I like the designs on paper, but there are too many snags in the experience, from laggy connections to an overactive kill switch that often blocks internet access even when the VPN is working perfectly. I also have some concerns about its commitment to data privacy, since its privacy policy retains the right to share your personal data with its entire corporate family. CyberGhost's parent company, Kape Technologies, also owns ExpressVPN and Private Internet Access, but neither of those VPNs have privacy policies quite so permissive. TunnelBear TunnelBear has a decent interface, which its target audience of VPN beginners will find very easy to use. Its speeds are perfectly good too, and I appreciate the depth and breadth of its transparency reports. But it's far too limited overall, with few extra features, less than 50 server locations and a free plan that caps data at 2GB per month. VyprVPN VyprVPN often flies under the radar, but it has some of the best apps in the business and a very good security record (there was a breach in 2023, but it didn't crack the VPN encryption itself). It's also got a verified privacy policy, a solid jurisdiction and runs every connection through an in-house DNS to prevent leaks. Despite all that, it didn't make the top seven because its connection speeds aren't up to scratch — you'll likely notice a bigger slowdown than average. It also has a troubling history of wild, seemingly experimental swings in its pricing and simultaneous connection limits. Norton VPN Norton VPN is part of the Norton 360 package that includes the well-known antivirus software and other security apps. It's a nice bonus if you use Norton already, but as a standalone VPN, it falls short. My tests repeatedly showed it dropping encryption and revealing my IP address whenever I switched servers, and not all of its locations managed to unblock Netflix. This isn't to say Norton VPN is terrible. It has a fairly large server network, user-friendly apps and some cool features like an IP rotator. It also recently revamped its OpenVPN infrastructure to improve speeds on Windows. But you probably won't find those things sufficient to balance out significant speed drops on other platforms or poorly written FAQs. I especially advise against Norton VPN for Apple users, as its Mac and iPhone apps are much more limited than their Windows and Android counterparts. What to look for in a VPN Choosing a VPN can quickly get you mired in analysis paralysis. We're here to help, but since only you know your particular needs, you should know the major red and green flags so you can make the final call yourself. Every reputable VPN provider offers a free trial or refund guarantee you can use to run the tests below. Compatibility: First, make sure your VPN works on all the platforms you plan to use it on. Most VPNs have apps for Windows, Mac, Android and iOS, but those apps aren't always created equal — check that the app for your chosen OS is user-friendly and has all the features you need. Speed: Use a speed testing app to see how fast your internet is before and after connecting to the VPN (I use Ookla's speedtest.net). To check security, look up your IP address while connected to a VPN server and see if it's actually changed your virtual location. Be sure it's using expert-vetted protocols like OpenVPN, WireGuard and IKEv2. Try connecting to streaming services and seeing whether the VPN changes the available content. Background: Do some outside research into the VPN's origins, especially its parent company, privacy policy and any past incidents. It's a dealbreaker if you can't figure out where the VPN is headquartered (which indicates a lax approach to transparency) or if it seems to have never passed a real third-party audit. Server network: Look at the server network to make sure the VPN has locations near you and in any countries where you'll want an IP address — e.g. if you need a VPN to unblock Canadian Netflix, look for multiple server locations in Canada. Customer Service: I also advise testing the customer support options by looking for the answer to a straightforward question. If phone support (versus email and chat) is important to you, make sure to prioritize that — and make sure it's available at convenient times in your timezone. Pricing: Finally, check prices. See if the VPN is affordable and decide whether you're comfortable taking a long-term subscription for better savings. If you do get a multi-year plan, check what price it will renew at, since many of the cheapest subscriptions are only introductory deals. VPN FAQs To wrap up, let's answer some of the most common questions we get about VPNs. Feel free to get in touch if you have a query I don't cover here. What is a VPN? VPN stands for virtual private network. There are a few different types of VPNs, but for this list, we're talking about commercial services that let individual users access the internet with an assumed identity. Whenever you get online, you're assigned an IP address — a digital nametag that tells websites where to send the information you request. For an IP address to work, it needs to be unique, which means it's possible to create a record of what an individual does online. When you use a VPN, all the data you send to the internet goes through one of the VPN's servers before heading to its final destination. The VPN encrypts the connection between your computer and its server so the data won't trace back to you. Any website, ISP or third party that cares to look will only see the VPN's IP address, not yours. What are some things VPNs are used for? The three main use cases for a commercial VPN are security, privacy and entertainment. Using a VPN conceals your real IP address from anyone who might want to use it for nefarious purposes like cyberstalking, DDoS attacks or deducing your real location. It also keeps your ISP from profiling you for ads based on where you live or what you do online. One side effect of borrowing a VPN's IP address is that you can make it appear as though your connection is coming from another country. You can use this to access streaming content and platforms that are only available in certain regions due to copyright. Changing your location can even get you better prices when shopping online. Location spoofing can also be used to get online in countries that censor internet access, like China and Russia, as well as certain US states or countries — like the UK — that are adding barriers like age-gating to previously unfettered online access. All you have to do is connect to a neighboring country (or locality) where the internet isn't blocked. If you plan to do this while traveling, make sure you have the VPN downloaded before you go, as some nations prevent you from even loading a VPN's homepage. Make sure you check with local laws regarding the legality of VPN use as well — just because your VPN traffic is encrypted doesn't mean that authorities can't detect that it's being used in a given location. Are VPNs worth it? Whether a VPN is worth the price depends on how much you value those three use cases above. It's no secret that your personal information is profitable for a lot of people, from illicit hackers to corporations to law enforcement. A VPN will not make you completely anonymous, nor is it a license to commit crimes (see the next question) but it will give you a lot more control over what you transmit to the world. With entertainment, the value is even clearer. You can use a VPN to fight back against streaming balkanization by getting more shows and movies out of a single platform — for example, a lot of shows that have been kicked off American Netflix are still on Netflix in other countries. What information does a VPN hide? A VPN does not make it impossible for you to be unmasked or taken advantage of online. It prevents you from passively leaking information, keeps your IP address undiscoverable on public wi-fi networks and gets you around online censorship. However, if you share personal information of your own volition, there's nothing the VPN can do. If you reveal your password in a social media post or click a link in a phishing email, that information bypasses the VPN. Likewise, if you do anything sensitive while logged into an account, the account holder will have that information even if you're using a VPN. A VPN is a critical part of your online security, but it can't do the whole job by itself. Healthy passwords, malware scanners, private search engines and common sense all have roles to play. Never forget, too, that using a VPN means trusting the VPN provider with access to information that's concealed from everyone else — make sure you trust the privacy policy before signing up. Are VPNs safe? As far as we can determine, all the VPNs recommended in this story are safe to use. As with anything you subscribe to online, due diligence is important, but there's very little inherent risk; generally, the worst thing a bad VPN will do is fail to work, leaving you no worse off than before. There are some VPNs (usually offered for free) that transmit malware, so always make sure to look up any complaints or warnings about a service before you download it. Can you get a VPN on your phone? Absolutely — almost every VPN has apps for both desktop and mobile devices. A good VPN will redesign its app to be mobile-friendly without dropping too many features. Both iOS and Android natively support VPN connections, so you're free to choose whichever provider you like. What about Google's One VPN? Google One VPN was, as you might expect, a VPN provided by Google. It was launched in 2020 for Google One subscribers and discontinued in 2024 due to lack of use. If you really want a Google VPN, you can still get one if you have certain Pixel models or if you're a Google Fi subscriber. That said, I don't recommend using a VPN from Google even if you do still have access to one. Google is one of the worst big tech companies at protecting user privacy. While its VPN might not leak, I wouldn't trust it to guard your sensitive information.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/best-vpn-130004396.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/ball-x-pits-deeply-satisfying-grind-keeps-me-coming-back-for-more-171000754.html",
          "published_at": "Wed, 15 Oct 2025 17:10:00 +0000",
          "title": "Ball x Pit's deeply satisfying grind keeps me coming back for more",
          "standfirst": "For as long as I can remember, I've had trouble going to sleep. When I lay down, my mind inevitably starts racing a thousand miles an hour, thinking about anything and everything. On several recent nights, though, my pre-slumber thoughts had a singular focus. I mulled over possibilities like, \"What if I fuse a ball that heals my character with one that splits into smaller balls with the same effect, and add a passive that fires a baby ball every time I'm healed?\" Then I grab my PlayStation Portal and do just that until I doze off. This is the hold Ball x Pit has had over me. Kenny Sun and a small group of collaborators have cooked up a mesmerizing brick-breaking roguelite. Ball x Pit is a blend of dual-stick shoot-'em-up action, base building and about a dozen other things that keeps calling me back for one more run... and another, and another.After a cataclysmic event wipes out the city of Ballbylon and leaves an enormous pit, hunters descend into the depths in search of treasure. For our purposes, this means playing levels to collect resources in order to build structures in New Ballbylon. These buildings unlock perks, such as new characters, that help with future runs. The sickly chaos of the levels and the calmer city building aspect feed into each other smartly and combine for a satisfying loop.Base building in Ball x PitKenny Sun/Devolver DigitalThat’s not the only important interplay here. Like any good roguelite, Ball x Pit is all about finding synergies for maximum impact. It's right there in the title, with the \"x\" denoting a relationship between two things (it's derived from shipping in fandom parlance). In the pit, you battle monsters by — surprise! — firing balls at them. Along with regular “baby balls,” each character has a unique ability and a special starter ball. In the vein of Vampire Survivors, you'll unlock more special balls and passive abilities when you collect enough gems to level up. One ball has a chance to freeze enemies and another is slower but deals much more damage. There are dozens of others.The real fun comes in when you start fusing these balls and their effects together, freeing up space for another weapon. It gets even better when you're able to evolve a pair of balls into something new. It's possible to fuse evolved balls, or even evolve them again. There’s a strategic aspect to this, as you won’t want to fuse balls that can nearly cancel each other out, such as merging an area-of-effect ball with one that disappears on impact, or leave yourself with too few balls in the face of danger.Once I unlocked the option to take two characters on a run and combine their passive abilities, that's where things went into overdrive. The possibilities became very exciting at this point, and I ended up playing Ball x Pit way past my ideal bedtime as a result.It does take a while to get to that point, though. Progression is slow at first. The repetition can get to be a little much as you need to beat each stage multiple times before moving onto the next. Also, I wish there was a bit more to the game narratively than a basic setup and some character descriptions. But there's so much to consider on each run, and that’s what keeps me coming back. Each of the nine levels is set in a different biome, with its own hazards, enemies and bosses. Some late-game characters turn the game on its head by shifting playstyles in surprising ways, but I don't want to spoil those. Along with the absolute chaos and dopamine hits of slicing through enemies, discovering killer combinations between characters, special balls — especially the evolutions — and passives drives so much of the joy of this game.Whenever you do fuse or evolve a pair of balls, rather than having to click an \"OK\" button to get back in the action, the prompt reads \"Whoa.\" That's on the nose, but funny. And I'll be damned if I didn't say that very thing out loud many times when I saw what a new evolved ball could do. Ball x Pit is out now on Steam, PS5, Xbox Series X/S and Nintendo Switch for $15. It's available via Game Pass Ultimate and PC Game Pass. A Nintendo Switch 2 version is coming later this fall with a free upgrade from the Switch version.This article originally appeared on Engadget at https://www.engadget.com/gaming/ball-x-pits-deeply-satisfying-grind-keeps-me-coming-back-for-more-171000754.html?src=rss",
          "content": "For as long as I can remember, I've had trouble going to sleep. When I lay down, my mind inevitably starts racing a thousand miles an hour, thinking about anything and everything. On several recent nights, though, my pre-slumber thoughts had a singular focus. I mulled over possibilities like, \"What if I fuse a ball that heals my character with one that splits into smaller balls with the same effect, and add a passive that fires a baby ball every time I'm healed?\" Then I grab my PlayStation Portal and do just that until I doze off. This is the hold Ball x Pit has had over me. Kenny Sun and a small group of collaborators have cooked up a mesmerizing brick-breaking roguelite. Ball x Pit is a blend of dual-stick shoot-'em-up action, base building and about a dozen other things that keeps calling me back for one more run... and another, and another.After a cataclysmic event wipes out the city of Ballbylon and leaves an enormous pit, hunters descend into the depths in search of treasure. For our purposes, this means playing levels to collect resources in order to build structures in New Ballbylon. These buildings unlock perks, such as new characters, that help with future runs. The sickly chaos of the levels and the calmer city building aspect feed into each other smartly and combine for a satisfying loop.Base building in Ball x PitKenny Sun/Devolver DigitalThat’s not the only important interplay here. Like any good roguelite, Ball x Pit is all about finding synergies for maximum impact. It's right there in the title, with the \"x\" denoting a relationship between two things (it's derived from shipping in fandom parlance). In the pit, you battle monsters by — surprise! — firing balls at them. Along with regular “baby balls,” each character has a unique ability and a special starter ball. In the vein of Vampire Survivors, you'll unlock more special balls and passive abilities when you collect enough gems to level up. One ball has a chance to freeze enemies and another is slower but deals much more damage. There are dozens of others.The real fun comes in when you start fusing these balls and their effects together, freeing up space for another weapon. It gets even better when you're able to evolve a pair of balls into something new. It's possible to fuse evolved balls, or even evolve them again. There’s a strategic aspect to this, as you won’t want to fuse balls that can nearly cancel each other out, such as merging an area-of-effect ball with one that disappears on impact, or leave yourself with too few balls in the face of danger.Once I unlocked the option to take two characters on a run and combine their passive abilities, that's where things went into overdrive. The possibilities became very exciting at this point, and I ended up playing Ball x Pit way past my ideal bedtime as a result.It does take a while to get to that point, though. Progression is slow at first. The repetition can get to be a little much as you need to beat each stage multiple times before moving onto the next. Also, I wish there was a bit more to the game narratively than a basic setup and some character descriptions. But there's so much to consider on each run, and that’s what keeps me coming back. Each of the nine levels is set in a different biome, with its own hazards, enemies and bosses. Some late-game characters turn the game on its head by shifting playstyles in surprising ways, but I don't want to spoil those. Along with the absolute chaos and dopamine hits of slicing through enemies, discovering killer combinations between characters, special balls — especially the evolutions — and passives drives so much of the joy of this game.Whenever you do fuse or evolve a pair of balls, rather than having to click an \"OK\" button to get back in the action, the prompt reads \"Whoa.\" That's on the nose, but funny. And I'll be damned if I didn't say that very thing out loud many times when I saw what a new evolved ball could do. Ball x Pit is out now on Steam, PS5, Xbox Series X/S and Nintendo Switch for $15. It's available via Game Pass Ultimate and PC Game Pass. A Nintendo Switch 2 version is coming later this fall with a free upgrade from the Switch version.This article originally appeared on Engadget at https://www.engadget.com/gaming/ball-x-pits-deeply-satisfying-grind-keeps-me-coming-back-for-more-171000754.html?src=rss",
          "feed_position": 2,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/ball_x_pit_base.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-cancel-proton-vpn-and-get-a-refund-170014128.html",
          "published_at": "Wed, 15 Oct 2025 17:00:14 +0000",
          "title": "How to cancel Proton VPN and get a refund",
          "standfirst": "Proton VPN currently tops my list of the best VPNs, and I gave it a glowing recommendation in my detailed Proton VPN review. It's easy to use, fast, cheap and secure, with a large server network and one of the industry's best scores at unblocking streaming sites. All that said, there's no such thing as a perfect VPN, and you may find that Proton isn't working for you. If that happens, here's how to cancel your subscription. How to cancel Proton VPN through a browser If you initially signed up less than 30 days ago, you can cancel your subscription and request a refund by contacting tech support. See \"How to get a refund from Proton VPN\" below for details. If more than 30 days have passed, use the following steps to cancel your subscription. Open your browser and go to protonvpn.com. At the top-right, click Sign in, then enter your username and password. You'll be taken to your account dashboard. At the left side of the dashboard, click the Subscription tab. Scroll all the way down to the section labeled Cancel subscription. Click the \"Continue\" button. A pop-up window will appear, asking if you're sure. Click Cancel subscription. Sam Chapman for Engadget Cancelling this way doesn't immediately terminate service — it just means your subscription won't auto-renew. You can still use Proton VPN's paid features, including the entire server network, until the current period expires. After that, you'll be automatically downgraded to the free plan. During this time, your account dashboard will still be active, so you can use it to turn renewal back on if you change your mind. This method also works in mobile browser apps. Just follow the same steps on your mobile device and you'll cancel in the same way, with service continuing until your subscription expires. How to downgrade from Proton Unlimited to Proton VPN only A Proton Unlimited subscription applies to all Proton products. Since it's mainly founded on Proton Mail, though, downgrading to VPN service only is tricky and requires some extra steps. First, downgrade Proton Unlimited to Proton Free from your main account dashboard. Log in at account.proton.me, then click Settings, All settings, Dashboard and Your plan. Under \"Proton Unlimited,\" click Explore other Proton plans. On the next page, select Proton Free. This will effectively cancel Proton Unlimited, though you can still use it until the end of the pay period. Finally, go to the Proton VPN website (not the overall Proton site) and sign up for a Proton VPN Plus plan. Since you downgraded instead of deleting your account, you should be able to use the same account address. How to delete your Proton account on mobile You can also use the mobile app to delete your entire Proton account, instantly and irreversibly ending your subscriptions to Proton VPN, Proton Mail and any other products in the line. Taking this action permanently burns your Proton username, so you won't be able to use it again if you decide to re-subscribe (in that case, you’ll just have to make a new one). The process is the same on both Android and iOS — the apps have slight cosmetic differences, but everything is in the same place. Follow the steps below to nuke your Proton account from orbit. Open the Proton VPN app on your Android phone. Click Settings at the bottom of the window. At the top of the settings page, click your account email address. This will take you to Account settings. Click Delete account. A window will open in your web browser, showing your general Proton account page. Scroll down to the bottom of this page and click the red Delete your account button. Select a reason for deleting your account and leave feedback in the box provided. You have to pick an option from the menu and type at least 10 characters in the box, though feel free to keyboard mash if you don't want to say anything. Check the box on the next page beside \"Yes, I want to permanently delete this account and all its data.\" Finally, click the red Delete account button. Sam Chapman for Engadget How to get a refund from Proton VPN Proton VPN has a 30-day refund policy. As long as you paid for your VPN less than 30 days ago, you can get your money back. To request a refund, send a message through the contact form on the website. You can also email protonvpn@support.zendesk.com. There's a minimum of 100 characters in the \"What happened?\" box. Unlike when you're simply deleting your account, I do recommend putting a brief real answer here, clearly stating that you would like to cancel your account and receive a refund. Sam Chapman for Engadget According to its terms of service, Proton will only refund you for the portion of the service you didn't use. If you spend $10 for a one-month subscription and cancel after 15 days, you'll get $5 back. The terms do state that the company \"may also provide you with a full refund upon request\" — directly asking for such a refund in your contact form makes this more likely. If you cancel after 30 days are up, you may still be able to get a prorated payment for your remaining time, either in cash or account credit. You'll have to ask for this specifically, as the default option is that your account just stays active until it runs out. What to do if you subscribed through an app store If you bought your Proton VPN subscription through the Apple App Store or Google Play Store, then Apple or Google processed your money and you're subject to their refund policies. If you subscribed through Apple, go to your Apple ID profile in iOS settings, click on Subscriptions, scroll to Proton VPN and click on Cancel subscription. You'll then get the opportunity to request a refund. On Android, log into the Google Play Store, click on your profile picture, then click Manage subscriptions. Find Proton VPN, click Cancel subscription and provide a reason. As with iOS, the steps will walk you through the refund process. Proton VPN alternatives Once you've fully cancelled Proton VPN, you may be in the market for an alternative. I recommend a few of my other favorites, depending on why Proton didn't work for you. Surfshark is faster, ExpressVPN has some of the best app design and NordVPN has a wider range of interesting features.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-proton-vpn-and-get-a-refund-170014128.html?src=rss",
          "content": "Proton VPN currently tops my list of the best VPNs, and I gave it a glowing recommendation in my detailed Proton VPN review. It's easy to use, fast, cheap and secure, with a large server network and one of the industry's best scores at unblocking streaming sites. All that said, there's no such thing as a perfect VPN, and you may find that Proton isn't working for you. If that happens, here's how to cancel your subscription. How to cancel Proton VPN through a browser If you initially signed up less than 30 days ago, you can cancel your subscription and request a refund by contacting tech support. See \"How to get a refund from Proton VPN\" below for details. If more than 30 days have passed, use the following steps to cancel your subscription. Open your browser and go to protonvpn.com. At the top-right, click Sign in, then enter your username and password. You'll be taken to your account dashboard. At the left side of the dashboard, click the Subscription tab. Scroll all the way down to the section labeled Cancel subscription. Click the \"Continue\" button. A pop-up window will appear, asking if you're sure. Click Cancel subscription. Sam Chapman for Engadget Cancelling this way doesn't immediately terminate service — it just means your subscription won't auto-renew. You can still use Proton VPN's paid features, including the entire server network, until the current period expires. After that, you'll be automatically downgraded to the free plan. During this time, your account dashboard will still be active, so you can use it to turn renewal back on if you change your mind. This method also works in mobile browser apps. Just follow the same steps on your mobile device and you'll cancel in the same way, with service continuing until your subscription expires. How to downgrade from Proton Unlimited to Proton VPN only A Proton Unlimited subscription applies to all Proton products. Since it's mainly founded on Proton Mail, though, downgrading to VPN service only is tricky and requires some extra steps. First, downgrade Proton Unlimited to Proton Free from your main account dashboard. Log in at account.proton.me, then click Settings, All settings, Dashboard and Your plan. Under \"Proton Unlimited,\" click Explore other Proton plans. On the next page, select Proton Free. This will effectively cancel Proton Unlimited, though you can still use it until the end of the pay period. Finally, go to the Proton VPN website (not the overall Proton site) and sign up for a Proton VPN Plus plan. Since you downgraded instead of deleting your account, you should be able to use the same account address. How to delete your Proton account on mobile You can also use the mobile app to delete your entire Proton account, instantly and irreversibly ending your subscriptions to Proton VPN, Proton Mail and any other products in the line. Taking this action permanently burns your Proton username, so you won't be able to use it again if you decide to re-subscribe (in that case, you’ll just have to make a new one). The process is the same on both Android and iOS — the apps have slight cosmetic differences, but everything is in the same place. Follow the steps below to nuke your Proton account from orbit. Open the Proton VPN app on your Android phone. Click Settings at the bottom of the window. At the top of the settings page, click your account email address. This will take you to Account settings. Click Delete account. A window will open in your web browser, showing your general Proton account page. Scroll down to the bottom of this page and click the red Delete your account button. Select a reason for deleting your account and leave feedback in the box provided. You have to pick an option from the menu and type at least 10 characters in the box, though feel free to keyboard mash if you don't want to say anything. Check the box on the next page beside \"Yes, I want to permanently delete this account and all its data.\" Finally, click the red Delete account button. Sam Chapman for Engadget How to get a refund from Proton VPN Proton VPN has a 30-day refund policy. As long as you paid for your VPN less than 30 days ago, you can get your money back. To request a refund, send a message through the contact form on the website. You can also email protonvpn@support.zendesk.com. There's a minimum of 100 characters in the \"What happened?\" box. Unlike when you're simply deleting your account, I do recommend putting a brief real answer here, clearly stating that you would like to cancel your account and receive a refund. Sam Chapman for Engadget According to its terms of service, Proton will only refund you for the portion of the service you didn't use. If you spend $10 for a one-month subscription and cancel after 15 days, you'll get $5 back. The terms do state that the company \"may also provide you with a full refund upon request\" — directly asking for such a refund in your contact form makes this more likely. If you cancel after 30 days are up, you may still be able to get a prorated payment for your remaining time, either in cash or account credit. You'll have to ask for this specifically, as the default option is that your account just stays active until it runs out. What to do if you subscribed through an app store If you bought your Proton VPN subscription through the Apple App Store or Google Play Store, then Apple or Google processed your money and you're subject to their refund policies. If you subscribed through Apple, go to your Apple ID profile in iOS settings, click on Subscriptions, scroll to Proton VPN and click on Cancel subscription. You'll then get the opportunity to request a refund. On Android, log into the Google Play Store, click on your profile picture, then click Manage subscriptions. Find Proton VPN, click Cancel subscription and provide a reason. As with iOS, the steps will walk you through the refund process. Proton VPN alternatives Once you've fully cancelled Proton VPN, you may be in the market for an alternative. I recommend a few of my other favorites, depending on why Proton didn't work for you. Surfshark is faster, ExpressVPN has some of the best app design and NordVPN has a wider range of interesting features.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-proton-vpn-and-get-a-refund-170014128.html?src=rss",
          "feed_position": 3,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/f5cc5570-a9d6-11f0-bbdf-90572b26b776"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/vsco-adds-its-first-ai-powered-photo-editing-tool-170000055.html",
          "published_at": "Wed, 15 Oct 2025 17:00:00 +0000",
          "title": "VSCO adds its first AI-powered photo editing tool",
          "standfirst": "The VSCO photo editing and sharing app has been around for nearly as long as Instagram, positioning itself as the serious photographer’s choice for mobile editing. The original focus was on tasteful filters and editing tools, all of which got significantly more powerful and flexible over time; VSCO has long been doing the same sort of film emulations that have made Fujifilm’s cameras so desirable in recent years. The company also built up a loyal community of photographers who share their edits far and wide, both in the VSCO app as well as on more mainstream platforms like Instagram itself. Now, the company is making an unsurprising but potentially controversial move: it is releasing its first AI-powered image editing tool. “Remove,” as the name suggests, lets you erase “unwanted elements” from your photos without compromising the image’s full resolution. At first glance, it feels quite similar to tools like Google’s own Magic Eraser. You just pop open an image in the editor and highlight the portion you want to remove, and VSCO will do its best to obliterate the offending bits and fill in whatever is in the background that it deems appropriate. I haven’t had a chance to test how effective this tool is yet, but VSCO is using Black Forest Lab’s FLUX.1 Kontext model to do its magic, combined with its own proprietary technology specifically focused on making results that the company says look authentic. A quick look at Black Forest Lab and the FLUX.1 model show a tool that does appear to be well-suited to removing unwanted parts of an image and properly filling in the space that remains — but we’ll have to see it in action to judge whether it does the job well.This new Remove tool isn’t the only AI-powered editor VSCO is working on. There’s also an Upscale tool in the works that the company says will “enhance image resolution” while keeping color and composition unchanged. These sorts of tools will live under a new umbrella the company is calling AI Lab, making it clear this will be an ongoing initiative and not just a one-off release.On one hand, I’m not at all surprised to see VSCO jumping into AI-powered editing; it has to keep up with the rest of the industry. But on the other hand, the company has made its mark by building a community of photographers who value authenticity in their work, something that cannot help but be in conflict with AI tools, at least on the surface.VSCO’s CEO Eric Wittman acknowledged that tension in a conversation with Engadget. “We have a very photographer-centric, creator-first point of view,” Wittman said. “But where we see AI fitting in is in support of those folks, and that work, and that vision. The intention isn’t to replace [that work], though — AI has a place, but it’s not to replace what creators, and photographers in particular, are doing.” That mindset makes sense with something like Remove, which duplicates something people have done with Photoshop for years. Rather than generating new images or radically changing the truth of a photo like you can do with some of Google’s tools on the Pixel phones, Remove is a bit more subtle. “You would use masks, you would manually painstakingly edit things at a pixel by pixel level,” Wittman said. “What a lot of Remove tools would do is basically like automate that.”Wittman also cited preserving image quality as a key part of the work behind its own Remove tool. “We know that many people who were attempting to use AI in the early days, especially photographers, a lot of their disappointment was just in the preservation of the integrity and the quality of the work,” he said. “So what we've really tried to do is continue to help automate where we can and make things easier, but also preserve the quality.” To that end, VSCO is stressing that all these edits are non-destructive and the output will be in full, original resolution. As VSCO starts dabbling in more AI editing tools, Wittman emphasized that the company wants to stay on the side of helping photographers realize a creative vision rather than helping them make entirely unreal images, while also avoiding the mess of copyright issues and inauthentic content that is flooding the internet thanks to AI. “When you think about things like copyright, and the incredible importance of copyright, integrity, and authenticity — we're big believers as a company in both the laws and the norms that have been around for many many years. But obviously on some platforms there are people who are maliciously manipulating things, and we don't want to be participants in that.”VSCO’s first AI Labs feature is available as of today in the VSCO app for iOS; it should come to Android eventually but there’s no word yet on specific timing. To use it, you’ll need an active VSCO Pro subscription, which runs $13 per month or $60 a year. A Pro plans contains a ton more than just AI Labs features, though — it unlocks a full editing suite on mobile and the web, professional profile and website creation, hundreds of presets and film emulation settings and a lot more. This article originally appeared on Engadget at https://www.engadget.com/apps/vsco-adds-its-first-ai-powered-photo-editing-tool-170000055.html?src=rss",
          "content": "The VSCO photo editing and sharing app has been around for nearly as long as Instagram, positioning itself as the serious photographer’s choice for mobile editing. The original focus was on tasteful filters and editing tools, all of which got significantly more powerful and flexible over time; VSCO has long been doing the same sort of film emulations that have made Fujifilm’s cameras so desirable in recent years. The company also built up a loyal community of photographers who share their edits far and wide, both in the VSCO app as well as on more mainstream platforms like Instagram itself. Now, the company is making an unsurprising but potentially controversial move: it is releasing its first AI-powered image editing tool. “Remove,” as the name suggests, lets you erase “unwanted elements” from your photos without compromising the image’s full resolution. At first glance, it feels quite similar to tools like Google’s own Magic Eraser. You just pop open an image in the editor and highlight the portion you want to remove, and VSCO will do its best to obliterate the offending bits and fill in whatever is in the background that it deems appropriate. I haven’t had a chance to test how effective this tool is yet, but VSCO is using Black Forest Lab’s FLUX.1 Kontext model to do its magic, combined with its own proprietary technology specifically focused on making results that the company says look authentic. A quick look at Black Forest Lab and the FLUX.1 model show a tool that does appear to be well-suited to removing unwanted parts of an image and properly filling in the space that remains — but we’ll have to see it in action to judge whether it does the job well.This new Remove tool isn’t the only AI-powered editor VSCO is working on. There’s also an Upscale tool in the works that the company says will “enhance image resolution” while keeping color and composition unchanged. These sorts of tools will live under a new umbrella the company is calling AI Lab, making it clear this will be an ongoing initiative and not just a one-off release.On one hand, I’m not at all surprised to see VSCO jumping into AI-powered editing; it has to keep up with the rest of the industry. But on the other hand, the company has made its mark by building a community of photographers who value authenticity in their work, something that cannot help but be in conflict with AI tools, at least on the surface.VSCO’s CEO Eric Wittman acknowledged that tension in a conversation with Engadget. “We have a very photographer-centric, creator-first point of view,” Wittman said. “But where we see AI fitting in is in support of those folks, and that work, and that vision. The intention isn’t to replace [that work], though — AI has a place, but it’s not to replace what creators, and photographers in particular, are doing.” That mindset makes sense with something like Remove, which duplicates something people have done with Photoshop for years. Rather than generating new images or radically changing the truth of a photo like you can do with some of Google’s tools on the Pixel phones, Remove is a bit more subtle. “You would use masks, you would manually painstakingly edit things at a pixel by pixel level,” Wittman said. “What a lot of Remove tools would do is basically like automate that.”Wittman also cited preserving image quality as a key part of the work behind its own Remove tool. “We know that many people who were attempting to use AI in the early days, especially photographers, a lot of their disappointment was just in the preservation of the integrity and the quality of the work,” he said. “So what we've really tried to do is continue to help automate where we can and make things easier, but also preserve the quality.” To that end, VSCO is stressing that all these edits are non-destructive and the output will be in full, original resolution. As VSCO starts dabbling in more AI editing tools, Wittman emphasized that the company wants to stay on the side of helping photographers realize a creative vision rather than helping them make entirely unreal images, while also avoiding the mess of copyright issues and inauthentic content that is flooding the internet thanks to AI. “When you think about things like copyright, and the incredible importance of copyright, integrity, and authenticity — we're big believers as a company in both the laws and the norms that have been around for many many years. But obviously on some platforms there are people who are maliciously manipulating things, and we don't want to be participants in that.”VSCO’s first AI Labs feature is available as of today in the VSCO app for iOS; it should come to Android eventually but there’s no word yet on specific timing. To use it, you’ll need an active VSCO Pro subscription, which runs $13 per month or $60 a year. A Pro plans contains a ton more than just AI Labs features, though — it unlocks a full editing suite on mobile and the web, professional profile and website creation, hundreds of presets and film emulation settings and a lot more. This article originally appeared on Engadget at https://www.engadget.com/apps/vsco-adds-its-first-ai-powered-photo-editing-tool-170000055.html?src=rss",
          "feed_position": 4
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/apples-long-rumored-smart-display-will-reportedly-cost-350-165801748.html",
          "published_at": "Wed, 15 Oct 2025 16:58:01 +0000",
          "title": "Apple's long-rumored smart display will reportedly cost $350",
          "standfirst": "Apple has been expected to widen its smart home offering for a long time now, and if a new report is accurate, we could be getting a trio of new devices fairly soon. According to Bloomberg, Apple is working on an indoor camera and a smart display to arrive in 2026, as well as a tabletop robot, with the latter expected to launch in 2027. An Apple-made smart display in particular has featured heavily in the rumor mill for a number of years, but it appears to be closer than ever. Bloomberg’s Mark Gurman reports that Apple’s new home hub will have a 7-inch square LCD display, a built-in FaceTime camera and an OS that dynamically adjusts depending on who’s using it. It will also ship with an improved version of Siri that will behave more like ChatGPT or other chatbots in how it uses the web to answer your questions. The product, along with the more advanced Siri chatbot, had been slated for release earlier this year, but Apple reportedly scrapped those plans in favor of a spring 2026 launch. Bloomberg claims there will be two versions of the home hub, one code-named J940 which takes the form of a display mounted on a HomePod mini-like speaker, and the other (J491) designed to be hung on a wall. With both you’ll be able to control smart appliances, play music and presumably interact with Apple’s various apps on other devices. Apple is said to be targeting a price of around $350, although the Bloomberg report does not specify which version of the device that price refers to. The tabletop robot scheduled to launch in 2027 will effectively be the smart display Apple could be releasing next year mounted into a motorized arm that can move the device to different positions, which sounds like the company’s take on Amazon’s (slightly creepy) swivelling Echo Show 10, first launched in 2021. This product will have a larger 9-inch display, but is said to be delayed after Apple encountered engineering challenges with the motor. Bloomberg reports that all three of these devices will be built in Vietnam, which sources said represented a \"major change\" in how Apple launches a new product category, as it has traditionally relied on China at the outset. In 2020 it emerged that Apple was looking to diversify its production by moving some of its iPad and MacBook manufacturing to Vietnam, and the US’ trade war with China has only intensified during Trump’s second administration. Vietnam has not escaped tariffs of its own, but they’re less severe than imports from China.This article originally appeared on Engadget at https://www.engadget.com/home/apples-long-rumored-smart-display-will-reportedly-cost-350-165801748.html?src=rss",
          "content": "Apple has been expected to widen its smart home offering for a long time now, and if a new report is accurate, we could be getting a trio of new devices fairly soon. According to Bloomberg, Apple is working on an indoor camera and a smart display to arrive in 2026, as well as a tabletop robot, with the latter expected to launch in 2027. An Apple-made smart display in particular has featured heavily in the rumor mill for a number of years, but it appears to be closer than ever. Bloomberg’s Mark Gurman reports that Apple’s new home hub will have a 7-inch square LCD display, a built-in FaceTime camera and an OS that dynamically adjusts depending on who’s using it. It will also ship with an improved version of Siri that will behave more like ChatGPT or other chatbots in how it uses the web to answer your questions. The product, along with the more advanced Siri chatbot, had been slated for release earlier this year, but Apple reportedly scrapped those plans in favor of a spring 2026 launch. Bloomberg claims there will be two versions of the home hub, one code-named J940 which takes the form of a display mounted on a HomePod mini-like speaker, and the other (J491) designed to be hung on a wall. With both you’ll be able to control smart appliances, play music and presumably interact with Apple’s various apps on other devices. Apple is said to be targeting a price of around $350, although the Bloomberg report does not specify which version of the device that price refers to. The tabletop robot scheduled to launch in 2027 will effectively be the smart display Apple could be releasing next year mounted into a motorized arm that can move the device to different positions, which sounds like the company’s take on Amazon’s (slightly creepy) swivelling Echo Show 10, first launched in 2021. This product will have a larger 9-inch display, but is said to be delayed after Apple encountered engineering challenges with the motor. Bloomberg reports that all three of these devices will be built in Vietnam, which sources said represented a \"major change\" in how Apple launches a new product category, as it has traditionally relied on China at the outset. In 2020 it emerged that Apple was looking to diversify its production by moving some of its iPad and MacBook manufacturing to Vietnam, and the US’ trade war with China has only intensified during Trump’s second administration. Vietnam has not escaped tariffs of its own, but they’re less severe than imports from China.This article originally appeared on Engadget at https://www.engadget.com/home/apples-long-rumored-smart-display-will-reportedly-cost-350-165801748.html?src=rss",
          "feed_position": 5
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/apples-first-m5-laptop-is-the-14-inch-macbook-pro-131314446.html",
          "published_at": "Wed, 15 Oct 2025 16:52:25 +0000",
          "title": "Apple's first M5 laptop is the 14-inch MacBook Pro",
          "standfirst": "The new M5 MacBook Pro has arrived — and brought something of a strategy change for Apple's chip release strategy this year. This time around, Apple has led with the entry-level 14-inch MacBook Pro, which retains the same $1,599 starting price as its M4 predecessor. It debuts alongside new 11- and 13-inch iPad Pros and a refreshed Apple Vision Pro that have the same M5 chipset, but — unlike last year — there's no M5 Pro and M5 Max devices to be found. In the past, Apple has favored launching its entire MacBook Pro lineup at once, as it did in 2024 with the M4, M4 Pro and M4 Max models. However, it may have decided to release the M5 model now so it could get a jump start on sales, since the M5 Pro and M5 Max versions are reportedly still several months away. Apple may have also opted for a low-key release since the M5 MacBook Pro is largely unchanged from the previous model. With that, the emphasis is squarely on the M5 chip and its extra performance. Reportedly due to cost reasons, Apple decided to use the same 3-nanometer fabrication process for the M5 as it did for the M4. The new chip has 10 GPU cores and 10 CPU cores, along with a 16-core Neural Engine. Apple claims the M5 has the \"world’s fastest CPU core\" with up to 20 percent faster multithreaded performance compared with the M4 chip. As for the GPU, the company says that offers \"up to 1.6x faster graphics performance in pro apps and enables up to 1.6x higher frame rates in games compared to the M4 model.\" That should make the M5 MacBook Pro a better option than the M4 model for things like gaming and video editing. To that end, compared with the M4 MacBook Pro, Apple says the latest model delivers up to 1.8x faster \"AI video-enhancing performance\" in Topaz Video, up to 1.7x faster 3D rendering in Blender and up to 1.2x faster build performance during code compiling in Xcode. The company is promising 3.5x faster AI performance than with the M4 model, and up to 6x faster performance than M1. It also claims SSD performance is up to twice as fast as the previous generation. The M5 MacBook Pro comes with the same 14.2-inch, 3,024 x 1,964 Liquid Retina XDR display that can hit 1,000 nits in SDR mode and up to 1,600 nits peak brightness for HDR content. It has adaptive refresh rates at up to 120Hz and offers a wide P3 color gamut with up to 1 billion colors, ideal for video editors and Lightroom users. Other key features include an SDXC card slot, HDMI port and 3.5mm headphone jack. There are three USB-C ports as before, but they're still the Thunderbolt 4 type with speeds up to 40 Gbps, and not the 80 Gbps Thunderbolt 5 ports found on M4 Pro and Max models. It also comes with a six-speaker system with support for Dolby Atmos and Spatial Audio as before, along with Wi-Fi 6E, Bluetooth 5.3 and a 12MP Center Stage 1080p webcam. As you might imagine, it comes with macOS Tahoe ready to go. Per the comparison page on Apple's site, except for the different CPU, the M5 MacBook Pro otherwise has identical specs to its M4 predecessor, right down to the same dimensions, weight and 70-watt power adapter. The 14-inch M5 MacBook Pro is now available for pre-order starting at $1,599 with 16GB memory and 512GB storage. It maxes out at 32GB of RAM and 4TB of storage. Shipping will start October 22. Update, 12:52PM ET: Confirmed via Apple's spec page that there are no real differences between the M4 and M5 MacBook Pro aside from the new CPU. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apples-first-m5-laptop-is-the-14-inch-macbook-pro-131314446.html?src=rss",
          "content": "The new M5 MacBook Pro has arrived — and brought something of a strategy change for Apple's chip release strategy this year. This time around, Apple has led with the entry-level 14-inch MacBook Pro, which retains the same $1,599 starting price as its M4 predecessor. It debuts alongside new 11- and 13-inch iPad Pros and a refreshed Apple Vision Pro that have the same M5 chipset, but — unlike last year — there's no M5 Pro and M5 Max devices to be found. In the past, Apple has favored launching its entire MacBook Pro lineup at once, as it did in 2024 with the M4, M4 Pro and M4 Max models. However, it may have decided to release the M5 model now so it could get a jump start on sales, since the M5 Pro and M5 Max versions are reportedly still several months away. Apple may have also opted for a low-key release since the M5 MacBook Pro is largely unchanged from the previous model. With that, the emphasis is squarely on the M5 chip and its extra performance. Reportedly due to cost reasons, Apple decided to use the same 3-nanometer fabrication process for the M5 as it did for the M4. The new chip has 10 GPU cores and 10 CPU cores, along with a 16-core Neural Engine. Apple claims the M5 has the \"world’s fastest CPU core\" with up to 20 percent faster multithreaded performance compared with the M4 chip. As for the GPU, the company says that offers \"up to 1.6x faster graphics performance in pro apps and enables up to 1.6x higher frame rates in games compared to the M4 model.\" That should make the M5 MacBook Pro a better option than the M4 model for things like gaming and video editing. To that end, compared with the M4 MacBook Pro, Apple says the latest model delivers up to 1.8x faster \"AI video-enhancing performance\" in Topaz Video, up to 1.7x faster 3D rendering in Blender and up to 1.2x faster build performance during code compiling in Xcode. The company is promising 3.5x faster AI performance than with the M4 model, and up to 6x faster performance than M1. It also claims SSD performance is up to twice as fast as the previous generation. The M5 MacBook Pro comes with the same 14.2-inch, 3,024 x 1,964 Liquid Retina XDR display that can hit 1,000 nits in SDR mode and up to 1,600 nits peak brightness for HDR content. It has adaptive refresh rates at up to 120Hz and offers a wide P3 color gamut with up to 1 billion colors, ideal for video editors and Lightroom users. Other key features include an SDXC card slot, HDMI port and 3.5mm headphone jack. There are three USB-C ports as before, but they're still the Thunderbolt 4 type with speeds up to 40 Gbps, and not the 80 Gbps Thunderbolt 5 ports found on M4 Pro and Max models. It also comes with a six-speaker system with support for Dolby Atmos and Spatial Audio as before, along with Wi-Fi 6E, Bluetooth 5.3 and a 12MP Center Stage 1080p webcam. As you might imagine, it comes with macOS Tahoe ready to go. Per the comparison page on Apple's site, except for the different CPU, the M5 MacBook Pro otherwise has identical specs to its M4 predecessor, right down to the same dimensions, weight and 70-watt power adapter. The 14-inch M5 MacBook Pro is now available for pre-order starting at $1,599 with 16GB memory and 512GB storage. It maxes out at 32GB of RAM and 4TB of storage. Shipping will start October 22. Update, 12:52PM ET: Confirmed via Apple's spec page that there are no real differences between the M4 and M5 MacBook Pro aside from the new CPU. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apples-first-m5-laptop-is-the-14-inch-macbook-pro-131314446.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-vpn-deals-120056041.html",
          "published_at": "Wed, 15 Oct 2025 15:31:23 +0000",
          "title": "The best VPN deals: Get up to 87 percent off ProtonVPN, ExpressVPN, Surfshark and more",
          "standfirst": "A virtual private network (VPN) is useful in lots of ways every day, whether you're streaming foreign TV shows or keeping yourself anonymous online so advertisers can't track you. But while we strongly recommend using a VPN, it pays to do some research before investing in one — pricing can be opaque for these services, and you can't always trust how the providers portray their best deals. Even so, there are genuinely great deals to be had. VPN providers love to give out deep discounts to anybody willing to sign up for a year or more at once. This means you've got to pay out more upfront, but if you divide the cost by the months of service, you're actually paying less per month over time. With deals like this, VPN providers boost their subscriber numbers, and you get heavy price cuts on some of our favorite services. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN — $83.43 for a two-year subscription with three months free (77 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 77 percent off the two-year plan, which also comes with three extra months — but there's no expiration date, so you have a little time for comparison shopping. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. It's the lowest I've seen ExpressVPN go in some time, though like NordVPN, it's not on a ticking clock. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (86 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This evergreen deal gives you 86 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA almost never comes off as a budget VPN, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-vpn-deals-120056041.html?src=rss",
          "content": "A virtual private network (VPN) is useful in lots of ways every day, whether you're streaming foreign TV shows or keeping yourself anonymous online so advertisers can't track you. But while we strongly recommend using a VPN, it pays to do some research before investing in one — pricing can be opaque for these services, and you can't always trust how the providers portray their best deals. Even so, there are genuinely great deals to be had. VPN providers love to give out deep discounts to anybody willing to sign up for a year or more at once. This means you've got to pay out more upfront, but if you divide the cost by the months of service, you're actually paying less per month over time. With deals like this, VPN providers boost their subscriber numbers, and you get heavy price cuts on some of our favorite services. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals NordVPN — $83.43 for a two-year subscription with three months free (77 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 77 percent off the two-year plan, which also comes with three extra months — but there's no expiration date, so you have a little time for comparison shopping. ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. It's the lowest I've seen ExpressVPN go in some time, though like NordVPN, it's not on a ticking clock. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark has a more closely connected server network than most VPNs, so it can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (86 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the previous tier. This evergreen deal gives you 86 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — while it's not totally clear what it does to optimize them, I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA almost never comes off as a budget VPN, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. hide.me — $69.95 for a two-year subscription with two months free (73 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. However, if you do want to upgrade to its paid plan, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. What makes a good VPN deal Like I said in the intro, practically every VPN heavily discounts its long-term subscriptions the whole year round. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-vpn-deals-120056041.html?src=rss",
          "feed_position": 8
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/apples-new-vision-pro-gets-an-m5-chip-and-dual-knit-band-but-its-still-3499-132123957.html",
          "published_at": "Wed, 15 Oct 2025 13:21:24 +0000",
          "title": "Apple's new Vision Pro gets an M5 chip and Dual Knit Band, but it's still $3,499",
          "standfirst": "Apple has introduced an upgraded version of its Vision Pro headset that's powered by the company's M5 chip, its latest silicon that will also come with the new iPad Pro and MacBook Pro. The first generation of the headset was equipped with Apple's M2, so you can expect this device to be faster and come with more capabilities. Apple hasn't budged the price from $3,499 with 256GB of storage, but at least it comes with a Dual Knit Band, which adds a top strap for extra security and comfort. (Existing Vision Pro users can also buy the Dual Knit Band separately for $99.) As you'd expect, Apple claims the refreshed Vision Pro should be faster while loading apps, browsing the web and doing just about everything. The M5 chip also includes a new 10-core GPU, with better support for hardware-accelerated ray tracing and mesh shading, \"enabling developers to add remarkable detail to lighting, shadows, and reflections in games like Control,\" according to Apple. The company also says the M5 Vision Pro renders 10 percent more pixels on its micro-OLED displays, which should make everything look a bit sharper. The M5 Vision Pro should last a bit longer than the original model, as well. Apple claims it supports up to two and a half hours of typical usage, and up to three hours of video playback. The previous model was rated for two hours of general usage and two and a half hours of video viewing. Bloomberg's Mark Gurman reported a few days ago that Apple was due for another wave of product announcements. He wrote back then that the new iPad Pro and Vision Pro are already being mass produced and that Apple is \"gearing up for an imminent release.\" Apple had originally wanted to launch a a lighter and cheaper version of the Vision Pro headset, as well, but it reportedly decided to shift its focus on the development of smart glasses. The company pulled people working on the lighter Vision Pro, Gurman said in another report, and moved them to its smart glasses project. Apple is reportedly working on a smart glasses model with no display and is meant to pair with iPhones, along with another model that's equipped with a built-in screen and can directly compete with Meta's Ray-Ban Display. The company is aiming to release the model with no screen in 2027 and the one with a screen in 2028, Gurman said. \"The Vision Pro is a flawed product, but it's certainly not empty,\" we noted in our review of the original headset. \"It's as if Apple has compiled everything it's learned from building the Mac, iPhone, Apple Watch and AirPods into a single device, all in a bid to avoid the Innovator's Dilemma.\" At first glance, the M5 Vision Pro doesn't seem to change that conclusion much, not without more content and apps built around spatial computing. A price drop and more storage on the base model would certainly make the Vision Pro more compelling, until that happens it'll remain more of a developer kit than a full-fledged consumer product. The M5 Vision Pro is now ready to pre-order and will once again set you back $3,499. Apple will start shipping the device on October 22.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/apples-new-vision-pro-gets-an-m5-chip-and-dual-knit-band-but-its-still-3499-132123957.html?src=rss",
          "content": "Apple has introduced an upgraded version of its Vision Pro headset that's powered by the company's M5 chip, its latest silicon that will also come with the new iPad Pro and MacBook Pro. The first generation of the headset was equipped with Apple's M2, so you can expect this device to be faster and come with more capabilities. Apple hasn't budged the price from $3,499 with 256GB of storage, but at least it comes with a Dual Knit Band, which adds a top strap for extra security and comfort. (Existing Vision Pro users can also buy the Dual Knit Band separately for $99.) As you'd expect, Apple claims the refreshed Vision Pro should be faster while loading apps, browsing the web and doing just about everything. The M5 chip also includes a new 10-core GPU, with better support for hardware-accelerated ray tracing and mesh shading, \"enabling developers to add remarkable detail to lighting, shadows, and reflections in games like Control,\" according to Apple. The company also says the M5 Vision Pro renders 10 percent more pixels on its micro-OLED displays, which should make everything look a bit sharper. The M5 Vision Pro should last a bit longer than the original model, as well. Apple claims it supports up to two and a half hours of typical usage, and up to three hours of video playback. The previous model was rated for two hours of general usage and two and a half hours of video viewing. Bloomberg's Mark Gurman reported a few days ago that Apple was due for another wave of product announcements. He wrote back then that the new iPad Pro and Vision Pro are already being mass produced and that Apple is \"gearing up for an imminent release.\" Apple had originally wanted to launch a a lighter and cheaper version of the Vision Pro headset, as well, but it reportedly decided to shift its focus on the development of smart glasses. The company pulled people working on the lighter Vision Pro, Gurman said in another report, and moved them to its smart glasses project. Apple is reportedly working on a smart glasses model with no display and is meant to pair with iPhones, along with another model that's equipped with a built-in screen and can directly compete with Meta's Ray-Ban Display. The company is aiming to release the model with no screen in 2027 and the one with a screen in 2028, Gurman said. \"The Vision Pro is a flawed product, but it's certainly not empty,\" we noted in our review of the original headset. \"It's as if Apple has compiled everything it's learned from building the Mac, iPhone, Apple Watch and AirPods into a single device, all in a bid to avoid the Innovator's Dilemma.\" At first glance, the M5 Vision Pro doesn't seem to change that conclusion much, not without more content and apps built around spatial computing. A price drop and more storage on the base model would certainly make the Vision Pro more compelling, until that happens it'll remain more of a developer kit than a full-fledged consumer product. The M5 Vision Pro is now ready to pre-order and will once again set you back $3,499. Apple will start shipping the device on October 22.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/apples-new-vision-pro-gets-an-m5-chip-and-dual-knit-band-but-its-still-3499-132123957.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/apples-latest-ipad-pro-get-a-power-boost-with-the-new-m5-chip-131036435.html",
          "published_at": "Wed, 15 Oct 2025 13:10:36 +0000",
          "title": "Apple's latest iPad Pro gets a power boost with the new M5 chip",
          "standfirst": "Apple's latest 11- and 13-inch iPad Pros have arrived, and though they're the first with the company's all-new M5 chip, they're otherwise largely identical to last year's models. The main reason to buy one, then, would be for the extra performance over the M4 — something that may be worthwhile to content creators and other power users looking for a tablet instead of a laptop. Last year Apple decided to debut its M4 chip with the iPad Pro lineup and not its laptops. The reason? Only the entry-level M4 was ready (and not the M4 Pro and M4 Max), so Apple decided to wait before putting in its MacBooks so it could launch the entire lineup at once. With updated Magic Keyboards, It also showed that Apple was marketing the iPad Pro as a feasible MacBook replacement for power users. The same applies with the M5, except this time the company also launched its entry-level 14-inch MacBook Pro at the same time. As before, the new M5 processor uses TSMC's 3-nanometer process, as Apple reportedly decided against 2-nanometer chips due to cost considerations. The entry-level M5 comes in a couple of versions. The iPad Pro with either 256GB or 512GB of storage gets an M5 with a 9-core CPU (3 performance cores and 6 efficiency cores), 10-core GPU and 12GB of RAM. The 1TB and 2TB models get a fourth performance core and 16GB of RAM. The big upgrade here appears to be to the GPU; Apple says each of the 10 GPU cores have a Neural Accelerator on board, which will allow GPU-based AI processing to run significantly faster than on the M4. Apple claims it has more than four times the peak GPU compute performance of the M4 (which is only about 18 months old, mind you). Graphics performance should be about 45 percent higher than on the M4, as well. Overall multithreaded performance is 15 percent faster than the M4, and Apple says that video transcoding is six times faster than what the old M1 iPad Pro from 2021 delivered. As for battery life, Apple claims the same 10 hours that basically every iPad has ever been rated at. But for the first time, the iPad Pro supports fast charging — you can get up to 50 percent in 30 minutes using a 60W USB-C power adaptor. Apple is also using the C1X modem that it originally introduced last month in the iPhone Air; that'll provide the optional 5G service that Apple has offered on iPads for a few years now. There's also an N1 chip (also found in the iPhone Air), which is an Apple-designed networking chip for Wi-Fi 7, Bluetooth 6 and Thread connectivity. Apple claims this new chip will make features like Personal Hotspot and Airdrop more reliable while also offering improved performance on 5GHz Wi-Fi networks. As before, the 2025 iPad Airs are extremely thin and light. The 11-inch model is 5.3mm thick and tips the scales at just under one pound, while the 13-incher is just 5.1mm thick weighs 1.29 pounds. Both feature \"tandem\" OLED Ultra Display XDR screens that hit up to 1,000 nits brightness and peak at 1,600 nits — so they're perfect for viewing and editing HDR content. The new iPad Pro starts at $999 for the 11-inch model with 256GB of storage ($1,199 with 5G) and $1,299 for the 13-inch ($1,499 with 5G). Those are the same prices as last year — still extremely expensive, but at least not more than before. You can pre-order the new iPad Pro now, and it'll be available on October 22. This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/apples-latest-ipad-pro-get-a-power-boost-with-the-new-m5-chip-131036435.html?src=rss",
          "content": "Apple's latest 11- and 13-inch iPad Pros have arrived, and though they're the first with the company's all-new M5 chip, they're otherwise largely identical to last year's models. The main reason to buy one, then, would be for the extra performance over the M4 — something that may be worthwhile to content creators and other power users looking for a tablet instead of a laptop. Last year Apple decided to debut its M4 chip with the iPad Pro lineup and not its laptops. The reason? Only the entry-level M4 was ready (and not the M4 Pro and M4 Max), so Apple decided to wait before putting in its MacBooks so it could launch the entire lineup at once. With updated Magic Keyboards, It also showed that Apple was marketing the iPad Pro as a feasible MacBook replacement for power users. The same applies with the M5, except this time the company also launched its entry-level 14-inch MacBook Pro at the same time. As before, the new M5 processor uses TSMC's 3-nanometer process, as Apple reportedly decided against 2-nanometer chips due to cost considerations. The entry-level M5 comes in a couple of versions. The iPad Pro with either 256GB or 512GB of storage gets an M5 with a 9-core CPU (3 performance cores and 6 efficiency cores), 10-core GPU and 12GB of RAM. The 1TB and 2TB models get a fourth performance core and 16GB of RAM. The big upgrade here appears to be to the GPU; Apple says each of the 10 GPU cores have a Neural Accelerator on board, which will allow GPU-based AI processing to run significantly faster than on the M4. Apple claims it has more than four times the peak GPU compute performance of the M4 (which is only about 18 months old, mind you). Graphics performance should be about 45 percent higher than on the M4, as well. Overall multithreaded performance is 15 percent faster than the M4, and Apple says that video transcoding is six times faster than what the old M1 iPad Pro from 2021 delivered. As for battery life, Apple claims the same 10 hours that basically every iPad has ever been rated at. But for the first time, the iPad Pro supports fast charging — you can get up to 50 percent in 30 minutes using a 60W USB-C power adaptor. Apple is also using the C1X modem that it originally introduced last month in the iPhone Air; that'll provide the optional 5G service that Apple has offered on iPads for a few years now. There's also an N1 chip (also found in the iPhone Air), which is an Apple-designed networking chip for Wi-Fi 7, Bluetooth 6 and Thread connectivity. Apple claims this new chip will make features like Personal Hotspot and Airdrop more reliable while also offering improved performance on 5GHz Wi-Fi networks. As before, the 2025 iPad Airs are extremely thin and light. The 11-inch model is 5.3mm thick and tips the scales at just under one pound, while the 13-incher is just 5.1mm thick weighs 1.29 pounds. Both feature \"tandem\" OLED Ultra Display XDR screens that hit up to 1,000 nits brightness and peak at 1,600 nits — so they're perfect for viewing and editing HDR content. The new iPad Pro starts at $999 for the 11-inch model with 256GB of storage ($1,199 with 5G) and $1,299 for the 13-inch ($1,499 with 5G). Those are the same prices as last year — still extremely expensive, but at least not more than before. You can pre-order the new iPad Pro now, and it'll be available on October 22. This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/apples-latest-ipad-pro-get-a-power-boost-with-the-new-m5-chip-131036435.html?src=rss",
          "feed_position": 13
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/asus-rog-xbox-ally-x-review-an-extra-life-for-xbox-130050224.html",
          "published_at": "Wed, 15 Oct 2025 13:00:50 +0000",
          "title": "ASUS ROG Xbox Ally X review: An extra life for Xbox",
          "standfirst": "Xbox is at a crossroads. While the PlayStation 5 and Switch 2 continue to gain popularity, multiple price hikes for the Xbox Series S and X have killed their momentum. And with several big box retailers like Costco deciding to drop Microsoft’s console from their shelves, the current-gen Xbox may be dead in the water. So what should the company do? Microsoft’s most straightforward option would be to simply punt the end of the Xbox's lifecycle, regroup and come back strong with a brand new console in a year or two. On the flipside, the company could follow in Sega's footsteps after the untimely demise of the Dreamcast and become a cross-platform game publisher with a large stable of first-party studios. However, there's a third route that could fill the gap between now and whenever the next Xbox arrives that could potentially expand its reach to a whole new segment: Give handheld gaming a go. Engineering and building a new portable gaming device isn't cheap or quick. So instead of doing everything itself, Microsoft teamed up with ASUS to create the ROG Xbox Ally and ROG Xbox Ally X — a pair of Windows 11-based portable gaming PCs enhanced with Microsoft's DNA. And while it's too early to say if these handhelds will help save Xbox itself, they're more than solid portables that could have a big impact on portable gaming going forward. Editor's note: This review is focused on the ROG Xbox Ally X, primarily because that's all we have at the moment. However, the Xbox Ally and Xbox Ally X share many features including the same basic design , display, button layout and software (the only difference is their color). That said, the base Xbox Ally has less impressive specs as it comes with a slower AMD Ryzen Z2 chip, 16GB of RAM, 512GB of storage and a smaller 60WHr battery. It’s also a touch lighter (1.48 pounds vs 1.58) and has a lower price of $600 instead of $1,000. Design and display: The Xbox goes portable Sam Rutherford for Engadget When you look at the ROG Xbox Ally X, it might appear as if ASUS bolted larger grips to its previous handheld — the Ally X — and called it a day. However, the company says the Xbox Ally was redesigned from the ground up, in large part to include a number of signature features that will make Xbox faithful feel right at home. This includes things like the classic ABXY button layout, Impulse triggers with tons of travel and, of course, the requisite Xbox home button. Then smack dab in the middle of everything is a 7-inch IPS LCD screen. Speaking of the display, ASUS picked a FHD IPS panel with a 120Hz refresh rate that appears to be the exact same screen used on the Ally X. While it doesn't deliver pure blacks like you'd get from OLED, contrast was still surprisingly good. With a brightness of 500 nits (the one on our review unit was actually a touch higher at 510 nits), this display delivers almost everything you want without feeling like you need to upgrade to something like the huge 8.8-inch OLED panel on the Lenovo Legion Go 2. Sam Rutherford for Engadget Around back, there are two customizable paddles while the top edge houses a fingerprint reader and all of the Xbox Ally X's connectivity: two USB-C ports, a microSD card reader and 3.5mm audio. Notably, while both ports support charging and display capabilities, the one furthest to the left is also Thunderbolt 4 compliant. This means it has enough bandwidth to support external GPUs like ASUS' recently updated XG Mobile graphics dock. Ultimately, the ROG Xbox Ally might not look all that different from ASUS' previous handhelds, but between its buttons, triggers and those big new grips, it really does feel like you're holding a portable version of Microsoft's console. Even without Hall Effect sensors, the Xbox Ally X's joysticks are tight and responsive, while the triggers offer a ton of travel. The only thing I wish ASUS and Microsoft had paid a little more attention to is the handheld's haptics, which are fine, but they’re a far cry from the expressive rumble motors you get from a DualSense controller or the Switch 2's Joy-Con. Performance: Flagship handheld power Sam Rutherford for Engadget As the higher-end model in ASUS and Microsoft's new joint handheld lineup, the ROG Xbox Ally X features a AMD Ryzen Z2 Extreme chip with 24GB of memory (which is shared with its GPU) and 1TB of storage that can be expanded via microSD. However, thanks in part to the new full-screen Xbox experience, Microsoft tweaked a number of the handheld's background processes and services for the first time on a Windows 11-based handheld. The result is a slightly more optimized device even when compared to its closest rivals. In Cyberpunk 2077 at 1,920 x 1,080, medium graphics and FSR set to performance, the ROG Xbox Ally X hit 62.1 fps while plugged in and set to its max 35-watt Turbo mode. That's almost five fps higher than what we got from the Lenovo Legion Go 2 (57.5 fps) when its settings are similarly maxed out. Admittedly, this might not sound like a huge improvement, but it ends up being an extra seven percent performance from the same chip, which ain't bad. Meanwhile in Returnal, I got similar numbers after switching to the Ally's more energy-efficient 17-watt Performance Mode (unplugged), where it produced 42 fps at full HD on medium versus 39 fps for the Lenovo. Sam Rutherford for Engadget That said, it's important to note that the Ally's performance changes depending on whether it's plugged into the wall or not. If you want its full 35-watt Turbo Mode, you're going to need to use a power adapter, while its 17-watt Performance and 13-watt Silent modes stay the same no matter what you do. There’s also a manual performance customization tool, but to access it, you'll need to switch over to ASUS' Armoury Crate app, as there isn't a place to change things directly inside the Xbox app. Software: The tailored gaming experience we needed Getting excited about the software on a gaming handheld is usually pretty difficult. However, between the aforementioned tweaks to background services and the new full-screen Xbox experience, Microsoft has managed to remove a ton of the clunkiness that typically plagues other Windows-based gaming handhelds. Instead of having to wade your way through the traditional Windows desktop before booting into a game, now you're greeted by the Xbox app upon startup (and even during initial setup), so there are fewer steps to get between you and your favorite title. Furthermore, Microsoft has come up with a revamped layout that makes core features super easy to find. The Home tab is where all your installed software is, while there are other dedicated sections for Game Pass downloads (assuming you have a subscription) cloud gaming/remote play (also via Game Pass) and the Microsoft Store. If you prefer other digital marketplaces like Steam or Epic, there are shortcuts to download installers for those stores (and a few more like GOG and Ubisoft) in the My Apps tab. You don't need to open a web browser and do things manually. To switch between apps in Microsoft's new full-screen Xbox experience, all you need to do is swipe up from the bottom of the ROG Xbox Ally X's screen. Sam Rutherford for Engadget Furthermore, hitting the Xbox button summons a handful of quick settings for all sorts of things, including the Command Center for performance, toggles for Wi-Fi and Bluetooth, your Xbox friends list and a whole lot more. It's kind of like a do-everything button and it makes accessing almost all of your most important tools and features quick and easy. On top of that, there are new gestures that you can access by swiping in on the screen in different directions. Dragging your finger in from the left calls up the Xbox Game Bar overlay, even when you're in the middle of playing a game, while swiping in from the right opens your Windows notifications. But my favorite command is swiping up from the bottom, which is a new way to switch between apps (or a cooler version of Alt + Tab, depending on how you look at it). From there, you can even scroll through any programs that are currently open just by tapping the Xbox Ally's shoulder buttons. If you want to use the handheld like a real PC, you can also activate the Windows desktop from there too. Microsoft has also thoughtfully included compatibility tags on a number of games in its store to give buyers a sense of how well a game will run on the ROG Xbox Ally X. Sam Rutherford for Engadget The redesigned Xbox experience is very breezy and handles 90 to 95 percent of your traditional gaming functions, but there are still times when some of Window's underlying awkwardness shows through. Most often, I found this happens when exiting a game from a third-party store, where the Xbox Ally will spit you out into your Steam library (for example), where you'll often have to rely on touchscreen controls instead of the joysticks or the desktop mode's mouse cursor to navigate around. It's not a big deal compared to other Windows-based handhelds, and even though Microsoft has taken a big step forward on the Xbox Ally, there is still a little polishing to be done. Battery life: A solid jump in longevity One of the biggest benefits of going with the ROG Xbox Ally X is that it comes with a larger 80WHr battery than the base model (60Whr). When that is combined with improved energy efficiency from its new chip, you get very solid battery life — just as long as you don’t max out the power settings. Sam Rutherford for Engadget I tested this by playing Clair Obscur: Expedition 33 at full HD on medium settings and max brightness (Protip: don’t do this at night if you want to get to sleep on time) and the Xbox Ally X lasted just shy of three and a half hours. That’s 30 minutes longer than what I got from the Legion Go 2, although considering the latter has a much larger screen (with the same 500 nits of brightness), that difference wasn’t a big shock. The bigger revelation is that when compared to the original Ally X, ASUS and Microsoft’s new jointly-made device provided an extra hour of runtime, which could make a meaningful difference on a long trip. Wrap-up While Microsoft’s first real foray into PC gaming handhelds isn’t upending the status quo and it’s way too early to say if this gadget will save Xbox as a whole, it is bringing some notable advancements. The new full-screen experience makes launching and playing games on Windows-based devices so much more seamless that it’s kind of wild it took so long to get here. Sure, there are still a few edge cases where you’ll have to tap the screen or flip between the Xbox app and ASUS’ Armoury Create to tweak certain settings, but compared to most of its rivals, the ASUS ROG Xbox Ally X is a massive upgrade in general usability. Here is a size comparison between the ASUS ROG Xbox Ally X (bottom) and the Lenovo Legion Go 2 (top). Sam Rutherford for Engadget The bigger grips and a familiar button layout will instantly make longtime Xbox fans feel right at home. And thanks to the new chip and more processes and services that run in the background while you’re gaming, you get class-leading performance and battery life. Aside from lackluster haptics, the ROG Xbox Ally X’s biggest issue is its price. I totally get that there’s a growing number of gamers who constantly crave better performance from their portable PCs. However, the trade-off for all this is a much bigger hit to your wallet. It wasn’t that long ago when the going rate for a premium handheld was more like $500, which made it easier to afford. After all, those devices weren’t really designed to be your main gaming rig like a laptop or desktop. Ultimately the biggest deciding factor for purchasing the ROG Xbox Ally X may be how much someone is already invested into the Xbox ecosystem. If you’re a fan of other game stores or you don’t have a subscription to Xbox Game Pass or a ton of friends on the platform, you won’t get the full benefit of everything Microsoft has integrated into the handheld’s new software. This goes double for devotees of Valve’s digital store and Linux-based OS that don’t need bleeding edge performance, who can safely stick to much more affordable Steam Decks or the Legion Go S. Alternatively, if you want a versatile portable with a giant OLED screen and detachable controllers, the Legion Go 2 is worth consideration as well. Though at $1,300 for the model with a Z2 Extreme chip, it’s even more expensive than this new handheld Xbox. Still, despite some minor caveats, Microsoft has finally put its spin on portable PC gaming (with an assist from ASUS) and brought some welcome upgrades to the space that have made the ROG Xbox Ally X a top shelf device.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/asus-rog-xbox-ally-x-review-an-extra-life-for-xbox-130050224.html?src=rss",
          "content": "Xbox is at a crossroads. While the PlayStation 5 and Switch 2 continue to gain popularity, multiple price hikes for the Xbox Series S and X have killed their momentum. And with several big box retailers like Costco deciding to drop Microsoft’s console from their shelves, the current-gen Xbox may be dead in the water. So what should the company do? Microsoft’s most straightforward option would be to simply punt the end of the Xbox's lifecycle, regroup and come back strong with a brand new console in a year or two. On the flipside, the company could follow in Sega's footsteps after the untimely demise of the Dreamcast and become a cross-platform game publisher with a large stable of first-party studios. However, there's a third route that could fill the gap between now and whenever the next Xbox arrives that could potentially expand its reach to a whole new segment: Give handheld gaming a go. Engineering and building a new portable gaming device isn't cheap or quick. So instead of doing everything itself, Microsoft teamed up with ASUS to create the ROG Xbox Ally and ROG Xbox Ally X — a pair of Windows 11-based portable gaming PCs enhanced with Microsoft's DNA. And while it's too early to say if these handhelds will help save Xbox itself, they're more than solid portables that could have a big impact on portable gaming going forward. Editor's note: This review is focused on the ROG Xbox Ally X, primarily because that's all we have at the moment. However, the Xbox Ally and Xbox Ally X share many features including the same basic design , display, button layout and software (the only difference is their color). That said, the base Xbox Ally has less impressive specs as it comes with a slower AMD Ryzen Z2 chip, 16GB of RAM, 512GB of storage and a smaller 60WHr battery. It’s also a touch lighter (1.48 pounds vs 1.58) and has a lower price of $600 instead of $1,000. Design and display: The Xbox goes portable Sam Rutherford for Engadget When you look at the ROG Xbox Ally X, it might appear as if ASUS bolted larger grips to its previous handheld — the Ally X — and called it a day. However, the company says the Xbox Ally was redesigned from the ground up, in large part to include a number of signature features that will make Xbox faithful feel right at home. This includes things like the classic ABXY button layout, Impulse triggers with tons of travel and, of course, the requisite Xbox home button. Then smack dab in the middle of everything is a 7-inch IPS LCD screen. Speaking of the display, ASUS picked a FHD IPS panel with a 120Hz refresh rate that appears to be the exact same screen used on the Ally X. While it doesn't deliver pure blacks like you'd get from OLED, contrast was still surprisingly good. With a brightness of 500 nits (the one on our review unit was actually a touch higher at 510 nits), this display delivers almost everything you want without feeling like you need to upgrade to something like the huge 8.8-inch OLED panel on the Lenovo Legion Go 2. Sam Rutherford for Engadget Around back, there are two customizable paddles while the top edge houses a fingerprint reader and all of the Xbox Ally X's connectivity: two USB-C ports, a microSD card reader and 3.5mm audio. Notably, while both ports support charging and display capabilities, the one furthest to the left is also Thunderbolt 4 compliant. This means it has enough bandwidth to support external GPUs like ASUS' recently updated XG Mobile graphics dock. Ultimately, the ROG Xbox Ally might not look all that different from ASUS' previous handhelds, but between its buttons, triggers and those big new grips, it really does feel like you're holding a portable version of Microsoft's console. Even without Hall Effect sensors, the Xbox Ally X's joysticks are tight and responsive, while the triggers offer a ton of travel. The only thing I wish ASUS and Microsoft had paid a little more attention to is the handheld's haptics, which are fine, but they’re a far cry from the expressive rumble motors you get from a DualSense controller or the Switch 2's Joy-Con. Performance: Flagship handheld power Sam Rutherford for Engadget As the higher-end model in ASUS and Microsoft's new joint handheld lineup, the ROG Xbox Ally X features a AMD Ryzen Z2 Extreme chip with 24GB of memory (which is shared with its GPU) and 1TB of storage that can be expanded via microSD. However, thanks in part to the new full-screen Xbox experience, Microsoft tweaked a number of the handheld's background processes and services for the first time on a Windows 11-based handheld. The result is a slightly more optimized device even when compared to its closest rivals. In Cyberpunk 2077 at 1,920 x 1,080, medium graphics and FSR set to performance, the ROG Xbox Ally X hit 62.1 fps while plugged in and set to its max 35-watt Turbo mode. That's almost five fps higher than what we got from the Lenovo Legion Go 2 (57.5 fps) when its settings are similarly maxed out. Admittedly, this might not sound like a huge improvement, but it ends up being an extra seven percent performance from the same chip, which ain't bad. Meanwhile in Returnal, I got similar numbers after switching to the Ally's more energy-efficient 17-watt Performance Mode (unplugged), where it produced 42 fps at full HD on medium versus 39 fps for the Lenovo. Sam Rutherford for Engadget That said, it's important to note that the Ally's performance changes depending on whether it's plugged into the wall or not. If you want its full 35-watt Turbo Mode, you're going to need to use a power adapter, while its 17-watt Performance and 13-watt Silent modes stay the same no matter what you do. There’s also a manual performance customization tool, but to access it, you'll need to switch over to ASUS' Armoury Crate app, as there isn't a place to change things directly inside the Xbox app. Software: The tailored gaming experience we needed Getting excited about the software on a gaming handheld is usually pretty difficult. However, between the aforementioned tweaks to background services and the new full-screen Xbox experience, Microsoft has managed to remove a ton of the clunkiness that typically plagues other Windows-based gaming handhelds. Instead of having to wade your way through the traditional Windows desktop before booting into a game, now you're greeted by the Xbox app upon startup (and even during initial setup), so there are fewer steps to get between you and your favorite title. Furthermore, Microsoft has come up with a revamped layout that makes core features super easy to find. The Home tab is where all your installed software is, while there are other dedicated sections for Game Pass downloads (assuming you have a subscription) cloud gaming/remote play (also via Game Pass) and the Microsoft Store. If you prefer other digital marketplaces like Steam or Epic, there are shortcuts to download installers for those stores (and a few more like GOG and Ubisoft) in the My Apps tab. You don't need to open a web browser and do things manually. To switch between apps in Microsoft's new full-screen Xbox experience, all you need to do is swipe up from the bottom of the ROG Xbox Ally X's screen. Sam Rutherford for Engadget Furthermore, hitting the Xbox button summons a handful of quick settings for all sorts of things, including the Command Center for performance, toggles for Wi-Fi and Bluetooth, your Xbox friends list and a whole lot more. It's kind of like a do-everything button and it makes accessing almost all of your most important tools and features quick and easy. On top of that, there are new gestures that you can access by swiping in on the screen in different directions. Dragging your finger in from the left calls up the Xbox Game Bar overlay, even when you're in the middle of playing a game, while swiping in from the right opens your Windows notifications. But my favorite command is swiping up from the bottom, which is a new way to switch between apps (or a cooler version of Alt + Tab, depending on how you look at it). From there, you can even scroll through any programs that are currently open just by tapping the Xbox Ally's shoulder buttons. If you want to use the handheld like a real PC, you can also activate the Windows desktop from there too. Microsoft has also thoughtfully included compatibility tags on a number of games in its store to give buyers a sense of how well a game will run on the ROG Xbox Ally X. Sam Rutherford for Engadget The redesigned Xbox experience is very breezy and handles 90 to 95 percent of your traditional gaming functions, but there are still times when some of Window's underlying awkwardness shows through. Most often, I found this happens when exiting a game from a third-party store, where the Xbox Ally will spit you out into your Steam library (for example), where you'll often have to rely on touchscreen controls instead of the joysticks or the desktop mode's mouse cursor to navigate around. It's not a big deal compared to other Windows-based handhelds, and even though Microsoft has taken a big step forward on the Xbox Ally, there is still a little polishing to be done. Battery life: A solid jump in longevity One of the biggest benefits of going with the ROG Xbox Ally X is that it comes with a larger 80WHr battery than the base model (60Whr). When that is combined with improved energy efficiency from its new chip, you get very solid battery life — just as long as you don’t max out the power settings. Sam Rutherford for Engadget I tested this by playing Clair Obscur: Expedition 33 at full HD on medium settings and max brightness (Protip: don’t do this at night if you want to get to sleep on time) and the Xbox Ally X lasted just shy of three and a half hours. That’s 30 minutes longer than what I got from the Legion Go 2, although considering the latter has a much larger screen (with the same 500 nits of brightness), that difference wasn’t a big shock. The bigger revelation is that when compared to the original Ally X, ASUS and Microsoft’s new jointly-made device provided an extra hour of runtime, which could make a meaningful difference on a long trip. Wrap-up While Microsoft’s first real foray into PC gaming handhelds isn’t upending the status quo and it’s way too early to say if this gadget will save Xbox as a whole, it is bringing some notable advancements. The new full-screen experience makes launching and playing games on Windows-based devices so much more seamless that it’s kind of wild it took so long to get here. Sure, there are still a few edge cases where you’ll have to tap the screen or flip between the Xbox app and ASUS’ Armoury Create to tweak certain settings, but compared to most of its rivals, the ASUS ROG Xbox Ally X is a massive upgrade in general usability. Here is a size comparison between the ASUS ROG Xbox Ally X (bottom) and the Lenovo Legion Go 2 (top). Sam Rutherford for Engadget The bigger grips and a familiar button layout will instantly make longtime Xbox fans feel right at home. And thanks to the new chip and more processes and services that run in the background while you’re gaming, you get class-leading performance and battery life. Aside from lackluster haptics, the ROG Xbox Ally X’s biggest issue is its price. I totally get that there’s a growing number of gamers who constantly crave better performance from their portable PCs. However, the trade-off for all this is a much bigger hit to your wallet. It wasn’t that long ago when the going rate for a premium handheld was more like $500, which made it easier to afford. After all, those devices weren’t really designed to be your main gaming rig like a laptop or desktop. Ultimately the biggest deciding factor for purchasing the ROG Xbox Ally X may be how much someone is already invested into the Xbox ecosystem. If you’re a fan of other game stores or you don’t have a subscription to Xbox Game Pass or a ton of friends on the platform, you won’t get the full benefit of everything Microsoft has integrated into the handheld’s new software. This goes double for devotees of Valve’s digital store and Linux-based OS that don’t need bleeding edge performance, who can safely stick to much more affordable Steam Decks or the Legion Go S. Alternatively, if you want a versatile portable with a giant OLED screen and detachable controllers, the Legion Go 2 is worth consideration as well. Though at $1,300 for the model with a Z2 Extreme chip, it’s even more expensive than this new handheld Xbox. Still, despite some minor caveats, Microsoft has finally put its spin on portable PC gaming (with an assist from ASUS) and brought some welcome upgrades to the space that have made the ROG Xbox Ally X a top shelf device.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/asus-rog-xbox-ally-x-review-an-extra-life-for-xbox-130050224.html?src=rss",
          "feed_position": 14,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/e3f439b0-a965-11f0-bf7f-a2f73997e601"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/halliday-glasses-review-ambitious-smart-glasses-with-frustrating-flaws-130000207.html",
          "published_at": "Wed, 15 Oct 2025 13:00:00 +0000",
          "title": "Halliday Glasses review: Ambitious smart glasses with frustrating flaws",
          "standfirst": "Every now and then, you review a product you can’t get along with in any way, shape or form. Sometimes, it’s about the quality of the hardware, but more often it’s about the philosophy of its makers. Imagine trying to review a toilet built by, and for, aliens from the planet Zog: You can appreciate the intention behind it, but you’ll never be able to praise it. That’s the issue I’ve had with Halliday’s smart glasses, because almost every design decision made by its creators feels, to me, like the wrong one. Cofounder Carter Hou conceded that some people love Halliday’s approach and others haven’t taken to it anywhere near as much. Sadly, I’ve found myself in the latter category. Halliday announced itself to the world at CES in January, dragging behind it a truckload of promises about its Wayfarer-style smart glasses. It said the glasses would be “invisible to onlookers,” styled to be as close to a regular pair of specs as it could manage. There’d be no outward facing camera or sensors, just a tiny interior display projecting data into the wearer’s view. It talked up its “proactive” AI assistant that was always listening and would pipe up with an answer when asked a question. It would be discreetly controlled with a touchpad ring, so you’d not need to visibly fiddle with your phone or the glasses’ touch-sensitive arm to use it. Plus, it would weigh just 35 grams. What’s not to like? The company launched a Kickstarter at the end of January, earning $3,305,917 from more than 8,000 backers. The company has already shared its first product with backers, and it’s now ready to share it with retail customers. I’ve been testing the hardware for around a month with regular software updates. Halliday assured me that the last few issues, like inconsistent Bluetooth connectivity, should be ironed out by the time it’s available to the masses. Hardware Halliday’s chunky Wayfarer-style glasses are made out of plastic, with thin plastic lenses set to your prescription. Plastic is obviously easy to work with and affordable, but it also can give the appearance and feel of looking a bit cheap and flimsy. Even the temple tips are made of solid plastic, which means they can’t be adjusted to suit your head shape and comfort levels.The only way to modify how they sit on your face is by contorting the nose pads, which you’ll be told to do during setup. On the underside of the right temple tip, you’ll find a rubber gasket covering its built-in USB-C charging port. Follow it towards the front and you’ll find one of two speakers (its twin sits on the opposite arm), the touch surface for control and the power button. Sitting over the right lens is a little plastic cantilever arm, on the end of which is a 3.6mm round microLED display module. The arm can be pulled in or out and tilted up and down to put the display into your peripheral vision. The aim, as stated, was to make a small and light pair of glasses that wouldn’t draw attention to themselves. Sadly, Halliday couldn’t avoid the issue that plagues all smart glasses, which is that they have to be bigger to accommodate all the electronics. But, to my eye, they only just about register as a bold style choice rather than as a comically-oversized pair of specs. I keep flip-flopping on this: Half the time, they’re bold, half the time, I feel like I’m wearing faux Marx-brothers glasses from a Halloween store. Daniel Cooper for Engadget The control ring is available in US sizes 8-15, and is made of silver plastic with a small clickpad section embedded. Continuing Halliday’s focus on subtlety, the ring’s only distinguishing mark is a small black line on one side of the clickpad to indicate the right hand side. Slide the ring on without remembering to check its orientation and you’ll be trying to use the menus upside down and back to front. Like a lot of smart rings, it’ll certainly stand out on your hand if you’re used to thinner, daintier adornments. The control ring is available in US sizes 8-15, and is made of silver plastic with a small clickpad section embedded. Continuing Halliday’s focus on subtlety, the ring’s only distinguishing mark is a small black line on one side of the clickpad to indicate the right hand side. Slide the ring on without remembering to check its orientation and you’ll be trying to use the menus upside down and back to front. Like a lot of smart rings, it’ll certainly stand out on your hand if you’re used to thinner, daintier adornments. Display Closeup image of the Halliday Smart Glasses display Daniel Cooper for Engadget It’s easy enough to put a teeny-tiny display close to your eye, ostensibly tricking it into thinking it's much larger. The 3.6mm microLED module is meant to project the equivalent of a 3.5-inch display into your field of view. It’s the same sort of barebones green monochrome display found in a lot of wearables since green is easy to read and not too power-hungry. Again, the focus on invisibility means you’re meant to flick your eyes toward it, read what you need and flick back before anyone’s really noticed. There are many reasons why this is a smart choice compared to companies using waveguide prisms embedded in the lenses itself. It saves a lot of weight, makes what you’re looking at far more private and cuts down the cost. Since, after all, you can just use cheap regular or prescription lenses in the frame, rather than specialist ones with the built-in prisms. But the use of a tiny-display-close-to-your-eye is a problem if you are already a glasses wearer. After all, the screen is behind the prescription, so it’s not as simple as just glancing or catching it in my peripheral vision. In my experience, I’d get a notification, look up, and then have to wait for my eyes to refocus before I could see what was going on. That’s not a big deal if it’s just the time or an icon telling you there’s a new WhatsApp, but it’s hard to read full sentences of text. Personally, I found the display to be too close and too unnaturally placed for me to comfortably use it. I tried every adjustment possible to make it easier to use, even wearing them in silly ways to no avail. And this gets worse when you’re being asked to engage with the lengthy responses produced by its “Proactive” AI. Reading paragraphs of text on a 3.6mm screen is a one-way ticket to the sort of eye pain you’d normally only experience after downing a pint of ice cream. If you struggle to use those sorts of displays, then you’ll also struggle with the other text-heavy features the glasses offer. Most notably, its “reactive” AI, translation and Cheatsheet — its teleprompter-esque service for presentations. In use Image of the rear temple tips of the Halliday Smart Glasses Daniel Cooper for Engadget Once you’ve followed the YouTube clip guiding you through setup, you’ll control your glasses via Halliday’s app. Set that up, make sure it’s connected, and it’ll be easy enough to run things just with the ring. You’ll need to memorize a cumbersome control scheme, which has to work to overcome its limited inputs. For instance, it’s easy enough to think that a click would be the dominant action, with the tap acting as the secondary one — but it’s the other way around. Initially, I was clicking (which activates the notification center) rather than tapping to access a menu item. That the clickpad is so small means you’ll do a fair bit of scrolling, too. Halliday’s focus on lightness extended beyond what you’d wear on your face, but how much you’d need to carry in your bag on the go. Rather than build a charging case, the USB-C charger is on the temple tip, hidden behind a little rubber gasket. Except, the gasket is very difficult to actually flick out of its recess and often gets pushed further in. It got to the point where I keep a paperclip on hand to flick it out when it’s time to recharge. Close up of the Control Ring and charger for the Halliday Smart Glasses Daniel Cooper for Engadget The control ring is charged magnetically, so you will be carrying around a little dongle and USB-C cable. It’s not much extra weight to carry, but it is yet another thing to deal with. Plus, if you’re in a hurry for power, you’ll need to charge two devices simultaneously rather than just putting both in a charging case. Look, maybe this is a gripe too far, but it feels like Halliday attempted to reduce complexity and, in doing so, made things a hell of a lot fiddlier when it comes to charging. Proactive AI Image of how Halliday pitched its proactive AI. Halliday Halliday pitched its glasses as being the “first” with a “proactive” AI running in the background of your day to offer context-based assistance. In one of the company’s examples, the system is listening to a conversation, enabling its wearer to act like a know-it-all. Certainly, it was this feature that most intrigued me as I’m sure we’ve all hoped for an electronic version of Gary from Veep every now and again. Image of a conversation between me and Halliday's Proactive AI Daniel Cooper for Engadget The Star Trek-esque promise of such a system clashes with its reality, since the proactive AI is just a constantly-running chatbot which treats everything as a prompt. Here’s the app’s own record of a conversation I had in which every line it heard gets its own response. It will even try to respond to the ums, ahs and other non-speech glue that holds speech together, saying that the line “doesn’t contain any factual claims.” And, don’t forget, all of this is being pushed into your peripheral vision for as long as the AI is active. Bear in mind you only have a limited amount of time credits with which to use the AI. So you can’t have it running in the background 24/7, but on this evidence, I’m not sure that you would ever want to. Hou says the company is working on improving this but, at this point, it doesn’t feel like a feature you’d want to use on a regular basis. Reactive AI The glasses’ reactive AI, meanwhile, is in dire need of some sort of help, since it often refused to answer my questions and, when it did, it often got its facts wrong. On September 18, I asked it who the current manager of (Portuguese football team) Benfica was, since it had just hired a new manager. But it told me the name of the old one, who’d been fired on August 31 — which isn’t ideal. Similarly, questions around basic facts concerning geography and science were either met with blank responses or lackluster answers. I know that plenty of AIs aren’t perfect for up-to-the-minute information, but what else would you want to use it for? Audio memo and transcription You can record audio memos through the glasses if you need to express an idea in a hurry. It’s worth noting, however, that the microphone quality is poor. It sounds like the sort of crunchy radio microphone audio you last heard in a live news broadcast from the 1980s. Given how much of the interaction with these glasses is through speech, the poor microphone quality is baffling. Sure, save on weight as much as possible, but not for the thing the glasses need to do one of their most critical jobs. Once recorded, you can then listen back to the memo in the app, and can even ask the system for a transcription. Bafflingly, you can’t just press the button and then go do something else in the app. If you want your words turned into (an approximate) text record, you’ll need to leave that specific pane open while it runs. I found this out after pressing the button a third time and, rather than moving to the next memo to get that transcribed, I was distracted by something on my laptop and then saw the transcript finally appear before my eyes. Music Halliday’s app claims it’s possible to use the glasses’ built-in speakers in place of your wireless headphones. And, yes, it is technically possible to do this, in the same way that it’s technically possible to steer a motorcycle with your feet or carve a block of marble with an iPhone. I’m no audiophile, but if you’re looking for a better listening experience, listening to a broken record player from a mile away with two paper cups and some string is probably better. It’s very much the sort of option you’d go for if you had to listen to something in the direst of emergencies — and then never again. Price and the competition If you opted to back Halliday’s glasses on Kickstarter, you could pick them up for $399. For the rest of us, it will be available to order through the Halliday website for $499, with shipping due to begin at the end of October. It is available in one of three colors: Black, Gradient or Tortoisehell, with prescription lenses included in the price, at least at the time of publication. If you order now, you will also get the control ring for free, but it will eventually cost $69. In terms of rival smart glasses, the closest competitor is likely Brilliant Labs’ Halo, which uses a similar standalone microLED display with the same focus on AI. Given the display option, if you think you’d struggle with Halliday, it’s easy to assume you won’t be happy with these either. Halo will set you back $299, although it’s worth mentioning that it’ll only be sold in limited quantities. One alternative is Rokid’s forthcoming Glasses, which are equipped with the sort of waveguide display lenses I prefer. The company promises it’ll offer real-time translation, a built-in AI assistant and an outward-facing camera. Would-be backers can pick them up for $549 on Kickstarter at present, with a retail price likely closer to $750 when they launch toward the end of this year. But if I was looking for a product that did a lot of what Halliday offered, albeit in a much more polished package, it’d be Even Realities G1. There’s a lot to like about the G1, as it offers a more limited feature set, but one in which things actually work a lot better. The one downside is the price, since you’ll need to fork out $600 for the glasses and another $150 for the lenses. The big tech elephant in the room, of course, is Meta’s Ray-Ban Display glasses that seem to pay off on the promise of smart glasses’ premise. They’re obviously pricey, retailing for $799, but have all of the gadgets and gizmos you are likely to want and need. It ships with a 600 x 600 full color display in the lens, letting you engage with notifications a lot more like you would if you were using your phone. Wrap-up Close up of the Halliday Smart Glasses ring Daniel Cooper for Engadget My issues with the display certainly didn’t endear Halliday to me. But I think that the product is less than the sum of its parts, both from a hardware and software standpoint. The “proactive” AI is perhaps the biggest disappointment, given it’s just a chatbot responding to every interaction like a prompt. In every facet, the company prioritized things that weren’t worth the effort. What appeared to be a series of great ideas on paper is, in reality, not all that. This article originally appeared on Engadget at https://www.engadget.com/wearables/halliday-glasses-review-ambitious-smart-glasses-with-frustrating-flaws-130000207.html?src=rss",
          "content": "Every now and then, you review a product you can’t get along with in any way, shape or form. Sometimes, it’s about the quality of the hardware, but more often it’s about the philosophy of its makers. Imagine trying to review a toilet built by, and for, aliens from the planet Zog: You can appreciate the intention behind it, but you’ll never be able to praise it. That’s the issue I’ve had with Halliday’s smart glasses, because almost every design decision made by its creators feels, to me, like the wrong one. Cofounder Carter Hou conceded that some people love Halliday’s approach and others haven’t taken to it anywhere near as much. Sadly, I’ve found myself in the latter category. Halliday announced itself to the world at CES in January, dragging behind it a truckload of promises about its Wayfarer-style smart glasses. It said the glasses would be “invisible to onlookers,” styled to be as close to a regular pair of specs as it could manage. There’d be no outward facing camera or sensors, just a tiny interior display projecting data into the wearer’s view. It talked up its “proactive” AI assistant that was always listening and would pipe up with an answer when asked a question. It would be discreetly controlled with a touchpad ring, so you’d not need to visibly fiddle with your phone or the glasses’ touch-sensitive arm to use it. Plus, it would weigh just 35 grams. What’s not to like? The company launched a Kickstarter at the end of January, earning $3,305,917 from more than 8,000 backers. The company has already shared its first product with backers, and it’s now ready to share it with retail customers. I’ve been testing the hardware for around a month with regular software updates. Halliday assured me that the last few issues, like inconsistent Bluetooth connectivity, should be ironed out by the time it’s available to the masses. Hardware Halliday’s chunky Wayfarer-style glasses are made out of plastic, with thin plastic lenses set to your prescription. Plastic is obviously easy to work with and affordable, but it also can give the appearance and feel of looking a bit cheap and flimsy. Even the temple tips are made of solid plastic, which means they can’t be adjusted to suit your head shape and comfort levels.The only way to modify how they sit on your face is by contorting the nose pads, which you’ll be told to do during setup. On the underside of the right temple tip, you’ll find a rubber gasket covering its built-in USB-C charging port. Follow it towards the front and you’ll find one of two speakers (its twin sits on the opposite arm), the touch surface for control and the power button. Sitting over the right lens is a little plastic cantilever arm, on the end of which is a 3.6mm round microLED display module. The arm can be pulled in or out and tilted up and down to put the display into your peripheral vision. The aim, as stated, was to make a small and light pair of glasses that wouldn’t draw attention to themselves. Sadly, Halliday couldn’t avoid the issue that plagues all smart glasses, which is that they have to be bigger to accommodate all the electronics. But, to my eye, they only just about register as a bold style choice rather than as a comically-oversized pair of specs. I keep flip-flopping on this: Half the time, they’re bold, half the time, I feel like I’m wearing faux Marx-brothers glasses from a Halloween store. Daniel Cooper for Engadget The control ring is available in US sizes 8-15, and is made of silver plastic with a small clickpad section embedded. Continuing Halliday’s focus on subtlety, the ring’s only distinguishing mark is a small black line on one side of the clickpad to indicate the right hand side. Slide the ring on without remembering to check its orientation and you’ll be trying to use the menus upside down and back to front. Like a lot of smart rings, it’ll certainly stand out on your hand if you’re used to thinner, daintier adornments. The control ring is available in US sizes 8-15, and is made of silver plastic with a small clickpad section embedded. Continuing Halliday’s focus on subtlety, the ring’s only distinguishing mark is a small black line on one side of the clickpad to indicate the right hand side. Slide the ring on without remembering to check its orientation and you’ll be trying to use the menus upside down and back to front. Like a lot of smart rings, it’ll certainly stand out on your hand if you’re used to thinner, daintier adornments. Display Closeup image of the Halliday Smart Glasses display Daniel Cooper for Engadget It’s easy enough to put a teeny-tiny display close to your eye, ostensibly tricking it into thinking it's much larger. The 3.6mm microLED module is meant to project the equivalent of a 3.5-inch display into your field of view. It’s the same sort of barebones green monochrome display found in a lot of wearables since green is easy to read and not too power-hungry. Again, the focus on invisibility means you’re meant to flick your eyes toward it, read what you need and flick back before anyone’s really noticed. There are many reasons why this is a smart choice compared to companies using waveguide prisms embedded in the lenses itself. It saves a lot of weight, makes what you’re looking at far more private and cuts down the cost. Since, after all, you can just use cheap regular or prescription lenses in the frame, rather than specialist ones with the built-in prisms. But the use of a tiny-display-close-to-your-eye is a problem if you are already a glasses wearer. After all, the screen is behind the prescription, so it’s not as simple as just glancing or catching it in my peripheral vision. In my experience, I’d get a notification, look up, and then have to wait for my eyes to refocus before I could see what was going on. That’s not a big deal if it’s just the time or an icon telling you there’s a new WhatsApp, but it’s hard to read full sentences of text. Personally, I found the display to be too close and too unnaturally placed for me to comfortably use it. I tried every adjustment possible to make it easier to use, even wearing them in silly ways to no avail. And this gets worse when you’re being asked to engage with the lengthy responses produced by its “Proactive” AI. Reading paragraphs of text on a 3.6mm screen is a one-way ticket to the sort of eye pain you’d normally only experience after downing a pint of ice cream. If you struggle to use those sorts of displays, then you’ll also struggle with the other text-heavy features the glasses offer. Most notably, its “reactive” AI, translation and Cheatsheet — its teleprompter-esque service for presentations. In use Image of the rear temple tips of the Halliday Smart Glasses Daniel Cooper for Engadget Once you’ve followed the YouTube clip guiding you through setup, you’ll control your glasses via Halliday’s app. Set that up, make sure it’s connected, and it’ll be easy enough to run things just with the ring. You’ll need to memorize a cumbersome control scheme, which has to work to overcome its limited inputs. For instance, it’s easy enough to think that a click would be the dominant action, with the tap acting as the secondary one — but it’s the other way around. Initially, I was clicking (which activates the notification center) rather than tapping to access a menu item. That the clickpad is so small means you’ll do a fair bit of scrolling, too. Halliday’s focus on lightness extended beyond what you’d wear on your face, but how much you’d need to carry in your bag on the go. Rather than build a charging case, the USB-C charger is on the temple tip, hidden behind a little rubber gasket. Except, the gasket is very difficult to actually flick out of its recess and often gets pushed further in. It got to the point where I keep a paperclip on hand to flick it out when it’s time to recharge. Close up of the Control Ring and charger for the Halliday Smart Glasses Daniel Cooper for Engadget The control ring is charged magnetically, so you will be carrying around a little dongle and USB-C cable. It’s not much extra weight to carry, but it is yet another thing to deal with. Plus, if you’re in a hurry for power, you’ll need to charge two devices simultaneously rather than just putting both in a charging case. Look, maybe this is a gripe too far, but it feels like Halliday attempted to reduce complexity and, in doing so, made things a hell of a lot fiddlier when it comes to charging. Proactive AI Image of how Halliday pitched its proactive AI. Halliday Halliday pitched its glasses as being the “first” with a “proactive” AI running in the background of your day to offer context-based assistance. In one of the company’s examples, the system is listening to a conversation, enabling its wearer to act like a know-it-all. Certainly, it was this feature that most intrigued me as I’m sure we’ve all hoped for an electronic version of Gary from Veep every now and again. Image of a conversation between me and Halliday's Proactive AI Daniel Cooper for Engadget The Star Trek-esque promise of such a system clashes with its reality, since the proactive AI is just a constantly-running chatbot which treats everything as a prompt. Here’s the app’s own record of a conversation I had in which every line it heard gets its own response. It will even try to respond to the ums, ahs and other non-speech glue that holds speech together, saying that the line “doesn’t contain any factual claims.” And, don’t forget, all of this is being pushed into your peripheral vision for as long as the AI is active. Bear in mind you only have a limited amount of time credits with which to use the AI. So you can’t have it running in the background 24/7, but on this evidence, I’m not sure that you would ever want to. Hou says the company is working on improving this but, at this point, it doesn’t feel like a feature you’d want to use on a regular basis. Reactive AI The glasses’ reactive AI, meanwhile, is in dire need of some sort of help, since it often refused to answer my questions and, when it did, it often got its facts wrong. On September 18, I asked it who the current manager of (Portuguese football team) Benfica was, since it had just hired a new manager. But it told me the name of the old one, who’d been fired on August 31 — which isn’t ideal. Similarly, questions around basic facts concerning geography and science were either met with blank responses or lackluster answers. I know that plenty of AIs aren’t perfect for up-to-the-minute information, but what else would you want to use it for? Audio memo and transcription You can record audio memos through the glasses if you need to express an idea in a hurry. It’s worth noting, however, that the microphone quality is poor. It sounds like the sort of crunchy radio microphone audio you last heard in a live news broadcast from the 1980s. Given how much of the interaction with these glasses is through speech, the poor microphone quality is baffling. Sure, save on weight as much as possible, but not for the thing the glasses need to do one of their most critical jobs. Once recorded, you can then listen back to the memo in the app, and can even ask the system for a transcription. Bafflingly, you can’t just press the button and then go do something else in the app. If you want your words turned into (an approximate) text record, you’ll need to leave that specific pane open while it runs. I found this out after pressing the button a third time and, rather than moving to the next memo to get that transcribed, I was distracted by something on my laptop and then saw the transcript finally appear before my eyes. Music Halliday’s app claims it’s possible to use the glasses’ built-in speakers in place of your wireless headphones. And, yes, it is technically possible to do this, in the same way that it’s technically possible to steer a motorcycle with your feet or carve a block of marble with an iPhone. I’m no audiophile, but if you’re looking for a better listening experience, listening to a broken record player from a mile away with two paper cups and some string is probably better. It’s very much the sort of option you’d go for if you had to listen to something in the direst of emergencies — and then never again. Price and the competition If you opted to back Halliday’s glasses on Kickstarter, you could pick them up for $399. For the rest of us, it will be available to order through the Halliday website for $499, with shipping due to begin at the end of October. It is available in one of three colors: Black, Gradient or Tortoisehell, with prescription lenses included in the price, at least at the time of publication. If you order now, you will also get the control ring for free, but it will eventually cost $69. In terms of rival smart glasses, the closest competitor is likely Brilliant Labs’ Halo, which uses a similar standalone microLED display with the same focus on AI. Given the display option, if you think you’d struggle with Halliday, it’s easy to assume you won’t be happy with these either. Halo will set you back $299, although it’s worth mentioning that it’ll only be sold in limited quantities. One alternative is Rokid’s forthcoming Glasses, which are equipped with the sort of waveguide display lenses I prefer. The company promises it’ll offer real-time translation, a built-in AI assistant and an outward-facing camera. Would-be backers can pick them up for $549 on Kickstarter at present, with a retail price likely closer to $750 when they launch toward the end of this year. But if I was looking for a product that did a lot of what Halliday offered, albeit in a much more polished package, it’d be Even Realities G1. There’s a lot to like about the G1, as it offers a more limited feature set, but one in which things actually work a lot better. The one downside is the price, since you’ll need to fork out $600 for the glasses and another $150 for the lenses. The big tech elephant in the room, of course, is Meta’s Ray-Ban Display glasses that seem to pay off on the promise of smart glasses’ premise. They’re obviously pricey, retailing for $799, but have all of the gadgets and gizmos you are likely to want and need. It ships with a 600 x 600 full color display in the lens, letting you engage with notifications a lot more like you would if you were using your phone. Wrap-up Close up of the Halliday Smart Glasses ring Daniel Cooper for Engadget My issues with the display certainly didn’t endear Halliday to me. But I think that the product is less than the sum of its parts, both from a hardware and software standpoint. The “proactive” AI is perhaps the biggest disappointment, given it’s just a chatbot responding to every interaction like a prompt. In every facet, the company prioritized things that weren’t worth the effort. What appeared to be a series of great ideas on paper is, in reality, not all that. This article originally appeared on Engadget at https://www.engadget.com/wearables/halliday-glasses-review-ambitious-smart-glasses-with-frustrating-flaws-130000207.html?src=rss",
          "feed_position": 15,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/selfie1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/windows-10-support-has-ended-but-heres-how-to-get-an-extra-year-for-free-125118875.html",
          "published_at": "Wed, 15 Oct 2025 11:00:37 +0000",
          "title": "Windows 10 support has ended, but here's how to get an extra year for free",
          "standfirst": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) Still running Windows 10 on your PC? Did you know that as of October 14, Microsoft moved the software to its \"end of life\" phase? So while Windows 10 PCs will continue to work, they'll stop getting important security updates by default. The good news is you still have three options to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. Option three is pretty easy — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to use your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/windows-10-support-has-ended-but-heres-how-to-get-an-extra-year-for-free-125118875.html?src=rss",
          "content": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) Still running Windows 10 on your PC? Did you know that as of October 14, Microsoft moved the software to its \"end of life\" phase? So while Windows 10 PCs will continue to work, they'll stop getting important security updates by default. The good news is you still have three options to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. Option three is pretty easy — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to use your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/windows-10-support-has-ended-but-heres-how-to-get-an-extra-year-for-free-125118875.html?src=rss",
          "feed_position": 17,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c836b6e0-a60d-11f0-aff0-71a091f199fd"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-budget-wireless-earbuds-130028735.html",
          "published_at": "Wed, 15 Oct 2025 09:00:36 +0000",
          "title": "The best budget wireless earbuds for 2025",
          "standfirst": "Big-name brands like Apple, Sony, and Bose tend to dominate the headlines when it comes to wireless earbuds, but that doesn’t mean you need to spend a ton to get something good. It’s more than possible to find a pair with clean sound, strong noise cancellation and a rich set of features for less than $100. That said, there’s still plenty of junk in the bargain bin, so you need to be careful.If you’re looking to make an audio upgrade on the cheap, we’ve read countless reviews, compared specs and tested a few dozen models ourselves to find the best budget wireless earbuds you can buy. This is a busy market with new options releasing all the time, but you can find our current favorites below. Table of contents Best budget wireless earbuds for 2025 Other budget wireless earbuds we tested Best cheap wireless earbuds: FAQs Recent updates Best budget wireless earbuds for 2025 Other budget wireless earbuds we tested The Skullcandy Method 360 ANC. Jeff Dunn for Engadget Note: This is a selection of noteworthy earbuds we’ve put through their paces, not a comprehensive list of everything we’ve ever tried. Skullcandy Method 360 ANC The Skullcandy Method 360 ANC is often available for $100, and at that price it’s worth considering over our picks above. These earphones have an extremely V-shaped sound signature with thunderous bass and noticeably clearer highs than the Soundcore Space A40, along with decent ANC and a bulky yet comfortable design that takes after Bose’s old QuietComfort Ultra Earbuds. They technically have a list price of $130, however, which puts them over the $100 limit we have for picks in this guide. Their enormous case and lack of wireless charging don’t help either. You can read our review for a full breakdown. Beats Solo Buds The $80 Beats Solo Buds are comfortable and long-lasting, with an impressive 18 hours of battery life. But they sound a bit flat and are severely lacking in features. There’s no ANC, wear detection or official water-resistance rating, and the included case can’t wirelessly charge the earbuds on its own. You can read our full review for more details. JLab Go Pop ANC The $30 JLab Go Pop ANC is worth a look if you just want a competent pair of wireless earphones for as little money as possible. It’s the cheapest set we’ve tested with active noise cancellation and transparency mode, though neither feature is all that effective. Like the Go Sport+, it also relies on a short USB-C cable tethered to its case to charge. But it actually sounds OK for the price: not particularly wide or detailed, but not harsh either, with decent energy and bass punch. The tiny earpieces fit snugly and isolate a good chunk of background noise passively. They’re also IP55-rated, while the case is similarly compact. There’s no auto-pausing, but you can connect to two devices at once, the touch controls work well and JLab’s app makes it easy to adjust settings. Battery life is alright at six to seven hours, too, though this is another one that’ll get wrecked by the wind if you take a call outside. The JLab Go Pop+ is another option here. It gives up the ANC, IP55 rating and multipoint connectivity, but it costs $5 less and has longer battery life. EarFun Air Pro 4 We liked what we heard from the EarFun Air Pro 4 for about a day or so — then one earbud broke, apparently deciding that it would only play at an extremely low volume from that point on. We’ve seen a few users report the same issue, while others have noted problems with crackling sounds coming out of single earpieces. This pair has received heaps of praise from other outlets, and we generally liked its predecessor, so it may well work for you. But we can’t recommend something that died before we could finish testing it. The Beats Solo Buds. Photo by Billy Steele / Engadget EarFun Free Pro 3 The EarFun Free Pro 3 are totally solid, but the Space A40 gets you superior ANC, longer battery life and a more comfortable design for a lower price these days. EarFun Air 2 Along those lines, the EarFun Air 2 are a good alternative to EarFun’s Free 2S if you’re partial an AirPods-style stem design, but they cost $10 more and aren’t significantly better. Baseus Bowie MA10 The Baseus Bowie MA10 are saddled with a ginormous charging case, a sloppy app and bulky earpieces that we found uncomfortable to wear over time. Baseus Eli Sport 1 The Baseus Eli Sport 1 have a fully open design that wraps around the ear and rests outside of your ear canal entirely. That’s nice for staying alert to the outside world, but it’s less so for getting the most detail out of your music. This is another pair with an oversized case, too. OnePlus Buds 3 The OnePlus Buds 3 have an excited sound and a stylish design in the same vein as the Soundcore Liberty 4 NC, and their mic is a bit clearer for phone calls. They fall short of Anker’s pair when it comes to noise cancellation and battery life, however. Skullcandy Dime 3 The Skullcandy Dime 3 deliver a surprisingly neutral sound profile for their dirt-cheap price, so they’re worth considering over the JLab Go Pop ANC if you see them in the $25 range. Like that pair, they can also connect to two devices simultaneously. But their overall battery life is a bit shorter, their call quality is poor and their physical controls are both unintuitive and uncomfortable, since they lead you to push the buds deeper into your ear canals. Skullcandy Smokin' Buds The Skullcandy Smokin’ Buds are another ultra-budget option with a sick name, bro, but they sound harsher in the treble than the JLab Go Pop ANC and offer worse battery life through their charging case. This pair does use tap-based controls, but they can be finicky, and they still aren’t the most straightforward things to operate. Best cheap wireless earbuds: FAQs The JLab Go Pop ANC (left) and EarFun Air Pro 4. Jeff Dunn for Engadget What are the biggest differences between cheaper earbuds and more premium models? A higher price does not guarantee higher quality. We'd take a pair like the Anker Soundcore Space A40 over many alternatives priced well over $100. Broadly speaking, though, the pricier components used by the best wireless earbuds let them put out a more detailed and versatile sound, more powerful active noise cancellation and a more complete list of features like multipoint connectivity, faster pairing, wear detection or wireless charging. They generally feel less flimsy in the hand, and their companion software tends to be less buggy. Battery life may be longer as well. But you have to look at these things on a case-by-case basis: Some earbuds justify their cost, others very much do not. Can you improve the sound of cheap wireless earbuds? Evaluating audio quality is always subjective to some extent — what I find \"bloated,\" you may consider \"fun\" or \"lively.\" In general, if a set of earbuds is tuned poorly or built with cheap materials, you can't magically fix that. However, most new pairs allow you to adjust their EQ curve through software, so you can sculpt the frequency ranges in a way that better suits your tastes, at least somewhat. Also, remember that fit is king: If your in-ear headphones aren't sealed tight enough, they'll inevitably sound less detailed, with weaker bass response and worse isolation from outside noise. Consider trying different ear tips in that case. Can cheap earbuds sound as good as AirPods? A few can, sure! I'd take the top-end AirPods Pro 3 over any of the top picks in this guide, but they are far from unassailable. Meanwhile, the AirPods 4's unsealed design prevents them from pumping out truly deep bass, and I find them to sound a bit veiled in the treble. (They're still a level above the open-back Amazon Echo Buds, though.) The big appeal with AirPods is how tightly they integrate with other Apple devices: You open them with an iPhone and they just work. No other earbuds can replicate that, cheap or otherwise, because Apple uses proprietary tech that prevents competitors from offering the same features. Again, price and advertising budget has little to do with how good a set of earbuds is. (This is a silly question, but we know some casual buyers will inevitably ask it.) Recent updates October 2025: We’ve made a few light edits to ensure our recommendations are still up-to-date. June 2025: We’ve ensured our picks are still accurate and added testing notes on Skullcandy’s Method 360 ANC. April 2025: The JLab Go Sport+ replaces the older JLab Go Air Sport as our “best for workouts” pick. We’ve also added testing notes on the EarFun Air Pro 4 and JLab Go Pop ANC, removing our blurbs for their predecessors along the way. December 2024: We’ve lightly edited this guide for clarity and moved the aging JLab Go Air Pop and EarFun Air Pro 3 from honorable mentions to our “others we tested” section. September 2024: We’ve added notes on a handful of other budget wireless earbuds that we’ve tested but fall short of our top picks, which remain unchanged. June 2024: We’ve checked this guide to ensure that all of our picks are still in stock. Accordingly, we’ve removed the Nothing Ear Stick as an honorable mention, as it no longer appears to be available — though it remains a decent option if you do see it and want an unsealed alternative to the Amazon Echo Buds. We’re also still in the process of testing several other sub-$100 Bluetooth earbuds for a future update.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-budget-wireless-earbuds-130028735.html?src=rss",
          "content": "Big-name brands like Apple, Sony, and Bose tend to dominate the headlines when it comes to wireless earbuds, but that doesn’t mean you need to spend a ton to get something good. It’s more than possible to find a pair with clean sound, strong noise cancellation and a rich set of features for less than $100. That said, there’s still plenty of junk in the bargain bin, so you need to be careful.If you’re looking to make an audio upgrade on the cheap, we’ve read countless reviews, compared specs and tested a few dozen models ourselves to find the best budget wireless earbuds you can buy. This is a busy market with new options releasing all the time, but you can find our current favorites below. Table of contents Best budget wireless earbuds for 2025 Other budget wireless earbuds we tested Best cheap wireless earbuds: FAQs Recent updates Best budget wireless earbuds for 2025 Other budget wireless earbuds we tested The Skullcandy Method 360 ANC. Jeff Dunn for Engadget Note: This is a selection of noteworthy earbuds we’ve put through their paces, not a comprehensive list of everything we’ve ever tried. Skullcandy Method 360 ANC The Skullcandy Method 360 ANC is often available for $100, and at that price it’s worth considering over our picks above. These earphones have an extremely V-shaped sound signature with thunderous bass and noticeably clearer highs than the Soundcore Space A40, along with decent ANC and a bulky yet comfortable design that takes after Bose’s old QuietComfort Ultra Earbuds. They technically have a list price of $130, however, which puts them over the $100 limit we have for picks in this guide. Their enormous case and lack of wireless charging don’t help either. You can read our review for a full breakdown. Beats Solo Buds The $80 Beats Solo Buds are comfortable and long-lasting, with an impressive 18 hours of battery life. But they sound a bit flat and are severely lacking in features. There’s no ANC, wear detection or official water-resistance rating, and the included case can’t wirelessly charge the earbuds on its own. You can read our full review for more details. JLab Go Pop ANC The $30 JLab Go Pop ANC is worth a look if you just want a competent pair of wireless earphones for as little money as possible. It’s the cheapest set we’ve tested with active noise cancellation and transparency mode, though neither feature is all that effective. Like the Go Sport+, it also relies on a short USB-C cable tethered to its case to charge. But it actually sounds OK for the price: not particularly wide or detailed, but not harsh either, with decent energy and bass punch. The tiny earpieces fit snugly and isolate a good chunk of background noise passively. They’re also IP55-rated, while the case is similarly compact. There’s no auto-pausing, but you can connect to two devices at once, the touch controls work well and JLab’s app makes it easy to adjust settings. Battery life is alright at six to seven hours, too, though this is another one that’ll get wrecked by the wind if you take a call outside. The JLab Go Pop+ is another option here. It gives up the ANC, IP55 rating and multipoint connectivity, but it costs $5 less and has longer battery life. EarFun Air Pro 4 We liked what we heard from the EarFun Air Pro 4 for about a day or so — then one earbud broke, apparently deciding that it would only play at an extremely low volume from that point on. We’ve seen a few users report the same issue, while others have noted problems with crackling sounds coming out of single earpieces. This pair has received heaps of praise from other outlets, and we generally liked its predecessor, so it may well work for you. But we can’t recommend something that died before we could finish testing it. The Beats Solo Buds. Photo by Billy Steele / Engadget EarFun Free Pro 3 The EarFun Free Pro 3 are totally solid, but the Space A40 gets you superior ANC, longer battery life and a more comfortable design for a lower price these days. EarFun Air 2 Along those lines, the EarFun Air 2 are a good alternative to EarFun’s Free 2S if you’re partial an AirPods-style stem design, but they cost $10 more and aren’t significantly better. Baseus Bowie MA10 The Baseus Bowie MA10 are saddled with a ginormous charging case, a sloppy app and bulky earpieces that we found uncomfortable to wear over time. Baseus Eli Sport 1 The Baseus Eli Sport 1 have a fully open design that wraps around the ear and rests outside of your ear canal entirely. That’s nice for staying alert to the outside world, but it’s less so for getting the most detail out of your music. This is another pair with an oversized case, too. OnePlus Buds 3 The OnePlus Buds 3 have an excited sound and a stylish design in the same vein as the Soundcore Liberty 4 NC, and their mic is a bit clearer for phone calls. They fall short of Anker’s pair when it comes to noise cancellation and battery life, however. Skullcandy Dime 3 The Skullcandy Dime 3 deliver a surprisingly neutral sound profile for their dirt-cheap price, so they’re worth considering over the JLab Go Pop ANC if you see them in the $25 range. Like that pair, they can also connect to two devices simultaneously. But their overall battery life is a bit shorter, their call quality is poor and their physical controls are both unintuitive and uncomfortable, since they lead you to push the buds deeper into your ear canals. Skullcandy Smokin' Buds The Skullcandy Smokin’ Buds are another ultra-budget option with a sick name, bro, but they sound harsher in the treble than the JLab Go Pop ANC and offer worse battery life through their charging case. This pair does use tap-based controls, but they can be finicky, and they still aren’t the most straightforward things to operate. Best cheap wireless earbuds: FAQs The JLab Go Pop ANC (left) and EarFun Air Pro 4. Jeff Dunn for Engadget What are the biggest differences between cheaper earbuds and more premium models? A higher price does not guarantee higher quality. We'd take a pair like the Anker Soundcore Space A40 over many alternatives priced well over $100. Broadly speaking, though, the pricier components used by the best wireless earbuds let them put out a more detailed and versatile sound, more powerful active noise cancellation and a more complete list of features like multipoint connectivity, faster pairing, wear detection or wireless charging. They generally feel less flimsy in the hand, and their companion software tends to be less buggy. Battery life may be longer as well. But you have to look at these things on a case-by-case basis: Some earbuds justify their cost, others very much do not. Can you improve the sound of cheap wireless earbuds? Evaluating audio quality is always subjective to some extent — what I find \"bloated,\" you may consider \"fun\" or \"lively.\" In general, if a set of earbuds is tuned poorly or built with cheap materials, you can't magically fix that. However, most new pairs allow you to adjust their EQ curve through software, so you can sculpt the frequency ranges in a way that better suits your tastes, at least somewhat. Also, remember that fit is king: If your in-ear headphones aren't sealed tight enough, they'll inevitably sound less detailed, with weaker bass response and worse isolation from outside noise. Consider trying different ear tips in that case. Can cheap earbuds sound as good as AirPods? A few can, sure! I'd take the top-end AirPods Pro 3 over any of the top picks in this guide, but they are far from unassailable. Meanwhile, the AirPods 4's unsealed design prevents them from pumping out truly deep bass, and I find them to sound a bit veiled in the treble. (They're still a level above the open-back Amazon Echo Buds, though.) The big appeal with AirPods is how tightly they integrate with other Apple devices: You open them with an iPhone and they just work. No other earbuds can replicate that, cheap or otherwise, because Apple uses proprietary tech that prevents competitors from offering the same features. Again, price and advertising budget has little to do with how good a set of earbuds is. (This is a silly question, but we know some casual buyers will inevitably ask it.) Recent updates October 2025: We’ve made a few light edits to ensure our recommendations are still up-to-date. June 2025: We’ve ensured our picks are still accurate and added testing notes on Skullcandy’s Method 360 ANC. April 2025: The JLab Go Sport+ replaces the older JLab Go Air Sport as our “best for workouts” pick. We’ve also added testing notes on the EarFun Air Pro 4 and JLab Go Pop ANC, removing our blurbs for their predecessors along the way. December 2024: We’ve lightly edited this guide for clarity and moved the aging JLab Go Air Pop and EarFun Air Pro 3 from honorable mentions to our “others we tested” section. September 2024: We’ve added notes on a handful of other budget wireless earbuds that we’ve tested but fall short of our top picks, which remain unchanged. June 2024: We’ve checked this guide to ensure that all of our picks are still in stock. Accordingly, we’ve removed the Nothing Ear Stick as an honorable mention, as it no longer appears to be available — though it remains a decent option if you do see it and want an unsealed alternative to the Amazon Echo Buds. We’re also still in the process of testing several other sub-$100 Bluetooth earbuds for a future update.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-budget-wireless-earbuds-130028735.html?src=rss",
          "feed_position": 18,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-05/777a5450-3673-11f0-af3f-d914145d5d26"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/dfinity-launches-caffeine-an-ai-platform-that-builds-production-apps-from",
          "published_at": "Wed, 15 Oct 2025 09:00:00 GMT",
          "title": "Dfinity launches Caffeine, an AI platform that builds production apps from natural language prompts",
          "standfirst": "The Dfinity Foundation on Wednesday released Caffeine, an artificial intelligence platform that allows users to build and deploy web applications through natural language conversation alone, bypassing traditional coding entirely. The system, which became publicly available today, represents a fundamental departure from existing AI coding assistants by building applications on a specialized decentralized infrastructure designed specifically for autonomous AI development.Unlike GitHub Copilot, Cursor, or other \"vibe coding\" tools that help human developers write code faster, Caffeine positions itself as a complete replacement for technical teams. Users describe what they want in plain language, and an ensemble of AI models writes, deploys, and continually updates production-grade applications — with no human intervention in the codebase itself.\"In the future, you as a prospective app owner or service owner… will talk to AI. AI will give you what you want on a URL,\" said Dominic Williams, founder and chief scientist at the Dfinity Foundation, in an exclusive interview with VentureBeat. \"You will use that, completely interact productively, and you&#x27;ll just keep talking to AI to evolve what that does. The AI, or an ensemble of AIs, will be your tech team.\"The platform has attracted significant early interest: more than 15,000 alpha users tested Caffeine before its public release, with daily active users representing 26% of those who received access codes — \"early Facebook kind of levels,\" according to Williams. The foundation reports some users spending entire days building applications on the platform, forcing Dfinity to consider usage limits due to underlying AI infrastructure costs.Why Caffeine&#x27;s custom programming language guarantees your data won&#x27;t disappearCaffeine&#x27;s most significant technical claim addresses a problem that has plagued AI-generated code: data loss during application updates. The platform builds applications using Motoko, a programming language developed by Dfinity specifically for AI use, which provides mathematical guarantees that upgrades cannot accidentally delete user data.\"When AI is updating apps and services in production, a mistake cannot lose data. That&#x27;s a guarantee,\" Williams said. \"It&#x27;s not like there are some safeguards to try and stop it losing data. This language framework gives it rails that guarantee if an upgrade, an update to its app&#x27;s underlying logic, would cause data loss, the upgrade fails and the AI just tries again.\"This addresses what Williams characterizes as critical failures in competing platforms. User forums for tools like Lovable and Replit, he notes, frequently report three major problems: applications that become irreparably broken as complexity increases, security vulnerabilities that allow unauthorized access, and mysterious data loss during updates.Traditional tech stacks evolved to meet human developer needs — familiarity with SQL databases, preference for known programming languages, existing skill investments. \"That&#x27;s how the traditional tech stacks evolved. It&#x27;s really evolved to meet human needs,\" Williams explained. \"But in the future, it&#x27;s going to be different. You&#x27;re not going to care how the AI did it. Instead, for you, AI is the tech stack.\"Caffeine&#x27;s architecture reflects this philosophy. Applications run entirely on the Internet Computer Protocol (ICP), a blockchain-based network that Dfinity launched in May 2021 after raising over $100 million from investors including Andreessen Horowitz and Polychain Capital. The ICP uses what Dfinity calls \"chain-key cryptography\" to create what Williams describes as \"tamper-proof\" code — applications that are mathematically guaranteed to execute their written logic without interference from traditional cyberattacks.\"The code can&#x27;t be affected by ransomware, so you don&#x27;t have to worry about malware in the same way you do,\" Williams said. \"Configuration errors don&#x27;t result in traditional cyber attacks. That passive traditional cyber attacks isn&#x27;t something you need to worry about.\"How &#x27;orthogonal persistence&#x27; lets AI build apps without managing databasesAt the heart of Caffeine&#x27;s technical approach is a concept called \"orthogonal persistence,\" which fundamentally reimagines how applications store and manage data. In traditional development, programmers must write extensive code to move data between application logic and separate database systems — marshaling data in and out of SQL servers, managing connections, handling synchronization.Motoko eliminates this entirely. Williams demonstrated with a simple example: defining a blog post data type and declaring a variable to store an array of posts requires just two lines of code. \"This declaration is all that&#x27;s necessary to have the blog maintain its list of posts,\" he explained during a presentation on the technology. \"Compare that to traditional IT where in order to persist the blog posts, you&#x27;d have to marshal them in and out of a database server. This is quite literally orders of magnitude more simple.\"This abstraction allows AI to work at a higher conceptual level, focusing on application logic rather than infrastructure plumbing. \"Logic and data are kind of the same,\" Williams said. \"This is one of the things that enables AI to build far more complicated functionality than it could otherwise do.\"The system also employs what Dfinity calls \"loss-safe data migration.\" When AI needs to modify an application&#x27;s data structure — adding a \"likes\" field to blog posts, for example — it must write migration logic in two passes. The framework automatically verifies that the transformation won&#x27;t result in data loss, refusing to compile or deploy code that could delete information unless explicitly instructed.From million-dollar SaaS contracts to conversational app building in minutesWilliams positions Caffeine as particularly transformative for enterprise IT, where he claims costs could fall to \"1% of what they were before\" while time-to-market shrinks to similar fractions. The platform targets a spectrum from individual creators to large corporations, all of whom currently face either expensive development teams or constraining low-code templates.\"A corporation or government department might want to create a corporate portal or CRM, ERP functionality,\" Williams said, referring to customer relationship management and enterprise resource planning systems. \"They will otherwise have to obtain this by signing up for some incredibly expensive SaaS service where they become locked in, their data gets stuck, and they still have to spend a lot of money on consultants customizing the functionality.\"Applications built through Caffeine are owned entirely by their creators and cannot be shut down by centralized parties — a consequence of running on the decentralized Internet Computer network rather than traditional cloud providers like Amazon Web Services. \"When someone says built on the internet computer, it actually means built on the internet computer,\" Williams emphasized, contrasting this with blockchain projects that merely host tokens while running actual applications on centralized infrastructure.The platform demonstrated this versatility during a July 2025 hackathon in San Francisco, where participants created applications ranging from a \"Will Maker\" tool for generating legal documents, to \"Blue Lens,\" a voice-AI water quality monitoring system, to \"Road Patrol,\" a gamified community reporting app for infrastructure problems. Critically, many of these came from non-technical participants with no coding background.\"I&#x27;m from a non-technical background, I&#x27;m actually a quality assurance professional,\" said the creator of Blue Lens in a video testimonial. \"Through Caffeine I can build something really intuitive and next-gen to the public.\" The application integrated multiple external services — Eleven Labs for voice AI, real-time government water data through retrieval-augmented generation, and Midjourney-generated visual assets — all coordinated through conversational prompts.What separates Caffeine from GitHub Copilot, Cursor, and the &#x27;vibe coding&#x27; waveCaffeine enters a crowded market of AI-assisted development tools, but Williams argues the competition isn&#x27;t truly comparable. GitHub Copilot, Cursor, and similar tools serve human developers working with traditional technology stacks. Platforms like Replit and Lovable occupy a middle ground, offering \"vibe coding\" that mixes AI generation with human editing.\"If you&#x27;re a Node.js developer, you know you&#x27;re working with the traditional stack, and you might want to do your coding with Copilot or using Claude or using Cursor,\" Williams said. \"That&#x27;s a very different thing to what Caffeine is offering. There&#x27;ll always be cases where you probably wouldn&#x27;t want to hand over the logic of the control system for a new nuclear missile silo to AI. But there&#x27;s going to be these holdout areas, right? And there&#x27;s all the legacy stuff that has to be maintained.\"The key distinction, according to Williams, lies in production readiness. Existing AI coding tools excel at rapid prototyping but stumble when applications grow complex or require guaranteed reliability. Reddit forums for these platforms document users hitting insurmountable walls where applications break irreparably, or where AI-generated code introduces security vulnerabilities.\"As the demands and the requirements become more complicated, eventually you can hit a limit, and when you hit that limit, not only can you not go any further, but sometimes your app will get broken and there&#x27;s no way of going back to where you were before,\" Williams said. \"That can&#x27;t happen with productive apps, and it also can&#x27;t be the case that you&#x27;re getting hacked and losing data, because once you go hands-free, if you like, and there&#x27;s no tech team, there&#x27;s no technical people involved, who&#x27;s going to run the backups and restore your app?\"The Internet Computer&#x27;s architecture addresses this through Byzantine fault tolerance — even if attackers gain physical control over some network hardware, they cannot corrupt applications or their data. \"This is the beginning of a compute revolution and it&#x27;s also the perfect platform for AI to build on,\" Williams said.Inside the vision: A web that programs itself through natural languageDfinity frames Caffeine within a broader vision it calls the \"self-writing internet,\" where the web literally programs itself through natural language interaction. This represents what Williams describes as a \"seismic shift coming to tech\" — from human developers selecting technology stacks based on their existing skills, to AI selecting optimal implementations invisible to users.\"You don&#x27;t care about whether some human being has learned all of the different platforms and Amazon Web Services or something like that. You don&#x27;t care about that. You just care: Is it secure? Do you get security guarantees? Is it resilient? What&#x27;s the level of resilience?\" Williams said. \"Those are the new parameters.\"The platform demonstrated this during live demonstrations, including at the World Computer Summit 2025 in Zurich. Williams created a talent recruitment application from scratch in under two minutes, then modified it in real-time while the application ran with users already interacting with it. \"You will continue talking to the AI and just keep on refreshing the URL to see the changes,\" he explained.This capability extends to complex scenarios. During demonstrations, Williams showed building a tennis lesson booking system, an e-commerce platform, and an event registration system — all simultaneously, working on multiple applications in parallel. \"We predict that as people get very proficient with Caffeine, they could be working on even 10 apps in parallel,\" he said.The system writes substantial code: a simple personal blog generated 700 lines of code in a couple of minutes. More complex applications can involve thousands of lines across frontend and backend components, all abstracted away from the user who only describes desired functionality.The economics of cloning: How Caffeine&#x27;s app market challenges traditional storesCaffeine&#x27;s economic model differs fundamentally from traditional software-as-a-service platforms. Applications run on the Internet Computer Protocol, which uses a \"reverse gas model\" where developers pay for computation rather than users paying transaction fees. The platform includes an integrated App Market where creators can publish applications for others to clone and adapt — creating what Dfinity envisions as a new economic ecosystem.\"App stores today obviously operate on gatekeeping,\" said Pierre Samaties, chief business officer at Dfinity, during the World Computer Summit. \"That&#x27;s going to erode.\" Rather than purchasing applications, users can clone them and modify them for their own purposes — fundamentally different from Apple&#x27;s App Store or Google Play models.Williams acknowledges that Caffeine itself currently runs on centralized infrastructure, despite building applications on the decentralized Internet Computer. \"Caffeine itself actually is centralized. It uses aspects of the Internet Computer. We want Caffeine itself to run on the Internet Computer in the future, but it&#x27;s not there now,\" he said. The platform leverages commercially available foundation models from companies like Anthropic, whose Claude Sonnet model powers much of Caffeine&#x27;s backend logic.This pragmatic approach reflects Dfinity&#x27;s strategy of using best-in-class AI models while focusing its own development on the specialized infrastructure and programming language designed for AI use. \"These content models have been developed by companies with enormous budgets, absolutely enormous budgets,\" Williams said. \"I don&#x27;t think in the near future we&#x27;ll run AI on the Internet Computer for that reason, unless there&#x27;s a special case.\"A decade in the making: From Ethereum roots to the self-writing internetThe Dfinity Foundation has pursued this vision since Williams began researching decentralized networks in late 2013. After involvement with Ethereum before its 2015 launch, Williams became fascinated with the concept of a \"world computer\"—a public blockchain network that could host not just tokens but entire applications and services.\"By 2015 I was talking about network-focused drivers, Dfinity back then, and that could really operate as an alternative tech stack, and eventually host even things like social networks and massive enterprise systems,\" Williams said. The foundation launched the Internet Computer Protocol in May 2021, initially focusing on Web3 developers. Despite not being among the highest-valued blockchain projects, ICP consistently ranks in the top 10 for developer numbers.The pivot to AI-driven development came from recognizing that \"in the future, the tech stack will be AI,\" according to Williams. This realization led to Caffeine&#x27;s development, announced on Dfinity&#x27;s public roadmap in March 2025 and demonstrated at the World Computer Summit in June 2025.One successful example of the Dfinity vision running in production is OpenChat, a messaging application that runs entirely on the Internet Computer and is governed by a decentralized autonomous organization (DAO) with tens of thousands of participants voting on source code updates through algorithmic governance. \"The community is actually controlling the source code updates,\" Williams explained. \"Developers propose updates, community reads the updates, and if the community is happy, OpenChat updates itself.\"The skeptics weigh in: Crypto baggage and real-world testing aheadThe platform faces several challenges. Dfinity&#x27;s crypto industry roots may create perception problems in enterprise markets, Williams acknowledges. \"The Web3 industry&#x27;s reputation is a bit tarnished and probably rightfully so,\" he said during the World Computer Summit. \"Now people can, for themselves, experience what a decentralized network is. We&#x27;re going to see self-writing take over the enterprise space because the speed and efficiency are just incredible.\"The foundation&#x27;s history includes controversy: ICP&#x27;s token launched in 2021 at over $100 per token with an all-time high around $700, then crashed below $3 in 2023 before recovering. The project has faced legal challenges, including class action lawsuits alleging misleading investors, and Dfinity filed defamation claims against industry critics.Technical limitations also remain. Caffeine cannot yet compile React front-ends on the Internet Computer itself, requiring some off-chain processing. Complex integrations with traditional systems — payment processing through Stripe, for example — still require centralized components. \"Your app is running end-to-end on the Internet Computer, then when it needs to actually accept payment, it&#x27;s going to hand over to your Stripe account,\" Williams explained.The platform&#x27;s claims about data loss prevention and security guarantees, while technically grounded in the Motoko language design and Internet Computer architecture, remain to be tested at scale with diverse real-world applications. The 26% daily active user rate from alpha testing is impressive but comes from a self-selected group of early adopters.When five billion smartphone users become developersWilliams rejects concerns that AI-driven development will eliminate software engineering jobs, arguing instead for market expansion. \"The self-writing internet empowers eight billion non-technical people,\" he said. \"Some of these people will enter roles in tech, becoming prompt engineers, tech entrepreneurs, or helping run online communities. Humanity will create millions of new custom apps and services, and a subset of those will require professional human assistance.\"During his World Computer Summit demonstration, Williams was explicit about the scale of transformation Dfinity envisions. \"Today there are about 35,000 Web3 engineers in the world. Worldwide there are about 15 million full-stack engineers,\" he said. \"But tomorrow with the self-writing internet, everyone will be a builder. Today there are already about five billion people with internet-connected smartphones and they&#x27;ll all be able to use Caffeine.\"The hackathon results suggest this isn&#x27;t pure hyperbole. A dentist built \"Dental Tracks\" to help patients manage their dental records. A transportation industry professional created \"Road Patrol\" for gamified infrastructure reporting. A frustrated knitting student built \"Skill Sprout,\" a garden-themed app for learning new hobbies, complete with material checklists and step-by-step skill breakdowns—all without writing a single line of code.\"I was learning to knit. I got irritated because I had the wrong materials,\" the creator explained in a video interview. \"I don&#x27;t know how to do the stitches, so I have to individually search, and it&#x27;s really intimidating when you&#x27;re trying to learn something you don&#x27;t—you don&#x27;t even know what you don&#x27;t know.\"Whether Caffeine succeeds depends on factors still unknown: how production applications perform under real-world stress, whether the Internet Computer scales to millions of applications, whether enterprises can overcome their skepticism of blockchain-adjacent technology. But if Williams is right about the fundamental shift — that AI will be the tech stack, not just a tool for human developers — then someone will build what Caffeine promises.The question isn&#x27;t whether the future looks like this. It&#x27;s who gets there first, and whether they can do it without losing everyone&#x27;s data along the way.",
          "content": "The Dfinity Foundation on Wednesday released Caffeine, an artificial intelligence platform that allows users to build and deploy web applications through natural language conversation alone, bypassing traditional coding entirely. The system, which became publicly available today, represents a fundamental departure from existing AI coding assistants by building applications on a specialized decentralized infrastructure designed specifically for autonomous AI development.Unlike GitHub Copilot, Cursor, or other \"vibe coding\" tools that help human developers write code faster, Caffeine positions itself as a complete replacement for technical teams. Users describe what they want in plain language, and an ensemble of AI models writes, deploys, and continually updates production-grade applications — with no human intervention in the codebase itself.\"In the future, you as a prospective app owner or service owner… will talk to AI. AI will give you what you want on a URL,\" said Dominic Williams, founder and chief scientist at the Dfinity Foundation, in an exclusive interview with VentureBeat. \"You will use that, completely interact productively, and you&#x27;ll just keep talking to AI to evolve what that does. The AI, or an ensemble of AIs, will be your tech team.\"The platform has attracted significant early interest: more than 15,000 alpha users tested Caffeine before its public release, with daily active users representing 26% of those who received access codes — \"early Facebook kind of levels,\" according to Williams. The foundation reports some users spending entire days building applications on the platform, forcing Dfinity to consider usage limits due to underlying AI infrastructure costs.Why Caffeine&#x27;s custom programming language guarantees your data won&#x27;t disappearCaffeine&#x27;s most significant technical claim addresses a problem that has plagued AI-generated code: data loss during application updates. The platform builds applications using Motoko, a programming language developed by Dfinity specifically for AI use, which provides mathematical guarantees that upgrades cannot accidentally delete user data.\"When AI is updating apps and services in production, a mistake cannot lose data. That&#x27;s a guarantee,\" Williams said. \"It&#x27;s not like there are some safeguards to try and stop it losing data. This language framework gives it rails that guarantee if an upgrade, an update to its app&#x27;s underlying logic, would cause data loss, the upgrade fails and the AI just tries again.\"This addresses what Williams characterizes as critical failures in competing platforms. User forums for tools like Lovable and Replit, he notes, frequently report three major problems: applications that become irreparably broken as complexity increases, security vulnerabilities that allow unauthorized access, and mysterious data loss during updates.Traditional tech stacks evolved to meet human developer needs — familiarity with SQL databases, preference for known programming languages, existing skill investments. \"That&#x27;s how the traditional tech stacks evolved. It&#x27;s really evolved to meet human needs,\" Williams explained. \"But in the future, it&#x27;s going to be different. You&#x27;re not going to care how the AI did it. Instead, for you, AI is the tech stack.\"Caffeine&#x27;s architecture reflects this philosophy. Applications run entirely on the Internet Computer Protocol (ICP), a blockchain-based network that Dfinity launched in May 2021 after raising over $100 million from investors including Andreessen Horowitz and Polychain Capital. The ICP uses what Dfinity calls \"chain-key cryptography\" to create what Williams describes as \"tamper-proof\" code — applications that are mathematically guaranteed to execute their written logic without interference from traditional cyberattacks.\"The code can&#x27;t be affected by ransomware, so you don&#x27;t have to worry about malware in the same way you do,\" Williams said. \"Configuration errors don&#x27;t result in traditional cyber attacks. That passive traditional cyber attacks isn&#x27;t something you need to worry about.\"How &#x27;orthogonal persistence&#x27; lets AI build apps without managing databasesAt the heart of Caffeine&#x27;s technical approach is a concept called \"orthogonal persistence,\" which fundamentally reimagines how applications store and manage data. In traditional development, programmers must write extensive code to move data between application logic and separate database systems — marshaling data in and out of SQL servers, managing connections, handling synchronization.Motoko eliminates this entirely. Williams demonstrated with a simple example: defining a blog post data type and declaring a variable to store an array of posts requires just two lines of code. \"This declaration is all that&#x27;s necessary to have the blog maintain its list of posts,\" he explained during a presentation on the technology. \"Compare that to traditional IT where in order to persist the blog posts, you&#x27;d have to marshal them in and out of a database server. This is quite literally orders of magnitude more simple.\"This abstraction allows AI to work at a higher conceptual level, focusing on application logic rather than infrastructure plumbing. \"Logic and data are kind of the same,\" Williams said. \"This is one of the things that enables AI to build far more complicated functionality than it could otherwise do.\"The system also employs what Dfinity calls \"loss-safe data migration.\" When AI needs to modify an application&#x27;s data structure — adding a \"likes\" field to blog posts, for example — it must write migration logic in two passes. The framework automatically verifies that the transformation won&#x27;t result in data loss, refusing to compile or deploy code that could delete information unless explicitly instructed.From million-dollar SaaS contracts to conversational app building in minutesWilliams positions Caffeine as particularly transformative for enterprise IT, where he claims costs could fall to \"1% of what they were before\" while time-to-market shrinks to similar fractions. The platform targets a spectrum from individual creators to large corporations, all of whom currently face either expensive development teams or constraining low-code templates.\"A corporation or government department might want to create a corporate portal or CRM, ERP functionality,\" Williams said, referring to customer relationship management and enterprise resource planning systems. \"They will otherwise have to obtain this by signing up for some incredibly expensive SaaS service where they become locked in, their data gets stuck, and they still have to spend a lot of money on consultants customizing the functionality.\"Applications built through Caffeine are owned entirely by their creators and cannot be shut down by centralized parties — a consequence of running on the decentralized Internet Computer network rather than traditional cloud providers like Amazon Web Services. \"When someone says built on the internet computer, it actually means built on the internet computer,\" Williams emphasized, contrasting this with blockchain projects that merely host tokens while running actual applications on centralized infrastructure.The platform demonstrated this versatility during a July 2025 hackathon in San Francisco, where participants created applications ranging from a \"Will Maker\" tool for generating legal documents, to \"Blue Lens,\" a voice-AI water quality monitoring system, to \"Road Patrol,\" a gamified community reporting app for infrastructure problems. Critically, many of these came from non-technical participants with no coding background.\"I&#x27;m from a non-technical background, I&#x27;m actually a quality assurance professional,\" said the creator of Blue Lens in a video testimonial. \"Through Caffeine I can build something really intuitive and next-gen to the public.\" The application integrated multiple external services — Eleven Labs for voice AI, real-time government water data through retrieval-augmented generation, and Midjourney-generated visual assets — all coordinated through conversational prompts.What separates Caffeine from GitHub Copilot, Cursor, and the &#x27;vibe coding&#x27; waveCaffeine enters a crowded market of AI-assisted development tools, but Williams argues the competition isn&#x27;t truly comparable. GitHub Copilot, Cursor, and similar tools serve human developers working with traditional technology stacks. Platforms like Replit and Lovable occupy a middle ground, offering \"vibe coding\" that mixes AI generation with human editing.\"If you&#x27;re a Node.js developer, you know you&#x27;re working with the traditional stack, and you might want to do your coding with Copilot or using Claude or using Cursor,\" Williams said. \"That&#x27;s a very different thing to what Caffeine is offering. There&#x27;ll always be cases where you probably wouldn&#x27;t want to hand over the logic of the control system for a new nuclear missile silo to AI. But there&#x27;s going to be these holdout areas, right? And there&#x27;s all the legacy stuff that has to be maintained.\"The key distinction, according to Williams, lies in production readiness. Existing AI coding tools excel at rapid prototyping but stumble when applications grow complex or require guaranteed reliability. Reddit forums for these platforms document users hitting insurmountable walls where applications break irreparably, or where AI-generated code introduces security vulnerabilities.\"As the demands and the requirements become more complicated, eventually you can hit a limit, and when you hit that limit, not only can you not go any further, but sometimes your app will get broken and there&#x27;s no way of going back to where you were before,\" Williams said. \"That can&#x27;t happen with productive apps, and it also can&#x27;t be the case that you&#x27;re getting hacked and losing data, because once you go hands-free, if you like, and there&#x27;s no tech team, there&#x27;s no technical people involved, who&#x27;s going to run the backups and restore your app?\"The Internet Computer&#x27;s architecture addresses this through Byzantine fault tolerance — even if attackers gain physical control over some network hardware, they cannot corrupt applications or their data. \"This is the beginning of a compute revolution and it&#x27;s also the perfect platform for AI to build on,\" Williams said.Inside the vision: A web that programs itself through natural languageDfinity frames Caffeine within a broader vision it calls the \"self-writing internet,\" where the web literally programs itself through natural language interaction. This represents what Williams describes as a \"seismic shift coming to tech\" — from human developers selecting technology stacks based on their existing skills, to AI selecting optimal implementations invisible to users.\"You don&#x27;t care about whether some human being has learned all of the different platforms and Amazon Web Services or something like that. You don&#x27;t care about that. You just care: Is it secure? Do you get security guarantees? Is it resilient? What&#x27;s the level of resilience?\" Williams said. \"Those are the new parameters.\"The platform demonstrated this during live demonstrations, including at the World Computer Summit 2025 in Zurich. Williams created a talent recruitment application from scratch in under two minutes, then modified it in real-time while the application ran with users already interacting with it. \"You will continue talking to the AI and just keep on refreshing the URL to see the changes,\" he explained.This capability extends to complex scenarios. During demonstrations, Williams showed building a tennis lesson booking system, an e-commerce platform, and an event registration system — all simultaneously, working on multiple applications in parallel. \"We predict that as people get very proficient with Caffeine, they could be working on even 10 apps in parallel,\" he said.The system writes substantial code: a simple personal blog generated 700 lines of code in a couple of minutes. More complex applications can involve thousands of lines across frontend and backend components, all abstracted away from the user who only describes desired functionality.The economics of cloning: How Caffeine&#x27;s app market challenges traditional storesCaffeine&#x27;s economic model differs fundamentally from traditional software-as-a-service platforms. Applications run on the Internet Computer Protocol, which uses a \"reverse gas model\" where developers pay for computation rather than users paying transaction fees. The platform includes an integrated App Market where creators can publish applications for others to clone and adapt — creating what Dfinity envisions as a new economic ecosystem.\"App stores today obviously operate on gatekeeping,\" said Pierre Samaties, chief business officer at Dfinity, during the World Computer Summit. \"That&#x27;s going to erode.\" Rather than purchasing applications, users can clone them and modify them for their own purposes — fundamentally different from Apple&#x27;s App Store or Google Play models.Williams acknowledges that Caffeine itself currently runs on centralized infrastructure, despite building applications on the decentralized Internet Computer. \"Caffeine itself actually is centralized. It uses aspects of the Internet Computer. We want Caffeine itself to run on the Internet Computer in the future, but it&#x27;s not there now,\" he said. The platform leverages commercially available foundation models from companies like Anthropic, whose Claude Sonnet model powers much of Caffeine&#x27;s backend logic.This pragmatic approach reflects Dfinity&#x27;s strategy of using best-in-class AI models while focusing its own development on the specialized infrastructure and programming language designed for AI use. \"These content models have been developed by companies with enormous budgets, absolutely enormous budgets,\" Williams said. \"I don&#x27;t think in the near future we&#x27;ll run AI on the Internet Computer for that reason, unless there&#x27;s a special case.\"A decade in the making: From Ethereum roots to the self-writing internetThe Dfinity Foundation has pursued this vision since Williams began researching decentralized networks in late 2013. After involvement with Ethereum before its 2015 launch, Williams became fascinated with the concept of a \"world computer\"—a public blockchain network that could host not just tokens but entire applications and services.\"By 2015 I was talking about network-focused drivers, Dfinity back then, and that could really operate as an alternative tech stack, and eventually host even things like social networks and massive enterprise systems,\" Williams said. The foundation launched the Internet Computer Protocol in May 2021, initially focusing on Web3 developers. Despite not being among the highest-valued blockchain projects, ICP consistently ranks in the top 10 for developer numbers.The pivot to AI-driven development came from recognizing that \"in the future, the tech stack will be AI,\" according to Williams. This realization led to Caffeine&#x27;s development, announced on Dfinity&#x27;s public roadmap in March 2025 and demonstrated at the World Computer Summit in June 2025.One successful example of the Dfinity vision running in production is OpenChat, a messaging application that runs entirely on the Internet Computer and is governed by a decentralized autonomous organization (DAO) with tens of thousands of participants voting on source code updates through algorithmic governance. \"The community is actually controlling the source code updates,\" Williams explained. \"Developers propose updates, community reads the updates, and if the community is happy, OpenChat updates itself.\"The skeptics weigh in: Crypto baggage and real-world testing aheadThe platform faces several challenges. Dfinity&#x27;s crypto industry roots may create perception problems in enterprise markets, Williams acknowledges. \"The Web3 industry&#x27;s reputation is a bit tarnished and probably rightfully so,\" he said during the World Computer Summit. \"Now people can, for themselves, experience what a decentralized network is. We&#x27;re going to see self-writing take over the enterprise space because the speed and efficiency are just incredible.\"The foundation&#x27;s history includes controversy: ICP&#x27;s token launched in 2021 at over $100 per token with an all-time high around $700, then crashed below $3 in 2023 before recovering. The project has faced legal challenges, including class action lawsuits alleging misleading investors, and Dfinity filed defamation claims against industry critics.Technical limitations also remain. Caffeine cannot yet compile React front-ends on the Internet Computer itself, requiring some off-chain processing. Complex integrations with traditional systems — payment processing through Stripe, for example — still require centralized components. \"Your app is running end-to-end on the Internet Computer, then when it needs to actually accept payment, it&#x27;s going to hand over to your Stripe account,\" Williams explained.The platform&#x27;s claims about data loss prevention and security guarantees, while technically grounded in the Motoko language design and Internet Computer architecture, remain to be tested at scale with diverse real-world applications. The 26% daily active user rate from alpha testing is impressive but comes from a self-selected group of early adopters.When five billion smartphone users become developersWilliams rejects concerns that AI-driven development will eliminate software engineering jobs, arguing instead for market expansion. \"The self-writing internet empowers eight billion non-technical people,\" he said. \"Some of these people will enter roles in tech, becoming prompt engineers, tech entrepreneurs, or helping run online communities. Humanity will create millions of new custom apps and services, and a subset of those will require professional human assistance.\"During his World Computer Summit demonstration, Williams was explicit about the scale of transformation Dfinity envisions. \"Today there are about 35,000 Web3 engineers in the world. Worldwide there are about 15 million full-stack engineers,\" he said. \"But tomorrow with the self-writing internet, everyone will be a builder. Today there are already about five billion people with internet-connected smartphones and they&#x27;ll all be able to use Caffeine.\"The hackathon results suggest this isn&#x27;t pure hyperbole. A dentist built \"Dental Tracks\" to help patients manage their dental records. A transportation industry professional created \"Road Patrol\" for gamified infrastructure reporting. A frustrated knitting student built \"Skill Sprout,\" a garden-themed app for learning new hobbies, complete with material checklists and step-by-step skill breakdowns—all without writing a single line of code.\"I was learning to knit. I got irritated because I had the wrong materials,\" the creator explained in a video interview. \"I don&#x27;t know how to do the stitches, so I have to individually search, and it&#x27;s really intimidating when you&#x27;re trying to learn something you don&#x27;t—you don&#x27;t even know what you don&#x27;t know.\"Whether Caffeine succeeds depends on factors still unknown: how production applications perform under real-world stress, whether the Internet Computer scales to millions of applications, whether enterprises can overcome their skepticism of blockchain-adjacent technology. But if Williams is right about the fundamental shift — that AI will be the tech stack, not just a tool for human developers — then someone will build what Caffeine promises.The question isn&#x27;t whether the future looks like this. It&#x27;s who gets there first, and whether they can do it without losing everyone&#x27;s data along the way.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4KtYR3vJAj9O1BxMtYqm9e/aad83e291aadf8fd2f12e6cf45aeede9/nuneybits_Vector_art_of_coffee_made_of_computer_code_87b3e7a8-f103-4de0-ae47-d17717e023f9.webp"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/best-streaming-service-deals-133028980.html",
          "published_at": "Wed, 15 Oct 2025 07:01:26 +0000",
          "title": "The best streaming deals: Save on Hulu + Live TV, Audible, Starz and more",
          "standfirst": "Whether you’re a true cord-cutter or you just want to watch the next season of Stranger Things when it drops, everyone’s on the lookout for streaming deals nowadays. Plenty have chosen VOD and live TV streaming services over traditional cable in recent years, but the savings that choice got you just a few years ago have somewhat evaporated now. Companies like Netflix, Disney, Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think so, for many reasons, but you can (and should) be smart with your money at the same time. Streaming deals are an option, even if they don’t come around with the same regularity as discounts on AirPods do. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Audible subscription (three months) for $3 ($42 off): From now through mid-December, you can get Amazon’s audiobook subscription for just a dollar a month for three months. Note that it will auto-renew at $15 per month after that, but you can cancel at any point. Starz (one year) for $30 ($40 off): Pay upfront for one year and you can get $40 off a Stars annual subscription. There's a month-to-month option too, which costs $5 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month ($35 off): All of DirecTV's signature packages are $35 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Spotify Premium Individual (1 month) for $0 ($12 off): This is our favorite music streaming service for podcasts and social features. Right now, users who have not signed up for Spotify's Premium service before are eligible to get one month for free. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing as of October 21, 2025, accounting for the latest price hike. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$/8month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "content": "Whether you’re a true cord-cutter or you just want to watch the next season of Stranger Things when it drops, everyone’s on the lookout for streaming deals nowadays. Plenty have chosen VOD and live TV streaming services over traditional cable in recent years, but the savings that choice got you just a few years ago have somewhat evaporated now. Companies like Netflix, Disney, Max and others have been consistently raising prices to the point where you may question if streaming is even worth it anymore. We at Engadget still think so, for many reasons, but you can (and should) be smart with your money at the same time. Streaming deals are an option, even if they don’t come around with the same regularity as discounts on AirPods do. If you’re looking to save money and still stream all of the content you want, Engadget can help by laying out the best streaming deals you can get right now, how you can save with bundles and everything you should know before paying for yet another streaming service. Best streaming deals True streaming deals can be hard to come by. Most often, they’ll pop up during the Black Friday shopping period. On occasion, we’ll see them sparingly throughout the year and they usually take the form of a discounted monthly or annual rate for a limited period of time. Also, true streaming deals are typically on the ad-supported versions of a service, but once in a while you’ll find a unicorn of a deal on a tier that has ad-free viewing. If you’re able to wait for a deal before subscribing to a streaming service, we recommend doing so. You’ll save money upfront and in the long run, and you also have the option to cancel your subscription before the price goes back up to the normal rate. Audible subscription (three months) for $3 ($42 off): From now through mid-December, you can get Amazon’s audiobook subscription for just a dollar a month for three months. Note that it will auto-renew at $15 per month after that, but you can cancel at any point. Starz (one year) for $30 ($40 off): Pay upfront for one year and you can get $40 off a Stars annual subscription. There's a month-to-month option too, which costs $5 per month for the first three months if you don't want to commit to the full year. Either option gives you access to the entire Starz TV and movie library with offline viewing and no ads. Fubo Pro for $55/month for the first month ($30 off): Fubo has introductory discounts on most of its packages, and the Pro package is the least expensive plan currently listed. It offers access to 224 channels, unlimited cloud DVR and up to 10 simultaneous streams. It even includes regional sports content from the NHL, MLB and NBA. DirecTV starting at $50/month for one month ($35 off): All of DirecTV's signature packages are $35 off right now for your first month when you sign up. If you opt for the base \"Entertainment\" package, you'll spend $50 for the first month and get access to over 90 channels, including many local stations as well as ESPN, ESPN 2 and Fox Sports 1. You'll also be able to watch on the go with the DirecTV mobile app. Spotify Premium Individual (1 month) for $0 ($12 off): This is our favorite music streaming service for podcasts and social features. Right now, users who have not signed up for Spotify's Premium service before are eligible to get one month for free. The Premium Individual plan lets you listen ad-free and skip songs at will. You can also organize your listening queue and download content for offline listening. Just be aware, your subscription will auto-renew at the end of the trial period. So if you don't want to be on the hook for the $12 monthly fee, set a reminder to cancel and go back to the free version. Streaming bundle discounts There’s more consolidation happening now than ever before in the streaming space, and that means there are more streaming bundle options. These bundles offer you access to more content with one subscription price, but those prices are typically higher than paying for a single service by itself (obviously). It may be tempting to just get the bundle, but if only one of those services in the bundle speaks to you, you’ll spend less overall by just paying for the single service. Speaking of a deep love for a single streaming service: if all of your favorite shows are on Peacock or the latest releases on HBO Max consistently bring you joy, consider paying for one year upfront. Subscribing with an annual plan usually saves you money in the long term over paying on a monthly basis. Unfortunately, not all streaming services (looking at you, Netflix) have an annual subscription option. Disney+ If you feel like Charlie Kelly trying to figure out who Pepe Silvia is when you look at Disney's streaming prices chart, you're not alone. The confusion comes from the fact that Disney owns, or has a hand in, many streaming services including Hulu and ESPN. Throw in a partnership with HBO Max and you have a ton of options to consider and, probably, whiplash to match. Here's a quick overview of popular Disney+ bundle pricing as of October 21, 2025, accounting for the latest price hike. Disney+ and Hulu bundle (with ads) — $13/month Disney+ and Hulu bundle (without ads) — $20/month Disney+, Hulu and ESPN Select (with ads) — $20/month Disney+, Hulu and ESPN Select (without ads on Disney+ and Hulu only) — $30/month Disney+, Hulu and HBO Max (with ads) — $20/month Disney+, Hulu and HBO Max (without ads) — $33/month Peacock TV Peacock doesn't have any streaming bundles available all year round, but you can save if you pay for one year upfront. Peacock Select (with ads) — $8/month or $80/year Peacock Premium (with ads) — $11/month or $110/year Peacock Premium Plus (without ads) — $17/month or $170/year Paramount+ Paramount+ used to bill its tier with Showtime as a sort of bundle, but it has since renamed its plans and focused the Showtime inclusion in its premium tier as just another bonus of paying for the higher priced plan. Paramount+ Essential (with ads) —$/8month or $60/year Paramount Premium (without ads) — $13/month or $120/year Student discounts on streaming services It pays to be a student — sometimes, at least. A number of streaming services have student discounts you can take advantage of as long as you're actively studying. What that translates to most of the time is being able to verify your student status and signing up with your .edu email address. HBO Max student discount — subscribe for $5/month (50 percent off): HBO Max offers their ad-supported tier to students for half off the usual rate. You’ll just have to verify that you’re a student through Unidays, and make note that this offer is only good for up to 12 months of service. Hulu student discount — subscribe for $2/month (75 percent off): Those with a valid student ID can get Hulu’s ad-supported tier for 75 percent off the typical rate. They’ll keep the same sale price for as long as they’re a student as well. Spotify student discount — Premium + Hulu with ads for $6/month (72 percent off): Spotify’s student offer continues to be one of the best around, giving you access to the Premium tier of the music streamer and Hulu’s ad-supported plan for only $6 monthly. Purchased separately, you’d pay $22 per month for both of the services. Plus, the first month is free when you sign up. NBA League Pass student discount — one year for $120 (40 percent off): Students can get one year of League Pass for only $10 per month, which includes access to NBA TV and the ability to watch classic and archive games on-demand. On the NBA League Pass website, look for the student discount banner at the top and follow the instructions to verify your student status. Read more streaming coverage The best live TV streaming services to cut cable The best streaming services: Netflix, Hulu, HBO Max and more The best streaming devices Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/best-streaming-service-deals-133028980.html?src=rss",
          "feed_position": 19
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/eaglet-boosts-ai-agent-performance-on-longer-horizon-tasks-by-generating",
          "published_at": "Tue, 14 Oct 2025 22:27:00 GMT",
          "title": "EAGLET boosts AI agent performance on longer-horizon tasks by generating custom plans",
          "standfirst": "2025 was supposed to be the year of \"AI agents,\" according to Nvidia CEO Jensen Huang, and other AI industry personnel. And it has been, in many ways, with numerous leading AI model providers such as OpenAI, Google, and even Chinese competitors like Alibaba releasing fine-tuned AI models or applications designed to focus on a narrow set of tasks, such as web search and report writing. But one big hurdle to a future of highly performant, reliable, AI agents remains: getting them to stay on task when the task extends over a number of steps. Third-party benchmark tests show even the most powerful AI models experience higher failure rates the more steps they take to complete a task, and the longer time they spend on it (exceeding hours). A new academic framework called EAGLET proposes a practical and efficient method to improve long-horizon task performance in LLM-based agents — without the need for manual data labeling or retraining. Developed by researchers from Tsinghua University, Peking University, DeepLang AI, and the University of Illinois Urbana-Champaign, EAGLET offers a \"global planner\" that can be integrated into existing agent workflows to reduce hallucinations and improve task efficiency.EAGLET is a fine-tuned language model that interprets task instructions — typically provided as prompts by the user or the agent&#x27;s operating environment — and generates a high-level plan for the agent (powered by its own LLM). It does not intervene during execution, but its up-front guidance helps reduce planning errors and improve task completion rates.Addressing the Planning Problem in Long-Horizon AgentsMany LLM-based agents struggle with long-horizon tasks because they rely on reactive, step-by-step reasoning. This approach often leads to trial-and-error behavior, planning hallucinations, and inefficient trajectories. EAGLET tackles this limitation by introducing a global planning module that works alongside the executor agent. Instead of blending planning and action generation in a single model, EAGLET separates them, enabling more coherent, task-level strategies.A Two-Stage Training Pipeline with No Human AnnotationsEAGLET’s planner is trained using a two-stage process that requires no human-written plans or annotations. The first stage involves generating synthetic plans with high-capability LLMs, such as GPT-5 and DeepSeek-V3.1-Think. These plans are then filtered using a novel strategy called homologous consensus filtering, which retains only those that improve task performance for both expert and novice executor agents. In the second stage, a rule-based reinforcement learning process further refines the planner, using a custom-designed reward function to assess how much each plan helps multiple agents succeed.Introducing the Executor Capability Gain Reward (ECGR)One of EAGLET’s key innovations is the Executor Capability Gain Reward (ECGR). This reward measures the value of a generated plan by checking whether it helps both high- and low-capability agents complete tasks more successfully and with fewer steps. It also includes a decay factor to favor shorter, more efficient task trajectories. This approach avoids over-rewarding plans that are only useful to already-competent agents and promotes more generalizable planning guidance.Compatible with Existing Agents and ModelsThe EAGLET planner is designed to be modular and \"plug-and-play,\" meaning it can be inserted into existing agent pipelines without requiring executor retraining. In evaluations, the planner boosted performance across a variety of foundational models, including GPT-4.1, GPT-5, Llama-3.1, and Qwen2.5. It also proved effective regardless of prompting strategy, working well with standard ReAct-style prompts as well as approaches like Reflexion.State-of-the-Art Performance Across BenchmarksEAGLET was tested on three widely used benchmarks for long-horizon agent tasks: ScienceWorld, which simulates scientific experiments in a text-based lab environment; ALFWorld, which tasks agents with completing household activities through natural language in a simulated home setting; and WebShop, which evaluates goal-driven behavior in a realistic online shopping interface.Across all three, executor agents equipped with EAGLET outperformed their non-planning counterparts and other planning baselines, including MPO and KnowAgent. In experiments with the open source Llama-3.1-8B-Instruct model, EAGLET boosted average performance from 39.5 to 59.4, a +19.9 point gain across tasks. On ScienceWorld unseen scenarios, it raised performance from 42.2 to 61.6. In ALFWorld seen scenarios, EAGLET improved outcomes from 22.9 to 54.3, a more than 2.3× increase in performance.Even stronger gains were seen with more capable models. For instance, GPT-4.1 improved from 75.5 to 82.2 average score with EAGLET, and GPT-5 rose from 84.5 to 88.1, despite already being strong performers. In some benchmarks, performance gains were as high as +11.8 points, such as when combining EAGLET with the ETO executor method on ALFWorld unseen tasks.Compared to other planning baselines like MPO, EAGLET consistently delivered higher task completion rates. For example, on ALFWorld unseen tasks with GPT-4.1, MPO achieved 79.1, while EAGLET scored 83.6—a +4.5 point advantage.Additionally, the paper reports that agents using EAGLET complete tasks in fewer steps on average. With GPT-4.1 as executor, average step count dropped from 13.0 (no planner) to 11.1 (EAGLET). With GPT-5, it dropped from 11.4 to 9.4, supporting the claim of improved execution efficiency.Efficiency Gains in Training and ExecutionCompared to RL-based methods like GiGPO, which can require hundreds of training iterations, EAGLET achieved better or comparable results with roughly one-eighth the training effort. This efficiency also carries over into execution: agents using EAGLET typically needed fewer steps to complete tasks. This translates into reduced inference time and compute cost in production scenarios.No Public Code—YetAs of the version submitted to arXiv, the authors have not released an open-source implementation of EAGLET. It is unclear if or when the code will be released, under what license, or how it will be maintained, which may limit the near-term utility of the framework for enterprise deployment. VentureBeat has reached out to the authors to clarify these points and will update this piece when we hear back.Enterprise Deployment Questions RemainWhile the planner is described as plug-and-play, it remains unclear whether EAGLET can be easily integrated into popular enterprise agent frameworks such as LangChain or AutoGen, or if it requires a custom stack to support plan-execute separation. Similarly, the training setup leverages multiple executor agents, which may be difficult to replicate in enterprise environments with limited model access. VentureBeat has asked the researchers whether the homologous consensus filtering method can be adapted for teams that only have access to one executor model or limited compute resources.EAGLET’s authors report success across model types and sizes, but it is not yet known what the minimal viable model scale is for practical deployment. For example, can enterprise teams use the planner effectively with sub-10B parameter open models in latency-sensitive environments? Additionally, the framework may offer industry-specific value in domains like customer support or IT automation, but it remains to be seen how easily the planner can be fine-tuned or customized for such verticals.Real-Time vs. Pre-Generated PlanningAnother open question is how EAGLET is best deployed in practice. Should the planner operate in real-time alongside executors within a loop, or is it better used offline to pre-generate global plans for known task types? Each approach has implications for latency, cost, and operational complexity. VentureBeat has posed this question to the authors and will report any insights that emerge.Strategic Tradeoffs for Enterprise TeamsFor technical leaders at medium-to-large enterprises, EAGLET represents a compelling proof of concept for improving the reliability and efficiency of LLM agents. But without public tooling or implementation guidelines, the framework still presents a build-versus-wait decision. Enterprises must weigh the potential gains in task performance and efficiency against the costs of reproducing or approximating the training process in-house.Potential Use Cases in Enterprise SettingsFor enterprises developing agentic AI systems—especially in environments requiring stepwise planning, such as IT automation, customer support, or online interactions—EAGLET offers a template for how to incorporate planning without retraining. Its ability to guide both open- and closed-source models, along with its efficient training method, may make it an appealing starting point for teams seeking to improve agent performance with minimal overhead.",
          "content": "2025 was supposed to be the year of \"AI agents,\" according to Nvidia CEO Jensen Huang, and other AI industry personnel. And it has been, in many ways, with numerous leading AI model providers such as OpenAI, Google, and even Chinese competitors like Alibaba releasing fine-tuned AI models or applications designed to focus on a narrow set of tasks, such as web search and report writing. But one big hurdle to a future of highly performant, reliable, AI agents remains: getting them to stay on task when the task extends over a number of steps. Third-party benchmark tests show even the most powerful AI models experience higher failure rates the more steps they take to complete a task, and the longer time they spend on it (exceeding hours). A new academic framework called EAGLET proposes a practical and efficient method to improve long-horizon task performance in LLM-based agents — without the need for manual data labeling or retraining. Developed by researchers from Tsinghua University, Peking University, DeepLang AI, and the University of Illinois Urbana-Champaign, EAGLET offers a \"global planner\" that can be integrated into existing agent workflows to reduce hallucinations and improve task efficiency.EAGLET is a fine-tuned language model that interprets task instructions — typically provided as prompts by the user or the agent&#x27;s operating environment — and generates a high-level plan for the agent (powered by its own LLM). It does not intervene during execution, but its up-front guidance helps reduce planning errors and improve task completion rates.Addressing the Planning Problem in Long-Horizon AgentsMany LLM-based agents struggle with long-horizon tasks because they rely on reactive, step-by-step reasoning. This approach often leads to trial-and-error behavior, planning hallucinations, and inefficient trajectories. EAGLET tackles this limitation by introducing a global planning module that works alongside the executor agent. Instead of blending planning and action generation in a single model, EAGLET separates them, enabling more coherent, task-level strategies.A Two-Stage Training Pipeline with No Human AnnotationsEAGLET’s planner is trained using a two-stage process that requires no human-written plans or annotations. The first stage involves generating synthetic plans with high-capability LLMs, such as GPT-5 and DeepSeek-V3.1-Think. These plans are then filtered using a novel strategy called homologous consensus filtering, which retains only those that improve task performance for both expert and novice executor agents. In the second stage, a rule-based reinforcement learning process further refines the planner, using a custom-designed reward function to assess how much each plan helps multiple agents succeed.Introducing the Executor Capability Gain Reward (ECGR)One of EAGLET’s key innovations is the Executor Capability Gain Reward (ECGR). This reward measures the value of a generated plan by checking whether it helps both high- and low-capability agents complete tasks more successfully and with fewer steps. It also includes a decay factor to favor shorter, more efficient task trajectories. This approach avoids over-rewarding plans that are only useful to already-competent agents and promotes more generalizable planning guidance.Compatible with Existing Agents and ModelsThe EAGLET planner is designed to be modular and \"plug-and-play,\" meaning it can be inserted into existing agent pipelines without requiring executor retraining. In evaluations, the planner boosted performance across a variety of foundational models, including GPT-4.1, GPT-5, Llama-3.1, and Qwen2.5. It also proved effective regardless of prompting strategy, working well with standard ReAct-style prompts as well as approaches like Reflexion.State-of-the-Art Performance Across BenchmarksEAGLET was tested on three widely used benchmarks for long-horizon agent tasks: ScienceWorld, which simulates scientific experiments in a text-based lab environment; ALFWorld, which tasks agents with completing household activities through natural language in a simulated home setting; and WebShop, which evaluates goal-driven behavior in a realistic online shopping interface.Across all three, executor agents equipped with EAGLET outperformed their non-planning counterparts and other planning baselines, including MPO and KnowAgent. In experiments with the open source Llama-3.1-8B-Instruct model, EAGLET boosted average performance from 39.5 to 59.4, a +19.9 point gain across tasks. On ScienceWorld unseen scenarios, it raised performance from 42.2 to 61.6. In ALFWorld seen scenarios, EAGLET improved outcomes from 22.9 to 54.3, a more than 2.3× increase in performance.Even stronger gains were seen with more capable models. For instance, GPT-4.1 improved from 75.5 to 82.2 average score with EAGLET, and GPT-5 rose from 84.5 to 88.1, despite already being strong performers. In some benchmarks, performance gains were as high as +11.8 points, such as when combining EAGLET with the ETO executor method on ALFWorld unseen tasks.Compared to other planning baselines like MPO, EAGLET consistently delivered higher task completion rates. For example, on ALFWorld unseen tasks with GPT-4.1, MPO achieved 79.1, while EAGLET scored 83.6—a +4.5 point advantage.Additionally, the paper reports that agents using EAGLET complete tasks in fewer steps on average. With GPT-4.1 as executor, average step count dropped from 13.0 (no planner) to 11.1 (EAGLET). With GPT-5, it dropped from 11.4 to 9.4, supporting the claim of improved execution efficiency.Efficiency Gains in Training and ExecutionCompared to RL-based methods like GiGPO, which can require hundreds of training iterations, EAGLET achieved better or comparable results with roughly one-eighth the training effort. This efficiency also carries over into execution: agents using EAGLET typically needed fewer steps to complete tasks. This translates into reduced inference time and compute cost in production scenarios.No Public Code—YetAs of the version submitted to arXiv, the authors have not released an open-source implementation of EAGLET. It is unclear if or when the code will be released, under what license, or how it will be maintained, which may limit the near-term utility of the framework for enterprise deployment. VentureBeat has reached out to the authors to clarify these points and will update this piece when we hear back.Enterprise Deployment Questions RemainWhile the planner is described as plug-and-play, it remains unclear whether EAGLET can be easily integrated into popular enterprise agent frameworks such as LangChain or AutoGen, or if it requires a custom stack to support plan-execute separation. Similarly, the training setup leverages multiple executor agents, which may be difficult to replicate in enterprise environments with limited model access. VentureBeat has asked the researchers whether the homologous consensus filtering method can be adapted for teams that only have access to one executor model or limited compute resources.EAGLET’s authors report success across model types and sizes, but it is not yet known what the minimal viable model scale is for practical deployment. For example, can enterprise teams use the planner effectively with sub-10B parameter open models in latency-sensitive environments? Additionally, the framework may offer industry-specific value in domains like customer support or IT automation, but it remains to be seen how easily the planner can be fine-tuned or customized for such verticals.Real-Time vs. Pre-Generated PlanningAnother open question is how EAGLET is best deployed in practice. Should the planner operate in real-time alongside executors within a loop, or is it better used offline to pre-generate global plans for known task types? Each approach has implications for latency, cost, and operational complexity. VentureBeat has posed this question to the authors and will report any insights that emerge.Strategic Tradeoffs for Enterprise TeamsFor technical leaders at medium-to-large enterprises, EAGLET represents a compelling proof of concept for improving the reliability and efficiency of LLM agents. But without public tooling or implementation guidelines, the framework still presents a build-versus-wait decision. Enterprises must weigh the potential gains in task performance and efficiency against the costs of reproducing or approximating the training process in-house.Potential Use Cases in Enterprise SettingsFor enterprises developing agentic AI systems—especially in environments requiring stepwise planning, such as IT automation, customer support, or online interactions—EAGLET offers a template for how to incorporate planning without retraining. Its ability to guide both open- and closed-source models, along with its efficient training method, may make it an appealing starting point for teams seeking to improve agent performance with minimal overhead.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1FsFs77cl1uzCE3JPEBnrk/7541c62def835191ff404046af4030c7/cfr0z3n_graphic_novel_hyper_detailed_close_up_on_a_cybernetic_b_9624e28f-5392-4c92-a115-0520c6058152.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/openai-forms-advisory-council-on-wellbeing-and-ai-183815365.html",
          "published_at": "Tue, 14 Oct 2025 18:38:15 +0000",
          "title": "OpenAI forms advisory council on wellbeing and AI",
          "standfirst": "OpenAI announced today that it is creating an advisory council centered on its users' mental and emotional wellness. The Expert Council on Well-being and AI comprises eight researchers and experts on the intersection of technology and mental health. Some of the members were experts that OpenAI consulted as it developed parental controls. Topics of safety and protecting younger users have become more of a talking point for all artificial intelligence companies, including OpenAI, after lawsuits questioned their complicity in multiple cases where teenagers committed suicide after sharing their plans with AI chatbots.This move sounds like a wise addition, but the effectiveness of any advisor hinges on listening to their insights. We've seen other tech companies establish and then utterly ignore their advisory councils; Meta is one of the notable recent examples. And the announcement from OpenAI even acknowledges that its new council has no real power to guide its operations: \"We remain responsible for the decisions we make, but we’ll continue learning from this council, the Global Physician Network, policymakers, and more, as we build advanced AI systems in ways that support people’s well-being.\" It may become clearer how seriously OpenAI is taking this effort when it starts to disagree with the council, whether the company is genuinely committed to mitigating the serious risks of AI or whether this is a smoke and mirrors attempt to paper over its issues.This article originally appeared on Engadget at https://www.engadget.com/openai-forms-advisory-council-on-wellbeing-and-ai-183815365.html?src=rss",
          "content": "OpenAI announced today that it is creating an advisory council centered on its users' mental and emotional wellness. The Expert Council on Well-being and AI comprises eight researchers and experts on the intersection of technology and mental health. Some of the members were experts that OpenAI consulted as it developed parental controls. Topics of safety and protecting younger users have become more of a talking point for all artificial intelligence companies, including OpenAI, after lawsuits questioned their complicity in multiple cases where teenagers committed suicide after sharing their plans with AI chatbots.This move sounds like a wise addition, but the effectiveness of any advisor hinges on listening to their insights. We've seen other tech companies establish and then utterly ignore their advisory councils; Meta is one of the notable recent examples. And the announcement from OpenAI even acknowledges that its new council has no real power to guide its operations: \"We remain responsible for the decisions we make, but we’ll continue learning from this council, the Global Physician Network, policymakers, and more, as we build advanced AI systems in ways that support people’s well-being.\" It may become clearer how seriously OpenAI is taking this effort when it starts to disagree with the council, whether the company is genuinely committed to mitigating the serious risks of AI or whether this is a smoke and mirrors attempt to paper over its issues.This article originally appeared on Engadget at https://www.engadget.com/openai-forms-advisory-council-on-wellbeing-and-ai-183815365.html?src=rss",
          "feed_position": 27
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openai-will-let-adults-use-chatgpt-for-erotica-starting-in-december-182417583.html",
          "published_at": "Tue, 14 Oct 2025 18:24:17 +0000",
          "title": "OpenAI will let adults use ChatGPT for erotica starting in December",
          "standfirst": "OpenAI plans to open the floodgates to more adult uses of ChatGPT starting in December, according to a new post from CEO Sam Altman. The company announced that it would add parental controls and automatic age detection features in September, and it seems like a benefit of sorting out children from adults is an ability to offer more freedom in what ChatGPT can show users. \"In December, as we roll out age-gating more fully and as part of our 'treat adult users like adults' principle, we will allow even more, like erotica for verified adults,\" Altman says. Some avid ChatGPT users already regularly manipulate the chatbot to engage in NSFW conversations, but Altman's announcement sounds more like tacit approval from OpenAI that those use-cases are okay. We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right.Now that we have…— Sam Altman (@sama) October 14, 2025 The company signaled something similar during its DevDay 2025 announcements, when its new guidelines for developers creating apps for ChatGPT shared that \"support for mature (18+) experiences will arrive once appropriate age verification and controls are in place.\" After December, it sounds like adult interactions with ChatGPT or apps the chatbot can access are fair game. All of these changes are being made in the shadow of disturbing stories of the seemingly negative influence ChatGPT can have on users, including the death of 16-year old Adam Raine, who allegedly used ChatGPT to plan his own suicide. Reducing the chatbot's sycophantic qualities with the release of GPT-5 was one of the ways OpenAI tried to address the mental health impacts of ChatGPT, along with built-in notifications to remind users to take breaks. It's hard to definitively say whether these tweaks have made a difference, but combined with age-gating, it's clear OpenAI feels comfortable giving its chatbot a longer leash.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-will-let-adults-use-chatgpt-for-erotica-starting-in-december-182417583.html?src=rss",
          "content": "OpenAI plans to open the floodgates to more adult uses of ChatGPT starting in December, according to a new post from CEO Sam Altman. The company announced that it would add parental controls and automatic age detection features in September, and it seems like a benefit of sorting out children from adults is an ability to offer more freedom in what ChatGPT can show users. \"In December, as we roll out age-gating more fully and as part of our 'treat adult users like adults' principle, we will allow even more, like erotica for verified adults,\" Altman says. Some avid ChatGPT users already regularly manipulate the chatbot to engage in NSFW conversations, but Altman's announcement sounds more like tacit approval from OpenAI that those use-cases are okay. We made ChatGPT pretty restrictive to make sure we were being careful with mental health issues. We realize this made it less useful/enjoyable to many users who had no mental health problems, but given the seriousness of the issue we wanted to get this right.Now that we have…— Sam Altman (@sama) October 14, 2025 The company signaled something similar during its DevDay 2025 announcements, when its new guidelines for developers creating apps for ChatGPT shared that \"support for mature (18+) experiences will arrive once appropriate age verification and controls are in place.\" After December, it sounds like adult interactions with ChatGPT or apps the chatbot can access are fair game. All of these changes are being made in the shadow of disturbing stories of the seemingly negative influence ChatGPT can have on users, including the death of 16-year old Adam Raine, who allegedly used ChatGPT to plan his own suicide. Reducing the chatbot's sycophantic qualities with the release of GPT-5 was one of the ways OpenAI tried to address the mental health impacts of ChatGPT, along with built-in notifications to remind users to take breaks. It's hard to definitively say whether these tweaks have made a difference, but combined with age-gating, it's clear OpenAI feels comfortable giving its chatbot a longer leash.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-will-let-adults-use-chatgpt-for-erotica-starting-in-december-182417583.html?src=rss",
          "feed_position": 28
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/x-experiments-with-showing-more-information-about-profiles-to-fight-inauthentic-engagement-172500501.html",
          "published_at": "Tue, 14 Oct 2025 17:25:00 +0000",
          "title": "X experiments with showing more information about profiles to fight inauthentic engagement",
          "standfirst": "X has long been a hotbed for fake accounts, bots and other scammy behavior. Many of those dynamics have been exacerbated by the rise of paid verification, which boosts the visibility of anyone who pays for a subscription. Now, the company is running a small experiment that could help users better identify potentially suspicious accounts.The service is starting to test a new \"about this account\" feature that will provide details about when an account joined the platform, where the person running it is based, how many times the username has been changed and how the account is connected to X. The feature is a lot like the \"page transparency\" information on Facebook, which provides similar details about when a given page was created and where the people running it are based. \"When you read content on X, you should be able to verify its authenticity,\" X's head of product, Nikita Bier, shared in a post about the change. \"This is critical to getting a pulse on important issues happening in the world.\" If fully rolled out, this type of feature could help people on X understand a lot of common scams and other deceptive behavior on the platform. For example, scammers often change the handle of a recently compromised account in order to trick an account's existing followers. And understanding the location of an account could help users root out people lying about their identity. However, it sounds like it could be some time before the feature is implemented in a way that could be broadly useful. Bier said that initially X will show this info on \"a handful of profiles of X team members\" — most of whom already have an official \"X\" badge on their profiles — in order to get feedback on the change.This article originally appeared on Engadget at https://www.engadget.com/social-media/x-experiments-with-showing-more-information-about-profiles-to-fight-inauthentic-engagement-172500501.html?src=rss",
          "content": "X has long been a hotbed for fake accounts, bots and other scammy behavior. Many of those dynamics have been exacerbated by the rise of paid verification, which boosts the visibility of anyone who pays for a subscription. Now, the company is running a small experiment that could help users better identify potentially suspicious accounts.The service is starting to test a new \"about this account\" feature that will provide details about when an account joined the platform, where the person running it is based, how many times the username has been changed and how the account is connected to X. The feature is a lot like the \"page transparency\" information on Facebook, which provides similar details about when a given page was created and where the people running it are based. \"When you read content on X, you should be able to verify its authenticity,\" X's head of product, Nikita Bier, shared in a post about the change. \"This is critical to getting a pulse on important issues happening in the world.\" If fully rolled out, this type of feature could help people on X understand a lot of common scams and other deceptive behavior on the platform. For example, scammers often change the handle of a recently compromised account in order to trick an account's existing followers. And understanding the location of an account could help users root out people lying about their identity. However, it sounds like it could be some time before the feature is implemented in a way that could be broadly useful. Bier said that initially X will show this info on \"a handful of profiles of X team members\" — most of whom already have an official \"X\" badge on their profiles — in order to get feedback on the change.This article originally appeared on Engadget at https://www.engadget.com/social-media/x-experiments-with-showing-more-information-about-profiles-to-fight-inauthentic-engagement-172500501.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/music/spotifys-managed-accounts-will-help-keep-your-kids-from-wrecking-your-music-taste-profile-154406843.html",
          "published_at": "Tue, 14 Oct 2025 15:44:06 +0000",
          "title": "Spotify's managed accounts will help keep your kids from wrecking your music taste profile",
          "standfirst": "Spotify has introduced a new \"managed accounts\" feature aimed at younger listeners. Initially piloted last year and launching in seven new markets, including the US, today, it allows parents and guardians with a Spotify Premium Family plan to allocate their children a dedicated profile with their own personalized recommendations and custom playlists. The idea is that the adults can filter out explicit content, limit the playback of certain artists and hide video playback features, including Canvas, should they want to. Users on this profile can’t use interactivity features like Messages either. Perhaps most importantly of all for some, a managed account also ensures that your personal Wrapped results at the end of the year aren’t dominated by whatever TikTok-viral songs the kids have been obsessively playing on repeat for months — and they won't mess with your Discover Weekly algorithm either. Spotify's 'Exclude from your Taste Profile' feature already offers a way of keeping the nonsense your kids might be listening to away from your own recommended content, but this feels like a cleaner option for families. Standard Spotify Premium features like daylist and the aforementioned Discover Weekly remain available to someone using a managed account, making it a better option for kids becoming interested in music (they may even have gotten hooked on a band you’ve been listening to in the car) than the Spotify Kids app, which is very much designed for the 'Baby Shark' devotees. It’s probably helpful to think of a managed account as a bridge between that and an unrestricted Premium account where all the music in the world is at your fingertips. To set up a managed account, the plan owner has to go into their account settings within the Spotify app and select \"Add a Member,\" followed by selecting \"Add a listener aged under 13.\" The app will provide further instructions from there. As a reminder, a Spotify Premium Family plan is required to set up a managed account. This currently costs $20 per month.This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-managed-accounts-will-help-keep-your-kids-from-wrecking-your-music-taste-profile-154406843.html?src=rss",
          "content": "Spotify has introduced a new \"managed accounts\" feature aimed at younger listeners. Initially piloted last year and launching in seven new markets, including the US, today, it allows parents and guardians with a Spotify Premium Family plan to allocate their children a dedicated profile with their own personalized recommendations and custom playlists. The idea is that the adults can filter out explicit content, limit the playback of certain artists and hide video playback features, including Canvas, should they want to. Users on this profile can’t use interactivity features like Messages either. Perhaps most importantly of all for some, a managed account also ensures that your personal Wrapped results at the end of the year aren’t dominated by whatever TikTok-viral songs the kids have been obsessively playing on repeat for months — and they won't mess with your Discover Weekly algorithm either. Spotify's 'Exclude from your Taste Profile' feature already offers a way of keeping the nonsense your kids might be listening to away from your own recommended content, but this feels like a cleaner option for families. Standard Spotify Premium features like daylist and the aforementioned Discover Weekly remain available to someone using a managed account, making it a better option for kids becoming interested in music (they may even have gotten hooked on a band you’ve been listening to in the car) than the Spotify Kids app, which is very much designed for the 'Baby Shark' devotees. It’s probably helpful to think of a managed account as a bridge between that and an unrestricted Premium account where all the music in the world is at your fingertips. To set up a managed account, the plan owner has to go into their account settings within the Spotify app and select \"Add a Member,\" followed by selecting \"Add a listener aged under 13.\" The app will provide further instructions from there. As a reminder, a Spotify Premium Family plan is required to set up a managed account. This currently costs $20 per month.This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-managed-accounts-will-help-keep-your-kids-from-wrecking-your-music-taste-profile-154406843.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/tv-movies/tivo-has-discontinued-its-dvr-boxes-123037999.html",
          "published_at": "Tue, 14 Oct 2025 12:30:37 +0000",
          "title": "TiVo has discontinued its DVR boxes",
          "standfirst": "TiVo has confirmed that it has stopped selling its DVR set-top boxes, marking the end of an era that changed how we watch television forever. As first reported earlier this month by Cord Cutters News, TiVo Corporation quietly pulled its once-groundbreaking digital video recorder from its website. Holding company Xperi later confirmed that the listing was removed on October 1. “I can confirm that as of October 1, 2025, TiVo stopped selling physical DVR products, including hardware and accessories, both online and through agents,” a TiVo spokesperson confirmed to PCMag. “TiVo no longer manufactures hardware, and our remaining inventory is now depleted, though we will continue to offer support for the products going forward.” The TiVo box revolutionized television upon its launch in 1999, allowing viewers to pause, rewind and record live television. There was a time when you would just miss the start of a show if you weren’t punctual, and you’d have to sync grabbing a snack with a commercial during the big game. You also had to actually watch the commercials, something that is unfortunately making a comeback with an increase in ad-supported streaming. The DVR pioneer is now a software company. It has been producing TiVo OS almost exclusively in the European market since 2022, though the smart TV OS premiered in the US this year via Sharp. “The Sharp Smart TV Powered by TiVo” launched as a 55-inch QLED display with 4K resolution and HDR support. TiVo OS functions like many other television operating systems, aggregating streaming services and offering its own library of free and paid content. TiVo will still offer customer support for its now-discontinued boxes, which bodes well for customers who have purchased a lifetime plan.This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/tivo-has-discontinued-its-dvr-boxes-123037999.html?src=rss",
          "content": "TiVo has confirmed that it has stopped selling its DVR set-top boxes, marking the end of an era that changed how we watch television forever. As first reported earlier this month by Cord Cutters News, TiVo Corporation quietly pulled its once-groundbreaking digital video recorder from its website. Holding company Xperi later confirmed that the listing was removed on October 1. “I can confirm that as of October 1, 2025, TiVo stopped selling physical DVR products, including hardware and accessories, both online and through agents,” a TiVo spokesperson confirmed to PCMag. “TiVo no longer manufactures hardware, and our remaining inventory is now depleted, though we will continue to offer support for the products going forward.” The TiVo box revolutionized television upon its launch in 1999, allowing viewers to pause, rewind and record live television. There was a time when you would just miss the start of a show if you weren’t punctual, and you’d have to sync grabbing a snack with a commercial during the big game. You also had to actually watch the commercials, something that is unfortunately making a comeback with an increase in ad-supported streaming. The DVR pioneer is now a software company. It has been producing TiVo OS almost exclusively in the European market since 2022, though the smart TV OS premiered in the US this year via Sharp. “The Sharp Smart TV Powered by TiVo” launched as a 55-inch QLED display with 4K resolution and HDR support. TiVo OS functions like many other television operating systems, aggregating streaming services and offering its own library of free and paid content. TiVo will still offer customer support for its now-discontinued boxes, which bodes well for customers who have purchased a lifetime plan.This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/tivo-has-discontinued-its-dvr-boxes-123037999.html?src=rss",
          "feed_position": 37
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/instagram-makes-teen-accounts-more-restrictive-120000653.html",
          "published_at": "Tue, 14 Oct 2025 12:00:00 +0000",
          "title": "Instagram makes 'teen accounts' more restrictive",
          "standfirst": "Instagram is tightening the settings on its \"teen accounts\" to add new limits on what kids on the platform are able to see. Older teens will also no longer be able to opt out of the default stricter settings without parental approval. Meta first introduced teen accounts for Instagram a year ago, when it began automatically moving teens into the more locked-down accounts that come with stricter privacy settings and parental controls. The company recently rolled out the accounts for teens on Facebook and Messenger too, and has used AI tools to detect teens that are lying about their age. While teen accounts are meant to address long-running criticism about Meta's handling of teen safety on its apps, the measures have been widely criticized as not going far enough to protect the company's most vulnerable users. A recent report from safety advocates at Heat Initiative found that \"young teen users today continue to be recommended or exposed to unsafe content and unwanted messages at alarmingly high rates while using Instagram Teen Accounts.\" (Meta called the report \"deeply subjective.\") Now, Meta is locking down teen accounts even more. With the latest changes, teens will no longer be able to follow or see content from accounts that \"regularly share age-inappropriate content\" or that seem \"age-inappropriate\" based on their bio or username. Meta says it will also block these accounts from appearing in teens' recommendations or in search results in the app. Instagram will also block a \"a wider range of mature search terms\" for teens, including words like \"alcohol,” \"gore,\" and intentional misspellings of these words, which is a common tactic to avoid Instagram's filters. And, even if an account a teen already follows shares a post that goes against these rules, teens should be prevented from seeing it, even if it's sent to their DMs.Instagram will block teens from searching for more term associated with inappropriate content,.MetaWhile these changes may seem like Meta once again filling somewhat obvious gaps in its safety features, the company says the revamp is meant to make the content teens encounter on Instagram more like a PG-13 movie. \"Just like you might see some suggestive content or hear some strong language in a PG-13 movie, teens may occasionally see something like that on Instagram - but we’re going to keep doing all we can to keep those instances as rare as possible,\" the company explained in a blog post.That's a somewhat confusing analogy as there's a fairly wide spectrum of what might appear in a PG-13 movie. Meta also says that some of its rules for teens are more restrictive than what teens might see in a PG-13 movie. For example, the app aims to prevent teens from seeing any kind of \"sexually suggestive\" content or images of \"near nudity\" even though that type of content might appear in movies rated for 13-year-olds. For parents that want even tighter restrictions, Instagram is also adding a new \"limited content\" setting that filters \"even more\" content from teens' view (Meta didn't explain what exactly would be restricted). The setting also prevents teens from accessing any comments on the platform, either on their own posts or other users'. Finally, Meta is testing a new reporting feature for parents that use Instagram's parental control settings to monitor their teens' use of the app. With the feature, parents can flag specific posts they feel are inappropriate to trigger a review by Meta. Meta says the latest changes will be rolling out \"gradually\" to teen accounts in the US, UK, Canada and Australia to start and that it will eventually \"add additional age-appropriate content protections for teens on Facebook.\" This article originally appeared on Engadget at https://www.engadget.com/social-media/instagram-makes-teen-accounts-more-restrictive-120000653.html?src=rss",
          "content": "Instagram is tightening the settings on its \"teen accounts\" to add new limits on what kids on the platform are able to see. Older teens will also no longer be able to opt out of the default stricter settings without parental approval. Meta first introduced teen accounts for Instagram a year ago, when it began automatically moving teens into the more locked-down accounts that come with stricter privacy settings and parental controls. The company recently rolled out the accounts for teens on Facebook and Messenger too, and has used AI tools to detect teens that are lying about their age. While teen accounts are meant to address long-running criticism about Meta's handling of teen safety on its apps, the measures have been widely criticized as not going far enough to protect the company's most vulnerable users. A recent report from safety advocates at Heat Initiative found that \"young teen users today continue to be recommended or exposed to unsafe content and unwanted messages at alarmingly high rates while using Instagram Teen Accounts.\" (Meta called the report \"deeply subjective.\") Now, Meta is locking down teen accounts even more. With the latest changes, teens will no longer be able to follow or see content from accounts that \"regularly share age-inappropriate content\" or that seem \"age-inappropriate\" based on their bio or username. Meta says it will also block these accounts from appearing in teens' recommendations or in search results in the app. Instagram will also block a \"a wider range of mature search terms\" for teens, including words like \"alcohol,” \"gore,\" and intentional misspellings of these words, which is a common tactic to avoid Instagram's filters. And, even if an account a teen already follows shares a post that goes against these rules, teens should be prevented from seeing it, even if it's sent to their DMs.Instagram will block teens from searching for more term associated with inappropriate content,.MetaWhile these changes may seem like Meta once again filling somewhat obvious gaps in its safety features, the company says the revamp is meant to make the content teens encounter on Instagram more like a PG-13 movie. \"Just like you might see some suggestive content or hear some strong language in a PG-13 movie, teens may occasionally see something like that on Instagram - but we’re going to keep doing all we can to keep those instances as rare as possible,\" the company explained in a blog post.That's a somewhat confusing analogy as there's a fairly wide spectrum of what might appear in a PG-13 movie. Meta also says that some of its rules for teens are more restrictive than what teens might see in a PG-13 movie. For example, the app aims to prevent teens from seeing any kind of \"sexually suggestive\" content or images of \"near nudity\" even though that type of content might appear in movies rated for 13-year-olds. For parents that want even tighter restrictions, Instagram is also adding a new \"limited content\" setting that filters \"even more\" content from teens' view (Meta didn't explain what exactly would be restricted). The setting also prevents teens from accessing any comments on the platform, either on their own posts or other users'. Finally, Meta is testing a new reporting feature for parents that use Instagram's parental control settings to monitor their teens' use of the app. With the feature, parents can flag specific posts they feel are inappropriate to trigger a review by Meta. Meta says the latest changes will be rolling out \"gradually\" to teen accounts in the US, UK, Canada and Australia to start and that it will eventually \"add additional age-appropriate content protections for teens on Facebook.\" This article originally appeared on Engadget at https://www.engadget.com/social-media/instagram-makes-teen-accounts-more-restrictive-120000653.html?src=rss",
          "feed_position": 40,
          "image_url": "https://d29szjachogqwa.cloudfront.net/videos/user-uploaded/image005.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-111557774.html",
          "published_at": "Tue, 14 Oct 2025 11:15:57 +0000",
          "title": "The Morning After: It’s the end for Windows 10",
          "standfirst": "After more than a decade of service, Microsoft is declaring the end of Windows 10’s usable life. If your machine still uses it, rest assured it’ll continue to work, but you won’t see any more software and security updates. If your machine is compatible, you’ll be able to upgrade to Windows 11 for free, or this can provide the justification you need to buy a new machine. But there’s also a way to keep your status quo without the additional stress, at least for the next year. It’s possible to sign up to Microsoft’s Extended Security updates program, giving you an extra year of software and security patches. It won’t cost you any money, but you will be expected to sign up to Microsoft’s cloud services. If you’d like to keep Windows 10 running and safe, you can head over to our comprehensive guide on what to do. And, if you’re ready to upgrade, check out our guide on the best Windows laptops to choose your next purchase. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Another Game Freak leak claims to show the Pokémon roadmap Anbernic’s modern-day Nintendo DS dupe is cheaper than the original The FCC is trying to make it easier for internet providers to charge hidden fees It’s comically evil, really. The FCC has outlined a plan to once again allow ISPs to charge hidden fees, making it easier to rip off consumers. It follows a complaint from those poor carriers that believe it’s far too hard to be required to tell customers what it is they’re charging for. I bet that’s loads of fun for all of the FCC employees who went into public service in the hope of actually serving the public. Continue Reading. Apple TV+ is now just Apple TV I’m in the minority, but I think that’s a good shout. Devindra Hardawar for Engadget Apple is dropping the + from the name of its TV subscription service. That’s a smart piece of branding, since everyone just calls it Apple TV anyway. But it does muddy the waters, given Apple’s set top box is also called Apple TV. But, as someone who reviews Apple TV shows and irritates editors by forgetting the plus sign, this will make my (and their) lives a lot easier. Continue Reading. The first products with Apple’s M5 chip could make their debut this week The rumor mill suggests we’ll see them in a few days. Apple Apple is reportedly gearing up to announce a series of updated devices, each one packing its new A5 chip. Bloomberg claims the company will announce new MacBook Pros, Pad Pros and an updated Vision Pro online over a period of days. If so, it would be mirroring the release pattern from last year, when an updated product was launched online each day across a week. Rumors suggest we’ll only get the vanilla A5 versions this fall, with the higher-end versions of the silicon not arriving until the start of next year. Continue Reading. A long-lost Ratchet and Clank mobile game has been found Clone Home was a successor to Going Mobile. The Golden Bolt Ratchet & Clank superfans have unearthed a fairly substantial gem after a years-long search: a finished but essentially unreleased mobile title from 2006. Clone Home was the sequel to Going Mobile developed for mobile phones running Java from those halcyon pre-iPhone days. It was axed shortly before launch, but a few copies did find their way into the ether, which enabled YouTuber The Golden Bolt to show it off to the world. Continue Reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111557774.html?src=rss",
          "content": "After more than a decade of service, Microsoft is declaring the end of Windows 10’s usable life. If your machine still uses it, rest assured it’ll continue to work, but you won’t see any more software and security updates. If your machine is compatible, you’ll be able to upgrade to Windows 11 for free, or this can provide the justification you need to buy a new machine. But there’s also a way to keep your status quo without the additional stress, at least for the next year. It’s possible to sign up to Microsoft’s Extended Security updates program, giving you an extra year of software and security patches. It won’t cost you any money, but you will be expected to sign up to Microsoft’s cloud services. If you’d like to keep Windows 10 running and safe, you can head over to our comprehensive guide on what to do. And, if you’re ready to upgrade, check out our guide on the best Windows laptops to choose your next purchase. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Another Game Freak leak claims to show the Pokémon roadmap Anbernic’s modern-day Nintendo DS dupe is cheaper than the original The FCC is trying to make it easier for internet providers to charge hidden fees It’s comically evil, really. The FCC has outlined a plan to once again allow ISPs to charge hidden fees, making it easier to rip off consumers. It follows a complaint from those poor carriers that believe it’s far too hard to be required to tell customers what it is they’re charging for. I bet that’s loads of fun for all of the FCC employees who went into public service in the hope of actually serving the public. Continue Reading. Apple TV+ is now just Apple TV I’m in the minority, but I think that’s a good shout. Devindra Hardawar for Engadget Apple is dropping the + from the name of its TV subscription service. That’s a smart piece of branding, since everyone just calls it Apple TV anyway. But it does muddy the waters, given Apple’s set top box is also called Apple TV. But, as someone who reviews Apple TV shows and irritates editors by forgetting the plus sign, this will make my (and their) lives a lot easier. Continue Reading. The first products with Apple’s M5 chip could make their debut this week The rumor mill suggests we’ll see them in a few days. Apple Apple is reportedly gearing up to announce a series of updated devices, each one packing its new A5 chip. Bloomberg claims the company will announce new MacBook Pros, Pad Pros and an updated Vision Pro online over a period of days. If so, it would be mirroring the release pattern from last year, when an updated product was launched online each day across a week. Rumors suggest we’ll only get the vanilla A5 versions this fall, with the higher-end versions of the silicon not arriving until the start of next year. Continue Reading. A long-lost Ratchet and Clank mobile game has been found Clone Home was a successor to Going Mobile. The Golden Bolt Ratchet & Clank superfans have unearthed a fairly substantial gem after a years-long search: a finished but essentially unreleased mobile title from 2006. Clone Home was the sequel to Going Mobile developed for mobile phones running Java from those halcyon pre-iPhone days. It was axed shortly before launch, but a few copies did find their way into the ether, which enabled YouTuber The Golden Bolt to show it off to the world. Continue Reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111557774.html?src=rss",
          "feed_position": 41,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/8a2cfc30-a8e0-11f0-9f7a-a1a711d9ca27"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-macbook-140032524.html",
          "published_at": "Tue, 14 Oct 2025 09:01:26 +0000",
          "title": "The best MacBook for 2025: Which Apple laptop should you buy?",
          "standfirst": "There wasn’t much Mac-related news at Apple’s latest to-do (to be expected at an iPhone event), aside from the announcement that macOS 26 would be available to the public on September 15. Historically, we’ve seen new Mac hardware in October and then again in spring. But as of right now, there are just two MacBooks in Apple’s lineup: MacBook Air models with the M4 chip and MacBook Pro models with the M4 chip. Within those two options lie a handful of choices, including chip type, screen size, storage capacity and more. This guide will help you suss out the Apple terminology and explain the options so you can pick the best MacBook configuration for your needs. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently sells MacBooks equipped with M4-series chips. You’ll find the standard M4 processor in the Air and the base-model Pro and the upgraded M4 Max and M4 Pro chips as options for the MacBook Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air and the base model MacBook Pro 14-inch. That chip houses a 10-core CPU and either an 8- or 10-core GPU. In total, there are three versions of the M4 chip: standard M4, M4 Pro and M4 Max (which are each a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The burliest chip, the M4 Max is built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM, or in Apple’s terminology, unified memory, varies, but with the switch to the M4 chip in all laptops, the lowest amount of RAM you can get is now 16GB. That’s a necessary spec-bump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14- or 16-inch MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage to make your machine as future-proof as possible. Of course, if you're just after the M4 chip and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M4 (14-inch) Best MacBook for creatives Apple M4, 16GB RAM, 512GB SSD 34.25 hours Up to 22 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? Both the MacBook Air and Pro models come with the M4 chip. MBP models have the option of more powerful M4 Pro or M4 Max chips. The Pro has a higher resolution screen with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "content": "There wasn’t much Mac-related news at Apple’s latest to-do (to be expected at an iPhone event), aside from the announcement that macOS 26 would be available to the public on September 15. Historically, we’ve seen new Mac hardware in October and then again in spring. But as of right now, there are just two MacBooks in Apple’s lineup: MacBook Air models with the M4 chip and MacBook Pro models with the M4 chip. Within those two options lie a handful of choices, including chip type, screen size, storage capacity and more. This guide will help you suss out the Apple terminology and explain the options so you can pick the best MacBook configuration for your needs. Table of contents Best MacBooks for 2025 What about budget MacBooks? Factors to consider when buying a MacBook MacBooks specs comparison chart Best MacBook FAQs Best MacBooks for 2025 What about budget MacBooks? Historically, Apple kept the previous year’s MacBook Air in its lineup as a sort of budget option. But the company took a different approach with the release of the M4 MacBook Air. Instead of continuing to sell the older model, Apple discontinued the M3 Air and gave its newest computer a $100 price cut. Now, if you can even find a brand new M3 MacBook Air (typically from retailers like Amazon or B&H), it’s often more expensive than the M4 version. During sales like Amazon Prime Day, we’ve seen the newest M4 Air go for as little as $799. That effectively makes our overall pick a budget pick as well. Of course, $800 isn’t exactly a small investment either for college students or others on a budget. Especially when you can find some decent PCs for under $500. If you’re looking to save even more on a MacBook, we recommend checking out refurbished options directly from Apple, or even third party sellers like BackMarket. There are a few guidelines to keep in mind, which we go over in our refurbished guide, but mainly, you’ll want to shop from a reputable source that has a stated process and offers at least a year-long warranty. Using your old gear as a trade-in will bring down your final cost as well. Factors to consider when buying a MacBook Compared to PCs, Apple computers tend to have more streamlined specifications. The company has long been known for this simplicity, and the M-series “system-on-a-chip” condenses things even further. Prior to the M1 chip, Apple used Intel chips in its laptop and desktop computers. The M2 and M3 generations followed that first chip and currently sells MacBooks equipped with M4-series chips. You’ll find the standard M4 processor in the Air and the base-model Pro and the upgraded M4 Max and M4 Pro chips as options for the MacBook Pro (currently there is no M4 Ultra chip, as there was with the M3 series in the Mac Studio). All M-series chips combine, among other technologies, the CPU, graphics card and unified memory (RAM). Apple’s Neural Engine is included too, which is a specialized group of processor cores that handles machine learning tasks such as image analysis and voice recognition. While a unified chip means you have fewer decisions to make when picking a MacBook, there are still a few factors to consider, including specs like the number of CPU cores, amount of RAM, storage capacity, screen size, and, obviously, price. The finish color may be a minor consideration, but it's worth pointing out that the Pro comes in just two colors (Silver or Space Black) but the Air comes in four hues (Midnight, Starlight, Sky Blue and Silver). CPU cores The lowest-specced chip in a current-lineup MacBook is the standard M4 chip, which is found in all models of the MacBook Air and the base model MacBook Pro 14-inch. That chip houses a 10-core CPU and either an 8- or 10-core GPU. In total, there are three versions of the M4 chip: standard M4, M4 Pro and M4 Max (which are each a step up from their predecessors, the M3, M3 Pro and M3 Max chips). The burliest chip, the M4 Max is built with either a 14- or 16-core CPU and a 32- or 40-core GPU. Cores are, in essence, smaller processing units that can handle different tasks simultaneously. Having more of them translates to the computer being able to run multiple programs and applications at once, while also smoothly processing demanding tasks like video and photo editing and high-level gaming. In short, more cores allow for more advanced computing and better performance. But if your processing power needs fall below professional-level gaming and cinematic video and audio editing, getting the highest number of cores is likely overkill — and after all, more cores equals higher cost and more power usage. Photo by Devindra Hardawar/Engadget RAM Your options for RAM, or in Apple’s terminology, unified memory, varies, but with the switch to the M4 chip in all laptops, the lowest amount of RAM you can get is now 16GB. That’s a necessary spec-bump to accommodate the tech world’s favorite feature of the moment: AI or, in this case, Apple Intelligence (still AI, but Cupertino’s version). The M4 Pro chip has 24 or 48GB memory options, while the M4 Max chip supports 48, 64 or a whopping 128GB of RAM. You’ve likely heard the analogy comparing memory to the amount of workspace available on a literal desktop surface, whereas storage is the amount of drawers you have to store projects to work on later. The larger the worktop surface, the more projects you can work on at once. The bigger the drawers, the more you can save for later. In addition to supporting Apple Intelligence, more RAM is ideal for people who plan to work in multiple apps at once. And the more demanding each program is, the more RAM will be required. Extra memory can also come in handy if you’re the type who likes to have infinite numbers of tabs open on your browser. If your daily workflow doesn’t involve simultaneously using a vast number of memory-intensive programs, you can save yourself money and buy the RAM configuration that you’re most likely to actually use. For a long time, Apple continued to offer MacBooks with just 8GB of RAM, and we recommended upgrading to at least 16GB of RAM. With this being the standard today, grabbing a base model should be fine for most non-pro-level users. One thing to note is that, unlike most PCs, the RAM in a MacBook is not user-upgradable since it’s tied into the system-on-a-chip. If you think you might end up needing more memory, you should go for the spec upgrade up front. Storage capacity (SSD) Storage options range from 256GB of SSD for the base-model MacBook Air and 8TB of storage for the MacBook Pros with the M4 Max chip. If you want to rotate between a long roster of game titles or keep lots of high-res videos on hand, you’ll want more storage. If you’re mostly working with browser- and cloud-based applications, you can get away with a smaller-capacity configuration. That said, we recommend springing for 512GB of storage or more, if it’s within your budget. You’ll quickly feel the limits of a 256GB machine as it ages since the operating system alone takes up a good portion of that space. Having 1TB will feel even roomier and allow for more data storage over the life of your laptop. When Apple announced the iPhone 15, the company also announced new iCloud+ storage storage plans, with subscriptions that allow up to 12TB of storage shared among your iOS and MacOS devices. You could also transfer files to an external storage device. But if you don’t want to pay for a monthly subscription and prefer the convenience of having immediate access to your files, it’s best to get the highest amount of storage space your budget allows for at the outset. Screen size The MacBook Air comes in 13- or 15-inch sizes. Pro models have either 14- or 16-inch screens. A two-inch delta may not seem like much but, as Engadget’s Nathan Ingraham noted when he reviewed the then-new 15-inch M2-powered MacBook Air, a larger screen \"makes a surprising difference.” That’s especially true if you plan to use your laptop as an all-day productivity machine and won’t be using an external monitor. More space means you can more clearly view side-by-side windows and have a more immersive experience when watching shows or gaming. But screen size is one of the main factors influencing weight. The 13-inch MacBook Air M4 weighs 2.7 pounds, whereas the top-end 16-inch MacBook Pro with the Max chip weighs 4.7 pounds. If you plan to travel a lot or swap your work locations regularly, a smaller screen will make life easier in the long run. All MacBooks feature IPS LCD panels (in-plane switching, liquid crystal display), which Apple markets as Retina displays. The MacBook Air M4 has a Liquid Retina display and the Pro models have Liquid Retina XDR displays. “Liquid” refers to the way the lighted portion of the display “flows” within the contours of the screen, filling the rounded corners and curving around the camera notch. “XDR” is what Apple calls HDR (high dynamic range). You also get the option of a standard or nano-texture display on the MacBook Pro. The glass, which reduces glare and is also available on the Studio Display, iMac and iPad Pro, comes with a $150 price increase, but if you really don’t like reflections on your screen, it could be worth it. Compared to most other laptops, MacBook displays are notably bright, sharp and lush. But one feature worth pointing out is another Apple marketing term: ProMotion. It’s the company’s term to describe a screen with a higher, 120Hz refresh rate, which results in smoother scrolling and more fluid-looking graphics. Only MacBook Pros offer ProMotion; the Air maxes out at 60Hz, which is perfectly fine for everyday browsing and typical workdays. But if you want buttery-smooth motion from your display, you’ll have to shell out more money for an upgrade. Operating systems Software considerations won’t make much of a difference when deciding between MacBook models — all come with macOS installed. But if you’re switching from, say, a Windows PC, the operating system may be something to factor into your decision — though it’s probably less of an issue than it once was. Now that so much of the work we do on our computers is browser- and cloud-based, the learning curve between the two platforms isn’t as steep. Apps and programs like Gmail perform similarly regardless of what computer you’re using. Apple machines have historically had more limited support of AAA gaming titles, but even that is changing with more AAA games and better graphics coming to Macs. As for macOS, it’s getting better too. With macOS Tahoe 26, the Spotlight function is more advanced, making it easier to find apps and perform tasks straight from your keyboard. The software also implements Apple's unifying Liquid Glass design for a modern look that looks consistent across iOS and iPad devices. New enhanced iPhone continuity features also make MacBooks and the handset work better together. A revamped Shortcuts app is more powerful as well, giving users custom automations that leverage Apple Intelligence (the company’s own AI). Price When Apple announced the MacBook Air M4, it also delivered a bit of refreshing news: The latest model now starts $100 cheaper than the previous generation. So now, the least expensive MacBook is the 13-inch, M4-powered Air with 16GB of RAM and 256GB of storage for $999. Alternatively, you can spend up to $7,349 for the 16-inch MacBook Pro M4 Max with the nano-texture glass, 128GB of RAM and 8TB of storage. Chip type, screen size, memory and storage capacity all influence the final price, which is why guides like this can help you determine just what you need (and what you don’t) so you can get the most cost-effective machine for you. AppleCare is another cost to consider. The extended warranty plan from Apple covers repairs from accidents and offers free battery replacement and starts at $3.50 per month or $35 per year for MacBooks. We recommend the MacBook Air M4 for most people, and thanks to that $100 price cut, it’s also a good budget option. If you want something even cheaper, we recommend looking at refurbished M-series models from Apple. We think the 14- or 16-inch MacBook Pros are best for professionals. If you have extra money to spare once you’ve picked your machine, we recommend upgrading to at least 512GB of storage to make your machine as future-proof as possible. Of course, if you're just after the M4 chip and want the cheapest route to get it, you might consider the M4 Mac mini, which starts at $599 (though you'll have to supply the screen, mouse and keyboard). Best MacBooks spec comparison chart Product Superlative Tested configuration Tested battery life Rated battery life Apple MacBook Air M4 (13-inch) Best MacBook overall Apple M4, 16GB RAM, 256GB SSD 18.25 hours Up to 18 hours Apple MacBook Pro M4 (14-inch) Best MacBook for creatives Apple M4, 16GB RAM, 512GB SSD 34.25 hours Up to 22 hours Best MacBook FAQs What's the difference between MacBook Air and Pro? Both the MacBook Air and Pro models come with the M4 chip. MBP models have the option of more powerful M4 Pro or M4 Max chips. The Pro has a higher resolution screen with a higher peak brightness that supports up to 120Hz adaptive refresh rates and XDR (extreme dynamic range). The battery life on most Pro models is longer than on the Air models as well. Pro models also have more ports and more speakers. In short, the MacBook Air is aimed at everyday users looking for good productivity and entertainment capabilities, while Pro models are aimed at professionals who need a high-performance computer. What's the difference between macOS and Windows? MacOS is the operating system developed by Apple and used in all of its desktop and laptop computers. It can only be found in hardware made by Apple including MacBooks and iMacs. Microsoft’s Windows operating system can be found in the company’s own Surface laptops as well as computers made by a wide array of manufacturers, like Acer, Asus, Dell and Razer.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-macbook-140032524.html?src=rss",
          "feed_position": 42,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-11/e536a1d0-7c1e-11ee-9e77-9ea8e142b078"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/visa-just-launched-a-protocol-to-secure-the-ai-shopping-boom-heres-what-it",
          "published_at": "Tue, 14 Oct 2025 07:00:00 GMT",
          "title": "Visa just launched a protocol to secure the AI shopping boom — here’s what it means for merchants",
          "standfirst": "Visa is introducing a new security framework designed to solve one of the thorniest problems emerging in artificial intelligence-powered commerce: how retailers can tell the difference between legitimate AI shopping assistants and the malicious bots that plague their websites.The payments giant unveiled its Trusted Agent Protocol on Tuesday, establishing what it describes as foundational infrastructure for \"agentic commerce\" — a term for the rapidly growing practice of consumers delegating shopping tasks to AI agents that can search products, compare prices, and complete purchases autonomously.The protocol enables merchants to cryptographically verify that an AI agent browsing their site is authorized and trustworthy, rather than a bot designed to scrape pricing data, test stolen credit cards, or carry out other fraudulent activities.The launch comes as AI-driven traffic to U.S. retail websites has exploded by more than 4,700% over the past year, according to data from Adobe cited by Visa. That dramatic surge has created an acute challenge for merchants whose existing bot detection systems — designed to block automated traffic — now risk accidentally blocking legitimate AI shoppers along with bad actors.\"Merchants need additional tools that provide them with greater insight and transparency into agentic commerce activities to ensure they can participate safely,\" said Rubail Birwadker, Visa&#x27;s Global Head of Growth, in an exclusive interview with VentureBeat. \"Without common standards, potential risks include ecosystem fragmentation and the proliferation of closed loop models.\"The stakes are substantial. While 85% of shoppers who have used AI to shop report improved experiences, merchants face the prospect of either turning away legitimate AI-powered customers or exposing themselves to sophisticated bot attacks. Visa&#x27;s own data shows the company prevented $40 billion in fraudulent activity between October 2022 and September 2023, nearly double the previous year, much of it involving AI-powered enumeration attacks where bots systematically test combinations of card numbers until finding valid credentials.Inside the cryptographic handshake: How Visa verifies AI shopping agentsVisa&#x27;s Trusted Agent Protocol operates through what Birwadker describes as a \"cryptographic trust handshake\" between merchants and approved AI agents. The system works in three steps:First, AI agents must be approved and onboarded through Visa&#x27;s Intelligent Commerce program, where they undergo vetting to meet trust and reliability standards. Each approved agent receives a unique digital signature key — essentially a cryptographic credential that proves its identity.When an approved agent visits a merchant&#x27;s website, it creates a digital signature using its key and transmits three categories of information: Agent Intent (indicating the agent is trusted and intends to retrieve product details or make a purchase), Consumer Recognition (data showing whether the underlying consumer has an existing account with the merchant), and Payment Information (optional payment data to support checkout).Merchants or their infrastructure providers, such as content delivery networks, then validate these digital signatures against Visa&#x27;s registry of approved agents. \"Upon proper validation of these fields, the merchant can confirm the signature is a trusted agent,\" Birwadker explained.Crucially, Visa designed the protocol to require minimal changes to existing merchant infrastructure. Built on the HTTP Message Signature standard and aligned with Web Both Auth, the protocol works with existing web infrastructure without requiring merchants to overhaul their checkout pages. \"This is no-code functionality,\" Birwadker emphasized, though merchants may need to integrate with Visa&#x27;s Developer Center to access the verification system.The race for AI commerce standards: Visa faces competition from Google, OpenAI, and StripeVisa developed the protocol in collaboration with Cloudflare, the web infrastructure and security company that already provides bot management services to millions of websites. The partnership reflects Visa&#x27;s recognition that solving bot verification requires cooperation across the entire web stack, not just the payments layer.\"Trusted Agent Protocol supplements traditional bot management by providing merchants insights that enable agentic commerce,\" Birwadker said. \"Agents are providing additional context they otherwise would not, including what it intends to do, who the underlying consumer is, and payment information.\"The protocol arrives as multiple technology giants race to establish competing standards for AI commerce. Google recently introduced its Agent Protocol for Payments (AP2), while OpenAI and Stripe have discussed their own approaches to enabling AI agents to make purchases. Microsoft, Shopify, Adyen, Ant International, Checkout.com, Cybersource, Elavon, Fiserv, Nuvei, and Worldpay provided feedback during Trusted Agent Protocol&#x27;s development, according to Visa.When asked how Visa&#x27;s protocol relates to these competing efforts, Birwadker struck a collaborative tone. \"Both Google&#x27;s AP2 and Visa&#x27;s Trusted Agent Protocol are working toward the same goal of building trust in agent-initiated payments,\" he said. \"We are engaged with Google, OpenAI, and Stripe and are looking to create compatibility across the ecosystem.\"Visa says it is working with global standards bodies including the Internet Engineering Task Force (IETF), OpenID Foundation, and EMVCo to ensure the protocol can eventually become interoperable with other emerging standards. \"While these specifications apply to the Visa network in this initial phase, enabling agents to safely and securely act on a consumer&#x27;s behalf requires an open, ecosystem-wide approach,\" Birwadker noted.Who pays when AI agents go rogue? Unanswered questions about liability and authorizationThe protocol raises important questions about authorization and liability when AI agents make purchases on behalf of consumers. If an agent completes an unauthorized transaction — perhaps misunderstanding a user&#x27;s intent or exceeding its delegated authority — who bears responsibility?Birwadker emphasized that the protocol helps merchants \"leverage this information to enable experiences tied to existing consumer relationships and more secure checkout,\" but he did not provide specific details about how disputes would be handled when agents make unauthorized purchases. Visa&#x27;s existing fraud protection and chargeback systems would presumably apply, though the company has not yet published detailed guidance on agent-initiated transaction disputes.The protocol also places Visa in the position of gatekeeper for the emerging agentic commerce ecosystem. Because Visa determines which AI agents get approved for the Intelligent Commerce program and receive cryptographic credentials, the company effectively controls which agents merchants can easily trust. \"Agents are approved and onboarded through the Visa Intelligent Commerce program, ensuring they meet our standards for trust and reliability,\" Birwadker said, though he did not detail the specific criteria agents must meet or whether Visa charges fees for approval.This gatekeeping role could prove contentious, particularly if Visa&#x27;s approval process favors large technology companies over startups, or if the company faces pressure to block agents from competitors or politically controversial entities. Visa declined to provide details about how many agents it has approved so far or how long the vetting process typically takes.Visa&#x27;s legal battles and the long road to merchant adoptionThe protocol launch comes at a complex moment for Visa, which continues to navigate significant legal and regulatory challenges even as its core business remains robust. The company&#x27;s latest earnings report for the third quarter of fiscal year 2025 showed a 10% increase in net revenues to $9.2 billion, driven by resilient consumer spending and strong growth in cross-border transaction volume. For the full fiscal year ending September 30, 2024, Visa processed 289 billion transactions, with a total payments volume of $15.2 trillion. However, the company&#x27;s legal headwinds have intensified. In July 2025, a federal judge rejected a landmark $30 billion settlement that Visa and Mastercard had reached with merchants over long-disputed credit card swipe fees, sending the parties back to the negotiating table and extending the long-running legal battle.Simultaneously, Visa remains under investigation by the Department of Justice over its rules for routing debit card transactions, with regulators scrutinizing whether the company&#x27;s practices unlawfully limit merchant choice and stifle competition. These domestic challenges are mirrored abroad, where European regulators have continued their own antitrust investigations into the fee structures of both Visa and its primary competitor, Mastercard.Against this backdrop of regulatory pressure, Birwadker acknowledged that adoption of the Trusted Agent Protocol will take time. \"As agentic commerce continues to rise, we recognize that consumer trust is still in its early stages,\" he said. \"That&#x27;s why our focus through 2025 is on building foundational credibility and demonstrating real-world value.\"The protocol is available immediately in Visa&#x27;s Developer Center and on GitHub, with agent onboarding already active and merchant integration resources available. But Birwadker declined to provide specific targets for how many merchants might adopt the protocol by the end of 2026. \"Adoption is aligned with the momentum we&#x27;re already seeing,\" he said. \"The launch of our protocol marks another big step — it&#x27;s not just a technical milestone, but a signal that the industry is beginning to unify.\"Industry analysts say merchant adoption will likely depend on how quickly agentic commerce grows as a percentage of overall e-commerce. While AI-driven traffic has surged dramatically, much of that consists of agents browsing and researching rather than completing purchases. If AI agents begin accounting for a significant share of completed transactions, merchants will face stronger incentives to adopt verification systems like Visa&#x27;s protocol.From fraud detection to AI gatekeeping: Visa&#x27;s $10 billion bet on artificial intelligenceVisa&#x27;s move reflects broader strategic bets on AI across the financial services industry. The company has invested $10 billion in technology over the past five years to reduce fraud and increase network security, with AI and machine learning central to those efforts. Visa&#x27;s fraud detection system analyzes over 500 different attributes for each transaction, using AI models to assign real-time risk scores to the 300 billion annual transactions flowing through its network.\"Every single one of those transactions has been processed by AI,\" James Mirfin, Visa&#x27;s global head of risk and identity solutions, said in a July 2024 CNBC interview discussing the company&#x27;s fraud prevention efforts. \"If you see a new type of fraud happening, our model will see that, it will catch it, it will score those transactions as high risk and then our customers can decide not to approve those transactions.\"The company has also moved aggressively into new payment territories beyond its core card business. In January 2025, Visa partnered with Elon Musk&#x27;s X (formerly Twitter) to provide the infrastructure for a digital wallet and peer-to-peer payment service called the X Money Account, competing with services like Venmo and Zelle. That deal marked Visa&#x27;s first major partnership in the social media payments space and reflected the company&#x27;s recognition that payment flows are increasingly happening outside traditional e-commerce channels.The agentic commerce protocol represents an extension of this strategy — an attempt to ensure Visa remains central to payment flows even as the mechanics of shopping shift from direct human interaction to AI intermediation. Jack Forestell, Visa&#x27;s Chief Product & Strategy Officer, framed the protocol in expansive terms: \"We believe the entire payments ecosystem has a responsibility to ensure sellers trust AI agents with the same confidence they place in their most valued customers and networks.\"The coming battle for control of AI shoppingThe real test for Visa&#x27;s protocol won&#x27;t be technical — it will be political. As AI agents become a larger force in retail, whoever controls the verification infrastructure controls access to hundreds of billions of dollars in commerce. Visa&#x27;s position as gatekeeper gives it enormous leverage, but also makes it a target.Merchants chafing under Visa&#x27;s existing fee structure and facing multiple antitrust investigations may resist ceding even more power to the payments giant. Competitors like Google and OpenAI, each with their own ambitions in commerce, have little incentive to let Visa dictate standards. Regulators already scrutinizing Visa&#x27;s market dominance will surely examine whether its agent approval process unfairly advantages certain players.And there&#x27;s a deeper question lurking beneath the technical specifications and corporate partnerships: In an economy increasingly mediated by AI, who decides which algorithms get to spend our money? Visa is making an aggressive bid to be that arbiter, wrapping its answer in the language of security and interoperability. Whether merchants, consumers, and regulators accept that proposition will determine not just the fate of the Trusted Agent Protocol, but the structure of AI-powered commerce itself.For now, Visa is moving forward with the confidence of a company that has weathered disruption before. But in the emerging world of agentic commerce, being too trusted might prove just as dangerous as not being trusted enough.",
          "content": "Visa is introducing a new security framework designed to solve one of the thorniest problems emerging in artificial intelligence-powered commerce: how retailers can tell the difference between legitimate AI shopping assistants and the malicious bots that plague their websites.The payments giant unveiled its Trusted Agent Protocol on Tuesday, establishing what it describes as foundational infrastructure for \"agentic commerce\" — a term for the rapidly growing practice of consumers delegating shopping tasks to AI agents that can search products, compare prices, and complete purchases autonomously.The protocol enables merchants to cryptographically verify that an AI agent browsing their site is authorized and trustworthy, rather than a bot designed to scrape pricing data, test stolen credit cards, or carry out other fraudulent activities.The launch comes as AI-driven traffic to U.S. retail websites has exploded by more than 4,700% over the past year, according to data from Adobe cited by Visa. That dramatic surge has created an acute challenge for merchants whose existing bot detection systems — designed to block automated traffic — now risk accidentally blocking legitimate AI shoppers along with bad actors.\"Merchants need additional tools that provide them with greater insight and transparency into agentic commerce activities to ensure they can participate safely,\" said Rubail Birwadker, Visa&#x27;s Global Head of Growth, in an exclusive interview with VentureBeat. \"Without common standards, potential risks include ecosystem fragmentation and the proliferation of closed loop models.\"The stakes are substantial. While 85% of shoppers who have used AI to shop report improved experiences, merchants face the prospect of either turning away legitimate AI-powered customers or exposing themselves to sophisticated bot attacks. Visa&#x27;s own data shows the company prevented $40 billion in fraudulent activity between October 2022 and September 2023, nearly double the previous year, much of it involving AI-powered enumeration attacks where bots systematically test combinations of card numbers until finding valid credentials.Inside the cryptographic handshake: How Visa verifies AI shopping agentsVisa&#x27;s Trusted Agent Protocol operates through what Birwadker describes as a \"cryptographic trust handshake\" between merchants and approved AI agents. The system works in three steps:First, AI agents must be approved and onboarded through Visa&#x27;s Intelligent Commerce program, where they undergo vetting to meet trust and reliability standards. Each approved agent receives a unique digital signature key — essentially a cryptographic credential that proves its identity.When an approved agent visits a merchant&#x27;s website, it creates a digital signature using its key and transmits three categories of information: Agent Intent (indicating the agent is trusted and intends to retrieve product details or make a purchase), Consumer Recognition (data showing whether the underlying consumer has an existing account with the merchant), and Payment Information (optional payment data to support checkout).Merchants or their infrastructure providers, such as content delivery networks, then validate these digital signatures against Visa&#x27;s registry of approved agents. \"Upon proper validation of these fields, the merchant can confirm the signature is a trusted agent,\" Birwadker explained.Crucially, Visa designed the protocol to require minimal changes to existing merchant infrastructure. Built on the HTTP Message Signature standard and aligned with Web Both Auth, the protocol works with existing web infrastructure without requiring merchants to overhaul their checkout pages. \"This is no-code functionality,\" Birwadker emphasized, though merchants may need to integrate with Visa&#x27;s Developer Center to access the verification system.The race for AI commerce standards: Visa faces competition from Google, OpenAI, and StripeVisa developed the protocol in collaboration with Cloudflare, the web infrastructure and security company that already provides bot management services to millions of websites. The partnership reflects Visa&#x27;s recognition that solving bot verification requires cooperation across the entire web stack, not just the payments layer.\"Trusted Agent Protocol supplements traditional bot management by providing merchants insights that enable agentic commerce,\" Birwadker said. \"Agents are providing additional context they otherwise would not, including what it intends to do, who the underlying consumer is, and payment information.\"The protocol arrives as multiple technology giants race to establish competing standards for AI commerce. Google recently introduced its Agent Protocol for Payments (AP2), while OpenAI and Stripe have discussed their own approaches to enabling AI agents to make purchases. Microsoft, Shopify, Adyen, Ant International, Checkout.com, Cybersource, Elavon, Fiserv, Nuvei, and Worldpay provided feedback during Trusted Agent Protocol&#x27;s development, according to Visa.When asked how Visa&#x27;s protocol relates to these competing efforts, Birwadker struck a collaborative tone. \"Both Google&#x27;s AP2 and Visa&#x27;s Trusted Agent Protocol are working toward the same goal of building trust in agent-initiated payments,\" he said. \"We are engaged with Google, OpenAI, and Stripe and are looking to create compatibility across the ecosystem.\"Visa says it is working with global standards bodies including the Internet Engineering Task Force (IETF), OpenID Foundation, and EMVCo to ensure the protocol can eventually become interoperable with other emerging standards. \"While these specifications apply to the Visa network in this initial phase, enabling agents to safely and securely act on a consumer&#x27;s behalf requires an open, ecosystem-wide approach,\" Birwadker noted.Who pays when AI agents go rogue? Unanswered questions about liability and authorizationThe protocol raises important questions about authorization and liability when AI agents make purchases on behalf of consumers. If an agent completes an unauthorized transaction — perhaps misunderstanding a user&#x27;s intent or exceeding its delegated authority — who bears responsibility?Birwadker emphasized that the protocol helps merchants \"leverage this information to enable experiences tied to existing consumer relationships and more secure checkout,\" but he did not provide specific details about how disputes would be handled when agents make unauthorized purchases. Visa&#x27;s existing fraud protection and chargeback systems would presumably apply, though the company has not yet published detailed guidance on agent-initiated transaction disputes.The protocol also places Visa in the position of gatekeeper for the emerging agentic commerce ecosystem. Because Visa determines which AI agents get approved for the Intelligent Commerce program and receive cryptographic credentials, the company effectively controls which agents merchants can easily trust. \"Agents are approved and onboarded through the Visa Intelligent Commerce program, ensuring they meet our standards for trust and reliability,\" Birwadker said, though he did not detail the specific criteria agents must meet or whether Visa charges fees for approval.This gatekeeping role could prove contentious, particularly if Visa&#x27;s approval process favors large technology companies over startups, or if the company faces pressure to block agents from competitors or politically controversial entities. Visa declined to provide details about how many agents it has approved so far or how long the vetting process typically takes.Visa&#x27;s legal battles and the long road to merchant adoptionThe protocol launch comes at a complex moment for Visa, which continues to navigate significant legal and regulatory challenges even as its core business remains robust. The company&#x27;s latest earnings report for the third quarter of fiscal year 2025 showed a 10% increase in net revenues to $9.2 billion, driven by resilient consumer spending and strong growth in cross-border transaction volume. For the full fiscal year ending September 30, 2024, Visa processed 289 billion transactions, with a total payments volume of $15.2 trillion. However, the company&#x27;s legal headwinds have intensified. In July 2025, a federal judge rejected a landmark $30 billion settlement that Visa and Mastercard had reached with merchants over long-disputed credit card swipe fees, sending the parties back to the negotiating table and extending the long-running legal battle.Simultaneously, Visa remains under investigation by the Department of Justice over its rules for routing debit card transactions, with regulators scrutinizing whether the company&#x27;s practices unlawfully limit merchant choice and stifle competition. These domestic challenges are mirrored abroad, where European regulators have continued their own antitrust investigations into the fee structures of both Visa and its primary competitor, Mastercard.Against this backdrop of regulatory pressure, Birwadker acknowledged that adoption of the Trusted Agent Protocol will take time. \"As agentic commerce continues to rise, we recognize that consumer trust is still in its early stages,\" he said. \"That&#x27;s why our focus through 2025 is on building foundational credibility and demonstrating real-world value.\"The protocol is available immediately in Visa&#x27;s Developer Center and on GitHub, with agent onboarding already active and merchant integration resources available. But Birwadker declined to provide specific targets for how many merchants might adopt the protocol by the end of 2026. \"Adoption is aligned with the momentum we&#x27;re already seeing,\" he said. \"The launch of our protocol marks another big step — it&#x27;s not just a technical milestone, but a signal that the industry is beginning to unify.\"Industry analysts say merchant adoption will likely depend on how quickly agentic commerce grows as a percentage of overall e-commerce. While AI-driven traffic has surged dramatically, much of that consists of agents browsing and researching rather than completing purchases. If AI agents begin accounting for a significant share of completed transactions, merchants will face stronger incentives to adopt verification systems like Visa&#x27;s protocol.From fraud detection to AI gatekeeping: Visa&#x27;s $10 billion bet on artificial intelligenceVisa&#x27;s move reflects broader strategic bets on AI across the financial services industry. The company has invested $10 billion in technology over the past five years to reduce fraud and increase network security, with AI and machine learning central to those efforts. Visa&#x27;s fraud detection system analyzes over 500 different attributes for each transaction, using AI models to assign real-time risk scores to the 300 billion annual transactions flowing through its network.\"Every single one of those transactions has been processed by AI,\" James Mirfin, Visa&#x27;s global head of risk and identity solutions, said in a July 2024 CNBC interview discussing the company&#x27;s fraud prevention efforts. \"If you see a new type of fraud happening, our model will see that, it will catch it, it will score those transactions as high risk and then our customers can decide not to approve those transactions.\"The company has also moved aggressively into new payment territories beyond its core card business. In January 2025, Visa partnered with Elon Musk&#x27;s X (formerly Twitter) to provide the infrastructure for a digital wallet and peer-to-peer payment service called the X Money Account, competing with services like Venmo and Zelle. That deal marked Visa&#x27;s first major partnership in the social media payments space and reflected the company&#x27;s recognition that payment flows are increasingly happening outside traditional e-commerce channels.The agentic commerce protocol represents an extension of this strategy — an attempt to ensure Visa remains central to payment flows even as the mechanics of shopping shift from direct human interaction to AI intermediation. Jack Forestell, Visa&#x27;s Chief Product & Strategy Officer, framed the protocol in expansive terms: \"We believe the entire payments ecosystem has a responsibility to ensure sellers trust AI agents with the same confidence they place in their most valued customers and networks.\"The coming battle for control of AI shoppingThe real test for Visa&#x27;s protocol won&#x27;t be technical — it will be political. As AI agents become a larger force in retail, whoever controls the verification infrastructure controls access to hundreds of billions of dollars in commerce. Visa&#x27;s position as gatekeeper gives it enormous leverage, but also makes it a target.Merchants chafing under Visa&#x27;s existing fee structure and facing multiple antitrust investigations may resist ceding even more power to the payments giant. Competitors like Google and OpenAI, each with their own ambitions in commerce, have little incentive to let Visa dictate standards. Regulators already scrutinizing Visa&#x27;s market dominance will surely examine whether its agent approval process unfairly advantages certain players.And there&#x27;s a deeper question lurking beneath the technical specifications and corporate partnerships: In an economy increasingly mediated by AI, who decides which algorithms get to spend our money? Visa is making an aggressive bid to be that arbiter, wrapping its answer in the language of security and interoperability. Whether merchants, consumers, and regulators accept that proposition will determine not just the fate of the Trusted Agent Protocol, but the structure of AI-powered commerce itself.For now, Visa is moving forward with the confidence of a company that has weathered disruption before. But in the emerging world of agentic commerce, being too trusted might prove just as dangerous as not being trusted enough.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4TWzzYHcsJXmxU7VYnIlKV/896cc598ae137fe841c13309d6aae3df/nuneybits_Vector_art_of_a_Visa_credit_card_c3c9580a-d8ce-4402-9763-bd56dc26549e.webp"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/energy/how-rose-rock-bridge-is-building-the-future-of-energy-in-tulsa-oklahoma",
          "published_at": "Tue, 14 Oct 2025 04:00:00 GMT",
          "title": "How Rose Rock Bridge is building the future of energy in Tulsa, Oklahoma",
          "standfirst": "Presented by Tulsa Innovation LabsTulsa was once called \"the oil capital of the world,” and since its launch in 2022, Rose Rock Bridge (RRB), a Tulsa-based non-profit startup incubator led by Tulsa Innovation Labs, has been capitalizing on this heritage, aiming to source and support emerging technologies targeting the energy sector. To create a tech economy that becomes foundational to the future of the sustainable energy industry, and competes on the world stage, they&#x27;re marrying the expertise and industry that already exists in Tulsa with promising entrepreneurial talent. \"Places like Tulsa, we’re tailor-made for tech excellence,\" says Jennifer Hankins, managing director, Tulsa Innovation Labs. \"Our legacy as an oil and gas leader means we know how to build things, and we know how to capture big industries, and we&#x27;re positioned to be a leader in energy innovation.\"RRB, in partnership with major stakeholders, is helping put the region&#x27;s strong corporate, academic, and workforce resources in the hands of innovative, early-stage startups developing the next-generation solutions that are solving pressing energy industry problems and opening up new markets. \"We&#x27;re building the next generation of big energy companies that tackle global challenges in a way that&#x27;s authentic to Tulsa&#x27;s local expertise, and not one that feels more extractive to it,\" she adds. \"RRB has already accelerated 33 companies, initiated 22 active pilots with industry partners, and secured 11 customer contracts, resulting in over $50 million in funding raised by its member companies. What sets the Rose Rock Bridge Showcase apartRRB&#x27;s Rose Rock Bridge Showcase is a showcase and pitch competition presented in partnership with four local energy industry partners: Williams, ONEOK, Devon Energy, and Helmerich and Payne. These partners identify white space problems they&#x27;re aiming to solve — this year, low carbon natural gas solutions — and RRB finds the startups that can solve them. From a competitive pool of more than 50 applications, fourteen companies are selected to pitch for pilot opportunities and potential investment from leading Oklahoma energy companies. While most pitch competitions are seen as pathways to venture capital, the RRB model is designed to accelerate commercialization; instead of vying for funding alone, these companies are competing for the chance to put their technology into practice, Hankins explains.\"What sets the winners apart is the way they&#x27;re solving big challenges with game-changing ideas in the energy space,\" Hankins says. \"But above and beyond just a great idea, it has to be an idea that’s commercial. We can say that our companies have already demonstrated the technology. They’ve already validated it. They’ve secured a big customer, gained traction, are on the path to secure follow-on funding. Those are things that hold back most startups, and our program brings all of those three things together to accelerate commercialization.\" Each startup receives $100,000 in non-dilutive funding to grow their business in Tulsa, along with support services and pilot opportunities through industry partners, equipping them with both the resources and real-world experience needed for long-term market integration — and a solid foothold in Tulsa.This year&#x27;s cohort is comprised of companies that are driving innovation in low carbon natural gas through technologies that enhance operations, control and reduce emissions, and turn waste from energy production into valuable materials:Eigen ControlDeveloping artificial intelligence/machine learning-assisted Raman Spectroscopy for real-time chemical analysis, which helps energy providers process their product more efficiently.Erdin Guma, Eigen ControlKinitics AutomationIncreasing the reliability of equipment while reducing methane emissions with spring-loaded electric valve actuatorsDean Pick, Kinitics AutomationLukera EnergyConverting wastewater and stranded gas into clean methanolBrian Worfolk, Lukera EnergyPike Robotics Making hazardous, high-risk environments safer with robotic inspection platforms.Connor Crawford, Pike RoboticsEmbedding global innovation in the Tulsa market\"We talk a lot about stickiness,\" Hankins says. \"Tulsa Innovation Labs, in addition to the Rose Rock Bridge initiative, is really focused on creating that supportive ecosystem in the region.\"For example, ensuring these companies have lab space if necessary, connecting them to university partners to sharpen research and development, and helping them establish relationships and follow-on funding with other energy-related funds, and embedding them into the Tulsa energy tech landscape. The RRB entrepreneur in residence and executive in residence offer in-depth mentoring as well.\"I call it polishing the startups,\" Hankins explains. \"You go through our program, get a pilot, get insight from the corporate perspective. That’s probably the highest value. But along the way, all the support to help you operationalize your company and your idea faster. We’re going to find a way that you’ll leave our program more ready to get to market, whether that be through some of those auxiliary supports, or we’re going to make sure that direct connection to the customer happens.\"Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Tulsa Innovation LabsTulsa was once called \"the oil capital of the world,” and since its launch in 2022, Rose Rock Bridge (RRB), a Tulsa-based non-profit startup incubator led by Tulsa Innovation Labs, has been capitalizing on this heritage, aiming to source and support emerging technologies targeting the energy sector. To create a tech economy that becomes foundational to the future of the sustainable energy industry, and competes on the world stage, they&#x27;re marrying the expertise and industry that already exists in Tulsa with promising entrepreneurial talent. \"Places like Tulsa, we’re tailor-made for tech excellence,\" says Jennifer Hankins, managing director, Tulsa Innovation Labs. \"Our legacy as an oil and gas leader means we know how to build things, and we know how to capture big industries, and we&#x27;re positioned to be a leader in energy innovation.\"RRB, in partnership with major stakeholders, is helping put the region&#x27;s strong corporate, academic, and workforce resources in the hands of innovative, early-stage startups developing the next-generation solutions that are solving pressing energy industry problems and opening up new markets. \"We&#x27;re building the next generation of big energy companies that tackle global challenges in a way that&#x27;s authentic to Tulsa&#x27;s local expertise, and not one that feels more extractive to it,\" she adds. \"RRB has already accelerated 33 companies, initiated 22 active pilots with industry partners, and secured 11 customer contracts, resulting in over $50 million in funding raised by its member companies. What sets the Rose Rock Bridge Showcase apartRRB&#x27;s Rose Rock Bridge Showcase is a showcase and pitch competition presented in partnership with four local energy industry partners: Williams, ONEOK, Devon Energy, and Helmerich and Payne. These partners identify white space problems they&#x27;re aiming to solve — this year, low carbon natural gas solutions — and RRB finds the startups that can solve them. From a competitive pool of more than 50 applications, fourteen companies are selected to pitch for pilot opportunities and potential investment from leading Oklahoma energy companies. While most pitch competitions are seen as pathways to venture capital, the RRB model is designed to accelerate commercialization; instead of vying for funding alone, these companies are competing for the chance to put their technology into practice, Hankins explains.\"What sets the winners apart is the way they&#x27;re solving big challenges with game-changing ideas in the energy space,\" Hankins says. \"But above and beyond just a great idea, it has to be an idea that’s commercial. We can say that our companies have already demonstrated the technology. They’ve already validated it. They’ve secured a big customer, gained traction, are on the path to secure follow-on funding. Those are things that hold back most startups, and our program brings all of those three things together to accelerate commercialization.\" Each startup receives $100,000 in non-dilutive funding to grow their business in Tulsa, along with support services and pilot opportunities through industry partners, equipping them with both the resources and real-world experience needed for long-term market integration — and a solid foothold in Tulsa.This year&#x27;s cohort is comprised of companies that are driving innovation in low carbon natural gas through technologies that enhance operations, control and reduce emissions, and turn waste from energy production into valuable materials:Eigen ControlDeveloping artificial intelligence/machine learning-assisted Raman Spectroscopy for real-time chemical analysis, which helps energy providers process their product more efficiently.Erdin Guma, Eigen ControlKinitics AutomationIncreasing the reliability of equipment while reducing methane emissions with spring-loaded electric valve actuatorsDean Pick, Kinitics AutomationLukera EnergyConverting wastewater and stranded gas into clean methanolBrian Worfolk, Lukera EnergyPike Robotics Making hazardous, high-risk environments safer with robotic inspection platforms.Connor Crawford, Pike RoboticsEmbedding global innovation in the Tulsa market\"We talk a lot about stickiness,\" Hankins says. \"Tulsa Innovation Labs, in addition to the Rose Rock Bridge initiative, is really focused on creating that supportive ecosystem in the region.\"For example, ensuring these companies have lab space if necessary, connecting them to university partners to sharpen research and development, and helping them establish relationships and follow-on funding with other energy-related funds, and embedding them into the Tulsa energy tech landscape. The RRB entrepreneur in residence and executive in residence offer in-depth mentoring as well.\"I call it polishing the startups,\" Hankins explains. \"You go through our program, get a pilot, get insight from the corporate perspective. That’s probably the highest value. But along the way, all the support to help you operationalize your company and your idea faster. We’re going to find a way that you’ll leave our program more ready to get to market, whether that be through some of those auxiliary supports, or we’re going to make sure that direct connection to the customer happens.\"Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4CvrYLswHJAPv6hA7Y9OEv/05b317701dbf8dd1141e164e77e67446/RRB_VB_Images.final.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/self-improving-language-models-are-becoming-reality-with-mits-updated-seal",
          "published_at": "Mon, 13 Oct 2025 22:51:00 GMT",
          "title": "Self-improving language models are becoming reality with MIT's updated SEAL technique",
          "standfirst": "Researchers at the Massachusetts Institute of Technology (MIT) are gaining renewed attention for developing and open sourcing a technique that allows large language models (LLMs) — like those underpinning ChatGPT and most modern AI chatbots — to improve themselves by generating synthetic data to fine-tune upon. The technique, known as SEAL (Self-Adapting LLMs), was first described in a paper published back in June and covered by VentureBeat at the time.A significantly expanded and updated version of the paper was released last month, as well as open source code posted on Github (under an MIT License, allowing for commercial and enterprise usage), and is making new waves among AI power users on the social network X this week.SEAL allows LLMs to autonomously generate and apply their own fine-tuning strategies. Unlike conventional models that rely on fixed external data and human-crafted optimization pipelines, SEAL enables models to evolve by producing their own synthetic training data and corresponding optimization directives.The development comes from a team affiliated with MIT’s Improbable AI Lab, including Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, and Pulkit Agrawal. Their research was recently presented at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025).Background: From “Beyond Static AI” to Self-Adaptive SystemsEarlier this year, VentureBeat first reported on SEAL as an early-stage framework that allowed language models to generate and train on their own synthetic data — a potential remedy for the stagnation of pretrained models once deployed. At that stage, SEAL was framed as a proof-of-concept that could let enterprise AI agents continuously learn in dynamic environments without manual retraining.Since then, the research has advanced considerably. The new version expands on the prior framework by demonstrating that SEAL’s self-adaptation ability scales with model size, integrates reinforcement learning more effectively to reduce catastrophic forgetting, and formalizes SEAL’s dual-loop structure (inner supervised fine-tuning and outer reinforcement optimization) for reproducibility. The updated paper also introduces evaluations across different prompting formats, improved stability during learning cycles, and a discussion of practical deployment challenges at inference time.Addressing the Limitations of Static ModelsWhile LLMs have demonstrated remarkable capabilities in text generation and understanding, their adaptation to new tasks or knowledge is often manual, brittle, or dependent on context. SEAL challenges this status quo by equipping models with the ability to generate what the authors call “self-edits” — natural language outputs that specify how the model should update its weights.These self-edits may take the form of reformulated information, logical implications, or tool configurations for augmentation and training. Once generated, the model fine-tunes itself based on these edits. The process is guided by reinforcement learning, where the reward signal comes from improved performance on a downstream task.The design mimics how human learners might rephrase or reorganize study materials to better internalize information. This restructuring of knowledge before assimilation serves as a key advantage over models that passively consume new data “as-is.”Performance Across TasksSEAL has been tested across two main domains: knowledge incorporation and few-shot learning.In the knowledge incorporation setting, the researchers evaluated how well a model could internalize new factual content from passages similar to those in the SQuAD dataset, a benchmark reading comprehension dataset introduced by Stanford University in 2016, consisting of over 100,000 crowd-sourced question–answer pairs based on Wikipedia articles (Rajpurkar et al., 2016). Rather than fine-tuning directly on passage text, the model generated synthetic implications of the passage and then fine-tuned on them. After two rounds of reinforcement learning, the model improved question-answering accuracy from 33.5% to 47.0% on a no-context version of SQuAD — surpassing results obtained using synthetic data generated by GPT-4.1.In the few-shot learning setting, SEAL was evaluated using a subset of the ARC benchmark, where tasks require reasoning from only a few examples. Here, SEAL generated self-edits specifying data augmentations and hyperparameters. After reinforcement learning, the success rate in correctly solving held-out tasks jumped to 72.5%, up from 20% using self-edits generated without reinforcement learning. Models that relied solely on in-context learning without any adaptation scored 0%.Technical FrameworkSEAL operates using a two-loop structure: an inner loop performs supervised fine-tuning based on the self-edit, while an outer loop uses reinforcement learning to refine the policy that generates those self-edits.The reinforcement learning algorithm used is based on ReSTEM, which combines sampling with filtered behavior cloning. During training, only self-edits that lead to performance improvements are reinforced. This approach effectively teaches the model which kinds of edits are most beneficial for learning.For efficiency, SEAL applies LoRA-based fine-tuning rather than full parameter updates, enabling rapid experimentation and low-cost adaptation.Strengths and LimitationsThe researchers report that SEAL can produce high-utility training data with minimal supervision, outperforming even large external models like GPT-4.1 in specific tasks. They also demonstrate that SEAL generalizes beyond its original setup: it continues to perform well when scaling from single-pass updates to multi-document continued pretraining scenarios.However, the framework is not without limitations. One issue is catastrophic forgetting, where updates to incorporate new information can degrade performance on previously learned tasks. In response to this concern, co-author Jyo Pari told VentureBeat via email that reinforcement learning (RL) appears to mitigate forgetting more effectively than standard supervised fine-tuning (SFT), citing a recent paper on the topic. He added that combining this insight with SEAL could lead to new variants where SEAL learns not just training data, but reward functions.Another challenge is computational overhead: evaluating each self-edit requires fine-tuning and performance testing, which can take 30–45 seconds per edit — significantly more than standard reinforcement learning tasks. As Jyo explained, “Training SEAL is non-trivial because it requires 2 loops of optimization, an outer RL one and an inner SFT one. At inference time, updating model weights will also require new systems infrastructure.” He emphasized the need for future research into deployment systems as a critical path to making SEAL practical.Additionally, SEAL’s current design assumes the presence of paired tasks and reference answers for every context, limiting its direct applicability to unlabeled corpora. However, Jyo clarified that as long as there is a downstream task with a computable reward, SEAL can be trained to adapt accordingly—even in safety-critical domains. In principle, a SEAL-trained model could learn to avoid training on harmful or malicious inputs if guided by the appropriate reward signal.AI Community ReactionsThe AI research and builder community has reacted with a mix of excitement and speculation to the SEAL paper. On X, formerly Twitter, several prominent AI-focused accounts weighed in on the potential impact.User @VraserX, a self-described educator and AI enthusiast, called SEAL “the birth of continuous self-learning AI” and predicted that models like OpenAI&#x27;s GPT-6 could adopt similar architecture. In their words, SEAL represents “the end of the frozen-weights era,” ushering in systems that evolve as the world around them changes. They highlighted SEAL&#x27;s ability to form persistent memories, repair knowledge, and learn from real-time data, comparing it to a foundational step toward models that don’t just use information but absorb it.Meanwhile, @alex_prompter, co-founder of an AI-powered marketing venture, framed SEAL as a leap toward models that literally rewrite themselves. “MIT just built an AI that can rewrite its own code to get smarter,” he wrote. Citing the paper’s key results — a 40% boost in factual recall and outperforming GPT-4.1 using self-generated data — he described the findings as confirmation that “LLMs that finetune themselves are no longer sci-fi.”The enthusiasm reflects a broader appetite in the AI space for models that can evolve without constant retraining or human oversight — particularly in rapidly changing domains or personalized use cases.Future Directions and Open QuestionsIn response to questions about scaling SEAL to larger models and tasks, Jyo pointed to experiments (Appendix B.7) showing that as model size increases, so does their self-adaptation ability. He compared this to students improving their study techniques over time — larger models are simply better at generating useful self-edits.When asked whether SEAL generalizes to new prompting styles, he confirmed it does, citing Table 10 in the paper. However, he also acknowledged that the team has not yet tested SEAL’s ability to transfer across entirely new domains or model architectures. “SEAL is an initial work showcasing the possibilities,” he said. “But it requires much more testing.” He added that generalization may improve as SEAL is trained on a broader distribution of tasks.Interestingly, the team found that only a few reinforcement learning steps already led to measurable performance gains. “This is exciting,” Jyo noted, “because it means that with more compute, we could hopefully get even more improvements.” He suggested future experiments could explore more advanced reinforcement learning methods beyond ReSTEM, such as Group Relative Policy Optimization (GRPO).Toward More Adaptive and Agentic ModelsSEAL represents a step toward models that can autonomously improve over time, both by integrating new knowledge and by reconfiguring how they learn. The authors envision future extensions where SEAL could assist in self-pretraining, continual learning, and the development of agentic systems — models that interact with evolving environments and adapt incrementally.In such settings, a model could use SEAL to synthesize weight updates after each interaction, gradually internalizing behaviors or insights. This could reduce the need for repeated supervision and manual intervention, particularly in data-constrained or specialized domains.As public web text becomes saturated and further scaling of LLMs becomes bottlenecked by data availability, self-directed approaches like SEAL could play a critical role in pushing the boundaries of what LLMs can achieve.You can access the SEAL project, including code and further documentation, at: https://jyopari.github.io/posts/seal",
          "content": "Researchers at the Massachusetts Institute of Technology (MIT) are gaining renewed attention for developing and open sourcing a technique that allows large language models (LLMs) — like those underpinning ChatGPT and most modern AI chatbots — to improve themselves by generating synthetic data to fine-tune upon. The technique, known as SEAL (Self-Adapting LLMs), was first described in a paper published back in June and covered by VentureBeat at the time.A significantly expanded and updated version of the paper was released last month, as well as open source code posted on Github (under an MIT License, allowing for commercial and enterprise usage), and is making new waves among AI power users on the social network X this week.SEAL allows LLMs to autonomously generate and apply their own fine-tuning strategies. Unlike conventional models that rely on fixed external data and human-crafted optimization pipelines, SEAL enables models to evolve by producing their own synthetic training data and corresponding optimization directives.The development comes from a team affiliated with MIT’s Improbable AI Lab, including Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, and Pulkit Agrawal. Their research was recently presented at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025).Background: From “Beyond Static AI” to Self-Adaptive SystemsEarlier this year, VentureBeat first reported on SEAL as an early-stage framework that allowed language models to generate and train on their own synthetic data — a potential remedy for the stagnation of pretrained models once deployed. At that stage, SEAL was framed as a proof-of-concept that could let enterprise AI agents continuously learn in dynamic environments without manual retraining.Since then, the research has advanced considerably. The new version expands on the prior framework by demonstrating that SEAL’s self-adaptation ability scales with model size, integrates reinforcement learning more effectively to reduce catastrophic forgetting, and formalizes SEAL’s dual-loop structure (inner supervised fine-tuning and outer reinforcement optimization) for reproducibility. The updated paper also introduces evaluations across different prompting formats, improved stability during learning cycles, and a discussion of practical deployment challenges at inference time.Addressing the Limitations of Static ModelsWhile LLMs have demonstrated remarkable capabilities in text generation and understanding, their adaptation to new tasks or knowledge is often manual, brittle, or dependent on context. SEAL challenges this status quo by equipping models with the ability to generate what the authors call “self-edits” — natural language outputs that specify how the model should update its weights.These self-edits may take the form of reformulated information, logical implications, or tool configurations for augmentation and training. Once generated, the model fine-tunes itself based on these edits. The process is guided by reinforcement learning, where the reward signal comes from improved performance on a downstream task.The design mimics how human learners might rephrase or reorganize study materials to better internalize information. This restructuring of knowledge before assimilation serves as a key advantage over models that passively consume new data “as-is.”Performance Across TasksSEAL has been tested across two main domains: knowledge incorporation and few-shot learning.In the knowledge incorporation setting, the researchers evaluated how well a model could internalize new factual content from passages similar to those in the SQuAD dataset, a benchmark reading comprehension dataset introduced by Stanford University in 2016, consisting of over 100,000 crowd-sourced question–answer pairs based on Wikipedia articles (Rajpurkar et al., 2016). Rather than fine-tuning directly on passage text, the model generated synthetic implications of the passage and then fine-tuned on them. After two rounds of reinforcement learning, the model improved question-answering accuracy from 33.5% to 47.0% on a no-context version of SQuAD — surpassing results obtained using synthetic data generated by GPT-4.1.In the few-shot learning setting, SEAL was evaluated using a subset of the ARC benchmark, where tasks require reasoning from only a few examples. Here, SEAL generated self-edits specifying data augmentations and hyperparameters. After reinforcement learning, the success rate in correctly solving held-out tasks jumped to 72.5%, up from 20% using self-edits generated without reinforcement learning. Models that relied solely on in-context learning without any adaptation scored 0%.Technical FrameworkSEAL operates using a two-loop structure: an inner loop performs supervised fine-tuning based on the self-edit, while an outer loop uses reinforcement learning to refine the policy that generates those self-edits.The reinforcement learning algorithm used is based on ReSTEM, which combines sampling with filtered behavior cloning. During training, only self-edits that lead to performance improvements are reinforced. This approach effectively teaches the model which kinds of edits are most beneficial for learning.For efficiency, SEAL applies LoRA-based fine-tuning rather than full parameter updates, enabling rapid experimentation and low-cost adaptation.Strengths and LimitationsThe researchers report that SEAL can produce high-utility training data with minimal supervision, outperforming even large external models like GPT-4.1 in specific tasks. They also demonstrate that SEAL generalizes beyond its original setup: it continues to perform well when scaling from single-pass updates to multi-document continued pretraining scenarios.However, the framework is not without limitations. One issue is catastrophic forgetting, where updates to incorporate new information can degrade performance on previously learned tasks. In response to this concern, co-author Jyo Pari told VentureBeat via email that reinforcement learning (RL) appears to mitigate forgetting more effectively than standard supervised fine-tuning (SFT), citing a recent paper on the topic. He added that combining this insight with SEAL could lead to new variants where SEAL learns not just training data, but reward functions.Another challenge is computational overhead: evaluating each self-edit requires fine-tuning and performance testing, which can take 30–45 seconds per edit — significantly more than standard reinforcement learning tasks. As Jyo explained, “Training SEAL is non-trivial because it requires 2 loops of optimization, an outer RL one and an inner SFT one. At inference time, updating model weights will also require new systems infrastructure.” He emphasized the need for future research into deployment systems as a critical path to making SEAL practical.Additionally, SEAL’s current design assumes the presence of paired tasks and reference answers for every context, limiting its direct applicability to unlabeled corpora. However, Jyo clarified that as long as there is a downstream task with a computable reward, SEAL can be trained to adapt accordingly—even in safety-critical domains. In principle, a SEAL-trained model could learn to avoid training on harmful or malicious inputs if guided by the appropriate reward signal.AI Community ReactionsThe AI research and builder community has reacted with a mix of excitement and speculation to the SEAL paper. On X, formerly Twitter, several prominent AI-focused accounts weighed in on the potential impact.User @VraserX, a self-described educator and AI enthusiast, called SEAL “the birth of continuous self-learning AI” and predicted that models like OpenAI&#x27;s GPT-6 could adopt similar architecture. In their words, SEAL represents “the end of the frozen-weights era,” ushering in systems that evolve as the world around them changes. They highlighted SEAL&#x27;s ability to form persistent memories, repair knowledge, and learn from real-time data, comparing it to a foundational step toward models that don’t just use information but absorb it.Meanwhile, @alex_prompter, co-founder of an AI-powered marketing venture, framed SEAL as a leap toward models that literally rewrite themselves. “MIT just built an AI that can rewrite its own code to get smarter,” he wrote. Citing the paper’s key results — a 40% boost in factual recall and outperforming GPT-4.1 using self-generated data — he described the findings as confirmation that “LLMs that finetune themselves are no longer sci-fi.”The enthusiasm reflects a broader appetite in the AI space for models that can evolve without constant retraining or human oversight — particularly in rapidly changing domains or personalized use cases.Future Directions and Open QuestionsIn response to questions about scaling SEAL to larger models and tasks, Jyo pointed to experiments (Appendix B.7) showing that as model size increases, so does their self-adaptation ability. He compared this to students improving their study techniques over time — larger models are simply better at generating useful self-edits.When asked whether SEAL generalizes to new prompting styles, he confirmed it does, citing Table 10 in the paper. However, he also acknowledged that the team has not yet tested SEAL’s ability to transfer across entirely new domains or model architectures. “SEAL is an initial work showcasing the possibilities,” he said. “But it requires much more testing.” He added that generalization may improve as SEAL is trained on a broader distribution of tasks.Interestingly, the team found that only a few reinforcement learning steps already led to measurable performance gains. “This is exciting,” Jyo noted, “because it means that with more compute, we could hopefully get even more improvements.” He suggested future experiments could explore more advanced reinforcement learning methods beyond ReSTEM, such as Group Relative Policy Optimization (GRPO).Toward More Adaptive and Agentic ModelsSEAL represents a step toward models that can autonomously improve over time, both by integrating new knowledge and by reconfiguring how they learn. The authors envision future extensions where SEAL could assist in self-pretraining, continual learning, and the development of agentic systems — models that interact with evolving environments and adapt incrementally.In such settings, a model could use SEAL to synthesize weight updates after each interaction, gradually internalizing behaviors or insights. This could reduce the need for repeated supervision and manual intervention, particularly in data-constrained or specialized domains.As public web text becomes saturated and further scaling of LLMs becomes bottlenecked by data availability, self-directed approaches like SEAL could play a critical role in pushing the boundaries of what LLMs can achieve.You can access the SEAL project, including code and further documentation, at: https://jyopari.github.io/posts/seal",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4816Y0YfsXKIENLGFsuaG6/a4620bd99d25c8fe32ab054bd16ff390/cfr0z3n_a_cybernetic_seal_looks_up_with_cute_alert_eyes_under_a_a6f43d56-7792-4d4f-bc1e-18b6dd2f5e4e.png"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/researchers-find-that-retraining-only-small-parts-of-ai-models-can-cut-costs",
          "published_at": "Mon, 13 Oct 2025 22:39:00 GMT",
          "title": "Researchers find that retraining only small parts of AI models can cut costs and prevent forgetting",
          "standfirst": "Enterprises often find that when they fine-tune models, one effective approach to making a large language model (LLM) fit for purpose and grounded in data is to have the model lose some of its abilities. After fine-tuning, some models “forget” how to perform certain tasks or other tasks they already learned. Research from the University of Illinois Urbana-Champaign proposes a new method for retraining models that avoids “catastrophic forgetting,” in which the model loses some of its prior knowledge. The paper focuses on two specific LLMs that generate responses from images: LLaVA and Qwen 2.5-VL.The approach encourages enterprises to retrain only narrow parts of an LLM to avoid retraining the entire model and incurring a significant increase in compute costs. The team claims that catastrophic forgetting isn’t true memory loss, but rather a side effect of bias drift. “Training a new LMM can cost millions of dollars, weeks of time, and emit hundreds of tons of CO2, so finding ways to more efficiently and effectively update existing models is a pressing concern,” the team wrote in the paper. “Guided by this result, we explore tuning recipes that preserve learning while limiting output shift.”The researchers focused on a multi-layer perceptron (MLP), the model&#x27;s internal decision-making component. Catastrophic forgetting The researchers wanted first to verify the existence and the cause of catastrophic forgetting in models. To do this, they created a set of target tasks for the models to complete. The models were then fine-tuned and evaluated to determine whether they led to substantial forgetting. But as the process went on, the researchers found that the models were recovering some of their abilities. “We also noticed a surprising result, that the model performance would drop significantly in held out benchmarks after training on the counting task, it would mostly recover on PathVQA, another specialized task that is not well represented in the benchmarks,” they said. “Meanwhile, while performing the forgetting mitigation experiments, we also tried separately tuning only the self-attention projection (SA Proj) or MLP layers, motivated by the finding that tuning only the LLM was generally better than tuning the full model. This led to another very surprising result – that tuning only self-attention projection layers led to very good learning of the target tasks with no drop in performance in held out tasks, even after training all five target tasks in a sequence.”The researchers said they believe that “what looks like forgetting or interference after fine-tuning on a narrow target task is actually bias in the output distribution due to the task distribution shift.”Narrow retrainingThat finding turned out to be the key to the experiment. The researchers noted that tuning the MLP increases the likelihood of “outputting numeric tokens and a highly correlated drop in held out task accuracy.” What it showed is that a model forgetting some of its knowledge is only temporary and not a long-term matter. “To avoid biasing the output distribution, we tune the MLP up/gating projections while keeping the down projection frozen, and find that it achieves similar learning to full MLP tuning with little forgetting,” the researchers said. This allows for a more straightforward and more reproducible method for fine-tuning a model. By focusing on a narrow segment of the model, rather than a wholesale retraining, enterprises can cut compute costs. It also allows better control of output drift. However, the research focuses only on two models, specifically those dealing with vision and language. The researchers noted that due to limited resources, they are unable to try the experiment with other models.Their findings, however, can be extended to other LLMs, especially for different modalities.",
          "content": "Enterprises often find that when they fine-tune models, one effective approach to making a large language model (LLM) fit for purpose and grounded in data is to have the model lose some of its abilities. After fine-tuning, some models “forget” how to perform certain tasks or other tasks they already learned. Research from the University of Illinois Urbana-Champaign proposes a new method for retraining models that avoids “catastrophic forgetting,” in which the model loses some of its prior knowledge. The paper focuses on two specific LLMs that generate responses from images: LLaVA and Qwen 2.5-VL.The approach encourages enterprises to retrain only narrow parts of an LLM to avoid retraining the entire model and incurring a significant increase in compute costs. The team claims that catastrophic forgetting isn’t true memory loss, but rather a side effect of bias drift. “Training a new LMM can cost millions of dollars, weeks of time, and emit hundreds of tons of CO2, so finding ways to more efficiently and effectively update existing models is a pressing concern,” the team wrote in the paper. “Guided by this result, we explore tuning recipes that preserve learning while limiting output shift.”The researchers focused on a multi-layer perceptron (MLP), the model&#x27;s internal decision-making component. Catastrophic forgetting The researchers wanted first to verify the existence and the cause of catastrophic forgetting in models. To do this, they created a set of target tasks for the models to complete. The models were then fine-tuned and evaluated to determine whether they led to substantial forgetting. But as the process went on, the researchers found that the models were recovering some of their abilities. “We also noticed a surprising result, that the model performance would drop significantly in held out benchmarks after training on the counting task, it would mostly recover on PathVQA, another specialized task that is not well represented in the benchmarks,” they said. “Meanwhile, while performing the forgetting mitigation experiments, we also tried separately tuning only the self-attention projection (SA Proj) or MLP layers, motivated by the finding that tuning only the LLM was generally better than tuning the full model. This led to another very surprising result – that tuning only self-attention projection layers led to very good learning of the target tasks with no drop in performance in held out tasks, even after training all five target tasks in a sequence.”The researchers said they believe that “what looks like forgetting or interference after fine-tuning on a narrow target task is actually bias in the output distribution due to the task distribution shift.”Narrow retrainingThat finding turned out to be the key to the experiment. The researchers noted that tuning the MLP increases the likelihood of “outputting numeric tokens and a highly correlated drop in held out task accuracy.” What it showed is that a model forgetting some of its knowledge is only temporary and not a long-term matter. “To avoid biasing the output distribution, we tune the MLP up/gating projections while keeping the down projection frozen, and find that it achieves similar learning to full MLP tuning with little forgetting,” the researchers said. This allows for a more straightforward and more reproducible method for fine-tuning a model. By focusing on a narrow segment of the model, rather than a wholesale retraining, enterprises can cut compute costs. It also allows better control of output drift. However, the research focuses only on two models, specifically those dealing with vision and language. The researchers noted that due to limited resources, they are unable to try the experiment with other models.Their findings, however, can be extended to other LLMs, especially for different modalities.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/wvhlzgUGzNikEzmtJxvNB/ed69fb909b090e1e7e6b81ff61abf8b0/crimedy7_illustration_of_a_sculptor_creating_a_robot_from_a_p_501bf165-0b44-4bb1-9608-1025a42400b7_1.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/apple-tv-is-now-just-apple-tv-200644609.html",
          "published_at": "Mon, 13 Oct 2025 20:06:44 +0000",
          "title": "Apple TV+ is now just Apple TV",
          "standfirst": "It’s been an interesting few months in the realm of streaming service branding. Warner Bros. Discovery reverted Max back to HBO Max after a baffling decision to trim the name in the first place. Disney made Hulu the \"global general entertainment brand\" on Disney+ when it rebranded the Star hub on the service. Now Apple would like you to know that it’s changing the name of its streaming service too. Going forward, Apple TV+ is now just Apple TV.The company revealed the news in very lowkey fashion, at the end of a press release about when its F1 movie will land on Apple TV, the streaming service with a monthly subscription (December 12, FYI). “Apple TV+ is now simply Apple TV, with a vibrant new identity,” the company said without elaborating.Apple does like to keep things clean, and shearing off the plus sign is one way of doing that. But oversimplification can cause greater confusion. As Apple states in its own press release, “Apple TV is available on the Apple TV app” and “For a limited time, customers who purchase and activate a new iPhone, iPad, Apple TV or Mac can enjoy three months of Apple TV for free.” Did no one at Apple’s (generally very effective) marketing team spot the problem with this? Buying Apple TV to get free Apple TV sounds like a recursive capitalist fever dream that will never end.As it stands, you can turn on your Apple TV device to open the Apple TV app to watch Apple TV. There are lots of things in the Apple TV app that aren’t actually Apple TV shows or movies and you may have to pay for those separately. The press release also states that you can watch F1 right now if you buy it on Apple TV through the Apple TV app, so you don’t have to wait for the film to make its “global streaming debut” on Apple TV. What a mess.Apple hasn’t fully rolled out the change yet, as there are still plenty of references to “Apple TV+” on the streaming service’s website. It’s still referred to as Apple TV+ on the TV app’s listing on the App Store too. I’m interested to see how confusing things really get if, in the coming months, Apple reveals a refreshed Apple TV. You know, that device you can use to watch Apple TV.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/apple-tv-is-now-just-apple-tv-200644609.html?src=rss",
          "content": "It’s been an interesting few months in the realm of streaming service branding. Warner Bros. Discovery reverted Max back to HBO Max after a baffling decision to trim the name in the first place. Disney made Hulu the \"global general entertainment brand\" on Disney+ when it rebranded the Star hub on the service. Now Apple would like you to know that it’s changing the name of its streaming service too. Going forward, Apple TV+ is now just Apple TV.The company revealed the news in very lowkey fashion, at the end of a press release about when its F1 movie will land on Apple TV, the streaming service with a monthly subscription (December 12, FYI). “Apple TV+ is now simply Apple TV, with a vibrant new identity,” the company said without elaborating.Apple does like to keep things clean, and shearing off the plus sign is one way of doing that. But oversimplification can cause greater confusion. As Apple states in its own press release, “Apple TV is available on the Apple TV app” and “For a limited time, customers who purchase and activate a new iPhone, iPad, Apple TV or Mac can enjoy three months of Apple TV for free.” Did no one at Apple’s (generally very effective) marketing team spot the problem with this? Buying Apple TV to get free Apple TV sounds like a recursive capitalist fever dream that will never end.As it stands, you can turn on your Apple TV device to open the Apple TV app to watch Apple TV. There are lots of things in the Apple TV app that aren’t actually Apple TV shows or movies and you may have to pay for those separately. The press release also states that you can watch F1 right now if you buy it on Apple TV through the Apple TV app, so you don’t have to wait for the film to make its “global streaming debut” on Apple TV. What a mess.Apple hasn’t fully rolled out the change yet, as there are still plenty of references to “Apple TV+” on the streaming service’s website. It’s still referred to as Apple TV+ on the TV app’s listing on the App Store too. I’m interested to see how confusing things really get if, in the coming months, Apple reveals a refreshed Apple TV. You know, that device you can use to watch Apple TV.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/apple-tv-is-now-just-apple-tv-200644609.html?src=rss",
          "feed_position": 47
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/4tvp7qfEbQOW0pucNGc3oW/21a8f215813133c934f9e71c0acff280/Screenshot_2025-10-15_at_2.53.23%C3%A2__PM.png",
      "popularity_score": 2019.5745247222221,
      "ai_summary": [
        "Google unveiled Veo 3.1, its latest AI video generation model, with upgrades.",
        "Veo 3.1 improves narrative control, audio integration, and overall realism.",
        "Native audio generation is now available across key features in Flow.",
        "Users can turn images into video, use objects from multiple images, and extend clips.",
        "The model offers greater command over tone, emotion, and storytelling capabilities."
      ]
    },
    {
      "id": "cluster_48",
      "coverage": 2,
      "updated_at": "Wed, 15 Oct 2025 11:20:00 -0400",
      "title": "Meta adds group chats to Threads, allowing users to add up to 50 people who follow their Threads account, rolling out globally, excluding the UK and Australia (Jess Weatherbed/The Verge)",
      "neutral_headline": "Meta Adds Group Chats to Threads Application",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251015/p33#a251015p33",
          "published_at": "Wed, 15 Oct 2025 11:20:00 -0400",
          "title": "Meta adds group chats to Threads, allowing users to add up to 50 people who follow their Threads account, rolling out globally, excluding the UK and Australia (Jess Weatherbed/The Verge)",
          "standfirst": "Jess Weatherbed / The Verge: Meta adds group chats to Threads, allowing users to add up to 50 people who follow their Threads account, rolling out globally, excluding the UK and Australia &mdash; &#65279;Users can add up to 50 people into a single conversation. &hellip; Threads users can create a group chat by starting &hellip;",
          "content": "Jess Weatherbed / The Verge: Meta adds group chats to Threads, allowing users to add up to 50 people who follow their Threads account, rolling out globally, excluding the UK and Australia &mdash; &#65279;Users can add up to 50 people into a single conversation. &hellip; Threads users can create a group chat by starting &hellip;",
          "feed_position": 11,
          "image_url": "http://www.techmeme.com/251015/i33.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/799943/meta-threads-group-chat-messaging",
          "published_at": "2025-10-15T11:00:00-04:00",
          "title": "Threads now has group chats",
          "standfirst": "Meta is adding group chats to Threads, allowing users to message multiple friends in shared conversations instead of sending separate DMs. Threads users can create a group chat by starting a new message and adding up to 50 people who follow their Threads account. The group chat name can be customized to make it easier [&#8230;]",
          "content": "The ability to add users to group chats via shared links is coming in a future update. Meta is adding group chats to Threads, allowing users to message multiple friends in shared conversations instead of sending separate DMs. Threads users can create a group chat by starting a new message and adding up to 50 people who follow their Threads account. The group chat name can be customized to make it easier to identify by topic or participants, similar to how group messages function on Facebook Messenger. Group chat support is currently rolling out globally, excluding the UK and Australia, with Meta spokesperson Alec Booker telling The Verge that the company is working to expand messaging to these regions “as quickly as possible.” Future updates will include improved inbox management tools and enabling Threads users to invite people to group chats by sharing a link, instead of individually adding them to the conversation. The group messaging launch coincides with Threads expanding messaging features to the EU “over the next few days,” including support for both individual DMs and group chats.",
          "feed_position": 7
        }
      ],
      "featured_image": "http://www.techmeme.com/251015/i33.jpg",
      "popularity_score": 2016.0745247222221,
      "ai_summary": [
        "Meta is adding group chats to Threads, allowing users to message multiple friends.",
        "Users can create group chats by adding up to 50 followers to a conversation.",
        "Group chat names can be customized for easier identification and use.",
        "The feature is rolling out globally, excluding the United Kingdom and Australia.",
        "Threads users can now have shared conversations instead of separate DMs."
      ]
    },
    {
      "id": "cluster_90",
      "coverage": 2,
      "updated_at": "Wed, 15 Oct 2025 09:00:32 GMT",
      "title": "Driverless taxis from Waymo will be on London’s roads next year, US firm announces",
      "neutral_headline": "Waymo Plans Driverless Taxi Service in London",
      "items": [
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2025/oct/15/driverless-taxis-from-waymo-will-be-on-londons-roads-next-year-us-firm-announces",
          "published_at": "Wed, 15 Oct 2025 09:00:32 GMT",
          "title": "Driverless taxis from Waymo will be on London’s roads next year, US firm announces",
          "standfirst": "Cars with human safety drivers set to appear in 2026 but black-cab drivers dismiss service as ‘fairground ride’ People in London could be hiring driverless taxis from Waymo next year, after the US autonomous vehicle company announced plans to launch its services there.The UK capital will become the first European city to have an autonomous taxi service of the kind now familiar in San Francisco and four other US cities using Waymo’s technology. Continue reading...",
          "content": "Cars with human safety drivers set to appear in 2026 but black-cab drivers dismiss service as ‘fairground ride’ People in London could be hiring driverless taxis from Waymo next year, after the US autonomous vehicle company announced plans to launch its services there.The UK capital will become the first European city to have an autonomous taxi service of the kind now familiar in San Francisco and four other US cities using Waymo’s technology. Continue reading...",
          "feed_position": 0
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/15/waymo-plans-to-launch-a-robotaxi-service-in-london-in-2026/",
          "published_at": "Wed, 15 Oct 2025 09:00:00 +0000",
          "title": "Waymo plans to launch a robotaxi service in London in 2026",
          "standfirst": "Waymo already has ties to the UK, which began after the autonomous vehicle technology company acquired Latent Logic in 2019.",
          "content": "Waymo already has ties to the UK, which began after the autonomous vehicle technology company acquired Latent Logic in 2019.",
          "feed_position": 17
        }
      ],
      "popularity_score": 2009.7500802777777,
      "ai_summary": [
        "Waymo plans to launch a robotaxi service in London in 2026.",
        "London will be the first European city to have this autonomous taxi service.",
        "Cars with human safety drivers are set to appear in 2026.",
        "Waymo acquired Latent Logic in 2019, establishing ties to the UK.",
        "Black-cab drivers dismiss the service as a \"fairground ride\"."
      ]
    },
    {
      "id": "cluster_39",
      "coverage": 1,
      "updated_at": "Wed, 15 Oct 2025 16:00:51 +0000",
      "title": "Google’s AI videos get a big upgrade with Veo 3.1",
      "neutral_headline": "Google's AI Videos Get a Big Upgrade with Veo 3.1",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/10/googles-ai-videos-get-a-big-upgrade-with-veo-3-1/",
          "published_at": "Wed, 15 Oct 2025 16:00:51 +0000",
          "title": "Google’s AI videos get a big upgrade with Veo 3.1",
          "standfirst": "Veo 3.1 is coming to the Gemini app and the Flow filmmaking tool.",
          "content": "It's getting harder to know what's real on the Internet, and Google is not helping one bit with the announcement of Veo 3.1. The company's new video model supposedly offers better audio and realism, along with greater prompt accuracy. The updated video AI will be available throughout the Google ecosystem, including the Flow filmmaking tool, where the new model will unlock additional features. And if you're worried about the cost of conjuring all these AI videos, Google is also adding a \"Fast\" variant of Veo. Veo made waves when it debuted earlier this year, demonstrating a staggering improvement in AI video quality just a few months after Veo 2's release. It turns out that having all that video on YouTube is very useful for training AI models, so Google is already moving on to Veo 3.1 with a raft of new features. Google says Veo 3.1 offers stronger prompt adherence, which results in better video outputs and fewer wasted compute cycles. Audio, which was a hallmark feature of the Veo 3 release, has reportedly improved, too. Veo 3's text-to-video was limited to 720p landscape output, but there's an ever-increasing volume of vertical video on the Internet. So Veo 3.1 can produce both landscape and portrait 16:9 video.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Veo-3.1-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Veo-3.1-1152x648.png",
      "popularity_score": 343.7553580555556,
      "ai_summary": [
        "Google's Veo 3.1 is coming to the Gemini app and the Flow filmmaking tool.",
        "The upgrade includes improvements to video generation capabilities.",
        "Veo 3.1 is the latest iteration of Google's AI video model.",
        "The update aims to enhance the user experience and creative possibilities.",
        "The new model is designed to improve video quality and functionality."
      ]
    },
    {
      "id": "cluster_6",
      "coverage": 1,
      "updated_at": "Wed, 15 Oct 2025 18:26:20 +0000",
      "title": "ISPs angry about California law that lets renters opt out of forced payments",
      "neutral_headline": "California Law Allows Renters to Opt Out of Payments",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/california-says-landlords-cant-make-tenants-pay-for-an-isp-they-dont-want/",
          "published_at": "Wed, 15 Oct 2025 18:26:20 +0000",
          "title": "ISPs angry about California law that lets renters opt out of forced payments",
          "standfirst": "Gov. Newsom signs broadband billing law hated by the cable industry.",
          "content": "Rejecting opposition from the cable and real estate industries, California Gov. Gavin Newsom signed a bill that aims to increase broadband competition in apartment buildings. The new law taking effect on January 1 says landlords must let tenants \"opt out of paying for any subscription from a third-party Internet service provider, such as through a bulk-billing arrangement, to provide service for wired Internet, cellular, or satellite service that is offered in connection with the tenancy.\" It was approved by the state Assembly in a 75–0 vote in April, and by the Senate in a 30–7 vote last month. \"This is kind of like a first step in trying to give this industry an opportunity to just treat people fairly,\" Assemblymember Rhodesia Ransom, a Democratic lawmaker who authored the bill, told Ars last month. \"It's not super restrictive. We are not banning bulk billing. We're not even limiting how much money the people can make. What we're saying here with this bill is that if a tenant wants to opt out of the arrangement, they should be allowed to opt out.\"Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/10/broadband-ethernet-cables-1152x648-1742589135.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2020/10/broadband-ethernet-cables-1152x648-1742589135.jpg",
      "popularity_score": 342.1800802777778,
      "ai_summary": [
        "California law allows renters to opt out of forced broadband payments.",
        "The law was signed by Governor Newsom, despite industry opposition.",
        "ISPs are unhappy about the new law regarding broadband billing.",
        "The law impacts how renters can access and pay for internet services.",
        "The cable industry has expressed strong disapproval of the legislation."
      ]
    },
    {
      "id": "cluster_18",
      "coverage": 1,
      "updated_at": "Wed, 15 Oct 2025 17:00:51 +0000",
      "title": "US demand grows for Chinese cars despite privacy and security fears",
      "neutral_headline": "US Demand Grows for Chinese Cars Despite Concerns",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/us-demand-grows-for-chinese-cars-despite-privacy-and-security-fears/",
          "published_at": "Wed, 15 Oct 2025 17:00:51 +0000",
          "title": "US demand grows for Chinese cars despite privacy and security fears",
          "standfirst": "But they're still unlikely to go on sale in the US.",
          "content": "More than half of American car buyers would consider a Chinese car brand for their next purchase, an increase of almost 25 percent compared to last year. That's according to a survey of prospective car buyers conducted annually by the research firm AutoPacific. And yes, those car buyers are conscious of the privacy and security fears. AutoPacific spoke to 18,000 people who said they were planning to buy or lease a new car within the next three years for its 2025 Future Attribution Demand Study, and the company has been releasing snippets of data as it analyzes them, ahead of the full report's release later this year. There has already been at least one surprise. Last year, partially automated driving systems like General Motors' Super Cruise or Ford's BlueCruise, or those developed by Tesla, were not in high demand. This year, that tech went to the top of the most-wanted list, with 43 percent of consumers saying they want hands-free partial automation. The same percentage also indicated a demand for rear automatic emergency braking. Wireless device charging, No. 1 in the list in 2024, didn't make the top 15 for 2025.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2240964205-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2240964205-1152x648.jpg",
      "popularity_score": 340.7553580555556,
      "ai_summary": [
        "US demand for Chinese cars is growing, despite privacy concerns.",
        "Security fears also exist regarding the use of Chinese vehicles.",
        "Chinese cars are unlikely to go on sale in the United States.",
        "The demand increase reflects changing consumer preferences.",
        "The situation highlights the complexities of international trade."
      ]
    },
    {
      "id": "cluster_50",
      "coverage": 1,
      "updated_at": "Wed, 15 Oct 2025 15:14:52 +0000",
      "title": "ChatGPT erotica coming soon with age verification, CEO says",
      "neutral_headline": "ChatGPT Erotica Coming Soon with Age Verification",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/chatgpt-will-soon-allow-erotic-chats-for-verified-adults-only/",
          "published_at": "Wed, 15 Oct 2025 15:14:52 +0000",
          "title": "ChatGPT erotica coming soon with age verification, CEO says",
          "standfirst": "Sam Altman claims new tools can detect mental distress while relaxing limits for adults.",
          "content": "On Tuesday, OpenAI CEO Sam Altman announced that the company will allow verified adult users to have erotic conversations with ChatGPT starting in December. The change represents a shift in how OpenAI approaches content restrictions, which the company had loosened in February but then dramatically tightened after an August lawsuit from parents of a teen who died by suicide after allegedly receiving encouragement from ChatGPT. \"In December, as we roll out age-gating more fully and as part of our 'treat adult users like adults' principle, we will allow even more, like erotica for verified adults,\" Altman wrote in his post on X (formerly Twitter). The announcement follows OpenAI's recent hint that it would allow developers to create \"mature\" ChatGPT applications once the company implements appropriate age verification and controls. Altman explained that OpenAI had made ChatGPT \"pretty restrictive to make sure we were being careful with mental health issues\" but acknowledged this approach made the chatbot \"less useful/enjoyable to many users who had no mental health problems.\" The CEO said the company now has new tools to better detect when users are experiencing mental distress, allowing OpenAI to relax restrictions in most cases.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/12/openai-math-apples-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/12/openai-math-apples-1152x648.jpg",
      "popularity_score": 323.98896916666666,
      "ai_summary": [
        "ChatGPT erotica is coming soon, with age verification measures.",
        "Sam Altman claims new tools can detect mental distress.",
        "Limits for adult content are being relaxed by OpenAI.",
        "The changes aim to balance content moderation and user experience.",
        "OpenAI is adjusting its policies regarding adult-oriented content."
      ]
    },
    {
      "id": "cluster_62",
      "coverage": 1,
      "updated_at": "Wed, 15 Oct 2025 14:35:48 +0000",
      "title": "Apple unveils M5 update for the 11- and 13-inch iPad Pros",
      "neutral_headline": "Apple Unveils M5 Update for the 11- and 13-inch iPad Pros",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/apple-unveils-m5-update-for-the-11-and-13-inch-ipad-pros/",
          "published_at": "Wed, 15 Oct 2025 14:35:48 +0000",
          "title": "Apple unveils M5 update for the 11- and 13-inch iPad Pros",
          "standfirst": "Leaks of the new tablet from a couple weeks ago appear to have been genuine.",
          "content": "A couple of weeks ago, a YouTuber unboxed what appeared to be a refreshed iPad Pro in full retail packaging, suggesting it would be launching imminently. Today, Apple formally announced the new tablets, and it looks like pretty much everything uncovered by that YouTuber turned out to be accurate. The new iPad Pros, powered by Apple's also-new M5 chip, use the same basic designs as the M4 iPad Pros from last year and are compatible with the same cases and accessories. The new iPad Pro starts at $999 for the 11-inch model and $1,299 for the 13-inch model, is available for pre-order today, and ships on October 22. Apple's M5 is similar in composition to the M4—the fully enabled version uses four high-performance CPU cores, six high-efficiency CPU cores, 10 GPU cores, and a 16-core Neural Engine. But a memory bandwidth increase, from 120GB/s for the M4 to 153GB/s for the M5, enables a 30 percent improvement in GPU performance and a 45 percent increase to ray-traced graphics performance, according to Apple's estimates. Apple's press release also highlighted improvements to storage performance, with \"up to 2x faster storage read and write speeds.\"Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Apple-iPad-Pro-hero-251015-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Apple-iPad-Pro-hero-251015-1152x648.jpg",
      "popularity_score": 310.33785805555556,
      "ai_summary": [
        "Apple has unveiled the M5 update for the 11- and 13-inch iPad Pros.",
        "Leaks of the new tablet from a couple weeks ago appear to be genuine.",
        "The new update includes performance and feature enhancements.",
        "The iPad Pro models are receiving a significant hardware upgrade.",
        "The update aligns with previously circulating information."
      ]
    },
    {
      "id": "cluster_70",
      "coverage": 1,
      "updated_at": "Wed, 15 Oct 2025 14:03:55 +0000",
      "title": "New Apple M5 is the centerpiece of an updated 14-inch MacBook Pro",
      "neutral_headline": "New Apple M5 is the Centerpiece of Updated MacBook Pro",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/new-apple-m5-is-the-centerpiece-of-an-updated-14-inch-macbook-pro/",
          "published_at": "Wed, 15 Oct 2025 14:03:55 +0000",
          "title": "New Apple M5 is the centerpiece of an updated 14-inch MacBook Pro",
          "standfirst": "A 27.5% increase in memory bandwidth provides a big boost to GPU performance.",
          "content": "Apple often releases a smaller second wave of new products in October after the dust settles from its September iPhone announcement, and this year that wave revolves around its brand-new M5 chip. The first Mac to get the new processor will be the new 14-inch MacBook Pro, which the company announced today on its press site alongside a new M5 iPad Pro and an updated version of the Vision Pro headset. But unlike the last couple MacBook Pro refreshes, Apple isn't ready with Pro and Max versions of the M5 for higher-end 14-inch MacBook Pros and 16-inch MacBook Pros. Those models will continue to use the M4 Pro and M4 Max for now, and we probably shouldn't expect an update for them until sometime next year. Aside from the M5, the 14-inch M5 MacBook Pro has essentially identical specs to the outgoing M4 version. It has a notched 14-inch screen with ProMotion support and a 3024×1964 resolution, three USB-C/Thunderbolt 4 ports, an HDMI port, an SD card slot, and a 12 MP Center Stage webcam. It still weighs 3.4 pounds, and Apple still estimates the battery should last for \"up to 16 hours\" of wireless web browsing and up to 24 hours of video streaming. The main internal difference is an option for a 4TB storage upgrade, which will run you $1,200 if you're upgrading from the base 512GB SSD.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Apple-MacBook-Pro-14-in-hero-251015-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Apple-MacBook-Pro-14-in-hero-251015-1152x648.jpg",
      "popularity_score": 299.80646916666666,
      "ai_summary": [
        "The new Apple M5 is the centerpiece of an updated 14-inch MacBook Pro.",
        "A 27.5% increase in memory bandwidth provides a big boost to GPU performance.",
        "The update includes significant improvements to the MacBook Pro's capabilities.",
        "The new MacBook Pro aims to enhance user experience and performance.",
        "The M5 chip is a key component of the updated MacBook Pro model."
      ]
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Wed, 15 Oct 2025 13:37:01 +0000",
      "title": "Believing misinformation is a “win” for some people, even when proven false",
      "neutral_headline": "Believing Misinformation is a “Win” for Some People",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/believing-misinformation-is-a-win-for-some-people-even-when-proven-false/",
          "published_at": "Wed, 15 Oct 2025 13:37:01 +0000",
          "title": "Believing misinformation is a “win” for some people, even when proven false",
          "standfirst": "\"Winning\" means prioritizing independence from outside influence over being right.",
          "content": "Why do some people endorse claims that can easily be disproved? It’s one thing to believe false information, but another to actively stick with something that’s obviously wrong. Our new research, published in the Journal of Social Psychology, suggests that some people consider it a “win” to lean in to known falsehoods. We are social psychologists who study political psychology and how people reason about reality. During the pandemic, we surveyed 5,535 people across eight countries to investigate why people believed COVID-19 misinformation, like false claims that 5G networks cause the virus.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/womanmask-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/womanmask-1152x648.jpg",
      "popularity_score": 283.35813583333334,
      "ai_summary": [
        "Believing misinformation is a \"win\" for some people, even when proven false.",
        "\"Winning\" means prioritizing independence from outside influence over being right.",
        "The phenomenon highlights the role of identity in information consumption.",
        "People may value their own beliefs over factual accuracy.",
        "The concept explains why some people reject corrected information."
      ]
    },
    {
      "id": "cluster_79",
      "coverage": 1,
      "updated_at": "Wed, 15 Oct 2025 13:27:08 +0000",
      "title": "With considerably less fanfare, Apple releases a second-generation Vision Pro",
      "neutral_headline": "Apple Releases Second-Generation Vision Pro",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/with-considerably-less-fanfare-apple-releases-a-second-generation-vision-pro/",
          "published_at": "Wed, 15 Oct 2025 13:27:08 +0000",
          "title": "With considerably less fanfare, Apple releases a second-generation Vision Pro",
          "standfirst": "Reports suggest that Apple has de-prioritized Vision Pro development internally.",
          "content": "Apple's announcement of the Vision Pro headset in 2023 was pretty hyperbolic about the device's potential, even by Apple's standards. CEO Tim Cook called it \"the beginning of a new era for computing,\" placing the Vision Pro in the same industry-shifting echelon as the Mac and the iPhone. The Vision Pro could still eventually lead to a product that ushers in a new age of \"spatial computing.\" But it does seem like Apple is a bit less optimistic about the headset's current form—at least, that's one possible way to read the fact that the second-generation Vision Pro is being announced via press release, rather than as the centerpiece of a product event. The new Vision Pro is available for the same $3,499 as the first model, which will likely continue to limit the headset's appeal outside of a die-hard community of early adopters and curious developers. It's available for pre-order today and ships on October 22.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Apple-Vision-Pro-hero-251015-1-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Apple-Vision-Pro-hero-251015-1-1152x648.jpeg",
      "popularity_score": 279.1934136111111,
      "ai_summary": [
        "Apple released a second-generation Vision Pro with less fanfare.",
        "Reports suggest that Apple has de-prioritized Vision Pro development internally.",
        "The release indicates a shift in Apple's focus on the product.",
        "The second generation may include improvements and refinements.",
        "The internal de-prioritization suggests a change in strategy."
      ]
    },
    {
      "id": "cluster_80",
      "coverage": 1,
      "updated_at": "Wed, 15 Oct 2025 13:00:23 +0000",
      "title": "ROG Xbox Ally X: The Ars Technica review",
      "neutral_headline": "ROG Xbox Ally X: The Ars Technica Review",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/10/rog-xbox-ally-x-the-ars-technica-review/",
          "published_at": "Wed, 15 Oct 2025 13:00:23 +0000",
          "title": "ROG Xbox Ally X: The Ars Technica review",
          "standfirst": "The first portable “Xbox” fails to unify a messy world of competing PC gaming platforms.",
          "content": "Here at Ars, we have been writing about rumors of a portable Xbox for literal decades now. With the ROG Xbox Ally, Microsoft has finally made those rumors a reality in the weirdest, most Microsoft way possible. Yes, the $600 ROG Xbox Ally—and its souped-up cousin, the $1,000, ridiculous-mouthful-of-a-name ROG Xbox Ally X, which we tested—are the first official handheld hardware to sport the Xbox brand name. But Microsoft isn’t taking the exclusive-heavy, walled garden software approach that it has been committed to for nearly 25 years of Xbox home consoles. Instead, the ROG Xbox Ally is, at its base, simply a new version of Asus’ Windows-based ROG Ally line with an Xbox-flavored coat of paint. That coat of paint—what Microsoft is calling the Xbox Full-screen Experience (FSE)—represents the company’s belated attempt to streamline the Windows gaming experience to be a bit more console-like in terms of user interface and overall simplicity. While that’s a worthy vision, the execution in these early days is so spotty and riddled with annoyances that it’s hard to recommend over the SteamOS-based competition.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rogpromo-1152x648-1760476814.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/rogpromo-1152x648-1760476814.jpg",
      "popularity_score": 264.7475802777778,
      "ai_summary": [
        "The Ars Technica review covers the ROG Xbox Ally X.",
        "The portable \"Xbox\" fails to unify competing PC gaming platforms.",
        "The review assesses the device's performance and features.",
        "The device aims to provide a portable gaming experience.",
        "The review highlights the challenges of the gaming platform."
      ]
    },
    {
      "id": "cluster_117",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 18:24:53 +0000",
      "title": "Google will let Gemini schedule meetings for you in Gmail",
      "neutral_headline": "Google Will Let Gemini Schedule Meetings for You",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/10/gemini-can-now-help-schedule-meetings-in-gmail/",
          "published_at": "Tue, 14 Oct 2025 18:24:53 +0000",
          "title": "Google will let Gemini schedule meetings for you in Gmail",
          "standfirst": "Help Me Schedule creates a meeting widget based on the context of your message.",
          "content": "Meetings can be a real drain on productivity, but a new Gmail feature might at least cut down on the time you spend scheduling them. The company has announced \"Help Me Schedule\" is coming to Gmail, leveraging Gemini AI to recognize when you want to schedule a meeting and offering possible meeting times for the email recipient to choose. The new meeting feature is reminiscent of Magic Cue on Google's latest Pixel phones. As you type emails, Gmail will be able to recognize when you are planning a meeting. A Help Me Schedule button will appear in the toolbar. Upon clicking, Google's AI will swing into action and find possible meeting times that match the context of your message and are available in your calendar. When you engage with Help me schedule, the AI generates an in-line meeting widget for your message. The recipient can select the time that works for them, and that's it—the meeting is scheduled for both parties. What about meetings with more than one invitee? Google says the feature won't support groups at launch.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg",
      "popularity_score": 160,
      "ai_summary": [
        "Google will let Gemini schedule meetings for you in Gmail.",
        "Help Me Schedule creates a meeting widget based on message context.",
        "The feature aims to simplify the process of scheduling meetings.",
        "The tool analyzes the content of your messages to assist.",
        "The new feature will be integrated into the Gmail platform."
      ]
    },
    {
      "id": "cluster_122",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 17:00:40 +0000",
      "title": "OpenAI unveils “wellness” council; suicide prevention expert not included",
      "neutral_headline": "OpenAI Unveils “Wellness” Council",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/openai-unveils-wellness-council-suicide-prevention-expert-not-included/",
          "published_at": "Tue, 14 Oct 2025 17:00:40 +0000",
          "title": "OpenAI unveils “wellness” council; suicide prevention expert not included",
          "standfirst": "OpenAI reveals which experts are steering ChatGPT mental health upgrades.",
          "content": "Ever since a lawsuit accused ChatGPT of becoming a teen's \"suicide coach,\" OpenAI has been scrambling to make its chatbot safer. Today, the AI firm unveiled the experts it hired to help make ChatGPT a healthier option for all users. In a press release, OpenAI explained its Expert Council on Wellness and AI started taking form after OpenAI began informally consulting with experts on parental controls earlier this year. Now it's been formalized, bringing together eight \"leading researchers and experts with decades of experience studying how technology affects our emotions, motivation, and mental health\" to help steer ChatGPT updates. One priority was finding \"several council members with backgrounds in understanding how to build technology that supports healthy youth development,\" OpenAI said, \"because teens use ChatGPT differently than adults.\"Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2207496721-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2207496721-1152x648.jpg",
      "popularity_score": 154,
      "ai_summary": [
        "OpenAI unveils a \"wellness\" council to guide mental health upgrades.",
        "A suicide prevention expert is not included in the council.",
        "The council will advise on ChatGPT's mental health features.",
        "The announcement reveals the experts involved in the project.",
        "The council's composition raises questions about its scope."
      ]
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 19:58:38 +0000",
      "title": "DirecTV screensavers will show AI-generated ads with your face in 2026",
      "neutral_headline": "DirecTV Plans AI-Generated Ads Featuring Viewer Faces",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/directv-screensavers-will-show-ai-generated-ads-with-your-face-in-2026/",
          "published_at": "Tue, 14 Oct 2025 19:58:38 +0000",
          "title": "DirecTV screensavers will show AI-generated ads with your face in 2026",
          "standfirst": "Like other companies with streaming businesses, DirecTV is leaning into ads more.",
          "content": "As if DirecTV doesn't have enough trouble keeping customers, the satellite TV provider's streaming devices will show AI-generated screensaver ads next year, according to an announcement today from partnering ads company Glance. People who use either of DirecTV’s two Gemini streaming devices will start seeing the ads “in early 2026,” per the announcement. DirecTV’s Gemini Air is an Android TV-powered USB device that people can plug into a TV for access to live TV channels, as well as streaming apps. Gemini Air doesn’t require a DirecTV satellite connection, and DirecTV gives all of its Internet customers the device. DirecTV first started selling Gemini devices in 2023, when it launched a separate Gemini set-top box that connects through DirecTV satellite setups. DirecTV made an agreement with Glance to show AI-generated content and ads on Gemini devices' screensavers. Currently, Gemini devices show Google wallpapers as screensavers, which are on by default. When the new screensavers launch, Glance's AI content will show if the TV is idle for 10 minutes, The Verge reported.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GEMINI-AIR_0-1152x648-1760468257.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GEMINI-AIR_0-1152x648-1760468257.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "DirecTV will use AI to generate personalized ads for its screensavers starting in 2026.",
        "These ads will incorporate viewers' faces, potentially creating a more engaging experience.",
        "The move reflects a broader trend of streaming services exploring new advertising strategies.",
        "The company aims to increase revenue through these AI-driven, personalized advertisements.",
        "This initiative is similar to other companies with streaming businesses that are leaning into ads."
      ]
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 16:58:21 +0000",
      "title": "Nvidia sells tiny new computer that puts big AI on your desktop",
      "neutral_headline": "Nvidia Releases Small Computer for AI on Desktops",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/nvidia-sells-tiny-new-computer-that-puts-big-ai-on-your-desktop/",
          "published_at": "Tue, 14 Oct 2025 16:58:21 +0000",
          "title": "Nvidia sells tiny new computer that puts big AI on your desktop",
          "standfirst": "The 1 petaflop DGX Spark system runs AI models with 200 billion parameters locally for $4K.",
          "content": "On Tuesday, Nvidia announced it will begin taking orders for the DGX Spark, a $4,000 desktop AI computer that wraps one petaflop of computing performance and 128GB of unified memory into a form factor small enough to sit on a desk. Its biggest selling point is likely its large integrated memory that can run larger AI models than consumer GPUs. Nvidia will begin taking orders for the DGX Spark on Wednesday, October 15, through its website, with systems also available from manufacturing partners and select US retail stores. The DGX Spark, which Nvidia previewed as \"Project DIGITS\" in January and formally named in May, represents Nvidia's attempt to create a new category of desktop computer workstation specifically for AI development.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/dgx_spark-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/dgx_spark-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Nvidia has launched a compact computer called DGX Spark for local AI model use.",
        "The system can run AI models with up to 200 billion parameters.",
        "It offers a performance of 1 petaflop, suitable for complex AI tasks.",
        "The DGX Spark is priced at approximately $4,000, making it accessible.",
        "This allows users to run AI applications directly on their desktops."
      ]
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 13:51:00 +0000",
      "title": "OpenAI wants to stop ChatGPT from validating users’ political views",
      "neutral_headline": "OpenAI Seeks to Prevent ChatGPT from Validating Political Views",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/openai-wants-to-stop-chatgpt-from-validating-users-political-views/",
          "published_at": "Tue, 14 Oct 2025 13:51:00 +0000",
          "title": "OpenAI wants to stop ChatGPT from validating users’ political views",
          "standfirst": "New paper reveals reducing \"bias\" means making ChatGPT stop mirroring users' political language.",
          "content": "\"ChatGPT shouldn't have political bias in any direction.\" That's OpenAI's stated goal in a new research paper released Thursday about measuring and reducing political bias in its AI models. The company says that \"people use ChatGPT as a tool to learn and explore ideas\" and argues \"that only works if they trust ChatGPT to be objective.\" But a closer reading of OpenAI's paper reveals something different from what the company's framing of objectivity suggests. The company never actually defines what it means by \"bias.\" And its evaluation axes show that it's focused on stopping ChatGPT from several behaviors: acting like it has personal political opinions, amplifying users' emotional political language, and providing one-sided coverage of contested topics.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/political_fracture_1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/political_fracture_1-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "OpenAI is working to reduce bias in ChatGPT's responses.",
        "The goal is to stop the chatbot from mirroring users' political language.",
        "The company's research focuses on mitigating the influence of user input.",
        "This aims to create a more neutral and objective AI experience.",
        "The project seeks to avoid reinforcing users' existing political beliefs."
      ]
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 15:16:15 +0000",
      "title": "GM’s EV push will cost it $1.6 billion in Q3 with end of the tax credit",
      "neutral_headline": "GM Faces $1.6 Billion Loss Due to EV Tax Credit Changes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/gms-ev-push-will-cost-it-1-6-billion-in-q3-with-end-of-the-tax-credit/",
          "published_at": "Tue, 14 Oct 2025 15:16:15 +0000",
          "title": "GM’s EV push will cost it $1.6 billion in Q3 with end of the tax credit",
          "standfirst": "With EV demand predicted to plummet, GM has rejiggered its production plans.",
          "content": "The prospects of continued electric vehicle adoption in the US are in an odd place. As promised, the Trump administration and its congressional Republican allies killed off as many of the clean energy and EV incentives as they could after taking power in January. Ironically, though, the end of the clean vehicle tax credit on September 30 actually spurred the sales of EVs, as customers rushed to dealerships to take advantage of the soon-to-disappear $7,500 credit. Predictions for EV sales going forward aren't so rosy, and automakers are reacting by adjusting their product portfolio plans. Today, General Motors revealed that will result in a $1.6 billion hit to its balance sheet when it reports its Q3 results late this month, according to its 8-K. Q3 was a decent one for GM, with sales up 8 percent year on year and up 10 percent for the year to date. GM EV sales look even better: up 104 percent for the year to date compared to the first nine months of 2024, with nearly 145,000 electric Cadillacs, Chevrolets, and GMCs finding homes.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2165725341-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2165725341-1152x648.jpg",
      "popularity_score": 139,
      "ai_summary": [
        "General Motors will incur a $1.6 billion loss in Q3 due to EV tax credit changes.",
        "The company is adjusting its production plans in response to the changes.",
        "Demand for electric vehicles is predicted to decrease.",
        "GM is responding to the evolving market dynamics.",
        "The tax credit changes are impacting the company's financial outlook."
      ]
    },
    {
      "id": "cluster_105",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 21:17:49 +0000",
      "title": "NATO boss mocks Russian navy, which is on the hunt for Red October “the nearest mechanic”",
      "neutral_headline": "NATO Head Comments on Russian Navy's Submarine Activity",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/nato-boss-mocks-russian-navy-which-is-on-the-hunt-for-red-october-the-nearest-mechanic/",
          "published_at": "Tue, 14 Oct 2025 21:17:49 +0000",
          "title": "NATO boss mocks Russian navy, which is on the hunt for Red October “the nearest mechanic”",
          "standfirst": "A Russian sub surfaces off of Western Europe. Is it damaged?",
          "content": "When one of its Kilo-class diesel-electric submarines recently surfaced off the coast of France, Russia denied that there was a problem with the vessel. The sub was simply surfacing to comply with maritime transit rules governing the English Channel, the Kremlin said—Russia being, of course, a noted follower of international law. But social media accounts historically linked to Russian security forces suggested a far more serious problem on the submarine Novorossiysk. According to The Maritime Executive, \"Rumors began to circulate on well-informed social media channels that the Novorossiysk had suffered a fuel leak. They suggested the vessel lacked onboard capabilities and was forced to surface to empty flooded compartments. Some reports said it was a dangerous fuel leak aboard the vessel, which was commissioned in 2012.\" France 24 quoted further social media reports as saying, \"The submarine has neither the spare parts nor the qualified specialists onboard to fix the malfunction,\" and it \"now poses an explosion hazard.\"Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/french-ships-shadows-russian-sub-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/french-ships-shadows-russian-sub-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "A Russian submarine surfaced near Western Europe, prompting questions.",
        "The NATO boss made a mocking comment about the Russian navy.",
        "The incident raises concerns about the submarine's condition.",
        "The focus is on whether the submarine is damaged or experiencing issues.",
        "The situation highlights ongoing tensions in the region."
      ]
    },
    {
      "id": "cluster_106",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 21:01:50 +0000",
      "title": "Feds seize $15 billion from alleged forced labor scam built on “human suffering”",
      "neutral_headline": "Feds Seize $15 Billion in Forced Labor Scam",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/feds-seize-15-billion-from-alleged-forced-labor-scam-built-on-human-suffering/",
          "published_at": "Tue, 14 Oct 2025 21:01:50 +0000",
          "title": "Feds seize $15 billion from alleged forced labor scam built on “human suffering”",
          "standfirst": "Scams like this one net billions from well-educated victims.",
          "content": "Federal prosecutors have seized $15 billion from the alleged kingpin of an operation that used imprisoned laborers to trick unsuspecting people into making investments in phony funds, often after spending months faking romantic relationships with the victims. Such \"pig butchering\" scams have operated for years. They typically work when members of the operation initiate conversations with people on social media and then spend months messaging them. Often, the scammers pose as attractive individuals who feign romantic interest for the victim. Forced labor, phone farms, and human suffering Eventually, conversations turn to phony investment funds with the end goal of convincing the victim to transfer large amounts of bitcoin. In many cases, the scammers are trafficked and held against their will in compounds surrounded by fences and barbed wire.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bitcoin-romance-pig-butchering-scam-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bitcoin-romance-pig-butchering-scam-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Federal authorities seized $15 billion from an alleged forced labor scam.",
        "The scam targeted well-educated victims, netting billions of dollars.",
        "The investigation revealed the scale of the fraudulent operation.",
        "The authorities are working to recover the stolen funds.",
        "The case highlights the prevalence of sophisticated financial crimes."
      ]
    },
    {
      "id": "cluster_107",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 20:44:02 +0000",
      "title": "Trump admin pressured Facebook into removing ICE-tracking group",
      "neutral_headline": "Trump Administration Pressured Facebook to Remove ICE Group",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/trump-admin-pressured-facebook-into-removing-ice-tracking-group/",
          "published_at": "Tue, 14 Oct 2025 20:44:02 +0000",
          "title": "Trump admin pressured Facebook into removing ICE-tracking group",
          "standfirst": "Pam Bondi claims Facebook group was used to “dox and target” ICE agents.",
          "content": "Attorney General Pam Bondi today said that Facebook removed an ICE-tracking group after \"outreach\" from the Department of Justice. \"Today following outreach from @thejusticedept, Facebook removed a large group page that was being used to dox and target @ICEgov agents in Chicago,\" Bondi wrote in an X post. Bondi alleged that a \"wave of violence against ICE has been driven by online apps and social media campaigns designed to put ICE officers at risk just for doing their jobs.\" She added that the DOJ \"will continue engaging tech companies to eliminate platforms where radicals can incite imminent violence against federal law enforcement.\" When contacted by Ars, Facebook owner Meta said the group \"was removed for violating our policies against coordinated harm.\" Meta didn't describe any specific violation but directed us to a policy against \"coordinating harm and promoting crime,\" which includes a prohibition against \"outing the undercover status of law enforcement, military, or security personnel.\"Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/zuckerberg-trump-1152x648-1760473002.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/zuckerberg-trump-1152x648-1760473002.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "The Trump administration pressured Facebook to remove an ICE-tracking group.",
        "Pam Bondi claimed the group was used to target ICE agents.",
        "The group allegedly facilitated doxing and harassment of ICE personnel.",
        "The action reflects the political tensions surrounding immigration enforcement.",
        "The situation highlights the role of social media in political discourse."
      ]
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Tue, 14 Oct 2025 14:58:23 +0000",
      "title": "Windows 10 support “ends” today, but it’s just the first of many deaths",
      "neutral_headline": "Windows 10 Support Ends, But Security Updates Continue",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/windows-10-support-ends-today-but-its-just-the-first-of-many-deaths/",
          "published_at": "Tue, 14 Oct 2025 14:58:23 +0000",
          "title": "Windows 10 support “ends” today, but it’s just the first of many deaths",
          "standfirst": "End users can get an extra year of security updates relatively easily.",
          "content": "Today is the official end-of-support date for Microsoft's Windows 10. That doesn't mean these PCs will suddenly stop working, but if you don't take action, it does mean your PC has received its last regular security patches and that Microsoft is washing its hands of technical support. This end-of-support date comes about a decade after the initial release of Windows 10, which is typical for most Windows versions. But it comes just four years after Windows 10 was replaced by Windows 11, a version with stricter system requirements that left many older-but-still-functional PCs with no officially supported upgrade path. As a result, Windows 10 still runs on roughly 40 percent of the world's Windows PCs (or around a third of US-based PCs), according to StatCounter data. But this end-of-support date also isn't set in stone. Home users with Windows 10 PCs can enroll in Microsoft's Extended Security Updates (ESU) program, which extends the support timeline by another year. We've published directions for how to do this here—while you do need one of the Microsoft accounts that the company is always pushing, it's relatively trivial to enroll in the ESU program for free.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/10/win10-wallpaper-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/10/win10-wallpaper-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Windows 10 support officially ended, but security updates are still available.",
        "Users can get an extra year of security updates relatively easily.",
        "This provides a transition period for users to upgrade.",
        "The extended support offers continued protection against threats.",
        "The move allows users to maintain system security."
      ]
    }
  ]
}