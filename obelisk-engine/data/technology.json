{
  "updated_at": "2026-01-26T04:15:55.186Z",
  "clusters": [
    {
      "id": "cluster_66",
      "coverage": 3,
      "updated_at": "Sat, 24 Jan 2026 20:50:00 -0500",
      "title": "Tests show GPT-5.2 on ChatGPT is citing Grokipedia as a source on some obscure topics, including Iranian political structures (Aisha Down/The Guardian)",
      "neutral_headline": "Report reveals that OpenAI's GPT-5.2 model cites Grokipedia",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260124/p15#a260124p15",
          "published_at": "Sat, 24 Jan 2026 20:50:00 -0500",
          "title": "Tests show GPT-5.2 on ChatGPT is citing Grokipedia as a source on some obscure topics, including Iranian political structures (Aisha Down/The Guardian)",
          "standfirst": "Aisha Down / The Guardian: Tests show GPT-5.2 on ChatGPT is citing Grokipedia as a source on some obscure topics, including Iranian political structures &mdash; Guardian found OpenAI's platform cited Grokipedia on topics including Iran and Holocaust deniers &mdash; The latest model of ChatGPT has begun to cite Elon Musk's Grokipedia &hellip;",
          "content": "Aisha Down / The Guardian: Tests show GPT-5.2 on ChatGPT is citing Grokipedia as a source on some obscure topics, including Iranian political structures &mdash; Guardian found OpenAI's platform cited Grokipedia on topics including Iran and Holocaust deniers &mdash; The latest model of ChatGPT has begun to cite Elon Musk's Grokipedia &hellip;",
          "feed_position": 12,
          "image_url": "http://www.techmeme.com/260124/i15.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/report-reveals-that-openais-gpt-52-model-cites-grokipedia-192532977.html",
          "published_at": "Sat, 24 Jan 2026 19:25:32 +0000",
          "title": "Report reveals that OpenAI's GPT-5.2 model cites Grokipedia",
          "standfirst": "OpenAI may have called GPT-5.2 its \"most advanced frontier model for professional work,\" but tests conducted by the Guardian cast doubt on its credibility. According to the report, OpenAI's GPT-5.2 model cited Grokipedia, the online encyclopedia powered by xAI, when it came to specific, but controversial topics related to Iran or the Holocaust. As seen in the Guardian's report, ChatGPT used Grokipedia as a source for claims about the Iranian government being tied to telecommunications company MTN-Irancell and questions related to Richard Evans, a British historian who served as an expert witness during a libel trial for Holocaust denier David Irving. However, the Guardian noted ChatGPT didn't use Grokipedia when it came to a prompt asking about media bias against Donald Trump and other controversial topics. OpenAI released the GPT-5.2 model in December to better perform at professional use, like creating spreadsheets or handling complex tasks. Grokipedia preceded GPT-5.2's release, but ran into some controversy when it was seen including citations to neo-Nazi forums. A study done by US researchers also showed that the AI-generated encyclopedia cited \"questionable\" and \"problematic\" sources. In response to the Guardian report, OpenAI told the outlet that its GPT-5.2 model searches the web for a \"broad range of publicly available sources and viewpoints,\" but applies \"safety filters to reduce the risk of surfacing links associated with high-severity harms.\"This article originally appeared on Engadget at https://www.engadget.com/ai/report-reveals-that-openais-gpt-52-model-cites-grokipedia-192532977.html?src=rss",
          "content": "OpenAI may have called GPT-5.2 its \"most advanced frontier model for professional work,\" but tests conducted by the Guardian cast doubt on its credibility. According to the report, OpenAI's GPT-5.2 model cited Grokipedia, the online encyclopedia powered by xAI, when it came to specific, but controversial topics related to Iran or the Holocaust. As seen in the Guardian's report, ChatGPT used Grokipedia as a source for claims about the Iranian government being tied to telecommunications company MTN-Irancell and questions related to Richard Evans, a British historian who served as an expert witness during a libel trial for Holocaust denier David Irving. However, the Guardian noted ChatGPT didn't use Grokipedia when it came to a prompt asking about media bias against Donald Trump and other controversial topics. OpenAI released the GPT-5.2 model in December to better perform at professional use, like creating spreadsheets or handling complex tasks. Grokipedia preceded GPT-5.2's release, but ran into some controversy when it was seen including citations to neo-Nazi forums. A study done by US researchers also showed that the AI-generated encyclopedia cited \"questionable\" and \"problematic\" sources. In response to the Guardian report, OpenAI told the outlet that its GPT-5.2 model searches the web for a \"broad range of publicly available sources and viewpoints,\" but applies \"safety filters to reduce the risk of surfacing links associated with high-severity harms.\"This article originally appeared on Engadget at https://www.engadget.com/ai/report-reveals-that-openais-gpt-52-model-cites-grokipedia-192532977.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/jan/24/latest-chatgpt-model-uses-elon-musks-grokipedia-as-source-tests-reveal",
          "published_at": "Sat, 24 Jan 2026 14:00:41 GMT",
          "title": "Latest ChatGPT model uses Elon Musk’s Grokipedia as source, tests reveal",
          "standfirst": "Guardian found OpenAI’s platform cited Grokipedia on topics including Iran and Holocaust deniersThe latest model of ChatGPT has begun to cite Elon Musk’s Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers, raising concerns about misinformation on the platform.In tests done by the Guardian, GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions. These included queries on political structures in Iran, such as salaries of the Basij paramilitary force and the ownership of the Mostazafan Foundation, and questions on the biography of Sir Richard Evans, a British historian and expert witness against Holocaust denier David Irving in his libel trial. Continue reading...",
          "content": "Guardian found OpenAI’s platform cited Grokipedia on topics including Iran and Holocaust deniersThe latest model of ChatGPT has begun to cite Elon Musk’s Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers, raising concerns about misinformation on the platform.In tests done by the Guardian, GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions. These included queries on political structures in Iran, such as salaries of the Basij paramilitary force and the ownership of the Mostazafan Foundation, and questions on the biography of Sir Richard Evans, a British historian and expert witness against Holocaust denier David Irving in his libel trial. Continue reading...",
          "feed_position": 2
        }
      ],
      "featured_image": "http://www.techmeme.com/260124/i15.jpg",
      "popularity_score": 3000
    },
    {
      "id": "cluster_20",
      "coverage": 2,
      "updated_at": "Sun, 25 Jan 2026 21:00:00 GMT",
      "title": "The era of agentic AI demands a data constitution, not better prompts",
      "neutral_headline": "The era of agentic AI demands a data constitution, not better prompts",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/the-era-of-agentic-ai-demands-a-data-constitution-not-better-prompts",
          "published_at": "Sun, 25 Jan 2026 21:00:00 GMT",
          "title": "The era of agentic AI demands a data constitution, not better prompts",
          "standfirst": "The industry consensus is that 2026 will be the year of \"agentic AI.\" We are rapidly moving past chatbots that simply summarize text. We are entering the era of autonomous agents that execute tasks. We expect them to book flights, diagnose system outages, manage cloud infrastructure and personalize media streams in real-time.As a technology executive overseeing platforms that serve 30 million concurrent users during massive global events like the Olympics and the Super Bowl, I have seen the unsexy reality behind the hype: Agents are incredibly fragile.Executives and VCs obsess over model benchmarks. They debate Llama 3 versus GPT-4. They focus on maximizing context window sizes. Yet they are ignoring the actual failure point. The primary reason autonomous agents fail in production is often due to data hygiene issues.In the previous era of \"human-in-the-loop\" analytics, data quality was a manageable nuisance. If an ETL pipeline experiences an issue, a dashboard may display an incorrect revenue number. A human analyst would spot the anomaly, flag it and fix it. The blast radius was contained.In the new world of autonomous agents, that safety net is gone.If a data pipeline drifts today, an agent doesn&#x27;t just report the wrong number. It takes the wrong action. It provisions the wrong server type. It recommends a horror movie to a user watching cartoons. It hallucinates a customer service answer based on corrupted vector embeddings.To run AI at the scale of the NFL or the Olympics, I realized that standard data cleaning is insufficient. We cannot just \"monitor\" data. We must legislate it.A solution to this specific problem could be in the form of a ‘data quality – creed’ framework. It functions as a &#x27;data constitution.&#x27; It enforces thousands of automated rules before a single byte of data is allowed to touch an AI model. While I applied this specifically to the streaming architecture at NBCUniversal, the methodology is universal for any enterprise looking to operationalize AI agents.Here is why \"defensive data engineering\" and the Creed philosophy are the only ways to survive the Agentic era.The vector database trapThe core problem with AI Agents is that they trust the context you give them implicitly. If you are using RAG, your vector database is the agent’s long-term memory.Standard data quality issues are catastrophic for vector databases. In traditional SQL databases, a null value is just a null value. In a vector database, a null value or a schema mismatch can warp the semantic meaning of the entire embedding.Consider a scenario where metadata drifts. Suppose your pipeline ingests video metadata, but a race condition causes the \"genre\" tag to slip. Your metadata might tag a video as \"live sports,\" but the embedding was generated from a \"news clip.\" When an agent queries the database for \"touchdown highlights,\" it retrieves the news clip because the vector similarity search is operating on a corrupted signal. The agent then serves that clip to millions of users.At scale, you cannot rely on downstream monitoring to catch this. By the time an anomaly alarm goes off, the agent has already made thousands of bad decisions. Quality controls must shift to the absolute \"left\" of the pipeline.The \"Creed\" framework: 3 principles for survivalThe Creed framework is expected to act as a gatekeeper. It is a multi-tenant quality architecture that sits between ingestion sources and AI models.For technology leaders looking to build their own \"constitution,\" here are the three non-negotiable principles I recommend.1. The \"quarantine\" pattern is mandatory: In many modern data organizations, engineers favor the \"ELT\" approach. They dump raw data into a lake and clean it up later. For AI Agents, this is unacceptable. You cannot let an agent drink from a polluted lake.The Creed methodology enforces a strict \"dead letter queue.\" If a data packet violates a contract, it is immediately quarantined. It never reaches the vector database. It is far better for an agent to say \"I don&#x27;t know\" due to missing data than to confidently lie due to bad data. This \"circuit breaker\" pattern is essential for preventing high-profile hallucinations.2. Schema is law: For years, the industry moved toward \"schemaless\" flexibility to move fast. We must reverse that trend for core AI pipelines. We must enforce strict typing and referential integrity.In my experience, a robust system requires scale. The implementation I oversee currently enforces more than 1,000 active rules running across real-time streams. These aren&#x27;t just checking for nulls. They check for business logic consistency.Example: Does the \"user_segment\" in the event stream match the active taxonomy in the feature store? If not, block it.Example: Is the timestamp within the acceptable latency window for real-time inference? If not, drop it.3. Vector consistency checks This is the new frontier for SREs. We must implement automated checks to ensure that the text chunks stored in a vector database actually match the embedding vectors associated with them. \"Silent\" failures in an embedding model API often leave you with vectors that point to nothing. This causes agents to retrieve pure noise.The culture war: Engineers vs. governanceImplementing a framework like Creed is not just a technical challenge. It is a cultural one.Engineers generally hate guardrails. They view strict schemas and data contracts as bureaucratic hurdles that slow down deployment velocity. When introducing a data constitution, leaders often face pushback. Teams feel they are returning to the \"waterfall\" era of rigid database administration.To succeed, you must flip the incentive structure. We demonstrated that Creed was actually an accelerator. By guaranteeing the purity of the input data, we eliminated the weeks data scientists used to spend debugging model hallucinations. We turned data governance from a compliance task into a \"quality of service\" guarantee.The lesson for data decision makersIf you are building an AI strategy for 2026, stop buying more GPUs. Stop worrying about which foundation model is slightly higher on the leaderboard this week.Start auditing your data contracts.An AI Agent is only as autonomous as its data is reliable. Without a strict, automated data constitution like the Creed framework, your agents will eventually go rogue. In an SRE’s world, a rogue agent is far worse than a broken dashboard. It is a silent killer of trust, revenue, and customer experience.Manoj Yerrasani is a senior technology executive.",
          "content": "The industry consensus is that 2026 will be the year of \"agentic AI.\" We are rapidly moving past chatbots that simply summarize text. We are entering the era of autonomous agents that execute tasks. We expect them to book flights, diagnose system outages, manage cloud infrastructure and personalize media streams in real-time.As a technology executive overseeing platforms that serve 30 million concurrent users during massive global events like the Olympics and the Super Bowl, I have seen the unsexy reality behind the hype: Agents are incredibly fragile.Executives and VCs obsess over model benchmarks. They debate Llama 3 versus GPT-4. They focus on maximizing context window sizes. Yet they are ignoring the actual failure point. The primary reason autonomous agents fail in production is often due to data hygiene issues.In the previous era of \"human-in-the-loop\" analytics, data quality was a manageable nuisance. If an ETL pipeline experiences an issue, a dashboard may display an incorrect revenue number. A human analyst would spot the anomaly, flag it and fix it. The blast radius was contained.In the new world of autonomous agents, that safety net is gone.If a data pipeline drifts today, an agent doesn&#x27;t just report the wrong number. It takes the wrong action. It provisions the wrong server type. It recommends a horror movie to a user watching cartoons. It hallucinates a customer service answer based on corrupted vector embeddings.To run AI at the scale of the NFL or the Olympics, I realized that standard data cleaning is insufficient. We cannot just \"monitor\" data. We must legislate it.A solution to this specific problem could be in the form of a ‘data quality – creed’ framework. It functions as a &#x27;data constitution.&#x27; It enforces thousands of automated rules before a single byte of data is allowed to touch an AI model. While I applied this specifically to the streaming architecture at NBCUniversal, the methodology is universal for any enterprise looking to operationalize AI agents.Here is why \"defensive data engineering\" and the Creed philosophy are the only ways to survive the Agentic era.The vector database trapThe core problem with AI Agents is that they trust the context you give them implicitly. If you are using RAG, your vector database is the agent’s long-term memory.Standard data quality issues are catastrophic for vector databases. In traditional SQL databases, a null value is just a null value. In a vector database, a null value or a schema mismatch can warp the semantic meaning of the entire embedding.Consider a scenario where metadata drifts. Suppose your pipeline ingests video metadata, but a race condition causes the \"genre\" tag to slip. Your metadata might tag a video as \"live sports,\" but the embedding was generated from a \"news clip.\" When an agent queries the database for \"touchdown highlights,\" it retrieves the news clip because the vector similarity search is operating on a corrupted signal. The agent then serves that clip to millions of users.At scale, you cannot rely on downstream monitoring to catch this. By the time an anomaly alarm goes off, the agent has already made thousands of bad decisions. Quality controls must shift to the absolute \"left\" of the pipeline.The \"Creed\" framework: 3 principles for survivalThe Creed framework is expected to act as a gatekeeper. It is a multi-tenant quality architecture that sits between ingestion sources and AI models.For technology leaders looking to build their own \"constitution,\" here are the three non-negotiable principles I recommend.1. The \"quarantine\" pattern is mandatory: In many modern data organizations, engineers favor the \"ELT\" approach. They dump raw data into a lake and clean it up later. For AI Agents, this is unacceptable. You cannot let an agent drink from a polluted lake.The Creed methodology enforces a strict \"dead letter queue.\" If a data packet violates a contract, it is immediately quarantined. It never reaches the vector database. It is far better for an agent to say \"I don&#x27;t know\" due to missing data than to confidently lie due to bad data. This \"circuit breaker\" pattern is essential for preventing high-profile hallucinations.2. Schema is law: For years, the industry moved toward \"schemaless\" flexibility to move fast. We must reverse that trend for core AI pipelines. We must enforce strict typing and referential integrity.In my experience, a robust system requires scale. The implementation I oversee currently enforces more than 1,000 active rules running across real-time streams. These aren&#x27;t just checking for nulls. They check for business logic consistency.Example: Does the \"user_segment\" in the event stream match the active taxonomy in the feature store? If not, block it.Example: Is the timestamp within the acceptable latency window for real-time inference? If not, drop it.3. Vector consistency checks This is the new frontier for SREs. We must implement automated checks to ensure that the text chunks stored in a vector database actually match the embedding vectors associated with them. \"Silent\" failures in an embedding model API often leave you with vectors that point to nothing. This causes agents to retrieve pure noise.The culture war: Engineers vs. governanceImplementing a framework like Creed is not just a technical challenge. It is a cultural one.Engineers generally hate guardrails. They view strict schemas and data contracts as bureaucratic hurdles that slow down deployment velocity. When introducing a data constitution, leaders often face pushback. Teams feel they are returning to the \"waterfall\" era of rigid database administration.To succeed, you must flip the incentive structure. We demonstrated that Creed was actually an accelerator. By guaranteeing the purity of the input data, we eliminated the weeks data scientists used to spend debugging model hallucinations. We turned data governance from a compliance task into a \"quality of service\" guarantee.The lesson for data decision makersIf you are building an AI strategy for 2026, stop buying more GPUs. Stop worrying about which foundation model is slightly higher on the leaderboard this week.Start auditing your data contracts.An AI Agent is only as autonomous as its data is reliable. Without a strict, automated data constitution like the Creed framework, your agents will eventually go rogue. In an SRE’s world, a rogue agent is far worse than a broken dashboard. It is a silent killer of trust, revenue, and customer experience.Manoj Yerrasani is a senior technology executive.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/51ivtIwaFfeOn1BNlUNuBg/27e59afbbbc17bed9aac28d1c3d6aa98/image2.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/conversational-ai-doesnt-understand-users-intent-first-architecture-does",
          "published_at": "Sun, 25 Jan 2026 18:00:00 GMT",
          "title": "Conversational AI doesn’t understand users — 'Intent First' architecture does",
          "standfirst": "The modern customer has just one need that matters: Getting the thing they want when they want it. The old standard RAG model embed+retrieve+LLM misunderstands intent, overloads context and misses freshness, repeatedly sending customers down the wrong paths. Instead, intent-first architecture uses a lightweight language model to parse the query for intent and context, before delivering to the most relevant content sources (documents, APIs, people).Enterprise AI is a speeding train headed for a cliff. Organizations are deploying LLM-powered search applications at a record pace, while a fundamental architectural issue is setting most up for failure.A recent Coveo study revealed that 72% of enterprise search queries fail to deliver meaningful results on the first attempt, while Gartner also predicts that the majority of conversational AI deployments have been falling short of enterprise expectations.The problem isn’t the underlying models. It’s the architecture around them.After designing and running live AI-driven customer interaction platforms at scale, serving millions of customer and citizen users at some of the world’s largest telecommunications and healthcare organizations, I’ve come to see a pattern. It’s the difference between successful AI-powered interaction deployments and multi-million-dollar failures.It’s a cloud-native architecture pattern that I call Intent-First. And it’s reshaping the way enterprises build AI-powered experiences.The $36 pillion problem Gartner projects the global conversational AI market will balloon to $36 billion by 2032. Enterprises are scrambling to get a slice. The demos are irresistible. Plug your LLM into your knowledge base, and suddenly it can answer customer questions in natural language.Magic. Then production happens. A major telecommunications provider I work with rolled out a RAG system with the expectation of driving down the support call rate. Instead, the rate increased. Callers tried AI-powered search, were provided incorrect answers with a high degree of confidence and called customer support angrier than before.This pattern is repeated over and over. In healthcare, customer-facing AI assistants are providing patients with formulary information that’s outdated by weeks or months. Financial services chatbots are spitting out answers from both retail and institutional product content. Retailers are seeing discontinued products surface in product searches.The issue isn’t a failure of AI technology. It’s a failure of architectureWhy standard RAG architectures fail The standard RAG pattern — embedding the query, retrieving semantically similar content, passing to an LLM —works beautifully in demos and proof of concepts. But it falls apart in production use cases for three systematic reasons:1. The intent gapIntent is not context. But standard RAG architectures don’t account for this.Say a customer types “I want to cancel” What does that mean? Cancel a service? Cancel an order? Cancel an appointment? During our telecommunications deployment, we found that 65% of queries for “cancel” were actually about orders or appointments, not service cancellation. The RAG system had no way of understanding this intent, so it consistently returned service cancellation documents.Intent matters. In healthcare, if a patient is typing “I need to cancel” because they&#x27;re trying to cancel an appointment, a prescription refill or a procedure, routing them to medication content from scheduling is not only frustrating — it&#x27;s also dangerous.2. Context flood Enterprise knowledge and experience is vast, spanning dozens of sources such as product catalogs, billing, support articles, policies, promotions and account data. Standard RAG models treat all of it the same, searching all for every query.When a customer asks “How do I activate my new phone,” they don’t care about billing FAQs, store locations or network status updates. But a standard RAG model retrieves semantically similar content from every source, returning search results that are a half-steps off the mark.3. Freshness blindspot Vector space is timeblind. Semantically, last quarter’s promotion is identical to this quarter’s. But presenting customers with outdated offers shatters trust. We linked a significant percentage of customer complaints to search results that surfaced expired products, offers, or features.The Intent-First architecture pattern The Intent-First architecture pattern is the mirror image of the standard RAG deployment. In the RAG model, you retrieve, then route. In the Intent-First model, you classify before you route or retrieve. Intent-First architectures use a lightweight language model to parse a query for intent and context, before dispatching to the most relevant content sources (documents, APIs, agents).Comparison: Intent-first vs standard RAGCloud-native implementationThe Intent-First pattern is designed for cloud-native deployment, leveraging microservices, containerization and elastic scaling to handle enterprise traffic patterns.Intent classification serviceThe classifier determines user intent before any retrieval occurs:ALGORITHM: Intent ClassificationINPUT: user_query (string)OUTPUT: intent_result (object)1. PREPROCESS query (normalize, expand contractions)2. CLASSIFY using transformer model: - primary_intent ← model.predict(query) - confidence ← model.confidence_score()3. IF confidence < 0.70 THEN - RETURN { requires_clarification: true, suggested_question: generate_clarifying_question(query) }4. EXTRACT sub_intent based on primary_intent: - IF primary = \"ACCOUNT\" → check for ORDER_STATUS, PROFILE, etc. - IF primary = \"SUPPORT\" → check for DEVICE_ISSUE, NETWORK, etc. - IF primary = \"BILLING\" → check for PAYMENT, DISPUTE, etc.5. DETERMINE target_sources based on intent mapping: - ORDER_STATUS → [orders_db, order_faq] - DEVICE_ISSUE → [troubleshooting_kb, device_guides] - MEDICATION → [formulary, clinical_docs] (healthcare)6. RETURN { primary_intent, sub_intent, confidence, target_sources, requires_personalization: true/false }Context-aware retrieval serviceOnce intent is classified, retrieval becomes targeted:ALGORITHM: Context-Aware RetrievalINPUT: query, intent_result, user_contextOUTPUT: ranked_documents1. GET source_config for intent_result.sub_intent: - primary_sources ← sources to search - excluded_sources ← sources to skip - freshness_days ← max content age2. IF intent requires personalization AND user is authenticated: - FETCH account_context from Account Service - IF intent = ORDER_STATUS: - FETCH recent_orders (last 60 days) - ADD to results3. BUILD search filters: - content_types ← primary_sources only - max_age ← freshness_days - user_context ← account_context (if available)4. FOR EACH source IN primary_sources: - documents ← vector_search(query, source, filters) - ADD documents to results5. SCORE each document: - relevance_score ← vector_similarity × 0.40 - recency_score ← freshness_weight × 0.20 - personalization_score ← user_match × 0.25 - intent_match_score ← type_match × 0.15 - total_score ← SUM of above6. RANK by total_score descending7. RETURN top 10 documentsHealthcare-specific considerationsIn healthcare deployments, the Intent-First pattern includes additional safeguards:Healthcare intent categories:Clinical: Medication questions, symptoms, care instructionsCoverage: Benefits, prior authorization, formularyScheduling: Appointments, provider availabilityBilling: Claims, payments, statementsAccount: Profile, dependents, ID cardsCritical safeguard: Clinical queries always include disclaimers and never replace professional medical advice. The system routes complex clinical questions to human support.Handling edge casesThe edge cases are where systems fail. The Intent-First pattern includes specific handlers:Frustration detection keywords:Anger: \"terrible,\" \"worst,\" \"hate,\" \"ridiculous\"Time: \"hours,\" \"days,\" \"still waiting\"Failure: \"useless,\" \"no help,\" \"doesn&#x27;t work\"Escalation: \"speak to human,\" \"real person,\" \"manager\"When frustration is detected, skip search entirely and route to human support.Cross-industry applicationsThe Intent-First pattern applies wherever enterprises deploy conversational AI over heterogeneous content:IndustryIntent categoriesKey benefitTelecommunicationsSales, Support, Billing, Account, RetentionPrevents \"cancel\" misclassificationHealthcareClinical, Coverage, Scheduling, BillingSeparates clinical from administrativeFinancial servicesRetail, Institutional, Lending, InsurancePrevents context mixingRetailProduct, Orders, Returns, LoyaltyEnsures promotional freshnessResultsAfter implementing Intent-First architecture across telecommunications and healthcare platforms:MetricImpactQuery success rateNearly doubledSupport escalationsReduced by more than halfTime to resolutionReduced approximately 70%User satisfactionImproved roughly 50%Return user rateMore than doubledThe return user rate proved most significant. When search works, users come back. When it fails, they abandon the channel entirely, increasing costs across all other support channels.The strategic imperativeThe conversational AI market will continue to experience hyper growth.But enterprises that build and deploy typical RAG architectures will continue to fail … repeatedly.AI will confidently give wrong answers, users will abandon digital channels out of frustration and support costs will go up instead of down.Intent-First is a fundamental shift in how enterprises need to architect and build AI-powered customer conversations. It’s not about better models or more data. It’s about understanding what a user wants before you try to help them.The sooner an organization realizes this as an architectural imperative, the sooner they will be able to capture the efficiency gains this technology is supposed to enable. Those that don’t will be debugging why their AI investments haven’t been producing expected business outcomes for many years to come.The demo is easy. Production is hard. But the pattern for production success is clear: Intent First.Sreenivasa Reddy Hulebeedu Reddy is a lead software engineer and enterprise architect",
          "content": "The modern customer has just one need that matters: Getting the thing they want when they want it. The old standard RAG model embed+retrieve+LLM misunderstands intent, overloads context and misses freshness, repeatedly sending customers down the wrong paths. Instead, intent-first architecture uses a lightweight language model to parse the query for intent and context, before delivering to the most relevant content sources (documents, APIs, people).Enterprise AI is a speeding train headed for a cliff. Organizations are deploying LLM-powered search applications at a record pace, while a fundamental architectural issue is setting most up for failure.A recent Coveo study revealed that 72% of enterprise search queries fail to deliver meaningful results on the first attempt, while Gartner also predicts that the majority of conversational AI deployments have been falling short of enterprise expectations.The problem isn’t the underlying models. It’s the architecture around them.After designing and running live AI-driven customer interaction platforms at scale, serving millions of customer and citizen users at some of the world’s largest telecommunications and healthcare organizations, I’ve come to see a pattern. It’s the difference between successful AI-powered interaction deployments and multi-million-dollar failures.It’s a cloud-native architecture pattern that I call Intent-First. And it’s reshaping the way enterprises build AI-powered experiences.The $36 pillion problem Gartner projects the global conversational AI market will balloon to $36 billion by 2032. Enterprises are scrambling to get a slice. The demos are irresistible. Plug your LLM into your knowledge base, and suddenly it can answer customer questions in natural language.Magic. Then production happens. A major telecommunications provider I work with rolled out a RAG system with the expectation of driving down the support call rate. Instead, the rate increased. Callers tried AI-powered search, were provided incorrect answers with a high degree of confidence and called customer support angrier than before.This pattern is repeated over and over. In healthcare, customer-facing AI assistants are providing patients with formulary information that’s outdated by weeks or months. Financial services chatbots are spitting out answers from both retail and institutional product content. Retailers are seeing discontinued products surface in product searches.The issue isn’t a failure of AI technology. It’s a failure of architectureWhy standard RAG architectures fail The standard RAG pattern — embedding the query, retrieving semantically similar content, passing to an LLM —works beautifully in demos and proof of concepts. But it falls apart in production use cases for three systematic reasons:1. The intent gapIntent is not context. But standard RAG architectures don’t account for this.Say a customer types “I want to cancel” What does that mean? Cancel a service? Cancel an order? Cancel an appointment? During our telecommunications deployment, we found that 65% of queries for “cancel” were actually about orders or appointments, not service cancellation. The RAG system had no way of understanding this intent, so it consistently returned service cancellation documents.Intent matters. In healthcare, if a patient is typing “I need to cancel” because they&#x27;re trying to cancel an appointment, a prescription refill or a procedure, routing them to medication content from scheduling is not only frustrating — it&#x27;s also dangerous.2. Context flood Enterprise knowledge and experience is vast, spanning dozens of sources such as product catalogs, billing, support articles, policies, promotions and account data. Standard RAG models treat all of it the same, searching all for every query.When a customer asks “How do I activate my new phone,” they don’t care about billing FAQs, store locations or network status updates. But a standard RAG model retrieves semantically similar content from every source, returning search results that are a half-steps off the mark.3. Freshness blindspot Vector space is timeblind. Semantically, last quarter’s promotion is identical to this quarter’s. But presenting customers with outdated offers shatters trust. We linked a significant percentage of customer complaints to search results that surfaced expired products, offers, or features.The Intent-First architecture pattern The Intent-First architecture pattern is the mirror image of the standard RAG deployment. In the RAG model, you retrieve, then route. In the Intent-First model, you classify before you route or retrieve. Intent-First architectures use a lightweight language model to parse a query for intent and context, before dispatching to the most relevant content sources (documents, APIs, agents).Comparison: Intent-first vs standard RAGCloud-native implementationThe Intent-First pattern is designed for cloud-native deployment, leveraging microservices, containerization and elastic scaling to handle enterprise traffic patterns.Intent classification serviceThe classifier determines user intent before any retrieval occurs:ALGORITHM: Intent ClassificationINPUT: user_query (string)OUTPUT: intent_result (object)1. PREPROCESS query (normalize, expand contractions)2. CLASSIFY using transformer model: - primary_intent ← model.predict(query) - confidence ← model.confidence_score()3. IF confidence < 0.70 THEN - RETURN { requires_clarification: true, suggested_question: generate_clarifying_question(query) }4. EXTRACT sub_intent based on primary_intent: - IF primary = \"ACCOUNT\" → check for ORDER_STATUS, PROFILE, etc. - IF primary = \"SUPPORT\" → check for DEVICE_ISSUE, NETWORK, etc. - IF primary = \"BILLING\" → check for PAYMENT, DISPUTE, etc.5. DETERMINE target_sources based on intent mapping: - ORDER_STATUS → [orders_db, order_faq] - DEVICE_ISSUE → [troubleshooting_kb, device_guides] - MEDICATION → [formulary, clinical_docs] (healthcare)6. RETURN { primary_intent, sub_intent, confidence, target_sources, requires_personalization: true/false }Context-aware retrieval serviceOnce intent is classified, retrieval becomes targeted:ALGORITHM: Context-Aware RetrievalINPUT: query, intent_result, user_contextOUTPUT: ranked_documents1. GET source_config for intent_result.sub_intent: - primary_sources ← sources to search - excluded_sources ← sources to skip - freshness_days ← max content age2. IF intent requires personalization AND user is authenticated: - FETCH account_context from Account Service - IF intent = ORDER_STATUS: - FETCH recent_orders (last 60 days) - ADD to results3. BUILD search filters: - content_types ← primary_sources only - max_age ← freshness_days - user_context ← account_context (if available)4. FOR EACH source IN primary_sources: - documents ← vector_search(query, source, filters) - ADD documents to results5. SCORE each document: - relevance_score ← vector_similarity × 0.40 - recency_score ← freshness_weight × 0.20 - personalization_score ← user_match × 0.25 - intent_match_score ← type_match × 0.15 - total_score ← SUM of above6. RANK by total_score descending7. RETURN top 10 documentsHealthcare-specific considerationsIn healthcare deployments, the Intent-First pattern includes additional safeguards:Healthcare intent categories:Clinical: Medication questions, symptoms, care instructionsCoverage: Benefits, prior authorization, formularyScheduling: Appointments, provider availabilityBilling: Claims, payments, statementsAccount: Profile, dependents, ID cardsCritical safeguard: Clinical queries always include disclaimers and never replace professional medical advice. The system routes complex clinical questions to human support.Handling edge casesThe edge cases are where systems fail. The Intent-First pattern includes specific handlers:Frustration detection keywords:Anger: \"terrible,\" \"worst,\" \"hate,\" \"ridiculous\"Time: \"hours,\" \"days,\" \"still waiting\"Failure: \"useless,\" \"no help,\" \"doesn&#x27;t work\"Escalation: \"speak to human,\" \"real person,\" \"manager\"When frustration is detected, skip search entirely and route to human support.Cross-industry applicationsThe Intent-First pattern applies wherever enterprises deploy conversational AI over heterogeneous content:IndustryIntent categoriesKey benefitTelecommunicationsSales, Support, Billing, Account, RetentionPrevents \"cancel\" misclassificationHealthcareClinical, Coverage, Scheduling, BillingSeparates clinical from administrativeFinancial servicesRetail, Institutional, Lending, InsurancePrevents context mixingRetailProduct, Orders, Returns, LoyaltyEnsures promotional freshnessResultsAfter implementing Intent-First architecture across telecommunications and healthcare platforms:MetricImpactQuery success rateNearly doubledSupport escalationsReduced by more than halfTime to resolutionReduced approximately 70%User satisfactionImproved roughly 50%Return user rateMore than doubledThe return user rate proved most significant. When search works, users come back. When it fails, they abandon the channel entirely, increasing costs across all other support channels.The strategic imperativeThe conversational AI market will continue to experience hyper growth.But enterprises that build and deploy typical RAG architectures will continue to fail … repeatedly.AI will confidently give wrong answers, users will abandon digital channels out of frustration and support costs will go up instead of down.Intent-First is a fundamental shift in how enterprises need to architect and build AI-powered customer conversations. It’s not about better models or more data. It’s about understanding what a user wants before you try to help them.The sooner an organization realizes this as an architectural imperative, the sooner they will be able to capture the efficiency gains this technology is supposed to enable. Those that don’t will be debugging why their AI investments haven’t been producing expected business outcomes for many years to come.The demo is easy. Production is hard. But the pattern for production success is clear: Intent First.Sreenivasa Reddy Hulebeedu Reddy is a lead software engineer and enterprise architect",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4RG14xD3FBupJCjwyfXnRQ/189358d225f858df792c92c95ee93bd1/Conversational_AI.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/how-to-use-workout-buddy-with-apple-watch-and-ios-26-130000922.html",
          "published_at": "Sat, 24 Jan 2026 13:00:00 +0000",
          "title": "How to use Workout Buddy with Apple Watch and iOS 26",
          "standfirst": "Apple’s iOS 26 and watchOS 26 introduced a new fitness companion called Workout Buddy. This feature uses Apple Intelligence to provide spoken feedback during workouts and give motivation based on your activity history. Workout Buddy analyzes your pace, heart rate, distance and other metrics to deliver real-time encouragement and performance insights directly through connected Bluetooth headphones. It works in conjunction with the Workout app on Apple Watch and is partially controlled through the Fitness app on iPhone. This guide walks you through everything needed to set up and use Workout Buddy effectively during workouts.What Workout Buddy doesIt’s important to note that Workout Buddy is not a full coaching program. Instead, it adds to your workout with spoken cues that reflect how your session is going. Workout Buddy can remind you of your weekly activity totals, alert you to personal bests or performance milestones and provide an overview when you’re finished. It is designed to feel like a supportive training partner rather than a strict coach.The feature operates in English by default and uses a text-to-speech model trained on voices from Apple Fitness+ trainers. It is available for a subset of workout types, including running, walking, cycling, high-intensity interval training (HIIT) and strength training. It requires on-device Apple Intelligence, which means you’ll need to keep one of the latest iPhones running updated software nearby during workouts. Supported models include iPhone 15 Pro, iPhone 15 Pro Max and any iPhone 16 model. You’ll also need an Apple Watch running watchOS 26. Requirements before you beginBefore Workout Buddy appears in your Fitness app or Workout app you must ensure a few things are in place. First, your Apple Watch must be running watchOS 26 or later and paired to an iPhone with iOS 26 installed. Second, your iPhone must be capable of on-device Apple Intelligence, meaning you must own one of the supported iPhone models we mentioned above and have Apple Intelligence enabled in the phone’s settings.You’ll also need Bluetooth headphones paired with either your iPhone or your Apple Watch. Workout Buddy’s audio feedback cannot play through the watch speaker so headphones are essential. Lastly, your device language must be set to English, at least initially. If any of these things are missing, the option to enable Workout Buddy may not appear.How to turn on Workout Buddy from iPhoneWhile much of the interaction with Workout Buddy happens on Apple Watch during workouts, you can enable it and choose voice options from the Fitness app on iPhone.Open the Fitness app on your iPhone and tap the Workout tab at the bottom. Scroll through the list of workout types until you find one you plan to use with Workout Buddy. Tap the waveform bubble icon associated with that workout. This will bring up settings where you can turn on Workout Buddy. Flip the toggle to enable it and choose a voice from the available options. Once you have selected a voice, close that screen and your choice is saved. When you start this workout type on Apple Watch, Workout Buddy will activate.Enabling Workout Buddy for a workout type on iPhone means you do not need to toggle it on separately on Apple Watch each time for that specific workout. However, you may still adjust it from the watch interface for more granular control.How to turn on Workout Buddy on Apple WatchTo use Workout Buddy during a session, open the Workout app on your Apple Watch. Turn the Digital Crown to scroll through and select the workout you want to do, such as Outdoor Run, Outdoor Walk, Outdoor Cycle, HIIT or Strength Training. If you want to see all available workouts, tap the Add button at the bottom.Once the workout type is selected, look for the Alerts button on screen. Tap Alerts then scroll until you see Workout Buddy. Tap Workout Buddy and flip the switch to on. You will then be asked to choose a voice if one is not already selected on your iPhone. After selecting the voice, return to the previous screen and tap Start. Workout Buddy will begin working as soon as the workout does.Using Workout Buddy during a workoutOnce you start an exercise on your Watch or iPhone, Workout Buddy will speak to you through your connected headphones. The feedback is designed to be encouraging and relevant to your pace, performance or milestones. It may mention your current progress toward activity goals, pace, splits, personal bests or other highlights from your fitness data. At the end of your session Workout Buddy will offer a summary of key metrics like duration distance and calorie burn.While a workout is active, you can temporarily mute the audio if you need silence. On Apple Watch during the session, swipe right to reveal controls then tap Mute. This pauses Workout Buddy’s spoken commentary without disabling the feature entirely.Customizing and managing Workout Buddy settingsWorkout Buddy is enabled on a per-workout-type basis. If you prefer voice feedback for running but silence for strength training, you can enable it for one and leave it off for the other. The Fitness app on iPhone allows you to set a default voice preference for each workout type. On Apple Watch you can quickly toggle the feature on or off before starting a session.If Workout Buddy does not appear as an option for a particular workout type, you may need to check compatibility. Apple’s documentation indicates that only certain types* are supported initially and that the option will not appear for unsupported workouts.*Apple Watch SE (2nd generation), Apple Watch SE 3, Apple Watch Series 6, Apple Watch Series 7, Apple Watch Series 8, Apple Watch Series 9, Apple Watch Series 10, Apple Watch Series 11, Apple Watch Ultra, Apple Watch Ultra 2, Apple Watch Ultra 3Troubleshooting common issuesIf Workout Buddy fails to activate make sure your devices meet the requirements outlined above. Confirm that your iPhone with Apple Intelligence is nearby and that Bluetooth headphones are connected. If audio feedback is missing, ensure headphones are paired correctly and that the language is set to English. Some users have reported that if the headphones are paired only to the Watch rather than the iPhone, it can interfere with feedback. Switching to the iPhone often resolves that issue.For workout types where Workout Buddy previously worked but suddenly does not appear, you may try toggling the feature off and on again in the Fitness app or rebooting both devices. In rare cases removing and re-adding the workout type on Apple Watch can refresh the settings.This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-use-workout-buddy-with-apple-watch-and-ios-26-130000922.html?src=rss",
          "content": "Apple’s iOS 26 and watchOS 26 introduced a new fitness companion called Workout Buddy. This feature uses Apple Intelligence to provide spoken feedback during workouts and give motivation based on your activity history. Workout Buddy analyzes your pace, heart rate, distance and other metrics to deliver real-time encouragement and performance insights directly through connected Bluetooth headphones. It works in conjunction with the Workout app on Apple Watch and is partially controlled through the Fitness app on iPhone. This guide walks you through everything needed to set up and use Workout Buddy effectively during workouts.What Workout Buddy doesIt’s important to note that Workout Buddy is not a full coaching program. Instead, it adds to your workout with spoken cues that reflect how your session is going. Workout Buddy can remind you of your weekly activity totals, alert you to personal bests or performance milestones and provide an overview when you’re finished. It is designed to feel like a supportive training partner rather than a strict coach.The feature operates in English by default and uses a text-to-speech model trained on voices from Apple Fitness+ trainers. It is available for a subset of workout types, including running, walking, cycling, high-intensity interval training (HIIT) and strength training. It requires on-device Apple Intelligence, which means you’ll need to keep one of the latest iPhones running updated software nearby during workouts. Supported models include iPhone 15 Pro, iPhone 15 Pro Max and any iPhone 16 model. You’ll also need an Apple Watch running watchOS 26. Requirements before you beginBefore Workout Buddy appears in your Fitness app or Workout app you must ensure a few things are in place. First, your Apple Watch must be running watchOS 26 or later and paired to an iPhone with iOS 26 installed. Second, your iPhone must be capable of on-device Apple Intelligence, meaning you must own one of the supported iPhone models we mentioned above and have Apple Intelligence enabled in the phone’s settings.You’ll also need Bluetooth headphones paired with either your iPhone or your Apple Watch. Workout Buddy’s audio feedback cannot play through the watch speaker so headphones are essential. Lastly, your device language must be set to English, at least initially. If any of these things are missing, the option to enable Workout Buddy may not appear.How to turn on Workout Buddy from iPhoneWhile much of the interaction with Workout Buddy happens on Apple Watch during workouts, you can enable it and choose voice options from the Fitness app on iPhone.Open the Fitness app on your iPhone and tap the Workout tab at the bottom. Scroll through the list of workout types until you find one you plan to use with Workout Buddy. Tap the waveform bubble icon associated with that workout. This will bring up settings where you can turn on Workout Buddy. Flip the toggle to enable it and choose a voice from the available options. Once you have selected a voice, close that screen and your choice is saved. When you start this workout type on Apple Watch, Workout Buddy will activate.Enabling Workout Buddy for a workout type on iPhone means you do not need to toggle it on separately on Apple Watch each time for that specific workout. However, you may still adjust it from the watch interface for more granular control.How to turn on Workout Buddy on Apple WatchTo use Workout Buddy during a session, open the Workout app on your Apple Watch. Turn the Digital Crown to scroll through and select the workout you want to do, such as Outdoor Run, Outdoor Walk, Outdoor Cycle, HIIT or Strength Training. If you want to see all available workouts, tap the Add button at the bottom.Once the workout type is selected, look for the Alerts button on screen. Tap Alerts then scroll until you see Workout Buddy. Tap Workout Buddy and flip the switch to on. You will then be asked to choose a voice if one is not already selected on your iPhone. After selecting the voice, return to the previous screen and tap Start. Workout Buddy will begin working as soon as the workout does.Using Workout Buddy during a workoutOnce you start an exercise on your Watch or iPhone, Workout Buddy will speak to you through your connected headphones. The feedback is designed to be encouraging and relevant to your pace, performance or milestones. It may mention your current progress toward activity goals, pace, splits, personal bests or other highlights from your fitness data. At the end of your session Workout Buddy will offer a summary of key metrics like duration distance and calorie burn.While a workout is active, you can temporarily mute the audio if you need silence. On Apple Watch during the session, swipe right to reveal controls then tap Mute. This pauses Workout Buddy’s spoken commentary without disabling the feature entirely.Customizing and managing Workout Buddy settingsWorkout Buddy is enabled on a per-workout-type basis. If you prefer voice feedback for running but silence for strength training, you can enable it for one and leave it off for the other. The Fitness app on iPhone allows you to set a default voice preference for each workout type. On Apple Watch you can quickly toggle the feature on or off before starting a session.If Workout Buddy does not appear as an option for a particular workout type, you may need to check compatibility. Apple’s documentation indicates that only certain types* are supported initially and that the option will not appear for unsupported workouts.*Apple Watch SE (2nd generation), Apple Watch SE 3, Apple Watch Series 6, Apple Watch Series 7, Apple Watch Series 8, Apple Watch Series 9, Apple Watch Series 10, Apple Watch Series 11, Apple Watch Ultra, Apple Watch Ultra 2, Apple Watch Ultra 3Troubleshooting common issuesIf Workout Buddy fails to activate make sure your devices meet the requirements outlined above. Confirm that your iPhone with Apple Intelligence is nearby and that Bluetooth headphones are connected. If audio feedback is missing, ensure headphones are paired correctly and that the language is set to English. Some users have reported that if the headphones are paired only to the Watch rather than the iPhone, it can interfere with feedback. Switching to the iPhone often resolves that issue.For workout types where Workout Buddy previously worked but suddenly does not appear, you may try toggling the feature off and on again in the Fitness app or rebooting both devices. In rare cases removing and re-adding the workout type on Apple Watch can refresh the settings.This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-use-workout-buddy-with-apple-watch-and-ios-26-130000922.html?src=rss",
          "feed_position": 10
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/more-cult-of-the-lamb-a-world-war-ii-computer-mystery-and-other-new-indie-games-worth-checking-out-120000807.html",
          "published_at": "Sat, 24 Jan 2026 12:00:00 +0000",
          "title": "More Cult of the Lamb, a World War II computer mystery and other new indie games worth checking out",
          "standfirst": "Welcome to our latest roundup of what's going on in the indie game space. It’s been a very busy week of fun game releases (next week will be too!), so let’s get into some of them after a quick reflection on gaming while traveling.I love my Steam Deck. I really truly do. It’s a fantastic machine. And yet when I brought it with me on a five-week trip over the holidays, I used it for barely an hour the entire time. That doesn’t really justify the space and weight it takes up in my bag. The same holds true for my Nintendo Switch 2 and PlayStation Portal. I’ll be leaving them all at home next time. I’ll take a small controller (probably OhSnap's MCON) so I can play the odd game on my laptop or phone. I’ll bring my Playdate as well. I adore that little yellow console, and I haven’t spent nearly enough time using it. I have a lot of neat-looking indie games to catch up on there (Diora looks particularly interesting). I’m more likely to play something on a flight if it’s on a device I can pull out from my pocket. I just wish Panic had put a backlight in the Playdate. New releasesMassive Monster and publisher Devolver Digital gave Cult of the Lamb fans a whole bunch of reasons to jump back into the game this week with the arrival of the Woolhaven expansion. You'll need to get close to the end of the base game (though you don't need to beat the final boss) before you can experience what the DLC has to offer. It includes weather effects, a new mountain area with a pair of fresh dungeons, a ranching system (which allows you to raise animals as pets or for food) and much more.Folks who dig Cult of the Lamb seem to get really into the game. After a few years of free updates from Massive Monster, Woolhaven is a major expansion that's similar in scope to the base game, so it should keep fans busy for quite a while if they want to try everything. The DLC is out now on PC, Nintendo Switch, PS4, PS5, Xbox Series X/S and Xbox One. It costs $17 if you already have the base game.Inkle, the studio behind Overboard! and the wonderful A Highland Song is back with TR-49, a puzzle game with a World War II computer at its core. Over five decades, an array of books, letters and journals were fed into the machine as part of an effort to \"crack the code of reality.\" But now you're tasked with finding and destroying one specific book before a timer runs out.It all seems rather mysterious. To give you a sense of what's going on here, Inkle says it drew inspiration from narrative deduction games like The Roottrees are Dead, The Return of the Obra Dinn and Her Story, as well as audio dramas. I can't see myself having the time or patience to figure out the enigma of this particular machine (I imagine many players will need a notebook for this one), but I'm intrigued enough to at least watch a Let's Play at some point. You can experience this mystery for yourself on Steam (normally $7, but there's a 10 percent launch discount until January 28).Another week, another Metroidvania, but MIO: Memories in Orbit has a more striking art style than most. This game from Douze Dixièmes and publisher Focus Entertainment debuted to positive reviews this week. After the AI caretakers on a forgotten spaceship stop working, you'll have to help the robot MIO explore the spacecraft \"to revive its lost memories\" and save it from doom. Naturally, you'll discover some new abilities along the way, including a grappling hook and air gliding.MIO: Memories in Orbit is available on PS5, Xbox Series X/S, Nintendo Switch, Switch 2, Steam, the Epic Games Store and the Microsoft Store for $20 (with a 10 percent launch discount on some platforms). You can also check it out via Game Pass Ultimate and PC Game Pass.Perfect Tides: Station to Station is a pixel-art point-and-click narrative adventure and a sequel to Three Bees' Perfect Tides. Over the course of an in-game year, you'll help 18-year-old Mara explore the big city and find her place in the world. The early 2000s vibes of the trailer are immaculate, so I'm going to have to try to play this at some point. Perfect Tides: Station to Station is out now on Steam for PC and Mac for $20.Cozy cafe sim Tailside debuted in early access on Steam (normally $11, but there's a 10 percent discount until January 28) this week. I'm bummed I haven't had a chance to try this one from Coffee Beans Dev yet, because it looks lovely. Along with serving snacks and drinks to your furry customers, you can learn more about the visitors to your cafe by reading stories about them in the newspaper (hopefully nice ones!). You can play at your own pace as you draw latte art and decorate your cafe. Eventually, you'll be able to visit other players' cafes and open a flower shop. Like I said, it looks lovely.Upcoming BALL x PIT’s first FREE major update, The Regal Update, launches on January 26th on all platforms! Adding:🤠2 new characters - The Carouser & The Falconer🏐8 new balls🎯New passives✨Plus a nice surprise you’re going to love! pic.twitter.com/t0tYlwjOXk— BALL x PIT 🏐 OUT NOW (@BALLxPIT) January 19, 2026 One of my favorite games of last year is getting a free update on January 26. Just when I thought I was out of Ball x Pit, Kenny Sun and friends (along with publisher Devolver) are pulling me right back in to check out two new characters, eight fresh balls with their own abilities, more passives and some kind of surprise. I adore Ball x Pit and this update is going to be a drop everything and play immediately deal for me. The Regal Update will be available on all platforms: Steam, PS5, Xbox Series X/S, Nintendo Switch and Switch 2. Ball x Pit costs $15. It's available via Game Pass Ultimate and PC Game Pass too.I'm interested to check out the demo for Vampire Crawlers, a Vampire Survivors spin-off. Poncle will release it on February 23 at Steam Next Fest as well as on Xbox. Your progress will carry over into the full game, which will be on Game Pass on day one.As a rule, turn-based games aren't really my jam, and nor are roguelike deckbuilders. But I'm a big fan of Vampire Survivors, so I'm definitely willing to give this a shot. It helps that Vampire Crawlers seems to be fast-paced and that it draws from the chaotic visuals of the original game. Vampire Crawlers is coming to Steam, Xbox Series X/S, PS5, Nintendo Switch, iOS and Android later this year.Speaking of interesting demos, one for Ratcheteer DX is available now on PC ahead of the full game's release on Switch, Steam (PC and Mac) and the Mac App Store on March 5. It'll normally cost $13, but a limited-time discount will reduce the price to $9.75. If the game's name sounds familiar, that's because this is a color version of the Playdate season one title Ratcheteer. This take on the pixel-art action-adventure has multiple visual filters, a \"CD-quality stereo soundtrack\" and support for more languages. Playdate creator Panic is publishing Ratcheteer DX, whose developers are Shaun Inman, Matthew Grimm and Charlie Davis.Let's wrap things up for this week with a cinematic trailer and release date for Aethus, a story-driven survival-crafting and base-building game from a solo developer at Pawsmonaut Games. It's coming to Steam on March 6.Aethus is a game about \"carving out a future from the ruins of corporate greed\" in a dystopian sci-fi world. As ex-mining engineer Maeve, you start with basic gear and a drone companion by your side. You'll explore what's left of a failed science expedition and abandoned facilities as you try to establish your own mining claim after leaving a company that drains planets of their resources. Of course, you'll upgrade your gear and build out your base as you progress. You can modify settings like the base's air supply, how quickly your hunger and thirst needs change and how much you can carry to fine tune the experience. This article originally appeared on Engadget at https://www.engadget.com/gaming/more-cult-of-the-lamb-a-world-war-ii-computer-mystery-and-other-new-indie-games-worth-checking-out-120000807.html?src=rss",
          "content": "Welcome to our latest roundup of what's going on in the indie game space. It’s been a very busy week of fun game releases (next week will be too!), so let’s get into some of them after a quick reflection on gaming while traveling.I love my Steam Deck. I really truly do. It’s a fantastic machine. And yet when I brought it with me on a five-week trip over the holidays, I used it for barely an hour the entire time. That doesn’t really justify the space and weight it takes up in my bag. The same holds true for my Nintendo Switch 2 and PlayStation Portal. I’ll be leaving them all at home next time. I’ll take a small controller (probably OhSnap's MCON) so I can play the odd game on my laptop or phone. I’ll bring my Playdate as well. I adore that little yellow console, and I haven’t spent nearly enough time using it. I have a lot of neat-looking indie games to catch up on there (Diora looks particularly interesting). I’m more likely to play something on a flight if it’s on a device I can pull out from my pocket. I just wish Panic had put a backlight in the Playdate. New releasesMassive Monster and publisher Devolver Digital gave Cult of the Lamb fans a whole bunch of reasons to jump back into the game this week with the arrival of the Woolhaven expansion. You'll need to get close to the end of the base game (though you don't need to beat the final boss) before you can experience what the DLC has to offer. It includes weather effects, a new mountain area with a pair of fresh dungeons, a ranching system (which allows you to raise animals as pets or for food) and much more.Folks who dig Cult of the Lamb seem to get really into the game. After a few years of free updates from Massive Monster, Woolhaven is a major expansion that's similar in scope to the base game, so it should keep fans busy for quite a while if they want to try everything. The DLC is out now on PC, Nintendo Switch, PS4, PS5, Xbox Series X/S and Xbox One. It costs $17 if you already have the base game.Inkle, the studio behind Overboard! and the wonderful A Highland Song is back with TR-49, a puzzle game with a World War II computer at its core. Over five decades, an array of books, letters and journals were fed into the machine as part of an effort to \"crack the code of reality.\" But now you're tasked with finding and destroying one specific book before a timer runs out.It all seems rather mysterious. To give you a sense of what's going on here, Inkle says it drew inspiration from narrative deduction games like The Roottrees are Dead, The Return of the Obra Dinn and Her Story, as well as audio dramas. I can't see myself having the time or patience to figure out the enigma of this particular machine (I imagine many players will need a notebook for this one), but I'm intrigued enough to at least watch a Let's Play at some point. You can experience this mystery for yourself on Steam (normally $7, but there's a 10 percent launch discount until January 28).Another week, another Metroidvania, but MIO: Memories in Orbit has a more striking art style than most. This game from Douze Dixièmes and publisher Focus Entertainment debuted to positive reviews this week. After the AI caretakers on a forgotten spaceship stop working, you'll have to help the robot MIO explore the spacecraft \"to revive its lost memories\" and save it from doom. Naturally, you'll discover some new abilities along the way, including a grappling hook and air gliding.MIO: Memories in Orbit is available on PS5, Xbox Series X/S, Nintendo Switch, Switch 2, Steam, the Epic Games Store and the Microsoft Store for $20 (with a 10 percent launch discount on some platforms). You can also check it out via Game Pass Ultimate and PC Game Pass.Perfect Tides: Station to Station is a pixel-art point-and-click narrative adventure and a sequel to Three Bees' Perfect Tides. Over the course of an in-game year, you'll help 18-year-old Mara explore the big city and find her place in the world. The early 2000s vibes of the trailer are immaculate, so I'm going to have to try to play this at some point. Perfect Tides: Station to Station is out now on Steam for PC and Mac for $20.Cozy cafe sim Tailside debuted in early access on Steam (normally $11, but there's a 10 percent discount until January 28) this week. I'm bummed I haven't had a chance to try this one from Coffee Beans Dev yet, because it looks lovely. Along with serving snacks and drinks to your furry customers, you can learn more about the visitors to your cafe by reading stories about them in the newspaper (hopefully nice ones!). You can play at your own pace as you draw latte art and decorate your cafe. Eventually, you'll be able to visit other players' cafes and open a flower shop. Like I said, it looks lovely.Upcoming BALL x PIT’s first FREE major update, The Regal Update, launches on January 26th on all platforms! Adding:🤠2 new characters - The Carouser & The Falconer🏐8 new balls🎯New passives✨Plus a nice surprise you’re going to love! pic.twitter.com/t0tYlwjOXk— BALL x PIT 🏐 OUT NOW (@BALLxPIT) January 19, 2026 One of my favorite games of last year is getting a free update on January 26. Just when I thought I was out of Ball x Pit, Kenny Sun and friends (along with publisher Devolver) are pulling me right back in to check out two new characters, eight fresh balls with their own abilities, more passives and some kind of surprise. I adore Ball x Pit and this update is going to be a drop everything and play immediately deal for me. The Regal Update will be available on all platforms: Steam, PS5, Xbox Series X/S, Nintendo Switch and Switch 2. Ball x Pit costs $15. It's available via Game Pass Ultimate and PC Game Pass too.I'm interested to check out the demo for Vampire Crawlers, a Vampire Survivors spin-off. Poncle will release it on February 23 at Steam Next Fest as well as on Xbox. Your progress will carry over into the full game, which will be on Game Pass on day one.As a rule, turn-based games aren't really my jam, and nor are roguelike deckbuilders. But I'm a big fan of Vampire Survivors, so I'm definitely willing to give this a shot. It helps that Vampire Crawlers seems to be fast-paced and that it draws from the chaotic visuals of the original game. Vampire Crawlers is coming to Steam, Xbox Series X/S, PS5, Nintendo Switch, iOS and Android later this year.Speaking of interesting demos, one for Ratcheteer DX is available now on PC ahead of the full game's release on Switch, Steam (PC and Mac) and the Mac App Store on March 5. It'll normally cost $13, but a limited-time discount will reduce the price to $9.75. If the game's name sounds familiar, that's because this is a color version of the Playdate season one title Ratcheteer. This take on the pixel-art action-adventure has multiple visual filters, a \"CD-quality stereo soundtrack\" and support for more languages. Playdate creator Panic is publishing Ratcheteer DX, whose developers are Shaun Inman, Matthew Grimm and Charlie Davis.Let's wrap things up for this week with a cinematic trailer and release date for Aethus, a story-driven survival-crafting and base-building game from a solo developer at Pawsmonaut Games. It's coming to Steam on March 6.Aethus is a game about \"carving out a future from the ruins of corporate greed\" in a dystopian sci-fi world. As ex-mining engineer Maeve, you start with basic gear and a drone companion by your side. You'll explore what's left of a failed science expedition and abandoned facilities as you try to establish your own mining claim after leaving a company that drains planets of their resources. Of course, you'll upgrade your gear and build out your base as you progress. You can modify settings like the base's air supply, how quickly your hunger and thirst needs change and how much you can carry to fine tune the experience. This article originally appeared on Engadget at https://www.engadget.com/gaming/more-cult-of-the-lamb-a-world-war-ii-computer-mystery-and-other-new-indie-games-worth-checking-out-120000807.html?src=rss",
          "feed_position": 12
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/51ivtIwaFfeOn1BNlUNuBg/27e59afbbbc17bed9aac28d1c3d6aa98/image2.png?w=300&q=30",
      "popularity_score": 2012.7346705555556
    },
    {
      "id": "cluster_0",
      "coverage": 1,
      "updated_at": "2026-01-26T04:15:54.495Z",
      "title": "2026 Lucid Air Touring review: This feels like a complete car now",
      "neutral_headline": "2026 Lucid Air Touring review: This feels like a complete car now",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2026/01/2026-lucid-air-touring-review-this-feels-like-a-complete-car-now/",
          "published_at": "2026-01-26T04:15:54.495Z",
          "title": "2026 Lucid Air Touring review: This feels like a complete car now",
          "standfirst": "",
          "content": "",
          "feed_position": 0
        }
      ],
      "popularity_score": 378.99980805555555
    },
    {
      "id": "cluster_49",
      "coverage": 1,
      "updated_at": "Sun, 25 Jan 2026 12:00:25 +0000",
      "title": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
      "neutral_headline": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/a-decade-of-star-trek-themed-fart-jokes-the-greatest-generation-podcast-turns-10/",
          "published_at": "Sun, 25 Jan 2026 12:00:25 +0000",
          "title": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
          "standfirst": "How two podcasters turned a Star Trek side project into a full-time career.",
          "content": "A decade is a long time for a TV series; no single iteration of Star Trek has made it that far. But “a Star Trek podcast by two guys just a little bit embarrassed to have a Star Trek podcast” has now passed the milestone. January 25, 2026, marks a full decade since The Greatest Generation, my favorite podcast, debuted. Like a bottle of Château Picard, the show has only improved with age. (I interviewed the guys behind the show back in 2016 when they were just getting started.) The podcast helped me rediscover, and appreciate more fully, Star Trek: The Next Generation—which is also my favorite TV show. The Greatest Generation continues to delight with its irreverent humor, its celebration of the most minor of characters, and its technical fascination with how a given episode was made.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ADAM_BEN_L1560319-1152x648-1769205900.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ADAM_BEN_L1560319-1152x648-1769205900.jpg",
      "popularity_score": 341.741615
    },
    {
      "id": "cluster_73",
      "coverage": 1,
      "updated_at": "Sat, 24 Jan 2026 19:08:06 +0000",
      "title": "Poland's energy grid was targeted by never-before-seen wiper malware",
      "neutral_headline": "Poland's energy grid was targeted by never-before-seen wiper malware",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/wiper-malware-targeted-poland-energy-grid-but-failed-to-knock-out-electricity/",
          "published_at": "Sat, 24 Jan 2026 19:08:06 +0000",
          "title": "Poland's energy grid was targeted by never-before-seen wiper malware",
          "standfirst": "Destructive payload unleashed on 10-year anniversary of Russia's attack on Ukraine's grid.",
          "content": "Researchers on Friday said that Poland’s electric grid was targeted by wiper malware, likely unleashed by Russia state hackers, in an attempt to disrupt electricity delivery operations. A cyberattack, Reuters reported, occurred during the last week of December. The news organization said it was aimed at disrupting communications between renewable installations and the power distribution operators but failed for reasons not explained. Wipers R Us On Friday, security firm ESET said the malware responsible was a wiper, a type of malware that permanently erases code and data stored on servers with the goal of destroying operations completely. After studying the tactics, techniques, and procedures (TTPs) used in the attack, company researchers said the wiper was likely the work of a Russian government hacker group tracked under the name Sandworm.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/data-wiper-malware-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/data-wiper-malware-1152x648.jpg",
      "popularity_score": 329
    },
    {
      "id": "cluster_5",
      "coverage": 1,
      "updated_at": "2026-01-26T04:15:54.496Z",
      "title": "DHS keeps trying and failing to unmask anonymous ICE critics online",
      "neutral_headline": "DHS keeps trying and failing to unmask anonymous ICE critics online",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/instagram-ice-critic-wins-fight-to-stay-anonymous-as-dhs-backs-down/",
          "published_at": "2026-01-26T04:15:54.496Z",
          "title": "DHS keeps trying and failing to unmask anonymous ICE critics online",
          "standfirst": "",
          "content": "",
          "feed_position": 5
        }
      ],
      "popularity_score": 317.99980833333336
    },
    {
      "id": "cluster_4",
      "coverage": 1,
      "updated_at": "2026-01-26T04:15:54.496Z",
      "title": "Demand for Intel&#8217;s processors is apparently there, but the supply is not",
      "neutral_headline": "Demand for Intel&#8217;s processors is apparently there, but the supply is not",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/core-ultra-series-3-launch-may-be-hampered-by-chip-shortages-says-intel/",
          "published_at": "2026-01-26T04:15:54.496Z",
          "title": "Demand for Intel&#8217;s processors is apparently there, but the supply is not",
          "standfirst": "",
          "content": "",
          "feed_position": 4
        }
      ],
      "popularity_score": 312.99980833333336
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Sat, 24 Jan 2026 18:36:11 +0000",
      "title": "Did Edison accidentally make graphene in 1879?",
      "neutral_headline": "Did Edison accidentally make graphene in 1879",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/did-edison-accidentally-make-graphene-in-1879/",
          "published_at": "Sat, 24 Jan 2026 18:36:11 +0000",
          "title": "Did Edison accidentally make graphene in 1879?",
          "standfirst": "Rice University chemists replicated Thomas Edison's seminal experiment and found a surprising byproduct.",
          "content": "Graphene is the thinnest material yet known, composed of a single layer of carbon atoms arranged in a hexagonal lattice. That structure gives it many unusual properties that hold great promise for real-world applications: batteries, super capacitors, antennas, water filters, transistors, solar cells, and touchscreens, just to name a few. The physicists who first synthesized graphene in the lab won the 2010 Nobel Prize in Physics. But 19th century inventor Thomas Edison may have unknowingly created graphene as a byproduct of his original experiments on incandescent bulbs over a century earlier, according to a new paper published in the journal ACS Nano. “To reproduce what Thomas Edison did, with the tools and knowledge we have now, is very exciting,” said co-author James Tour, a chemist at Rice University. “Finding that he could have produced graphene inspires curiosity about what other information lies buried in historical experiments. What questions would our scientific forefathers ask if they could join us in the lab today? What questions can we answer when we revisit their work through a modern lens?” Edison didn't invent the concept of incandescent lamps; there were several versions predating his efforts. However, they generally had a a very short life span and required high electric current, so they weren't well suited to Edison's vision of large-scale commercialization. He experimented with different filament materials starting with carbonized cardboard and compressed lampblack. This, too, quickly burnt out, as did filaments made with various grasses and canes, like hemp and palmetto. Eventually Edison discovered that carbonized bamboo made for the best filament, with life spans over 1200 hours using a 110 volt power source.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/edison3-1152x632.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/edison3-1152x632.jpg",
      "popularity_score": 310
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Sat, 24 Jan 2026 12:00:57 +0000",
      "title": "A weird, itchy rash is linked to the keto diet—but no one knows why",
      "neutral_headline": "A weird, itchy rash is linked to the keto diet—but no one knows why",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/a-weird-itchy-rash-is-linked-to-the-keto-diet-but-no-one-knows-why/",
          "published_at": "Sat, 24 Jan 2026 12:00:57 +0000",
          "title": "A weird, itchy rash is linked to the keto diet—but no one knows why",
          "standfirst": "While the rash has a clear link to ketones, the underlying mechanism remains elusive.",
          "content": "A 20-year old man in Taiwan went to a dermatology clinic for a strange rash that had developed across his shoulders and chest. The raised, red, and itchy condition had been bothering him for a full month. By this point, he had also developed patches of pigmented skin interlaced with the red rash. According to a case report in the New England Journal of Medicine, a skin biopsy showed swelling between his skin cells and inflammation around blood vessels, but testing came up negative for other common signs of skin conditions, leaving doctors with few leads. The doctors ultimately came to a diagnosis not by analyzing his skin further but by hearing about his diet. The man's chest and shoulders, showing his rash and hyperpigmentation. Credit: New England Journal of Medicine, 2026 The man told doctors that two months prior to his clinic appointment—a month before his rash developed—he had switched to a ketogenic diet, which is a high-fat but very low-carbohydrate eating pattern. This diet forces the body to shift from using glucose (sugar derived from carbohydrates) as an energy source to fat instead.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/nejmicm2514242_f1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/nejmicm2514242_f1-1152x648.jpg",
      "popularity_score": 303
    },
    {
      "id": "cluster_6",
      "coverage": 1,
      "updated_at": "2026-01-26T04:15:54.496Z",
      "title": "White House alters arrest photo of ICE protester, says &#8220;the memes will continue&#8221;",
      "neutral_headline": "White House alters arrest photo of ICE protester, says...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/white-house-posts-altered-arrest-photo-to-make-it-appear-ice-critic-was-sobbing/",
          "published_at": "2026-01-26T04:15:54.496Z",
          "title": "White House alters arrest photo of ICE protester, says &#8220;the memes will continue&#8221;",
          "standfirst": "",
          "content": "",
          "feed_position": 6
        }
      ],
      "popularity_score": 297.99980833333336
    },
    {
      "id": "cluster_7",
      "coverage": 1,
      "updated_at": "2026-01-26T04:15:54.496Z",
      "title": "Telly’s &#8220;free&#8221; ad-based TVs make notable revenue—when they’re actually delivered",
      "neutral_headline": "Telly’s &#8220;free&#8221; ad-based TVs make notable revenue—when...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/tellys-free-ad-based-tvs-make-notable-revenue-when-theyre-actually-delivered/",
          "published_at": "2026-01-26T04:15:54.496Z",
          "title": "Telly’s &#8220;free&#8221; ad-based TVs make notable revenue—when they’re actually delivered",
          "standfirst": "",
          "content": "",
          "feed_position": 7
        }
      ],
      "popularity_score": 288.99980833333336
    },
    {
      "id": "cluster_8",
      "coverage": 1,
      "updated_at": "2026-01-26T04:15:54.496Z",
      "title": "TikTok deal is done; Trump wants praise while users fear MAGA tweaks",
      "neutral_headline": "TikTok deal is done; Trump wants praise while users fear MAGA tweaks",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/tiktok-finalizes-trump-deal-that-allows-bytedance-to-maintain-some-control/",
          "published_at": "2026-01-26T04:15:54.496Z",
          "title": "TikTok deal is done; Trump wants praise while users fear MAGA tweaks",
          "standfirst": "",
          "content": "",
          "feed_position": 8
        }
      ],
      "popularity_score": 287.99980833333336
    },
    {
      "id": "cluster_9",
      "coverage": 1,
      "updated_at": "2026-01-26T04:15:54.496Z",
      "title": "Has Gemini surpassed ChatGPT? We put the AI models to the test.",
      "neutral_headline": "Has Gemini surpassed ChatGPT? We put the AI models to the test.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2026/01/has-gemini-surpassed-chatgpt-we-put-the-ai-models-to-the-test/",
          "published_at": "2026-01-26T04:15:54.496Z",
          "title": "Has Gemini surpassed ChatGPT? We put the AI models to the test.",
          "standfirst": "",
          "content": "",
          "feed_position": 9
        }
      ],
      "popularity_score": 282.99980833333336
    }
  ]
}