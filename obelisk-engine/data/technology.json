{
  "updated_at": "2026-02-03T19:44:26.575Z",
  "clusters": [
    {
      "id": "cluster_49",
      "coverage": 2,
      "updated_at": "Tue, 03 Feb 2026 17:00:00 GMT",
      "title": "Databricks' serverless database slashes app development from months to days as companies prep for agentic AI",
      "neutral_headline": "Databricks launches serverless database service",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/databricks-serverless-database-slashes-app-development-from-months-to-days",
          "published_at": "Tue, 03 Feb 2026 17:00:00 GMT",
          "title": "Databricks' serverless database slashes app development from months to days as companies prep for agentic AI",
          "standfirst": "Five years ago, Databricks coined the term &#x27;data lakehouse&#x27; to describe a new type of data architecture that combines a data lake with a data warehouse. That term and data architecture are now commonplace across the data industry for analytics workloads.Now, Databricks is once again looking to create a new category with its Lakebase service, now generally available today. While the data lakehouse construct deals with OLAP (online analytical processing) databases, Lakebase is all about OLTP (online transaction processing) and operational databases. The Lakebase service has been in development since June 2025 and is based on technology Databricks gained via its acquisition of PostgreSQL database provider Neon. It was further enhanced in October of 2025 with the acquisition of Mooncake, which brought capabilities to help bridge PostgreSQL with lakehouse data formats.Lakebase is a serverless operational database that represents a fundamental rethinking of how databases work in the age of autonomous AI agents. Early adopters, including easyJet, Hafnia and Warner Music Group, are cutting application delivery times by 75 to 95%, but the deeper architectural innovation positions databases as ephemeral, self-service infrastructure that AI agents can provision and manage without human intervention.This isn&#x27;t just another managed Postgres service. Lakebase treats operational databases as lightweight, disposable compute running on data lake storage rather than monolithic systems requiring careful capacity planning and database administrator (DBA) oversight. \"Really, for the vibe coding trend to take off, you need developers to believe they can actually create new apps very quickly, but you also need the central IT team, or DBAs, to be comfortable with the tsunami of apps and databases,\" Databricks co-founder Reynold Xin told VentureBeat. \"Classic databases simply won&#x27;t scale to that because they can&#x27;t afford to put a DBA per database and per app.\"92% faster delivery: From two months to five daysThe production numbers demonstrate immediate impact beyond the agent provisioning vision. Hafnia reduced delivery time for production-ready applications from two months to five days — or 92% — using Lakebase as the transactional engine for their internal operations portal. The shipping company moved beyond static BI reports to real-time business applications for fleet, commercial and finance workflows.EasyJet consolidated more than 100 Git repositories into just two and cut development cycles from nine months to four months — a 56% reduction — while building a web-based revenue management hub on Lakebase to replace a decade-old desktop app and one of Europe&#x27;s largest legacy SQL Server environments.Warner Music Group is moving insights directly into production systems using the unified foundation, while Quantum Capital Group uses it to maintain consistent, governed data for identifying and evaluating oil and gas investments — eliminating the data duplication that previously forced teams to maintain multiple copies in different formats.The acceleration stems from the elimination of two major bottlenecks: database cloning for test environments and ETL pipeline maintenance for syncing operational and analytical data.Technical architecture: Why this isn&#x27;t just managed PostgresTraditional databases couple storage and compute — organizations provision a database instance with attached storage and scale by adding more instances or storage. AWS Aurora innovated by separating these layers using proprietary storage, but the storage remained locked inside AWS&#x27;s ecosystem and wasn&#x27;t independently accessible for analytics.Lakebase takes the separation of storage and compute to its logical conclusion by putting storage directly in the data lakehouse. The compute layer runs essentially vanilla PostgreSQL— maintaining full compatibility with the Postgres ecosystem — but every write goes to lakehouse storage in formats that Spark, Databricks SQL and other analytics engines can immediately query without ETL.\"The unique technical insight was that data lakes decouple storage from compute, which was great, but we need to introduce data management capabilities like governance and transaction management into the data lake,\" Xin explained. \"We&#x27;re actually not that different from the lakehouse concept, but we&#x27;re building lightweight, ephemeral compute for OLTP databases on top.\"Databricks built Lakebase with the technology it gained from the acquisition of Neon. But Xin emphasized that Databricks significantly expanded Neon&#x27;s original capabilities to create something fundamentally different.\"They didn’t have the enterprise experience, and they didn’t have the cloud scale,\" Xin said. \"We brought the Neon team&#x27;s novel architectural idea together with the robustness of the Databricks infrastructure and combined them. So now we&#x27;ve created a super scalable platform.\"From hundreds of databases to millions built for agentic AIXin outlined a vision directly tied to the economics of AI coding tools that explains why the Lakebase construct matters beyond current use cases. As development costs plummet, enterprises will shift from buying hundreds of SaaS applications to building millions of bespoke internal applications.\"As the cost of software development goes down, which we&#x27;re seeing today because of AI coding tools, it will shift from the proliferation of SaaS in the last 10 to 15 years to the proliferation of in-house application development,\" Xin said. \"Instead of building maybe hundreds of applications, they&#x27;ll be building millions of bespoke apps over time.\"This creates an impossible fleet management problem with traditional approaches. You cannot hire enough DBAs to manually provision, monitor and troubleshoot thousands of databases. Xin&#x27;s solution: Treat database management itself as a data problem rather than an operations problem.Lakebase stores all telemetry and metadata — query performance, resource utilization, connection patterns, error rates — directly in the lakehouse, where it can be analyzed using standard data engineering and data science tools. Instead of configuring dashboards in database-specific monitoring tools, data teams query telemetry data with SQL or analyze it with machine learning models to identify outliers and predict issues.\"Instead of creating a dashboard for every 50 or 100 databases, you can actually look at the chart to understand if something has misbehaved,\" Xin explained. \"Database management will look very similar to an analytics problem. You look at outliers, you look at trends, you try to understand why things happen. This is how you manage at scale when agents are creating and destroying databases programmatically.\"The implications extend to autonomous agents themselves. An AI agent experiencing performance issues could query the telemetry data to diagnose problems — treating database operations as just another analytics task rather than requiring specialized DBA knowledge. Database management becomes something agents can do for themselves using the same data analysis capabilities they already have.What this means for enterprise data teamsThe Lakebase construct signals a fundamental shift in how enterprises should think about operational databases — not as precious, carefully managed infrastructure requiring specialized DBAs, but as ephemeral, self-service resources that scale programmatically like cloud compute. This matters whether or not autonomous agents materialize as quickly as Databricks envisions, because the underlying architectural principle — treating database management as an analytics problem rather than an operations problem — changes the skill sets and team structures enterprises need.Data leaders should pay attention to the convergence of operational and analytical data happening across the industry. When writes to an operational database are immediately queryable by analytics engines without ETL, the traditional boundaries between transactional systems and data warehouses blur. This unified architecture reduces the operational overhead of maintaining separate systems, but it also requires rethinking data team structures built around those boundaries.When lakehouse launched, competitors rejected the concept before eventually adopting it themselves. Xin expects the same trajectory for Lakebase. \"It just makes sense to separate storage and compute and put all the storage in the lake — it enables so many capabilities and possibilities,\" he said.",
          "content": "Five years ago, Databricks coined the term &#x27;data lakehouse&#x27; to describe a new type of data architecture that combines a data lake with a data warehouse. That term and data architecture are now commonplace across the data industry for analytics workloads.Now, Databricks is once again looking to create a new category with its Lakebase service, now generally available today. While the data lakehouse construct deals with OLAP (online analytical processing) databases, Lakebase is all about OLTP (online transaction processing) and operational databases. The Lakebase service has been in development since June 2025 and is based on technology Databricks gained via its acquisition of PostgreSQL database provider Neon. It was further enhanced in October of 2025 with the acquisition of Mooncake, which brought capabilities to help bridge PostgreSQL with lakehouse data formats.Lakebase is a serverless operational database that represents a fundamental rethinking of how databases work in the age of autonomous AI agents. Early adopters, including easyJet, Hafnia and Warner Music Group, are cutting application delivery times by 75 to 95%, but the deeper architectural innovation positions databases as ephemeral, self-service infrastructure that AI agents can provision and manage without human intervention.This isn&#x27;t just another managed Postgres service. Lakebase treats operational databases as lightweight, disposable compute running on data lake storage rather than monolithic systems requiring careful capacity planning and database administrator (DBA) oversight. \"Really, for the vibe coding trend to take off, you need developers to believe they can actually create new apps very quickly, but you also need the central IT team, or DBAs, to be comfortable with the tsunami of apps and databases,\" Databricks co-founder Reynold Xin told VentureBeat. \"Classic databases simply won&#x27;t scale to that because they can&#x27;t afford to put a DBA per database and per app.\"92% faster delivery: From two months to five daysThe production numbers demonstrate immediate impact beyond the agent provisioning vision. Hafnia reduced delivery time for production-ready applications from two months to five days — or 92% — using Lakebase as the transactional engine for their internal operations portal. The shipping company moved beyond static BI reports to real-time business applications for fleet, commercial and finance workflows.EasyJet consolidated more than 100 Git repositories into just two and cut development cycles from nine months to four months — a 56% reduction — while building a web-based revenue management hub on Lakebase to replace a decade-old desktop app and one of Europe&#x27;s largest legacy SQL Server environments.Warner Music Group is moving insights directly into production systems using the unified foundation, while Quantum Capital Group uses it to maintain consistent, governed data for identifying and evaluating oil and gas investments — eliminating the data duplication that previously forced teams to maintain multiple copies in different formats.The acceleration stems from the elimination of two major bottlenecks: database cloning for test environments and ETL pipeline maintenance for syncing operational and analytical data.Technical architecture: Why this isn&#x27;t just managed PostgresTraditional databases couple storage and compute — organizations provision a database instance with attached storage and scale by adding more instances or storage. AWS Aurora innovated by separating these layers using proprietary storage, but the storage remained locked inside AWS&#x27;s ecosystem and wasn&#x27;t independently accessible for analytics.Lakebase takes the separation of storage and compute to its logical conclusion by putting storage directly in the data lakehouse. The compute layer runs essentially vanilla PostgreSQL— maintaining full compatibility with the Postgres ecosystem — but every write goes to lakehouse storage in formats that Spark, Databricks SQL and other analytics engines can immediately query without ETL.\"The unique technical insight was that data lakes decouple storage from compute, which was great, but we need to introduce data management capabilities like governance and transaction management into the data lake,\" Xin explained. \"We&#x27;re actually not that different from the lakehouse concept, but we&#x27;re building lightweight, ephemeral compute for OLTP databases on top.\"Databricks built Lakebase with the technology it gained from the acquisition of Neon. But Xin emphasized that Databricks significantly expanded Neon&#x27;s original capabilities to create something fundamentally different.\"They didn’t have the enterprise experience, and they didn’t have the cloud scale,\" Xin said. \"We brought the Neon team&#x27;s novel architectural idea together with the robustness of the Databricks infrastructure and combined them. So now we&#x27;ve created a super scalable platform.\"From hundreds of databases to millions built for agentic AIXin outlined a vision directly tied to the economics of AI coding tools that explains why the Lakebase construct matters beyond current use cases. As development costs plummet, enterprises will shift from buying hundreds of SaaS applications to building millions of bespoke internal applications.\"As the cost of software development goes down, which we&#x27;re seeing today because of AI coding tools, it will shift from the proliferation of SaaS in the last 10 to 15 years to the proliferation of in-house application development,\" Xin said. \"Instead of building maybe hundreds of applications, they&#x27;ll be building millions of bespoke apps over time.\"This creates an impossible fleet management problem with traditional approaches. You cannot hire enough DBAs to manually provision, monitor and troubleshoot thousands of databases. Xin&#x27;s solution: Treat database management itself as a data problem rather than an operations problem.Lakebase stores all telemetry and metadata — query performance, resource utilization, connection patterns, error rates — directly in the lakehouse, where it can be analyzed using standard data engineering and data science tools. Instead of configuring dashboards in database-specific monitoring tools, data teams query telemetry data with SQL or analyze it with machine learning models to identify outliers and predict issues.\"Instead of creating a dashboard for every 50 or 100 databases, you can actually look at the chart to understand if something has misbehaved,\" Xin explained. \"Database management will look very similar to an analytics problem. You look at outliers, you look at trends, you try to understand why things happen. This is how you manage at scale when agents are creating and destroying databases programmatically.\"The implications extend to autonomous agents themselves. An AI agent experiencing performance issues could query the telemetry data to diagnose problems — treating database operations as just another analytics task rather than requiring specialized DBA knowledge. Database management becomes something agents can do for themselves using the same data analysis capabilities they already have.What this means for enterprise data teamsThe Lakebase construct signals a fundamental shift in how enterprises should think about operational databases — not as precious, carefully managed infrastructure requiring specialized DBAs, but as ephemeral, self-service resources that scale programmatically like cloud compute. This matters whether or not autonomous agents materialize as quickly as Databricks envisions, because the underlying architectural principle — treating database management as an analytics problem rather than an operations problem — changes the skill sets and team structures enterprises need.Data leaders should pay attention to the convergence of operational and analytical data happening across the industry. When writes to an operational database are immediately queryable by analytics engines without ETL, the traditional boundaries between transactional systems and data warehouses blur. This unified architecture reduces the operational overhead of maintaining separate systems, but it also requires rethinking data team structures built around those boundaries.When lakehouse launched, competitors rejected the concept before eventually adopting it themselves. Xin expects the same trajectory for Lakebase. \"It just makes sense to separate storage and compute and put all the storage in the lake — it enables so many capabilities and possibilities,\" he said.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/469ZkXofQMti2royetGH8u/756e2b7f0b026e2b48d72bf886cd7868/database-in-a-lake-smk1.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/vercel-rebuilt-v0-to-tackle-the-90-problem-connecting-ai-generated-code-to",
          "published_at": "Tue, 03 Feb 2026 14:00:00 GMT",
          "title": "Vercel rebuilt v0 to tackle the 90% problem: Connecting AI-generated code to existing production infrastructure, not prototypes",
          "standfirst": "Before Claude Code wrote its first line of code, Vercel was already in the vibe coding space with its v0 service.The basic idea behind the original v0, which launched in 2024, was essentially to be version 0. That is, the earliest version of an application, helping developers solve the blank canvas problem. Developers could prompt their way to a user interface (UI) scaffolding that looked good, but the code was disposable. Getting those prototypes into production required rewrites.More than 4 million people have used v0 to build millions of prototypes, but the platform was missing elements required to get into production. The challenge is a familiar one with vibe coding tools, as there is a gap in what tools provide and what enterprise builders require. Claude Code, for instance, generates backend logic and scripts effectively, but does not deploy production UIs within existing company design systems while enforcing security policiesThis creates what Vercel CPO Tom Occhino calls \"the world&#x27;s largest shadow IT problem.\" AI-enabled software creation is already happening inside every enterprise. Credentials are copied into prompts. Company data flows to unmanaged tools. Apps deploy outside approved infrastructure. There&#x27;s no audit trail.Vercel rebuilt v0 to address this production deployment gap. The new version, generally available today, imports existing GitHub repositories and automatically pulls environment variables and configurations. It generates code in a sandbox-based runtime that maps directly to real Vercel deployments and enforces security controls and proper git workflows while allowing non-engineers to ship production code.\"What&#x27;s really nice about v0 is that you still have the code visible and reviewable and governed,\" Occhino told VentureBeat in an exclusive interview. \"Teams end up collaborating on the product, not on PRDs and stuff.\"This shift matters because most enterprise software work happens on existing applications, not new prototypes. Teams need tools that integrate with their current codebases and infrastructure.How v0&#x27;s sandbox runtime connects AI-generated code to existing repositoriesThe original v0 generated UI scaffolding from prompts and let users iterate through conversations. But the code lived in v0&#x27;s isolated environment, which meant moving it to production required copying files, rewriting imports and manually wiring everything together.The rebuilt v0 fundamentally changes this by directly importing existing GitHub repositories. A sandbox-based runtime automatically pulls environment variables, deployments and configurations from Vercel, so every prompt generates production-ready code that already understands the company&#x27;s infrastructure. The code lives in the repository, not a separate prototyping tool.Previously, v0 was a separate prototyping environment. Now, it&#x27;s connected to the actual codebase with full VS Code built into the interface, which means developers can edit code directly without switching tools.A new git panel handles proper workflows. Anyone on a team can create branches from within v0, open pull requests against main and deploy on merge. Pull requests are first-class citizens and previews map directly to real Vercel deployments, not isolated demos.This matters because product managers and marketers can now ship production code through proper git workflows without needing local development environments or handing code snippets to engineers for integration. The new version also adds direct integrations with Snowflake and AWS databases, so teams can wire apps to production data sources with proper access controls built in, rather than requiring manual work.Vercel&#x27;s React and Next.js experience explains v0&#x27;s deployment infrastructurePrior to joining Vercel in 2023, Occhino spent a dozen years as an engineer at Meta (formerly Facebook) and helped lead that company&#x27;s development of the widely-used React JavaScript framework.Vercel&#x27;s claim to fame is that its company founder, Guillermo Rauch, is the creator of Next.js, a full-stack framework built on top of React. In the vibe coding era, Next.js has become an increasingly popular framework. The company recently published a list of React best practices specifically designed to help AI agents and LLMs work.The Vercel platform encapsulates best practices and learnings from Next.js and React. That decade of building frameworks and infrastructure together means v0 outputs production-ready code that deploys on the same infrastructure Vercel uses for millions of deployments annually. The platform includes agentic workflow support, MCP integration, web application firewall, SSO and deployment protections. Teams can open any project in a cloud dev environment and push changes in a single click to a Vercel preview or production deployment.With no shortage of competitive offerings in the vibe coding space, including Replit, Lovable and Cursor among others, it&#x27;s the core foundational infrastructure that Occhino sees as standing out.\"The biggest differentiator for us is the Vercel infrastructure,\" Occhino said. \"It&#x27;s been building managed infrastructure, framework-defined infrastructure, now self-driving infrastructure for the past 10 years.\"Why vibe coding security requires infrastructure control, not just policyThe shadow IT problem isn&#x27;t that employees are using AI tools. It&#x27;s that most vibe coding tools operate entirely outside enterprise infrastructure. Credentials are copied into prompts because there&#x27;s no secure way to connect generated code to enterprise databases. Apps deploy to public URLs because the tools don&#x27;t integrate with company deployment pipelines. Data leaks happen because visibility controls don&#x27;t exist.The technical challenge is that securing AI-generated code requires controlling where it runs and what it can access. Policy documents don&#x27;t help if the tooling itself can&#x27;t enforce those policies.This is where infrastructure matters. When vibe coding tools operate on separate platforms, enterprises face a choice: Block the tools entirely or accept the security risks. When the vibe coding tool runs on the same infrastructure as production deployments, security controls can be enforced automatically.v0 runs on Vercel&#x27;s infrastructure, which means enterprises can set deployment protections, visibility controls and access policies that apply to AI-generated code the same way they apply to hand-written code. Direct integrations with Snowflake and AWS databases let teams connect to production data with proper access controls rather than copying credentials into prompts.\"IT teams are comfortable with what their teams are building because they have control over who has access,\" Occhino said. \"They have control over what those applications have access to from Snowflake or data systems.\"Generative UI vs. generative softwareIn addition to the new version of v0, Vercel has recently introduced a generative UI technology called json-render.v0 is what Vercel calls generative software. This differs from the company&#x27;s json-render framework for a true generative UI. Vercel software engineer Chris Tate explained that v0 builds full-stack apps and agents, not just UIs or frontends. In contrast, json-render is a framework that enables AI to generate UI components directly at runtime by outputting JSON instead of code. \"The AI doesn&#x27;t write software,\" Tate told VentureBeat. \"It plugs directly into the rendering layer to create spontaneous, personalized interfaces on demand.\"The distinction matters for enterprise use cases. Teams use v0 when they need to build complete applications, custom components or production software.They use JSON-render for dynamic, personalized UI elements within applications, dashboards that adapt to individual users, contextual widgets and interfaces that respond to changing data without code changes.Both leverage the AI SDK infrastructure that Vercel has built for streaming and structured outputs.Three lessons enterprises learned from vibe coding adoptionAs enterprises adopted vibe coding tools over the past two years, several patterns emerged about AI-generated code in production environments.Lesson 1: Prototyping without production deployment creates false progress. Enterprises saw teams generate impressive demos in v0&#x27;s early versions, then hit a wall moving those demos to production. The problem wasn&#x27;t the quality of generated code. It was that prototypes lived in isolated environments disconnected from production infrastructure.\"While demos are easy to generate, I think most of the iteration that&#x27;s happening on these code bases is happening on real production apps,\" Occhino said. \"90% of what we need to do is make changes to an existing code base.\"Lesson 2: The software development lifecycle has already changed, whether enterprises planned for it or not. Domain experts are building software directly instead of writing product requirement documents (PRDs) for engineers to interpret. Product managers and marketers ship features without waiting for engineering sprints.This shift means enterprises need tools that maintain code visibility and governance while enabling non-engineers to ship. The alternative is creating bottlenecks by forcing all AI-generated code through traditional development workflows.Lesson 3: Blocking vibe coding tools doesn&#x27;t stop vibe coding. It just pushes the activity outside IT&#x27;s visibility. Enterprises that try to restrict AI-powered development find employees using tools anyway, creating the shadow IT problem at scale.The practical implication is that enterprises should focus less on whether to allow vibe coding and more on ensuring it happens within infrastructure that can enforce existing security and deployment policies.",
          "content": "Before Claude Code wrote its first line of code, Vercel was already in the vibe coding space with its v0 service.The basic idea behind the original v0, which launched in 2024, was essentially to be version 0. That is, the earliest version of an application, helping developers solve the blank canvas problem. Developers could prompt their way to a user interface (UI) scaffolding that looked good, but the code was disposable. Getting those prototypes into production required rewrites.More than 4 million people have used v0 to build millions of prototypes, but the platform was missing elements required to get into production. The challenge is a familiar one with vibe coding tools, as there is a gap in what tools provide and what enterprise builders require. Claude Code, for instance, generates backend logic and scripts effectively, but does not deploy production UIs within existing company design systems while enforcing security policiesThis creates what Vercel CPO Tom Occhino calls \"the world&#x27;s largest shadow IT problem.\" AI-enabled software creation is already happening inside every enterprise. Credentials are copied into prompts. Company data flows to unmanaged tools. Apps deploy outside approved infrastructure. There&#x27;s no audit trail.Vercel rebuilt v0 to address this production deployment gap. The new version, generally available today, imports existing GitHub repositories and automatically pulls environment variables and configurations. It generates code in a sandbox-based runtime that maps directly to real Vercel deployments and enforces security controls and proper git workflows while allowing non-engineers to ship production code.\"What&#x27;s really nice about v0 is that you still have the code visible and reviewable and governed,\" Occhino told VentureBeat in an exclusive interview. \"Teams end up collaborating on the product, not on PRDs and stuff.\"This shift matters because most enterprise software work happens on existing applications, not new prototypes. Teams need tools that integrate with their current codebases and infrastructure.How v0&#x27;s sandbox runtime connects AI-generated code to existing repositoriesThe original v0 generated UI scaffolding from prompts and let users iterate through conversations. But the code lived in v0&#x27;s isolated environment, which meant moving it to production required copying files, rewriting imports and manually wiring everything together.The rebuilt v0 fundamentally changes this by directly importing existing GitHub repositories. A sandbox-based runtime automatically pulls environment variables, deployments and configurations from Vercel, so every prompt generates production-ready code that already understands the company&#x27;s infrastructure. The code lives in the repository, not a separate prototyping tool.Previously, v0 was a separate prototyping environment. Now, it&#x27;s connected to the actual codebase with full VS Code built into the interface, which means developers can edit code directly without switching tools.A new git panel handles proper workflows. Anyone on a team can create branches from within v0, open pull requests against main and deploy on merge. Pull requests are first-class citizens and previews map directly to real Vercel deployments, not isolated demos.This matters because product managers and marketers can now ship production code through proper git workflows without needing local development environments or handing code snippets to engineers for integration. The new version also adds direct integrations with Snowflake and AWS databases, so teams can wire apps to production data sources with proper access controls built in, rather than requiring manual work.Vercel&#x27;s React and Next.js experience explains v0&#x27;s deployment infrastructurePrior to joining Vercel in 2023, Occhino spent a dozen years as an engineer at Meta (formerly Facebook) and helped lead that company&#x27;s development of the widely-used React JavaScript framework.Vercel&#x27;s claim to fame is that its company founder, Guillermo Rauch, is the creator of Next.js, a full-stack framework built on top of React. In the vibe coding era, Next.js has become an increasingly popular framework. The company recently published a list of React best practices specifically designed to help AI agents and LLMs work.The Vercel platform encapsulates best practices and learnings from Next.js and React. That decade of building frameworks and infrastructure together means v0 outputs production-ready code that deploys on the same infrastructure Vercel uses for millions of deployments annually. The platform includes agentic workflow support, MCP integration, web application firewall, SSO and deployment protections. Teams can open any project in a cloud dev environment and push changes in a single click to a Vercel preview or production deployment.With no shortage of competitive offerings in the vibe coding space, including Replit, Lovable and Cursor among others, it&#x27;s the core foundational infrastructure that Occhino sees as standing out.\"The biggest differentiator for us is the Vercel infrastructure,\" Occhino said. \"It&#x27;s been building managed infrastructure, framework-defined infrastructure, now self-driving infrastructure for the past 10 years.\"Why vibe coding security requires infrastructure control, not just policyThe shadow IT problem isn&#x27;t that employees are using AI tools. It&#x27;s that most vibe coding tools operate entirely outside enterprise infrastructure. Credentials are copied into prompts because there&#x27;s no secure way to connect generated code to enterprise databases. Apps deploy to public URLs because the tools don&#x27;t integrate with company deployment pipelines. Data leaks happen because visibility controls don&#x27;t exist.The technical challenge is that securing AI-generated code requires controlling where it runs and what it can access. Policy documents don&#x27;t help if the tooling itself can&#x27;t enforce those policies.This is where infrastructure matters. When vibe coding tools operate on separate platforms, enterprises face a choice: Block the tools entirely or accept the security risks. When the vibe coding tool runs on the same infrastructure as production deployments, security controls can be enforced automatically.v0 runs on Vercel&#x27;s infrastructure, which means enterprises can set deployment protections, visibility controls and access policies that apply to AI-generated code the same way they apply to hand-written code. Direct integrations with Snowflake and AWS databases let teams connect to production data with proper access controls rather than copying credentials into prompts.\"IT teams are comfortable with what their teams are building because they have control over who has access,\" Occhino said. \"They have control over what those applications have access to from Snowflake or data systems.\"Generative UI vs. generative softwareIn addition to the new version of v0, Vercel has recently introduced a generative UI technology called json-render.v0 is what Vercel calls generative software. This differs from the company&#x27;s json-render framework for a true generative UI. Vercel software engineer Chris Tate explained that v0 builds full-stack apps and agents, not just UIs or frontends. In contrast, json-render is a framework that enables AI to generate UI components directly at runtime by outputting JSON instead of code. \"The AI doesn&#x27;t write software,\" Tate told VentureBeat. \"It plugs directly into the rendering layer to create spontaneous, personalized interfaces on demand.\"The distinction matters for enterprise use cases. Teams use v0 when they need to build complete applications, custom components or production software.They use JSON-render for dynamic, personalized UI elements within applications, dashboards that adapt to individual users, contextual widgets and interfaces that respond to changing data without code changes.Both leverage the AI SDK infrastructure that Vercel has built for streaming and structured outputs.Three lessons enterprises learned from vibe coding adoptionAs enterprises adopted vibe coding tools over the past two years, several patterns emerged about AI-generated code in production environments.Lesson 1: Prototyping without production deployment creates false progress. Enterprises saw teams generate impressive demos in v0&#x27;s early versions, then hit a wall moving those demos to production. The problem wasn&#x27;t the quality of generated code. It was that prototypes lived in isolated environments disconnected from production infrastructure.\"While demos are easy to generate, I think most of the iteration that&#x27;s happening on these code bases is happening on real production apps,\" Occhino said. \"90% of what we need to do is make changes to an existing code base.\"Lesson 2: The software development lifecycle has already changed, whether enterprises planned for it or not. Domain experts are building software directly instead of writing product requirement documents (PRDs) for engineers to interpret. Product managers and marketers ship features without waiting for engineering sprints.This shift means enterprises need tools that maintain code visibility and governance while enabling non-engineers to ship. The alternative is creating bottlenecks by forcing all AI-generated code through traditional development workflows.Lesson 3: Blocking vibe coding tools doesn&#x27;t stop vibe coding. It just pushes the activity outside IT&#x27;s visibility. Enterprises that try to restrict AI-powered development find employees using tools anyway, creating the shadow IT problem at scale.The practical implication is that enterprises should focus less on whether to allow vibe coding and more on ensuring it happens within infrastructure that can enforce existing security and deployment policies.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2U5I1bHA9QfvqoZdPB6qk0/7e4945d1392da8bd955144193be626f7/enterprise-vibe-coder-smk1.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-bluetooth-tracker-140028377.html",
          "published_at": "Tue, 03 Feb 2026 08:00:35 +0000",
          "title": "The best Bluetooth trackers for 2026",
          "standfirst": "Most people think of AirTags when they picture a Bluetooth tracker. And indeed, Apple’s little white discs were once the only capable option, relying on a vast finding network of nearby iPhones to pinpoint lost tags. But now Google has a finding network of its own, and third party brands like Chipolo, Hyper and Pebblebee have trackers that pair with your choice of Google or Apple’s network. That means you’ve got a lot of options for tagging and tracking your keys, backpacks, luggage and more. We tested the major brands out there to see how well they work, how loud they are and how they look to put together a guide to help you get the most out of your chosen tracker. Here are the best Bluetooth trackers you can buy.Editor's note: Apple just released a new version of its AirTag trackers. We are in the process of testing the new model and will update this guide once we're done. Best Bluetooth trackers for 2026 What to look for in a Bluetooth tracking device Bluetooth trackers are small discs or cards that rely on short-range, low-energy wireless signals to communicate with your smartphone. Attach one of these gadgets your stuff and, if it’s in range, your phone can “ring” the chip so you can find it. These tracking devices offer other features like separation alerts to tell you when you’ve left a tagged item behind, or where a lost item was last detected. Some can even tap into a larger network of smartphones to track down your device when you’re out of range. Depending on what you want the tracker to do, there are a few specs to look for when deciding which to get. Device compatibility Like most things from the folks in Cupertino, AirTags only work with products in the Apple ecosystem. Both Apple and Google have opened up access to the Find My and Find Hub networks to third-party manufacturers, including Chipolo and Pebblebee. Those two companies make device-agnostic models that will work with the larger tracking network from either brand, so iPhone and Android users can buy the same tag. Tile trackers work with either Android or Apple devices, but use Tile’s own Life 360 finding network. Samsung’s latest fob, the Galaxy SmartTag2, only works with Samsung phones and taps into a finding system that relies on other Samsung devices to locate lost tags. Finding network Crowd-sourced finding capabilities are what make headlines, with stories about recovering stolen equipment or tracking lost luggage across the globe. Using anonymous signals that ping other people’s devices, these Bluetooth tracking devices can potentially tell you where a tagged item is, even if your smartphone is out of Bluetooth range. Apple’s Find My network is the largest, with over a billion iPhones and iPads in service all running Apple’s Find My app by default. So unless an iPhone user opts out, their phone silently acts as a location detector for any nearby AirTags. Apple recently increased the AirTag’s finding power by enabling you to share the tracker's location with a third party, party, like an airline. Chipolo fobs that work on Apple’s network have the same ability. Google launched its Find My Device network in 2024 and has since renamed it Find Hub, which, like Apple's fining app, combines devices and people finding in one place. That network is now a close second for the largest in the US Now that Google’s Find Hub network is up and running, it’s a close second for the largest in the US. Like Apple, Android users are automatically part of the network, but can opt-out by selecting the Google services option in their phone’s Settings app and toggling the option in the Find Hub menu. Samsung’s SmartTag 2 and related network also defaults to an opt-in status for finding tags and other devices. Tile offers a large finding grid that includes Tile users, Amazon Sidewalk customers and people running the Life360 network. Life360 acquired Tile in 2021, and, according to the company, the Life360 network has more than 70 million monthly active users. In our tests, AirTags and third-party tags using its network, like the Chipolo Loop and Pop and the Pebblebee Clip 5, were the fastest to track down lost items. They offered nearly real-time location data in moderately to heavily trafficked spots around Albuquerque, including a bar, bookstore and coffee shops in Nob Hill, along with various outdoor hangouts on UNM’s campus. Samsung's SmartTags were able to locate our lost items most of the time, though not with the same precision finding accuracy as AirTags. When we tested Google’s Find Hub (then called Find My Device) network right after launch, it was noticeably slower than Apple’s network when using the community finding feature. Testing it again in mid 2025, the time it took to locate a lost item was considerably improved, taking less than 20 minutes on average for the community to track a fob. In our tests, Tile’s finding network wasn’t able to consistently locate its lost fobs. Amy Skorheim / Engadget Separation alerts A tracker’s day-to-day utility becomes really apparent when it prevents you from losing something in the first place. Separation alerts tell you when you’ve traveled too far from your tagged items. Useful if you want to make sure your laptop bag, jacket or umbrella always comes with you when you leave the house. Apple’s Find My app delivers these notifications, but Google’s Find Hub does not. However, if you have a Chipolo device and allow its companion app to run in the background on your Android phone, left-behind alerts are enabled. Tile trackers require a yearly subscription to enable the alerts (currently $7 to $25 monthly). Both AirTags and Tiles allow you to turn off separation alerts at certain locations, meaning you can set your home as a “safe” place where items can be left behind, but alerts will still trigger elsewhere. In our tests, AirTags and others using the Find My network alerted us between the 600- and 1,400-foot mark. Tiles sent a notification after about an average of 1,500 feet and were more consistent when using an Android phone than an iPhone. Chipolo Pop tags paired with an Android phone and using its own app sent an alert when we got around 450 feet away from our tagged item. Connectivity and volume The feature you may use most often is the key finder function, which makes the tracker ring when you hit a button in the app. With Apple's AirTags, you can say \"Hey Siri, where are my keys?\" and the assistant will ring the tag (assuming it doesn't mistakenly think you're asking for directions to the Floridian archipelago). You can also use the Find Item app in your Apple Watch to ring your fob. Asking smart home/personal assistants like Alexa or the Google Assistant to find your keys will work with Chipolo, Tile and Pebblebee trackers linked to your Android device. If you have your tag but can’t find your phone, some trackers will let you ring them to find your handset. SmartTag2 fobs reliably rang our Galaxy phone when we double-pressed it. Tile trackers have the same feature. Chipolo Pop and Loop trackers can ring your phone, but uses the Chipolo app to do so, which can run concurrently with the Find My or Find Hub connection. AirTags and third-party tags using Google’s network don’t offer this feature. The volume of the Bluetooth tracking device may determine whether you can find an item buried in your couch cushions or in a noisy room. AirTags have a reputation for being on the quiet side, and that aligned with what we saw (measuring roughly 65 decibels). Chipolo’s Pop tags and Tile’s Pro model measure between 83 and 86 decibels on average. Pebblebee’s new Clip 5 was the loudest of any tag we’ve tested, clocking in at 97 ear-splitting decibels. Design and alternative formats Design will determine what you can attach the tracker to. AirTags are small, smooth discs that can’t be secured to anything without accessories, which are numerous, but that is an additional cost to consider. Chipolo, Pebblebee and Tile offer trackers with holes that easily attach to your key ring, and all three companies also offer card-shaped versions designed to fit in your wallet. Pebblebee Clip 5 tags come with a handy carabiner-style key ring. You can even get trackers embedded into useful items like luggage locks. The SmartLock from KeySmart is a TSA-approved luggage lock, but in addition to the three digit code, it’s also a Bluetooth tracker that’s compatible with Apple Find My. It wasn’t quite as loud as other trackers in my tests, and the range wasn’t as long, but it paired easily and worked with Apple’s finding network just like an AirTag. Battery life AirTag, Tile Pro, SmartTag2, HyperShield and Chipolo Pop fobs use replaceable batteries and each should go for at least a year before needing to be swapped. Pebblebee Clip 5 and Chipolo Loop trackers are rechargeable via a standard USB-C port. The Clip 5 has a long battery life claim at 12 months. The Loop should go for six months on a charge. Trackers shaped like credit cards, aka wallet trackers, don't have replaceable batteries, but some, like the Chipolo Card and the Pebblebee Card 5 are USB-C rechargeable. Stalking, theft and data privacy AirTags have gotten a lot of attention and even prompted some lawsuits for Apple due to bad actors planting them on people in order to stalk them. While this fact may not influence your buying decision, any discussion of Bluetooth trackers should note what steps Apple, Google and Tile have taken to address the issue. Last year, all the major players in the Bluetooth tracker business teamed up to combat misuse and standardize how unauthorized tracking detection and alerts work for iOS and Android. Last year, Tile launched a feature called Anti-Theft Mode, which enables you to render one of its trackers undetectable by others. That means if someone steals your tagged item, they won’t be able to use the anti-stalking features to find and disable the tracker. That sort of negates one of the major ways potential stalking victims can stay safe, so Tile hopes ID verification and a $1 million penalty will deter misuse. As a theft deterrent, a Bluetooth tracker may or may not be the best option. Anecdotal stories abound in which people have recovered stolen goods using a tracker — but other tales are more cautionary. Neither Apple nor Google promotes its trackers or finding networks as a way to deal with theft. GPS trackers, on the other hand, are typically marketed for just that purpose. How we tested Bluetooth trackers Before deciding on which trackers to test, we researched the field, looking at user reviews on Amazon, Best Buy and other retailers, along with discussions on sites like Reddit. We also checked out what other publications had to say on the matter before narrowing down our options. Here’s the full list of every tracker we tested: Apple AirTag Chipolo Card Spot Chipolo One Spot Chipolo One Chipolo Card Chipolo Loop Chipolo Pop HyperShield KeySmart SmartLock Motorola Moto Tag Pebblebee Clip 5 Pebblebee Clip Universal Pebblebee Clip Samsung SmartTag 2 Chipolo One Point Pebblebee Clip for Android Tile Pro (2024) Tile Mate (2024) Tile Mate (2022) Tile Pro (2022) Tile Slim (2022) After acquiring the trackers, I tested each one over the course of a few weeks using both an iPhone 11 followed by an iPhone 16 and a Samsung Galaxy S22 then an S23 Ultra. I recreated likely user experiences, such as losing and leaving items behind at home and out in the city. I planted trackers at different spots near downtown Albuquerque, mostly concentrated in and around the University of New Mexico and the surrounding neighborhood of Nob Hill. Later, I conducted tests in the Queen Anne neighborhood of Seattle. Each test was performed multiple times, both while walking and driving and I used the measure distance feature on Google Maps to track footage for alerts. I paid attention to how easy the app was to use, how reliable the phone-to-tracker connection was and any other perks and drawbacks that came up during regular use. As new trackers come to market, or as we learn of worthy models to try, I'll test them and add the results to this guide. Other Bluetooth trackers we tested Motorola Moto Tag The Moto Tag haunts me. At this very moment, my Galaxy phone says the fob is “Near you right now.” But I don’t know where. I tap to play a sound and the Find Hub tries, but ultimately says it can’t. I tap the Find Nearby function that’s supposed to visually guide you to the tag. I parade my phone around the house like a divining rod, take it down into the basement, walk it all over the garage. Nothing. But the Hub app unendingly says the Moto Tag is “Near you right now” and I get flashes of every old-school horror movie where the telephone operator tells the soon-to-be victim that the call is coming from inside the house. It’s partly my fault. I tend to keep good tabs on the gadgets I test for work. But during my most recent move, the tiny green disc didn’t make it into the safety of my review unit cabinet after relocation. Perhaps in retribution for my neglect, the Moto Tag keeps itself just out of reach. Taunting me. I’ll let you know if I ever find it, but in the meantime, it’s clear this finding device doesn’t want to be found. The recommended tags in this guide will serve you better. Tile Pro and Tile Mate (2024) Tile recently came out with a new suite of trackers, replacing the Tile Mate, Tile Pro, Tile Sticker and Tile Slim with updated models. In addition to fun new colors for the Mate and Slim, Tile added an SOS feature that can send a notification to your Life360 Circle when you triple press the button on the tracker. It’s a clever addition that turns your keys into a panic button, something offered by personal safety companies as standalone devices. There are a few caveats: You and the people you want to notify in an emergency will need the Life360 app installed on your phones. If you want your Tile to also trigger a call to emergency services, you’ll need a $15-per-month Life360 subscription (that’s in addition to a Tile membership, which starts at $3/month or $30 annually). And enabling the SOS triple-press disables the ability to ring your phone with the fob. I tested the SOS feature and it did indeed send a text message to my Circle, with the message that I had triggered an SOS and a link to a website that showed my current location. I thought it odd that the link didn’t open the Life360 app (which shows the location of users' phones), but I wasn’t as much concerned with Tile’s personal safety features as I was with the tracking capabilities, which turned out to be less than ideal. For my tests, I planted Tile trackers in a densely populated area of Seattle (about 15,000 people per square mile). After setting the trackers to “lost” in the Tile app, I waited. After four hours, one of the trackers was not discovered by the finding community, so I went and retrieved it. Another fob I planted alerted me that the tracker had been found by the Tile community after three hours — but the location it gave me was off by a third of a mile. I then decided to plant a tracker in the busiest place I could think of — the dried fruit and nuts aisle of a Trader Joes on a Friday evening before a major holiday. It still took over a half an hour before another Tile user anonymously pinged my lost tracker. In my tests with Samsung’s trackers and the fobs on Google’s Find Hub network, it took around ten minutes for them to be discovered. AirTags took half that time and all were tested in a far less populated city. Tile's four hours with no ping and over a half hour before getting a hit in a crowded TJs were pretty long stretches. Tile devices work with both mobile operating systems and its latest models are indeed louder than they were before. But they aren’t as quick to connect and you need to pay for a membership to activate left-behind alerts. And when you do, those notifications don’t kick in as quickly as they do with competing trackers. Bluetooth tracker FAQs Which Bluetooth tracker has the longest range? Both the Tile Pro and the Samsung Galaxy SmartTag2 claim a maximum range of around 400 feet, which is longer than the 300-foot claim for Chipolo’s Pop tags. The Pebblebee Clip 5 claims a 500-foot range, though other trackers with a shorter claimed range often performed better in our tests. Apple doesn’t make range claims for AirTags, but 30 meters (100 feet) seems to be the general consensus for those fobs. Any Bluetooth signal, of course, is dependent on a few factors. Obstacles like walls and people can block the signal, so a clear line of sight is the only way to achieve the maximum range. Other signals, like Wi-Fi, can also interfere with Bluetooth connections. Even high humidity can have an effect and lessen the distance at which your phone will connect to your tracker. Remember, when considering the range of Bluetooth trackers, the size of the “finding network” also comes into play. This is the number of nearby phones that can be used to anonymously ping your tracker when your own phone is out of Bluetooth range. As of now, Apple AirTags have the largest network, followed by Google’s Find Hub, Samsung’s finding community and finally, Tile’s Life360 members. What is the best Bluetooth tracker for a car? Bluetooth trackers are designed to track small, personal items like keys, jackets, backpacks and the like. All trackers have safeguards to prohibit the tag from being used to stalk people, so most will alert someone if a tracker that does not belong to them is detected following them. That means a car thief may get tipped off that there’s a tracker in the car they’re trying to steal. That said, you’ll see plenty of stories about people finding their car thanks to a Bluetooth tracker. Some police departments have even handed out trackers to combat high rates of carjacking. In most instances, the tracker of choice has been AirTags thanks to their wide finding network. If you’re looking for a tracker for your car, you may want to look into GPS trackers, some of which are designed for just that purpose. How accurate are Bluetooth trackers? Accuracy for Bluetooth trackers can be looked at in two ways: Finding items nearby and finding items misplaced outside your home. For nearby items, you’ll most often use the ring function on the device to hunt it down. Apple’s AirTags also use ultra-wideband technology, which creates directional navigation on your phone to get you within a foot of the tracker. Accurately finding lost items outside your home depends on the size of the finding network. Since this relies on the serendipity of a random phone passing within Bluetooth range of your tracker, the more phones on a given network, the better. And since Bluetooth ranges and distance estimates are only precise within about a meter or so, getting pings from more than one phone will help locating items. Here again, it’s worth noting that Apple’s Find My network is the largest, followed by Google, Samsung and Tile (both Chipolo and Pebblebee have fobs that work with the Apple and Google networks). Recent Updates February 2026: Added Pebblebee Clip 5 as the best rechargeable device. Added HyperShield tag as a budget pick. Updated FAQs for accuracy. October 2025: Added Chipolo Loop as a new pick for best rechargeable Bluetooth tracker. Detailed our experience with the Moto Tag and KeySmart SmartLock. Updated details about separation alerts and Ultra Wideband tech. August 2025: Updated the name of Google's finding network to Find Hub, instead of Find My Device. Added details about Pebblebee's new Alert feature. Added a table of contents. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-bluetooth-tracker-140028377.html?src=rss",
          "content": "Most people think of AirTags when they picture a Bluetooth tracker. And indeed, Apple’s little white discs were once the only capable option, relying on a vast finding network of nearby iPhones to pinpoint lost tags. But now Google has a finding network of its own, and third party brands like Chipolo, Hyper and Pebblebee have trackers that pair with your choice of Google or Apple’s network. That means you’ve got a lot of options for tagging and tracking your keys, backpacks, luggage and more. We tested the major brands out there to see how well they work, how loud they are and how they look to put together a guide to help you get the most out of your chosen tracker. Here are the best Bluetooth trackers you can buy.Editor's note: Apple just released a new version of its AirTag trackers. We are in the process of testing the new model and will update this guide once we're done. Best Bluetooth trackers for 2026 What to look for in a Bluetooth tracking device Bluetooth trackers are small discs or cards that rely on short-range, low-energy wireless signals to communicate with your smartphone. Attach one of these gadgets your stuff and, if it’s in range, your phone can “ring” the chip so you can find it. These tracking devices offer other features like separation alerts to tell you when you’ve left a tagged item behind, or where a lost item was last detected. Some can even tap into a larger network of smartphones to track down your device when you’re out of range. Depending on what you want the tracker to do, there are a few specs to look for when deciding which to get. Device compatibility Like most things from the folks in Cupertino, AirTags only work with products in the Apple ecosystem. Both Apple and Google have opened up access to the Find My and Find Hub networks to third-party manufacturers, including Chipolo and Pebblebee. Those two companies make device-agnostic models that will work with the larger tracking network from either brand, so iPhone and Android users can buy the same tag. Tile trackers work with either Android or Apple devices, but use Tile’s own Life 360 finding network. Samsung’s latest fob, the Galaxy SmartTag2, only works with Samsung phones and taps into a finding system that relies on other Samsung devices to locate lost tags. Finding network Crowd-sourced finding capabilities are what make headlines, with stories about recovering stolen equipment or tracking lost luggage across the globe. Using anonymous signals that ping other people’s devices, these Bluetooth tracking devices can potentially tell you where a tagged item is, even if your smartphone is out of Bluetooth range. Apple’s Find My network is the largest, with over a billion iPhones and iPads in service all running Apple’s Find My app by default. So unless an iPhone user opts out, their phone silently acts as a location detector for any nearby AirTags. Apple recently increased the AirTag’s finding power by enabling you to share the tracker's location with a third party, party, like an airline. Chipolo fobs that work on Apple’s network have the same ability. Google launched its Find My Device network in 2024 and has since renamed it Find Hub, which, like Apple's fining app, combines devices and people finding in one place. That network is now a close second for the largest in the US Now that Google’s Find Hub network is up and running, it’s a close second for the largest in the US. Like Apple, Android users are automatically part of the network, but can opt-out by selecting the Google services option in their phone’s Settings app and toggling the option in the Find Hub menu. Samsung’s SmartTag 2 and related network also defaults to an opt-in status for finding tags and other devices. Tile offers a large finding grid that includes Tile users, Amazon Sidewalk customers and people running the Life360 network. Life360 acquired Tile in 2021, and, according to the company, the Life360 network has more than 70 million monthly active users. In our tests, AirTags and third-party tags using its network, like the Chipolo Loop and Pop and the Pebblebee Clip 5, were the fastest to track down lost items. They offered nearly real-time location data in moderately to heavily trafficked spots around Albuquerque, including a bar, bookstore and coffee shops in Nob Hill, along with various outdoor hangouts on UNM’s campus. Samsung's SmartTags were able to locate our lost items most of the time, though not with the same precision finding accuracy as AirTags. When we tested Google’s Find Hub (then called Find My Device) network right after launch, it was noticeably slower than Apple’s network when using the community finding feature. Testing it again in mid 2025, the time it took to locate a lost item was considerably improved, taking less than 20 minutes on average for the community to track a fob. In our tests, Tile’s finding network wasn’t able to consistently locate its lost fobs. Amy Skorheim / Engadget Separation alerts A tracker’s day-to-day utility becomes really apparent when it prevents you from losing something in the first place. Separation alerts tell you when you’ve traveled too far from your tagged items. Useful if you want to make sure your laptop bag, jacket or umbrella always comes with you when you leave the house. Apple’s Find My app delivers these notifications, but Google’s Find Hub does not. However, if you have a Chipolo device and allow its companion app to run in the background on your Android phone, left-behind alerts are enabled. Tile trackers require a yearly subscription to enable the alerts (currently $7 to $25 monthly). Both AirTags and Tiles allow you to turn off separation alerts at certain locations, meaning you can set your home as a “safe” place where items can be left behind, but alerts will still trigger elsewhere. In our tests, AirTags and others using the Find My network alerted us between the 600- and 1,400-foot mark. Tiles sent a notification after about an average of 1,500 feet and were more consistent when using an Android phone than an iPhone. Chipolo Pop tags paired with an Android phone and using its own app sent an alert when we got around 450 feet away from our tagged item. Connectivity and volume The feature you may use most often is the key finder function, which makes the tracker ring when you hit a button in the app. With Apple's AirTags, you can say \"Hey Siri, where are my keys?\" and the assistant will ring the tag (assuming it doesn't mistakenly think you're asking for directions to the Floridian archipelago). You can also use the Find Item app in your Apple Watch to ring your fob. Asking smart home/personal assistants like Alexa or the Google Assistant to find your keys will work with Chipolo, Tile and Pebblebee trackers linked to your Android device. If you have your tag but can’t find your phone, some trackers will let you ring them to find your handset. SmartTag2 fobs reliably rang our Galaxy phone when we double-pressed it. Tile trackers have the same feature. Chipolo Pop and Loop trackers can ring your phone, but uses the Chipolo app to do so, which can run concurrently with the Find My or Find Hub connection. AirTags and third-party tags using Google’s network don’t offer this feature. The volume of the Bluetooth tracking device may determine whether you can find an item buried in your couch cushions or in a noisy room. AirTags have a reputation for being on the quiet side, and that aligned with what we saw (measuring roughly 65 decibels). Chipolo’s Pop tags and Tile’s Pro model measure between 83 and 86 decibels on average. Pebblebee’s new Clip 5 was the loudest of any tag we’ve tested, clocking in at 97 ear-splitting decibels. Design and alternative formats Design will determine what you can attach the tracker to. AirTags are small, smooth discs that can’t be secured to anything without accessories, which are numerous, but that is an additional cost to consider. Chipolo, Pebblebee and Tile offer trackers with holes that easily attach to your key ring, and all three companies also offer card-shaped versions designed to fit in your wallet. Pebblebee Clip 5 tags come with a handy carabiner-style key ring. You can even get trackers embedded into useful items like luggage locks. The SmartLock from KeySmart is a TSA-approved luggage lock, but in addition to the three digit code, it’s also a Bluetooth tracker that’s compatible with Apple Find My. It wasn’t quite as loud as other trackers in my tests, and the range wasn’t as long, but it paired easily and worked with Apple’s finding network just like an AirTag. Battery life AirTag, Tile Pro, SmartTag2, HyperShield and Chipolo Pop fobs use replaceable batteries and each should go for at least a year before needing to be swapped. Pebblebee Clip 5 and Chipolo Loop trackers are rechargeable via a standard USB-C port. The Clip 5 has a long battery life claim at 12 months. The Loop should go for six months on a charge. Trackers shaped like credit cards, aka wallet trackers, don't have replaceable batteries, but some, like the Chipolo Card and the Pebblebee Card 5 are USB-C rechargeable. Stalking, theft and data privacy AirTags have gotten a lot of attention and even prompted some lawsuits for Apple due to bad actors planting them on people in order to stalk them. While this fact may not influence your buying decision, any discussion of Bluetooth trackers should note what steps Apple, Google and Tile have taken to address the issue. Last year, all the major players in the Bluetooth tracker business teamed up to combat misuse and standardize how unauthorized tracking detection and alerts work for iOS and Android. Last year, Tile launched a feature called Anti-Theft Mode, which enables you to render one of its trackers undetectable by others. That means if someone steals your tagged item, they won’t be able to use the anti-stalking features to find and disable the tracker. That sort of negates one of the major ways potential stalking victims can stay safe, so Tile hopes ID verification and a $1 million penalty will deter misuse. As a theft deterrent, a Bluetooth tracker may or may not be the best option. Anecdotal stories abound in which people have recovered stolen goods using a tracker — but other tales are more cautionary. Neither Apple nor Google promotes its trackers or finding networks as a way to deal with theft. GPS trackers, on the other hand, are typically marketed for just that purpose. How we tested Bluetooth trackers Before deciding on which trackers to test, we researched the field, looking at user reviews on Amazon, Best Buy and other retailers, along with discussions on sites like Reddit. We also checked out what other publications had to say on the matter before narrowing down our options. Here’s the full list of every tracker we tested: Apple AirTag Chipolo Card Spot Chipolo One Spot Chipolo One Chipolo Card Chipolo Loop Chipolo Pop HyperShield KeySmart SmartLock Motorola Moto Tag Pebblebee Clip 5 Pebblebee Clip Universal Pebblebee Clip Samsung SmartTag 2 Chipolo One Point Pebblebee Clip for Android Tile Pro (2024) Tile Mate (2024) Tile Mate (2022) Tile Pro (2022) Tile Slim (2022) After acquiring the trackers, I tested each one over the course of a few weeks using both an iPhone 11 followed by an iPhone 16 and a Samsung Galaxy S22 then an S23 Ultra. I recreated likely user experiences, such as losing and leaving items behind at home and out in the city. I planted trackers at different spots near downtown Albuquerque, mostly concentrated in and around the University of New Mexico and the surrounding neighborhood of Nob Hill. Later, I conducted tests in the Queen Anne neighborhood of Seattle. Each test was performed multiple times, both while walking and driving and I used the measure distance feature on Google Maps to track footage for alerts. I paid attention to how easy the app was to use, how reliable the phone-to-tracker connection was and any other perks and drawbacks that came up during regular use. As new trackers come to market, or as we learn of worthy models to try, I'll test them and add the results to this guide. Other Bluetooth trackers we tested Motorola Moto Tag The Moto Tag haunts me. At this very moment, my Galaxy phone says the fob is “Near you right now.” But I don’t know where. I tap to play a sound and the Find Hub tries, but ultimately says it can’t. I tap the Find Nearby function that’s supposed to visually guide you to the tag. I parade my phone around the house like a divining rod, take it down into the basement, walk it all over the garage. Nothing. But the Hub app unendingly says the Moto Tag is “Near you right now” and I get flashes of every old-school horror movie where the telephone operator tells the soon-to-be victim that the call is coming from inside the house. It’s partly my fault. I tend to keep good tabs on the gadgets I test for work. But during my most recent move, the tiny green disc didn’t make it into the safety of my review unit cabinet after relocation. Perhaps in retribution for my neglect, the Moto Tag keeps itself just out of reach. Taunting me. I’ll let you know if I ever find it, but in the meantime, it’s clear this finding device doesn’t want to be found. The recommended tags in this guide will serve you better. Tile Pro and Tile Mate (2024) Tile recently came out with a new suite of trackers, replacing the Tile Mate, Tile Pro, Tile Sticker and Tile Slim with updated models. In addition to fun new colors for the Mate and Slim, Tile added an SOS feature that can send a notification to your Life360 Circle when you triple press the button on the tracker. It’s a clever addition that turns your keys into a panic button, something offered by personal safety companies as standalone devices. There are a few caveats: You and the people you want to notify in an emergency will need the Life360 app installed on your phones. If you want your Tile to also trigger a call to emergency services, you’ll need a $15-per-month Life360 subscription (that’s in addition to a Tile membership, which starts at $3/month or $30 annually). And enabling the SOS triple-press disables the ability to ring your phone with the fob. I tested the SOS feature and it did indeed send a text message to my Circle, with the message that I had triggered an SOS and a link to a website that showed my current location. I thought it odd that the link didn’t open the Life360 app (which shows the location of users' phones), but I wasn’t as much concerned with Tile’s personal safety features as I was with the tracking capabilities, which turned out to be less than ideal. For my tests, I planted Tile trackers in a densely populated area of Seattle (about 15,000 people per square mile). After setting the trackers to “lost” in the Tile app, I waited. After four hours, one of the trackers was not discovered by the finding community, so I went and retrieved it. Another fob I planted alerted me that the tracker had been found by the Tile community after three hours — but the location it gave me was off by a third of a mile. I then decided to plant a tracker in the busiest place I could think of — the dried fruit and nuts aisle of a Trader Joes on a Friday evening before a major holiday. It still took over a half an hour before another Tile user anonymously pinged my lost tracker. In my tests with Samsung’s trackers and the fobs on Google’s Find Hub network, it took around ten minutes for them to be discovered. AirTags took half that time and all were tested in a far less populated city. Tile's four hours with no ping and over a half hour before getting a hit in a crowded TJs were pretty long stretches. Tile devices work with both mobile operating systems and its latest models are indeed louder than they were before. But they aren’t as quick to connect and you need to pay for a membership to activate left-behind alerts. And when you do, those notifications don’t kick in as quickly as they do with competing trackers. Bluetooth tracker FAQs Which Bluetooth tracker has the longest range? Both the Tile Pro and the Samsung Galaxy SmartTag2 claim a maximum range of around 400 feet, which is longer than the 300-foot claim for Chipolo’s Pop tags. The Pebblebee Clip 5 claims a 500-foot range, though other trackers with a shorter claimed range often performed better in our tests. Apple doesn’t make range claims for AirTags, but 30 meters (100 feet) seems to be the general consensus for those fobs. Any Bluetooth signal, of course, is dependent on a few factors. Obstacles like walls and people can block the signal, so a clear line of sight is the only way to achieve the maximum range. Other signals, like Wi-Fi, can also interfere with Bluetooth connections. Even high humidity can have an effect and lessen the distance at which your phone will connect to your tracker. Remember, when considering the range of Bluetooth trackers, the size of the “finding network” also comes into play. This is the number of nearby phones that can be used to anonymously ping your tracker when your own phone is out of Bluetooth range. As of now, Apple AirTags have the largest network, followed by Google’s Find Hub, Samsung’s finding community and finally, Tile’s Life360 members. What is the best Bluetooth tracker for a car? Bluetooth trackers are designed to track small, personal items like keys, jackets, backpacks and the like. All trackers have safeguards to prohibit the tag from being used to stalk people, so most will alert someone if a tracker that does not belong to them is detected following them. That means a car thief may get tipped off that there’s a tracker in the car they’re trying to steal. That said, you’ll see plenty of stories about people finding their car thanks to a Bluetooth tracker. Some police departments have even handed out trackers to combat high rates of carjacking. In most instances, the tracker of choice has been AirTags thanks to their wide finding network. If you’re looking for a tracker for your car, you may want to look into GPS trackers, some of which are designed for just that purpose. How accurate are Bluetooth trackers? Accuracy for Bluetooth trackers can be looked at in two ways: Finding items nearby and finding items misplaced outside your home. For nearby items, you’ll most often use the ring function on the device to hunt it down. Apple’s AirTags also use ultra-wideband technology, which creates directional navigation on your phone to get you within a foot of the tracker. Accurately finding lost items outside your home depends on the size of the finding network. Since this relies on the serendipity of a random phone passing within Bluetooth range of your tracker, the more phones on a given network, the better. And since Bluetooth ranges and distance estimates are only precise within about a meter or so, getting pings from more than one phone will help locating items. Here again, it’s worth noting that Apple’s Find My network is the largest, followed by Google, Samsung and Tile (both Chipolo and Pebblebee have fobs that work with the Apple and Google networks). Recent Updates February 2026: Added Pebblebee Clip 5 as the best rechargeable device. Added HyperShield tag as a budget pick. Updated FAQs for accuracy. October 2025: Added Chipolo Loop as a new pick for best rechargeable Bluetooth tracker. Detailed our experience with the Moto Tag and KeySmart SmartLock. Updated details about separation alerts and Ultra Wideband tech. August 2025: Updated the name of Google's finding network to Find Hub, instead of Find My Device. Added details about Pebblebee's new Alert feature. Added a table of contents. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-bluetooth-tracker-140028377.html?src=rss",
          "feed_position": 25,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-02/94489620-abc7-11ed-b375-842957054bf1"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/openai-launches-a-codex-desktop-app-for-macos-to-run-multiple-ai-coding",
          "published_at": "Mon, 02 Feb 2026 18:00:00 GMT",
          "title": "OpenAI launches a Codex desktop app for macOS to run multiple AI coding agents in parallel",
          "standfirst": "OpenAI on Monday released a new desktop application for its Codex artificial intelligence coding system, a tool the company says transforms software development from a collaborative exercise with a single AI assistant into something more akin to managing a team of autonomous workers.The Codex app for macOS functions as what OpenAI executives describe as a \"command center for agents,\" allowing developers to delegate multiple coding tasks simultaneously, automate repetitive work, and supervise AI systems that can run for up to 30 minutes independently before returning completed code.\"This is the most loved internal product we&#x27;ve ever had,\" Sam Altman, OpenAI&#x27;s chief executive, told VentureBeat in a press briefing ahead of Monday&#x27;s launch. \"It&#x27;s been totally an amazing thing for us to be using recently at OpenAI.\"The release arrives at a pivotal moment for the enterprise AI market. According to a survey of 100 Global 2000 companies published last week by venture capital firm Andreessen Horowitz, 78% of enterprise CIOs now use OpenAI models in production, though competitors Anthropic and Google are gaining ground rapidly. Anthropic posted the largest share increase of any frontier lab since May 2025, growing 25% in enterprise penetration, with 44% of enterprises now using Anthropic in production.The timing of OpenAI&#x27;s Codex app launch — with its focus on professional software engineering workflows — appears designed to defend the company&#x27;s position in what has become the most contested segment of the AI market: coding tools.Why developers are abandoning their IDEs for AI agent managementThe Codex app introduces a fundamentally different approach to AI-assisted coding. While previous tools like GitHub Copilot focused on autocompleting lines of code in real-time, the new application enables developers to \"effortlessly manage multiple agents at once, run work in parallel, and collaborate with agents over long-running tasks.\"Alexander Embiricos, the product lead for Codex, explained the evolution during the press briefing by tracing the product&#x27;s lineage back to 2021, when OpenAI first introduced a model called Codex that powered GitHub Copilot.\"Back then, people were using AI to write small chunks of code in their IDEs,\" Embiricos said. \"GPT-5 in August last year was a big jump, and then 5.2 in December was another massive jump, where people started doing longer and longer tasks, asking models to do work end to end. So what we saw is that developers, instead of working closely with the model, pair coding, they started delegating entire features.\"The shift has been so profound that Altman said he recently completed a substantial coding project without ever opening a traditional integrated development environment.\"I was astonished by this…I did this fairly big project in a few days earlier this week and over the weekend. I did not open an IDE during the process. Not a single time,\" Altman said. \"I did look at some code, but I was not doing it the old-fashioned way, and I did not think that was going to be happening by now.\"How skills and automations extend AI coding beyond simple code generationThe Codex app introduces several new capabilities designed to extend AI coding beyond writing lines of code. Chief among these are \"Skills,\" which bundle instructions, resources, and scripts so that Codex can \"reliably connect to tools, run workflows, and complete tasks according to your team&#x27;s preferences.\"The app includes a dedicated interface for creating and managing skills, and users can explicitly invoke specific skills or allow the system to automatically select them based on the task at hand. OpenAI has published a library of skills for common workflows, including tools to fetch design context from Figma, manage projects in Linear, deploy web applications to cloud hosts like Cloudflare and Vercel, generate images using GPT Image, and create professional documents in PDF, spreadsheet, and Word formats.To demonstrate the system&#x27;s capabilities, OpenAI asked Codex to build a racing game from a single prompt. Using an image generation skill and a web game development skill, Codex built the game by working independently using more than 7 million tokens with just one initial user prompt, taking on \"the roles of designer, game developer, and QA tester to validate its work by actually playing the game.\"The company has also introduced \"Automations,\" which allow developers to schedule Codex to work in the background on an automatic schedule. \"When an Automation finishes, the results land in a review queue so you can jump back in and continue working if needed.\"Thibault Sottiaux, who leads the Codex team at OpenAI, described how the company uses these automations internally: \"We&#x27;ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more.\"The app also includes built-in support for \"worktrees,\" allowing multiple agents to work on the same repository without conflicts. \"Each agent works on an isolated copy of your code, allowing you to explore different paths without needing to track how they impact your codebase.\"OpenAI battles Anthropic and Google for control of enterprise AI spendingThe launch comes as enterprise spending on AI coding tools accelerates dramatically. According to the Andreessen Horowitz survey, average enterprise AI spend on large language models has risen from approximately $4.5 million to $7 million over the last two years, with enterprises expecting growth of another 65% this year to approximately $11.6 million.Leadership in the enterprise AI market varies significantly by use case. OpenAI dominates \"early, horizontal use cases like general purpose chatbots, enterprise knowledge management and customer support,\" while Anthropic leads in \"software development and data analysis, where CIOs consistently cite rapid capability gains since the second half of 2024.\"When asked during the press briefing how Codex differentiates from Anthropic&#x27;s Claude Code, which has been described as having its \"ChatGPT moment,\" Sottiaux emphasized OpenAI&#x27;s focus on model capability for long-running tasks.\"One of the things that our models are extremely good at—they really sit at the frontier of intelligence and doing reliable work for long periods of time,\" Sottiaux said. \"This is also what we&#x27;re optimizing this new surface to be very good at, so that you can start many parallel agents and coordinate them over long periods of time and not get lost.\"Altman added that while many tools can handle \"vibe coding front ends,\" OpenAI&#x27;s 5.2 model remains \"the strongest model by far\" for sophisticated work on complex systems.\"Taking that level of model capability and putting it in an interface where you can do what Thibault was saying, we think is going to matter quite a bit,\" Altman said. \"That&#x27;s probably the, at least listening to users and sort of looking at the chatter on social that&#x27;s that&#x27;s the single biggest differentiator.\"The surprising satisfies on AI progress: how fast humans can typeThe philosophical underpinning of the Codex app reflects a view that OpenAI executives have been articulating for months: that human limitations — not AI capabilities — now constitute the primary constraint on productivity.In a December appearance on Lenny’s Podcast, Embiricos described human typing speed as \"the current underappreciated limiting factor\" to achieving artificial general intelligence. The logic: if AI can perform complex coding tasks but humans can&#x27;t write prompts or review outputs fast enough, progress stalls.The Codex app attempts to address this by enabling what the team calls an \"abundance mindset\" — running multiple tasks in parallel rather than perfecting single requests. During the briefing, Embiricos described how power users at OpenAI work with the tool.\"Last night, I was working on the app, and I was making a few changes, and all of these changes are able to run in parallel together. And I was just sort of going between them, managing them,\" Embiricos said. \"Behind the scenes, all these tasks are running on something called gate work trees, which means that the agents are running independently, and you don&#x27;t have to manage them.\"In the Sequoia Capital podcast \"Training Data,\" Embiricos elaborated on this mindset shift: \"The mindset that works really well for Codex is, like, kind of like this abundance mindset and, like, hey, let&#x27;s try anything. Let&#x27;s try anything even multiple times and see what works.\" He noted that when users run 20 or more tasks in a day or an hour, \"they&#x27;ve probably understood basically how to use the tool.\"Building trust through sandboxes: how OpenAI secures autonomous coding agentsOpenAI has built security measures into the Codex architecture from the ground up. The app uses \"native, open-source and configurable system-level sandboxing,\" and by default, \"Codex agents are limited to editing files in the folder or branch where they&#x27;re working and using cached web search, then asking for permission to run commands that require elevated permissions like network access.\"Embiricos elaborated on the security approach during the briefing, noting that OpenAI has open-sourced its sandbox technology.\"Codex has this sandbox that we&#x27;re actually incredibly proud of, and it&#x27;s open source, so you can go check it out,\" Embiricos said. The sandbox \"basically ensures that when the agent is working on your computer, it can only make writes in a specific folder that you want it to make rights into, and it doesn&#x27;t access network without information.\"The system also includes a granular permission model that allows users to configure persistent approvals for specific actions, avoiding the need to repeatedly authorize routine operations. \"If the agent wants to do something and you find yourself annoyed that you&#x27;re constantly having to approve it, instead of just saying, &#x27;All right, you can do everything,&#x27; you can just say, &#x27;Hey, remember this one thing — I&#x27;m actually okay with you doing this going forward,&#x27;\" Embiricos explained.Altman emphasized that the permission architecture signals a broader philosophy about AI safety in agentic systems.\"I think this is going to be really important. I mean, it&#x27;s been so clear to us using this, how much you want it to have control of your computer, and how much you need it,\" Altman said. \"And the way the team built Codex such that you can sensibly limit what&#x27;s happening and also pick the level of control you&#x27;re comfortable with is important.\"He also acknowledged the dual-use nature of the technology. \"We do expect to get to our internal cybersecurity high moment of our models very soon. We&#x27;ve been preparing for this. We&#x27;ve talked about our mitigation plan,\" Altman said. \"A real thing for the world to contend with is going to be defending against a lot of capable cybersecurity threats using these models very quickly.\"The same capabilities that make Codex valuable for fixing bugs and refactoring code could, in the wrong hands, be used to discover vulnerabilities or write malicious software—a tension that will only intensify as AI coding agents become more capable.From Android apps to research breakthroughs: how Codex transformed OpenAI&#x27;s own operationsPerhaps the most compelling evidence for Codex&#x27;s capabilities comes from OpenAI&#x27;s own use of the tool. Sottiaux described how the system has accelerated internal development.\"A Sora Android app is an example of that where four engineers shipped in only 18 days internally, and then within the month we give access to the world,\" Sottiaux said. \"I had never noticed such speed at this scale before.\"Beyond product development, Sottiaux described how Codex has become integral to OpenAI&#x27;s research operations.\"Codex is really involved in all parts of the research — making new data sets, investigating its own screening runs,\" he said. \"When I sit in meetings with researchers, they all send Codex off to do an investigation while we&#x27;re having a chat, and then it will come back with useful information, and we&#x27;re able to debug much faster.\"The tool has also begun contributing to its own development. \"Codex also is starting to build itself,\" Sottiaux noted. \"There&#x27;s no screen within the Codex engineering team that doesn&#x27;t have Codex running on multiple, six, eight, ten, tasks at a time.\"When asked whether this constitutes evidence of \"recursive self-improvement\" — a concept that has long concerned AI safety researchers — Sottiaux was measured in his response.\"There is a human in the loop at all times,\" he said. \"I wouldn&#x27;t necessarily call it recursive self-improvement, a glimpse into the future there.\"Altman offered a more expansive view of the research implications.\"There&#x27;s two parts of what people talk about when they talk about automating research to a degree where you can imagine that happening,\" Altman said. \"One is, can you write software, extremely complex infrastructure, software to run training jobs across hundreds of thousands of GPUs and babysit them. And the second is, can you come up with the new scientific ideas that make algorithms more efficient.\"He noted that OpenAI is \"seeing early but promising signs on both of those.\"The end of technical debt? AI agents take on the work engineers hate mostOne of the more unexpected applications of Codex has been addressing technical debt — the accumulated maintenance burden that plagues most software projects.Altman described how AI coding agents excel at the unglamorous work that human engineers typically avoid.\"The kind of work that human engineers hate to do — go refactor this, clean up this code base, rewrite this, write this test — this is where the model doesn&#x27;t care. The model will do anything, whether it&#x27;s fun or not,\" Altman said.He reported that some infrastructure teams at OpenAI that \"had sort of like, given up hope that you were ever really going to long term win the war against tech debt, are now like, we&#x27;re going to win this, because the model is going to constantly be working behind us, making sure we have great test coverage, making sure that we refactor when we&#x27;re supposed to.\"The observation speaks to a broader theme that emerged repeatedly during the briefing: AI coding agents don&#x27;t experience the motivational fluctuations that affect human programmers. As Altman noted, a team member recently observed that \"the hardest mental adjustment to make about working with these sort of like aI coding teammates, unlike a human, is the models just don&#x27;t run out of dopamine. They keep trying. They don&#x27;t run out of motivation. They don&#x27;t get, you know, they don&#x27;t lose energy when something&#x27;s not working. They just keep going and, you know, they figure out how to get it done.\"What the Codex app costs and who can use it starting todayThe Codex app launches today on macOS and is available to anyone with a ChatGPT Plus, Pro, Business, Enterprise, or Edu subscription. Usage is included in ChatGPT subscriptions, with the option to purchase additional credits if needed.In a promotional push, OpenAI is temporarily making Codex available to ChatGPT Free and Go users \"to help more people try agentic workflows.\" The company is also doubling rate limits for existing Codex users across all paid plans during this promotional period.The pricing strategy reflects OpenAI&#x27;s determination to establish Codex as the default tool for AI-assisted development before competitors can gain further traction. More than a million developers have used Codex in the past month, and usage has nearly doubled since the launch of GPT-5.2-Codex in mid-December, building on more than 20x usage growth since August 2025.Customers using Codex include large enterprises like Cisco, Ramp, Virgin Atlantic, Vanta, Duolingo, and Gap, as well as startups like Harvey, Sierra, and Wonderful. Individual developers have also embraced the tool: Peter Steinberger, creator of OpenClaw, built the project entirely with Codex and reports that since fully switching to the tool, his productivity has roughly doubled across more than 82,000 GitHub contributions.OpenAI&#x27;s ambitious roadmap: Windows support, cloud triggers, and continuous background agentsOpenAI outlined an aggressive development roadmap for Codex. The company plans to make the app available on Windows, continue pushing \"the frontier of model capabilities,\" and roll out faster inference.Within the app, OpenAI will \"keep refining multi-agent workflows based on real-world feedback\" and is \"building out Automations with support for cloud-based triggers, so Codex can run continuously in the background—not just when your computer is open.\"The company also announced a new \"plan mode\" feature that allows Codex to read through complex changes in read-only mode, then discuss with the user before executing. \"This means that it lets you build a lot of confidence before, again, sending it to do a lot of work by itself, independently, in parallel to you,\" Embiricos explained.Additionally, OpenAI is introducing customizable personalities for Codex. \"The default personality for Codex has been quite terse. A lot of people love it, but some people want something more engaging,\" Embiricos said. Users can access the new personalities using the /personality command.Altman also hinted at future integration with ChatGPT&#x27;s broader ecosystem.\"There will be all kinds of cool things we can do over time to connect people&#x27;s ChatGPT accounts and leverage sort of all the history they&#x27;ve built up there,\" Altman said.Microsoft still dominates enterprise AI, but the window for disruption is openThe Codex app launch occurs as most enterprises have moved beyond single-vendor strategies. According to the Andreessen Horowitz survey, \"81% now use three or more model families in testing or production, up from 68% less than a year ago.\"Despite the proliferation of AI coding tools, Microsoft continues to dominate enterprise adoption through its existing relationships. \"Microsoft 365 Copilot leads enterprise chat though ChatGPT has closed the gap meaningfully,\" and \"Github Copilot is still the coding leader for enterprises.\" The survey found that \"65% of enterprises noted they preferred to go with incumbent solutions when available,\" citing trust, integration, and procurement simplicity.However, the survey also suggests significant opportunity for challengers: \"Enterprises consistently say they value faster innovation, deeper AI focus, and greater flexibility paired with cutting edge capabilities that AI native startups bring.\"OpenAI appears to be positioning Codex as a bridge between these worlds. \"Codex is built on a simple premise: everything is controlled by code,\" the company stated. \"The better an agent is at reasoning about and producing code, the more capable it becomes across all forms of technical and knowledge work.\"The company&#x27;s ambition extends beyond coding. \"We&#x27;ve focused on making Codex the best coding agent, which has also laid the foundation for it to become a strong agent for a broad range of knowledge work tasks that extend beyond writing code.\"When asked whether AI coding tools could eventually move beyond early adopters to become mainstream, Altman suggested the transition may be closer than many expect.\"Can it go from vibe coding to serious software engineering? That&#x27;s what this is about,\" Altman said. \"I think we are over the bar on that. I think this will be the way that most serious coders do their job — and very rapidly from now.\"He then pivoted to an even bolder prediction: that code itself could become the universal interface for all computer-based work.\"Code is a universal language to get computers to do what you want. And it&#x27;s gotten so good that I think, very quickly, we can go not just from vibe coding silly apps but to doing all the non-coding knowledge work,\" Altman said.At the close of the briefing, Altman urged journalists to try the product themselves: \"Please try the app. There&#x27;s no way to get this across just by talking about it. It&#x27;s a crazy amount of power.\"For developers who have spent careers learning to write code, the message was clear: the future belongs to those who learn to manage the machines that write it for them.",
          "content": "OpenAI on Monday released a new desktop application for its Codex artificial intelligence coding system, a tool the company says transforms software development from a collaborative exercise with a single AI assistant into something more akin to managing a team of autonomous workers.The Codex app for macOS functions as what OpenAI executives describe as a \"command center for agents,\" allowing developers to delegate multiple coding tasks simultaneously, automate repetitive work, and supervise AI systems that can run for up to 30 minutes independently before returning completed code.\"This is the most loved internal product we&#x27;ve ever had,\" Sam Altman, OpenAI&#x27;s chief executive, told VentureBeat in a press briefing ahead of Monday&#x27;s launch. \"It&#x27;s been totally an amazing thing for us to be using recently at OpenAI.\"The release arrives at a pivotal moment for the enterprise AI market. According to a survey of 100 Global 2000 companies published last week by venture capital firm Andreessen Horowitz, 78% of enterprise CIOs now use OpenAI models in production, though competitors Anthropic and Google are gaining ground rapidly. Anthropic posted the largest share increase of any frontier lab since May 2025, growing 25% in enterprise penetration, with 44% of enterprises now using Anthropic in production.The timing of OpenAI&#x27;s Codex app launch — with its focus on professional software engineering workflows — appears designed to defend the company&#x27;s position in what has become the most contested segment of the AI market: coding tools.Why developers are abandoning their IDEs for AI agent managementThe Codex app introduces a fundamentally different approach to AI-assisted coding. While previous tools like GitHub Copilot focused on autocompleting lines of code in real-time, the new application enables developers to \"effortlessly manage multiple agents at once, run work in parallel, and collaborate with agents over long-running tasks.\"Alexander Embiricos, the product lead for Codex, explained the evolution during the press briefing by tracing the product&#x27;s lineage back to 2021, when OpenAI first introduced a model called Codex that powered GitHub Copilot.\"Back then, people were using AI to write small chunks of code in their IDEs,\" Embiricos said. \"GPT-5 in August last year was a big jump, and then 5.2 in December was another massive jump, where people started doing longer and longer tasks, asking models to do work end to end. So what we saw is that developers, instead of working closely with the model, pair coding, they started delegating entire features.\"The shift has been so profound that Altman said he recently completed a substantial coding project without ever opening a traditional integrated development environment.\"I was astonished by this…I did this fairly big project in a few days earlier this week and over the weekend. I did not open an IDE during the process. Not a single time,\" Altman said. \"I did look at some code, but I was not doing it the old-fashioned way, and I did not think that was going to be happening by now.\"How skills and automations extend AI coding beyond simple code generationThe Codex app introduces several new capabilities designed to extend AI coding beyond writing lines of code. Chief among these are \"Skills,\" which bundle instructions, resources, and scripts so that Codex can \"reliably connect to tools, run workflows, and complete tasks according to your team&#x27;s preferences.\"The app includes a dedicated interface for creating and managing skills, and users can explicitly invoke specific skills or allow the system to automatically select them based on the task at hand. OpenAI has published a library of skills for common workflows, including tools to fetch design context from Figma, manage projects in Linear, deploy web applications to cloud hosts like Cloudflare and Vercel, generate images using GPT Image, and create professional documents in PDF, spreadsheet, and Word formats.To demonstrate the system&#x27;s capabilities, OpenAI asked Codex to build a racing game from a single prompt. Using an image generation skill and a web game development skill, Codex built the game by working independently using more than 7 million tokens with just one initial user prompt, taking on \"the roles of designer, game developer, and QA tester to validate its work by actually playing the game.\"The company has also introduced \"Automations,\" which allow developers to schedule Codex to work in the background on an automatic schedule. \"When an Automation finishes, the results land in a review queue so you can jump back in and continue working if needed.\"Thibault Sottiaux, who leads the Codex team at OpenAI, described how the company uses these automations internally: \"We&#x27;ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more.\"The app also includes built-in support for \"worktrees,\" allowing multiple agents to work on the same repository without conflicts. \"Each agent works on an isolated copy of your code, allowing you to explore different paths without needing to track how they impact your codebase.\"OpenAI battles Anthropic and Google for control of enterprise AI spendingThe launch comes as enterprise spending on AI coding tools accelerates dramatically. According to the Andreessen Horowitz survey, average enterprise AI spend on large language models has risen from approximately $4.5 million to $7 million over the last two years, with enterprises expecting growth of another 65% this year to approximately $11.6 million.Leadership in the enterprise AI market varies significantly by use case. OpenAI dominates \"early, horizontal use cases like general purpose chatbots, enterprise knowledge management and customer support,\" while Anthropic leads in \"software development and data analysis, where CIOs consistently cite rapid capability gains since the second half of 2024.\"When asked during the press briefing how Codex differentiates from Anthropic&#x27;s Claude Code, which has been described as having its \"ChatGPT moment,\" Sottiaux emphasized OpenAI&#x27;s focus on model capability for long-running tasks.\"One of the things that our models are extremely good at—they really sit at the frontier of intelligence and doing reliable work for long periods of time,\" Sottiaux said. \"This is also what we&#x27;re optimizing this new surface to be very good at, so that you can start many parallel agents and coordinate them over long periods of time and not get lost.\"Altman added that while many tools can handle \"vibe coding front ends,\" OpenAI&#x27;s 5.2 model remains \"the strongest model by far\" for sophisticated work on complex systems.\"Taking that level of model capability and putting it in an interface where you can do what Thibault was saying, we think is going to matter quite a bit,\" Altman said. \"That&#x27;s probably the, at least listening to users and sort of looking at the chatter on social that&#x27;s that&#x27;s the single biggest differentiator.\"The surprising satisfies on AI progress: how fast humans can typeThe philosophical underpinning of the Codex app reflects a view that OpenAI executives have been articulating for months: that human limitations — not AI capabilities — now constitute the primary constraint on productivity.In a December appearance on Lenny’s Podcast, Embiricos described human typing speed as \"the current underappreciated limiting factor\" to achieving artificial general intelligence. The logic: if AI can perform complex coding tasks but humans can&#x27;t write prompts or review outputs fast enough, progress stalls.The Codex app attempts to address this by enabling what the team calls an \"abundance mindset\" — running multiple tasks in parallel rather than perfecting single requests. During the briefing, Embiricos described how power users at OpenAI work with the tool.\"Last night, I was working on the app, and I was making a few changes, and all of these changes are able to run in parallel together. And I was just sort of going between them, managing them,\" Embiricos said. \"Behind the scenes, all these tasks are running on something called gate work trees, which means that the agents are running independently, and you don&#x27;t have to manage them.\"In the Sequoia Capital podcast \"Training Data,\" Embiricos elaborated on this mindset shift: \"The mindset that works really well for Codex is, like, kind of like this abundance mindset and, like, hey, let&#x27;s try anything. Let&#x27;s try anything even multiple times and see what works.\" He noted that when users run 20 or more tasks in a day or an hour, \"they&#x27;ve probably understood basically how to use the tool.\"Building trust through sandboxes: how OpenAI secures autonomous coding agentsOpenAI has built security measures into the Codex architecture from the ground up. The app uses \"native, open-source and configurable system-level sandboxing,\" and by default, \"Codex agents are limited to editing files in the folder or branch where they&#x27;re working and using cached web search, then asking for permission to run commands that require elevated permissions like network access.\"Embiricos elaborated on the security approach during the briefing, noting that OpenAI has open-sourced its sandbox technology.\"Codex has this sandbox that we&#x27;re actually incredibly proud of, and it&#x27;s open source, so you can go check it out,\" Embiricos said. The sandbox \"basically ensures that when the agent is working on your computer, it can only make writes in a specific folder that you want it to make rights into, and it doesn&#x27;t access network without information.\"The system also includes a granular permission model that allows users to configure persistent approvals for specific actions, avoiding the need to repeatedly authorize routine operations. \"If the agent wants to do something and you find yourself annoyed that you&#x27;re constantly having to approve it, instead of just saying, &#x27;All right, you can do everything,&#x27; you can just say, &#x27;Hey, remember this one thing — I&#x27;m actually okay with you doing this going forward,&#x27;\" Embiricos explained.Altman emphasized that the permission architecture signals a broader philosophy about AI safety in agentic systems.\"I think this is going to be really important. I mean, it&#x27;s been so clear to us using this, how much you want it to have control of your computer, and how much you need it,\" Altman said. \"And the way the team built Codex such that you can sensibly limit what&#x27;s happening and also pick the level of control you&#x27;re comfortable with is important.\"He also acknowledged the dual-use nature of the technology. \"We do expect to get to our internal cybersecurity high moment of our models very soon. We&#x27;ve been preparing for this. We&#x27;ve talked about our mitigation plan,\" Altman said. \"A real thing for the world to contend with is going to be defending against a lot of capable cybersecurity threats using these models very quickly.\"The same capabilities that make Codex valuable for fixing bugs and refactoring code could, in the wrong hands, be used to discover vulnerabilities or write malicious software—a tension that will only intensify as AI coding agents become more capable.From Android apps to research breakthroughs: how Codex transformed OpenAI&#x27;s own operationsPerhaps the most compelling evidence for Codex&#x27;s capabilities comes from OpenAI&#x27;s own use of the tool. Sottiaux described how the system has accelerated internal development.\"A Sora Android app is an example of that where four engineers shipped in only 18 days internally, and then within the month we give access to the world,\" Sottiaux said. \"I had never noticed such speed at this scale before.\"Beyond product development, Sottiaux described how Codex has become integral to OpenAI&#x27;s research operations.\"Codex is really involved in all parts of the research — making new data sets, investigating its own screening runs,\" he said. \"When I sit in meetings with researchers, they all send Codex off to do an investigation while we&#x27;re having a chat, and then it will come back with useful information, and we&#x27;re able to debug much faster.\"The tool has also begun contributing to its own development. \"Codex also is starting to build itself,\" Sottiaux noted. \"There&#x27;s no screen within the Codex engineering team that doesn&#x27;t have Codex running on multiple, six, eight, ten, tasks at a time.\"When asked whether this constitutes evidence of \"recursive self-improvement\" — a concept that has long concerned AI safety researchers — Sottiaux was measured in his response.\"There is a human in the loop at all times,\" he said. \"I wouldn&#x27;t necessarily call it recursive self-improvement, a glimpse into the future there.\"Altman offered a more expansive view of the research implications.\"There&#x27;s two parts of what people talk about when they talk about automating research to a degree where you can imagine that happening,\" Altman said. \"One is, can you write software, extremely complex infrastructure, software to run training jobs across hundreds of thousands of GPUs and babysit them. And the second is, can you come up with the new scientific ideas that make algorithms more efficient.\"He noted that OpenAI is \"seeing early but promising signs on both of those.\"The end of technical debt? AI agents take on the work engineers hate mostOne of the more unexpected applications of Codex has been addressing technical debt — the accumulated maintenance burden that plagues most software projects.Altman described how AI coding agents excel at the unglamorous work that human engineers typically avoid.\"The kind of work that human engineers hate to do — go refactor this, clean up this code base, rewrite this, write this test — this is where the model doesn&#x27;t care. The model will do anything, whether it&#x27;s fun or not,\" Altman said.He reported that some infrastructure teams at OpenAI that \"had sort of like, given up hope that you were ever really going to long term win the war against tech debt, are now like, we&#x27;re going to win this, because the model is going to constantly be working behind us, making sure we have great test coverage, making sure that we refactor when we&#x27;re supposed to.\"The observation speaks to a broader theme that emerged repeatedly during the briefing: AI coding agents don&#x27;t experience the motivational fluctuations that affect human programmers. As Altman noted, a team member recently observed that \"the hardest mental adjustment to make about working with these sort of like aI coding teammates, unlike a human, is the models just don&#x27;t run out of dopamine. They keep trying. They don&#x27;t run out of motivation. They don&#x27;t get, you know, they don&#x27;t lose energy when something&#x27;s not working. They just keep going and, you know, they figure out how to get it done.\"What the Codex app costs and who can use it starting todayThe Codex app launches today on macOS and is available to anyone with a ChatGPT Plus, Pro, Business, Enterprise, or Edu subscription. Usage is included in ChatGPT subscriptions, with the option to purchase additional credits if needed.In a promotional push, OpenAI is temporarily making Codex available to ChatGPT Free and Go users \"to help more people try agentic workflows.\" The company is also doubling rate limits for existing Codex users across all paid plans during this promotional period.The pricing strategy reflects OpenAI&#x27;s determination to establish Codex as the default tool for AI-assisted development before competitors can gain further traction. More than a million developers have used Codex in the past month, and usage has nearly doubled since the launch of GPT-5.2-Codex in mid-December, building on more than 20x usage growth since August 2025.Customers using Codex include large enterprises like Cisco, Ramp, Virgin Atlantic, Vanta, Duolingo, and Gap, as well as startups like Harvey, Sierra, and Wonderful. Individual developers have also embraced the tool: Peter Steinberger, creator of OpenClaw, built the project entirely with Codex and reports that since fully switching to the tool, his productivity has roughly doubled across more than 82,000 GitHub contributions.OpenAI&#x27;s ambitious roadmap: Windows support, cloud triggers, and continuous background agentsOpenAI outlined an aggressive development roadmap for Codex. The company plans to make the app available on Windows, continue pushing \"the frontier of model capabilities,\" and roll out faster inference.Within the app, OpenAI will \"keep refining multi-agent workflows based on real-world feedback\" and is \"building out Automations with support for cloud-based triggers, so Codex can run continuously in the background—not just when your computer is open.\"The company also announced a new \"plan mode\" feature that allows Codex to read through complex changes in read-only mode, then discuss with the user before executing. \"This means that it lets you build a lot of confidence before, again, sending it to do a lot of work by itself, independently, in parallel to you,\" Embiricos explained.Additionally, OpenAI is introducing customizable personalities for Codex. \"The default personality for Codex has been quite terse. A lot of people love it, but some people want something more engaging,\" Embiricos said. Users can access the new personalities using the /personality command.Altman also hinted at future integration with ChatGPT&#x27;s broader ecosystem.\"There will be all kinds of cool things we can do over time to connect people&#x27;s ChatGPT accounts and leverage sort of all the history they&#x27;ve built up there,\" Altman said.Microsoft still dominates enterprise AI, but the window for disruption is openThe Codex app launch occurs as most enterprises have moved beyond single-vendor strategies. According to the Andreessen Horowitz survey, \"81% now use three or more model families in testing or production, up from 68% less than a year ago.\"Despite the proliferation of AI coding tools, Microsoft continues to dominate enterprise adoption through its existing relationships. \"Microsoft 365 Copilot leads enterprise chat though ChatGPT has closed the gap meaningfully,\" and \"Github Copilot is still the coding leader for enterprises.\" The survey found that \"65% of enterprises noted they preferred to go with incumbent solutions when available,\" citing trust, integration, and procurement simplicity.However, the survey also suggests significant opportunity for challengers: \"Enterprises consistently say they value faster innovation, deeper AI focus, and greater flexibility paired with cutting edge capabilities that AI native startups bring.\"OpenAI appears to be positioning Codex as a bridge between these worlds. \"Codex is built on a simple premise: everything is controlled by code,\" the company stated. \"The better an agent is at reasoning about and producing code, the more capable it becomes across all forms of technical and knowledge work.\"The company&#x27;s ambition extends beyond coding. \"We&#x27;ve focused on making Codex the best coding agent, which has also laid the foundation for it to become a strong agent for a broad range of knowledge work tasks that extend beyond writing code.\"When asked whether AI coding tools could eventually move beyond early adopters to become mainstream, Altman suggested the transition may be closer than many expect.\"Can it go from vibe coding to serious software engineering? That&#x27;s what this is about,\" Altman said. \"I think we are over the bar on that. I think this will be the way that most serious coders do their job — and very rapidly from now.\"He then pivoted to an even bolder prediction: that code itself could become the universal interface for all computer-based work.\"Code is a universal language to get computers to do what you want. And it&#x27;s gotten so good that I think, very quickly, we can go not just from vibe coding silly apps but to doing all the non-coding knowledge work,\" Altman said.At the close of the briefing, Altman urged journalists to try the product themselves: \"Please try the app. There&#x27;s no way to get this across just by talking about it. It&#x27;s a crazy amount of power.\"For developers who have spent careers learning to write code, the message was clear: the future belongs to those who learn to manage the machines that write it for them.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5ixq6lS6l5yrO3RJxCtr5w/c11ddd394c8969826452a5a30312234b/nuneybits_Vector_art_of_an_Apple_iMac_monitor_displaying_cascad_ecce1621-251d-41d9-ac6e-72eb25b2fd35.webp?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/469ZkXofQMti2royetGH8u/756e2b7f0b026e2b48d72bf886cd7868/database-in-a-lake-smk1.jpg?w=300&q=30",
      "popularity_score": 2017.2592847222222,
      "ai_summary": [
        "Databricks introduces Lakebase service for app development",
        "Service aims to reduce app development time from months to days",
        "Lakebase uses technology from acquired companies",
        "Early adopters report significant reduction in delivery times",
        "Service positions databases as ephemeral infrastructure for AI"
      ]
    },
    {
      "id": "cluster_82",
      "coverage": 2,
      "updated_at": "2026-02-03T09:53:18-05:00",
      "title": "China is banning hidden electric door handles for EVs",
      "neutral_headline": "China bans hidden electric door handles for EVs",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/transportation/873039/china-ban-hidden-tesla-door-handles-january-2027",
          "published_at": "2026-02-03T09:53:18-05:00",
          "title": "China is banning hidden electric door handles for EVs",
          "standfirst": "China is banning Tesla-style concealed door handles on electric vehicles to address safety concerns regarding people getting trapped inside their cars. The ban will take effect on January 1st next year, according to the Ministry of Industry and Information Technology's announcement, and will require all vehicles sold in China to have mechanical release door handles [&#8230;]",
          "content": "Close-up of flush-mounted, retracting door handle on Tesla automobile, San Ramon, California, in September of 2020. | Gado via Getty Images China is banning Tesla-style concealed door handles on electric vehicles to address safety concerns regarding people getting trapped inside their cars. The ban will take effect on January 1st next year, according to the Ministry of Industry and Information Technology's announcement, and will require all vehicles sold in China to have mechanical release door handles on the inside and outside. The ban specifically targets hidden handles that retract to sit flush with vehicle doors, a design popularized by Tesla and has since been adopted by other EV makers. According to China Daily, more than 60 percent of the top 100 hybrid and electric vehi … Read the full story at The Verge.",
          "feed_position": 8
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/02/china-is-leading-the-fight-against-hidden-car-door-handles/",
          "published_at": "Mon, 02 Feb 2026 21:55:38 +0000",
          "title": "China is leading the fight against hidden car door handles",
          "standfirst": "Under new safety rules published Monday by China's Ministry of Industry and Information Technology, cars sold in the country must have mechanical releases on their door handles. The new rules, which go in effect January 1, 2027, will prohibit the hidden, electronically actuated door handles popularized by Tesla — and now found on numerous other electric vehicles in China.",
          "content": "Under new safety rules published Monday by China's Ministry of Industry and Information Technology, cars sold in the country must have mechanical releases on their door handles. The new rules, which go in effect January 1, 2027, will prohibit the hidden, electronically actuated door handles popularized by Tesla — and now found on numerous other electric vehicles in China.",
          "feed_position": 19
        }
      ],
      "popularity_score": 2015.1476180555555,
      "ai_summary": [
        "China prohibits concealed door handles on electric vehicles",
        "Ban takes effect on January 1st next year",
        "Mechanical release door handles now required",
        "Safety concerns cited as reason for ban",
        "Manufacturers must comply with new regulations"
      ]
    },
    {
      "id": "cluster_22",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 18:25:18 +0000",
      "title": "Google court filings suggest ChromeOS has an expiration date",
      "neutral_headline": "Google court filings suggest ChromeOS expiration",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/02/google-court-filings-suggest-googles-chromeos-has-an-expiration-date/",
          "published_at": "Tue, 03 Feb 2026 18:25:18 +0000",
          "title": "Google court filings suggest ChromeOS has an expiration date",
          "standfirst": "ChromeOS may be canned once the current support guarantee has run its course.",
          "content": "Chromebooks debuted 16 years ago with the limited release of Google's Cr-48, an unassuming compact laptop that was provided free to select users. From there, Chromebooks became one of the most popular budget computing options and a common fixture in schools and businesses. According to some newly uncovered court documents, Google's shift to Android PCs means Chromebooks have an expiration date in 2034. The documents were filed as part of Google's long-running search antitrust case, which began in 2020 and reached a verdict in 2024. While Google is still seeking to have the guilty verdict overturned, it has escaped most of the remedies that government prosecutors requested. According to The Verge, the company's plans for Chromebooks and the upcoming Android-based Aluminium came up in filings from the remedy phase of the trial. As Google moves toward releasing Aluminium, it sought to keep the upcoming machines above the fray and retain the Chrome browser (which it did). In Judge Amit Mehta's final order, devices running ChromeOS or a ChromeOS successor are excluded. To get there, Google had to provide a little more detail on its plans.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/9_Lenovo-Chromebook-Plus-14-copy-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/9_Lenovo-Chromebook-Plus-14-copy-1152x648.jpg",
      "popularity_score": 353.6809513888889,
      "ai_summary": [
        "ChromeOS may be discontinued after support guarantee ends",
        "Google court filings hint at potential expiration date",
        "ChromeOS support guarantee currently in place",
        "Expiration could impact users and developers",
        "Google has not officially commented on ChromeOS future"
      ]
    },
    {
      "id": "cluster_10",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 18:56:20 +0000",
      "title": "Original Nintendo Switch passes the DS to become Nintendo's bestselling console",
      "neutral_headline": "Nintendo Switch becomes bestselling console",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/original-nintendo-switch-passes-the-ds-to-become-nintendos-bestselling-console/",
          "published_at": "Tue, 03 Feb 2026 18:56:20 +0000",
          "title": "Original Nintendo Switch passes the DS to become Nintendo's bestselling console",
          "standfirst": "Switch 2 has already beaten the Wii U and is on its way to overtaking GameCube.",
          "content": "Though it was finally replaced last year by the new Switch 2, the orginal switch isn't done just yet. Many recent Switch games (and a handful of major updates, like the one for Animal Crossing) have been released in both Switch and Switch 2 editions, and Nintendo continues to sell all editions of the original console as entry-level systems for those who can't pay $450 for a Switch 2. The nine-year-old Switch's continued availability has helped it clear a milestone, according to the company's third-quarter financial results (PDF). As of December 31, 2025, Nintendo says the Switch \"has reached the highest sales volume of any Nintendo hardware\" with a total of 155.37 million units sold, surpassing the original DS's lifetime total of 154.02 million units. The console has sold 3.25 million units in Nintendo's fiscal 2026 so far, including 1.36 million units over the holidays. Those consoles have sold despite price hikes that Nintendo introduced in August of 2025, citing \"market conditions.\" That makes the Switch the second-bestselling game console of all time, just three years after it became the third-bestselling game console of all time. The only frontier left for the Switch to conquer is Sony's PlayStation 2, which Sony says sold \"over 160 million units\" over its long life. At its current sales rate (Nintendo predicts it will sell roughly 750,000 Switches in the next quarter), it would take the Switch another couple of years to cross that line, but those numbers are likely to taper off as we get deeper into the Switch 2 era.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/07/NintendoSwitchOLEDmodel_02-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/07/NintendoSwitchOLEDmodel_02-1152x648.jpg",
      "popularity_score": 352.1981736111111,
      "ai_summary": [
        "Original Nintendo Switch passes DS sales record",
        "Switch becomes Nintendo's bestselling console",
        "Switch 2 has already surpassed Wii U sales",
        "Console on track to overtake GameCube sales",
        "Nintendo's success attributed to popular games and hardware"
      ]
    },
    {
      "id": "cluster_27",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 18:01:49 +0000",
      "title": "Xcode 26.3 adds support for Claude, Codex, and other agentic tools via MCP",
      "neutral_headline": "Xcode update adds support for agentic tools",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/apple/2026/02/xcode-26-3-adds-support-for-claude-codex-and-other-agentic-tools-via-mcp/",
          "published_at": "Tue, 03 Feb 2026 18:01:49 +0000",
          "title": "Xcode 26.3 adds support for Claude, Codex, and other agentic tools via MCP",
          "standfirst": "With Model Context Protocol (MCP), this works with more than Codex/Claude, too.",
          "content": "Apple has announced a new version of Xcode, the latest version of its integrated development environment (IDE) for building software for its own platforms, like the iPhone and Mac. The key feature of 26.3 is support for full-fledged agentic coding tools, like OpenAI's Codex or Claude Agent, with a side panel interface for assigning tasks to agents with prompts and tracking their progress and changes. This is achieved via Model Context Protocol (MCP), an open protocol that lets AI agents work with external tools and structured resources. Xcode acts as an MCP endpoint that exposes a bunch of machine-invocable interfaces and gives AI tools like Codex or Claude Agent access to a wide range of IDE primitives like file graph, docs search, project settings, and so on. While AI chat and workflows were supported in Xcode before, this release gives them much deeper access to the features and capabilities of Xcode. This approach is notable because it means that even though OpenAI and Anthropic's model integrations are privileged with a dedicated spot in Xcode's settings, it's possible to connect other tooling that supports MCP, which also allows doing some of this with models running locally.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Xcode-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Xcode-1152x648.png",
      "popularity_score": 331.2895625,
      "ai_summary": [
        "Xcode 26.3 includes support for Claude and Codex",
        "Model Context Protocol enables integration with tools",
        "Update enhances development capabilities for users",
        "Support for agentic tools expands Xcode functionality",
        "Developers can now use Xcode with more tools and services"
      ]
    },
    {
      "id": "cluster_37",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 17:29:16 +0000",
      "title": "Wing Commander III: \"Isn't that the guy from Star Wars?\"",
      "neutral_headline": "Wing Commander III retrospective",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/wing-commander-iii-the-game-kind-of-sucked-but-the-experience-blew-me-away/",
          "published_at": "Tue, 03 Feb 2026 17:29:16 +0000",
          "title": "Wing Commander III: \"Isn't that the guy from Star Wars?\"",
          "standfirst": "C:\\ArsGames looks at a vanguard of the multimedia FMV future that never quite came to pass.",
          "content": "It's Christmas of 1994, and I am 16 years old. Sitting on the table in our family room next to a pile of cow-spotted boxes is the most incredible thing in the world: a brand-new Gateway 66MHz Pentium tower, with a 540MB hard disk drive, 8MB of RAM, and, most importantly, a CD-ROM drive. I am agog, practically trembling with barely suppressed joy, my bored Gen-X teenager mask threatening to slip and let actual feelings out. My life was about to change—at least where games were concerned. I'd been working for several months at Babbage's store No. 9, near Baybrook Mall in southeast suburban Houston. Although the Gateway PC's arrival on Christmas morning was utterly unexpected, the choice of what game to buy required no planning at all. I'd already decided a few weeks earlier, when Chris Roberts' latest opus had been drop-shipped to our shelves, just in time for the holiday season. The choice made itself, really. Gimli and Luke, together at last! Credit: Origin Systems / Electronic Arts The moment Babbage's opened its doors on December 26—a day I had off, fortunately—I was there, checkbook in hand. One entire paycheck's worth of capitalism later, I was sprinting out to my creaky 280-Z, sweatily clutching two boxes—one an impulse buy, The Star Trek: The Next Generation Interactive Technical Manual, and the other a game I felt sure would be the best thing I'd ever played or ever would play: Origin's Wing Commander III: The Heart of the Tiger. On the backs of Wing Commander I and Wing Commander II, how could it not be?!Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/wc3_boxart_sm-1152x648-1770132197.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/wc3_boxart_sm-1152x648-1770132197.jpg",
      "popularity_score": 320.74706249999997,
      "ai_summary": [
        "Wing Commander III explored multimedia FMV future",
        "Game was ahead of its time in terms of technology",
        "FMV format never became widely adopted",
        "Game remains notable for its innovative approach",
        "Retrospective looks at game's development and impact"
      ]
    },
    {
      "id": "cluster_44",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 17:08:34 +0000",
      "title": "Upset at reports that he'd given up, Trump now wants $1B from Harvard",
      "neutral_headline": "Trump demands 1 billion from Harvard",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/upset-at-reports-that-hed-given-up-trump-now-wants-1b-from-harvard/",
          "published_at": "Tue, 03 Feb 2026 17:08:34 +0000",
          "title": "Upset at reports that he'd given up, Trump now wants $1B from Harvard",
          "standfirst": "Hefty \"fine\" comes in wake of NY Times reporting of money-free settlement.",
          "content": "Amid the Trump administration's attack on universities, Harvard has emerged as a particular target. Early on, the administration put $2.2 billion in research money on hold and shortly thereafter blocked all future funding while demanding intrusive control over Harvard's hiring and admissions. Unlike many of its peer institutions, Harvard fought back, filing and ultimately winning a lawsuit that restored the cut funds. Despite Harvard's victory, the Trump administration continued to push for some sort of formal agreement that would settle the administration's accusations that Harvard created an environment that allowed antisemitism to flourish. In fact, it had become a running joke among some journalists that The New York Times had devoted a monthly column to reporting that a settlement between the two parties was near. Given the government's loss of leverage, it was no surprise that the latest installment of said column included the detail that the latest negotiations had dropped demands that Harvard pay any money as part of a final agreement. The Trump administration had extracted hundreds of millions of dollars from some other universities and had demanded over a billion dollars from UCLA, so this appeared to be a major concession to Harvard.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-578751544-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-578751544-1152x648.jpg",
      "popularity_score": 310.4020625,
      "ai_summary": [
        "Trump seeks 1 billion dollars from Harvard",
        "Hefty fine comes after NY Times reporting",
        "Money free settlement was previously reported",
        "Trump now wants significant payment",
        "Harvard has not commented on demand"
      ]
    },
    {
      "id": "cluster_87",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 14:02:57 +0000",
      "title": "Senior staff departing OpenAI as firm prioritizes ChatGPT development",
      "neutral_headline": "OpenAI senior staff depart company",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/senior-staff-departing-openai-as-firm-prioritizes-chatgpt-development/",
          "published_at": "Tue, 03 Feb 2026 14:02:57 +0000",
          "title": "Senior staff departing OpenAI as firm prioritizes ChatGPT development",
          "standfirst": "Resources are redirected from long-term research toward improving the flagship chatbot.",
          "content": "OpenAI is prioritizing the advancement of ChatGPT over more long-term research, prompting the departure of senior staff as the $500 billion company adapts to stiff competition from rivals such as Google and Anthropic. The San Francisco-based start-up has reallocated resources for experimental work in favor of advances to the large language models that power its flagship chatbot, according to 10 current and former employees. Among those to leave OpenAI in recent months over the strategic shift are vice-president of research Jerry Tworek, model policy researcher Andrea Vallone, and economist Tom Cunningham.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/openai-logo-1152x648-1741196873.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/openai-logo-1152x648-1741196873.jpg",
      "popularity_score": 308.3084513888889,
      "ai_summary": [
        "Senior staff leave OpenAI due to priorities",
        "Firm prioritizes ChatGPT development now",
        "Resources redirected to chatbot improvement",
        "Long term research affected by changes",
        "ChatGPT is OpenAI's flagship product"
      ]
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 12:00:01 +0000",
      "title": "The rise of Moltbook suggests viral AI prompts may be the next big security threat",
      "neutral_headline": "Viral AI prompts pose security threat",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/the-rise-of-moltbook-suggests-viral-ai-prompts-may-be-the-next-big-security-threat/",
          "published_at": "Tue, 03 Feb 2026 12:00:01 +0000",
          "title": "The rise of Moltbook suggests viral AI prompts may be the next big security threat",
          "standfirst": "We don't need self-replicating AI models to have problems, just self-replicating prompts.",
          "content": "On November 2, 1988, graduate student Robert Morris released a self-replicating program into the early Internet. Within 24 hours, the Morris worm had infected roughly 10 percent of all connected computers, crashing systems at Harvard, Stanford, NASA, and Lawrence Livermore National Laboratory. The worm exploited security flaws in Unix systems that administrators knew existed but had not bothered to patch. Morris did not intend to cause damage. He wanted to measure the size of the Internet. But a coding error caused the worm to replicate far faster than expected, and by the time he tried to send instructions for removing it, the network was too clogged to deliver the message. History may soon repeat itself with a novel new platform: networks of AI agents carrying out instructions from prompts and sharing them with other AI agents, which could spread the instructions further.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/moltbook-chest-burster-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/moltbook-chest-burster-1152x648.jpg",
      "popularity_score": 300.2595625,
      "ai_summary": [
        "AI prompts may be next big security issue",
        "Self replicating prompts cause problems",
        "No self replicating AI models needed",
        "Moltbook suggests viral AI prompts rising",
        "Security threats from AI prompts increasing"
      ]
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 15:33:06 +0000",
      "title": "China bans all retractable car door handles, starting next year",
      "neutral_headline": "China bans retractable car door handles",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/china-bans-all-retractable-car-door-handles-starting-next-year/",
          "published_at": "Tue, 03 Feb 2026 15:33:06 +0000",
          "title": "China bans all retractable car door handles, starting next year",
          "standfirst": "The pop-out door handle ban starts in 2027 for new cars, 2029 for existing models.",
          "content": "Flush door handles have been quite the automotive design trend of late. Stylists like them because they don't add visual noise to the side of a car. And aerodynamicists like them because they make a vehicle more slippery through the air. When Tesla designed its Model S, it needed a car that was both desirable and as efficient as possible, so flush door handles were a no-brainer. Since then, as electric vehicles have proliferated, so too have flush door handles. But as of next year, China says no. Just like pop-up headlights, despite the aesthetic and aerodynamic advantages, there are safety downsides. Tesla's handles are an extreme example: In the event of a crash and a loss of 12 V power, there is no way for first responders to open the door from the outside, which has resulted in at least 15 deaths. Those deaths prompted the National Highway Traffic Safety Administration to open an investigation last year, but China is being a little more proactive. It has been looking at whether retractable car door handles are safe since mid-2024, according to Bloomberg, and has concluded that no, they are not.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1277594023-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1277594023-1152x648.jpg",
      "popularity_score": 298.8109513888889,
      "ai_summary": [
        "China bans pop out door handles starting 2027",
        "Ban applies to new cars first",
        "Existing models banned in 2029",
        "Door handle ban for safety reasons",
        "New cars must comply with rule"
      ]
    },
    {
      "id": "cluster_113",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 08:06:50 +0000",
      "title": "Unable to tame hydrogen leaks, NASA delays launch of Artemis II until March",
      "neutral_headline": "NASA delays Artemis II launch",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/unable-to-tame-hydrogen-leaks-nasa-delays-launch-of-artemis-ii-until-march/",
          "published_at": "Tue, 03 Feb 2026 08:06:50 +0000",
          "title": "Unable to tame hydrogen leaks, NASA delays launch of Artemis II until March",
          "standfirst": "NASA spent most of Monday trying to overcome hydrogen leaks on the Artemis II rocket.",
          "content": "The launch of NASA's Artemis II mission, the first flight of astronauts to the Moon in more than 53 years, will have to wait another month after a fueling test Monday uncovered hydrogen leaks in the connection between the rocket and its launch platform at Kennedy Space Center in Florida. \"Engineers pushed through several challenges during the two-day test and met many of the planned objectives,\" NASA said in a statement following the conclusion of the mock countdown, or wet dress rehearsal (WDR), early Tuesday morning. \"To allow teams to review data and conduct a second Wet Dress Rehearsal, NASA now will target March as the earliest possible launch opportunity for the flight test.\" The practice countdown was designed to identify problems and provide NASA an opportunity to fix them before launch. Most importantly, the test revealed NASA still has not fully resolved recurring hydrogen leaks that delayed the launch of the unpiloted Artemis I test flight by several months in 2022. Artemis I finally launched successfully after engineers revised their hydrogen loading procedures to overcome the leak.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/AFRC2026-0017-15orig-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/AFRC2026-0017-15orig-1152x648.jpg",
      "popularity_score": 261.3731736111111,
      "ai_summary": [
        "NASA delays Artemis II launch until March",
        "Hydrogen leaks caused launch delay",
        "NASA spent Monday overcoming leaks",
        "Artemis II rocket launch delayed again",
        "New launch date set for March"
      ]
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 22:57:56 +0000",
      "title": "Looking back at Catacomb 3D, the game that led to Wolfenstein 3D",
      "neutral_headline": "Catacomb 3D led to Wolfenstein 3D",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/looking-back-at-catacomb-3d-the-game-that-led-to-wolfenstein-3d/",
          "published_at": "Mon, 02 Feb 2026 22:57:56 +0000",
          "title": "Looking back at Catacomb 3D, the game that led to Wolfenstein 3D",
          "standfirst": "Romero, Carmack, and colleagues discuss an oft-forgotten piece of PC gaming history.",
          "content": "If you know anything about the history of id Software, you know how 1992's Wolfenstein 3D helped establish the company's leadership in the burgeoning first-person shooter genre, leading directly to subsequent hits like Doom and Quake. But only the serious id Software nerds remember Catacomb 3D, id's first-person adventure game that directly preceded and inspired work on Wolfenstein 3D. Now, nearly 35 years after Catacomb 3D's initial release, id co-founder John Romero brought the company's founding members together for an informative retrospective video on the creation of the oft-forgotten game. But the pioneering game—which included mouse support, color-coded keys, and shooting walls to find secrets—almost ended up being a gimmicky dead end for the company. id Software's founders look back at an oft-forgotten piece of gaming history. Texture maps and \"undo\" animation Catacomb 3D was a follow-up to id's earlier Catacomb, which was a simplified clone of the popular arcade hit Gauntlet. As such, the 3D game still has some of that \"quarter eater\" mentality that was not very fashionable in PC gaming at the time, as John Carmack remembered.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/c3d-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/c3d-1152x648.jpg",
      "popularity_score": 243,
      "ai_summary": [
        "Catacomb 3D influenced Wolfenstein 3D",
        "Romero and Carmack discuss game history",
        "Catacomb 3D is oft forgotten game",
        "Game led to development of Wolfenstein",
        "PC gaming history includes Catacomb 3D"
      ]
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 21:55:44 +0000",
      "title": "SpaceX acquires xAI, plans to launch a massive satellite constellation to power it",
      "neutral_headline": "SpaceX acquires xAI company",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/spacex-acquires-xai-plans-1-million-satellite-constellation-to-power-it/",
          "published_at": "Mon, 02 Feb 2026 21:55:44 +0000",
          "title": "SpaceX acquires xAI, plans to launch a massive satellite constellation to power it",
          "standfirst": "\"This marks not just the next chapter, but the next book in SpaceX and xAI's mission.\"",
          "content": "SpaceX has formally acquired another one of Elon Musk's companies, xAi, the space company announced on Monday afternoon. \"SpaceX has acquired xAI to form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform,\" the company said. \"This marks not just the next chapter, but the next book in SpaceX and xAI's mission: scaling to make a sentient sun to understand the Universe and extend the light of consciousness to the stars!\" The merging of what is arguably Musk's most successful company, SpaceX, with the more speculative xAI venture is a risk. Founded in 2023, xAI's main products are the generative AI chatbot Grok and the social media site X, formerly known as Twitter. The company aims to compete with OpenAI and other artificial intelligence firms. However, Grok has been controversial, including the sexualization of women and children through AI-generated images, as has Musk's management of Twitter.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-1152x648.jpg",
      "popularity_score": 156,
      "ai_summary": [
        "SpaceX acquires xAI for satellite plans",
        "Massive satellite constellation planned",
        "Constellation will power xAI services",
        "SpaceX plans to launch satellites soon",
        "xAI will support SpaceX mission"
      ]
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 22:31:46 +0000",
      "title": "Streaming service Crunchyroll raises prices weeks after killing its free tier",
      "neutral_headline": "Crunchyroll raises streaming prices",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/streaming-service-crunchyroll-raises-prices-weeks-after-killing-its-free-tier/",
          "published_at": "Mon, 02 Feb 2026 22:31:46 +0000",
          "title": "Streaming service Crunchyroll raises prices weeks after killing its free tier",
          "standfirst": "Sony has made streaming anime pricier since buying Crunchyroll.",
          "content": "Crunchyroll is one of the most popular streaming platforms for anime viewers. Over the past six years, the service has raised prices for fans, and today, it announced that it's increasing monthly subscription prices by up to 25 percent. Sony bought Crunchyroll from AT&T in 2020. At the time, Crunchyroll had 3 million paid subscribers and an additional 197 million users with free accounts, which let people watch a limited number of titles with commercials. At the time, Crunchyroll monthly subscription tiers cost $8, $10, or $15. After its acquisition by Sony, like many large technology companies that buy a smaller, beloved product, the company made controversial changes. The Tokyo-based company folded rival Funimation into Crunchyroll; Sony shut down Funimation, which it bought in 2017, in April 2024.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2258531948-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2258531948-1024x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Crunchyroll raises prices for streaming",
        "Free tier was killed weeks ago",
        "Sony increased prices after buying Crunchyroll",
        "Streaming anime now more expensive",
        "Price hike affects all Crunchyroll users"
      ]
    },
    {
      "id": "cluster_128",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 21:32:18 +0000",
      "title": "Russian drones use Starlink, but Ukraine has plan to block their Internet access",
      "neutral_headline": "Ukraine plans to block Russian drones",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/russian-drones-use-starlink-but-ukraine-has-plan-to-block-their-internet-access/",
          "published_at": "Mon, 02 Feb 2026 21:32:18 +0000",
          "title": "Russian drones use Starlink, but Ukraine has plan to block their Internet access",
          "standfirst": "Defense chief: \"No Ukrainians have been killed by Russian drones using Starlink.\"",
          "content": "Ukraine and SpaceX say they recently collaborated to stop strikes by Russian drones using Starlink and will soon block all unregistered use of Starlink terminals in an attempt to stop Russia's military from using the satellite broadband network over Ukraine territory. Ukrainians will soon be required to register their Starlink terminals to get on a whitelist. After that, \"only verified and registered terminals will be allowed to operate in the country. All others will be disconnected,\" the Ukraine Ministry of Defense said in a press release today. Ukraine Minister of Defense Mykhailo Fedorov \"emphasized that the only technical solution to counter this threat is to introduce a 'whitelist' and authorize all terminals,\" according to the ministry. \"This is a necessary step by the Government to save Ukrainian lives and protect critical energy infrastructure,\" Fedorov said.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/getty-ukraine-starlink-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/getty-ukraine-starlink-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Ukraine will block Russian drone internet",
        "Russian drones use Starlink services",
        "Defense chief comments on drone issue",
        "No Ukrainians killed by drones using Starlink",
        "Ukraine has plan to stop drone access"
      ]
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 20:00:35 +0000",
      "title": "A century of hair samples proves leaded gas ban worked",
      "neutral_headline": "Leaded gas ban proved effective",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/a-century-of-hair-samples-proves-leaded-gas-ban-worked/",
          "published_at": "Mon, 02 Feb 2026 20:00:35 +0000",
          "title": "A century of hair samples proves leaded gas ban worked",
          "standfirst": "“We should not forget the lessons of history. And the lesson is those regulations have been very important.”",
          "content": "The Environmental Protection Agency (EPA) cracked down on lead-based products—including lead paint and leaded gasoline—in the 1970s because of its toxic effects on human health. Scientists at the University of Utah have analyzed human hair samples spanning nearly 100 years and found a 100-fold decrease in lead concentrations, concluding that this regulatory action was highly effective in achieving its stated objectives. They described their findings in a new paper published in the Proceedings of the National Academy of Sciences. We've known about the dangers of lead exposure for a very long time—arguably since the second century BCE—so why conduct this research now? Per the authors, it's because there are growing concerns over the Trump administration's move last year to deregulate many key elements of the EPA's mission. Lead specifically has not yet been deregulated, but there are hints that there could be a loosening of enforcement of the 2024 Lead and Cooper rule requiring water systems to replace old lead pipes. “We should not forget the lessons of history. And the lesson is those regulations have been very important,” said co-author Thure Cerling. “Sometimes they seem onerous and mean that industry can't do exactly what they'd like to do when they want to do it or as quickly as they want to do it. But it's had really, really positive effects.”Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lead2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lead2-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "Leaded gas ban worked according to study",
        "Hair samples show lead levels decreased",
        "Ban on leaded gas was effective measure",
        "Regulations had significant impact",
        "Study proves importance of regulations"
      ]
    },
    {
      "id": "cluster_146",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 18:23:56 +0000",
      "title": "Intel Panther Lake Core Ultra review: Intel's best laptop CPU in a very long time",
      "neutral_headline": "Intel Panther Lake Core Ultra reviewed",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/intel-panther-lake-core-ultra-review-intels-best-laptop-cpu-in-a-very-long-time/",
          "published_at": "Mon, 02 Feb 2026 18:23:56 +0000",
          "title": "Intel Panther Lake Core Ultra review: Intel's best laptop CPU in a very long time",
          "standfirst": "Intel manages big boosts to CPU and GPU speed without blowing up battery life.",
          "content": "Intel's Core Ultra lineup of desktop and laptop processors has been frustrating to review. None of them has been across-the-board awful or totally without redeeming qualities. But Intel has struggled mightily this decade to produce new processors that are straightforward, easy-to-recommend improvements over their predecessors. The company's 12th- and 13th-generation Core chips offered big boosts to CPU performance over the 11th-generation CPUs, for example, but they also usually came with a significant hit to battery life, and they only minimally improved the GPU. The first-generation Core Ultra chips, codenamed Meteor Lake, improved the GPU but couldn't beat the CPU performance of older chips. Last year's Core Ultra 200V series, codenamed Lunar Lake, boasted good battery life and solid graphics performance but weaker CPU performance; better-performing Core Ultra 200H chips (codenamed Arrow Lake) improved CPU performance but came with lesser GPUs and some other missing features. The Core Ultra Series 3 processors, codenamed Panther Lake, finally put an end to the years of uneven zig-zagging advancement we've seen in the last half-decade.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_3607-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_3607-1152x648.jpeg",
      "popularity_score": 144,
      "ai_summary": [
        "Intel Panther Lake Core Ultra reviewed",
        "Intel's best laptop CPU in long time",
        "CPU and GPU speed increased significantly",
        "Battery life not affected by boosts",
        "Intel manages big improvements"
      ]
    },
    {
      "id": "cluster_134",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 20:30:56 +0000",
      "title": "Notepad++ users take note: It's time to check if you're hacked",
      "neutral_headline": "Notepad++ users warned of hacking",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/02/notepad-updater-was-compromised-for-6-months-in-supply-chain-attack/",
          "published_at": "Mon, 02 Feb 2026 20:30:56 +0000",
          "title": "Notepad++ users take note: It's time to check if you're hacked",
          "standfirst": "Suspected China-state hackers used update infrastructure to deliver backdoored version.",
          "content": "Infrastructure delivering updates for Notepad++—a widely used text editor for Windows—was compromised for six months by suspected China-state hackers who used their control to deliver backdoored versions of the app to select targets, developers said Monday. “I deeply apologize to all users affected by this hijacking,” the author of a post published to the official notepad-plus-plus.org site wrote Monday. The post said that the attack began last June with an “infrastructure-level compromise that allowed malicious actors to intercept and redirect update traffic destined for notepad-plus-plus.org.” The attackers, whom multiple investigators tied to the Chinese government, then selectively redirected certain targeted users to malicious update servers where they received backdoored updates. Notepad++ didn’t regain control of its infrastructure until December. The attackers used their access to install a never-before-seen payload that has been dubbed Chrysalis. Security firm Rapid 7 descrbed it as a \"custom, feature-rich backdoor.\"Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security.jpg",
      "popularity_score": 143,
      "ai_summary": [
        "Notepad++ users warned of hacking risk",
        "Suspected China state hackers involved",
        "Hackers used update infrastructure",
        "Backdoored version of Notepad++ delivered",
        "Users should check for hacking signs"
      ]
    },
    {
      "id": "cluster_139",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 19:40:40 +0000",
      "title": "Judge rules Department of Energy's climate working group was illegal",
      "neutral_headline": "Judge rules climate working group illegal",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/us-forced-to-disclose-its-climate-working-groups-communications/",
          "published_at": "Mon, 02 Feb 2026 19:40:40 +0000",
          "title": "Judge rules Department of Energy's climate working group was illegal",
          "standfirst": "Meant to undercut EPA regulations, the group tried to work in secret.",
          "content": "On Friday, a judge ruled that the Trump administration violated the law in forming its Climate Working Group, which released a report that was intended to undercut the rationale behind greenhouse gas regulations. The judge overseeing the case determined that the government tried to treat the Climate Working Group as a formal advisory body, while not having it obey many of the statutory requirements that govern such bodies. While the Department of Energy (DOE) later disbanded the Climate Working Group in the hopes of avoiding legal scrutiny, documents obtained during the proceedings have now revealed the group's electronic communications. As such, the judge ruled that the trial itself had essentially overcome the government's illegal attempts to hide those communications. Legal and scientific flaws The whole saga derives from a Supreme Court Ruling that compelled the Environmental Protection Agency (EPA) to evaluate the risks posed to the US public by greenhouse gases. During the Obama administration, this resulted in an endangerment finding that created the foundation for the EPA to regulate carbon emissions under the Clean Air Act. The science underlying the endangerment finding was so solid that it was left unchallenged during the first Trump administration.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1804069599-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1804069599-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "Judge rules climate working group illegal",
        "Group was meant to undercut EPA rules",
        "Working group tried to work in secret",
        "Group's actions were deemed unlawful",
        "Ruling affects climate regulations"
      ]
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 20:43:31 +0000",
      "title": "Court orders restart of all US offshore wind construction",
      "neutral_headline": "Court orders restart of wind construction",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/court-orders-restart-of-all-us-offshore-wind-construction/",
          "published_at": "Mon, 02 Feb 2026 20:43:31 +0000",
          "title": "Court orders restart of all US offshore wind construction",
          "standfirst": "Trump admin's \"it's classified\" ploy put on hold in five different cases.",
          "content": "The Trump administration is no fan of renewable energy, but it reserves special ire for wind power. Trump himself has repeatedly made false statements about the cost of wind power, its use around the world, and its environmental impacts. That animosity was paired with an executive order that blocked all permitting for offshore wind and some land-based projects, an order that has since been thrown out by a court that ruled it arbitrary and capricious. Not content to block all future developments, the administration has also gone after the five offshore wind projects currently under construction. After temporarily blocking two of them for reasons that were never fully elaborated, the Department of the Interior settled on a single justification for blocking turbine installation: a classified national security risk. The response to that late-December announcement has been uniform: The companies building each of the projects sued the administration. As of Monday, every single one of them has achieved the same result: a temporary injunction that allows them to continue construction. This, despite the fact that the suits were filed in three different courts and heard by four different judges.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1623091024.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1623091024.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Court orders restart of wind construction",
        "Trump admin's ploy put on hold",
        "Five different cases affected by ruling",
        "Construction of offshore wind farms",
        "Ruling supports renewable energy plans"
      ]
    },
    {
      "id": "cluster_137",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 19:52:32 +0000",
      "title": "Ongoing RAM crisis prompts Raspberry Pi's second price hike in two months",
      "neutral_headline": "Raspberry Pi price increased again",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/ongoing-ram-crisis-prompts-raspberry-pis-second-price-hike-in-two-months/",
          "published_at": "Mon, 02 Feb 2026 19:52:32 +0000",
          "title": "Ongoing RAM crisis prompts Raspberry Pi's second price hike in two months",
          "standfirst": "The more RAM the Pi board has, the more its price is increasing.",
          "content": "The ongoing AI-fueled shortages of memory and storage chips has hit RAM kits and SSDs for PC builders the fastest and hardest, meaning it's likely that, for other products that use these chips, we'll be seeing price hikes for the entire rest of the year, if not for longer. The latest price hike news comes courtesy of Raspberry Pi CEO Eben Upton, who announced today that the company would be raising prices on most of its single-board computers for the second time in two months. Prices are going up for all Raspberry Pi 4 and Raspberry Pi 5 boards with 2GB of more of LPDDR4 RAM, including the Compute Module 4 and 5 and the Raspberry Pi 500 computer-inside-a-keyboard. The 2GB boards' pricing will go up by $10, 4GB boards will go up by $15, 8GB boards will go up by $30, and 16GB boards will increase by a whopping $60.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0625-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0625-1152x648.jpeg",
      "popularity_score": 133,
      "ai_summary": [
        "Raspberry Pi price increased due to RAM",
        "Ongoing RAM crisis causes price hike",
        "Second price hike in two months",
        "Price increase affects all Raspberry Pi boards",
        "More RAM means higher price for boards"
      ]
    },
    {
      "id": "cluster_142",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 18:58:10 +0000",
      "title": "DOJ released Epstein files with dozens of nudes and victims' names, reports say",
      "neutral_headline": "DOJ Releases Epstein Files With Sensitive Information",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/doj-released-epstein-files-with-dozens-of-nudes-and-victims-names-reports-say/",
          "published_at": "Mon, 02 Feb 2026 18:58:10 +0000",
          "title": "DOJ released Epstein files with dozens of nudes and victims' names, reports say",
          "standfirst": "DOJ reportedly failed to redact nearly 40 nude photos and 43 victims' names.",
          "content": "The Epstein files released by the Department of Justice on Friday included at least a few dozen unredacted nude photos and names of at least 43 victims, according to news reports. The DOJ missed a December 19 deadline set by the Epstein Files Transparency Act by more than a month, but still released the files without fully redacting nude photos and names of Jeffrey Epstein's victims. The New York Times reported yesterday that it found \"nearly 40 unredacted images that appeared to be part of a personal photo collection, showing both nude bodies and the faces of the people portrayed.\" While the people in the photos were young, \"it was unclear whether they were minors,\" the article said. \"Some of the images seemed to show Mr. Epstein’s private island, including a beach. Others were taken in bedrooms and other private spaces.\" The photos \"appeared to show at least seven different people,\" the article said.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/epstein-files-1152x648-1770057497.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/epstein-files-1152x648-1770057497.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "DOJ released Epstein files with dozens of nudes",
        "Files contain names of 43 victims",
        "Nearly 40 nude photos were not redacted",
        "Reports say DOJ failed to redact sensitive information",
        "Epstein files reveal new details about the case"
      ]
    }
  ]
}