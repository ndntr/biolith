{
  "updated_at": "2026-01-20T20:12:33.835Z",
  "clusters": [
    {
      "id": "cluster_9",
      "coverage": 3,
      "updated_at": "Tue, 20 Jan 2026 19:24:12 +0000",
      "title": "Netflix to pay all cash for Warner Bros. to fend off Paramount hostile takeover",
      "neutral_headline": "Netflix to pay all cash for Warner Bros. to fend off Paramount hostile takeover",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/netflix-to-pay-all-cash-for-warner-bros-to-fend-off-paramount-hostile-takeover/",
          "published_at": "Tue, 20 Jan 2026 19:24:12 +0000",
          "title": "Netflix to pay all cash for Warner Bros. to fend off Paramount hostile takeover",
          "standfirst": "Netflix and Warner seek quick shareholder vote as Paramount tries to upend deal.",
          "content": "Netflix agreed to pay all cash for Warner Bros. Discovery, amending its $72 billion deal in an attempt to fight off Paramount's hostile takeover bid. Netflix originally agreed to buy the company with a mix of cash and stock. To sweeten the offer for shareholders, Netflix and Warner Bros. today announced that Netflix will pay all cash instead. If successful, Netflix's purchase will include HBO Max, WB Studios, and other assets. The price is unchanged at $27.75 per share, and Warner Bros. is targeting an April 2026 shareholder vote. The original plan was for Netflix to buy each Warner Bros. share with $23.25 in cash and $4.50 in Netflix stock.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/netflix-paramount-wb-icons-1152x648-1767815429.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/20/netflix-revises-offer-to-pay-all-cash-for-warner-bros-to-stave-off-paramount/",
          "published_at": "Tue, 20 Jan 2026 14:00:40 +0000",
          "title": "Netflix revises offer to pay all cash for Warner Bros. to fend off Paramount",
          "standfirst": "However, the streaming giant is still offering the same $27.75 the companies had agreed on for WBD's movie studio and streaming assets, and the deal continues to value the company at $82.7 billion.",
          "content": "However, the streaming giant is still offering the same $27.75 the companies had agreed on for WBD's movie studio and streaming assets, and the deal continues to value the company at $82.7 billion.",
          "feed_position": 9
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/863318/netflix-warner-bros-discovery-merger-revision-cash-deal",
          "published_at": "2026-01-20T07:26:10-05:00",
          "title": "Netflix revises Warner Bros. bid to an all-cash offer",
          "standfirst": "Netflix has updated the acquisition terms for its Warner Bros. Discovery offer to an all-cash deal, replacing its initial $82.7 billion cash and stock agreement. The changes are designed to expedite the sale of WBD studios and streaming businesses, following repeated attempts by rival bidder Paramount to pressure shareholders into accepting its own $108 billion [&#8230;]",
          "content": "Netflix has updated the acquisition terms for its Warner Bros. Discovery offer to an all-cash deal, replacing its initial $82.7 billion cash and stock agreement. The changes are designed to expedite the sale of WBD studios and streaming businesses, following repeated attempts by rival bidder Paramount to pressure shareholders into accepting its own $108 billion all-cash offer. \"The WBD Board continues to support and unanimously recommend our transaction, and we are confident that it will deliver the best outcome for stockholders, consumers, creators, and the broader entertainment community,\" said Ted Sarandos, co-CEO of Netflix. \"Our revise … Read the full story at The Verge.",
          "feed_position": 9
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/netflix-paramount-wb-icons-1152x648-1767815429.jpg",
      "popularity_score": 3019.1939347222224
    },
    {
      "id": "cluster_20",
      "coverage": 2,
      "updated_at": "Tue, 20 Jan 2026 18:33:00 GMT",
      "title": "X open sources its algorithm: 5 ways businesses can benefit",
      "neutral_headline": "X open sources its algorithm: 5 ways businesses can benefit",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/x-open-sources-its-algorithm-5-ways-businesses-can-benefit",
          "published_at": "Tue, 20 Jan 2026 18:33:00 GMT",
          "title": "X open sources its algorithm: 5 ways businesses can benefit",
          "standfirst": "Elon Musk&#x27;s social network X (formerly known as Twitter) last night released some of the code and architecture of its overhauled social recommendation algorithm under a permissive, enterprise-friendly open source license (Apache 2.0) on Github, allowing for commercial usage and modification. This is the algorithm that decides which X posts and accounts to show to which users on the social network.The new X algorithm, as opposed toto the manual heuristic rules and legacy models in the past, is based on a \"Transformer\" architecture powered by its parent company, xAI’s, Grok AI language model. This is a significant release for enterprises who have brand accounts on X, or whose leaders and employees use X to post company promotional messages, links, content, etc — as it now provides a look at how X evaluates posts and accounts on the platform, and what criteria go into it deciding to show a post or specific account to users. Therefore, it&#x27;s imperative for any businesses using X to post promotional and informational content to understand how the X algorithm works as best as they can, in order to maximize their usage of the platform. To analogize: imagine trying to navigate a hike through a massive woods without a map. You&#x27;d likely end up lost and waste time and energy (resources) trying to get to your destination. But with a map, you could plot your route, look for the appropriate landmarks, check your progress along the way, and revise your path as necessary to stay on track. X open sourcing its new transformer-based recommendation algorithm is in many ways just this — providing a \"map\" to all those who use the platform on how to achieve the best performance they (and their brands) can.Here is the technical breakdown of the new architecture and five data-backed strategies to leverage it for commercial growth.The \"Red Herring\" of 2023 vs. The \"Grok\" Reality of 2026In March 2023, shortly after it was acquired by Musk, X also open sourced its recommendation algorithm.However, the release revealed a tangled web of \"spaghetti code\" and manual heuristics and was criticized by outlets like Wired (where my wife works, full disclosure) and organizations including the Center for Democracy and Technology, as being too heavily redacted to be useful. It was seen as a static snapshot of a decaying system.The code released on January 19, 2026, confirms that the spaghetti is gone. X has replaced the manual filtering layers with a unified, AI-driven Transformer architecture. The system uses a RecsysBatch input model that ingests user history and action probabilities to output a raw score. It is cleaner, faster, and infinitely more ruthless.But there is a catch: The specific \"weighting constants\"—the magic numbers that tell us exactly how much a Like or Reply is worth—have been redacted from this release.Here are the five strategic imperatives for brands operating in this new, Grok-mediated environment.1. The \"Velocity\" Window: You Have 30 Minutes to Live or DieIn the 2023 legacy code, content drifted through complex clusters, often finding life hours after posting. The new Grok architecture is designed for immediate signal processing.Community analysis of the new Rust-based scoring functions reveals a strict \"Velocity\" mechanic. The lifecycle of a corporate post is determined in the first half-hour. If engagement signals (clicks, dwells, replies) fail to exceed a dynamic threshold in the first 15 minutes, the post is mathematically unlikely to breach the general \"For You\" pool.The architecture includes a specific scorer that penalizes multiple posts from the same user in a short window. Posting 10 times a day yields diminishing returns; the algorithm actively downranks your 3rd, 4th, and 5th posts to force variety into the feed. Space your announcements out.Thus, the takeaway for business data leads is to coordinate your internal comms and advocacy programs with military precision. \"Employee advocacy\" can no longer be asynchronous. If your employees or partners engage with a company announcement two hours later, the mathematical window has likely closed. You must front-load engagement in the first 10 minutes to artificially spike the velocity signal.2. The \"Reply\" Trap: Why Engagement Bait is DeadIn 2023, data suggested that an author replying to comments was a \"cheat code\" for visibility. In 2026, this strategy has become a trap.While early analysis circulated rumors of a \"75x\" boost for replies, developers examining the new repository have confirmed that the actual weighting constants are hidden. More importantly, X’s Head of Product, Nikita Bier, has explicitly stated that \"Replies don&#x27;t count anymore\" for revenue sharing, in a move designed to kill \"reply rings\" and spam farms.Bier clarified that replies only generate value if they are high-quality enough to generate \"Home Timeline impressions\" on their own merit.As this is the case, businesses should stop optimizing for \"reply volume\" and start optimizing for \"reply quality.\" The algorithm is actively hostile toward low-effort engagement rings. Businesses and individuals should not reply incessantly to every comment with emojis or generic thanks. They should only reply if the response adds enough value to stand alone as a piece of content in a user’s feed.With replies devalued, focus on the other positive signals visible in the code: dwell_time (how long a user freezes on your post) and share_via_dm. Long-form threads or visual data that force a user to stop scrolling are now mathematically safer bets than controversial questions.3. X Is Basically Pay-to-Play, NowThe 2023 algorithm used X paid subscription status as one of many variables. The 2026 architecture simplifies this into a brutal base-score reality.Code analysis reveals that before a post is evaluated for quality, the account is assigned a base score. X accounts that are \"verified\" by paying the monthly \"Premium\" subscription ($3 per month for individual account Premium Basic, $200/month for businesses) receive a significantly higher ceiling (up to +100) compared to unverified accounts, which are capped (max +55).Therefore, if your brand, executives, or key spokespeople are not verified (X Premium or Verified Organizations), you are competing with a handicap. For a business looking to acquire customers or leads via X, verification is a mandatory infrastructure cost to remove a programmatic throttle on your reach.4. The \"Report\" Penalty: Brand Safety Requires De-escalationThe Grok model has replaced complex \"toxicity\" rules with a simplified feedback loop. While the exact weight of someone filing a \"Report\" on your X post or account over objectionable or false material is hidden in the new config files, it remains the ultimate negative signal. But it isn&#x27;t the only one. The model also outputs probabilities for P(not_interested) and P(mute_author). Irrelevant clickbait doesn&#x27;t just get ignored; it actively trains the model to predict that users will mute you, permanently suppressing your future reach.In a system driven by AI probabilities, a \"Report\" or \"Block\" signal trains the model to permanently dissociate your brand from that user&#x27;s entire cluster.In practice, this means \"rage bait\" or controversial takes are now incredibly dangerous for brands. It takes only a tiny fraction of users utilizing the \"Report\" function to tank a post&#x27;s visibility entirely. Your content strategy must prioritize engagement that excites users enough to reply, but never enough to report.5. OSINT as a Competency: Watch the Execs, Not Just the RepoThe most significant takeaway from today&#x27;s release is what is missing. The repository provides the architecture (the \"car\"), but it hides the weights (the \"fuel\").As X user @Tenobrus noted, the repo is \"barebones\" regarding constants. This means you cannot rely solely on the code to dictate strategy. You must triangulate the code with executive communications. When Bier announces a change to \"revenue share\" logic, you must assume it mirrors a change in the \"ranking\" logic.Therefore, data decision makers should assign a technical lead to monitor both the xai-org/x-algorithm repository and the public statements of the Engineering team. The code tells you *how* the system thinks; the executives tell you *what* it is currently rewarding.Summary: The Code is the StrategyThe Grok-based transformer architecture is cleaner, faster, and more logical than its predecessor. It does not care about your legacy or your follower count. It cares about Velocity and Quality.The Winning Formula:1. Verify to secure the base score. 2. Front-load engagement to survive the 30-minute velocity check. 3. Avoid \"spammy\" replies; focus on standalone value. 4. Monitor executive comms to fill in the gaps left by the code.In the era of Grok, the algorithm is smarter. Your data and business strategy using X ought to be, too.",
          "content": "Elon Musk&#x27;s social network X (formerly known as Twitter) last night released some of the code and architecture of its overhauled social recommendation algorithm under a permissive, enterprise-friendly open source license (Apache 2.0) on Github, allowing for commercial usage and modification. This is the algorithm that decides which X posts and accounts to show to which users on the social network.The new X algorithm, as opposed toto the manual heuristic rules and legacy models in the past, is based on a \"Transformer\" architecture powered by its parent company, xAI’s, Grok AI language model. This is a significant release for enterprises who have brand accounts on X, or whose leaders and employees use X to post company promotional messages, links, content, etc — as it now provides a look at how X evaluates posts and accounts on the platform, and what criteria go into it deciding to show a post or specific account to users. Therefore, it&#x27;s imperative for any businesses using X to post promotional and informational content to understand how the X algorithm works as best as they can, in order to maximize their usage of the platform. To analogize: imagine trying to navigate a hike through a massive woods without a map. You&#x27;d likely end up lost and waste time and energy (resources) trying to get to your destination. But with a map, you could plot your route, look for the appropriate landmarks, check your progress along the way, and revise your path as necessary to stay on track. X open sourcing its new transformer-based recommendation algorithm is in many ways just this — providing a \"map\" to all those who use the platform on how to achieve the best performance they (and their brands) can.Here is the technical breakdown of the new architecture and five data-backed strategies to leverage it for commercial growth.The \"Red Herring\" of 2023 vs. The \"Grok\" Reality of 2026In March 2023, shortly after it was acquired by Musk, X also open sourced its recommendation algorithm.However, the release revealed a tangled web of \"spaghetti code\" and manual heuristics and was criticized by outlets like Wired (where my wife works, full disclosure) and organizations including the Center for Democracy and Technology, as being too heavily redacted to be useful. It was seen as a static snapshot of a decaying system.The code released on January 19, 2026, confirms that the spaghetti is gone. X has replaced the manual filtering layers with a unified, AI-driven Transformer architecture. The system uses a RecsysBatch input model that ingests user history and action probabilities to output a raw score. It is cleaner, faster, and infinitely more ruthless.But there is a catch: The specific \"weighting constants\"—the magic numbers that tell us exactly how much a Like or Reply is worth—have been redacted from this release.Here are the five strategic imperatives for brands operating in this new, Grok-mediated environment.1. The \"Velocity\" Window: You Have 30 Minutes to Live or DieIn the 2023 legacy code, content drifted through complex clusters, often finding life hours after posting. The new Grok architecture is designed for immediate signal processing.Community analysis of the new Rust-based scoring functions reveals a strict \"Velocity\" mechanic. The lifecycle of a corporate post is determined in the first half-hour. If engagement signals (clicks, dwells, replies) fail to exceed a dynamic threshold in the first 15 minutes, the post is mathematically unlikely to breach the general \"For You\" pool.The architecture includes a specific scorer that penalizes multiple posts from the same user in a short window. Posting 10 times a day yields diminishing returns; the algorithm actively downranks your 3rd, 4th, and 5th posts to force variety into the feed. Space your announcements out.Thus, the takeaway for business data leads is to coordinate your internal comms and advocacy programs with military precision. \"Employee advocacy\" can no longer be asynchronous. If your employees or partners engage with a company announcement two hours later, the mathematical window has likely closed. You must front-load engagement in the first 10 minutes to artificially spike the velocity signal.2. The \"Reply\" Trap: Why Engagement Bait is DeadIn 2023, data suggested that an author replying to comments was a \"cheat code\" for visibility. In 2026, this strategy has become a trap.While early analysis circulated rumors of a \"75x\" boost for replies, developers examining the new repository have confirmed that the actual weighting constants are hidden. More importantly, X’s Head of Product, Nikita Bier, has explicitly stated that \"Replies don&#x27;t count anymore\" for revenue sharing, in a move designed to kill \"reply rings\" and spam farms.Bier clarified that replies only generate value if they are high-quality enough to generate \"Home Timeline impressions\" on their own merit.As this is the case, businesses should stop optimizing for \"reply volume\" and start optimizing for \"reply quality.\" The algorithm is actively hostile toward low-effort engagement rings. Businesses and individuals should not reply incessantly to every comment with emojis or generic thanks. They should only reply if the response adds enough value to stand alone as a piece of content in a user’s feed.With replies devalued, focus on the other positive signals visible in the code: dwell_time (how long a user freezes on your post) and share_via_dm. Long-form threads or visual data that force a user to stop scrolling are now mathematically safer bets than controversial questions.3. X Is Basically Pay-to-Play, NowThe 2023 algorithm used X paid subscription status as one of many variables. The 2026 architecture simplifies this into a brutal base-score reality.Code analysis reveals that before a post is evaluated for quality, the account is assigned a base score. X accounts that are \"verified\" by paying the monthly \"Premium\" subscription ($3 per month for individual account Premium Basic, $200/month for businesses) receive a significantly higher ceiling (up to +100) compared to unverified accounts, which are capped (max +55).Therefore, if your brand, executives, or key spokespeople are not verified (X Premium or Verified Organizations), you are competing with a handicap. For a business looking to acquire customers or leads via X, verification is a mandatory infrastructure cost to remove a programmatic throttle on your reach.4. The \"Report\" Penalty: Brand Safety Requires De-escalationThe Grok model has replaced complex \"toxicity\" rules with a simplified feedback loop. While the exact weight of someone filing a \"Report\" on your X post or account over objectionable or false material is hidden in the new config files, it remains the ultimate negative signal. But it isn&#x27;t the only one. The model also outputs probabilities for P(not_interested) and P(mute_author). Irrelevant clickbait doesn&#x27;t just get ignored; it actively trains the model to predict that users will mute you, permanently suppressing your future reach.In a system driven by AI probabilities, a \"Report\" or \"Block\" signal trains the model to permanently dissociate your brand from that user&#x27;s entire cluster.In practice, this means \"rage bait\" or controversial takes are now incredibly dangerous for brands. It takes only a tiny fraction of users utilizing the \"Report\" function to tank a post&#x27;s visibility entirely. Your content strategy must prioritize engagement that excites users enough to reply, but never enough to report.5. OSINT as a Competency: Watch the Execs, Not Just the RepoThe most significant takeaway from today&#x27;s release is what is missing. The repository provides the architecture (the \"car\"), but it hides the weights (the \"fuel\").As X user @Tenobrus noted, the repo is \"barebones\" regarding constants. This means you cannot rely solely on the code to dictate strategy. You must triangulate the code with executive communications. When Bier announces a change to \"revenue share\" logic, you must assume it mirrors a change in the \"ranking\" logic.Therefore, data decision makers should assign a technical lead to monitor both the xai-org/x-algorithm repository and the public statements of the Engineering team. The code tells you *how* the system thinks; the executives tell you *what* it is currently rewarding.Summary: The Code is the StrategyThe Grok-based transformer architecture is cleaner, faster, and more logical than its predecessor. It does not care about your legacy or your follower count. It cares about Velocity and Quality.The Winning Formula:1. Verify to secure the base score. 2. Front-load engagement to survive the 30-minute velocity check. 3. Avoid \"spammy\" replies; focus on standalone value. 4. Monitor executive comms to fill in the gaps left by the code.In the era of Grok, the algorithm is smarter. Your data and business strategy using X ought to be, too.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/16AQsBHmZwamZhEThe81IE/c62d8f72d2a927091292807e176cbf7c/1c3ad1be-18a5-42ae-9e71-8e1407640d0f.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-wireless-charger-140036359.html",
          "published_at": "Tue, 20 Jan 2026 10:01:26 +0000",
          "title": "The best wireless chargers for 2026",
          "standfirst": "If you’ve upgraded your phone recently, there’s a good chance it supports wireless charging. Battery life can be one of the first things to deteriorate as your phone ages, so you’ll need quick and easy ways to power up wherever you are. You may not always be able to have a cable on your person, but investing in a wireless phone charger (or a few) can make it more convenient to plop your phone down and know it’ll have more juice when you pick it back up again.While you’re not going to get the same charging speed with a wireless charger that you would with a power cable, the convenience of a power source like this is undeniable. Stick a wireless charger on your bedside, on your desk at work, in your kitchen or wherever you spend a good chunk of your time and you’ll have a reliable way to power up your phone, sans bulky, messy cables. Needless to say, there are a ton of options out there with different charging capabilities and price ranges. Below, we’ve collected the best wireless chargers we’ve tested to make your search a little easier. Table of contents Best wireless chargers for 2026 What to look for in a wireless charger Where and how will you use your charger? Wireless charging performance Quality and box contents Wireless chargers FAQs Best wireless chargers for 2026 What to look for in a wireless charger While it’s tempting to buy a wireless charging pad optimized for the specific phone you have now, resist that urge. Instead, think about the types of devices (phones included) that you could see yourself using in the near future. If you’re sure you’ll use iPhones for a long time, an Apple MagSafe-compatible magnetic wireless charger will be faster and more convenient. If you use Android phones or think you might switch sides, however, you’ll want a more universal design. If you have other accessories like wireless earbuds or a smartwatch that supports wireless charging, maybe you’d be better off with a 3-in-1 wireless charger or full wireless charging station. Where and how will you use your charger? Odds are that you have a specific use case in mind for your charger. You may want it by your bedside on your nightstand for a quick charge in the morning, or on your desk for at-a-glance notifications. You might even keep it in your bag for convenient travel charging instead of bulky portable chargers or power banks. Think about where you want to use this accessory and what you want to do with the device(s) it charges while it’s powering up. For example, a wireless charging pad might be better for bedside use if you just want to be able to drop your phone down at the end of a long day and know it’ll be powered up in the morning. However, a stand will be better if you have an iPhone and want to make use of the Standby feature during the nighttime hours. For a desk wireless charger, a stand lets you more easily glance at phone notifications throughout the day. For traveling, undoubtedly, a puck-style charging pad is best since it will take up much less space in your bag than a stand would. Many power banks also include wireless charging pads built in, so one of those might make even more sense for those who are always on the go. Some foldable chargers are also designed for travel, collapsing flat to take up less space. Wireless charging performance Although wireless charging is usually slower than its wired equivalent, speed and wattage are still important considerations. A fast charger can supply enough power for a long night out in the time it takes to change outfits. Look for options that promise faster charging and support standards like Qi2 certified charging for the best balance of efficiency and compatibility. In general, a 15W charger is more than quick enough for most situations, and you’ll need a MagSafe-compatible charger to extract that level of performance from an iPhone. With that said, even the slower 7.5W and 10W chargers are fast enough for an overnight power-up. If anything, you’ll want to worry more about support for cases. While many models can deliver power through a reasonably thick case (typically 3mm to 5mm), you’ll occasionally run into examples that only work with naked phones. There are some proprietary chargers that smash the 15W barrier if you have the right phone. Apple’s latest MagSafe charging pad can provide up to 25W of wireless power to compatible iPhones when paired with a 30W or 35W adapter — the latter being another component you’ll have to get right to make sure the whole equation works as fast as it possibly can. Quality and box contents Pay attention to what’s included in the box. Some wireless chargers don’t include power adapters, and others may even ask you to reuse your phone’s USB-C charging cable. What may seem to be a bargain may prove expensive if you have to buy extras just to use it properly. As mentioned above, you’ll want to make sure all of the components needed to use the wireless charger can provide the level of power you need — you’re only as strong (or in this case, fast) as your weakest link. Fit and finish is also worth considering. You’re likely going to use your wireless charger every day, so even small differences in build quality could make the difference between joy and frustration. If your charger doesn’t use MagSafe-compatible tech, textured surfaces like fabric or rubberized plastic are more likely to keep your phone in place. The base should be grippy or weighty enough that the charger won’t slide around. Also double check that the wireless charger you’re considering can support phones outfitted with cases — the specifications are usually listed in the charger’s description or specs. You’ll also want to think about the minor conveniences. Status lights are useful for indicating correct phone placement, but an overly bright light can be distracting. Ideally, the light dims or shuts off after a certain period of time. And while we caution against lips and trays that limit compatibility, you may still want some barriers to prevent your device falling off its perch on the charging station. Wireless chargers FAQs Do wireless chargers work if you have a phone case? Many wireless chargers do work if you leave the case on your phone. Generally, a case up to 3mm thick should be compatible with most wireless chargers. However, you should check the manufacturer’s guide to ensure a case is supported. How do I know if my phone supports wireless charging? Checking the phone’s specification should tell you if your phone is compatible with wireless charging. You might see words like “Qi wireless charging” or “wireless charging compatible.” Do cords charge your phone faster? Most often, wired charging will be faster than wireless charging. However, wired charging also depends on what the charging cable’s speed is and how much power it’s designed to carry. A quick-charging cable that can transmit up to 120W of power is going to be faster than a wireless charger.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-wireless-charger-140036359.html?src=rss",
          "content": "If you’ve upgraded your phone recently, there’s a good chance it supports wireless charging. Battery life can be one of the first things to deteriorate as your phone ages, so you’ll need quick and easy ways to power up wherever you are. You may not always be able to have a cable on your person, but investing in a wireless phone charger (or a few) can make it more convenient to plop your phone down and know it’ll have more juice when you pick it back up again.While you’re not going to get the same charging speed with a wireless charger that you would with a power cable, the convenience of a power source like this is undeniable. Stick a wireless charger on your bedside, on your desk at work, in your kitchen or wherever you spend a good chunk of your time and you’ll have a reliable way to power up your phone, sans bulky, messy cables. Needless to say, there are a ton of options out there with different charging capabilities and price ranges. Below, we’ve collected the best wireless chargers we’ve tested to make your search a little easier. Table of contents Best wireless chargers for 2026 What to look for in a wireless charger Where and how will you use your charger? Wireless charging performance Quality and box contents Wireless chargers FAQs Best wireless chargers for 2026 What to look for in a wireless charger While it’s tempting to buy a wireless charging pad optimized for the specific phone you have now, resist that urge. Instead, think about the types of devices (phones included) that you could see yourself using in the near future. If you’re sure you’ll use iPhones for a long time, an Apple MagSafe-compatible magnetic wireless charger will be faster and more convenient. If you use Android phones or think you might switch sides, however, you’ll want a more universal design. If you have other accessories like wireless earbuds or a smartwatch that supports wireless charging, maybe you’d be better off with a 3-in-1 wireless charger or full wireless charging station. Where and how will you use your charger? Odds are that you have a specific use case in mind for your charger. You may want it by your bedside on your nightstand for a quick charge in the morning, or on your desk for at-a-glance notifications. You might even keep it in your bag for convenient travel charging instead of bulky portable chargers or power banks. Think about where you want to use this accessory and what you want to do with the device(s) it charges while it’s powering up. For example, a wireless charging pad might be better for bedside use if you just want to be able to drop your phone down at the end of a long day and know it’ll be powered up in the morning. However, a stand will be better if you have an iPhone and want to make use of the Standby feature during the nighttime hours. For a desk wireless charger, a stand lets you more easily glance at phone notifications throughout the day. For traveling, undoubtedly, a puck-style charging pad is best since it will take up much less space in your bag than a stand would. Many power banks also include wireless charging pads built in, so one of those might make even more sense for those who are always on the go. Some foldable chargers are also designed for travel, collapsing flat to take up less space. Wireless charging performance Although wireless charging is usually slower than its wired equivalent, speed and wattage are still important considerations. A fast charger can supply enough power for a long night out in the time it takes to change outfits. Look for options that promise faster charging and support standards like Qi2 certified charging for the best balance of efficiency and compatibility. In general, a 15W charger is more than quick enough for most situations, and you’ll need a MagSafe-compatible charger to extract that level of performance from an iPhone. With that said, even the slower 7.5W and 10W chargers are fast enough for an overnight power-up. If anything, you’ll want to worry more about support for cases. While many models can deliver power through a reasonably thick case (typically 3mm to 5mm), you’ll occasionally run into examples that only work with naked phones. There are some proprietary chargers that smash the 15W barrier if you have the right phone. Apple’s latest MagSafe charging pad can provide up to 25W of wireless power to compatible iPhones when paired with a 30W or 35W adapter — the latter being another component you’ll have to get right to make sure the whole equation works as fast as it possibly can. Quality and box contents Pay attention to what’s included in the box. Some wireless chargers don’t include power adapters, and others may even ask you to reuse your phone’s USB-C charging cable. What may seem to be a bargain may prove expensive if you have to buy extras just to use it properly. As mentioned above, you’ll want to make sure all of the components needed to use the wireless charger can provide the level of power you need — you’re only as strong (or in this case, fast) as your weakest link. Fit and finish is also worth considering. You’re likely going to use your wireless charger every day, so even small differences in build quality could make the difference between joy and frustration. If your charger doesn’t use MagSafe-compatible tech, textured surfaces like fabric or rubberized plastic are more likely to keep your phone in place. The base should be grippy or weighty enough that the charger won’t slide around. Also double check that the wireless charger you’re considering can support phones outfitted with cases — the specifications are usually listed in the charger’s description or specs. You’ll also want to think about the minor conveniences. Status lights are useful for indicating correct phone placement, but an overly bright light can be distracting. Ideally, the light dims or shuts off after a certain period of time. And while we caution against lips and trays that limit compatibility, you may still want some barriers to prevent your device falling off its perch on the charging station. Wireless chargers FAQs Do wireless chargers work if you have a phone case? Many wireless chargers do work if you leave the case on your phone. Generally, a case up to 3mm thick should be compatible with most wireless chargers. However, you should check the manufacturer’s guide to ensure a case is supported. How do I know if my phone supports wireless charging? Checking the phone’s specification should tell you if your phone is compatible with wireless charging. You might see words like “Qi wireless charging” or “wireless charging compatible.” Do cords charge your phone faster? Most often, wired charging will be faster than wireless charging. However, wired charging also depends on what the charging cable’s speed is and how much power it’s designed to carry. A quick-charging cable that can transmit up to 120W of power is going to be faster than a wireless charger.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-wireless-charger-140036359.html?src=rss",
          "feed_position": 13,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-02/c9a24a20-b7a0-11ed-b3cd-16d5d607f8d1"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
          "published_at": "Mon, 19 Jan 2026 14:00:00 GMT",
          "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.",
          "standfirst": "The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.Claude Code, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its pricing — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.Now, a free alternative is gaining traction. Goose, an open-source AI agent developed by Block (the financial technology company formerly known as Square), offers nearly identical functionality to Claude Code but runs entirely on a user&#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.\"Your data stays with you, period,\" said Parth Sareen, a software engineer who demonstrated the tool during a recent livestream. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.The project has exploded in popularity. Goose now boasts more than 26,100 stars on GitHub, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, 1.20.1, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.For developers frustrated by Claude Code&#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.Anthropic&#x27;s new rate limits spark a developer revoltTo understand why Goose matters, you need to understand the Claude Code pricing controversy.Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The Pro plan, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.The Max plans, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&#x27;s most powerful model, Claude 4.5 Opus. But even these premium tiers come with restrictions that have inflamed the developer community.In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.The problem? Those \"hours\" are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.\"It&#x27;s confusing and vague,\" one developer wrote in a widely shared analysis. \"When they say &#x27;24-40 hours of Opus 4,&#x27; that doesn&#x27;t really tell you anything useful about what you&#x27;re actually getting.\"The backlash on Reddit and developer forums has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions \"a joke\" and \"unusable for real work.\"Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code \"continuously in the background, 24/7.\" But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.How Block built a free AI coding agent that works offlineGoose takes a radically different approach to the same problem.Built by Block, the payments company led by Jack Dorsey, Goose is what engineers call an \"on-machine AI agent.\" Unlike Claude Code, which sends your queries to Anthropic&#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.The project&#x27;s documentation describes it as going \"beyond code suggestions\" to \"install, execute, edit, and test with any LLM.\" That last phrase — \"any LLM\" — is the key differentiator. Goose is model-agnostic by design.You can connect Goose to Anthropic&#x27;s Claude models if you have API access. You can use OpenAI&#x27;s GPT-5 or Google&#x27;s Gemini. You can route it through services like Groq or OpenRouter. Or — and this is where things get interesting — you can run it entirely locally using tools like Ollama, which let you download and execute open-source models on your own hardware.The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.\"I use Ollama all the time on planes — it&#x27;s a lot of fun!\" Sareen noted during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.What Goose can do that traditional code assistants can&#x27;tGoose operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.The architecture relies on what the AI industry calls \"tool calling\" or \"function calling\" — the ability for a language model to request specific actions from external systems. When you ask Goose to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&#x27;t just generate text describing what should happen. It actually executes those operations.This capability depends heavily on the underlying language model. Claude 4 models from Anthropic currently perform best at tool calling, according to the Berkeley Function-Calling Leaderboard, which ranks models on their ability to translate natural language requests into executable code and system commands.But newer open-source models are catching up quickly. Goose&#x27;s documentation highlights several options with strong tool-calling support: Meta&#x27;s Llama series, Alibaba&#x27;s Qwen models, Google&#x27;s Gemma variants, and DeepSeek&#x27;s reasoning-focused architectures.The tool also integrates with the Model Context Protocol, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.Setting Up Goose with a Local ModelFor developers interested in a completely free, privacy-preserving setup, the process involves three main components: Goose itself, Ollama (a tool for running open-source models locally), and a compatible language model.Step 1: Install OllamaOllama is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.Download and install Ollama from ollama.com. Once installed, you can pull models with a single command. For coding tasks, Qwen 2.5 offers strong tool-calling support:ollama run qwen2.5The model downloads automatically and begins running on your machine.Step 2: Install GooseGoose is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.Installation instructions vary by operating system but generally involve downloading from Goose&#x27;s GitHub releases page or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.Step 3: Configure the ConnectionIn Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&#x27;s default port) and click Submit.For the command-line version, run goose configure, select \"Configure Providers,\" choose Ollama, and enter the model name when prompted.That&#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.The RAM, processing power, and trade-offs you should know aboutThe obvious question: what kind of computer do you need?Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.Block&#x27;s documentation suggests that 32 gigabytes of RAM provides \"a solid baseline for larger models and outputs.\" For Mac users, this means the computer&#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.But you don&#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. Qwen 2.5, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.\"You don&#x27;t need to run the largest models to get excellent results,\" Sareen emphasized. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.For context, Apple&#x27;s entry-level MacBook Air with 8 gigabytes of RAM would struggle with most capable coding models. But a MacBook Pro with 32 gigabytes — increasingly common among professional developers — handles them comfortably.Why keeping your code off the cloud matters more than everGoose with a local LLM is not a perfect substitute for Claude Code. The comparison involves real trade-offs that developers should understand.Model Quality: Claude 4.5 Opus, Anthropic&#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.One developer who switched to the $200 Claude Code plan described the difference bluntly: \"When I say &#x27;make this look modern,&#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.\"Context Window: Claude Sonnet 4.5, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.Speed: Cloud-based services like Claude Code run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&#x27;re making rapid changes and waiting for AI feedback.Tooling Maturity: Claude Code benefits from Anthropic&#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. Goose, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding marketGoose enters a crowded market of AI coding tools, but occupies a distinctive position.Cursor, a popular AI-enhanced code editor, charges $20 per month for its Pro tier and $200 for Ultra—pricing that mirrors Claude Code&#x27;s Max plans. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&#x27;s hourly resets.Cline, Roo Code, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.Amazon&#x27;s CodeWhisperer, GitHub Copilot, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.Goose&#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&#x27;s competing on freedom — both financial and architectural.The $200-a-month era for AI coding tools may be endingThe AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&#x27;s Kimi K2 and z.ai&#x27;s GLM 4.5 now benchmark near Claude Sonnet 4 levels — and they&#x27;re freely available.If this trajectory continues, the quality advantage that justifies Claude Code&#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer Claude Code. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in Goose.The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.Goose is available for download at github.com/block/goose. Ollama is available at ollama.com. Both projects are free and open source.",
          "content": "The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.Claude Code, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its pricing — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.Now, a free alternative is gaining traction. Goose, an open-source AI agent developed by Block (the financial technology company formerly known as Square), offers nearly identical functionality to Claude Code but runs entirely on a user&#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.\"Your data stays with you, period,\" said Parth Sareen, a software engineer who demonstrated the tool during a recent livestream. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.The project has exploded in popularity. Goose now boasts more than 26,100 stars on GitHub, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, 1.20.1, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.For developers frustrated by Claude Code&#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.Anthropic&#x27;s new rate limits spark a developer revoltTo understand why Goose matters, you need to understand the Claude Code pricing controversy.Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The Pro plan, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.The Max plans, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&#x27;s most powerful model, Claude 4.5 Opus. But even these premium tiers come with restrictions that have inflamed the developer community.In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.The problem? Those \"hours\" are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.\"It&#x27;s confusing and vague,\" one developer wrote in a widely shared analysis. \"When they say &#x27;24-40 hours of Opus 4,&#x27; that doesn&#x27;t really tell you anything useful about what you&#x27;re actually getting.\"The backlash on Reddit and developer forums has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions \"a joke\" and \"unusable for real work.\"Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code \"continuously in the background, 24/7.\" But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.How Block built a free AI coding agent that works offlineGoose takes a radically different approach to the same problem.Built by Block, the payments company led by Jack Dorsey, Goose is what engineers call an \"on-machine AI agent.\" Unlike Claude Code, which sends your queries to Anthropic&#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.The project&#x27;s documentation describes it as going \"beyond code suggestions\" to \"install, execute, edit, and test with any LLM.\" That last phrase — \"any LLM\" — is the key differentiator. Goose is model-agnostic by design.You can connect Goose to Anthropic&#x27;s Claude models if you have API access. You can use OpenAI&#x27;s GPT-5 or Google&#x27;s Gemini. You can route it through services like Groq or OpenRouter. Or — and this is where things get interesting — you can run it entirely locally using tools like Ollama, which let you download and execute open-source models on your own hardware.The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.\"I use Ollama all the time on planes — it&#x27;s a lot of fun!\" Sareen noted during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.What Goose can do that traditional code assistants can&#x27;tGoose operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.The architecture relies on what the AI industry calls \"tool calling\" or \"function calling\" — the ability for a language model to request specific actions from external systems. When you ask Goose to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&#x27;t just generate text describing what should happen. It actually executes those operations.This capability depends heavily on the underlying language model. Claude 4 models from Anthropic currently perform best at tool calling, according to the Berkeley Function-Calling Leaderboard, which ranks models on their ability to translate natural language requests into executable code and system commands.But newer open-source models are catching up quickly. Goose&#x27;s documentation highlights several options with strong tool-calling support: Meta&#x27;s Llama series, Alibaba&#x27;s Qwen models, Google&#x27;s Gemma variants, and DeepSeek&#x27;s reasoning-focused architectures.The tool also integrates with the Model Context Protocol, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.Setting Up Goose with a Local ModelFor developers interested in a completely free, privacy-preserving setup, the process involves three main components: Goose itself, Ollama (a tool for running open-source models locally), and a compatible language model.Step 1: Install OllamaOllama is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.Download and install Ollama from ollama.com. Once installed, you can pull models with a single command. For coding tasks, Qwen 2.5 offers strong tool-calling support:ollama run qwen2.5The model downloads automatically and begins running on your machine.Step 2: Install GooseGoose is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.Installation instructions vary by operating system but generally involve downloading from Goose&#x27;s GitHub releases page or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.Step 3: Configure the ConnectionIn Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&#x27;s default port) and click Submit.For the command-line version, run goose configure, select \"Configure Providers,\" choose Ollama, and enter the model name when prompted.That&#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.The RAM, processing power, and trade-offs you should know aboutThe obvious question: what kind of computer do you need?Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.Block&#x27;s documentation suggests that 32 gigabytes of RAM provides \"a solid baseline for larger models and outputs.\" For Mac users, this means the computer&#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.But you don&#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. Qwen 2.5, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.\"You don&#x27;t need to run the largest models to get excellent results,\" Sareen emphasized. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.For context, Apple&#x27;s entry-level MacBook Air with 8 gigabytes of RAM would struggle with most capable coding models. But a MacBook Pro with 32 gigabytes — increasingly common among professional developers — handles them comfortably.Why keeping your code off the cloud matters more than everGoose with a local LLM is not a perfect substitute for Claude Code. The comparison involves real trade-offs that developers should understand.Model Quality: Claude 4.5 Opus, Anthropic&#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.One developer who switched to the $200 Claude Code plan described the difference bluntly: \"When I say &#x27;make this look modern,&#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.\"Context Window: Claude Sonnet 4.5, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.Speed: Cloud-based services like Claude Code run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&#x27;re making rapid changes and waiting for AI feedback.Tooling Maturity: Claude Code benefits from Anthropic&#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. Goose, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding marketGoose enters a crowded market of AI coding tools, but occupies a distinctive position.Cursor, a popular AI-enhanced code editor, charges $20 per month for its Pro tier and $200 for Ultra—pricing that mirrors Claude Code&#x27;s Max plans. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&#x27;s hourly resets.Cline, Roo Code, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.Amazon&#x27;s CodeWhisperer, GitHub Copilot, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.Goose&#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&#x27;s competing on freedom — both financial and architectural.The $200-a-month era for AI coding tools may be endingThe AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&#x27;s Kimi K2 and z.ai&#x27;s GLM 4.5 now benchmark near Claude Sonnet 4 levels — and they&#x27;re freely available.If this trajectory continues, the quality advantage that justifies Claude Code&#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer Claude Code. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in Goose.The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.Goose is available for download at github.com/block/goose. Ollama is available at ollama.com. Both projects are free and open source.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1U9H8GLIqoGqKpitVfgw3T/ba56292f99409eca709dac0b176ec245/nuneybits_Vector_art_of_white_goose_silhouette_flying_through_c_8100d5a7-9e36-4ed6-a188-016470e1d0e1.webp?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/16AQsBHmZwamZhEThe81IE/c62d8f72d2a927091292807e176cbf7c/1c3ad1be-18a5-42ae-9e71-8e1407640d0f.jpg?w=300&q=30",
      "popularity_score": 2018.340601388889
    },
    {
      "id": "cluster_26",
      "coverage": 2,
      "updated_at": "Tue, 20 Jan 2026 13:00:37 -0500",
      "title": "Netflix adds a real-time voting feature for its Star Search reboot, available on mobile, smart TVs, and streaming devices, but not on a browser (Ivan Mehta/TechCrunch)",
      "neutral_headline": "Netflix’s Star Search will let you vote to decide who wins",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260120/p28#a260120p28",
          "published_at": "Tue, 20 Jan 2026 13:00:37 -0500",
          "title": "Netflix adds a real-time voting feature for its Star Search reboot, available on mobile, smart TVs, and streaming devices, but not on a browser (Ivan Mehta/TechCrunch)",
          "standfirst": "Ivan Mehta / TechCrunch: Netflix adds a real-time voting feature for its Star Search reboot, available on mobile, smart TVs, and streaming devices, but not on a browser &mdash; Netflix today is launching a new feature that will allow users to interact with live content through voting. The streaming company said the option &hellip;",
          "content": "Ivan Mehta / TechCrunch: Netflix adds a real-time voting feature for its Star Search reboot, available on mobile, smart TVs, and streaming devices, but not on a browser &mdash; Netflix today is launching a new feature that will allow users to interact with live content through voting. The streaming company said the option &hellip;",
          "feed_position": 5,
          "image_url": "http://www.techmeme.com/260120/i28.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/entertainment/864424/netflix-star-search-live-voting",
          "published_at": "2026-01-20T12:19:41-05:00",
          "title": "Netflix’s Star Search will let you vote to decide who wins",
          "standfirst": "Though Netflix's upcoming Star Search reboot will feature a panel of celebrity judges, viewers are going to have a hand in choosing which contestants win the competition. Ahead of Star Search's premiere tonight, Netflix has announced that it is launching a new real-time voting functionality that will give you the ability to tell the streamer [&#8230;]",
          "content": "Though Netflix's upcoming Star Search reboot will feature a panel of celebrity judges, viewers are going to have a hand in choosing which contestants win the competition. Ahead of Star Search's premiere tonight, Netflix has announced that it is launching a new real-time voting functionality that will give you the ability to tell the streamer which performer you want to see succeed. Rather than having to send in a text message or visit a special website as was the case with American Idol, Star Search's voting can be done within the Netflix app while the show is airing live on Tuesdays and Wednesdays at 9PM ET / 6PM PT. In addition to the a … Read the full story at The Verge.",
          "feed_position": 4
        }
      ],
      "featured_image": "http://www.techmeme.com/260120/i28.jpg",
      "popularity_score": 2017.8008791666666
    },
    {
      "id": "cluster_34",
      "coverage": 2,
      "updated_at": "Tue, 20 Jan 2026 11:45:03 -0500",
      "title": "Setapp Mobile, one of the first alt iOS app stores launched in 2024 after the EU's DMA, plans to shut down, blaming \"still-evolving and complex business terms\" (Tim Hardwick/MacRumors)",
      "neutral_headline": "One of the first alternative app stores in the EU is shutting down",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260120/p25#a260120p25",
          "published_at": "Tue, 20 Jan 2026 11:45:03 -0500",
          "title": "Setapp Mobile, one of the first alt iOS app stores launched in 2024 after the EU's DMA, plans to shut down, blaming \"still-evolving and complex business terms\" (Tim Hardwick/MacRumors)",
          "standfirst": "Tim Hardwick / MacRumors: Setapp Mobile, one of the first alt iOS app stores launched in 2024 after the EU's DMA, plans to shut down, blaming &ldquo;still-evolving and complex business terms&rdquo; &mdash; Ukraine-based developer MacPaw is set to close Setapp Mobile, its alternative app store for iOS devices in the European Union, next month.",
          "content": "Tim Hardwick / MacRumors: Setapp Mobile, one of the first alt iOS app stores launched in 2024 after the EU's DMA, plans to shut down, blaming &ldquo;still-evolving and complex business terms&rdquo; &mdash; Ukraine-based developer MacPaw is set to close Setapp Mobile, its alternative app store for iOS devices in the European Union, next month.",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/260120/i25.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/20/one-of-the-first-alternative-app-stores-in-the-eu-is-shutting-down/",
          "published_at": "Tue, 20 Jan 2026 16:22:53 +0000",
          "title": "One of the first alternative app stores in the EU is shutting down",
          "standfirst": "Setapp Mobile, one of the first alternative app stores in the EU, is shutting down next month, citing Apple's ever-changing terms.",
          "content": "Setapp Mobile, one of the first alternative app stores in the EU, is shutting down next month, citing Apple's ever-changing terms.",
          "feed_position": 3
        }
      ],
      "featured_image": "http://www.techmeme.com/260120/i25.jpg",
      "popularity_score": 2016.5414347222222
    },
    {
      "id": "cluster_14",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 18:58:22 +0000",
      "title": "Sony is giving TCL control over its high-end Bravia TVs",
      "neutral_headline": "Sony is giving TCL control over its high-end Bravia TVs",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/tcl-to-gain-majority-ownership-over-sonys-bravia-tvs/",
          "published_at": "Tue, 20 Jan 2026 18:58:22 +0000",
          "title": "Sony is giving TCL control over its high-end Bravia TVs",
          "standfirst": "TCL will own 51 percent of the high-end TVs.",
          "content": "TCL is taking majority ownership of Sony’s Bravia series of TVs, the two companies announced today. The two firms said they have signed a memorandum of understanding and aim to sign binding agreements by the end of March. Pending “relevant regulatory approvals and other conditions,” the joint venture is expected to launch in April 2027. Under a new joint venture, Huizhou, China-headquartered TCL will own 51 percent of Tokyo, Japan-headquartered Sony’s “home entertainment business,” and Sony will own 49 percent, per an announcement today, adding:Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1236174910-1152x648-1768934089.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1236174910-1152x648-1768934089.jpg",
      "popularity_score": 341.76337916666665
    },
    {
      "id": "cluster_57",
      "coverage": 1,
      "updated_at": "Tue, 20 Jan 2026 15:00:04 +0000",
      "title": "The first commercial space station, Haven-1, is now undergoing assembly for launch",
      "neutral_headline": "The first commercial space station, Haven-1, is now undergoing assembly for launch",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/the-first-commercial-space-station-haven-1-is-now-undergoing-assembly-for-launch/",
          "published_at": "Tue, 20 Jan 2026 15:00:04 +0000",
          "title": "The first commercial space station, Haven-1, is now undergoing assembly for launch",
          "standfirst": "\"We have a very strong incentive to send a crew as quickly as we can safely do so.\"",
          "content": "As Ars reported last week, NASA's plan to replace the International Space Station with commercial space stations is running into a time crunch. The sprawling International Space Station is due to be decommissioned less than five years from now, and the US space agency has yet to formally publish rules and requirements for the follow-on stations being designed and developed by several different private companies. Although there are expected to be multiple bidders in \"phase two\" of NASA's commercial space station program, there are at present four main contenders: Voyager Technologies, Axiom Space, Blue Origin, and Vast Space. At some point later this year, the space agency is expected to select one, or more likely two, of these companies for larger contracts that will support their efforts to build their stations.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Vast_Haven-1_Integration_Phase-1_ISO8_Cleanroom_Spring_2026-01-15-DSC_1375-3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Vast_Haven-1_Integration_Phase-1_ISO8_Cleanroom_Spring_2026-01-15-DSC_1375-3-1152x648.jpg",
      "popularity_score": 335.7917125
    },
    {
      "id": "cluster_87",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 22:01:52 +0000",
      "title": "The fastest human spaceflight mission in history crawls closer to liftoff",
      "neutral_headline": "The fastest human spaceflight mission in history crawls closer to liftoff",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasas-artemis-ii-rocket-rolls-to-launch-pad-but-key-test-looms-ahead/",
          "published_at": "Mon, 19 Jan 2026 22:01:52 +0000",
          "title": "The fastest human spaceflight mission in history crawls closer to liftoff",
          "standfirst": "After a remarkably smooth launch campaign, Artemis II reached its last stop before the Moon.",
          "content": "KENNEDY SPACE CENTER, Florida—Preparations for the first human spaceflight to the Moon in more than 50 years took a big step forward this weekend with the rollout of the Artemis II rocket to its launch pad. The rocket reached a top speed of just 1 mph on the four-mile, 12-hour journey from the Vehicle Assembly Building to Launch Complex 39B at NASA's Kennedy Space Center in Florida. At the end of its nearly 10-day tour through cislunar space, the Orion capsule on top of the rocket will exceed 25,000 mph as it plunges into the atmosphere to bring its four-person crew back to Earth. \"This is the start of a very long journey,\" said NASA Administrator Jared Isaacman. \"We ended our last human exploration of the moon on Apollo 17.\"Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_0127-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_0127-1-1152x648.jpg",
      "popularity_score": 316
    },
    {
      "id": "cluster_91",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 19:04:18 +0000",
      "title": "Elon Musk accused of making up math to squeeze $134B from OpenAI, Microsoft",
      "neutral_headline": "Elon Musk accused of making up math to squeeze $134B from OpenAI, Microsoft",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/elon-musk-accused-of-making-up-math-to-squeeze-134b-from-openai-microsoft/",
          "published_at": "Mon, 19 Jan 2026 19:04:18 +0000",
          "title": "Elon Musk accused of making up math to squeeze $134B from OpenAI, Microsoft",
          "standfirst": "Musk's math reduced ChatGPT inventors' contributions to \"zero,\" OpenAI argued.",
          "content": "Elon Musk is going for some substantial damages in his lawsuit accusing OpenAI of abandoning its nonprofit mission and \"making a fool out of him\" as an early investor. On Friday, Musk filed a notice on remedies sought in the lawsuit, confirming that he's seeking damages between $79 billion and $134 billion from OpenAI and its largest backer, co-defendant Microsoft. Musk hired an expert he has never used before, C. Paul Wazzan, who reached this estimate by concluding that Musk's early contributions to OpenAI generated 50 to 75 percent of the nonprofit's current value. He got there by analyzing four factors: Musk's total financial contributions before he left OpenAI in 2018, Musk's proposed equity stake in OpenAI in 2017, Musk's current equity stake in xAI, and Musk's nonmonetary contributions to OpenAI (like investing time or lending his reputation).Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2087343447-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2087343447-1024x648.jpg",
      "popularity_score": 300
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 21:07:55 +0000",
      "title": "The first new Marathon game in decades will launch on March 5",
      "neutral_headline": "The first new Marathon game in decades will launch on March 5",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/bungies-delayed-marathon-revival-will-finally-launch-march-5/",
          "published_at": "Mon, 19 Jan 2026 21:07:55 +0000",
          "title": "The first new Marathon game in decades will launch on March 5",
          "standfirst": "Development hasn't exactly been smooth since the extraction shooter's 2023 announcement.",
          "content": "It has been nearly three years now since Destiny maker (and Sony subsidiary) Bungie formally announced a revival of the storied Marathon FPS franchise. And it has been about seven months since the game's originally announced release date of September 23, 2025, was pushed back indefinitely after a reportedly poor response to the game's first Alpha test. But today, in a post on the PlayStation Blog, Bungie revealed that the new Marathon would finally be hitting PS5, Windows, and Xbox Series X|S on March 5, narrowing down the monthlong March release window announced back in December. Today's preorder trailer revealing the Marathon release date. Unlike Destiny 2, which transitioned to a free-to-play model in 2019, the new Marathon sells a Standard Edition for $40 or a $60 Deluxe Edition that includes some digital rewards and cosmetics. That mirrors the pricing of the somewhat similar Arc Raiders, which recently hit 12 million sales in less than 12 weeks.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/marathon-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/marathon-1152x648.png",
      "popularity_score": 293
    },
    {
      "id": "cluster_89",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 19:52:22 +0000",
      "title": "Signs point to a sooner-rather-than-later M5 MacBook Pro refresh",
      "neutral_headline": "Signs point to a sooner-rather-than-later M5 MacBook Pro refresh",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/signs-point-to-a-sooner-rather-than-later-m5-macbook-pro-refresh/",
          "published_at": "Mon, 19 Jan 2026 19:52:22 +0000",
          "title": "Signs point to a sooner-rather-than-later M5 MacBook Pro refresh",
          "standfirst": "Delayed shipping times for current models sometimes means an update is imminent.",
          "content": "Mac power users waiting on new high-end MacBook Pro models may have been disappointed last fall when Apple released an M5 upgrade for the low-end 14-inch MacBook Pro without touching the M4 Pro or Max versions of the laptop. But the wait for M5 Pro and M5 Max models may be nearing its end. The tea-leaf readers at MacRumors noticed that shipping times for a handful of high-end MacBook Pro configurations have slipped into mid-to-late February, rather than being available immediately as most Mac models are. This is often, though not always, a sign that Apple has slowed down or stopped production of an existing product in anticipation of an update. Currently, the shipping delays affect the M4 Max versions of both the 14-inch and 16-inch MacBook Pros. If you order them today, these models will arrive sometime between February 3 and February 24, depending on the configuration you choose; many M4 Pro versions are still available for same-day shipping, though adding a nano-texture display or upgrading RAM can still add a week or so to the shipping time.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_6215-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_6215-1152x648.jpeg",
      "popularity_score": 283
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 17:16:38 +0000",
      "title": "Reports of ad-supported Xbox game streams show Microsoft's lack of imagination",
      "neutral_headline": "Reports of ad-supported Xbox game streams show Microsoft's lack of imagination",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/reports-of-ad-supported-xbox-game-streams-show-microsofts-lack-of-imagination/",
          "published_at": "Mon, 19 Jan 2026 17:16:38 +0000",
          "title": "Reports of ad-supported Xbox game streams show Microsoft's lack of imagination",
          "standfirst": "Xbox maker needs some fresher ideas for expanding access to cloud gaming.",
          "content": "Currently, Microsoft's long-running Cloud Gaming service is limited to players who have a Microsoft's Game Pass subscription. Now, new reporting suggests Microsoft is planning to offer non-subscribers access to game streams paid for by advertising in the near future, but only in extremely limited circumstances. The latest wave of rumors was set off late last week when The Verge's Tom Warren shared an Xbox Cloud Gaming loading screen with a message mentioning \"1 hour of ad supported playtime per session.\" That leaked message comes after Windows Central reported last summer that Microsoft has been \"exploring video ads for free games for quite some time,\" à la the two-minute sponsorships that appear before free-tier game streams on Nvidia's GeForce Now service. Don't get your hopes up for easy, free, ad-supported access to the entire Xbox Cloud Gaming library, though. Windows Central now reports that Microsoft will be using ads merely to slightly expand access to its \"Stream your own game\" program. That program currently offers subscribers to the Xbox Game Pass Essentials tier (or higher) the privilege of streaming versions of some of the Xbox games they've already purchased digitally. Windows Central's unnamed sources suggest that a \"session-based ad-supported access tier\" to stream those purchased games will be offered to non-subscribers as soon as \"this year.\"Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/06/Cloud-Gaming_iPadSurfaceiPhone-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/06/Cloud-Gaming_iPadSurfaceiPhone-1152x648.jpg",
      "popularity_score": 265
    },
    {
      "id": "cluster_92",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 18:24:49 +0000",
      "title": "Asus confirms its smartphone business is on indefinite hiatus",
      "neutral_headline": "Asus confirms its smartphone business is on indefinite hiatus",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/asus-confirms-its-smartphone-business-is-on-indefinite-hiatus/",
          "published_at": "Mon, 19 Jan 2026 18:24:49 +0000",
          "title": "Asus confirms its smartphone business is on indefinite hiatus",
          "standfirst": "Asus chairman Jonney Shih sees AI applications as the company's main focus going forward.",
          "content": "An unconfirmed report early this month suggested Asus was pulling back on its smartphone plans, but the company declined to comment at the time. Asus chairman Jonney Shih has now confirmed during an event in Taiwan the wind-down of its smartphone business. Instead, Asus will focus on AI products like robots and smart glasses. Shih addressed the company's future plans during a 2026 kick-off event in Taiwan, as reported by Inside. \"Asus will no longer add new mobile phone models in the future,\" said Shih (machine translated). So don't expect a new Zenfone or ROG Phone from Asus in 2026. That said, very few phone buyers were keeping tabs on the latest Asus phones anyway, which is probably why Asus is throwing in the towel. Shih isn't saying Asus won't ever release a new phone, but the company will take an \"indefinite wait-and-see\" approach. Again, this is a translation and could be interpreted in multiple ways.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ROG-2-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ROG-2-1-1152x648.jpg",
      "popularity_score": 263
    },
    {
      "id": "cluster_96",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 17:06:28 +0000",
      "title": "The race to build a super-large ground telescope is likely down to two competitors",
      "neutral_headline": "The race to build a super-large ground telescope is likely down to two competitors",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/as-europes-large-ground-telescope-project-advances-how-is-its-us-competitor-faring/",
          "published_at": "Mon, 19 Jan 2026 17:06:28 +0000",
          "title": "The race to build a super-large ground telescope is likely down to two competitors",
          "standfirst": "Ars checks in with the new president of the Giant Magellan Telescope.",
          "content": "I have been writing about the Giant Magellan Telescope for a long time. Nearly two decades ago, for example, I wrote that time was \"running out\" in the race to build the next great optical telescope on the ground. At the time the proposed telescope was one of three contenders to make a giant leap in mirror size from the roughly 10-meter-diameter instruments that existed then, to approximately 30 meters. This represented a huge increase in light-gathering potential, allowing astronomers to see much further into the universe—and therefore back into time—with far greater clarity. Since then the projects have advanced at various rates. An international consortium to build the Thirty Meter Telescope in Hawaii ran into local protests that have bogged down development. Its future came further into question when the US National Science Foundation dropped support for the project in favor of the Giant Magellan Telescope. Meanwhile the European Extremely Large Telescope (ELT) has advanced on a faster schedule, and this 39.5-meter telescope could observe its first light in 2029.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GMT-Rendering-IDOM-Enclosure-2024-1-scaled-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GMT-Rendering-IDOM-Enclosure-2024-1-scaled-1-1152x648.jpg",
      "popularity_score": 243
    },
    {
      "id": "cluster_108",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 12:00:45 +0000",
      "title": "10 things I learned from burning myself out with AI coding agents",
      "neutral_headline": "10 things I learned from burning myself out with AI coding agents",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2026/01/10-things-i-learned-from-burning-myself-out-with-ai-coding-agents/",
          "published_at": "Mon, 19 Jan 2026 12:00:45 +0000",
          "title": "10 things I learned from burning myself out with AI coding agents",
          "standfirst": "Opinion: As software power tools, AI agents may make people busier than ever before.",
          "content": "If you've ever used a 3D printer, you may recall the wondrous feeling when you first printed something you could have never sculpted or built yourself. Download a model file, load some plastic filament, push a button, and almost like magic, a three-dimensional object appears. But the result isn't polished and ready for mass production, and creating a novel shape requires more skills than just pushing a button. Interestingly, today's AI coding agents feel much the same way. Since November, I have used Claude Code and Claude Opus 4.5 through a personal Claude Max account to extensively experiment with AI-assisted software development (I have also used OpenAI's Codex in a similar way, though not as frequently). Fifty projects later, I'll be frank: I have not had this much fun with a computer since I learned BASIC on my Apple II Plus when I was 9 years old. This opinion comes not as an endorsement but as personal experience: I voluntarily undertook this project, and I paid out of pocket for both OpenAI and Anthropic's premium AI plans. Throughout my life, I have dabbled in programming as a utilitarian coder, writing small tools or scripts when needed. In my web development career, I wrote some small tools from scratch, but I primarily modified other people's code for my needs. Since 1990, I've programmed in BASIC, C, Visual Basic, PHP, ASP, Perl, Python, Ruby, MUSHcode, and some others. I am not an expert in any of these languages—I learned just enough to get the job done. I have developed my own hobby games over the years using BASIC, Torque Game Engine, and Godot, so I have some idea of what makes a good architecture for a modular program that can be expanded over time.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/super-programmer-hes-heating-up-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/super-programmer-hes-heating-up-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_98",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 16:00:27 +0000",
      "title": "Meet Veronika, the tool-using cow",
      "neutral_headline": "Meet Veronika, the tool-using cow",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/meet-veronika-the-tool-using-cow/",
          "published_at": "Mon, 19 Jan 2026 16:00:27 +0000",
          "title": "Meet Veronika, the tool-using cow",
          "standfirst": "Veronika uses sticks to scratch herself, suggesting scientists have underestimated cow cognition.",
          "content": "Far Side fans might recall a classic 1982 cartoon called \"Cow Tools,\" featuring a cow standing next to a jumble of strange objects—the joke being that cows don't use tools. That's why a pet Swiss brown cow in Austria named Veronika has caused a bit of a sensation: she likes to pick up random sticks and use them to scratch herself. According to a new paper published in the journal Current Biology, this is a form of multipurpose tool use and suggests that the cognitive capabilities of cows have been underestimated by scientists. As previously reported, tool use was once thought to be one of the defining features of humans, but examples of it were eventually observed in primates and other mammals. Dolphins can toss objects as a form of play, which some scientists consider to be a type of tool use, particularly when it involves another member of the same species. Potential purposes include a means of communication, social bonding, or aggressiveness. (Octopuses have also been observed engaging in similar throwing behavior.) But the biggest surprise came when birds were observed using tools in the wild. After all, birds are the only surviving dinosaurs, and mammals and dinosaurs hadn’t shared a common ancestor for hundreds of millions of years. In the wild, observed tool use has been limited to the corvids (crows and jays), which show a variety of other complex behaviors—they’ll remember your face and recognize the passing of their dead.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cowtool1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cowtool1-1152x648.jpg",
      "popularity_score": 130
    }
  ]
}