{
  "updated_at": "2025-12-09T07:22:14.246Z",
  "clusters": [
    {
      "id": "cluster_16",
      "coverage": 2,
      "updated_at": "Tue, 09 Dec 2025 01:03:00 GMT",
      "title": "Z.ai debuts open source GLM-4.6V, a native tool-calling vision model for multimodal reasoning",
      "neutral_headline": "Here's how Google is laying the foundation for our mixed reality future",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/z-ai-debuts-open-source-glm-4-6v-a-native-tool-calling-vision-model-for",
          "published_at": "Tue, 09 Dec 2025 01:03:00 GMT",
          "title": "Z.ai debuts open source GLM-4.6V, a native tool-calling vision model for multimodal reasoning",
          "standfirst": "Chinese AI startup Zhipu AI aka Z.ai has released its GLM-4.6V series, a new generation of open-source vision-language models (VLMs) optimized for multimodal reasoning, frontend automation, and high-efficiency deployment. The release includes two models in \"large\" and \"small\" sizes: GLM-4.6V (106B), a larger 106-billion parameter model aimed at cloud-scale inferenceGLM-4.6V-Flash (9B), a smaller model of only 9 billion parameters designed for low-latency, local applicationsRecall that generally speaking, models with more parameters — or internal settings governing their behavior, i.e. weights and biases — are more powerful, performant, and capable of performing at a higher general level across more varied tasks.However, smaller models can offer better efficiency for edge or real-time applications where latency and resource constraints are critical.The defining innovation in this series is the introduction of native function calling in a vision-language model—enabling direct use of tools such as search, cropping, or chart recognition with visual inputs. With a 128,000 token context length (equivalent to a 300-page novel&#x27;s worth of text exchanged in a single input/output interaction with the user) and state-of-the-art (SoTA) results across more than 20 benchmarks, the GLM-4.6V series positions itself as a highly competitive alternative to both closed and open-source VLMs. It&#x27;s available in the following formats:API access via OpenAI-compatible interfaceTry the demo on Zhipu’s web interfaceDownload weights from Hugging FaceDesktop assistant app available on Hugging Face SpacesLicensing and Enterprise UseGLM‑4.6V and GLM‑4.6V‑Flash are distributed under the MIT license, a permissive open-source license that allows free commercial and non-commercial use, modification, redistribution, and local deployment without obligation to open-source derivative works. This licensing model makes the series suitable for enterprise adoption, including scenarios that require full control over infrastructure, compliance with internal governance, or air-gapped environments.Model weights and documentation are publicly hosted on Hugging Face, with supporting code and tooling available on GitHub. The MIT license ensures maximum flexibility for integration into proprietary systems, including internal tools, production pipelines, and edge deployments.Architecture and Technical CapabilitiesThe GLM-4.6V models follow a conventional encoder-decoder architecture with significant adaptations for multimodal input. Both models incorporate a Vision Transformer (ViT) encoder—based on AIMv2-Huge—and an MLP projector to align visual features with a large language model (LLM) decoder. Video inputs benefit from 3D convolutions and temporal compression, while spatial encoding is handled using 2D-RoPE and bicubic interpolation of absolute positional embeddings.A key technical feature is the system’s support for arbitrary image resolutions and aspect ratios, including wide panoramic inputs up to 200:1. In addition to static image and document parsing, GLM-4.6V can ingest temporal sequences of video frames with explicit timestamp tokens, enabling robust temporal reasoning.On the decoding side, the model supports token generation aligned with function-calling protocols, allowing for structured reasoning across text, image, and tool outputs. This is supported by extended tokenizer vocabulary and output formatting templates to ensure consistent API or agent compatibility.Native Multimodal Tool UseGLM-4.6V introduces native multimodal function calling, allowing visual assets—such as screenshots, images, and documents—to be passed directly as parameters to tools. This eliminates the need for intermediate text-only conversions, which have historically introduced information loss and complexity.The tool invocation mechanism works bi-directionally:Input tools can be passed images or videos directly (e.g., document pages to crop or analyze).Output tools such as chart renderers or web snapshot utilities return visual data, which GLM-4.6V integrates directly into the reasoning chain.In practice, this means GLM-4.6V can complete tasks such as:Generating structured reports from mixed-format documentsPerforming visual audit of candidate imagesAutomatically cropping figures from papers during generationConducting visual web search and answering multimodal queriesHigh Performance Benchmarks Compared to Other Similar-Sized ModelsGLM-4.6V was evaluated across more than 20 public benchmarks covering general VQA, chart understanding, OCR, STEM reasoning, frontend replication, and multimodal agents. According to the benchmark chart released by Zhipu AI:GLM-4.6V (106B) achieves SoTA or near-SoTA scores among open-source models of comparable size (106B) on MMBench, MathVista, MMLongBench, ChartQAPro, RefCOCO, TreeBench, and more.GLM-4.6V-Flash (9B) outperforms other lightweight models (e.g., Qwen3-VL-8B, GLM-4.1V-9B) across almost all categories tested.The 106B model’s 128K-token window allows it to outperform larger models like Step-3 (321B) and Qwen3-VL-235B on long-context document tasks, video summarization, and structured multimodal reasoning.Example scores from the leaderboard include:MathVista: 88.2 (GLM-4.6V) vs. 84.6 (GLM-4.5V) vs. 81.4 (Qwen3-VL-8B)WebVoyager: 81.0 vs. 68.4 (Qwen3-VL-8B)Ref-L4-test: 88.9 vs. 89.5 (GLM-4.5V), but with better grounding fidelity at 87.7 (Flash) vs. 86.8Both models were evaluated using the vLLM inference backend and support SGLang for video-based tasks.Frontend Automation and Long-Context WorkflowsZhipu AI emphasized GLM-4.6V’s ability to support frontend development workflows. The model can:Replicate pixel-accurate HTML/CSS/JS from UI screenshotsAccept natural language editing commands to modify layoutsIdentify and manipulate specific UI components visuallyThis capability is integrated into an end-to-end visual programming interface, where the model iterates on layout, design intent, and output code using its native understanding of screen captures.In long-document scenarios, GLM-4.6V can process up to 128,000 tokens—enabling a single inference pass across:150 pages of text (input)200 slide decks1-hour videosZhipu AI reported successful use of the model in financial analysis across multi-document corpora and in summarizing full-length sports broadcasts with timestamped event detection.Training and Reinforcement LearningThe model was trained using multi-stage pre-training followed by supervised fine-tuning (SFT) and reinforcement learning (RL). Key innovations include:Curriculum Sampling (RLCS): Dynamically adjusts the difficulty of training samples based on model progressMulti-domain reward systems: Task-specific verifiers for STEM, chart reasoning, GUI agents, video QA, and spatial groundingFunction-aware training: Uses structured tags (e.g., <think>, <answer>, <|begin_of_box|>) to align reasoning and answer formattingThe reinforcement learning pipeline emphasizes verifiable rewards (RLVR) over human feedback (RLHF) for scalability, and avoids KL/entropy losses to stabilize training across multimodal domainsPricing (API)Zhipu AI offers competitive pricing for the GLM-4.6V series, with both the flagship model and its lightweight variant positioned for high accessibility.GLM-4.6V: $0.30 (input) / $0.90 (output) per 1M tokensGLM-4.6V-Flash: FreeCompared to major vision-capable and text-first LLMs, GLM-4.6V is among the most cost-efficient for multimodal reasoning at scale. Below is a comparative snapshot of pricing across providers:USD per 1M tokens — sorted lowest → highest total costModelInputOutputTotal CostSourceQwen 3 Turbo$0.05$0.20$0.25Alibaba CloudERNIE 4.5 Turbo$0.11$0.45$0.56QianfanGLM‑4.6V$0.30$0.90$1.20Z.AIGrok 4.1 Fast (reasoning)$0.20$0.50$0.70xAIGrok 4.1 Fast (non-reasoning)$0.20$0.50$0.70xAIdeepseek-chat (V3.2-Exp)$0.28$0.42$0.70DeepSeekdeepseek-reasoner (V3.2-Exp)$0.28$0.42$0.70DeepSeekQwen 3 Plus$0.40$1.20$1.60Alibaba CloudERNIE 5.0$0.85$3.40$4.25QianfanQwen-Max$1.60$6.40$8.00Alibaba CloudGPT-5.1$1.25$10.00$11.25OpenAIGemini 2.5 Pro (≤200K)$1.25$10.00$11.25GoogleGemini 3 Pro (≤200K)$2.00$12.00$14.00GoogleGemini 2.5 Pro (>200K)$2.50$15.00$17.50GoogleGrok 4 (0709)$3.00$15.00$18.00xAIGemini 3 Pro (>200K)$4.00$18.00$22.00GoogleClaude Opus 4.1$15.00$75.00$90.00AnthropicPrevious Releases: GLM‑4.5 Series and Enterprise ApplicationsPrior to GLM‑4.6V, Z.ai released the GLM‑4.5 family in mid-2025, establishing the company as a serious contender in open-source LLM development. The flagship GLM‑4.5 and its smaller sibling GLM‑4.5‑Air both support reasoning, tool use, coding, and agentic behaviors, while offering strong performance across standard benchmarks. The models introduced dual reasoning modes (“thinking” and “non-thinking”) and could automatically generate complete PowerPoint presentations from a single prompt — a feature positioned for use in enterprise reporting, education, and internal comms workflows. Z.ai also extended the GLM‑4.5 series with additional variants such as GLM‑4.5‑X, AirX, and Flash, targeting ultra-fast inference and low-cost scenarios.Together, these features position the GLM‑4.5 series as a cost-effective, open, and production-ready alternative for enterprises needing autonomy over model deployment, lifecycle management, and integration pipelEcosystem ImplicationsThe GLM-4.6V release represents a notable advance in open-source multimodal AI. While large vision-language models have proliferated over the past year, few offer:Integrated visual tool usageStructured multimodal generationAgent-oriented memory and decision logicZhipu AI’s emphasis on “closing the loop” from perception to action via native function calling marks a step toward agentic multimodal systems. The model’s architecture and training pipeline show a continued evolution of the GLM family, positioning it competitively alongside offerings like OpenAI’s GPT-4V and Google DeepMind’s Gemini-VL.Takeaway for Enterprise LeadersWith GLM-4.6V, Zhipu AI introduces an open-source VLM capable of native visual tool use, long-context reasoning, and frontend automation. It sets new performance marks among models of similar size and provides a scalable platform for building agentic, multimodal AI systems.",
          "content": "Chinese AI startup Zhipu AI aka Z.ai has released its GLM-4.6V series, a new generation of open-source vision-language models (VLMs) optimized for multimodal reasoning, frontend automation, and high-efficiency deployment. The release includes two models in \"large\" and \"small\" sizes: GLM-4.6V (106B), a larger 106-billion parameter model aimed at cloud-scale inferenceGLM-4.6V-Flash (9B), a smaller model of only 9 billion parameters designed for low-latency, local applicationsRecall that generally speaking, models with more parameters — or internal settings governing their behavior, i.e. weights and biases — are more powerful, performant, and capable of performing at a higher general level across more varied tasks.However, smaller models can offer better efficiency for edge or real-time applications where latency and resource constraints are critical.The defining innovation in this series is the introduction of native function calling in a vision-language model—enabling direct use of tools such as search, cropping, or chart recognition with visual inputs. With a 128,000 token context length (equivalent to a 300-page novel&#x27;s worth of text exchanged in a single input/output interaction with the user) and state-of-the-art (SoTA) results across more than 20 benchmarks, the GLM-4.6V series positions itself as a highly competitive alternative to both closed and open-source VLMs. It&#x27;s available in the following formats:API access via OpenAI-compatible interfaceTry the demo on Zhipu’s web interfaceDownload weights from Hugging FaceDesktop assistant app available on Hugging Face SpacesLicensing and Enterprise UseGLM‑4.6V and GLM‑4.6V‑Flash are distributed under the MIT license, a permissive open-source license that allows free commercial and non-commercial use, modification, redistribution, and local deployment without obligation to open-source derivative works. This licensing model makes the series suitable for enterprise adoption, including scenarios that require full control over infrastructure, compliance with internal governance, or air-gapped environments.Model weights and documentation are publicly hosted on Hugging Face, with supporting code and tooling available on GitHub. The MIT license ensures maximum flexibility for integration into proprietary systems, including internal tools, production pipelines, and edge deployments.Architecture and Technical CapabilitiesThe GLM-4.6V models follow a conventional encoder-decoder architecture with significant adaptations for multimodal input. Both models incorporate a Vision Transformer (ViT) encoder—based on AIMv2-Huge—and an MLP projector to align visual features with a large language model (LLM) decoder. Video inputs benefit from 3D convolutions and temporal compression, while spatial encoding is handled using 2D-RoPE and bicubic interpolation of absolute positional embeddings.A key technical feature is the system’s support for arbitrary image resolutions and aspect ratios, including wide panoramic inputs up to 200:1. In addition to static image and document parsing, GLM-4.6V can ingest temporal sequences of video frames with explicit timestamp tokens, enabling robust temporal reasoning.On the decoding side, the model supports token generation aligned with function-calling protocols, allowing for structured reasoning across text, image, and tool outputs. This is supported by extended tokenizer vocabulary and output formatting templates to ensure consistent API or agent compatibility.Native Multimodal Tool UseGLM-4.6V introduces native multimodal function calling, allowing visual assets—such as screenshots, images, and documents—to be passed directly as parameters to tools. This eliminates the need for intermediate text-only conversions, which have historically introduced information loss and complexity.The tool invocation mechanism works bi-directionally:Input tools can be passed images or videos directly (e.g., document pages to crop or analyze).Output tools such as chart renderers or web snapshot utilities return visual data, which GLM-4.6V integrates directly into the reasoning chain.In practice, this means GLM-4.6V can complete tasks such as:Generating structured reports from mixed-format documentsPerforming visual audit of candidate imagesAutomatically cropping figures from papers during generationConducting visual web search and answering multimodal queriesHigh Performance Benchmarks Compared to Other Similar-Sized ModelsGLM-4.6V was evaluated across more than 20 public benchmarks covering general VQA, chart understanding, OCR, STEM reasoning, frontend replication, and multimodal agents. According to the benchmark chart released by Zhipu AI:GLM-4.6V (106B) achieves SoTA or near-SoTA scores among open-source models of comparable size (106B) on MMBench, MathVista, MMLongBench, ChartQAPro, RefCOCO, TreeBench, and more.GLM-4.6V-Flash (9B) outperforms other lightweight models (e.g., Qwen3-VL-8B, GLM-4.1V-9B) across almost all categories tested.The 106B model’s 128K-token window allows it to outperform larger models like Step-3 (321B) and Qwen3-VL-235B on long-context document tasks, video summarization, and structured multimodal reasoning.Example scores from the leaderboard include:MathVista: 88.2 (GLM-4.6V) vs. 84.6 (GLM-4.5V) vs. 81.4 (Qwen3-VL-8B)WebVoyager: 81.0 vs. 68.4 (Qwen3-VL-8B)Ref-L4-test: 88.9 vs. 89.5 (GLM-4.5V), but with better grounding fidelity at 87.7 (Flash) vs. 86.8Both models were evaluated using the vLLM inference backend and support SGLang for video-based tasks.Frontend Automation and Long-Context WorkflowsZhipu AI emphasized GLM-4.6V’s ability to support frontend development workflows. The model can:Replicate pixel-accurate HTML/CSS/JS from UI screenshotsAccept natural language editing commands to modify layoutsIdentify and manipulate specific UI components visuallyThis capability is integrated into an end-to-end visual programming interface, where the model iterates on layout, design intent, and output code using its native understanding of screen captures.In long-document scenarios, GLM-4.6V can process up to 128,000 tokens—enabling a single inference pass across:150 pages of text (input)200 slide decks1-hour videosZhipu AI reported successful use of the model in financial analysis across multi-document corpora and in summarizing full-length sports broadcasts with timestamped event detection.Training and Reinforcement LearningThe model was trained using multi-stage pre-training followed by supervised fine-tuning (SFT) and reinforcement learning (RL). Key innovations include:Curriculum Sampling (RLCS): Dynamically adjusts the difficulty of training samples based on model progressMulti-domain reward systems: Task-specific verifiers for STEM, chart reasoning, GUI agents, video QA, and spatial groundingFunction-aware training: Uses structured tags (e.g., <think>, <answer>, <|begin_of_box|>) to align reasoning and answer formattingThe reinforcement learning pipeline emphasizes verifiable rewards (RLVR) over human feedback (RLHF) for scalability, and avoids KL/entropy losses to stabilize training across multimodal domainsPricing (API)Zhipu AI offers competitive pricing for the GLM-4.6V series, with both the flagship model and its lightweight variant positioned for high accessibility.GLM-4.6V: $0.30 (input) / $0.90 (output) per 1M tokensGLM-4.6V-Flash: FreeCompared to major vision-capable and text-first LLMs, GLM-4.6V is among the most cost-efficient for multimodal reasoning at scale. Below is a comparative snapshot of pricing across providers:USD per 1M tokens — sorted lowest → highest total costModelInputOutputTotal CostSourceQwen 3 Turbo$0.05$0.20$0.25Alibaba CloudERNIE 4.5 Turbo$0.11$0.45$0.56QianfanGLM‑4.6V$0.30$0.90$1.20Z.AIGrok 4.1 Fast (reasoning)$0.20$0.50$0.70xAIGrok 4.1 Fast (non-reasoning)$0.20$0.50$0.70xAIdeepseek-chat (V3.2-Exp)$0.28$0.42$0.70DeepSeekdeepseek-reasoner (V3.2-Exp)$0.28$0.42$0.70DeepSeekQwen 3 Plus$0.40$1.20$1.60Alibaba CloudERNIE 5.0$0.85$3.40$4.25QianfanQwen-Max$1.60$6.40$8.00Alibaba CloudGPT-5.1$1.25$10.00$11.25OpenAIGemini 2.5 Pro (≤200K)$1.25$10.00$11.25GoogleGemini 3 Pro (≤200K)$2.00$12.00$14.00GoogleGemini 2.5 Pro (>200K)$2.50$15.00$17.50GoogleGrok 4 (0709)$3.00$15.00$18.00xAIGemini 3 Pro (>200K)$4.00$18.00$22.00GoogleClaude Opus 4.1$15.00$75.00$90.00AnthropicPrevious Releases: GLM‑4.5 Series and Enterprise ApplicationsPrior to GLM‑4.6V, Z.ai released the GLM‑4.5 family in mid-2025, establishing the company as a serious contender in open-source LLM development. The flagship GLM‑4.5 and its smaller sibling GLM‑4.5‑Air both support reasoning, tool use, coding, and agentic behaviors, while offering strong performance across standard benchmarks. The models introduced dual reasoning modes (“thinking” and “non-thinking”) and could automatically generate complete PowerPoint presentations from a single prompt — a feature positioned for use in enterprise reporting, education, and internal comms workflows. Z.ai also extended the GLM‑4.5 series with additional variants such as GLM‑4.5‑X, AirX, and Flash, targeting ultra-fast inference and low-cost scenarios.Together, these features position the GLM‑4.5 series as a cost-effective, open, and production-ready alternative for enterprises needing autonomy over model deployment, lifecycle management, and integration pipelEcosystem ImplicationsThe GLM-4.6V release represents a notable advance in open-source multimodal AI. While large vision-language models have proliferated over the past year, few offer:Integrated visual tool usageStructured multimodal generationAgent-oriented memory and decision logicZhipu AI’s emphasis on “closing the loop” from perception to action via native function calling marks a step toward agentic multimodal systems. The model’s architecture and training pipeline show a continued evolution of the GLM family, positioning it competitively alongside offerings like OpenAI’s GPT-4V and Google DeepMind’s Gemini-VL.Takeaway for Enterprise LeadersWith GLM-4.6V, Zhipu AI introduces an open-source VLM capable of native visual tool use, long-context reasoning, and frontend automation. It sets new performance marks among models of similar size and provides a scalable platform for building agentic, multimodal AI systems.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/c8LjxKPtjJumRUwmgig3W/3ceb88204d1ec334f3ce3719b80793eb/6Ud5A3f_99gyh14m2ffZr.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/heres-how-google-is-laying-the-foundation-for-our-mixed-reality-future-180000716.html",
          "published_at": "Mon, 08 Dec 2025 19:57:32 +0000",
          "title": "Here's how Google is laying the foundation for our mixed reality future",
          "standfirst": "Today, during the XR edition of The Android Show, Google showed off a bunch of updates and new features headed to its mixed reality OS. And while most of the news was aimed at developers, I got a chance to demo some of the platform's expanded capabilities on a range of hardware including Samsung's Galaxy XR headset, two different reference designs and an early version of Xreal's Project Aura smart glasses and I came away rather impressed. So here's a rundown of what I saw and how it will impact the rapidly growing ecosystem of head-mounted displays.First up was one of Google's reference design smart glasses with a single waveguide RGB display built into its right lens. I've included a picture of it here, but try not to read too deeply into its design or aesthetics, as this device is meant to be a testbed for Android XR features and not an early look at upcoming models.Try not to read too much into the appearance of Google's reference design smart glasses, as they are explicitly labeled as prototypes meant to test upcoming features in Android XR.Sam Rutherford for EngadgetAfter putting them on, I was able to ask Gemini to play some tunes on YouTube Music before answering a call simply by tapping on the touchpad built into the right side of the frames. And because the reference model also had onboard world-facing cameras, I could easily share my view with the person on the other end of the line. Naturally, I was curious about how glasses had the bandwidth to do all this, because in normal use, they rely on a Bluetooth or Bluetooth LE connection. When asked, Max Spear, Group Product Manager for XR, shared that depending on the situation, the device can seamlessly switch between both Bluetooth and Wi-Fi, which was rather impressive because I couldn't even detect when that transition happened. Spear also noted that one of Google's focuses for Android XR is making it easier for developers to port over the apps people already know and love. This means for devices like the reference design I wore that feature a built-in display (or displays), the OS actually uses the same code meant for standard Android notifications (like quick replies) to create a minimalist UI instead of forcing app makers to update each piece of software to be compliant with an ever-increasing number of devices. Alternatively, for models that are super lightweight and rely strictly on speakers (like Bose Frames), Google has also designed Android XR so that you only need mics and voice controls to access a wide variety of apps without the need for visual menus. This is the picture Google's reference design smart glasses created (via Gemini ) when I asked it to transform a photo I took of some pantry shelves into a sci-fi kitchen. Sam Rutherford for EngadgetMeanwhile, if you're hoping to take photos with your smart glasses, there's a surprising amount of capability there, too. Not only was I able to ask Gemini to take a photo, the glasses were also able to send a higher-res version to a connected smartwatch, which is super handy in case you want to review the image before moving on to the next shot. And when you want to inject some creativity, you can ask Gemini to transform pictures into practically anything you can imagine via Nano Banana. In my case, I asked the AI to change a shot of a pantry into a sci-fi kitchen and Gemini delivered with aplomb, including converting the room into a metal-clad setting complete with lots of light strips and a few bursts of steam.However, one of the most impressive demos was when I asked Google's reference glasses to look at some of that same pantry environment and then use the ingredients to create a recipe based on my specifications (no tomatoes please, my wife isn't a fan). Gemini went down an Italian route by picking pasta, jarred banana peppers, bell peppers (which I thought was a somewhat unusual combination) and more, before launching into the first steps of the recipe. Sadly, I didn't have time to actually cook it, but as part of the demo, I learned that Gemini has been trained to understand human-centric gestures like pointing and picking things up. This allows it to better understand context without the need to be super specific, which is one of those little but very impactful tricks that allows AI to feel way less robotic. This is how Google Maps will look on Android XR. Note that this is the flat 2D version instead of the more detailed stereoscopic view available on smart glasses with dual displays. Sam Rutherford for EngadgetThen I had a chance to see how Uber and Google Maps ran on the reference glasses, this time using models with both single and dual RGB displays. Surprisingly, even on the monocular version, Maps was able to generate a detailed map with the ability to zoom in and out. But when I switched over to the binocular model, I noticed a significant jump in sharpness and clarity along with a higher-fidelity map with stereoscopic 3D images of buildings. Now, it may be a bit early to call this, and the perception of sharpness varies greatly between people based on their head shape and other factors, but after seeing that, I'm even more convinced that the smart glasses with dual RGB displays are what the industry will settle on in the long term.The second type of device I used was the Samsung Galaxy XR, which I originally tried out when it was announced back in October. However, in the short time since, Google has cooked up a few new features that really help expand the headset's capabilities. By using the goggle's exterior-facing cameras, I was able to play a game of I Spy with Gemini. Admittedly, this might sound like a small addition, but I think it's going to play a big part in how we use devices running Android XR, because it allows the headset (or glasses) to understand better what you're looking at in order to provide more helpful contextual responses. Even though it was announced not long ago in late October, Samsung's Galaxy XR headset is already getting some new features thanks to some updates coming to Android XR. Sam Rutherford for EngadgetHowever, the biggest surprise was when I joined a virtual call with someone using one of Google's new avatars, called Likeness. Instead of the low-polygon cartoony characters we've seen before in places like Meta Horizon, Google's virtual representations of people's faces are almost scary good. So good I had to double-check that they weren't real and from what I've seen they're even a step up from Apple's Personas. Google says that headsets like the Galaxy XR rely on interior sensors to track and respond to facial movements, while users will be able to create and edit their avatars using a standalone app due out sometime next year. The person in the bottom right is using a Likeness, which during my demo looked surprisingly responsive and realistic. GoogleNext, I got a chance to test out the Android XR's PC connectivity by playing Stray on the Galaxy XR while it was tethered wirelessly to a nearby laptop. Not only did it run almost flawlessly with low latency, I was also able to use a paired controller instead of relying on hand-tracking or the laptop's mouse and keyboard. This is something I've been eagerly waiting to try because it feels like Google has put a lot of work into making Android XR devices play nicely with other devices and OSes. Initially, you'll only be able to connect Windows PCs to the Galaxy XR, but Google says it's looking to support macOS systems as well.Finally, I got to try out Xreal's Project Aura glasses to see how Android XR works on a device primarily designed to give you big virtual displays in a portable form factor. Unfortunately, because this was a pre-production unit, I wasn't able to take photos. That said, as far as the glasses go, I was really impressed with their resolution and sharpness and the inclusion of electrochromic glass is a really nice touch, as it allows users to change how heavily the lenses are tinted with a single touch. Alternatively, the glasses can also adjust the tint automatically based on whatever app you are using to give you a more or less isolated atmosphere, depending on the situation. I also appreciate the Aura's increased 70-degree FOV, but if I'm nitpicking, I wish it were a bit higher, as I occasionally found myself wanting a bit more vertical display area. Unfortunately, I wasn't allowed to take photos of Xreal's Project Aura smart glasses, as the model I used was still an early pre-production unit. So here's a shot provided by Google instead. Google / XrealAs a device that's sort of between lightweight smart glasses and a full VR headset, the Aura relies on a wired battery pack that also doubles as a touchpad and a hub for plugging in external devices like your phone, laptop or even game consoles. While using the Aura, I was able to connect to a different PC and multitask in style, as the glasses were able to support multiple virtual displays while running several different apps at the same time. This allowed me to be on a virtual call with someone using a Likeness while I had two other virtual windows open on either side. I also played an AR game (Demeo) while I moved around in virtual space and used my hands to reposition the battlefield or pick up objects with my hands. Now I will fully admit this is a lot and it took me a bit to process everything. But upon reflection, I have a few takeaways from my time with the various Android XR devices and prototypes. More than any other headset or smart glasses platform out now, it feels like Google is doing a ton to embrace a growing ecosystem of devices. That's really important because we're still so early in the lifecycle for wearable gadgets with displays that no one has really figured out a truly polished design like we have for smartphones and laptops. And until we get there, this means that a highly adaptable OS will go a long way towards supporting OEMs like Samsung, Xreal and others. But that's not all. It's clear Google is focused on making Android XR devices easy to build for. That's because the company knows that without useful software that can highlight the components and features coming on next-gen spectacles, there's a chance that interest will remain rather niche — similar to what we've seen when looking at the adoption of VR headsets. So in a way, Google is waging a battle on two fronts, which makes navigating uncharted waters that much more difficult. A major focus for Android XR while people are still figuring out how to make smart glasses is to support a wide variety of designs including those with single displays, dual displays or models without any displays that rely on cameras and speakers. Sam Rutherford for EngadgetGoogle is putting a major emphasis on Android XR's ability to serve as a framework for future gadgets and support and address developer needs. This mirrors the approach the company takes with regular Android and the opposite of Apple's typical MO, because unlike the Vision Pro and visionOS, it appears Google is going to rely heavily on its partners like Xreal, Warby Parker, Gentle Monster and others to create engaging hardware. Furthermore, Google says it plans to support smart glasses that can be tethered to Android and iOS phones, as well as smartwatches from both ecosystems, though there will be some limitations for people using Apple devices due to inherent OS restrictions. That's not to say that there won't be Pixel glasses sometime down the road, but at least for now, I think that's a smart approach and possibly a lesson Google learned after releasing Google Glass over a decade ago. Meanwhile, hi-res and incredibly realistic avatars like Likenesses could be a turning point for virtual collaboration, because, in a first for me, talking to a digital representation of someone else felt kind of natural. After my demos, I had a chance to talk to Senior Director of Product Management for XR Juston Payne, who highlighted the difference between smart glasses and typical gadgets by saying \"Smart glasses have to be great glasses first. They need to have a good form factor, good lenses with prescription support, they need to look good and they have to be easy to buy.\"That's no simple task and there's no guarantee that next-gen smart glasses and headsets will be a grand slam. But from what I've seen, Google is building a very compelling foundation with Android XR.This article originally appeared on Engadget at https://www.engadget.com/wearables/heres-how-google-is-laying-the-foundation-for-our-mixed-reality-future-180000716.html?src=rss",
          "content": "Today, during the XR edition of The Android Show, Google showed off a bunch of updates and new features headed to its mixed reality OS. And while most of the news was aimed at developers, I got a chance to demo some of the platform's expanded capabilities on a range of hardware including Samsung's Galaxy XR headset, two different reference designs and an early version of Xreal's Project Aura smart glasses and I came away rather impressed. So here's a rundown of what I saw and how it will impact the rapidly growing ecosystem of head-mounted displays.First up was one of Google's reference design smart glasses with a single waveguide RGB display built into its right lens. I've included a picture of it here, but try not to read too deeply into its design or aesthetics, as this device is meant to be a testbed for Android XR features and not an early look at upcoming models.Try not to read too much into the appearance of Google's reference design smart glasses, as they are explicitly labeled as prototypes meant to test upcoming features in Android XR.Sam Rutherford for EngadgetAfter putting them on, I was able to ask Gemini to play some tunes on YouTube Music before answering a call simply by tapping on the touchpad built into the right side of the frames. And because the reference model also had onboard world-facing cameras, I could easily share my view with the person on the other end of the line. Naturally, I was curious about how glasses had the bandwidth to do all this, because in normal use, they rely on a Bluetooth or Bluetooth LE connection. When asked, Max Spear, Group Product Manager for XR, shared that depending on the situation, the device can seamlessly switch between both Bluetooth and Wi-Fi, which was rather impressive because I couldn't even detect when that transition happened. Spear also noted that one of Google's focuses for Android XR is making it easier for developers to port over the apps people already know and love. This means for devices like the reference design I wore that feature a built-in display (or displays), the OS actually uses the same code meant for standard Android notifications (like quick replies) to create a minimalist UI instead of forcing app makers to update each piece of software to be compliant with an ever-increasing number of devices. Alternatively, for models that are super lightweight and rely strictly on speakers (like Bose Frames), Google has also designed Android XR so that you only need mics and voice controls to access a wide variety of apps without the need for visual menus. This is the picture Google's reference design smart glasses created (via Gemini ) when I asked it to transform a photo I took of some pantry shelves into a sci-fi kitchen. Sam Rutherford for EngadgetMeanwhile, if you're hoping to take photos with your smart glasses, there's a surprising amount of capability there, too. Not only was I able to ask Gemini to take a photo, the glasses were also able to send a higher-res version to a connected smartwatch, which is super handy in case you want to review the image before moving on to the next shot. And when you want to inject some creativity, you can ask Gemini to transform pictures into practically anything you can imagine via Nano Banana. In my case, I asked the AI to change a shot of a pantry into a sci-fi kitchen and Gemini delivered with aplomb, including converting the room into a metal-clad setting complete with lots of light strips and a few bursts of steam.However, one of the most impressive demos was when I asked Google's reference glasses to look at some of that same pantry environment and then use the ingredients to create a recipe based on my specifications (no tomatoes please, my wife isn't a fan). Gemini went down an Italian route by picking pasta, jarred banana peppers, bell peppers (which I thought was a somewhat unusual combination) and more, before launching into the first steps of the recipe. Sadly, I didn't have time to actually cook it, but as part of the demo, I learned that Gemini has been trained to understand human-centric gestures like pointing and picking things up. This allows it to better understand context without the need to be super specific, which is one of those little but very impactful tricks that allows AI to feel way less robotic. This is how Google Maps will look on Android XR. Note that this is the flat 2D version instead of the more detailed stereoscopic view available on smart glasses with dual displays. Sam Rutherford for EngadgetThen I had a chance to see how Uber and Google Maps ran on the reference glasses, this time using models with both single and dual RGB displays. Surprisingly, even on the monocular version, Maps was able to generate a detailed map with the ability to zoom in and out. But when I switched over to the binocular model, I noticed a significant jump in sharpness and clarity along with a higher-fidelity map with stereoscopic 3D images of buildings. Now, it may be a bit early to call this, and the perception of sharpness varies greatly between people based on their head shape and other factors, but after seeing that, I'm even more convinced that the smart glasses with dual RGB displays are what the industry will settle on in the long term.The second type of device I used was the Samsung Galaxy XR, which I originally tried out when it was announced back in October. However, in the short time since, Google has cooked up a few new features that really help expand the headset's capabilities. By using the goggle's exterior-facing cameras, I was able to play a game of I Spy with Gemini. Admittedly, this might sound like a small addition, but I think it's going to play a big part in how we use devices running Android XR, because it allows the headset (or glasses) to understand better what you're looking at in order to provide more helpful contextual responses. Even though it was announced not long ago in late October, Samsung's Galaxy XR headset is already getting some new features thanks to some updates coming to Android XR. Sam Rutherford for EngadgetHowever, the biggest surprise was when I joined a virtual call with someone using one of Google's new avatars, called Likeness. Instead of the low-polygon cartoony characters we've seen before in places like Meta Horizon, Google's virtual representations of people's faces are almost scary good. So good I had to double-check that they weren't real and from what I've seen they're even a step up from Apple's Personas. Google says that headsets like the Galaxy XR rely on interior sensors to track and respond to facial movements, while users will be able to create and edit their avatars using a standalone app due out sometime next year. The person in the bottom right is using a Likeness, which during my demo looked surprisingly responsive and realistic. GoogleNext, I got a chance to test out the Android XR's PC connectivity by playing Stray on the Galaxy XR while it was tethered wirelessly to a nearby laptop. Not only did it run almost flawlessly with low latency, I was also able to use a paired controller instead of relying on hand-tracking or the laptop's mouse and keyboard. This is something I've been eagerly waiting to try because it feels like Google has put a lot of work into making Android XR devices play nicely with other devices and OSes. Initially, you'll only be able to connect Windows PCs to the Galaxy XR, but Google says it's looking to support macOS systems as well.Finally, I got to try out Xreal's Project Aura glasses to see how Android XR works on a device primarily designed to give you big virtual displays in a portable form factor. Unfortunately, because this was a pre-production unit, I wasn't able to take photos. That said, as far as the glasses go, I was really impressed with their resolution and sharpness and the inclusion of electrochromic glass is a really nice touch, as it allows users to change how heavily the lenses are tinted with a single touch. Alternatively, the glasses can also adjust the tint automatically based on whatever app you are using to give you a more or less isolated atmosphere, depending on the situation. I also appreciate the Aura's increased 70-degree FOV, but if I'm nitpicking, I wish it were a bit higher, as I occasionally found myself wanting a bit more vertical display area. Unfortunately, I wasn't allowed to take photos of Xreal's Project Aura smart glasses, as the model I used was still an early pre-production unit. So here's a shot provided by Google instead. Google / XrealAs a device that's sort of between lightweight smart glasses and a full VR headset, the Aura relies on a wired battery pack that also doubles as a touchpad and a hub for plugging in external devices like your phone, laptop or even game consoles. While using the Aura, I was able to connect to a different PC and multitask in style, as the glasses were able to support multiple virtual displays while running several different apps at the same time. This allowed me to be on a virtual call with someone using a Likeness while I had two other virtual windows open on either side. I also played an AR game (Demeo) while I moved around in virtual space and used my hands to reposition the battlefield or pick up objects with my hands. Now I will fully admit this is a lot and it took me a bit to process everything. But upon reflection, I have a few takeaways from my time with the various Android XR devices and prototypes. More than any other headset or smart glasses platform out now, it feels like Google is doing a ton to embrace a growing ecosystem of devices. That's really important because we're still so early in the lifecycle for wearable gadgets with displays that no one has really figured out a truly polished design like we have for smartphones and laptops. And until we get there, this means that a highly adaptable OS will go a long way towards supporting OEMs like Samsung, Xreal and others. But that's not all. It's clear Google is focused on making Android XR devices easy to build for. That's because the company knows that without useful software that can highlight the components and features coming on next-gen spectacles, there's a chance that interest will remain rather niche — similar to what we've seen when looking at the adoption of VR headsets. So in a way, Google is waging a battle on two fronts, which makes navigating uncharted waters that much more difficult. A major focus for Android XR while people are still figuring out how to make smart glasses is to support a wide variety of designs including those with single displays, dual displays or models without any displays that rely on cameras and speakers. Sam Rutherford for EngadgetGoogle is putting a major emphasis on Android XR's ability to serve as a framework for future gadgets and support and address developer needs. This mirrors the approach the company takes with regular Android and the opposite of Apple's typical MO, because unlike the Vision Pro and visionOS, it appears Google is going to rely heavily on its partners like Xreal, Warby Parker, Gentle Monster and others to create engaging hardware. Furthermore, Google says it plans to support smart glasses that can be tethered to Android and iOS phones, as well as smartwatches from both ecosystems, though there will be some limitations for people using Apple devices due to inherent OS restrictions. That's not to say that there won't be Pixel glasses sometime down the road, but at least for now, I think that's a smart approach and possibly a lesson Google learned after releasing Google Glass over a decade ago. Meanwhile, hi-res and incredibly realistic avatars like Likenesses could be a turning point for virtual collaboration, because, in a first for me, talking to a digital representation of someone else felt kind of natural. After my demos, I had a chance to talk to Senior Director of Product Management for XR Juston Payne, who highlighted the difference between smart glasses and typical gadgets by saying \"Smart glasses have to be great glasses first. They need to have a good form factor, good lenses with prescription support, they need to look good and they have to be easy to buy.\"That's no simple task and there's no guarantee that next-gen smart glasses and headsets will be a grand slam. But from what I've seen, Google is building a very compelling foundation with Android XR.This article originally appeared on Engadget at https://www.engadget.com/wearables/heres-how-google-is-laying-the-foundation-for-our-mixed-reality-future-180000716.html?src=rss",
          "feed_position": 5,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/google-reference-design-side-view.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/anthropics-claude-code-can-now-read-your-slack-messages-and-write-code-for",
          "published_at": "Mon, 08 Dec 2025 19:00:00 GMT",
          "title": "Anthropic's Claude Code can now read your Slack messages and write code for you",
          "standfirst": "Anthropic on Monday launched a beta integration that connects its fast-growing Claude Code programming agent directly to Slack, allowing software engineers to delegate coding tasks without leaving the workplace messaging platform where much of their daily communication already happens.The release, which Anthropic describes as a \"research preview,\" is the AI safety company&#x27;s latest move to embed its technology deeper into enterprise workflows — and comes as Claude Code has emerged as a surprise revenue engine, generating over $1 billion in annualized revenue just six months after its public debut in May.\"The critical context around engineering work often lives in Slack, including bug reports, feature requests, and engineering discussion,\" the company wrote in its announcement blog post. \"When a bug report appears or a teammate needs a code fix, you can now tag Claude in Slack to automatically spin up a Claude Code session using the surrounding context.\"From bug report to pull request: how the new Slack integration actually worksThe mechanics are deceptively simple but address a persistent friction point in software development: the gap between where problems get discussed and where they get fixed.When a user mentions @Claude in a Slack channel or thread, Claude analyzes the message to determine whether it constitutes a coding task. If it does, the system automatically creates a new Claude Code session. Users can also explicitly instruct Claude to treat requests as coding tasks.Claude gathers context from recent channel and thread messages in Slack to feed into the Claude Code session. It will use this context to automatically choose which repository to run the task on based on the repositories you&#x27;ve authenticated to Claude Code on the web.As the Claude Code session progresses, Claude posts status updates back to the Slack thread. Once complete, users receive a link to the full session where they can review changes, along with a direct link to open a pull request.The feature builds on Anthropic&#x27;s existing Claude for Slack integration and requires users to have access to Claude Code on the web. In practical terms, a product manager reporting a bug in Slack could tag Claude, which would then analyze the conversation context, identify the relevant code repository, investigate the issue, propose a fix, and post a pull request—all while updating the original Slack thread with its progress.Why Anthropic is betting big on enterprise workflow integrationsThe Slack integration arrives at a pivotal moment for Anthropic. Claude Code has already hit $1 billion in revenue six months since its public debut in May, according to a LinkedIn post from Anthropic&#x27;s chief product officer, Mike Krieger. The coding agent continues to barrel toward scale with customers like Netflix, Spotify, and Salesforce.The velocity of that growth helps explain why Anthropic made its first-ever acquisition earlier this month. Anthropic declined to comment on financial details. The Information earlier reported on Anthropic&#x27;s bid to acquire Bun.Bun is a breakthrough JavaScript runtime that is dramatically faster than the leading competition. As an all-in-one toolkit — combining runtime, package manager, bundler, and test runner — it&#x27;s become essential infrastructure for AI-led software engineering, helping developers build and test applications at unprecedented velocity.Since becoming generally available in May 2025, Claude Code has grown from its origins as an internal engineering experiment into a critical tool for many of the world&#x27;s category-leading enterprises, including Netflix, Spotify, KPMG, L&#x27;Oreal, and Salesforce — and Bun has been key in helping scale its infrastructure throughout that evolution.The acquisition signals that Anthropic views Claude Code not as a peripheral feature but as a core business line worth substantial investment. The Slack integration extends that bet, positioning Claude Code as an ambient presence in the workspaces where engineering decisions actually get made.According to an Anthropic spokesperson, companies including Rakuten, Novo Nordisk, Uber, Snowflake, and Ramp now use Claude Code for both professional and novice developers. Rakuten, the Japanese e-commerce giant, has reportedly reduced software development timelines from 24 days to just 5 days using the tool — a 79% reduction that illustrates the productivity claims Anthropic has been making.Claude Code&#x27;s rapid rise from internal experiment to billion-dollar productThe Slack launch is the latest in a rapid series of Claude Code expansions. In late November, Claude Code was added to Anthropic&#x27;s desktop apps including the Mac version. Claude Code was previously limited to mobile apps and the web. It allows software engineers to code, research, and update work with multiple local and remote sessions running at the same time.That release accompanied Anthropic&#x27;s unveiling of Claude Opus 4.5, its newest and most capable model. Claude Opus 4.5 is available today on the company&#x27;s apps, API, and on all three major cloud platforms. Pricing is $5/$25 per million tokens — making Opus-level capabilities accessible to even more users, teams, and enterprises.The company has also invested heavily in the developer infrastructure that powers Claude Code. In late November, Anthropic released three new beta features for tool use: Tool Search Tool, which allows Claude to use search tools to access thousands of tools without consuming its context window; Programmatic Tool Calling, which allows Claude to invoke tools in a code execution environment reducing the impact on the model&#x27;s context window; and Tool Use Examples, which provides a universal standard for demonstrating how to effectively use a given tool.The Model Context Protocol (MCP) is an open standard for connecting AI agents to external systems. Connecting agents to tools and data traditionally requires a custom integration for each pairing, creating fragmentation and duplicated effort that makes it difficult to scale truly connected systems. MCP provides a universal protocol — developers implement MCP once in their agent and it unlocks an entire ecosystem of integrations.Inside Anthropic&#x27;s own AI transformation: what happens when engineers use Claude all dayAnthropic has been unusually transparent about how its own engineers use Claude Code — and the findings offer a preview of broader workforce implications. In August 2025, Anthropic surveyed 132 engineers and researchers, conducted 53 in-depth qualitative interviews, and studied internal Claude Code usage data to understand how AI use is changing work at the company.Employees self-reported using Claude in 60% of their work and achieving a 50% productivity boost, a 2-3x increase from this time last year. This productivity looks like slightly less time per task category, but considerably more output volume.Perhaps most notably, 27% of Claude-assisted work consists of tasks that wouldn&#x27;t have been done otherwise, such as scaling projects, making nice-to-have tools like interactive data dashboards, and exploratory work that wouldn&#x27;t be cost-effective if done manually.The internal research also revealed how Claude is changing the nature of engineering collaboration. The maximum number of consecutive tool calls Claude Code makes per transcript increased by 116%. Claude now chains together 21.2 independent tool calls without need for human intervention versus 9.8 tool calls from six months ago.The number of human turns decreased by 33%. The average number of human turns decreased from 6.2 to 4.1 per transcript, suggesting that less human input is necessary to accomplish a given task now compared to six months ago.But the research also surfaced tensions. One prominent theme was that Claude has become the first stop for questions that once went to colleagues. \"It has reduced my dependence on [my team] by 80%, [but] the last 20% is crucial and I go and talk to them,\" one engineer explained. Several engineers said they \"bounce ideas off\" Claude, similar to interactions with human collaborators.Others described experiencing less interaction with colleagues. Some appreciate the reduced social friction, but others resist the change or miss the older way of working: \"I like working with people and it is sad that I &#x27;need&#x27; them less now.\"How Anthropic stacks up against OpenAI, Google, and Microsoft in the enterprise AI raceAnthropic is not alone in racing to capture the enterprise coding market. OpenAI, Google, and Microsoft (through GitHub Copilot) are all pursuing similar integrations. The Slack launch gives Anthropic a presence in one of the most widely-used enterprise communication platforms — Slack claims over 750,000 organizations use its software.The deal comes as Anthropic pursues a more disciplined growth path than rival OpenAI, focusing on enterprise customers and coding workloads. Internal financials reported by The Wall Street Journal show Anthropic expects to break even by 2028 — two years earlier than OpenAI, which continues to invest heavily in infrastructure as it expands into video, hardware, and consumer products.The move also marks an increased push into developer tooling. Anthropic has recently seen backing from some of tech&#x27;s biggest titans. Microsoft and Nvidia pledged up to $15 billion in fresh investment in Anthropic last month, alongside a $30 billion commitment from Anthropic to run Claude Code on Microsoft&#x27;s cloud. This is in addition to the $8 billion invested from Amazon and $3 billion from Google.The cross-investment from both Microsoft and Google — fierce competitors in the cloud and AI spaces — highlights how valuable Anthropic&#x27;s enterprise positioning has become. By integrating with Slack (which is owned by Salesforce), Anthropic further embeds itself in the enterprise software ecosystem while remaining platform-agnostic.What the Slack integration means for developers — and whether they can trust itFor engineering teams, the Slack integration promises to collapse the distance between problem identification and problem resolution. A bug report in a Slack channel can immediately trigger investigation. A feature request can spawn a prototype. A code review comment can generate a refactor.But the integration also raises questions about oversight and code quality. Most Anthropic employees use Claude frequently while reporting they can \"fully delegate\" only 0-20% of their work to it. Claude is a constant collaborator but using it generally involves active supervision and validation, especially in high-stakes work — versus handing off tasks requiring no verification at all.Some employees are concerned about the atrophy of deeper skillsets required for both writing and critiquing code — \"When producing output is so easy and fast, it gets harder and harder to actually take the time to learn something.\"The Slack integration, by making Claude Code invocation as simple as an @mention, may accelerate both the productivity benefits and the skill-atrophy concerns that Anthropic&#x27;s own research has documented.The future of coding may be conversational—and Anthropic is racing to prove itThe beta launch marks the beginning of what Anthropic expects will be a broader rollout, with documentation forthcoming for teams looking to deploy the integration and refinements planned based on user feedback during the research preview phase.For Anthropic, the Slack integration is a calculated bet on a fundamental shift in how software gets written. The company is wagering that the future of coding will be conversational — that the walls between where developers talk about problems and where they solve them will dissolve entirely. The companies that win enterprise AI, in this view, will be the ones that meet developers not in specialized tools but in the chat windows they already have open all day.Whether that vision becomes reality will depend on whether Claude Code can deliver enterprise-grade reliability while maintaining the security that organizations demand. The early returns are promising: a billion dollars in revenue, a roster of Fortune 500 customers, and a growing ecosystem of integrations suggest Anthropic is onto something real.But in one of Anthropic&#x27;s own internal interviews, an engineer offered a more cautious assessment of the transformation underway: \"Nobody knows what&#x27;s going to happen… the important thing is to just be really adaptable.\"In the age of AI coding agents, that may be the only career advice that holds up.",
          "content": "Anthropic on Monday launched a beta integration that connects its fast-growing Claude Code programming agent directly to Slack, allowing software engineers to delegate coding tasks without leaving the workplace messaging platform where much of their daily communication already happens.The release, which Anthropic describes as a \"research preview,\" is the AI safety company&#x27;s latest move to embed its technology deeper into enterprise workflows — and comes as Claude Code has emerged as a surprise revenue engine, generating over $1 billion in annualized revenue just six months after its public debut in May.\"The critical context around engineering work often lives in Slack, including bug reports, feature requests, and engineering discussion,\" the company wrote in its announcement blog post. \"When a bug report appears or a teammate needs a code fix, you can now tag Claude in Slack to automatically spin up a Claude Code session using the surrounding context.\"From bug report to pull request: how the new Slack integration actually worksThe mechanics are deceptively simple but address a persistent friction point in software development: the gap between where problems get discussed and where they get fixed.When a user mentions @Claude in a Slack channel or thread, Claude analyzes the message to determine whether it constitutes a coding task. If it does, the system automatically creates a new Claude Code session. Users can also explicitly instruct Claude to treat requests as coding tasks.Claude gathers context from recent channel and thread messages in Slack to feed into the Claude Code session. It will use this context to automatically choose which repository to run the task on based on the repositories you&#x27;ve authenticated to Claude Code on the web.As the Claude Code session progresses, Claude posts status updates back to the Slack thread. Once complete, users receive a link to the full session where they can review changes, along with a direct link to open a pull request.The feature builds on Anthropic&#x27;s existing Claude for Slack integration and requires users to have access to Claude Code on the web. In practical terms, a product manager reporting a bug in Slack could tag Claude, which would then analyze the conversation context, identify the relevant code repository, investigate the issue, propose a fix, and post a pull request—all while updating the original Slack thread with its progress.Why Anthropic is betting big on enterprise workflow integrationsThe Slack integration arrives at a pivotal moment for Anthropic. Claude Code has already hit $1 billion in revenue six months since its public debut in May, according to a LinkedIn post from Anthropic&#x27;s chief product officer, Mike Krieger. The coding agent continues to barrel toward scale with customers like Netflix, Spotify, and Salesforce.The velocity of that growth helps explain why Anthropic made its first-ever acquisition earlier this month. Anthropic declined to comment on financial details. The Information earlier reported on Anthropic&#x27;s bid to acquire Bun.Bun is a breakthrough JavaScript runtime that is dramatically faster than the leading competition. As an all-in-one toolkit — combining runtime, package manager, bundler, and test runner — it&#x27;s become essential infrastructure for AI-led software engineering, helping developers build and test applications at unprecedented velocity.Since becoming generally available in May 2025, Claude Code has grown from its origins as an internal engineering experiment into a critical tool for many of the world&#x27;s category-leading enterprises, including Netflix, Spotify, KPMG, L&#x27;Oreal, and Salesforce — and Bun has been key in helping scale its infrastructure throughout that evolution.The acquisition signals that Anthropic views Claude Code not as a peripheral feature but as a core business line worth substantial investment. The Slack integration extends that bet, positioning Claude Code as an ambient presence in the workspaces where engineering decisions actually get made.According to an Anthropic spokesperson, companies including Rakuten, Novo Nordisk, Uber, Snowflake, and Ramp now use Claude Code for both professional and novice developers. Rakuten, the Japanese e-commerce giant, has reportedly reduced software development timelines from 24 days to just 5 days using the tool — a 79% reduction that illustrates the productivity claims Anthropic has been making.Claude Code&#x27;s rapid rise from internal experiment to billion-dollar productThe Slack launch is the latest in a rapid series of Claude Code expansions. In late November, Claude Code was added to Anthropic&#x27;s desktop apps including the Mac version. Claude Code was previously limited to mobile apps and the web. It allows software engineers to code, research, and update work with multiple local and remote sessions running at the same time.That release accompanied Anthropic&#x27;s unveiling of Claude Opus 4.5, its newest and most capable model. Claude Opus 4.5 is available today on the company&#x27;s apps, API, and on all three major cloud platforms. Pricing is $5/$25 per million tokens — making Opus-level capabilities accessible to even more users, teams, and enterprises.The company has also invested heavily in the developer infrastructure that powers Claude Code. In late November, Anthropic released three new beta features for tool use: Tool Search Tool, which allows Claude to use search tools to access thousands of tools without consuming its context window; Programmatic Tool Calling, which allows Claude to invoke tools in a code execution environment reducing the impact on the model&#x27;s context window; and Tool Use Examples, which provides a universal standard for demonstrating how to effectively use a given tool.The Model Context Protocol (MCP) is an open standard for connecting AI agents to external systems. Connecting agents to tools and data traditionally requires a custom integration for each pairing, creating fragmentation and duplicated effort that makes it difficult to scale truly connected systems. MCP provides a universal protocol — developers implement MCP once in their agent and it unlocks an entire ecosystem of integrations.Inside Anthropic&#x27;s own AI transformation: what happens when engineers use Claude all dayAnthropic has been unusually transparent about how its own engineers use Claude Code — and the findings offer a preview of broader workforce implications. In August 2025, Anthropic surveyed 132 engineers and researchers, conducted 53 in-depth qualitative interviews, and studied internal Claude Code usage data to understand how AI use is changing work at the company.Employees self-reported using Claude in 60% of their work and achieving a 50% productivity boost, a 2-3x increase from this time last year. This productivity looks like slightly less time per task category, but considerably more output volume.Perhaps most notably, 27% of Claude-assisted work consists of tasks that wouldn&#x27;t have been done otherwise, such as scaling projects, making nice-to-have tools like interactive data dashboards, and exploratory work that wouldn&#x27;t be cost-effective if done manually.The internal research also revealed how Claude is changing the nature of engineering collaboration. The maximum number of consecutive tool calls Claude Code makes per transcript increased by 116%. Claude now chains together 21.2 independent tool calls without need for human intervention versus 9.8 tool calls from six months ago.The number of human turns decreased by 33%. The average number of human turns decreased from 6.2 to 4.1 per transcript, suggesting that less human input is necessary to accomplish a given task now compared to six months ago.But the research also surfaced tensions. One prominent theme was that Claude has become the first stop for questions that once went to colleagues. \"It has reduced my dependence on [my team] by 80%, [but] the last 20% is crucial and I go and talk to them,\" one engineer explained. Several engineers said they \"bounce ideas off\" Claude, similar to interactions with human collaborators.Others described experiencing less interaction with colleagues. Some appreciate the reduced social friction, but others resist the change or miss the older way of working: \"I like working with people and it is sad that I &#x27;need&#x27; them less now.\"How Anthropic stacks up against OpenAI, Google, and Microsoft in the enterprise AI raceAnthropic is not alone in racing to capture the enterprise coding market. OpenAI, Google, and Microsoft (through GitHub Copilot) are all pursuing similar integrations. The Slack launch gives Anthropic a presence in one of the most widely-used enterprise communication platforms — Slack claims over 750,000 organizations use its software.The deal comes as Anthropic pursues a more disciplined growth path than rival OpenAI, focusing on enterprise customers and coding workloads. Internal financials reported by The Wall Street Journal show Anthropic expects to break even by 2028 — two years earlier than OpenAI, which continues to invest heavily in infrastructure as it expands into video, hardware, and consumer products.The move also marks an increased push into developer tooling. Anthropic has recently seen backing from some of tech&#x27;s biggest titans. Microsoft and Nvidia pledged up to $15 billion in fresh investment in Anthropic last month, alongside a $30 billion commitment from Anthropic to run Claude Code on Microsoft&#x27;s cloud. This is in addition to the $8 billion invested from Amazon and $3 billion from Google.The cross-investment from both Microsoft and Google — fierce competitors in the cloud and AI spaces — highlights how valuable Anthropic&#x27;s enterprise positioning has become. By integrating with Slack (which is owned by Salesforce), Anthropic further embeds itself in the enterprise software ecosystem while remaining platform-agnostic.What the Slack integration means for developers — and whether they can trust itFor engineering teams, the Slack integration promises to collapse the distance between problem identification and problem resolution. A bug report in a Slack channel can immediately trigger investigation. A feature request can spawn a prototype. A code review comment can generate a refactor.But the integration also raises questions about oversight and code quality. Most Anthropic employees use Claude frequently while reporting they can \"fully delegate\" only 0-20% of their work to it. Claude is a constant collaborator but using it generally involves active supervision and validation, especially in high-stakes work — versus handing off tasks requiring no verification at all.Some employees are concerned about the atrophy of deeper skillsets required for both writing and critiquing code — \"When producing output is so easy and fast, it gets harder and harder to actually take the time to learn something.\"The Slack integration, by making Claude Code invocation as simple as an @mention, may accelerate both the productivity benefits and the skill-atrophy concerns that Anthropic&#x27;s own research has documented.The future of coding may be conversational—and Anthropic is racing to prove itThe beta launch marks the beginning of what Anthropic expects will be a broader rollout, with documentation forthcoming for teams looking to deploy the integration and refinements planned based on user feedback during the research preview phase.For Anthropic, the Slack integration is a calculated bet on a fundamental shift in how software gets written. The company is wagering that the future of coding will be conversational — that the walls between where developers talk about problems and where they solve them will dissolve entirely. The companies that win enterprise AI, in this view, will be the ones that meet developers not in specialized tools but in the chat windows they already have open all day.Whether that vision becomes reality will depend on whether Claude Code can deliver enterprise-grade reliability while maintaining the security that organizations demand. The early returns are promising: a billion dollars in revenue, a roster of Fortune 500 customers, and a growing ecosystem of integrations suggest Anthropic is onto something real.But in one of Anthropic&#x27;s own internal interviews, an engineer offered a more cautious assessment of the transformation underway: \"Nobody knows what&#x27;s going to happen… the important thing is to just be really adaptable.\"In the age of AI coding agents, that may be the only career advice that holds up.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/667OUCJyzh5TAzDpX4UQDa/d1b772df47ef4e01e6450e1bb9979970/nuneybits_Vector_art_of_code-filled_speech_bubble_in_burnt_oran_78f6bff7-7863-4363-bcad-892c8f7cf2f7.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/techs-biggest-winners-of-2025-180000177.html",
          "published_at": "Mon, 08 Dec 2025 18:00:00 +0000",
          "title": "Tech's biggest winners of 2025",
          "standfirst": "Every December, the Engadget staff compiles a list of the year’s biggest winners. We scour over articles from the previous 12 months to determine the people, companies, products and trends that made the most impact over the course of the year. Not all of that influence is positive, however, and some selections may also appear on our list of biggest losers. Still, sit back and enjoy our picks for the biggest winners of 2025.Nintendo Switch 2Playing Mario Kart World on the Switch 2 in handheld mode.Sam Rutherford for EngadgetAside from a big bump in battery life that many were hoping for, Nintendo took just about everything that made its last console such a phenomenon and upgraded it on the Switch 2. A sleeker design with magnetic Joy-Cons that are less likely to break, a larger (albeit LCD) 1080p display with HDR, much stronger performance, mouse controls and a boost to the base storage were all very welcome.Of course, the vast majority of Switch games run on the Switch 2 (often with visual improvements or other upgrades), so the new console had a vast library right from the jump. Nintendo is building out its slate of first-party games with treats like Donkey Kong Bananza and Metroid Prime 4, and the third-party support is seriously impressive too. Cyberpunk 2077, Street Fighter 6 and Hitman: World of Assassination are already available, and the likes of Final Fantasy VII Remake Intergrade and FromSoftware's Switch 2 exclusive The Duskbloods are on the way.The Switch 2 is an iteration, not a revolution, but Nintendo didn't need to reinvent the wheel to make another great system. It's little surprise, then, that we gave the Switch 2 a score of 93 in our review. The console is surpassing Nintendo's sales expectations as well. The company said in November that it believes it will sell 19 million units (up from 15 million) by the time its current fiscal year ends in March. — Kris Holt, Contributing reporterNVIDIANVIDIA GeForce 5070 TiDevindra Hardawar for EngadgetCould things be any rosier for NVIDIA? Once just a video card company for gamers, NVIDIA's GPU hardware is now directly tied to the rise of the AI industry. Its stock has jumped a whopping 1,235 percent over the past five years, going from $13.56 per share in 2020 to a peak of $202.49 this past October. NVIDIA's server-grade cards are being used en masse to train AI models, as well as to power AI inferencing. At home, its GeForce GPUs are enabling local AI development and they're still the gaming cards to beat, despite AMD's steadily improving competition.Clearly, the company's bet on parallel processing has paid off enormously. Its GPUs can handle tons of computations simultaneously, making them ideally suited for the demands of the AI industry. They're not exactly efficient — that's why neural processing units, or NPUs have sprung up to power consumer AI features — but it's hard to deny NVIDIA's raw computational power. NVIDIA's AI success may not last forever, though. Companies like Google and Microsoft are already working on their own AI chips, and it's still unclear if consumers actually want widespread AI features as much as tech companies think. If the AI industry crashes, NVIDIA will be one of the first victims. — Devindra Hardawar, Senior reporterTech billionairesUS President Donald Trump speaks during a news conference with Elon Musk (L) in the Oval Office of the White House in Washington, DC, on May 30, 2025. ALLISON ROBBERT via Getty ImagesThere's no doubt that tech billionaires, especially those that lean conservatively, have benefitted tremendously from the Trump administration over the past year. Elon Musk's DOGE team of tech loyalists chainsawed their way through the budgets and staff of several federal agencies, including the National Highway Traffic Safety Administration (NHTSA), which regulates Tesla. (That hasn't stopped the NHTSA from launching a new investigation into Tesla's full self-driving tech, though.)According to a recent report by Oxfam, the 10 richest US billionaires (who are all tech leaders, save for Warren Buffet) increased their wealth by $698 billion of the past year. Of course, it took plenty of wining and dining to get there. Elon Musk reportedly donated nearly $300 million to Trump and Republican allies, and several tech companies have pitched in to build the president's lavish White House ballroom. But the result for the tech elite is increased access to the president, less scrutiny when it comes to acquisitions and other deals, and the potential for massive corporate and elite tax cuts. — D.H.AI videoA silhouetted individual is seen holding a mobile phone with a Sora of ChatGPT OpenAI logo displayed in the backgroundSOPA Images via Getty ImagesAI slop didn't start in 2025, but it reached new heights thanks to updates from Meta, Google, OpenAI and others that made it easier than ever to create a real-ish (emphasis on the ish) looking clips from nothing but your most unhinged mad libs. Now, AI-generated videos are just about impossible to avoid. Some platforms, like Pinterest and TikTok, have even begun offering people the ability to ask their algorithms to show less AI content in their feeds. Unfortunately, there's no way to stuff Shrimp Jesus back into the bottle. AI video is everywhere and it's here to stay. It's not only overtaken Facebook and Instagram's recommendations, Meta created an entirely separate feed just for users' AI-generated fever dreams. OpenAI's Sora, which lets you make AI videos of real people, was downloaded a million times in just a few days. Google's Veo, which generated more than 40 million videos in a matter of weeks, is now built-in to YouTube Shorts.It's now trivially easy for creators to churn out fake movie trailers, cute animal videos that never happened or viral clips of made up ICE raids. Hell, the president of the United States regularly shares bizarre, sometimes poop-themed, AI videos on his official social media channels. During the government shutdown, the official X account for Senate Republicans shared a deepfake of Senate minority leader Chuck Schumer. AI video is winning not just because it's everywhere, but because so many are unable, or unwilling, to understand what's real and what isn't. More than half of Americans say they are not confident in their ability to distinguish between human and AI-generated content, according to Pew Research. Similar numbers of people report being \"more concerned than excited about the increased use of AI in daily life.\" But those concerns have done little to stop AI slop from dominating all of our feeds, and there's no sign it will ever slow down. — Karissa Bell, Senior reporterGalaxy Z Fold 7Samsung Galaxy Z Fold 7Sam Rutherford for EngadgetAfter seven generations, Samsung reached an important milestone this year with its Galaxy Z Fold line: It made a foldable phone that’s the same size as a regular handset. In fact, weighing 7.58 ounces and measuring 72.8mm wide, the Galaxy Z Fold 7 is actually lighter and narrower than an S25 Ultra, while being practically just as thin at 8.9mm (folded). It’s a real marvel of engineering, especially when you consider the phone also features a 200MP main camera, an IPX8 rating for water resistance and a 5,000 mAh battery with 45-watt wired charging. And of course, there's that huge 8-inch main screen hiding inside, which makes the Z Fold 7 both a phone and a tablet in one device. The only thing it's really missing is the improved dust resistance Google gave to the Pixel 10 Pro Fold. But perhaps more importantly, the Z Fold 7's reduced size and weight have created a device with wider appeal. This has propelled sales of Samsung's latest flagship foldable up 50 percent compared to the previous generation while pushing shipments of foldables as a whole to record highs. Who knew that when Samsung focuses on creating world-class hardware instead of overindexing on AI, good things happen? Okay, maybe that’s a bit harsh. Regardless, for a phone category that has struggled with excess weight and bulk since its inception, the Z Fold 7 feels like a revelation and the beginning of a new era for handsets with flexible displays. Now, can we just bring their prices down, please? — Sam Rutherford, Senior reporterSmart glassesSenior reporter Karissa Bell wearing a pair of Ray Ban Display glasses. Karissa Bell for EngadgetLike it or not, smart glasses are having a moment. Propelled by new devices like the Meta Ray-Ban Display and upcoming models like Xreal’s Project Aura, the idea of wearing specs with built-in screens suddenly became an attractive proposition. And that means a lot for a category of gadgets that’s often best remembered by the fashion tragedy that was Google Glass in 2013. However, this development isn’t purely by chance. The latest generation of smart glasses has only just now become a reality due to the convergence of several branches of tech — including improved optics, lightweight batteries and, of course, AI. Now that last one might sound silly considering how many big companies seem to be betting the farm on machine learning being the next big thing, but AI will be a critical feature for enabling the hands-free experience that you need to make smartglasses work when you can’t rely on touch input. While this category is still in its early stages of development, the increased momentum we've seen from smart glasses this year seems poised to carry them towards being a future pillar of people's core tech kits. — S.R.Fast chargingFast charging on the Pixel Watch 4 is one implementation that impressed us this year.Cherlynn Low for EngadgetDevices like tablets and smartwatches have matured to the point where each generation mostly sees iterative upgrades, making covering them seem boring. But this year, as the hardware review season came to a close, I noticed an interesting trend. One feature, across various product categories, genuinely excited myself and other reviewers at Engadget and around the internet: impressively fast charging. By itself, high-speed charging isn’t new. But when I reviewed the Pixel Watch 4 in October, I was shocked that one seemingly little update changed how I went about my day. The new power system on Google’s smartwatch was so efficient that after about ten minutes on a cradle, the wearable went from below 20 percent to past 50 percent. With that boost, I stopped having to remind myself to plug the watch in — any time I ran low or was about to run out the door, I just plopped it on the charger and would have enough juice for hours.Google wasn’t the only company to make fast-charging a meaningful addition to one of its 2025 products. Apple’s iPad Pro M5 is the first iPad to support the feature, and while in our testing it fell a little short of the 50 percent charge in 30 minutes that the company promised, our reviewer Nate Ingraham still found it a meaningful improvement.Observers of the smartphone industry will likely point out two things. First, battery technology can be volatile, and larger, faster-charging cells might lead to exploding phones. So my optimism about this development is not without caution. Secondly, we’ve already seen all this come to handsets, especially in phones that launched outside the US first. OnePlus is known for its SUPERVOOC fast charging system, for example, and we’re seeing even more novel battery tech show up abroad. Calling fast charging a winner of 2025 may feel untimely to some.But when you consider the spread of speedier charging to other types of products, especially in electric vehicles that till now take forever to top up, the benefits are clear. This year, we saw Formula E (finally) debut its fast-charging pit stops, Honda announce its first full-size electric motorcycle with fast charging and Chinese EV maker BYD unveiling new tech that delivers peak EV charging speeds of 1,000 kilowatts. That should about halve the time it currently takes to top up your electric car. Sure, it’s not the most eye-catching or novel technological development. But when counted in terms of precious time saved, fast charging coming to more types of devices certainly amounts to a greater good in gadgets in 2025. — Cherlynn Low, Managing editorMagnetsThe Pixel 10 Pro Fold and the Pixel Ring StandSam Rutherford for EngadgetTwo years after the announcement of the Qi 2 wireless charging standard and its support of magnetic attachment accessories (a la Apple’s MagSafe), we’re finally seeing one of the more mainstream Android devices adopt it. In 2025, Google became the first Android phone maker that’s not HMD to do so, bringing such magnetic capabilities to the Pixel 10 series. It also introduced Pixelsnap — its own version of a MagSafe accessory ecosystem, including a slim puck with a fold-out kickstand that you can snap onto a phone. I love the Pixel Ring Stand and make sure to bring it with me whenever I can. It works perfectly with my iPhone 17 Pro, and has a compact footprint that makes it easy to take anywhere. Of course, it’s not the first of its kind — Case-Mate and PopSocket, among others, already make similar products but they’re either pricier or rated poorly. But it’s not just Google that made a magnetic accessory I unexpectedly adored. When reports of Apple’s Crossbody Strap first trickled out, I was underwhelmed. Who cares about a crossbody strap for an iPhone? But when I was presented with one to try at the iPhone 17 launch event, my cynicism quickly melted into desire. Setting aside the convenience of having your phone on your person when you don’t have pockets or a purse, the way magnets play a part here also won me over. To adjust the length of the straps, you just separate the two overlapping pieces that stick together magnetically, move them along each other till you’re satisfied with the length and let them snap back in place. I’m sure Apple isn’t the first to make a crossbody strap accessory for iPhones, nor is it the first to use magnets to adjust such straps. But like many Redditors, I’ve slowly come to realize the differences between those products and the Crossbody Strap for iPhone 17. It’s far from perfect, but in 2025 it was another implementation of magnets in tech that caught my attention and brought convenience to my life. — C.L.This article originally appeared on Engadget at https://www.engadget.com/techs-biggest-winners-of-2025-180000177.html?src=rss",
          "content": "Every December, the Engadget staff compiles a list of the year’s biggest winners. We scour over articles from the previous 12 months to determine the people, companies, products and trends that made the most impact over the course of the year. Not all of that influence is positive, however, and some selections may also appear on our list of biggest losers. Still, sit back and enjoy our picks for the biggest winners of 2025.Nintendo Switch 2Playing Mario Kart World on the Switch 2 in handheld mode.Sam Rutherford for EngadgetAside from a big bump in battery life that many were hoping for, Nintendo took just about everything that made its last console such a phenomenon and upgraded it on the Switch 2. A sleeker design with magnetic Joy-Cons that are less likely to break, a larger (albeit LCD) 1080p display with HDR, much stronger performance, mouse controls and a boost to the base storage were all very welcome.Of course, the vast majority of Switch games run on the Switch 2 (often with visual improvements or other upgrades), so the new console had a vast library right from the jump. Nintendo is building out its slate of first-party games with treats like Donkey Kong Bananza and Metroid Prime 4, and the third-party support is seriously impressive too. Cyberpunk 2077, Street Fighter 6 and Hitman: World of Assassination are already available, and the likes of Final Fantasy VII Remake Intergrade and FromSoftware's Switch 2 exclusive The Duskbloods are on the way.The Switch 2 is an iteration, not a revolution, but Nintendo didn't need to reinvent the wheel to make another great system. It's little surprise, then, that we gave the Switch 2 a score of 93 in our review. The console is surpassing Nintendo's sales expectations as well. The company said in November that it believes it will sell 19 million units (up from 15 million) by the time its current fiscal year ends in March. — Kris Holt, Contributing reporterNVIDIANVIDIA GeForce 5070 TiDevindra Hardawar for EngadgetCould things be any rosier for NVIDIA? Once just a video card company for gamers, NVIDIA's GPU hardware is now directly tied to the rise of the AI industry. Its stock has jumped a whopping 1,235 percent over the past five years, going from $13.56 per share in 2020 to a peak of $202.49 this past October. NVIDIA's server-grade cards are being used en masse to train AI models, as well as to power AI inferencing. At home, its GeForce GPUs are enabling local AI development and they're still the gaming cards to beat, despite AMD's steadily improving competition.Clearly, the company's bet on parallel processing has paid off enormously. Its GPUs can handle tons of computations simultaneously, making them ideally suited for the demands of the AI industry. They're not exactly efficient — that's why neural processing units, or NPUs have sprung up to power consumer AI features — but it's hard to deny NVIDIA's raw computational power. NVIDIA's AI success may not last forever, though. Companies like Google and Microsoft are already working on their own AI chips, and it's still unclear if consumers actually want widespread AI features as much as tech companies think. If the AI industry crashes, NVIDIA will be one of the first victims. — Devindra Hardawar, Senior reporterTech billionairesUS President Donald Trump speaks during a news conference with Elon Musk (L) in the Oval Office of the White House in Washington, DC, on May 30, 2025. ALLISON ROBBERT via Getty ImagesThere's no doubt that tech billionaires, especially those that lean conservatively, have benefitted tremendously from the Trump administration over the past year. Elon Musk's DOGE team of tech loyalists chainsawed their way through the budgets and staff of several federal agencies, including the National Highway Traffic Safety Administration (NHTSA), which regulates Tesla. (That hasn't stopped the NHTSA from launching a new investigation into Tesla's full self-driving tech, though.)According to a recent report by Oxfam, the 10 richest US billionaires (who are all tech leaders, save for Warren Buffet) increased their wealth by $698 billion of the past year. Of course, it took plenty of wining and dining to get there. Elon Musk reportedly donated nearly $300 million to Trump and Republican allies, and several tech companies have pitched in to build the president's lavish White House ballroom. But the result for the tech elite is increased access to the president, less scrutiny when it comes to acquisitions and other deals, and the potential for massive corporate and elite tax cuts. — D.H.AI videoA silhouetted individual is seen holding a mobile phone with a Sora of ChatGPT OpenAI logo displayed in the backgroundSOPA Images via Getty ImagesAI slop didn't start in 2025, but it reached new heights thanks to updates from Meta, Google, OpenAI and others that made it easier than ever to create a real-ish (emphasis on the ish) looking clips from nothing but your most unhinged mad libs. Now, AI-generated videos are just about impossible to avoid. Some platforms, like Pinterest and TikTok, have even begun offering people the ability to ask their algorithms to show less AI content in their feeds. Unfortunately, there's no way to stuff Shrimp Jesus back into the bottle. AI video is everywhere and it's here to stay. It's not only overtaken Facebook and Instagram's recommendations, Meta created an entirely separate feed just for users' AI-generated fever dreams. OpenAI's Sora, which lets you make AI videos of real people, was downloaded a million times in just a few days. Google's Veo, which generated more than 40 million videos in a matter of weeks, is now built-in to YouTube Shorts.It's now trivially easy for creators to churn out fake movie trailers, cute animal videos that never happened or viral clips of made up ICE raids. Hell, the president of the United States regularly shares bizarre, sometimes poop-themed, AI videos on his official social media channels. During the government shutdown, the official X account for Senate Republicans shared a deepfake of Senate minority leader Chuck Schumer. AI video is winning not just because it's everywhere, but because so many are unable, or unwilling, to understand what's real and what isn't. More than half of Americans say they are not confident in their ability to distinguish between human and AI-generated content, according to Pew Research. Similar numbers of people report being \"more concerned than excited about the increased use of AI in daily life.\" But those concerns have done little to stop AI slop from dominating all of our feeds, and there's no sign it will ever slow down. — Karissa Bell, Senior reporterGalaxy Z Fold 7Samsung Galaxy Z Fold 7Sam Rutherford for EngadgetAfter seven generations, Samsung reached an important milestone this year with its Galaxy Z Fold line: It made a foldable phone that’s the same size as a regular handset. In fact, weighing 7.58 ounces and measuring 72.8mm wide, the Galaxy Z Fold 7 is actually lighter and narrower than an S25 Ultra, while being practically just as thin at 8.9mm (folded). It’s a real marvel of engineering, especially when you consider the phone also features a 200MP main camera, an IPX8 rating for water resistance and a 5,000 mAh battery with 45-watt wired charging. And of course, there's that huge 8-inch main screen hiding inside, which makes the Z Fold 7 both a phone and a tablet in one device. The only thing it's really missing is the improved dust resistance Google gave to the Pixel 10 Pro Fold. But perhaps more importantly, the Z Fold 7's reduced size and weight have created a device with wider appeal. This has propelled sales of Samsung's latest flagship foldable up 50 percent compared to the previous generation while pushing shipments of foldables as a whole to record highs. Who knew that when Samsung focuses on creating world-class hardware instead of overindexing on AI, good things happen? Okay, maybe that’s a bit harsh. Regardless, for a phone category that has struggled with excess weight and bulk since its inception, the Z Fold 7 feels like a revelation and the beginning of a new era for handsets with flexible displays. Now, can we just bring their prices down, please? — Sam Rutherford, Senior reporterSmart glassesSenior reporter Karissa Bell wearing a pair of Ray Ban Display glasses. Karissa Bell for EngadgetLike it or not, smart glasses are having a moment. Propelled by new devices like the Meta Ray-Ban Display and upcoming models like Xreal’s Project Aura, the idea of wearing specs with built-in screens suddenly became an attractive proposition. And that means a lot for a category of gadgets that’s often best remembered by the fashion tragedy that was Google Glass in 2013. However, this development isn’t purely by chance. The latest generation of smart glasses has only just now become a reality due to the convergence of several branches of tech — including improved optics, lightweight batteries and, of course, AI. Now that last one might sound silly considering how many big companies seem to be betting the farm on machine learning being the next big thing, but AI will be a critical feature for enabling the hands-free experience that you need to make smartglasses work when you can’t rely on touch input. While this category is still in its early stages of development, the increased momentum we've seen from smart glasses this year seems poised to carry them towards being a future pillar of people's core tech kits. — S.R.Fast chargingFast charging on the Pixel Watch 4 is one implementation that impressed us this year.Cherlynn Low for EngadgetDevices like tablets and smartwatches have matured to the point where each generation mostly sees iterative upgrades, making covering them seem boring. But this year, as the hardware review season came to a close, I noticed an interesting trend. One feature, across various product categories, genuinely excited myself and other reviewers at Engadget and around the internet: impressively fast charging. By itself, high-speed charging isn’t new. But when I reviewed the Pixel Watch 4 in October, I was shocked that one seemingly little update changed how I went about my day. The new power system on Google’s smartwatch was so efficient that after about ten minutes on a cradle, the wearable went from below 20 percent to past 50 percent. With that boost, I stopped having to remind myself to plug the watch in — any time I ran low or was about to run out the door, I just plopped it on the charger and would have enough juice for hours.Google wasn’t the only company to make fast-charging a meaningful addition to one of its 2025 products. Apple’s iPad Pro M5 is the first iPad to support the feature, and while in our testing it fell a little short of the 50 percent charge in 30 minutes that the company promised, our reviewer Nate Ingraham still found it a meaningful improvement.Observers of the smartphone industry will likely point out two things. First, battery technology can be volatile, and larger, faster-charging cells might lead to exploding phones. So my optimism about this development is not without caution. Secondly, we’ve already seen all this come to handsets, especially in phones that launched outside the US first. OnePlus is known for its SUPERVOOC fast charging system, for example, and we’re seeing even more novel battery tech show up abroad. Calling fast charging a winner of 2025 may feel untimely to some.But when you consider the spread of speedier charging to other types of products, especially in electric vehicles that till now take forever to top up, the benefits are clear. This year, we saw Formula E (finally) debut its fast-charging pit stops, Honda announce its first full-size electric motorcycle with fast charging and Chinese EV maker BYD unveiling new tech that delivers peak EV charging speeds of 1,000 kilowatts. That should about halve the time it currently takes to top up your electric car. Sure, it’s not the most eye-catching or novel technological development. But when counted in terms of precious time saved, fast charging coming to more types of devices certainly amounts to a greater good in gadgets in 2025. — Cherlynn Low, Managing editorMagnetsThe Pixel 10 Pro Fold and the Pixel Ring StandSam Rutherford for EngadgetTwo years after the announcement of the Qi 2 wireless charging standard and its support of magnetic attachment accessories (a la Apple’s MagSafe), we’re finally seeing one of the more mainstream Android devices adopt it. In 2025, Google became the first Android phone maker that’s not HMD to do so, bringing such magnetic capabilities to the Pixel 10 series. It also introduced Pixelsnap — its own version of a MagSafe accessory ecosystem, including a slim puck with a fold-out kickstand that you can snap onto a phone. I love the Pixel Ring Stand and make sure to bring it with me whenever I can. It works perfectly with my iPhone 17 Pro, and has a compact footprint that makes it easy to take anywhere. Of course, it’s not the first of its kind — Case-Mate and PopSocket, among others, already make similar products but they’re either pricier or rated poorly. But it’s not just Google that made a magnetic accessory I unexpectedly adored. When reports of Apple’s Crossbody Strap first trickled out, I was underwhelmed. Who cares about a crossbody strap for an iPhone? But when I was presented with one to try at the iPhone 17 launch event, my cynicism quickly melted into desire. Setting aside the convenience of having your phone on your person when you don’t have pockets or a purse, the way magnets play a part here also won me over. To adjust the length of the straps, you just separate the two overlapping pieces that stick together magnetically, move them along each other till you’re satisfied with the length and let them snap back in place. I’m sure Apple isn’t the first to make a crossbody strap accessory for iPhones, nor is it the first to use magnets to adjust such straps. But like many Redditors, I’ve slowly come to realize the differences between those products and the Crossbody Strap for iPhone 17. It’s far from perfect, but in 2025 it was another implementation of magnets in tech that caught my attention and brought convenience to my life. — C.L.This article originally appeared on Engadget at https://www.engadget.com/techs-biggest-winners-of-2025-180000177.html?src=rss",
          "feed_position": 11,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-06/0a096060-55df-11f0-ba9d-0a6ff3cbbb07"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/booking-coms-agent-strategy-disciplined-modular-and-already-delivering-2",
          "published_at": "Mon, 08 Dec 2025 15:00:00 GMT",
          "title": "Booking.com’s agent strategy: Disciplined, modular and already delivering 2× accuracy",
          "standfirst": "When many enterprises weren’t even thinking about agentic behaviors or infrastructures, Booking.com had already “stumbled” into them with its homegrown conversational recommendation system. This early experimentation has allowed the company to take a step back and avoid getting swept up in the frantic AI agent hype. Instead, it is taking a disciplined, layered, modular approach to model development: small, travel-specific models for cheap, fast inference; larger large language models (LLMs) for reasoning and understanding; and domain-tuned evaluations built in-house when precision is critical. With this hybrid strategy — combined with selective collaboration with OpenAI — Booking.com has seen accuracy double across key retrieval, ranking and customer-interaction tasks. As Pranav Pathak, Booking.com’s AI product development lead, posed to VentureBeat in a new podcast: “Do you build it very, very specialized and bespoke and then have an army of a hundred agents? Or do you keep it general enough and have five agents that are good at generalized tasks, but then you have to orchestrate a lot around them? That&#x27;s a balance that I think we&#x27;re still trying to figure out, as is the rest of the industry.” Check out the new Beyond the Pilot podcast here, and continue reading for highlights. Moving from guessing to deep personalization without being ‘creepy’Recommendation systems are core to Booking.com’s customer-facing platforms; however, traditional recommendation tools have been less about recommendation and more about guessing, Pathak conceded. So, from the start, he and his team vowed to avoid generic tools: As he put it, the price and recommendation should be based on customer context. Booking.com’s initial pre-gen AI tooling for intent and topic detection was a small language model, what Pathak described as “the scale and size of BERT.” The model ingested the customer’s inputs around their problem to determine whether it could be solved through self-service or bumped to a human agent. “We started with an architecture of ‘you have to call a tool if this is the intent you detect and this is how you&#x27;ve parsed the structure,” Pathak explained. “That was very, very similar to the first few agentic architectures that came out in terms of reason and defining a tool call.” His team has since built out that architecture to include an LLM orchestrator that classifies queries, triggers retrieval-augmented generation (RAG) and calls APIs or smaller, specialized language models. “We&#x27;ve been able to scale that system quite well because it was so close in architecture that, with a few tweaks, we now have a full agentic stack,” said Pathak. As a result, Booking.com is seeing a 2X increase in topic detection, which in turn is freeing up human agents’ bandwidth by 1.5 to 1.7X. More topics, even complicated ones previously identified as ‘other’ and requiring escalation, are being automated. Ultimately, this supports more self-service, freeing human agents to focus on customers with uniquely-specific problems that the platform doesn’t have a dedicated tool flow for — say, a family that is unable to access its hotel room at 2 a.m. when the front desk is closed. That not only “really starts to compound,” but has a direct, long-term impact on customer retention, Pathak noted. “One of the things we&#x27;ve seen is, the better we are at customer service, the more loyal our customers are.” Another recent rollout is personalized filtering. Booking.com has between 200 and 250 search filters on its website — an unrealistic amount for any human to sift through, Pathak pointed out. So, his team introduced a free text box that users can type into to immediately receive tailored filters. “That becomes such an important cue for personalization in terms of what you&#x27;re looking for in your own words rather than a clickstream,” said Pathak. In turn, it cues Booking.com into what customers actually want. For instance, hot tubs — when filter personalization first rolled out, jacuzzi’s were one of the most popular requests. That wasn’t even a consideration previously; there wasn’t even a filter. Now that filter is live. “I had no idea,” Pathak noted. “I had never searched for a hot tub in my room honestly.” When it comes to personalization, though, there is a fine line; memory remains complicated, Pathak emphasized. While it’s important to have long-term memories and evolving threads with customers — retaining information like their typical budgets, preferred hotel star ratings or whether they need disability access — it must be on their terms and protective of their privacy. Booking.com is extremely mindful with memory, seeking consent so as to not be “creepy” when collecting customer information. “Managing memory is much harder than actually building memory,” said Pathak. “The tech is out there, we have the technical chops to build it. We want to make sure we don&#x27;t launch a memory object that doesn&#x27;t respect customer consent, that doesn&#x27;t feel very natural.”Finding a balance of build versus buy As agents mature, Booking.com is navigating a central question facing the entire industry: How narrow should agents become? Instead of committing to either a swarm of highly specialized agents or a few generalized ones, the company aims for reversible decisions and avoids “one-way doors” that lock its architecture into long-term, costly paths. Pathak’s strategy is: Generalize where possible, specialize where necessary and keep agent design flexible to help ensure resiliency. Pathak and his team are “very mindful” of use cases, evaluating where to build more generalized, reusable agents or more task-specific ones. They strive to use the smallest model possible, with the highest level of accuracy and output quality, for each use case. Whatever can be generalized is. Latency is another important consideration. When factual accuracy and avoiding hallucinations is paramount, his team will use a larger, much slower model; but with search and recommendations, user expectations set speed. (Pathak noted: “No one’s patient.”) “We would, for example, never use something as heavy as GPT-5 for just topic detection or for entity extraction,” he said. Booking.com takes a similarly elastic tack when it comes to monitoring and evaluations: If it&#x27;s general-purpose monitoring that someone else is better at building and has horizontal capability, they’ll buy it. But if it’s instances where brand guidelines must be enforced, they’ll build their own evals. Ultimately, Booking.com has leaned into being “super anticipatory,” agile and flexible. “At this point with everything that&#x27;s happening with AI, we are a little bit averse to walking through one way doors,” said Pathak. “We want as many of our decisions to be reversible as possible. We don&#x27;t want to get locked into a decision that we cannot reverse two years from now.”What other builders can learn from Booking.com’s AI journeyBooking.com’s AI journey can serve as an important blueprint for other enterprises. Looking back, Pathak acknowledged that they started out with a “pretty complicated” tech stack. They’re now in a good place with that, “but we probably could have started something much simpler and seen how customers interacted with it.” Given that, he offered this valuable advice: If you’re just starting out with LLMs or agents, out-of-the-box APIs will do just fine. “There&#x27;s enough customization with APIs that you can already get a lot of leverage before you decide you want to go do more.” On the other hand, if a use case requires customization not available through a standard API call, that makes a case for in-house tools. Still, he emphasized: Don&#x27;t start with the complicated stuff. Tackle the “simplest, most painful problem you can find and the simplest, most obvious solution to that.” Identify the product market fit, then investigate the ecosystems, he advised — but don’t just rip out old infrastructures because a new use case demands something specific (like moving an entire cloud strategy from AWS to Azure just to use the OpenAI endpoint). Ultimately: “Don&#x27;t lock yourself in too early,” Pathak noted. “Don&#x27;t make decisions that are one-way doors until you are very confident that that&#x27;s the solution that you want to go with.”",
          "content": "When many enterprises weren’t even thinking about agentic behaviors or infrastructures, Booking.com had already “stumbled” into them with its homegrown conversational recommendation system. This early experimentation has allowed the company to take a step back and avoid getting swept up in the frantic AI agent hype. Instead, it is taking a disciplined, layered, modular approach to model development: small, travel-specific models for cheap, fast inference; larger large language models (LLMs) for reasoning and understanding; and domain-tuned evaluations built in-house when precision is critical. With this hybrid strategy — combined with selective collaboration with OpenAI — Booking.com has seen accuracy double across key retrieval, ranking and customer-interaction tasks. As Pranav Pathak, Booking.com’s AI product development lead, posed to VentureBeat in a new podcast: “Do you build it very, very specialized and bespoke and then have an army of a hundred agents? Or do you keep it general enough and have five agents that are good at generalized tasks, but then you have to orchestrate a lot around them? That&#x27;s a balance that I think we&#x27;re still trying to figure out, as is the rest of the industry.” Check out the new Beyond the Pilot podcast here, and continue reading for highlights. Moving from guessing to deep personalization without being ‘creepy’Recommendation systems are core to Booking.com’s customer-facing platforms; however, traditional recommendation tools have been less about recommendation and more about guessing, Pathak conceded. So, from the start, he and his team vowed to avoid generic tools: As he put it, the price and recommendation should be based on customer context. Booking.com’s initial pre-gen AI tooling for intent and topic detection was a small language model, what Pathak described as “the scale and size of BERT.” The model ingested the customer’s inputs around their problem to determine whether it could be solved through self-service or bumped to a human agent. “We started with an architecture of ‘you have to call a tool if this is the intent you detect and this is how you&#x27;ve parsed the structure,” Pathak explained. “That was very, very similar to the first few agentic architectures that came out in terms of reason and defining a tool call.” His team has since built out that architecture to include an LLM orchestrator that classifies queries, triggers retrieval-augmented generation (RAG) and calls APIs or smaller, specialized language models. “We&#x27;ve been able to scale that system quite well because it was so close in architecture that, with a few tweaks, we now have a full agentic stack,” said Pathak. As a result, Booking.com is seeing a 2X increase in topic detection, which in turn is freeing up human agents’ bandwidth by 1.5 to 1.7X. More topics, even complicated ones previously identified as ‘other’ and requiring escalation, are being automated. Ultimately, this supports more self-service, freeing human agents to focus on customers with uniquely-specific problems that the platform doesn’t have a dedicated tool flow for — say, a family that is unable to access its hotel room at 2 a.m. when the front desk is closed. That not only “really starts to compound,” but has a direct, long-term impact on customer retention, Pathak noted. “One of the things we&#x27;ve seen is, the better we are at customer service, the more loyal our customers are.” Another recent rollout is personalized filtering. Booking.com has between 200 and 250 search filters on its website — an unrealistic amount for any human to sift through, Pathak pointed out. So, his team introduced a free text box that users can type into to immediately receive tailored filters. “That becomes such an important cue for personalization in terms of what you&#x27;re looking for in your own words rather than a clickstream,” said Pathak. In turn, it cues Booking.com into what customers actually want. For instance, hot tubs — when filter personalization first rolled out, jacuzzi’s were one of the most popular requests. That wasn’t even a consideration previously; there wasn’t even a filter. Now that filter is live. “I had no idea,” Pathak noted. “I had never searched for a hot tub in my room honestly.” When it comes to personalization, though, there is a fine line; memory remains complicated, Pathak emphasized. While it’s important to have long-term memories and evolving threads with customers — retaining information like their typical budgets, preferred hotel star ratings or whether they need disability access — it must be on their terms and protective of their privacy. Booking.com is extremely mindful with memory, seeking consent so as to not be “creepy” when collecting customer information. “Managing memory is much harder than actually building memory,” said Pathak. “The tech is out there, we have the technical chops to build it. We want to make sure we don&#x27;t launch a memory object that doesn&#x27;t respect customer consent, that doesn&#x27;t feel very natural.”Finding a balance of build versus buy As agents mature, Booking.com is navigating a central question facing the entire industry: How narrow should agents become? Instead of committing to either a swarm of highly specialized agents or a few generalized ones, the company aims for reversible decisions and avoids “one-way doors” that lock its architecture into long-term, costly paths. Pathak’s strategy is: Generalize where possible, specialize where necessary and keep agent design flexible to help ensure resiliency. Pathak and his team are “very mindful” of use cases, evaluating where to build more generalized, reusable agents or more task-specific ones. They strive to use the smallest model possible, with the highest level of accuracy and output quality, for each use case. Whatever can be generalized is. Latency is another important consideration. When factual accuracy and avoiding hallucinations is paramount, his team will use a larger, much slower model; but with search and recommendations, user expectations set speed. (Pathak noted: “No one’s patient.”) “We would, for example, never use something as heavy as GPT-5 for just topic detection or for entity extraction,” he said. Booking.com takes a similarly elastic tack when it comes to monitoring and evaluations: If it&#x27;s general-purpose monitoring that someone else is better at building and has horizontal capability, they’ll buy it. But if it’s instances where brand guidelines must be enforced, they’ll build their own evals. Ultimately, Booking.com has leaned into being “super anticipatory,” agile and flexible. “At this point with everything that&#x27;s happening with AI, we are a little bit averse to walking through one way doors,” said Pathak. “We want as many of our decisions to be reversible as possible. We don&#x27;t want to get locked into a decision that we cannot reverse two years from now.”What other builders can learn from Booking.com’s AI journeyBooking.com’s AI journey can serve as an important blueprint for other enterprises. Looking back, Pathak acknowledged that they started out with a “pretty complicated” tech stack. They’re now in a good place with that, “but we probably could have started something much simpler and seen how customers interacted with it.” Given that, he offered this valuable advice: If you’re just starting out with LLMs or agents, out-of-the-box APIs will do just fine. “There&#x27;s enough customization with APIs that you can already get a lot of leverage before you decide you want to go do more.” On the other hand, if a use case requires customization not available through a standard API call, that makes a case for in-house tools. Still, he emphasized: Don&#x27;t start with the complicated stuff. Tackle the “simplest, most painful problem you can find and the simplest, most obvious solution to that.” Identify the product market fit, then investigate the ecosystems, he advised — but don’t just rip out old infrastructures because a new use case demands something specific (like moving an entire cloud strategy from AWS to Azure just to use the OpenAI endpoint). Ultimately: “Don&#x27;t lock yourself in too early,” Pathak noted. “Don&#x27;t make decisions that are one-way doors until you are very confident that that&#x27;s the solution that you want to go with.”",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2t04hE5kMFifED9FQ12PcA/86ec4e3895472b25edb77273488d1c7a/Booking.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/the-best-budgeting-apps-to-replace-mint-143047346.html",
          "published_at": "Mon, 08 Dec 2025 10:01:27 +0000",
          "title": "The 5 best Mint alternatives to replace the budgeting app that shut down",
          "standfirst": "It's been over one year since Intuit shut down the popular budgeting app Mint. I was a Mint user for many years; millions of other users like me enjoyed how easily Mint allowed us to track all accounts in one place and monitor credit scores. I also used it regularly to help me track spending, set goals like pay my mortgage down faster and with general money management.Ahead of Mint’s demise, I gave Credit Karma, Intuit’s other financial app, a try but found it to be a poor Mint alternative. So I set out to find a true replacement in another budgeting app. The following guide lays out my experience testing some of the most popular Mint replacement apps available today. Our pick for best Mint alternative remains Quicken Simplifi, even this long after Mint being shut down, thanks to its easy to use app, good income and bill detection and its affordable price. But there are plenty of other solid options out there for those with different needs. If you’re also on the hunt for a budgeting app to replace Mint, we hope these details can empower you to choose which of the best budgeting apps out there will be right for you. Table of contents Best Mint alternatives in 2025 Other Mint alternatives we tested What is Plaid and how does it work? How to import your financial data from the Mint app How we tested Mint alternatives What about Rocket Money? Best Mint alternatives in 2025 No pun intended, but what I like about Quicken Simplifi is its simplicity. Whereas other budgeting apps try to distinguish themselves with dark themes and customizable emoji, Simplifi has a clean user interface, with a landing page that you just keep scrolling through to get a detailed overview of all your stats. These include your top-line balances; net worth; recent spending; upcoming recurring payments; a snapshot of your spending plan; top spending categories; achievements; and any watchlists you’ve set up. Another one of the key features I appreciate is the ability to set up savings goals elsewhere in the app. I also appreciate how it offers neat, almost playful visualizations without ever looking cluttered. I felt at home in the mobile and web dashboards after a day or so, which is faster than I adapted to some competing services (I’m looking at you, YNAB and Monarch). Getting set up with Simplifi was mostly painless. I was particularly impressed at how easily it connected to Fidelity; not all budget trackers do, for whatever reason. This is also one of the only services I tested that gives you the option of inviting a spouse or financial advisor to co-manage your account. One thing I would add to my initial assessment of the app, having used it for a few months now: I wish Simplifi offered Zillow integration for easily tracking your home value (or at least a rough estimate of it). Various competitors including Monarch Money and Copilot Money work with Zillow, so clearly there's a Zillow API available for use. As it stands, Simplifi users must add real estate manually like any other asset. Dana Wollman / Engadget In practice, Simplifi miscategorized some of my expenses, but nothing out of the ordinary compared to any of these budget trackers. As you’re reviewing transactions, you can also mark if you’re expecting a refund, which is a unique feature among the services I tested. Simplifi also estimated my regular income better than some other apps I tested. Most of all, I appreciated the option of being able to categorize some, but not all, purchases from a merchant as recurring. For instance, I can add my two Amazon subscribe-and-saves as recurring payments, without having to create a broad-strokes rule for every Amazon purchase. The budgeting feature is also self-explanatory and can likely accommodate your preferred budgeting method. Just check that your regular income is accurate and be sure to set up recurring payments, making note of which are bills and which are subscriptions. This is important because Simplifi shows you your total take-home income as well as an “income after bills” figure. That number includes, well, bills but not discretionary subscriptions. From there, you can add spending targets by category in the “planned spending” bucket. Planned spending can also include one-time expenditures, not just monthly budgets. When you create a budget, Simplifi will suggest a number based on a six-month average. Not dealbreakers, but two things to keep in mind as you get started: Simplifi is notable in that you can’t set up an account through Apple or Google. There is also no option for a free trial, though Quicken promises a “30-day money back guarantee.” Monarch Money grew on me. My first impression of the budgeting app, which was founded by a former Mint product manager, was that it's more difficult to use than others on this list, including Simplifi, NerdWallet and Copilot. And it is. Editing expense categories, adding recurring transactions and creating rules, for example, is a little more complicated than it needs to be, especially in the mobile app. (My advice: Use the web app for fine-tuning details.) Monarch also didn’t get my income right; I had to edit it. Once you’re set up, though, Monarch offers an impressive level of granularity. In the budgets section, you can see a bona fide balance sheet showing budgets and actuals for each category. You'll also find a forecast, for the year or by month. And recurring expenses can be set not just by merchant, but other parameters as well. For instance, while most Amazon purchases might be marked as “shopping,” those for the amounts of $54.18 or $34.18 are definitely baby supplies, and can be automatically marked as such each time, not to mention programmed as recurring payments. Weirdly, though, there’s no way to mark certain recurring payments as bills, specifically. Dana Wollman / Engadget Not long after I first published this story in December 2023, Monarch introduced a detailed reporting section where you can create on-demand graphs based on things like accounts, categories and tags. That feature is available just on the web version of the app for now. As part of this same update, Monarch added support for an aggregator that makes it possible to automatically update the value of your car. This, combined with the existing Zillow integration for tracking your home value, makes it easy to quickly add a non-liquid asset like a vehicle or real estate, and have it show up in your net worth graph. The mobile app is mostly self-explanatory. The main dashboard shows your net worth; your four most recent transactions; a month-over-month spending comparison; income month-to-date; upcoming bills; an investments snapshot; a list of any goals you’ve set; and, finally, a link to your month-in-review. That month-in-review is more detailed than most, delving into cash flow; top income and expense categories; cash flow trends; changes to your net worth, assets and liabilities; plus asset and liability breakdowns. In February 2024, Monarch expanded on the net worth graph, so that if you click on the Accounts tab you can see how your net worth changed over different periods of time, including one month, three months, six months, a year or all time. On the main screen, you’ll also find tabs for savings and checking accounts (and all others as well), transactions, cash flow, budget and recurring. Like many of the other apps featured here, Monarch can auto-detect recurring expenses and income, even if it gets the category wrong. (They all do to an extent.) Expense categories are marked by emoji, which you can customize if you’re so inclined. Monarch Money uses a combination of networks to connect with banks, including Plaid, MX and Finicity, a competing network owned by Mastercard. (I have a quick explainer on Plaid, the industry standard in this space, toward the end of this guide.) As part of an update in late December, Monarch has also made it easier to connect through those other two networks, if for some reason Plaid fails. Similar to NerdWallet, I found myself completing two-factor authentication every time I wanted to get past the Plaid screen to add another account. Notably, Monarch is the only other app I tested that allows you to grant access to someone else in your family — likely a spouse or financial advisor. Monarch also has a Chrome extension for importing from Mint, though really this is just a shortcut for downloading a CSV file, which you’ll have to do regardless of where you choose to take your Mint data. Additionally, Monarch just added the ability to track Apple Card, Apple Cash, and Savings accounts, thanks to new functionality brought with the iOS 17.4 update. It's not the only one either; currently, Copilot and YNAB have also added similar functionality that will be available to anyone with the latest versions of their respective apps on a device running iOS 17.4. Instead of manually uploading statements, the new functionality allows apps like Monarch's to automatically pull in transactions and balance history. That should make it easier to account for spending on Apple cards and accounts throughout the month. Monarch also recently launched investment transactions in beta. It also says bill tracking and an overhauled goals system are coming soon. Monarch hasn't provided a timeline for that last one, except to say that the improved goals feature is coming soon. Copilot Money might be the best-looking budgeting app I tested. It also has the distinction of being exclusive to iOS and Macs — at least for now. Andres Ugarte, the company’s CEO, has publicly promised that Android and web apps are coming soon. But until it follows through, I can’t recommend Copilot for most people with so many good competitors out there. Copilot Money for Web and Android!Thanks to the support from our users, and the overwhelming positive reception we're seeing from folks migrating from Mint, we can now say that we'll be building @copilotmoney for Web and Android with a goal to launch in 2024.We'll continue to…— Andres Ugarte (@chuga) November 15, 2023 There are other features that Copilot is missing, which I’ll get into. But it is promising, and one to keep an eye on. It’s just a fast, efficient, well designed app, and Android users will be in for a treat when they’ll finally be able to download it. It makes good use of colors, emoji and graphs to help you understand at a glance how you’re doing on everything from your budgets to your investment performance to your credit card debt over time. In particular, Copilot does a better job than almost any other app of visualizing your recurring monthly expenses. Behind those punchy colors and cutesy emoji, though, is some sophisticated performance. Copilot’s AI-powered “Intelligence” gets smarter as you go at categorizing your expenses. (You can also add your own categories, complete with your choice of emoji.) It’s not perfect. Copilot miscategorized some purchases (they all do), but it makes it easier to edit than most. On top of that, the internal search feature is very fast; it starts whittling down results in your transaction history as soon as you begin typing. Dana Wollman / Engadget Copilot is also unique in offering Amazon and Venmo integrations, allowing you to see transaction details. With Amazon, this requires just signing into your Amazon account via an in-app browser. For Venmo, you have to set up fwd@copilot.money as a forwarding address and then create a filter, wherein emails from venmo@venmo.com are automatically forwarded to fwd@copilot.money. Like Monarch Money, you can also add any property you own and track its value through Zillow, which is integrated with the app. While the app is heavily automated, I still appreciate that Copilot marks new transactions for review. It’s a good way to both weed out fraudulent charges, and also be somewhat intentional about your spending habits. Like Monarch Money, Copilot updated its app to make it easier to connect to banks through networks other than Plaid. As part of the same update, Copilot said it has improved its connections to both American Express and Fidelity which, again, can be a bugbear for some budget tracking apps. In an even more recent update, Copilot added a Mint import option, which other budgeting apps have begun to offer as well. Because the app is relatively new (it launched in early 2020), the company is still catching up to the competition on some table-stakes features. Ugarte told me that his team is almost done building out a detailed cash flow section as well. On its website, Copilot also promises a raft of AI-powered features that build on its current “Intelligence” platform, the one that powers its smart expense categorization. These include “smart financial goals,” natural language search, a chat interface, forecasting and benchmarking. That benchmarking, Ugarte tells me, is meant to give people a sense of how they’re doing compared to other Copilot users, on both spending and investment performance. Most of these features should arrive in the new year. Copilot does a couple interesting things for new customers that distinguish it from the competition. There’s a “demo mode” that feels like a game simulator; no need to add your own accounts. The company is also offering two free months with RIPMINT — a more generous introductory offer than most. When it finally does come time to pony up, the $7.92 monthly plan is cheaper than some competing apps, although the $95-a-year-option is in the same ballpark. You may know NerdWallet as a site that offers a mix of personal finance news, explainers and guides. I see it often when I google a financial term I don’t know and sure enough, it’s one of the sites I’m most likely to click on. As it happens, NerdWallet also has the distinction of offering one of the only free budgeting apps I tested. In fact, there is no paid version; nothing is locked behind a paywall. The main catch: There are ads everywhere. To be fair, the free version of Mint was like this, too. Even with the inescapable credit card offers, NerdWallet has a clean, easy-to-understand user interface, which includes both a web and a mobile app. The key metrics that it highlights most prominently are your cash flow, net worth and credit score. (Of note, although Mint itself offered credit score monitoring, most of its rivals do not.) I particularly enjoyed the weekly insights, which delve into things like where you spent the most money or how much you paid in fees — and how that compares to the previous month. Because this is NerdWallet, an encyclopedia of financial info, you get some particularly specific category options when setting up your accounts (think: a Roth or non-Roth IRA). Dana Wollman / Engadget As a budgeting app, NerdWallet is more than serviceable, if a bit basic. Like other apps I tested, you can set up recurring bills. Importantly, it follows the popular 50/30/20 budgeting rule, which has you putting 50% of your budget toward things you need, 30% toward things you want, and the remaining 20% into savings or debt repayments. If this works for you, great — just know that you can’t customize your budget to the same degree as some competing apps. You can’t currently create custom spending categories, though a note inside the dashboard section of the app says “you’ll be able to customize them in the future.” You also can’t move items from the wants column to “needs” or vice versa but “In the future, you'll be able to move specific transactions to actively manage what falls into each group.” A NerdWallet spokesperson declined to provide an ETA, though. Lastly, it’s worth noting that NerdWallet had one of the most onerous setup processes of any app I tested. I don’t think this is a dealbreaker, as you’ll only have to do it once and, hopefully, you aren’t setting up six or seven apps in tandem as I was. What made NerdWallet’s onboarding especially tedious is that every time I wanted to add an account, I had to go through a two-factor authentication process to even get past the Plaid splash screen, and that’s not including the 2FA I had set up at each of my banks. This is a security policy on NerdWallet’s end, not Plaid’s, a Plaid spokesperson says. Precisely because NerdWallet is one of the only budget trackers to offer credit score monitoring, it also needs more of your personal info during setup, including your birthday, address, phone number and the last four digits of your social security number. It’s the same with Credit Karma, which also does credit score monitoring. Related to the setup process, I found that NerdWallet was less adept than other apps at automatically detecting my regular income. In my case, it counted a large one-time wire transfer as income, at which point my only other option was to enter my income manually (which is slightly annoying because I would have needed my pay stub handy to double-check my take-home pay). YNAB is, by its own admission, “different from anything you’ve tried before.” The app, whose name is short for You Need a Budget, promotes a so-called zero-based budgeting system, which forces you to assign a purpose for every dollar you earn. A frequently used analogy is to put each dollar in an envelope; you can always move money from one envelope to another in a pinch. These envelopes can include rent and utilities, along with unforeseen expenses like holiday gifts and the inevitable car repair. The idea is that if you budget a certain amount for the unknowns each month, they won’t feel like they’re sneaking up on you. Importantly, YNAB is only concerned with the money you have in your accounts now. The app does not ask you to provide your take-home income or set up recurring income payments (although there is a way to do this). The money you will make later in the month through your salaried job is not relevant, because YNAB does not engage in forecasting. The app is harder to learn than any other here, and it requires more ongoing effort from the user. And YNAB knows that. Inside both the mobile and web apps are links to videos and other tutorials. Although I never quite got comfortable with the user interface, I did come to appreciate YNAB’s insistence on intentionality. Forcing users to draft a new budget each month and to review each transaction is not necessarily a bad thing. As YNAB says on its website, “Sure, you’ve got pie charts showing that you spent an obscene amount of money in restaurants — but you’ve still spent an obscene amount of money in restaurants.” I can see this approach being useful for people who don’t tend to have a lot of cash in reserve at a given time, or who have spending habits they want to correct (to riff off of YNAB’s own example, ordering Seamless four times a week). My colleague Valentina Palladino, knowing I was working on this guide, penned a respectful rebuttal, explaining why she’s been using YNAB for years. Perhaps, like her, you have major savings goals you want to achieve, whether it’s paying for a wedding or buying a house. I suggest you give her column a read. For me, though, YNAB’s approach feels like overkill. Other Mint alternatives we tested PocketGuard PocketGuard used to be a solid free budget tracker, but the company has since limited its “free” version to just a free seven-day trial. Now, you’ll have to choose between two plans once the trial is over: a $13 monthly plan or a $75 annual plan. When I first tested it, I found it to be more restricted than NerdWallet, but still a decent option. The main overview screen shows you your net worth, total assets and debts; net income and total spending for the month; upcoming bills; a handy reminder of when your next paycheck lands; any debt payoff plan you have; and any goals. Like some other apps, including Quicken Simplifi, PocketGuard promotes an “after bills” approach, where you enter all of your recurring bills, and then PocketGuard shows you what’s left, and that’s what you’re supposed to be budgeting: your disposable income. Although PocketGuard’s UI is easy enough to understand, it lacks polish. The “accounts” tab is a little busy, and doesn’t show totals for categories like cash or investments. Seemingly small details like weirdly phrased or punctuated copy occasionally make the app feel janky. More than once, it prompted me to update the app when no updates were available. The web version, meanwhile, feels like the mobile app blown up to a larger format and doesn’t take advantage of the extra screen real estate. Ultimately, now that the free tier is gone, it just doesn’t present the same value proposition as it once did. What is Plaid and how does it work? Each of the apps I tested uses the same underlying network, called Plaid, to pull in financial data, so it’s worth explaining in its own section what it is and how it works. Plaid was founded as a fintech startup in 2013 and is today the industry standard in connecting banks with third-party apps. Plaid works with over 12,000 financial institutions across the US, Canada and Europe. Additionally, more than 8,000 third-party apps and services rely on Plaid, the company claims. To be clear, you don’t need a dedicated Plaid app to use it; the technology is baked into a wide array of apps, including the budget trackers I tested for this guide. Once you find the “add an account” option in whichever one you’re using, you’ll see a menu of commonly used banks. There’s also a search field you can use to look yours up directly. Once you find yours, you’ll be prompted to enter your login credentials. If you have two-factor authentication set up, you’ll need to enter a one-time passcode as well. As the middleman, Plaid is a passthrough for information that may include your account balances, transaction history, account type and routing or account number. Plaid uses encryption, and says it has a policy of not selling or renting customer data to other companies. However, I would not be doing my job if I didn’t note that in 2022 Plaid was forced to pay $58 million to consumers in a class action suit for collecting “more financial data than was needed.” As part of the settlement, Plaid was compelled to change some of its business practices. In a statement provided to Engadget, a Plaid spokesperson said the company continues to deny the allegations underpinning the lawsuit and that “the crux of the non-financial terms in the settlement are focused on us accelerating workstreams already underway related to giving people more transparency into Plaid’s role in connecting their accounts, and ensuring that our workstreams around data minimization remain on track.” How to import your financial data from the Mint app Mint users should consider getting their data ready to migrate to their new budgeting app of choice soon. Unfortunately, importing data from Mint is not as easy as entering your credentials from inside your new app and hitting “import.” In fact, any app that advertises the ability to port over your stats from Mint is just going to have you upload a CSV file of transactions and other data. To download a CSV file from Mint, do the following: Sign into Mint.com and hit Transactions in the menu on the left side of the screen. Select an account, or all accounts. Scroll down and look for “export [number] transactions” in smaller print. Your CSV file should begin downloading. Note: Downloading on a per-account basis might seem more annoying, but could help you get set up on the other side, if the app you’re using has you importing transactions one-for-one into their corresponding accounts. How we tested Mint alternatives Before I dove into the world of budgeting apps, I had to do some research. To find a list of apps to test, I consulted trusty ol’ Google (and even trustier Reddit); read reviews of popular apps on the App Store; and also asked friends and colleagues what budget tracking apps they might be using. Some of the apps I found were free, just like Mint. These, of course, show loads of ads (excuse me, “offers”) to stay in business. But most of the available apps require paid subscriptions, with prices typically topping out around $100 a year, or $15 a month. (Spoiler: My top pick is cheaper than that.) Since this guide is meant to help Mint users find a permanent replacement, any services I chose to test needed to do several things: import all of your account data into one place; offer budgeting tools; and track your spending, net worth and credit score. Except where noted, all of these apps are available for iOS, Android and on the web. Once I had my shortlist of six apps, I got to work setting them up. For the sake of thoroughly testing these apps (and remember, I really was looking for a Mint alternative myself), I made a point of adding every account to every budgeting app, no matter how small or immaterial the balance. What ensued was a veritable Groundhog Day of two-factor authentication. Just hours of entering passwords and one-time passcodes, for the same banks half a dozen times over. Hopefully, you only have to do this once. What about Rocket Money? Rocket Money is another free financial app that tracks spending and supports things like balance alerts and account linking. If you pay for the premium tier, the service can also help you cancel unwanted subscriptions. We did not test it for this guide, but we'll consider it in future updates.This article originally appeared on Engadget at https://www.engadget.com/apps/the-best-budgeting-apps-to-replace-mint-143047346.html?src=rss",
          "content": "It's been over one year since Intuit shut down the popular budgeting app Mint. I was a Mint user for many years; millions of other users like me enjoyed how easily Mint allowed us to track all accounts in one place and monitor credit scores. I also used it regularly to help me track spending, set goals like pay my mortgage down faster and with general money management.Ahead of Mint’s demise, I gave Credit Karma, Intuit’s other financial app, a try but found it to be a poor Mint alternative. So I set out to find a true replacement in another budgeting app. The following guide lays out my experience testing some of the most popular Mint replacement apps available today. Our pick for best Mint alternative remains Quicken Simplifi, even this long after Mint being shut down, thanks to its easy to use app, good income and bill detection and its affordable price. But there are plenty of other solid options out there for those with different needs. If you’re also on the hunt for a budgeting app to replace Mint, we hope these details can empower you to choose which of the best budgeting apps out there will be right for you. Table of contents Best Mint alternatives in 2025 Other Mint alternatives we tested What is Plaid and how does it work? How to import your financial data from the Mint app How we tested Mint alternatives What about Rocket Money? Best Mint alternatives in 2025 No pun intended, but what I like about Quicken Simplifi is its simplicity. Whereas other budgeting apps try to distinguish themselves with dark themes and customizable emoji, Simplifi has a clean user interface, with a landing page that you just keep scrolling through to get a detailed overview of all your stats. These include your top-line balances; net worth; recent spending; upcoming recurring payments; a snapshot of your spending plan; top spending categories; achievements; and any watchlists you’ve set up. Another one of the key features I appreciate is the ability to set up savings goals elsewhere in the app. I also appreciate how it offers neat, almost playful visualizations without ever looking cluttered. I felt at home in the mobile and web dashboards after a day or so, which is faster than I adapted to some competing services (I’m looking at you, YNAB and Monarch). Getting set up with Simplifi was mostly painless. I was particularly impressed at how easily it connected to Fidelity; not all budget trackers do, for whatever reason. This is also one of the only services I tested that gives you the option of inviting a spouse or financial advisor to co-manage your account. One thing I would add to my initial assessment of the app, having used it for a few months now: I wish Simplifi offered Zillow integration for easily tracking your home value (or at least a rough estimate of it). Various competitors including Monarch Money and Copilot Money work with Zillow, so clearly there's a Zillow API available for use. As it stands, Simplifi users must add real estate manually like any other asset. Dana Wollman / Engadget In practice, Simplifi miscategorized some of my expenses, but nothing out of the ordinary compared to any of these budget trackers. As you’re reviewing transactions, you can also mark if you’re expecting a refund, which is a unique feature among the services I tested. Simplifi also estimated my regular income better than some other apps I tested. Most of all, I appreciated the option of being able to categorize some, but not all, purchases from a merchant as recurring. For instance, I can add my two Amazon subscribe-and-saves as recurring payments, without having to create a broad-strokes rule for every Amazon purchase. The budgeting feature is also self-explanatory and can likely accommodate your preferred budgeting method. Just check that your regular income is accurate and be sure to set up recurring payments, making note of which are bills and which are subscriptions. This is important because Simplifi shows you your total take-home income as well as an “income after bills” figure. That number includes, well, bills but not discretionary subscriptions. From there, you can add spending targets by category in the “planned spending” bucket. Planned spending can also include one-time expenditures, not just monthly budgets. When you create a budget, Simplifi will suggest a number based on a six-month average. Not dealbreakers, but two things to keep in mind as you get started: Simplifi is notable in that you can’t set up an account through Apple or Google. There is also no option for a free trial, though Quicken promises a “30-day money back guarantee.” Monarch Money grew on me. My first impression of the budgeting app, which was founded by a former Mint product manager, was that it's more difficult to use than others on this list, including Simplifi, NerdWallet and Copilot. And it is. Editing expense categories, adding recurring transactions and creating rules, for example, is a little more complicated than it needs to be, especially in the mobile app. (My advice: Use the web app for fine-tuning details.) Monarch also didn’t get my income right; I had to edit it. Once you’re set up, though, Monarch offers an impressive level of granularity. In the budgets section, you can see a bona fide balance sheet showing budgets and actuals for each category. You'll also find a forecast, for the year or by month. And recurring expenses can be set not just by merchant, but other parameters as well. For instance, while most Amazon purchases might be marked as “shopping,” those for the amounts of $54.18 or $34.18 are definitely baby supplies, and can be automatically marked as such each time, not to mention programmed as recurring payments. Weirdly, though, there’s no way to mark certain recurring payments as bills, specifically. Dana Wollman / Engadget Not long after I first published this story in December 2023, Monarch introduced a detailed reporting section where you can create on-demand graphs based on things like accounts, categories and tags. That feature is available just on the web version of the app for now. As part of this same update, Monarch added support for an aggregator that makes it possible to automatically update the value of your car. This, combined with the existing Zillow integration for tracking your home value, makes it easy to quickly add a non-liquid asset like a vehicle or real estate, and have it show up in your net worth graph. The mobile app is mostly self-explanatory. The main dashboard shows your net worth; your four most recent transactions; a month-over-month spending comparison; income month-to-date; upcoming bills; an investments snapshot; a list of any goals you’ve set; and, finally, a link to your month-in-review. That month-in-review is more detailed than most, delving into cash flow; top income and expense categories; cash flow trends; changes to your net worth, assets and liabilities; plus asset and liability breakdowns. In February 2024, Monarch expanded on the net worth graph, so that if you click on the Accounts tab you can see how your net worth changed over different periods of time, including one month, three months, six months, a year or all time. On the main screen, you’ll also find tabs for savings and checking accounts (and all others as well), transactions, cash flow, budget and recurring. Like many of the other apps featured here, Monarch can auto-detect recurring expenses and income, even if it gets the category wrong. (They all do to an extent.) Expense categories are marked by emoji, which you can customize if you’re so inclined. Monarch Money uses a combination of networks to connect with banks, including Plaid, MX and Finicity, a competing network owned by Mastercard. (I have a quick explainer on Plaid, the industry standard in this space, toward the end of this guide.) As part of an update in late December, Monarch has also made it easier to connect through those other two networks, if for some reason Plaid fails. Similar to NerdWallet, I found myself completing two-factor authentication every time I wanted to get past the Plaid screen to add another account. Notably, Monarch is the only other app I tested that allows you to grant access to someone else in your family — likely a spouse or financial advisor. Monarch also has a Chrome extension for importing from Mint, though really this is just a shortcut for downloading a CSV file, which you’ll have to do regardless of where you choose to take your Mint data. Additionally, Monarch just added the ability to track Apple Card, Apple Cash, and Savings accounts, thanks to new functionality brought with the iOS 17.4 update. It's not the only one either; currently, Copilot and YNAB have also added similar functionality that will be available to anyone with the latest versions of their respective apps on a device running iOS 17.4. Instead of manually uploading statements, the new functionality allows apps like Monarch's to automatically pull in transactions and balance history. That should make it easier to account for spending on Apple cards and accounts throughout the month. Monarch also recently launched investment transactions in beta. It also says bill tracking and an overhauled goals system are coming soon. Monarch hasn't provided a timeline for that last one, except to say that the improved goals feature is coming soon. Copilot Money might be the best-looking budgeting app I tested. It also has the distinction of being exclusive to iOS and Macs — at least for now. Andres Ugarte, the company’s CEO, has publicly promised that Android and web apps are coming soon. But until it follows through, I can’t recommend Copilot for most people with so many good competitors out there. Copilot Money for Web and Android!Thanks to the support from our users, and the overwhelming positive reception we're seeing from folks migrating from Mint, we can now say that we'll be building @copilotmoney for Web and Android with a goal to launch in 2024.We'll continue to…— Andres Ugarte (@chuga) November 15, 2023 There are other features that Copilot is missing, which I’ll get into. But it is promising, and one to keep an eye on. It’s just a fast, efficient, well designed app, and Android users will be in for a treat when they’ll finally be able to download it. It makes good use of colors, emoji and graphs to help you understand at a glance how you’re doing on everything from your budgets to your investment performance to your credit card debt over time. In particular, Copilot does a better job than almost any other app of visualizing your recurring monthly expenses. Behind those punchy colors and cutesy emoji, though, is some sophisticated performance. Copilot’s AI-powered “Intelligence” gets smarter as you go at categorizing your expenses. (You can also add your own categories, complete with your choice of emoji.) It’s not perfect. Copilot miscategorized some purchases (they all do), but it makes it easier to edit than most. On top of that, the internal search feature is very fast; it starts whittling down results in your transaction history as soon as you begin typing. Dana Wollman / Engadget Copilot is also unique in offering Amazon and Venmo integrations, allowing you to see transaction details. With Amazon, this requires just signing into your Amazon account via an in-app browser. For Venmo, you have to set up fwd@copilot.money as a forwarding address and then create a filter, wherein emails from venmo@venmo.com are automatically forwarded to fwd@copilot.money. Like Monarch Money, you can also add any property you own and track its value through Zillow, which is integrated with the app. While the app is heavily automated, I still appreciate that Copilot marks new transactions for review. It’s a good way to both weed out fraudulent charges, and also be somewhat intentional about your spending habits. Like Monarch Money, Copilot updated its app to make it easier to connect to banks through networks other than Plaid. As part of the same update, Copilot said it has improved its connections to both American Express and Fidelity which, again, can be a bugbear for some budget tracking apps. In an even more recent update, Copilot added a Mint import option, which other budgeting apps have begun to offer as well. Because the app is relatively new (it launched in early 2020), the company is still catching up to the competition on some table-stakes features. Ugarte told me that his team is almost done building out a detailed cash flow section as well. On its website, Copilot also promises a raft of AI-powered features that build on its current “Intelligence” platform, the one that powers its smart expense categorization. These include “smart financial goals,” natural language search, a chat interface, forecasting and benchmarking. That benchmarking, Ugarte tells me, is meant to give people a sense of how they’re doing compared to other Copilot users, on both spending and investment performance. Most of these features should arrive in the new year. Copilot does a couple interesting things for new customers that distinguish it from the competition. There’s a “demo mode” that feels like a game simulator; no need to add your own accounts. The company is also offering two free months with RIPMINT — a more generous introductory offer than most. When it finally does come time to pony up, the $7.92 monthly plan is cheaper than some competing apps, although the $95-a-year-option is in the same ballpark. You may know NerdWallet as a site that offers a mix of personal finance news, explainers and guides. I see it often when I google a financial term I don’t know and sure enough, it’s one of the sites I’m most likely to click on. As it happens, NerdWallet also has the distinction of offering one of the only free budgeting apps I tested. In fact, there is no paid version; nothing is locked behind a paywall. The main catch: There are ads everywhere. To be fair, the free version of Mint was like this, too. Even with the inescapable credit card offers, NerdWallet has a clean, easy-to-understand user interface, which includes both a web and a mobile app. The key metrics that it highlights most prominently are your cash flow, net worth and credit score. (Of note, although Mint itself offered credit score monitoring, most of its rivals do not.) I particularly enjoyed the weekly insights, which delve into things like where you spent the most money or how much you paid in fees — and how that compares to the previous month. Because this is NerdWallet, an encyclopedia of financial info, you get some particularly specific category options when setting up your accounts (think: a Roth or non-Roth IRA). Dana Wollman / Engadget As a budgeting app, NerdWallet is more than serviceable, if a bit basic. Like other apps I tested, you can set up recurring bills. Importantly, it follows the popular 50/30/20 budgeting rule, which has you putting 50% of your budget toward things you need, 30% toward things you want, and the remaining 20% into savings or debt repayments. If this works for you, great — just know that you can’t customize your budget to the same degree as some competing apps. You can’t currently create custom spending categories, though a note inside the dashboard section of the app says “you’ll be able to customize them in the future.” You also can’t move items from the wants column to “needs” or vice versa but “In the future, you'll be able to move specific transactions to actively manage what falls into each group.” A NerdWallet spokesperson declined to provide an ETA, though. Lastly, it’s worth noting that NerdWallet had one of the most onerous setup processes of any app I tested. I don’t think this is a dealbreaker, as you’ll only have to do it once and, hopefully, you aren’t setting up six or seven apps in tandem as I was. What made NerdWallet’s onboarding especially tedious is that every time I wanted to add an account, I had to go through a two-factor authentication process to even get past the Plaid splash screen, and that’s not including the 2FA I had set up at each of my banks. This is a security policy on NerdWallet’s end, not Plaid’s, a Plaid spokesperson says. Precisely because NerdWallet is one of the only budget trackers to offer credit score monitoring, it also needs more of your personal info during setup, including your birthday, address, phone number and the last four digits of your social security number. It’s the same with Credit Karma, which also does credit score monitoring. Related to the setup process, I found that NerdWallet was less adept than other apps at automatically detecting my regular income. In my case, it counted a large one-time wire transfer as income, at which point my only other option was to enter my income manually (which is slightly annoying because I would have needed my pay stub handy to double-check my take-home pay). YNAB is, by its own admission, “different from anything you’ve tried before.” The app, whose name is short for You Need a Budget, promotes a so-called zero-based budgeting system, which forces you to assign a purpose for every dollar you earn. A frequently used analogy is to put each dollar in an envelope; you can always move money from one envelope to another in a pinch. These envelopes can include rent and utilities, along with unforeseen expenses like holiday gifts and the inevitable car repair. The idea is that if you budget a certain amount for the unknowns each month, they won’t feel like they’re sneaking up on you. Importantly, YNAB is only concerned with the money you have in your accounts now. The app does not ask you to provide your take-home income or set up recurring income payments (although there is a way to do this). The money you will make later in the month through your salaried job is not relevant, because YNAB does not engage in forecasting. The app is harder to learn than any other here, and it requires more ongoing effort from the user. And YNAB knows that. Inside both the mobile and web apps are links to videos and other tutorials. Although I never quite got comfortable with the user interface, I did come to appreciate YNAB’s insistence on intentionality. Forcing users to draft a new budget each month and to review each transaction is not necessarily a bad thing. As YNAB says on its website, “Sure, you’ve got pie charts showing that you spent an obscene amount of money in restaurants — but you’ve still spent an obscene amount of money in restaurants.” I can see this approach being useful for people who don’t tend to have a lot of cash in reserve at a given time, or who have spending habits they want to correct (to riff off of YNAB’s own example, ordering Seamless four times a week). My colleague Valentina Palladino, knowing I was working on this guide, penned a respectful rebuttal, explaining why she’s been using YNAB for years. Perhaps, like her, you have major savings goals you want to achieve, whether it’s paying for a wedding or buying a house. I suggest you give her column a read. For me, though, YNAB’s approach feels like overkill. Other Mint alternatives we tested PocketGuard PocketGuard used to be a solid free budget tracker, but the company has since limited its “free” version to just a free seven-day trial. Now, you’ll have to choose between two plans once the trial is over: a $13 monthly plan or a $75 annual plan. When I first tested it, I found it to be more restricted than NerdWallet, but still a decent option. The main overview screen shows you your net worth, total assets and debts; net income and total spending for the month; upcoming bills; a handy reminder of when your next paycheck lands; any debt payoff plan you have; and any goals. Like some other apps, including Quicken Simplifi, PocketGuard promotes an “after bills” approach, where you enter all of your recurring bills, and then PocketGuard shows you what’s left, and that’s what you’re supposed to be budgeting: your disposable income. Although PocketGuard’s UI is easy enough to understand, it lacks polish. The “accounts” tab is a little busy, and doesn’t show totals for categories like cash or investments. Seemingly small details like weirdly phrased or punctuated copy occasionally make the app feel janky. More than once, it prompted me to update the app when no updates were available. The web version, meanwhile, feels like the mobile app blown up to a larger format and doesn’t take advantage of the extra screen real estate. Ultimately, now that the free tier is gone, it just doesn’t present the same value proposition as it once did. What is Plaid and how does it work? Each of the apps I tested uses the same underlying network, called Plaid, to pull in financial data, so it’s worth explaining in its own section what it is and how it works. Plaid was founded as a fintech startup in 2013 and is today the industry standard in connecting banks with third-party apps. Plaid works with over 12,000 financial institutions across the US, Canada and Europe. Additionally, more than 8,000 third-party apps and services rely on Plaid, the company claims. To be clear, you don’t need a dedicated Plaid app to use it; the technology is baked into a wide array of apps, including the budget trackers I tested for this guide. Once you find the “add an account” option in whichever one you’re using, you’ll see a menu of commonly used banks. There’s also a search field you can use to look yours up directly. Once you find yours, you’ll be prompted to enter your login credentials. If you have two-factor authentication set up, you’ll need to enter a one-time passcode as well. As the middleman, Plaid is a passthrough for information that may include your account balances, transaction history, account type and routing or account number. Plaid uses encryption, and says it has a policy of not selling or renting customer data to other companies. However, I would not be doing my job if I didn’t note that in 2022 Plaid was forced to pay $58 million to consumers in a class action suit for collecting “more financial data than was needed.” As part of the settlement, Plaid was compelled to change some of its business practices. In a statement provided to Engadget, a Plaid spokesperson said the company continues to deny the allegations underpinning the lawsuit and that “the crux of the non-financial terms in the settlement are focused on us accelerating workstreams already underway related to giving people more transparency into Plaid’s role in connecting their accounts, and ensuring that our workstreams around data minimization remain on track.” How to import your financial data from the Mint app Mint users should consider getting their data ready to migrate to their new budgeting app of choice soon. Unfortunately, importing data from Mint is not as easy as entering your credentials from inside your new app and hitting “import.” In fact, any app that advertises the ability to port over your stats from Mint is just going to have you upload a CSV file of transactions and other data. To download a CSV file from Mint, do the following: Sign into Mint.com and hit Transactions in the menu on the left side of the screen. Select an account, or all accounts. Scroll down and look for “export [number] transactions” in smaller print. Your CSV file should begin downloading. Note: Downloading on a per-account basis might seem more annoying, but could help you get set up on the other side, if the app you’re using has you importing transactions one-for-one into their corresponding accounts. How we tested Mint alternatives Before I dove into the world of budgeting apps, I had to do some research. To find a list of apps to test, I consulted trusty ol’ Google (and even trustier Reddit); read reviews of popular apps on the App Store; and also asked friends and colleagues what budget tracking apps they might be using. Some of the apps I found were free, just like Mint. These, of course, show loads of ads (excuse me, “offers”) to stay in business. But most of the available apps require paid subscriptions, with prices typically topping out around $100 a year, or $15 a month. (Spoiler: My top pick is cheaper than that.) Since this guide is meant to help Mint users find a permanent replacement, any services I chose to test needed to do several things: import all of your account data into one place; offer budgeting tools; and track your spending, net worth and credit score. Except where noted, all of these apps are available for iOS, Android and on the web. Once I had my shortlist of six apps, I got to work setting them up. For the sake of thoroughly testing these apps (and remember, I really was looking for a Mint alternative myself), I made a point of adding every account to every budgeting app, no matter how small or immaterial the balance. What ensued was a veritable Groundhog Day of two-factor authentication. Just hours of entering passwords and one-time passcodes, for the same banks half a dozen times over. Hopefully, you only have to do this once. What about Rocket Money? Rocket Money is another free financial app that tracks spending and supports things like balance alerts and account linking. If you pay for the premium tier, the service can also help you cancel unwanted subscriptions. We did not test it for this guide, but we'll consider it in future updates.This article originally appeared on Engadget at https://www.engadget.com/apps/the-best-budgeting-apps-to-replace-mint-143047346.html?src=rss",
          "feed_position": 21,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-12/9003a9c0-9dd8-11ee-8bf5-613f22f37439"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/design-in-the-age-of-ai-how-small-businesses-are-building-big-brands-faster",
          "published_at": "Mon, 08 Dec 2025 08:00:00 GMT",
          "title": "Design in the age of AI: How small businesses are building big brands faster",
          "standfirst": "Presented by Design.comFor most of history, design was the last step in starting a business — something entrepreneurs invested in once the idea was proven. Today, it’s one of the first. The rise of generative AI has shifted how small businesses imagine, launch, and grow — turning what used to be a months-long creative process into something interactive, iterative, and accessible from day one.Search data tells the story. Since 2022, global interest in “AI business name generator” has surged more than 700%. Searches for “AI logo generator” are up 1,200%, and “AI website generator” 1,600%. Small businesses aren’t waiting for enterprise AI trickle-down. They’re adopting these tools en masse to move faster from concept to brand identity.“The appetite for AI-powered design has been extraordinary,” says Alec Lynch, founder and CEO of Design.com. “Entrepreneurs are realizing they can bring their ideas to life immediately — they don’t have to wait for funding, agencies, or a full creative team. They can start now.”The democratization of design powerFor decades, small businesses were boxed out of high-end design. Building a brand required deep pockets and specialized talent. AI has redrawn that map.Large language models and image generators now act as collaborative partners — sparking ideas, testing directions, and handling tedious layout and copy work. For founders, that means fewer barriers and faster iteration.Instead of hiring separate agencies for naming, logo design, and web development, small businesses are turning to unified AI platforms that handle the full early-stage design stack. Tools like Design.com merge naming, logo creation, and website generation into a single workflow — turning an entrepreneur’s first sketch into a polished brand system within minutes.“AI isn’t replacing creativity,” Lynch adds. “It’s giving people the confidence to express it.”The five frontiers of AI-powered entrepreneurshipToday’s AI tools mirror the creative journey every founder takes — from naming a business to sharing it with the world. The five fastest-growing design categories on Google reflect each stage of that journey.1. Naming: From idea to identityAI naming tools do more than spit out clever words — they help founders discover their voice. A good generator blends tone, personality, and domain availability so the result feels like a fit, not a random suggestion.2. Logos: From visuals to meaningLogo creation is one of the most emotionally resonant steps in brand-building. AI has turned it into a playground for experimentation. Entrepreneurs can test dozens of looks and get instant feedback.3. Websites: From static pages to adaptive brandsThe surge in “AI website generator” searches signals a deeper shift. Websites are no longer static brochures; they’re dynamic brand environments. AI-driven builders now create layouts, headlines, and imagery that adapt to a company’s tone and focus — drastically reducing time to launch.4. Business cards and brand collateralEven in a digital age, tangible touchpoints matter. AI-generated business cards give founders an immediate sense of legitimacy while ensuring design consistency across brand assets.5. Presentations: From slides to storytellingFounders aren’t just designing assets; they’re designing narratives. Generative AI turns bullet points into persuasive visual stories — raising the quality of pitches, decks, and demos once out of reach for most small teams.Together, these five frontiers show that small businesses aren’t just using AI to look more polished — they’re using it to think more strategically about brand, story, and customer experience from the start.The new design ecosystemBehind the surge in AI design tools lies a broader ecosystem shift. Companies like Canva and Wix made design accessible; the current wave — led by AI-native platforms like Design.com — is more personal and adaptive.Unlike templated platforms, these tools understand context. A restaurant founder and a SaaS startup will get not just different visuals, but different copy tones, typography systems, and user flows — automatically.“What we’re seeing,” Lynch explains, “isn’t just growth in one product category. It’s a movement toward connected creativity — where every part of the brand experience learns from every other.”From AI tools to AI brand systemsThe next evolution of small-business design won’t be about single-purpose tools. It will be about connected systems that share data, context, and creative intent across every brand touchpoint.Imagine naming a company and watching an AI instantly generate a logo, color palette, and homepage layout that all reflect the same personality. As your audience grows, the same system helps you update your visual identity or tone to match new goals — while preserving your original DNA.That’s the future Design.com and others are building toward: intelligent brand ecosystems that evolve alongside their founders.“AI design tools are giving small businesses superpowers,” Lynch says. “They’re removing friction from creativity.”And that frictionless design process is quietly rewriting what entrepreneurship looks like. The ability to create, iterate, and launch in hours instead of months is changing the tempo of business itself — and redefining what it means to be a designer in the age of AI.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Design.comFor most of history, design was the last step in starting a business — something entrepreneurs invested in once the idea was proven. Today, it’s one of the first. The rise of generative AI has shifted how small businesses imagine, launch, and grow — turning what used to be a months-long creative process into something interactive, iterative, and accessible from day one.Search data tells the story. Since 2022, global interest in “AI business name generator” has surged more than 700%. Searches for “AI logo generator” are up 1,200%, and “AI website generator” 1,600%. Small businesses aren’t waiting for enterprise AI trickle-down. They’re adopting these tools en masse to move faster from concept to brand identity.“The appetite for AI-powered design has been extraordinary,” says Alec Lynch, founder and CEO of Design.com. “Entrepreneurs are realizing they can bring their ideas to life immediately — they don’t have to wait for funding, agencies, or a full creative team. They can start now.”The democratization of design powerFor decades, small businesses were boxed out of high-end design. Building a brand required deep pockets and specialized talent. AI has redrawn that map.Large language models and image generators now act as collaborative partners — sparking ideas, testing directions, and handling tedious layout and copy work. For founders, that means fewer barriers and faster iteration.Instead of hiring separate agencies for naming, logo design, and web development, small businesses are turning to unified AI platforms that handle the full early-stage design stack. Tools like Design.com merge naming, logo creation, and website generation into a single workflow — turning an entrepreneur’s first sketch into a polished brand system within minutes.“AI isn’t replacing creativity,” Lynch adds. “It’s giving people the confidence to express it.”The five frontiers of AI-powered entrepreneurshipToday’s AI tools mirror the creative journey every founder takes — from naming a business to sharing it with the world. The five fastest-growing design categories on Google reflect each stage of that journey.1. Naming: From idea to identityAI naming tools do more than spit out clever words — they help founders discover their voice. A good generator blends tone, personality, and domain availability so the result feels like a fit, not a random suggestion.2. Logos: From visuals to meaningLogo creation is one of the most emotionally resonant steps in brand-building. AI has turned it into a playground for experimentation. Entrepreneurs can test dozens of looks and get instant feedback.3. Websites: From static pages to adaptive brandsThe surge in “AI website generator” searches signals a deeper shift. Websites are no longer static brochures; they’re dynamic brand environments. AI-driven builders now create layouts, headlines, and imagery that adapt to a company’s tone and focus — drastically reducing time to launch.4. Business cards and brand collateralEven in a digital age, tangible touchpoints matter. AI-generated business cards give founders an immediate sense of legitimacy while ensuring design consistency across brand assets.5. Presentations: From slides to storytellingFounders aren’t just designing assets; they’re designing narratives. Generative AI turns bullet points into persuasive visual stories — raising the quality of pitches, decks, and demos once out of reach for most small teams.Together, these five frontiers show that small businesses aren’t just using AI to look more polished — they’re using it to think more strategically about brand, story, and customer experience from the start.The new design ecosystemBehind the surge in AI design tools lies a broader ecosystem shift. Companies like Canva and Wix made design accessible; the current wave — led by AI-native platforms like Design.com — is more personal and adaptive.Unlike templated platforms, these tools understand context. A restaurant founder and a SaaS startup will get not just different visuals, but different copy tones, typography systems, and user flows — automatically.“What we’re seeing,” Lynch explains, “isn’t just growth in one product category. It’s a movement toward connected creativity — where every part of the brand experience learns from every other.”From AI tools to AI brand systemsThe next evolution of small-business design won’t be about single-purpose tools. It will be about connected systems that share data, context, and creative intent across every brand touchpoint.Imagine naming a company and watching an AI instantly generate a logo, color palette, and homepage layout that all reflect the same personality. As your audience grows, the same system helps you update your visual identity or tone to match new goals — while preserving your original DNA.That’s the future Design.com and others are building toward: intelligent brand ecosystems that evolve alongside their founders.“AI design tools are giving small businesses superpowers,” Lynch says. “They’re removing friction from creativity.”And that frictionless design process is quietly rewriting what entrepreneurship looks like. The ability to create, iterate, and launch in hours instead of months is changing the tempo of business itself — and redefining what it means to be a designer in the age of AI.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5vOHZEQlNQsMRQBrdSXMLg/f701adc6486654954fb4b6b456792ccc/AdobeStock_1562823709.jpeg?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/c8LjxKPtjJumRUwmgig3W/3ceb88204d1ec334f3ce3719b80793eb/6Ud5A3f_99gyh14m2ffZr.jpg?w=300&q=30",
      "popularity_score": 2013.6793761111112
    },
    {
      "id": "cluster_21",
      "coverage": 2,
      "updated_at": "Mon, 08 Dec 2025 18:50:50 -0500",
      "title": "US lawmakers remove provisions in the National Defense Authorization Act for 2026 that would have ensured military members' right to repair their own equipment (Boone Ashworth/Wired)",
      "neutral_headline": "The Military Almost Got the Right to Repair. Lawmakers Just Took It Away",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251208/p43#a251208p43",
          "published_at": "Mon, 08 Dec 2025 18:50:50 -0500",
          "title": "US lawmakers remove provisions in the National Defense Authorization Act for 2026 that would have ensured military members' right to repair their own equipment (Boone Ashworth/Wired)",
          "standfirst": "Boone Ashworth / Wired: US lawmakers remove provisions in the National Defense Authorization Act for 2026 that would have ensured military members' right to repair their own equipment &mdash; The final language of the annual bill that funds the US military is in. It removes provisions that would have helped ensure &hellip;",
          "content": "Boone Ashworth / Wired: US lawmakers remove provisions in the National Defense Authorization Act for 2026 that would have ensured military members' right to repair their own equipment &mdash; The final language of the annual bill that funds the US military is in. It removes provisions that would have helped ensure &hellip;",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/251208/i43.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/the-military-almost-got-the-right-to-repair-lawmakers-just-took-it-away/",
          "published_at": "Mon, 08 Dec 2025 22:12:03 +0000",
          "title": "The Military Almost Got the Right to Repair. Lawmakers Just Took It Away",
          "standfirst": "The final language of the annual bill that funds the US military is in. It removes provisions that would have helped ensure service members’ ability to fix their own equipment.",
          "content": "The final language of the annual bill that funds the US military is in. It removes provisions that would have helped ensure service members’ ability to fix their own equipment.",
          "feed_position": 6,
          "image_url": "https://media.wired.com/photos/6937302b019e80e6895e02c4/master/pass/pol-military-righttorepair-957005644.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251208/i43.jpg",
      "popularity_score": 2012.4765983333334
    },
    {
      "id": "cluster_61",
      "coverage": 2,
      "updated_at": "Mon, 08 Dec 2025 18:10:00 GMT",
      "title": "ChatGPT saves the average worker nearly an hour each day, says OpenAI - here's how",
      "neutral_headline": "OpenAI boasts enterprise win days after internal ‘code red’ on Google threat",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/chatgpt-saving-time-work/",
          "published_at": "Mon, 08 Dec 2025 18:10:00 GMT",
          "title": "ChatGPT saves the average worker nearly an hour each day, says OpenAI - here's how",
          "standfirst": "The company is stepping up its efforts to attract enterprise customers amid growing competition from Google and Anthropic.",
          "content": "The company is stepping up its efforts to attract enterprise customers amid growing competition from Google and Anthropic.",
          "feed_position": 9
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/08/openai-boasts-enterprise-win-days-after-internal-code-red-on-google-threat/",
          "published_at": "Mon, 08 Dec 2025 12:00:00 +0000",
          "title": "OpenAI boasts enterprise win days after internal ‘code red’ on Google threat",
          "standfirst": "ChatGPT Enterprise usage grew 8x year-over-year as workers report saving an hour daily, but OpenAI faces competitive pressure from Anthropic and questions about cost sustainability.",
          "content": "ChatGPT Enterprise usage grew 8x year-over-year as workers report saving an hour daily, but OpenAI faces competitive pressure from Anthropic and questions about cost sustainability.",
          "feed_position": 19
        }
      ],
      "popularity_score": 2006.7960427777778
    },
    {
      "id": "cluster_32",
      "coverage": 1,
      "updated_at": "Mon, 08 Dec 2025 21:54:58 +0000",
      "title": "ICEBlock lawsuit: Trump admin bragged about demanding App Store removal",
      "neutral_headline": "ICEBlock lawsuit: Trump admin bragged about demanding App Store removal",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/iceblock-lawsuit-trump-admin-bragged-about-demanding-app-store-removal/",
          "published_at": "Mon, 08 Dec 2025 21:54:58 +0000",
          "title": "ICEBlock lawsuit: Trump admin bragged about demanding App Store removal",
          "standfirst": "ICEBlock creator sues to protect apps that are crowd-sourcing ICE sightings.",
          "content": "In a lawsuit filed against top Trump administration officials on Monday, Apple was accused of caving to unconstitutional government demands by removing an Immigration and Customs Enforcement-spotting app from the App Store with more than a million users. In his complaint, Joshua Aaron, creator of ICEBlock, cited a Fox News interview in which Attorney General Pam Bondi “made plain that the United States government used its regulatory power to coerce a private platform to suppress First Amendment-protected expression.” Suing Bondi—along with Department of Homeland Security Secretary Kristi Noem, Acting Director of ICE Todd Lyons, White House “Border Czar” Thomas D. Homan, and unnamed others—Aaron further alleged that US officials made false statements and “unlawful threats” to criminally investigate and prosecute him for developing ICEBlock.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2235825531-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2235825531-1024x648.jpg",
      "popularity_score": 343.5454872222222
    },
    {
      "id": "cluster_55",
      "coverage": 1,
      "updated_at": "Mon, 08 Dec 2025 18:36:16 +0000",
      "title": "Paramount tries to swipe Warner Bros. from Netflix with a hostile takeover",
      "neutral_headline": "Paramount tries to swipe Warner Bros. from Netflix with a hostile takeover",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/paramount-says-it-could-get-antitrust-approval-for-wbd-before-netflix/",
          "published_at": "Mon, 08 Dec 2025 18:36:16 +0000",
          "title": "Paramount tries to swipe Warner Bros. from Netflix with a hostile takeover",
          "standfirst": "Paramount has already proven it can get a controversial merger done.",
          "content": "Netflix won the bidding war for Warner Bros. Discovery’s (WBD’s) streaming and movie studio businesses last week. But Paramount Skydance isn’t relenting on its dreams of owning WBD and is pushing forward with a hostile takeover bid. On Friday, Netflix announced that it had agreed to pay an equity value of $72 billion, or an approximate total enterprise value of $82.7 billion, for WBD’s streaming and film businesses, as well as its film and TV libraries. The deal includes HBO and the HBO Max streaming service but not WBD’s cable channels, which are to be split off ahead of the acquisition into a separate company called Discovery Global. Netflix said WBD’s split should conclude in Q3 2026. Paramount has different plans, though.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2250240969-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2250240969-1024x648.jpg",
      "popularity_score": 330.23382055555555
    },
    {
      "id": "cluster_67",
      "coverage": 1,
      "updated_at": "Mon, 08 Dec 2025 17:01:37 +0000",
      "title": "F1 in Abu Dhabi: And that’s the championship",
      "neutral_headline": "F1 in Abu Dhabi: And that’s the championship",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/12/f1-in-abu-dhabi-and-thats-the-championship/",
          "published_at": "Mon, 08 Dec 2025 17:01:37 +0000",
          "title": "F1 in Abu Dhabi: And that’s the championship",
          "standfirst": "A three-way fight down to the wire as the ground effect era comes to a close.",
          "content": "The 2025 Formula 1 World Championship drew to a close this past weekend in Abu Dhabi, and with it came the end of the current generation of cars. After a grueling 24 races, the title was decided in a three-way fight by the finest of margins; just two points, less than half a percent, separated the winning driver from second place when the checkered flag waved on Sunday. Coming into Abu Dhabi, McLaren’s Lando Norris was, if not a comfortable favorite, then at least the driver with the highest odds of prevailing. After a strong start to the season, the British driver’s form dipped at the Dutch Grand Prix. But he bounced back, retaking the championship lead from his Australian teammate Oscar Piastri in Mexico in October. For much of the season, it seemed to be a two-car race. McLaren had a clear car advantage and two strong drivers, suggesting a repeat of the years we saw Lewis Hamilton and Nico Rosberg duking it out to bring home titles for Mercedes. But that didn’t figure on Red Bull developing its car late in the season. New boss Laurent Mekies has revitalized the energy drinks squad, and four-time champion Max Verstappen was able to close inexorably toward the McLaren drivers in the points with a string of sublime performances.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2250341495-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2250341495-1152x648.jpg",
      "popularity_score": 315.65632055555557
    },
    {
      "id": "cluster_77",
      "coverage": 1,
      "updated_at": "Mon, 08 Dec 2025 15:49:32 +0000",
      "title": "A big bike on a budget: Lectric’s XPress 750",
      "neutral_headline": "A big bike on a budget: Lectric’s XPress 750",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/12/lectric-xpress-750-a-full-sized-bike-for-the-budget-minded/",
          "published_at": "Mon, 08 Dec 2025 15:49:32 +0000",
          "title": "A big bike on a budget: Lectric’s XPress 750",
          "standfirst": "A budget e-bike that offers more than you might expect.",
          "content": "Almost every bit of bike testing I’ve done starts out the same way. After assembling the bike, I set the seatpost to its maximum recommended height, take it on a short test ride, and try to figure out new and creative phrasing to describe the same old problem: The frame isn’t quite big enough to accommodate my legs. While I’m on the tall side at a bit over 6 feet (~190 cm), I’m definitely not abnormally large. Yet very few e-bike manufacturers seem to be interested in giving people my height a comfortable ride. So imagine my surprise when, within two blocks of my first ride on the XPress 750, I had to pull off to the side of the street and lower the seat. This was especially notable given that the XPress is a budget bike (currently on sale for just under $1,000.00) that is only offered in a single frame size. So kudos to Lectric for giving me a comfortable and enjoyable ride, and doing so with a lot of features I wouldn’t expect at this price point. That said, hitting that price necessitated some significant compromises. We’ll discuss those in detail so you can get a sense of whether any of them will get in the way of your riding enjoyment.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/IMG_1802-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/IMG_1802-1152x648.jpeg",
      "popularity_score": 304.45493166666665
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Mon, 08 Dec 2025 14:57:11 +0000",
      "title": "Meta offers EU users ad-light option in push to end investigation",
      "neutral_headline": "Meta offers EU users ad-light option in push to end investigation",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2025/12/meta-offers-eu-users-ad-light-option-in-push-to-end-investigation/",
          "published_at": "Mon, 08 Dec 2025 14:57:11 +0000",
          "title": "Meta offers EU users ad-light option in push to end investigation",
          "standfirst": "Facebook agrees to change \"pay or consent\" model after talks with European Commission.",
          "content": "Meta has agreed to make changes to its “pay or consent” business model in the EU, seeking to agree to a deal that avoids further regulatory fines at a time when the bloc’s digital rule book is drawing anger from US authorities. On Tuesday, the European Commission announced that the social media giant had offered users an alternative choice of Facebook and Instagram services that would show them fewer personalized advertisements. The offer follows an EU investigation into Meta’s policy of requiring users either to consent to data tracking or pay for an ad-free service. The Financial Times reported on optimism that an agreement could be reached between the parties in October.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1359152239-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1359152239-1152x648.jpg",
      "popularity_score": 296.58243166666665
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Sun, 07 Dec 2025 12:08:58 +0000",
      "title": "Why is my dog like this? Current DNA tests won’t explain it to you.",
      "neutral_headline": "Why is my dog like this? Current DNA tests won’t explain it to you.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/why-is-my-dog-like-this-current-dna-tests-wont-explain-it-to-you/",
          "published_at": "Sun, 07 Dec 2025 12:08:58 +0000",
          "title": "Why is my dog like this? Current DNA tests won’t explain it to you.",
          "standfirst": "Dog behavior is a lot more complicated than any one gene variant.",
          "content": "Popular genetics tests can’t tell you much about your dog’s personality, according to a recent study. A team of geneticists recently found no connection between simple genetic variants and behavioral traits in more than 3,200 dogs, even though previous studies suggested that hundreds of genes might predict aspects of a dog’s behavior and personality. That’s despite the popularity of at-home genetic tests that claim they can tell you whether your dog’s genes contain the recipe for anxiety or a fondness for cuddles. This is Max, and no single genetic variant can explain why he is the way he is. Credit: Kiona Smith Gattaca for dogs, except it doesn’t work University of Massachusetts genomicist Kathryn Lord and her colleagues compared DNA sequences and behavioral surveys from more than 3,000 dogs whose humans had enrolled them in the Darwin’s Ark project (and filled out the surveys). “Genetic tests for behavioral and personality traits in dogs are now being marketed to pet owners, but their predictive accuracy has not been validated,” wrote Lord and her colleagues in their recent paper.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1498905251-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1498905251-1152x648.jpg",
      "popularity_score": 283
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Mon, 08 Dec 2025 14:03:30 +0000",
      "title": "The Boys gears up for a supe-ocalypse in S5 teaser",
      "neutral_headline": "The Boys gears up for a supe-ocalypse in S5 teaser",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/12/the-boys-gears-up-for-a-supe-ocalypse-in-s5-teaser/",
          "published_at": "Mon, 08 Dec 2025 14:03:30 +0000",
          "title": "The Boys gears up for a supe-ocalypse in S5 teaser",
          "standfirst": "\"So how about it, you lot? One last go?\"",
          "content": "Prime Video dropped an extended teaser for the fifth and final season of The Boys—based on the comic book series of the same name by Garth Ennis and Darick Robertson—during CCXP in Sao Paulo, Brazil. And it looks like we’re getting nothing less than a full-on Supe-ocalypse as an all-powerful Homelander seeks revenge on The Boys. (Spoilers for prior seasons of The Boys and S2 of Gen V below.) Things were not looking good for our antiheroes after the S4 finale. They managed to thwart the assassination of newly elected US President Robert Singer, but new Vought CEO/evil supe Sister Sage (Susan Heyward) essentially overthrew the election and installed Senator Steve Calhoun (David Andrews) as president. Calhoun declared martial law, and naturally, Homelander (Antony “Give Him an Emmy Already” Starr) swore loyalty as his chief enforcer. Butcher (Karl Urban) and Annie (Erin Moriarty) escaped, but the rest of The Boys were rounded up and placed in re-education—er, “Freedom”—camps.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/boys2-1152x648-1765118776.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/boys2-1152x648-1765118776.jpg",
      "popularity_score": 282.68770944444447
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Mon, 08 Dec 2025 12:00:14 +0000",
      "title": "Please send help. I can’t stop playing these roguelikes.",
      "neutral_headline": "Please send help. I can’t stop playing these roguelikes.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/12/please-send-help-i-cant-stop-playing-these-roguelikes/",
          "published_at": "Mon, 08 Dec 2025 12:00:14 +0000",
          "title": "Please send help. I can’t stop playing these roguelikes.",
          "standfirst": "2025 was a very good year for my favorite genre.",
          "content": "It’s time to admit, before God and the good readers of Ars Technica, that I have a problem. I love roguelikes. Reader, I can’t get enough of them. If there’s even a whisper of a hot new roguelike on Steam, I’m there. You may call them arcane, repetitive, or maddeningly difficult; I call them heaven. The second best part of video games is taking a puny little character and, over 100 hours, transforming that adventurer into a god of destruction. The best thing about video games is doing the same thing in under an hour. Beat a combat encounter, get an upgrade. Enter a new area, choose a new item. Put together a build and watch it sing. If you die—immediately ending your ascent and returning you to the beginning of the game—you’ll often make a pit stop at a home base to unlock new goodies to help you on your next run. (Some people distiguish between roguelikes and “roguelites,” with the latter including permanent, between-run upgrades. For simplicity’s sake, I’ll use “roguelike” as an umbrella term).Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/hades2_dec22_01-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/hades2_dec22_01-1152x648.jpg",
      "popularity_score": 273.633265
    }
  ]
}