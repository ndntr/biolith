{
  "updated_at": "2025-12-16T23:20:09.659Z",
  "clusters": [
    {
      "id": "cluster_41",
      "coverage": 2,
      "updated_at": "Tue, 16 Dec 2025 18:36:35 +0000",
      "title": "CES 2026 preview: What we're expecting from tech's biggest conference in January",
      "neutral_headline": "CES 2026 preview: What we're expecting from tech's biggest conference in January",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/ces-2026-preview-what-were-expecting-from-techs-biggest-conference-in-january-120000768.html",
          "published_at": "Tue, 16 Dec 2025 18:36:35 +0000",
          "title": "CES 2026 preview: What we're expecting from tech's biggest conference in January",
          "standfirst": "CES doesn't start until January, but whispers of the products and announcements that could be in store for tech's biggest annual conference have already started to take shape. The CES 2026 show floor is officially open from January 6 through 9, although the show kicks off with events on Sunday January 4 and a host of press conferences on Monday. As always, product demos, announcements and networking will be happening at the Las Vegas Convention Center and surrounding hotels all over the city. As usual, Engadget will be covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements should trickle out as CES approaches, but in the meantime, we do know what companies will be hosting press conferences and what tech trends could rear their heads at the show.What we already know aboutPress conferences and show floor booths are the bread and butter of CES. The Consumer Technology Association has already published a searchable directory of who will have a presence at the show, along with a schedule of every official panel and presentation.On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" That'll be followed by multiple press conferences throughout Monday, January 5. LG is hosting its \"Innovation in Tune with You\" presentation to share \"its vision for elevating daily life through Affectionate Intelligence\" at the start of the day, Intel is launching its new Core Ultra Series 3 processors in the afternoon, Sony Honda Mobility is holding a press conference on its first car and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day.On the week of December 15, the CTA added a keynote by NVIDIA CEO Jensen Huang to its schedule. The event will take place on January 5 at 1PM PT and, according to the website, will last about 90 minutes. Based on the description on the listing, the presentation will “showcase the latest NVIDIA solutions driving innovation and productivity across industries.”Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\" It’s worth noting that Lenovo is the parent company of Motorola, which still makes phones and foldables that feature AI tools, so it’s possible those devices feature in the presentation as well. Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensSony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots, bipedal or otherwise, competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!Update, December 11 2025, 11:03AM ET: This story has been updated to include detail on Lenovo being Motorola’s parent company and how the latter might have a part in the Tuesday presentation.Update, December 16 2025, 1:33PM ET: This story has been updated to include the NVIDIA press conference, which was added to the CTA schedule within the last two days.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-preview-what-were-expecting-from-techs-biggest-conference-in-january-120000768.html?src=rss",
          "content": "CES doesn't start until January, but whispers of the products and announcements that could be in store for tech's biggest annual conference have already started to take shape. The CES 2026 show floor is officially open from January 6 through 9, although the show kicks off with events on Sunday January 4 and a host of press conferences on Monday. As always, product demos, announcements and networking will be happening at the Las Vegas Convention Center and surrounding hotels all over the city. As usual, Engadget will be covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements should trickle out as CES approaches, but in the meantime, we do know what companies will be hosting press conferences and what tech trends could rear their heads at the show.What we already know aboutPress conferences and show floor booths are the bread and butter of CES. The Consumer Technology Association has already published a searchable directory of who will have a presence at the show, along with a schedule of every official panel and presentation.On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" That'll be followed by multiple press conferences throughout Monday, January 5. LG is hosting its \"Innovation in Tune with You\" presentation to share \"its vision for elevating daily life through Affectionate Intelligence\" at the start of the day, Intel is launching its new Core Ultra Series 3 processors in the afternoon, Sony Honda Mobility is holding a press conference on its first car and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day.On the week of December 15, the CTA added a keynote by NVIDIA CEO Jensen Huang to its schedule. The event will take place on January 5 at 1PM PT and, according to the website, will last about 90 minutes. Based on the description on the listing, the presentation will “showcase the latest NVIDIA solutions driving innovation and productivity across industries.”Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\" It’s worth noting that Lenovo is the parent company of Motorola, which still makes phones and foldables that feature AI tools, so it’s possible those devices feature in the presentation as well. Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensSony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots, bipedal or otherwise, competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!Update, December 11 2025, 11:03AM ET: This story has been updated to include detail on Lenovo being Motorola’s parent company and how the latter might have a part in the Tuesday presentation.Update, December 16 2025, 1:33PM ET: This story has been updated to include the NVIDIA press conference, which was added to the CTA schedule within the last two days.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-preview-what-were-expecting-from-techs-biggest-conference-in-january-120000768.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/what-happened-to-irobot-can-happen-to-anyone-164500625.html",
          "published_at": "Tue, 16 Dec 2025 16:45:00 +0000",
          "title": "What happened to iRobot can happen to anyone",
          "standfirst": "The company which popularized robot vacuum cleaners around the world has filed for Chapter 11 bankruptcy. iRobot, makers of the Roomba, has been synonymous with the category since its inception, but its star had dulled in recent years. The company plans to sell its assets to its primary supplier, China’s Picea Robotics, in the hope of maintaining its business.Everyone’s got a strident opinion as to why iRobot fell from grace. The rugged individualists blame limp regulators on both sides of the pond (and their hatred for big tech) for blocking Amazon’s attempted purchase in 2023. Those on the hardware side of the fence say iRobot’s refusal to embrace LiDAR for navigation until this year left it behind rivals.Then there’s the geopolitical experts, who can point at China’s industrial policy, subsidies and favorable regulatory environment compared to the US approach. After all, iRobot’s US gear is made in Vietnam, which is now subject to a 46 percent import levy. As BBC News reported, that added around $23 million to iRobot’s costs and increased the price of its hardware.The real answer is that iRobot’s demise was caused by a perfect storm of all these factors piling on to the company. More importantly, iRobot’s situation isn’t any way unique, and should serve as a warning to every major American technology brand. It’s also a lesson in why companies need to deal with existential threats when they have the time and cash to do so. For instance, once iRobot perfected the concept for the Roomba, it wasn’t long before the first copies burst onto the scene. iRobot had the brand and the know-how, but that only goes so far against well-motivated copycats. Think about the first Samsung Android handsets, and how quickly they went from iPhone imitations to class-defining devices of their own — and how hard Apple fought in court to prevent it.Even before this year’s tariffs, iRobot struggled to compete on price in a manner we’ve seen in other fields. Remember Fitbit before Google purchased it, happily selling $80 fitness trackers for years until Xiaomi swiped the low-end part of its business for itself. Even if the early MiBands weren’t very good, you could buy three for the price of a single Fitbit Charge. Yes, the argument around quality and reliability is important, but it’s often not as loud or compelling as a competing product sold for a fraction of the price.iRobot should have either made more of an effort to offer a dirt-cheap model to undercut its rivals, or more likely pull out of the low end altogether. Earlier today, I checked out local retail listings for Roombas and its nearest competitors. Next to one another were the Roomba 405 Combo with Dock and the Roborock Q7 L5+ — both capable of vacuuming and mopping your floor. The former is currently on sale for $400 direct from iRobot, while the latter is currently selling for $220. I’m sure plenty of buyers would have seen the price difference and opted for the cheaper model.I’m not going to throw too many Told You So’s over iRobot’s fence for not embracing LiDAR sooner. Its omission was a mistake, but you could see why it was shy about abandoning its existing setup. But the company had forgotten one key mantra about the tech world, Andy Grove’s maxim that “only the paranoid survive.” Even the fanciest, highest-end Roombas of the last five years felt a generation behind rival products.And, at the risk of sounding like a marketing guru, it was never clear what iRobot, or Roomba, stood for. When companies flooded the market with cheaper models, iRobot needed to make it clear what it meant when you bought a Roomba over a generic model. What did, and could, it offer beyond the name and history that made it stand out against cheaper competitors? Companies like Apple and Dyson command a premium, but you almost always know what you’re getting for your money.All I can say is that it’s good that there isn’t another American company presently in a similar position. I certainly can’t think of a controversial US company that builds things with wheels that has historically rejected LiDAR for its autonomous services. One that has a brand that doesn’t stand for much, or has its identity tied too closely to the identity of its CEO. One that is staring down the barrel at a raft of better equipped and often cheaper Chinese alternatives. Because that company could surely be looking at a similar fate a decade or so down the road.This article originally appeared on Engadget at https://www.engadget.com/home/what-happened-to-irobot-can-happen-to-anyone-164500625.html?src=rss",
          "content": "The company which popularized robot vacuum cleaners around the world has filed for Chapter 11 bankruptcy. iRobot, makers of the Roomba, has been synonymous with the category since its inception, but its star had dulled in recent years. The company plans to sell its assets to its primary supplier, China’s Picea Robotics, in the hope of maintaining its business.Everyone’s got a strident opinion as to why iRobot fell from grace. The rugged individualists blame limp regulators on both sides of the pond (and their hatred for big tech) for blocking Amazon’s attempted purchase in 2023. Those on the hardware side of the fence say iRobot’s refusal to embrace LiDAR for navigation until this year left it behind rivals.Then there’s the geopolitical experts, who can point at China’s industrial policy, subsidies and favorable regulatory environment compared to the US approach. After all, iRobot’s US gear is made in Vietnam, which is now subject to a 46 percent import levy. As BBC News reported, that added around $23 million to iRobot’s costs and increased the price of its hardware.The real answer is that iRobot’s demise was caused by a perfect storm of all these factors piling on to the company. More importantly, iRobot’s situation isn’t any way unique, and should serve as a warning to every major American technology brand. It’s also a lesson in why companies need to deal with existential threats when they have the time and cash to do so. For instance, once iRobot perfected the concept for the Roomba, it wasn’t long before the first copies burst onto the scene. iRobot had the brand and the know-how, but that only goes so far against well-motivated copycats. Think about the first Samsung Android handsets, and how quickly they went from iPhone imitations to class-defining devices of their own — and how hard Apple fought in court to prevent it.Even before this year’s tariffs, iRobot struggled to compete on price in a manner we’ve seen in other fields. Remember Fitbit before Google purchased it, happily selling $80 fitness trackers for years until Xiaomi swiped the low-end part of its business for itself. Even if the early MiBands weren’t very good, you could buy three for the price of a single Fitbit Charge. Yes, the argument around quality and reliability is important, but it’s often not as loud or compelling as a competing product sold for a fraction of the price.iRobot should have either made more of an effort to offer a dirt-cheap model to undercut its rivals, or more likely pull out of the low end altogether. Earlier today, I checked out local retail listings for Roombas and its nearest competitors. Next to one another were the Roomba 405 Combo with Dock and the Roborock Q7 L5+ — both capable of vacuuming and mopping your floor. The former is currently on sale for $400 direct from iRobot, while the latter is currently selling for $220. I’m sure plenty of buyers would have seen the price difference and opted for the cheaper model.I’m not going to throw too many Told You So’s over iRobot’s fence for not embracing LiDAR sooner. Its omission was a mistake, but you could see why it was shy about abandoning its existing setup. But the company had forgotten one key mantra about the tech world, Andy Grove’s maxim that “only the paranoid survive.” Even the fanciest, highest-end Roombas of the last five years felt a generation behind rival products.And, at the risk of sounding like a marketing guru, it was never clear what iRobot, or Roomba, stood for. When companies flooded the market with cheaper models, iRobot needed to make it clear what it meant when you bought a Roomba over a generic model. What did, and could, it offer beyond the name and history that made it stand out against cheaper competitors? Companies like Apple and Dyson command a premium, but you almost always know what you’re getting for your money.All I can say is that it’s good that there isn’t another American company presently in a similar position. I certainly can’t think of a controversial US company that builds things with wheels that has historically rejected LiDAR for its autonomous services. One that has a brand that doesn’t stand for much, or has its identity tied too closely to the identity of its CEO. One that is staring down the barrel at a raft of better equipped and often cheaper Chinese alternatives. Because that company could surely be looking at a similar fate a decade or so down the road.This article originally appeared on Engadget at https://www.engadget.com/home/what-happened-to-irobot-can-happen-to-anyone-164500625.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/zoom-says-it-aced-ais-hardest-exam-critics-say-it-copied-off-its-neighbors",
          "published_at": "Tue, 16 Dec 2025 14:00:00 GMT",
          "title": "Zoom says it aced AI’s hardest exam. Critics say it copied off its neighbors.",
          "standfirst": "Zoom Video Communications, the company best known for keeping remote workers connected during the pandemic, announced last week that it had achieved the highest score ever recorded on one of artificial intelligence&#x27;s most demanding tests — a claim that sent ripples of surprise, skepticism, and genuine curiosity through the technology industry.The San Jose-based company said its AI system scored 48.1 percent on the Humanity&#x27;s Last Exam, a benchmark designed by subject-matter experts worldwide to stump even the most advanced AI models. That result edges out Google&#x27;s Gemini 3 Pro, which held the previous record at 45.8 percent.\"Zoom has achieved a new state-of-the-art result on the challenging Humanity&#x27;s Last Exam full-set benchmark, scoring 48.1%, which represents a substantial 2.3% improvement over the previous SOTA result,\" wrote Xuedong Huang, Zoom&#x27;s chief technology officer, in a blog post.The announcement raises a provocative question that has consumed AI watchers for days: How did a video conferencing company — one with no public history of training large language models — suddenly vault past Google, OpenAI, and Anthropic on a benchmark built to measure the frontiers of machine intelligence?The answer reveals as much about where AI is headed as it does about Zoom&#x27;s own technical ambitions. And depending on whom you ask, it&#x27;s either an ingenious demonstration of practical engineering or a hollow claim that appropriates credit for others&#x27; work.How Zoom built an AI traffic controller instead of training its own modelZoom did not train its own large language model. Instead, the company developed what it calls a \"federated AI approach\" — a system that routes queries to multiple existing models from OpenAI, Google, and Anthropic, then uses proprietary software to select, combine, and refine their outputs.At the heart of this system sits what Zoom calls its \"Z-scorer,\" a mechanism that evaluates responses from different models and chooses the best one for any given task. The company pairs this with what it describes as an \"explore-verify-federate strategy,\" an agentic workflow that balances exploratory reasoning with verification across multiple AI systems.\"Our federated approach combines Zoom&#x27;s own small language models with advanced open-source and closed-source models,\" Huang wrote. The framework \"orchestrates diverse models to generate, challenge, and refine reasoning through dialectical collaboration.\"In simpler terms: Zoom built a sophisticated traffic controller for AI, not the AI itself.This distinction matters enormously in an industry where bragging rights — and billions in valuation — often hinge on who can claim the most capable model. The major AI laboratories spend hundreds of millions of dollars training frontier systems on vast computing clusters. Zoom&#x27;s achievement, by contrast, appears to rest on clever integration of those existing systems.Why AI researchers are divided over what counts as real innovationThe response from the AI community was swift and sharply divided.Max Rumpf, an AI engineer who says he has trained state-of-the-art language models, posted a pointed critique on social media. \"Zoom strung together API calls to Gemini, GPT, Claude et al. and slightly improved on a benchmark that delivers no value for their customers,\" he wrote. \"They then claim SOTA.\"Rumpf did not dismiss the technical approach itself. Using multiple models for different tasks, he noted, is \"actually quite smart and most applications should do this.\" He pointed to Sierra, an AI customer service company, as an example of this multi-model strategy executed effectively.His objection was more specific: \"They did not train the model, but obfuscate this fact in the tweet. The injustice of taking credit for the work of others sits deeply with people.\"But other observers saw the achievement differently. Hongcheng Zhu, a developer, offered a more measured assessment: \"To top an AI eval, you will most likely need model federation, like what Zoom did. An analogy is that every Kaggle competitor knows you have to ensemble models to win a contest.\"The comparison to Kaggle — the competitive data science platform where combining multiple models is standard practice among winning teams — reframes Zoom&#x27;s approach as industry best practice rather than sleight of hand. Academic research has long established that ensemble methods routinely outperform individual models.Still, the debate exposed a fault line in how the industry understands progress. Ryan Pream, founder of Exoria AI, was dismissive: \"Zoom are just creating a harness around another LLM and reporting that. It is just noise.\" Another commenter captured the sheer unexpectedness of the news: \"That the video conferencing app ZOOM developed a SOTA model that achieved 48% HLE was not on my bingo card.\"Perhaps the most pointed critique concerned priorities. Rumpf argued that Zoom could have directed its resources toward problems its customers actually face. \"Retrieval over call transcripts is not &#x27;solved&#x27; by SOTA LLMs,\" he wrote. \"I figure Zoom&#x27;s users would care about this much more than HLE.\"The Microsoft veteran betting his reputation on a different kind of AIIf Zoom&#x27;s benchmark result seemed to come from nowhere, its chief technology officer did not.Xuedong Huang joined Zoom from Microsoft, where he spent decades building the company&#x27;s AI capabilities. He founded Microsoft&#x27;s speech technology group in 1993 and led teams that achieved what the company described as human parity in speech recognition, machine translation, natural language understanding, and computer vision.Huang holds a Ph.D. in electrical engineering from the University of Edinburgh. He is an elected member of the National Academy of Engineering and the American Academy of Arts and Sciences, as well as a fellow of both the IEEE and the ACM. His credentials place him among the most accomplished AI executives in the industry.His presence at Zoom signals that the company&#x27;s AI ambitions are serious, even if its methods differ from the research laboratories that dominate headlines. In his tweet celebrating the benchmark result, Huang framed the achievement as validation of Zoom&#x27;s strategy: \"We have unlocked stronger capabilities in exploration, reasoning, and multi-model collaboration, surpassing the performance limits of any single model.\"That final clause — \"surpassing the performance limits of any single model\" — may be the most significant. Huang is not claiming Zoom built a better model. He is claiming Zoom built a better system for using models.Inside the test designed to stump the world&#x27;s smartest machinesThe benchmark at the center of this controversy, Humanity&#x27;s Last Exam, was designed to be exceptionally difficult. Unlike earlier tests that AI systems learned to game through pattern matching, HLE presents problems that require genuine understanding, multi-step reasoning, and the synthesis of information across complex domains.The exam draws on questions from experts around the world, spanning fields from advanced mathematics to philosophy to specialized scientific knowledge. A score of 48.1 percent might sound unimpressive to anyone accustomed to school grading curves, but in the context of HLE, it represents the current ceiling of machine performance.\"This benchmark was developed by subject-matter experts globally and has become a crucial metric for measuring AI&#x27;s progress toward human-level performance on challenging intellectual tasks,\" Zoom’s announcement noted.The company&#x27;s improvement of 2.3 percentage points over Google&#x27;s previous best may appear modest in isolation. But in competitive benchmarking, where gains often come in fractions of a percent, such a jump commands attention.What Zoom&#x27;s approach reveals about the future of enterprise AIZoom&#x27;s approach carries implications that extend well beyond benchmark leaderboards. The company is signaling a vision for enterprise AI that differs fundamentally from the model-centric strategies pursued by OpenAI, Anthropic, and Google.Rather than betting everything on building the single most capable model, Zoom is positioning itself as an orchestration layer — a company that can integrate the best capabilities from multiple providers and deliver them through products that businesses already use every day.This strategy hedges against a critical uncertainty in the AI market: no one knows which model will be best next month, let alone next year. By building infrastructure that can swap between providers, Zoom avoids vendor lock-in while theoretically offering customers the best available AI for any given task.The announcement of OpenAI&#x27;s GPT-5.2 the following day underscored this dynamic. OpenAI&#x27;s own communications named Zoom as a partner that had evaluated the new model&#x27;s performance \"across their AI workloads and saw measurable gains across the board.\" Zoom, in other words, is both a customer of the frontier labs and now a competitor on their benchmarks — using their own technology.This arrangement may prove sustainable. The major model providers have every incentive to sell API access widely, even to companies that might aggregate their outputs. The more interesting question is whether Zoom&#x27;s orchestration capabilities constitute genuine intellectual property or merely sophisticated prompt engineering that others could replicate.The real test arrives when Zoom&#x27;s 300 million users start asking questionsZoom titled its announcement section on industry relations \"A Collaborative Future,\" and Huang struck notes of gratitude throughout. \"The future of AI is collaborative, not competitive,\" he wrote. \"By combining the best innovations from across the industry with our own research breakthroughs, we create solutions that are greater than the sum of their parts.\"This framing positions Zoom as a beneficent integrator, bringing together the industry&#x27;s best work for the benefit of enterprise customers. Critics see something else: a company claiming the prestige of an AI laboratory without doing the foundational research that earns it.The debate will likely be settled not by leaderboards but by products. When AI Companion 3.0 reaches Zoom&#x27;s hundreds of millions of users in the coming months, they will render their own verdict — not on benchmarks they have never heard of, but on whether the meeting summary actually captured what mattered, whether the action items made sense, whether the AI saved them time or wasted it.In the end, Zoom&#x27;s most provocative claim may not be that it topped a benchmark. It may be the implicit argument that in the age of AI, the best model is not the one you build — it&#x27;s the one you know how to use.",
          "content": "Zoom Video Communications, the company best known for keeping remote workers connected during the pandemic, announced last week that it had achieved the highest score ever recorded on one of artificial intelligence&#x27;s most demanding tests — a claim that sent ripples of surprise, skepticism, and genuine curiosity through the technology industry.The San Jose-based company said its AI system scored 48.1 percent on the Humanity&#x27;s Last Exam, a benchmark designed by subject-matter experts worldwide to stump even the most advanced AI models. That result edges out Google&#x27;s Gemini 3 Pro, which held the previous record at 45.8 percent.\"Zoom has achieved a new state-of-the-art result on the challenging Humanity&#x27;s Last Exam full-set benchmark, scoring 48.1%, which represents a substantial 2.3% improvement over the previous SOTA result,\" wrote Xuedong Huang, Zoom&#x27;s chief technology officer, in a blog post.The announcement raises a provocative question that has consumed AI watchers for days: How did a video conferencing company — one with no public history of training large language models — suddenly vault past Google, OpenAI, and Anthropic on a benchmark built to measure the frontiers of machine intelligence?The answer reveals as much about where AI is headed as it does about Zoom&#x27;s own technical ambitions. And depending on whom you ask, it&#x27;s either an ingenious demonstration of practical engineering or a hollow claim that appropriates credit for others&#x27; work.How Zoom built an AI traffic controller instead of training its own modelZoom did not train its own large language model. Instead, the company developed what it calls a \"federated AI approach\" — a system that routes queries to multiple existing models from OpenAI, Google, and Anthropic, then uses proprietary software to select, combine, and refine their outputs.At the heart of this system sits what Zoom calls its \"Z-scorer,\" a mechanism that evaluates responses from different models and chooses the best one for any given task. The company pairs this with what it describes as an \"explore-verify-federate strategy,\" an agentic workflow that balances exploratory reasoning with verification across multiple AI systems.\"Our federated approach combines Zoom&#x27;s own small language models with advanced open-source and closed-source models,\" Huang wrote. The framework \"orchestrates diverse models to generate, challenge, and refine reasoning through dialectical collaboration.\"In simpler terms: Zoom built a sophisticated traffic controller for AI, not the AI itself.This distinction matters enormously in an industry where bragging rights — and billions in valuation — often hinge on who can claim the most capable model. The major AI laboratories spend hundreds of millions of dollars training frontier systems on vast computing clusters. Zoom&#x27;s achievement, by contrast, appears to rest on clever integration of those existing systems.Why AI researchers are divided over what counts as real innovationThe response from the AI community was swift and sharply divided.Max Rumpf, an AI engineer who says he has trained state-of-the-art language models, posted a pointed critique on social media. \"Zoom strung together API calls to Gemini, GPT, Claude et al. and slightly improved on a benchmark that delivers no value for their customers,\" he wrote. \"They then claim SOTA.\"Rumpf did not dismiss the technical approach itself. Using multiple models for different tasks, he noted, is \"actually quite smart and most applications should do this.\" He pointed to Sierra, an AI customer service company, as an example of this multi-model strategy executed effectively.His objection was more specific: \"They did not train the model, but obfuscate this fact in the tweet. The injustice of taking credit for the work of others sits deeply with people.\"But other observers saw the achievement differently. Hongcheng Zhu, a developer, offered a more measured assessment: \"To top an AI eval, you will most likely need model federation, like what Zoom did. An analogy is that every Kaggle competitor knows you have to ensemble models to win a contest.\"The comparison to Kaggle — the competitive data science platform where combining multiple models is standard practice among winning teams — reframes Zoom&#x27;s approach as industry best practice rather than sleight of hand. Academic research has long established that ensemble methods routinely outperform individual models.Still, the debate exposed a fault line in how the industry understands progress. Ryan Pream, founder of Exoria AI, was dismissive: \"Zoom are just creating a harness around another LLM and reporting that. It is just noise.\" Another commenter captured the sheer unexpectedness of the news: \"That the video conferencing app ZOOM developed a SOTA model that achieved 48% HLE was not on my bingo card.\"Perhaps the most pointed critique concerned priorities. Rumpf argued that Zoom could have directed its resources toward problems its customers actually face. \"Retrieval over call transcripts is not &#x27;solved&#x27; by SOTA LLMs,\" he wrote. \"I figure Zoom&#x27;s users would care about this much more than HLE.\"The Microsoft veteran betting his reputation on a different kind of AIIf Zoom&#x27;s benchmark result seemed to come from nowhere, its chief technology officer did not.Xuedong Huang joined Zoom from Microsoft, where he spent decades building the company&#x27;s AI capabilities. He founded Microsoft&#x27;s speech technology group in 1993 and led teams that achieved what the company described as human parity in speech recognition, machine translation, natural language understanding, and computer vision.Huang holds a Ph.D. in electrical engineering from the University of Edinburgh. He is an elected member of the National Academy of Engineering and the American Academy of Arts and Sciences, as well as a fellow of both the IEEE and the ACM. His credentials place him among the most accomplished AI executives in the industry.His presence at Zoom signals that the company&#x27;s AI ambitions are serious, even if its methods differ from the research laboratories that dominate headlines. In his tweet celebrating the benchmark result, Huang framed the achievement as validation of Zoom&#x27;s strategy: \"We have unlocked stronger capabilities in exploration, reasoning, and multi-model collaboration, surpassing the performance limits of any single model.\"That final clause — \"surpassing the performance limits of any single model\" — may be the most significant. Huang is not claiming Zoom built a better model. He is claiming Zoom built a better system for using models.Inside the test designed to stump the world&#x27;s smartest machinesThe benchmark at the center of this controversy, Humanity&#x27;s Last Exam, was designed to be exceptionally difficult. Unlike earlier tests that AI systems learned to game through pattern matching, HLE presents problems that require genuine understanding, multi-step reasoning, and the synthesis of information across complex domains.The exam draws on questions from experts around the world, spanning fields from advanced mathematics to philosophy to specialized scientific knowledge. A score of 48.1 percent might sound unimpressive to anyone accustomed to school grading curves, but in the context of HLE, it represents the current ceiling of machine performance.\"This benchmark was developed by subject-matter experts globally and has become a crucial metric for measuring AI&#x27;s progress toward human-level performance on challenging intellectual tasks,\" Zoom’s announcement noted.The company&#x27;s improvement of 2.3 percentage points over Google&#x27;s previous best may appear modest in isolation. But in competitive benchmarking, where gains often come in fractions of a percent, such a jump commands attention.What Zoom&#x27;s approach reveals about the future of enterprise AIZoom&#x27;s approach carries implications that extend well beyond benchmark leaderboards. The company is signaling a vision for enterprise AI that differs fundamentally from the model-centric strategies pursued by OpenAI, Anthropic, and Google.Rather than betting everything on building the single most capable model, Zoom is positioning itself as an orchestration layer — a company that can integrate the best capabilities from multiple providers and deliver them through products that businesses already use every day.This strategy hedges against a critical uncertainty in the AI market: no one knows which model will be best next month, let alone next year. By building infrastructure that can swap between providers, Zoom avoids vendor lock-in while theoretically offering customers the best available AI for any given task.The announcement of OpenAI&#x27;s GPT-5.2 the following day underscored this dynamic. OpenAI&#x27;s own communications named Zoom as a partner that had evaluated the new model&#x27;s performance \"across their AI workloads and saw measurable gains across the board.\" Zoom, in other words, is both a customer of the frontier labs and now a competitor on their benchmarks — using their own technology.This arrangement may prove sustainable. The major model providers have every incentive to sell API access widely, even to companies that might aggregate their outputs. The more interesting question is whether Zoom&#x27;s orchestration capabilities constitute genuine intellectual property or merely sophisticated prompt engineering that others could replicate.The real test arrives when Zoom&#x27;s 300 million users start asking questionsZoom titled its announcement section on industry relations \"A Collaborative Future,\" and Huang struck notes of gratitude throughout. \"The future of AI is collaborative, not competitive,\" he wrote. \"By combining the best innovations from across the industry with our own research breakthroughs, we create solutions that are greater than the sum of their parts.\"This framing positions Zoom as a beneficent integrator, bringing together the industry&#x27;s best work for the benefit of enterprise customers. Critics see something else: a company claiming the prestige of an AI laboratory without doing the foundational research that earns it.The debate will likely be settled not by leaderboards but by products. When AI Companion 3.0 reaches Zoom&#x27;s hundreds of millions of users in the coming months, they will render their own verdict — not on benchmarks they have never heard of, but on whether the meeting summary actually captured what mattered, whether the action items made sense, whether the AI saved them time or wasted it.In the end, Zoom&#x27;s most provocative claim may not be that it topped a benchmark. It may be the implicit argument that in the age of AI, the best model is not the one you build — it&#x27;s the one you know how to use.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5oDy4S77FSU28G1miSj9Ha/cda550cda52e6f8a81d2837d77efe6ff/nuneybits_Vector_art_of_a_video_conference_in_Zoom_blue_b4fb4be6-243a-4462-8913-626538caf7f6.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/echo-raises-usd35m-to-secure-the-enterprise-clouds-base-layer-container",
          "published_at": "Tue, 16 Dec 2025 14:00:00 GMT",
          "title": "Echo raises $35M to secure the enterprise cloud's base layer — container images — with autonomous AI agents",
          "standfirst": "As enterprises accelerate the deployment of LLMs and agentic workflows, they are hitting a critical infrastructure bottleneck: the container base images powering these applications are riddled with inherited security debt. Echo, an Israeli startup, is announcing a $35 million in Series A funding today (bringing its to-date total to $50 million in funding) to fix this by fundamentally reimagining how cloud infrastructure is built.The round was led by N47, with participation from Notable Capital, Hyperwise Ventures, and SentinelOne. But the real story isn&#x27;t the capital—it&#x27;s the company’s ambitious goal to replace the chaotic open-source supply chain with a managed, \"secure-by-design\" operating system.The Hidden Operating System of the CloudTo understand why Echo matters, you first have to understand the invisible foundation of the modern internet: container base images.Think of a \"container\" like a shipping box for software. It holds the application code (what the developers write) and everything that code needs to run (the \"base image\"). For a non-technical audience, the best way to understand a base image is to compare it to a brand-new laptop. When you buy a computer, it comes with an Operating System (OS) like Windows or macOS pre-installed to handle the basics—talking to the hard drive, connecting to Wi-Fi, and running programs. Without it, the computer is useless.In the cloud, the base image is that Operating System. Whether a company like Netflix or Uber is building a simple web app or a complex network of autonomous AI agents, they rely on these pre-built layers (like Alpine, Python, or Node.js) to define the underlying runtimes and dependencies.Here is where the risk begins. Unlike Windows or macOS, which are maintained by tech giants, most base images are open-source and created by communities of volunteers. Because they are designed to be useful to everyone, they are often packed with \"bloat\"—hundreds of extra tools and settings that most companies don&#x27;t actually need.Eylam Milner, Echo’s CTO, uses a stark analogy to explain why this is dangerous: \"Taking software just from the open source world, it&#x27;s like taking a computer found on the sidewalk and plugging it into your [network].\"Traditionally, companies try to fix this by downloading the image, scanning it for bugs, and attempting to \"patch\" the holes. But it is a losing battle. Echo’s research indicates that official Docker images often contain over 1,000 known vulnerabilities (CVEs) the moment they are downloaded. For enterprise security teams, this creates an impossible game of \"whac-a-mole,\" inheriting infrastructure debt before their engineers write a single line of code.The \"Enterprise Linux\" Moment for AIFor Eilon Elhadad, Echo’s co-founder and CEO, the industry is repeating history. \"Exactly what&#x27;s happened in the past... everybody run with Linux, and then they move to Enterprise Linux,\" Elhadad told VentureBeat. Just as Red Hat professionalized open-source Linux for the corporate world, Echo aims to be the \"enterprise AI native OS\"—a hardened, curated foundation for the AI era.\"We see ourselves in the AI native era, the foundation of everything,\" says Elhadad.The Tech: A \"Software Compilation Factory\"Echo is not a scanning tool. It does not look for vulnerabilities after the fact. Instead, it operates as a \"software compilation factory\" that rebuilds images from scratch.According to Milner, Echo’s approach to eliminating vulnerabilities relies on a rigorous, two-step engineering process for every workload:Compilation from Source: Echo starts with an empty canvas. It does not patch existing bloated images; it compiles binaries and libraries directly from source code. This ensures that only essential components are included, drastically reducing the attack surface.Hardening & Provenance (SLSA Level 3): The resulting images are hardened with aggressive security configurations to make exploitation difficult. Crucially, the build pipeline adheres to SLSA Level 3 standards (Supply-chain Levels for Software Artifacts), ensuring that every artifact is signed, tested, and verifiable.The result is a \"drop-in replacement.\" A developer simply changes one line in their Dockerfile to point to Echo’s registry. The application runs identically, but the underlying OS layer is mathematically cleaner and free of known CVEs.AI Defending Against AIThe need for this level of hygiene is being driven by the \"AI vs. AI\" security arms race. Bad actors are increasingly using AI to compress exploit windows from weeks down to days. Simultaneously, \"coding agents\"—AI tools that autonomously write software—are becoming the number one generators of code, often statistically selecting outdated or vulnerable libraries from open source.To counter this, Echo has built a proprietary infrastructure of AI agents that autonomously manage vulnerability research.Continuous Monitoring: Echo’s agents monitor the 4,000+ new CVEs added to the National Vulnerability Database (NVD) monthly.Unstructured Research: Beyond official databases, these agents scour unstructured sources like GitHub comments and developer forums to identify patches before they are widely published.Self-Healing: When a vulnerability is confirmed, the agents identify affected images, apply the fix, run compatibility tests, and generate a pull request for human review.This automation allows Echo’s engineering team to maintain over 600 secure images—a scale that would traditionally require hundreds of security researchers.Why It Matters to the CISOFor technical decision-makers, Echo represents a shift from \"mean time to remediation\" to \"zero vulnerabilities by default.\"Dan Garcia, CISO of EDB, noted in a press release that the platform \"saves at least 235 developer hours per release\" by eliminating the need for engineers to investigate false positives or patch base images manually.Echo is already securing production workloads for major enterprises like UiPath, EDB, and Varonis. As enterprises move from containers to agentic workflows, the ability to trust the underlying infrastructure—without managing it—may be the defining characteristic of the next generation of DevSecOps.Pricing for Echo&#x27;s solution is not publicly listed, but the company says on its website it prices \"based on image consumption, to ensure it scales with how you actually build and ship software.\"",
          "content": "As enterprises accelerate the deployment of LLMs and agentic workflows, they are hitting a critical infrastructure bottleneck: the container base images powering these applications are riddled with inherited security debt. Echo, an Israeli startup, is announcing a $35 million in Series A funding today (bringing its to-date total to $50 million in funding) to fix this by fundamentally reimagining how cloud infrastructure is built.The round was led by N47, with participation from Notable Capital, Hyperwise Ventures, and SentinelOne. But the real story isn&#x27;t the capital—it&#x27;s the company’s ambitious goal to replace the chaotic open-source supply chain with a managed, \"secure-by-design\" operating system.The Hidden Operating System of the CloudTo understand why Echo matters, you first have to understand the invisible foundation of the modern internet: container base images.Think of a \"container\" like a shipping box for software. It holds the application code (what the developers write) and everything that code needs to run (the \"base image\"). For a non-technical audience, the best way to understand a base image is to compare it to a brand-new laptop. When you buy a computer, it comes with an Operating System (OS) like Windows or macOS pre-installed to handle the basics—talking to the hard drive, connecting to Wi-Fi, and running programs. Without it, the computer is useless.In the cloud, the base image is that Operating System. Whether a company like Netflix or Uber is building a simple web app or a complex network of autonomous AI agents, they rely on these pre-built layers (like Alpine, Python, or Node.js) to define the underlying runtimes and dependencies.Here is where the risk begins. Unlike Windows or macOS, which are maintained by tech giants, most base images are open-source and created by communities of volunteers. Because they are designed to be useful to everyone, they are often packed with \"bloat\"—hundreds of extra tools and settings that most companies don&#x27;t actually need.Eylam Milner, Echo’s CTO, uses a stark analogy to explain why this is dangerous: \"Taking software just from the open source world, it&#x27;s like taking a computer found on the sidewalk and plugging it into your [network].\"Traditionally, companies try to fix this by downloading the image, scanning it for bugs, and attempting to \"patch\" the holes. But it is a losing battle. Echo’s research indicates that official Docker images often contain over 1,000 known vulnerabilities (CVEs) the moment they are downloaded. For enterprise security teams, this creates an impossible game of \"whac-a-mole,\" inheriting infrastructure debt before their engineers write a single line of code.The \"Enterprise Linux\" Moment for AIFor Eilon Elhadad, Echo’s co-founder and CEO, the industry is repeating history. \"Exactly what&#x27;s happened in the past... everybody run with Linux, and then they move to Enterprise Linux,\" Elhadad told VentureBeat. Just as Red Hat professionalized open-source Linux for the corporate world, Echo aims to be the \"enterprise AI native OS\"—a hardened, curated foundation for the AI era.\"We see ourselves in the AI native era, the foundation of everything,\" says Elhadad.The Tech: A \"Software Compilation Factory\"Echo is not a scanning tool. It does not look for vulnerabilities after the fact. Instead, it operates as a \"software compilation factory\" that rebuilds images from scratch.According to Milner, Echo’s approach to eliminating vulnerabilities relies on a rigorous, two-step engineering process for every workload:Compilation from Source: Echo starts with an empty canvas. It does not patch existing bloated images; it compiles binaries and libraries directly from source code. This ensures that only essential components are included, drastically reducing the attack surface.Hardening & Provenance (SLSA Level 3): The resulting images are hardened with aggressive security configurations to make exploitation difficult. Crucially, the build pipeline adheres to SLSA Level 3 standards (Supply-chain Levels for Software Artifacts), ensuring that every artifact is signed, tested, and verifiable.The result is a \"drop-in replacement.\" A developer simply changes one line in their Dockerfile to point to Echo’s registry. The application runs identically, but the underlying OS layer is mathematically cleaner and free of known CVEs.AI Defending Against AIThe need for this level of hygiene is being driven by the \"AI vs. AI\" security arms race. Bad actors are increasingly using AI to compress exploit windows from weeks down to days. Simultaneously, \"coding agents\"—AI tools that autonomously write software—are becoming the number one generators of code, often statistically selecting outdated or vulnerable libraries from open source.To counter this, Echo has built a proprietary infrastructure of AI agents that autonomously manage vulnerability research.Continuous Monitoring: Echo’s agents monitor the 4,000+ new CVEs added to the National Vulnerability Database (NVD) monthly.Unstructured Research: Beyond official databases, these agents scour unstructured sources like GitHub comments and developer forums to identify patches before they are widely published.Self-Healing: When a vulnerability is confirmed, the agents identify affected images, apply the fix, run compatibility tests, and generate a pull request for human review.This automation allows Echo’s engineering team to maintain over 600 secure images—a scale that would traditionally require hundreds of security researchers.Why It Matters to the CISOFor technical decision-makers, Echo represents a shift from \"mean time to remediation\" to \"zero vulnerabilities by default.\"Dan Garcia, CISO of EDB, noted in a press release that the platform \"saves at least 235 developer hours per release\" by eliminating the need for engineers to investigate false positives or patch base images manually.Echo is already securing production workloads for major enterprises like UiPath, EDB, and Varonis. As enterprises move from containers to agentic workflows, the ability to trust the underlying infrastructure—without managing it—may be the defining characteristic of the next generation of DevSecOps.Pricing for Echo&#x27;s solution is not publicly listed, but the company says on its website it prices \"based on image consumption, to ensure it scales with how you actually build and ship software.\"",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/29nysowN3KMSbwi3CYrkQg/4892ce19c3e761292423571389627d18/ngO-AORrCt0qnBT1tmzjJ.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/with-91-accuracy-open-source-hindsight-agentic-memory-provides-20-20-vision",
          "published_at": "Tue, 16 Dec 2025 14:00:00 GMT",
          "title": "With 91% accuracy, open source Hindsight agentic memory provides 20/20 vision for AI agents stuck on failing RAG",
          "standfirst": "It has become increasingly clear in 2025 that retrieval augmented generation (RAG) isn&#x27;t enough to meet the growing data requirements for agentic AI.RAG emerged in the last couple of years to become the default approach for connecting LLMs to external knowledge. The pattern is straightforward: chunk documents, embed them into vectors, store them in a database, and retrieve the most similar passages when queries arrive. This works adequately for one-off questions over static documents. But the architecture breaks down when AI agents need to operate across multiple sessions, maintain context over time, or distinguish what they&#x27;ve observed from what they believe.A new open source memory architecture called Hindsight tackles this challenge by organizing AI agent memory into four separate networks that distinguish world facts, agent experiences, synthesized entity summaries, and evolving beliefs. The system, which was developed by Vectorize.io in collaboration with Virginia Tech and The Washington Post, achieved 91.4% accuracy on the LongMemEval benchmark, outperforming existing memory systems.\"RAG is on life support, and agent memory is about to kill it entirely,\" Chris Latimer, co-founder and CEO of Vectorize.io, told VentureBeat in an exclusive interview. \"Most of the existing RAG infrastructure that people have put into place is not performing at the level that they would like it to.\"Why RAG can&#x27;t handle long-term agent memoryRAG was originally developed as an approach to give LLMs access to information beyond their training data without retraining the model. The core problem is that RAG treats all retrieved information uniformly. A fact observed six months ago receives the same treatment as an opinion formed yesterday. Information that contradicts earlier statements sits alongside the original claims with no mechanism to reconcile them. The system has no way to represent uncertainty, track how beliefs evolved, or understand why it reached a particular conclusion.The problem becomes acute in multi-session conversations. When an agent needs to recall details from hundreds of thousands of tokens spread across dozens of sessions, RAG systems either flood the context window with irrelevant information or miss critical details entirely. Vector similarity alone cannot determine what matters for a given query when that query requires understanding temporal relationships, causal chains or entity-specific context accumulated over weeks.\"If you have a one-size-fits-all approach to memory, either you&#x27;re carrying too much context you shouldn&#x27;t be carrying, or you&#x27;re carrying too little context,\" Naren Ramakrishnan, professor of computer science at Virginia Tech and director of the Sangani Center for AI and Data Analytics, told VentureBeat. The shift from RAG to agentic memory with HindsightThe shift from RAG to agent memory represents a fundamental architectural change. Instead of treating memory as an external retrieval layer that dumps text chunks into prompts, Hindsight integrates memory as a structured, first-class substrate for reasoning. The core innovation in Hindsight is its separation of knowledge into four logical networks. The world network stores objective facts about the external environment. The bank network captures the agent&#x27;s own experiences and actions, written in first person. The opinion network maintains subjective judgments with confidence scores that update as new evidence arrives. The observation network holds preference-neutral summaries of entities synthesized from underlying facts.This separation addresses what researchers call \"epistemic clarity\" by structurally distinguishing evidence from inference. When an agent forms an opinion, that belief is stored separately from the facts that support it, along with a confidence score. As new information arrives, the system can strengthen or weaken existing opinions rather than treating all stored information as equally certain.The architecture consists of two components that mimic how human memory works.TEMPR (Temporal Entity Memory Priming Retrieval) handles memory retention and recall by running four parallel searches: semantic vector similarity, keyword matching via BM25, graph traversal through shared entities, and temporal filtering for time-constrained queries. The system merges results using Reciprocal Rank Fusion and applies a neural reranker for final precision.CARA (Coherent Adaptive Reasoning Agents) handles preference-aware reflection by integrating configurable disposition parameters into reasoning: skepticism, literalism, and empathy. This addresses inconsistent reasoning across sessions. Without preference conditioning, agents produce locally plausible but globally inconsistent responses because the underlying LLM has no stable perspective.Hindsight achieves highest LongMemEval score at 91%Hindsight isn&#x27;t just theoretical academic research; the open-source technology was evaluated on the LongMemEval benchmark. The test evaluates agents on conversations spanning up to 1.5 million tokens across multiple sessions, measuring their ability to recall information, reason across time, and maintain consistent perspectives.The LongMemEval benchmark tests whether AI agents can handle real-world deployment scenarios. One of the key challenges enterprises face is agents that work well in testing but fail in production. Hindsight achieved 91.4% accuracy on the benchmark, the highest score recorded on the test.The broader set of results showed where structured memory provides the biggest gains: multi-session questions improved from 21.1% to 79.7%; temporal reasoning jumped from 31.6% to 79.7%; and knowledge update questions improved from 60.3% to 84.6%.\"It means that your agents will be able to perform more tasks, more accurately and consistently than they could before,\" Latimer said. \"What this allows you to do is to get a more accurate agent that can handle more mission critical business processes.\"Enterprise deployment and hyperscaler integrationFor enterprises considering how to deploy Hindsight, the implementation path is straightforward. The system runs as a single Docker container and integrates using an LLM wrapper that works with any language model. \"It&#x27;s a drop-in replacement for your API calls, and you start populating memories immediately,\" Latimer said.The technology targets enterprises that have already deployed RAG infrastructure and are not seeing the performance they need. \"Most of the existing RAG infrastructure that people have put into place is not performing at the level that they would like it to, and they&#x27;re looking for more robust solutions that can solve the problems that companies have, which is generally the inability to retrieve the correct information to complete a task or to answer a set of questions,\" Latimer said.Vectorize is working with hyperscalers to integrate the technology into cloud platforms. The company is actively partnering with cloud providers to support their LLMs with agent memory capabilities. What this means for enterprisesFor enterprises leading AI adoption, Hindsight represents a path beyond the limitations of current RAG deployments. Organizations that have invested in retrieval augmented generation and are seeing inconsistent agent performance should evaluate whether structured memory can address their specific failure modes. The technology particularly suits applications where agents must maintain context across multiple sessions, handle contradictory information over time or explain their reasoning\"RAG is dead, and I think agent memory is what&#x27;s going to kill it completely,\" Latimer said.",
          "content": "It has become increasingly clear in 2025 that retrieval augmented generation (RAG) isn&#x27;t enough to meet the growing data requirements for agentic AI.RAG emerged in the last couple of years to become the default approach for connecting LLMs to external knowledge. The pattern is straightforward: chunk documents, embed them into vectors, store them in a database, and retrieve the most similar passages when queries arrive. This works adequately for one-off questions over static documents. But the architecture breaks down when AI agents need to operate across multiple sessions, maintain context over time, or distinguish what they&#x27;ve observed from what they believe.A new open source memory architecture called Hindsight tackles this challenge by organizing AI agent memory into four separate networks that distinguish world facts, agent experiences, synthesized entity summaries, and evolving beliefs. The system, which was developed by Vectorize.io in collaboration with Virginia Tech and The Washington Post, achieved 91.4% accuracy on the LongMemEval benchmark, outperforming existing memory systems.\"RAG is on life support, and agent memory is about to kill it entirely,\" Chris Latimer, co-founder and CEO of Vectorize.io, told VentureBeat in an exclusive interview. \"Most of the existing RAG infrastructure that people have put into place is not performing at the level that they would like it to.\"Why RAG can&#x27;t handle long-term agent memoryRAG was originally developed as an approach to give LLMs access to information beyond their training data without retraining the model. The core problem is that RAG treats all retrieved information uniformly. A fact observed six months ago receives the same treatment as an opinion formed yesterday. Information that contradicts earlier statements sits alongside the original claims with no mechanism to reconcile them. The system has no way to represent uncertainty, track how beliefs evolved, or understand why it reached a particular conclusion.The problem becomes acute in multi-session conversations. When an agent needs to recall details from hundreds of thousands of tokens spread across dozens of sessions, RAG systems either flood the context window with irrelevant information or miss critical details entirely. Vector similarity alone cannot determine what matters for a given query when that query requires understanding temporal relationships, causal chains or entity-specific context accumulated over weeks.\"If you have a one-size-fits-all approach to memory, either you&#x27;re carrying too much context you shouldn&#x27;t be carrying, or you&#x27;re carrying too little context,\" Naren Ramakrishnan, professor of computer science at Virginia Tech and director of the Sangani Center for AI and Data Analytics, told VentureBeat. The shift from RAG to agentic memory with HindsightThe shift from RAG to agent memory represents a fundamental architectural change. Instead of treating memory as an external retrieval layer that dumps text chunks into prompts, Hindsight integrates memory as a structured, first-class substrate for reasoning. The core innovation in Hindsight is its separation of knowledge into four logical networks. The world network stores objective facts about the external environment. The bank network captures the agent&#x27;s own experiences and actions, written in first person. The opinion network maintains subjective judgments with confidence scores that update as new evidence arrives. The observation network holds preference-neutral summaries of entities synthesized from underlying facts.This separation addresses what researchers call \"epistemic clarity\" by structurally distinguishing evidence from inference. When an agent forms an opinion, that belief is stored separately from the facts that support it, along with a confidence score. As new information arrives, the system can strengthen or weaken existing opinions rather than treating all stored information as equally certain.The architecture consists of two components that mimic how human memory works.TEMPR (Temporal Entity Memory Priming Retrieval) handles memory retention and recall by running four parallel searches: semantic vector similarity, keyword matching via BM25, graph traversal through shared entities, and temporal filtering for time-constrained queries. The system merges results using Reciprocal Rank Fusion and applies a neural reranker for final precision.CARA (Coherent Adaptive Reasoning Agents) handles preference-aware reflection by integrating configurable disposition parameters into reasoning: skepticism, literalism, and empathy. This addresses inconsistent reasoning across sessions. Without preference conditioning, agents produce locally plausible but globally inconsistent responses because the underlying LLM has no stable perspective.Hindsight achieves highest LongMemEval score at 91%Hindsight isn&#x27;t just theoretical academic research; the open-source technology was evaluated on the LongMemEval benchmark. The test evaluates agents on conversations spanning up to 1.5 million tokens across multiple sessions, measuring their ability to recall information, reason across time, and maintain consistent perspectives.The LongMemEval benchmark tests whether AI agents can handle real-world deployment scenarios. One of the key challenges enterprises face is agents that work well in testing but fail in production. Hindsight achieved 91.4% accuracy on the benchmark, the highest score recorded on the test.The broader set of results showed where structured memory provides the biggest gains: multi-session questions improved from 21.1% to 79.7%; temporal reasoning jumped from 31.6% to 79.7%; and knowledge update questions improved from 60.3% to 84.6%.\"It means that your agents will be able to perform more tasks, more accurately and consistently than they could before,\" Latimer said. \"What this allows you to do is to get a more accurate agent that can handle more mission critical business processes.\"Enterprise deployment and hyperscaler integrationFor enterprises considering how to deploy Hindsight, the implementation path is straightforward. The system runs as a single Docker container and integrates using an LLM wrapper that works with any language model. \"It&#x27;s a drop-in replacement for your API calls, and you start populating memories immediately,\" Latimer said.The technology targets enterprises that have already deployed RAG infrastructure and are not seeing the performance they need. \"Most of the existing RAG infrastructure that people have put into place is not performing at the level that they would like it to, and they&#x27;re looking for more robust solutions that can solve the problems that companies have, which is generally the inability to retrieve the correct information to complete a task or to answer a set of questions,\" Latimer said.Vectorize is working with hyperscalers to integrate the technology into cloud platforms. The company is actively partnering with cloud providers to support their LLMs with agent memory capabilities. What this means for enterprisesFor enterprises leading AI adoption, Hindsight represents a path beyond the limitations of current RAG deployments. Organizations that have invested in retrieval augmented generation and are seeing inconsistent agent performance should evaluate whether structured memory can address their specific failure modes. The technology particularly suits applications where agents must maintain context across multiple sessions, handle contradictory information over time or explain their reasoning\"RAG is dead, and I think agent memory is what&#x27;s going to kill it completely,\" Latimer said.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4yzwbomyw8VMX7Q4ybtqkw/3c90b622308dfcddebc91ca2d547a740/hindsight-failing-RAG-smk.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/zencoder-drops-zenflow-a-free-ai-orchestration-tool-that-pits-claude-against",
          "published_at": "Tue, 16 Dec 2025 14:00:00 GMT",
          "title": "Zencoder drops Zenflow, a free AI orchestration tool that pits Claude against OpenAI’s models to catch coding errors",
          "standfirst": "Zencoder, the Silicon Valley startup that builds AI-powered coding agents, released a free desktop application on Monday that it says will fundamentally change how software engineers interact with artificial intelligence — moving the industry beyond the freewheeling era of \"vibe coding\" toward a more disciplined, verifiable approach to AI-assisted development.The product, called Zenflow, introduces what the company describes as an \"AI orchestration layer\" that coordinates multiple AI agents to plan, implement, test, and review code in structured workflows. The launch is Zencoder&#x27;s most ambitious attempt yet to differentiate itself in an increasingly crowded market dominated by tools like Cursor, GitHub Copilot, and coding agents built directly by AI giants Anthropic, OpenAI, and Google.\"Chat UIs were fine for copilots, but they break down when you try to scale,\" said Andrew Filev, Zencoder&#x27;s chief executive, in an exclusive interview with VentureBeat. \"Teams are hitting a wall where speed without structure creates technical debt. Zenflow replaces &#x27;Prompt Roulette&#x27; with an engineering assembly line where agents plan, implement, and, crucially, verify each other&#x27;s work.\"The announcement arrives at a critical moment for enterprise software development. Companies across industries have poured billions of dollars into AI coding tools over the past two years, hoping to dramatically accelerate their engineering output. Yet the promised productivity revolution has largely failed to materialize at scale.Why AI coding tools have failed to deliver on their 10x productivity promiseFilev, who previously founded and sold the project management company Wrike to Citrix, pointed to a growing disconnect between AI coding hype and reality. While vendors have promised tenfold productivity gains, rigorous studies — including research from Stanford University — consistently show improvements closer to 20 percent.\"If you talk to real engineering leaders, I don&#x27;t remember a single conversation where somebody vibe coded themselves to 2x or 5x or 10x productivity on serious engineering production,\" Filev said. \"The typical number you would hear would be about 20 percent.\"The problem, according to Filev, lies not with the AI models themselves but with how developers interact with them. The standard approach of typing requests into a chat interface and hoping for usable code works well for simple tasks but falls apart on complex enterprise projects.Zencoder&#x27;s internal engineering team claims to have cracked a different approach. Filev said the company now operates at roughly twice the velocity it achieved 12 months ago, not primarily because AI models improved, but because the team restructured its development processes.\"We had to change our process and use a variety of different best practices,\" he said.Inside the four pillars that power Zencoder&#x27;s AI orchestration platformZenflow organizes its approach around four core capabilities that Zencoder argues any serious AI orchestration platform must support.Structured workflows replace ad-hoc prompting with repeatable sequences (plan, implement, test, review) that agents follow consistently. Filev drew parallels to his experience building Wrike, noting that individual to-do lists rarely scale across organizations, while defined workflows create predictable outcomes.Spec-driven development requires AI agents to first generate a technical specification, then create a step-by-step plan, and only then write code. The approach became so effective that frontier AI labs including Anthropic and OpenAI have since trained their models to follow it automatically. The specification anchors agents to clear requirements, preventing what Zencoder calls \"iteration drift,\" or the tendency for AI-generated code to gradually diverge from the original intent.Multi-agent verification deploys different AI models to critique each other&#x27;s work. Because AI models from the same family tend to share blind spots, Zencoder routes verification tasks across model providers, asking Claude to review code written by OpenAI&#x27;s models, or vice versa.\"Think of it as a second opinion from a doctor,\" Filev told VentureBeat. \"With the right pipeline, we see results on par with what you&#x27;d expect from Claude 5 or GPT-6. You&#x27;re getting the benefit of a next-generation model today.\"Parallel execution lets developers run multiple AI agents simultaneously in isolated sandboxes, preventing them from interfering with each other&#x27;s work. The interface provides a command center for monitoring this fleet, a significant departure from the current practice of managing multiple terminal windows.How verification solves AI coding&#x27;s biggest reliability problemZencoder&#x27;s emphasis on verification addresses one of the most persistent criticisms of AI-generated code: its tendency to produce \"slop,\" or code that appears correct but fails in production or degrades over successive iterations.The company&#x27;s internal research found that developers who skip verification often fall into what Filev called a \"death loop.\" An AI agent completes a task successfully, but the developer, reluctant to review unfamiliar code, moves on without understanding what was written. When subsequent tasks fail, the developer lacks the context to fix problems manually and instead keeps prompting the AI for solutions.\"They literally spend more than a day in that death loop,\" Filev said. \"That&#x27;s why the productivity is not 2x, because they were running at 3x first, and then they wasted the whole day.\"The multi-agent verification approach also gives Zencoder an unusual competitive advantage over the frontier AI labs themselves. While Anthropic, OpenAI, and Google each optimize their own models, Zencoder can mix and match across providers to reduce bias.\"This is a rare situation where we have an edge on the frontier labs,\" Filev said. \"Most of the time they have an edge on us, but this is a rare case.\"Zencoder faces steep competition from AI giants and well-funded startupsZencoder enters the AI orchestration market at a moment of intense competition. The company has positioned itself as a model-agnostic platform, supporting major providers including Anthropic, OpenAI, and Google Gemini. In September, Zencoder expanded its platform to let developers use command-line coding agents from any provider within its interface.That strategy reflects a pragmatic acknowledgment that developers increasingly maintain relationships with multiple AI providers rather than committing exclusively to one. Zencoder&#x27;s universal platform approach lets it serve as the orchestration layer regardless of which underlying models a company prefers.The company also emphasizes enterprise readiness, touting SOC 2 Type II, ISO 27001, and ISO 42001 certifications along with GDPR compliance. These credentials matter for regulated industries like financial services and healthcare, where compliance requirements can block adoption of consumer-oriented AI tools.But Zencoder faces formidable competition from multiple directions. Cursor and Windsurf have built dedicated AI-first code editors with devoted user bases. GitHub Copilot benefits from Microsoft&#x27;s distribution muscle and deep integration with the world&#x27;s largest code repository. And the frontier AI labs continue expanding their own coding capabilities.Filev dismissed concerns about competition from the AI labs, arguing that smaller players like Zencoder can move faster on user experience innovation.\"I&#x27;m sure they will come to the same conclusion, and they&#x27;re smart and moving fast, so I&#x27;m sure they will catch up fairly quickly,\" he said. \"That&#x27;s why I said in the next six to 12 months, you&#x27;re going to see a lot of this propagating through the whole space.\"The case for adopting AI orchestration now instead of waiting for better modelsTechnical executives weighing AI coding investments face a difficult timing question: Should they adopt orchestration tools now, or wait for frontier AI labs to build these capabilities natively into their models?Filev argued that waiting carries significant competitive risk.\"Right now, everybody is under pressure to deliver more in less time, and everybody expects engineering leaders to deliver results from AI,\" he said. \"As a founder and CEO, I do not expect 20 percent from my VP of engineering. I expect 2x.\"He also questioned whether the major AI labs will prioritize orchestration capabilities when their core business remains model development.\"In the ideal world, frontier labs should be building the best-ever models and competing with each other, and Zencoders and Cursors need to build the best-ever UI and UX application layer on top of those models,\" Filev said. \"I don&#x27;t see a world where OpenAI will offer you our code verifier, or vice versa.\"Zenflow launches as a free desktop application, with updated plugins available for Visual Studio Code and JetBrains integrated development environments. The product supports what Zencoder calls \"dynamic workflows,\" meaning the system automatically adjusts process complexity based on whether a human is actively monitoring and on the difficulty of the task at hand.Zencoder said internal testing showed that replacing standard prompting with Zenflow&#x27;s orchestration layer improved code correctness by approximately 20 percent on average.What Zencoder&#x27;s bet on orchestration reveals about the future of AI codingZencoder frames Zenflow as the first product in what it expects to become a significant new software category. The company believes every vendor focused on AI coding will eventually arrive at similar conclusions about the need for orchestration tools.\"I think the next six to 12 months will be all about orchestration,\" Filev predicted. \"A lot of organizations will finally reach that 2x. Not 10x yet, but at least the 2x they were promised a year ago.\"Rather than competing head-to-head with frontier AI labs on model quality, Zencoder is betting that the application layer (the software that helps developers actually use these models effectively) will determine winners and losers.It is, Filev suggested, a familiar pattern from technology history.\"This is very similar to what I observed when I started Wrike,\" he said. \"As work went digital, people relied on email and spreadsheets to manage everything, and neither could keep up.\"The same dynamic, he argued, now applies to AI coding. Chat interfaces were designed for conversation, not for orchestrating complex engineering workflows. Whether Zencoder can establish itself as the essential layer between developers and AI models before the giants build their own solutions remains an open question.But Filev seems comfortable with the race. The last time he spotted a gap between how people worked and the tools they had to work with, he built a company worth over a billion dollars.Zenflow is available immediately as a free download at zencoder.ai/zenflow.",
          "content": "Zencoder, the Silicon Valley startup that builds AI-powered coding agents, released a free desktop application on Monday that it says will fundamentally change how software engineers interact with artificial intelligence — moving the industry beyond the freewheeling era of \"vibe coding\" toward a more disciplined, verifiable approach to AI-assisted development.The product, called Zenflow, introduces what the company describes as an \"AI orchestration layer\" that coordinates multiple AI agents to plan, implement, test, and review code in structured workflows. The launch is Zencoder&#x27;s most ambitious attempt yet to differentiate itself in an increasingly crowded market dominated by tools like Cursor, GitHub Copilot, and coding agents built directly by AI giants Anthropic, OpenAI, and Google.\"Chat UIs were fine for copilots, but they break down when you try to scale,\" said Andrew Filev, Zencoder&#x27;s chief executive, in an exclusive interview with VentureBeat. \"Teams are hitting a wall where speed without structure creates technical debt. Zenflow replaces &#x27;Prompt Roulette&#x27; with an engineering assembly line where agents plan, implement, and, crucially, verify each other&#x27;s work.\"The announcement arrives at a critical moment for enterprise software development. Companies across industries have poured billions of dollars into AI coding tools over the past two years, hoping to dramatically accelerate their engineering output. Yet the promised productivity revolution has largely failed to materialize at scale.Why AI coding tools have failed to deliver on their 10x productivity promiseFilev, who previously founded and sold the project management company Wrike to Citrix, pointed to a growing disconnect between AI coding hype and reality. While vendors have promised tenfold productivity gains, rigorous studies — including research from Stanford University — consistently show improvements closer to 20 percent.\"If you talk to real engineering leaders, I don&#x27;t remember a single conversation where somebody vibe coded themselves to 2x or 5x or 10x productivity on serious engineering production,\" Filev said. \"The typical number you would hear would be about 20 percent.\"The problem, according to Filev, lies not with the AI models themselves but with how developers interact with them. The standard approach of typing requests into a chat interface and hoping for usable code works well for simple tasks but falls apart on complex enterprise projects.Zencoder&#x27;s internal engineering team claims to have cracked a different approach. Filev said the company now operates at roughly twice the velocity it achieved 12 months ago, not primarily because AI models improved, but because the team restructured its development processes.\"We had to change our process and use a variety of different best practices,\" he said.Inside the four pillars that power Zencoder&#x27;s AI orchestration platformZenflow organizes its approach around four core capabilities that Zencoder argues any serious AI orchestration platform must support.Structured workflows replace ad-hoc prompting with repeatable sequences (plan, implement, test, review) that agents follow consistently. Filev drew parallels to his experience building Wrike, noting that individual to-do lists rarely scale across organizations, while defined workflows create predictable outcomes.Spec-driven development requires AI agents to first generate a technical specification, then create a step-by-step plan, and only then write code. The approach became so effective that frontier AI labs including Anthropic and OpenAI have since trained their models to follow it automatically. The specification anchors agents to clear requirements, preventing what Zencoder calls \"iteration drift,\" or the tendency for AI-generated code to gradually diverge from the original intent.Multi-agent verification deploys different AI models to critique each other&#x27;s work. Because AI models from the same family tend to share blind spots, Zencoder routes verification tasks across model providers, asking Claude to review code written by OpenAI&#x27;s models, or vice versa.\"Think of it as a second opinion from a doctor,\" Filev told VentureBeat. \"With the right pipeline, we see results on par with what you&#x27;d expect from Claude 5 or GPT-6. You&#x27;re getting the benefit of a next-generation model today.\"Parallel execution lets developers run multiple AI agents simultaneously in isolated sandboxes, preventing them from interfering with each other&#x27;s work. The interface provides a command center for monitoring this fleet, a significant departure from the current practice of managing multiple terminal windows.How verification solves AI coding&#x27;s biggest reliability problemZencoder&#x27;s emphasis on verification addresses one of the most persistent criticisms of AI-generated code: its tendency to produce \"slop,\" or code that appears correct but fails in production or degrades over successive iterations.The company&#x27;s internal research found that developers who skip verification often fall into what Filev called a \"death loop.\" An AI agent completes a task successfully, but the developer, reluctant to review unfamiliar code, moves on without understanding what was written. When subsequent tasks fail, the developer lacks the context to fix problems manually and instead keeps prompting the AI for solutions.\"They literally spend more than a day in that death loop,\" Filev said. \"That&#x27;s why the productivity is not 2x, because they were running at 3x first, and then they wasted the whole day.\"The multi-agent verification approach also gives Zencoder an unusual competitive advantage over the frontier AI labs themselves. While Anthropic, OpenAI, and Google each optimize their own models, Zencoder can mix and match across providers to reduce bias.\"This is a rare situation where we have an edge on the frontier labs,\" Filev said. \"Most of the time they have an edge on us, but this is a rare case.\"Zencoder faces steep competition from AI giants and well-funded startupsZencoder enters the AI orchestration market at a moment of intense competition. The company has positioned itself as a model-agnostic platform, supporting major providers including Anthropic, OpenAI, and Google Gemini. In September, Zencoder expanded its platform to let developers use command-line coding agents from any provider within its interface.That strategy reflects a pragmatic acknowledgment that developers increasingly maintain relationships with multiple AI providers rather than committing exclusively to one. Zencoder&#x27;s universal platform approach lets it serve as the orchestration layer regardless of which underlying models a company prefers.The company also emphasizes enterprise readiness, touting SOC 2 Type II, ISO 27001, and ISO 42001 certifications along with GDPR compliance. These credentials matter for regulated industries like financial services and healthcare, where compliance requirements can block adoption of consumer-oriented AI tools.But Zencoder faces formidable competition from multiple directions. Cursor and Windsurf have built dedicated AI-first code editors with devoted user bases. GitHub Copilot benefits from Microsoft&#x27;s distribution muscle and deep integration with the world&#x27;s largest code repository. And the frontier AI labs continue expanding their own coding capabilities.Filev dismissed concerns about competition from the AI labs, arguing that smaller players like Zencoder can move faster on user experience innovation.\"I&#x27;m sure they will come to the same conclusion, and they&#x27;re smart and moving fast, so I&#x27;m sure they will catch up fairly quickly,\" he said. \"That&#x27;s why I said in the next six to 12 months, you&#x27;re going to see a lot of this propagating through the whole space.\"The case for adopting AI orchestration now instead of waiting for better modelsTechnical executives weighing AI coding investments face a difficult timing question: Should they adopt orchestration tools now, or wait for frontier AI labs to build these capabilities natively into their models?Filev argued that waiting carries significant competitive risk.\"Right now, everybody is under pressure to deliver more in less time, and everybody expects engineering leaders to deliver results from AI,\" he said. \"As a founder and CEO, I do not expect 20 percent from my VP of engineering. I expect 2x.\"He also questioned whether the major AI labs will prioritize orchestration capabilities when their core business remains model development.\"In the ideal world, frontier labs should be building the best-ever models and competing with each other, and Zencoders and Cursors need to build the best-ever UI and UX application layer on top of those models,\" Filev said. \"I don&#x27;t see a world where OpenAI will offer you our code verifier, or vice versa.\"Zenflow launches as a free desktop application, with updated plugins available for Visual Studio Code and JetBrains integrated development environments. The product supports what Zencoder calls \"dynamic workflows,\" meaning the system automatically adjusts process complexity based on whether a human is actively monitoring and on the difficulty of the task at hand.Zencoder said internal testing showed that replacing standard prompting with Zenflow&#x27;s orchestration layer improved code correctness by approximately 20 percent on average.What Zencoder&#x27;s bet on orchestration reveals about the future of AI codingZencoder frames Zenflow as the first product in what it expects to become a significant new software category. The company believes every vendor focused on AI coding will eventually arrive at similar conclusions about the need for orchestration tools.\"I think the next six to 12 months will be all about orchestration,\" Filev predicted. \"A lot of organizations will finally reach that 2x. Not 10x yet, but at least the 2x they were promised a year ago.\"Rather than competing head-to-head with frontier AI labs on model quality, Zencoder is betting that the application layer (the software that helps developers actually use these models effectively) will determine winners and losers.It is, Filev suggested, a familiar pattern from technology history.\"This is very similar to what I observed when I started Wrike,\" he said. \"As work went digital, people relied on email and spreadsheets to manage everything, and neither could keep up.\"The same dynamic, he argued, now applies to AI coding. Chat interfaces were designed for conversation, not for orchestrating complex engineering workflows. Whether Zencoder can establish itself as the essential layer between developers and AI models before the giants build their own solutions remains an open question.But Filev seems comfortable with the race. The last time he spotted a gap between how people worked and the tools they had to work with, he built a company worth over a billion dollars.Zenflow is available immediately as a free download at zencoder.ai/zenflow.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/hCrfjXJOZJtvGggguzyQk/77b7b582d2e5725acbeb633ff25f8152/nuneybits_Vector_art_of_a_retro_desktop_computer_screen_with_a__c249085b-3fdb-4462-bdea-a029b200a558.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/tv-movies/avatar-fire-and-ash-review-maybe-its-time-to-sunset-pandora-140000997.html",
          "published_at": "Tue, 16 Dec 2025 14:00:00 +0000",
          "title": "Avatar Fire and Ash review: Maybe it's time to sunset Pandora",
          "standfirst": "No matter what you think of James Cameron's Avatar movies, their technical ambitions are undeniable. Cameron developed his own camera system to shoot the first Avatar in 3D, but since most of the actors were digitally captured, he also had the freedom to construct scenes with a virtual camera after they were physically shot. For Avatar: The Way of Water, which arrived a whopping 13 years after the first film, Cameron also leaned into high frame rate footage and new ways of modeling natural fluid dynamics. Even though the third entry, Avatar: Fire and Ash, is coming just a few years after the last sequel, I still expected Cameron to deliver some sort of new feat to wow audiences. He could have found a smoother way to employ high frame rate footage, so the film wasn't jarringly shifting between traditional 24 fps scenes and smoother 48 fps action shots. Maybe we'd see more natural interactions between live actors and virtual characters and environments (it sure is hard to beat Edie Falco suited up in a wicked exoskeleton in the last film, though). Instead, Avatar: Fire and Ash is just another Avatar film — it doesn't push any boundaries, narratively or technically. And without any technical achievements to lean on, the narrative issues inherent with Avatar become all the more glaring. It's still basically a story that places a clueless white dude in the middle of a fight between indigenous and colonialist powers. (Improbably, he's crowned one of the Na'vi's best warriors!). The script from Cameron and his co-writers (Rick Jaffa and Amanda Silver, continuing their work from The Way of Water) often hits identical beats to a low-rent CW show. And perhaps worst of all, the stakes of the story haven't really changed much. Jake Sully (Sam Worthington) and his family are still fighting off the militarized Resource Development Association (RDA), Col. Quaritch still holds a grudge from being killed (twice now!) and from the Sullies raising his Tarzan-like son, Spider (Jack Champion).There’s an attempt to cast the Na’vi in a new light with the villainous Ash People, who spend their days attacking and stealing from other tribes. While most Na’vi people work cooperatively with other clans and share their reverence for Eywa, the collective consciousness of Pandora, the Ash People resent it for not saving their villages from natural disasters. Despite a deliciously evil performance by Oona Chaplin (Charlie Chaplin's grandaughter!) as Varang, the Ash People don't amount to much more than \"evil Na'vi.\" When they inevitably work together with humans to attack other Na’vi, it doesn’t feel surprising in the least. Honestly, it’s a tad insulting.Avatar: Fire and Ash20th. Century StudiosPerhaps we've been spoiled by Cameron's last few films, but Avatar: Fire and Ash ultimately feels like more of the same. Even its massive final battle feels like a retread, since it’s set in the same ocean environment as The Way of Water and is once again focused on protecting psychic alien whales from humans. Cameron does let his action chops shine throughout the film, but after a certain point, trying to enjoy those sequences is like trying to eat a family-sized carton of ice cream by yourself. You’ll enjoy it for a little while, but eventually you’re left with a massive headache and sugar hangover.It’s clear that James Cameron has built the Avatar franchise to explore everything he loves: Stories about protecting the environment, fighting against capitalist excess and kicking tons of ass. Parts of Avatar 4 have already been shot, and that film is expected to arrive in 2029. But I’m hoping the 71-year-old filmmaker eventually finds his way out of Pandora. He’s co-directing the Billie Eilish concert film, Hit Me Hard and Soft: The Tour, so that’s a start. But I’m eager to see what other new worlds he can dream up. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/avatar-fire-and-ash-review-maybe-its-time-to-sunset-pandora-140000997.html?src=rss",
          "content": "No matter what you think of James Cameron's Avatar movies, their technical ambitions are undeniable. Cameron developed his own camera system to shoot the first Avatar in 3D, but since most of the actors were digitally captured, he also had the freedom to construct scenes with a virtual camera after they were physically shot. For Avatar: The Way of Water, which arrived a whopping 13 years after the first film, Cameron also leaned into high frame rate footage and new ways of modeling natural fluid dynamics. Even though the third entry, Avatar: Fire and Ash, is coming just a few years after the last sequel, I still expected Cameron to deliver some sort of new feat to wow audiences. He could have found a smoother way to employ high frame rate footage, so the film wasn't jarringly shifting between traditional 24 fps scenes and smoother 48 fps action shots. Maybe we'd see more natural interactions between live actors and virtual characters and environments (it sure is hard to beat Edie Falco suited up in a wicked exoskeleton in the last film, though). Instead, Avatar: Fire and Ash is just another Avatar film — it doesn't push any boundaries, narratively or technically. And without any technical achievements to lean on, the narrative issues inherent with Avatar become all the more glaring. It's still basically a story that places a clueless white dude in the middle of a fight between indigenous and colonialist powers. (Improbably, he's crowned one of the Na'vi's best warriors!). The script from Cameron and his co-writers (Rick Jaffa and Amanda Silver, continuing their work from The Way of Water) often hits identical beats to a low-rent CW show. And perhaps worst of all, the stakes of the story haven't really changed much. Jake Sully (Sam Worthington) and his family are still fighting off the militarized Resource Development Association (RDA), Col. Quaritch still holds a grudge from being killed (twice now!) and from the Sullies raising his Tarzan-like son, Spider (Jack Champion).There’s an attempt to cast the Na’vi in a new light with the villainous Ash People, who spend their days attacking and stealing from other tribes. While most Na’vi people work cooperatively with other clans and share their reverence for Eywa, the collective consciousness of Pandora, the Ash People resent it for not saving their villages from natural disasters. Despite a deliciously evil performance by Oona Chaplin (Charlie Chaplin's grandaughter!) as Varang, the Ash People don't amount to much more than \"evil Na'vi.\" When they inevitably work together with humans to attack other Na’vi, it doesn’t feel surprising in the least. Honestly, it’s a tad insulting.Avatar: Fire and Ash20th. Century StudiosPerhaps we've been spoiled by Cameron's last few films, but Avatar: Fire and Ash ultimately feels like more of the same. Even its massive final battle feels like a retread, since it’s set in the same ocean environment as The Way of Water and is once again focused on protecting psychic alien whales from humans. Cameron does let his action chops shine throughout the film, but after a certain point, trying to enjoy those sequences is like trying to eat a family-sized carton of ice cream by yourself. You’ll enjoy it for a little while, but eventually you’re left with a massive headache and sugar hangover.It’s clear that James Cameron has built the Avatar franchise to explore everything he loves: Stories about protecting the environment, fighting against capitalist excess and kicking tons of ass. Parts of Avatar 4 have already been shot, and that film is expected to arrive in 2029. But I’m hoping the 71-year-old filmmaker eventually finds his way out of Pandora. He’s co-directing the Billie Eilish concert film, Hit Me Hard and Soft: The Tour, so that’s a start. But I’m eager to see what other new worlds he can dream up. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/avatar-fire-and-ash-review-maybe-its-time-to-sunset-pandora-140000997.html?src=rss",
          "feed_position": 20,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/3248B_0010_v0800.le.1131.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/evs/mercedes-benz-cla-first-drive-head-of-the-ev-class-140000562.html",
          "published_at": "Tue, 16 Dec 2025 14:00:00 +0000",
          "title": "Mercedes-Benz CLA first drive: Head of the EV class",
          "standfirst": "This one's been a long time coming. Mercedes-Benz has been researching, refining and even reshaping the car that would ultimately be the CLA for years now, teasing us with technical briefings and even showing off a sultry crimson concept car a full two years ago.That was the Concept CLA, and while the production CLA you see here doesn't look quite that good, it is a fine-looking little electric sedan. More importantly, it goes as far as you'd think its slippery, 0.21-coefficient-of-drag body would carry it: up to 374 miles on a charge.With a $47,250 starting price, is this electric CLA the complete package? After spending a day behind the wheel of one, I think it might just be. Higher density2026 Mercedes-Benz CLA 250+ EQTim Stevens for EngadgetThe CLA has long been Mercedes-Benz's most attainable sedan, a machine for those wanting something fun and stylish that offers a taste of the M-B lifestyle without breaking the bank.Attainability is still a big focus of this newly rebooted CLA, which serves as the debut venue for the company's latest generation of electrification. While most luxury auto makers would have you swing for their top-tier models to get the newest tech, Mercedes is actually bringing it to the lower end first. The new CLA is built around a new battery pack that offers 20 percent more energy density than the company's previous EVs. There's a big boost in efficiency, too. Where the EQS, the company's current range meister, does up to 390 miles on a charge from roughly 110 kilowatt-hours, the CLA manages 374 miles from just 85. It's a much smaller car, sure, and lighter too at about 4,500 pounds versus 5,500 and up for the EQS, but there are bigger efficiencies at play here thanks to advanced motors and the aforementioned aerodynamics.The CLA’s 0.21 coefficient of drag slots it right in between the 0.20 rating for the EQS sedan and 0.22 for the EQE. Crucially, though, despite being just as slippery as those cars, Mercedes-Benz's designers also managed to make the CLS stylish, a big step up from the efficient but amorphous profiles of its previous EVs. That aerodynamic efficiency is a big part of what delivers the 374-mile range for the single-motor CLA 250+ with EQ Technology model, the formal and long-winded designation for what I drove. It delivers 268 horsepower through the rear wheels. Those wanting a bit more oomph can step up to the 349-hp, dual-motor, all-wheel-drive 350 4MATIC model. That extra power and low-grip surety costs an extra $2,550, but the bigger penalty is range: the dual-motor model maxes out at 312 miles on a charge. (There is a hybrid version of the new CLA coming as well, but we'll cover that on its own later.)When it comes to charging, the new CLA impresses there, too. Charging at up to 320 kilowatts via the company's first NACS plug, the CLA adds a whopping 200 miles of range in 10 minutes. Weirdly, the car also has a separate, older-style J1772 plug for slower, level-two charging.Accessible, not basicThe interior displays of the 2026 Mercedes-Benz CLA 250+ EQTim Stevens for EngadgetAs a more attainable machine, you wouldn't necessarily expect the CLA to be completely loaded with features. Still, tick enough boxes and you can definitely get it there. While it doesn't have the luscious, curving Hyperscreen display as the EQS, it does offer a similar experience called Superscreen. You can get up to three displays spread across the dashboard: a 10.25-inch gauge cluster on the left, a 14-inch touchscreen in the center and an optional third display (also 14 inches) on the right for the passenger to play Angry Birds or stream videos. If, for some reason, they wouldn't rather just look at their phone.All those displays run the latest version of the MBUX user interface, similar to what we've seen in the company's other EVs, but it’s a bit simpler and easier to use here. That's backed by a wholly new system-level operating system called MB.OS running on NVIDIA silicon, also making its debut on the CLA. Mercedes says this not only has far more capability but can also be more comprehensively updated via the car's 5G connection. One of the features in the latest Mercedes software is baked-in AI. Say \"Hey, Mercedes,\" and you can not only change just about any setting in the car, but also engage in any number of inane conversations. I asked for a weather update for my next trip to Chicago, the latest releases from a few of my forgotten bands and even got an explanation of why the lyrics in the song \"Water's Edge\" by Seven Mary Three are so very creepy. (Don't go down there, friends.)It's all reasonably snappy and quite useful, but not perfect. When I said \"I'm hungry,\" I got a quick listing of restaurants and offers for quick routing. When I said, \"I need a hospital,\" the system, flummoxed, just stopped talking to me. Thankfully, I did not need a hospital. I was actually feeling pretty okay. That extensive software upgradability is also opening the door to a new era of car upgrades. Yes, the automotive DLC era is here, and you can pay extra to unlock additional active features like automated parking, navigation, a dashcam function and whatever else Mercedes-Benz's product planners can dream up in the future. Hopefully, there's no horse armor involved.We'll see how that shakes out, but my only real complaint about the interior was that it felt a bit cramped. It's a sedan on the small side, sure, but the layout feels a bit claustrophobic. That dashboard with all the displays is situated nearly vertically, as are the sides of the center console. Sitting in the passenger seat felt like being tucked in a box.Mind you, it was a very comfortable box, well-upholstered and featuring a lovely interior trim made of recycled paper, grooved to give the effect of a Zen garden. Headroom up front is generous and actually isn't too bad in the rear, but ducking under that sweeping roofline to get into the back seats requires a bit of flexibility.Drive time2026 Mercedes-Benz CLA 250+ EQTim Stevens for EngadgetDespite being the slowest electric CLA, this little sedan gets off the line quickly. A 6.6-second 0-to-60 time under-sells the feeling of instant acceleration and throttle response that make EVs so very compelling. You only start to feel the CLA's relative lack of horsepower at higher speeds, but even there, it's hardly lacking.That made it a blast to scoot from light to light as I was escaping from San Francisco, but it was much more fun in the foothills of Mt. Tamalpais. The CLA's steering is light yet has good feedback. I could really feel the road beneath the front tires, making for a more engaging machine than I was expecting.That battery pack in the floor keeps body roll in check, but a positively pliant suspension makes for a relaxed affair. The CLA did a great job of soaking up the countless imperfections in and around San Francisco, making for an extremely comfortable commuter, if one that felt a bit floaty at times.It'll be a safe commuter, too. The car is festooned with sensors, including 10 cameras of various resolutions and focal lengths, five radar sensors firing in every direction and 12 ultrasonic sensors. You'll need to pay extra for the digital keys to unlock their full functionality, though, like advanced lane-keeping and automated lane changes. There's even an advanced, point-to-point driver assistance system coming called MB.DRIVE Assist Pro that'll let the car handle most of the steering — even on secondary roads. More details on that to come. For now, the car did great at managing itself on the highway, changing lanes with enough initiative to get through commuter traffic without issue, and not only bringing itself to a complete stop in traffic, but resuming again as soon as the cars ahead moved.It even delivered good efficiency. I saw 3.9 miles per kWh, which would equate to a theoretical 331 miles from the 85 kWh battery pack. That's despite my driving with a good amount of enthusiasm and a heavy right foot. Edmunds, driving more conservatively, got 434 miles from a single charge,Wrap-up2026 Mercedes-Benz CLA 250+ EQTim Stevens for EngadgetSo the CLA looks great, drives well, has plenty of range and again, starting at $47,250, feels well-priced. Yes, you'll need to pay extra if you want to get all the toys, like the epic Dolby Atmos-capable Burmester sound system or the lovely Natural Fiber Zen interior trim. But when I ticked all the boxes I wanted, I still came out under $60,000. That put me about $5,000 below the base price of the company's next-bigger EV, the EQE.The CLA really is a big step forward on the EV front, and it’s a car that's hard to fault. The new CLA is hitting dealerships presently, and I have a feeling you'll be seeing plenty of them on the road soon.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/mercedes-benz-cla-first-drive-head-of-the-ev-class-140000562.html?src=rss",
          "content": "This one's been a long time coming. Mercedes-Benz has been researching, refining and even reshaping the car that would ultimately be the CLA for years now, teasing us with technical briefings and even showing off a sultry crimson concept car a full two years ago.That was the Concept CLA, and while the production CLA you see here doesn't look quite that good, it is a fine-looking little electric sedan. More importantly, it goes as far as you'd think its slippery, 0.21-coefficient-of-drag body would carry it: up to 374 miles on a charge.With a $47,250 starting price, is this electric CLA the complete package? After spending a day behind the wheel of one, I think it might just be. Higher density2026 Mercedes-Benz CLA 250+ EQTim Stevens for EngadgetThe CLA has long been Mercedes-Benz's most attainable sedan, a machine for those wanting something fun and stylish that offers a taste of the M-B lifestyle without breaking the bank.Attainability is still a big focus of this newly rebooted CLA, which serves as the debut venue for the company's latest generation of electrification. While most luxury auto makers would have you swing for their top-tier models to get the newest tech, Mercedes is actually bringing it to the lower end first. The new CLA is built around a new battery pack that offers 20 percent more energy density than the company's previous EVs. There's a big boost in efficiency, too. Where the EQS, the company's current range meister, does up to 390 miles on a charge from roughly 110 kilowatt-hours, the CLA manages 374 miles from just 85. It's a much smaller car, sure, and lighter too at about 4,500 pounds versus 5,500 and up for the EQS, but there are bigger efficiencies at play here thanks to advanced motors and the aforementioned aerodynamics.The CLA’s 0.21 coefficient of drag slots it right in between the 0.20 rating for the EQS sedan and 0.22 for the EQE. Crucially, though, despite being just as slippery as those cars, Mercedes-Benz's designers also managed to make the CLS stylish, a big step up from the efficient but amorphous profiles of its previous EVs. That aerodynamic efficiency is a big part of what delivers the 374-mile range for the single-motor CLA 250+ with EQ Technology model, the formal and long-winded designation for what I drove. It delivers 268 horsepower through the rear wheels. Those wanting a bit more oomph can step up to the 349-hp, dual-motor, all-wheel-drive 350 4MATIC model. That extra power and low-grip surety costs an extra $2,550, but the bigger penalty is range: the dual-motor model maxes out at 312 miles on a charge. (There is a hybrid version of the new CLA coming as well, but we'll cover that on its own later.)When it comes to charging, the new CLA impresses there, too. Charging at up to 320 kilowatts via the company's first NACS plug, the CLA adds a whopping 200 miles of range in 10 minutes. Weirdly, the car also has a separate, older-style J1772 plug for slower, level-two charging.Accessible, not basicThe interior displays of the 2026 Mercedes-Benz CLA 250+ EQTim Stevens for EngadgetAs a more attainable machine, you wouldn't necessarily expect the CLA to be completely loaded with features. Still, tick enough boxes and you can definitely get it there. While it doesn't have the luscious, curving Hyperscreen display as the EQS, it does offer a similar experience called Superscreen. You can get up to three displays spread across the dashboard: a 10.25-inch gauge cluster on the left, a 14-inch touchscreen in the center and an optional third display (also 14 inches) on the right for the passenger to play Angry Birds or stream videos. If, for some reason, they wouldn't rather just look at their phone.All those displays run the latest version of the MBUX user interface, similar to what we've seen in the company's other EVs, but it’s a bit simpler and easier to use here. That's backed by a wholly new system-level operating system called MB.OS running on NVIDIA silicon, also making its debut on the CLA. Mercedes says this not only has far more capability but can also be more comprehensively updated via the car's 5G connection. One of the features in the latest Mercedes software is baked-in AI. Say \"Hey, Mercedes,\" and you can not only change just about any setting in the car, but also engage in any number of inane conversations. I asked for a weather update for my next trip to Chicago, the latest releases from a few of my forgotten bands and even got an explanation of why the lyrics in the song \"Water's Edge\" by Seven Mary Three are so very creepy. (Don't go down there, friends.)It's all reasonably snappy and quite useful, but not perfect. When I said \"I'm hungry,\" I got a quick listing of restaurants and offers for quick routing. When I said, \"I need a hospital,\" the system, flummoxed, just stopped talking to me. Thankfully, I did not need a hospital. I was actually feeling pretty okay. That extensive software upgradability is also opening the door to a new era of car upgrades. Yes, the automotive DLC era is here, and you can pay extra to unlock additional active features like automated parking, navigation, a dashcam function and whatever else Mercedes-Benz's product planners can dream up in the future. Hopefully, there's no horse armor involved.We'll see how that shakes out, but my only real complaint about the interior was that it felt a bit cramped. It's a sedan on the small side, sure, but the layout feels a bit claustrophobic. That dashboard with all the displays is situated nearly vertically, as are the sides of the center console. Sitting in the passenger seat felt like being tucked in a box.Mind you, it was a very comfortable box, well-upholstered and featuring a lovely interior trim made of recycled paper, grooved to give the effect of a Zen garden. Headroom up front is generous and actually isn't too bad in the rear, but ducking under that sweeping roofline to get into the back seats requires a bit of flexibility.Drive time2026 Mercedes-Benz CLA 250+ EQTim Stevens for EngadgetDespite being the slowest electric CLA, this little sedan gets off the line quickly. A 6.6-second 0-to-60 time under-sells the feeling of instant acceleration and throttle response that make EVs so very compelling. You only start to feel the CLA's relative lack of horsepower at higher speeds, but even there, it's hardly lacking.That made it a blast to scoot from light to light as I was escaping from San Francisco, but it was much more fun in the foothills of Mt. Tamalpais. The CLA's steering is light yet has good feedback. I could really feel the road beneath the front tires, making for a more engaging machine than I was expecting.That battery pack in the floor keeps body roll in check, but a positively pliant suspension makes for a relaxed affair. The CLA did a great job of soaking up the countless imperfections in and around San Francisco, making for an extremely comfortable commuter, if one that felt a bit floaty at times.It'll be a safe commuter, too. The car is festooned with sensors, including 10 cameras of various resolutions and focal lengths, five radar sensors firing in every direction and 12 ultrasonic sensors. You'll need to pay extra for the digital keys to unlock their full functionality, though, like advanced lane-keeping and automated lane changes. There's even an advanced, point-to-point driver assistance system coming called MB.DRIVE Assist Pro that'll let the car handle most of the steering — even on secondary roads. More details on that to come. For now, the car did great at managing itself on the highway, changing lanes with enough initiative to get through commuter traffic without issue, and not only bringing itself to a complete stop in traffic, but resuming again as soon as the cars ahead moved.It even delivered good efficiency. I saw 3.9 miles per kWh, which would equate to a theoretical 331 miles from the 85 kWh battery pack. That's despite my driving with a good amount of enthusiasm and a heavy right foot. Edmunds, driving more conservatively, got 434 miles from a single charge,Wrap-up2026 Mercedes-Benz CLA 250+ EQTim Stevens for EngadgetSo the CLA looks great, drives well, has plenty of range and again, starting at $47,250, feels well-priced. Yes, you'll need to pay extra if you want to get all the toys, like the epic Dolby Atmos-capable Burmester sound system or the lovely Natural Fiber Zen interior trim. But when I ticked all the boxes I wanted, I still came out under $60,000. That put me about $5,000 below the base price of the company's next-bigger EV, the EQE.The CLA really is a big step forward on the EV front, and it’s a car that's hard to fault. The new CLA is hitting dealerships presently, and I have a feeling you'll be seeing plenty of them on the road soon.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/mercedes-benz-cla-first-drive-head-of-the-ev-class-140000562.html?src=rss",
          "feed_position": 21,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/2026_Mercedes-Benz_CLA_EQ_first_drive_012.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/tv-movies/fallout-season-2-review-viva-new-vegas-140000678.html",
          "published_at": "Tue, 16 Dec 2025 14:00:00 +0000",
          "title": "Fallout Season 2 review: Viva New Vegas",
          "standfirst": "The follow-up to a successful debut is often harder to make than the first, and that goes double when the inspiration for a show comes from the most beloved installment of the underlying franchise. That's precisely the challenge Fallout season 2 is facing as the TV series shifts its stage to the irradiated lights of New Vegas when the series returns on December 16 at 9PM ET/6PM PT on Prime Video. However, while other video game adaptations like The Last of Us suffered from a bit of a sophomore slump, Fallout continues to get more crass, vulgar and abrasive in the most entertaining ways. Editor's note: We were provided the first six of eight episodes of Fallout season 2 for this review, so if the ending of this season misses its landing, blame The Enclave. Season two picks up directly after the first as Lucy (played by Ella Purnelle) and The Ghoul (Walton Goggins) make their way across the wasteland in pursuit of Lucy's father. And right away, we're instantly reminded of the magnetic chemistry between our leading lady vault dweller and her endearing naivete and our post-apocalyptic cowboy afflicted with dark pragmatism from having simply lived through too much. This simple combo not only often provides the setup for Lucy's signature catchphrase — which is both quaint and refreshing — it also sets the stage for some interesting plot points. Just hearing The Ghoul say things like \"Do more drugs\" with Goggin's classic drawl and without a hint of irony is a real treat. There's never a dull moment when Lucy and The Ghoul are traveling together. Prime VideoOne of the potential pitfalls of a second season though, is an expanded storyline. That's because unlike the Fallout games where you get to steer the action, we're just here for the ride as we flip between Lucy's search for her father, the existential crises facing multiple vaults and an expanded role for Maximus (Aaron Moten) as he suddenly finds himself near the top of the Brotherhood of Steel's org chart. But somehow, the showrunners have managed to make each branching path just as engaging as the others. There were hints of his range in the first season, but Moises Arias shines as Lucy's brother Norm as the leader of a new crew (I'm trying to keep this review as spoiler-free as possible) while Annabel O'Hagan as Overseer Harper does a fantastic job of switching between being out of her depth and completely unhinged at a moment's notice. In season two, it feels like Aaron Moten's Maximus is so close to figuring out what kind of soldier he wants to be. Prime VideoThe one path that still feels like it hasn't fully hit its stride is Maximus', due in large part to the fact that the character's actions often feel like they are influenced more by circumstance than personal agency. In some ways, it's the continuation of someone defining their own morality, which rarely feels as convincing or driven as someone with a plan. But there's still intrigue there too.Meanwhile, for fans of the games, the number of easter eggs and callbacks is downright delightful. The set design and cinematography make the wasteland a character in its own right, even if the last thing I want to see is someone eat flea soup. We're also treated to an ever-growing zoography of nuclear critters such as rad scorpions, all sorts of mutants and more, along with appearances from iconic characters like everyone's favorite cowboy-coded security robot. And I appreciate how the show spends a little extra time to go over the myriad of factions (like The Legion and the NCR), which pays homage to the core series while functioning as an interesting side quest at the same time. With Overseer Harper at the helm, there's no telling what will happen to Vault 32. Prime VideoWith this much going on, it would be easy for a series to become overburdened. But the pacing isn't labored, because while the show doesn't actually get to New Vegas until episode four, the journey there was so entertaining that I didn't mind. Perhaps most importantly, even though it would be impossible to completely recreate New Vegas on TV (since you can’t choose your own adventure here like you can in the game), it really feels like Fallout's showrunners have nailed the balance between respecting the source material and tweaking the story to fit a different medium. That's a big credit to the franchise, especially coming from a genre that often gets maligned for a lack of depth or nuance. But it's also a tribute to this series, which continues to be a prime example of how to make the jump from pixels to TV screens look gook. And after seeing The Last of Us stumble a bit during its second cour, I might even go so far as to say that Fallout is the best live-action video game crossover to date. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/fallout-season-2-review-viva-new-vegas-140000678.html?src=rss",
          "content": "The follow-up to a successful debut is often harder to make than the first, and that goes double when the inspiration for a show comes from the most beloved installment of the underlying franchise. That's precisely the challenge Fallout season 2 is facing as the TV series shifts its stage to the irradiated lights of New Vegas when the series returns on December 16 at 9PM ET/6PM PT on Prime Video. However, while other video game adaptations like The Last of Us suffered from a bit of a sophomore slump, Fallout continues to get more crass, vulgar and abrasive in the most entertaining ways. Editor's note: We were provided the first six of eight episodes of Fallout season 2 for this review, so if the ending of this season misses its landing, blame The Enclave. Season two picks up directly after the first as Lucy (played by Ella Purnelle) and The Ghoul (Walton Goggins) make their way across the wasteland in pursuit of Lucy's father. And right away, we're instantly reminded of the magnetic chemistry between our leading lady vault dweller and her endearing naivete and our post-apocalyptic cowboy afflicted with dark pragmatism from having simply lived through too much. This simple combo not only often provides the setup for Lucy's signature catchphrase — which is both quaint and refreshing — it also sets the stage for some interesting plot points. Just hearing The Ghoul say things like \"Do more drugs\" with Goggin's classic drawl and without a hint of irony is a real treat. There's never a dull moment when Lucy and The Ghoul are traveling together. Prime VideoOne of the potential pitfalls of a second season though, is an expanded storyline. That's because unlike the Fallout games where you get to steer the action, we're just here for the ride as we flip between Lucy's search for her father, the existential crises facing multiple vaults and an expanded role for Maximus (Aaron Moten) as he suddenly finds himself near the top of the Brotherhood of Steel's org chart. But somehow, the showrunners have managed to make each branching path just as engaging as the others. There were hints of his range in the first season, but Moises Arias shines as Lucy's brother Norm as the leader of a new crew (I'm trying to keep this review as spoiler-free as possible) while Annabel O'Hagan as Overseer Harper does a fantastic job of switching between being out of her depth and completely unhinged at a moment's notice. In season two, it feels like Aaron Moten's Maximus is so close to figuring out what kind of soldier he wants to be. Prime VideoThe one path that still feels like it hasn't fully hit its stride is Maximus', due in large part to the fact that the character's actions often feel like they are influenced more by circumstance than personal agency. In some ways, it's the continuation of someone defining their own morality, which rarely feels as convincing or driven as someone with a plan. But there's still intrigue there too.Meanwhile, for fans of the games, the number of easter eggs and callbacks is downright delightful. The set design and cinematography make the wasteland a character in its own right, even if the last thing I want to see is someone eat flea soup. We're also treated to an ever-growing zoography of nuclear critters such as rad scorpions, all sorts of mutants and more, along with appearances from iconic characters like everyone's favorite cowboy-coded security robot. And I appreciate how the show spends a little extra time to go over the myriad of factions (like The Legion and the NCR), which pays homage to the core series while functioning as an interesting side quest at the same time. With Overseer Harper at the helm, there's no telling what will happen to Vault 32. Prime VideoWith this much going on, it would be easy for a series to become overburdened. But the pacing isn't labored, because while the show doesn't actually get to New Vegas until episode four, the journey there was so entertaining that I didn't mind. Perhaps most importantly, even though it would be impossible to completely recreate New Vegas on TV (since you can’t choose your own adventure here like you can in the game), it really feels like Fallout's showrunners have nailed the balance between respecting the source material and tweaking the story to fit a different medium. That's a big credit to the franchise, especially coming from a genre that often gets maligned for a lack of depth or nuance. But it's also a tribute to this series, which continues to be a prime example of how to make the jump from pixels to TV screens look gook. And after seeing The Last of Us stumble a bit during its second cour, I might even go so far as to say that Fallout is the best live-action video game crossover to date. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/fallout-season-2-review-viva-new-vegas-140000678.html?src=rss",
          "feed_position": 22,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/FalloutS2FLimage1_3000.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-121547853.html",
          "published_at": "Tue, 16 Dec 2025 12:15:47 +0000",
          "title": "The Morning After: Roomba maker iRobot files for bankruptcy",
          "standfirst": "iRobot, the company that brought robotic vacuum cleaners to homes and popular culture, has filed for bankruptcy. It plans to sell all assets to its primary supplier, the Chinese company Picea Robotics. Investors “will experience a total loss and not receive recovery on their investment” if the deal is approved, iRobot said. The company didn’t discuss how the move might affect its employees in the US or elsewhere. Amazon dropped its $1.7 billion acquisition of the company last year after a veto threat from European regulators, leaving the Roomba maker with no other option. Political scrutiny came on two fronts: The company was also reportedly hit hard by Trump’s tariffs in Vietnam, where it manufactures products for the US market. iRobot launched its first Roomba in 2002, arguably inventing the world of robot vacuums — and the first robots to enter many of our homes. Competition from rivals has chipped away at its dominance, with other companies coming in at both lower and higher prices, like Roborock, Dyson and Anker’s Eufy. — Mat Smith The other big stories this morning In 2025, tech giants decided smart glasses are the next big thing Grok is spreading inaccurate info again, this time about the Bondi Beach shooting 47 Ronin director found guilty of defrauding Netflix out of $11 million The best things Engadget editors bought in 2025 IKEA’s new wireless charger is cute I like the illuminated charging bowl too. IKEA IKEA’s revamp of its smart home products doesn’t end with Matter support. It also has some new Qi wireless chargers. First up, the $10 VÄSTMÄRKE combines a PopSockets-style phone grip with cable storage in a donut-shaped package. It can magnetically attach to iPhones with MagSafe or Pixel phones with Google’s Pixelsnap magnets. Then there’s the $25 VÄSTMÄRKE wireless charger with lighting, a bowl-shaped charging pad in the center for your smartphone or wireless earbuds. Continue reading. LG will debut its first Micro RGB television at CES More color and better dimming than a standard LCD. LG says it will unveil its LG Micro RGB evo TV at CES 2026, but ahead of that, it shared some preliminary information about the screen. Instead of just white lights, Micro RGB means the backlight can be any hue, thanks to individually controlled red, green and blue Micro LEDs, offering a wider color array. This approach is midway between OLED’s individual-pixel lighting and TVs that use typical mini-LEDs. Continue reading. ‘Slop’ is Merriam-Webster’s word of the year 2025 saw AI slop sludge into every nook and cranny of online life. OpenAI Merriam-Webster has selected “slop” for its 2025 word of the year. It’s defined as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.” We’ve seen an absolute deluge of AI slop this year, from fake movie trailers on YouTube to AI-generated bands on Spotify. It was (unfortunately) one of our winners of 2025. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-121547853.html?src=rss",
          "content": "iRobot, the company that brought robotic vacuum cleaners to homes and popular culture, has filed for bankruptcy. It plans to sell all assets to its primary supplier, the Chinese company Picea Robotics. Investors “will experience a total loss and not receive recovery on their investment” if the deal is approved, iRobot said. The company didn’t discuss how the move might affect its employees in the US or elsewhere. Amazon dropped its $1.7 billion acquisition of the company last year after a veto threat from European regulators, leaving the Roomba maker with no other option. Political scrutiny came on two fronts: The company was also reportedly hit hard by Trump’s tariffs in Vietnam, where it manufactures products for the US market. iRobot launched its first Roomba in 2002, arguably inventing the world of robot vacuums — and the first robots to enter many of our homes. Competition from rivals has chipped away at its dominance, with other companies coming in at both lower and higher prices, like Roborock, Dyson and Anker’s Eufy. — Mat Smith The other big stories this morning In 2025, tech giants decided smart glasses are the next big thing Grok is spreading inaccurate info again, this time about the Bondi Beach shooting 47 Ronin director found guilty of defrauding Netflix out of $11 million The best things Engadget editors bought in 2025 IKEA’s new wireless charger is cute I like the illuminated charging bowl too. IKEA IKEA’s revamp of its smart home products doesn’t end with Matter support. It also has some new Qi wireless chargers. First up, the $10 VÄSTMÄRKE combines a PopSockets-style phone grip with cable storage in a donut-shaped package. It can magnetically attach to iPhones with MagSafe or Pixel phones with Google’s Pixelsnap magnets. Then there’s the $25 VÄSTMÄRKE wireless charger with lighting, a bowl-shaped charging pad in the center for your smartphone or wireless earbuds. Continue reading. LG will debut its first Micro RGB television at CES More color and better dimming than a standard LCD. LG says it will unveil its LG Micro RGB evo TV at CES 2026, but ahead of that, it shared some preliminary information about the screen. Instead of just white lights, Micro RGB means the backlight can be any hue, thanks to individually controlled red, green and blue Micro LEDs, offering a wider color array. This approach is midway between OLED’s individual-pixel lighting and TVs that use typical mini-LEDs. Continue reading. ‘Slop’ is Merriam-Webster’s word of the year 2025 saw AI slop sludge into every nook and cranny of online life. OpenAI Merriam-Webster has selected “slop” for its 2025 word of the year. It’s defined as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.” We’ve seen an absolute deluge of AI slop this year, from fake movie trailers on YouTube to AI-generated bands on Spotify. It was (unfortunately) one of our winners of 2025. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-121547853.html?src=rss",
          "feed_position": 28,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/d99e51c1-da6c-11f0-9ffd-3e161c9efe47"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-mobile-microphones-for-recording-with-a-phone-154536629.html",
          "published_at": "Tue, 16 Dec 2025 10:01:25 +0000",
          "title": "The best mobile microphones for 2026",
          "standfirst": "There’s nothing more frustrating than shooting the perfect reel only to realize that the audio sounds like garbage. For budding creators, it’s a frustration; for those looking to make more professional content, it’s a dealbreaker. Fortunately, the world of mobile-specific (or phone-friendly) microphones has exploded with great options in the last few years. Whether you’ve been tasked with recording candid moments at a relative’s wedding, shooting a friend’s dance moves or are a journalist out in the field traveling light — there’s an option out there that will be perfect for you.We’ve tested a wide range of popular microphones with a mobile focus so that you don’t have to. Below is our hand-picked list of the very best options for a variety of use cases. Some microphones — the wireless lavalier kind, for example — will be more versatile and convenient, useful for a number of different applications. Others, such as our musician or field-recording picks, are where we explore more exotic form factors such as shotgun mics and mobile-friendly desktop options. As always, above everything else is sound quality and general performance. The good news for you is that we’ve done all the hard work for you. Happy recording! Best phone mics for 2026: Best wireless mics for creators “Creator” is a broad term, but for the purposes of this guide, it’s anyone that wants to make videos or recordings to share on the internet. This is possibly the most exciting category right now with excellent options from brands such as Rode and DJI, but also some compelling budget options too. Once the domain of TV and pro productions, wireless lavalier mics are now the go-to choice for anyone creating in front of (or even behind) the camera. They usually sound great, offer hands-free flexibility and premium models come with extra features that will streamline your creative process. How we test mobile microphones The world of mobile microphones has exploded in recent years thanks to affordable, high-quality wireless systems, the popularity of social media and content creation and, of course, Apple’s reluctant switch to USB-C on the iPhone which has removed connectivity complications for manufacturers. When it comes to testing, my experience as a journalist, podcast producer, YouTuber and (failing) music producer has given me a lot of real-world experience with a wide variety of products all aimed at different jobs. When compiling this guide for Engadget, I filter that experience down to a few simple criteria that allows us to focus on what’s important to you, the reader and whatever it is you’re trying to record. The main criteria for mobile microphones are simple: Does it sound great? Does it connect to a phone directly and reliably? And, is it good value for its intended purpose? A hobbyist and a professional have different budgets after all. What every microphone endures is repeated recording in treated, non-treated and outdoor environments. I’ll also A/B test each one against its rivals and usually a suitable reference microphone — Shure’s SM7b for podcasting microphones or Rode’s NTG 5 for shotgun/video mics, for example. Some sub-categories of microphone require a slightly different approach. For wireless systems, I test how far I can walk from the receiver before recordings degrade, along with a standard battery life test by setting them to record until they power off. For podcast and vocal-focused microphones, I record in different spaces to see how they cope with different environments and measure self noise (recording “silence”). Lastly, I test how they sound when recording at different distances from the microphone.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-mobile-microphones-for-recording-with-a-phone-154536629.html?src=rss",
          "content": "There’s nothing more frustrating than shooting the perfect reel only to realize that the audio sounds like garbage. For budding creators, it’s a frustration; for those looking to make more professional content, it’s a dealbreaker. Fortunately, the world of mobile-specific (or phone-friendly) microphones has exploded with great options in the last few years. Whether you’ve been tasked with recording candid moments at a relative’s wedding, shooting a friend’s dance moves or are a journalist out in the field traveling light — there’s an option out there that will be perfect for you.We’ve tested a wide range of popular microphones with a mobile focus so that you don’t have to. Below is our hand-picked list of the very best options for a variety of use cases. Some microphones — the wireless lavalier kind, for example — will be more versatile and convenient, useful for a number of different applications. Others, such as our musician or field-recording picks, are where we explore more exotic form factors such as shotgun mics and mobile-friendly desktop options. As always, above everything else is sound quality and general performance. The good news for you is that we’ve done all the hard work for you. Happy recording! Best phone mics for 2026: Best wireless mics for creators “Creator” is a broad term, but for the purposes of this guide, it’s anyone that wants to make videos or recordings to share on the internet. This is possibly the most exciting category right now with excellent options from brands such as Rode and DJI, but also some compelling budget options too. Once the domain of TV and pro productions, wireless lavalier mics are now the go-to choice for anyone creating in front of (or even behind) the camera. They usually sound great, offer hands-free flexibility and premium models come with extra features that will streamline your creative process. How we test mobile microphones The world of mobile microphones has exploded in recent years thanks to affordable, high-quality wireless systems, the popularity of social media and content creation and, of course, Apple’s reluctant switch to USB-C on the iPhone which has removed connectivity complications for manufacturers. When it comes to testing, my experience as a journalist, podcast producer, YouTuber and (failing) music producer has given me a lot of real-world experience with a wide variety of products all aimed at different jobs. When compiling this guide for Engadget, I filter that experience down to a few simple criteria that allows us to focus on what’s important to you, the reader and whatever it is you’re trying to record. The main criteria for mobile microphones are simple: Does it sound great? Does it connect to a phone directly and reliably? And, is it good value for its intended purpose? A hobbyist and a professional have different budgets after all. What every microphone endures is repeated recording in treated, non-treated and outdoor environments. I’ll also A/B test each one against its rivals and usually a suitable reference microphone — Shure’s SM7b for podcasting microphones or Rode’s NTG 5 for shotgun/video mics, for example. Some sub-categories of microphone require a slightly different approach. For wireless systems, I test how far I can walk from the receiver before recordings degrade, along with a standard battery life test by setting them to record until they power off. For podcast and vocal-focused microphones, I record in different spaces to see how they cope with different environments and measure self noise (recording “silence”). Lastly, I test how they sound when recording at different distances from the microphone.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-mobile-microphones-for-recording-with-a-phone-154536629.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/black-box-ai-isnt-enough-why-enterprise-consulting-is-moving-to-grounded",
          "published_at": "Tue, 16 Dec 2025 05:00:00 GMT",
          "title": "Black box AI isn’t enough: Why enterprise consulting is moving to grounded models",
          "standfirst": "Presented by SAPIn an era where anyone can spin up an LLM, the real differentiator isn’t the AI technology itself, but the institutional knowledge it’s grounded in. Internal and partner consultants leading operational transformation can’t risk hallucinated guidance when their recommendations impact integrated processes across supply chain, manufacturing, finance, and other core functions. \"Grounded AI is non-negotiable, because accuracy isn’t optional when we’re doing million-dollar transformation projects within the SAP ecosystem, for example,\" says Natalie Han, VP and chief product officer, gen AI at SAP Business AI. \"Retrieval-augmented generation technology, and the ability to anchor responses in trusted enterprise knowledge, helps ensure accurate code interpretation, best-practice guidance, and clean-core decision support. It&#x27;s how we bring real trust into AI-powered consulting.\"A fully grounded AI assistant like SAP Joule for Consultants has tremendous value in production use cases, she adds. SAP Joule has terabytes of institutional data that&#x27;s continuously curated and updated, so a consultant is assured they&#x27;re getting up-to-the-minute SAP best practices and methodologies when relying on Joule, while at the same time accelerating project delivery. \"We’re saving rework time by 14%, and saving consultants 1.5 hours per day per user, which is huge when you consider how expensive consultants are now,\" Han says. \"Early adopters like Wipro have estimated they&#x27;ve saved 7 million hours on a manual basis for their consultants.\"The foundation of SAP JouleSAP Joule is as certified as any consultant, says Sachin Kaura, chief architect, SAP Business AI. The tool was born in 2023, when GPTs famously passed a simulated bar exam and ignited buzz around the ability of LLMs to handle large amounts of context. It is widely acknowledged that the SAP ecosystem, along with its associated domain ontology and taxonomy, is incredibly vast and can be very complex to navigate. The question became, how could an AI co-pilot be used to navigate that complexity when it was actually grounded within the SAP ecosystem itself? Sachin Kaura began experimenting with frontier LLM models by putting them through the same certification exams SAP consultants take. The early results were poor, but after extensive context tuning and a focus on delivering value to the partner ecosystem, Joule now consistently scores 95% or higher.\"Not only were we testing from a data perspective, but we were able to work with all of our consultants to get what we call the golden data set,\" Han added. \"It’s non-deterministic, language-based, and thoroughly grounded in human consultant expertise. We partnered with the whole consulting organization to manually label the golden data set across all of the products. That’s become the foundation for everything we do even now.\"A state-of-the-art indexing pipelineJoule for Consultants stays up-to-date in real time. A state-of-the-art indexing pipeline pushes new SAP documentation and release content into the model as soon as it’s published, giving consultants confidence that every answer reflects the most current guidance.\"This is pure engineering work done by our data scientists and engineers, using a lot of underlying SAP technology,\" Kaura explains. \"We leverage the SAP business foundation layer, document grounding services, and a lot of purpose-built systems to stay on top of current events in the system.\"SAP Business AI also has board-level alignment, ensuring this isn’t just a one-team effort but a company-wide priority. They’ve built strong internal partnerships with content owners across SAP — including SAP Learning, SAP Community, SAP Help, product teams, and consultant teams. Together, they continuously update proprietary content such as SAP Notes, Knowledge Base Articles (KBAs), and other domain-specific guidance that reflects SAP’s evolving best practices.All of this means Joule for Consultants can take that continuously refreshed data and deliver answers in near real time. It&#x27;s the kind of research that would otherwise take a consultant hours. But information pulled directly from the source gives consultants the most current and authoritative guidance available, helping eliminate the early-stage missteps that can derail a project months later when scoping wasn’t aligned with the latest capabilities.Ensuring enterprise-grade security SAP is building a product that is relevant, reliable, and responsible, Han says. As a company founded in Europe, it takes data privacy seriously, adhering to the GDPR and other EU company regulations. At the core of SAP Business AI is the AI Foundation, the AI operating system that governs AI with built-in security, ethics, and orchestration, using automation and intelligence to manage lifecycles, optimize resources, and boost resilience.All the LLMs SAP and its customers use operate within the AI foundation, which protects private and proprietary data from being leaked. Beyond data protection, SAP treats bias, ethics, and security at an enterprise level as well, with humans in the loop to run checks and balances.\"We have an enterprise-grade security framework as well as prompt injection and guardrail testing,\" Kaura says. \"The orchestration layer, built within the AI Foundation, anonymizes inputs as well as moderates them to prevent malicious content. That ensures that the output we give to our customers is relevant to the SAP ecosystem, relevant to the domain they’re asking about, and not just generic LLM excess. This set of tools, from the framework layer to the application layer to the product standards, and also the very thorough testing is critical to securing our product. Then and only then can it reach our customers and partners.\"Pushing the limits of Joule for Consultants\"We’re barely scratching the surface of what LLMs and agentic AI can offer,\" Han says. \"Accessing knowledge is just the beginning. We’re going to have a much deeper understanding of customers’ SAP systems and be able to help them implement and transform their journey. The product team and our engineers are working to make the tool more transformative, able to unearth more insights, connect with customers’ systems, and understand and optimize their processes, including generating code and handling customer code migration.\" The next step is adding a second layer of grounding. SAP’s customer base is vast, and its partner ecosystem has implemented countless business scenarios. Grounding Joule in SAP’s institutional knowledge was the first milestone; the next is layering in each customer’s own proprietary context — historical system data, process designs, implementation blueprints, and internal documentation. This turns Joule from SAP-aware to customer-aware, delivering guidance that aligns with how a business actually operates.“Think of it as grounding your knowledge on top of SAP knowledge — giving you more accurate and relevant guidance,” Kaura says. “Information that might otherwise be lost can sit on top of Joule for Consultants. Our system processes it and ensures it comes to you in the right manner and at the right time.”This expanded grounding also lets Joule adjust its guidance to the consultant’s role — whether they’re working as an architect, a functional consultant, or a technical consultant.\"We deliver the information they need for a particular customer configuration,\" Han explains. \"Then we can not only answer generic questions, but we can answer their particular configuration. From there it’s one step ahead to generating more insights and taking more actions.\"Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by SAPIn an era where anyone can spin up an LLM, the real differentiator isn’t the AI technology itself, but the institutional knowledge it’s grounded in. Internal and partner consultants leading operational transformation can’t risk hallucinated guidance when their recommendations impact integrated processes across supply chain, manufacturing, finance, and other core functions. \"Grounded AI is non-negotiable, because accuracy isn’t optional when we’re doing million-dollar transformation projects within the SAP ecosystem, for example,\" says Natalie Han, VP and chief product officer, gen AI at SAP Business AI. \"Retrieval-augmented generation technology, and the ability to anchor responses in trusted enterprise knowledge, helps ensure accurate code interpretation, best-practice guidance, and clean-core decision support. It&#x27;s how we bring real trust into AI-powered consulting.\"A fully grounded AI assistant like SAP Joule for Consultants has tremendous value in production use cases, she adds. SAP Joule has terabytes of institutional data that&#x27;s continuously curated and updated, so a consultant is assured they&#x27;re getting up-to-the-minute SAP best practices and methodologies when relying on Joule, while at the same time accelerating project delivery. \"We’re saving rework time by 14%, and saving consultants 1.5 hours per day per user, which is huge when you consider how expensive consultants are now,\" Han says. \"Early adopters like Wipro have estimated they&#x27;ve saved 7 million hours on a manual basis for their consultants.\"The foundation of SAP JouleSAP Joule is as certified as any consultant, says Sachin Kaura, chief architect, SAP Business AI. The tool was born in 2023, when GPTs famously passed a simulated bar exam and ignited buzz around the ability of LLMs to handle large amounts of context. It is widely acknowledged that the SAP ecosystem, along with its associated domain ontology and taxonomy, is incredibly vast and can be very complex to navigate. The question became, how could an AI co-pilot be used to navigate that complexity when it was actually grounded within the SAP ecosystem itself? Sachin Kaura began experimenting with frontier LLM models by putting them through the same certification exams SAP consultants take. The early results were poor, but after extensive context tuning and a focus on delivering value to the partner ecosystem, Joule now consistently scores 95% or higher.\"Not only were we testing from a data perspective, but we were able to work with all of our consultants to get what we call the golden data set,\" Han added. \"It’s non-deterministic, language-based, and thoroughly grounded in human consultant expertise. We partnered with the whole consulting organization to manually label the golden data set across all of the products. That’s become the foundation for everything we do even now.\"A state-of-the-art indexing pipelineJoule for Consultants stays up-to-date in real time. A state-of-the-art indexing pipeline pushes new SAP documentation and release content into the model as soon as it’s published, giving consultants confidence that every answer reflects the most current guidance.\"This is pure engineering work done by our data scientists and engineers, using a lot of underlying SAP technology,\" Kaura explains. \"We leverage the SAP business foundation layer, document grounding services, and a lot of purpose-built systems to stay on top of current events in the system.\"SAP Business AI also has board-level alignment, ensuring this isn’t just a one-team effort but a company-wide priority. They’ve built strong internal partnerships with content owners across SAP — including SAP Learning, SAP Community, SAP Help, product teams, and consultant teams. Together, they continuously update proprietary content such as SAP Notes, Knowledge Base Articles (KBAs), and other domain-specific guidance that reflects SAP’s evolving best practices.All of this means Joule for Consultants can take that continuously refreshed data and deliver answers in near real time. It&#x27;s the kind of research that would otherwise take a consultant hours. But information pulled directly from the source gives consultants the most current and authoritative guidance available, helping eliminate the early-stage missteps that can derail a project months later when scoping wasn’t aligned with the latest capabilities.Ensuring enterprise-grade security SAP is building a product that is relevant, reliable, and responsible, Han says. As a company founded in Europe, it takes data privacy seriously, adhering to the GDPR and other EU company regulations. At the core of SAP Business AI is the AI Foundation, the AI operating system that governs AI with built-in security, ethics, and orchestration, using automation and intelligence to manage lifecycles, optimize resources, and boost resilience.All the LLMs SAP and its customers use operate within the AI foundation, which protects private and proprietary data from being leaked. Beyond data protection, SAP treats bias, ethics, and security at an enterprise level as well, with humans in the loop to run checks and balances.\"We have an enterprise-grade security framework as well as prompt injection and guardrail testing,\" Kaura says. \"The orchestration layer, built within the AI Foundation, anonymizes inputs as well as moderates them to prevent malicious content. That ensures that the output we give to our customers is relevant to the SAP ecosystem, relevant to the domain they’re asking about, and not just generic LLM excess. This set of tools, from the framework layer to the application layer to the product standards, and also the very thorough testing is critical to securing our product. Then and only then can it reach our customers and partners.\"Pushing the limits of Joule for Consultants\"We’re barely scratching the surface of what LLMs and agentic AI can offer,\" Han says. \"Accessing knowledge is just the beginning. We’re going to have a much deeper understanding of customers’ SAP systems and be able to help them implement and transform their journey. The product team and our engineers are working to make the tool more transformative, able to unearth more insights, connect with customers’ systems, and understand and optimize their processes, including generating code and handling customer code migration.\" The next step is adding a second layer of grounding. SAP’s customer base is vast, and its partner ecosystem has implemented countless business scenarios. Grounding Joule in SAP’s institutional knowledge was the first milestone; the next is layering in each customer’s own proprietary context — historical system data, process designs, implementation blueprints, and internal documentation. This turns Joule from SAP-aware to customer-aware, delivering guidance that aligns with how a business actually operates.“Think of it as grounding your knowledge on top of SAP knowledge — giving you more accurate and relevant guidance,” Kaura says. “Information that might otherwise be lost can sit on top of Joule for Consultants. Our system processes it and ensures it comes to you in the right manner and at the right time.”This expanded grounding also lets Joule adjust its guidance to the consultant’s role — whether they’re working as an architect, a functional consultant, or a technical consultant.\"We deliver the information they need for a particular customer configuration,\" Han explains. \"Then we can not only answer generic questions, but we can answer their particular configuration. From there it’s one step ahead to generating more insights and taking more actions.\"Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7qgqONMtKtXQLPIpAHmJcz/08126cd291920b5ce60125a0c59f7129/AdobeStock_734215442.jpeg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/lg-will-debut-its-first-micro-rgb-television-at-ces-010037923.html",
          "published_at": "Tue, 16 Dec 2025 01:00:37 +0000",
          "title": "LG will debut its first Micro RGB television at CES",
          "standfirst": "LG is getting in on one of the newest trends for televisions with the introduction of Micro RGB. The company will unveil the LG Micro RGB evo at CES 2026, but it shared some preliminary information about the screen today. Micro RGB is a newer screen technology where rather than white lights, the backlight can be any hue thanks to individually controlled red, green and blue Micro LEDs, offering a wider color array. This approach is a mid-way point between the precision of OLED with its individual pixel lighting, but it offers an upgrade over screens only using mini LEDs. The television is also equipped with an upgraded engine for AI upscaling. According to the company's press release, the LG Micro RGB evo is certified by Intertek for 100 percent color gamut coverage in BT.2020, DCI-P3, and Adobe RGB. The TV has more than a thousand dimming zones for brightness control. The few other brands currently using micro RGB are charging a pretty penny for it; the one announced by Samsung earlier this year costs $29,999. At 115 inches, the Samsung version is also much larger than LG's offerings, which include options at 100 inches, 86 inches and 75 inches. Although the size is reduced, expect the eventual prices for the LG Micro RGB evo to also be very expensive.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-will-debut-its-first-micro-rgb-television-at-ces-010037923.html?src=rss",
          "content": "LG is getting in on one of the newest trends for televisions with the introduction of Micro RGB. The company will unveil the LG Micro RGB evo at CES 2026, but it shared some preliminary information about the screen today. Micro RGB is a newer screen technology where rather than white lights, the backlight can be any hue thanks to individually controlled red, green and blue Micro LEDs, offering a wider color array. This approach is a mid-way point between the precision of OLED with its individual pixel lighting, but it offers an upgrade over screens only using mini LEDs. The television is also equipped with an upgraded engine for AI upscaling. According to the company's press release, the LG Micro RGB evo is certified by Intertek for 100 percent color gamut coverage in BT.2020, DCI-P3, and Adobe RGB. The TV has more than a thousand dimming zones for brightness control. The few other brands currently using micro RGB are charging a pretty penny for it; the one announced by Samsung earlier this year costs $29,999. At 115 inches, the Samsung version is also much larger than LG's offerings, which include options at 100 inches, 86 inches and 75 inches. Although the size is reduced, expect the eventual prices for the LG Micro RGB evo to also be very expensive.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-will-debut-its-first-micro-rgb-television-at-ces-010037923.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/the-best-christmas-gift-ideas-everyone-on-your-2025-holiday-shopping-list-will-love-170018978.html",
          "published_at": "Mon, 15 Dec 2025 21:01:40 +0000",
          "title": "The best Christmas gift ideas everyone on your 2025 holiday shopping list will love",
          "standfirst": "This time of year has a lot of merry and bright things to be excited about, but it can be stressful if you’re stumped on what to get your mom, dad, best friend, coworker or kids’ teacher as a holiday gift. Whether you enjoy or dread buying gifts for people, it’s safe to say we all want to give our loved ones things they will enjoy and appreciate. But there’s a lot of noise, junk and bad deals disguised as good deals to sift through as we get closer and closer to the holidays.Allow us at Engadget to help you through it. Here, you’ll find all of our holiday gift guides collected in one place, so you can more easily find the best Christmas gifts you need this year. Are you looking for white elephant gift ideas? Are you struggling to come up with a good gift for the father figure in your life? Are you just looking for a good board game to pick up for your own family? We’ve got you covered with gift ideas for all of those scenarios and more. Best white elephant gift ideas According to legend, the King of Siam would give a white elephant to courtiers who had upset them. The recipient had no choice but to simply thank the king for such an opulent gift, knowing that they likely could not afford the upkeep for such an animal. It would inevitably lead them to financial ruin. This story is almost certainly untrue, but it has led to a modern holiday staple: the white elephant gift exchange. These gift ideas will not only get you a few chuckles, but will also make your recipient feel (slightly) burdened. Read more: The best white elephant gift ideas Best Secret Santa gifts Secret Santa gift exchanges are supposed to be fun, but it’s easy to overthink it. You want a gift that feels thoughtful without being awkward, useful without being boring, and most importantly, affordable. The sweet spot is under $50, which is plenty to find something that fits your recipient’s personality. Whether you’re buying for a co-worker you only chat with at the coffee machine, a friend who already has everything or a cousin who never gives you ideas, there are clever options that will make them smile. Read more: The best Secret Santa gift ideas Best tech gifts and gadgets Trying to find the right gift for an unabashed gadget lover during the holidays can be difficult, especially if you don’t keep up with tech industry news yourself. Fortunately, you’re reading Engadget.com, a site entirely staffed by people who spend all day figuring out what new stuff is and isn’t actually good. So allow us to help. We’ve rounded up some of our favorite gadgets and gear that just might satisfy the avid geek in your life. Read more: The best tech gifts and gadgets Best board game gifts We could all use more time away from screens of all types and sizes, and board games are a fun way to do that and bond with friends and family. You can find plenty of unique sets out there now, from word puzzles to whodunnits to calming playthroughs that showcase the beauty of the little things in life. From games with giant monsters to those with haunted mansions, we’re sure at least one of our suggestions will be a hit with you and your loved ones. Read more: The best board games to gift this season Best gifts for $25 or less So you want to give someone a gift but you don’t have a ton of cash to spare. Don’t fret because first, you’re not alone, and second, there are tons of options to choose from. Especially if you’re looking in the tech space, it can feel especially daunting to find a gadget that’s affordable but also worth gifting — in other words, not a piece of junk that will eventually take up residence at the bottom of a drawer. But you don’t have to drain your wallet to get someone a cool gadget that will both be useful and make their lives easier. We’ve collected our favorite pieces of tech under $25 that make great gifts and help you to stick to a budget. Read more: The best gifts for $25 or less Best gifts under $50 We wouldn’t blame you if you try to do all of your tech shopping around the holidays. That’s when you can typically get the best sales, both on relatively affordable gear and (more importantly) on big-ticket items. But it would be wrong to think that only the most expensive tech is worth gifting. Since we at Engadget test a plethora of gadgets every year, we know that there are some hidden (and not so hidden) tech gems at lower price ranges — you just have to know where to find them. Read more: The best gifts under $50 that make great stocking stuffers Best gifts under $100 Finding a gift for the tech nerd on your list can be tough. They likely have all the tech they need and then some, but you can add to their kit with the right accessories. Apple, Samsung, Sony and other big tech companies all have affordable gear that comes in at $100 or less, you just have to know where to look. We've collected some of our favorites, but remember: you can often find alternatives that are just as good (and sometimes better) than these. However, for the people in your life for which brand names really do matter, these gifts will speak to them. Read more: The best tech gifts under $100 Best tech toys for kids We know it’s been a pretty crazy year that’s got you wondering how exactly you’re going to make the holiday season extra special, especially for the kids in your life. The good news is that the toy industry is just as creative as ever, and this year’s crop of hot tech toys is filled with plenty of surprise and delight, all at affordable prices. We’ve picked some of our favorites under $100, ones that will not only thrill right out of the box, but keep the kids entertained for months to come. Read more: The best tech toys for kids Best gifts for remote workers There's a pretty good chance you know at least one person who works remotely in some fashion. While the WFH life has its perks — nobody likes a long commute — it comes with its own set of challenges, from lacking pro-level equipment to dealing with household disturbances. If you’re looking to give a gift to someone who spends much of their time in their home office, we’ve rounded up a few techy gift ideas that should make their days a little more delightful, or at least easier to manage. Read more: The best gift ideas for the remote worker in your life Best travel gifts For as long as humans have traveled, they've carried gear with them to make long journeys easier. Airplanes may have made travel faster, but crossing states and countries can still be exhausting. If you have a friend or family member who loves exploring the world, they'll appreciate things that will save them stress when they're far from home. So let Engadget help you find the perfect gift for the person in your life with wanderlust. Read more: The best gifts for travelers Best gifts for Nintendo lovers If you're like us, Nintendo holds a special place in your heart thanks to iconic characters like Mario, Peach and Donkey Kong and multiple generations of best-selling consoles. But little did we know that outside of gaming hardware and accessories, there's an ever-growing assortment of Nintendo-themed toys, clothes and decor. And it's kind of a problem because we want all of it. So to help you figure out the best gifts for the Nintendo fan in your life, we've put together a big list of our favorite products that will give anyone a power-up this holiday season. Of course, if none of the ones on our list quite fit the bill, you can also head over to our full list of the best Nintendo Switch 2 accessories for even more ideas. Read more: The best Nintendo gifts for the holiday season Best retro gaming gifts The stream of new video games never ends, but for some of us, nothing beats the classics. If you don’t feel like hunting through eBay and local game shops for old cartridges to add to your loved one’s collection, we’ve picked out a few other gift ideas for the nostalgic gamer in your life — from video upscalers for old consoles to retro-themed books and artwork. Read more: The best retro gaming gifts for the holidays Best gifts for gamers The year may not be over, but 2025 is all but guaranteed to go down as one of the best 12 months in gaming history. Between releases like Hades 2, Hollow Knight: Silksong and Ghost of Yotei, to name just a few, there was truly something for everyone in 2025. Of course, that abundance also means it can be tricky to find a gift for the gamers in your life, especially if you're not one yourself. Worry not — Engadget is here to help. We guarantee our guide will help you find the perfect gift for your friend or loved one. Read more: The best gifts for gamers Best gifts for moms Some moms really do mean it when they say they don’t need any gifts. But those same moms will probably appreciate getting something thoughtful and personal — a gift that shows you put in a bit of consideration. It’s tough to pin-point what that ideal gift is for any given mom, but we’ve got ideas to get you started. Since we spend our days testing and otherwise thinking about tech, most of the presents here have a gadget spin, but all of them are a heck of a lot more unique than a candle and a bath bomb. Read more: The best gifts for mom Best gifts for dads It's not always easy to find gifts for dads, especially for those who are often quick to snap up whatever they need on their own. But even the geekiest and most well-informed dads have blind spots — the trick is to find something they've never heard of, but could actually make their lives useful. We've collected some of our favorite dadcore gift ideas, which would suit everyone from a complete gadgetphobe to a total techie. Read more: The best gifts for dads Best subscription box gifts Subscription boxes are the rare gift that keeps its charm long after the wrapping paper is gone. You make the choice once, but the surprises keep landing on their doorstep for months after that. For anyone who loves the buzz of a delivery, these are gifts that extend the season well past December. Each box on this list combines a bit of discovery with something tangible, such as gadgets, books, collectibles, snacks or clever projects. Some appeal to hardcore hobbyists, others to the curious or the comfort seekers, but all offer that same spark of delight that comes from unboxing something unexpected. Read more: The best subscription box gifts Best gifts for home cooks For home cooks, kitchen tools are the equipment that make all your favorite dishes and meals possible. And while having the fanciest gear certainly isn't a requirement, it is really nice, which makes products like the ones here such great gifts. These are the kind of things that people want but might not be able to justify buying for themselves, or essential pieces that would be handy additions to any kitchen or pantry. So if you're looking for present ideas for the chef in your life, check out our guide of tried and tested cooking tools and gadgets. Read more: The best cooking gifts Best gifts for coffee lovers When it comes to making coffee at home, us coffee nerds are constantly evolving. Whether the person you’re shopping for is newly indoctrinated into the world of small-batch roasters or obsessive over every possible aspect of every brewing process, we’ve compiled a list of the best coffee gear for any coffee geek this holiday season. For brewing, grinding and drinking, we’ve got multiple options at a range of prices to help expand any java geek’s horizons. And if you think the coffee aficionado on your list already has everything they need, we’ve got a recommendation for them too. Read more: The best gifts for coffee lovers Best gadgets for your pets We're a pet-loving staff here at Engadget, with diverse distribution of cat people, dog people, other-small-fuzzy-creature people, bird feeder enjoyers and so on (at press time, I'm unsure if we have a rat person, but I'd be surprised if we didn't). And, of course, we love getting new gadgets of all sorts for our pets as much as for ourselves. Our list, with gifts as low-tech as a blanket and as high-tech as the best $30 two-way camera you'll ever use, is for the pet lover in your life — whether that's you or another favorite human. Read more: The best gadgets for your pets Check out the rest of our gift ideas here.This article originally appeared on Engadget at https://www.engadget.com/the-best-christmas-gift-ideas-everyone-on-your-2025-holiday-shopping-list-will-love-170018978.html?src=rss",
          "content": "This time of year has a lot of merry and bright things to be excited about, but it can be stressful if you’re stumped on what to get your mom, dad, best friend, coworker or kids’ teacher as a holiday gift. Whether you enjoy or dread buying gifts for people, it’s safe to say we all want to give our loved ones things they will enjoy and appreciate. But there’s a lot of noise, junk and bad deals disguised as good deals to sift through as we get closer and closer to the holidays.Allow us at Engadget to help you through it. Here, you’ll find all of our holiday gift guides collected in one place, so you can more easily find the best Christmas gifts you need this year. Are you looking for white elephant gift ideas? Are you struggling to come up with a good gift for the father figure in your life? Are you just looking for a good board game to pick up for your own family? We’ve got you covered with gift ideas for all of those scenarios and more. Best white elephant gift ideas According to legend, the King of Siam would give a white elephant to courtiers who had upset them. The recipient had no choice but to simply thank the king for such an opulent gift, knowing that they likely could not afford the upkeep for such an animal. It would inevitably lead them to financial ruin. This story is almost certainly untrue, but it has led to a modern holiday staple: the white elephant gift exchange. These gift ideas will not only get you a few chuckles, but will also make your recipient feel (slightly) burdened. Read more: The best white elephant gift ideas Best Secret Santa gifts Secret Santa gift exchanges are supposed to be fun, but it’s easy to overthink it. You want a gift that feels thoughtful without being awkward, useful without being boring, and most importantly, affordable. The sweet spot is under $50, which is plenty to find something that fits your recipient’s personality. Whether you’re buying for a co-worker you only chat with at the coffee machine, a friend who already has everything or a cousin who never gives you ideas, there are clever options that will make them smile. Read more: The best Secret Santa gift ideas Best tech gifts and gadgets Trying to find the right gift for an unabashed gadget lover during the holidays can be difficult, especially if you don’t keep up with tech industry news yourself. Fortunately, you’re reading Engadget.com, a site entirely staffed by people who spend all day figuring out what new stuff is and isn’t actually good. So allow us to help. We’ve rounded up some of our favorite gadgets and gear that just might satisfy the avid geek in your life. Read more: The best tech gifts and gadgets Best board game gifts We could all use more time away from screens of all types and sizes, and board games are a fun way to do that and bond with friends and family. You can find plenty of unique sets out there now, from word puzzles to whodunnits to calming playthroughs that showcase the beauty of the little things in life. From games with giant monsters to those with haunted mansions, we’re sure at least one of our suggestions will be a hit with you and your loved ones. Read more: The best board games to gift this season Best gifts for $25 or less So you want to give someone a gift but you don’t have a ton of cash to spare. Don’t fret because first, you’re not alone, and second, there are tons of options to choose from. Especially if you’re looking in the tech space, it can feel especially daunting to find a gadget that’s affordable but also worth gifting — in other words, not a piece of junk that will eventually take up residence at the bottom of a drawer. But you don’t have to drain your wallet to get someone a cool gadget that will both be useful and make their lives easier. We’ve collected our favorite pieces of tech under $25 that make great gifts and help you to stick to a budget. Read more: The best gifts for $25 or less Best gifts under $50 We wouldn’t blame you if you try to do all of your tech shopping around the holidays. That’s when you can typically get the best sales, both on relatively affordable gear and (more importantly) on big-ticket items. But it would be wrong to think that only the most expensive tech is worth gifting. Since we at Engadget test a plethora of gadgets every year, we know that there are some hidden (and not so hidden) tech gems at lower price ranges — you just have to know where to find them. Read more: The best gifts under $50 that make great stocking stuffers Best gifts under $100 Finding a gift for the tech nerd on your list can be tough. They likely have all the tech they need and then some, but you can add to their kit with the right accessories. Apple, Samsung, Sony and other big tech companies all have affordable gear that comes in at $100 or less, you just have to know where to look. We've collected some of our favorites, but remember: you can often find alternatives that are just as good (and sometimes better) than these. However, for the people in your life for which brand names really do matter, these gifts will speak to them. Read more: The best tech gifts under $100 Best tech toys for kids We know it’s been a pretty crazy year that’s got you wondering how exactly you’re going to make the holiday season extra special, especially for the kids in your life. The good news is that the toy industry is just as creative as ever, and this year’s crop of hot tech toys is filled with plenty of surprise and delight, all at affordable prices. We’ve picked some of our favorites under $100, ones that will not only thrill right out of the box, but keep the kids entertained for months to come. Read more: The best tech toys for kids Best gifts for remote workers There's a pretty good chance you know at least one person who works remotely in some fashion. While the WFH life has its perks — nobody likes a long commute — it comes with its own set of challenges, from lacking pro-level equipment to dealing with household disturbances. If you’re looking to give a gift to someone who spends much of their time in their home office, we’ve rounded up a few techy gift ideas that should make their days a little more delightful, or at least easier to manage. Read more: The best gift ideas for the remote worker in your life Best travel gifts For as long as humans have traveled, they've carried gear with them to make long journeys easier. Airplanes may have made travel faster, but crossing states and countries can still be exhausting. If you have a friend or family member who loves exploring the world, they'll appreciate things that will save them stress when they're far from home. So let Engadget help you find the perfect gift for the person in your life with wanderlust. Read more: The best gifts for travelers Best gifts for Nintendo lovers If you're like us, Nintendo holds a special place in your heart thanks to iconic characters like Mario, Peach and Donkey Kong and multiple generations of best-selling consoles. But little did we know that outside of gaming hardware and accessories, there's an ever-growing assortment of Nintendo-themed toys, clothes and decor. And it's kind of a problem because we want all of it. So to help you figure out the best gifts for the Nintendo fan in your life, we've put together a big list of our favorite products that will give anyone a power-up this holiday season. Of course, if none of the ones on our list quite fit the bill, you can also head over to our full list of the best Nintendo Switch 2 accessories for even more ideas. Read more: The best Nintendo gifts for the holiday season Best retro gaming gifts The stream of new video games never ends, but for some of us, nothing beats the classics. If you don’t feel like hunting through eBay and local game shops for old cartridges to add to your loved one’s collection, we’ve picked out a few other gift ideas for the nostalgic gamer in your life — from video upscalers for old consoles to retro-themed books and artwork. Read more: The best retro gaming gifts for the holidays Best gifts for gamers The year may not be over, but 2025 is all but guaranteed to go down as one of the best 12 months in gaming history. Between releases like Hades 2, Hollow Knight: Silksong and Ghost of Yotei, to name just a few, there was truly something for everyone in 2025. Of course, that abundance also means it can be tricky to find a gift for the gamers in your life, especially if you're not one yourself. Worry not — Engadget is here to help. We guarantee our guide will help you find the perfect gift for your friend or loved one. Read more: The best gifts for gamers Best gifts for moms Some moms really do mean it when they say they don’t need any gifts. But those same moms will probably appreciate getting something thoughtful and personal — a gift that shows you put in a bit of consideration. It’s tough to pin-point what that ideal gift is for any given mom, but we’ve got ideas to get you started. Since we spend our days testing and otherwise thinking about tech, most of the presents here have a gadget spin, but all of them are a heck of a lot more unique than a candle and a bath bomb. Read more: The best gifts for mom Best gifts for dads It's not always easy to find gifts for dads, especially for those who are often quick to snap up whatever they need on their own. But even the geekiest and most well-informed dads have blind spots — the trick is to find something they've never heard of, but could actually make their lives useful. We've collected some of our favorite dadcore gift ideas, which would suit everyone from a complete gadgetphobe to a total techie. Read more: The best gifts for dads Best subscription box gifts Subscription boxes are the rare gift that keeps its charm long after the wrapping paper is gone. You make the choice once, but the surprises keep landing on their doorstep for months after that. For anyone who loves the buzz of a delivery, these are gifts that extend the season well past December. Each box on this list combines a bit of discovery with something tangible, such as gadgets, books, collectibles, snacks or clever projects. Some appeal to hardcore hobbyists, others to the curious or the comfort seekers, but all offer that same spark of delight that comes from unboxing something unexpected. Read more: The best subscription box gifts Best gifts for home cooks For home cooks, kitchen tools are the equipment that make all your favorite dishes and meals possible. And while having the fanciest gear certainly isn't a requirement, it is really nice, which makes products like the ones here such great gifts. These are the kind of things that people want but might not be able to justify buying for themselves, or essential pieces that would be handy additions to any kitchen or pantry. So if you're looking for present ideas for the chef in your life, check out our guide of tried and tested cooking tools and gadgets. Read more: The best cooking gifts Best gifts for coffee lovers When it comes to making coffee at home, us coffee nerds are constantly evolving. Whether the person you’re shopping for is newly indoctrinated into the world of small-batch roasters or obsessive over every possible aspect of every brewing process, we’ve compiled a list of the best coffee gear for any coffee geek this holiday season. For brewing, grinding and drinking, we’ve got multiple options at a range of prices to help expand any java geek’s horizons. And if you think the coffee aficionado on your list already has everything they need, we’ve got a recommendation for them too. Read more: The best gifts for coffee lovers Best gadgets for your pets We're a pet-loving staff here at Engadget, with diverse distribution of cat people, dog people, other-small-fuzzy-creature people, bird feeder enjoyers and so on (at press time, I'm unsure if we have a rat person, but I'd be surprised if we didn't). And, of course, we love getting new gadgets of all sorts for our pets as much as for ourselves. Our list, with gifts as low-tech as a blanket and as high-tech as the best $30 two-way camera you'll ever use, is for the pet lover in your life — whether that's you or another favorite human. Read more: The best gadgets for your pets Check out the rest of our gift ideas here.This article originally appeared on Engadget at https://www.engadget.com/the-best-christmas-gift-ideas-everyone-on-your-2025-holiday-shopping-list-will-love-170018978.html?src=rss",
          "feed_position": 36
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/slop-is-merriam-websters-word-of-the-year-181903322.html",
          "published_at": "Mon, 15 Dec 2025 18:19:03 +0000",
          "title": "'Slop' is Merriam-Webster's word of the year",
          "standfirst": "Merriam-Webster has selected \"slop\" for the dictionary company's 2025 word of the year. The leading lexicographers define slop as \"digital content of low quality that is produced usually in quantity by means of artificial intelligence.\" We've seen an absolute deluge of AI slop this year, from fake movie trailers on YouTube to AI-generated bands on Spotify. Not even food delivery like Uber Eats could escape the onslaught of AI-generated garbage that no one asked for. It's gotten to the point that half the videos my well-meaning parents send me on social media are AI-generated videos of dogs. This isn't all that surprising given how very intentionally the social media giants have added slop to all our feeds. Merriam-Webster rightly points out the somewhat mocking nature of calling it “slop.” \"Like slime, sludge and muck, slop has the wet sound of something you don't want to touch. Slop oozes into everything. The original sense of the word, in the 1700s, was 'soft mud.' In the 1800s it came to mean 'food waste' (as in 'pig slop'), and then more generally, 'rubbish' or 'a product of little or no value,'\" the dictionary distributors wrote. As the proliferation of AI slop expanded, some platforms like TikTok and Pinterest got wise and began offering users the choice to tone down the sheer amount of it in their feeds. Even Spotify is at least trying to combat some of this stuff now, though that didn't stop an AI-generated copycat from going unnoticed on the platform for weeks. Elsewhere, companies like Google leaned in, incorporating Veo 3-generated videos into YouTube Shorts. We'll only be able to tell in hindsight if 2025 was the peak of AI slop, but for now it shows no signs of abating. Merriam-Webster highlighted some other words for the year (some of which the chronically online will be familiar with), including Gerrymander, Touch Grass, Performative, Tariff, Conclave and Six Seven.This article originally appeared on Engadget at https://www.engadget.com/ai/slop-is-merriam-websters-word-of-the-year-181903322.html?src=rss",
          "content": "Merriam-Webster has selected \"slop\" for the dictionary company's 2025 word of the year. The leading lexicographers define slop as \"digital content of low quality that is produced usually in quantity by means of artificial intelligence.\" We've seen an absolute deluge of AI slop this year, from fake movie trailers on YouTube to AI-generated bands on Spotify. Not even food delivery like Uber Eats could escape the onslaught of AI-generated garbage that no one asked for. It's gotten to the point that half the videos my well-meaning parents send me on social media are AI-generated videos of dogs. This isn't all that surprising given how very intentionally the social media giants have added slop to all our feeds. Merriam-Webster rightly points out the somewhat mocking nature of calling it “slop.” \"Like slime, sludge and muck, slop has the wet sound of something you don't want to touch. Slop oozes into everything. The original sense of the word, in the 1700s, was 'soft mud.' In the 1800s it came to mean 'food waste' (as in 'pig slop'), and then more generally, 'rubbish' or 'a product of little or no value,'\" the dictionary distributors wrote. As the proliferation of AI slop expanded, some platforms like TikTok and Pinterest got wise and began offering users the choice to tone down the sheer amount of it in their feeds. Even Spotify is at least trying to combat some of this stuff now, though that didn't stop an AI-generated copycat from going unnoticed on the platform for weeks. Elsewhere, companies like Google leaned in, incorporating Veo 3-generated videos into YouTube Shorts. We'll only be able to tell in hindsight if 2025 was the peak of AI slop, but for now it shows no signs of abating. Merriam-Webster highlighted some other words for the year (some of which the chronically online will be familiar with), including Gerrymander, Touch Grass, Performative, Tariff, Conclave and Six Seven.This article originally appeared on Engadget at https://www.engadget.com/ai/slop-is-merriam-websters-word-of-the-year-181903322.html?src=rss",
          "feed_position": 42
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/the-10-best-white-elephant-gifts-worth-fighting-over-for-2025-150516281.html",
          "published_at": "Mon, 15 Dec 2025 18:00:35 +0000",
          "title": "The 10 best white elephant gifts worth fighting over for 2025",
          "standfirst": "If you have a white elephant gift exchange at work this year or with friends and family, there’s a good chance you’re scrambling right now to find a good gift — or decipher what even makes a good white elephant gift. The possible origins of the term “white elephant” provide one way of looking at it: According to legend, the King of Siam would give a white elephant to courtiers who had upset them. It was a far more devious punishment than simply having them executed. The recipient had no choice but to simply thank the king for such an opulent gift, knowing that they likely could not afford the upkeep for such an animal. It would inevitably lead them to financial ruin.Whether or not that story is true, it gives us one way of looking at a white elephant gift: something just useful or amusing enough that it won’t immediately get tossed into the trash, but is also somewhat of a burden. However, there are plenty of other ways of interpreting this strange yet delightful tradition. Some compete to get a gift that others will surely want to steal, while others scavenge for the most niche and targeted gag gifts. Almost all of them, though, typically have a price limit that keeps the burden of gift giving to a minimum — usually $50 or less. So with all of that in mind, here are some white elephant gift ideas that will get you a few chuckles without requiring you to spend too much (or think too hard about it). Best white elephant gift ideas White elephant FAQs What is white elephant? A white elephant gift exchange is a party game typically played around the holidays in which people exchange funny, impractical gifts. How does white elephant work? A group of people each bring one wrapped gift to the white elephant gift exchange, and each gift is typically of a similar value. All gifts are then placed together and the group decides the order in which they will each claim a gift. The first person picks a white elephant gift from the pile, unwraps it and their turn ends. The following players can either decide to unwrap another gift and claim it as their own, or steal a gift from someone who has already taken a turn. The rules can vary from there, including the guidelines around how often a single item can be stolen — some say twice, max. The game ends when every person has a white elephant gift. Why is it called white elephant? The term “white elephant” is said to come from the legend of the King of Siam gifting white elephants to courtiers who upset him. While it seems like a lavish gift on its face, the belief is that the courtiers would be ruined by the animal’s upkeep costs. Check out the rest of our gift ideas here.This article originally appeared on Engadget at https://www.engadget.com/the-10-best-white-elephant-gifts-worth-fighting-over-for-2025-150516281.html?src=rss",
          "content": "If you have a white elephant gift exchange at work this year or with friends and family, there’s a good chance you’re scrambling right now to find a good gift — or decipher what even makes a good white elephant gift. The possible origins of the term “white elephant” provide one way of looking at it: According to legend, the King of Siam would give a white elephant to courtiers who had upset them. It was a far more devious punishment than simply having them executed. The recipient had no choice but to simply thank the king for such an opulent gift, knowing that they likely could not afford the upkeep for such an animal. It would inevitably lead them to financial ruin.Whether or not that story is true, it gives us one way of looking at a white elephant gift: something just useful or amusing enough that it won’t immediately get tossed into the trash, but is also somewhat of a burden. However, there are plenty of other ways of interpreting this strange yet delightful tradition. Some compete to get a gift that others will surely want to steal, while others scavenge for the most niche and targeted gag gifts. Almost all of them, though, typically have a price limit that keeps the burden of gift giving to a minimum — usually $50 or less. So with all of that in mind, here are some white elephant gift ideas that will get you a few chuckles without requiring you to spend too much (or think too hard about it). Best white elephant gift ideas White elephant FAQs What is white elephant? A white elephant gift exchange is a party game typically played around the holidays in which people exchange funny, impractical gifts. How does white elephant work? A group of people each bring one wrapped gift to the white elephant gift exchange, and each gift is typically of a similar value. All gifts are then placed together and the group decides the order in which they will each claim a gift. The first person picks a white elephant gift from the pile, unwraps it and their turn ends. The following players can either decide to unwrap another gift and claim it as their own, or steal a gift from someone who has already taken a turn. The rules can vary from there, including the guidelines around how often a single item can be stolen — some say twice, max. The game ends when every person has a white elephant gift. Why is it called white elephant? The term “white elephant” is said to come from the legend of the King of Siam gifting white elephants to courtiers who upset him. While it seems like a lavish gift on its face, the belief is that the courtiers would be ruined by the animal’s upkeep costs. Check out the rest of our gift ideas here.This article originally appeared on Engadget at https://www.engadget.com/the-10-best-white-elephant-gifts-worth-fighting-over-for-2025-150516281.html?src=rss",
          "feed_position": 43
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/in-2025-tech-giants-decided-smart-glasses-are-the-next-big-thing-163000812.html",
          "published_at": "Mon, 15 Dec 2025 16:30:00 +0000",
          "title": "In 2025, tech giants decided smart glasses are the next big thing",
          "standfirst": "There's a growing sentiment that gadgets have gotten boring. And while I don't fully agree, I understand why people might feel that way. Just think about some of the novel device types that companies have tried to push since the original iPhone came out. 3D TVs were a massive flop and tablets still feel like extra-large smartphones despite Apple's efforts to prop them up as laptop replacements. Meanwhile, even with huge technological advancements over the last decade, VR headsets remain relatively niche due to factors like high prices and a lack of compelling content. And although big names like Google, Microsoft, Meta and others continue to dump billions into AI development, the first wave of dedicated AI devices was an abject failure. When you think about it, the only new(ish) class of gadget that has made major inroads to the mainstream market is smartwatches. That said, because they've evolved into wearable health and fitness sensors instead of the wrist-based computers that many once thought they would be, they haven't really disrupted our lives like the personal computer and smartphone did. But that seems poised to change because the tech giants have decided that smart glasses are going to be the next big thing. Headsets versus smart glasses, what’s the difference?Google is planning to support both smart glasses and headsets with Android XR, though the increased size and weight of devices like the Galaxy XR means it's not a great choice for all-day functionality. Sam Rutherford for EngadgetAt this point, you might be saying, \"Wait, hold on. Aren't VR headsets and smart glasses kind of the same thing?\" Well, yes and no. Both types of gadgets require similar software and hardware, but they utilize them in very different ways. Not only are VR goggles typically much bigger and heavier, they also provide a more isolated experience that can make it feel like you've been transported to another world. Sure, most modern headsets have exterior cameras that support some level of mixed reality (blending virtual graphics with physical objects) or let you peek quickly into meatspace (passthrough view) for when you need to get a drink or acknowledge other humans in the room. But in many respects, that closed-off feeling is the goal because it creates the ideal environment for playing games, taking virtual meetings or modeling 3D objects without real-world distractions. Furthermore, while many headsets like the Vision Pro and the Meta Quest 3 can function as standalone systems and support accessories like controllers or other motion trackers, they can also be tethered to a nearby PC for enhanced functionality. On the other hand, the default use case for smart glasses is a mixed reality environment where the spectacles can overlay helpful info or messages while you stay active and aware of your surroundings. Notably, while smart glasses might come with lenses or clip-on attachments that allow them to get darker or serve as sunglasses when you're outside, there typically isn't a way to completely block out the world like you can with a headset, mostly because that's simply not the point. And even though most smart spectacles can be paired with a phone to get access to mobile data or notifications, they're generally not meant to be tethered to a PC full-time (though there are some exceptions). The goal for smart glasses is more to provide a mobile-first heads-up display that augments what you see with your eyes instead of replacing things entirely with a digital environment. OK, but what makes you so sure that smart glasses are \"it?\"Now that we've discussed what separates smart glasses from headsets, what makes it so obvious that they are going to be the next big thing? This one is a bit easier to answer because we can simply look at the sheer number of companies that have released smart glasses or are planning to do so in the future. If we skip past the Google Glass from 2013 as forward-thinking specs that were ahead of their time, the most well-known example of modern smart glasses is the Meta Ray-Ban (or the even earlier Ray-Ban Stories from back when Facebook was still Facebook). While they are a bit chunky, the Meta Ray-Ban Display are some of the most sophisticated smart glasses on the market right now due in large part to their single full-color screen. Karissa Bell for EngadgetEven though they don't have built-in displays, the ability to capture photos and videos and play audio via built-in speakers brought the idea of smart glasses into the mainstream without making the concept look or feel completely ridiculous. Those earlier models then paved the way for even more sophisticated iterations like the Meta Ray-Ban Display from earlier this fall, which features a stunning RGB HUD (though only in the right lens) that has gotten us tantalizingly close to a true wearable display that doesn't make you look like a cyborg. Of course, Meta isn't the only game in town: there's a rapidly growing number of competitors from companies like Even Realities, Rokkid, TCL, Xreal, Viture and more. But for an even clearer sign of where the tech giants are heading, we can just look at Meta's two biggest competitors: Apple and Google. While Apple hasn't publicly announced plans to make its own smart glasses, Bloomberg's Mark Gurman — who is one of the company's most reliable analysts — provided inside info earlier this fall that Tim Cook and Co. are planning to pivot away from a proper follow-up to the Vision Pro in favor of more lightweight spectacles with greater mass appeal. This shouldn't really come as a major surprise, as sales of Apple's $3,500 headset have been lackluster. But more importantly, for a company that's extremely cautious about entering new product categories (foldable iPhone anyone?), it feels very telling to hear that Apple is shifting to smart glasses instead of abandoning the idea of wearable displays entirely. This is a company that doesn't swing and miss very often, so the idea of two flops in a row seems preposterous. If this pivot is real, there must be some Apple execs who are big believers that glasses and not goggles are the right choice for future development. Here are two of Google's reference design smart glasses. The one in the front features dual RGB waveguide displays while the one in the back relies on a single monocular screen.Sam Rutherford for EngadgetMeanwhile, Google is taking a two-pronged approach. In addition to releasing a new mixed reality OS — Android XR — on Samsung's Galaxy XR headset in October, the company has also teased upcoming smart glasses along with a handful of partners including glasses makers Gentle Monster and Warby Parker. Just this week, the company also added a number of new features to Android XR designed to support a wide range of upcoming devices while simultaneously making it easier for developers to port existing apps over to smart glasses and headsets. And if you still need additional evidence regarding Google's desire to get into smart glasses, consider that even with its ongoing collaboration, the company also spent $100 million to acquire a 4 percent stake in Gentle Monster. Regardless of who is making them though, the big draw for these companies is the idea that smart glasses will become a new piece of core personal computing, similar to how people rely on smartphones and laptops today (or to a lesser extent wireless headphones and smartwatches). If true, that could become a trillion-dollar market in the next 10 to 15 years (or sooner, who knows), which not only makes it a natural avenue for expansion but possibly a future existential crisis for certain companies. After all, none of these organizations want to be the next Microsoft after it failed to develop a successful smartphone or mobile OS.Fine, the smart glasses trend is real, but why would we even want them?At this point, I hope it's clear that the push for smart glasses is very real and very serious. But so far, we've only addressed why companies are betting big on them. So what's in it for us, the people who might actually buy and use them? Well, to answer that, we need to separate the current models into three main categories.A great use case for smart glasses would be to provide heads-up mapping without the need to constantly look down at your phone as seen in this demo clip of Android XR. GoogleFirst, there are the most basic smart glasses that don't come with built-in displays and typically rely on cameras and built-in speakers for enhanced functionality. The best example of this class of devices is the Meta Ray-Ban smart glasses (or the original Ray-Ban Stories) along with rivals like the Bose Sound Frames, which, believe it or not, have been on the market since 2019. However, before anyone gets attached to these early models, the simplest smart glasses already kind of feel like dinosaurs and will probably, in the not-too-distant future, go extinct. They were an interesting attempt to add things like music playback or photo and video capture to regular-looking sunglasses, but their limited feature set puts a clear ceiling on what they can do. Plus, if this is what people really wanted, they would have taken off already. Waveguides like the ones built into the Even Realities G2 project images directly onto their lenses allowing for super sleek glasses featuring a heads-up display. Sam Rutherford for EngadgetThis brings us to more recent offerings like the Meta Ray-Ban Display, Even Realities G2, the Halliday glasses and others which add some type of built-in display to the mix. Most often, these models rely on waveguide displays as they enable thinner and lighter designs while propagating images onto the glasses' lenses. Currently, most of these smart glasses feature single-color optics (usually green) to reduce complexity and power draw, but there are others like the Meta Ray-Ban Display and both the TCL RayNeo X2 and X3 that support full color.In this day and age when everyone is surrounded by screens, the idea of yet another display mounted inches away from your eyeballs might sound like the last thing you want. However, because modern smart glasses are much more discreet and less awkward-looking, I find that they can actually help cut down on distractions. That's because instead of having to peek down at your phone or smartwatch to check notifications, reply to messages or look up directions, you can do many or all of these things using smart glasses — all in the middle of a conversation without anyone noticing. Not only does this keep your focus where it should be — on people instead of gadgets — the glasses are also just as easy to wear as a smartwatch and far more comfortable than bulky VR headsets. Then, when you consider some other features of modern smart glasses like on-the-fly translation, the ability to function as a teleprompter hidden in plain sight or additional support from AI, suddenly you have a wearable that allows you to keep all of your other devices neatly stashed away. In many respects, smart glasses could be the portable displays that people might not even know they want.Compared to rivals with waveguides, glasses featuring \"birdbath\" optics are often significantly thicker and bulkier. Sam Rutherford for EngadgetSpeaking of portable displays: If you recall, I mentioned above how most smart glasses generally don't need to be tethered to other devices. The exception to that comes from a subclass of specs that are primarily designed to function as wearable monitors capable of supporting one or more virtual screens that can be in excess of 100 inches in size, relatively speaking. The most well-known smart glasses in this category come from Xreal and Viture, with both companies offering a range of models with varying levels of performance. One interesting thing to note is instead of waveguides, some of these smart glasses rely on birdbath optics. This means instead of projecting an image into the lens itself, they use a beamsplitter and mirror to reflect images into your eye. The benefit of this is that you get good image quality from components that cost less than an equivalent waveguide setup, with the downside being increased light loss, potentially lower brightness and a much thicker design. This results in chunky frames that often look like they are sitting too far away from your face, which might not be immediately apparent if you see someone using them from afar. But up close, they don't look quite right. Or at least they don’t look like a pair of \"normal\" glasses.Another issue is that due to more light loss, birdbath smart glasses require darker lenses (similar to sunglasses), which means they aren't great for wearing all day in a variety of environments. And because we still don't really have a great protocol for wireless displays (though it looks like Valve may be cooking up something with the Steam Frames), most of these need to be connected by wire to a nearby PC. So you plug them in, put them on, get your work done and then you take them off. Project Aura is Xreal's next-gen smart glasses and they feature a large 70-degree field of view and fancy electrochromic lenses. Sam Rutherford for EngadgetThat said, for those who need a ton of screen real estate, this type of smart glasses can be a very attractive alternative to traditional portable monitors. On top of being smaller and more portable, they provide additional privacy when working in public spaces like a cafe or plane, which is what prompted a doctor friend of mine to get a pair instead of going with a portable display. And for the gamers out there, because they can be connected to a phone or even a portable PC or Switch 2 (with the proper dock, of course), they're great for people who might not have room for or access to a big screen TV.So where do we go from here?Ultimately, I think all three types of smart glasses will merge into one as engineers perfect the tech and steal ideas from one another, though there will surely be plenty of room for more niche designs. But more importantly, if we consider the types of gadgets most people carry around today, it boils down to just a handful of devices: a smartphone, some type of wireless audio (either earbuds or headphones) and maybe a health and fitness tracker of some kind (typically a smartwatch or smart ring). Even tough they didn't have a built-in display, the Meta Ray-Ban smart glasses from 2023 raised a ton of awareness for the category.Sam Rutherford for EngadgetSmart glasses have the potential to really round out that kit by allowing us to keep most of those devices in our pocket while the wearables serve up helpful info when we need it, but without being overly intrusive or distracting. In the short term, you'll still need a laptop for work, but smart glasses may have a role to play there too, as they can provide way more screen space than a traditional physical display (even the new-fangled flexible ones). It might never happen, but I wouldn’t rule out a future scenario where your next employer gives you a company-issued phone and a pair of smart glasses and that's it. Before that happens though, there are still a bunch of other things that need to be figured out. Without help from a mouse or keyboard, navigating a virtual display is a bit of a challenge. AI combined with hand and eye tracking can help, but no one has really nailed that combo yet. Not even Apple could do so on the much bulkier Vision Pro. To address this, Meta created a bracelet (they call it a neural band) that pairs with the Ray-Ban Display that can detect subtle movements so you can type or navigate menus practically anywhere. Even Realities opted for a ring accessory that does some basic health monitoring and comes with a tiny touchpad. In the more distant future, this hurdle may be solved by BCIs (brain-computer interfaces), but even the most optimistic view suggests that those aren't going to be mainstream for a long time.Even though we're still a long ways away, one day everyone might be able to have something like Tony Stark's E.D.I.T.H. smart glasses from the Marvel Universe. MarvelThe issue for Meta is that it's pretty obvious that its wristband really ought to be incorporated into a smartwatch. The idea of a single-purpose bracelet that doesn't track your health or do anything else sort of feels like a step backwards. And there's the problem of Meta's glasses being largely tied down to its own platforms (i.e. Instagram, Whatsapp and Facebook), which may end up being a major hindrance after rivals like Google and Apple catch up.And then there's the cost. Right now, a pair of Meta Ray-Ban Displays (which thankfully come with the wristband) costs $800. That's a lot for what is basically a publicly available beta test. But when you consider that an Even Realties G2 and an R2 ring costs even more at $850, it's clear that wearing smart glasses is going to be a very expensive hobby for at least the next few years. And while more single-purpose smart glasses from Xreal and Viture are a bit more affordable, with models ranging from $400 to $550 or $600, they still aren't cheap. On top of that, getting prescription lenses for smart glasses can often be a major pain in the ass and may not even be an option for people with more limited eyesight. But those are problems for another day. And just because tech giants are pouring billions into the development of smart glasses doesn't mean they will be a guaranteed hit. If you care about tech, alongside AI and possibly EVTOL aircraft (aka flying taxis), pay attention to the advancements in smart glasses. Otherwise, you could miss out on what might be the next major wave in sci-fi gadgetry made real.This article originally appeared on Engadget at https://www.engadget.com/wearables/in-2025-tech-giants-decided-smart-glasses-are-the-next-big-thing-163000812.html?src=rss",
          "content": "There's a growing sentiment that gadgets have gotten boring. And while I don't fully agree, I understand why people might feel that way. Just think about some of the novel device types that companies have tried to push since the original iPhone came out. 3D TVs were a massive flop and tablets still feel like extra-large smartphones despite Apple's efforts to prop them up as laptop replacements. Meanwhile, even with huge technological advancements over the last decade, VR headsets remain relatively niche due to factors like high prices and a lack of compelling content. And although big names like Google, Microsoft, Meta and others continue to dump billions into AI development, the first wave of dedicated AI devices was an abject failure. When you think about it, the only new(ish) class of gadget that has made major inroads to the mainstream market is smartwatches. That said, because they've evolved into wearable health and fitness sensors instead of the wrist-based computers that many once thought they would be, they haven't really disrupted our lives like the personal computer and smartphone did. But that seems poised to change because the tech giants have decided that smart glasses are going to be the next big thing. Headsets versus smart glasses, what’s the difference?Google is planning to support both smart glasses and headsets with Android XR, though the increased size and weight of devices like the Galaxy XR means it's not a great choice for all-day functionality. Sam Rutherford for EngadgetAt this point, you might be saying, \"Wait, hold on. Aren't VR headsets and smart glasses kind of the same thing?\" Well, yes and no. Both types of gadgets require similar software and hardware, but they utilize them in very different ways. Not only are VR goggles typically much bigger and heavier, they also provide a more isolated experience that can make it feel like you've been transported to another world. Sure, most modern headsets have exterior cameras that support some level of mixed reality (blending virtual graphics with physical objects) or let you peek quickly into meatspace (passthrough view) for when you need to get a drink or acknowledge other humans in the room. But in many respects, that closed-off feeling is the goal because it creates the ideal environment for playing games, taking virtual meetings or modeling 3D objects without real-world distractions. Furthermore, while many headsets like the Vision Pro and the Meta Quest 3 can function as standalone systems and support accessories like controllers or other motion trackers, they can also be tethered to a nearby PC for enhanced functionality. On the other hand, the default use case for smart glasses is a mixed reality environment where the spectacles can overlay helpful info or messages while you stay active and aware of your surroundings. Notably, while smart glasses might come with lenses or clip-on attachments that allow them to get darker or serve as sunglasses when you're outside, there typically isn't a way to completely block out the world like you can with a headset, mostly because that's simply not the point. And even though most smart spectacles can be paired with a phone to get access to mobile data or notifications, they're generally not meant to be tethered to a PC full-time (though there are some exceptions). The goal for smart glasses is more to provide a mobile-first heads-up display that augments what you see with your eyes instead of replacing things entirely with a digital environment. OK, but what makes you so sure that smart glasses are \"it?\"Now that we've discussed what separates smart glasses from headsets, what makes it so obvious that they are going to be the next big thing? This one is a bit easier to answer because we can simply look at the sheer number of companies that have released smart glasses or are planning to do so in the future. If we skip past the Google Glass from 2013 as forward-thinking specs that were ahead of their time, the most well-known example of modern smart glasses is the Meta Ray-Ban (or the even earlier Ray-Ban Stories from back when Facebook was still Facebook). While they are a bit chunky, the Meta Ray-Ban Display are some of the most sophisticated smart glasses on the market right now due in large part to their single full-color screen. Karissa Bell for EngadgetEven though they don't have built-in displays, the ability to capture photos and videos and play audio via built-in speakers brought the idea of smart glasses into the mainstream without making the concept look or feel completely ridiculous. Those earlier models then paved the way for even more sophisticated iterations like the Meta Ray-Ban Display from earlier this fall, which features a stunning RGB HUD (though only in the right lens) that has gotten us tantalizingly close to a true wearable display that doesn't make you look like a cyborg. Of course, Meta isn't the only game in town: there's a rapidly growing number of competitors from companies like Even Realities, Rokkid, TCL, Xreal, Viture and more. But for an even clearer sign of where the tech giants are heading, we can just look at Meta's two biggest competitors: Apple and Google. While Apple hasn't publicly announced plans to make its own smart glasses, Bloomberg's Mark Gurman — who is one of the company's most reliable analysts — provided inside info earlier this fall that Tim Cook and Co. are planning to pivot away from a proper follow-up to the Vision Pro in favor of more lightweight spectacles with greater mass appeal. This shouldn't really come as a major surprise, as sales of Apple's $3,500 headset have been lackluster. But more importantly, for a company that's extremely cautious about entering new product categories (foldable iPhone anyone?), it feels very telling to hear that Apple is shifting to smart glasses instead of abandoning the idea of wearable displays entirely. This is a company that doesn't swing and miss very often, so the idea of two flops in a row seems preposterous. If this pivot is real, there must be some Apple execs who are big believers that glasses and not goggles are the right choice for future development. Here are two of Google's reference design smart glasses. The one in the front features dual RGB waveguide displays while the one in the back relies on a single monocular screen.Sam Rutherford for EngadgetMeanwhile, Google is taking a two-pronged approach. In addition to releasing a new mixed reality OS — Android XR — on Samsung's Galaxy XR headset in October, the company has also teased upcoming smart glasses along with a handful of partners including glasses makers Gentle Monster and Warby Parker. Just this week, the company also added a number of new features to Android XR designed to support a wide range of upcoming devices while simultaneously making it easier for developers to port existing apps over to smart glasses and headsets. And if you still need additional evidence regarding Google's desire to get into smart glasses, consider that even with its ongoing collaboration, the company also spent $100 million to acquire a 4 percent stake in Gentle Monster. Regardless of who is making them though, the big draw for these companies is the idea that smart glasses will become a new piece of core personal computing, similar to how people rely on smartphones and laptops today (or to a lesser extent wireless headphones and smartwatches). If true, that could become a trillion-dollar market in the next 10 to 15 years (or sooner, who knows), which not only makes it a natural avenue for expansion but possibly a future existential crisis for certain companies. After all, none of these organizations want to be the next Microsoft after it failed to develop a successful smartphone or mobile OS.Fine, the smart glasses trend is real, but why would we even want them?At this point, I hope it's clear that the push for smart glasses is very real and very serious. But so far, we've only addressed why companies are betting big on them. So what's in it for us, the people who might actually buy and use them? Well, to answer that, we need to separate the current models into three main categories.A great use case for smart glasses would be to provide heads-up mapping without the need to constantly look down at your phone as seen in this demo clip of Android XR. GoogleFirst, there are the most basic smart glasses that don't come with built-in displays and typically rely on cameras and built-in speakers for enhanced functionality. The best example of this class of devices is the Meta Ray-Ban smart glasses (or the original Ray-Ban Stories) along with rivals like the Bose Sound Frames, which, believe it or not, have been on the market since 2019. However, before anyone gets attached to these early models, the simplest smart glasses already kind of feel like dinosaurs and will probably, in the not-too-distant future, go extinct. They were an interesting attempt to add things like music playback or photo and video capture to regular-looking sunglasses, but their limited feature set puts a clear ceiling on what they can do. Plus, if this is what people really wanted, they would have taken off already. Waveguides like the ones built into the Even Realities G2 project images directly onto their lenses allowing for super sleek glasses featuring a heads-up display. Sam Rutherford for EngadgetThis brings us to more recent offerings like the Meta Ray-Ban Display, Even Realities G2, the Halliday glasses and others which add some type of built-in display to the mix. Most often, these models rely on waveguide displays as they enable thinner and lighter designs while propagating images onto the glasses' lenses. Currently, most of these smart glasses feature single-color optics (usually green) to reduce complexity and power draw, but there are others like the Meta Ray-Ban Display and both the TCL RayNeo X2 and X3 that support full color.In this day and age when everyone is surrounded by screens, the idea of yet another display mounted inches away from your eyeballs might sound like the last thing you want. However, because modern smart glasses are much more discreet and less awkward-looking, I find that they can actually help cut down on distractions. That's because instead of having to peek down at your phone or smartwatch to check notifications, reply to messages or look up directions, you can do many or all of these things using smart glasses — all in the middle of a conversation without anyone noticing. Not only does this keep your focus where it should be — on people instead of gadgets — the glasses are also just as easy to wear as a smartwatch and far more comfortable than bulky VR headsets. Then, when you consider some other features of modern smart glasses like on-the-fly translation, the ability to function as a teleprompter hidden in plain sight or additional support from AI, suddenly you have a wearable that allows you to keep all of your other devices neatly stashed away. In many respects, smart glasses could be the portable displays that people might not even know they want.Compared to rivals with waveguides, glasses featuring \"birdbath\" optics are often significantly thicker and bulkier. Sam Rutherford for EngadgetSpeaking of portable displays: If you recall, I mentioned above how most smart glasses generally don't need to be tethered to other devices. The exception to that comes from a subclass of specs that are primarily designed to function as wearable monitors capable of supporting one or more virtual screens that can be in excess of 100 inches in size, relatively speaking. The most well-known smart glasses in this category come from Xreal and Viture, with both companies offering a range of models with varying levels of performance. One interesting thing to note is instead of waveguides, some of these smart glasses rely on birdbath optics. This means instead of projecting an image into the lens itself, they use a beamsplitter and mirror to reflect images into your eye. The benefit of this is that you get good image quality from components that cost less than an equivalent waveguide setup, with the downside being increased light loss, potentially lower brightness and a much thicker design. This results in chunky frames that often look like they are sitting too far away from your face, which might not be immediately apparent if you see someone using them from afar. But up close, they don't look quite right. Or at least they don’t look like a pair of \"normal\" glasses.Another issue is that due to more light loss, birdbath smart glasses require darker lenses (similar to sunglasses), which means they aren't great for wearing all day in a variety of environments. And because we still don't really have a great protocol for wireless displays (though it looks like Valve may be cooking up something with the Steam Frames), most of these need to be connected by wire to a nearby PC. So you plug them in, put them on, get your work done and then you take them off. Project Aura is Xreal's next-gen smart glasses and they feature a large 70-degree field of view and fancy electrochromic lenses. Sam Rutherford for EngadgetThat said, for those who need a ton of screen real estate, this type of smart glasses can be a very attractive alternative to traditional portable monitors. On top of being smaller and more portable, they provide additional privacy when working in public spaces like a cafe or plane, which is what prompted a doctor friend of mine to get a pair instead of going with a portable display. And for the gamers out there, because they can be connected to a phone or even a portable PC or Switch 2 (with the proper dock, of course), they're great for people who might not have room for or access to a big screen TV.So where do we go from here?Ultimately, I think all three types of smart glasses will merge into one as engineers perfect the tech and steal ideas from one another, though there will surely be plenty of room for more niche designs. But more importantly, if we consider the types of gadgets most people carry around today, it boils down to just a handful of devices: a smartphone, some type of wireless audio (either earbuds or headphones) and maybe a health and fitness tracker of some kind (typically a smartwatch or smart ring). Even tough they didn't have a built-in display, the Meta Ray-Ban smart glasses from 2023 raised a ton of awareness for the category.Sam Rutherford for EngadgetSmart glasses have the potential to really round out that kit by allowing us to keep most of those devices in our pocket while the wearables serve up helpful info when we need it, but without being overly intrusive or distracting. In the short term, you'll still need a laptop for work, but smart glasses may have a role to play there too, as they can provide way more screen space than a traditional physical display (even the new-fangled flexible ones). It might never happen, but I wouldn’t rule out a future scenario where your next employer gives you a company-issued phone and a pair of smart glasses and that's it. Before that happens though, there are still a bunch of other things that need to be figured out. Without help from a mouse or keyboard, navigating a virtual display is a bit of a challenge. AI combined with hand and eye tracking can help, but no one has really nailed that combo yet. Not even Apple could do so on the much bulkier Vision Pro. To address this, Meta created a bracelet (they call it a neural band) that pairs with the Ray-Ban Display that can detect subtle movements so you can type or navigate menus practically anywhere. Even Realities opted for a ring accessory that does some basic health monitoring and comes with a tiny touchpad. In the more distant future, this hurdle may be solved by BCIs (brain-computer interfaces), but even the most optimistic view suggests that those aren't going to be mainstream for a long time.Even though we're still a long ways away, one day everyone might be able to have something like Tony Stark's E.D.I.T.H. smart glasses from the Marvel Universe. MarvelThe issue for Meta is that it's pretty obvious that its wristband really ought to be incorporated into a smartwatch. The idea of a single-purpose bracelet that doesn't track your health or do anything else sort of feels like a step backwards. And there's the problem of Meta's glasses being largely tied down to its own platforms (i.e. Instagram, Whatsapp and Facebook), which may end up being a major hindrance after rivals like Google and Apple catch up.And then there's the cost. Right now, a pair of Meta Ray-Ban Displays (which thankfully come with the wristband) costs $800. That's a lot for what is basically a publicly available beta test. But when you consider that an Even Realties G2 and an R2 ring costs even more at $850, it's clear that wearing smart glasses is going to be a very expensive hobby for at least the next few years. And while more single-purpose smart glasses from Xreal and Viture are a bit more affordable, with models ranging from $400 to $550 or $600, they still aren't cheap. On top of that, getting prescription lenses for smart glasses can often be a major pain in the ass and may not even be an option for people with more limited eyesight. But those are problems for another day. And just because tech giants are pouring billions into the development of smart glasses doesn't mean they will be a guaranteed hit. If you care about tech, alongside AI and possibly EVTOL aircraft (aka flying taxis), pay attention to the advancements in smart glasses. Otherwise, you could miss out on what might be the next major wave in sci-fi gadgetry made real.This article originally appeared on Engadget at https://www.engadget.com/wearables/in-2025-tech-giants-decided-smart-glasses-are-the-next-big-thing-163000812.html?src=rss",
          "feed_position": 44,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Galaxy-XR-lead.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/swallowing-the-moon-and-other-new-indie-games-worth-checking-out-154937071.html",
          "published_at": "Mon, 15 Dec 2025 15:49:37 +0000",
          "title": "Swallowing the Moon and other new indie games worth checking out",
          "standfirst": "Welcome to our latest roundup of what's going on in the indie game space. Between The Game Awards and showcases like Day of the Devs, Wholesome Snack, Latin American Games and Women-Led Games, there’s been a ton of video game news over the last week (I need Control Resonant ASAP, please and thank you, Remedy). And hey, guess what? I've got even more for you to dig into, including info on some new releases that you can play right now.One of those is a game I’d been looking forward to since about 2022, and it’s always nice when something you’ve remained patient for turns out to be worth the wait. In Sam Eng's Skate Story, you play as a demon who accepts a deal offered by the Devil. If the demon can ride a skateboard to the Moon and swallow it after being transformed into a creature made of “glass and pain,” the Devil will grant them their freedom. It’s just as strange as that setup sounds. While you’ll need to execute combos to defeat bosses, this is a skateboarding game that leans more heavily on story than pure gameplay. It’s visually and sonically arresting too, with Blood Cultures and John Fio crafting a killer soundtrack I know I’ll be listening to for a long time to come. Skate Story is out now on Nintendo Switch 2, Steam and PS5 for $20. PlayStation Plus Extra and Premium members can play it at no extra cost. New releasesUnbeatable is another game I’ve had on my radar for some time, though I haven’t had a chance to jump in yet. This is another stylish game in which you play as Beat, who sings in a band. However, music is outlawed in this world (oh no!). Through rhythm-based minigames and battles with cops, Beat tries to bring back the music. There's a separate arcade mode with a dedicated progression system too.I'm a sucker for stories about rebellious underdogs, and this rhythm adventure could well hook me in. Unbeatable — from D-Cell Games and publisher Playstack — is available on Steam and PS5 for $28 (there’s a 10 percent discount on Steam until December 23). It's set to hit Xbox Series X/S very soon too.Speaking of games I've been keeping an eye on, Adrift (from solo developer S.K.9.8 and co-publisher Secret Sauce) was one of the first games I covered when I started doing this weekly roundup earlier this year. It's a driving game in which your aim is to deliver a volatile energy core. Since you're traversing a hot desert, you'll need to be careful to prevent the core from overheating and blowing up. Thankfully, there are safe spots and cooling stations where you can bring down the temperature.The vaporwave aesthetic of Adrift caught my eye and although I dig the presentation, the game isn't quite clicking for me in the early going. It didn't take long before my vehicle got stuck and I had to reset, and I'm finding the top-down world a little confusing to navigate. I'll stick with it for at least a little longer, though. Adrift is out now on Steam. It usually costs $13 though there's a 25 percent discount until December 23. I've very happy that a game like Drywall Eating Simulator can exist. Peripheral Playbox's satirical walking sim sees your character trying to deal with the maddening realities of daily life and the frustration that one may find in dealing with other people. Get mad enough and you'll be able to punch through a wall (something you'll have to do to move through the levels anyway). Then, you can munch on some drywall to calm yourself down.I had a good time with it and there’s some pointedly funny writing here. “I thought AI sucks but it told me that was wrong and I believed it,” says one person. That's all well and good, but I mainly just want the NPCs to leave me alone so I can eat drywall in peace. Drywall Eating Simulator is out now on Steam. It'll usually run you $10, but there's a 10 percent discount until December 17.Planet of Lana was one of my favorite games of 2023 and now it's available on iOS and Android for $9. It sees teenage Lana and her cute companion Mui making their way through a world that's been taken over by alien robots as they try to rescue Lana's sister.This is a puzzle platformer in the vein of Inside and Limbo, and despite the pretty and often bright presentation, it's just as dystopian as those games. It sounds gorgeous too, thanks in large part to a beautiful score from The Last Guardian composer Takeshi Furukawa. I'm very much looking forward to the sequel from Wishfully and publisher Thunderful. That's set to arrive next year.A Game About Digging A Hole is one of this year's real indie success stories. It’s a game that a developer started making in their spare time that has sold more than 1.2 million copies since February. After landing on PC and mobile, the $5 game from Doublebee and publisher Rokaplay is now on Nintendo Switch, Xbox Series X/S and PS5. It's on Game Pass Ultimate, Game Pass Premium and PC Game Pass.It's a straightforward loop. Start digging a hole in your backyard, sell the stuff you find, upgrade your equipment and keep going. Just, uh, be careful down there. You never quite know what you'll run into.Upcoming Vampire Therapist developer Little Bat Games has revealed its latest project, Better Than Us, which is coming to Steam in 2026. It's a narrative-driven sci-fi narrative game in which you'll infiltrate swanky parties thrown by wealth hoarders in the future to steal spoils back from them. Violence isn't the solution here, as you'll need to charm the ultra-rich, who buy elections and have \"monopolized AI development to ensure machines serve their interests\" (I dunno, this all seems extremely far-fetched). You can spin up a web of lies about things like how your husband died and how much Worldcoin you have. To maintain your ruse, you'll need to keep your story straight by remembering what you said and to which characters. Okomotive (Herdling, Far: Changing Tides) just revealed its next game. PinKeep is a roguelike deckbuilder in which you'll place structures on a playing field to fend off enemies. To collect resources, you'll need to play some pinball. By using the flippers (and flicking the ball for more precise movement), you can pick up what you need to fight back against your opponents. You can damage bad guys directly with the balls too. As a Ball x Pit enthusiast with a tepid but growing interest in deckbuilders, this speaks to me. A PinKeep demo is coming to Steam in January, with the full game set to arrive late in 2026.AudioMech is a neat-looking game that popped up for the first time during the pre-show of The Game Awards. This is a rhythm-based action title from Dylan Fitterer, the creator of Audiosurf. It taps into whatever music you have playing on your computer (even something that you're streaming or playing through a microphone) to customize both your weapons and opponents.A track that's heavy on bass might give you a longer sword, while vocals and lead instruments can power a cannon. There are several ways to play, including a mode in which you don't take damage and a boss rush option. AudioMech is coming to Steam and there's a demo available now. Let's wrap things up with something a little more relaxing. Lost and Found Co. is a hidden object game from Bit Egg Inc. and co-publisher Gamirror Games. During the latest Wholesome Snack showcase, it was revealed that the game is coming to Steam on February 11.It's little wonder that more than 170,000 Steam users have wishlisted this game. It looks absolutely lovely. The developers sought to recapture the \"magic\" of childhood puzzle books in their hand-drawn world. Here, you'll help Ducky, a duck-turned-human intern at a startup that hunts for items that townspeople have lost. There's a demo available that features the option to decorate a part of the world using items you find.This article originally appeared on Engadget at https://www.engadget.com/gaming/swallowing-the-moon-and-other-new-indie-games-worth-checking-out-154937071.html?src=rss",
          "content": "Welcome to our latest roundup of what's going on in the indie game space. Between The Game Awards and showcases like Day of the Devs, Wholesome Snack, Latin American Games and Women-Led Games, there’s been a ton of video game news over the last week (I need Control Resonant ASAP, please and thank you, Remedy). And hey, guess what? I've got even more for you to dig into, including info on some new releases that you can play right now.One of those is a game I’d been looking forward to since about 2022, and it’s always nice when something you’ve remained patient for turns out to be worth the wait. In Sam Eng's Skate Story, you play as a demon who accepts a deal offered by the Devil. If the demon can ride a skateboard to the Moon and swallow it after being transformed into a creature made of “glass and pain,” the Devil will grant them their freedom. It’s just as strange as that setup sounds. While you’ll need to execute combos to defeat bosses, this is a skateboarding game that leans more heavily on story than pure gameplay. It’s visually and sonically arresting too, with Blood Cultures and John Fio crafting a killer soundtrack I know I’ll be listening to for a long time to come. Skate Story is out now on Nintendo Switch 2, Steam and PS5 for $20. PlayStation Plus Extra and Premium members can play it at no extra cost. New releasesUnbeatable is another game I’ve had on my radar for some time, though I haven’t had a chance to jump in yet. This is another stylish game in which you play as Beat, who sings in a band. However, music is outlawed in this world (oh no!). Through rhythm-based minigames and battles with cops, Beat tries to bring back the music. There's a separate arcade mode with a dedicated progression system too.I'm a sucker for stories about rebellious underdogs, and this rhythm adventure could well hook me in. Unbeatable — from D-Cell Games and publisher Playstack — is available on Steam and PS5 for $28 (there’s a 10 percent discount on Steam until December 23). It's set to hit Xbox Series X/S very soon too.Speaking of games I've been keeping an eye on, Adrift (from solo developer S.K.9.8 and co-publisher Secret Sauce) was one of the first games I covered when I started doing this weekly roundup earlier this year. It's a driving game in which your aim is to deliver a volatile energy core. Since you're traversing a hot desert, you'll need to be careful to prevent the core from overheating and blowing up. Thankfully, there are safe spots and cooling stations where you can bring down the temperature.The vaporwave aesthetic of Adrift caught my eye and although I dig the presentation, the game isn't quite clicking for me in the early going. It didn't take long before my vehicle got stuck and I had to reset, and I'm finding the top-down world a little confusing to navigate. I'll stick with it for at least a little longer, though. Adrift is out now on Steam. It usually costs $13 though there's a 25 percent discount until December 23. I've very happy that a game like Drywall Eating Simulator can exist. Peripheral Playbox's satirical walking sim sees your character trying to deal with the maddening realities of daily life and the frustration that one may find in dealing with other people. Get mad enough and you'll be able to punch through a wall (something you'll have to do to move through the levels anyway). Then, you can munch on some drywall to calm yourself down.I had a good time with it and there’s some pointedly funny writing here. “I thought AI sucks but it told me that was wrong and I believed it,” says one person. That's all well and good, but I mainly just want the NPCs to leave me alone so I can eat drywall in peace. Drywall Eating Simulator is out now on Steam. It'll usually run you $10, but there's a 10 percent discount until December 17.Planet of Lana was one of my favorite games of 2023 and now it's available on iOS and Android for $9. It sees teenage Lana and her cute companion Mui making their way through a world that's been taken over by alien robots as they try to rescue Lana's sister.This is a puzzle platformer in the vein of Inside and Limbo, and despite the pretty and often bright presentation, it's just as dystopian as those games. It sounds gorgeous too, thanks in large part to a beautiful score from The Last Guardian composer Takeshi Furukawa. I'm very much looking forward to the sequel from Wishfully and publisher Thunderful. That's set to arrive next year.A Game About Digging A Hole is one of this year's real indie success stories. It’s a game that a developer started making in their spare time that has sold more than 1.2 million copies since February. After landing on PC and mobile, the $5 game from Doublebee and publisher Rokaplay is now on Nintendo Switch, Xbox Series X/S and PS5. It's on Game Pass Ultimate, Game Pass Premium and PC Game Pass.It's a straightforward loop. Start digging a hole in your backyard, sell the stuff you find, upgrade your equipment and keep going. Just, uh, be careful down there. You never quite know what you'll run into.Upcoming Vampire Therapist developer Little Bat Games has revealed its latest project, Better Than Us, which is coming to Steam in 2026. It's a narrative-driven sci-fi narrative game in which you'll infiltrate swanky parties thrown by wealth hoarders in the future to steal spoils back from them. Violence isn't the solution here, as you'll need to charm the ultra-rich, who buy elections and have \"monopolized AI development to ensure machines serve their interests\" (I dunno, this all seems extremely far-fetched). You can spin up a web of lies about things like how your husband died and how much Worldcoin you have. To maintain your ruse, you'll need to keep your story straight by remembering what you said and to which characters. Okomotive (Herdling, Far: Changing Tides) just revealed its next game. PinKeep is a roguelike deckbuilder in which you'll place structures on a playing field to fend off enemies. To collect resources, you'll need to play some pinball. By using the flippers (and flicking the ball for more precise movement), you can pick up what you need to fight back against your opponents. You can damage bad guys directly with the balls too. As a Ball x Pit enthusiast with a tepid but growing interest in deckbuilders, this speaks to me. A PinKeep demo is coming to Steam in January, with the full game set to arrive late in 2026.AudioMech is a neat-looking game that popped up for the first time during the pre-show of The Game Awards. This is a rhythm-based action title from Dylan Fitterer, the creator of Audiosurf. It taps into whatever music you have playing on your computer (even something that you're streaming or playing through a microphone) to customize both your weapons and opponents.A track that's heavy on bass might give you a longer sword, while vocals and lead instruments can power a cannon. There are several ways to play, including a mode in which you don't take damage and a boss rush option. AudioMech is coming to Steam and there's a demo available now. Let's wrap things up with something a little more relaxing. Lost and Found Co. is a hidden object game from Bit Egg Inc. and co-publisher Gamirror Games. During the latest Wholesome Snack showcase, it was revealed that the game is coming to Steam on February 11.It's little wonder that more than 170,000 Steam users have wishlisted this game. It looks absolutely lovely. The developers sought to recapture the \"magic\" of childhood puzzle books in their hand-drawn world. Here, you'll help Ducky, a duck-turned-human intern at a startup that hunts for items that townspeople have lost. There's a demo available that features the option to decorate a part of the world using items you find.This article originally appeared on Engadget at https://www.engadget.com/gaming/swallowing-the-moon-and-other-new-indie-games-worth-checking-out-154937071.html?src=rss",
          "feed_position": 46
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/5oDy4S77FSU28G1miSj9Ha/cda550cda52e6f8a81d2837d77efe6ff/nuneybits_Vector_art_of_a_video_conference_in_Zoom_blue_b4fb4be6-243a-4462-8913-626538caf7f6.webp?w=300&q=30",
      "popularity_score": 2015.2737058333332
    },
    {
      "id": "cluster_46",
      "coverage": 2,
      "updated_at": "Tue, 16 Dec 2025 13:25:02 -0500",
      "title": "Leona Health, the maker of an AI copilot that integrates with doctors' WhatsApp accounts for patient chats in Latin America, raised a $14M seed led by a16z (Marina Temkin/TechCrunch)",
      "neutral_headline": "Uber Eats alum lands $14M seed from a16z to fix...",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251216/p27#a251216p27",
          "published_at": "Tue, 16 Dec 2025 13:25:02 -0500",
          "title": "Leona Health, the maker of an AI copilot that integrates with doctors' WhatsApp accounts for patient chats in Latin America, raised a $14M seed led by a16z (Marina Temkin/TechCrunch)",
          "standfirst": "Marina Temkin / TechCrunch: Leona Health, the maker of an AI copilot that integrates with doctors' WhatsApp accounts for patient chats in Latin America, raised a $14M seed led by a16z &mdash; Caroline Merin, who spent nearly a decade developing on-demand speed as the first Latin American General Manager for Uber Eats &hellip;",
          "content": "Marina Temkin / TechCrunch: Leona Health, the maker of an AI copilot that integrates with doctors' WhatsApp accounts for patient chats in Latin America, raised a $14M seed led by a16z &mdash; Caroline Merin, who spent nearly a decade developing on-demand speed as the first Latin American General Manager for Uber Eats &hellip;",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/251216/i27.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/16/uber-eats-alum-lands-14m-seed-from-a16z-to-fix-whatsapp-chaos-for-latams-doctors/",
          "published_at": "Tue, 16 Dec 2025 18:11:58 +0000",
          "title": "Uber Eats alum lands $14M seed from a16z to fix WhatsApp chaos for LatAm&#8217;s doctors",
          "standfirst": "Leona Health built an AI co-pilot to manage the flood of patient messages Latin American doctors receive on WhatsApp.",
          "content": "Leona Health built an AI co-pilot to manage the flood of patient messages Latin American doctors receive on WhatsApp.",
          "feed_position": 8
        }
      ],
      "featured_image": "http://www.techmeme.com/251216/i27.jpg",
      "popularity_score": 2015.0812058333333
    },
    {
      "id": "cluster_52",
      "coverage": 2,
      "updated_at": "Tue, 16 Dec 2025 13:00:36 -0500",
      "title": "Source: OpenAI rolled back ChatGPT's model router, which sent some queries to reasoning models, for Free and $5/month Go tiers, as it was costly and hurt DAUs (Maxwell Zeff/Wired)",
      "neutral_headline": "OpenAI Rolls Back ChatGPT’s Model Router System for Most Users",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251216/p24#a251216p24",
          "published_at": "Tue, 16 Dec 2025 13:00:36 -0500",
          "title": "Source: OpenAI rolled back ChatGPT's model router, which sent some queries to reasoning models, for Free and $5/month Go tiers, as it was costly and hurt DAUs (Maxwell Zeff/Wired)",
          "standfirst": "Maxwell Zeff / Wired: Source: OpenAI rolled back ChatGPT's model router, which sent some queries to reasoning models, for Free and $5/month Go tiers, as it was costly and hurt DAUs &mdash; As OpenAI scrambles to improve ChatGPT, it's ditching a feature in its free tier that contributed to last summer's user revolt.",
          "content": "Maxwell Zeff / Wired: Source: OpenAI rolled back ChatGPT's model router, which sent some queries to reasoning models, for Free and $5/month Go tiers, as it was costly and hurt DAUs &mdash; As OpenAI scrambles to improve ChatGPT, it's ditching a feature in its free tier that contributed to last summer's user revolt.",
          "feed_position": 11,
          "image_url": "http://www.techmeme.com/251216/i24.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/openai-router-relaunch-gpt-5-sam-altman/",
          "published_at": "Tue, 16 Dec 2025 17:30:00 +0000",
          "title": "OpenAI Rolls Back ChatGPT’s Model Router System for Most Users",
          "standfirst": "As OpenAI scrambles to improve ChatGPT, it's ditching a feature in its free tier that contributed to last summer's user revolt.",
          "content": "As OpenAI scrambles to improve ChatGPT, it's ditching a feature in its free tier that contributed to last summer's user revolt.",
          "feed_position": 3,
          "image_url": "https://media.wired.com/photos/6940568e6f1488718f54b69a/master/pass/Model-Behavior-Why-OpenAI-Killed-the-Model-Router-in-GPT-5-2218344204.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251216/i24.jpg",
      "popularity_score": 2014.673983611111
    },
    {
      "id": "cluster_54",
      "coverage": 2,
      "updated_at": "Tue, 16 Dec 2025 18:00:00 +0000",
      "title": "ChatGPT image generation is now faster and better at following tweaks",
      "neutral_headline": "ChatGPT image generation is now faster and better at following tweaks",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/chatgpt-image-generation-is-now-faster-and-better-at-following-tweaks-180000750.html",
          "published_at": "Tue, 16 Dec 2025 18:00:00 +0000",
          "title": "ChatGPT image generation is now faster and better at following tweaks",
          "standfirst": "Following the release of GPT-5.2 last week, OpenAI has begun rolling out a new image generation model. The company says the updated ChatGPT Images is four times faster than its predecessor. If you're a frequent ChatGPT user, you'll know it can sometimes take a while for OpenAI's servers to create images, particularly during peak times and if you're not paying for ChatGPT Plus. In that respect, any improvement in speed is welcome. The new version is also better at following instructions, including when you want to edit something the new model just generated. You can ask the system to add, subtract, combine, blend and even transpose elements. At the same time, OpenAI says the update offers better text rendering. That's something many image models have traditionally struggled with, but according to the company, the new ChatGPT Images is capable of handling denser and smaller text. As part of the today's model update, OpenAI is additionally adding a dedicated Images section to the ChatGPT sidebar. Here you'll find preset filters and prompts you can look to for inspiration. A portrait of Sam Altman, in the style of Johannes Vermeer's Girl with a Pearl Earring. OpenAIThe new ChatGPT Images arrives just as Nano Banana Pro is responsible for a surge in Gemini usage. In October, Google said its chatbot had 650 million users, up from 450 million just a few months earlier in July. Nano Banana Pro has proven so popular, the company recently limited free users to just two image generations per day. For OpenAI, a strong response to Nano Banana Pro probably wasn't as important as ensuring it came out swinging against Gemini 3 Pro, but ChatGPT Images is a big part of why there are 800 million ChatGPT users. \"We believe we’re still at the beginning of what image generation can enable,\" OpenAI said. \"Today’s update is a meaningful step forward with more to come, from finer-grained edits to richer, more detailed outputs across languages.\"OpenAI is rolling out the new ChatGPT Images to all users starting today. If you're one of those people who miss GPT-4o, you'll be happy to learn you can continue to use the older version of the tool through a custom GPT. This article originally appeared on Engadget at https://www.engadget.com/ai/chatgpt-image-generation-is-now-faster-and-better-at-following-tweaks-180000750.html?src=rss",
          "content": "Following the release of GPT-5.2 last week, OpenAI has begun rolling out a new image generation model. The company says the updated ChatGPT Images is four times faster than its predecessor. If you're a frequent ChatGPT user, you'll know it can sometimes take a while for OpenAI's servers to create images, particularly during peak times and if you're not paying for ChatGPT Plus. In that respect, any improvement in speed is welcome. The new version is also better at following instructions, including when you want to edit something the new model just generated. You can ask the system to add, subtract, combine, blend and even transpose elements. At the same time, OpenAI says the update offers better text rendering. That's something many image models have traditionally struggled with, but according to the company, the new ChatGPT Images is capable of handling denser and smaller text. As part of the today's model update, OpenAI is additionally adding a dedicated Images section to the ChatGPT sidebar. Here you'll find preset filters and prompts you can look to for inspiration. A portrait of Sam Altman, in the style of Johannes Vermeer's Girl with a Pearl Earring. OpenAIThe new ChatGPT Images arrives just as Nano Banana Pro is responsible for a surge in Gemini usage. In October, Google said its chatbot had 650 million users, up from 450 million just a few months earlier in July. Nano Banana Pro has proven so popular, the company recently limited free users to just two image generations per day. For OpenAI, a strong response to Nano Banana Pro probably wasn't as important as ensuring it came out swinging against Gemini 3 Pro, but ChatGPT Images is a big part of why there are 800 million ChatGPT users. \"We believe we’re still at the beginning of what image generation can enable,\" OpenAI said. \"Today’s update is a meaningful step forward with more to come, from finer-grained edits to richer, more detailed outputs across languages.\"OpenAI is rolling out the new ChatGPT Images to all users starting today. If you're one of those people who miss GPT-4o, you'll be happy to learn you can continue to use the older version of the tool through a custom GPT. This article originally appeared on Engadget at https://www.engadget.com/ai/chatgpt-image-generation-is-now-faster-and-better-at-following-tweaks-180000750.html?src=rss",
          "feed_position": 10,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/sam-chatgpt-images.gif"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/openais-gpt-image-1-5-challenges-google-at-enterprise-grade-visuals",
          "published_at": "Tue, 16 Dec 2025 05:00:00 GMT",
          "title": "OpenAI's GPT Image 1.5 challenges Google at enterprise-grade visuals",
          "standfirst": "OpenAI made its image generation offerings more precise and consistent in its latest update to ChatGPT Images, as more enterprises and brands use AI image generation to help with design visualization. The updates will roll out to all ChatGPT users and the API as GPT Image 1.5. The company said it&#x27;s powered by GPT 5.2, which many early users found to be a powerful update for business use cases. “Many people’s first experience with ChatGPT involves turning a text prompt into a picture,” said Fidji Simo, OpenAI CEO of Applications, in a Substack post. “It’s a magical way to see what this technology can do, but the chat interface wasn&#x27;t originally designed for this. Creating and editing images is a different kind of task and deserves a space built for visuals.”Business-friendly updates in precise editing and instruction followingOne of the biggest updates to ChatGPT Images is more targeted editing, even when the image is generated on the chat platform rather than through the API. Image generation models such as ChatGPT Images, Google’s Nano Banana, and Stable Diffusion tout prompt-based tweaks to AI-made pictures, where the user can pinpoint specific parts of the photo to change. But those features can sometimes be hit-and-miss. With the update, OpenAI said the model better adheres to what the user wants “while keeping elements like lighting, composition, and people’s appearances consistent across inputs, outputs and subsequent edits.”Users can instruct the model to do most types of image editing, such as adding or subtracting an element, combining, blending, and transposing. OpenAI said that this model “follows instructions more reliably” than previous versions. It’s also able to render text better and generate actual, readable letters, even when these are denser or smaller. OpenAI updated the model to create better, smaller faces in photos featuring a large group of people. “These transformations work for both simple and more intricate concepts, and are easy to try using preset styles and ideas in the new ChatGPT Images feature — no written prompt required,” according to OpenAI.Battle of the image generators OpenAI’s image model update comes after Google’s much-lauded Nano Banana Pro image model, which drew praise from the developer community. The company must compete with other ever-growing, continually improving image-generation models that aim to attract more enterprise users. And it isn’t just Google that OpenAI has to contend with. In August, Alibaba announced that Qwen-Image can render readable text in both Chinese and English. Black Forest Labs released Flux.2, which also offers a robust, open-source image model.",
          "content": "OpenAI made its image generation offerings more precise and consistent in its latest update to ChatGPT Images, as more enterprises and brands use AI image generation to help with design visualization. The updates will roll out to all ChatGPT users and the API as GPT Image 1.5. The company said it&#x27;s powered by GPT 5.2, which many early users found to be a powerful update for business use cases. “Many people’s first experience with ChatGPT involves turning a text prompt into a picture,” said Fidji Simo, OpenAI CEO of Applications, in a Substack post. “It’s a magical way to see what this technology can do, but the chat interface wasn&#x27;t originally designed for this. Creating and editing images is a different kind of task and deserves a space built for visuals.”Business-friendly updates in precise editing and instruction followingOne of the biggest updates to ChatGPT Images is more targeted editing, even when the image is generated on the chat platform rather than through the API. Image generation models such as ChatGPT Images, Google’s Nano Banana, and Stable Diffusion tout prompt-based tweaks to AI-made pictures, where the user can pinpoint specific parts of the photo to change. But those features can sometimes be hit-and-miss. With the update, OpenAI said the model better adheres to what the user wants “while keeping elements like lighting, composition, and people’s appearances consistent across inputs, outputs and subsequent edits.”Users can instruct the model to do most types of image editing, such as adding or subtracting an element, combining, blending, and transposing. OpenAI said that this model “follows instructions more reliably” than previous versions. It’s also able to render text better and generate actual, readable letters, even when these are denser or smaller. OpenAI updated the model to create better, smaller faces in photos featuring a large group of people. “These transformations work for both simple and more intricate concepts, and are easy to try using preset styles and ideas in the new ChatGPT Images feature — no written prompt required,” according to OpenAI.Battle of the image generators OpenAI’s image model update comes after Google’s much-lauded Nano Banana Pro image model, which drew praise from the developer community. The company must compete with other ever-growing, continually improving image-generation models that aim to attract more enterprise users. And it isn’t just Google that OpenAI has to contend with. In August, Alibaba announced that Qwen-Image can render readable text in both Chinese and English. Black Forest Labs released Flux.2, which also offers a robust, open-source image model.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1IcAgCMelBUgBUy62Yr6fq/b26d47dd27075b8c1546a7a146f79d5f/robot_camera_cute_gpt.png?w=300&q=30"
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/sam-chatgpt-images.gif",
      "popularity_score": 2014.663983611111
    },
    {
      "id": "cluster_11",
      "coverage": 1,
      "updated_at": "Tue, 16 Dec 2025 21:57:55 +0000",
      "title": "Texas sues biggest TV makers, alleging smart TVs spy on users without consent",
      "neutral_headline": "Texas sues biggest TV makers, alleging smart TVs spy on users without consent",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/texas-sues-biggest-tv-makers-alleging-smart-tvs-spy-on-users-without-consent/",
          "published_at": "Tue, 16 Dec 2025 21:57:55 +0000",
          "title": "Texas sues biggest TV makers, alleging smart TVs spy on users without consent",
          "standfirst": "Automated Content Recognition brings \"mass surveillance\" to homes, lawsuits say.",
          "content": "Texas Attorney General Ken Paxton sued five large TV manufacturers yesterday, alleging that their smart TVs spy on viewers without consent. Paxton sued Samsung, the longtime TV market share leader, along with LG, Sony, Hisense, and TCL. “These companies have been unlawfully collecting personal data through Automated Content Recognition (‘ACR’) technology,” Paxton’s office alleged in a press release that contains links to all five lawsuits. “ACR in its simplest terms is an uninvited, invisible digital invader. This software can capture screenshots of a user’s television display every 500 milliseconds, monitor viewing activity in real time, and transmit that information back to the company without the user’s knowledge or consent. The companies then sell that consumer information to target ads across platforms for a profit. This technology puts users’ privacy and sensitive information, such as passwords, bank information, and other personal information at risk.” The lawsuits allege violations of the Texas Deceptive Trade Practices Act, seeking damages of up to $10,000 for each violation and up to $250,000 for each violation affecting people 65 years or older. Texas also wants restraining orders prohibiting the collection, sharing, and selling of ACR data while the lawsuits are pending.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/smart-tv-and-phone-1152x648-1765917384.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/smart-tv-and-phone-1152x648-1765917384.jpg",
      "popularity_score": 351.6292613888889
    },
    {
      "id": "cluster_15",
      "coverage": 1,
      "updated_at": "Tue, 16 Dec 2025 21:25:05 +0000",
      "title": "The $4.3 billion space telescope Trump tried to cancel is now complete",
      "neutral_headline": "The $4.3 billion space telescope Trump tried to cancel is now complete",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/the-4-3-billion-space-telescope-trump-tried-to-cancel-is-now-complete/",
          "published_at": "Tue, 16 Dec 2025 21:25:05 +0000",
          "title": "The $4.3 billion space telescope Trump tried to cancel is now complete",
          "standfirst": "\"We're going to be making 3D movies of what is going on in the Milky Way galaxy.\"",
          "content": "A few weeks ago, technicians inside a cavernous clean room in Maryland made the final connection to complete assembly of NASA’s Nancy Grace Roman Space Telescope. Parts of this new observatory, named for NASA’s first chief astronomer, recently completed a spate of tests to ensure it can survive the shaking and intense sound of a rocket launch. Engineers placed the core of the telescope inside a thermal vacuum chamber, where it withstood the airless conditions and extreme temperature swings it will see in space. Then, on November 25, teams at NASA’s Goddard Space Flight Center in Greenbelt, Maryland, joined the inner and outer portions of the Roman Space Telescope. With this milestone, NASA declared the observatory complete and on track for launch as soon as the fall of 2026.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Trailer_still_1-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Trailer_still_1-1-1152x648.jpg",
      "popularity_score": 349.0820391666667
    },
    {
      "id": "cluster_38",
      "coverage": 1,
      "updated_at": "Tue, 16 Dec 2025 18:52:43 +0000",
      "title": "Software leaks point to the first Apple Silicon “iMac Pro,” among other devices",
      "neutral_headline": "Software leaks point to the first Apple Silicon “iMac Pro,” among other devices",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/leaked-debug-kit-suggests-apple-is-testing-a-new-imac-pro-among-many-other-macs/",
          "published_at": "Tue, 16 Dec 2025 18:52:43 +0000",
          "title": "Software leaks point to the first Apple Silicon “iMac Pro,” among other devices",
          "standfirst": "Resurrected high-end all-in-one could be a worthy successor to 2017's iMac Pro.",
          "content": "Apple doesn’t like to talk about its upcoming products before it’s ready, but sometimes the company’s software does the talking for it. So far this week we’ve had a couple of software-related leaks that have outed products Apple is currently testing—one a pre-release build of iOS 26, and the other some leaked files from a kernel debug kit (both via MacRumors). Most of the new devices referenced in these leaks are straightforward updates to products that already exist: a new Apple TV, a HomePod mini 2, new AirTags and AirPods, an M4 iPad Air, a 12th-generation iPad to replace the current A16 version, next-generation iPhones (including the 17e, 18, and the rumored foldable model), a new Studio Display model, some new smart home products we’ve already heard about elsewhere, and M5 updates for the MacBook Air, Mac mini, Mac Studio, and the other MacBook Pros. There’s also yet another reference to the lower-cost MacBook that Apple is apparently planning to replace the M1 MacBook Air it still sells via Walmart for $599. For power users, though, the most interesting revelation might be that Apple is working on a higher-end Apple Silicon iMac powered by an M5 Max chip. The kernel debug kit references an iMac with the internal identifier J833c, based on a platform identified as H17C—and H17C is apparently based on the M5 Max, rather than a lower-end M5 chip. (For those who don’t have Apple’s branding memorized, “Max” is associated with Apple’s second-fastest chips; the M5 Max would be faster than the M5 or M5 Pro, but slower than the rumored M5 Ultra.)Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/iMac-Pro-front-scaled-1-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/iMac-Pro-front-scaled-1-1152x648.jpeg",
      "popularity_score": 336.54259472222225
    },
    {
      "id": "cluster_22",
      "coverage": 1,
      "updated_at": "Tue, 16 Dec 2025 20:25:57 +0000",
      "title": "Senators count the shady ways data centers pass energy costs on to Americans",
      "neutral_headline": "Senators count the shady ways data centers pass energy costs on to Americans",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/shady-data-center-deals-doom-americans-to-higher-energy-bills-senators-say/",
          "published_at": "Tue, 16 Dec 2025 20:25:57 +0000",
          "title": "Senators count the shady ways data centers pass energy costs on to Americans",
          "standfirst": "Senators demand Big Tech pay upfront for data center spikes in electricity bills.",
          "content": "Senators launched a probe Tuesday demanding that tech companies explain exactly how they plan to prevent data center projects from increasing electricity bills in communities where prices are already skyrocketing. In letters to seven AI firms, Senators Elizabeth Warren (D-Mass.), Chris Van Hollen (D-Md.), and Richard Blumenthal (D-Conn.) cited a study estimating that “electricity prices have increased by as much as 267 percent in the past five years” in “areas located near significant data center activity.” Prices increase, senators noted, when utility companies build out extra infrastructure to meet data centers’ energy demands—which can amount to one customer suddenly consuming as much power as an entire city. They also increase when demand for local power outweighs supply. In some cases, residents are blindsided by higher bills, not even realizing a data center project was approved, because tech companies seem intent on dodging backlash and frequently do not allow terms of deals to be publicly disclosed.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249021916-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249021916-1024x648.jpg",
      "popularity_score": 330.0964836111111
    },
    {
      "id": "cluster_59",
      "coverage": 1,
      "updated_at": "Tue, 16 Dec 2025 17:28:32 +0000",
      "title": "Reporter suggests Half-Life 3 will be a Steam Machine launch title",
      "neutral_headline": "Reporter suggests Half-Life 3 will be a Steam Machine launch title",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/12/journalist-insists-half-life-3-will-launch-with-steam-machine-in-spring-2026/",
          "published_at": "Tue, 16 Dec 2025 17:28:32 +0000",
          "title": "Reporter suggests Half-Life 3 will be a Steam Machine launch title",
          "standfirst": "\"Everybody I've talked to are still adamant,\" even after previous rumors didn't pan out.",
          "content": "If you can take your mind way back to the beginning of 2025, you might remember a fresh wave of rumors suggesting that Half-Life 3 was finally reaching the final stages of production, and could be announced and/or released at any moment. Now, though, 2025 seems set to come to a close without any official news of a game fans have been waiting literal decades for. That doesn’t necessarily mean a Half-Life 3 announcement and/or release isn’t imminent, though. On the contrary, veteran journalist Mike Straw insisted on a recent Insider Gaming podcast that “everybody I’ve talked to are still adamant [Half-Life 3] is a game that will be a launch title with the Steam Machine.” Straw—who has a long history of reporting gaming rumors from anonymous sources—said this Half-Life 3 information is “not [from] these run-of-the-mill sources that haven’t gotten me information before. … These aren’t like random, one-off people.” And those sources are “still adamant that the game is coming in the spring,” Straw added, noting that he was “specifically told [that] spring 2026 [is the window] for the Steam Machine, for the Frame, for the Controller, [and] for Half-Life 3.”Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2017/08/024-1152x648-1740609184.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2017/08/024-1152x648-1740609184.jpg",
      "popularity_score": 307.1395391666667
    },
    {
      "id": "cluster_64",
      "coverage": 1,
      "updated_at": "Tue, 16 Dec 2025 17:00:57 +0000",
      "title": "Utah leaders hinder efforts to develop solar energy supply",
      "neutral_headline": "Utah leaders hinder efforts to develop solar energy supply",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/utah-leaders-hinder-efforts-to-develop-solar-energy-supply/",
          "published_at": "Tue, 16 Dec 2025 17:00:57 +0000",
          "title": "Utah leaders hinder efforts to develop solar energy supply",
          "standfirst": "Solar power accounts for two-thirds of the new projects waiting to connect to the state’s power grid.",
          "content": "Utah Gov. Spencer Cox believes his state needs more power—a lot more. By some estimates, Utah will require as much electricity in the next five years as it generated all last century to meet the demands of a growing population as well as chase data centers and AI developers to fuel its economy. To that end, Cox announced Operation Gigawatt last year, declaring the state would double energy production in the next decade. Although the announcement was short on details, Cox, a Republican, promised his administration would take an “any of the above” approach, which aims to expand all sources of energy production. Despite that goal, the Utah Legislature’s Republican supermajority, with Cox’s acquiescence, has taken a hard turn against solar power—which has been coming online faster than any other source in Utah and accounts for two-thirds of the new projects waiting to connect to the state’s power grid.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2241255023-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2241255023-1152x648.jpg",
      "popularity_score": 302.67981694444444
    },
    {
      "id": "cluster_77",
      "coverage": 1,
      "updated_at": "Tue, 16 Dec 2025 15:38:57 +0000",
      "title": "2026 Mercedes CLA first drive: Entry level doesn’t mean basic",
      "neutral_headline": "2026 Mercedes CLA first drive: Entry level doesn’t mean basic",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/12/2026-mercedes-cla-first-drive-entry-level-doesnt-mean-basic/",
          "published_at": "Tue, 16 Dec 2025 15:38:57 +0000",
          "title": "2026 Mercedes CLA first drive: Entry level doesn’t mean basic",
          "standfirst": "Starting at $47,250, Mercedes' new electric sedan is quite compelling.",
          "content": "Mercedes-Benz provided flights from Washington to San Francisco and accommodation so Ars could drive the CLA. Ars does not accept paid editorial content. SAN FRANCISCO—Automakers are starting to follow somewhat familiar paths as they continue their journeys to electrification. Electric vehicles are, at first, strange new tech, and usually look like it. Mercedes-Benz’s EQS and EQE are good examples—with bodies that look like bars of soap worn down in the shower, they stood out. For early adopters and trailblazers that might be fine, but you need to sell cars to normal people if you want to survive, and that means making EVs more normal. Which is what Mercedes did with its newest one, the all-electric CLA. The normal looks belie the amount of new technology that Mercedes has packed into the CLA, though. The car sticks to the four-door coupe look that the company pioneered a couple of decades ago, but there’s a thoroughly modern electric powertrain connected to the wheels, run by four powerful networked computers. And yes, there’s AI. (For the pedants, “coupe” means cut down, not two-door, so the name is accurate.) The CLA is the first of a new series of Mercedes that will use the same modular architecture, and interestingly, it’s powertrain agnostic—a hybrid CLA is coming in time, too. But first the battery EV, which makes good use of some technology Mercedes developed for the EQXX concept car.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/2026-Mercedes-Benz-CLA-4-1152x648-1765897346.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/2026-Mercedes-Benz-CLA-4-1152x648-1765897346.jpg",
      "popularity_score": 291.31315027777777
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Tue, 16 Dec 2025 15:09:45 +0000",
      "title": "Ars Live Today: 3 former CDC leaders detail impacts of RFK Jr.’s anti-science agenda",
      "neutral_headline": "Ars Live Today: 3 former CDC leaders detail impacts of RFK Jr.’s anti-science agenda",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/ars-live-3-former-cdc-leaders-detail-impacts-of-rfk-jr-s-anti-science-agenda/",
          "published_at": "Tue, 16 Dec 2025 15:09:45 +0000",
          "title": "Ars Live Today: 3 former CDC leaders detail impacts of RFK Jr.’s anti-science agenda",
          "standfirst": "Join us today, December 16, at 2 pm ET to hear from leaders who resigned in protest.",
          "content": "The Centers for Disease Control and Prevention is in critical condition. This year, the premier public health agency had its funding brutally cut and staff gutted, its mission sabotaged, and its headquarters riddled with literal bullets. The over 500 rounds fired were meant for its scientists and public health experts, who endured only to be sidelined, ignored, and overruled by Health Secretary Robert F. Kennedy Jr., an anti-vaccine activist hellbent on warping the agency to fit his anti-science agenda. Then, on August 27, Kennedy fired CDC Director Susan Monarez just weeks after she was confirmed by the Senate. She had refused to blindly approve vaccine recommendations from a panel of vaccine skeptics and contrarians that he had hand-selected. The agency descended into chaos, and Monarez wasn’t the only one to leave the agency that day. Three top leaders had reached their breaking point and coordinated their resignations upon the dramatic ouster: Drs. Demetre Daskalakis, Debra Houry, and Daniel Jernigan walked out of the agency as their colleagues rallied around them.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2231820155-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2231820155-1152x648.jpg",
      "popularity_score": 289.8264836111111
    },
    {
      "id": "cluster_114",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 22:41:43 +0000",
      "title": "Merriam-Webster’s word of the year delivers a dismissive verdict on junk AI content",
      "neutral_headline": "Merriam-Webster’s word of the year delivers a dismissive verdict on junk AI content",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/12/merriam-webster-crowns-slop-word-of-the-year-as-ai-content-floods-internet/",
          "published_at": "Mon, 15 Dec 2025 22:41:43 +0000",
          "title": "Merriam-Webster’s word of the year delivers a dismissive verdict on junk AI content",
          "standfirst": "Dictionary codifies the term that took hold in 2024 for low-quality AI-generated content.",
          "content": "Like most tools, generative AI models can be misused. And when the misuse gets bad enough that a major dictionary notices, you know it has become a cultural phenomenon. On Sunday, Merriam-Webster announced that “slop” is its 2025 Word of the Year, reflecting how the term has become shorthand for the flood of low-quality AI-generated content that has spread across social media, search results, and the web at large. The dictionary defines slop as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.” “It’s such an illustrative word,” Merriam-Webster President Greg Barlow told The Associated Press. “It’s part of a transformative technology, AI, and it’s something that people have found fascinating, annoying, and a little bit ridiculous.”Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2241620003-1152x648-1765829622.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2241620003-1152x648-1765829622.jpg",
      "popularity_score": 268
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 22:14:28 +0000",
      "title": "Stranger Things S5 trailer teases Vol. 2",
      "neutral_headline": "Stranger Things S5 trailer teases Vol. 2",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/12/stranger-things-s5-trailer-teases-vol-2/",
          "published_at": "Mon, 15 Dec 2025 22:14:28 +0000",
          "title": "Stranger Things S5 trailer teases Vol. 2",
          "standfirst": "\"Everything we've ever assumed about the Upside Down has been dead wrong.\"",
          "content": "We’re 10 days away from the next installment of the fifth and final season of Stranger Things, and Netflix has released a new trailer for what it’s calling Volume 2. This will cover episodes five through seven, with the final episode comprising Vol. 3. (Spoilers for Season 5, Vol. 1 below.) Season 4 ended with Vecna—the Big Bad behind it all—opening the gate that allowed the Upside Down to leak into Hawkins. We got a time jump for S5, Vol. 1, but in a way, we came full circle, since those events coincided with the third anniversary of Will’s original disappearance in S1.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/vecna1-1152x648-1765835577.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/vecna1-1152x648-1765835577.jpg",
      "popularity_score": 255
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 20:10:25 +0000",
      "title": "Murder-suicide case shows OpenAI selectively hides data after users die",
      "neutral_headline": "Murder-suicide case shows OpenAI selectively hides data after users die",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/openai-refuses-to-say-where-chatgpt-logs-go-when-users-die/",
          "published_at": "Mon, 15 Dec 2025 20:10:25 +0000",
          "title": "Murder-suicide case shows OpenAI selectively hides data after users die",
          "standfirst": "OpenAI accused of hiding full ChatGPT logs in murder-suicide case.",
          "content": "OpenAI is facing increasing scrutiny over how it handles ChatGPT data after users die, only selectively sharing data in lawsuits over ChatGPT-linked suicides. Last week, OpenAI was accused of hiding key ChatGPT logs from the days before a 56-year-old bodybuilder, Stein-Erik Soelberg, took his own life after “savagely” murdering his mother, 83-year-old Suzanne Adams. According to the lawsuit—which was filed by Adams’ estate on behalf of surviving family members—Soelberg struggled with mental health problems after a divorce led him to move back into Adams’ home in 2018. But allegedly Soelberg did not turn violent until ChatGPT became his sole confidant, validating a wide range of wild conspiracies, including a dangerous delusion that his mother was part of a network of conspirators spying on him, tracking him, and making attempts on his life.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Stein-Erik-Soelberg-and-Suzanne-Adams-via-complaint-1152x648-1765827196.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Stein-Erik-Soelberg-and-Suzanne-Adams-via-complaint-1152x648-1765827196.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_117",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 21:15:55 +0000",
      "title": "Microsoft will finally kill obsolete cipher that has wreaked decades of havoc",
      "neutral_headline": "Microsoft will finally kill obsolete cipher that has wreaked decades of havoc",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/12/microsoft-will-finally-kill-obsolete-cipher-that-has-wreaked-decades-of-havoc/",
          "published_at": "Mon, 15 Dec 2025 21:15:55 +0000",
          "title": "Microsoft will finally kill obsolete cipher that has wreaked decades of havoc",
          "standfirst": "The weak RC4 for administrative authentication has been a hacker holy grail for decades.",
          "content": "Microsoft is killing off an obsolete and vulnerable encryption cipher that Windows has supported by default for 26 years following more than a decade of devastating hacks that exploited it and recently faced blistering criticism from a prominent US senator. When the software maker rolled out Active Directory in 2000, it made RC4 a sole means of securing the Windows component, which administrators use to configure and provision fellow administrator and user accounts inside large organizations. RC4, short for Rivist Cipher 4, is a nod to mathematician and cryptographer Ron Rivest of RSA Security, who developed the stream cipher in 1987. Within days of the trade-secret-protected algorithm being leaked in 1994, a researcher demonstrated a cryptographic attack that significantly weakened the security it had been believed to provide. Despite the known susceptibility, RC4 remained a staple in encryption protocols, including SSL and its successor TLS, until about a decade ago. Out with the old One of the most visible holdouts in supporting RC4 has been Microsoft. Eventually, Microsoft upgraded Active Directory to support the much more secure AES encryption standard. But by default, Windows servers have continued to respond to RC4-based authentication requests and return an RC4-based response. The RC4 fallback has been a favorite weakness hackers have exploited to compromise enterprise networks. Use of RC4 played a key role in last year’s breach of health giant Ascension. The breach caused life-threatening disruptions at 140 hospitals and put the medical records of 5.6 million patients into the hands of the attackers. US Senator Ron Wyden (D-Ore.) in September called on the Federal Trade Commission to investigate Microsoft for “gross cybersecurity negligence,” citing the continued default support for RC4.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/microsoft-logo-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/microsoft-logo-1024x648.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 20:20:05 +0000",
      "title": "Microsoft takes down mod that re-created Halo 3 in Counter-Strike 2",
      "neutral_headline": "Microsoft takes down mod that re-created Halo 3 in Counter-Strike 2",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/12/microsoft-takes-down-mod-that-recreated-halo-3-in-counter-strike-2/",
          "published_at": "Mon, 15 Dec 2025 20:20:05 +0000",
          "title": "Microsoft takes down mod that re-created Halo 3 in Counter-Strike 2",
          "standfirst": "Project Misriah creator vows to use new experience \"to cook up something else.\"",
          "content": "Last month saw the release of Project Misriah, an ambitious modding project that tried to re-create the feel of Halo 3 inside Valve’s Counter-Strike 2. That project has now been taken down from the Steam Workshop, though, after drawing a Digital Millennium Copyright Act complaint from Microsoft. Modder Froddoyo introduced Project Misriah on November 16 as “a workshop collection of Halo ported maps and assets that aims to bring a Halo 3 multiplayer-like experience to Counter-Strike 2.” Far from just being inspired by Halo 3, the mod directly copied multiple sound effects, character models, maps, and even movement mechanics from Bungie and Microsoft’s popular series. In the weeks since, Project Misriah has drawn a lot of praise from both Halo fans and those impressed by what modders could pull off with the Source 2 engine. But last Wednesday, modder Froddoyo shared a DMCA request from Microsoft citing the “unauthorized use of Halo game content in a [Steam] workshop not associated with Halo games.”Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/mistriah-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/mistriah-1152x648.png",
      "popularity_score": 145
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 19:38:32 +0000",
      "title": "UK to “encourage” Apple and Google to put nudity-blocking systems on phones",
      "neutral_headline": "UK to “encourage” Apple and Google to put nudity-blocking systems on phones",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/uk-to-encourage-apple-and-google-to-put-nudity-blocking-systems-on-phones/",
          "published_at": "Mon, 15 Dec 2025 19:38:32 +0000",
          "title": "UK to “encourage” Apple and Google to put nudity-blocking systems on phones",
          "standfirst": "Government seeks \"nudity-detection algorithms\" in iOS and Android, report says.",
          "content": "The UK government reportedly will “encourage” Apple and Google to prevent phones from displaying nude images except when users verify that they are adults. The forthcoming push for nudity-blocking systems was reported by the Financial Times today. The report said the UK won’t institute a legal requirement “for now.” But asking companies to block nude images could be the first step toward making it mandatory if the government doesn’t get what it wants. “The UK government wants technology companies to block explicit images on phones and computers by default to protect children, with adults having to verify their age to create and access such content,” the FT report said. “Ministers want the likes of Apple and Google to incorporate nudity-detection algorithms into their device operating systems to prevent users taking photos or sharing images of genitalia unless they are verified as adults.”Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/10/phone-locking-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/10/phone-locking-1152x648.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 18:13:24 +0000",
      "title": "Google will end dark web reports that alerted users to leaked data",
      "neutral_headline": "Google will end dark web reports that alerted users to leaked data",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/google-is-shutting-down-dark-web-reports-in-january-because-they-werent-helpful/",
          "published_at": "Mon, 15 Dec 2025 18:13:24 +0000",
          "title": "Google will end dark web reports that alerted users to leaked data",
          "standfirst": "Google says the reports lacked \"helpful next steps.\"",
          "content": "Google began offering “dark web reports” a while back, but the company has just announced the feature will be going away very soon. In an email to users of the service, Google says it will stop telling you about dark web data leaks in February. This probably won’t negatively impact your security or privacy because, as Google points out in its latest email, there’s really nothing you can do about the dark web. The dark web reports launched in March 2023 as a perk for Google One subscribers. The reports were expanded to general access in 2024. Now, barely a year later, Google has decided it doesn’t see the value in this type of alert for users. Dark web reports provide a list of partially redacted user data retrieved from shadowy forums and sites where such information is bought and sold. However, that’s all it is—a list. The dark web consists of so-called hidden services hosted inside the Tor network. You need a special browser or connection tools in order to access Tor hidden services, and its largely anonymous nature has made it a favorite hangout for online criminals. If a company with your personal data has been hacked, that data probably lives somewhere on the dark web.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/google-logo-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/google-logo-1152x648.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_140",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 12:30:44 +0000",
      "title": "Verizon refused to unlock man’s iPhone, so he sued the carrier and won",
      "neutral_headline": "Verizon refused to unlock man’s iPhone, so he sued the carrier and won",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/verizon-refused-to-unlock-mans-iphone-so-he-sued-the-carrier-and-won/",
          "published_at": "Mon, 15 Dec 2025 12:30:44 +0000",
          "title": "Verizon refused to unlock man’s iPhone, so he sued the carrier and won",
          "standfirst": "Verizon changed policy after he bought the phone, wouldn't unlock it despite FCC rule.",
          "content": "When Verizon refused to unlock an iPhone purchased by Kansas resident Patrick Roach, he had no intention of giving up without a fight. Roach sued the wireless carrier in small claims court and won. Roach bought a discounted iPhone 16e from Verizon’s Straight Talk brand on February 28, 2025, as a gift for his wife’s birthday. He intended to pay for one month of service, cancel, and then switch the phone to the US Mobile service plan that the couple uses. Under federal rules that apply to Verizon and a Verizon unlocking policy that was in place when Roach bought the phone, this strategy should have worked. “The best deals tend to be buying it from one of these MVNOs [Mobile Virtual Network Operators] and then activating it until it unlocks and then switching it to whatever you are planning to use it with. It usually saves you about half the value of the phone,” Roach said in a phone interview.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/verizon-jerks-locked-phone-1152x648-1765486982.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/verizon-jerks-locked-phone-1152x648-1765486982.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_119",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 21:05:18 +0000",
      "title": "Ford ends F-150 Lightning production, starts battery storage business",
      "neutral_headline": "Ford ends F-150 Lightning production, starts battery storage business",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/12/ford-ends-f-150-lightning-production-starts-battery-storage-business/",
          "published_at": "Mon, 15 Dec 2025 21:05:18 +0000",
          "title": "Ford ends F-150 Lightning production, starts battery storage business",
          "standfirst": "It looks like battery electric vehicles are out of fashion at the Blue Oval.",
          "content": "Ford’s F-150 Lightning production line has fallen silent, and its employees are now building more gas and hybrid trucks. The automaker continues to retreat from the big bet it made on Americans embracing full-size battery electric pickup trucks, and will focus instead on cheaper vehicles, hybrids, and range-extended electric vehicles—or EREVs—instead, it announced today. One of those EREVs will be the Lighting’s replacement. With a gasoline generator that just charges the battery—series hybrid fans rejoice—the next Lightning comes with the towing ability that Ford says its customers consider “non-negotiable,” and up to 700 miles (1,126 km) of range. “Our next-generation F-150 Lightning EREV will be every bit as revolutionary. It delivers everything Lightning customers love – near instantaneous torque and pure electric driving. But with a high-power generator enabling an estimated range of 700+ miles, it tows like a locomotive. Heavy-duty towing and cross-country travel will be as effortless as the daily commute,” said Doug Field, Ford’s chief EV, digital and design officer.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2250038446-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2250038446-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_125",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 19:53:04 +0000",
      "title": "Filmmaker Rob Reiner, wife, killed in horrific home attack",
      "neutral_headline": "Filmmaker Rob Reiner, wife, killed in horrific home attack",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/12/r-i-p-rob-reiner-beloved-filmmaker-dead-at-78/",
          "published_at": "Mon, 15 Dec 2025 19:53:04 +0000",
          "title": "Filmmaker Rob Reiner, wife, killed in horrific home attack",
          "standfirst": "The Reiners' troubled 32-year-old son, Nick, has been arrested in conjunction with the killings.",
          "content": "We woke up this morning to the horrifying news that beloved actor and director Rob Reiner and his wife Michele were killed in their Brentwood home in Los Angeles last night. Both had been stabbed multiple times. Details are scarce, but the couple’s 32-year-old son, Nick—who has long struggled with addiction and recently moved back in with his parents—has been arrested in connection with the killings, with bail set at $4 million. [UPDATE: Nick Reiner’s bail has been revoked and he faces possible life in prison.] “As a result of the initial investigation, it was determined that the Reiners were the victims of homicide,” the LAPD said. “The investigation further revealed that Nick Reiner, the 32-year-old son of Robert and Michele Reiner, was responsible for their deaths. Nick Reiner was located and arrested at approximately 9:15 p.m. He was booked for murder and remains in custody with no bail. On Tuesday, December 16, 2025, the case will be presented to the Los Angeles County District Attorney’s Office for filing consideration.” “It is with profound sorrow that we announce the tragic passing of Michele and Rob Reiner,” the family said in a statement confirming the deaths. “We are heartbroken by this sudden loss, and we ask for privacy during this unbelievably difficult time.”Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/reiner1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/reiner1-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 16:44:01 +0000",
      "title": "Oh look, yet another Starship clone has popped up in China",
      "neutral_headline": "Oh look, yet another Starship clone has popped up in China",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/oh-look-yet-another-starship-clone-has-popped-up-in-china/",
          "published_at": "Mon, 15 Dec 2025 16:44:01 +0000",
          "title": "Oh look, yet another Starship clone has popped up in China",
          "standfirst": "Chinese companies are no longer hiding their intent to clone SpaceX. They're advertising it.",
          "content": "Every other week, it seems, a new Chinese launch company pops up with a rocket design and a plan to reach orbit within a few years. For a long time, the majority of these companies revealed designs that looked a lot like SpaceX’s Falcon 9 rocket. The first of these copy cats, the medium-lift Zhuque-3 rocket built by LandSpace, launched earlier this month. Its primary mission was nominal, but the Zhuque-3 rocket failed its landing attempt, which is understandable for a first flight. Doubtless there will be more Chinese Falcon 9-like rockets making their debut in the near future. However, over the last year, there has been a distinct change in announcements from China when it comes to new launch technology. Just as SpaceX is seeking to transition from its workhorse Falcon 9 rocket—which has now been flying for a decade and a half—to the fully reusable Starship design, so too are Chinese companies modifying their visions.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/china-rocket.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/china-rocket.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Mon, 15 Dec 2025 15:24:41 +0000",
      "title": "Roomba maker iRobot swept into bankruptcy",
      "neutral_headline": "Roomba maker iRobot swept into bankruptcy",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2025/12/roomba-maker-irobot-swept-into-bankruptcy/",
          "published_at": "Mon, 15 Dec 2025 15:24:41 +0000",
          "title": "Roomba maker iRobot swept into bankruptcy",
          "standfirst": "Shenzhen-based Picea Robotics, its lender and primary supplier, will acquire all of iRobot’s shares.",
          "content": "Roomba maker iRobot has filed for bankruptcy and will be taken over by its Chinese supplier after the company that popularized the robot vacuum cleaner fell under the weight of competition from cheaper rivals. The US-listed group on Sunday said it had filed for Chapter 11 bankruptcy in Delaware as part of a restructuring agreement with Shenzhen-based Picea Robotics, its lender and primary supplier, which will acquire all of iRobot’s shares. The deal comes nearly two years after a proposed $1.5 billion acquisition by Amazon fell through over competition concerns from EU regulators.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-633690806-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-633690806-1152x648.jpg",
      "popularity_score": 130
    }
  ]
}