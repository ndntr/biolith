{
  "updated_at": "2026-01-05T07:28:54.236Z",
  "clusters": [
    {
      "id": "cluster_3",
      "coverage": 2,
      "updated_at": "Mon, 05 Jan 2026 07:00:00 +0000",
      "title": "L'Oréal’s CES 2026 beauty devices include a skin-like flexible LED mask",
      "neutral_headline": "L'Oréal’s CES 2026 beauty devices include a skin-like flexible LED mask",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/science/loreals-ces-2026-beauty-devices-include-a-skin-like-flexible-led-mask-070000576.html",
          "published_at": "Mon, 05 Jan 2026 07:00:00 +0000",
          "title": "L'Oréal’s CES 2026 beauty devices include a skin-like flexible LED mask",
          "standfirst": "Over the last ten or so years, L'Oréal has brought a taste of beauty tech to the masses at CES 2026. This time, it has three devices to show off: the “Light Straight + Multi-styler” as well as the helpfully named LED Face Mask and LED Eye Mask. Don’t let the unassuming names mislead you. These three products actually harbor some unique traits. The Light Straight (and multi-styler, which I’m going to just call the Light Straight from here on), for instance, uses infrared light to help generate the heat required to style your hair. Meanwhile, the LED Face Mask is different from those made by companies like Dr. Dennis Gross, Omnilux, Therabody and Shark. Instead of fairly hard shells that sit rigidly on your face, L'Oréal’s version looks to be pliable and thin. I haven’t seen this in person yet, though I do intend to do so as soon as possible, but the pictures of the LED Eye Mask look, and I mean this in the best way, ridonkulous. Not only do they appear supple, but they also seem to be transparent, with bulbs and wires you can see inside. In some of the images that the company provided, the masks are completely awash in red as the lights are on. In others, only parts of it are red. One of them even shows the masks sitting in a little carrying case and they almost look like wireless earbuds. I haven’t seen any photos of the LED Face Mask but I can imagine they’d be fairly similar to these.The L'Oréal LED Eye Mask in a carrying caseL'Oréal According to the press release, this “ultra-thin, flexible silicone mask” is currently “in prototype form” and was developed in collaboration with LED solutions company iSmart. The company said this mask “delivers light directly to the face” in 10-minute automatically timed sessions. That’s not too different from existing red light masks, but L’Oréal said it believes “the key to the mask’s effectiveness is its advanced, transparent support, which integrates a skin-safe microcircuit to precisely control the emission of two selected wavelengths of light—red light (630 nm) and near-infrared light (830 nm).”Since the mask is only launching in 2027, there aren’t details yet on pricing and availability, though the company’s global vice president of tech and open innovation Guive Balooch told Engadget that it would be a premium product that would sit somewhere below the highest priced offerings currently out there.One of my problems with full-face LED masks is that my skin always feels too parched under them, because you have to use them on clean, dry skin for 10 minutes at a time. Balooch told me that L'Oréal would have a serum developed to be used with its mask that would help with that, while also improving the effectiveness of the light treatment.That certainly is intriguing, and Balooch indicated that creating formulations that are designed to work with devices like the LED masks is a future direction for the company. A pair of hands using the L'Oréal Light Straight and multi-styler on a person's hair. L'Oréal I’m also interested in the Light Straight, which like the company’s AirLight Pro uses infrared light to help dry or style hair. According to the company’s press release, hair straighteners with “ordinary heating places can reach temperatures of 400°F and higher—above the threshold at which keratin denatures, leading to weakened cuticles, breakage and reduced shine.” For context, I used to turn my flatiron all the way up to 425 degrees Fahrenheit to tame my tresses (though these days I find a more reasonable 330 degrees is good enough).L’Oréal says the Light Straight and its “patented infrared light technology” can “help provide exceptional styling results at lower temperatures, to better protect the health of the hair.” The device’s glass plates never exceed 320 degrees, and the company says its testing found that the Light Straight is three times faster and leaves hair twice as smooth as “leading premium hair stylers.” I’m not sure how you would quantify smoothness, but I’m hopeful the results do pan out in the real world. The Light Straight uses near-infrared light that L’Oréal says “penetrates deeply into hair fibers” to “reshape internal hydrogen bonds.” It also has sensors onboard with “built-in proprietary algorithms and machine learning” to adapt to your gestures “to maximize individual experience.” I’m not sure what that means, but I hope to find out more this week at CES. Given the Light Straight doesn’t launch till 2027, it’s not surprising that pricing and other details aren’t yet available. But for now, I’m keen to see companies continue to investigate novel, hopefully healthier ways for us to look and feel beautiful.This article originally appeared on Engadget at https://www.engadget.com/science/loreals-ces-2026-beauty-devices-include-a-skin-like-flexible-led-mask-070000576.html?src=rss",
          "content": "Over the last ten or so years, L'Oréal has brought a taste of beauty tech to the masses at CES 2026. This time, it has three devices to show off: the “Light Straight + Multi-styler” as well as the helpfully named LED Face Mask and LED Eye Mask. Don’t let the unassuming names mislead you. These three products actually harbor some unique traits. The Light Straight (and multi-styler, which I’m going to just call the Light Straight from here on), for instance, uses infrared light to help generate the heat required to style your hair. Meanwhile, the LED Face Mask is different from those made by companies like Dr. Dennis Gross, Omnilux, Therabody and Shark. Instead of fairly hard shells that sit rigidly on your face, L'Oréal’s version looks to be pliable and thin. I haven’t seen this in person yet, though I do intend to do so as soon as possible, but the pictures of the LED Eye Mask look, and I mean this in the best way, ridonkulous. Not only do they appear supple, but they also seem to be transparent, with bulbs and wires you can see inside. In some of the images that the company provided, the masks are completely awash in red as the lights are on. In others, only parts of it are red. One of them even shows the masks sitting in a little carrying case and they almost look like wireless earbuds. I haven’t seen any photos of the LED Face Mask but I can imagine they’d be fairly similar to these.The L'Oréal LED Eye Mask in a carrying caseL'Oréal According to the press release, this “ultra-thin, flexible silicone mask” is currently “in prototype form” and was developed in collaboration with LED solutions company iSmart. The company said this mask “delivers light directly to the face” in 10-minute automatically timed sessions. That’s not too different from existing red light masks, but L’Oréal said it believes “the key to the mask’s effectiveness is its advanced, transparent support, which integrates a skin-safe microcircuit to precisely control the emission of two selected wavelengths of light—red light (630 nm) and near-infrared light (830 nm).”Since the mask is only launching in 2027, there aren’t details yet on pricing and availability, though the company’s global vice president of tech and open innovation Guive Balooch told Engadget that it would be a premium product that would sit somewhere below the highest priced offerings currently out there.One of my problems with full-face LED masks is that my skin always feels too parched under them, because you have to use them on clean, dry skin for 10 minutes at a time. Balooch told me that L'Oréal would have a serum developed to be used with its mask that would help with that, while also improving the effectiveness of the light treatment.That certainly is intriguing, and Balooch indicated that creating formulations that are designed to work with devices like the LED masks is a future direction for the company. A pair of hands using the L'Oréal Light Straight and multi-styler on a person's hair. L'Oréal I’m also interested in the Light Straight, which like the company’s AirLight Pro uses infrared light to help dry or style hair. According to the company’s press release, hair straighteners with “ordinary heating places can reach temperatures of 400°F and higher—above the threshold at which keratin denatures, leading to weakened cuticles, breakage and reduced shine.” For context, I used to turn my flatiron all the way up to 425 degrees Fahrenheit to tame my tresses (though these days I find a more reasonable 330 degrees is good enough).L’Oréal says the Light Straight and its “patented infrared light technology” can “help provide exceptional styling results at lower temperatures, to better protect the health of the hair.” The device’s glass plates never exceed 320 degrees, and the company says its testing found that the Light Straight is three times faster and leaves hair twice as smooth as “leading premium hair stylers.” I’m not sure how you would quantify smoothness, but I’m hopeful the results do pan out in the real world. The Light Straight uses near-infrared light that L’Oréal says “penetrates deeply into hair fibers” to “reshape internal hydrogen bonds.” It also has sensors onboard with “built-in proprietary algorithms and machine learning” to adapt to your gestures “to maximize individual experience.” I’m not sure what that means, but I hope to find out more this week at CES. Given the Light Straight doesn’t launch till 2027, it’s not surprising that pricing and other details aren’t yet available. But for now, I’m keen to see companies continue to investigate novel, hopefully healthier ways for us to look and feel beautiful.This article originally appeared on Engadget at https://www.engadget.com/science/loreals-ces-2026-beauty-devices-include-a-skin-like-flexible-led-mask-070000576.html?src=rss",
          "feed_position": 0,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Loreal-LED-Eye-Mask-7.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/samsung-freestyle-plus-projector-hands-on-ces-2026-060840386.html",
          "published_at": "Mon, 05 Jan 2026 06:08:41 +0000",
          "title": "Samsung’s Freestyle+ projector hands-on: Much brighter and impressively adaptable",
          "standfirst": "Samsung announced its newest portable projector ahead of its First Look showcase at CES 2026, but you might have been a little confused as to what’s changed. The company says the Freestyle+ is nearly twice as bright as the 2022 Freestyle projector, rated at 230 ISO lumens, which was pretty underwhelming. The new Freestyle+ can output at 430 ISO lumens. If this is the first you’re hearing of ISO Lumens, it’s an internationally standardized rating for projectors, intended to standardize manufacturers' claims of brightness. It still looks very similar to its predecessors, with 160 degrees of rotation that makes it easy to set up in most homes, Airbnbs or meeting rooms. Samsung added support for Q-Symphony, allowing you to connect it to the company’s soundbars, if you conveniently have one nearby. While the sound quality of its built-in speaker was hard to test in the middle of a post-keynote trade show floor, you’ll probably want to augment the built-in speaker, if only because it’s so small. Vision AI, mentioned several times during Samsung’s CES keynote, is also built into the portable projector. You can summon Bixby to adjust settings and whatever you’re watching. Based on the demos I saw, you’ll need to speak into the remote to access Bixby. Other improvements bring the projector into 2026, with keystone correction and focus. The Freestyle+’s AI OptiScreen can calibrate projections to different wall surfaces and colors to improve visibility even on your most vivid walls. Mat Smith for Engadget The updated 3D Auto Keystone corrects distortion even when projecting onto uneven or non-flat surfaces, such as corners, curtains or angled walls. It’s hard to put into words, but pointing the Freestyle+ to a corner, or at an undulating curtain, and watching the image morph and contort was almost hypnotic. The premise is that you can point this at any area of your home (or even, say, the side of a tent), and the 3D Auto Keystone will flatten the image in seconds. There’s also Screen Fit, which automatically adjusts the image to match a projector screen size. The Freestyle+ can project up to a 100-inch 1080p image, at maximum. However, Wall Calibration might be the most technically impressive in a device this size. It detects and analyzes the color of the projection surface and recalibrates the image’s color tone to minimize the effect. It can even detect and match a wall pattern to reduce visual interference, which worked well in person. The Samsung spokesperson used the aforementioned Bixby voice commands to calibrate the screen. If there’s still something to address, it’s that this portable projector must be plugged in to operate. When that can be either a power bank or a wall outlet, it seems a bit cheeky to call it portable. Samsung typically announces prices and launch dates once the CES dust has settled, but it's set to arrive in the first half of 2026. Previous iterations cost around $900, but early impressions suggest it’s a versatile, petite projector. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/samsung-freestyle-plus-projector-hands-on-ces-2026-060840386.html?src=rss",
          "content": "Samsung announced its newest portable projector ahead of its First Look showcase at CES 2026, but you might have been a little confused as to what’s changed. The company says the Freestyle+ is nearly twice as bright as the 2022 Freestyle projector, rated at 230 ISO lumens, which was pretty underwhelming. The new Freestyle+ can output at 430 ISO lumens. If this is the first you’re hearing of ISO Lumens, it’s an internationally standardized rating for projectors, intended to standardize manufacturers' claims of brightness. It still looks very similar to its predecessors, with 160 degrees of rotation that makes it easy to set up in most homes, Airbnbs or meeting rooms. Samsung added support for Q-Symphony, allowing you to connect it to the company’s soundbars, if you conveniently have one nearby. While the sound quality of its built-in speaker was hard to test in the middle of a post-keynote trade show floor, you’ll probably want to augment the built-in speaker, if only because it’s so small. Vision AI, mentioned several times during Samsung’s CES keynote, is also built into the portable projector. You can summon Bixby to adjust settings and whatever you’re watching. Based on the demos I saw, you’ll need to speak into the remote to access Bixby. Other improvements bring the projector into 2026, with keystone correction and focus. The Freestyle+’s AI OptiScreen can calibrate projections to different wall surfaces and colors to improve visibility even on your most vivid walls. Mat Smith for Engadget The updated 3D Auto Keystone corrects distortion even when projecting onto uneven or non-flat surfaces, such as corners, curtains or angled walls. It’s hard to put into words, but pointing the Freestyle+ to a corner, or at an undulating curtain, and watching the image morph and contort was almost hypnotic. The premise is that you can point this at any area of your home (or even, say, the side of a tent), and the 3D Auto Keystone will flatten the image in seconds. There’s also Screen Fit, which automatically adjusts the image to match a projector screen size. The Freestyle+ can project up to a 100-inch 1080p image, at maximum. However, Wall Calibration might be the most technically impressive in a device this size. It detects and analyzes the color of the projection surface and recalibrates the image’s color tone to minimize the effect. It can even detect and match a wall pattern to reduce visual interference, which worked well in person. The Samsung spokesperson used the aforementioned Bixby voice commands to calibrate the screen. If there’s still something to address, it’s that this portable projector must be plugged in to operate. When that can be either a power bank or a wall outlet, it seems a bit cheeky to call it portable. Samsung typically announces prices and launch dates once the CES dust has settled, but it's set to arrive in the first half of 2026. Previous iterations cost around $900, but early impressions suggest it’s a versatile, petite projector. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/samsung-freestyle-plus-projector-hands-on-ces-2026-060840386.html?src=rss",
          "feed_position": 1,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/6825cde0-e9f6-11f0-bb3b-f9df6ed116f0"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/samsung-brought-an-absolute-beast-of-a-130-inch-micro-rgb-tv-to-ces-2026-060245387.html",
          "published_at": "Mon, 05 Jan 2026 06:02:45 +0000",
          "title": "Samsung brought an absolute beast of a 130-inch Micro RGB TV to CES 2026",
          "standfirst": "Amid endless AI hype and a guest visit from the CEO of Hartford Steam Boiler (?!), Samsung had a big surprise for us tonight at CES 2026: A massive 130-inch Micro RGB TV. It’s so large, it’s suspended by a large metal stand that surrounds the entire screen, which also lets you tilt the screen just a bit. (For the Samsung diehards, it’s basically a reinvention of its “timeless gallery” stand from 2013.) I imagine bringing this TV home would be like Bart Simpson adopting his beloved elephant Stampy: Your pets would be terrified, and your family would probably be annoyed at this television dominating so much of your home.But boy, it sure looks amazing in person. Just like LG’s Micro RGB set, it’s using an evolved form of Mini LED technology that allows for far better color accuracy and richness. As I fought through the crowds of Samsung’s CES First Look event to catch a glimpse of it, I couldn’t help but notice how everyone just looked a bit stunned, like the monkeys from 2001 seeing the monolith for the first time.Samsung's 130-inch Micro RGB TV from the side.Devindra Hardawar for EngadgetSamsung representatives were clear that this Micro RGB set was only a concept of what the company could do with the technology, it’s not an actual product it plans to ship. In another demo, Samsung took the 130-inch screen and mounted it directly on a wall (below). Of course, it still looked stunning. I also learned that if you wanted to wall mount the “timeless gallery” stand concept, you actually have to mount the entire stand to the wall, since it’s part of the TV’s speaker system.Samsung didn’t have too many details about the technical aspects of the 130-inch Micro RGB TV, but it did shout buzzwords at us during its announcement. it’s powered by the company’s “Micro RGB AI Engine Pro” processor, which includes “Micro RGB Color Booster Pro” and “Micro RGB HDR Pro” technology, using AI to “enhance dull tones and refine contrast, delivering vivid color and subtle detail across bright and dark scenes alike for realism and picture fidelity.”Samsung's 130-inch Micro RGB TV mounted in a wall.Devindra Hardawar for EngadgetThe Micro RGB set also sports the company’s Glare Free technology to reduce reflections, and it supports HDR 10+ Advanced and the company’s Eclipsa Audio. It can also tap into Samsung’s Vision AI Companion for conversational search, as well as Microsoft Copilot and Perplexity.But of course, those details really don’t matter, because you won’t be able to buy the 130-inch Micro RGB TV in its current form. We were impressed by last year’s 115-inch model, but its $30,000 price didn’t make it feasible for anyone but the ultra-rich. And those folks would be better off investing in Samsung’s own Micro LED sets, which offer the benefits of OLED that Micro RGB does not. (Sure, those TVs start at $110,000, but for that’s not exactly a huge leap for those with deep pockets.) Samsung's 130-inch Micro RGB TV from the rear.Devindra Hardawar for EngadgetThis article originally appeared on Engadget at https://www.engadget.com/home/home-theater/samsung-brought-an-absolute-beast-of-a-130-inch-micro-rgb-tv-to-ces-2026-060245387.html?src=rss",
          "content": "Amid endless AI hype and a guest visit from the CEO of Hartford Steam Boiler (?!), Samsung had a big surprise for us tonight at CES 2026: A massive 130-inch Micro RGB TV. It’s so large, it’s suspended by a large metal stand that surrounds the entire screen, which also lets you tilt the screen just a bit. (For the Samsung diehards, it’s basically a reinvention of its “timeless gallery” stand from 2013.) I imagine bringing this TV home would be like Bart Simpson adopting his beloved elephant Stampy: Your pets would be terrified, and your family would probably be annoyed at this television dominating so much of your home.But boy, it sure looks amazing in person. Just like LG’s Micro RGB set, it’s using an evolved form of Mini LED technology that allows for far better color accuracy and richness. As I fought through the crowds of Samsung’s CES First Look event to catch a glimpse of it, I couldn’t help but notice how everyone just looked a bit stunned, like the monkeys from 2001 seeing the monolith for the first time.Samsung's 130-inch Micro RGB TV from the side.Devindra Hardawar for EngadgetSamsung representatives were clear that this Micro RGB set was only a concept of what the company could do with the technology, it’s not an actual product it plans to ship. In another demo, Samsung took the 130-inch screen and mounted it directly on a wall (below). Of course, it still looked stunning. I also learned that if you wanted to wall mount the “timeless gallery” stand concept, you actually have to mount the entire stand to the wall, since it’s part of the TV’s speaker system.Samsung didn’t have too many details about the technical aspects of the 130-inch Micro RGB TV, but it did shout buzzwords at us during its announcement. it’s powered by the company’s “Micro RGB AI Engine Pro” processor, which includes “Micro RGB Color Booster Pro” and “Micro RGB HDR Pro” technology, using AI to “enhance dull tones and refine contrast, delivering vivid color and subtle detail across bright and dark scenes alike for realism and picture fidelity.”Samsung's 130-inch Micro RGB TV mounted in a wall.Devindra Hardawar for EngadgetThe Micro RGB set also sports the company’s Glare Free technology to reduce reflections, and it supports HDR 10+ Advanced and the company’s Eclipsa Audio. It can also tap into Samsung’s Vision AI Companion for conversational search, as well as Microsoft Copilot and Perplexity.But of course, those details really don’t matter, because you won’t be able to buy the 130-inch Micro RGB TV in its current form. We were impressed by last year’s 115-inch model, but its $30,000 price didn’t make it feasible for anyone but the ultra-rich. And those folks would be better off investing in Samsung’s own Micro LED sets, which offer the benefits of OLED that Micro RGB does not. (Sure, those TVs start at $110,000, but for that’s not exactly a huge leap for those with deep pockets.) Samsung's 130-inch Micro RGB TV from the rear.Devindra Hardawar for EngadgetThis article originally appeared on Engadget at https://www.engadget.com/home/home-theater/samsung-brought-an-absolute-beast-of-a-130-inch-micro-rgb-tv-to-ces-2026-060245387.html?src=rss",
          "feed_position": 2,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Samsung_Micro_RGB-2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/speakers/samsung-music-studio-5-and-7-hands-on-unique-speaker-designs-debut-at-ces-2026-052009007.html",
          "published_at": "Mon, 05 Jan 2026 05:20:09 +0000",
          "title": "Samsung Music Studio 5 and 7 hands-on: Unique speaker designs debut at CES 2026",
          "standfirst": "In addition to its annual soundbar updates, Samsung debuted two new home speakers at CES 2026. The Music Studio 5 and 7 are Bluetooth and Wi-Fi units designed to blend in with your home decor thanks to their minimalist look. They certainly don’t look like your typical speakers, and Samsung has packed them with features that it says will ensure optimal sound quality from each one. The Music Studio 5 has a four-inch woofer and two tweeters, and a sound profile that’s optimized by AI Dynamic Bass Control. The design is an interesting interplay between a circle and a square, but the speaker delivers crisp, clear sound — even in the roar of a CES demo area. The Music Studio 5 will also come in a smattering of colors, which could lend a pop to a bookshelf. Controls line the top edge, including one-touch access to Spotify.Samsung Music Studio 7Billy Steele for EngadgetIf you’re looking for something more robust, the Music Studio 7 is a 3.1.1-channel unit that’s capable of four-direction spatial audio and high-resolution listening. Samsung says you can enjoy tunes at up to up to 24-bit/96kHz and the speaker can be used as part of a turntable setup. The sound here is more robust as I heard noticeably more bass from the 7 than on the 5. The various control buttons are up top here as well, positioned near the front of the speaker for easy access. You can also use up to four Music Studio speakers as a surround sound setup in your living room. I listened to a brief demo where Samsung was using four Music Studio 7 units in a makeshift home theater. This combo provided great immersion, with lots of detail in the directional sound in the clips being broadcast on the connected TV. Samsung also says you can use up to 10 Music Studio speakers for audio only.The company didn’t announce any pricing details yet, but that’s likely to come just before the Music Studio speakers are available for purchase. That date is TBD as well. This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/samsung-music-studio-5-and-7-hands-on-unique-speaker-designs-debut-at-ces-2026-052009007.html?src=rss",
          "content": "In addition to its annual soundbar updates, Samsung debuted two new home speakers at CES 2026. The Music Studio 5 and 7 are Bluetooth and Wi-Fi units designed to blend in with your home decor thanks to their minimalist look. They certainly don’t look like your typical speakers, and Samsung has packed them with features that it says will ensure optimal sound quality from each one. The Music Studio 5 has a four-inch woofer and two tweeters, and a sound profile that’s optimized by AI Dynamic Bass Control. The design is an interesting interplay between a circle and a square, but the speaker delivers crisp, clear sound — even in the roar of a CES demo area. The Music Studio 5 will also come in a smattering of colors, which could lend a pop to a bookshelf. Controls line the top edge, including one-touch access to Spotify.Samsung Music Studio 7Billy Steele for EngadgetIf you’re looking for something more robust, the Music Studio 7 is a 3.1.1-channel unit that’s capable of four-direction spatial audio and high-resolution listening. Samsung says you can enjoy tunes at up to up to 24-bit/96kHz and the speaker can be used as part of a turntable setup. The sound here is more robust as I heard noticeably more bass from the 7 than on the 5. The various control buttons are up top here as well, positioned near the front of the speaker for easy access. You can also use up to four Music Studio speakers as a surround sound setup in your living room. I listened to a brief demo where Samsung was using four Music Studio 7 units in a makeshift home theater. This combo provided great immersion, with lots of detail in the directional sound in the clips being broadcast on the connected TV. Samsung also says you can use up to 10 Music Studio speakers for audio only.The company didn’t announce any pricing details yet, but that’s likely to come just before the Music Studio speakers are available for purchase. That date is TBD as well. This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/samsung-music-studio-5-and-7-hands-on-unique-speaker-designs-debut-at-ces-2026-052009007.html?src=rss",
          "feed_position": 3,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/sound-studio-4.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/samsung-hw-qs90h-soundbar-hands-on-impressive-bass-performance-without-a-subwoofer-045727939.html",
          "published_at": "Mon, 05 Jan 2026 04:57:27 +0000",
          "title": "Samsung HW-QS90H soundbar hands-on: Impressive bass performance without a subwoofer",
          "standfirst": "We’re used to Samsung updating its Q990 soundbar at CES every year, and 2026 is no different. However, the company also debuted the HW-QS90H: a new all-in-one option that Samsung says won’t require a standalone subwoofer due to its Quad Bass Woofer system. The QS90H offers 7.1.2-channel audio with 13 total drivers. Before the show properly kicks off, we got to listen to the new soundbar for a quick judge of its merits. The first thing I noticed about the QS90H is its impressive bass performance. Most of the time when a company claims its soundbar doesn’t need a subwoofer, that proves to be untrue. But even in the chaos of a noisy demo area, I could clearly hear the bassy thump coming from the QS90H’s built-in subwoofers. For once, I think would-be buyers could get by without a sub, especially in smaller living rooms. Samsung achieved this with two of those Quad woofers. These drivers push air in two directions rather than just one, which helps with the extra low-end tone. The company didn’t sacrifice clarity either. The nine additional drivers, positioned for front, side, wide and up firing sound, provide the clear detail I’ve come to expect from Samsung.Samsung QS90H soundbarBilly Steele for EngadgetThe QS90H also features Samsung’s Convertible Fit Design technology that debuted on the QS700F last year. This tool allows you to sit the soundbar flat on a shelf or mantle, or rotate it to mount on the wall. Built-in sensors automatically adjust the driver performance for each orientation, so that sound quality isn’t affected by the selected positioning. During my demo, I didn’t notice any difference in performance when the orientation changed. In fact, the QS90H looks a lot like the QS700F on the outside, with similar grille patters and control designs. Samsung didn’t announce pricing or availability tonight, but that’s likely to come just prior to any on-sale date. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/samsung-hw-qs90h-soundbar-hands-on-impressive-bass-performance-without-a-subwoofer-045727939.html?src=rss",
          "content": "We’re used to Samsung updating its Q990 soundbar at CES every year, and 2026 is no different. However, the company also debuted the HW-QS90H: a new all-in-one option that Samsung says won’t require a standalone subwoofer due to its Quad Bass Woofer system. The QS90H offers 7.1.2-channel audio with 13 total drivers. Before the show properly kicks off, we got to listen to the new soundbar for a quick judge of its merits. The first thing I noticed about the QS90H is its impressive bass performance. Most of the time when a company claims its soundbar doesn’t need a subwoofer, that proves to be untrue. But even in the chaos of a noisy demo area, I could clearly hear the bassy thump coming from the QS90H’s built-in subwoofers. For once, I think would-be buyers could get by without a sub, especially in smaller living rooms. Samsung achieved this with two of those Quad woofers. These drivers push air in two directions rather than just one, which helps with the extra low-end tone. The company didn’t sacrifice clarity either. The nine additional drivers, positioned for front, side, wide and up firing sound, provide the clear detail I’ve come to expect from Samsung.Samsung QS90H soundbarBilly Steele for EngadgetThe QS90H also features Samsung’s Convertible Fit Design technology that debuted on the QS700F last year. This tool allows you to sit the soundbar flat on a shelf or mantle, or rotate it to mount on the wall. Built-in sensors automatically adjust the driver performance for each orientation, so that sound quality isn’t affected by the selected positioning. During my demo, I didn’t notice any difference in performance when the orientation changed. In fact, the QS90H looks a lot like the QS700F on the outside, with similar grille patters and control designs. Samsung didn’t announce pricing or availability tonight, but that’s likely to come just prior to any on-sale date. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/samsung-hw-qs90h-soundbar-hands-on-impressive-bass-performance-without-a-subwoofer-045727939.html?src=rss",
          "feed_position": 4,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/qs90h-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/lg-tvs-at-ces-2026-a-stunning-wallpaper-set-glorious-micro-rgb-colors-and-a-better-gallery-tv-033739600.html",
          "published_at": "Mon, 05 Jan 2026 03:37:39 +0000",
          "title": "LG TVs at CES 2026: A stunning Wallpaper set, glorious Micro RGB colors and a better Gallery TV",
          "standfirst": "LG usually announces its CES TV lineup well ahead of the show, but this year the company had a surprise at CES 2026: The return of its ultra-thin \"Wallpaper\" TV. Now it's toting a gorgeous OLED screen and wireless connectivity, and it's about as thin as a pencil. We got a chance to check out the Wallpaper TV in action during a CES preview event, as well as the previously announced Gallery and Micro RGB sets. LG still has its typically OLED and LED sets around, but it's clear that 2026 will be filled with intriguing TVs for a variety of consumers.LG's 2026 Wallpaper OLED TVDevindra Hardawar for EngadgetThe Wallpaper TV (LG W6)If money were no object, I'd want a 100-inch LG Wallpaper TV in my family room immediately. It looks shockingly thin in person — almost as if it's some sort of sci-fi prop — and it delivers the rich colors and dark levels we expect from OLED. Cable management is also a cinch, since it requires just a single power cable. The A/V inputs are handled by LG's One Connect box, which you can position wirelessly up to 10 meters away from the TV. LG's 2026 Wallpaper OLED TV from the rearDevindra Hardawar for EngadgetThe LG W6 combines the best of LG's OLED technology, including \"Hyper Radiant Color\" for improved black levels and color, \"Brightness Booster Ultra\" to crank up luminance 3.9 times more than conventional OLEDs and a reflection free screen material. LG's Alpha 9 Gen 3 processor beefs up its performance, and its NPU also helps to improve upscaling and overall image performance. (And yes, you can also access generative AI features via Microsoft Copilot and Google Gemini, if you're into that sort of thing.)All of that adds up to one of the most remarkable TVs I've seen in years. I haven't been too enamored with other TV gimmicks lately, like everything trying to mimic Samsung's The Frame, or the usless 8K sets. But a super-thin wireless TV with the best OLED panel available? That's the stuff dreams are made of. LG's 2026 Gallery TVDevindra Hardawar for EngadgetThe Gallery TV competes with Samsung’s FrameWhile LG has made Gallery TVs before, in 2026 it's making a more concerted effort to take on Samsung's popular Frame TV. LG says the new sets were designed with the help of museum curators, which helps the \"Gallery Mode\" adjust brightness and contrast to specific works of art. They also ship with magnetic frame-like bezels, and they have anti-reflective screens to help make the art shine. In person, the new Gallery TV looks fine, though it's easy to tell that the colors and contrast levels don't match LG's premium OLED TVs. To avoid burn-in issues, these sets feature Mini LED panels. As I noted above, I'm not the core consumer for one of these TVs, but it's nice to see more competition against Samsung's Frame TVs. (Despite pioneering the idea of TVs displaying art, the Frame sets are still fairly mediocre when it comes to actually watching TV shows and movies.) LG's Micro RGB TVDevindra Hardawar for EngadgetMicro RGB looks like a genuine Mini LED upgradeAs if we needed more TV acronyms to worry about, say hello to Micro RGB, a new technology built atop Mini LED to cover vastly more color range. Just don't confuse it with Micro LED, which is the wildly expensive evolutionary step forward for OLED. LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES. Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like. I'd have to compare it to LG's Wall TV side-by-side to truly see how Micro RGB competes with OLED, but technically OLED should still offer better contrast and black levels, since each of its pixels are self-emissive. But sure, if I couldn't get a 100-inch Wall TV in my family room, I certainly wouldn't turn down an enormous Micro RGB. What about LG's other OLED TVs?All of the next-generation OLED technology in the wallpaper TV will also make its way into LG's G6 OLED models, while the new C6 and other lines will see improvements of their own. All I can say is that the new G6 OLED looked impressive, with a noticeably brighter picture and HDR elements compared to G-series OLEDs from several years ago. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-tvs-at-ces-2026-a-stunning-wallpaper-set-glorious-micro-rgb-colors-and-a-better-gallery-tv-033739600.html?src=rss",
          "content": "LG usually announces its CES TV lineup well ahead of the show, but this year the company had a surprise at CES 2026: The return of its ultra-thin \"Wallpaper\" TV. Now it's toting a gorgeous OLED screen and wireless connectivity, and it's about as thin as a pencil. We got a chance to check out the Wallpaper TV in action during a CES preview event, as well as the previously announced Gallery and Micro RGB sets. LG still has its typically OLED and LED sets around, but it's clear that 2026 will be filled with intriguing TVs for a variety of consumers.LG's 2026 Wallpaper OLED TVDevindra Hardawar for EngadgetThe Wallpaper TV (LG W6)If money were no object, I'd want a 100-inch LG Wallpaper TV in my family room immediately. It looks shockingly thin in person — almost as if it's some sort of sci-fi prop — and it delivers the rich colors and dark levels we expect from OLED. Cable management is also a cinch, since it requires just a single power cable. The A/V inputs are handled by LG's One Connect box, which you can position wirelessly up to 10 meters away from the TV. LG's 2026 Wallpaper OLED TV from the rearDevindra Hardawar for EngadgetThe LG W6 combines the best of LG's OLED technology, including \"Hyper Radiant Color\" for improved black levels and color, \"Brightness Booster Ultra\" to crank up luminance 3.9 times more than conventional OLEDs and a reflection free screen material. LG's Alpha 9 Gen 3 processor beefs up its performance, and its NPU also helps to improve upscaling and overall image performance. (And yes, you can also access generative AI features via Microsoft Copilot and Google Gemini, if you're into that sort of thing.)All of that adds up to one of the most remarkable TVs I've seen in years. I haven't been too enamored with other TV gimmicks lately, like everything trying to mimic Samsung's The Frame, or the usless 8K sets. But a super-thin wireless TV with the best OLED panel available? That's the stuff dreams are made of. LG's 2026 Gallery TVDevindra Hardawar for EngadgetThe Gallery TV competes with Samsung’s FrameWhile LG has made Gallery TVs before, in 2026 it's making a more concerted effort to take on Samsung's popular Frame TV. LG says the new sets were designed with the help of museum curators, which helps the \"Gallery Mode\" adjust brightness and contrast to specific works of art. They also ship with magnetic frame-like bezels, and they have anti-reflective screens to help make the art shine. In person, the new Gallery TV looks fine, though it's easy to tell that the colors and contrast levels don't match LG's premium OLED TVs. To avoid burn-in issues, these sets feature Mini LED panels. As I noted above, I'm not the core consumer for one of these TVs, but it's nice to see more competition against Samsung's Frame TVs. (Despite pioneering the idea of TVs displaying art, the Frame sets are still fairly mediocre when it comes to actually watching TV shows and movies.) LG's Micro RGB TVDevindra Hardawar for EngadgetMicro RGB looks like a genuine Mini LED upgradeAs if we needed more TV acronyms to worry about, say hello to Micro RGB, a new technology built atop Mini LED to cover vastly more color range. Just don't confuse it with Micro LED, which is the wildly expensive evolutionary step forward for OLED. LG already announced its Micro RGB set a few weeks ago, but that didn't prepare me for standing in front of the 100-inch demo TV it brought to CES. Throughout a variety of clips, colors looked wonderfully rich, and the overall texture of the images looked surprisingly life-like. I'd have to compare it to LG's Wall TV side-by-side to truly see how Micro RGB competes with OLED, but technically OLED should still offer better contrast and black levels, since each of its pixels are self-emissive. But sure, if I couldn't get a 100-inch Wall TV in my family room, I certainly wouldn't turn down an enormous Micro RGB. What about LG's other OLED TVs?All of the next-generation OLED technology in the wallpaper TV will also make its way into LG's G6 OLED models, while the new C6 and other lines will see improvements of their own. All I can say is that the new G6 OLED looked impressive, with a noticeably brighter picture and HDR elements compared to G-series OLEDs from several years ago. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-tvs-at-ces-2026-a-stunning-wallpaper-set-glorious-micro-rgb-colors-and-a-better-gallery-tv-033739600.html?src=rss",
          "feed_position": 5,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/LG_CES_2026-5.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/lg-brought-back-the-wallpaper-tv-for-ces-and-ditched-the-companion-sound-bar-030057927.html",
          "published_at": "Mon, 05 Jan 2026 03:00:57 +0000",
          "title": "LG brought back the Wallpaper TV for CES and ditched the companion sound bar",
          "standfirst": "It's been nearly 10 years since LG first introduced its Wallpaper TV that was so thin that the mounting process felt like applying wallpaper. After eventually discontinuing the ultra-thin TVs in 2020, LG is finally reviving the Wallpaper TV series with the OLED evo W6 that will make its debut at CES 2026. LG is marketing the updated Wallpaper TV as the \"world's thinnest\" OLED that's truly wireless, making some major upgrades to the original. Instead of the companion soundbar that housed all the ports, LG designed the Zero Connect Box that hosts all the inputs and can transmit from up to roughly 32 feet away. It's similar to what Samsung has been doing with its Wireless One Connect Box, which is often paired with its Frame TV lineup. While you won't have to worry about a web of tangled wires or a clunky soundbar, the OLED evo W6 measures slightly thicker at 9mm, compared to its predecessor's hyperthin 2.6mm measurement. That's more than three times the thickness, but it's still impressive if you consider that the W6 will feel about as thick as putting an iPhone 17 Pro Max against your wall. LG The latest Wallpaper TV does come with plenty of improvements, though, including LG's third-gen α 11 Processor. LG also added its new Hyper Radiant Color Technology to the W6, which translates to deeper blacks, improved colors and higher brightness levels. There's even a Brightness Booster Ultra feature that LG claims results in four times the brightness of conventional OLED. To complement the extra nits, LG specifically designed a screen that reduces reflections for the Wallpaper TV. The updated W6 can handle gaming better, too, since it supports a 4K 165Hz refresh rate and has a 0.1 pixel response time that's crucial for competitive gaming. LG added compatibility with NVIDIA's G-Sync, AMD's FreeSync Premium, Google Gemini and Microsoft Copilot. When you're not using the Wallpaper TV, LG has its Gallery+ feature that can display screensaver visuals, personal photos or images created with generative AI. LG LG didn't reveal what sizes the upgraded Wallpaper TV would be available in, but it will be on display later this week at CES 2026. LG hasn't offered any clues about pricing yet either, but we wouldn't be surprised to see an equally shocking price as compared to the last Wallpaper TV, which cost up to $20,000.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-brought-back-the-wallpaper-tv-for-ces-and-ditched-the-companion-sound-bar-030057927.html?src=rss",
          "content": "It's been nearly 10 years since LG first introduced its Wallpaper TV that was so thin that the mounting process felt like applying wallpaper. After eventually discontinuing the ultra-thin TVs in 2020, LG is finally reviving the Wallpaper TV series with the OLED evo W6 that will make its debut at CES 2026. LG is marketing the updated Wallpaper TV as the \"world's thinnest\" OLED that's truly wireless, making some major upgrades to the original. Instead of the companion soundbar that housed all the ports, LG designed the Zero Connect Box that hosts all the inputs and can transmit from up to roughly 32 feet away. It's similar to what Samsung has been doing with its Wireless One Connect Box, which is often paired with its Frame TV lineup. While you won't have to worry about a web of tangled wires or a clunky soundbar, the OLED evo W6 measures slightly thicker at 9mm, compared to its predecessor's hyperthin 2.6mm measurement. That's more than three times the thickness, but it's still impressive if you consider that the W6 will feel about as thick as putting an iPhone 17 Pro Max against your wall. LG The latest Wallpaper TV does come with plenty of improvements, though, including LG's third-gen α 11 Processor. LG also added its new Hyper Radiant Color Technology to the W6, which translates to deeper blacks, improved colors and higher brightness levels. There's even a Brightness Booster Ultra feature that LG claims results in four times the brightness of conventional OLED. To complement the extra nits, LG specifically designed a screen that reduces reflections for the Wallpaper TV. The updated W6 can handle gaming better, too, since it supports a 4K 165Hz refresh rate and has a 0.1 pixel response time that's crucial for competitive gaming. LG added compatibility with NVIDIA's G-Sync, AMD's FreeSync Premium, Google Gemini and Microsoft Copilot. When you're not using the Wallpaper TV, LG has its Gallery+ feature that can display screensaver visuals, personal photos or images created with generative AI. LG LG didn't reveal what sizes the upgraded Wallpaper TV would be available in, but it will be on display later this week at CES 2026. LG hasn't offered any clues about pricing yet either, but we wouldn't be surprised to see an equally shocking price as compared to the last Wallpaper TV, which cost up to $20,000.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/lg-brought-back-the-wallpaper-tv-for-ces-and-ditched-the-companion-sound-bar-030057927.html?src=rss",
          "feed_position": 6,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/c9966240-e98a-11f0-bbdb-1e7df9d48ea7"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/partystudio-is-a-wireless-midi-speaker-with-128-built-in-instrument-sounds-015511003.html",
          "published_at": "Mon, 05 Jan 2026 01:55:11 +0000",
          "title": "PartyStudio is a wireless MIDI speaker with 128 built-in instrument sounds",
          "standfirst": "There are a slew of keyboards and apps that help people learn how to play the piano, but a small company called PopuMusic is showing off an intriguing set of products at CES to make the process easier. PartyKeys and PartyStudio are a 36-key MIDI keyboard and MIDI / Bluetooth speaker that pair together in seamless fashion. The PartyStudio is particularly interesting because it has a built-in library of 128 instrument tones and more than 50 different drum machine patterns. Naturally, it works with the PartyKeys, but any MIDI keyboard can connect to it and use those sounds. The PartyStudio and PartyKeys both use NFC to connect to each other — you can just tap and hold the keyboard up to the speaker for pairing. You can connect up to three devices using MIDI over Bluetooth Low-Energy (BLE MIDI) as well as a fourth using a wired connection. If you have more than one keyboard, meanwhile, you can connect them together with NFC as well — you can pair three keyboards together total, giving you a huge 108-key surface to play.Both the PartyStudio and PartyKeys have an understated but appealing look to them (they’re available in black or white) and feel quite substantial and well-made. PopuMusic has been releasing hardware via Kickstarters campaigns for a few years now, so even though they’re a relatively small and new company they have some experience in this department. The speaker seems to hit a nice balance of portability and power; it has two tweeters and two woofers and weighs in at 3.75 pounds. It’s about 13.5 inches wide, 5.2 inches tall and 4 inches deep, so it’s not a tiny speaker you’ll just throw in your bag, but it still feels easy to tote around thanks to its attached handle.The other trick that the PartyStudio and PartyKeys have is on the software side. Using a companion app, multiple people can play along with a song. The light-up keyboard can show you what to play, and if you have multiple people playing each keyboard can display complimentary parts. It starts with simple three-key chord voicings, but I also saw a demo that used a familiar Guitar Hero-style interface of different notes flying down the screen, making for a more involved and advanced performance.The PartyKeys are up for order on Kickstarter now for $199, while the PartyStudio costs $349. The company says they’re on track to ship both products in Q1 of 2026.This article originally appeared on Engadget at https://www.engadget.com/audio/partystudio-is-a-wireless-midi-speaker-with-128-built-in-instrument-sounds-015511003.html?src=rss",
          "content": "There are a slew of keyboards and apps that help people learn how to play the piano, but a small company called PopuMusic is showing off an intriguing set of products at CES to make the process easier. PartyKeys and PartyStudio are a 36-key MIDI keyboard and MIDI / Bluetooth speaker that pair together in seamless fashion. The PartyStudio is particularly interesting because it has a built-in library of 128 instrument tones and more than 50 different drum machine patterns. Naturally, it works with the PartyKeys, but any MIDI keyboard can connect to it and use those sounds. The PartyStudio and PartyKeys both use NFC to connect to each other — you can just tap and hold the keyboard up to the speaker for pairing. You can connect up to three devices using MIDI over Bluetooth Low-Energy (BLE MIDI) as well as a fourth using a wired connection. If you have more than one keyboard, meanwhile, you can connect them together with NFC as well — you can pair three keyboards together total, giving you a huge 108-key surface to play.Both the PartyStudio and PartyKeys have an understated but appealing look to them (they’re available in black or white) and feel quite substantial and well-made. PopuMusic has been releasing hardware via Kickstarters campaigns for a few years now, so even though they’re a relatively small and new company they have some experience in this department. The speaker seems to hit a nice balance of portability and power; it has two tweeters and two woofers and weighs in at 3.75 pounds. It’s about 13.5 inches wide, 5.2 inches tall and 4 inches deep, so it’s not a tiny speaker you’ll just throw in your bag, but it still feels easy to tote around thanks to its attached handle.The other trick that the PartyStudio and PartyKeys have is on the software side. Using a companion app, multiple people can play along with a song. The light-up keyboard can show you what to play, and if you have multiple people playing each keyboard can display complimentary parts. It starts with simple three-key chord voicings, but I also saw a demo that used a familiar Guitar Hero-style interface of different notes flying down the screen, making for a more involved and advanced performance.The PartyKeys are up for order on Kickstarter now for $199, while the PartyStudio costs $349. The company says they’re on track to ship both products in Q1 of 2026.This article originally appeared on Engadget at https://www.engadget.com/audio/partystudio-is-a-wireless-midi-speaker-with-128-built-in-instrument-sounds-015511003.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/ces-2026-what-to-expect-from-techs-big-january-conference-120000956.html",
          "published_at": "Mon, 05 Jan 2026 01:18:08 +0000",
          "title": "CES 2026: What to expect from tech's big January conference",
          "standfirst": "The pre-show events are already up and running at CES 2026 — the tech world’s biggest annual conference — and the news is already flowing. While the CES show floor doesn't officially open until Tuesday, January 6, Las Vegas is already abuzz with various pre-show events, including the CES Unveiled mini show and Samsung's First Look press conference, scheduled for late Sunday. Nearly all day Monday will be comprised of more press conferences from the likes of LG, Intel, NVIDIA and Sony. And that doesn't include the product demos, announcements and networking that will be happening at the Las Vegas Convention Center and other hotels all over the city. Engadget is covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements are already trickling out as CES approaches, and thanks to the schedule of the Consumer Technology Association (the trade organization that runs the show) we have a full itinerary of press conferences. We’re also using our experience and expertise to predict what tech trends could rear their heads at the show.The CES 2026 schedulePress conferences and show floor booths are the bread and butter of CES. The CTA has already published a searchable directory of who will have an official presence at the show, along with a schedule of every official panel and presentation. However, the press conference schedule gives us a more digestible rundown of the first 48 hours of big events. On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" Ahead of that, though, Samsung has already outlined a variety of more specifics (scroll down for details). Concurrent with the Samsung presentation will be the official CES Unveiled mini-show, which is generally comprised of smaller and start-up vendors. That'll be followed by multiple press conferences throughout Monday, January 5. The LG CES 2026 press conference, titled \"Innovation in Tune with You,\" is ostensibly to share \"its vision for elevating daily life through Affectionate Intelligence.\" But, like Samsung, this fellow Korean giant has already spent the three weeks leading up to CES pre-announcing many of its new products, so this may be more of a summary than breaking news. Following LG, we’ll also see press conferences from Bosch and Hisense, as well as the first-ever CES appearance from Lego. As the Las Vegas afternoon rolls around, we get the first of three chip giants: NVIDIA CEO Jensen Huang takes the stage on January 5 at 1PM PT (4PM ET) and, according to the website, his presentation will last about 90 minutes. Based on the description on the listing, the presentation will “showcase the latest NVIDIA solutions driving innovation and productivity across industries.” NVIDIA’s presser is concurrent with one from Hyundai, where the Korean automotive company will focus on in-cabin car tech and robotics. Later in the day, we get to hear from NVIDIA frenemies Intel and AMD. Intel’s 3PM PT (6PM PT) event will ostensibly feature its new Core Ultra Series 3 processors, and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day. But expect both of them to be very heavy on AI applications, of course. Sandwiched in between those chip manufacturers will be Sony Honda Mobility. The joint venture will be offering yet more details on its Afeela EV. Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at the Las Vegas Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\" It’s worth noting that Lenovo is the parent company of Motorola, which still makes phones and foldables that feature AI tools, so it’s possible those devices feature in the presentation as well. Here’s a handy cheatsheet for easy access to all of Engadget’s coverage: Samsung (Sunday, Jan. 4, 10PM ET)Samsung CES liveblog and livestreamLG (Monday, Jan. 5, 11AM ET)LG CES liveblog and livestreamBosch (Monday, Jan. 5, 12PM ET)Bosch CES livestreamHisense (Monday, Jan. 5, 1PM ET)Hisense CES livestreamLego (Monday, Jan. 5, 1PM ET)Lego CES liveblogNVIDIA (Monday, Jan. 5, 4PM ET)NVIDIA CES liveblog and livestreamHyundai (Monday, Jan. 5, 4PM ET)Hyundai CES livestreamIntel (Monday, Jan. 5, 6PM ET)Intel CES liveblog and livestreamSony Honda Afeela (Monday, Jan. 5, 8PM ET)Sony Honda CES liveblog and livestreamAMD keynote (Monday, Jan. 5, 9:30PM ET)AMD CES liveblog and livestreamLenovo (Tuesday, Jan. 6, 8PM ET)Lenovo CES liveblog and livestreamSamsung and LG vie for pre-show publicityAs noted above, both Samsung and LG have continued their recent trend of spoiling nearly all of their respective CES announcements in the days and weeks before the show. LG, for example, has said it will debut its first Micro RGB television at CES. While details are scarce, the company’s press release for the LG Micro RGB evo did confirm it has received certifications by Intertek for 100 percent color gamut coverage in DCI-P3 an Adobe RGB, and that it has more than a thousand dimming zones for brightness control. Elsewhere in the TV space, LG is throwing its hat into the “art TV” ring that Samsung pioneered with its Frame TVs: The LG Gallery TV will debut in 55- and 65-inch screen sizes, and it will of course show off various artwork when it’s not otherwise in use. And if PC gaming displays are more your speed, LG will have that covered, too, with a new line of 5K-capable gaming monitors on deck with built-in AI upscaling.But LG’s not just showing off displays. The Korean multinational will also introduce a Dolby-powered modular home audio system, a new line of its xboom speakers (developed with will.i.am) and the company will flex its automation muscles with a humanoid home automation robot named CLOiD. We’re also looking forward to checking out the company’s new ultralight Aerominum laptops.Of course, Samsung refuses to be outdone by its hometown rival, and has also released a pre-CES press release document dump. Samsung will be launching its own lineup of Micro RGB TVs at CES, for starters. The company already introduced its first Micro RGB TV at CES 2025, which was a 115-inch model available for a cool $30,000. Next year, Samsung is expanding the range with 55-, 65-, 75-, 85-, 100- and 115-inch models that use the next evolution of the company’s Micro RGB technology. Samsung is also countering LG’s 5K monitors with a 6K model that aims to deliver glasses-free 3D (another long-time CES staple). It’ll be one of several new displays in the company’s Odyssey gaming line. And the company is also updating its Freestyle projector for 2026, too. And on the audio front, Samsung has teased several new soundbars and speakers, including Sonos-style Wi-Fi streaming models call the Music Studio 5 and Studio 7.Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensAs noted above, Samsung and LG appear to be going all-in on Micro RGB display tech for TVs. Expect that to be a huge buzzword at CES, with Hisense and Sony debuting new models, too.Sony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.And maybe your future TV won’t need a power cord, either: Displace will be showing off a mounting option that includes a 15,000mAh battery to juice up whatever giant TV screen you choose to attach.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots — like LG’s aforementioned CLOiD — competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!Update, December 11 2025, 11:03AM ET: This story has been updated to include detail on Lenovo being Motorola’s parent company and how the latter might have a part in the Tuesday presentation.Update, December 16 2025, 1:33PM ET: This story has been updated to include the NVIDIA press conference, which was added to the CTA schedule within the last two days.Update, December 23 2025, 7:28AM ET: This story has been updated to include LG and Samsung’s Micro RGB TV announcements, which were made public in the past seven days. The intro was also tweaked to reflect how soon CES is at this point.Update, December 29 2025, 11:03AM ET: This story has been updated to include additional details on pre-announcements from Samsung, LG and Displace. Update, December 31 2025, 12:05PM ET: This story has been updated to include yet more early LG announcements.Update, January 3 2026, 8:45AM ET: This story has been updated to include still more Samsung and LG announcements.Update, January 4 2026, 8:45PM ET: This story has been updated to include new links and a press conference schedule.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-what-to-expect-from-techs-big-january-conference-120000956.html?src=rss",
          "content": "The pre-show events are already up and running at CES 2026 — the tech world’s biggest annual conference — and the news is already flowing. While the CES show floor doesn't officially open until Tuesday, January 6, Las Vegas is already abuzz with various pre-show events, including the CES Unveiled mini show and Samsung's First Look press conference, scheduled for late Sunday. Nearly all day Monday will be comprised of more press conferences from the likes of LG, Intel, NVIDIA and Sony. And that doesn't include the product demos, announcements and networking that will be happening at the Las Vegas Convention Center and other hotels all over the city. Engadget is covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements are already trickling out as CES approaches, and thanks to the schedule of the Consumer Technology Association (the trade organization that runs the show) we have a full itinerary of press conferences. We’re also using our experience and expertise to predict what tech trends could rear their heads at the show.The CES 2026 schedulePress conferences and show floor booths are the bread and butter of CES. The CTA has already published a searchable directory of who will have an official presence at the show, along with a schedule of every official panel and presentation. However, the press conference schedule gives us a more digestible rundown of the first 48 hours of big events. On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" Ahead of that, though, Samsung has already outlined a variety of more specifics (scroll down for details). Concurrent with the Samsung presentation will be the official CES Unveiled mini-show, which is generally comprised of smaller and start-up vendors. That'll be followed by multiple press conferences throughout Monday, January 5. The LG CES 2026 press conference, titled \"Innovation in Tune with You,\" is ostensibly to share \"its vision for elevating daily life through Affectionate Intelligence.\" But, like Samsung, this fellow Korean giant has already spent the three weeks leading up to CES pre-announcing many of its new products, so this may be more of a summary than breaking news. Following LG, we’ll also see press conferences from Bosch and Hisense, as well as the first-ever CES appearance from Lego. As the Las Vegas afternoon rolls around, we get the first of three chip giants: NVIDIA CEO Jensen Huang takes the stage on January 5 at 1PM PT (4PM ET) and, according to the website, his presentation will last about 90 minutes. Based on the description on the listing, the presentation will “showcase the latest NVIDIA solutions driving innovation and productivity across industries.” NVIDIA’s presser is concurrent with one from Hyundai, where the Korean automotive company will focus on in-cabin car tech and robotics. Later in the day, we get to hear from NVIDIA frenemies Intel and AMD. Intel’s 3PM PT (6PM PT) event will ostensibly feature its new Core Ultra Series 3 processors, and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day. But expect both of them to be very heavy on AI applications, of course. Sandwiched in between those chip manufacturers will be Sony Honda Mobility. The joint venture will be offering yet more details on its Afeela EV. Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at the Las Vegas Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\" It’s worth noting that Lenovo is the parent company of Motorola, which still makes phones and foldables that feature AI tools, so it’s possible those devices feature in the presentation as well. Here’s a handy cheatsheet for easy access to all of Engadget’s coverage: Samsung (Sunday, Jan. 4, 10PM ET)Samsung CES liveblog and livestreamLG (Monday, Jan. 5, 11AM ET)LG CES liveblog and livestreamBosch (Monday, Jan. 5, 12PM ET)Bosch CES livestreamHisense (Monday, Jan. 5, 1PM ET)Hisense CES livestreamLego (Monday, Jan. 5, 1PM ET)Lego CES liveblogNVIDIA (Monday, Jan. 5, 4PM ET)NVIDIA CES liveblog and livestreamHyundai (Monday, Jan. 5, 4PM ET)Hyundai CES livestreamIntel (Monday, Jan. 5, 6PM ET)Intel CES liveblog and livestreamSony Honda Afeela (Monday, Jan. 5, 8PM ET)Sony Honda CES liveblog and livestreamAMD keynote (Monday, Jan. 5, 9:30PM ET)AMD CES liveblog and livestreamLenovo (Tuesday, Jan. 6, 8PM ET)Lenovo CES liveblog and livestreamSamsung and LG vie for pre-show publicityAs noted above, both Samsung and LG have continued their recent trend of spoiling nearly all of their respective CES announcements in the days and weeks before the show. LG, for example, has said it will debut its first Micro RGB television at CES. While details are scarce, the company’s press release for the LG Micro RGB evo did confirm it has received certifications by Intertek for 100 percent color gamut coverage in DCI-P3 an Adobe RGB, and that it has more than a thousand dimming zones for brightness control. Elsewhere in the TV space, LG is throwing its hat into the “art TV” ring that Samsung pioneered with its Frame TVs: The LG Gallery TV will debut in 55- and 65-inch screen sizes, and it will of course show off various artwork when it’s not otherwise in use. And if PC gaming displays are more your speed, LG will have that covered, too, with a new line of 5K-capable gaming monitors on deck with built-in AI upscaling.But LG’s not just showing off displays. The Korean multinational will also introduce a Dolby-powered modular home audio system, a new line of its xboom speakers (developed with will.i.am) and the company will flex its automation muscles with a humanoid home automation robot named CLOiD. We’re also looking forward to checking out the company’s new ultralight Aerominum laptops.Of course, Samsung refuses to be outdone by its hometown rival, and has also released a pre-CES press release document dump. Samsung will be launching its own lineup of Micro RGB TVs at CES, for starters. The company already introduced its first Micro RGB TV at CES 2025, which was a 115-inch model available for a cool $30,000. Next year, Samsung is expanding the range with 55-, 65-, 75-, 85-, 100- and 115-inch models that use the next evolution of the company’s Micro RGB technology. Samsung is also countering LG’s 5K monitors with a 6K model that aims to deliver glasses-free 3D (another long-time CES staple). It’ll be one of several new displays in the company’s Odyssey gaming line. And the company is also updating its Freestyle projector for 2026, too. And on the audio front, Samsung has teased several new soundbars and speakers, including Sonos-style Wi-Fi streaming models call the Music Studio 5 and Studio 7.Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensAs noted above, Samsung and LG appear to be going all-in on Micro RGB display tech for TVs. Expect that to be a huge buzzword at CES, with Hisense and Sony debuting new models, too.Sony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.And maybe your future TV won’t need a power cord, either: Displace will be showing off a mounting option that includes a 15,000mAh battery to juice up whatever giant TV screen you choose to attach.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots — like LG’s aforementioned CLOiD — competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!Update, December 11 2025, 11:03AM ET: This story has been updated to include detail on Lenovo being Motorola’s parent company and how the latter might have a part in the Tuesday presentation.Update, December 16 2025, 1:33PM ET: This story has been updated to include the NVIDIA press conference, which was added to the CTA schedule within the last two days.Update, December 23 2025, 7:28AM ET: This story has been updated to include LG and Samsung’s Micro RGB TV announcements, which were made public in the past seven days. The intro was also tweaked to reflect how soon CES is at this point.Update, December 29 2025, 11:03AM ET: This story has been updated to include additional details on pre-announcements from Samsung, LG and Displace. Update, December 31 2025, 12:05PM ET: This story has been updated to include yet more early LG announcements.Update, January 3 2026, 8:45AM ET: This story has been updated to include still more Samsung and LG announcements.Update, January 4 2026, 8:45PM ET: This story has been updated to include new links and a press conference schedule.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-what-to-expect-from-techs-big-january-conference-120000956.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/xreal-updates-its-entry-level-personal-cinema-glasses-at-ces-140000544.html",
          "published_at": "Mon, 05 Jan 2026 01:03:51 +0000",
          "title": "Xreal updates its entry-level personal cinema glasses at CES",
          "standfirst": "If you’ve been on the fence about trying the sort of “AR glasses” that, until recently, were called “personal cinemas,” then check this out. Xreal has turned up to CES 2026 with an updated version of its entry level Xreal One glasses, first launched at the end of 2024. The new model, dubbed the 1S (yes, with a numeral rather than the word) gets marginally better specs and $50 knocked from the asking price. If you’re unfamiliar, One is a wearable spatial display that connects over USB-C to any compatible device including smartphones, tablets, laptops and consoles. It has two teeny-tiny displays in the eyecups that, when worn close to the eyes, trick your brain into thinking you’re looking at a big screen. The average would measure in at around 171 inches, but it’s possible to push the view to a screen closer to 500 inches if your eyes are capable of focusing that far. As for the changes, they’re all firmly in the welcome nip-and-tuck department, boosting many of the original’s key specs. For instance, the 1080p screens have been swapped out for 1200p full HD, while the field of view has gone from 50 degrees to 52. Brightness has been boosted from 600 nits on the old model to 700 nits here, while the aspect ratio has grown from 16x9 to 16x10. But the change Xreal is arguably most proud of is the drop in price, from $499 down to $449. Certainly, the bustling trade show floor is not the best place to sample the delights of Xreal’s 1S, but it was able to make a fairly persuasive argument as to its value. I was able to view Avatar: One Of The Avatar Movies and my eyes were almost tricked into thinking it was viewing it in a small multiplex cinema room. The usual Xreal strengths — that they don’t cause me eyestrain and offer a compelling degree of immersion — are fully evident here. At the same time, the company is launching the Xreal Neo, an external battery-cum-DisplayPort hub for your glasses. Inside you’ll find a 10,000mAh power bank to keep your glasses going for longer and, more importantly, offers better connection for your Switch consoles. After all, before now, if you wanted to play with your Switch or Switch 2, you’d need to hook it up to its own dock. With the Neo, however, you can eliminate that from your bag when you’re playing out and about. That’s available as a standalone purchase for $99 which, like the new 1S, are ready to buy right now. This article originally appeared on Engadget at https://www.engadget.com/wearables/xreal-updates-its-entry-level-personal-cinema-glasses-at-ces-140000544.html?src=rss",
          "content": "If you’ve been on the fence about trying the sort of “AR glasses” that, until recently, were called “personal cinemas,” then check this out. Xreal has turned up to CES 2026 with an updated version of its entry level Xreal One glasses, first launched at the end of 2024. The new model, dubbed the 1S (yes, with a numeral rather than the word) gets marginally better specs and $50 knocked from the asking price. If you’re unfamiliar, One is a wearable spatial display that connects over USB-C to any compatible device including smartphones, tablets, laptops and consoles. It has two teeny-tiny displays in the eyecups that, when worn close to the eyes, trick your brain into thinking you’re looking at a big screen. The average would measure in at around 171 inches, but it’s possible to push the view to a screen closer to 500 inches if your eyes are capable of focusing that far. As for the changes, they’re all firmly in the welcome nip-and-tuck department, boosting many of the original’s key specs. For instance, the 1080p screens have been swapped out for 1200p full HD, while the field of view has gone from 50 degrees to 52. Brightness has been boosted from 600 nits on the old model to 700 nits here, while the aspect ratio has grown from 16x9 to 16x10. But the change Xreal is arguably most proud of is the drop in price, from $499 down to $449. Certainly, the bustling trade show floor is not the best place to sample the delights of Xreal’s 1S, but it was able to make a fairly persuasive argument as to its value. I was able to view Avatar: One Of The Avatar Movies and my eyes were almost tricked into thinking it was viewing it in a small multiplex cinema room. The usual Xreal strengths — that they don’t cause me eyestrain and offer a compelling degree of immersion — are fully evident here. At the same time, the company is launching the Xreal Neo, an external battery-cum-DisplayPort hub for your glasses. Inside you’ll find a 10,000mAh power bank to keep your glasses going for longer and, more importantly, offers better connection for your Switch consoles. After all, before now, if you wanted to play with your Switch or Switch 2, you’d need to hook it up to its own dock. With the Neo, however, you can eliminate that from your bag when you’re playing out and about. That’s available as a standalone purchase for $99 which, like the new 1S, are ready to buy right now. This article originally appeared on Engadget at https://www.engadget.com/wearables/xreal-updates-its-entry-level-personal-cinema-glasses-at-ces-140000544.html?src=rss",
          "feed_position": 13
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/shure-debuts-a-usb-c-version-of-its-mv88-microphone-at-ces-2026-010000294.html",
          "published_at": "Mon, 05 Jan 2026 01:00:00 +0000",
          "title": "Shure debuts a USB-C version of its MV88 microphone at CES 2026",
          "standfirst": "Shure’s original MV88 microphone (no, not the + version) was a convenient snap-on option for iPhone users. Since Apple ditched the port for USB-C, the audio accessory became obsolete for newer handsets. At CES 2026, the company debuted a revised version of the mic, swapping the Lightning connection for USB-C, which also adds compatibility for Android users and a host of other devices. The best part is the updated MV88 is available now, and it’s priced at $159. If you missed the 2015 version, the MV88 is a compact stereo condenser microphone that simply snaps onto a phone, tablet or one of your laptop’s ports. It provides a packable boost to any built-in mics on your devices, allowing you to capture better audio for voice and video clips. What’s more, it’s a simple, plug-and-play option that doesn’t require additional setup. And if you choose to employ Shure’s suite of apps, you’ll get access to things like presets, microphone gain control, a five-band EQ, limiter, compression and a high-pass filter. Plus, the company’s apps will give you a microphone level meter to keep tabs on your input. Shure MV88 USB-C Billy Steele for Engadget With Auto Level Mode, the mic automatically adjusts gain in real time so that your clips aren’t too loud or too quiet. There’s also a Real-Time Denoiser that works to reduce background noise. The MV88 USB-C has four selectable polar patterns — stereo, mono cardioid, mono bi-directional and raw mid-side — and you can tilt the microphone so that it either points straight up or towards you. I’ve been testing the new MV88 for a few days ahead of CES and I can confirm it’s a substantial boost over anything a device’s built-in microphone can offer. It’s also a nice alternative to popular lapel mics you’ve likely seen creators and influencers use. Those need to be held close to the speaker’s mouth, so they don’t pic up ambient sound or multiple speakers well without moving them. The MV88 would the better choice for capturing clips of live music, the great outdoors or other places where you want some level of background noise. Shure MV88 USB-C Billy Steele for Engadget Sound quality has been impressive thus far. After barely tweaking any settings, audio capture is warm, but also crisp and clear. That Real-Time Denoiser completely eliminated a noisy hotel room A/C unit during one of my testing sessions. This means the new MV88 will improve my sound if I need to do any voice or video interviews this week from my room. I’m also looking forward to seeing how well it does at some of the evening events and on the CES show floor. To me, the best part about the MV88 is the quick and easy setup. You literally just snap it on your phone, or another device with a USB-C port, and after a few taps you’re ready to record. Shure also included a small case for the microphone, so it’s less likely to get damaged any time you just need to chuck it in your bag. This article originally appeared on Engadget at https://www.engadget.com/audio/shure-debuts-a-usb-c-version-of-its-mv88-microphone-at-ces-2026-010000294.html?src=rss",
          "content": "Shure’s original MV88 microphone (no, not the + version) was a convenient snap-on option for iPhone users. Since Apple ditched the port for USB-C, the audio accessory became obsolete for newer handsets. At CES 2026, the company debuted a revised version of the mic, swapping the Lightning connection for USB-C, which also adds compatibility for Android users and a host of other devices. The best part is the updated MV88 is available now, and it’s priced at $159. If you missed the 2015 version, the MV88 is a compact stereo condenser microphone that simply snaps onto a phone, tablet or one of your laptop’s ports. It provides a packable boost to any built-in mics on your devices, allowing you to capture better audio for voice and video clips. What’s more, it’s a simple, plug-and-play option that doesn’t require additional setup. And if you choose to employ Shure’s suite of apps, you’ll get access to things like presets, microphone gain control, a five-band EQ, limiter, compression and a high-pass filter. Plus, the company’s apps will give you a microphone level meter to keep tabs on your input. Shure MV88 USB-C Billy Steele for Engadget With Auto Level Mode, the mic automatically adjusts gain in real time so that your clips aren’t too loud or too quiet. There’s also a Real-Time Denoiser that works to reduce background noise. The MV88 USB-C has four selectable polar patterns — stereo, mono cardioid, mono bi-directional and raw mid-side — and you can tilt the microphone so that it either points straight up or towards you. I’ve been testing the new MV88 for a few days ahead of CES and I can confirm it’s a substantial boost over anything a device’s built-in microphone can offer. It’s also a nice alternative to popular lapel mics you’ve likely seen creators and influencers use. Those need to be held close to the speaker’s mouth, so they don’t pic up ambient sound or multiple speakers well without moving them. The MV88 would the better choice for capturing clips of live music, the great outdoors or other places where you want some level of background noise. Shure MV88 USB-C Billy Steele for Engadget Sound quality has been impressive thus far. After barely tweaking any settings, audio capture is warm, but also crisp and clear. That Real-Time Denoiser completely eliminated a noisy hotel room A/C unit during one of my testing sessions. This means the new MV88 will improve my sound if I need to do any voice or video interviews this week from my room. I’m also looking forward to seeing how well it does at some of the evening events and on the CES show floor. To me, the best part about the MV88 is the quick and easy setup. You literally just snap it on your phone, or another device with a USB-C port, and after a few taps you’re ready to record. Shure also included a small case for the microphone, so it’s less likely to get damaged any time you just need to chuck it in your bag. This article originally appeared on Engadget at https://www.engadget.com/audio/shure-debuts-a-usb-c-version-of-its-mv88-microphone-at-ces-2026-010000294.html?src=rss",
          "feed_position": 15,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/shure-2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/how-to-watch-the-samsung-first-look-ces-2026-presentation-190027420.html",
          "published_at": "Mon, 05 Jan 2026 00:25:37 +0000",
          "title": "How to watch the Samsung 'First Look' CES 2026 presentation",
          "standfirst": "NurPhoto via Getty Images Are you ready for CES 2026? While the show floor doesn't open until Tuesday, things are effectively kicking off this evening with the first big press event of the show. Samsung is taking the stage to set the agenda for the new year and share an overview of its latest and greatest advances. Instead of its longtime midday Monday press conference, the Korean giant will take the lead of the show with a Sunday night presentation. Over the past few weeks, Samsung has been dropping press releases left and right, so we know at least some of what to expect in Vegas this year. Of course, we're holding out hope that we get to hear an update on the Ballie robot — a star of previous CES presentations that ostensibly missed its previously promised 2025 release date. How to watch Samsung's \"The First Look\" presentation at CES 2026 The event will stream live from the Wynn Hotel in Las Vegas tonight — Sunday, January 4 at 10PM ET (7PM PT). There are several ways to tune in: you can watch via Samsung Electronic' official YouTube channel (which we've embedded below), Samsung Newsroom or via Samsung TV Plus. Engadget is on-site at the event, and we'll be running a Samsung CES 2026 liveblog as well. Tune in for real-time updates and commentary. What to expect from Samsung at CES 2026 Keynote speaker TM Roh, the CEO of Samsung's Device eXperience (DX) Division, will discuss the company's plans for the new year and beyond, which will (of course) include \"new AI-driven customer experiences,\" the company said in a press release. In addition, we'll hear from the President and Head of the Visual Display Business, SW Yong and Executive Vice President and Head of Digital Appliances Business, Cheolgi Kim. Those two will \"share their respective business directions for the upcoming year.\" But if you're looking for more specifics, Samsung has been following its \"Advent calendar\" approach to early CES announcements, with new press releases dropping nearly every day in late December and early January. So far, we know that — like competitors LG and Hisense — the company will be offering details on a line of micro RGB TVs (replete with confirmed screen sizes of 55 to 115 inches). Also confirmed: a full line of appliances infused with what Samsung calls Bespoke AI. Samsung will also display its two newest speakers, Music Studio 5 and 7, at CES this year. Additionally, it'll debut its latest Freestyle+ portable projector. Just before the holidays, Samsung also unveiled a slew of new gaming monitors, but most impressive is the Odyssey gaming monitor. It boasts a 32-inch 6K screen and has glasses-free 3D. It's likely we could see this at CES, along with other models like the 27-inch Odyssey G6 and the Odyssey G8 models. It's possible that Samsung will share even more early CES announcements in the hours preceding its presentation. If that happens, we'll add them here! Update, January 4 2026, 11:15AM ET: This story has been updated to include the embedded YouTube viewer for the Samsung event. Update, January 4 2026, 7:25PM ET: This story has been updated to include a link to the Engadget liveblog of this event. This article originally appeared on Engadget at https://www.engadget.com/mobile/how-to-watch-the-samsung-first-look-ces-2026-presentation-190027420.html?src=rss",
          "content": "NurPhoto via Getty Images Are you ready for CES 2026? While the show floor doesn't open until Tuesday, things are effectively kicking off this evening with the first big press event of the show. Samsung is taking the stage to set the agenda for the new year and share an overview of its latest and greatest advances. Instead of its longtime midday Monday press conference, the Korean giant will take the lead of the show with a Sunday night presentation. Over the past few weeks, Samsung has been dropping press releases left and right, so we know at least some of what to expect in Vegas this year. Of course, we're holding out hope that we get to hear an update on the Ballie robot — a star of previous CES presentations that ostensibly missed its previously promised 2025 release date. How to watch Samsung's \"The First Look\" presentation at CES 2026 The event will stream live from the Wynn Hotel in Las Vegas tonight — Sunday, January 4 at 10PM ET (7PM PT). There are several ways to tune in: you can watch via Samsung Electronic' official YouTube channel (which we've embedded below), Samsung Newsroom or via Samsung TV Plus. Engadget is on-site at the event, and we'll be running a Samsung CES 2026 liveblog as well. Tune in for real-time updates and commentary. What to expect from Samsung at CES 2026 Keynote speaker TM Roh, the CEO of Samsung's Device eXperience (DX) Division, will discuss the company's plans for the new year and beyond, which will (of course) include \"new AI-driven customer experiences,\" the company said in a press release. In addition, we'll hear from the President and Head of the Visual Display Business, SW Yong and Executive Vice President and Head of Digital Appliances Business, Cheolgi Kim. Those two will \"share their respective business directions for the upcoming year.\" But if you're looking for more specifics, Samsung has been following its \"Advent calendar\" approach to early CES announcements, with new press releases dropping nearly every day in late December and early January. So far, we know that — like competitors LG and Hisense — the company will be offering details on a line of micro RGB TVs (replete with confirmed screen sizes of 55 to 115 inches). Also confirmed: a full line of appliances infused with what Samsung calls Bespoke AI. Samsung will also display its two newest speakers, Music Studio 5 and 7, at CES this year. Additionally, it'll debut its latest Freestyle+ portable projector. Just before the holidays, Samsung also unveiled a slew of new gaming monitors, but most impressive is the Odyssey gaming monitor. It boasts a 32-inch 6K screen and has glasses-free 3D. It's likely we could see this at CES, along with other models like the 27-inch Odyssey G6 and the Odyssey G8 models. It's possible that Samsung will share even more early CES announcements in the hours preceding its presentation. If that happens, we'll add them here! Update, January 4 2026, 11:15AM ET: This story has been updated to include the embedded YouTube viewer for the Samsung event. Update, January 4 2026, 7:25PM ET: This story has been updated to include a link to the Engadget liveblog of this event. This article originally appeared on Engadget at https://www.engadget.com/mobile/how-to-watch-the-samsung-first-look-ces-2026-presentation-190027420.html?src=rss",
          "feed_position": 18,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/54afdb10-dd18-11f0-b2f7-d2b3086683ec"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/the-subtle-voicebuds-use-ai-to-transcribe-your-words-below-a-whisper-or-in-very-loud-spaces-like-the-ces-show-floor-000000019.html",
          "published_at": "Mon, 05 Jan 2026 00:00:00 +0000",
          "title": "The Subtle Voicebuds use AI to transcribe your words below a whisper, or in very loud spaces (like the CES show floor)",
          "standfirst": "There's a good chance you spend more time talking to your phone's virtual assistant, or dictating text with your voice, instead of actually calling people these days. But, as convenient as voice input can be, you don't want to be the obnoxious person shouting commands to Siri or ChatGPT in a quiet library. And you probably won't have much luck dictating an email in a room with toddlers screaming and Peppa Pig blaring on the TV. (Ask me how I know.) At CES 2026, the startup Subtle is unveiling its solution to those issues: Voicebuds. While they look like a typical pair of wireless earbuds, they feature a custom AI model that lets you dictate text below the sound of a whisper. Additionally, they can also filter out noisy environments so that you don't have to shout for dictation and voice commands. The Voicebuds seem similar to the WHSP ring we saw at CES 2024, which let whisper to your phone, and they also compete with other AI earbuds like the Notebuds One. Subtle Voicebuds.SubtleSubtle claims its Voicebuds deliver five times fewer transcription errors than the AirPods Pro 3 with OpenAI transcription. At $199, they're also priced competitively with Apple's best buds. As with many new hardware products, though, there's also an additional subscription for premium features on Subtle's app, including instant dictation and the ability to transcribe notes without looking at your phone. You'll get a year's worth of access to the Subtle iOS app (there's no Android support so far) when you buy the Voicebuds, but after that it's a $17 a month fee. Without the subscription, the Voicebuds still offer better overall transcription accuracy with its on-device machine learning model. When I tried the Voicebuds at the absolutely raucous CES Unveiled show floor, it was able accurately dictate several sentences at my normal speaking voice. Subtle CEO Tyler Chen was able to replicate that experience across several demos. In a separate remote demonstration, he was also able to dictate several sentences while barely whispering in a quiet room. (He was so quiet, I couldn't even hear what he was saying over video chat). As you’d expect, you can use Voicebuds to take calls and listen to audio just like any other pair of headphones. They also offer other modern features, like active noise cancellation and a multi-mic array. Still, I can't imagine a fledgling startup will be able to match the refined audio quality we've seen from the AirPods Pro 3 and Sony's latest buds, or their well-honed ANC capabilities.As someone who's practically attached to my AirPods Pros, primarily because they handle Siri voice commands so well, it would have to take a truly transformative product to replace them. Voicebuds won't support Apple's \"Hey, Siri\" command, since that involves having one of Apple's proprietary chips, though Chen says the company is integrating its own AI assistant. But if the Voicebud's transcription is as great as the company claims, they may eventually earn a coveted place in my pocket alongside Apple's buds. This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/the-subtle-voicebuds-use-ai-to-transcribe-your-words-below-a-whisper-or-in-very-loud-spaces-like-the-ces-show-floor-000000019.html?src=rss",
          "content": "There's a good chance you spend more time talking to your phone's virtual assistant, or dictating text with your voice, instead of actually calling people these days. But, as convenient as voice input can be, you don't want to be the obnoxious person shouting commands to Siri or ChatGPT in a quiet library. And you probably won't have much luck dictating an email in a room with toddlers screaming and Peppa Pig blaring on the TV. (Ask me how I know.) At CES 2026, the startup Subtle is unveiling its solution to those issues: Voicebuds. While they look like a typical pair of wireless earbuds, they feature a custom AI model that lets you dictate text below the sound of a whisper. Additionally, they can also filter out noisy environments so that you don't have to shout for dictation and voice commands. The Voicebuds seem similar to the WHSP ring we saw at CES 2024, which let whisper to your phone, and they also compete with other AI earbuds like the Notebuds One. Subtle Voicebuds.SubtleSubtle claims its Voicebuds deliver five times fewer transcription errors than the AirPods Pro 3 with OpenAI transcription. At $199, they're also priced competitively with Apple's best buds. As with many new hardware products, though, there's also an additional subscription for premium features on Subtle's app, including instant dictation and the ability to transcribe notes without looking at your phone. You'll get a year's worth of access to the Subtle iOS app (there's no Android support so far) when you buy the Voicebuds, but after that it's a $17 a month fee. Without the subscription, the Voicebuds still offer better overall transcription accuracy with its on-device machine learning model. When I tried the Voicebuds at the absolutely raucous CES Unveiled show floor, it was able accurately dictate several sentences at my normal speaking voice. Subtle CEO Tyler Chen was able to replicate that experience across several demos. In a separate remote demonstration, he was also able to dictate several sentences while barely whispering in a quiet room. (He was so quiet, I couldn't even hear what he was saying over video chat). As you’d expect, you can use Voicebuds to take calls and listen to audio just like any other pair of headphones. They also offer other modern features, like active noise cancellation and a multi-mic array. Still, I can't imagine a fledgling startup will be able to match the refined audio quality we've seen from the AirPods Pro 3 and Sony's latest buds, or their well-honed ANC capabilities.As someone who's practically attached to my AirPods Pros, primarily because they handle Siri voice commands so well, it would have to take a truly transformative product to replace them. Voicebuds won't support Apple's \"Hey, Siri\" command, since that involves having one of Apple's proprietary chips, though Chen says the company is integrating its own AI assistant. But if the Voicebud's transcription is as great as the company claims, they may eventually earn a coveted place in my pocket alongside Apple's buds. This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/the-subtle-voicebuds-use-ai-to-transcribe-your-words-below-a-whisper-or-in-very-loud-spaces-like-the-ces-show-floor-000000019.html?src=rss",
          "feed_position": 20,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/VoicebudsInkBlack2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/how-to-watch-the-amd-ces-2026-keynote-with-ceo-lisa-su-live-190012438.html",
          "published_at": "Sun, 04 Jan 2026 22:43:56 +0000",
          "title": "How to watch the AMD CES 2026 keynote with CEO Lisa Su live",
          "standfirst": "AMD is kicking off CES 2026 on Monday, where it'll cover its latest AI developments and perhaps show off its newest Ryzen chips. The company will outline the full scope of its vision for AI implementations across the full spectrum of consumer and enterprise applications. The presentation — which is the lead keynote for CES 2026 — will be led by CEO Dr. Lisa Su. We'll tell you how to tune in to the livestream and what else you can expect to see. How to watch AMD's keynote live Dr. Su will deliver a keynote speech from the Palazzo Ballroom at the Venetian on Monday, January 5 at 9:30PM ET (6:30PM PT). You can watch the event live on the CES YouTube channel (we've embedded the livestream below). What to expect While AMD says it's keeping its product details under wraps, we can expect \"updates on AI solutions, from cloud to enterprise, edge and devices.\" It's also likely that AMD will unveil its new versions of the Ryzen chips during its keynote on Monday, as Su will talk about the \"advancements driven by Ryzen CPUs.\" That could include the Ryzen 7 9850X3D, which is expected to have better single-threaded performance. Additionally, we can expect to see the Ryzen 9000G series, which is potentially built with AMD's Zen 5 architecture. Regarding AI, AMD could further discuss its new FSR Redstone technology, which it previously previewed on December 10. AMD's upscaling tech aims to close the gap on NVIDIA's DLSS 4, which was announced during CES 2025. Su's presentation caps off CES's press day, so she'll be taking the stage in the hours after rivals NVIDIA and Intel present their chipmaking and AI plans to the world. As a reminder of how cross-linked these companies have become: OpenAI has pledged billions of dollars of hardware orders to AMD, while rival NVIDIA has invested billions in OpenAI — and taken a stake worth billions in Intel, too. This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-amd-ces-2026-keynote-with-ceo-lisa-su-live-190012438.html?src=rss",
          "content": "AMD is kicking off CES 2026 on Monday, where it'll cover its latest AI developments and perhaps show off its newest Ryzen chips. The company will outline the full scope of its vision for AI implementations across the full spectrum of consumer and enterprise applications. The presentation — which is the lead keynote for CES 2026 — will be led by CEO Dr. Lisa Su. We'll tell you how to tune in to the livestream and what else you can expect to see. How to watch AMD's keynote live Dr. Su will deliver a keynote speech from the Palazzo Ballroom at the Venetian on Monday, January 5 at 9:30PM ET (6:30PM PT). You can watch the event live on the CES YouTube channel (we've embedded the livestream below). What to expect While AMD says it's keeping its product details under wraps, we can expect \"updates on AI solutions, from cloud to enterprise, edge and devices.\" It's also likely that AMD will unveil its new versions of the Ryzen chips during its keynote on Monday, as Su will talk about the \"advancements driven by Ryzen CPUs.\" That could include the Ryzen 7 9850X3D, which is expected to have better single-threaded performance. Additionally, we can expect to see the Ryzen 9000G series, which is potentially built with AMD's Zen 5 architecture. Regarding AI, AMD could further discuss its new FSR Redstone technology, which it previously previewed on December 10. AMD's upscaling tech aims to close the gap on NVIDIA's DLSS 4, which was announced during CES 2025. Su's presentation caps off CES's press day, so she'll be taking the stage in the hours after rivals NVIDIA and Intel present their chipmaking and AI plans to the world. As a reminder of how cross-linked these companies have become: OpenAI has pledged billions of dollars of hardware orders to AMD, while rival NVIDIA has invested billions in OpenAI — and taken a stake worth billions in Intel, too. This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-amd-ces-2026-keynote-with-ceo-lisa-su-live-190012438.html?src=rss",
          "feed_position": 21
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/evs/how-to-watch-the-sony-honda-afeela-ces-2026-presentation-130048804.html",
          "published_at": "Sun, 04 Jan 2026 21:18:05 +0000",
          "title": "How to watch the Sony Honda Afeela CES 2026 presentation",
          "standfirst": "Sony's CES 2026 press conference is just a few days away, and this year comes with a twist: Rather than an overview of Sony's electronics, video game and Hollywood studio plans for the new year, the presser will have a more narrow focus: electric vehicles. Sound odd? That's because the traditional end-of-press-day slot isn't just Sony, but rather Sony Honda Mobility — the joint venture responsible for the Afeela 1 electric car that has been showcased at CES for the better part of a decade. But this year, we'll get to see an all-new concept model at the event. How to watch the Sony Afeela CES 2026 press conference The event will be streamed live from Las Vegas on Monday, January 5 at 8PM ET via the Afeela official YouTube channel, which we've embedded below. What to expect from Sony Afeela at CES The Afeela 1 has been shown in various incarnations since CES 2020, where it was originally announced as the Vision-S. But so many more important details were confirmed in the past couple of years, including the price, which starts at a staggering $89,900. However, the earlier impressions were less than impressive, and as of CES 2025, that thought remains the same. Engadget's automotive expert Tim Stevens said a year ago that the EV \"feels like a PlayStation 4 in the PS5 era,\" and that \"the car lost what little interesting styling it had while sticking true to some specifications that sounded good five years ago.\" Ouch. But the Afeela 1 won't be the only vehicle on display. Its CES booth will showcase \"several Afeela 1 pre-production vehicles in multiple color variations, alongside a new Afeela concept model,\" Sony Honda Mobility said in a press release. The company recently announced that the Afeela will be the first vehicle ever to offer PlayStation Remote Play, which lets players stream their PS4 or PS5 games from their consoles remotely while inside the car. That's no doubt built on the same streaming improvements that have been incorporated into the PlayStation Portal. We're hoping to hear about what else is new and improved at CES 2026, and we're also excited to see its newest concept model. And between booth displays and press releases, we're hoping we'll get to see at least a few new Sony Electronics products on the docket for 2026, too. Update, January 4 2026, 4:17PM ET: This story has been updated to include the embedded YouTube stream for the Afeela presentation.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/how-to-watch-the-sony-honda-afeela-ces-2026-presentation-130048804.html?src=rss",
          "content": "Sony's CES 2026 press conference is just a few days away, and this year comes with a twist: Rather than an overview of Sony's electronics, video game and Hollywood studio plans for the new year, the presser will have a more narrow focus: electric vehicles. Sound odd? That's because the traditional end-of-press-day slot isn't just Sony, but rather Sony Honda Mobility — the joint venture responsible for the Afeela 1 electric car that has been showcased at CES for the better part of a decade. But this year, we'll get to see an all-new concept model at the event. How to watch the Sony Afeela CES 2026 press conference The event will be streamed live from Las Vegas on Monday, January 5 at 8PM ET via the Afeela official YouTube channel, which we've embedded below. What to expect from Sony Afeela at CES The Afeela 1 has been shown in various incarnations since CES 2020, where it was originally announced as the Vision-S. But so many more important details were confirmed in the past couple of years, including the price, which starts at a staggering $89,900. However, the earlier impressions were less than impressive, and as of CES 2025, that thought remains the same. Engadget's automotive expert Tim Stevens said a year ago that the EV \"feels like a PlayStation 4 in the PS5 era,\" and that \"the car lost what little interesting styling it had while sticking true to some specifications that sounded good five years ago.\" Ouch. But the Afeela 1 won't be the only vehicle on display. Its CES booth will showcase \"several Afeela 1 pre-production vehicles in multiple color variations, alongside a new Afeela concept model,\" Sony Honda Mobility said in a press release. The company recently announced that the Afeela will be the first vehicle ever to offer PlayStation Remote Play, which lets players stream their PS4 or PS5 games from their consoles remotely while inside the car. That's no doubt built on the same streaming improvements that have been incorporated into the PlayStation Portal. We're hoping to hear about what else is new and improved at CES 2026, and we're also excited to see its newest concept model. And between booth displays and press releases, we're hoping we'll get to see at least a few new Sony Electronics products on the docket for 2026, too. Update, January 4 2026, 4:17PM ET: This story has been updated to include the embedded YouTube stream for the Afeela presentation.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/how-to-watch-the-sony-honda-afeela-ces-2026-presentation-130048804.html?src=rss",
          "feed_position": 24,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/3f099890-d9ef-11f0-a3f3-bb8a02df8254"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/how-to-watch-the-nvidia-ces-2026-press-conference-with-jensen-huang-live-130028602.html",
          "published_at": "Sun, 04 Jan 2026 20:19:45 +0000",
          "title": "How to watch the NVIDIA CES 2026 press conference with Jensen Huang live",
          "standfirst": "CFOTO via Getty Images During CES 2025, NVIDIA spent much of its keynote touting its leading position in artificial intelligence. Still, the company managed to squeeze in a few notable hardware announcements, including its RTX 5000-series GPUs and Project Digits desktop supercomputer (later redubbed Spark). For this year's show, the company's website says it's \"lighting up CES 2026 with the power of AI.\" To that end, NVIDIA is going big in Las Vegas, promising hands-on demos in its Fontainebleau booth, replete with the \"latest NVIDIA solutions driving innovation and productivity across industries.\" But if you won't be in Vegas for the action, don't worry. Here's how you can watch the livestream of the company's January 5 press conference, and what NVIDIA is expected to unveil at CES this year. How to watch the NVIDIA CES 2026 keynote NVIDIA CEO Jensen Huang will deliver a 90-minute keynote at CES 2026. The event will be livestreamed on Monday, January 5 at 4PM ET via NVIDIA's website (and likely on YouTube as well). We'll embed the link here once it's available. What to expect NVIDIA's game plan for CES is suitably vague so far, including \"cutting-edge AI, robotics, simulation, gaming and content creation at the NVIDIA Showcase.\" It also notes there will be more than 20 demos. Although we're unsure if all of these will be shown during the keynote, we can at least expect to see them throughout the week of CES. NVIDIA arrives at CES as the most valuable publicly traded company in the world (a stunning $4.6 trillion at the time of this writing, albeit down from an even higher valuation earlier in 2025). And given that the health of the US and global economy seems increasingly linked to infrastructure spending on AI data centers — largely powered by chips from NVIDIA and its competitors — expect Huang's remarks to be as closely followed by Wall Street investors as technology acolytes, if not more so. Will we get any insight on a successor to the company's Blackwell chip? A more detailed look at how NVIDIA's partners are applying AI to real-world robotics? Time will tell, but you might want to keep your stock portfolio in a split screen while taking in Huang's presentation.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-nvidia-ces-2026-press-conference-with-jensen-huang-live-130028602.html?src=rss",
          "content": "CFOTO via Getty Images During CES 2025, NVIDIA spent much of its keynote touting its leading position in artificial intelligence. Still, the company managed to squeeze in a few notable hardware announcements, including its RTX 5000-series GPUs and Project Digits desktop supercomputer (later redubbed Spark). For this year's show, the company's website says it's \"lighting up CES 2026 with the power of AI.\" To that end, NVIDIA is going big in Las Vegas, promising hands-on demos in its Fontainebleau booth, replete with the \"latest NVIDIA solutions driving innovation and productivity across industries.\" But if you won't be in Vegas for the action, don't worry. Here's how you can watch the livestream of the company's January 5 press conference, and what NVIDIA is expected to unveil at CES this year. How to watch the NVIDIA CES 2026 keynote NVIDIA CEO Jensen Huang will deliver a 90-minute keynote at CES 2026. The event will be livestreamed on Monday, January 5 at 4PM ET via NVIDIA's website (and likely on YouTube as well). We'll embed the link here once it's available. What to expect NVIDIA's game plan for CES is suitably vague so far, including \"cutting-edge AI, robotics, simulation, gaming and content creation at the NVIDIA Showcase.\" It also notes there will be more than 20 demos. Although we're unsure if all of these will be shown during the keynote, we can at least expect to see them throughout the week of CES. NVIDIA arrives at CES as the most valuable publicly traded company in the world (a stunning $4.6 trillion at the time of this writing, albeit down from an even higher valuation earlier in 2025). And given that the health of the US and global economy seems increasingly linked to infrastructure spending on AI data centers — largely powered by chips from NVIDIA and its competitors — expect Huang's remarks to be as closely followed by Wall Street investors as technology acolytes, if not more so. Will we get any insight on a successor to the company's Blackwell chip? A more detailed look at how NVIDIA's partners are applying AI to real-world robotics? Time will tell, but you might want to keep your stock portfolio in a split screen while taking in Huang's presentation.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-nvidia-ces-2026-press-conference-with-jensen-huang-live-130028602.html?src=rss",
          "feed_position": 25,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/b0333b00-dcee-11f0-a993-97c527ebca4b"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/lgs-aerominum-gram-pro-laptops-feel-impossibly-light-and-strong-200317743.html",
          "published_at": "Sun, 04 Jan 2026 20:03:17 +0000",
          "title": "LG's 'Aerominum' Gram Pro laptops feel impossibly light and strong",
          "standfirst": "For years, LG has pushed its ultra-light Gram laptops as a way to stand out from the PC crowd, for better or worse. I was't a big fan of the flex-prone case in the 2017 Gram, and we had similar concerns with the first 17-inch Gram in 2019. But in fairness, it's been a while since we've reviewed one, and we found a lot to like in our preview of last year's AI-equipped model. Now LG is back with a major Gram Pro redesign at CES 2026, which features a new aluminum/magnesium alloy it's dubbed \"Aerominum.\" And finally, it seems LG has found a balance between building a super-light notebook (the 16-inch Gram Pro weighs just 2.6 pounds), and crafting something that actually feels durable. Admittedly, the Gram Pro doesn't look particularly impressive at first glance. It has a large 16-inch 2.8K OLED screen, which certainly looks nice, but doesn't really stand out from the glut of other OLED laptops on market. It's also powered by Intel's new Panther Lake chips, and it supports dual NVMe SSDs. The magic happens when you pick it up: My brain had a hard time computing how such a large computer felt so light in my hands. And best of all, it didn't flex much when I tried to squeeze the case. LG Gram Pro 16 side ports.Devindra Hardawar for EngadgetThere's still a bit of give, to be clear, but it didn't feel as precariously bendy as earlier models. I wouldn't stress too much about throwing it into a messenger bag without additional protection. The more I handled the Gram Pro, the more I wished other PC makers strived for similar weight reduction. The Gram Pro weighs about as much as the 13-inch MacBook Air! That's certainly an impressive feat.The LG Gram Pro 16's disappointing keyboard.Devindra Hardawar for EngadgetI just wish LG spent as much time refining the Gram Pro's keyboard as its case design. There's barely any key travel, which made for an unresponsive and unsatisfying typing experience. I get it, LG probably doesn't have the available vertical height for much key movement, but there are other ways to make typing feel more dynamic. The Gram Pro's trackpad, meanwhile, is serviceable, but it also didn't feel as smooth and responsive as what we see from Apple's notebooks or Microsoft's Surface Laptop.LG Gram Pro 17LGIn addition to the 16-inch Gram Pro, LG also debuted a 17-inch model with an Aerominum case, which is notable for being the lightest notebook at that size with an NVIDIA RTX GPU. Specifically, it's toting the RTX 5050, which should be enough to play most games at the laptop's native 2,880 by 1,800 resolution (or 1440p blown up a bit). Given the more powerful hardware, the Gram Pro 17 is heavier than the 16-inch model, but it still comes at a relatively light 3.8 pounds. I didn't get a chance to play any games on the laptop, unfortunately, but overall it looks like a decent option for someone who wants a large screen with a bit of horsepower.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/lgs-aerominum-gram-pro-laptops-feel-impossibly-light-and-strong-200317743.html?src=rss",
          "content": "For years, LG has pushed its ultra-light Gram laptops as a way to stand out from the PC crowd, for better or worse. I was't a big fan of the flex-prone case in the 2017 Gram, and we had similar concerns with the first 17-inch Gram in 2019. But in fairness, it's been a while since we've reviewed one, and we found a lot to like in our preview of last year's AI-equipped model. Now LG is back with a major Gram Pro redesign at CES 2026, which features a new aluminum/magnesium alloy it's dubbed \"Aerominum.\" And finally, it seems LG has found a balance between building a super-light notebook (the 16-inch Gram Pro weighs just 2.6 pounds), and crafting something that actually feels durable. Admittedly, the Gram Pro doesn't look particularly impressive at first glance. It has a large 16-inch 2.8K OLED screen, which certainly looks nice, but doesn't really stand out from the glut of other OLED laptops on market. It's also powered by Intel's new Panther Lake chips, and it supports dual NVMe SSDs. The magic happens when you pick it up: My brain had a hard time computing how such a large computer felt so light in my hands. And best of all, it didn't flex much when I tried to squeeze the case. LG Gram Pro 16 side ports.Devindra Hardawar for EngadgetThere's still a bit of give, to be clear, but it didn't feel as precariously bendy as earlier models. I wouldn't stress too much about throwing it into a messenger bag without additional protection. The more I handled the Gram Pro, the more I wished other PC makers strived for similar weight reduction. The Gram Pro weighs about as much as the 13-inch MacBook Air! That's certainly an impressive feat.The LG Gram Pro 16's disappointing keyboard.Devindra Hardawar for EngadgetI just wish LG spent as much time refining the Gram Pro's keyboard as its case design. There's barely any key travel, which made for an unresponsive and unsatisfying typing experience. I get it, LG probably doesn't have the available vertical height for much key movement, but there are other ways to make typing feel more dynamic. The Gram Pro's trackpad, meanwhile, is serviceable, but it also didn't feel as smooth and responsive as what we see from Apple's notebooks or Microsoft's Surface Laptop.LG Gram Pro 17LGIn addition to the 16-inch Gram Pro, LG also debuted a 17-inch model with an Aerominum case, which is notable for being the lightest notebook at that size with an NVIDIA RTX GPU. Specifically, it's toting the RTX 5050, which should be enough to play most games at the laptop's native 2,880 by 1,800 resolution (or 1440p blown up a bit). Given the more powerful hardware, the Gram Pro 17 is heavier than the 16-inch model, but it still comes at a relatively light 3.8 pounds. I didn't get a chance to play any games on the laptop, unfortunately, but overall it looks like a decent option for someone who wants a large screen with a bit of horsepower.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/lgs-aerominum-gram-pro-laptops-feel-impossibly-light-and-strong-200317743.html?src=rss",
          "feed_position": 26,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/LG_Gram_Pro-3.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/how-to-watch-the-lego-ces-2026-press-conference-live-130005019.html",
          "published_at": "Sun, 04 Jan 2026 19:23:55 +0000",
          "title": "How to watch the Lego CES 2026 press conference live",
          "standfirst": "picture alliance via Getty Images Are you a Lego Adult? No guilt implied — we hear you, whether you enjoy building Death Stars, Starship Enterprises or even just the occasional flower bouquet. But you may be surprised to hear that the Lego Group is set to host its very first press conference at CES 2026. Exactly what it plans to unveil is still under wraps, however. The iconic toy brick maker has offered no clues about what's on the agenda, leaving speculation wide open, from new video games to Formula 1 race cars. Here's how you can watch Lego's presentation at CES, along with what we think the company could reveal. How to watch The Lego Group's CES 2026 press conference The Lego CES press conference is scheduled for Monday, January 5 at 1PM ET. While Lego and the Consumer Technology Association haven't yet provided the details, we expect that the press conference will be available as a livestream. Once the details are confirmed, we'll update this post to confirm them. But if a livestream isn't immediately available, the Engadget team will be liveblogging the Lego presser and posting timely details. What to expect Thus far, Lego hasn't shared any public info about its CES plans, so we're largely in the dark as to what to expect. At CES 2025, for instance, the toy production giant partnered with Sony to announce the animated Lego Horizon Adventures online game. As such, Lego may spend some time talking up its new 2026 game, Lego Batman: Legacy of the Dark Knight. The company may also give some stage time to its Lego Group F1 Academy racing car, though that too would be more about brand building than consumer products. And given Lego's focus on the environment, the company may discuss its efforts to reach its 2032 ecological goals, including making its Lego bricks more sustainable and reducing carbon emissions by 37%. While there are plenty of new Lego sets for 2026, however, this is CES, not Toy Fair. So we're assuming that the company will be showcasing something that's more tech-centric. Stay tuned.This article originally appeared on Engadget at https://www.engadget.com/gaming/how-to-watch-the-lego-ces-2026-press-conference-live-130005019.html?src=rss",
          "content": "picture alliance via Getty Images Are you a Lego Adult? No guilt implied — we hear you, whether you enjoy building Death Stars, Starship Enterprises or even just the occasional flower bouquet. But you may be surprised to hear that the Lego Group is set to host its very first press conference at CES 2026. Exactly what it plans to unveil is still under wraps, however. The iconic toy brick maker has offered no clues about what's on the agenda, leaving speculation wide open, from new video games to Formula 1 race cars. Here's how you can watch Lego's presentation at CES, along with what we think the company could reveal. How to watch The Lego Group's CES 2026 press conference The Lego CES press conference is scheduled for Monday, January 5 at 1PM ET. While Lego and the Consumer Technology Association haven't yet provided the details, we expect that the press conference will be available as a livestream. Once the details are confirmed, we'll update this post to confirm them. But if a livestream isn't immediately available, the Engadget team will be liveblogging the Lego presser and posting timely details. What to expect Thus far, Lego hasn't shared any public info about its CES plans, so we're largely in the dark as to what to expect. At CES 2025, for instance, the toy production giant partnered with Sony to announce the animated Lego Horizon Adventures online game. As such, Lego may spend some time talking up its new 2026 game, Lego Batman: Legacy of the Dark Knight. The company may also give some stage time to its Lego Group F1 Academy racing car, though that too would be more about brand building than consumer products. And given Lego's focus on the environment, the company may discuss its efforts to reach its 2032 ecological goals, including making its Lego bricks more sustainable and reducing carbon emissions by 37%. While there are plenty of new Lego sets for 2026, however, this is CES, not Toy Fair. So we're assuming that the company will be showcasing something that's more tech-centric. Stay tuned.This article originally appeared on Engadget at https://www.engadget.com/gaming/how-to-watch-the-lego-ces-2026-press-conference-live-130005019.html?src=rss",
          "feed_position": 27,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/ced0c170-dd13-11f0-b394-1dea3c7b6af3"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-press-conference-live-190040504.html",
          "published_at": "Sun, 04 Jan 2026 19:18:05 +0000",
          "title": "How to watch the Hisense CES 2026 press conference live",
          "standfirst": "Xinhua News Agency via Getty Images Hisense is typically best known for its affordable electronics and home appliances, from TVs to refrigerators. But at CES 2025, the China-based company showed off its premium side with a massive 136-inch micro LED TV — now available for a jaw-dropping $100,000. So what's in store for this year's show? New leadership, for starters. The company has two new hires, including Chief Marketing Officer Sarah Larsen and Chief Commercial Officer James Fishler. In a press release, Hisense said Fishler's experience in home entertainment, appliances and HVAC is important as the company \"builds toward a milestone 2026 and its presence at CES.\" We'll give you a rundown of what to expect during Hisense's presentation and how you can watch it live. How to watch Hisense's presentation Hisense will have a livestream available on Monday, January 5 at 1PM ET on its website. We'll embed the link here once it's available. What to expect With its new hires in place, Hisense is clearly aiming to further polish its brand. Between Fishler and Larsen, the new front office is bringing to bear their experience from such high-powered competitors as LG, Samsung and Beats. And in a recent interview with Tom's Guide, Larsen emphasized a continued focus on the company's fast turnaround time from concept to market as a key differentiator for Hisense. As for actual announcements, expect Hisense to split the difference between large appliances and consumer electronics. In an early press release, the company is touting (what else) the enhanced AI smarts of its ConnectLife platform, stretching across everything from HVAC systems to kitchen gear to washer/dryers (\"... with the enhanced AI Laundry Agent, fabric types and soil levels are automatically identified...\"). Meanwhile, Larsen's aforementioned interview specifically calls out the emerging RGB TV space as a focus. We expect this year's show will be all about explaining the shades of difference between mini and micro LED display technologies, as both Samsung and LG have already thrown down pre-announcement gauntlets on the latter. Will any of them cost less than six figures? Let's hope Hisense has some good news to share on that front. Update, January 4 2026, 2:17PM ET: This story has been updated to include information on the Hisense ConnectLife AI platform.This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-press-conference-live-190040504.html?src=rss",
          "content": "Xinhua News Agency via Getty Images Hisense is typically best known for its affordable electronics and home appliances, from TVs to refrigerators. But at CES 2025, the China-based company showed off its premium side with a massive 136-inch micro LED TV — now available for a jaw-dropping $100,000. So what's in store for this year's show? New leadership, for starters. The company has two new hires, including Chief Marketing Officer Sarah Larsen and Chief Commercial Officer James Fishler. In a press release, Hisense said Fishler's experience in home entertainment, appliances and HVAC is important as the company \"builds toward a milestone 2026 and its presence at CES.\" We'll give you a rundown of what to expect during Hisense's presentation and how you can watch it live. How to watch Hisense's presentation Hisense will have a livestream available on Monday, January 5 at 1PM ET on its website. We'll embed the link here once it's available. What to expect With its new hires in place, Hisense is clearly aiming to further polish its brand. Between Fishler and Larsen, the new front office is bringing to bear their experience from such high-powered competitors as LG, Samsung and Beats. And in a recent interview with Tom's Guide, Larsen emphasized a continued focus on the company's fast turnaround time from concept to market as a key differentiator for Hisense. As for actual announcements, expect Hisense to split the difference between large appliances and consumer electronics. In an early press release, the company is touting (what else) the enhanced AI smarts of its ConnectLife platform, stretching across everything from HVAC systems to kitchen gear to washer/dryers (\"... with the enhanced AI Laundry Agent, fabric types and soil levels are automatically identified...\"). Meanwhile, Larsen's aforementioned interview specifically calls out the emerging RGB TV space as a focus. We expect this year's show will be all about explaining the shades of difference between mini and micro LED display technologies, as both Samsung and LG have already thrown down pre-announcement gauntlets on the latter. Will any of them cost less than six figures? Let's hope Hisense has some good news to share on that front. Update, January 4 2026, 2:17PM ET: This story has been updated to include information on the Hisense ConnectLife AI platform.This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-hisense-ces-2026-press-conference-live-190040504.html?src=rss",
          "feed_position": 28,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/834aecc0-dcf1-11f0-b7de-13a29302f310"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/how-to-watch-the-lenovo-tech-world-event-at-ces-2026-130004983.html",
          "published_at": "Sun, 04 Jan 2026 19:01:27 +0000",
          "title": "How to watch the Lenovo Tech World event at CES 2026",
          "standfirst": "We've known for several months now that tech giant Lenovo is hosting its Tech World event at Sphere is Las Vegas during CES week. And like many other tech conglomerates, the world's largest PC manufacturer by units shipped is centering its focus on AI. Lenovo says it will be a \"Tech World experience unlike anything CES has seen before.\" We'll tell you where to livestream the event and what the company has teased so far. How to watch the Lenovo CES 2026 event live Lenovo CEO Yuanqing Yang will host the event on Tuesday, January 6 at 8PM ET. You can follow along to the livestream on YouTube once the event starts. (We've embedded the code below.) What to expect Lenovo is using the high-profile Sphere venue to share some of its tie-ins to the sports world, offering an exclusive look at how the company's technology has \"revolutionized F1,\" Yang said in a press release. He'll also preview the plans for leveraging AI at this summer's FIFA World Cup, which takes place in the US. After the event has wrapped up, pop singer Gwen Stefani will take the stage to perform. As for real products, look for Lenovo to build on some of its successful launches from CES 2025. A year ago, we saw the portable Lenovo Legion Go S – the first third-party SteamOS handheld gaming device – as well as its \"stretchy\" laptop, the ThinkBook Plus Gen 6 Rollable that extends 2.7 inches taller with a touch of a button. To Lenovo's credit, both products were actually released and available for sale within months, unlike the vaporware that seems to comprise the bulk of many companies' CES announcements. Lastly, don't be surprised if we see some new Motorola smartphones, given that Lenovo is the parent company of the phone manufacturer. Maybe a new Razr foldable? We'll find out either way on Tuesday evening.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-lenovo-tech-world-event-at-ces-2026-130004983.html?src=rss",
          "content": "We've known for several months now that tech giant Lenovo is hosting its Tech World event at Sphere is Las Vegas during CES week. And like many other tech conglomerates, the world's largest PC manufacturer by units shipped is centering its focus on AI. Lenovo says it will be a \"Tech World experience unlike anything CES has seen before.\" We'll tell you where to livestream the event and what the company has teased so far. How to watch the Lenovo CES 2026 event live Lenovo CEO Yuanqing Yang will host the event on Tuesday, January 6 at 8PM ET. You can follow along to the livestream on YouTube once the event starts. (We've embedded the code below.) What to expect Lenovo is using the high-profile Sphere venue to share some of its tie-ins to the sports world, offering an exclusive look at how the company's technology has \"revolutionized F1,\" Yang said in a press release. He'll also preview the plans for leveraging AI at this summer's FIFA World Cup, which takes place in the US. After the event has wrapped up, pop singer Gwen Stefani will take the stage to perform. As for real products, look for Lenovo to build on some of its successful launches from CES 2025. A year ago, we saw the portable Lenovo Legion Go S – the first third-party SteamOS handheld gaming device – as well as its \"stretchy\" laptop, the ThinkBook Plus Gen 6 Rollable that extends 2.7 inches taller with a touch of a button. To Lenovo's credit, both products were actually released and available for sale within months, unlike the vaporware that seems to comprise the bulk of many companies' CES announcements. Lastly, don't be surprised if we see some new Motorola smartphones, given that Lenovo is the parent company of the phone manufacturer. Maybe a new Razr foldable? We'll find out either way on Tuesday evening.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-lenovo-tech-world-event-at-ces-2026-130004983.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/intelition-changes-everything-ai-is-no-longer-a-tool-you-invoke",
          "published_at": "Sun, 04 Jan 2026 19:00:00 GMT",
          "title": "'Intelition' changes everything: AI is no longer a tool you invoke",
          "standfirst": "AI is evolving faster than our vocabulary for describing it. We may need a few new words. We have “cognition” for how a single mind thinks, but we don&#x27;t have a word for what happens when human and machine intelligence work together to perceive, decide, create and act. Let’s call that process intelition. Intelition isn’t a feature; it’s the organizing principle for the next wave of software where humans and AI operate inside the same shared model of the enterprise. Today’s systems treat AI models as things you invoke from the outside. You act as a “user,” prompting for responses or wiring a “human in the loop” step into agentic workflows. But that&#x27;s evolving into continuous co-production: People and agents are shaping decisions, logic and actions together, in real time. Read on for a breakdown of the three forces driving this new paradigm. A unified ontology is just the beginningIn a recent shareholder letter, Palantir CEO Alex Karp wrote that “all the value in the market is going to go to chips and what we call ontology,” and argued that this shift is “only the beginning of something much larger and more significant.” By ontology, Karp means a shared model of objects (customers, policies, assets, events) and their relationships. This also includes what Palantir calls an ontology’s “kinetic layer” that defines the actions and security permissions connecting objects.In the SaaS era, every enterprise application creates its own object and process models. Combined with a host of legacy systems and often chaotic models, enterprises face the challenge of stitching all this together. It’s a big and difficult job, with redundancies, incomplete structures and missing data. The reality: No matter how many data warehouse or data lake projects commissioned, few enterprises come close to creating a consolidated enterprise ontology. A unified ontology is essential for today’s agentic AI tools. As organizations link and federate ontologies, a new software paradigm emerges: Agentic AI can reason and act across suppliers, regulators, customers and operations, not just within a single app. As Karp describes it, the aim is “to tether the power of artificial intelligence to objects and relationships in the real world.” World models and continuous learningToday’s models can hold extensive context, but holding information isn’t the same as learning from it. Continual learning requires the accumulation of understanding, rather than resets with each retraining. To his aim, Google recently announced “Nested Learning” as a potential solution, grounded direclty into existing LLM architecture and training data. The authors don’t claim to have solved the challenges of building world models. But, Nested Learning could supply the raw ingredients for them: Durable memory with continual learning layered into the system. The endpoint would make retraining obsolete. In June 2022, Meta&#x27;s chief AI scientist Yann LeCun created a blueprint for “autonomous machine intelligence” that featured a hierarchical approach to using joint embeddings to make predictions using world models. He called the technique H-JEPA, and later put bluntly: “LLMs are good at manipulating language, but not at thinking.”Over the past three years, LeCun and his colleagues at Meta have moved H-JEPA theory into practice with open source models V-JEPA and I-JEPA, which learn image and video representations of the world. The personal intelition interface The third force in this agentic, ontology-driven world is the personal interface. This puts people at the center rather than as “users” on the periphery. This is not another app; it is the primary way a person participates in the next era of work and life. Rather than treating AI as something we visit through a chat window or API cal, the personal intelition interface will be always-on, aware of our context, preferences and goals and capable of acting on our behalf across the entire federated economy. Let’s analyze how this is already coming together.In May, Jony Ive sold his AI device company io to OpenAI to accelerate a new AI device category. He noted at the time: “If you make something new, if you innovate, there will be consequences unforeseen, and some will be wonderful, and some will be harmful. While some of the less positive consequences were unintentional, I still feel responsibility. And the manifestation of that is a determination to try and be useful.” That is, getting the personal intelligence device right means more than an attractive venture opportunity. Apple is looking beyond LLMs for on-device solutions that require less processing power and result in less latency when creating AI apps to understand “user intent.” Last year, they created UI-JEPA, an innovation that moves to “on-device analysis” of what the user wants. This strikes directly at the business model of today’s digital economy, where centralized profiling of “users” transforms intent and behavior data into vast revenue streams.Tim Berners-Lee, the inventor of the World Wide Web, recently noted: “The user has been reduced to a consumable product for the advertiser ... there&#x27;s still time to build machines that work for humans, and not the other way around.\" Moving user intent to the device will drive interest in a secure personal data management standard, Solid, that Berners-Lee and his colleagues have been developing since 2022. The standard is ideally suited to pair with new personal AI devices. For instance, Inrupt, Inc., a company founded by Berners-Lee, recently combined Solid with Anthropic’s MCP standard for Agentic Wallets. Personal control is more than a feature of this paradigm; it is the architectural safeguard as systems gain the ability to learn and act continuously.Ultimately, these three forces are moving and converging faster than most realize. Enterprise ontologies provide the nouns and verbs, world-model research supplies durable memory and learning and the personal interface becomes the permissioned point of control. The next software era isn&#x27;t coming. It&#x27;s already here.Brian Mulconrey is SVP at Sureify Labs.",
          "content": "AI is evolving faster than our vocabulary for describing it. We may need a few new words. We have “cognition” for how a single mind thinks, but we don&#x27;t have a word for what happens when human and machine intelligence work together to perceive, decide, create and act. Let’s call that process intelition. Intelition isn’t a feature; it’s the organizing principle for the next wave of software where humans and AI operate inside the same shared model of the enterprise. Today’s systems treat AI models as things you invoke from the outside. You act as a “user,” prompting for responses or wiring a “human in the loop” step into agentic workflows. But that&#x27;s evolving into continuous co-production: People and agents are shaping decisions, logic and actions together, in real time. Read on for a breakdown of the three forces driving this new paradigm. A unified ontology is just the beginningIn a recent shareholder letter, Palantir CEO Alex Karp wrote that “all the value in the market is going to go to chips and what we call ontology,” and argued that this shift is “only the beginning of something much larger and more significant.” By ontology, Karp means a shared model of objects (customers, policies, assets, events) and their relationships. This also includes what Palantir calls an ontology’s “kinetic layer” that defines the actions and security permissions connecting objects.In the SaaS era, every enterprise application creates its own object and process models. Combined with a host of legacy systems and often chaotic models, enterprises face the challenge of stitching all this together. It’s a big and difficult job, with redundancies, incomplete structures and missing data. The reality: No matter how many data warehouse or data lake projects commissioned, few enterprises come close to creating a consolidated enterprise ontology. A unified ontology is essential for today’s agentic AI tools. As organizations link and federate ontologies, a new software paradigm emerges: Agentic AI can reason and act across suppliers, regulators, customers and operations, not just within a single app. As Karp describes it, the aim is “to tether the power of artificial intelligence to objects and relationships in the real world.” World models and continuous learningToday’s models can hold extensive context, but holding information isn’t the same as learning from it. Continual learning requires the accumulation of understanding, rather than resets with each retraining. To his aim, Google recently announced “Nested Learning” as a potential solution, grounded direclty into existing LLM architecture and training data. The authors don’t claim to have solved the challenges of building world models. But, Nested Learning could supply the raw ingredients for them: Durable memory with continual learning layered into the system. The endpoint would make retraining obsolete. In June 2022, Meta&#x27;s chief AI scientist Yann LeCun created a blueprint for “autonomous machine intelligence” that featured a hierarchical approach to using joint embeddings to make predictions using world models. He called the technique H-JEPA, and later put bluntly: “LLMs are good at manipulating language, but not at thinking.”Over the past three years, LeCun and his colleagues at Meta have moved H-JEPA theory into practice with open source models V-JEPA and I-JEPA, which learn image and video representations of the world. The personal intelition interface The third force in this agentic, ontology-driven world is the personal interface. This puts people at the center rather than as “users” on the periphery. This is not another app; it is the primary way a person participates in the next era of work and life. Rather than treating AI as something we visit through a chat window or API cal, the personal intelition interface will be always-on, aware of our context, preferences and goals and capable of acting on our behalf across the entire federated economy. Let’s analyze how this is already coming together.In May, Jony Ive sold his AI device company io to OpenAI to accelerate a new AI device category. He noted at the time: “If you make something new, if you innovate, there will be consequences unforeseen, and some will be wonderful, and some will be harmful. While some of the less positive consequences were unintentional, I still feel responsibility. And the manifestation of that is a determination to try and be useful.” That is, getting the personal intelligence device right means more than an attractive venture opportunity. Apple is looking beyond LLMs for on-device solutions that require less processing power and result in less latency when creating AI apps to understand “user intent.” Last year, they created UI-JEPA, an innovation that moves to “on-device analysis” of what the user wants. This strikes directly at the business model of today’s digital economy, where centralized profiling of “users” transforms intent and behavior data into vast revenue streams.Tim Berners-Lee, the inventor of the World Wide Web, recently noted: “The user has been reduced to a consumable product for the advertiser ... there&#x27;s still time to build machines that work for humans, and not the other way around.\" Moving user intent to the device will drive interest in a secure personal data management standard, Solid, that Berners-Lee and his colleagues have been developing since 2022. The standard is ideally suited to pair with new personal AI devices. For instance, Inrupt, Inc., a company founded by Berners-Lee, recently combined Solid with Anthropic’s MCP standard for Agentic Wallets. Personal control is more than a feature of this paradigm; it is the architectural safeguard as systems gain the ability to learn and act continuously.Ultimately, these three forces are moving and converging faster than most realize. Enterprise ontologies provide the nouns and verbs, world-model research supplies durable memory and learning and the personal interface becomes the permissioned point of control. The next software era isn&#x27;t coming. It&#x27;s already here.Brian Mulconrey is SVP at Sureify Labs.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7nS0fhhd8rb4GWzz2aXNYd/2f0ea05e1f3753e57a1ef4b14cc773d0/Thinking_together.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/how-to-watch-the-lg-ces-2026-press-conference-190159378.html",
          "published_at": "Sun, 04 Jan 2026 18:10:35 +0000",
          "title": "How to watch the LG CES 2026 press conference",
          "standfirst": "LG For years, LG has opened CES press day with the first event of the morning. Though arch-rival Samsung getting the jump on its fellow Korean rival by giving its presentation the evening before, LG will be hitting the podium at breakfast time with the theme \"Innovation in Tune with You.\" As with many tech-focused events nowadays, AI is expected to serve as the unifying thread of LG's CES 2026 presentation. That said, LG — much like Apple — has its own take on the acronym, referring to it as \"Affectionate Intelligence.\" The company will share \"its vision for elevating daily life through Affectionate Intelligence — delivering harmonized and seamlessly connected customer experiences.\" The irony, though, is that LG has already shown its cards, thanks to a long string of pre-show press releases offering details about a litany of new products (see below). How to watch LG's CES 2026 presentation The event will stream live from Las Vegas on Monday, January 5 at 11AM ET. You've got a few options for tuning in — watch the livestream on the LG website, the LG Global X channel or the LG Global YouTube channel (embedded below). What to expect Here's what LG has already confirmed it will be showcasing at CES 2026: LG will debut its first Micro RGB TV, a display with a cutting-edge screen technology with multicolor backlights that should one-up mini LED displays. The size options are 100 inches, 86 inches and 75 inches. The company is countering Samsung's Frame TVs with its new LG Gallery TV, arriving in 55- and 65-inch screen sizes. Look for a new LG humanoid home automation robot named CLOiD to take the stage. In the audio realm, the Korean multinational will also introduce a Dolby-powered modular home audio system and a new line of its xboom speakers (developed with musician will.i.am). LG is revamping its ultralight Gram laptop line with a proprietary material it calls Aerominum. Does that leave any surprises for the CES press conference? We'll find out on January 5. Update, December 31 2025, 12:36PM ET: This story has been updated to include more LG CES pre-announcements, and to embed the YouTube stream. Update, January 4 2026, 1:09PM ET: This story has been updated to include information on LG's new laptop line. This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-lg-ces-2026-press-conference-190159378.html?src=rss",
          "content": "LG For years, LG has opened CES press day with the first event of the morning. Though arch-rival Samsung getting the jump on its fellow Korean rival by giving its presentation the evening before, LG will be hitting the podium at breakfast time with the theme \"Innovation in Tune with You.\" As with many tech-focused events nowadays, AI is expected to serve as the unifying thread of LG's CES 2026 presentation. That said, LG — much like Apple — has its own take on the acronym, referring to it as \"Affectionate Intelligence.\" The company will share \"its vision for elevating daily life through Affectionate Intelligence — delivering harmonized and seamlessly connected customer experiences.\" The irony, though, is that LG has already shown its cards, thanks to a long string of pre-show press releases offering details about a litany of new products (see below). How to watch LG's CES 2026 presentation The event will stream live from Las Vegas on Monday, January 5 at 11AM ET. You've got a few options for tuning in — watch the livestream on the LG website, the LG Global X channel or the LG Global YouTube channel (embedded below). What to expect Here's what LG has already confirmed it will be showcasing at CES 2026: LG will debut its first Micro RGB TV, a display with a cutting-edge screen technology with multicolor backlights that should one-up mini LED displays. The size options are 100 inches, 86 inches and 75 inches. The company is countering Samsung's Frame TVs with its new LG Gallery TV, arriving in 55- and 65-inch screen sizes. Look for a new LG humanoid home automation robot named CLOiD to take the stage. In the audio realm, the Korean multinational will also introduce a Dolby-powered modular home audio system and a new line of its xboom speakers (developed with musician will.i.am). LG is revamping its ultralight Gram laptop line with a proprietary material it calls Aerominum. Does that leave any surprises for the CES press conference? We'll find out on January 5. Update, December 31 2025, 12:36PM ET: This story has been updated to include more LG CES pre-announcements, and to embed the YouTube stream. Update, January 4 2026, 1:09PM ET: This story has been updated to include information on LG's new laptop line. This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-lg-ces-2026-press-conference-190159378.html?src=rss",
          "feed_position": 30,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/6f089c60-db4f-11f0-ab9d-5c52fd4922f7"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/how-to-watch-the-intel-ces-2026-launch-event-130040089.html",
          "published_at": "Sun, 04 Jan 2026 13:00:40 +0000",
          "title": "How to watch the Intel CES 2026 launch event",
          "standfirst": "SOPA Images via Getty Images We're just hours away from the start of CES 2026, and with that comes Intel's launch event. The chip giant is expected to provide more details on its AI PC initiative and the new processors powering it: The Core Ultra Series 3 CPUs (aka Panther Lake) are made using an 18A process — that's 18 angstroms, or just under 2nm — and designed for high-end laptops and gaming devices. For Intel, the stakes at CES are higher than ever. In the past 12 months, both NVIDIA and the US government acquired ownership stakes in the company, helping nearly double the stock price by the end of the year. But that's still down over more than 20 percent since 2021, as rivals like TSMC, Qualcomm, AMD and NVIDIA have taken the leadership mantle in chip fabrication and AI hardware. How to watch Intel's launch event Senior VP of Intel's Client Computing Group Jim Johnson will kick off the launch event on Monday, January 5 at 6PM ET. A livestream will be available on the Intel Newsroom YouTube channel, which we'll post here when it's live. What to expect from Intel at CES 2026 As we noted above, Intel has publicly confirmed that it will be highlighting \"the next generation of Intel-powered PCs, edge solution, and the AI experiences enabled by the new Intel Core Ultra Series 3 Processors.\" We'll be keen to hear if the company can address the profitability concerns that have surrounded those next-gen chips since at least last summer, when published reports indicated that yields were still under 50 percent. (In response, Intel told Engadget that it felt \"very good\" about its trajectory on Panther Lake, though it didn't hit the late 2025 release date it had envisioned at the time.) Will we get any updates on that NVIDIA partnership? It's possible. But don't expect to hear anything about Intel possibly fabricating the chips for that rumored new entry-level MacBook Air. If that comes to pass, the announcement will definitely be at a time and place of Apple's choosing. This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-intel-ces-2026-launch-event-130040089.html?src=rss",
          "content": "SOPA Images via Getty Images We're just hours away from the start of CES 2026, and with that comes Intel's launch event. The chip giant is expected to provide more details on its AI PC initiative and the new processors powering it: The Core Ultra Series 3 CPUs (aka Panther Lake) are made using an 18A process — that's 18 angstroms, or just under 2nm — and designed for high-end laptops and gaming devices. For Intel, the stakes at CES are higher than ever. In the past 12 months, both NVIDIA and the US government acquired ownership stakes in the company, helping nearly double the stock price by the end of the year. But that's still down over more than 20 percent since 2021, as rivals like TSMC, Qualcomm, AMD and NVIDIA have taken the leadership mantle in chip fabrication and AI hardware. How to watch Intel's launch event Senior VP of Intel's Client Computing Group Jim Johnson will kick off the launch event on Monday, January 5 at 6PM ET. A livestream will be available on the Intel Newsroom YouTube channel, which we'll post here when it's live. What to expect from Intel at CES 2026 As we noted above, Intel has publicly confirmed that it will be highlighting \"the next generation of Intel-powered PCs, edge solution, and the AI experiences enabled by the new Intel Core Ultra Series 3 Processors.\" We'll be keen to hear if the company can address the profitability concerns that have surrounded those next-gen chips since at least last summer, when published reports indicated that yields were still under 50 percent. (In response, Intel told Engadget that it felt \"very good\" about its trajectory on Panther Lake, though it didn't hit the late 2025 release date it had envisioned at the time.) Will we get any updates on that NVIDIA partnership? It's possible. But don't expect to hear anything about Intel possibly fabricating the chips for that rumored new entry-level MacBook Air. If that comes to pass, the announcement will definitely be at a time and place of Apple's choosing. This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-intel-ces-2026-launch-event-130040089.html?src=rss",
          "feed_position": 32,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/9e1dc860-e813-11f0-bffc-4cb5d6b5aab1"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/why-which-api-do-i-call-is-the-wrong-question-in-the-llm-era",
          "published_at": "Sat, 03 Jan 2026 22:00:00 GMT",
          "title": "Why “which API do I call?” is the wrong question in the LLM era",
          "standfirst": "For decades, we have adapted to software. We learned shell commands, memorized HTTP method names and wired together SDKs. Each interface assumed we would speak its language. In the 1980s, we typed &#x27;grep&#x27;, &#x27;ssh&#x27; and &#x27;ls&#x27; into a shell; by the mid-2000s, we were invoking REST endpoints like GET /users; by the 2010s, we imported SDKs (client.orders.list()) so we didn’t have to think about HTTP. But underlying each of those steps was the same premise: Expose capabilities in a structured form so others can invoke them.But now we are entering the next interface paradigm. Modern LLMs are challenging the notion that a user must choose a function or remember a method signature. Instead of “Which API do I call?” the question becomes: “What outcome am I trying to achieve?” In other words, the interface is shifting from code → to language. In this shift, Model Context Protocol (MCP) emerges as the abstraction that allows models to interpret human intent, discover capabilities and execute workflows, effectively exposing software functions not as programmers know them, but as natural-language requests.MCP is not a hype-term; multiple independent studies identify the architectural shift required for “LLM-consumable” tool invocation. One blog by Akamai engineers describes the transition from traditional APIs to “language-driven integrations” for LLMs. Another academic paper on “AI agentic workflows and enterprise APIs” talks about how enterprise API architecture must evolve to support goal-oriented agents rather than human-driven calls. In short: We are no longer merely designing APIs for code; we are designing capabilities for intent.Why does this matter for enterprises? Because enterprises are drowning in internal systems, integration sprawl and user training costs. Workers struggle not because they don’t have tools, but because they have too many tools, each with its own interface. When natural language becomes the primary interface, the barrier of “which function do I call?” disappears. One recent business blog observed that natural‐language interfaces (NLIs) are enabling self-serve data access for marketers who previously had to wait for analysts to write SQL. When the user just states intent (like “fetch last quarter revenue for region X and flag anomalies”), the system underneath can translate that into calls, orchestration, context memory and deliver results. Natural language becomes not a convenience, but the interfaceTo understand how this evolution works, consider the interface ladder:EraInterfaceWho it was built forCLIShell commandsExpert users typing textAPIWeb or RPC endpointsDevelopers integrating systemsSDKLibrary functionsProgrammers using abstractionsNatural language (MCP)Intent-based requestsHuman + AI agents stating what they wantThrough each step, humans had to “learn the machine’s language.” With MCP, the machine absorbs the human’s language and works out the rest. That’s not just UX improvement, it’s an architectural shift.Under MCP, functions of code are still there: data access, business logic and orchestration. But they’re discovered rather than invoked manually. For example, rather than calling \"billingApi.fetchInvoices(customerId=…),\" you say “Show all invoices for Acme Corp since January and highlight any late payments.” The model resolves the entities, calls the right systems, filters and returns structured insight. The developer’s work shifts from wiring endpoints to defining capability surfaces and guardrails.This shift transforms developer experience and enterprise integration. Teams often struggle to onboard new tools because they require mapping schemas, writing glue code and training users. With a natural-language front, onboarding involves defining business entity names, declaring capabilities and exposing them via the protocol. The human (or AI agent) no longer needs to know parameter names or call order. Studies show that using LLMs as interfaces to APIs can reduce the time and resources required to develop chatbots or tool-invoked workflows.The change also brings productivity benefits. Enterprises that adopt LLM-driven interfaces can turn data access latency (hours/days) into conversation latency (seconds). For instance, if an analyst previously had to export CSVs, run transforms and deploy slides, a language interface allows “Summarize the top five risk factors for churn over the last quarter” and generate narrative + visuals in one go. The human then reviews, adjusts and acts — shifting from data plumber to decision maker. That matters: According to a survey by McKinsey & Company, 63% of organizations using gen AI are already creating text outputs, and more than one-third are generating images or code. (While many are still in the early days of capturing enterprise-wide ROI, the signal is clear: Language as interface unlocks new value.In architectural terms, this means software design must evolve. MCP demands systems that publish capability metadata, support semantic routing, maintain context memory and enforce guardrails. An API design no longer needs to ask “What function will the user call?”, but rather “What intent might the user express?” A recently published framework for improving enterprise APIs for LLMs shows how APIs can be enriched with natural-language-friendly metadata so that agents can select tools dynamically. The implication: Software becomes modular around intent surfaces rather than function surfaces.Language-first systems also bring risks and requirements. Natural language is ambiguous by nature, so enterprises must implement authentication, logging, provenance and access control, just as they did for APIs. Without these guardrails, an agent might call the wrong system, expose data or misinterpret intent. One post on “prompt collapse” calls out the danger: As natural-language UI becomes dominant, software may turn into “a capability accessed through conversation” and the company into “an API with a natural-language frontend”. That transformation is powerful, but only safe if systems are designed for introspection, audit and governance.The shift also has cultural and organizational ramifications. For decades, enterprises hired integration engineers to design APIs and middleware. With MCP-driven models, companies will increasingly hire ontology engineers, capability architects and agent enablement specialists. These roles focus on defining the semantics of business operations, mapping business entities to system capabilities and curating context memory. Because the interface is now human-centric, skills such as domain knowledge, prompt framing, oversight and evaluation become central.What should enterprise leaders do today? First, think of natural language as the interface layer, not as a fancy add-on. Map your business workflows that can safely be invoked via language. Then catalogue the underlying capabilities you already have: data services, analytics and APIs. Then ask: “Are these discoverable? Can they be called via intent?” Finally, pilot an MCP-style layer: Build a small domain (customer support triage) where a user or agent can express outcomes in language, and let systems do the orchestration. Then iterate and scale.Natural language is not just the new front-end. It is becoming the default interface layer for software, replacing CLI, then APIs, then SDKs. MCP is the abstraction that makes this possible. Benefits include faster integration, modular systems, higher productivity and new roles. For those organizations still tethered to calling endpoints manually, the shift will feel like learning a new platform all over again. The question is no longer “which function do I call?” but “what do I want to do?”Dhyey Mavani is accelerating gen AI and computational mathematics.",
          "content": "For decades, we have adapted to software. We learned shell commands, memorized HTTP method names and wired together SDKs. Each interface assumed we would speak its language. In the 1980s, we typed &#x27;grep&#x27;, &#x27;ssh&#x27; and &#x27;ls&#x27; into a shell; by the mid-2000s, we were invoking REST endpoints like GET /users; by the 2010s, we imported SDKs (client.orders.list()) so we didn’t have to think about HTTP. But underlying each of those steps was the same premise: Expose capabilities in a structured form so others can invoke them.But now we are entering the next interface paradigm. Modern LLMs are challenging the notion that a user must choose a function or remember a method signature. Instead of “Which API do I call?” the question becomes: “What outcome am I trying to achieve?” In other words, the interface is shifting from code → to language. In this shift, Model Context Protocol (MCP) emerges as the abstraction that allows models to interpret human intent, discover capabilities and execute workflows, effectively exposing software functions not as programmers know them, but as natural-language requests.MCP is not a hype-term; multiple independent studies identify the architectural shift required for “LLM-consumable” tool invocation. One blog by Akamai engineers describes the transition from traditional APIs to “language-driven integrations” for LLMs. Another academic paper on “AI agentic workflows and enterprise APIs” talks about how enterprise API architecture must evolve to support goal-oriented agents rather than human-driven calls. In short: We are no longer merely designing APIs for code; we are designing capabilities for intent.Why does this matter for enterprises? Because enterprises are drowning in internal systems, integration sprawl and user training costs. Workers struggle not because they don’t have tools, but because they have too many tools, each with its own interface. When natural language becomes the primary interface, the barrier of “which function do I call?” disappears. One recent business blog observed that natural‐language interfaces (NLIs) are enabling self-serve data access for marketers who previously had to wait for analysts to write SQL. When the user just states intent (like “fetch last quarter revenue for region X and flag anomalies”), the system underneath can translate that into calls, orchestration, context memory and deliver results. Natural language becomes not a convenience, but the interfaceTo understand how this evolution works, consider the interface ladder:EraInterfaceWho it was built forCLIShell commandsExpert users typing textAPIWeb or RPC endpointsDevelopers integrating systemsSDKLibrary functionsProgrammers using abstractionsNatural language (MCP)Intent-based requestsHuman + AI agents stating what they wantThrough each step, humans had to “learn the machine’s language.” With MCP, the machine absorbs the human’s language and works out the rest. That’s not just UX improvement, it’s an architectural shift.Under MCP, functions of code are still there: data access, business logic and orchestration. But they’re discovered rather than invoked manually. For example, rather than calling \"billingApi.fetchInvoices(customerId=…),\" you say “Show all invoices for Acme Corp since January and highlight any late payments.” The model resolves the entities, calls the right systems, filters and returns structured insight. The developer’s work shifts from wiring endpoints to defining capability surfaces and guardrails.This shift transforms developer experience and enterprise integration. Teams often struggle to onboard new tools because they require mapping schemas, writing glue code and training users. With a natural-language front, onboarding involves defining business entity names, declaring capabilities and exposing them via the protocol. The human (or AI agent) no longer needs to know parameter names or call order. Studies show that using LLMs as interfaces to APIs can reduce the time and resources required to develop chatbots or tool-invoked workflows.The change also brings productivity benefits. Enterprises that adopt LLM-driven interfaces can turn data access latency (hours/days) into conversation latency (seconds). For instance, if an analyst previously had to export CSVs, run transforms and deploy slides, a language interface allows “Summarize the top five risk factors for churn over the last quarter” and generate narrative + visuals in one go. The human then reviews, adjusts and acts — shifting from data plumber to decision maker. That matters: According to a survey by McKinsey & Company, 63% of organizations using gen AI are already creating text outputs, and more than one-third are generating images or code. (While many are still in the early days of capturing enterprise-wide ROI, the signal is clear: Language as interface unlocks new value.In architectural terms, this means software design must evolve. MCP demands systems that publish capability metadata, support semantic routing, maintain context memory and enforce guardrails. An API design no longer needs to ask “What function will the user call?”, but rather “What intent might the user express?” A recently published framework for improving enterprise APIs for LLMs shows how APIs can be enriched with natural-language-friendly metadata so that agents can select tools dynamically. The implication: Software becomes modular around intent surfaces rather than function surfaces.Language-first systems also bring risks and requirements. Natural language is ambiguous by nature, so enterprises must implement authentication, logging, provenance and access control, just as they did for APIs. Without these guardrails, an agent might call the wrong system, expose data or misinterpret intent. One post on “prompt collapse” calls out the danger: As natural-language UI becomes dominant, software may turn into “a capability accessed through conversation” and the company into “an API with a natural-language frontend”. That transformation is powerful, but only safe if systems are designed for introspection, audit and governance.The shift also has cultural and organizational ramifications. For decades, enterprises hired integration engineers to design APIs and middleware. With MCP-driven models, companies will increasingly hire ontology engineers, capability architects and agent enablement specialists. These roles focus on defining the semantics of business operations, mapping business entities to system capabilities and curating context memory. Because the interface is now human-centric, skills such as domain knowledge, prompt framing, oversight and evaluation become central.What should enterprise leaders do today? First, think of natural language as the interface layer, not as a fancy add-on. Map your business workflows that can safely be invoked via language. Then catalogue the underlying capabilities you already have: data services, analytics and APIs. Then ask: “Are these discoverable? Can they be called via intent?” Finally, pilot an MCP-style layer: Build a small domain (customer support triage) where a user or agent can express outcomes in language, and let systems do the orchestration. Then iterate and scale.Natural language is not just the new front-end. It is becoming the default interface layer for software, replacing CLI, then APIs, then SDKs. MCP is the abstraction that makes this possible. Benefits include faster integration, modular systems, higher productivity and new roles. For those organizations still tethered to calling endpoints manually, the shift will feel like learning a new platform all over again. The question is no longer “which function do I call?” but “what do I want to do?”Dhyey Mavani is accelerating gen AI and computational mathematics.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/P8UEbu2620zRqcW1UFux1/d072a1aa21ec528b2c6b98ca1701e800/MCP.jpeg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-presentation-live-190051072.html",
          "published_at": "Sat, 03 Jan 2026 19:00:37 +0000",
          "title": "How to watch the Hyundai CES 2026 presentation live",
          "standfirst": "A look at Hyundai's Holographic Windshield Display. (Hyundai) CES has long felt like a full-on auto show, but the car-centric energy seems somewhat muted at CES 2026. Sure, the Afeela electric vehicle from the Sony-Honda joint venture is returning to the show floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That said, there's no shortage of in-cabin car tech on display, including Hyundai's Holographic Windshield Display. Indeed, the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES. And we'll also get to see Hyundai's AI Robotics Strategy, which will showcase its new Atlas robot fresh out of the lab. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place on January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. We'll embed the stream here once it's available. What to expect As mentioned above, Hyundai will have its Holographic Windshield Display for viewing. It's essentially a next-gen heads-up display that projects key data from the vehicle's dash on the windshield for less distraction, and without obstructing the driver's view. It's a vertically expandable 18.1-inch large display, and passengers can even watch videos without being visible to the driver. Hyundai Mobis collaborated with German optics specialist Zeiss to develop the \"world's first system to utilize holographic film to transform the entire front windshield into an ultra-large display surface.\" It says it will begin mass production in 2029, so don't expect to see this on the market anytime soon. Beyond automotive, though, we'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. Hyundai said it will also discuss its other tech areas, including electronics and chassis system safety, as well as an AR head-up display, low-power display solutions and EV drive systems.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-presentation-live-190051072.html?src=rss",
          "content": "A look at Hyundai's Holographic Windshield Display. (Hyundai) CES has long felt like a full-on auto show, but the car-centric energy seems somewhat muted at CES 2026. Sure, the Afeela electric vehicle from the Sony-Honda joint venture is returning to the show floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That said, there's no shortage of in-cabin car tech on display, including Hyundai's Holographic Windshield Display. Indeed, the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES. And we'll also get to see Hyundai's AI Robotics Strategy, which will showcase its new Atlas robot fresh out of the lab. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place on January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. We'll embed the stream here once it's available. What to expect As mentioned above, Hyundai will have its Holographic Windshield Display for viewing. It's essentially a next-gen heads-up display that projects key data from the vehicle's dash on the windshield for less distraction, and without obstructing the driver's view. It's a vertically expandable 18.1-inch large display, and passengers can even watch videos without being visible to the driver. Hyundai Mobis collaborated with German optics specialist Zeiss to develop the \"world's first system to utilize holographic film to transform the entire front windshield into an ultra-large display surface.\" It says it will begin mass production in 2029, so don't expect to see this on the market anytime soon. Beyond automotive, though, we'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. Hyundai said it will also discuss its other tech areas, including electronics and chassis system safety, as well as an AR head-up display, low-power display solutions and EV drive systems.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-presentation-live-190051072.html?src=rss",
          "feed_position": 35,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/2a54c910-e5bb-11f0-9fd7-0fe99fe4214d"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/how-to-watch-the-bosch-ces-2026-press-conference-live-on-monday-130020396.html",
          "published_at": "Sat, 03 Jan 2026 12:00:36 +0000",
          "title": "How to watch the Bosch CES 2026 press conference live on Monday",
          "standfirst": "You might recognize Bosch as a home appliance name (thanks to its partnership with Siemens), but the German multinational brand's core business is really about providing the underlying technology and engineering that powers cars, homes and factories around the world. That focus is reflected at CES 2026, where much of what Bosch is unveiling is intended to be licensed to other companies rather than sold as Bosch-branded products on store shelves. Case in point is Bosch's automotive plans at CES. The company is showcasing what it calls \"AI in the car,\" or more specifically, in the cockpit of the car. \"Bosch's AI-powered cockpit makes driving more comfortable, intuitive, and safer for all occupants,\" Bosch board member Markus Heyn said in a press release. We'll get into all the details below, as well as how to tune in to the press conference on Monday. How to watch Bosch's CES 2026 presentation You can livestream the event on Monday, January 5 at 12PM ET via the Bosch press page or YouTube. (We've embedded the stream link below.) What to expect Bosch will be setting up shop in the Central Hall of the Las Vegas Convention Center (booth 16203), where the company will be focusing on its three big themes — mobility, smart home integrations and manufacturing — all of which will include hardware, software and AI solutions. Like many other CES 2026 exhibitors, look for Bosch to emphasize its partnerships with the big dogs of the AI space at the show. For instance, that AI-powered car cockpit mentioned above will feature integrations with both Microsoft and NVIDIA. For instance, Bosch is touting the ability to use voice commands to join a Teams call, while the car's system will automatically activate adaptive cruise control. And it's noting that NVIDIA's software suites will help manage \"real-time sensor processing and vision-language models.\" Here's a glimpse of what the booth will look like: This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-watch-the-bosch-ces-2026-press-conference-live-on-monday-130020396.html?src=rss",
          "content": "You might recognize Bosch as a home appliance name (thanks to its partnership with Siemens), but the German multinational brand's core business is really about providing the underlying technology and engineering that powers cars, homes and factories around the world. That focus is reflected at CES 2026, where much of what Bosch is unveiling is intended to be licensed to other companies rather than sold as Bosch-branded products on store shelves. Case in point is Bosch's automotive plans at CES. The company is showcasing what it calls \"AI in the car,\" or more specifically, in the cockpit of the car. \"Bosch's AI-powered cockpit makes driving more comfortable, intuitive, and safer for all occupants,\" Bosch board member Markus Heyn said in a press release. We'll get into all the details below, as well as how to tune in to the press conference on Monday. How to watch Bosch's CES 2026 presentation You can livestream the event on Monday, January 5 at 12PM ET via the Bosch press page or YouTube. (We've embedded the stream link below.) What to expect Bosch will be setting up shop in the Central Hall of the Las Vegas Convention Center (booth 16203), where the company will be focusing on its three big themes — mobility, smart home integrations and manufacturing — all of which will include hardware, software and AI solutions. Like many other CES 2026 exhibitors, look for Bosch to emphasize its partnerships with the big dogs of the AI space at the show. For instance, that AI-powered car cockpit mentioned above will feature integrations with both Microsoft and NVIDIA. For instance, Bosch is touting the ability to use voice commands to join a Teams call, while the car's system will automatically activate adaptive cruise control. And it's noting that NVIDIA's software suites will help manage \"real-time sensor processing and vision-language models.\" Here's a glimpse of what the booth will look like: This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-watch-the-bosch-ces-2026-press-conference-live-on-monday-130020396.html?src=rss",
          "feed_position": 37
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Loreal-LED-Eye-Mask-7.jpg",
      "popularity_score": 2019.5182677777777
    },
    {
      "id": "cluster_12",
      "coverage": 2,
      "updated_at": "Mon, 05 Jan 2026 00:10:01 -0500",
      "title": "Samsung upgrades its Family Hub refrigerators with AI features, such as voice control to open and close the door and Gemini-powered AI Vision to track inventory (Jennifer Pattison Tuohy/The Verge)",
      "neutral_headline": "Shut the fridge door.",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260105/p1#a260105p1",
          "published_at": "Mon, 05 Jan 2026 00:10:01 -0500",
          "title": "Samsung upgrades its Family Hub refrigerators with AI features, such as voice control to open and close the door and Gemini-powered AI Vision to track inventory (Jennifer Pattison Tuohy/The Verge)",
          "standfirst": "Jennifer Pattison Tuohy / The Verge: Samsung upgrades its Family Hub refrigerators with AI features, such as voice control to open and close the door and Gemini-powered AI Vision to track inventory &mdash; Voice control opening and closing comes to Samsung's Family Hub smart fridges. &hellip; Samsung's latest update &hellip;",
          "content": "Jennifer Pattison Tuohy / The Verge: Samsung upgrades its Family Hub refrigerators with AI features, such as voice control to open and close the door and Gemini-powered AI Vision to track inventory &mdash; Voice control opening and closing comes to Samsung's Family Hub smart fridges. &hellip; Samsung's latest update &hellip;",
          "feed_position": 1,
          "image_url": "http://www.techmeme.com/260105/i1.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/853758/shut-the-fridge-door",
          "published_at": "2026-01-04T22:00:00-05:00",
          "title": "Shut the fridge door!",
          "standfirst": "Samsung's latest update to its Family Hub smart fridge line adds a feature I've always wanted - voice-activated door opening and closing. Using the device's built-in Bixby voice control, you will soon be able to say \"Shut the fridge door,\" or \"Open the door,\" and your machine will obey. According to a press release from [&#8230;]",
          "content": "Family Hub fridges are getting a new hands-free feature. Samsung's latest update to its Family Hub smart fridge line adds a feature I've always wanted - voice-activated door opening and closing. Using the device's built-in Bixby voice control, you will soon be able to say \"Shut the fridge door,\" or \"Open the door,\" and your machine will obey. According to a press release from Samsung at CES 2026 this week, the voice commands will open the door fully, not just a smidge - over 90 degrees. You can also tap the door with the palm or the back of your hand to activate the movement. This could be super helpful when cooking, say when your hands are dirty and you want to get the milk out. It's also a … Read the full story at The Verge.",
          "feed_position": 3
        }
      ],
      "featured_image": "http://www.techmeme.com/260105/i1.jpg",
      "popularity_score": 2017.6852122222222
    },
    {
      "id": "cluster_0",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "Film Technica: Our top picks for the best films of 2025",
      "neutral_headline": "Film Technica: Our top picks for the best films of 2025",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/film-technica-our-top-picks-for-the-best-films-of-2025/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "Film Technica: Our top picks for the best films of 2025",
          "standfirst": "",
          "content": "",
          "feed_position": 0
        }
      ],
      "popularity_score": 352.99980027777775
    },
    {
      "id": "cluster_1",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "No, Grok can’t really “apologize” for posting non-consensual sexual images",
      "neutral_headline": "No, Grok can’t really “apologize” for posting non-consensual sexual images",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/no-grok-cant-really-apologize-for-posting-non-consensual-sexual-images/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "No, Grok can’t really “apologize” for posting non-consensual sexual images",
          "standfirst": "",
          "content": "",
          "feed_position": 1
        }
      ],
      "popularity_score": 342.99980027777775
    },
    {
      "id": "cluster_3",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "OpenAI reorganizes some teams to build audio-based AI hardware products",
      "neutral_headline": "OpenAI reorganizes some teams to build audio-based AI hardware products",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/openai-plans-new-voice-model-in-early-2026-audio-based-hardware-in-2027/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "OpenAI reorganizes some teams to build audio-based AI hardware products",
          "standfirst": "",
          "content": "",
          "feed_position": 3
        }
      ],
      "popularity_score": 337.99980027777775
    },
    {
      "id": "cluster_2",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "Healthy 18-year-old welder nearly died of anthrax—the 9th such puzzling case",
      "neutral_headline": "Healthy 18-year-old welder nearly died of anthrax—the 9th such puzzling case",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/anthrax-nearly-kills-healthy-18-year-old-welder-amid-puzzling-pattern/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "Healthy 18-year-old welder nearly died of anthrax—the 9th such puzzling case",
          "standfirst": "",
          "content": "",
          "feed_position": 2
        }
      ],
      "popularity_score": 332.99980027777775
    },
    {
      "id": "cluster_4",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "Researchers spot Saturn-sized planet in the “Einstein desert”",
      "neutral_headline": "Researchers spot Saturn-sized planet in the “Einstein desert”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/researchers-spot-saturn-sized-planet-in-the-einstein-desert/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "Researchers spot Saturn-sized planet in the “Einstein desert”",
          "standfirst": "",
          "content": "",
          "feed_position": 4
        }
      ],
      "popularity_score": 312.99980027777775
    },
    {
      "id": "cluster_5",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "SpaceX begins “significant reconfiguration” of Starlink satellite constellation",
      "neutral_headline": "SpaceX begins “significant reconfiguration” of Starlink satellite constellation",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/spacex-begins-significant-reconfiguration-of-starlink-satellite-constellation/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "SpaceX begins “significant reconfiguration” of Starlink satellite constellation",
          "standfirst": "",
          "content": "",
          "feed_position": 5
        }
      ],
      "popularity_score": 310.99980027777775
    },
    {
      "id": "cluster_7",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "xAI silent after Grok sexualized images of kids; dril mocks Grok’s “apology”",
      "neutral_headline": "XAI silent after Grok sexualized images of kids; dril mocks Grok’s “apology”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/xai-silent-after-grok-sexualized-images-of-kids-dril-mocks-groks-apology/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "xAI silent after Grok sexualized images of kids; dril mocks Grok’s “apology”",
          "standfirst": "",
          "content": "",
          "feed_position": 7
        }
      ],
      "popularity_score": 297.99980027777775
    },
    {
      "id": "cluster_6",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "Final reminder: Donate to win swag in our annual Charity Drive sweepstakes",
      "neutral_headline": "Final reminder: Donate to win swag in our annual Charity Drive sweepstakes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/final-reminder-donate-to-win-swag-in-our-annual-charity-drive-sweepstakes-4/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "Final reminder: Donate to win swag in our annual Charity Drive sweepstakes",
          "standfirst": "",
          "content": "",
          "feed_position": 6
        }
      ],
      "popularity_score": 292.99980027777775
    },
    {
      "id": "cluster_8",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "Tesla sales fell by 9 percent in 2025, its second yearly decline",
      "neutral_headline": "Tesla sales fell by 9 percent in 2025, its second yearly decline",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/tesla-sales-fell-by-9-percent-in-2025-its-second-yearly-decline/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "Tesla sales fell by 9 percent in 2025, its second yearly decline",
          "standfirst": "",
          "content": "",
          "feed_position": 8
        }
      ],
      "popularity_score": 278.99980027777775
    },
    {
      "id": "cluster_9",
      "coverage": 1,
      "updated_at": "2026-01-05T07:28:53.517Z",
      "title": "After half a decade, the Russian space station segment stopped leaking",
      "neutral_headline": "After half a decade, the Russian space station segment stopped leaking",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/finally-some-good-news-for-russia-the-space-station-is-no-longer-leaking/",
          "published_at": "2026-01-05T07:28:53.517Z",
          "title": "After half a decade, the Russian space station segment stopped leaking",
          "standfirst": "",
          "content": "",
          "feed_position": 9
        }
      ],
      "popularity_score": 270.99980027777775
    }
  ]
}