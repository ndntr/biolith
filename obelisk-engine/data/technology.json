{
  "updated_at": "2026-01-16T19:19:54.453Z",
  "clusters": [
    {
      "id": "cluster_0",
      "coverage": 2,
      "updated_at": "Fri, 16 Jan 2026 19:14:51 +0000",
      "title": "The mother of one of Elon Musk's children is suing xAI over nonconsensual deepfake images",
      "neutral_headline": "Audible deal: Three months of access is only $3 right now",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/the-mother-of-one-of-elon-musks-children-is-suing-xai-over-nonconsensual-deepfake-images-191451979.html",
          "published_at": "Fri, 16 Jan 2026 19:14:51 +0000",
          "title": "The mother of one of Elon Musk's children is suing xAI over nonconsensual deepfake images",
          "standfirst": "Although X removed Grok’s ability to create nonconsensual digitally undressed images on the social platform, the standalone Grok app is another story. It reportedly continues to produce “nudified” deepfakes of real people. And now, Ashley St. Clair, a conservative political strategist and mother of one of Elon Musk’s 14 children, has sued xAI for nonconsensual sexualized images of her that Grok allegedly produced.In the court filing, St. Clair accused xAI’s Grok chatbot of creating and disseminating deepfakes of her “as a child stripped down to a string bikini, and as an adult in sexually explicit poses, covered in semen, or wearing only bikini floss.” In some cases, the chatbot allegedly produced bikini-clad deepfakes of St. Clair based on a photo of her as a 14-year-old. “People took pictures of me as a child and undressed me. There’s one where they undressed me and bent me over, and in the background is my child’s backpack that he’s wearing right now,” she said.“I am also seeing images where they add bruises to women, beat them up, tie them up, mutilated,” St. Clair told The Guardian. “These sickos used to have to go to the dark depths of the internet, and now it is on a mainstream social media app.”St. Clair said that, after she reported the images to X, the social platform replied that the content didn’t violate any policies. In addition, she claims that X left the images posted for up to seven days after she reported them. St. Clair said xAI then retaliated against her by creating more digitally undressed deepfakes of her, therefore “making [St. Clair] the laughingstock of the social media platform.”She accused the company of then revoking her X Premium subscription, verification checkmark, and ability to monetize content on the platform. “xAI further banned [her] from repurchasing Premium,” St. Clair’s court filing states.On Wednesday, X said it changed its policies so that Grok would no longer generate sexualized images of children or nonconsensual nudity “in those jurisdictions where it’s illegal.” However, the standalone Grok app reportedly continues to undress and sexualize photos when prompted to do so.Neither Apple nor Google has removed the Grok app despite explicit policy violations.Anna Moneymaker via Getty ImagesApple and Google have thus far done, well, absolutely nothing. Despite the multi-week outrage over the deepfakes, neither company removed the X or Grok apps from their app stores. Both the App Store and Play Store have policies that explicitly prohibit apps that generate such content.Neither Apple nor Google has responded to multiple requests for comment from Engadget. That includes a follow-up email sent on Friday, regarding the Grok app continuing to “nudify” photos of real women and other people.While Apple and Google fail to act, many governments have done the opposite. On Monday, Malaysia and Indonesia banned Grok. The same day, UK regulator Ofcom opened a formal investigation into X. California opened one on Wednesday. The US Senate even passed the Defiance Act for a second time in the wake of the blowback. “If you are a woman, you can’t post a picture, and you can’t speak, or you risk this abuse,” St. Clair told The Guardian. “It’s dangerous, and I believe this is by design. You are supposed to feed AI humanity and thoughts, and when you are doing things that particularly impact women, and they don’t want to participate in it because they are being targeted, it means the AI is inherently going to be biased.”Speaking about Musk and his team, she added that “these people believe they are above the law, because they are. They don’t think they are going to get in trouble, they think they have no consequences.”This article originally appeared on Engadget at https://www.engadget.com/ai/the-mother-of-one-of-elon-musks-children-is-suing-xai-over-nonconsensual-deepfake-images-191451979.html?src=rss",
          "content": "Although X removed Grok’s ability to create nonconsensual digitally undressed images on the social platform, the standalone Grok app is another story. It reportedly continues to produce “nudified” deepfakes of real people. And now, Ashley St. Clair, a conservative political strategist and mother of one of Elon Musk’s 14 children, has sued xAI for nonconsensual sexualized images of her that Grok allegedly produced.In the court filing, St. Clair accused xAI’s Grok chatbot of creating and disseminating deepfakes of her “as a child stripped down to a string bikini, and as an adult in sexually explicit poses, covered in semen, or wearing only bikini floss.” In some cases, the chatbot allegedly produced bikini-clad deepfakes of St. Clair based on a photo of her as a 14-year-old. “People took pictures of me as a child and undressed me. There’s one where they undressed me and bent me over, and in the background is my child’s backpack that he’s wearing right now,” she said.“I am also seeing images where they add bruises to women, beat them up, tie them up, mutilated,” St. Clair told The Guardian. “These sickos used to have to go to the dark depths of the internet, and now it is on a mainstream social media app.”St. Clair said that, after she reported the images to X, the social platform replied that the content didn’t violate any policies. In addition, she claims that X left the images posted for up to seven days after she reported them. St. Clair said xAI then retaliated against her by creating more digitally undressed deepfakes of her, therefore “making [St. Clair] the laughingstock of the social media platform.”She accused the company of then revoking her X Premium subscription, verification checkmark, and ability to monetize content on the platform. “xAI further banned [her] from repurchasing Premium,” St. Clair’s court filing states.On Wednesday, X said it changed its policies so that Grok would no longer generate sexualized images of children or nonconsensual nudity “in those jurisdictions where it’s illegal.” However, the standalone Grok app reportedly continues to undress and sexualize photos when prompted to do so.Neither Apple nor Google has removed the Grok app despite explicit policy violations.Anna Moneymaker via Getty ImagesApple and Google have thus far done, well, absolutely nothing. Despite the multi-week outrage over the deepfakes, neither company removed the X or Grok apps from their app stores. Both the App Store and Play Store have policies that explicitly prohibit apps that generate such content.Neither Apple nor Google has responded to multiple requests for comment from Engadget. That includes a follow-up email sent on Friday, regarding the Grok app continuing to “nudify” photos of real women and other people.While Apple and Google fail to act, many governments have done the opposite. On Monday, Malaysia and Indonesia banned Grok. The same day, UK regulator Ofcom opened a formal investigation into X. California opened one on Wednesday. The US Senate even passed the Defiance Act for a second time in the wake of the blowback. “If you are a woman, you can’t post a picture, and you can’t speak, or you risk this abuse,” St. Clair told The Guardian. “It’s dangerous, and I believe this is by design. You are supposed to feed AI humanity and thoughts, and when you are doing things that particularly impact women, and they don’t want to participate in it because they are being targeted, it means the AI is inherently going to be biased.”Speaking about Musk and his team, she added that “these people believe they are above the law, because they are. They don’t think they are going to get in trouble, they think they have no consequences.”This article originally appeared on Engadget at https://www.engadget.com/ai/the-mother-of-one-of-elon-musks-children-is-suing-xai-over-nonconsensual-deepfake-images-191451979.html?src=rss",
          "feed_position": 0,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2023-09/8424f5a0-4f40-11ee-acbb-bab134a1b1db"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/legos-latest-educational-kit-seeks-to-teach-ai-as-part-of-computer-science-not-to-build-a-chatbot-184636741.html",
          "published_at": "Fri, 16 Jan 2026 18:46:36 +0000",
          "title": "Lego's latest educational kit seeks to teach AI as part of computer science, not to build a chatbot",
          "standfirst": "Last week at CES, Lego introduced its new Smart Play system, with a tech-packed Smart Brick that can recognize and interact with sets and minifigures. It was unexpected and delightful to see Lego come up with a way to modernize its bricks without the need for apps, screens or AI. So I was a little surprised this week when the Lego Education group announced its latest initiative is the Computer Science and AI Learning Solution. After all, generative AI feels like the antithesis of Lego’s creative values. But Andrew Silwinski, Lego Education’s head of product experience, was quick to defend Lego’s approach, noting that being fluent in the tools behind AI is not about generating sloppy images or music and more about expanding what it means by teaching computer science.“I think most people should probably know that we started working on this before ChatGPT [got big],” Silwinski told Engadget earlier this week. “Some of the ideas that underline AI are really powerful foundational ideas, regardless of the current frontier model that's out this week. Helping children understand probability and statistics, data quality, algorithmic bias, sensors, machine perception. These are really foundational core ideas that go back to the 1970s.” To that end, Lego Education designed courses for grades K-2, 3-5 and 6-8 that incorporate Lego bricks, additional hardware and lessons tailored to introducing the fundamentals of AI as an extension of existing computer science education. The kits are designed for four students to work together, with teacher oversight. Much of this all comes from learnings Lego found in a study it commissioned showing that teachers often find they don’t have the right resources to teach these subjects. The study showed that half of teachers globally say “current resources leave students bored” while nearly half say “computer science isn’t relatable and doesn’t connect to students’ interests or day to day.” Given kids’ familiarity with Lego and the multiple decades of experience Lego Education has in putting courses like this together, it seems like a logical step to push in this direction. In Lego’s materials about the new courses, AI is far from the only subject covered. Coding, looping code, triggering events and sequences, if/then conditionals and more are all on display through the combination of Lego-built models and other hardware to motorize it. It feels more like a computer science course that also introduces concepts of AI rather than something with an end goal of having kids build a chatbot.In fact, Lego set up a number of “red lines” in terms of how it would introduce AI. “No data can ever go across the internet to us or any other third party,” Silwinski said. “And that's a really hard bar if you know anything about AI.” So instead of going to the cloud, everything had to be able to do local inference on, as Silwinski said, “the 10-year-old Chromebooks you’ll see in classrooms.” He added that “kids can train their own machine learning models, and all of that is happening locally in the classroom, and none of that data ever leaves the student's device.”Lego also says that its lessons never anthropomorphize AI, one of the things that is so common in consumer-facing AI tools like ChatGPT, Gemini and many more. “One of the things we're seeing a lot of with generative AI tools is children have a tendency to see them as somehow human or almost magical. A lot of it's because of the conversational interface, it abstracts all the mechanics away from the child.” Lego also recognized that it had to build a course that’ll work regardless of a teacher’s fluency in such subjects. So a big part of developing the course was making sure that teachers had the tools they needed to be on top of whatever lessons they’re working on. “When we design and we test the products, we're not the ones testing in the classroom,” Silwinski said. “We give it to a teacher and we provide all of the lesson materials, all of the training, all of the notes, all the presentation materials, everything that they need to be able to teach the lesson.” Lego also took into account the fact that some schools might introduce its students to these things starting in Kindergarten, whereas others might skip to the grade 3-5 or 6-8 sets. To alleviate any bumps in the courses for students or teachers, Lego Education works with school districts and individual schools to make sure there’s an on-ramp for those starting from different places in their fluency.While the idea of “teaching AI” seemed out of character for Lego initially, the approach it’s taking here actually reminds me a bit of Smart Play. With Smart Play, the technology is essentially invisible — kids can just open up a set, start building, and get all the benefits of the new system without having to hook up to an app or a screen. In the same vein, Silwinski said that a lot of the work you can do with the Computer Science and AI kit doesn’t need a screen, particularly the lessons designed for younger kids. And the sets themselves have a mode that acts similar to a mesh, where you connect numerous motors and sensors together to build “incredibly complex interactions and behaviors” without even needing a computer.For educators interested in checking out this latest course, Lego has single kits up for pre-order starting at $339.95; they’ll start shipping in April. That’s the pricing for the K-2 sets, the 3-5 and 6-8 sets are $429.95 and $529.95, respectively. A single kit covers four students. Lego is also selling bundles with six kits, and school districts can also request a quote for bigger orders. This article originally appeared on Engadget at https://www.engadget.com/ai/legos-latest-educational-kit-seeks-to-teach-ai-as-part-of-computer-science-not-to-build-a-chatbot-184636741.html?src=rss",
          "content": "Last week at CES, Lego introduced its new Smart Play system, with a tech-packed Smart Brick that can recognize and interact with sets and minifigures. It was unexpected and delightful to see Lego come up with a way to modernize its bricks without the need for apps, screens or AI. So I was a little surprised this week when the Lego Education group announced its latest initiative is the Computer Science and AI Learning Solution. After all, generative AI feels like the antithesis of Lego’s creative values. But Andrew Silwinski, Lego Education’s head of product experience, was quick to defend Lego’s approach, noting that being fluent in the tools behind AI is not about generating sloppy images or music and more about expanding what it means by teaching computer science.“I think most people should probably know that we started working on this before ChatGPT [got big],” Silwinski told Engadget earlier this week. “Some of the ideas that underline AI are really powerful foundational ideas, regardless of the current frontier model that's out this week. Helping children understand probability and statistics, data quality, algorithmic bias, sensors, machine perception. These are really foundational core ideas that go back to the 1970s.” To that end, Lego Education designed courses for grades K-2, 3-5 and 6-8 that incorporate Lego bricks, additional hardware and lessons tailored to introducing the fundamentals of AI as an extension of existing computer science education. The kits are designed for four students to work together, with teacher oversight. Much of this all comes from learnings Lego found in a study it commissioned showing that teachers often find they don’t have the right resources to teach these subjects. The study showed that half of teachers globally say “current resources leave students bored” while nearly half say “computer science isn’t relatable and doesn’t connect to students’ interests or day to day.” Given kids’ familiarity with Lego and the multiple decades of experience Lego Education has in putting courses like this together, it seems like a logical step to push in this direction. In Lego’s materials about the new courses, AI is far from the only subject covered. Coding, looping code, triggering events and sequences, if/then conditionals and more are all on display through the combination of Lego-built models and other hardware to motorize it. It feels more like a computer science course that also introduces concepts of AI rather than something with an end goal of having kids build a chatbot.In fact, Lego set up a number of “red lines” in terms of how it would introduce AI. “No data can ever go across the internet to us or any other third party,” Silwinski said. “And that's a really hard bar if you know anything about AI.” So instead of going to the cloud, everything had to be able to do local inference on, as Silwinski said, “the 10-year-old Chromebooks you’ll see in classrooms.” He added that “kids can train their own machine learning models, and all of that is happening locally in the classroom, and none of that data ever leaves the student's device.”Lego also says that its lessons never anthropomorphize AI, one of the things that is so common in consumer-facing AI tools like ChatGPT, Gemini and many more. “One of the things we're seeing a lot of with generative AI tools is children have a tendency to see them as somehow human or almost magical. A lot of it's because of the conversational interface, it abstracts all the mechanics away from the child.” Lego also recognized that it had to build a course that’ll work regardless of a teacher’s fluency in such subjects. So a big part of developing the course was making sure that teachers had the tools they needed to be on top of whatever lessons they’re working on. “When we design and we test the products, we're not the ones testing in the classroom,” Silwinski said. “We give it to a teacher and we provide all of the lesson materials, all of the training, all of the notes, all the presentation materials, everything that they need to be able to teach the lesson.” Lego also took into account the fact that some schools might introduce its students to these things starting in Kindergarten, whereas others might skip to the grade 3-5 or 6-8 sets. To alleviate any bumps in the courses for students or teachers, Lego Education works with school districts and individual schools to make sure there’s an on-ramp for those starting from different places in their fluency.While the idea of “teaching AI” seemed out of character for Lego initially, the approach it’s taking here actually reminds me a bit of Smart Play. With Smart Play, the technology is essentially invisible — kids can just open up a set, start building, and get all the benefits of the new system without having to hook up to an app or a screen. In the same vein, Silwinski said that a lot of the work you can do with the Computer Science and AI kit doesn’t need a screen, particularly the lessons designed for younger kids. And the sets themselves have a mode that acts similar to a mesh, where you connect numerous motors and sensors together to build “incredibly complex interactions and behaviors” without even needing a computer.For educators interested in checking out this latest course, Lego has single kits up for pre-order starting at $339.95; they’ll start shipping in April. That’s the pricing for the K-2 sets, the 3-5 and 6-8 sets are $429.95 and $529.95, respectively. A single kit covers four students. Lego is also selling bundles with six kits, and school districts can also request a quote for bigger orders. This article originally appeared on Engadget at https://www.engadget.com/ai/legos-latest-educational-kit-seeks-to-teach-ai-as-part-of-computer-science-not-to-build-a-chatbot-184636741.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/audible-deal-three-months-of-access-is-only-3-right-now-193859977.html",
          "published_at": "Fri, 16 Jan 2026 16:46:26 +0000",
          "title": "Audible deal: Three months of access is only $3 right now",
          "standfirst": "One way to read more in the new year is to incorporate audiobooks as part of your reading habit. Audible is having a sale right now that makes that easier and cheaper to do: you can get three months of access for only $1 per month, or a total of $3. The promotion runs through January 21. An Audible subscription grants one audiobook per month to keep. This can be selected from a massive catalog of new releases and bestsellers. The collection here has just about everything. However, it's easy to plow through a single book in a month. Users also get streaming access to thousands of curated titles. Think of it like Netflix for audiobooks. The catalog is limited, but it gets the job done in a pinch. Subscribers do get access to all Audible original content and they will receive discounts on purchasing audiobooks outright. In other words, it's a neat little service and well worth a buck. The regular price is $15, so make sure to cancel at the end of that three months if you aren't enjoying the platform. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/audible-deal-three-months-of-access-is-only-3-right-now-193859977.html?src=rss",
          "content": "One way to read more in the new year is to incorporate audiobooks as part of your reading habit. Audible is having a sale right now that makes that easier and cheaper to do: you can get three months of access for only $1 per month, or a total of $3. The promotion runs through January 21. An Audible subscription grants one audiobook per month to keep. This can be selected from a massive catalog of new releases and bestsellers. The collection here has just about everything. However, it's easy to plow through a single book in a month. Users also get streaming access to thousands of curated titles. Think of it like Netflix for audiobooks. The catalog is limited, but it gets the job done in a pinch. Subscribers do get access to all Audible original content and they will receive discounts on purchasing audiobooks outright. In other words, it's a neat little service and well worth a buck. The regular price is $15, so make sure to cancel at the end of that three months if you aren't enjoying the platform. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/audible-deal-three-months-of-access-is-only-3-right-now-193859977.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-100-off-apples-mac-mini-m4-desktop-141615926.html",
          "published_at": "Fri, 16 Jan 2026 14:45:36 +0000",
          "title": "Get $100 off Apple's Mac mini M4 desktop",
          "standfirst": "The holiday season is fully in the rear view mirror and real life is here to stay. But that doesn't mean the time for gifts is over — especially ones for yourself. You can still take advantage of great January sales on some awesome tech products. Take the Apple Mac mini M4, which is down to $500 from $599. The 17 percent discount gives you 16GB of RAM and 256GB of SSD for only about $20 more than the computer's Black Friday sale. Its beefier models are also on sale: opting for 512GB of SSD will cost you $690, down from $799, while also upping your RAM to 24GB is available for $890, dropping from $999. We gave the Apple Mac mini M4 a 90 in our review thanks in large part to its powerful chip. The M4 works very fast despite being in such a small device. It also offers front-facing headphone and USB-C ports. You can further upgrade to the Apple M4 Pro chip for $1,270, down from $1,399 — a nine percent discount. The Pro model also has Thunderbolt 5 support. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-100-off-apples-mac-mini-m4-desktop-141615926.html?src=rss",
          "content": "The holiday season is fully in the rear view mirror and real life is here to stay. But that doesn't mean the time for gifts is over — especially ones for yourself. You can still take advantage of great January sales on some awesome tech products. Take the Apple Mac mini M4, which is down to $500 from $599. The 17 percent discount gives you 16GB of RAM and 256GB of SSD for only about $20 more than the computer's Black Friday sale. Its beefier models are also on sale: opting for 512GB of SSD will cost you $690, down from $799, while also upping your RAM to 24GB is available for $890, dropping from $999. We gave the Apple Mac mini M4 a 90 in our review thanks in large part to its powerful chip. The M4 works very fast despite being in such a small device. It also offers front-facing headphone and USB-C ports. You can further upgrade to the Apple M4 Pro chip for $1,270, down from $1,399 — a nine percent discount. The Pro model also has Thunderbolt 5 support. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-100-off-apples-mac-mini-m4-desktop-141615926.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-is-on-sale-for-32-percent-off-214707127.html",
          "published_at": "Fri, 16 Jan 2026 14:15:36 +0000",
          "title": "Our favorite 3-in-1 wireless charger is on sale for 32 percent off",
          "standfirst": "Now that the winter holidays are well and truly past, now's the perfect time to take stock of your tech setup. If you were gifted (or gifted yourself) some new gear in December, make sure that you've got the proper accessories to keep that gear performing at its best. If a new way to power all those batteries would be a benefit, Amazon's currently running a discount on an excellent wireless charging pad. The UGREEN MagFlow Qi2 3-in-1 Charger Station 25W is on sale for $95. That's only a little bit above the lowest price we've ever seen for the product (which was $90), and it's still a 32 percent discount off its usual cost. This is our top pick for a 3-in-1 charging pad thanks to its versatility. The UGREEN can work equally well as a permanent fixture in your home or act as a portable charging station. It boasts a foldable design and has smart little design details to keep it feeling like a premium product. The Qi2 25W charging works across a range of iPhone models and accessories, such as AirPods. There's also a dedicated part of the pad's design for an Apple Watch, which uses a proprietary charging standard, to power up too. Just note that you'll need a newer model of phone and the latest iOS 26 in order to take full advantage of the 25W charging capability. The wireless pad also comes with both a charging plug and a cable. We felt this UGREEN model was a great value at $140, so being able to snag one for a third of the usual price is an even better deal. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-is-on-sale-for-32-percent-off-214707127.html?src=rss",
          "content": "Now that the winter holidays are well and truly past, now's the perfect time to take stock of your tech setup. If you were gifted (or gifted yourself) some new gear in December, make sure that you've got the proper accessories to keep that gear performing at its best. If a new way to power all those batteries would be a benefit, Amazon's currently running a discount on an excellent wireless charging pad. The UGREEN MagFlow Qi2 3-in-1 Charger Station 25W is on sale for $95. That's only a little bit above the lowest price we've ever seen for the product (which was $90), and it's still a 32 percent discount off its usual cost. This is our top pick for a 3-in-1 charging pad thanks to its versatility. The UGREEN can work equally well as a permanent fixture in your home or act as a portable charging station. It boasts a foldable design and has smart little design details to keep it feeling like a premium product. The Qi2 25W charging works across a range of iPhone models and accessories, such as AirPods. There's also a dedicated part of the pad's design for an Apple Watch, which uses a proprietary charging standard, to power up too. Just note that you'll need a newer model of phone and the latest iOS 26 in order to take full advantage of the 25W charging capability. The wireless pad also comes with both a charging plug and a cable. We felt this UGREEN model was a great value at $140, so being able to snag one for a third of the usual price is an even better deal. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-is-on-sale-for-32-percent-off-214707127.html?src=rss",
          "feed_position": 10
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
          "published_at": "Fri, 16 Jan 2026 14:01:00 GMT",
          "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews",
          "standfirst": "Alfred Wahlforss was running out of options. His startup, Listen Labs, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s $100 million offers seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a billboard in San Francisco displaying what looked like gibberish: five strings of random numbers.The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.That unconventional approach has now attracted $69 million in Series B funding, led by Ribbit Capital with participation from Evantic and existing investors Sequoia Capital, Conviction, and Pear VC. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.\"When you obsess over customers, everything else follows,\" Wahlforss said in an interview with VentureBeat. \"Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.\"Why traditional market research is broken, and what Listen Labs is building to fix itListen&#x27;s AI researcher finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.Wahlforss explained the limitation of existing approaches: \"Essentially surveys give you false precision because people end up answering the same question... You can&#x27;t get the outliers. People are actually not honest on surveys.\" The alternative, one-on-one human interviews, \"gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they&#x27;re talking about. And the problem is you can&#x27;t scale that.\"The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.What distinguishes Listen&#x27;s approach is its use of open-ended video conversations rather than multiple-choice forms. \"In a survey, you can kind of guess what you should answer, and you have four options,\" Wahlforss said. \"Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.\"The dirty secret of the $140 billion market research industry: rampant fraudListen finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called \"one of the most shocking things that we&#x27;ve learned when we entered this industry\"—rampant fraud.\"Essentially, there&#x27;s a financial transaction involved, which means there will be bad players,\" he explained. \"We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.\"The company built what it calls a \"quality guard\" that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: \"People talk three times more. They&#x27;re much more honest when they talk about sensitive topics like politics and mental health.\"Emeritus, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. \"We did not have to replace any responses because of fraud or gibberish information,\" said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better productsThe speed advantage has proven central to Listen&#x27;s pitch. Traditional customer research at Microsoft could take four to six weeks to generate insights. \"By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,\" said Romani Patel, Senior Research Manager at Microsoft.With Listen, Microsoft can now get insights in days, and in many cases, within hours.The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. \"We wanted users to share how Copilot is empowering them to bring their best self forward,\" Patel said, \"and we were able to collect those user video stories within a day.\" Traditionally, that kind of work would have taken six to eight weeks.Simple Modern, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. \"We went from &#x27;Should we even have this product?&#x27; to &#x27;How should we launch it?&#x27;\" said Chris Hoyle, the company&#x27;s Chief Marketing Officer.Chubbies, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. \"There&#x27;s school, sports, dinner, and homework,\" explained Lauren Neville, Director of Insights and Innovation. \"I had to find a way to hear from them that fit into their schedules.\"The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI \"through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.\" The redesigned product became \"a blockbuster hit.\"The Jevons paradox explains why cheaper research creates more demand, not lessListen Labs is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly $140 billion annually, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.\"There are very much existing budget lines that we are replacing,\" Wahlforss said. \"Why we&#x27;re replacing them is that one, they&#x27;re super costly. Two, they&#x27;re kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.\"But the more intriguing dynamic may be that AI-powered research doesn&#x27;t just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.\"What I&#x27;ve noticed is that as something gets cheaper, you don&#x27;t need less of it. You want more of it,\" Wahlforss explained. \"There&#x27;s infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren&#x27;t researchers before can now do that as part of their job.\"Inside the elite engineering team that built Listen Labs before they had a working toiletListen Labs traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. \"We built this consumer app that got 20,000 downloads in one day,\" Wahlforss recalled. \"We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.\"The founding team brings an unusual pedigree. Wahlforss&#x27;s co-founder \"was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.\" The company claims that 30% of its engineering team are medalists from the International Olympiad in Informatics — the same competition that produced the founders of Cognition, the AI coding startup.The Berghain billboard stunt generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.\"We had to do these things because some of our, like early employees, joined the company before we had a working toilet,\" he said. \"But now we fixed that situation.\"The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.Synthetic customers and automated decisions: what Listen Labs is building nextWahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building \"the ability to simulate your customers, so you can take all of those interviews we&#x27;ve done, and then extrapolate based on that and create synthetic users or simulated user voices.\"Beyond simulation, Listen aims to enable automated action based on research findings. \"Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?\"Wahlforss acknowledged the ethical implications. \"Obviously, as you said, there&#x27;s kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.\"The company already handles sensitive data with care. \"We don&#x27;t train on any of the data,\" Wahlforss said. \"We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.\"How AI could reshape the future of product developmentPerhaps the most provocative implication of Listen&#x27;s model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.\"They&#x27;re based in Australia, so they&#x27;re coding during the day, and then in their night, they&#x27;re releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.\"The vision extends Y Combinator&#x27;s famous dictum — \"write code, talk to users\" — into an automated cycle. \"Write code is now getting automated. And I think like talk to users will be as well, and you&#x27;ll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.\"Whether that vision materializes depends on factors beyond Listen&#x27;s control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A 2024 MIT study found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.\"I&#x27;m constantly have to emphasize like, let&#x27;s make sure the quality is there and the details are right,\" he said.But the company&#x27;s growth suggests appetite for the experiment. Microsoft&#x27;s Patel said Listen has \"removed the drudgery of research and brought the fun and joy back into my work.\" Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.\"It&#x27;s a total game changer,\" said Ali Romero, Sling Money&#x27;s marketing manager.Wahlforss has a different phrase for what he&#x27;s building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.One of them: \"Slow is fake.\"It&#x27;s an aggressive claim for an industry built on methodological caution. But Listen Labs is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.",
          "content": "Alfred Wahlforss was running out of options. His startup, Listen Labs, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s $100 million offers seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a billboard in San Francisco displaying what looked like gibberish: five strings of random numbers.The numbers were actually AI tokens. Decoded, they led to a coding challenge: build an algorithm to act as a digital bouncer at Berghain, the Berlin nightclub famous for rejecting nearly everyone at the door. Within days, thousands attempted the puzzle. 430 cracked it. Some got hired. The winner flew to Berlin, all expenses paid.That unconventional approach has now attracted $69 million in Series B funding, led by Ribbit Capital with participation from Evantic and existing investors Sequoia Capital, Conviction, and Pear VC. The round values Listen Labs at $500 million and brings its total capital to $100 million. In nine months since launch, the company has grown annualized revenue by 15x to eight figures and conducted over one million AI-powered interviews.\"When you obsess over customers, everything else follows,\" Wahlforss said in an interview with VentureBeat. \"Teams that use Listen bring the customer into every decision, from marketing to product, and when the customer is delighted, everyone is.\"Why traditional market research is broken, and what Listen Labs is building to fix itListen&#x27;s AI researcher finds participants, conducts in-depth interviews, and delivers actionable insights in hours, not weeks. The platform replaces the traditional choice between quantitative surveys — which provide statistical precision but miss nuance—and qualitative interviews, which deliver depth but cannot scale.Wahlforss explained the limitation of existing approaches: \"Essentially surveys give you false precision because people end up answering the same question... You can&#x27;t get the outliers. People are actually not honest on surveys.\" The alternative, one-on-one human interviews, \"gives you a lot of depth. You can ask follow up questions. You can kind of double check if they actually know what they&#x27;re talking about. And the problem is you can&#x27;t scale that.\"The platform works in four steps: users create a study with AI assistance, Listen recruits participants from its global network of 30 million people, an AI moderator conducts in-depth interviews with follow-up questions, and results are packaged into executive-ready reports including key themes, highlight reels, and slide decks.What distinguishes Listen&#x27;s approach is its use of open-ended video conversations rather than multiple-choice forms. \"In a survey, you can kind of guess what you should answer, and you have four options,\" Wahlforss said. \"Oh, they probably want me to buy high income. Let me click on that button versus an open ended response. It just generates much more honesty.\"The dirty secret of the $140 billion market research industry: rampant fraudListen finds and qualifies the right participants in its global network of 30 million people. But building that panel required confronting what Wahlforss called \"one of the most shocking things that we&#x27;ve learned when we entered this industry\"—rampant fraud.\"Essentially, there&#x27;s a financial transaction involved, which means there will be bad players,\" he explained. \"We actually had some of the largest companies, some of them have billions in revenue, send us people who claim to be kind of enterprise buyers to our platform and our system immediately detected, like, fraud, fraud, fraud, fraud, fraud.\"The company built what it calls a \"quality guard\" that cross-references LinkedIn profiles with video responses to verify identity, checks consistency across how participants answer questions, and flags suspicious patterns. The result, according to Wahlforss: \"People talk three times more. They&#x27;re much more honest when they talk about sensitive topics like politics and mental health.\"Emeritus, an online education company that uses Listen, reported that approximately 20% of survey responses previously fell into the fraudulent or low-quality category. With Listen, they reduced this to almost zero. \"We did not have to replace any responses because of fraud or gibberish information,\" said Gabrielli Tiburi, Assistant Manager of Customer Insights at Emeritus.How Microsoft, Sweetgreen, and Chubbies are using AI interviews to build better productsThe speed advantage has proven central to Listen&#x27;s pitch. Traditional customer research at Microsoft could take four to six weeks to generate insights. \"By the time we get to them, either the decision has been made or we lose out on the opportunity to actually influence it,\" said Romani Patel, Senior Research Manager at Microsoft.With Listen, Microsoft can now get insights in days, and in many cases, within hours.The platform has already powered several high-profile initiatives. Microsoft used Listen Labs to collect global customer stories for its 50th anniversary celebration. \"We wanted users to share how Copilot is empowering them to bring their best self forward,\" Patel said, \"and we were able to collect those user video stories within a day.\" Traditionally, that kind of work would have taken six to eight weeks.Simple Modern, an Oklahoma-based drinkware company, used Listen to test a new product concept. The process took about an hour to write questions, an hour to launch the study, and 2.5 hours to receive feedback from 120 people across the country. \"We went from &#x27;Should we even have this product?&#x27; to &#x27;How should we launch it?&#x27;\" said Chris Hoyle, the company&#x27;s Chief Marketing Officer.Chubbies, the shorts brand, achieved a 24x increase in youth research participation—growing from 5 to 120 participants — by using Listen to overcome the scheduling challenges of traditional focus groups with children. \"There&#x27;s school, sports, dinner, and homework,\" explained Lauren Neville, Director of Insights and Innovation. \"I had to find a way to hear from them that fit into their schedules.\"The company also discovered product issues through AI interviews that might have gone undetected otherwise. Wahlforss described how the AI \"through conversations, realized there were like issues with the the kids short line, and decided to, like, interview hundreds of kids. And I understand that there were issues in the liner of the shorts and that they were, like, scratchy, quote, unquote, according to the people interviewed.\" The redesigned product became \"a blockbuster hit.\"The Jevons paradox explains why cheaper research creates more demand, not lessListen Labs is entering a massive but fragmented market. Wahlforss cited research from Andreessen Horowitz estimating the market research industry at roughly $140 billion annually, populated by legacy players — some with more than a billion dollars in revenue — that he believes are vulnerable to disruption.\"There are very much existing budget lines that we are replacing,\" Wahlforss said. \"Why we&#x27;re replacing them is that one, they&#x27;re super costly. Two, they&#x27;re kind of stuck in this old paradigm of choosing between a survey or interview, and they also take months to work with.\"But the more intriguing dynamic may be that AI-powered research doesn&#x27;t just replace existing spending — it creates new demand. Wahlforss invoked the Jevons paradox, an economic principle that occurs when technological advancements make a resource more efficient to use, but increased efficiency leads to increased overall consumption rather than decreased consumption.\"What I&#x27;ve noticed is that as something gets cheaper, you don&#x27;t need less of it. You want more of it,\" Wahlforss explained. \"There&#x27;s infinite demand for customer understanding. So the researchers on the team can do an order of magnitude more research, and also other people who weren&#x27;t researchers before can now do that as part of their job.\"Inside the elite engineering team that built Listen Labs before they had a working toiletListen Labs traces its origins to a consumer app that Wahlforss and his co-founder built after meeting at Harvard. \"We built this consumer app that got 20,000 downloads in one day,\" Wahlforss recalled. \"We had all these users, and we were thinking like, okay, what can we do to get to know them better? And we built this prototype of what Listen is today.\"The founding team brings an unusual pedigree. Wahlforss&#x27;s co-founder \"was the national champion in competitive programming in Germany, and he worked at Tesla Autopilot.\" The company claims that 30% of its engineering team are medalists from the International Olympiad in Informatics — the same competition that produced the founders of Cognition, the AI coding startup.The Berghain billboard stunt generated approximately 5 million views across social media, according to Wahlforss. It reflected the intensity of the talent war in the Bay Area.\"We had to do these things because some of our, like early employees, joined the company before we had a working toilet,\" he said. \"But now we fixed that situation.\"The company grew from 5 to 40 employees in 2024 and plans to reach 150 this year. It hires engineers for non-engineering roles across marketing, growth, and operations — a bet that in the AI era, technical fluency matters everywhere.Synthetic customers and automated decisions: what Listen Labs is building nextWahlforss outlined an ambitious product roadmap that pushes into more speculative territory. The company is building \"the ability to simulate your customers, so you can take all of those interviews we&#x27;ve done, and then extrapolate based on that and create synthetic users or simulated user voices.\"Beyond simulation, Listen aims to enable automated action based on research findings. \"Can you not just make recommendations, but also create spawn agents to either change things in code or some customer churns? Can you give them a discount and try to bring them back?\"Wahlforss acknowledged the ethical implications. \"Obviously, as you said, there&#x27;s kind of ethical concerns there. Of like, automated decision making overall can be bad, but we will have considerable guardrails to make sure that the companies are always in the loop.\"The company already handles sensitive data with care. \"We don&#x27;t train on any of the data,\" Wahlforss said. \"We will also scrub any sensitive PII automatically so the model can detect that. And there are times when, for example, you work with investors, where if you accidentally mention something that could be material, non public information, the AI can actually detect that and remove any information like that.\"How AI could reshape the future of product developmentPerhaps the most provocative implication of Listen&#x27;s model is how it could reshape product development itself. Wahlforss described a customer — an Australian startup — that has adopted what amounts to a continuous feedback loop.\"They&#x27;re based in Australia, so they&#x27;re coding during the day, and then in their night, they&#x27;re releasing a Listen study with an American audience. Listen validates whatever they built during the day, and they get feedback on that. They can then plug that feedback directly into coding tools like Claude Code and iterate.\"The vision extends Y Combinator&#x27;s famous dictum — \"write code, talk to users\" — into an automated cycle. \"Write code is now getting automated. And I think like talk to users will be as well, and you&#x27;ll have this kind of infinite loop where you can start to ship this truly amazing product, almost kind of autonomously.\"Whether that vision materializes depends on factors beyond Listen&#x27;s control — the continued improvement of AI models, enterprise willingness to trust automated research, and whether speed truly correlates with better products. A 2024 MIT study found that 95% of AI pilots fail to move into production, a statistic Wahlforss cited as the reason he emphasizes quality over demos.\"I&#x27;m constantly have to emphasize like, let&#x27;s make sure the quality is there and the details are right,\" he said.But the company&#x27;s growth suggests appetite for the experiment. Microsoft&#x27;s Patel said Listen has \"removed the drudgery of research and brought the fun and joy back into my work.\" Chubbies is now pushing its founder to give everyone in the company a login. Sling Money, a stablecoin payments startup, can create a survey in ten minutes and receive results the same day.\"It&#x27;s a total game changer,\" said Ali Romero, Sling Money&#x27;s marketing manager.Wahlforss has a different phrase for what he&#x27;s building. When asked about the tension between speed and rigor — the long-held belief that moving fast means cutting corners — he cited Nat Friedman, the former GitHub CEO and Listen investor, who keeps a list of one-liners on his website.One of them: \"Slow is fake.\"It&#x27;s an aggressive claim for an industry built on methodological caution. But Listen Labs is betting that in the AI era, the companies that listen fastest will be the ones that win. The only question is whether customers will talk back.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4gD12ThOmNHZuosqC4xCTz/277b1e8968da602108a29fae2eaca440/nuneybits_Vector_art_of_billboard_with_cryptic_code_dbe5b0ff-7644-45e6-a1ca-4a5dceeff986.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/kilo-launches-ai-powered-slack-bot-that-ships-code-from-a-chat-message",
          "published_at": "Fri, 16 Jan 2026 14:00:00 GMT",
          "title": "Kilo launches AI-powered Slack bot that ships code from a chat message",
          "standfirst": "Kilo Code, the open-source AI coding startup backed by GitLab cofounder Sid Sijbrandij, is launching a Slack integration that allows software engineering teams to execute code changes, debug issues, and push pull requests directly from their team chat — without opening an IDE or switching applications.The product, called Kilo for Slack, arrives as the AI-assisted coding market heats up with multibillion-dollar acquisitions and funding rounds. But rather than building another siloed coding assistant, Kilo is making a calculated bet: that the future of AI development tools lies not in locking engineers into a single interface, but in embedding AI capabilities into the fragmented workflows where decisions actually happen.\"Engineering teams don&#x27;t make decisions in IDE sidebars. They make them in Slack,\" Scott Breitenother, Kilo Code&#x27;s co-founder and CEO, said in an interview with VentureBeat. \"The Slackbot allows you to do all this — and more — without leaving Slack.\"The launch also marks a partnership with MiniMax, the Hong Kong-based AI company that recently completed a successful initial public offering. MiniMax&#x27;s M2.1 model will serve as the default model powering Kilo for Slack — a decision the company frames as a statement about the closing gap between open-weight and proprietary frontier models.How Kilo for Slack turns team conversations into pull requests without leaving the chatThe integration operates on a simple premise: Slack threads often contain the context needed to fix a bug or implement a feature, but that context gets lost the moment a developer switches to their code editor.With Kilo for Slack, users mention @Kilo in a Slack thread, and the bot reads the entire conversation, accesses connected GitHub repositories, and either answers questions about the codebase or creates a branch and submits a pull request.A typical interaction might look like this: A product manager reports a bug in a Slack channel. Engineers discuss potential causes. Instead of someone copying the conversation into their IDE and re-explaining the problem to an AI assistant, a developer simply types: \"@Kilo based on this thread, can you implement the fix for the null pointer exception in the Authentication service?\"The bot then spins up a cloud agent, reads the thread context, implements the fix, and pushes a pull request — all visible in Slack.The company says the entire process eliminates the need to copy information between apps or jump between windows — developers can trigger complex code changes with nothing more than a single message in Slack.Why Kilo says Cursor and Claude Code fall short when developers need multi-repo contextKilo&#x27;s launch explicitly positions the product against two leading AI coding tools: Cursor, which raised $2.3 billion at a $29.3 billion valuation in November, and Claude Code, Anthropic&#x27;s agentic coding tool.Breitenother outlined specific limitations he sees in both products&#x27; Slack capabilities.\"The Cursor Slack integration is configured on a single-repository basis per workspace or channel,\" he said. \"As a result, if a Slack thread references multiple repositories, users need to manually switch or reconfigure the integration to pull in that additional context.\"On Anthropic&#x27;s offering, he added: \"Claude Code documentation for Slack shows how Claude can be added to a workspace and respond to mentions using the surrounding conversation context. However, it does not describe persistent, multi-turn thread state or task-level continuity across longer workflows. Each interaction is handled based on the context included at the time of the prompt, rather than maintaining an evolving execution state over time.\"Kilo claims its integration works across multiple repositories simultaneously, maintains conversational context across extended Slack threads, and enables handoffs between Slack, IDEs, cloud agents, and the command-line interface.Kilo picks a Chinese AI company&#x27;s model as its default—and addresses enterprise security concerns head-onPerhaps the most provocative element of the announcement is Kilo&#x27;s choice of default model. MiniMax is headquartered in Shanghai and recently went public in Hong Kong — a lineage that may raise eyebrows among enterprise customers wary of sending proprietary code through Chinese infrastructure.Breitenother addressed the concern directly: \"MiniMax&#x27;s recent Hong Kong IPO drew backing from major global institutional investors, including Baillie Gifford, ADIA, GIC, Mirae Asset, Aspex, and EastSpring. This speaks to strong global confidence in models built for global users.\"He emphasized that MiniMax models are hosted by major U.S.-compliant cloud providers. \"MiniMax M2-series are global leading open-source models, and are hosted by many U.S. compliant cloud providers such as AWS Bedrock, Google Vertex and Microsoft AI Foundry,\" he said. \"In fact, MiniMax models were featured by Matt Garman, the AWS CEO, during this year&#x27;s re:Invent keynote, showing they&#x27;re ready for enterprise use at scale.\"The company stresses that Kilo for Slack is fundamentally model-agnostic. \"Kilo doesn&#x27;t force customers into any single model,\" Breitenother said. \"Enterprise customers choose which models they use, where they&#x27;re hosted, and what fits their security, compliance, and risk requirements. Kilo offers access to more than 500 models, so teams can always choose the right model for the job.\"The decision to default to M2.1 reflects Kilo&#x27;s broader thesis about the AI market. According to the company, the performance gap between open-weight and proprietary models has narrowed from 8 percent to 1.7 percent on several key benchmarks. Breitenother clarified that this figure \"refers to convergence between open and closed models as measured by the Stanford AI Index using major general benchmarks like HumanEval, MATH, and MMLU, not to any specific agentic coding evaluation.\"In third-party evaluations, M2.1 has performed competitively. \"In LMArena, an open platform for community-driven AI benchmarking, M2.1 achieved a number-four ranking, right after OpenAI, Anthropic, and Google,\" Breitenother noted. \"What this shows is that M2.1 competes with frontier models in real-world coding workflows, as judged directly by developers.\"What happens to your code when you @mention an AI bot in SlackFor engineering teams evaluating the tool, a critical question is what happens to sensitive code and conversations when routed through the integration.Breitenother walked through the data flow: \"When someone mentions @Kilo in Slack, Kilo reads only the content of the Slack thread where it&#x27;s mentioned, along with basic metadata needed to understand context. It does not have blanket access to a workspace. Access is governed by Slack&#x27;s standard permission model and the scopes the customer approves during installation.\"For repository access, he added: \"If the request requires code context, Kilo accesses only the GitHub repositories the customer has explicitly connected. It does not index unrelated repos. Permissions mirror the access level granted through GitHub, and Kilo can&#x27;t see anything the user or workspace hasn&#x27;t authorized.\"The company states that data is not used to train models and that output visibility follows existing Slack and GitHub permissions.A particularly thorny question for any AI system that can push code directly to repositories is security. What prevents an AI-generated vulnerability from being merged into production?\"Nothing gets merged automatically,\" Breitenother said. \"When the Kilo Slackbot opens a pull request from a Slack thread, it follows the same guardrails teams already rely on today. The PR goes through existing review workflows and approval processes before anything reaches production.\"He added that Kilo can automatically run its built-in code review feature on AI-generated pull requests, \"flagging potential issues or security concerns before it ever reaches a developer for review.\"The open-source paradox: why Kilo believes giving away its code won&#x27;t kill the businessKilo Code sits in an increasingly common but still tricky position: the open-source company charging for hosted services. The complete IDE extension is open-source under an Apache 2.0 license, but Kilo for Slack is a paid, hosted product.The obvious question: What stops a well-funded competitor — or even a customer — from forking the code and building their own version?\"Forking the code isn&#x27;t what worries us, because the code itself isn&#x27;t the hardest part,\" Breitenother said. \"A competitor could fork the repository tomorrow. What they wouldn&#x27;t get is the infrastructure that safely executes agentic workflows across Slack, GitHub, IDEs, and cloud agents. The experience we&#x27;ve built operating this at scale across many teams and repositories. The trust, integrations, and enterprise-ready controls customers expect out of the box.\"He drew parallels to other successful open-source companies: \"Open core drives adoption and trust, while the hosted product delivers convenience, reliability, and ongoing innovation. Customers aren&#x27;t paying for access to code. They&#x27;re paying for a system that works every day, securely, at scale.\"Inside the $29 billion \"vibe coding\" market that Kilo wants to disruptKilo enters a market that has attracted extraordinary attention and capital over the past year. The practice of using large language models to write and modify code — popularly known as \"vibe coding,\" a term coined by OpenAI co-founder Andrej Karpathy in February 2025 — has become a central focus of enterprise AI investment.Microsoft CEO Satya Nadella disclosed in April that AI-generated code now accounts for 30 percent of Microsoft&#x27;s codebase. Google acquired senior employees from AI coding startup Windsurf in a $2.4 billion transaction in July. Cursor&#x27;s November funding round valued the company at $29.3 billion.Kilo raised $8 million in seed funding in December 2025 from Breakers, Cota Capital, General Catalyst, Quiet Capital, and Tokyo Black. Sijbrandij, who stepped down as GitLab CEO in 2024 to focus on cancer treatment but remains board chair, contributed early capital and remains involved in day-to-day strategy.Asked about non-compete considerations given GitLab&#x27;s own AI investments, Breitenother was brief: \"There are no non-compete issues. Kilo is building a fundamentally different approach to AI coding.\"Notably, GitLab disclosed in a recent SEC filing that it paid Kilo $1,000 in exchange for a right of first refusal for 10 business days should the startup receive an acquisition proposal before August 2026.When asked to name an enterprise customer using the Slack integration in production, Breitenother declined: \"That&#x27;s not something we can disclose.\"How a 34-person startup plans to outmaneuver OpenAI and Anthropic in AI codingThe most significant threat to Kilo&#x27;s position may come not from other startups but from the frontier AI labs themselves. OpenAI and Anthropic are both building deeper integrations for coding workflows, and both have vastly greater resources.Breitenother argued that Kilo&#x27;s advantage lies in its architecture, not its model performance.\"We don&#x27;t think the long-term moat in AI coding is raw compute or who ships a Slack agent first,\" he said. \"OpenAI and Anthropic are world-class model companies, and they&#x27;ll continue to build impressive capabilities. But Kilo is built around a different thesis: the hard problem isn&#x27;t generating code, it&#x27;s integrating AI into real engineering workflows across tools, repos, and environments.\"He outlined three areas where he believes Kilo can differentiate:\"Workflow depth: Kilo is designed to operate across Slack, IDEs, cloud agents, GitHub, and the CLI, with persistent context and execution. Even with OpenAI or Anthropic Slack-native agents, those agents are still fundamentally model-centric. Kilo is workflow-centric.\"\"Model flexibility: We&#x27;re model-agnostic by design. Teams don&#x27;t have to bet on one frontier model or vendor roadmap. That&#x27;s difficult for companies like OpenAI or Anthropic, whose incentives are naturally aligned with driving usage toward their own models first.\"\"Platform neutrality: Kilo isn&#x27;t trying to pull developers into a closed ecosystem. It fits into the tools teams already use.\"The future of AI-assisted software development may belong to whoever solves the integration problem firstKilo&#x27;s launch reflects a maturing phase in the AI coding market. The initial wave of tools focused on proving that large language models could generate useful code. The current wave is about integration — fitting AI capabilities into the messy reality of how software actually gets built.That reality involves context fragmented across Slack threads, GitHub issues, IDE windows, and command-line sessions. It involves teams that use different models for different tasks and organizations with complex compliance requirements around data residency and model providers.Kilo is betting that the winners in this market will not be the companies with the best models, but those that best solve the integration problem — meeting developers in the tools they already use rather than forcing them into new ones.Kilo for Slack is available now for teams with Kilo Code accounts. Users connect their GitHub repositories through Kilo&#x27;s integrations dashboard, add the Slack integration, and can then mention @Kilo in any channel where the bot has been added. Usage-based pricing matches the rates of whatever model the team selects.Whether a 34-person startup can execute on that vision against competitors with billions in capital remains an open question. But if Breitenother is right that the hard problem in AI coding isn&#x27;t generating code but integrating into workflows, Kilo may have picked the right fight. After all, the best AI in the world doesn&#x27;t matter much if developers have to leave the conversation to use it.",
          "content": "Kilo Code, the open-source AI coding startup backed by GitLab cofounder Sid Sijbrandij, is launching a Slack integration that allows software engineering teams to execute code changes, debug issues, and push pull requests directly from their team chat — without opening an IDE or switching applications.The product, called Kilo for Slack, arrives as the AI-assisted coding market heats up with multibillion-dollar acquisitions and funding rounds. But rather than building another siloed coding assistant, Kilo is making a calculated bet: that the future of AI development tools lies not in locking engineers into a single interface, but in embedding AI capabilities into the fragmented workflows where decisions actually happen.\"Engineering teams don&#x27;t make decisions in IDE sidebars. They make them in Slack,\" Scott Breitenother, Kilo Code&#x27;s co-founder and CEO, said in an interview with VentureBeat. \"The Slackbot allows you to do all this — and more — without leaving Slack.\"The launch also marks a partnership with MiniMax, the Hong Kong-based AI company that recently completed a successful initial public offering. MiniMax&#x27;s M2.1 model will serve as the default model powering Kilo for Slack — a decision the company frames as a statement about the closing gap between open-weight and proprietary frontier models.How Kilo for Slack turns team conversations into pull requests without leaving the chatThe integration operates on a simple premise: Slack threads often contain the context needed to fix a bug or implement a feature, but that context gets lost the moment a developer switches to their code editor.With Kilo for Slack, users mention @Kilo in a Slack thread, and the bot reads the entire conversation, accesses connected GitHub repositories, and either answers questions about the codebase or creates a branch and submits a pull request.A typical interaction might look like this: A product manager reports a bug in a Slack channel. Engineers discuss potential causes. Instead of someone copying the conversation into their IDE and re-explaining the problem to an AI assistant, a developer simply types: \"@Kilo based on this thread, can you implement the fix for the null pointer exception in the Authentication service?\"The bot then spins up a cloud agent, reads the thread context, implements the fix, and pushes a pull request — all visible in Slack.The company says the entire process eliminates the need to copy information between apps or jump between windows — developers can trigger complex code changes with nothing more than a single message in Slack.Why Kilo says Cursor and Claude Code fall short when developers need multi-repo contextKilo&#x27;s launch explicitly positions the product against two leading AI coding tools: Cursor, which raised $2.3 billion at a $29.3 billion valuation in November, and Claude Code, Anthropic&#x27;s agentic coding tool.Breitenother outlined specific limitations he sees in both products&#x27; Slack capabilities.\"The Cursor Slack integration is configured on a single-repository basis per workspace or channel,\" he said. \"As a result, if a Slack thread references multiple repositories, users need to manually switch or reconfigure the integration to pull in that additional context.\"On Anthropic&#x27;s offering, he added: \"Claude Code documentation for Slack shows how Claude can be added to a workspace and respond to mentions using the surrounding conversation context. However, it does not describe persistent, multi-turn thread state or task-level continuity across longer workflows. Each interaction is handled based on the context included at the time of the prompt, rather than maintaining an evolving execution state over time.\"Kilo claims its integration works across multiple repositories simultaneously, maintains conversational context across extended Slack threads, and enables handoffs between Slack, IDEs, cloud agents, and the command-line interface.Kilo picks a Chinese AI company&#x27;s model as its default—and addresses enterprise security concerns head-onPerhaps the most provocative element of the announcement is Kilo&#x27;s choice of default model. MiniMax is headquartered in Shanghai and recently went public in Hong Kong — a lineage that may raise eyebrows among enterprise customers wary of sending proprietary code through Chinese infrastructure.Breitenother addressed the concern directly: \"MiniMax&#x27;s recent Hong Kong IPO drew backing from major global institutional investors, including Baillie Gifford, ADIA, GIC, Mirae Asset, Aspex, and EastSpring. This speaks to strong global confidence in models built for global users.\"He emphasized that MiniMax models are hosted by major U.S.-compliant cloud providers. \"MiniMax M2-series are global leading open-source models, and are hosted by many U.S. compliant cloud providers such as AWS Bedrock, Google Vertex and Microsoft AI Foundry,\" he said. \"In fact, MiniMax models were featured by Matt Garman, the AWS CEO, during this year&#x27;s re:Invent keynote, showing they&#x27;re ready for enterprise use at scale.\"The company stresses that Kilo for Slack is fundamentally model-agnostic. \"Kilo doesn&#x27;t force customers into any single model,\" Breitenother said. \"Enterprise customers choose which models they use, where they&#x27;re hosted, and what fits their security, compliance, and risk requirements. Kilo offers access to more than 500 models, so teams can always choose the right model for the job.\"The decision to default to M2.1 reflects Kilo&#x27;s broader thesis about the AI market. According to the company, the performance gap between open-weight and proprietary models has narrowed from 8 percent to 1.7 percent on several key benchmarks. Breitenother clarified that this figure \"refers to convergence between open and closed models as measured by the Stanford AI Index using major general benchmarks like HumanEval, MATH, and MMLU, not to any specific agentic coding evaluation.\"In third-party evaluations, M2.1 has performed competitively. \"In LMArena, an open platform for community-driven AI benchmarking, M2.1 achieved a number-four ranking, right after OpenAI, Anthropic, and Google,\" Breitenother noted. \"What this shows is that M2.1 competes with frontier models in real-world coding workflows, as judged directly by developers.\"What happens to your code when you @mention an AI bot in SlackFor engineering teams evaluating the tool, a critical question is what happens to sensitive code and conversations when routed through the integration.Breitenother walked through the data flow: \"When someone mentions @Kilo in Slack, Kilo reads only the content of the Slack thread where it&#x27;s mentioned, along with basic metadata needed to understand context. It does not have blanket access to a workspace. Access is governed by Slack&#x27;s standard permission model and the scopes the customer approves during installation.\"For repository access, he added: \"If the request requires code context, Kilo accesses only the GitHub repositories the customer has explicitly connected. It does not index unrelated repos. Permissions mirror the access level granted through GitHub, and Kilo can&#x27;t see anything the user or workspace hasn&#x27;t authorized.\"The company states that data is not used to train models and that output visibility follows existing Slack and GitHub permissions.A particularly thorny question for any AI system that can push code directly to repositories is security. What prevents an AI-generated vulnerability from being merged into production?\"Nothing gets merged automatically,\" Breitenother said. \"When the Kilo Slackbot opens a pull request from a Slack thread, it follows the same guardrails teams already rely on today. The PR goes through existing review workflows and approval processes before anything reaches production.\"He added that Kilo can automatically run its built-in code review feature on AI-generated pull requests, \"flagging potential issues or security concerns before it ever reaches a developer for review.\"The open-source paradox: why Kilo believes giving away its code won&#x27;t kill the businessKilo Code sits in an increasingly common but still tricky position: the open-source company charging for hosted services. The complete IDE extension is open-source under an Apache 2.0 license, but Kilo for Slack is a paid, hosted product.The obvious question: What stops a well-funded competitor — or even a customer — from forking the code and building their own version?\"Forking the code isn&#x27;t what worries us, because the code itself isn&#x27;t the hardest part,\" Breitenother said. \"A competitor could fork the repository tomorrow. What they wouldn&#x27;t get is the infrastructure that safely executes agentic workflows across Slack, GitHub, IDEs, and cloud agents. The experience we&#x27;ve built operating this at scale across many teams and repositories. The trust, integrations, and enterprise-ready controls customers expect out of the box.\"He drew parallels to other successful open-source companies: \"Open core drives adoption and trust, while the hosted product delivers convenience, reliability, and ongoing innovation. Customers aren&#x27;t paying for access to code. They&#x27;re paying for a system that works every day, securely, at scale.\"Inside the $29 billion \"vibe coding\" market that Kilo wants to disruptKilo enters a market that has attracted extraordinary attention and capital over the past year. The practice of using large language models to write and modify code — popularly known as \"vibe coding,\" a term coined by OpenAI co-founder Andrej Karpathy in February 2025 — has become a central focus of enterprise AI investment.Microsoft CEO Satya Nadella disclosed in April that AI-generated code now accounts for 30 percent of Microsoft&#x27;s codebase. Google acquired senior employees from AI coding startup Windsurf in a $2.4 billion transaction in July. Cursor&#x27;s November funding round valued the company at $29.3 billion.Kilo raised $8 million in seed funding in December 2025 from Breakers, Cota Capital, General Catalyst, Quiet Capital, and Tokyo Black. Sijbrandij, who stepped down as GitLab CEO in 2024 to focus on cancer treatment but remains board chair, contributed early capital and remains involved in day-to-day strategy.Asked about non-compete considerations given GitLab&#x27;s own AI investments, Breitenother was brief: \"There are no non-compete issues. Kilo is building a fundamentally different approach to AI coding.\"Notably, GitLab disclosed in a recent SEC filing that it paid Kilo $1,000 in exchange for a right of first refusal for 10 business days should the startup receive an acquisition proposal before August 2026.When asked to name an enterprise customer using the Slack integration in production, Breitenother declined: \"That&#x27;s not something we can disclose.\"How a 34-person startup plans to outmaneuver OpenAI and Anthropic in AI codingThe most significant threat to Kilo&#x27;s position may come not from other startups but from the frontier AI labs themselves. OpenAI and Anthropic are both building deeper integrations for coding workflows, and both have vastly greater resources.Breitenother argued that Kilo&#x27;s advantage lies in its architecture, not its model performance.\"We don&#x27;t think the long-term moat in AI coding is raw compute or who ships a Slack agent first,\" he said. \"OpenAI and Anthropic are world-class model companies, and they&#x27;ll continue to build impressive capabilities. But Kilo is built around a different thesis: the hard problem isn&#x27;t generating code, it&#x27;s integrating AI into real engineering workflows across tools, repos, and environments.\"He outlined three areas where he believes Kilo can differentiate:\"Workflow depth: Kilo is designed to operate across Slack, IDEs, cloud agents, GitHub, and the CLI, with persistent context and execution. Even with OpenAI or Anthropic Slack-native agents, those agents are still fundamentally model-centric. Kilo is workflow-centric.\"\"Model flexibility: We&#x27;re model-agnostic by design. Teams don&#x27;t have to bet on one frontier model or vendor roadmap. That&#x27;s difficult for companies like OpenAI or Anthropic, whose incentives are naturally aligned with driving usage toward their own models first.\"\"Platform neutrality: Kilo isn&#x27;t trying to pull developers into a closed ecosystem. It fits into the tools teams already use.\"The future of AI-assisted software development may belong to whoever solves the integration problem firstKilo&#x27;s launch reflects a maturing phase in the AI coding market. The initial wave of tools focused on proving that large language models could generate useful code. The current wave is about integration — fitting AI capabilities into the messy reality of how software actually gets built.That reality involves context fragmented across Slack threads, GitHub issues, IDE windows, and command-line sessions. It involves teams that use different models for different tasks and organizations with complex compliance requirements around data residency and model providers.Kilo is betting that the winners in this market will not be the companies with the best models, but those that best solve the integration problem — meeting developers in the tools they already use rather than forcing them into new ones.Kilo for Slack is available now for teams with Kilo Code accounts. Users connect their GitHub repositories through Kilo&#x27;s integrations dashboard, add the Slack integration, and can then mention @Kilo in any channel where the bot has been added. Usage-based pricing matches the rates of whatever model the team selects.Whether a 34-person startup can execute on that vision against competitors with billions in capital remains an open question. But if Breitenother is right that the hard problem in AI coding isn&#x27;t generating code but integrating into workflows, Kilo may have picked the right fight. After all, the best AI in the world doesn&#x27;t matter much if developers have to leave the conversation to use it.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4cptf24mzCK6LcSxsLAHoi/596ad32d8a9666e72b0f1d3077648ec8/nuneybits_Chat_bubble_in_rainbow_colors_turning_into_computer_c_325860e4-2d7b-49f6-9118-9bad9740085b.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/apples-latest-magsafe-charger-is-on-sale-for-30-141707636.html",
          "published_at": "Fri, 16 Jan 2026 13:50:37 +0000",
          "title": "Apple's latest MagSafe charger is on sale for $30",
          "standfirst": "One way you can reduce the number of cables you have to deal with on the regular is by investing in a few wireless chargers. Those with iPhones should consider Apple's own MagSafe charger not only because of its sleek and effective design, but also because it's on sale right now at Amazon. The Qi2.2-rated MagSafe charger is down to $30 for the one-meter version, or $40 for the two-meter version. If you have an iPhone 16, iPhone 17 or iPhone Air, this cable can charge your device at 25W as long as it's connected to a 30W power adapter on the other end. While you'll need a more recent iPhone to get the fastest MagSafe charging speeds, the charger can wirelessly top up the battery of any iPhone from the last eight years (iPhone 8 and later). With older iPhones, the charging speed tops out at 15W. The cable works with AirPods wireless charging cases too — it's certified for Qi2.2 and Qi charging. The MagSafe charger is one of our favorite iPhone accessories, and would pair quite nicely with your new iPhone if you're picking up one of the latest models. If you're on the fence about that, be sure to check out our reviews of the iPhone 17, iPhone Pro/Pro Max and iPhone Air. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-latest-magsafe-charger-is-on-sale-for-30-141707636.html?src=rss",
          "content": "One way you can reduce the number of cables you have to deal with on the regular is by investing in a few wireless chargers. Those with iPhones should consider Apple's own MagSafe charger not only because of its sleek and effective design, but also because it's on sale right now at Amazon. The Qi2.2-rated MagSafe charger is down to $30 for the one-meter version, or $40 for the two-meter version. If you have an iPhone 16, iPhone 17 or iPhone Air, this cable can charge your device at 25W as long as it's connected to a 30W power adapter on the other end. While you'll need a more recent iPhone to get the fastest MagSafe charging speeds, the charger can wirelessly top up the battery of any iPhone from the last eight years (iPhone 8 and later). With older iPhones, the charging speed tops out at 15W. The cable works with AirPods wireless charging cases too — it's certified for Qi2.2 and Qi charging. The MagSafe charger is one of our favorite iPhone accessories, and would pair quite nicely with your new iPhone if you're picking up one of the latest models. If you're on the fence about that, be sure to check out our reviews of the iPhone 17, iPhone Pro/Pro Max and iPhone Air. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-latest-magsafe-charger-is-on-sale-for-30-141707636.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/disney-and-hulu-deal-get-the-bundle-for-only-10-for-one-month-192814913.html",
          "published_at": "Fri, 16 Jan 2026 13:21:26 +0000",
          "title": "Disney+ and Hulu deal: Get the bundle for only $10 for one month",
          "standfirst": "You have the best chance to save on streaming services during the holiday shopping season, but throughout the year, the occasional deal pops up that's worth considering. Case in point: this new Disney+ deal. New and eligible returning subscribers can sign up for the Disney+ Hulu bundle (with ads) for $10 for one month of access. That's $3 off the usual price of the bundle for one month, and more than 58 percent off if you consider the cost of each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/disney-and-hulu-deal-get-the-bundle-for-only-10-for-one-month-192814913.html?src=rss",
          "content": "You have the best chance to save on streaming services during the holiday shopping season, but throughout the year, the occasional deal pops up that's worth considering. Case in point: this new Disney+ deal. New and eligible returning subscribers can sign up for the Disney+ Hulu bundle (with ads) for $10 for one month of access. That's $3 off the usual price of the bundle for one month, and more than 58 percent off if you consider the cost of each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/disney-and-hulu-deal-get-the-bundle-for-only-10-for-one-month-192814913.html?src=rss",
          "feed_position": 16
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/one-of-our-favorite-budgeting-apps-is-only-50-for-the-year-for-new-users-204507183.html",
          "published_at": "Fri, 16 Jan 2026 13:13:18 +0000",
          "title": "One of our favorite budgeting apps is only $50 for the year for new users",
          "standfirst": "The start of the new year is a great time to get your finances in order, and a good budgeting app can help with that. Instead of laboring over a spreadsheet, you can try one of our favorite budgeting apps for less than usual. Monarch Money is running a sale that gives new users 50 percent off one year of the service, bringing the final cost down to just $50. Just use the code NEWYEAR2026 at checkout to get the discount. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/apps/one-of-our-favorite-budgeting-apps-is-only-50-for-the-year-for-new-users-204507183.html?src=rss",
          "content": "The start of the new year is a great time to get your finances in order, and a good budgeting app can help with that. Instead of laboring over a spreadsheet, you can try one of our favorite budgeting apps for less than usual. Monarch Money is running a sale that gives new users 50 percent off one year of the service, bringing the final cost down to just $50. Just use the code NEWYEAR2026 at checkout to get the discount. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/apps/one-of-our-favorite-budgeting-apps-is-only-50-for-the-year-for-new-users-204507183.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/asus-changes-mind-will-continue-selling-the-rtx-5070-ti-after-all-130934271.html",
          "published_at": "Fri, 16 Jan 2026 13:09:34 +0000",
          "title": "ASUS changes mind, will continue selling the RTX 5070 Ti after all",
          "standfirst": "After telling the YouTube channel Hardware Unboxed that it was putting its RTX 5060 Ti 16GB and 5070 Ti into \"end-of-life status,\" ASUS has backtracked on those comments and now says the GPUs will remain on sale. \"Certain media may have received incomplete information from an ASUS PR representative regarding these products,\" the company said in a dedicated press release.\" The GeForce RTX 5070 Ti and GeForce RTX 5060 Ti 16 GB have not been discontinued or designated as end-of-life (EOL). ASUS has no plans to stop selling these models.\" ASUS further clarified that supply fluctuations, primarily due to memory supply constraints, have temporarily affected production output and stocks. \"As a result, availability may appear limited in certain markets, but this should not be interpreted as a production halt or product retirement. ASUS will continue to support the GeForce RTX 5070 Ti and RTX 5060 Ti 16 GB and is working closely with partners to stabilize supply as conditions improve.\" Yesterday, Hardware Unboxed said that ASUS \"explicitly told us this model is currently facing a supply shortage and, as such, they have placed the model into end-of-life status.\" In a new pinned comment, the channel noted that the new information \"completely walks back their original statement to us.\" Hardware Unboxed learned of the shortage by speaking to resellers in Australia, who said that the 5070 Ti is “no longer available to purchase from partners and distributors,” adding they expect that to be the case throughout at least the first quarter of the year. Based on that, along with ASUS's statement, they released the video in question yesterday. Although ASUS now says that it will still make both of those GPUs, being able to buy one could be next to impossible, based on what retailers told Hardware Unboxed. The AI boom has sent the cost of memory soaring, leading to price hikes for GPUs and other PC components. That in turn has led to anger among gamers, and the problem may get much worse before it gets better. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/asus-changes-mind-will-continue-selling-the-rtx-5070-ti-after-all-130934271.html?src=rss",
          "content": "After telling the YouTube channel Hardware Unboxed that it was putting its RTX 5060 Ti 16GB and 5070 Ti into \"end-of-life status,\" ASUS has backtracked on those comments and now says the GPUs will remain on sale. \"Certain media may have received incomplete information from an ASUS PR representative regarding these products,\" the company said in a dedicated press release.\" The GeForce RTX 5070 Ti and GeForce RTX 5060 Ti 16 GB have not been discontinued or designated as end-of-life (EOL). ASUS has no plans to stop selling these models.\" ASUS further clarified that supply fluctuations, primarily due to memory supply constraints, have temporarily affected production output and stocks. \"As a result, availability may appear limited in certain markets, but this should not be interpreted as a production halt or product retirement. ASUS will continue to support the GeForce RTX 5070 Ti and RTX 5060 Ti 16 GB and is working closely with partners to stabilize supply as conditions improve.\" Yesterday, Hardware Unboxed said that ASUS \"explicitly told us this model is currently facing a supply shortage and, as such, they have placed the model into end-of-life status.\" In a new pinned comment, the channel noted that the new information \"completely walks back their original statement to us.\" Hardware Unboxed learned of the shortage by speaking to resellers in Australia, who said that the 5070 Ti is “no longer available to purchase from partners and distributors,” adding they expect that to be the case throughout at least the first quarter of the year. Based on that, along with ASUS's statement, they released the video in question yesterday. Although ASUS now says that it will still make both of those GPUs, being able to buy one could be next to impossible, based on what retailers told Hardware Unboxed. The AI boom has sent the cost of memory soaring, leading to price hikes for GPUs and other PC components. That in turn has led to anger among gamers, and the problem may get much worse before it gets better. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/asus-changes-mind-will-continue-selling-the-rtx-5070-ti-after-all-130934271.html?src=rss",
          "feed_position": 18
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/tiktok-tightens-age-verification-across-europe-130000847.html",
          "published_at": "Fri, 16 Jan 2026 13:00:00 +0000",
          "title": "TikTok tightens age verification across Europe",
          "standfirst": "TikTok is bolstering its age-verification measures across Europe. In the coming weeks, the platform will roll out upgraded age-detection tech in the European Economic Area, as well as in the UK and Switzerland. The systems will assess the likely age of a user based on their profile information and activity. When the tech flags an account that may belong to a user aged under 13 (the minimum age to use TikTok), a specialist moderator will assess whether it should be banned. TikTok will send users in Europe a notification to tell them about these measures and offer them a chance to learn more.Also, if a moderator is looking at content for other reasons and thinks an account might belong to an underage user, they can flag it to a specialist for further review. Anyone can report an account they suspect is used by someone under 13 as well. TikTok says it removes about 6 million underage accounts in total from the platform every month.Those whose accounts are banned can appeal if they think their access was wrongly terminated. Users can then provide a government-approved ID, a credit card authorization or selfie for age estimation (the latter process has not gone well for Roblox as of late, as kids found workarounds for age checks). TikTok acknowledged that there's no single ideal solution to the issue as things stand. \"Despite best efforts, there remains no globally agreed-upon method for effectively confirming a person's age in a way that also preserves their privacy,\" it stated in a blog post. \"At TikTok, we're committed to keeping children under the age of 13 off our platform, providing teens with age-appropriate experiences and continuing to assess and implement a range of solutions. We believe that a multi-layered approach to age assurance — one in which multiple techniques are used — is essential to protecting teens and upholding safety-by-design principles.\"TikTok is rolling out these practices after a pilot in Europe over the last year. That project helped the platform to identify and remove thousands more underage accounts. It worked with the Data Protection Commission (its main privacy regulator in the EU) to help ensure it complied with the bloc’s strict data protection standards.These measures are coming into force amid intensifying calls to keep kids off social media. A social media ban for under 16s in Australia went into effect last month. Affected platforms have collectively closed or restricted millions of accounts as a result. Reddit has filed a lawsuit over the ban. A similar ban might be on the cards in the UK amid public pressure and cross-party support. Prime Minister Keir Starmer said \"all options are on the table\" and that he was watching \"what is happening in Australia.\"The House of Lords is set to vote on proposals for an under-16 social media ban next week. If an amendment passes, members of parliament will hold a binding vote on the matter in the coming months.This article originally appeared on Engadget at https://www.engadget.com/social-media/tiktok-tightens-age-verification-across-europe-130000847.html?src=rss",
          "content": "TikTok is bolstering its age-verification measures across Europe. In the coming weeks, the platform will roll out upgraded age-detection tech in the European Economic Area, as well as in the UK and Switzerland. The systems will assess the likely age of a user based on their profile information and activity. When the tech flags an account that may belong to a user aged under 13 (the minimum age to use TikTok), a specialist moderator will assess whether it should be banned. TikTok will send users in Europe a notification to tell them about these measures and offer them a chance to learn more.Also, if a moderator is looking at content for other reasons and thinks an account might belong to an underage user, they can flag it to a specialist for further review. Anyone can report an account they suspect is used by someone under 13 as well. TikTok says it removes about 6 million underage accounts in total from the platform every month.Those whose accounts are banned can appeal if they think their access was wrongly terminated. Users can then provide a government-approved ID, a credit card authorization or selfie for age estimation (the latter process has not gone well for Roblox as of late, as kids found workarounds for age checks). TikTok acknowledged that there's no single ideal solution to the issue as things stand. \"Despite best efforts, there remains no globally agreed-upon method for effectively confirming a person's age in a way that also preserves their privacy,\" it stated in a blog post. \"At TikTok, we're committed to keeping children under the age of 13 off our platform, providing teens with age-appropriate experiences and continuing to assess and implement a range of solutions. We believe that a multi-layered approach to age assurance — one in which multiple techniques are used — is essential to protecting teens and upholding safety-by-design principles.\"TikTok is rolling out these practices after a pilot in Europe over the last year. That project helped the platform to identify and remove thousands more underage accounts. It worked with the Data Protection Commission (its main privacy regulator in the EU) to help ensure it complied with the bloc’s strict data protection standards.These measures are coming into force amid intensifying calls to keep kids off social media. A social media ban for under 16s in Australia went into effect last month. Affected platforms have collectively closed or restricted millions of accounts as a result. Reddit has filed a lawsuit over the ban. A similar ban might be on the cards in the UK amid public pressure and cross-party support. Prime Minister Keir Starmer said \"all options are on the table\" and that he was watching \"what is happening in Australia.\"The House of Lords is set to vote on proposals for an under-16 social media ban next week. If an amendment passes, members of parliament will hold a binding vote on the matter in the coming months.This article originally appeared on Engadget at https://www.engadget.com/social-media/tiktok-tightens-age-verification-across-europe-130000847.html?src=rss",
          "feed_position": 19
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-121506027.html",
          "published_at": "Fri, 16 Jan 2026 12:15:06 +0000",
          "title": "The Morning After: ASUS stops making some NVIDIA GPUs due to memory supply crunch",
          "standfirst": "If you thought we were exaggerating, the hunger for memory and GPUs is making many companies reassess their priorities. YouTube channel Hardware Unboxed discovered ASUS has stopped producing the RTX 5070 Ti and 5060 Ti 16GB due to the ongoing memory crunch. Both GPUs are 16GB models, making them more expensive to manufacture in the current climate. “Demand for GeForce RTX GPUs is strong, and memory supply is constrained. We continue to ship all GeForce SKUs and are working closely with our suppliers to maximize memory availability,” an NVIDIA spokesperson told Engadget. At CES 2026, we saw PCs and computing in the next 12 months will have higher prices and more limited availability for consumers. At the end of 2025, RAM prices skyrocketed, driven by demand from AI data centers. That’s not stopping anytime soon. — Mat Smith The other big stories (and deals) this morning The Animal Crossing: New Horizons 3.0 expansion has arrived earlier than expected How to claim Verizon’s $20 credit for Wednesday’s service outage Get one month of the Disney+ and Hulu bundle for only $10 Valerion VisionMaster Max projector review: Near-perfect image quality comes at a price Matthew McConaughey just trademarked himself In the fight against AI. Getty Matthew McConaughey filed trademark applications to prevent AI companies from using his likeness without permission, and the US Patent and Trademark Office has approved eight so far. Trademarks were for video and audio clips featuring the actor staring, smiling and talking. One was for an audio recording of him saying “alright, alright, alright,” his catchphrase from the movie Dazed and Confused. Under the law, it’s already prohibited for companies to steal someone’s likeness to sell products. However, given the vague rules governing the use of someone’s likeness, McConaughey is taking a proactive approach. McConaughey himself is an investor in ElevenLabs and has partnered with the AI startup to create a Spanish version of his newsletter. Está bien, está bien, está bien. Continue reading. Amazon is making a Fallout competition reality TV show Addiction! Radiation poisoning! Skeletal law enforcement? AMAZON The second season of Amazon’s excellent Fallout show is currently streaming, but the company is already looking to generate more revenue from its license to the well-regarded game series. Prime Video has greenlit an unscripted reality show titled Fallout Shelter. It will be a 10-episode run with Studio Lambert, the team behind reality projects including Squid Game: The Challenge and The Traitors. Continue reading. X says Grok will no longer edit images of real people into bikinis But image generation isn’t going anywhere. Following numerous complaints and several state and national investigations, X is revising its policies on Grok’s image-editing capabilities. New safeguards will place Grok’s image-generating features behind X’s subscription offering, and it will geoblock all users’ ability to generate images of real people in… well, less clothing, in regions where it’s illegal. California Attorney General Rob Bonta cited one analysis that found “more than half of the 20,000 images generated by xAI between Christmas and New Year depicted people in minimal clothing.” That’s been the primary use? Continue reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-121506027.html?src=rss",
          "content": "If you thought we were exaggerating, the hunger for memory and GPUs is making many companies reassess their priorities. YouTube channel Hardware Unboxed discovered ASUS has stopped producing the RTX 5070 Ti and 5060 Ti 16GB due to the ongoing memory crunch. Both GPUs are 16GB models, making them more expensive to manufacture in the current climate. “Demand for GeForce RTX GPUs is strong, and memory supply is constrained. We continue to ship all GeForce SKUs and are working closely with our suppliers to maximize memory availability,” an NVIDIA spokesperson told Engadget. At CES 2026, we saw PCs and computing in the next 12 months will have higher prices and more limited availability for consumers. At the end of 2025, RAM prices skyrocketed, driven by demand from AI data centers. That’s not stopping anytime soon. — Mat Smith The other big stories (and deals) this morning The Animal Crossing: New Horizons 3.0 expansion has arrived earlier than expected How to claim Verizon’s $20 credit for Wednesday’s service outage Get one month of the Disney+ and Hulu bundle for only $10 Valerion VisionMaster Max projector review: Near-perfect image quality comes at a price Matthew McConaughey just trademarked himself In the fight against AI. Getty Matthew McConaughey filed trademark applications to prevent AI companies from using his likeness without permission, and the US Patent and Trademark Office has approved eight so far. Trademarks were for video and audio clips featuring the actor staring, smiling and talking. One was for an audio recording of him saying “alright, alright, alright,” his catchphrase from the movie Dazed and Confused. Under the law, it’s already prohibited for companies to steal someone’s likeness to sell products. However, given the vague rules governing the use of someone’s likeness, McConaughey is taking a proactive approach. McConaughey himself is an investor in ElevenLabs and has partnered with the AI startup to create a Spanish version of his newsletter. Está bien, está bien, está bien. Continue reading. Amazon is making a Fallout competition reality TV show Addiction! Radiation poisoning! Skeletal law enforcement? AMAZON The second season of Amazon’s excellent Fallout show is currently streaming, but the company is already looking to generate more revenue from its license to the well-regarded game series. Prime Video has greenlit an unscripted reality show titled Fallout Shelter. It will be a 10-episode run with Studio Lambert, the team behind reality projects including Squid Game: The Challenge and The Traitors. Continue reading. X says Grok will no longer edit images of real people into bikinis But image generation isn’t going anywhere. Following numerous complaints and several state and national investigations, X is revising its policies on Grok’s image-editing capabilities. New safeguards will place Grok’s image-generating features behind X’s subscription offering, and it will geoblock all users’ ability to generate images of real people in… well, less clothing, in regions where it’s illegal. California Attorney General Rob Bonta cited one analysis that found “more than half of the 20,000 images generated by xAI between Christmas and New Year depicted people in minimal clothing.” That’s been the primary use? Continue reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-121506027.html?src=rss",
          "feed_position": 20,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/e93f6ce1-f2d1-11f0-bd5f-40209b88cdb9"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/best-midrange-smartphone-183006463.html",
          "published_at": "Fri, 16 Jan 2026 10:01:27 +0000",
          "title": "The best midrange smartphone for 2026",
          "standfirst": "Gone are the days in which you needed to spend a fortune to get a good smartphone. In 2026, features once exclusive to high-end smartphones – big batteries, multi-camera arrays, high refresh rate OLED displays and more – have made their way down to more affordable models. Yes, you’ll still need to buy a flagship smartphone to get the best camera or fastest processor, but you don't have to make nearly as many compromises as you once did if you have a strict budget to adhere to when you go shopping for your next smartphone. If you have less than $600 to spend, let us help you figure out what features to prioritize when trying to find the best midrange smartphone. Table of contents Best midrange phones in 2026 What is a midrange phone? What to consider before buying a midrange smartphone What won't you get from a midrange phone Best midrange phones for 2026 What is a midrange phone? While the term frequently appears in articles and videos, there isn’t an agreed-upon definition for “midrange” beyond a phone that isn’t a flagship or an entry-level option. Most of our recommendations cost between $400 and $600 — any less and you should expect significant compromises. If you have more to spend, you might as well consider flagships like the Apple iPhone 17 and the Samsung Galaxy S25 if you want the best smartphone experience. Devices like Pixel phones often sit in this price range too, offering some of the best value for Android buyers. What to consider before buying a midrange smartphone Buying a new device can be intimidating, but a few questions can help guide you through the process. First: what platform do you want to use? If the answer is iOS, that narrows your options down to exactly one phone. (Thankfully, it’s great.) And if you’re an Android fan, there’s no shortage of compelling options. Both platforms have their strengths, so you shouldn’t rule either out. Of course, also consider how much you’re comfortable spending. Even increasing your budget by $100 more can get you a dramatically better product. Moreover, manufacturers tend to support their more expensive devices for longer with software updates and security updates, so it’s worth buying something toward the top limit of what you can afford. Having an idea of your priorities will help inform your budget. Do you want a long battery life or fast charging? Do you value speedy performance above all else? Or would you like the best possible cameras with high megapixel counts? While they continue to improve every year, even the best midrange smartphones still demand some compromises, and knowing what’s important to you will make choosing one easier. What won’t you get from a midrange smartphone? Every year, the line between midrange and flagship phones blurs as more upmarket features and functions trickle down to more affordable models. When Engadget first published this guide in 2020, it was tricky to find a $500 phone with waterproofing and 5G. In 2026, the biggest thing you might miss out on is wireless charging – and even then, that’s becoming less true. One thing your new phone probably won’t come with is a power adapter; many companies have stopped including chargers with all of their smartphones. Performance has improved in recent years, but can still be hit or miss as most midrange phones use slower processors that can struggle with multitasking. Thankfully, their camera systems have improved dramatically, and you can typically expect at least a dual-lens system on most midrange smartphones below $600 with decent camera quality, selfie performance and software support to keep things running smoothly for years to come.. Midrange smartphone FAQs How long do midrange phones get software updates? Support varies by brand, but most midrange phones receive around three to five years of software and security updates. Apple tends to support iPhones longer while companies like Google and Samsung now promise several years of Android and security patches for their midrange models. Budget-focused brands might offer less so it’s worth checking the update policy before you buy. Are midrange phones good for gaming? Yes, many midrange phones handle gaming well, especially popular titles like Fortnite, Genshin Impact and Call of Duty Mobile. They usually include capable processors, though you won’t always get the smoothest performance in the most demanding mobile games or at max settings. If you play casually or stick to less graphically intensive titles a midrange phone will feel more than adequate. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-midrange-smartphone-183006463.html?src=rss",
          "content": "Gone are the days in which you needed to spend a fortune to get a good smartphone. In 2026, features once exclusive to high-end smartphones – big batteries, multi-camera arrays, high refresh rate OLED displays and more – have made their way down to more affordable models. Yes, you’ll still need to buy a flagship smartphone to get the best camera or fastest processor, but you don't have to make nearly as many compromises as you once did if you have a strict budget to adhere to when you go shopping for your next smartphone. If you have less than $600 to spend, let us help you figure out what features to prioritize when trying to find the best midrange smartphone. Table of contents Best midrange phones in 2026 What is a midrange phone? What to consider before buying a midrange smartphone What won't you get from a midrange phone Best midrange phones for 2026 What is a midrange phone? While the term frequently appears in articles and videos, there isn’t an agreed-upon definition for “midrange” beyond a phone that isn’t a flagship or an entry-level option. Most of our recommendations cost between $400 and $600 — any less and you should expect significant compromises. If you have more to spend, you might as well consider flagships like the Apple iPhone 17 and the Samsung Galaxy S25 if you want the best smartphone experience. Devices like Pixel phones often sit in this price range too, offering some of the best value for Android buyers. What to consider before buying a midrange smartphone Buying a new device can be intimidating, but a few questions can help guide you through the process. First: what platform do you want to use? If the answer is iOS, that narrows your options down to exactly one phone. (Thankfully, it’s great.) And if you’re an Android fan, there’s no shortage of compelling options. Both platforms have their strengths, so you shouldn’t rule either out. Of course, also consider how much you’re comfortable spending. Even increasing your budget by $100 more can get you a dramatically better product. Moreover, manufacturers tend to support their more expensive devices for longer with software updates and security updates, so it’s worth buying something toward the top limit of what you can afford. Having an idea of your priorities will help inform your budget. Do you want a long battery life or fast charging? Do you value speedy performance above all else? Or would you like the best possible cameras with high megapixel counts? While they continue to improve every year, even the best midrange smartphones still demand some compromises, and knowing what’s important to you will make choosing one easier. What won’t you get from a midrange smartphone? Every year, the line between midrange and flagship phones blurs as more upmarket features and functions trickle down to more affordable models. When Engadget first published this guide in 2020, it was tricky to find a $500 phone with waterproofing and 5G. In 2026, the biggest thing you might miss out on is wireless charging – and even then, that’s becoming less true. One thing your new phone probably won’t come with is a power adapter; many companies have stopped including chargers with all of their smartphones. Performance has improved in recent years, but can still be hit or miss as most midrange phones use slower processors that can struggle with multitasking. Thankfully, their camera systems have improved dramatically, and you can typically expect at least a dual-lens system on most midrange smartphones below $600 with decent camera quality, selfie performance and software support to keep things running smoothly for years to come.. Midrange smartphone FAQs How long do midrange phones get software updates? Support varies by brand, but most midrange phones receive around three to five years of software and security updates. Apple tends to support iPhones longer while companies like Google and Samsung now promise several years of Android and security patches for their midrange models. Budget-focused brands might offer less so it’s worth checking the update policy before you buy. Are midrange phones good for gaming? Yes, many midrange phones handle gaming well, especially popular titles like Fortnite, Genshin Impact and Call of Duty Mobile. They usually include capable processors, though you won’t always get the smoothest performance in the most demanding mobile games or at max settings. If you play casually or stick to less graphically intensive titles a midrange phone will feel more than adequate. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-midrange-smartphone-183006463.html?src=rss",
          "feed_position": 21
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/asus-has-stopped-producing-the-nvidia-rtx-5070-ti-and-5060-ti-16gb-saying-theyve-reached-end-of-life-162012253.html",
          "published_at": "Thu, 15 Jan 2026 23:32:30 +0000",
          "title": "ASUS has stopped producing the NVIDIA RTX 5070 Ti and 5060 Ti 16GB, saying they've reached 'end of life'",
          "standfirst": "YouTube channel Hardware Unboxed is reporting that ASUS has stopped producing the RTX 5070 Ti and 5060 Ti 16GB due to the ongoing memory crunch. In its most recent video, the channel states ASUS “explicitly” told it the RTX 5070 Ti is “currently facing a supply shortage.” As a result, the company has “placed the model into end of life status,” and no longer plans to produce it. Hardware Unboxed also spoke to retailers in Australia, who told the channel the 5070 Ti is “no longer available to purchase from partners and distributors,” adding they expect that to be the case throughout at least the first quarter of the year. The 5060 Ti 16GB “is almost done as well,\" with ASUS stating it no longer plans to produce that model going forward either. Both GPUs are 16GB models, making them more expensive to manufacture in the current economic climate. And while there might be some hope of the 5070 Ti and 5060 Ti 16GB returning later this year, the channel suggests both are unlikely to make a comeback. “Demand for GeForce RTX GPUs is strong, and memory supply is constrained. We continue to ship all GeForce SKUs and are working closely with our suppliers to maximize memory availability,” a NVIDIA spokesperson told Engadget. ASUS did not immediately respond to Engadget’s comment request. After uploading its video, Hardware Unboxed published a clarification. “ASUS did not tell us that NVIDIA said the RTX 5070 Ti has been discontinued. ASUS told us there is very little supply of the 5070 Ti, so their own 5070 Ti products (e.g, the Prime and TUF Gaming) have been put into end of life status,” the channel said. “With retailers also unable to source 5070 Ti SKUs from any AIB, this effectively makes it a dead product.” The AI boom has created an insatiable demand for RAM and other computer components from data center infrastructure companies. In response, many memory manufacturers have shifted their production lines to focus on high bandwidth memory for those clients at the expense of their regular offerings, leading to dramatically increased prices among consumer RAM kits, GPUs and SSDs. In December, Micron Technology announced it would wind down its consumer-facing Crucial brand to focus exclusively on providing components to the AI industry. ASUS is the first of NVIDIA’s add-in board (AIB) partners to comment on the memory crunch. AIBs are the companies that produce the majority of GPUs you can buy from NVIDIA and AMD. Historically, NVIDIA has provided its board partners with both the die and memory needed to make a graphics cards. However, a recent rumor suggested the company had told it partners they would need to start sourcing memory on their own. Update 12:55PM ET: Added more context.Update 2:06PM ET: Added comment from NVIDIA. Update 6:31PM ET: Added additional comment from Hardware Unboxed.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/asus-has-stopped-producing-the-nvidia-rtx-5070-ti-and-5060-ti-16gb-saying-theyve-reached-end-of-life-162012253.html?src=rss",
          "content": "YouTube channel Hardware Unboxed is reporting that ASUS has stopped producing the RTX 5070 Ti and 5060 Ti 16GB due to the ongoing memory crunch. In its most recent video, the channel states ASUS “explicitly” told it the RTX 5070 Ti is “currently facing a supply shortage.” As a result, the company has “placed the model into end of life status,” and no longer plans to produce it. Hardware Unboxed also spoke to retailers in Australia, who told the channel the 5070 Ti is “no longer available to purchase from partners and distributors,” adding they expect that to be the case throughout at least the first quarter of the year. The 5060 Ti 16GB “is almost done as well,\" with ASUS stating it no longer plans to produce that model going forward either. Both GPUs are 16GB models, making them more expensive to manufacture in the current economic climate. And while there might be some hope of the 5070 Ti and 5060 Ti 16GB returning later this year, the channel suggests both are unlikely to make a comeback. “Demand for GeForce RTX GPUs is strong, and memory supply is constrained. We continue to ship all GeForce SKUs and are working closely with our suppliers to maximize memory availability,” a NVIDIA spokesperson told Engadget. ASUS did not immediately respond to Engadget’s comment request. After uploading its video, Hardware Unboxed published a clarification. “ASUS did not tell us that NVIDIA said the RTX 5070 Ti has been discontinued. ASUS told us there is very little supply of the 5070 Ti, so their own 5070 Ti products (e.g, the Prime and TUF Gaming) have been put into end of life status,” the channel said. “With retailers also unable to source 5070 Ti SKUs from any AIB, this effectively makes it a dead product.” The AI boom has created an insatiable demand for RAM and other computer components from data center infrastructure companies. In response, many memory manufacturers have shifted their production lines to focus on high bandwidth memory for those clients at the expense of their regular offerings, leading to dramatically increased prices among consumer RAM kits, GPUs and SSDs. In December, Micron Technology announced it would wind down its consumer-facing Crucial brand to focus exclusively on providing components to the AI industry. ASUS is the first of NVIDIA’s add-in board (AIB) partners to comment on the memory crunch. AIBs are the companies that produce the majority of GPUs you can buy from NVIDIA and AMD. Historically, NVIDIA has provided its board partners with both the die and memory needed to make a graphics cards. However, a recent rumor suggested the company had told it partners they would need to start sourcing memory on their own. Update 12:55PM ET: Added more context.Update 2:06PM ET: Added comment from NVIDIA. Update 6:31PM ET: Added additional comment from Hardware Unboxed.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/asus-has-stopped-producing-the-nvidia-rtx-5070-ti-and-5060-ti-16gb-saying-theyve-reached-end-of-life-162012253.html?src=rss",
          "feed_position": 24
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/science/space/senate-passes-minibus-bill-funding-nasa-rejecting-trumps-proposed-cuts-231605536.html",
          "published_at": "Thu, 15 Jan 2026 23:16:05 +0000",
          "title": "Senate passes minibus bill funding NASA, rejecting Trump's proposed cuts",
          "standfirst": "After a tumultuous 2025 that saw it lose around 4,000 employees, NASA finally has an operating budget for 2026, and one that largely preserves its scientific capabilities. On Thursday, the Senate passed an appropriations bill funding NASA, alongside the National Science Foundation and a handful of other federal agencies. Going into the appropriations process, the president called for a 24 percent year over year reduction to NASA's total operating budget. As part of that plan, the White House wanted to reduce the Science Mission Directorate's funding by nearly half, a move that would have forced NASA to cancel 55 ongoing and planned missions, including efforts like OSIRIS-APEX. The bill effectively rejects President Trump's plan, reducing NASA's total operating budget by just 1.6 percent year over year to $24.4 billion. Per the new appropriations, NASA's science budget will stand at $7.25 billion, 1.1 percent less relative to fiscal 2024, while shuffling the remaining funds to focus on different priorities. For instance, the House and Senate allocated $874 million (+8.7 percent) for the agency's heliophysics work; planetary sciences, which oversees missions like New Horizons, was cut to $2.5 billion (-6.5 percent) compared to 2024. At the same time, NASA's STEM engagement office, which the president proposed eliminating, escaped unscathed with its funding maintained at parity.\"It's almost everything we had been asking for, and it's very encouraging to see a House and Senate run by the president's own party agreeing that we need to keep investing in things like NASA science,\" says Casey Dreier, chief of policy at the Planetary Society, a nonprofit founded by Carl Sagan that advocates for the exploration and study of space. \"It contains very clear and direct language that not only is this funding made available to these projects, but that it will be spent on the initiatives that Congress states.\"Lawmakers also rejected Trump's effort to scuttle the Space Launch System after its third flight. NASA's heavy-lift rocket is billions of dollars over budget, but remains — as of now — the only spacecraft ready to ferry astronauts to the Moon. Compared to the rest of NASA, the fate of the SLS was never really in doubt. Senator Ted Cruz (R-TX) secured funding for the rocket as part of Trump's Big Beautiful Bill. \"I've been saying for a long time you should never underestimate the political coalition behind the SLS, and I think that was very much validated this year,\" says Dreier. More importantly, it appears the Goddard Space Flight Center will be safe from further damage. Over the summer, the future of the facility, known for its work on projects like the James Webb Space Telescope, was put in jeopardy. By some estimates, the campus has lost a third of its staff due to workforce cuts, and dozens of buildings, including some 100 laboratories, have been shut down by management. One of the casualties was NASA's largest library, which houses irreplaceable documents chronicling the history of the space race. As part of a \"consolidation\" effort, many of those documents will be thrown out.Under the appropriations bill, the Senate has directed NASA to “preserve all the technical and scientific world-class capabilities at Goddard.” It has also instructed the agency to ensure employees of the Goddard Institute for Space Studies are able to continue their work with \"minimal disruption.\" The New York-based office, one of America's leading climate labs, was sent into limbo last spring after the Trump administration moved to shut it down. The bill also provides a lifeline for NASA's to bring back samples of Martian dirt collected by the Perseverance rover. Congress has effectively cancelled the official program tied to that ambition, the Mars Sample Return (MSR), but has set aside $110 million for the agency to continue developing technologies for future science missions to the Red Planet. MSR advocates have argued the mission could lead to significant scientific discoveries, but Dreier notes the program was \"ripe for cancellation\" after it became mired in mismanagement. \"I worry MSR now has this stink of bloat, excess cost and threat of overruns that are really going to make it challenging to restart this without having a dramatically different approach,\" says Dreier, adding that deciding what to do with mission will likely be top of mind for the agency's new administrator, Jared Isaacman. The 2026 budget leaves NASA with fewer resources. Even in areas where Congress allocated the same amount of funds as it did in 2024, the agency will need to do more with less due to inflation. Compared to the absolute blood bath that would have been Trump's proposed budget, a marginal funding cut is the best case scenario given the circumstances, but the circumstances remain less than ideal. \"There will be another presidential budget request coming out in the next couple of months,\" Dreier said. \"They could do this all over again if they wanted to.\"In the immediate future, NASA and its employees are at least protected from the potential fallout of another impending government shutdown. Congress has until January 30 to fully fund the federal government, and as of earlier this week, it has yet to find a way forward on appropriations for agencies like the Department of Labor. Correction 9:05PM ET: A previous version of this article incorrectly stated Casey Dreier’s surename as Drier. We regret the error. This article originally appeared on Engadget at https://www.engadget.com/science/space/senate-passes-minibus-bill-funding-nasa-rejecting-trumps-proposed-cuts-231605536.html?src=rss",
          "content": "After a tumultuous 2025 that saw it lose around 4,000 employees, NASA finally has an operating budget for 2026, and one that largely preserves its scientific capabilities. On Thursday, the Senate passed an appropriations bill funding NASA, alongside the National Science Foundation and a handful of other federal agencies. Going into the appropriations process, the president called for a 24 percent year over year reduction to NASA's total operating budget. As part of that plan, the White House wanted to reduce the Science Mission Directorate's funding by nearly half, a move that would have forced NASA to cancel 55 ongoing and planned missions, including efforts like OSIRIS-APEX. The bill effectively rejects President Trump's plan, reducing NASA's total operating budget by just 1.6 percent year over year to $24.4 billion. Per the new appropriations, NASA's science budget will stand at $7.25 billion, 1.1 percent less relative to fiscal 2024, while shuffling the remaining funds to focus on different priorities. For instance, the House and Senate allocated $874 million (+8.7 percent) for the agency's heliophysics work; planetary sciences, which oversees missions like New Horizons, was cut to $2.5 billion (-6.5 percent) compared to 2024. At the same time, NASA's STEM engagement office, which the president proposed eliminating, escaped unscathed with its funding maintained at parity.\"It's almost everything we had been asking for, and it's very encouraging to see a House and Senate run by the president's own party agreeing that we need to keep investing in things like NASA science,\" says Casey Dreier, chief of policy at the Planetary Society, a nonprofit founded by Carl Sagan that advocates for the exploration and study of space. \"It contains very clear and direct language that not only is this funding made available to these projects, but that it will be spent on the initiatives that Congress states.\"Lawmakers also rejected Trump's effort to scuttle the Space Launch System after its third flight. NASA's heavy-lift rocket is billions of dollars over budget, but remains — as of now — the only spacecraft ready to ferry astronauts to the Moon. Compared to the rest of NASA, the fate of the SLS was never really in doubt. Senator Ted Cruz (R-TX) secured funding for the rocket as part of Trump's Big Beautiful Bill. \"I've been saying for a long time you should never underestimate the political coalition behind the SLS, and I think that was very much validated this year,\" says Dreier. More importantly, it appears the Goddard Space Flight Center will be safe from further damage. Over the summer, the future of the facility, known for its work on projects like the James Webb Space Telescope, was put in jeopardy. By some estimates, the campus has lost a third of its staff due to workforce cuts, and dozens of buildings, including some 100 laboratories, have been shut down by management. One of the casualties was NASA's largest library, which houses irreplaceable documents chronicling the history of the space race. As part of a \"consolidation\" effort, many of those documents will be thrown out.Under the appropriations bill, the Senate has directed NASA to “preserve all the technical and scientific world-class capabilities at Goddard.” It has also instructed the agency to ensure employees of the Goddard Institute for Space Studies are able to continue their work with \"minimal disruption.\" The New York-based office, one of America's leading climate labs, was sent into limbo last spring after the Trump administration moved to shut it down. The bill also provides a lifeline for NASA's to bring back samples of Martian dirt collected by the Perseverance rover. Congress has effectively cancelled the official program tied to that ambition, the Mars Sample Return (MSR), but has set aside $110 million for the agency to continue developing technologies for future science missions to the Red Planet. MSR advocates have argued the mission could lead to significant scientific discoveries, but Dreier notes the program was \"ripe for cancellation\" after it became mired in mismanagement. \"I worry MSR now has this stink of bloat, excess cost and threat of overruns that are really going to make it challenging to restart this without having a dramatically different approach,\" says Dreier, adding that deciding what to do with mission will likely be top of mind for the agency's new administrator, Jared Isaacman. The 2026 budget leaves NASA with fewer resources. Even in areas where Congress allocated the same amount of funds as it did in 2024, the agency will need to do more with less due to inflation. Compared to the absolute blood bath that would have been Trump's proposed budget, a marginal funding cut is the best case scenario given the circumstances, but the circumstances remain less than ideal. \"There will be another presidential budget request coming out in the next couple of months,\" Dreier said. \"They could do this all over again if they wanted to.\"In the immediate future, NASA and its employees are at least protected from the potential fallout of another impending government shutdown. Congress has until January 30 to fully fund the federal government, and as of earlier this week, it has yet to find a way forward on appropriations for agencies like the Department of Labor. Correction 9:05PM ET: A previous version of this article incorrectly stated Casey Dreier’s surename as Drier. We regret the error. This article originally appeared on Engadget at https://www.engadget.com/science/space/senate-passes-minibus-bill-funding-nasa-rejecting-trumps-proposed-cuts-231605536.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/flaw-in-17-google-fast-pair-audio-devices-could-let-hackers-eavesdrop-194613456.html",
          "published_at": "Thu, 15 Jan 2026 19:46:13 +0000",
          "title": "Flaw in 17 Google Fast Pair audio devices could let hackers eavesdrop",
          "standfirst": "Now would be a good time to update all your Bluetooth audio devices. On Thursday, Wired reported on a security flaw in 17 headphone and speaker models that could allow hackers to access your devices, including their microphones. The vulnerability stems from a faulty implementation of Google's one-tap (Fast Pair) protocol.Security researchers at Belgium's KU Leuven University Computer Security and Industrial Cryptography group, who discovered the security hole, named the flaw WhisperPair. They say a hacker within Bluetooth range would only require the accessory's (easily attainable) device model number and a few seconds.\"You're walking down the street with your headphones on, you're listening to some music. In less than 15 seconds, we can hijack your device,\" KU Leuven researcher Sayon Duttagupta told Wired. \"Which means that I can turn on the microphone and listen to your ambient sound. I can inject audio. I can track your location.\" The researchers notified Google about WhisperPair in August, and the company has been working with them since then.Fast Pair is supposed to only allow new connections while the audio device is in pairing mode. (A proper implementation of this would have prevented this flaw.) But a Google spokesperson told Engadget that the vulnerability stemmed from an improper implementation of Fast Pair by some of its hardware partners. This could then allow a hacker's device to pair with your headphones or speaker after it's already paired with your device.\"We appreciate collaborating with security researchers through our Vulnerability Rewards Program, which helps keep our users safe,\" a Google spokesperson wrote in a statement sent to Engadget. \"We worked with these researchers to fix these vulnerabilities, and we have not seen evidence of any exploitation outside of this report's lab setting. As a best security practice, we recommend users check their headphones for the latest firmware updates. We are constantly evaluating and enhancing Fast Pair and Find Hub security.\"The researchers created the video below to demonstrate how the flaw worksIn an email to Engadget, Google said the steps required to access the device’s microphone or audio are complex and involve multiple stages. The attackers would also need to remain within Bluetooth range. The company added that it provided its OEM partners with recommended fixes in September. Google also updated its Validator certification tool and its certification requirements.The researchers say that, in some cases, the risk applies even to those who don't use Android phones. For example, if the audio accessory has never been paired with a Google account, a hacker could use WhisperPair to not only pair with the audio device but also link it to their own Google account. They could then use Google's Find Hub tool to track the device's (and therefore your) location.Google said it rolled out a fix to its Find Hub network to address that particular scenario. However, the researchers told Wired that, within hours of the patch’s rollout, they found a workaround.The 17 affected devices are made by 10 different companies, all of which received Google Fast Pair certification. They include Sony, Jabra, JBL, Marshall, Xiaomi, Nothing, OnePlus, Soundcore, Logitech and Google. (Google says its affected Pixel Buds are already patched and protected.) The researchers posted a search tool that lets you see if your audio accessories are vulnerable.In a statement sent to Engadget, OnePlus said it's investigating the issue and \"will take appropriate action to protect our users' security and privacy.\" We also contacted the other accessory makers and will update this story if we hear back.The researchers recommend updating your audio devices regularly. However, one of their concerns is that many people will never install the third-party manufacturer's app (required for updates), leaving their devices vulnerable.The full report from Wired has much more detail and is worth a read.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/flaw-in-17-google-fast-pair-audio-devices-could-let-hackers-eavesdrop-194613456.html?src=rss",
          "content": "Now would be a good time to update all your Bluetooth audio devices. On Thursday, Wired reported on a security flaw in 17 headphone and speaker models that could allow hackers to access your devices, including their microphones. The vulnerability stems from a faulty implementation of Google's one-tap (Fast Pair) protocol.Security researchers at Belgium's KU Leuven University Computer Security and Industrial Cryptography group, who discovered the security hole, named the flaw WhisperPair. They say a hacker within Bluetooth range would only require the accessory's (easily attainable) device model number and a few seconds.\"You're walking down the street with your headphones on, you're listening to some music. In less than 15 seconds, we can hijack your device,\" KU Leuven researcher Sayon Duttagupta told Wired. \"Which means that I can turn on the microphone and listen to your ambient sound. I can inject audio. I can track your location.\" The researchers notified Google about WhisperPair in August, and the company has been working with them since then.Fast Pair is supposed to only allow new connections while the audio device is in pairing mode. (A proper implementation of this would have prevented this flaw.) But a Google spokesperson told Engadget that the vulnerability stemmed from an improper implementation of Fast Pair by some of its hardware partners. This could then allow a hacker's device to pair with your headphones or speaker after it's already paired with your device.\"We appreciate collaborating with security researchers through our Vulnerability Rewards Program, which helps keep our users safe,\" a Google spokesperson wrote in a statement sent to Engadget. \"We worked with these researchers to fix these vulnerabilities, and we have not seen evidence of any exploitation outside of this report's lab setting. As a best security practice, we recommend users check their headphones for the latest firmware updates. We are constantly evaluating and enhancing Fast Pair and Find Hub security.\"The researchers created the video below to demonstrate how the flaw worksIn an email to Engadget, Google said the steps required to access the device’s microphone or audio are complex and involve multiple stages. The attackers would also need to remain within Bluetooth range. The company added that it provided its OEM partners with recommended fixes in September. Google also updated its Validator certification tool and its certification requirements.The researchers say that, in some cases, the risk applies even to those who don't use Android phones. For example, if the audio accessory has never been paired with a Google account, a hacker could use WhisperPair to not only pair with the audio device but also link it to their own Google account. They could then use Google's Find Hub tool to track the device's (and therefore your) location.Google said it rolled out a fix to its Find Hub network to address that particular scenario. However, the researchers told Wired that, within hours of the patch’s rollout, they found a workaround.The 17 affected devices are made by 10 different companies, all of which received Google Fast Pair certification. They include Sony, Jabra, JBL, Marshall, Xiaomi, Nothing, OnePlus, Soundcore, Logitech and Google. (Google says its affected Pixel Buds are already patched and protected.) The researchers posted a search tool that lets you see if your audio accessories are vulnerable.In a statement sent to Engadget, OnePlus said it's investigating the issue and \"will take appropriate action to protect our users' security and privacy.\" We also contacted the other accessory makers and will update this story if we hear back.The researchers recommend updating your audio devices regularly. However, one of their concerns is that many people will never install the third-party manufacturer's app (required for updates), leaving their devices vulnerable.The full report from Wired has much more detail and is worth a read.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/flaw-in-17-google-fast-pair-audio-devices-could-let-hackers-eavesdrop-194613456.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/claude-code-just-got-updated-with-one-of-the-most-requested-user-features",
          "published_at": "Thu, 15 Jan 2026 19:37:00 GMT",
          "title": "Claude Code just got updated with one of the most-requested user features",
          "standfirst": "Anthropic&#x27;s open source standard, the Model Context Protocol (MCP), released in late 2024, allows users to connect AI models and the agents atop them to external tools in a structured, reliable format. It is the engine behind Anthropic&#x27;s hit AI agentic programming harness, Claude Code, allowing it to access numerous functions like web browsing and file creation immediately when asked.But there was one problem: Claude Code typically had to \"read\" the instruction manual for every single tool available, regardless of whether it was needed for the immediate task, using up the available context that could otherwise be filled with more information from the user&#x27;s prompts or the agent&#x27;s responses.At least until last night. The Claude Code team released an update that fundamentally alters this equation. Dubbed MCP Tool Search, the feature introduces \"lazy loading\" for AI tools, allowing agents to dynamically fetch tool definitions only when necessary. It is a shift that moves AI agents from a brute-force architecture to something resembling modern software engineering—and according to early data, it effectively solves the \"bloat\" problem that was threatening to stifle the ecosystem.The &#x27;Startup Tax&#x27; on AgentsTo understand the significance of Tool Search, one must understand the friction of the previous system. The Model Context Protocol (MCP), released in 2024 by Anthropic as an open source standard was designed to be a universal standard for connecting AI models to data sources and tools—everything from GitHub repositories to local file systems.However, as the ecosystem grew, so did the \"startup tax.\"Thariq Shihipar, a member of the technical staff at Anthropic, highlighted the scale of the problem in the announcement.\"We&#x27;ve found that MCP servers may have up to 50+ tools,\" Shihipar wrote. \"Users were documenting setups with 7+ servers consuming 67k+ tokens.\"In practical terms, this meant a developer using a robust set of tools might sacrifice 33% or more of their available context window limit of 200,000 tokens before they even typed a single character of a prompt, as AI newsletter author Aakash Gupta pointed out in a post on X.The model was effectively \"reading\" hundreds of pages of technical documentation for tools it might never use during that session.Community analysis provided even starker examples. Gupta further noted that a single Docker MCP server could consume 125,000 tokens just to define its 135 tools.\"The old constraint forced a brutal tradeoff,\" he wrote. \"Either limit your MCP servers to 2-3 core tools, or accept that half your context budget disappears before you start working.\"How Tool Search WorksThe solution Anthropic rolled out — which Shihipar called \"one of our most-requested features on GitHub\" — is elegant in its restraint. Instead of preloading every definition, Claude Code now monitors context usage.According to the release notes, the system automatically detects when tool descriptions would consume more than 10% of the available context. When that threshold is crossed, the system switches strategies. Instead of dumping raw documentation into the prompt, it loads a lightweight search index.When the user asks for a specific action—say, \"deploy this container\"—Claude Code doesn&#x27;t scan a massive, pre-loaded list of 200 commands. Instead, it queries the index, finds the relevant tool definition, and pulls only that specific tool into the context.\"Tool Search flips the architecture,\" Gupta analyzed. \"The token savings are dramatic: from ~134k to ~5k in Anthropic’s internal testing. That’s an 85% reduction while maintaining full tool access.\"For developers maintaining MCP servers, this shifts the optimization strategy. Shihipar noted that the `server instructions` field in the MCP definition—previously a \"nice to have\"—is now critical. It acts as the metadata that helps Claude \"know when to search for your tools, similar to skills.\"&#x27;Lazy Loading&#x27; and Accuracy GainsWhile the token savings are the headline metric—saving money and memory is always popular—the secondary effect of this update might be more important: focus.LLMs are notoriously sensitive to \"distraction.\" When a model&#x27;s context window is stuffed with thousands of lines of irrelevant tool definitions, its ability to reason decreases. It creates a \"needle in a haystack\" problem where the model struggles to differentiate between similar commands, such as `notification-send-user` versus `notification-send-channel`.Boris Cherny, Head of Claude Code, emphasized this in his reaction to the launch on X: \"Every Claude Code user just got way more context, better instruction following, and the ability to plug in even more tools.\"The data backs this up. Internal benchmarks shared by the community indicate that enabling Tool Search improved the accuracy of the Opus 4 model on MCP evaluations from 49% to 74%. For the newer Opus 4.5, accuracy jumped from 79.5% to 88.1%.By removing the noise of hundreds of unused tools, the model can dedicate its \"attention\" mechanisms to the user&#x27;s actual query and the relevant active tools.Maturing the StackThis update signals a maturation in how we treat AI infrastructure. In the early days of any software paradigm, brute force is common. But as systems scale, efficiency becomes the primary engineering challenge.Aakash Gupta drew a parallel to the evolution of Integrated Development Environments (IDEs) like VSCode or JetBrains. \"The bottleneck wasn’t &#x27;too many tools.&#x27; It was loading tool definitions like 2020-era static imports instead of 2024-era lazy loading,\" he wrote. \"VSCode doesn’t load every extension at startup. JetBrains doesn’t inject every plugin’s docs into memory.\"By adopting \"lazy loading\"—a standard best practice in web and software development—Anthropic is acknowledging that AI agents are no longer just novelties; they are complex software platforms that require architectural discipline.Implications for the EcosystemFor the end user, this update is seamless: Claude Code simply feels \"smarter\" and retains more memory of the conversation. But for the developer ecosystem, it opens the floodgates.Previously, there was a \"soft cap\" on how capable an agent could be. Developers had to curate their toolsets carefully to avoid lobotomizing the model with excessive context. With Tool Search, that ceiling is effectively removed. An agent can theoretically have access to thousands of tools—database connectors, cloud deployment scripts, API wrappers, local file manipulators—without paying a penalty until those tools are actually touched.It turns the \"context economy\" from a scarcity model into an access model. As Gupta summarized, \"They’re not just optimizing context usage. They’re changing what ‘tool-rich agents’ can mean.\"The update is rolling out immediately for Claude Code users. For developers building MCP clients, Anthropic recommends implementing the `ToolSearchTool` to support this dynamic loading, ensuring that as the agentic future arrives, it doesn&#x27;t run out of memory before it even says hello.",
          "content": "Anthropic&#x27;s open source standard, the Model Context Protocol (MCP), released in late 2024, allows users to connect AI models and the agents atop them to external tools in a structured, reliable format. It is the engine behind Anthropic&#x27;s hit AI agentic programming harness, Claude Code, allowing it to access numerous functions like web browsing and file creation immediately when asked.But there was one problem: Claude Code typically had to \"read\" the instruction manual for every single tool available, regardless of whether it was needed for the immediate task, using up the available context that could otherwise be filled with more information from the user&#x27;s prompts or the agent&#x27;s responses.At least until last night. The Claude Code team released an update that fundamentally alters this equation. Dubbed MCP Tool Search, the feature introduces \"lazy loading\" for AI tools, allowing agents to dynamically fetch tool definitions only when necessary. It is a shift that moves AI agents from a brute-force architecture to something resembling modern software engineering—and according to early data, it effectively solves the \"bloat\" problem that was threatening to stifle the ecosystem.The &#x27;Startup Tax&#x27; on AgentsTo understand the significance of Tool Search, one must understand the friction of the previous system. The Model Context Protocol (MCP), released in 2024 by Anthropic as an open source standard was designed to be a universal standard for connecting AI models to data sources and tools—everything from GitHub repositories to local file systems.However, as the ecosystem grew, so did the \"startup tax.\"Thariq Shihipar, a member of the technical staff at Anthropic, highlighted the scale of the problem in the announcement.\"We&#x27;ve found that MCP servers may have up to 50+ tools,\" Shihipar wrote. \"Users were documenting setups with 7+ servers consuming 67k+ tokens.\"In practical terms, this meant a developer using a robust set of tools might sacrifice 33% or more of their available context window limit of 200,000 tokens before they even typed a single character of a prompt, as AI newsletter author Aakash Gupta pointed out in a post on X.The model was effectively \"reading\" hundreds of pages of technical documentation for tools it might never use during that session.Community analysis provided even starker examples. Gupta further noted that a single Docker MCP server could consume 125,000 tokens just to define its 135 tools.\"The old constraint forced a brutal tradeoff,\" he wrote. \"Either limit your MCP servers to 2-3 core tools, or accept that half your context budget disappears before you start working.\"How Tool Search WorksThe solution Anthropic rolled out — which Shihipar called \"one of our most-requested features on GitHub\" — is elegant in its restraint. Instead of preloading every definition, Claude Code now monitors context usage.According to the release notes, the system automatically detects when tool descriptions would consume more than 10% of the available context. When that threshold is crossed, the system switches strategies. Instead of dumping raw documentation into the prompt, it loads a lightweight search index.When the user asks for a specific action—say, \"deploy this container\"—Claude Code doesn&#x27;t scan a massive, pre-loaded list of 200 commands. Instead, it queries the index, finds the relevant tool definition, and pulls only that specific tool into the context.\"Tool Search flips the architecture,\" Gupta analyzed. \"The token savings are dramatic: from ~134k to ~5k in Anthropic’s internal testing. That’s an 85% reduction while maintaining full tool access.\"For developers maintaining MCP servers, this shifts the optimization strategy. Shihipar noted that the `server instructions` field in the MCP definition—previously a \"nice to have\"—is now critical. It acts as the metadata that helps Claude \"know when to search for your tools, similar to skills.\"&#x27;Lazy Loading&#x27; and Accuracy GainsWhile the token savings are the headline metric—saving money and memory is always popular—the secondary effect of this update might be more important: focus.LLMs are notoriously sensitive to \"distraction.\" When a model&#x27;s context window is stuffed with thousands of lines of irrelevant tool definitions, its ability to reason decreases. It creates a \"needle in a haystack\" problem where the model struggles to differentiate between similar commands, such as `notification-send-user` versus `notification-send-channel`.Boris Cherny, Head of Claude Code, emphasized this in his reaction to the launch on X: \"Every Claude Code user just got way more context, better instruction following, and the ability to plug in even more tools.\"The data backs this up. Internal benchmarks shared by the community indicate that enabling Tool Search improved the accuracy of the Opus 4 model on MCP evaluations from 49% to 74%. For the newer Opus 4.5, accuracy jumped from 79.5% to 88.1%.By removing the noise of hundreds of unused tools, the model can dedicate its \"attention\" mechanisms to the user&#x27;s actual query and the relevant active tools.Maturing the StackThis update signals a maturation in how we treat AI infrastructure. In the early days of any software paradigm, brute force is common. But as systems scale, efficiency becomes the primary engineering challenge.Aakash Gupta drew a parallel to the evolution of Integrated Development Environments (IDEs) like VSCode or JetBrains. \"The bottleneck wasn’t &#x27;too many tools.&#x27; It was loading tool definitions like 2020-era static imports instead of 2024-era lazy loading,\" he wrote. \"VSCode doesn’t load every extension at startup. JetBrains doesn’t inject every plugin’s docs into memory.\"By adopting \"lazy loading\"—a standard best practice in web and software development—Anthropic is acknowledging that AI agents are no longer just novelties; they are complex software platforms that require architectural discipline.Implications for the EcosystemFor the end user, this update is seamless: Claude Code simply feels \"smarter\" and retains more memory of the conversation. But for the developer ecosystem, it opens the floodgates.Previously, there was a \"soft cap\" on how capable an agent could be. Developers had to curate their toolsets carefully to avoid lobotomizing the model with excessive context. With Tool Search, that ceiling is effectively removed. An agent can theoretically have access to thousands of tools—database connectors, cloud deployment scripts, API wrappers, local file manipulators—without paying a penalty until those tools are actually touched.It turns the \"context economy\" from a scarcity model into an access model. As Gupta summarized, \"They’re not just optimizing context usage. They’re changing what ‘tool-rich agents’ can mean.\"The update is rolling out immediately for Claude Code users. For developers building MCP clients, Anthropic recommends implementing the `ToolSearchTool` to support this dynamic loading, ensuring that as the agentic future arrives, it doesn&#x27;t run out of memory before it even says hello.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2O6Qr56XqUqVJ0oxVIN0iL/cbac7e02f806b97695bbc4df6b6fe226/Gemini_Generated_Image_autofiautofiauto.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/tv-movies/amazon-is-making-a-fallout-shelter-competition-reality-tv-show-190151855.html",
          "published_at": "Thu, 15 Jan 2026 19:01:51 +0000",
          "title": "Amazon is making a Fallout Shelter competition reality TV show",
          "standfirst": "The second season of Amazon's excellent Fallout show is currently airing, but the company is already looking to expand its programming around the popular franchise. Prime Video has greenlit a unscripted reality show titled Fallout Shelter. It will be a ten-episode run with Studio Lambert, the team behind reality projects including Squid Game: The Challenge and The Traitors, as its primary producer. Bethesda Game Studios’ head honcho Todd Howard is attached as an executive producer. Amazon's description of Fallout Shelter is: \"Across a series of escalating challenges, strategic dilemmas and moral crossroads, contestants must prove their ingenuity, teamwork and resilience as they compete for safety, power and ultimately a huge cash prize.\" It seems fitting that the producer is the same as Squid Game: The Challenge, where a show critiquing capitalism is turned into a competition about winning money. A reality show sounds like the sort of thing you'd find in a Fallout game side quest accompanied by pointed commentary about greed rather than an activity people of the Wasteland would take seriously. Maybe the new series will be an interesting mix of survival skills and dark humor that feels true to the Fallout ethos. But, and I say this as a big viewer of reality shows, I’m not holding my breath.The name echos the free-to-play mobile game Bethesda released in 2015. Fallout Shelter lets people build and improve their out Vault-Tec residence, managing the resources for a growing cadre of underground survivors. It seems pretty likely that there will be some type of tie-in between the game and the show, but any details about that might pop up closer to when the program is ready to air. It's currently casting, and no release timeline has been shared. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/amazon-is-making-a-fallout-shelter-competition-reality-tv-show-190151855.html?src=rss",
          "content": "The second season of Amazon's excellent Fallout show is currently airing, but the company is already looking to expand its programming around the popular franchise. Prime Video has greenlit a unscripted reality show titled Fallout Shelter. It will be a ten-episode run with Studio Lambert, the team behind reality projects including Squid Game: The Challenge and The Traitors, as its primary producer. Bethesda Game Studios’ head honcho Todd Howard is attached as an executive producer. Amazon's description of Fallout Shelter is: \"Across a series of escalating challenges, strategic dilemmas and moral crossroads, contestants must prove their ingenuity, teamwork and resilience as they compete for safety, power and ultimately a huge cash prize.\" It seems fitting that the producer is the same as Squid Game: The Challenge, where a show critiquing capitalism is turned into a competition about winning money. A reality show sounds like the sort of thing you'd find in a Fallout game side quest accompanied by pointed commentary about greed rather than an activity people of the Wasteland would take seriously. Maybe the new series will be an interesting mix of survival skills and dark humor that feels true to the Fallout ethos. But, and I say this as a big viewer of reality shows, I’m not holding my breath.The name echos the free-to-play mobile game Bethesda released in 2015. Fallout Shelter lets people build and improve their out Vault-Tec residence, managing the resources for a growing cadre of underground survivors. It seems pretty likely that there will be some type of tie-in between the game and the show, but any details about that might pop up closer to when the program is ready to air. It's currently casting, and no release timeline has been shared. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/amazon-is-making-a-fallout-shelter-competition-reality-tv-show-190151855.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/why-mongodb-thinks-better-retrieval-not-bigger-models-is-the-key-to",
          "published_at": "Thu, 15 Jan 2026 18:00:00 GMT",
          "title": "Why MongoDB thinks better retrieval — not bigger models — is the key to trustworthy enterprise AI",
          "standfirst": "Agentic systems and enterprise search depend on strong data retrieval that works efficiently and accurately. Database provider MongoDB thinks its newest embeddings models help solve falling retrieval quality as more AI systems go into production.As agentic and RAG systems move into production, retrieval quality is emerging as a quiet failure point — one that can undermine accuracy, cost, and user trust even when models themselves perform well.The company launched four new versions of its embeddings and reranking models. Voyage 4 will be available in four modes: voyage-4 embedding, voyage-4-large, voyage-4-lite, and voyage-4-nano. MongoDB said the voyage-4 embedding serves as its general-purpose model; MongoDB considers Voyage-4-large its flagship model. Voyage-4-lite focuses on tasks requiring little latency and lower costs, and voyage-4-nano is intended for more local development and testing environments or for on-device data retrieval. Voyage-4-nano is also MongoDB’s first open-weight model. All models are available via an API and on MongoDB’s Atlas platform. The company said the models outperform similar models from Google and Cohere on the RTEB benchmark. Hugging Face’s RTEB benchmark puts Voyage 4 as the top embedding model. “Embedding models are one of those invisible choices that can really make or break AI experiences,” Frank Liu, product manager at MongoDB, said in a briefing. “You get them wrong, your search results will feel pretty random and shallow, but if you get them right, your application suddenly feels like it understands your users and your data.”He added that the goal of the Voyage 4 models is to improve the retrieval of real-world data, which often collapses once agentic and RAG pipelines go into production. MongoDB also released a new multimodal embedding model, voyage-multimodal-3.5, that can handle documents that include text, images, and video. This model vectorizes the data and extracts semantic meaning from the tables, graphics, figures, and slides typically found in enterprise documents.Enterprise’s embeddings problemsFor enterprises, an agentic system is only as good as its ability to reliably retrieve the right information at the right time. This requirement becomes harder as workloads scale and context windows fragment.Several model providers target that layer of agentic AI. Google’s Gemini Embedding model topped the embedding leaderboards, and Cohere launched its Embed 4 multimodal model, which processes documents more than 200 pages long. Mistral said its coding-embedding model, Codestral Embedding, outperforms Cohere, Google, and even MongoDB’s Voyage Code 3. MongoDB argues that benchmark performance alone doesn’t address the operational complexity enterprises face in production.MongoDB said many clients have found that their data stacks cannot handle context-aware, retrieval-intensive workloads in production. The company said it&#x27;s seeing more fragmentation with enterprises having to stitch together different solutions to connect databases with a retrieval or reranking model. To help customers who don’t want fragmented solutions, the company is offering its models through a single data platform, Atlas. MongoDB’s bet is that retrieval can’t be treated as a loose collection of best-of-breed components anymore. For enterprise agents to work reliably at scale, embeddings, reranking, and the data layer need to operate as a tightly integrated system rather than a stitched-together stack.",
          "content": "Agentic systems and enterprise search depend on strong data retrieval that works efficiently and accurately. Database provider MongoDB thinks its newest embeddings models help solve falling retrieval quality as more AI systems go into production.As agentic and RAG systems move into production, retrieval quality is emerging as a quiet failure point — one that can undermine accuracy, cost, and user trust even when models themselves perform well.The company launched four new versions of its embeddings and reranking models. Voyage 4 will be available in four modes: voyage-4 embedding, voyage-4-large, voyage-4-lite, and voyage-4-nano. MongoDB said the voyage-4 embedding serves as its general-purpose model; MongoDB considers Voyage-4-large its flagship model. Voyage-4-lite focuses on tasks requiring little latency and lower costs, and voyage-4-nano is intended for more local development and testing environments or for on-device data retrieval. Voyage-4-nano is also MongoDB’s first open-weight model. All models are available via an API and on MongoDB’s Atlas platform. The company said the models outperform similar models from Google and Cohere on the RTEB benchmark. Hugging Face’s RTEB benchmark puts Voyage 4 as the top embedding model. “Embedding models are one of those invisible choices that can really make or break AI experiences,” Frank Liu, product manager at MongoDB, said in a briefing. “You get them wrong, your search results will feel pretty random and shallow, but if you get them right, your application suddenly feels like it understands your users and your data.”He added that the goal of the Voyage 4 models is to improve the retrieval of real-world data, which often collapses once agentic and RAG pipelines go into production. MongoDB also released a new multimodal embedding model, voyage-multimodal-3.5, that can handle documents that include text, images, and video. This model vectorizes the data and extracts semantic meaning from the tables, graphics, figures, and slides typically found in enterprise documents.Enterprise’s embeddings problemsFor enterprises, an agentic system is only as good as its ability to reliably retrieve the right information at the right time. This requirement becomes harder as workloads scale and context windows fragment.Several model providers target that layer of agentic AI. Google’s Gemini Embedding model topped the embedding leaderboards, and Cohere launched its Embed 4 multimodal model, which processes documents more than 200 pages long. Mistral said its coding-embedding model, Codestral Embedding, outperforms Cohere, Google, and even MongoDB’s Voyage Code 3. MongoDB argues that benchmark performance alone doesn’t address the operational complexity enterprises face in production.MongoDB said many clients have found that their data stacks cannot handle context-aware, retrieval-intensive workloads in production. The company said it&#x27;s seeing more fragmentation with enterprises having to stitch together different solutions to connect databases with a retrieval or reranking model. To help customers who don’t want fragmented solutions, the company is offering its models through a single data platform, Atlas. MongoDB’s bet is that retrieval can’t be treated as a loose collection of best-of-breed components anymore. For enterprise agents to work reliably at scale, embeddings, reranking, and the data layer need to operate as a tightly integrated system rather than a stitched-together stack.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3ahIcS5AJ5RCuVRg8hgyxx/86c2a7aa169e87babbfe7f7ffc3700a9/crimedy7_illustration_of_a_robot_poring_through_expense_repor_a03892f6-f441-4dab-a57b-8e664b411198_3.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/samsung-refreshed-mobile-gaming-hub-150010632.html",
          "published_at": "Thu, 15 Jan 2026 15:00:10 +0000",
          "title": "Samsung’s refreshed Mobile Gaming Hub is trying to make it easier to discover new games",
          "standfirst": "During CES 2026, Samsung unveiled plenty of new TVs, monitors and other hardware. However, the company is also looking to expand further into video games and has announced a significant refresh to its Gaming Hub on smartphones. Engadget spoke with Samsung’s Jong Woo, VP of Game Services, who explained that the update will offer more personalized, faster ways to play and place greater emphasis on up-and-coming titles. Now available on Galaxy devices, with further updates planned, the new hub wants to be a more active space for the latest mobile games. \"We believe that gamers want to find new content that is personalized to them,\" said the VP of Samsung Games Services. He continued: \"We want to bring content to users and make it immediately available for them to play. We have instant plays where, through our cloud streaming technology, we can take Android-native games and put them in the cloud, so that when users want to try them, they don't have to go through the friction of downloading them first.” According to Samsung, the mobile Gaming Hub attracts over 160 million users across smartphones and other devices. However, the VP of Game Services at Samsung believes that, despite the vast library of games across many genres available to mobile users, \"mobile game discovery is broken.\" Samsung Initially, the mobile Gaming Hub was a supplemental app for all purchased games, allowing users to track their collection. With this update, all games purchased from both Google Play and the Galaxy Store are stored in the Gaming Hub. It's designed to be a single place for players to view their owned games, find recommendations, access cloud streaming for select games and even watch highlights from content creators. According to Woo, the larger goal of the new Samsung mobile Gaming Hub is to personalize and guide the mobile gaming experience for players, which has remained nebulous compared with gaming discovery experiences on PC and consoles. “We're getting a lot of feedback from the users, a lot of it from focus testing and beta testing, and what we're finding is that we believe we are solving pain points for mobile gamers,\" said Woo about rebuilding the Gaming Hub. \"We're getting an idea of gamer preferences at the individual, personalized level. Based on all of that, we're able to provide different types of recommendations.\" Another reason for the new changes to the Samsung Gaming Hub was to help foster a community for mobile gamers, including players and developers. In addition to sharing YouTube videos and content from gaming creators and streamers, the company plans to add more social elements to the Gaming Hub to make mobile gaming feel more active and less isolating. \"Mobile is a very personal experience, right? It's your personal device, and oftentimes when you play games on mobile, it feels like a solitary experience,” said Woo. Currently, the revamped Mobile Gaming Hub is only available for Galaxy smartphones and tablets. Users on non-Galaxy devices will still use the previous version of the Gaming Hub, for now. Compared with PC and console online hubs like Steam and PlayStation Network, it's clear that mobile platforms are still figuring out how to create an equally compelling space for engagement. Even with the vast user base, mobile game hubs tend to be a go-between for users to get to the products. There's more work to do, but the new Gaming Hub could be the first step in the right direction.This article originally appeared on Engadget at https://www.engadget.com/gaming/samsung-refreshed-mobile-gaming-hub-150010632.html?src=rss",
          "content": "During CES 2026, Samsung unveiled plenty of new TVs, monitors and other hardware. However, the company is also looking to expand further into video games and has announced a significant refresh to its Gaming Hub on smartphones. Engadget spoke with Samsung’s Jong Woo, VP of Game Services, who explained that the update will offer more personalized, faster ways to play and place greater emphasis on up-and-coming titles. Now available on Galaxy devices, with further updates planned, the new hub wants to be a more active space for the latest mobile games. \"We believe that gamers want to find new content that is personalized to them,\" said the VP of Samsung Games Services. He continued: \"We want to bring content to users and make it immediately available for them to play. We have instant plays where, through our cloud streaming technology, we can take Android-native games and put them in the cloud, so that when users want to try them, they don't have to go through the friction of downloading them first.” According to Samsung, the mobile Gaming Hub attracts over 160 million users across smartphones and other devices. However, the VP of Game Services at Samsung believes that, despite the vast library of games across many genres available to mobile users, \"mobile game discovery is broken.\" Samsung Initially, the mobile Gaming Hub was a supplemental app for all purchased games, allowing users to track their collection. With this update, all games purchased from both Google Play and the Galaxy Store are stored in the Gaming Hub. It's designed to be a single place for players to view their owned games, find recommendations, access cloud streaming for select games and even watch highlights from content creators. According to Woo, the larger goal of the new Samsung mobile Gaming Hub is to personalize and guide the mobile gaming experience for players, which has remained nebulous compared with gaming discovery experiences on PC and consoles. “We're getting a lot of feedback from the users, a lot of it from focus testing and beta testing, and what we're finding is that we believe we are solving pain points for mobile gamers,\" said Woo about rebuilding the Gaming Hub. \"We're getting an idea of gamer preferences at the individual, personalized level. Based on all of that, we're able to provide different types of recommendations.\" Another reason for the new changes to the Samsung Gaming Hub was to help foster a community for mobile gamers, including players and developers. In addition to sharing YouTube videos and content from gaming creators and streamers, the company plans to add more social elements to the Gaming Hub to make mobile gaming feel more active and less isolating. \"Mobile is a very personal experience, right? It's your personal device, and oftentimes when you play games on mobile, it feels like a solitary experience,” said Woo. Currently, the revamped Mobile Gaming Hub is only available for Galaxy smartphones and tablets. Users on non-Galaxy devices will still use the previous version of the Gaming Hub, for now. Compared with PC and console online hubs like Steam and PlayStation Network, it's clear that mobile platforms are still figuring out how to create an equally compelling space for engagement. Even with the vast user base, mobile game hubs tend to be a go-between for users to get to the products. There's more work to do, but the new Gaming Hub could be the first step in the right direction.This article originally appeared on Engadget at https://www.engadget.com/gaming/samsung-refreshed-mobile-gaming-hub-150010632.html?src=rss",
          "feed_position": 38,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/963273a0-f211-11f0-bffa-698d12cdda28"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/robloxs-age-verification-system-is-reportedly-a-trainwreck-220320016.html",
          "published_at": "Thu, 15 Jan 2026 14:52:58 +0000",
          "title": "Roblox's age verification system is reportedly a trainwreck",
          "standfirst": "Roblox's age-verification system was designed as a response to allegations it has a child predator problem. Less than a week in, how's it going? Well, Wired reported on Tuesday that, in some cases, it's classifying children as adults and adults as children. So, not so great!Last week, Roblox made age verification mandatory for anyone using the platform's chat feature. That process involves either submitting a facial age estimate via selfie or (optionally for anyone 13 or older) uploading a government ID check. After verifying, you can only chat with groups of players around your age.The move came after reports grew of predators using the platform to groom young children. That, in turn, led to lawsuits from Louisiana, Texas and Kentucky. Meanwhile, Florida's attorney general has issued criminal subpoenas.So, it might not be hyperbole to say Roblox's survival could depend on how it handles this problem. It isn't exactly off to a hot start. There are reports of a 23-year-old being misidentified as a 16- to 17-year-old. (\"I don't want to be chatting with fucking children,\" they said.) Another report claimed an 18-year-old was placed in the 13 to 15 range.But the problem is happening in reverse, too. Online videos show children spoofing the system into believing they were adults by using avatar images. One clever kid drew wrinkles and stubble on his face and was instantly deemed 21+. Another flashed a photo of Kurt Cobain and got an adult classification.The feature isn't working as planned, to say the least.RobloxIn addition, Roblox posted last week that some parents were providing age checks on behalf of their children, leading to their children being placed in the 21+ category. The company said it's \"working on solutions to address\" that particular problem and will share more soon.Roblox shared the following statement from Matt Kaufman, the company’s Chief Safety Officer:“To suggest that our age check technology isn't working is a fundamental misunderstanding of what it takes to shift safety at scale. With a global community of over 150 million daily active users, we are pleased with where we are in the roll out process. It’s a process that will take time, you can’t flip a switch while building something that hasn’t existed before. Tens of millions of users have already completed the process, proving that the vast majority of our community values a safer, more age-appropriate environment. Expecting the system to be flawless overnight is ignoring the scale of this undertaking. We’ve already shared updates with our creator community to make this a smoother transition. This technology is the foundation of a new gold standard that limits communication between adults and minors by default. We are building for the next decade of the internet, not the next news cycle. We will continue to innovate, continue to require age checks, and continue to lead the industry where others have been too hesitant to go.”Developers with games on Roblox are upset. The platform's dev forum includes thousands of negative comments about the updates, with many of them wanting the entire update reversed. One shared a graph showing that the percentage using the chat feature dropped from around 90 percent to 36.5 percent.Where does this leave Roblox? Well, with some developers describing games on the platform as feeling \"lifeless\" or like \"a total ghost town,\" the company has its hands full. It will have to figure out how to balance its priorities of keeping predators out without breaking things for everyone else. The full report from Wired is worth a read.Update, January 15, 2026, 9:52AM ET: This story has been updated to include a statement from Roblox.This article originally appeared on Engadget at https://www.engadget.com/gaming/robloxs-age-verification-system-is-reportedly-a-trainwreck-220320016.html?src=rss",
          "content": "Roblox's age-verification system was designed as a response to allegations it has a child predator problem. Less than a week in, how's it going? Well, Wired reported on Tuesday that, in some cases, it's classifying children as adults and adults as children. So, not so great!Last week, Roblox made age verification mandatory for anyone using the platform's chat feature. That process involves either submitting a facial age estimate via selfie or (optionally for anyone 13 or older) uploading a government ID check. After verifying, you can only chat with groups of players around your age.The move came after reports grew of predators using the platform to groom young children. That, in turn, led to lawsuits from Louisiana, Texas and Kentucky. Meanwhile, Florida's attorney general has issued criminal subpoenas.So, it might not be hyperbole to say Roblox's survival could depend on how it handles this problem. It isn't exactly off to a hot start. There are reports of a 23-year-old being misidentified as a 16- to 17-year-old. (\"I don't want to be chatting with fucking children,\" they said.) Another report claimed an 18-year-old was placed in the 13 to 15 range.But the problem is happening in reverse, too. Online videos show children spoofing the system into believing they were adults by using avatar images. One clever kid drew wrinkles and stubble on his face and was instantly deemed 21+. Another flashed a photo of Kurt Cobain and got an adult classification.The feature isn't working as planned, to say the least.RobloxIn addition, Roblox posted last week that some parents were providing age checks on behalf of their children, leading to their children being placed in the 21+ category. The company said it's \"working on solutions to address\" that particular problem and will share more soon.Roblox shared the following statement from Matt Kaufman, the company’s Chief Safety Officer:“To suggest that our age check technology isn't working is a fundamental misunderstanding of what it takes to shift safety at scale. With a global community of over 150 million daily active users, we are pleased with where we are in the roll out process. It’s a process that will take time, you can’t flip a switch while building something that hasn’t existed before. Tens of millions of users have already completed the process, proving that the vast majority of our community values a safer, more age-appropriate environment. Expecting the system to be flawless overnight is ignoring the scale of this undertaking. We’ve already shared updates with our creator community to make this a smoother transition. This technology is the foundation of a new gold standard that limits communication between adults and minors by default. We are building for the next decade of the internet, not the next news cycle. We will continue to innovate, continue to require age checks, and continue to lead the industry where others have been too hesitant to go.”Developers with games on Roblox are upset. The platform's dev forum includes thousands of negative comments about the updates, with many of them wanting the entire update reversed. One shared a graph showing that the percentage using the chat feature dropped from around 90 percent to 36.5 percent.Where does this leave Roblox? Well, with some developers describing games on the platform as feeling \"lifeless\" or like \"a total ghost town,\" the company has its hands full. It will have to figure out how to balance its priorities of keeping predators out without breaking things for everyone else. The full report from Wired is worth a read.Update, January 15, 2026, 9:52AM ET: This story has been updated to include a statement from Roblox.This article originally appeared on Engadget at https://www.engadget.com/gaming/robloxs-age-verification-system-is-reportedly-a-trainwreck-220320016.html?src=rss",
          "feed_position": 39,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/EN_Age_Check_Flow_1_9823.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/nba-league-pass-subscriptions-are-up-to-55-percent-off-right-now-163421756.html",
          "published_at": "Thu, 15 Jan 2026 14:05:38 +0000",
          "title": "NBA League Pass subscriptions are up to 55 percent off right now",
          "standfirst": "Basketball fans can save on NBA League Pass right now, which lets you catch a bunch of out-of-market NBA games via streaming. The League Pass Premium subscription is on sale for $75, down from the usual $160, and League Pass Standard is marked down to $50 from $110. Considering we're almost halfway though the season, the discount makes sense and is a good deal for anyone who wants to keep a close eye on the rest of the games to be played this year. The Standard plan includes commercials and support for only one device at a time, while the Premium tier offers no commercials, in-arena streams during breaks in the game, offline viewing of full games and concurrent streams on up to three devices at once. Last year, League Pass added multiview, which allows you to view up to four games at once on a single screen. This is included across both subscription tiers. The service also added a smart rewind tool that automatically selects key highlights and plays from each game. Outside the US and Canada, League Pass carries every single NBA game live, but within these countries a bevy of restrictions apply. In the US, any games being shown on your regional sports network will be blacked out as the service is meant for out-of-market games only. Also, any nationally broadcast games will not be available live, but instead will be available for on-demand viewing at 6AM ET the following day. The service is only for regular-season games. If you're an avid NBA fan that follows multiple teams then the League Pass almost certainly carries dozens of games you can watch even with the restrictions in the US. Subscribers can get a list of applicable blackouts by entering their ZIP code before signing up. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/nba-league-pass-subscriptions-are-up-to-55-percent-off-right-now-163421756.html?src=rss",
          "content": "Basketball fans can save on NBA League Pass right now, which lets you catch a bunch of out-of-market NBA games via streaming. The League Pass Premium subscription is on sale for $75, down from the usual $160, and League Pass Standard is marked down to $50 from $110. Considering we're almost halfway though the season, the discount makes sense and is a good deal for anyone who wants to keep a close eye on the rest of the games to be played this year. The Standard plan includes commercials and support for only one device at a time, while the Premium tier offers no commercials, in-arena streams during breaks in the game, offline viewing of full games and concurrent streams on up to three devices at once. Last year, League Pass added multiview, which allows you to view up to four games at once on a single screen. This is included across both subscription tiers. The service also added a smart rewind tool that automatically selects key highlights and plays from each game. Outside the US and Canada, League Pass carries every single NBA game live, but within these countries a bevy of restrictions apply. In the US, any games being shown on your regional sports network will be blacked out as the service is meant for out-of-market games only. Also, any nationally broadcast games will not be available live, but instead will be available for on-demand viewing at 6AM ET the following day. The service is only for regular-season games. If you're an avid NBA fan that follows multiple teams then the League Pass almost certainly carries dozens of games you can watch even with the restrictions in the US. Subscribers can get a list of applicable blackouts by entering their ZIP code before signing up. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/nba-league-pass-subscriptions-are-up-to-55-percent-off-right-now-163421756.html?src=rss",
          "feed_position": 41
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/valerion-visionmaster-max-projector-review-near-perfect-image-quality-comes-at-a-price-140045939.html",
          "published_at": "Thu, 15 Jan 2026 14:00:45 +0000",
          "title": "Valerion VisionMaster Max projector review: Near-perfect image quality comes at a price",
          "standfirst": "After a widely hyped and successful Kickstarter campaign, Valerion’s 4K VisionMaster Max laser projector has finally arrived. It’s the company’s new flagship model in the VisionMaster series, offering better image quality and more convenience than its other models. However, it’s quite expensive and has some stiff competition from Anker’s Nebula X1 and XGIMI’s Horizon 20 Max. I was eager to see how it compared to those models and if it delivers on Valerion’s promise of “pure cinema.” It does offer better image quality, but the difference isn’t quite enough to justify the big jump in price for most users. Features and design The VisionMaster Max has a classy squarish design with a glossy black finish up front and chrome fins on the side that house two 12W speakers. It’s smaller and fit my decor better than Nebula’s tall, plasticky X1, though to be fair the latter is also designed for outdoor use. The VisionMaster Max has a similar form factor to XGIMI’s Horizon 20 Max, but that model pivots on its stand, while the Valerion uses a kickstand-like support. For setup, the VisionMaster Max is quite flexible. It comes with a 0.9-1.5x optical zoom, so it can be installed between 7.8 and 13 feet away for a 120-inch screen size, which covers a wide range of scenarios. It also features a +/- 105 percent vertical shift option that helps you get an optically perfect screen fit without moving the projector or employing digital “keystone” adjustments that affect picture quality. If that still doesn’t work, you can swap out the included lens with a long-throw 0.9-2.0:1 option once it becomes available. The company has even promised an anamorphic lens for users with CinemaScope screens. Both of those items will be available for purchase separately with the prices yet to be disclosed. Steve Dent for Engadget For my space, I placed the VisionMaster Max on a table about 12 feet from my 120-inch screen and centered it horizontally as there’s no horizontal shift option (it can also be ceiling mounted, of course). Then, I went into the auto-alignment setting, made sure that the projected image was larger than my screen and hit “start alignment” to get a perfect fit to my screen. Though it lacks a motorized lens gimbal like the Nebula X1, the lens shift option provides the same flexibility, so setup was just as easy. For inputs, the VisionMaster Max comes with three HDMI 2.1 ports, including one with eARC for a sound bar, along with S/PDIF optical and 3.5mm audio outputs. Impressively, it includes a gigabit ethernet connection so you can either hardwire it to the internet or connect via Wi-Fi. The VisionMaster Max lacks liquid cooling like the Nebula X1, but Valerion claims a similar fan noise level of 28db. When I compared them side by side, it was only a touch louder than the X1 and not at all bothersome. Google TV is built in for streaming and projector control via the high-quality, partially backlit remote. It provides a large library of apps via Google Play along with a familiar interface. You get certified versions of Netflix, YouTube, Prime Video, Disney+, Max and others, plus Chromecast and AirPlay support, and Google Assistant for voice control. With 4GB of RAM and 128GB of ROM, the software felt a bit more responsive than Google TV on the Nebula X1. Image quality Steve Dent for Engadget The VisionMaster Max has a number of features designed to optimize image quality. It’s one of the few consumer projectors with a dynamic iris and a feature called Enhanced Black Level (EBL) for improved contrast. It uses an RGB triple-laser light source (rated for 25,000 hours) paired with a 0.47-inch DLP chip that projects 1080p natively or 4K video via pixel shifting. This same chip is used on almost every consumer-level 4K projector, but XGIMI’s upcoming Titan Noir Max projector will pack a much larger 0.78-inch DMD chip that should deliver a sharper picture. The VisionMaster Max also supports every HDR format, including Dolby Vision and Samsung’s HDR10+, along with Valerion’s own tone-mapping HDR setting. You can choose from seven picture modes for SDR, eight for HDR, three for Dolby Vision and four for HDR10+. The projector handled most HDR content well, though it occasionally lost detail in extra-bright shots. However, that can largely be fixed using the extensive manual color controls. With all those features, the VisionMaster Max can output 4K 60 fps video at up to 3,500 ANSI lumens with a 50,000:1 contrast ratio, easily besting its main rivals. On top of that, it promises an impressive 110 percent of the Rec.2020 HDR color spectrum, with a delta E (color accuracy) value of less than 0.8 straight out of the box (any delta E less than 2 is undetectable by the human eye). Another key feature is reduction of the rainbow effect that can occur with DLP projectors. After some fine-tuning that’s typically required with new projectors, I was highly impressed with the image quality. Brightness was high enough in “standard” mode to watch content like sports or TV shows without lowering the blinds, and can be increased if you don’t mind compromising color accuracy. When used in ideal conditions like a darkened room, the VisionMaster Max’s image quality is the best of any projector I’ve tested to date. In Filmmaker mode (with the EBL setting enabled), contrast levels are outstanding, with true blacks showing in dark-lit scenes instead of the washed-out greys seen on most projectors. However, I kept the EBL mode at the minimum setting as I noticed it caused some color shifting at the other levels. Dynamic iris projectors can cause excessive “pumping” or sudden changes in light levels, but after adjusting the iris to a medium setting, I saw no signs of that. The famously dark Game of Thrones Night King battle scene was easy to see on the VisionMaster Max. Steve Dent for Engadget Color accuracy is outstanding straight out of the box both in HDR and non-HDR modes, particularly, again in Filmmaker mode. Visually, I couldn’t detect any anomalies when looking at color bars or other charts, though my Calibrite Color Checker told me that the gamut of hues was slightly less than what Valerion claims (under 100 percent of BT.2020). Still, the Max’s high color accuracy allowed me to see TV series and movies exactly as the filmmakers intended for a range of HDR and non-HDR movies including White Lotus season 3, Once Upon a Time in Hollywood, Andor and Dune 2. The projector’s excellent dynamic range and contrast revealed shadow details in Game of Thrones’ Night King battle, which has famously dark scenes that are difficult to see on some TVs. I have a slight amount of sensitivity to the “rainbow” effect, but the RBE Reduction feature effectively eliminated that visual artifact for me. However, it also introduced a slight amount of noise, so I disabled it. The feature might be a godsend for some users who are particularly susceptible, but it still needs a bit more refinement. Audio and gaming Of all the luxury projectors I’ve tested to date, the VisionMaster Max is the best for gaming — even compared to some dedicated models. It delivers latency as low as 4ms and a refresh rate up to 240Hz at 1080p, and 15ms for 4K at 60Hz. I tested a couple of PC titles including Cyberpunk 2077 and Hollow Knight: Silksong and found them to be as responsive as I’ve seen on any TV, but with far more immersion thanks to the huge, bright and color-accurate image. Steve Dent for Engadget You can output audio via the S/PDIF optical output, 3.5mm headphone jack, HDMI 2.1 ports and even USB 3.0 Type A ports. The built-in 12W stereo speakers work well and are fairly loud, so you can use them in a pinch. However, since it supports both DTS:X and Dolby Atmos, you’ll ideally want to connect it to a nice home theater audio system with support for at least 5.1 surround sound. In comparison, the Nebula X1 doesn’t have Dolby Atmos support, but it does give you the option to purchase and easily connect stereo Bluetooth speakers at a relatively cheap price. For around the same cost as the Valerion Max, Anker is also offering the Nebula X1 Pro that comes with a giant outdoor sound system and does support Dolby Atmos. Wrap-up The Valerion VisionMaster Max is a highly capable indoor projector that offers the best image quality I’ve seen thanks to the dynamic iris and Enhanced Black Level features. However, it’s also a lot more expensive than rival models at $5,000. It’s pretty hard to justify that extra money, unless you’re really fussy about picture accuracy and gaming performance, or need other features like the 1Gbps ethernet port. Most buyers would be better off spending a lot less on Valerion’s own $2,699 VisionMaster Pro2, Anker’s $2,999 Nebula X1 or the $2,999 XGIMI Horizon 20 Max. Again, the difference in picture quality is too slight to justify the huge price jump to the VisionMaster Max. You might also want to wait to see how much XGIMI’s incoming Titan Noir Max 4K costs, as it also offers a dynamic iris but has a much bigger DLP chip.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/valerion-visionmaster-max-projector-review-near-perfect-image-quality-comes-at-a-price-140045939.html?src=rss",
          "content": "After a widely hyped and successful Kickstarter campaign, Valerion’s 4K VisionMaster Max laser projector has finally arrived. It’s the company’s new flagship model in the VisionMaster series, offering better image quality and more convenience than its other models. However, it’s quite expensive and has some stiff competition from Anker’s Nebula X1 and XGIMI’s Horizon 20 Max. I was eager to see how it compared to those models and if it delivers on Valerion’s promise of “pure cinema.” It does offer better image quality, but the difference isn’t quite enough to justify the big jump in price for most users. Features and design The VisionMaster Max has a classy squarish design with a glossy black finish up front and chrome fins on the side that house two 12W speakers. It’s smaller and fit my decor better than Nebula’s tall, plasticky X1, though to be fair the latter is also designed for outdoor use. The VisionMaster Max has a similar form factor to XGIMI’s Horizon 20 Max, but that model pivots on its stand, while the Valerion uses a kickstand-like support. For setup, the VisionMaster Max is quite flexible. It comes with a 0.9-1.5x optical zoom, so it can be installed between 7.8 and 13 feet away for a 120-inch screen size, which covers a wide range of scenarios. It also features a +/- 105 percent vertical shift option that helps you get an optically perfect screen fit without moving the projector or employing digital “keystone” adjustments that affect picture quality. If that still doesn’t work, you can swap out the included lens with a long-throw 0.9-2.0:1 option once it becomes available. The company has even promised an anamorphic lens for users with CinemaScope screens. Both of those items will be available for purchase separately with the prices yet to be disclosed. Steve Dent for Engadget For my space, I placed the VisionMaster Max on a table about 12 feet from my 120-inch screen and centered it horizontally as there’s no horizontal shift option (it can also be ceiling mounted, of course). Then, I went into the auto-alignment setting, made sure that the projected image was larger than my screen and hit “start alignment” to get a perfect fit to my screen. Though it lacks a motorized lens gimbal like the Nebula X1, the lens shift option provides the same flexibility, so setup was just as easy. For inputs, the VisionMaster Max comes with three HDMI 2.1 ports, including one with eARC for a sound bar, along with S/PDIF optical and 3.5mm audio outputs. Impressively, it includes a gigabit ethernet connection so you can either hardwire it to the internet or connect via Wi-Fi. The VisionMaster Max lacks liquid cooling like the Nebula X1, but Valerion claims a similar fan noise level of 28db. When I compared them side by side, it was only a touch louder than the X1 and not at all bothersome. Google TV is built in for streaming and projector control via the high-quality, partially backlit remote. It provides a large library of apps via Google Play along with a familiar interface. You get certified versions of Netflix, YouTube, Prime Video, Disney+, Max and others, plus Chromecast and AirPlay support, and Google Assistant for voice control. With 4GB of RAM and 128GB of ROM, the software felt a bit more responsive than Google TV on the Nebula X1. Image quality Steve Dent for Engadget The VisionMaster Max has a number of features designed to optimize image quality. It’s one of the few consumer projectors with a dynamic iris and a feature called Enhanced Black Level (EBL) for improved contrast. It uses an RGB triple-laser light source (rated for 25,000 hours) paired with a 0.47-inch DLP chip that projects 1080p natively or 4K video via pixel shifting. This same chip is used on almost every consumer-level 4K projector, but XGIMI’s upcoming Titan Noir Max projector will pack a much larger 0.78-inch DMD chip that should deliver a sharper picture. The VisionMaster Max also supports every HDR format, including Dolby Vision and Samsung’s HDR10+, along with Valerion’s own tone-mapping HDR setting. You can choose from seven picture modes for SDR, eight for HDR, three for Dolby Vision and four for HDR10+. The projector handled most HDR content well, though it occasionally lost detail in extra-bright shots. However, that can largely be fixed using the extensive manual color controls. With all those features, the VisionMaster Max can output 4K 60 fps video at up to 3,500 ANSI lumens with a 50,000:1 contrast ratio, easily besting its main rivals. On top of that, it promises an impressive 110 percent of the Rec.2020 HDR color spectrum, with a delta E (color accuracy) value of less than 0.8 straight out of the box (any delta E less than 2 is undetectable by the human eye). Another key feature is reduction of the rainbow effect that can occur with DLP projectors. After some fine-tuning that’s typically required with new projectors, I was highly impressed with the image quality. Brightness was high enough in “standard” mode to watch content like sports or TV shows without lowering the blinds, and can be increased if you don’t mind compromising color accuracy. When used in ideal conditions like a darkened room, the VisionMaster Max’s image quality is the best of any projector I’ve tested to date. In Filmmaker mode (with the EBL setting enabled), contrast levels are outstanding, with true blacks showing in dark-lit scenes instead of the washed-out greys seen on most projectors. However, I kept the EBL mode at the minimum setting as I noticed it caused some color shifting at the other levels. Dynamic iris projectors can cause excessive “pumping” or sudden changes in light levels, but after adjusting the iris to a medium setting, I saw no signs of that. The famously dark Game of Thrones Night King battle scene was easy to see on the VisionMaster Max. Steve Dent for Engadget Color accuracy is outstanding straight out of the box both in HDR and non-HDR modes, particularly, again in Filmmaker mode. Visually, I couldn’t detect any anomalies when looking at color bars or other charts, though my Calibrite Color Checker told me that the gamut of hues was slightly less than what Valerion claims (under 100 percent of BT.2020). Still, the Max’s high color accuracy allowed me to see TV series and movies exactly as the filmmakers intended for a range of HDR and non-HDR movies including White Lotus season 3, Once Upon a Time in Hollywood, Andor and Dune 2. The projector’s excellent dynamic range and contrast revealed shadow details in Game of Thrones’ Night King battle, which has famously dark scenes that are difficult to see on some TVs. I have a slight amount of sensitivity to the “rainbow” effect, but the RBE Reduction feature effectively eliminated that visual artifact for me. However, it also introduced a slight amount of noise, so I disabled it. The feature might be a godsend for some users who are particularly susceptible, but it still needs a bit more refinement. Audio and gaming Of all the luxury projectors I’ve tested to date, the VisionMaster Max is the best for gaming — even compared to some dedicated models. It delivers latency as low as 4ms and a refresh rate up to 240Hz at 1080p, and 15ms for 4K at 60Hz. I tested a couple of PC titles including Cyberpunk 2077 and Hollow Knight: Silksong and found them to be as responsive as I’ve seen on any TV, but with far more immersion thanks to the huge, bright and color-accurate image. Steve Dent for Engadget You can output audio via the S/PDIF optical output, 3.5mm headphone jack, HDMI 2.1 ports and even USB 3.0 Type A ports. The built-in 12W stereo speakers work well and are fairly loud, so you can use them in a pinch. However, since it supports both DTS:X and Dolby Atmos, you’ll ideally want to connect it to a nice home theater audio system with support for at least 5.1 surround sound. In comparison, the Nebula X1 doesn’t have Dolby Atmos support, but it does give you the option to purchase and easily connect stereo Bluetooth speakers at a relatively cheap price. For around the same cost as the Valerion Max, Anker is also offering the Nebula X1 Pro that comes with a giant outdoor sound system and does support Dolby Atmos. Wrap-up The Valerion VisionMaster Max is a highly capable indoor projector that offers the best image quality I’ve seen thanks to the dynamic iris and Enhanced Black Level features. However, it’s also a lot more expensive than rival models at $5,000. It’s pretty hard to justify that extra money, unless you’re really fussy about picture accuracy and gaming performance, or need other features like the 1Gbps ethernet port. Most buyers would be better off spending a lot less on Valerion’s own $2,699 VisionMaster Pro2, Anker’s $2,999 Nebula X1 or the $2,999 XGIMI Horizon 20 Max. Again, the difference in picture quality is too slight to justify the huge price jump to the VisionMaster Max. You might also want to wait to see how much XGIMI’s incoming Titan Noir Max 4K costs, as it also offers a dynamic iris but has a much bigger DLP chip.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/valerion-visionmaster-max-projector-review-near-perfect-image-quality-comes-at-a-price-140045939.html?src=rss",
          "feed_position": 42,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/89dc1780-f1e6-11f0-8fff-30947e843542"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/music/spotifys-getting-a-buck-more-expensive-in-february-132300118.html",
          "published_at": "Thu, 15 Jan 2026 13:23:00 +0000",
          "title": "Spotify is getting a buck more expensive in February",
          "standfirst": "Spotify is raising the prices for its premium subscriptions by $1 to $2 across the board, starting this February. Those are similar figures to the company’s last price hike in 2024. Subscribers across the US, Estonia and Latvia will soon receive an email, notifying them that they’ll be paying a larger amount for their February bill. The streaming service said it’s raising its prices occasionally to “reflect the value that Spotify delivers,” “to continue offering the best possible experience” and to “benefit artists.” It reported last year that it paid out $10 billion to music rights-holders in 2024. However, it’s worth noting that several Grammy-nominated songwriters boycotted an awards event it hosted to protest the supposed decreasing royalties songwriters are getting from Spotify plays. Subscribers who choose to keep their accounts will now have to pay $13 instead of $12 a month for an individual plan or $7 instead of $6 for a student plan. The Duo plan will now cost users $19 a month instead of $17, while the Family plan will cost them $22, up $2 from its previous price of $20. Meanwhile, those who decide to cancel their plans can follow our guide right here. Spotify came under fire late last year for running recruitment ads for ICE. It said the advertisements were part of a larger campaign by the US government that ran across platforms, including Meta and Google. The company also recently confirmed that the campaign has ended that there are no ICE ads currently running on the service. This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-getting-a-buck-more-expensive-in-february-132300118.html?src=rss",
          "content": "Spotify is raising the prices for its premium subscriptions by $1 to $2 across the board, starting this February. Those are similar figures to the company’s last price hike in 2024. Subscribers across the US, Estonia and Latvia will soon receive an email, notifying them that they’ll be paying a larger amount for their February bill. The streaming service said it’s raising its prices occasionally to “reflect the value that Spotify delivers,” “to continue offering the best possible experience” and to “benefit artists.” It reported last year that it paid out $10 billion to music rights-holders in 2024. However, it’s worth noting that several Grammy-nominated songwriters boycotted an awards event it hosted to protest the supposed decreasing royalties songwriters are getting from Spotify plays. Subscribers who choose to keep their accounts will now have to pay $13 instead of $12 a month for an individual plan or $7 instead of $6 for a student plan. The Duo plan will now cost users $19 a month instead of $17, while the Family plan will cost them $22, up $2 from its previous price of $20. Meanwhile, those who decide to cancel their plans can follow our guide right here. Spotify came under fire late last year for running recruitment ads for ICE. It said the advertisements were part of a larger campaign by the US government that ran across platforms, including Meta and Google. The company also recently confirmed that the campaign has ended that there are no ICE ads currently running on the service. This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-getting-a-buck-more-expensive-in-february-132300118.html?src=rss",
          "feed_position": 45
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/get-up-to-90-off-remarkable-e-ink-tablet-bundles-150242530.html",
          "published_at": "Thu, 15 Jan 2026 13:21:27 +0000",
          "title": "Get up to $90 off reMarkable E Ink tablet bundles",
          "standfirst": "E Ink tablets can provide the best of both worlds, giving you a similar tactile response to writing with pen and paper while also conveniently holding all of your digital files. reMarkable has a new year sale going on right now on its E Ink tablets, where you can save between $70 and $90 on a bundle, depending on the configuration you choose. For example, you can get the reMarkable 2 tablet with the Marker and Book Folio for $449, instead of the usual $568. The company also sells a newer stylus called Marker Plus that lets you erase by flipping it around just like a real pencil, but that will cost you an extra $50. If you’ve been eyeing a dedicated writing tablet for work, school or just jotting down notes without the distraction of endless apps, this bundle deal is an ideal opportunity to pick one up. The reMarkable 2 earned our top pick for best e-ink tablet. In our review, we said the tablet was prettier than ever with a 10.3-inch display and a handsome aluminum frame. The tablet is only 4.7mm thick and weighs less than a pound, helping it feel lean and portable. The display can detect over 4,000 different levels of pressure with the Marker stylus, allowing for precise shading when sketching and the latency between the stylus and the screen is just 21ms. reMarkable fitted the display with a resin layer on top of the glass to make writing on it feel more realistic. We didn't think this passed muster, but we found writing on it was a joy nonetheless. The tablet supports PDFs and ePUBs, which can be added via the companion mobile app or a desktop computer. You can also pair the reMarkable 2 with Google Drive, Microsoft OneDrive or Dropbox to access files. The battery is rated for an impressive two weeks between charges. The reMarkable Paper Pro, a higher-end model with a richer feature set like a full color display and a built-in reading light, is our pick for best premium e-ink tablet. The pricier tablet also has bundle deals right now with savings up to $80 depending on configuration. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/get-up-to-90-off-remarkable-e-ink-tablet-bundles-150242530.html?src=rss",
          "content": "E Ink tablets can provide the best of both worlds, giving you a similar tactile response to writing with pen and paper while also conveniently holding all of your digital files. reMarkable has a new year sale going on right now on its E Ink tablets, where you can save between $70 and $90 on a bundle, depending on the configuration you choose. For example, you can get the reMarkable 2 tablet with the Marker and Book Folio for $449, instead of the usual $568. The company also sells a newer stylus called Marker Plus that lets you erase by flipping it around just like a real pencil, but that will cost you an extra $50. If you’ve been eyeing a dedicated writing tablet for work, school or just jotting down notes without the distraction of endless apps, this bundle deal is an ideal opportunity to pick one up. The reMarkable 2 earned our top pick for best e-ink tablet. In our review, we said the tablet was prettier than ever with a 10.3-inch display and a handsome aluminum frame. The tablet is only 4.7mm thick and weighs less than a pound, helping it feel lean and portable. The display can detect over 4,000 different levels of pressure with the Marker stylus, allowing for precise shading when sketching and the latency between the stylus and the screen is just 21ms. reMarkable fitted the display with a resin layer on top of the glass to make writing on it feel more realistic. We didn't think this passed muster, but we found writing on it was a joy nonetheless. The tablet supports PDFs and ePUBs, which can be added via the companion mobile app or a desktop computer. You can also pair the reMarkable 2 with Google Drive, Microsoft OneDrive or Dropbox to access files. The battery is rated for an impressive two weeks between charges. The reMarkable Paper Pro, a higher-end model with a richer feature set like a full color display and a built-in reading light, is our pick for best premium e-ink tablet. The pricier tablet also has bundle deals right now with savings up to $80 depending on configuration. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/get-up-to-90-off-remarkable-e-ink-tablet-bundles-150242530.html?src=rss",
          "feed_position": 46
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/airtags-drop-back-down-to-65-for-a-four-pack-202333775.html",
          "published_at": "Thu, 15 Jan 2026 13:02:12 +0000",
          "title": "AirTags drop back down to $65 for a four-pack",
          "standfirst": "Apple keeps most of its product pricing on a tight leash, but we do see the company's AirTags go on sale pretty frequently. Another cost cut has come around for this item just in time for the holidays. Amazon is currently selling a four-pack of AirTags for $65. At a third off the regular cost, that price is pretty close to the record low discount of $63 we've seen for these Bluetooth trackers. AirTags can be useful for people who travel frequently, helping you to keep track of essentials like your passport as well as a way to keep tabs on luggage while you're on the go. If you do purchase some AirTags, we have some recommendations for useful accessories to go along with them, such as different styles of cases to best attach the trackers to different types of items. These are worth looking over and adding to your shopping cart in order to make the most of the product. AirTags have an IP67 rating for water and dust resistance and their replaceable batteries should last for about a year. They can also support Precision Finding, which gives more exact directions to a lost item, when paired with most models after the iPhone 11. Up to five people can share an AirTag's location, which is helpful for families or large travel groups. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/airtags-drop-back-down-to-65-for-a-four-pack-202333775.html?src=rss",
          "content": "Apple keeps most of its product pricing on a tight leash, but we do see the company's AirTags go on sale pretty frequently. Another cost cut has come around for this item just in time for the holidays. Amazon is currently selling a four-pack of AirTags for $65. At a third off the regular cost, that price is pretty close to the record low discount of $63 we've seen for these Bluetooth trackers. AirTags can be useful for people who travel frequently, helping you to keep track of essentials like your passport as well as a way to keep tabs on luggage while you're on the go. If you do purchase some AirTags, we have some recommendations for useful accessories to go along with them, such as different styles of cases to best attach the trackers to different types of items. These are worth looking over and adding to your shopping cart in order to make the most of the product. AirTags have an IP67 rating for water and dust resistance and their replaceable batteries should last for about a year. They can also support Precision Finding, which gives more exact directions to a lost item, when paired with most models after the iPhone 11. Up to five people can share an AirTag's location, which is helpful for families or large travel groups. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/airtags-drop-back-down-to-65-for-a-four-pack-202333775.html?src=rss",
          "feed_position": 47
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/ftc-finalizes-gm-punishment-over-driver-data-sharing-scandal-130012313.html",
          "published_at": "Thu, 15 Jan 2026 13:00:12 +0000",
          "title": "FTC finalizes GM punishment over driver data sharing scandal",
          "standfirst": "After reaching a proposed settlement last year, the FTC has banned General Motors from sharing specific consumer data with third parties, TechCrunch reported. The finalized order wraps up one of the more egregious cases of a corporation collecting its customers' data and then using it against them. Two years ago, the New York Times report released a report detailing how GM's OnStar \"Smart Driver\" program collected and sold detailed geolocation and driving behavior data to third parties, including data brokers. Those brokers in turn sold the data to insurance providers, which jacked up the rates for some drivers based on the data. \"It felt like a betrayal,\" said a Chevy Bolt owner that saw his insurance rise by 21 percent based on the data. \"They’re taking information that I didn’t realize was going to be shared and screwing with our insurance.\" According to the terms of the settlement, GM is barred from sharing specific user data with consumer reporting agencies for a five year period. The automaker is also required to request user permission before collecting, using or sharing vehicle data with any third party. It must do that when a consumer purchases a car at a dealership, with the customer asked in person whether they agree or not with the data collection, GM said. Some of the settlement is moot as GM stopped its Smart Driver program for all brands in April 2024. The company unenrolled all customers and stopped its third-party relationship with LexisNexis and Verisk, the brokers that sold driver data to insurance companies. GM faced other actions over the data collection, including lawsuits from Texas, Nebraska and other states. \"Our investigation revealed that General Motors has engaged in egregious business practices that violated Texans’ privacy and broke the law. We will hold them accountable,\" said Texas AG Ken Paxton at the time. In a statement to TechCrunch, GM said: \"The Federal Trade Commission has formally approved the agreement reached last year with General Motors to address concerns. As vehicle connectivity becomes increasingly integral to the driving experience, GM remains committed to protecting customer privacy, maintaining trust, and ensuring customers have a clear understanding of our practices.\" This article originally appeared on Engadget at https://www.engadget.com/transportation/ftc-finalizes-gm-punishment-over-driver-data-sharing-scandal-130012313.html?src=rss",
          "content": "After reaching a proposed settlement last year, the FTC has banned General Motors from sharing specific consumer data with third parties, TechCrunch reported. The finalized order wraps up one of the more egregious cases of a corporation collecting its customers' data and then using it against them. Two years ago, the New York Times report released a report detailing how GM's OnStar \"Smart Driver\" program collected and sold detailed geolocation and driving behavior data to third parties, including data brokers. Those brokers in turn sold the data to insurance providers, which jacked up the rates for some drivers based on the data. \"It felt like a betrayal,\" said a Chevy Bolt owner that saw his insurance rise by 21 percent based on the data. \"They’re taking information that I didn’t realize was going to be shared and screwing with our insurance.\" According to the terms of the settlement, GM is barred from sharing specific user data with consumer reporting agencies for a five year period. The automaker is also required to request user permission before collecting, using or sharing vehicle data with any third party. It must do that when a consumer purchases a car at a dealership, with the customer asked in person whether they agree or not with the data collection, GM said. Some of the settlement is moot as GM stopped its Smart Driver program for all brands in April 2024. The company unenrolled all customers and stopped its third-party relationship with LexisNexis and Verisk, the brokers that sold driver data to insurance companies. GM faced other actions over the data collection, including lawsuits from Texas, Nebraska and other states. \"Our investigation revealed that General Motors has engaged in egregious business practices that violated Texans’ privacy and broke the law. We will hold them accountable,\" said Texas AG Ken Paxton at the time. In a statement to TechCrunch, GM said: \"The Federal Trade Commission has formally approved the agreement reached last year with General Motors to address concerns. As vehicle connectivity becomes increasingly integral to the driving experience, GM remains committed to protecting customer privacy, maintaining trust, and ensuring customers have a clear understanding of our practices.\" This article originally appeared on Engadget at https://www.engadget.com/transportation/ftc-finalizes-gm-punishment-over-driver-data-sharing-scandal-130012313.html?src=rss",
          "feed_position": 48
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/breaking-through-ais-memory-wall-with-token-warehousing",
          "published_at": "Thu, 15 Jan 2026 05:00:00 GMT",
          "title": "Breaking through AI’s memory wall with token warehousing",
          "standfirst": "As agentic AI moves from experiments to real production workloads, a quiet but serious infrastructure problem is coming into focus: memory. Not compute. Not models. Memory.Under the hood, today’s GPUs simply don’t have enough space to hold the Key-Value (KV) caches that modern, long-running AI agents depend on to maintain context. The result is a lot of invisible waste — GPUs redoing work they’ve already done, cloud costs climbing, and performance taking a hit. It’s a problem that’s already showing up in production environments, even if most people haven’t named it yet.At a recent stop on the VentureBeat AI Impact Series, WEKA CTO Shimon Ben-David joined VentureBeat CEO Matt Marshall to unpack the industry’s emerging “memory wall,” and why it’s becoming one of the biggest blockers to scaling truly stateful agentic AI — systems that can remember and build on context over time. The conversation didn’t just diagnose the issue; it laid out a new way to think about memory entirely, through an approach WEKA calls token warehousing.The GPU memory problem“When we&#x27;re looking at the infrastructure of inferencing, it is not a GPU cycles challenge. It&#x27;s mostly a GPU memory problem,” said Ben-David. The root of the issue comes down to how transformer models work. To generate responses, they rely on KV caches that store contextual information for every token in a conversation. The longer the context window, the more memory those caches consume, and it adds up fast. A single 100,000-token sequence can require roughly 40GB of GPU memory, noted Ben-David.That wouldn’t be a problem if GPUs had unlimited memory. But they don’t. Even the most advanced GPUs top out at around 288GB of high-bandwidth memory (HBM), and that space also has to hold the model itself. In real-world, multi-tenant inference environments, this becomes painful quickly. Workloads like code development or processing tax returns rely heavily on KV-cache for context. “If I&#x27;m loading three or four 100,000-token PDFs into a model, that&#x27;s it — I&#x27;ve exhausted the KV cache capacity on HBM,” said Ben-David. This is what’s known as the memory wall. “Suddenly, what the inference environment is forced to do is drop data,\" he added. That means GPUs are constantly throwing away context they’ll soon need again, preventing agents from being stateful and maintaining conversations and context over timeThe hidden inference tax “We constantly see GPUs in inference environments recalculating things they already did,” Ben-David said. Systems prefill the KV cache, start decoding, then run out of space and evict earlier data. When that context is needed again, the whole process repeats — prefill, decode, prefill again. At scale, that’s an enormous amount of wasted work. It also means wasted energy, added latency, and degraded user experience — all while margins get squeezed.That GPU recalculation waste shows up directly on the balance sheet. Organizations can suffer nearly 40% overhead just from redundant prefill cycles This is creating ripple effects in the inference market.“If you look at the pricing of large model providers like Anthropic and OpenAI, they are actually teaching users to structure their prompts in ways that increase the likelihood of hitting the same GPU that has their KV cache stored,” said Ben-David. “If you hit that GPU, the system can skip the prefill phase and start decoding immediately, which lets them generate more tokens efficiently.” But this still doesn&#x27;t solve the underlying infrastructure problem of extremely limited GPU memory capacity. Solving for stateful AI“How do you climb over that memory wall? How do you surpass it? That&#x27;s the key for modern, cost- effective inferencing,” Ben-David said. “We see multiple companies trying to solve that in different ways.”Some organizations are deploying new linear models that try to create smaller KV caches. Others are focused on tackling cache efficiency. “To be more efficient, companies are using environments that calculate the KV cache on one GPU and then try to copy it from GPU memory or use a local environment for that,” Ben-David explained. “But how do you do that at scale in a cost-effective manner that doesn&#x27;t strain your memory and doesn&#x27;t strain your networking? That&#x27;s something that WEKA is helping our customers with.”Simply throwing more GPUs at the problem doesn’t solve the AI memory barrier. “There are some problems that you cannot throw enough money at to solve,\" Ben-David said. Augmented memory and token warehousing, explainedWEKA’s answer is what it calls augmented memory and token warehousing — a way to rethink where and how KV cache data lives. Instead of forcing everything to fit inside GPU memory, WEKA’s Augmented Memory Grid extends the KV cache into a fast, shared “warehouse” within its NeuralMesh architecture.In practice, this turns memory from a hard constraint into a scalable resource — without adding inference latency. WEKA says customers see KV cache hit rates jump to 96–99% for agentic workloads, along with efficiency gains of up to 4.2x more tokens produced per GPU.Ben-David put it simply: \"Imagine that you have 100 GPUs producing a certain amount of tokens. Now imagine that those hundred GPUs are working as if they&#x27;re 420 GPUs.\"For large inference providers, the result isn’t just better performance — it translates directly to real economic impact. “Just by adding that accelerated KV cache layer, we&#x27;re looking at some use cases where the savings amount would be millions of dollars per day,” said Ben-DavidThis efficiency multiplier also opens up new strategic options for businesses. Platform teams can design stateful agents without worrying about blowing up memory budgets. Service providers can offer pricing tiers based on persistent context, with cached inference delivered at dramatically lower cost. What comes nextNVIDIA projects a 100x increase in inference demand as agentic AI becomes the dominant workload. That pressure is already trickling down from hyperscalers to everyday enterprise deployments— this isn’t just a “big tech” problem anymore.As enterprises move from proofs of concept into real production systems, memory persistence is becoming a core infrastructure concern. Organizations that treat it as an architectural priority rather than an afterthought will gain a clear advantage in both cost and performance.The memory wall is not something organizations can simply outspend to overcome. As agentic AI scales, it is one of the first AI infrastructure limits that forces a deeper rethink, and as Ben-David’s insights made clear, memory may also be where the next wave of competitive differentiation begins.",
          "content": "As agentic AI moves from experiments to real production workloads, a quiet but serious infrastructure problem is coming into focus: memory. Not compute. Not models. Memory.Under the hood, today’s GPUs simply don’t have enough space to hold the Key-Value (KV) caches that modern, long-running AI agents depend on to maintain context. The result is a lot of invisible waste — GPUs redoing work they’ve already done, cloud costs climbing, and performance taking a hit. It’s a problem that’s already showing up in production environments, even if most people haven’t named it yet.At a recent stop on the VentureBeat AI Impact Series, WEKA CTO Shimon Ben-David joined VentureBeat CEO Matt Marshall to unpack the industry’s emerging “memory wall,” and why it’s becoming one of the biggest blockers to scaling truly stateful agentic AI — systems that can remember and build on context over time. The conversation didn’t just diagnose the issue; it laid out a new way to think about memory entirely, through an approach WEKA calls token warehousing.The GPU memory problem“When we&#x27;re looking at the infrastructure of inferencing, it is not a GPU cycles challenge. It&#x27;s mostly a GPU memory problem,” said Ben-David. The root of the issue comes down to how transformer models work. To generate responses, they rely on KV caches that store contextual information for every token in a conversation. The longer the context window, the more memory those caches consume, and it adds up fast. A single 100,000-token sequence can require roughly 40GB of GPU memory, noted Ben-David.That wouldn’t be a problem if GPUs had unlimited memory. But they don’t. Even the most advanced GPUs top out at around 288GB of high-bandwidth memory (HBM), and that space also has to hold the model itself. In real-world, multi-tenant inference environments, this becomes painful quickly. Workloads like code development or processing tax returns rely heavily on KV-cache for context. “If I&#x27;m loading three or four 100,000-token PDFs into a model, that&#x27;s it — I&#x27;ve exhausted the KV cache capacity on HBM,” said Ben-David. This is what’s known as the memory wall. “Suddenly, what the inference environment is forced to do is drop data,\" he added. That means GPUs are constantly throwing away context they’ll soon need again, preventing agents from being stateful and maintaining conversations and context over timeThe hidden inference tax “We constantly see GPUs in inference environments recalculating things they already did,” Ben-David said. Systems prefill the KV cache, start decoding, then run out of space and evict earlier data. When that context is needed again, the whole process repeats — prefill, decode, prefill again. At scale, that’s an enormous amount of wasted work. It also means wasted energy, added latency, and degraded user experience — all while margins get squeezed.That GPU recalculation waste shows up directly on the balance sheet. Organizations can suffer nearly 40% overhead just from redundant prefill cycles This is creating ripple effects in the inference market.“If you look at the pricing of large model providers like Anthropic and OpenAI, they are actually teaching users to structure their prompts in ways that increase the likelihood of hitting the same GPU that has their KV cache stored,” said Ben-David. “If you hit that GPU, the system can skip the prefill phase and start decoding immediately, which lets them generate more tokens efficiently.” But this still doesn&#x27;t solve the underlying infrastructure problem of extremely limited GPU memory capacity. Solving for stateful AI“How do you climb over that memory wall? How do you surpass it? That&#x27;s the key for modern, cost- effective inferencing,” Ben-David said. “We see multiple companies trying to solve that in different ways.”Some organizations are deploying new linear models that try to create smaller KV caches. Others are focused on tackling cache efficiency. “To be more efficient, companies are using environments that calculate the KV cache on one GPU and then try to copy it from GPU memory or use a local environment for that,” Ben-David explained. “But how do you do that at scale in a cost-effective manner that doesn&#x27;t strain your memory and doesn&#x27;t strain your networking? That&#x27;s something that WEKA is helping our customers with.”Simply throwing more GPUs at the problem doesn’t solve the AI memory barrier. “There are some problems that you cannot throw enough money at to solve,\" Ben-David said. Augmented memory and token warehousing, explainedWEKA’s answer is what it calls augmented memory and token warehousing — a way to rethink where and how KV cache data lives. Instead of forcing everything to fit inside GPU memory, WEKA’s Augmented Memory Grid extends the KV cache into a fast, shared “warehouse” within its NeuralMesh architecture.In practice, this turns memory from a hard constraint into a scalable resource — without adding inference latency. WEKA says customers see KV cache hit rates jump to 96–99% for agentic workloads, along with efficiency gains of up to 4.2x more tokens produced per GPU.Ben-David put it simply: \"Imagine that you have 100 GPUs producing a certain amount of tokens. Now imagine that those hundred GPUs are working as if they&#x27;re 420 GPUs.\"For large inference providers, the result isn’t just better performance — it translates directly to real economic impact. “Just by adding that accelerated KV cache layer, we&#x27;re looking at some use cases where the savings amount would be millions of dollars per day,” said Ben-DavidThis efficiency multiplier also opens up new strategic options for businesses. Platform teams can design stateful agents without worrying about blowing up memory budgets. Service providers can offer pricing tiers based on persistent context, with cached inference delivered at dramatically lower cost. What comes nextNVIDIA projects a 100x increase in inference demand as agentic AI becomes the dominant workload. That pressure is already trickling down from hyperscalers to everyday enterprise deployments— this isn’t just a “big tech” problem anymore.As enterprises move from proofs of concept into real production systems, memory persistence is becoming a core infrastructure concern. Organizations that treat it as an architectural priority rather than an afterthought will gain a clear advantage in both cost and performance.The memory wall is not something organizations can simply outspend to overcome. As agentic AI scales, it is one of the first AI infrastructure limits that forces a deeper rethink, and as Ben-David’s insights made clear, memory may also be where the next wave of competitive differentiation begins.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4oxKXvOOiNDzKlG7ycGI78/fa4c22e954e072347b2c26d0f0e3ef06/VB-WEKA-AI-Impact-2025-093.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/z-ais-open-source-glm-image-beats-googles-nano-banana-pro-at-complex-text",
          "published_at": "Wed, 14 Jan 2026 20:59:00 GMT",
          "title": "Z.ai's open source GLM-Image beats Google's Nano Banana Pro at complex text rendering, but not aesthetics",
          "standfirst": "The two big stories of AI in 2026 so far have been the incredible rise in usage and praise for Anthropic&#x27;s Claude Code and a similar huge boost in user adoption for Google&#x27;s Gemini 3 AI model family released late last year — the latter of which includes Nano Banana Pro (also known as Gemini 3 Pro Image), a powerful, fast, and flexible image generation model that renders complex, text-heavy infographics quickly and accurately, making it an excellent fit for enterprise use (think: collateral, trainings, onboarding, stationary, etc).But of course, both of those are proprietary offerings. And yet, open source rivals have not been far behind. This week, we got a new open source alternative to Nano Banana Pro in the category of precise, text-heavy image generators: GLM-Image, a new 16-billion parameter open-source model from recently public Chinese startup Z.ai.By abandoning the industry-standard \"pure diffusion\" architecture that powers most leading image generator models in favor of a hybrid auto-regressive (AR) + diffusion design, GLM-Image has achieved what was previously thought to be the domain of closed, proprietary models: state-of-the-art performance in generating text-heavy, information-dense visuals like infographics, slides, and technical diagrams.It even beats Google&#x27;s Nano Banana Pro on the shared by z.ai — though in practice, my own quick usage found it to be far less accurate at instruction following and text rendering (and other users seem to agree). But for enterprises seeking cost-effective and customizable, friendly-licensed alternatives to proprietary AI models, z.ai&#x27;s GLM-Image may be \"good enough\" or then some to take over the job of a primary image generator, depending on their specific use cases, needs and requirements.The Benchmark: Toppling the Proprietary GiantThe most compelling argument for GLM-Image is not its aesthetics, but its precision. In the CVTG-2k (Complex Visual Text Generation) benchmark, which evaluates a model&#x27;s ability to render accurate text across multiple regions of an image, GLM-Image scored a Word Accuracy average of 0.9116.To put that number in perspective, Nano Banana 2.0 aka Pro—often cited as the benchmark for enterprise reliability—scored 0.7788. This isn&#x27;t a marginal gain; it is a generational leap in semantic control.While Nano Banana Pro retains a slight edge in single-stream English long-text generation (0.9808 vs. GLM-Image&#x27;s 0.9524), it falters significantly when the complexity increases. As the number of text regions grows, Nano Banana&#x27;s accuracy remains in the 70s, whereas GLM-Image maintains >90% accuracy even with multiple distinct text elements. For enterprise use cases—where a marketing slide needs a title, three bullet points, and a caption simultaneously—this reliability is the difference between a production-ready asset and a hallucination.Unfortunately, my own usage of a demo inference of GLM-Image on Hugging Face proved to be less reliable than the benchmarks might suggest. My prompt to generate an \"infographic labeling all the major constellations visible from the U.S. Northern Hemisphere right now on Jan 14 2026 and putting faded images of their namesakes behind the star connection line diagrams\" did not result in what I asked for, instead fulfilling maybe 20% or less of the specified content. But Google&#x27;s Nano Banana Pro handled it like a champ, as you&#x27;ll see below:Of course, a large portion of this is no doubt due to the fact that Nano Banana Pro is integrated with Google search, so it can look up information on the web in response to my prompt, whereas GLM-Image is not, and therefore, likely requires far more specific instructions about the actual text and other content the image should contain. But still, once you&#x27;re used to being able to type some simple instructions and get a fully researched and well populated image via the latter, it&#x27;s hard to imagine deploying a sub-par alternative unless you have very specific requirements around cost, data residency and security — or the customizability needs of your organization are so great. Furthermore, Nano Banana Pro still edged out GLM-Image in terms of pure aesthetics — using the OneIG benchmark, Nano Banana 2.0 is at 0.578 vs. GLM-Image at 0.528 — and indeed, as the top header artwork of this article indicates, GLM-Image does not always render as crisp, finely detailed and pleasing an image as Google&#x27;s generator. The Architectural Shift: Why \"Hybrid\" MattersWhy does GLM-Image succeed where pure diffusion models fail? The answer lies in Z.ai’s decision to treat image generation as a reasoning problem first and a painting problem second.Standard latent diffusion models (like Stable Diffusion or Flux) attempt to handle global composition and fine-grained texture simultaneously. This often leads to \"semantic drift,\" where the model forgets specific instructions (like \"place the text in the top left\") as it focuses on making the pixels look realistic.GLM-Image decouples these objectives into two specialized \"brains\" totaling 16 billion parameters:The Auto-Regressive Generator (The \"Architect\"): Initialized from Z.ai’s GLM-4-9B language model, this 9-billion parameter module processes the prompt logically. It doesn&#x27;t generate pixels; instead, it outputs \"visual tokens\"—specifically semantic-VQ tokens. These tokens act as a compressed blueprint of the image, locking in the layout, text placement, and object relationships before a single pixel is drawn. This leverages the reasoning power of an LLM, allowing the model to \"understand\" complex instructions (e.g., \"A four-panel tutorial\") in a way diffusion noise predictors cannot.The Diffusion Decoder (The \"Painter\"): Once the layout is locked by the AR module, a 7-billion parameter Diffusion Transformer (DiT) decoder takes over. Based on the CogView4 architecture, this module fills in the high-frequency details—texture, lighting, and style.By separating the \"what\" (AR) from the \"how\" (Diffusion), GLM-Image solves the \"dense knowledge\" problem. The AR module ensures the text is spelled correctly and placed accurately, while the Diffusion module ensures the final result looks photorealistic.Training the Hybrid: A Multi-Stage EvolutionThe secret sauce of GLM-Image’s performance isn&#x27;t just the architecture; it is a highly specific, multi-stage training curriculum that forces the model to learn structure before detail.The training process began by freezing the text word embedding layer of the original GLM-4 model while training a new \"vision word embedding\" layer and a specialized vision LM head. This allowed the model to project visual tokens into the same semantic space as text, effectively teaching the LLM to \"speak\" in images. Crucially, Z.ai implemented MRoPE (Multidimensional Rotary Positional Embedding) to handle the complex interleaving of text and images required for mixed-modal generation.The model was then subjected to a progressive resolution strategy:Stage 1 (256px): The model trained on low-resolution, 256-token sequences using a simple raster scan order.Stage 2 (512px - 1024px): As resolution increased to a mixed stage (512px to 1024px), the team observed a drop in controllability. To fix this, they abandoned simple scanning for a progressive generation strategy.In this advanced stage, the model first generates approximately 256 \"layout tokens\" from a down-sampled version of the target image. These tokens act as a structural anchor. By increasing the training weight on these preliminary tokens, the team forced the model to prioritize the global layout—where things are—before generating the high-resolution details. This is why GLM-Image excels at posters and diagrams: it \"sketches\" the layout first, ensuring the composition is mathematically sound before rendering the pixels.Licensing Analysis: A Permissive, If Slightly Ambiguous, Win for EnterpriseFor enterprise CTOs and legal teams, the licensing structure of GLM-Image is a significant competitive advantage over proprietary APIs, though it comes with a minor caveat regarding documentation.The Ambiguity: There is a slight discrepancy in the release materials. The model’s Hugging Face repository explicitly tags the weights with the MIT License. However, the accompanying GitHub repository and documentation reference the Apache License 2.0.Why This Is Still Good News: Despite the mismatch, both licenses are the \"gold standard\" for enterprise-friendly open source.Commercial Viability: Both MIT and Apache 2.0 allow for unrestricted commercial use, modification, and distribution. Unlike the \"open rail\" licenses common in other image models (which often restrict specific use cases) or \"research-only\" licenses (like early LLaMA releases), GLM-Image is effectively \"open for business\" immediately.The Apache Advantage (If Applicable): If the code falls under Apache 2.0, this is particularly beneficial for large organizations. Apache 2.0 includes an explicit patent grant clause, meaning that by contributing to or using the software, contributors grant a patent license to users. This reduces the risk of future patent litigation—a major concern for enterprises building products on top of open-source codebases.No \"Infection\": Neither license is \"copyleft\" (like GPL). You can integrate GLM-Image into a proprietary workflow or product without being forced to open-source your own intellectual property.For developers, the recommendation is simple: Treat the weights as MIT (per the repository hosting them) and the inference code as Apache 2.0. Both paths clear the runway for internal hosting, fine-tuning on sensitive data, and building commercial products without a vendor lock-in contract.The \"Why Now\" for Enterprise OperationsFor the enterprise decision maker, GLM-Image arrives at a critical inflection point. Companies are moving beyond using generative AI for abstract blog headers and into functional territory: multilingual localization of ads, automated UI mockup generation, and dynamic educational materials.In these workflows, a 5% error rate in text rendering is a blocker. If a model generates a beautiful slide but misspells the product name, the asset is useless. The benchmarks suggest GLM-Image is the first open-source model to cross the threshold of reliability for these complex tasks.Furthermore, the permissive licensing fundamentally changes the economics of deployment. While Nano Banana Pro locks enterprises into a per-call API cost structure or restrictive cloud contracts, GLM-Image can be self-hosted, fine-tuned on proprietary brand assets, and integrated into secure, air-gapped pipelines without data leakage concerns.The Catch: Heavy Compute RequirementsThe trade-off for this reasoning capability is compute intensity. The dual-model architecture is heavy. Generating a single 2048x2048 image requires approximately 252 seconds on an H100 GPU. This is significantly slower than highly optimized, smaller diffusion models.However, for high-value assets—where the alternative is a human designer spending hours in Photoshop—this latency is acceptable. Z.ai also offers a managed API at $0.015 per image, providing a bridge for teams who want to test the capabilities without investing in H100 clusters immediately.GLM-Image is a signal that the open-source community is no longer just fast-following proprietary labs; in specific, high-value verticals like knowledge-dense generation, they are now setting the pace. For the enterprise, the message is clear: if your operational bottleneck is the reliability of complex visual content, the solution is no longer necessarily a closed Google product—it might be an open-source model you can run yourself.",
          "content": "The two big stories of AI in 2026 so far have been the incredible rise in usage and praise for Anthropic&#x27;s Claude Code and a similar huge boost in user adoption for Google&#x27;s Gemini 3 AI model family released late last year — the latter of which includes Nano Banana Pro (also known as Gemini 3 Pro Image), a powerful, fast, and flexible image generation model that renders complex, text-heavy infographics quickly and accurately, making it an excellent fit for enterprise use (think: collateral, trainings, onboarding, stationary, etc).But of course, both of those are proprietary offerings. And yet, open source rivals have not been far behind. This week, we got a new open source alternative to Nano Banana Pro in the category of precise, text-heavy image generators: GLM-Image, a new 16-billion parameter open-source model from recently public Chinese startup Z.ai.By abandoning the industry-standard \"pure diffusion\" architecture that powers most leading image generator models in favor of a hybrid auto-regressive (AR) + diffusion design, GLM-Image has achieved what was previously thought to be the domain of closed, proprietary models: state-of-the-art performance in generating text-heavy, information-dense visuals like infographics, slides, and technical diagrams.It even beats Google&#x27;s Nano Banana Pro on the shared by z.ai — though in practice, my own quick usage found it to be far less accurate at instruction following and text rendering (and other users seem to agree). But for enterprises seeking cost-effective and customizable, friendly-licensed alternatives to proprietary AI models, z.ai&#x27;s GLM-Image may be \"good enough\" or then some to take over the job of a primary image generator, depending on their specific use cases, needs and requirements.The Benchmark: Toppling the Proprietary GiantThe most compelling argument for GLM-Image is not its aesthetics, but its precision. In the CVTG-2k (Complex Visual Text Generation) benchmark, which evaluates a model&#x27;s ability to render accurate text across multiple regions of an image, GLM-Image scored a Word Accuracy average of 0.9116.To put that number in perspective, Nano Banana 2.0 aka Pro—often cited as the benchmark for enterprise reliability—scored 0.7788. This isn&#x27;t a marginal gain; it is a generational leap in semantic control.While Nano Banana Pro retains a slight edge in single-stream English long-text generation (0.9808 vs. GLM-Image&#x27;s 0.9524), it falters significantly when the complexity increases. As the number of text regions grows, Nano Banana&#x27;s accuracy remains in the 70s, whereas GLM-Image maintains >90% accuracy even with multiple distinct text elements. For enterprise use cases—where a marketing slide needs a title, three bullet points, and a caption simultaneously—this reliability is the difference between a production-ready asset and a hallucination.Unfortunately, my own usage of a demo inference of GLM-Image on Hugging Face proved to be less reliable than the benchmarks might suggest. My prompt to generate an \"infographic labeling all the major constellations visible from the U.S. Northern Hemisphere right now on Jan 14 2026 and putting faded images of their namesakes behind the star connection line diagrams\" did not result in what I asked for, instead fulfilling maybe 20% or less of the specified content. But Google&#x27;s Nano Banana Pro handled it like a champ, as you&#x27;ll see below:Of course, a large portion of this is no doubt due to the fact that Nano Banana Pro is integrated with Google search, so it can look up information on the web in response to my prompt, whereas GLM-Image is not, and therefore, likely requires far more specific instructions about the actual text and other content the image should contain. But still, once you&#x27;re used to being able to type some simple instructions and get a fully researched and well populated image via the latter, it&#x27;s hard to imagine deploying a sub-par alternative unless you have very specific requirements around cost, data residency and security — or the customizability needs of your organization are so great. Furthermore, Nano Banana Pro still edged out GLM-Image in terms of pure aesthetics — using the OneIG benchmark, Nano Banana 2.0 is at 0.578 vs. GLM-Image at 0.528 — and indeed, as the top header artwork of this article indicates, GLM-Image does not always render as crisp, finely detailed and pleasing an image as Google&#x27;s generator. The Architectural Shift: Why \"Hybrid\" MattersWhy does GLM-Image succeed where pure diffusion models fail? The answer lies in Z.ai’s decision to treat image generation as a reasoning problem first and a painting problem second.Standard latent diffusion models (like Stable Diffusion or Flux) attempt to handle global composition and fine-grained texture simultaneously. This often leads to \"semantic drift,\" where the model forgets specific instructions (like \"place the text in the top left\") as it focuses on making the pixels look realistic.GLM-Image decouples these objectives into two specialized \"brains\" totaling 16 billion parameters:The Auto-Regressive Generator (The \"Architect\"): Initialized from Z.ai’s GLM-4-9B language model, this 9-billion parameter module processes the prompt logically. It doesn&#x27;t generate pixels; instead, it outputs \"visual tokens\"—specifically semantic-VQ tokens. These tokens act as a compressed blueprint of the image, locking in the layout, text placement, and object relationships before a single pixel is drawn. This leverages the reasoning power of an LLM, allowing the model to \"understand\" complex instructions (e.g., \"A four-panel tutorial\") in a way diffusion noise predictors cannot.The Diffusion Decoder (The \"Painter\"): Once the layout is locked by the AR module, a 7-billion parameter Diffusion Transformer (DiT) decoder takes over. Based on the CogView4 architecture, this module fills in the high-frequency details—texture, lighting, and style.By separating the \"what\" (AR) from the \"how\" (Diffusion), GLM-Image solves the \"dense knowledge\" problem. The AR module ensures the text is spelled correctly and placed accurately, while the Diffusion module ensures the final result looks photorealistic.Training the Hybrid: A Multi-Stage EvolutionThe secret sauce of GLM-Image’s performance isn&#x27;t just the architecture; it is a highly specific, multi-stage training curriculum that forces the model to learn structure before detail.The training process began by freezing the text word embedding layer of the original GLM-4 model while training a new \"vision word embedding\" layer and a specialized vision LM head. This allowed the model to project visual tokens into the same semantic space as text, effectively teaching the LLM to \"speak\" in images. Crucially, Z.ai implemented MRoPE (Multidimensional Rotary Positional Embedding) to handle the complex interleaving of text and images required for mixed-modal generation.The model was then subjected to a progressive resolution strategy:Stage 1 (256px): The model trained on low-resolution, 256-token sequences using a simple raster scan order.Stage 2 (512px - 1024px): As resolution increased to a mixed stage (512px to 1024px), the team observed a drop in controllability. To fix this, they abandoned simple scanning for a progressive generation strategy.In this advanced stage, the model first generates approximately 256 \"layout tokens\" from a down-sampled version of the target image. These tokens act as a structural anchor. By increasing the training weight on these preliminary tokens, the team forced the model to prioritize the global layout—where things are—before generating the high-resolution details. This is why GLM-Image excels at posters and diagrams: it \"sketches\" the layout first, ensuring the composition is mathematically sound before rendering the pixels.Licensing Analysis: A Permissive, If Slightly Ambiguous, Win for EnterpriseFor enterprise CTOs and legal teams, the licensing structure of GLM-Image is a significant competitive advantage over proprietary APIs, though it comes with a minor caveat regarding documentation.The Ambiguity: There is a slight discrepancy in the release materials. The model’s Hugging Face repository explicitly tags the weights with the MIT License. However, the accompanying GitHub repository and documentation reference the Apache License 2.0.Why This Is Still Good News: Despite the mismatch, both licenses are the \"gold standard\" for enterprise-friendly open source.Commercial Viability: Both MIT and Apache 2.0 allow for unrestricted commercial use, modification, and distribution. Unlike the \"open rail\" licenses common in other image models (which often restrict specific use cases) or \"research-only\" licenses (like early LLaMA releases), GLM-Image is effectively \"open for business\" immediately.The Apache Advantage (If Applicable): If the code falls under Apache 2.0, this is particularly beneficial for large organizations. Apache 2.0 includes an explicit patent grant clause, meaning that by contributing to or using the software, contributors grant a patent license to users. This reduces the risk of future patent litigation—a major concern for enterprises building products on top of open-source codebases.No \"Infection\": Neither license is \"copyleft\" (like GPL). You can integrate GLM-Image into a proprietary workflow or product without being forced to open-source your own intellectual property.For developers, the recommendation is simple: Treat the weights as MIT (per the repository hosting them) and the inference code as Apache 2.0. Both paths clear the runway for internal hosting, fine-tuning on sensitive data, and building commercial products without a vendor lock-in contract.The \"Why Now\" for Enterprise OperationsFor the enterprise decision maker, GLM-Image arrives at a critical inflection point. Companies are moving beyond using generative AI for abstract blog headers and into functional territory: multilingual localization of ads, automated UI mockup generation, and dynamic educational materials.In these workflows, a 5% error rate in text rendering is a blocker. If a model generates a beautiful slide but misspells the product name, the asset is useless. The benchmarks suggest GLM-Image is the first open-source model to cross the threshold of reliability for these complex tasks.Furthermore, the permissive licensing fundamentally changes the economics of deployment. While Nano Banana Pro locks enterprises into a per-call API cost structure or restrictive cloud contracts, GLM-Image can be self-hosted, fine-tuned on proprietary brand assets, and integrated into secure, air-gapped pipelines without data leakage concerns.The Catch: Heavy Compute RequirementsThe trade-off for this reasoning capability is compute intensity. The dual-model architecture is heavy. Generating a single 2048x2048 image requires approximately 252 seconds on an H100 GPU. This is significantly slower than highly optimized, smaller diffusion models.However, for high-value assets—where the alternative is a human designer spending hours in Photoshop—this latency is acceptable. Z.ai also offers a managed API at $0.015 per image, providing a bridge for teams who want to test the capabilities without investing in H100 clusters immediately.GLM-Image is a signal that the open-source community is no longer just fast-following proprietary labs; in specific, high-value verticals like knowledge-dense generation, they are now setting the pace. For the enterprise, the message is clear: if your operational bottleneck is the reliability of complex visual content, the solution is no longer necessarily a closed Google product—it might be an open-source model you can run yourself.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1UjUf0KRfpbNaTSF2uk1Dz/7b76ade2243333f36713a89e8612b817/0yZhP9i_2swwDcPvoyypB.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2023-09/8424f5a0-4f40-11ee-acbb-bab134a1b1db",
      "popularity_score": 2019.9157075
    },
    {
      "id": "cluster_6",
      "coverage": 2,
      "updated_at": "2026-01-16T13:24:07-05:00",
      "title": "Ted Sarandos says Netflix will commit to 45-day theatrical releases",
      "neutral_headline": "Ted Sarandos says Netflix will commit to 45-day theatrical releases",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/streaming/863511/ted-sarandos-netflix-theatrical-movie-release-windows",
          "published_at": "2026-01-16T13:24:07-05:00",
          "title": "Ted Sarandos says Netflix will commit to 45-day theatrical releases",
          "standfirst": "Though Netflix's plan to buy Warner Bros. Discovery has prompted concerns about how the deal might hurt the movie theater business, the streamer's co-CEO says that there is nothing to worry about. In a new interview with The New York Times, Netflix co-CEO Ted Sarandos said that, should the WBD acquisition go through, the streamer [&#8230;]",
          "content": "Though Netflix's plan to buy Warner Bros. Discovery has prompted concerns about how the deal might hurt the movie theater business, the streamer's co-CEO says that there is nothing to worry about. In a new interview with The New York Times, Netflix co-CEO Ted Sarandos said that, should the WBD acquisition go through, the streamer will commit to 45-day theatrical release windows for the legacy studio's upcoming releases. Sarandos insisted that Netflix has no intentions of disrupting \"a theatrical distribution engine that is phenomenal and produces billions of dollars,\" and that believes there is value in the movie theater experience. \"I'm g … Read the full story at The Verge.",
          "feed_position": 1
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260116/p7#a260116p7",
          "published_at": "Fri, 16 Jan 2026 07:10:12 -0500",
          "title": "Q&A with Netflix co-CEO Ted Sarandos about the $83B WBD bid, Trump's involvement in the deal, maintaining a 45-day theatrical window for WBD releases, and more (Nicole Sperling/New York Times)",
          "standfirst": "Nicole Sperling / New York Times: Q&A with Netflix co-CEO Ted Sarandos about the $83B WBD bid, Trump's involvement in the deal, maintaining a 45-day theatrical window for WBD releases, and more &mdash; The company's co-chief executive sat down for an extensive interview for the first time since announcing plans to buy Warner Bros. Discovery's film and TV business.",
          "content": "Nicole Sperling / New York Times: Q&A with Netflix co-CEO Ted Sarandos about the $83B WBD bid, Trump's involvement in the deal, maintaining a 45-day theatrical window for WBD releases, and more &mdash; The company's co-chief executive sat down for an extensive interview for the first time since announcing plans to buy Warner Bros. Discovery's film and TV business.",
          "feed_position": 11,
          "image_url": "http://www.techmeme.com/260116/i7.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260116/i7.jpg",
      "popularity_score": 2019.0701519444444
    },
    {
      "id": "cluster_7",
      "coverage": 2,
      "updated_at": "Fri, 16 Jan 2026 13:24:00 -0500",
      "title": "OpenAI expands its $8/month ChatGPT Go subscription tier to the US and the rest of the world, after previously launching it in India and some other countries (Elissa Welle/The Verge)",
      "neutral_headline": "OpenAI releases a cheaper ChatGPT subscription",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260116/p18#a260116p18",
          "published_at": "Fri, 16 Jan 2026 13:24:00 -0500",
          "title": "OpenAI expands its $8/month ChatGPT Go subscription tier to the US and the rest of the world, after previously launching it in India and some other countries (Elissa Welle/The Verge)",
          "standfirst": "Elissa Welle / The Verge: OpenAI expands its $8/month ChatGPT Go subscription tier to the US and the rest of the world, after previously launching it in India and some other countries &mdash; &#65279;'ChatGPT Go' is available worldwide for $8 per month. &hellip; OpenAI is expanding a low-cost subscription tier called ChatGPT Go to the US and the rest of the world.",
          "content": "Elissa Welle / The Verge: OpenAI expands its $8/month ChatGPT Go subscription tier to the US and the rest of the world, after previously launching it in India and some other countries &mdash; &#65279;'ChatGPT Go' is available worldwide for $8 per month. &hellip; OpenAI is expanding a low-cost subscription tier called ChatGPT Go to the US and the rest of the world.",
          "feed_position": 0,
          "image_url": "http://www.techmeme.com/260116/i18.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/863466/openai-chatgpt-go-global-release",
          "published_at": "2026-01-16T13:00:00-05:00",
          "title": "OpenAI releases a cheaper ChatGPT subscription",
          "standfirst": "OpenAI is expanding a low-cost subscription tier called ChatGPT Go to the US and the rest of the world. Go was released in India in August and later became available in another 170 countries prior to Friday's global release. \"In markets where Go has been available, we've seen strong adoption and regular everyday use for [&#8230;]",
          "content": "OpenAI is expanding a low-cost subscription tier called ChatGPT Go to the US and the rest of the world. Go was released in India in August and later became available in another 170 countries prior to Friday's global release. \"In markets where Go has been available, we've seen strong adoption and regular everyday use for tasks like writing, learning, image creation, and problem-solving,\" the company's announcement stated. For $8 per month, Go subscribers get more messages, file uploads, and image generation than the free ChatGPT tier subscribers. The price slots Go between the free version of the AI chatbot and the $20-a-month \"Plus\" subscri … Read the full story at The Verge.",
          "feed_position": 3
        }
      ],
      "featured_image": "http://www.techmeme.com/260116/i18.jpg",
      "popularity_score": 2019.0682075
    },
    {
      "id": "cluster_9",
      "coverage": 2,
      "updated_at": "Fri, 16 Jan 2026 13:20:01 -0500",
      "title": "OpenAI will match ads to conversation topics using some personalization data, but claims it will not sell user data or expose user conversations to advertisers (Maxwell Zeff/Wired)",
      "neutral_headline": "Ads Are Coming to ChatGPT. Here’s How They’ll Work",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260116/p17#a260116p17",
          "published_at": "Fri, 16 Jan 2026 13:20:01 -0500",
          "title": "OpenAI will match ads to conversation topics using some personalization data, but claims it will not sell user data or expose user conversations to advertisers (Maxwell Zeff/Wired)",
          "standfirst": "Maxwell Zeff / Wired: OpenAI will match ads to conversation topics using some personalization data, but claims it will not sell user data or expose user conversations to advertisers &mdash; OpenAI says ads will not influence ChatGPT's responses, and that it won't sell user data to advertisers.",
          "content": "Maxwell Zeff / Wired: OpenAI will match ads to conversation topics using some personalization data, but claims it will not sell user data or expose user conversations to advertisers &mdash; OpenAI says ads will not influence ChatGPT's responses, and that it won't sell user data to advertisers.",
          "feed_position": 1,
          "image_url": "http://www.techmeme.com/260116/i17.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/openai-testing-ads-us/",
          "published_at": "Fri, 16 Jan 2026 18:00:00 +0000",
          "title": "Ads Are Coming to ChatGPT. Here’s How They’ll Work",
          "standfirst": "OpenAI says ads will not influence ChatGPT’s responses, and that it won’t sell user data to advertisers.",
          "content": "OpenAI says ads will not influence ChatGPT’s responses, and that it won’t sell user data to advertisers.",
          "feed_position": 0,
          "image_url": "https://media.wired.com/photos/6969e23027d67473e4bb6b79/master/pass/GettyImages-2253746109.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260116/i17.jpg",
      "popularity_score": 2019.001818611111
    },
    {
      "id": "cluster_25",
      "coverage": 2,
      "updated_at": "Fri, 16 Jan 2026 17:06:00 GMT",
      "title": "X outage reports spiked Friday morning - what we know",
      "neutral_headline": "X outage reports spiked Friday morning - what we know",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/x-cloudflare-aws-outage-friday/",
          "published_at": "Fri, 16 Jan 2026 17:06:00 GMT",
          "title": "X outage reports spiked Friday morning - what we know",
          "standfirst": "The social media site was down today. What we know so far.",
          "content": "The social media site was down today. What we know so far.",
          "feed_position": 10
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/16/x-is-down-for-the-second-time-this-week/",
          "published_at": "Fri, 16 Jan 2026 16:29:38 +0000",
          "title": "X is down for the second time this week",
          "standfirst": "Elon Musk's X, formerly Twitter, is down for the second time this week. Nearly 80,000 reports have spiked on Down Detector since around 10 a.m. ET Friday morning.",
          "content": "Elon Musk's X, formerly Twitter, is down for the second time this week. Nearly 80,000 reports have spiked on Down Detector since around 10 a.m. ET Friday morning.",
          "feed_position": 2
        }
      ],
      "popularity_score": 2017.7682075
    },
    {
      "id": "cluster_26",
      "coverage": 2,
      "updated_at": "Fri, 16 Jan 2026 17:04:46 +0000",
      "title": "TikTok sued by former workers over alleged union-busting",
      "neutral_headline": "TikTok sued by former workers over alleged union-busting",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/tiktok-sued-by-former-workers-over-alleged-union-busting-170446921.html",
          "published_at": "Fri, 16 Jan 2026 17:04:46 +0000",
          "title": "TikTok sued by former workers over alleged union-busting",
          "standfirst": "You know things are messed up when a Big Tech company fights accusations of union-busting by insisting it was only AI layoffs. That's where things stand after a group of fired TikTok moderators in the UK filed a legal claim with an employment tribunal. The Guardian reported on Friday that around 400 TikTok content moderators who were unionizing were laid off before Christmas.The workers were sacked a week before a vote was scheduled to establish a collective bargaining unit. The moderators said they wanted better protection against the personal toll of processing traumatic content at a high speed. They accused TikTok of unfair dismissal and violating UK trade union laws.\"Content moderators have the most dangerous job on the internet,\" John Chadfield, the national officer for tech workers at the Communication Workers Union (CWU), said in a statement to The Guardian. \"They are exposed to the child sex abuse material, executions, war and drug use. Their job is to make sure this content doesn't reach TikTok's 30 million monthly users. It is high pressure and low paid. They wanted input into their workflows and more say over how they kept the platform safe. They said they were being asked to do too much with too few resources.\"TikTok denied that the firings were union-busting, calling the accusations \"baseless.\" Instead, the company claimed the layoffs were part of a restructuring plan amid its adoption of AI for content moderation. The company said 91 percent of transgressive content is now removed automatically.The company first announced a restructuring exercise in August, just as hundreds of moderators in TikTok's London offices were organizing for union recognition. At the time, John Chadfield, CWU's National Officer for Tech, said the workers had long been \"sounding the alarm over the real-world costs of cutting human moderation teams in favour of hastily developed, immature AI alternatives.\"\"That TikTok management have announced these cuts just as the company's workers are about to vote on having their union recognised stinks of union-busting and putting corporate greed over the safety of workers and the public,” Chadfield said.This article originally appeared on Engadget at https://www.engadget.com/big-tech/tiktok-sued-by-former-workers-over-alleged-union-busting-170446921.html?src=rss",
          "content": "You know things are messed up when a Big Tech company fights accusations of union-busting by insisting it was only AI layoffs. That's where things stand after a group of fired TikTok moderators in the UK filed a legal claim with an employment tribunal. The Guardian reported on Friday that around 400 TikTok content moderators who were unionizing were laid off before Christmas.The workers were sacked a week before a vote was scheduled to establish a collective bargaining unit. The moderators said they wanted better protection against the personal toll of processing traumatic content at a high speed. They accused TikTok of unfair dismissal and violating UK trade union laws.\"Content moderators have the most dangerous job on the internet,\" John Chadfield, the national officer for tech workers at the Communication Workers Union (CWU), said in a statement to The Guardian. \"They are exposed to the child sex abuse material, executions, war and drug use. Their job is to make sure this content doesn't reach TikTok's 30 million monthly users. It is high pressure and low paid. They wanted input into their workflows and more say over how they kept the platform safe. They said they were being asked to do too much with too few resources.\"TikTok denied that the firings were union-busting, calling the accusations \"baseless.\" Instead, the company claimed the layoffs were part of a restructuring plan amid its adoption of AI for content moderation. The company said 91 percent of transgressive content is now removed automatically.The company first announced a restructuring exercise in August, just as hundreds of moderators in TikTok's London offices were organizing for union recognition. At the time, John Chadfield, CWU's National Officer for Tech, said the workers had long been \"sounding the alarm over the real-world costs of cutting human moderation teams in favour of hastily developed, immature AI alternatives.\"\"That TikTok management have announced these cuts just as the company's workers are about to vote on having their union recognised stinks of union-busting and putting corporate greed over the safety of workers and the public,” Chadfield said.This article originally appeared on Engadget at https://www.engadget.com/big-tech/tiktok-sued-by-former-workers-over-alleged-union-busting-170446921.html?src=rss",
          "feed_position": 5
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/jan/16/sacked-tiktok-workers-uk-legal-action-union",
          "published_at": "Fri, 16 Jan 2026 15:04:24 GMT",
          "title": "Sacked TikTok workers in UK launch legal action over ‘union busting’",
          "standfirst": "Moderators accuse social media firm of unfair dismissal after it fired hundreds in UK just before vote to form unionTikTok moderators have accused the social media company of “oppressive and intimidating” union busting after it fired hundreds of workers in the UK, beginning the process just before they were due to vote on forming a union.The moderators wanted to establish a collective bargaining unit to protect themselves from the personal costs of checking extreme and violent content, and have claimed TikTok is guilty of unfair dismissal and breaching trade union laws. Continue reading...",
          "content": "Moderators accuse social media firm of unfair dismissal after it fired hundreds in UK just before vote to form unionTikTok moderators have accused the social media company of “oppressive and intimidating” union busting after it fired hundreds of workers in the UK, beginning the process just before they were due to vote on forming a union.The moderators wanted to establish a collective bargaining unit to protect themselves from the personal costs of checking extreme and violent content, and have claimed TikTok is guilty of unfair dismissal and breaching trade union laws. Continue reading...",
          "feed_position": 1
        }
      ],
      "popularity_score": 2017.7476519444444
    },
    {
      "id": "cluster_45",
      "coverage": 2,
      "updated_at": "Fri, 16 Jan 2026 15:02:49 +0000",
      "title": "Italy investigates Activision Blizzard for pushing in-game purchases",
      "neutral_headline": "Italy investigates Activision Blizzard for pushing in-game purchases",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/16/italy-investigates-activision-blizzard-for-pushing-in-game-purchases/",
          "published_at": "Fri, 16 Jan 2026 15:02:49 +0000",
          "title": "Italy investigates Activision Blizzard for pushing in-game purchases",
          "standfirst": "Italy has launched two investigations into Microsoft's Activision Blizzard, alleging the company has engaged in \"misleading and aggressive\" sales practices for two of its most popular smartphone games.",
          "content": "Italy has launched two investigations into Microsoft's Activision Blizzard, alleging the company has engaged in \"misleading and aggressive\" sales practices for two of its most popular smartphone games.",
          "feed_position": 6
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260116/p5#a260116p5",
          "published_at": "Fri, 16 Jan 2026 06:10:02 -0500",
          "title": "Italy's competition watchdog opens two investigations into Microsoft's Activision Blizzard over sales practices the regulator calls \"misleading and aggressive\" (Reuters)",
          "standfirst": "Reuters: Italy's competition watchdog opens two investigations into Microsoft's Activision Blizzard over sales practices the regulator calls &ldquo;misleading and aggressive&rdquo; &mdash; Italy's competition watchdog on Friday announced investigations into Microsoft's (MSFT.O) Activision Blizzard unit over allegedly &hellip;",
          "content": "Reuters: Italy's competition watchdog opens two investigations into Microsoft's Activision Blizzard over sales practices the regulator calls &ldquo;misleading and aggressive&rdquo; &mdash; Italy's competition watchdog on Friday announced investigations into Microsoft's (MSFT.O) Activision Blizzard unit over allegedly &hellip;",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/260116/i5.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260116/i5.jpg",
      "popularity_score": 2015.7151519444444
    },
    {
      "id": "cluster_107",
      "coverage": 2,
      "updated_at": "Thu, 15 Jan 2026 18:24:51 +0000",
      "title": "OpenAI Invests in Sam Altman’s New Brain-Tech Startup Merge Labs",
      "neutral_headline": "OpenAI Invests in Sam Altman’s New Brain-Tech Startup Merge Labs",
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/openai-invests-in-sam-altmans-new-brain-tech-startup-merge-labs/",
          "published_at": "Thu, 15 Jan 2026 18:24:51 +0000",
          "title": "OpenAI Invests in Sam Altman’s New Brain-Tech Startup Merge Labs",
          "standfirst": "Merge Labs has emerged from stealth with $252 million in funding from OpenAI and others. It aims to use ultrasound to read from and write to the brain.",
          "content": "Merge Labs has emerged from stealth with $252 million in funding from OpenAI and others. It aims to use ultrasound to read from and write to the brain.",
          "feed_position": 23,
          "image_url": "https://media.wired.com/photos/69690ee78f59220ea2e720b9/master/pass/sci-openai-2220468498.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/15/openai-invests-in-sam-altmans-brain-computer-interface-startup-merge-labs/",
          "published_at": "Thu, 15 Jan 2026 16:31:00 +0000",
          "title": "OpenAI invests in Sam Altman’s brain computer interface startup Merge Labs",
          "standfirst": "Merge Labs is a “research lab” dedicated to “bridging biological and artificial intelligence to maximize human ability.” OpenAI wrote the largest check in Merge Labs' $250 million seed round at an $850 million valuation.",
          "content": "Merge Labs is a “research lab” dedicated to “bridging biological and artificial intelligence to maximize human ability.” OpenAI wrote the largest check in Merge Labs' $250 million seed round at an $850 million valuation.",
          "feed_position": 16
        }
      ],
      "featured_image": "https://media.wired.com/photos/69690ee78f59220ea2e720b9/master/pass/sci-openai-2220468498.jpg",
      "popularity_score": 2000
    },
    {
      "id": "cluster_118",
      "coverage": 2,
      "updated_at": "Thu, 15 Jan 2026 15:25:52 +0000",
      "title": "Wikipedia signs major AI firms to new priority data access deals",
      "neutral_headline": "Wikipedia signs major AI firms to new priority data access deals",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/wikipedia-will-share-content-with-ai-firms-in-new-licensing-deals/",
          "published_at": "Thu, 15 Jan 2026 15:25:52 +0000",
          "title": "Wikipedia signs major AI firms to new priority data access deals",
          "standfirst": "Wikimedia Enterprise signs Microsoft, Meta, Amazon, Perplexity, and Mistral to API access deals.",
          "content": "On Thursday, the Wikimedia Foundation announced API access deals with Microsoft, Meta, Amazon, Perplexity, and Mistral AI, expanding its effort to get major tech companies to pay for high-volume API access to Wikipedia content, which these companies use to train AI models like Microsoft Copilot and ChatGPT. The deals mean that most major AI developers have now signed on to the foundation's Wikimedia Enterprise program, a commercial subsidiary that sells high-speed API access to Wikipedia's 65 million articles at higher speeds and volumes than the free public APIs provide. Wikipedia's content remains freely available under a Creative Commons license, but the Enterprise program charges for faster, higher-volume access to the data. The foundation did not disclose the financial terms of the deals. The new partners join Google, which signed a deal with Wikimedia Enterprise in 2022, as well as smaller companies like Ecosia, Nomic, Pleias, ProRata, and Reef Media. The revenue helps offset infrastructure costs for the nonprofit, which otherwise relies on small public donations while watching its content become a staple of training data for AI models.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Wikipedia-AI-1152x648.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/15/wikimedia-foundation-announces-new-ai-partnerships-with-amazon-meta-microsoft-perplexity-and-others/",
          "published_at": "Thu, 15 Jan 2026 15:19:05 +0000",
          "title": "Wikimedia Foundation announces new AI partnerships with Amazon, Meta, Microsoft, Perplexity, and others",
          "standfirst": "The AI partnerships allow companies to access the org's content, like Wikipedia, at scale.",
          "content": "The AI partnerships allow companies to access the org's content, like Wikipedia, at scale.",
          "feed_position": 17
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Wikipedia-AI-1152x648.jpg",
      "popularity_score": 2000
    },
    {
      "id": "cluster_27",
      "coverage": 1,
      "updated_at": "Fri, 16 Jan 2026 16:55:08 +0000",
      "title": "TSMC says AI demand is “endless” after record Q4 earnings",
      "neutral_headline": "TSMC says AI demand is “endless” after record Q4 earnings",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/tsmc-says-ai-demand-is-endless-after-record-q4-earnings/",
          "published_at": "Fri, 16 Jan 2026 16:55:08 +0000",
          "title": "TSMC says AI demand is “endless” after record Q4 earnings",
          "standfirst": "Amid fears of bubble, world's top chipmaker TSMC says customers just keep asking for more.",
          "content": "On Thursday, Taiwan Semiconductor Manufacturing Company (TSMC) reported record fourth-quarter earnings and said it expects AI chip demand to continue for years. During an earnings call, CEO C.C. Wei told investors that while he cannot predict the semiconductor industry's long-term trajectory, he remains bullish on AI. TSMC manufactures chips for companies including Apple, Nvidia, AMD, and Qualcomm, making it a linchpin of the global electronics supply chain. The company produces the vast majority of the world's most advanced semiconductors, and its factories in Taiwan have become a focal point of US-China tensions over technology and trade. When TSMC reports strong demand and ramps up spending, it signals that the companies designing AI chips expect years of continued growth. \"All in all, I believe in my point of view, the AI is real—not only real, it's starting to grow into our daily life. And we believe that is kind of—we call it AI megatrend, we certainly would believe that,\" Wei said during the call. \"So another question is 'can the semiconductor industry be good for three, four, five years in a row?' I'll tell you the truth, I don't know. But I look at the AI, it looks like it's going to be like an endless—I mean, that for many years to come.\"Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/tsmc_factory-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/tsmc_factory-1152x648.jpg",
      "popularity_score": 365.5870963888889
    },
    {
      "id": "cluster_1",
      "coverage": 1,
      "updated_at": "Fri, 16 Jan 2026 19:12:04 +0000",
      "title": "Verizon, Frontier to complete $10B merger after approvals from FCC and states",
      "neutral_headline": "Verizon, Frontier to complete $10B merger after approvals from FCC and states",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/tech-policy/2026/01/verizon-frontier-to-complete-10b-merger-after-approvals-from-fcc-and-states/",
          "published_at": "Fri, 16 Jan 2026 19:12:04 +0000",
          "title": "Verizon, Frontier to complete $10B merger after approvals from FCC and states",
          "standfirst": "Verizon touts \"expanded reach of almost 30 million fiber passings\" across US.",
          "content": "Verizon has received all approvals it needs for a $9.6 billion acquisition of Frontier Communications, an Internet service provider with about 3.3 million broadband customers in 25 states. Verizon said it expects to complete the merger on January 20. The last approval came from the California Public Utilities Commission (CPUC), which allowed the deal in a 5–0 vote yesterday. There were months of negotiations that resulted in requirements to deploy more fiber and wireless infrastructure, offer $20-per-month Internet service to people with low incomes for the next decade, and other commitments, including some designed to replace the DEI (diversity, equity, and inclusion) policies that Verizon had to end because of demands by the Trump administration. \"The approval follows extensive public participation, testimony from multiple parties, and negotiated settlement agreements with consumer advocates and labor organizations,\" the CPUC said yesterday.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/02/verizon-sign-logo-1152x648-1739298990.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/02/verizon-sign-logo-1152x648-1739298990.jpg",
      "popularity_score": 352.8693186111111
    },
    {
      "id": "cluster_41",
      "coverage": 1,
      "updated_at": "Fri, 16 Jan 2026 15:40:00 +0000",
      "title": "Feds give Tesla another five weeks to respond to FSD probe",
      "neutral_headline": "Feds give Tesla another five weeks to respond to FSD probe",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/feds-give-tesla-another-five-weeks-to-respond-to-fsd-probe/",
          "published_at": "Fri, 16 Jan 2026 15:40:00 +0000",
          "title": "Feds give Tesla another five weeks to respond to FSD probe",
          "standfirst": "Regulators want to know why Tesla's system ignores red lights and runs into traffic.",
          "content": "Late last year, the National Highway Traffic Safety Administration opened yet another investigation into Tesla and its partially automated driver assist systems. This time it was about FSD (again), which has been the subject of more than 60 complaints to the regulator after Teslas operating under FSD either ignored red traffic lights or crossed into oncoming traffic. As part of the preliminary investigation, NHTSA's Office of Defects Investigation has asked Tesla for more information on the problem. This week, it told the automaker it could have a five-week extension on its homework. To be fair to Tesla, NHTSA has asked for a comprehensive amount of information: a list of every Tesla produced and sold or leased in the United States, including whether or not that car had FSD and which version; cumulative data on how many US Teslas have FSD and how often it's used; and a list of all the customer complaints, field reports, incident reports, lawsuits, and other data related to FSD ignoring traffic laws. For each incident involving a crash, Tesla must give NHTSA a summary of the incident, including \"causal and contributing factors.\" Further questions require information on FSD use by crashed cars; any alert shown to the drivers; what work, simulation, or otherwise Tesla has conducted to ameliorate the problem; any modifications or changes to FSD hardware or software; an explanation of Tesla's theory of operation for traffic lights and stop signs; and Tesla's assessment of the problem.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1149999036-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1149999036-1152x648.jpg",
      "popularity_score": 345.3348741666667
    },
    {
      "id": "cluster_46",
      "coverage": 1,
      "updated_at": "Fri, 16 Jan 2026 15:00:31 +0000",
      "title": "Ferrari doing what it does best: The 12Cilindri review",
      "neutral_headline": "Ferrari doing what it does best: The 12Cilindri review",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/driven-the-ferrari-12cilindri-spider-is-open-top-grand-touring-bliss/",
          "published_at": "Fri, 16 Jan 2026 15:00:31 +0000",
          "title": "Ferrari doing what it does best: The 12Cilindri review",
          "standfirst": "Retro design and a naturally aspirated V12 deliver tremendous appeal, but it’ll cost ya.",
          "content": "It has been nearly 80 years since Ferrari unleashed its first V12-powered sports car upon the world with the 125 S. In 1947, its debut year, the 125 S secured Ferrari’s first race victory, along with five other wins in the 14 events it competed in that season. Although it was soon replaced by the 159 S, the success of the 125 S kick-started Ferrari’s storied history of producing some of the most desirable 12-cylinder performance cars known to man. And while the Italian automaker has come to embrace forced induction and electrification in recent years, its legacy of building stunning front-engine, rear-wheel drive machines with spectacular V12s stuffed into their engine bays continues with the 12Cilindri Spider. Ferrari hasn’t shied away from leveraging cutting-edge technology in the development of its latest models, but the company also understands the value of a good throwback. As the successor to the 812 Superfast, the 12Cilindri boasts clever performance technologies, like a sophisticated active aero system and a four-wheel steering system that can manage each corner independently to enhance response, but it’s ultimately an homage to the heady days of late '60s luxury grand touring. The exterior styling takes obvious inspiration from the 365 GTB Daytona, while its lack of all-wheel drive, turbocharging, and electric assistance bucks trends that have become nearly inescapable in modern performance cars.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/13-2025-Ferrari-12Cilindri-Spider-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/13-2025-Ferrari-12Cilindri-Spider-1152x648.jpg",
      "popularity_score": 339.6768186111111
    },
    {
      "id": "cluster_53",
      "coverage": 1,
      "updated_at": "Fri, 16 Jan 2026 14:16:26 +0000",
      "title": "Mother of one of Elon Musk’s offspring sues xAI over sexualized deepfakes",
      "neutral_headline": "Mother of one of Elon Musk’s offspring sues xAI over sexualized deepfakes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/mother-of-one-of-elon-musks-offspring-sues-xai-over-sexualized-deepfakes/",
          "published_at": "Fri, 16 Jan 2026 14:16:26 +0000",
          "title": "Mother of one of Elon Musk’s offspring sues xAI over sexualized deepfakes",
          "standfirst": "Claims Grok chatbot created \"countless\" sexual images of her without her consent.",
          "content": "Ashley St Clair, the influencer and mother of one of Elon Musk’s children, has sued the billionaire’s AI company, accusing its Grok chatbot of creating fake sexual imagery of her without her consent. In the lawsuit, filed in New York state court, St Clair alleged that xAI’s Grok first created an AI-generated or altered image of her in a bikini earlier this month. St Clair claims she made a request to xAI that no further such images be made, but nevertheless “countless sexually abusive, intimate, and degrading deepfake content of St. Clair [were] produced and distributed publicly by Grok.”Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ashleystclair-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ashleystclair-1152x648.jpg",
      "popularity_score": 332.9420963888889
    },
    {
      "id": "cluster_67",
      "coverage": 1,
      "updated_at": "Fri, 16 Jan 2026 12:00:50 +0000",
      "title": "Rocket Report: Ariane 64 to debut soon; India has a Falcon 9 clone too?",
      "neutral_headline": "Rocket Report: Ariane 64 to debut soon; India has a Falcon 9 clone too",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/rocket-report-ariane-64-to-debut-soon-india-has-a-falcon-9-clone-too/",
          "published_at": "Fri, 16 Jan 2026 12:00:50 +0000",
          "title": "Rocket Report: Ariane 64 to debut soon; India has a Falcon 9 clone too?",
          "standfirst": "\"We are fundamentally shifting our approach to securing our munitions supply chain.\"",
          "content": "Welcome to Edition 8.25 of the Rocket Report! All eyes are on Florida this weekend as NASA rolls out the Space Launch System rocket and Orion spacecraft to its launch site in Florida for the Artemis II mission. NASA has not announced a launch date yet, and this will depend in part on how well a \"wet dress rehearsal\" goes with fueling the rocket. However, it is likely the rocket has a no-earlier-than launch date of February 8. Our own Stephen Clark will be in Florida for the rollout on Saturday, so be sure and check back here for coverage. As always, we welcome reader submissions, and if you don't want to miss an issue, please subscribe using the box below (the form will not appear on AMP-enabled versions of the site). Each report will include information on small-, medium-, and heavy-lift rockets as well as a quick look ahead at the next three launches on the calendar. MaiaSpace scores a major launch deal. The ArianeGroup subsidiary, created in 2022, has inked a major new launch contract with satellite operator Eutelsat, Le Monde reports. A significant portion of the 440 new satellites ordered by Eutelsat from Airbus to renew or expand its OneWeb constellation will be launched into orbit by the new Maia rocket. MaiaSpace previously signed two contracts: one with Exotrail for the launch of an orbital transfer, and the other for two satellites for the Toutatis mission, a defense system developed by U-Space.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spacex-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spacex-1152x648.jpg",
      "popularity_score": 305.6820963888889
    },
    {
      "id": "cluster_91",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 21:29:58 +0000",
      "title": "Why I’m withholding certainty that “precise” US cyber-op disrupted Venezuelan electricity",
      "neutral_headline": "Why I’m withholding certainty that “precise” US...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/unnamed-officials-tell-nyt-precise-cyber-op-took-out-venezuelas-power-grid/",
          "published_at": "Thu, 15 Jan 2026 21:29:58 +0000",
          "title": "Why I’m withholding certainty that “precise” US cyber-op disrupted Venezuelan electricity",
          "standfirst": "NYT says US hackers were able to turn off power and then quickly turn it back on.",
          "content": "The New York Times has published new details about a purported cyberattack that unnamed US officials claim plunged parts of Venezuela into darkness in the lead-up to the capture of the country’s president, Nicolás Maduro. Key among the new details is that the cyber operation was able to turn off electricity for most residents in the capital city of Caracas for only a few minutes, though in some neighborhoods close to the military base where Maduro was seized, the outage lasted for three days. The cyber-op also targeted Venezuelan military radar defenses. The paper said the US Cyber Command was involved. Got more details? “Turning off the power in Caracas and interfering with radar allowed US military helicopters to move into the country undetected on their mission to capture Nicolás Maduro, the Venezuelan president who has now been brought to the United States to face drug charges,” the NYT reported.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/power-outage-electric-cord-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/power-outage-electric-cord-1152x648.jpg",
      "popularity_score": 294
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 23:01:24 +0000",
      "title": "“I am very annoyed”: Pharma execs blast RFK Jr.’s attack on vaccines",
      "neutral_headline": "“I am very annoyed”: Pharma execs blast RFK Jr.’s attack on vaccines",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/big-pharma-is-openly-railing-against-rfk-jr-s-anti-vaccine-agenda/",
          "published_at": "Thu, 15 Jan 2026 23:01:24 +0000",
          "title": "“I am very annoyed”: Pharma execs blast RFK Jr.’s attack on vaccines",
          "standfirst": "Pharma execs had avoided conflict with Trump admin, but now join doctors in rebukes.",
          "content": "Pharmaceutical executives are finally saying how they really feel about the extreme anti-vaccine agenda Health Secretary Robert F. Kennedy Jr. has been ruthlessly implementing—and it's not pretty. According to reporting from Bloomberg at the J.P. Morgan Healthcare Conference that ended today in San Francisco, pharmaceutical executives who had previously been careful to avoid criticizing the Trump administration appear to have reached a breaking point, with Pfizer CEO Albert Bourla offering some of the most candid comments. \"I am very annoyed. I'm very disappointed. I'm seriously frustrated,\" Bourla said. \"What is happening has zero scientific merit and is just serving an agenda which is political, and then antivax.\"Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/11/GettyImages-1232477788-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/11/GettyImages-1232477788-1152x648.jpeg",
      "popularity_score": 283
    },
    {
      "id": "cluster_96",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 20:19:41 +0000",
      "title": "NASA’s first medical evacuation from space ends with on-target splashdown",
      "neutral_headline": "NASA’s first medical evacuation from space ends with on-target splashdown",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasas-first-ever-medical-evacuation-from-space-ends-with-on-target-splashdown/",
          "published_at": "Thu, 15 Jan 2026 20:19:41 +0000",
          "title": "NASA’s first medical evacuation from space ends with on-target splashdown",
          "standfirst": "This is the first time NASA has called an early end to a space mission for medical reasons.",
          "content": "Two Americans, a Japanese astronaut, and a Russian cosmonaut returned to Earth early Thursday after 167 days in orbit, cutting short their stay on the International Space Station by more than a month after one of the crew members encountered an unspecified medical issue last week. The early homecoming culminated in an on-target splashdown in the Pacific Ocean off the coast of San Diego at 12:41 am PST (08:41 UTC) inside a SpaceX Crew Dragon spacecraft. The splashdown occurred minutes after the Dragon capsule streaked through the atmosphere along the California coastline, with sightings of Dragon's fiery trail reported from San Francisco to Los Angeles. Four parachutes opened to slow the capsule for the final descent. Zena Cardman, NASA's commander of the Crew-11 mission, radioed SpaceX mission control moments after splashdown: \"It feels good to be home, with deep gratitude to the teams who got us there and back.\"Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/55042362006_eb0e4d16ab_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/55042362006_eb0e4d16ab_k-1152x648.jpg",
      "popularity_score": 267
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 21:09:10 +0000",
      "title": "Star Trek: Starfleet Academy tries something different, and I don’t hate it",
      "neutral_headline": "Star Trek: Starfleet Academy tries something different, and I don’t hate it",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/star-trek-starfleet-academy-tries-something-different-and-i-dont-hate-it/",
          "published_at": "Thu, 15 Jan 2026 21:09:10 +0000",
          "title": "Star Trek: Starfleet Academy tries something different, and I don’t hate it",
          "standfirst": "An interesting new take on Trek includes some characters you already know.",
          "content": "This post contains some mild spoilers, mostly from the beginning of the first episode. Today is a good day to watch television. That's because the first two episodes of Star Trek: Starfleet Academy hit the Paramount+ streaming service, becoming the newest addition to the long-running Star Trek franchise. It's set in the late 32nd century, 120 years after the burn that ended all warp travel, and with it, most of Starfleet in the process. Now that warp travel is once again possible—you'll have to watch Discovery's final three seasons for more on that—the Federation is putting itself back together, and that includes reopening Starfleet Academy. That means this show is about young people in space, like Caleb Mir (Sandro Rosta), who was separated from his mother by Starfleet as a child, 15 years earlier. Mir and his mother, played by Tatiana Maslany, were traveling with a pirate—Nus Braka, played by a scenery-chewing Paul Giamatti—who killed a Federation officer while stealing food for them. The first episode opens on Braka and the Mirs being apprehended by Starfleet. Despite her misgivings, Captain Nahla Ake (Holly Hunter) carries out her order to separate mother and child. She's to go to a rehabilitation colony, he's to become a ward of the Federation and go to school on Bajor. At least that's the plan until he escapes a few minutes later. Then we jump forward 15 years. Ake is teaching on Bajor, having retired from the Federation, ashamed of what she'd done. Admiral Vance (Oded Fehr) shows up and asks her to become commandant at the newly reopened academy in San Francisco; for the past few decades, new recruits have been trained instead by the War College. But Starfleet needs explorers now, and having a rival school means they can show up at some point to challenge some of the show's protagonists to a Parrises Squares tournament.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/SFA_101_BP_0918_0764_RT_f-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/SFA_101_BP_0918_0764_RT_f-1152x648.jpg",
      "popularity_score": 263
    },
    {
      "id": "cluster_101",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 19:22:07 +0000",
      "title": "Spotify’s 3rd price hike in 2.5 years hints at potential new normal",
      "neutral_headline": "Spotify’s 3rd price hike in 2.5 years hints at potential new normal",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/spotify-to-raise-subscription-prices-by-up-to-2-in-february/",
          "published_at": "Thu, 15 Jan 2026 19:22:07 +0000",
          "title": "Spotify’s 3rd price hike in 2.5 years hints at potential new normal",
          "standfirst": "Spotify claims the higher fees will help \"benefit artists.\"",
          "content": "After a dozen years of keeping subscription prices stable, Spotify has issued three price hikes in 2.5 years. Spotify informed subscribers via email today that Premium monthly subscriptions would go from $12 to $13 per month as of users' February billing date. Spotify is already advertising the higher prices to new subscribers. Although not explicitly mentioned in Spotify's correspondence, other plans are getting more expensive, too. Student monthly subscriptions are going from $6 to $7. Duo monthly plans, for two accounts in the same household, are going from $17 to $19, and Family plans, for up to six users, are moving from $20 to $22.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2248295045-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2248295045-1024x648.jpg",
      "popularity_score": 243
    },
    {
      "id": "cluster_109",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 17:46:40 +0000",
      "title": "Many Bluetooth devices with Google Fast Pair vulnerable to “WhisperPair” hack",
      "neutral_headline": "Many Bluetooth devices with Google Fast Pair vulnerable to “WhisperPair” hack",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/researchers-reveal-whisperpair-attack-to-eavesdrop-on-google-fast-pair-headphones/",
          "published_at": "Thu, 15 Jan 2026 17:46:40 +0000",
          "title": "Many Bluetooth devices with Google Fast Pair vulnerable to “WhisperPair” hack",
          "standfirst": "Even Google's own earbuds are vulnerable to the Fast Pair hack.",
          "content": "Pairing Bluetooth devices can be a pain, but Google Fast Pair makes it almost seamless. Unfortunately, it may also leave your headphones vulnerable to remote hacking. A team of security researchers from Belgium’s KU Leuven University has revealed a vulnerability dubbed WhisperPair that allows an attacker to hijack Fast Pair-enabled devices to spy on the owner. Fast Pair is widely used, and your device may be vulnerable even if you've never used a Google product. The bug affects more than a dozen devices from 10 manufacturers, including Sony, Nothing, JBL, OnePlus, and Google itself. Google has acknowledged the flaw and notified its partners of the danger, but it's up to these individual companies to create patches for their accessories. A full list of vulnerable devices is available on the project's website. The researchers say that it takes only a moment to gain control of a vulnerable Fast Pair device (a median of just 10 seconds) at ranges up to 14 meters. That's near the limit of the Bluetooth protocol and far enough that the target wouldn't notice anyone skulking around while they hack headphones.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Buds-Pro-2-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Buds-Pro-2-1-1152x648.jpg",
      "popularity_score": 176
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 19:07:09 +0000",
      "title": "ChatGPT wrote “Goodnight Moon” suicide lullaby for man who later killed himself",
      "neutral_headline": "ChatGPT wrote “Goodnight Moon” suicide lullaby for man who later killed himself",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/chatgpt-wrote-goodnight-moon-suicide-lullaby-for-man-who-later-killed-himself/",
          "published_at": "Thu, 15 Jan 2026 19:07:09 +0000",
          "title": "ChatGPT wrote “Goodnight Moon” suicide lullaby for man who later killed himself",
          "standfirst": "ChatGPT used a man's favorite children's book to romanticize his suicide.",
          "content": "OpenAI is once again being accused of failing to do enough to prevent ChatGPT from encouraging suicides, even after a series of safety updates were made to a controversial model, 4o, which OpenAI designed to feel like a user's closest confidant. It's now been revealed that one of the most shocking ChatGPT-linked suicides happened shortly after Sam Altman claimed on X that ChatGPT 4o was safe. OpenAI had \"been able to mitigate the serious mental health issues\" associated with ChatGPT use, Altman claimed in October, hoping to alleviate concerns after ChatGPT became a \"suicide coach\" for a vulnerable teenager named Adam Raine, the family's lawsuit said. Altman's post came on October 14. About two weeks later, 40-year-old Austin Gordon, died by suicide between October 29 and November 2, according to a lawsuit filed by his mother, Stephanie Gray.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2236630617-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2236630617-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 14:22:35 +0000",
      "title": "US government to take 25% cut of AMD, NVIDIA AI sales to China",
      "neutral_headline": "US government to take 25% cut of AMD, NVIDIA AI sales to China",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/us-government-to-take-25-cut-of-amd-nvidia-ai-sales-to-china/",
          "published_at": "Thu, 15 Jan 2026 14:22:35 +0000",
          "title": "US government to take 25% cut of AMD, NVIDIA AI sales to China",
          "standfirst": "These new tariffs are designed to survive legal challenges.",
          "content": "US President Donald Trump has announced new tariffs on Nvidia and AMD as part of a novel scheme to enact a deal with the technology giants to take a 25 percent cut of sales of their AI processors to China. In December, the White House said it would allow Nvidia to start shipping its H200 chips to China, reversing a policy that prohibited the export of advanced AI hardware. However, it demanded a 25 percent cut of the sales. The new US tariffs on certain chips, announced on Wednesday, were designed to implement these payments and protect the unusual arrangement from legal challenges, according to several industry executives.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/GettyImages-2200759945-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/GettyImages-2200759945-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_121",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 15:15:15 +0000",
      "title": "Key Senate staffer is “begging” NASA to get on with commercial space stations",
      "neutral_headline": "Key Senate staffer is “begging” NASA to get on with commercial space stations",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/key-senate-staffer-is-begging-nasa-to-get-on-with-commercial-space-stations/",
          "published_at": "Thu, 15 Jan 2026 15:15:15 +0000",
          "title": "Key Senate staffer is “begging” NASA to get on with commercial space stations",
          "standfirst": "\"It comes up almost every time that I see him. Continuous human presence and no gap.\"",
          "content": "In remarks this week to a Texas space organization, a key Senate staff member said an \"extension\" of the International Space Station is on the table and that NASA needs to accelerate a program to replace the aging station with commercial alternatives. Maddy Davis, a space policy staff member for US Sen. Ted Cruz, R-Texas, made the comments to the Texas Space Coalition during a virtual event. Cruz is chairman of the Senate Committee on Commerce, Science, and Transportation and has an outsized say in space policy. As a senator from Texas, he has a parochial interest in Johnson Space Center, where the International Space Station Program is led.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/51814201006_e93b98b15e_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/51814201006_e93b98b15e_k-1152x648.jpg",
      "popularity_score": 141
    },
    {
      "id": "cluster_144",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 08:00:15 +0000",
      "title": "Exclusive: Volvo tells us why having Gemini in your next car is a good thing",
      "neutral_headline": "Volvo tells us why having Gemini in your next car is a good thing",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/exclusive-volvo-tells-us-why-having-gemini-in-your-next-car-is-a-good-thing/",
          "published_at": "Thu, 15 Jan 2026 08:00:15 +0000",
          "title": "Exclusive: Volvo tells us why having Gemini in your next car is a good thing",
          "standfirst": "In-car personal assistants are about to get useful, it looks like.",
          "content": "Next week, Volvo shows off its new EX60 SUV to the world. It's the brand's next electric vehicle, one built on an all-new, EV-only platform that makes use of the latest in vehicle design trends, like a cell-to-body battery pack, large weight-saving castings, and an advanced electronic architecture run by a handful of computers capable of more than 250 trillion operations per second. This new software-defined platform even has a name: HuginCore, after one of the two ravens that collected information for the Norse god Odin. It's not Volvo's first reference to mythology. \"We have Thor's Hammer [Volvo's distinctive headlight design] and now we have HuginCore... one of the two trusted Ravens of Oden. He sent Hugin and Muninn out to fly across the realms and observe and gather information and knowledge, which they then share with Odin that enabled him to make the right decisions as the ruler of Asgard,\" said Alwin Bakkenes, head of global software engineering at Volvo Cars. \"And much like Hugin, the way we look at this technology platform, it collects information from all of the sensors, all of the actuators in the vehicle. It understands the world around the vehicle, and it enables us to actually anticipate around what lies ahead,\" Bakkenes told me.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-1152x648.jpg",
      "popularity_score": 141
    },
    {
      "id": "cluster_134",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 12:00:57 +0000",
      "title": "The difficulty of driving an EV in the “most beautiful race in the world”",
      "neutral_headline": "The difficulty of driving an EV in the “most beautiful race in the world”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2026/01/the-difficulty-of-driving-an-ev-in-the-most-beautiful-race-in-the-world/",
          "published_at": "Thu, 15 Jan 2026 12:00:57 +0000",
          "title": "The difficulty of driving an EV in the “most beautiful race in the world”",
          "standfirst": "Jet lag and charging added plenty of complications to this regularity road rally.",
          "content": "Polestar provided flights from Los Angeles to Milan and accommodation so Ars could participate in the Green Mille Miglia. Ars does not accept paid editorial content. On the first day of this year’s Mille Miglia, a voice rose from the crowds gathered on the shore of Lago di Garda to shout “no sound, no feeling!”at my Polestar 3. Italians love their cars, and they revealed a clear preference for internal combustion engines over the next four days and over 1,200 km of driving. But plenty of other spectators smiled and waved, and some even did a double-take at seeing an electric vehicle amid the sea of modern Ferraris and world-class vintage racers taking on this modern regulation rally. I flew to Italy to join the Mille Miglia “Green,” which, for the past five years, has sought to raise awareness of sustainability and electric cars amid this famous (some might say infamous) race. And despite mixed reactions from the Italian crowds, our Polestar 3 performed quite well as it traced a historical route from Brescia to Rome and back. The route snaked a trail through the Italian countryside based on the original speed race’s first 12 outings, but instead of going for overall pace, we spent five days competing against six other EVs for points based on time, distance, and average speed. Our team included a Polestar 2 and 4, and we faced a Mercedes-Benz G 580 with EQ Technology, an Abarth 600e, a Lotus Eletre, and a BYD Denza Z9GT saloon.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Polestar-Mille-Miglia-Pics-18-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Polestar-Mille-Miglia-Pics-18-1152x648.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_103",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 18:54:57 +0000",
      "title": "Six months later, Trump Mobile still hasn’t delivered preordered phones",
      "neutral_headline": "Six months later, Trump Mobile still hasn’t delivered preordered phones",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/democrats-ask-trumps-ftc-to-investigate-trump-mobiles-broken-promises/",
          "published_at": "Thu, 15 Jan 2026 18:54:57 +0000",
          "title": "Six months later, Trump Mobile still hasn’t delivered preordered phones",
          "standfirst": "Lawmakers seek FTC investigation, but Trump has taken control of the agency.",
          "content": "Sen. Elizabeth Warren (D-Mass.) and 10 other Democratic members of Congress today urged the Federal Trade Commission to investigate Trump Mobile's broken promises related to Trump phone delivery dates and claims that it is \"made in the USA.\" The request isn't likely to get very far. Trump declared early in his second term that independent agencies like the FTC may no longer operate independently from the White House, and FTC Chairman Andrew Ferguson has backed Trump's claim of authority over historically independent agencies. The Supreme Court appears likely to approve Trump's firing of an FTC Democrat, giving him expanded power over the agency. The letter, led by Warren and other lawmakers, was sent to Ferguson. \"We write today regarding questions about false advertising and deceptive practices by Trump Mobile, and to seek information on how the Federal Trade Commission (FTC) intends to address any potential violations of consumer protection law given the inherent conflicts of interest presented by the company’s relationship to President Donald Trump,\" the letter said.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/trump-mobile-1152x648-1750889842.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/trump-mobile-1152x648-1750889842.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_106",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 18:37:34 +0000",
      "title": "Are people avoiding iOS 26 because of Liquid Glass? It’s complicated.",
      "neutral_headline": "Are people avoiding iOS 26 because of Liquid Glass? It’s complicated.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/are-people-avoiding-ios-26-because-of-liquid-glass-its-complicated/",
          "published_at": "Thu, 15 Jan 2026 18:37:34 +0000",
          "title": "Are people avoiding iOS 26 because of Liquid Glass? It’s complicated.",
          "standfirst": "Liquid Glass is controversial, but adoption rates aren't as low as they seem.",
          "content": "Last week, news about the adoption rates for Apple's iOS 26 update started making the rounds. The new update, these reports claim, was being installed at dramatically lower rates than past iOS updates. And while we can't infer anything about why people might choose not to install iOS 26, the conclusion being jumped to is that iPhone users are simply desperate to avoid the redesigned Liquid Glass user interface. The numbers do, in fact, look bad: Statcounter data for January suggests that the various versions of iOS 26 are running on just 16.6 percent of all devices, compared to around 70 percent for the various versions of iOS 18. The iOS 18.7 update alone—released at the same time as iOS 26.0 in September for people who wanted the security patches but weren't ready to step up to a brand-new OS—appears to be running on nearly one-third of all iOS devices. Those original reports were picked up and repeated because they tell a potentially interesting story of the \"huge if true\" variety: that users' aversion to the Liquid Glass design is so intense and widespread that it's actively keeping users away from the operating system. But after examining our own traffic numbers, as well as some technical changes made in iOS 26, it appears Statcounter's data is dramatically undercounting the number of iOS 26 devices in the wild.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Screenshot-2025-06-09-at-12.40.54%E2%80%AFPM-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Screenshot-2025-06-09-at-12.40.54%E2%80%AFPM-1152x648.jpeg",
      "popularity_score": 133
    },
    {
      "id": "cluster_117",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 16:23:14 +0000",
      "title": "Bully Online mod taken down abruptly one month after launch",
      "neutral_headline": "Bully Online mod taken down abruptly one month after launch",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/online-mod-for-rockstars-classic-bully-is-abruptly-taken-down-after-one-month/",
          "published_at": "Thu, 15 Jan 2026 16:23:14 +0000",
          "title": "Bully Online mod taken down abruptly one month after launch",
          "standfirst": "Developers say \"this was not something we wanted\" as they purge open source project.",
          "content": "A PC mod that added online gameplay to Rockstar's 2006 school-exploration title Bully was abruptly taken down on Wednesday, roughly a month after it was first made available. While the specific reason for the \"Bully Online\" takedown hasn't been publicly discussed, a message posted by the developers to the project's now-defunct Discord server clarifies that \"this was not something we wanted.\" The Bully Online mod was spearheaded by Swegta, a Rockstar-focused YouTuber who formally announced the project in October as a mod that \"allows you and your friends to play minigames, role-play, compete in racing, fend off against NPCs, and much more.\" At the time of the announcement, Swegta said the mod was \"a project me and my team have been working on for a very long time\" and that early access in December would be limited to those who contributed at least $8 to a Ko-Fi account. When December actually rolled around, though, a message on Swegta.com (archived) suggested that the mod was being released freely as an open source project, with a registration page (archived) offering new accounts to anyone.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/bullyonline.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/bullyonline.png",
      "popularity_score": 133
    }
  ]
}