{
  "updated_at": "2026-01-04T19:16:04.458Z",
  "clusters": [
    {
      "id": "cluster_1",
      "coverage": 2,
      "updated_at": "Sun, 04 Jan 2026 19:01:27 +0000",
      "title": "How to watch the Lenovo Tech World event at CES 2026",
      "neutral_headline": "How to watch the Lenovo Tech World event at CES 2026",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/how-to-watch-the-lenovo-tech-world-event-at-ces-2026-130004983.html",
          "published_at": "Sun, 04 Jan 2026 19:01:27 +0000",
          "title": "How to watch the Lenovo Tech World event at CES 2026",
          "standfirst": "We've known for several months now that tech giant Lenovo is hosting its Tech World event at Sphere is Las Vegas during CES week. And like many other tech conglomerates, the world's largest PC manufacturer by units shipped is centering its focus on AI. Lenovo says it will be a \"Tech World experience unlike anything CES has seen before.\" We'll tell you where to livestream the event and what the company has teased so far. How to watch the Lenovo CES 2026 event live Lenovo CEO Yuanqing Yang will host the event on Tuesday, January 6 at 8PM ET. You can follow along to the livestream on YouTube once the event starts. (We've embedded the code below.) What to expect Lenovo is using the high-profile Sphere venue to share some of its tie-ins to the sports world, offering an exclusive look at how the company's technology has \"revolutionized F1,\" Yang said in a press release. He'll also preview the plans for leveraging AI at this summer's FIFA World Cup, which takes place in the US. After the event has wrapped up, pop singer Gwen Stefani will take the stage to perform. As for real products, look for Lenovo to build on some of its successful launches from CES 2025. A year ago, we saw the portable Lenovo Legion Go S – the first third-party SteamOS handheld gaming device – as well as its \"stretchy\" laptop, the ThinkBook Plus Gen 6 Rollable that extends 2.7 inches taller with a touch of a button. To Lenovo's credit, both products were actually released and available for sale within months, unlike the vaporware that seems to comprise the bulk of many companies' CES announcements. Lastly, don't be surprised if we see some new Motorola smartphones, given that Lenovo is the parent company of the phone manufacturer. Maybe a new Razr foldable? We'll find out either way on Tuesday evening.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-lenovo-tech-world-event-at-ces-2026-130004983.html?src=rss",
          "content": "We've known for several months now that tech giant Lenovo is hosting its Tech World event at Sphere is Las Vegas during CES week. And like many other tech conglomerates, the world's largest PC manufacturer by units shipped is centering its focus on AI. Lenovo says it will be a \"Tech World experience unlike anything CES has seen before.\" We'll tell you where to livestream the event and what the company has teased so far. How to watch the Lenovo CES 2026 event live Lenovo CEO Yuanqing Yang will host the event on Tuesday, January 6 at 8PM ET. You can follow along to the livestream on YouTube once the event starts. (We've embedded the code below.) What to expect Lenovo is using the high-profile Sphere venue to share some of its tie-ins to the sports world, offering an exclusive look at how the company's technology has \"revolutionized F1,\" Yang said in a press release. He'll also preview the plans for leveraging AI at this summer's FIFA World Cup, which takes place in the US. After the event has wrapped up, pop singer Gwen Stefani will take the stage to perform. As for real products, look for Lenovo to build on some of its successful launches from CES 2025. A year ago, we saw the portable Lenovo Legion Go S – the first third-party SteamOS handheld gaming device – as well as its \"stretchy\" laptop, the ThinkBook Plus Gen 6 Rollable that extends 2.7 inches taller with a touch of a button. To Lenovo's credit, both products were actually released and available for sale within months, unlike the vaporware that seems to comprise the bulk of many companies' CES announcements. Lastly, don't be surprised if we see some new Motorola smartphones, given that Lenovo is the parent company of the phone manufacturer. Maybe a new Razr foldable? We'll find out either way on Tuesday evening.This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-lenovo-tech-world-event-at-ces-2026-130004983.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/how-to-watch-the-lg-ces-2026-press-conference-190159378.html",
          "published_at": "Sun, 04 Jan 2026 18:10:35 +0000",
          "title": "How to watch the LG CES 2026 press conference",
          "standfirst": "LG For years, LG has opened CES press day with the first event of the morning. Though arch-rival Samsung getting the jump on its fellow Korean rival by giving its presentation the evening before, LG will be hitting the podium at breakfast time with the theme \"Innovation in Tune with You.\" As with many tech-focused events nowadays, AI is expected to serve as the unifying thread of LG's CES 2026 presentation. That said, LG — much like Apple — has its own take on the acronym, referring to it as \"Affectionate Intelligence.\" The company will share \"its vision for elevating daily life through Affectionate Intelligence — delivering harmonized and seamlessly connected customer experiences.\" The irony, though, is that LG has already shown its cards, thanks to a long string of pre-show press releases offering details about a litany of new products (see below). How to watch LG's CES 2026 presentation The event will stream live from Las Vegas on Monday, January 5 at 11AM ET. You've got a few options for tuning in — watch the livestream on the LG website, the LG Global X channel or the LG Global YouTube channel (embedded below). What to expect Here's what LG has already confirmed it will be showcasing at CES 2026: LG will debut its first Micro RGB TV, a display with a cutting-edge screen technology with multicolor backlights that should one-up mini LED displays. The size options are 100 inches, 86 inches and 75 inches. The company is countering Samsung's Frame TVs with its new LG Gallery TV, arriving in 55- and 65-inch screen sizes. Look for a new LG humanoid home automation robot named CLOiD to take the stage. In the audio realm, the Korean multinational will also introduce a Dolby-powered modular home audio system and a new line of its xboom speakers (developed with musician will.i.am). LG is revamping its ultralight Gram laptop line with a proprietary material it calls Aerominum. Does that leave any surprises for the CES press conference? We'll find out on January 5. Update, December 31 2025, 12:36PM ET: This story has been updated to include more LG CES pre-announcements, and to embed the YouTube stream. Update, January 4 2026, 1:09PM ET: This story has been updated to include information on LG's new laptop line. This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-lg-ces-2026-press-conference-190159378.html?src=rss",
          "content": "LG For years, LG has opened CES press day with the first event of the morning. Though arch-rival Samsung getting the jump on its fellow Korean rival by giving its presentation the evening before, LG will be hitting the podium at breakfast time with the theme \"Innovation in Tune with You.\" As with many tech-focused events nowadays, AI is expected to serve as the unifying thread of LG's CES 2026 presentation. That said, LG — much like Apple — has its own take on the acronym, referring to it as \"Affectionate Intelligence.\" The company will share \"its vision for elevating daily life through Affectionate Intelligence — delivering harmonized and seamlessly connected customer experiences.\" The irony, though, is that LG has already shown its cards, thanks to a long string of pre-show press releases offering details about a litany of new products (see below). How to watch LG's CES 2026 presentation The event will stream live from Las Vegas on Monday, January 5 at 11AM ET. You've got a few options for tuning in — watch the livestream on the LG website, the LG Global X channel or the LG Global YouTube channel (embedded below). What to expect Here's what LG has already confirmed it will be showcasing at CES 2026: LG will debut its first Micro RGB TV, a display with a cutting-edge screen technology with multicolor backlights that should one-up mini LED displays. The size options are 100 inches, 86 inches and 75 inches. The company is countering Samsung's Frame TVs with its new LG Gallery TV, arriving in 55- and 65-inch screen sizes. Look for a new LG humanoid home automation robot named CLOiD to take the stage. In the audio realm, the Korean multinational will also introduce a Dolby-powered modular home audio system and a new line of its xboom speakers (developed with musician will.i.am). LG is revamping its ultralight Gram laptop line with a proprietary material it calls Aerominum. Does that leave any surprises for the CES press conference? We'll find out on January 5. Update, December 31 2025, 12:36PM ET: This story has been updated to include more LG CES pre-announcements, and to embed the YouTube stream. Update, January 4 2026, 1:09PM ET: This story has been updated to include information on LG's new laptop line. This article originally appeared on Engadget at https://www.engadget.com/home/how-to-watch-the-lg-ces-2026-press-conference-190159378.html?src=rss",
          "feed_position": 1,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/6f089c60-db4f-11f0-ab9d-5c52fd4922f7"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/how-to-watch-the-samsung-first-look-ces-2026-presentation-190027420.html",
          "published_at": "Sun, 04 Jan 2026 16:16:26 +0000",
          "title": "How to watch the Samsung 'First Look' CES 2026 presentation",
          "standfirst": "NurPhoto via Getty Images Samsung is arguably the 800-pound gorilla of CES, since many of the other consumer tech titans — Apple, Google, Microsoft, Meta, Amazon — either no longer have a presence, or have never shown up to begin with. In the past, that's given Samsung free range to bow a full spectrum of products that range from phones and computers to refrigerators, AI assistants and rolling robots. But for CES 2026, the company is switching things up a bit: Instead of its longtime midday Monday press conference, the Korean giant will take the lead of the show with a Sunday night presentation. Over the past few weeks, Samsung has been dropping press releases left and right, so we know at least some of what to expect in Vegas this year. Of course, we're holding out hope that we get to hear an update on the Ballie robot — a star of previous CES presentations that ostensibly missed its previously promised 2025 release date. How to watch Samsung's \"The First Look\" presentation at CES 2026 The event will stream live from the Wynn Hotel in Las Vegas on Sunday, January 4 at 10PM ET. There are several ways to tune in: you can watch via Samsung Electronic' official YouTube channel (which we've embedded below), Samsung Newsroom or via Samsung TV Plus. What to expect from Samsung at CES 2026 Keynote speaker TM Roh, the CEO of Samsung's Device eXperience (DX) Division, will discuss the company's plans for the new year and beyond, which will (of course) include \"new AI-driven customer experiences,\" the company said in a press release. In addition, we'll hear from the President and Head of the Visual Display Business, SW Yong and Executive Vice President and Head of Digital Appliances Business, Cheolgi Kim. Those two will \"share their respective business directions for the upcoming year.\" But if you're looking for more specifics, Samsung has been following its \"Advent calendar\" approach to early CES announcements, with new press releases dropping nearly every day in late December and early January. So far, we know that — like competitors LG and Hisense — the company will be offering details on a line of micro RGB TVs (replete with confirmed screen sizes of 55 to 115 inches). Also confirmed: a full line of appliances infused with what Samsung calls Bespoke AI. Samsung will also display its two newest speakers, Music Studio 5 and 7, at CES this year. Additionally, it'll debut its latest Freestyle+ portable projector. Just before the holidays, Samsung also unveiled a slew of new gaming monitors, but most impressive is the Odyssey gaming monitor. It boasts a 32-inch 6K screen and has glasses-free 3D. It's likely we could see this at CES, along with other models like the 27-inch Odyssey G6 and the Odyssey G8 models. It's possible that Samsung will share even more early CES announcements in the hours preceding its presentation. If that happens, we'll add them here! Update, January 4 2026, 11:15AM ET: This story has been updated to include the embedded YouTube viewer for the Samsung event.This article originally appeared on Engadget at https://www.engadget.com/mobile/how-to-watch-the-samsung-first-look-ces-2026-presentation-190027420.html?src=rss",
          "content": "NurPhoto via Getty Images Samsung is arguably the 800-pound gorilla of CES, since many of the other consumer tech titans — Apple, Google, Microsoft, Meta, Amazon — either no longer have a presence, or have never shown up to begin with. In the past, that's given Samsung free range to bow a full spectrum of products that range from phones and computers to refrigerators, AI assistants and rolling robots. But for CES 2026, the company is switching things up a bit: Instead of its longtime midday Monday press conference, the Korean giant will take the lead of the show with a Sunday night presentation. Over the past few weeks, Samsung has been dropping press releases left and right, so we know at least some of what to expect in Vegas this year. Of course, we're holding out hope that we get to hear an update on the Ballie robot — a star of previous CES presentations that ostensibly missed its previously promised 2025 release date. How to watch Samsung's \"The First Look\" presentation at CES 2026 The event will stream live from the Wynn Hotel in Las Vegas on Sunday, January 4 at 10PM ET. There are several ways to tune in: you can watch via Samsung Electronic' official YouTube channel (which we've embedded below), Samsung Newsroom or via Samsung TV Plus. What to expect from Samsung at CES 2026 Keynote speaker TM Roh, the CEO of Samsung's Device eXperience (DX) Division, will discuss the company's plans for the new year and beyond, which will (of course) include \"new AI-driven customer experiences,\" the company said in a press release. In addition, we'll hear from the President and Head of the Visual Display Business, SW Yong and Executive Vice President and Head of Digital Appliances Business, Cheolgi Kim. Those two will \"share their respective business directions for the upcoming year.\" But if you're looking for more specifics, Samsung has been following its \"Advent calendar\" approach to early CES announcements, with new press releases dropping nearly every day in late December and early January. So far, we know that — like competitors LG and Hisense — the company will be offering details on a line of micro RGB TVs (replete with confirmed screen sizes of 55 to 115 inches). Also confirmed: a full line of appliances infused with what Samsung calls Bespoke AI. Samsung will also display its two newest speakers, Music Studio 5 and 7, at CES this year. Additionally, it'll debut its latest Freestyle+ portable projector. Just before the holidays, Samsung also unveiled a slew of new gaming monitors, but most impressive is the Odyssey gaming monitor. It boasts a 32-inch 6K screen and has glasses-free 3D. It's likely we could see this at CES, along with other models like the 27-inch Odyssey G6 and the Odyssey G8 models. It's possible that Samsung will share even more early CES announcements in the hours preceding its presentation. If that happens, we'll add them here! Update, January 4 2026, 11:15AM ET: This story has been updated to include the embedded YouTube viewer for the Samsung event.This article originally appeared on Engadget at https://www.engadget.com/mobile/how-to-watch-the-samsung-first-look-ces-2026-presentation-190027420.html?src=rss",
          "feed_position": 4,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/54afdb10-dd18-11f0-b2f7-d2b3086683ec"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/how-to-watch-the-intel-ces-2026-launch-event-130040089.html",
          "published_at": "Sun, 04 Jan 2026 13:00:40 +0000",
          "title": "How to watch the Intel CES 2026 launch event",
          "standfirst": "SOPA Images via Getty Images We're just hours away from the start of CES 2026, and with that comes Intel's launch event. The chip giant is expected to provide more details on its AI PC initiative and the new processors powering it: The Core Ultra Series 3 CPUs (aka Panther Lake) are made using an 18A process — that's 18 angstroms, or just under 2nm — and designed for high-end laptops and gaming devices. For Intel, the stakes at CES are higher than ever. In the past 12 months, both NVIDIA and the US government acquired ownership stakes in the company, helping nearly double the stock price by the end of the year. But that's still down over more than 20 percent since 2021, as rivals like TSMC, Qualcomm, AMD and NVIDIA have taken the leadership mantle in chip fabrication and AI hardware. How to watch Intel's launch event Senior VP of Intel's Client Computing Group Jim Johnson will kick off the launch event on Monday, January 5 at 6PM ET. A livestream will be available on the Intel Newsroom YouTube channel, which we'll post here when it's live. What to expect from Intel at CES 2026 As we noted above, Intel has publicly confirmed that it will be highlighting \"the next generation of Intel-powered PCs, edge solution, and the AI experiences enabled by the new Intel Core Ultra Series 3 Processors.\" We'll be keen to hear if the company can address the profitability concerns that have surrounded those next-gen chips since at least last summer, when published reports indicated that yields were still under 50 percent. (In response, Intel told Engadget that it felt \"very good\" about its trajectory on Panther Lake, though it didn't hit the late 2025 release date it had envisioned at the time.) Will we get any updates on that NVIDIA partnership? It's possible. But don't expect to hear anything about Intel possibly fabricating the chips for that rumored new entry-level MacBook Air. If that comes to pass, the announcement will definitely be at a time and place of Apple's choosing. This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-intel-ces-2026-launch-event-130040089.html?src=rss",
          "content": "SOPA Images via Getty Images We're just hours away from the start of CES 2026, and with that comes Intel's launch event. The chip giant is expected to provide more details on its AI PC initiative and the new processors powering it: The Core Ultra Series 3 CPUs (aka Panther Lake) are made using an 18A process — that's 18 angstroms, or just under 2nm — and designed for high-end laptops and gaming devices. For Intel, the stakes at CES are higher than ever. In the past 12 months, both NVIDIA and the US government acquired ownership stakes in the company, helping nearly double the stock price by the end of the year. But that's still down over more than 20 percent since 2021, as rivals like TSMC, Qualcomm, AMD and NVIDIA have taken the leadership mantle in chip fabrication and AI hardware. How to watch Intel's launch event Senior VP of Intel's Client Computing Group Jim Johnson will kick off the launch event on Monday, January 5 at 6PM ET. A livestream will be available on the Intel Newsroom YouTube channel, which we'll post here when it's live. What to expect from Intel at CES 2026 As we noted above, Intel has publicly confirmed that it will be highlighting \"the next generation of Intel-powered PCs, edge solution, and the AI experiences enabled by the new Intel Core Ultra Series 3 Processors.\" We'll be keen to hear if the company can address the profitability concerns that have surrounded those next-gen chips since at least last summer, when published reports indicated that yields were still under 50 percent. (In response, Intel told Engadget that it felt \"very good\" about its trajectory on Panther Lake, though it didn't hit the late 2025 release date it had envisioned at the time.) Will we get any updates on that NVIDIA partnership? It's possible. But don't expect to hear anything about Intel possibly fabricating the chips for that rumored new entry-level MacBook Air. If that comes to pass, the announcement will definitely be at a time and place of Apple's choosing. This article originally appeared on Engadget at https://www.engadget.com/computing/how-to-watch-the-intel-ces-2026-launch-event-130040089.html?src=rss",
          "feed_position": 6,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/9e1dc860-e813-11f0-bffc-4cb5d6b5aab1"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/why-which-api-do-i-call-is-the-wrong-question-in-the-llm-era",
          "published_at": "Sat, 03 Jan 2026 22:00:00 GMT",
          "title": "Why “which API do I call?” is the wrong question in the LLM era",
          "standfirst": "For decades, we have adapted to software. We learned shell commands, memorized HTTP method names and wired together SDKs. Each interface assumed we would speak its language. In the 1980s, we typed &#x27;grep&#x27;, &#x27;ssh&#x27; and &#x27;ls&#x27; into a shell; by the mid-2000s, we were invoking REST endpoints like GET /users; by the 2010s, we imported SDKs (client.orders.list()) so we didn’t have to think about HTTP. But underlying each of those steps was the same premise: Expose capabilities in a structured form so others can invoke them.But now we are entering the next interface paradigm. Modern LLMs are challenging the notion that a user must choose a function or remember a method signature. Instead of “Which API do I call?” the question becomes: “What outcome am I trying to achieve?” In other words, the interface is shifting from code → to language. In this shift, Model Context Protocol (MCP) emerges as the abstraction that allows models to interpret human intent, discover capabilities and execute workflows, effectively exposing software functions not as programmers know them, but as natural-language requests.MCP is not a hype-term; multiple independent studies identify the architectural shift required for “LLM-consumable” tool invocation. One blog by Akamai engineers describes the transition from traditional APIs to “language-driven integrations” for LLMs. Another academic paper on “AI agentic workflows and enterprise APIs” talks about how enterprise API architecture must evolve to support goal-oriented agents rather than human-driven calls. In short: We are no longer merely designing APIs for code; we are designing capabilities for intent.Why does this matter for enterprises? Because enterprises are drowning in internal systems, integration sprawl and user training costs. Workers struggle not because they don’t have tools, but because they have too many tools, each with its own interface. When natural language becomes the primary interface, the barrier of “which function do I call?” disappears. One recent business blog observed that natural‐language interfaces (NLIs) are enabling self-serve data access for marketers who previously had to wait for analysts to write SQL. When the user just states intent (like “fetch last quarter revenue for region X and flag anomalies”), the system underneath can translate that into calls, orchestration, context memory and deliver results. Natural language becomes not a convenience, but the interfaceTo understand how this evolution works, consider the interface ladder:EraInterfaceWho it was built forCLIShell commandsExpert users typing textAPIWeb or RPC endpointsDevelopers integrating systemsSDKLibrary functionsProgrammers using abstractionsNatural language (MCP)Intent-based requestsHuman + AI agents stating what they wantThrough each step, humans had to “learn the machine’s language.” With MCP, the machine absorbs the human’s language and works out the rest. That’s not just UX improvement, it’s an architectural shift.Under MCP, functions of code are still there: data access, business logic and orchestration. But they’re discovered rather than invoked manually. For example, rather than calling \"billingApi.fetchInvoices(customerId=…),\" you say “Show all invoices for Acme Corp since January and highlight any late payments.” The model resolves the entities, calls the right systems, filters and returns structured insight. The developer’s work shifts from wiring endpoints to defining capability surfaces and guardrails.This shift transforms developer experience and enterprise integration. Teams often struggle to onboard new tools because they require mapping schemas, writing glue code and training users. With a natural-language front, onboarding involves defining business entity names, declaring capabilities and exposing them via the protocol. The human (or AI agent) no longer needs to know parameter names or call order. Studies show that using LLMs as interfaces to APIs can reduce the time and resources required to develop chatbots or tool-invoked workflows.The change also brings productivity benefits. Enterprises that adopt LLM-driven interfaces can turn data access latency (hours/days) into conversation latency (seconds). For instance, if an analyst previously had to export CSVs, run transforms and deploy slides, a language interface allows “Summarize the top five risk factors for churn over the last quarter” and generate narrative + visuals in one go. The human then reviews, adjusts and acts — shifting from data plumber to decision maker. That matters: According to a survey by McKinsey & Company, 63% of organizations using gen AI are already creating text outputs, and more than one-third are generating images or code. (While many are still in the early days of capturing enterprise-wide ROI, the signal is clear: Language as interface unlocks new value.In architectural terms, this means software design must evolve. MCP demands systems that publish capability metadata, support semantic routing, maintain context memory and enforce guardrails. An API design no longer needs to ask “What function will the user call?”, but rather “What intent might the user express?” A recently published framework for improving enterprise APIs for LLMs shows how APIs can be enriched with natural-language-friendly metadata so that agents can select tools dynamically. The implication: Software becomes modular around intent surfaces rather than function surfaces.Language-first systems also bring risks and requirements. Natural language is ambiguous by nature, so enterprises must implement authentication, logging, provenance and access control, just as they did for APIs. Without these guardrails, an agent might call the wrong system, expose data or misinterpret intent. One post on “prompt collapse” calls out the danger: As natural-language UI becomes dominant, software may turn into “a capability accessed through conversation” and the company into “an API with a natural-language frontend”. That transformation is powerful, but only safe if systems are designed for introspection, audit and governance.The shift also has cultural and organizational ramifications. For decades, enterprises hired integration engineers to design APIs and middleware. With MCP-driven models, companies will increasingly hire ontology engineers, capability architects and agent enablement specialists. These roles focus on defining the semantics of business operations, mapping business entities to system capabilities and curating context memory. Because the interface is now human-centric, skills such as domain knowledge, prompt framing, oversight and evaluation become central.What should enterprise leaders do today? First, think of natural language as the interface layer, not as a fancy add-on. Map your business workflows that can safely be invoked via language. Then catalogue the underlying capabilities you already have: data services, analytics and APIs. Then ask: “Are these discoverable? Can they be called via intent?” Finally, pilot an MCP-style layer: Build a small domain (customer support triage) where a user or agent can express outcomes in language, and let systems do the orchestration. Then iterate and scale.Natural language is not just the new front-end. It is becoming the default interface layer for software, replacing CLI, then APIs, then SDKs. MCP is the abstraction that makes this possible. Benefits include faster integration, modular systems, higher productivity and new roles. For those organizations still tethered to calling endpoints manually, the shift will feel like learning a new platform all over again. The question is no longer “which function do I call?” but “what do I want to do?”Dhyey Mavani is accelerating gen AI and computational mathematics.",
          "content": "For decades, we have adapted to software. We learned shell commands, memorized HTTP method names and wired together SDKs. Each interface assumed we would speak its language. In the 1980s, we typed &#x27;grep&#x27;, &#x27;ssh&#x27; and &#x27;ls&#x27; into a shell; by the mid-2000s, we were invoking REST endpoints like GET /users; by the 2010s, we imported SDKs (client.orders.list()) so we didn’t have to think about HTTP. But underlying each of those steps was the same premise: Expose capabilities in a structured form so others can invoke them.But now we are entering the next interface paradigm. Modern LLMs are challenging the notion that a user must choose a function or remember a method signature. Instead of “Which API do I call?” the question becomes: “What outcome am I trying to achieve?” In other words, the interface is shifting from code → to language. In this shift, Model Context Protocol (MCP) emerges as the abstraction that allows models to interpret human intent, discover capabilities and execute workflows, effectively exposing software functions not as programmers know them, but as natural-language requests.MCP is not a hype-term; multiple independent studies identify the architectural shift required for “LLM-consumable” tool invocation. One blog by Akamai engineers describes the transition from traditional APIs to “language-driven integrations” for LLMs. Another academic paper on “AI agentic workflows and enterprise APIs” talks about how enterprise API architecture must evolve to support goal-oriented agents rather than human-driven calls. In short: We are no longer merely designing APIs for code; we are designing capabilities for intent.Why does this matter for enterprises? Because enterprises are drowning in internal systems, integration sprawl and user training costs. Workers struggle not because they don’t have tools, but because they have too many tools, each with its own interface. When natural language becomes the primary interface, the barrier of “which function do I call?” disappears. One recent business blog observed that natural‐language interfaces (NLIs) are enabling self-serve data access for marketers who previously had to wait for analysts to write SQL. When the user just states intent (like “fetch last quarter revenue for region X and flag anomalies”), the system underneath can translate that into calls, orchestration, context memory and deliver results. Natural language becomes not a convenience, but the interfaceTo understand how this evolution works, consider the interface ladder:EraInterfaceWho it was built forCLIShell commandsExpert users typing textAPIWeb or RPC endpointsDevelopers integrating systemsSDKLibrary functionsProgrammers using abstractionsNatural language (MCP)Intent-based requestsHuman + AI agents stating what they wantThrough each step, humans had to “learn the machine’s language.” With MCP, the machine absorbs the human’s language and works out the rest. That’s not just UX improvement, it’s an architectural shift.Under MCP, functions of code are still there: data access, business logic and orchestration. But they’re discovered rather than invoked manually. For example, rather than calling \"billingApi.fetchInvoices(customerId=…),\" you say “Show all invoices for Acme Corp since January and highlight any late payments.” The model resolves the entities, calls the right systems, filters and returns structured insight. The developer’s work shifts from wiring endpoints to defining capability surfaces and guardrails.This shift transforms developer experience and enterprise integration. Teams often struggle to onboard new tools because they require mapping schemas, writing glue code and training users. With a natural-language front, onboarding involves defining business entity names, declaring capabilities and exposing them via the protocol. The human (or AI agent) no longer needs to know parameter names or call order. Studies show that using LLMs as interfaces to APIs can reduce the time and resources required to develop chatbots or tool-invoked workflows.The change also brings productivity benefits. Enterprises that adopt LLM-driven interfaces can turn data access latency (hours/days) into conversation latency (seconds). For instance, if an analyst previously had to export CSVs, run transforms and deploy slides, a language interface allows “Summarize the top five risk factors for churn over the last quarter” and generate narrative + visuals in one go. The human then reviews, adjusts and acts — shifting from data plumber to decision maker. That matters: According to a survey by McKinsey & Company, 63% of organizations using gen AI are already creating text outputs, and more than one-third are generating images or code. (While many are still in the early days of capturing enterprise-wide ROI, the signal is clear: Language as interface unlocks new value.In architectural terms, this means software design must evolve. MCP demands systems that publish capability metadata, support semantic routing, maintain context memory and enforce guardrails. An API design no longer needs to ask “What function will the user call?”, but rather “What intent might the user express?” A recently published framework for improving enterprise APIs for LLMs shows how APIs can be enriched with natural-language-friendly metadata so that agents can select tools dynamically. The implication: Software becomes modular around intent surfaces rather than function surfaces.Language-first systems also bring risks and requirements. Natural language is ambiguous by nature, so enterprises must implement authentication, logging, provenance and access control, just as they did for APIs. Without these guardrails, an agent might call the wrong system, expose data or misinterpret intent. One post on “prompt collapse” calls out the danger: As natural-language UI becomes dominant, software may turn into “a capability accessed through conversation” and the company into “an API with a natural-language frontend”. That transformation is powerful, but only safe if systems are designed for introspection, audit and governance.The shift also has cultural and organizational ramifications. For decades, enterprises hired integration engineers to design APIs and middleware. With MCP-driven models, companies will increasingly hire ontology engineers, capability architects and agent enablement specialists. These roles focus on defining the semantics of business operations, mapping business entities to system capabilities and curating context memory. Because the interface is now human-centric, skills such as domain knowledge, prompt framing, oversight and evaluation become central.What should enterprise leaders do today? First, think of natural language as the interface layer, not as a fancy add-on. Map your business workflows that can safely be invoked via language. Then catalogue the underlying capabilities you already have: data services, analytics and APIs. Then ask: “Are these discoverable? Can they be called via intent?” Finally, pilot an MCP-style layer: Build a small domain (customer support triage) where a user or agent can express outcomes in language, and let systems do the orchestration. Then iterate and scale.Natural language is not just the new front-end. It is becoming the default interface layer for software, replacing CLI, then APIs, then SDKs. MCP is the abstraction that makes this possible. Benefits include faster integration, modular systems, higher productivity and new roles. For those organizations still tethered to calling endpoints manually, the shift will feel like learning a new platform all over again. The question is no longer “which function do I call?” but “what do I want to do?”Dhyey Mavani is accelerating gen AI and computational mathematics.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/P8UEbu2620zRqcW1UFux1/d072a1aa21ec528b2c6b98ca1701e800/MCP.jpeg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-presentation-live-190051072.html",
          "published_at": "Sat, 03 Jan 2026 19:00:37 +0000",
          "title": "How to watch the Hyundai CES 2026 presentation live",
          "standfirst": "A look at Hyundai's Holographic Windshield Display. (Hyundai) CES has long felt like a full-on auto show, but the car-centric energy seems somewhat muted at CES 2026. Sure, the Afeela electric vehicle from the Sony-Honda joint venture is returning to the show floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That said, there's no shortage of in-cabin car tech on display, including Hyundai's Holographic Windshield Display. Indeed, the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES. And we'll also get to see Hyundai's AI Robotics Strategy, which will showcase its new Atlas robot fresh out of the lab. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place on January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. We'll embed the stream here once it's available. What to expect As mentioned above, Hyundai will have its Holographic Windshield Display for viewing. It's essentially a next-gen heads-up display that projects key data from the vehicle's dash on the windshield for less distraction, and without obstructing the driver's view. It's a vertically expandable 18.1-inch large display, and passengers can even watch videos without being visible to the driver. Hyundai Mobis collaborated with German optics specialist Zeiss to develop the \"world's first system to utilize holographic film to transform the entire front windshield into an ultra-large display surface.\" It says it will begin mass production in 2029, so don't expect to see this on the market anytime soon. Beyond automotive, though, we'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. Hyundai said it will also discuss its other tech areas, including electronics and chassis system safety, as well as an AR head-up display, low-power display solutions and EV drive systems.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-presentation-live-190051072.html?src=rss",
          "content": "A look at Hyundai's Holographic Windshield Display. (Hyundai) CES has long felt like a full-on auto show, but the car-centric energy seems somewhat muted at CES 2026. Sure, the Afeela electric vehicle from the Sony-Honda joint venture is returning to the show floor, but with the Trump administration yanking most EV incentives from the market, the industry isn't offering a full-court press of new vehicles in Las Vegas this year. That said, there's no shortage of in-cabin car tech on display, including Hyundai's Holographic Windshield Display. Indeed, the company's Mobis subsidiary will present \"more than 30 mobility convergence technologies\" during CES. And we'll also get to see Hyundai's AI Robotics Strategy, which will showcase its new Atlas robot fresh out of the lab. How to watch Hyundai's presentation at CES 2026 Hyundai's presentation takes place on January 5 at 4PM ET, and you can livestream it on either its HyundaiUSA YouTube channel or its global YouTube channel. We'll embed the stream here once it's available. What to expect As mentioned above, Hyundai will have its Holographic Windshield Display for viewing. It's essentially a next-gen heads-up display that projects key data from the vehicle's dash on the windshield for less distraction, and without obstructing the driver's view. It's a vertically expandable 18.1-inch large display, and passengers can even watch videos without being visible to the driver. Hyundai Mobis collaborated with German optics specialist Zeiss to develop the \"world's first system to utilize holographic film to transform the entire front windshield into an ultra-large display surface.\" It says it will begin mass production in 2029, so don't expect to see this on the market anytime soon. Beyond automotive, though, we'll also get a first-ever look at the company's new Atlas robot. In the teaser image shown in the press release, Atlas looks rather dog-like, which makes sense when you remember that Boston Dynamics was purchased by the Korean multinational back in 2020. \"This next-generation Atlas represents a tangible step toward the commercialization of AI Robotics, highlighting the Group’s commitment to building safe and adaptable robotic co-workers,\" the company said in the same press release. Hyundai said it will also discuss its other tech areas, including electronics and chassis system safety, as well as an AR head-up display, low-power display solutions and EV drive systems.This article originally appeared on Engadget at https://www.engadget.com/transportation/how-to-watch-the-hyundai-ces-2026-presentation-live-190051072.html?src=rss",
          "feed_position": 9,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/2a54c910-e5bb-11f0-9fd7-0fe99fe4214d"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/ces-2026-what-to-expect-from-techs-big-january-conference-120000956.html",
          "published_at": "Sat, 03 Jan 2026 13:45:00 +0000",
          "title": "CES 2026: What to expect from tech's big January conference",
          "standfirst": "The new year is upon us, and that means CES 2026 is imminent. The biggest tech trade show of the calendar comes with a bevy of new and notable announcements that set the tone for trends and expectations for the subsequent 12 months. The CES 2026 show floor is officially open from January 6 through 9, but the fun kicks off with events on Sunday January 4, followed by a host of press conferences on Monday. As always, product demos, announcements and networking will be happening at the Las Vegas Convention Center and other hotels all over the city. As usual, Engadget will be covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements are already trickling out as CES approaches, and thanks to the schedule of the Consumer Technology Association (the trade organization that runs the show) we have a full itinerary of press conferences. We’re also using our experience and expertise to predict what tech trends could rear their heads at the show.The CES 2026 schedulePress conferences and show floor booths are the bread and butter of CES. The CTA has already published a searchable directory of who will have an official presence at the show, along with a schedule of every official panel and presentation. However, the press conference schedule gives us a more digestible rundown of the first 48 hours of big events. On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" Ahead of that, though, Samsung has already outlined a variety of more specifics (scroll down for details). Concurrent with the Samsung presentation will be the official CES Unveiled mini-show, which is generally comprised of smaller and start-up vendors. That'll be followed by multiple press conferences throughout Monday, January 5. The LG CES 2026 press conference, titled \"Innovation in Tune with You,\" is ostensibly to share \"its vision for elevating daily life through Affectionate Intelligence.\" But, like Samsung, this fellow Korean giant has already spent the three weeks leading up to CES pre-announcing many of its new products, so this may be more of a summary than breaking news. Following LG, we’ll also see press conferences from Bosch and Hisense, as well as the first-ever CES appearance from Lego. As the Las Vegas afternoon rolls around, we get the first of three chip giants: NVIDIA CEO Jensen Huang takes the stage on January 5 at 1PM PT (4PM ET) and, according to the website, his presentation will last about 90 minutes. Based on the description on the listing, the presentation will “showcase the latest NVIDIA solutions driving innovation and productivity across industries.” NVIDIA’s presser is concurrent with one from Hyundai, where the Korean automotive company will focus on in-cabin car tech and robotics. Later in the day, we get to hear from NVIDIA frenemies Intel and AMD. Intel’s 3PM PT (6PM PT) event will ostensibly feature its new Core Ultra Series 3 processors, and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day. But expect both of them to be very heavy on AI applications, of course. Sandwiched in between those chip manufacturers will be Sony Honda Mobility. The joint venture will be offering yet more details on its Afeela EV. Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at the Las Vegas Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\" It’s worth noting that Lenovo is the parent company of Motorola, which still makes phones and foldables that feature AI tools, so it’s possible those devices feature in the presentation as well. Samsung and LG vie for pre-show publicityAs noted above, both Samsung and LG have continued their recent trend of spoiling nearly all of their respective CES announcements in the days and weeks before the show. LG, for example, has said it will debut its first Micro RGB television at CES. While details are scarce, the company’s press release for the LG Micro RGB evo did confirm it has received certifications by Intertek for 100 percent color gamut coverage in DCI-P3 an Adobe RGB, and that it has more than a thousand dimming zones for brightness control. Elsewhere in the TV space, LG is throwing its hat into the “art TV” ring that Samsung pioneered with its Frame TVs: The LG Gallery TV will debut in 55- and 65-inch screen sizes, and it will of course show off various artwork when it’s not otherwise in use. And if PC gaming displays are more your speed, LG will have that covered, too, with a new line of 5K-capable gaming monitors on deck with built-in AI upscaling.But LG’s not just showing off displays. The Korean multinational will also introduce a Dolby-powered modular home audio system, a new line of its xboom speakers (developed with will.i.am) and the company will flex its automation muscles with a humanoid home automation robot named CLOiD. We’re also looking forward to checking out the company’s new ultralight Aerominum laptops.Of course, Samsung refuses to be outdone by its hometown rival, and has also released a pre-CES press release document dump. Samsung will be launching its own lineup of Micro RGB TVs at CES, for starters. The company already introduced its first Micro RGB TV at CES 2025, which was a 115-inch model available for a cool $30,000. Next year, Samsung is expanding the range with 55-, 65-, 75-, 85-, 100- and 115-inch models that use the next evolution of the company’s Micro RGB technology. Samsung is also countering LG’s 5K monitors with a 6K model that aims to deliver glasses-free 3D (another long-time CES staple). It’ll be one of several new displays in the company’s Odyssey gaming line. And the company is also updating its Freestyle projector for 2026, too. And on the audio front, Samsung has teased several new soundbars and speakers, including Sonos-style Wi-Fi streaming models call the Music Studio 5 and Studio 7.Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensAs noted above, Samsung and LG appear to be going all-in on Micro RGB display tech for TVs. Expect that to be a huge buzzword at CES, with Hisense and Sony debuting new models, too.Sony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.And maybe your future TV won’t need a power cord, either: Displace will be showing off a mounting option that includes a 15,000mAh battery to juice up whatever giant TV screen you choose to attach.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots — like LG’s aforementioned CLOiD — competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!Update, December 11 2025, 11:03AM ET: This story has been updated to include detail on Lenovo being Motorola’s parent company and how the latter might have a part in the Tuesday presentation.Update, December 16 2025, 1:33PM ET: This story has been updated to include the NVIDIA press conference, which was added to the CTA schedule within the last two days.Update, December 23 2025, 7:28AM ET: This story has been updated to include LG and Samsung’s Micro RGB TV announcements, which were made public in the past seven days. The intro was also tweaked to reflect how soon CES is at this point.Update, December 29 2025, 11:03AM ET: This story has been updated to include additional details on pre-announcements from Samsung, LG and Displace. Update, December 31 2025, 12:05PM ET: This story has been updated to include yet more early LG announcements.Update, January 3 2026, 8:45AM ET: This story has been updated to include still more Samsung and LG announcements.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-what-to-expect-from-techs-big-january-conference-120000956.html?src=rss",
          "content": "The new year is upon us, and that means CES 2026 is imminent. The biggest tech trade show of the calendar comes with a bevy of new and notable announcements that set the tone for trends and expectations for the subsequent 12 months. The CES 2026 show floor is officially open from January 6 through 9, but the fun kicks off with events on Sunday January 4, followed by a host of press conferences on Monday. As always, product demos, announcements and networking will be happening at the Las Vegas Convention Center and other hotels all over the city. As usual, Engadget will be covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements are already trickling out as CES approaches, and thanks to the schedule of the Consumer Technology Association (the trade organization that runs the show) we have a full itinerary of press conferences. We’re also using our experience and expertise to predict what tech trends could rear their heads at the show.The CES 2026 schedulePress conferences and show floor booths are the bread and butter of CES. The CTA has already published a searchable directory of who will have an official presence at the show, along with a schedule of every official panel and presentation. However, the press conference schedule gives us a more digestible rundown of the first 48 hours of big events. On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" Ahead of that, though, Samsung has already outlined a variety of more specifics (scroll down for details). Concurrent with the Samsung presentation will be the official CES Unveiled mini-show, which is generally comprised of smaller and start-up vendors. That'll be followed by multiple press conferences throughout Monday, January 5. The LG CES 2026 press conference, titled \"Innovation in Tune with You,\" is ostensibly to share \"its vision for elevating daily life through Affectionate Intelligence.\" But, like Samsung, this fellow Korean giant has already spent the three weeks leading up to CES pre-announcing many of its new products, so this may be more of a summary than breaking news. Following LG, we’ll also see press conferences from Bosch and Hisense, as well as the first-ever CES appearance from Lego. As the Las Vegas afternoon rolls around, we get the first of three chip giants: NVIDIA CEO Jensen Huang takes the stage on January 5 at 1PM PT (4PM ET) and, according to the website, his presentation will last about 90 minutes. Based on the description on the listing, the presentation will “showcase the latest NVIDIA solutions driving innovation and productivity across industries.” NVIDIA’s presser is concurrent with one from Hyundai, where the Korean automotive company will focus on in-cabin car tech and robotics. Later in the day, we get to hear from NVIDIA frenemies Intel and AMD. Intel’s 3PM PT (6PM PT) event will ostensibly feature its new Core Ultra Series 3 processors, and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day. But expect both of them to be very heavy on AI applications, of course. Sandwiched in between those chip manufacturers will be Sony Honda Mobility. The joint venture will be offering yet more details on its Afeela EV. Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at the Las Vegas Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\" It’s worth noting that Lenovo is the parent company of Motorola, which still makes phones and foldables that feature AI tools, so it’s possible those devices feature in the presentation as well. Samsung and LG vie for pre-show publicityAs noted above, both Samsung and LG have continued their recent trend of spoiling nearly all of their respective CES announcements in the days and weeks before the show. LG, for example, has said it will debut its first Micro RGB television at CES. While details are scarce, the company’s press release for the LG Micro RGB evo did confirm it has received certifications by Intertek for 100 percent color gamut coverage in DCI-P3 an Adobe RGB, and that it has more than a thousand dimming zones for brightness control. Elsewhere in the TV space, LG is throwing its hat into the “art TV” ring that Samsung pioneered with its Frame TVs: The LG Gallery TV will debut in 55- and 65-inch screen sizes, and it will of course show off various artwork when it’s not otherwise in use. And if PC gaming displays are more your speed, LG will have that covered, too, with a new line of 5K-capable gaming monitors on deck with built-in AI upscaling.But LG’s not just showing off displays. The Korean multinational will also introduce a Dolby-powered modular home audio system, a new line of its xboom speakers (developed with will.i.am) and the company will flex its automation muscles with a humanoid home automation robot named CLOiD. We’re also looking forward to checking out the company’s new ultralight Aerominum laptops.Of course, Samsung refuses to be outdone by its hometown rival, and has also released a pre-CES press release document dump. Samsung will be launching its own lineup of Micro RGB TVs at CES, for starters. The company already introduced its first Micro RGB TV at CES 2025, which was a 115-inch model available for a cool $30,000. Next year, Samsung is expanding the range with 55-, 65-, 75-, 85-, 100- and 115-inch models that use the next evolution of the company’s Micro RGB technology. Samsung is also countering LG’s 5K monitors with a 6K model that aims to deliver glasses-free 3D (another long-time CES staple). It’ll be one of several new displays in the company’s Odyssey gaming line. And the company is also updating its Freestyle projector for 2026, too. And on the audio front, Samsung has teased several new soundbars and speakers, including Sonos-style Wi-Fi streaming models call the Music Studio 5 and Studio 7.Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensAs noted above, Samsung and LG appear to be going all-in on Micro RGB display tech for TVs. Expect that to be a huge buzzword at CES, with Hisense and Sony debuting new models, too.Sony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.And maybe your future TV won’t need a power cord, either: Displace will be showing off a mounting option that includes a 15,000mAh battery to juice up whatever giant TV screen you choose to attach.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots — like LG’s aforementioned CLOiD — competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!Update, December 11 2025, 11:03AM ET: This story has been updated to include detail on Lenovo being Motorola’s parent company and how the latter might have a part in the Tuesday presentation.Update, December 16 2025, 1:33PM ET: This story has been updated to include the NVIDIA press conference, which was added to the CTA schedule within the last two days.Update, December 23 2025, 7:28AM ET: This story has been updated to include LG and Samsung’s Micro RGB TV announcements, which were made public in the past seven days. The intro was also tweaked to reflect how soon CES is at this point.Update, December 29 2025, 11:03AM ET: This story has been updated to include additional details on pre-announcements from Samsung, LG and Displace. Update, December 31 2025, 12:05PM ET: This story has been updated to include yet more early LG announcements.Update, January 3 2026, 8:45AM ET: This story has been updated to include still more Samsung and LG announcements.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-what-to-expect-from-techs-big-january-conference-120000956.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/how-to-watch-the-bosch-ces-2026-press-conference-live-on-monday-130020396.html",
          "published_at": "Sat, 03 Jan 2026 12:00:36 +0000",
          "title": "How to watch the Bosch CES 2026 press conference live on Monday",
          "standfirst": "You might recognize Bosch as a home appliance name (thanks to its partnership with Siemens), but the German multinational brand's core business is really about providing the underlying technology and engineering that powers cars, homes and factories around the world. That focus is reflected at CES 2026, where much of what Bosch is unveiling is intended to be licensed to other companies rather than sold as Bosch-branded products on store shelves. Case in point is Bosch's automotive plans at CES. The company is showcasing what it calls \"AI in the car,\" or more specifically, in the cockpit of the car. \"Bosch's AI-powered cockpit makes driving more comfortable, intuitive, and safer for all occupants,\" Bosch board member Markus Heyn said in a press release. We'll get into all the details below, as well as how to tune in to the press conference on Monday. How to watch Bosch's CES 2026 presentation You can livestream the event on Monday, January 5 at 12PM ET via the Bosch press page or YouTube. (We've embedded the stream link below.) What to expect Bosch will be setting up shop in the Central Hall of the Las Vegas Convention Center (booth 16203), where the company will be focusing on its three big themes — mobility, smart home integrations and manufacturing — all of which will include hardware, software and AI solutions. Like many other CES 2026 exhibitors, look for Bosch to emphasize its partnerships with the big dogs of the AI space at the show. For instance, that AI-powered car cockpit mentioned above will feature integrations with both Microsoft and NVIDIA. For instance, Bosch is touting the ability to use voice commands to join a Teams call, while the car's system will automatically activate adaptive cruise control. And it's noting that NVIDIA's software suites will help manage \"real-time sensor processing and vision-language models.\" Here's a glimpse of what the booth will look like: This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-watch-the-bosch-ces-2026-press-conference-live-on-monday-130020396.html?src=rss",
          "content": "You might recognize Bosch as a home appliance name (thanks to its partnership with Siemens), but the German multinational brand's core business is really about providing the underlying technology and engineering that powers cars, homes and factories around the world. That focus is reflected at CES 2026, where much of what Bosch is unveiling is intended to be licensed to other companies rather than sold as Bosch-branded products on store shelves. Case in point is Bosch's automotive plans at CES. The company is showcasing what it calls \"AI in the car,\" or more specifically, in the cockpit of the car. \"Bosch's AI-powered cockpit makes driving more comfortable, intuitive, and safer for all occupants,\" Bosch board member Markus Heyn said in a press release. We'll get into all the details below, as well as how to tune in to the press conference on Monday. How to watch Bosch's CES 2026 presentation You can livestream the event on Monday, January 5 at 12PM ET via the Bosch press page or YouTube. (We've embedded the stream link below.) What to expect Bosch will be setting up shop in the Central Hall of the Las Vegas Convention Center (booth 16203), where the company will be focusing on its three big themes — mobility, smart home integrations and manufacturing — all of which will include hardware, software and AI solutions. Like many other CES 2026 exhibitors, look for Bosch to emphasize its partnerships with the big dogs of the AI space at the show. For instance, that AI-powered car cockpit mentioned above will feature integrations with both Microsoft and NVIDIA. For instance, Bosch is touting the ability to use voice commands to join a Teams call, while the car's system will automatically activate adaptive cruise control. And it's noting that NVIDIA's software suites will help manage \"real-time sensor processing and vision-language models.\" Here's a glimpse of what the booth will look like: This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-watch-the-bosch-ces-2026-press-conference-live-on-monday-130020396.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/inference-is-splitting-in-two-nvidias-usd20b-groq-bet-explains-its-next-act",
          "published_at": "Sat, 03 Jan 2026 01:00:00 GMT",
          "title": "Nvidia just admitted the general-purpose GPU era is ending",
          "standfirst": "Nvidia’s $20 billion strategic licensing deal with Groq represents one of the first clear moves in a four-front fight over the future AI stack. 2026 is when that fight becomes obvious to enterprise builders.For the technical decision-makers we talk to every day — the people building the AI applications and the data pipelines that drive them — this deal is a signal that the era of the one-size-fits-all GPU as the default AI inference answer is ending.We are entering the age of the disaggregated inference architecture, where the silicon itself is being split into two different types to accommodate a world that demands both massive context and instantaneous reasoning.Why inference is breaking the GPU architecture in twoTo understand why Nvidia CEO Jensen Huang dropped one-third of his reported $60 billion cash pile on a licensing deal, you have to look at the existential threats converging on his company’s reported 92% market share. The industry reached a tipping point in late 2025: For the first time, inference — the phase where trained models actually run — surpassed training in terms of total data center revenue, according to Deloitte. In this new \"Inference Flip,\" the metrics have changed. While accuracy remains the baseline, the battle is now being fought over latency and the ability to maintain \"state\" in autonomous agents.There are four fronts of that battle, and each front points to the same conclusion: Inference workloads are fragmenting faster than GPUs can generalize. 1. Breaking the GPU in two: Prefill vs. decodeGavin Baker, an investor in Groq (and therefore biased, but also unusually fluent on the architecture), summarized the core driver of the Groq deal cleanly: “Inference is disaggregating into prefill and decode.”Prefill and decode are two distinct phases:The prefill phase: Think of this as the user’s \"prompt\" stage. The model must ingest massive amounts of data — whether it&#x27;s a 100,000-line codebase or an hour of video — and compute a contextual understanding. This is \"compute-bound,\" requiring massive matrix multiplication that Nvidia’s GPUs are historically excellent at.The generation (decode) phase: This is the actual token-by-token \"generation.” Once the prompt is ingested, the model generates one word (or token) at a time, feeding each one back into the system to predict the next. This is \"memory-bandwidth bound.\" If the data can&#x27;t move from the memory to the processor fast enough, the model stutters, no matter how powerful the GPU is. (This is where Nvidia was weak, and where Groq’s special language processing unit (LPU) and its related SRAM memory, shines. More on that in a bit.)Nvidia has announced an upcoming Vera Rubin family of chips that it’s architecting specifically to handle this split. The Rubin CPX component of this family is the designated \"prefill\" workhorse, optimized for massive context windows of 1 million tokens or more. To handle this scale affordably, it moves away from the eye-watering expense of high bandwidth memory (HBM) — Nvidia’s current gold-standard memory that sits right next to the GPU die — and instead utilizes 128GB of a new kind of memory, GDDR7. While HBM provides extreme speed (though not as quick as Groq’s static random-access memory (SRAM)), its supply on GPUs is limited and its cost is a barrier to scale; GDDR7 provides a more cost-effective way to ingest massive datasets.Meanwhile, the \"Groq-flavored\" silicon, which Nvidia is integrating into its inference roadmap, will serve as the high-speed \"decode\" engine. This is about neutralizing a threat from alternative architectures like Google&#x27;s TPUs and maintaining the dominance of CUDA, Nvidia’s software ecosystem that has served as its primary moat for over a decade.All of this was enough for Baker, the Groq investor, to predict that Nvidia’s move to license Groq will cause all other specialized AI chips to be canceled — that is, outside of Google’s TPU, Tesla’s AI5, and AWS’s Trainium.2. The differentiated power of SRAMAt the heart of Groq’s technology is SRAM. Unlike the DRAM found in your PC or the HBM on an Nvidia H100 GPU, SRAM is etched directly into the logic of the processor.Michael Stewart, managing partner of Microsoft’s venture fund, M12, describes SRAM as the best for moving data over short distances with minimal energy. \"The energy to move a bit in SRAM is like 0.1 picojoules or less,\" Stewart said. \"To move it between DRAM and the processor is more like 20 to 100 times worse.\"In the world of 2026, where agents must reason in real-time, SRAM acts as the ultimate \"scratchpad\": a high-speed workspace where the model can manipulate symbolic operations and complex reasoning processes without the \"wasted cycles\" of external memory shuttling.However, SRAM has a major drawback: it is physically bulky and expensive to manufacture, meaning its capacity is limited compared to DRAM. This is where Val Bercovici, chief AI officer at Weka, another company offering memory for GPUs, sees the market segmenting.Groq-friendly AI workloads — where SRAM has the advantage — are those that use small models of 8 billion parameters and below, Bercovici said. This isn’t a small market, though. “It’s just a giant market segment that was not served by Nvidia, which was edge inference, low latency, robotics, voice, IoT devices — things we want running on our phones without the cloud for convenience, performance, or privacy,\" he said.This 8B \"sweet spot\" is significant because 2025 saw an explosion in model distillation, where many enterprise companies are shrinking massive models into highly efficient smaller versions. While SRAM isn&#x27;t practical for the trillion-parameter \"frontier\" models, it is perfect for these smaller, high-velocity models.3. The Anthropic threat: The rise of the ‘portable stack’Perhaps the most under-appreciated driver of this deal is Anthropic’s success in making its stack portable across accelerators.The company has pioneered a portable engineering approach for training and inference — basically a software layer that allows its Claude models to run across multiple AI accelerator families — including Nvidia’s GPUs and Google’s Ironwood TPUs. Until recently, Nvidia&#x27;s dominance was protected because running high-performance models outside of the Nvidia stack was a technical nightmare. “It’s Anthropic,” Weka’s Bercovici told me. “The fact that Anthropic was able to … build up a software stack that could work on TPUs as well as on GPUs, I don’t think that’s being appreciated enough in the marketplace.”(Disclosure: Weka has been a sponsor of VentureBeat events.)Anthropic recently committed to accessing up to 1 million TPUs from Google, representing over a gigawatt of compute capacity. This multi-platform approach ensures the company isn&#x27;t held hostage by Nvidia&#x27;s pricing or supply constraints. So for Nvidia, the Groq deal is equally a defensive move. By integrating Groq’s ultra-fast inference IP, Nvidia is making sure that the most performance-sensitive workloads — like those running small models or as part of real-time agents — can be accommodated within Nvidia’s CUDA ecosystem, even as competitors try to jump ship to Google&#x27;s Ironwood TPUs. CUDA is the special software Nvidia provides to developers to integrate GPUs. 4. The agentic ‘statehood’ war: Manus and the KV CacheThe timing of this Groq deal coincides with Meta’s acquisition of the agent pioneer Manus just two days ago. The significance of Manus was partly its obsession with statefulness.If an agent can’t remember what it did 10 steps ago, it is useless for real-world tasks like market research or software development. KV Cache (Key-Value Cache) is the \"short-term memory\" that an LLM builds during the prefill phase.Manus reported that for production-grade agents, the ratio of input tokens to output tokens can reach 100:1. This means for every word an agent says, it is \"thinking\" and \"remembering\" 100 others. In this environment, the KV Cache hit rate is the single most important metric for a production agent, Manus said. If that cache is \"evicted\" from memory, the agent loses its train of thought, and the model must burn massive energy to recompute the prompt.Groq’s SRAM can be a \"scratchpad\" for these agents — although, again, mostly for smaller models — because it allows for the near-instant retrieval of that state. Combined with Nvidia&#x27;s Dynamo framework and the KVBM, Nvidia is building an \"inference operating system\" that enables inference servers to tier this state across SRAM, DRAM, HBM, and other flash-based offerings like that from Bercovici’s Weka.Thomas Jorgensen, senior director of Technology Enablement at Supermicro, which specializes in building clusters of GPUs for large enterprise companies, told me in September that compute is no longer the primary bottleneck for advanced clusters. Feeding data to GPUs was the bottleneck, and breaking that bottleneck requires memory.\"The whole cluster is now the computer,\" Jorgensen said. \"Networking becomes an internal part of the beast … feeding the beast with data is becoming harder because the bandwidth between GPUs is growing faster than anything else.\"This is why Nvidia is pushing into disaggregated inference. By separating the workloads, enterprise applications can use specialized storage tiers to feed data at memory-class performance, while the specialized \"Groq-inside\" silicon handles the high-speed token generation.The verdict for 2026We are entering an era of extreme specialization. For decades, incumbents could win by shipping one dominant general-purpose architecture — and their blind spot was often what they ignored on the edges. Intel’s long neglect of low-power is the classic example, Michael Stewart, managing partner of Microsoft’s venture fund M12, told me. Nvidia is signaling it won’t repeat that mistake. “If even the leader, even the lion of the jungle will acquire talent, will acquire technology — it’s a sign that the whole market is just wanting more options,” Stewart said.For technical leaders, the message is to stop architecting your stack like it’s one rack, one accelerator, one answer. In 2026, advantage will go to the teams that label workloads explicitly — and route them to the right tier:prefill-heavy vs. decode-heavylong-context vs. short-contextinteractive vs. batchsmall-model vs. large-modeledge constraints vs. data-center assumptionsYour architecture will follow those labels. In 2026, “GPU strategy” stops being a purchasing decision and becomes a routing decision. The winners won’t ask which chip they bought — they’ll ask where every token ran, and why.",
          "content": "Nvidia’s $20 billion strategic licensing deal with Groq represents one of the first clear moves in a four-front fight over the future AI stack. 2026 is when that fight becomes obvious to enterprise builders.For the technical decision-makers we talk to every day — the people building the AI applications and the data pipelines that drive them — this deal is a signal that the era of the one-size-fits-all GPU as the default AI inference answer is ending.We are entering the age of the disaggregated inference architecture, where the silicon itself is being split into two different types to accommodate a world that demands both massive context and instantaneous reasoning.Why inference is breaking the GPU architecture in twoTo understand why Nvidia CEO Jensen Huang dropped one-third of his reported $60 billion cash pile on a licensing deal, you have to look at the existential threats converging on his company’s reported 92% market share. The industry reached a tipping point in late 2025: For the first time, inference — the phase where trained models actually run — surpassed training in terms of total data center revenue, according to Deloitte. In this new \"Inference Flip,\" the metrics have changed. While accuracy remains the baseline, the battle is now being fought over latency and the ability to maintain \"state\" in autonomous agents.There are four fronts of that battle, and each front points to the same conclusion: Inference workloads are fragmenting faster than GPUs can generalize. 1. Breaking the GPU in two: Prefill vs. decodeGavin Baker, an investor in Groq (and therefore biased, but also unusually fluent on the architecture), summarized the core driver of the Groq deal cleanly: “Inference is disaggregating into prefill and decode.”Prefill and decode are two distinct phases:The prefill phase: Think of this as the user’s \"prompt\" stage. The model must ingest massive amounts of data — whether it&#x27;s a 100,000-line codebase or an hour of video — and compute a contextual understanding. This is \"compute-bound,\" requiring massive matrix multiplication that Nvidia’s GPUs are historically excellent at.The generation (decode) phase: This is the actual token-by-token \"generation.” Once the prompt is ingested, the model generates one word (or token) at a time, feeding each one back into the system to predict the next. This is \"memory-bandwidth bound.\" If the data can&#x27;t move from the memory to the processor fast enough, the model stutters, no matter how powerful the GPU is. (This is where Nvidia was weak, and where Groq’s special language processing unit (LPU) and its related SRAM memory, shines. More on that in a bit.)Nvidia has announced an upcoming Vera Rubin family of chips that it’s architecting specifically to handle this split. The Rubin CPX component of this family is the designated \"prefill\" workhorse, optimized for massive context windows of 1 million tokens or more. To handle this scale affordably, it moves away from the eye-watering expense of high bandwidth memory (HBM) — Nvidia’s current gold-standard memory that sits right next to the GPU die — and instead utilizes 128GB of a new kind of memory, GDDR7. While HBM provides extreme speed (though not as quick as Groq’s static random-access memory (SRAM)), its supply on GPUs is limited and its cost is a barrier to scale; GDDR7 provides a more cost-effective way to ingest massive datasets.Meanwhile, the \"Groq-flavored\" silicon, which Nvidia is integrating into its inference roadmap, will serve as the high-speed \"decode\" engine. This is about neutralizing a threat from alternative architectures like Google&#x27;s TPUs and maintaining the dominance of CUDA, Nvidia’s software ecosystem that has served as its primary moat for over a decade.All of this was enough for Baker, the Groq investor, to predict that Nvidia’s move to license Groq will cause all other specialized AI chips to be canceled — that is, outside of Google’s TPU, Tesla’s AI5, and AWS’s Trainium.2. The differentiated power of SRAMAt the heart of Groq’s technology is SRAM. Unlike the DRAM found in your PC or the HBM on an Nvidia H100 GPU, SRAM is etched directly into the logic of the processor.Michael Stewart, managing partner of Microsoft’s venture fund, M12, describes SRAM as the best for moving data over short distances with minimal energy. \"The energy to move a bit in SRAM is like 0.1 picojoules or less,\" Stewart said. \"To move it between DRAM and the processor is more like 20 to 100 times worse.\"In the world of 2026, where agents must reason in real-time, SRAM acts as the ultimate \"scratchpad\": a high-speed workspace where the model can manipulate symbolic operations and complex reasoning processes without the \"wasted cycles\" of external memory shuttling.However, SRAM has a major drawback: it is physically bulky and expensive to manufacture, meaning its capacity is limited compared to DRAM. This is where Val Bercovici, chief AI officer at Weka, another company offering memory for GPUs, sees the market segmenting.Groq-friendly AI workloads — where SRAM has the advantage — are those that use small models of 8 billion parameters and below, Bercovici said. This isn’t a small market, though. “It’s just a giant market segment that was not served by Nvidia, which was edge inference, low latency, robotics, voice, IoT devices — things we want running on our phones without the cloud for convenience, performance, or privacy,\" he said.This 8B \"sweet spot\" is significant because 2025 saw an explosion in model distillation, where many enterprise companies are shrinking massive models into highly efficient smaller versions. While SRAM isn&#x27;t practical for the trillion-parameter \"frontier\" models, it is perfect for these smaller, high-velocity models.3. The Anthropic threat: The rise of the ‘portable stack’Perhaps the most under-appreciated driver of this deal is Anthropic’s success in making its stack portable across accelerators.The company has pioneered a portable engineering approach for training and inference — basically a software layer that allows its Claude models to run across multiple AI accelerator families — including Nvidia’s GPUs and Google’s Ironwood TPUs. Until recently, Nvidia&#x27;s dominance was protected because running high-performance models outside of the Nvidia stack was a technical nightmare. “It’s Anthropic,” Weka’s Bercovici told me. “The fact that Anthropic was able to … build up a software stack that could work on TPUs as well as on GPUs, I don’t think that’s being appreciated enough in the marketplace.”(Disclosure: Weka has been a sponsor of VentureBeat events.)Anthropic recently committed to accessing up to 1 million TPUs from Google, representing over a gigawatt of compute capacity. This multi-platform approach ensures the company isn&#x27;t held hostage by Nvidia&#x27;s pricing or supply constraints. So for Nvidia, the Groq deal is equally a defensive move. By integrating Groq’s ultra-fast inference IP, Nvidia is making sure that the most performance-sensitive workloads — like those running small models or as part of real-time agents — can be accommodated within Nvidia’s CUDA ecosystem, even as competitors try to jump ship to Google&#x27;s Ironwood TPUs. CUDA is the special software Nvidia provides to developers to integrate GPUs. 4. The agentic ‘statehood’ war: Manus and the KV CacheThe timing of this Groq deal coincides with Meta’s acquisition of the agent pioneer Manus just two days ago. The significance of Manus was partly its obsession with statefulness.If an agent can’t remember what it did 10 steps ago, it is useless for real-world tasks like market research or software development. KV Cache (Key-Value Cache) is the \"short-term memory\" that an LLM builds during the prefill phase.Manus reported that for production-grade agents, the ratio of input tokens to output tokens can reach 100:1. This means for every word an agent says, it is \"thinking\" and \"remembering\" 100 others. In this environment, the KV Cache hit rate is the single most important metric for a production agent, Manus said. If that cache is \"evicted\" from memory, the agent loses its train of thought, and the model must burn massive energy to recompute the prompt.Groq’s SRAM can be a \"scratchpad\" for these agents — although, again, mostly for smaller models — because it allows for the near-instant retrieval of that state. Combined with Nvidia&#x27;s Dynamo framework and the KVBM, Nvidia is building an \"inference operating system\" that enables inference servers to tier this state across SRAM, DRAM, HBM, and other flash-based offerings like that from Bercovici’s Weka.Thomas Jorgensen, senior director of Technology Enablement at Supermicro, which specializes in building clusters of GPUs for large enterprise companies, told me in September that compute is no longer the primary bottleneck for advanced clusters. Feeding data to GPUs was the bottleneck, and breaking that bottleneck requires memory.\"The whole cluster is now the computer,\" Jorgensen said. \"Networking becomes an internal part of the beast … feeding the beast with data is becoming harder because the bandwidth between GPUs is growing faster than anything else.\"This is why Nvidia is pushing into disaggregated inference. By separating the workloads, enterprise applications can use specialized storage tiers to feed data at memory-class performance, while the specialized \"Groq-inside\" silicon handles the high-speed token generation.The verdict for 2026We are entering an era of extreme specialization. For decades, incumbents could win by shipping one dominant general-purpose architecture — and their blind spot was often what they ignored on the edges. Intel’s long neglect of low-power is the classic example, Michael Stewart, managing partner of Microsoft’s venture fund M12, told me. Nvidia is signaling it won’t repeat that mistake. “If even the leader, even the lion of the jungle will acquire talent, will acquire technology — it’s a sign that the whole market is just wanting more options,” Stewart said.For technical leaders, the message is to stop architecting your stack like it’s one rack, one accelerator, one answer. In 2026, advantage will go to the teams that label workloads explicitly — and route them to the right tier:prefill-heavy vs. decode-heavylong-context vs. short-contextinteractive vs. batchsmall-model vs. large-modeledge constraints vs. data-center assumptionsYour architecture will follow those labels. In 2026, “GPU strategy” stops being a purchasing decision and becomes a routing decision. The winners won’t ask which chip they bought — they’ll ask where every token ran, and why.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3tWpekn9Sk9YGgDsob9YyB/73d4e0ae1c2864638b814778cf0c8cb7/ChatGPT_Image_Jan_2__2026__04_53_16_PM.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html",
          "published_at": "Fri, 02 Jan 2026 20:46:33 +0000",
          "title": "The best VPN deals: Up to 88 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "Christmas may be over, but some holiday VPN deals are still going strong. The early days of January are a great time to grab a last-minute subscription for yourself or a loved one. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. Although we strongly recommend using a VPN, jumping on the first deal that comes along might get you stuck with a substandard app. Beyond that, even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This holiday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another holiday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "content": "Christmas may be over, but some holiday VPN deals are still going strong. The early days of January are a great time to grab a last-minute subscription for yourself or a loved one. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. Although we strongly recommend using a VPN, jumping on the first deal that comes along might get you stuck with a substandard app. Beyond that, even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This holiday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another holiday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/where-are-engadgets-ces-2025-winners-now-194500216.html",
          "published_at": "Fri, 02 Jan 2026 19:45:00 +0000",
          "title": "Where are Engadget's CES 2025 winners now?",
          "standfirst": "With CES 2026 slated to officially start next week, the focus is understandably on all the new products that will be announced at this year's event. But before diving into what’s new, we thought it was a good idea to revisit our best of show winners from last year to see where they're at. After all, CES is synonymous with vaporware. The good news is the Engadget team has a keen sense for BS. Of the ones we awarded at CES 2025 that haven’t been released, most are coming this year. For the remaining few, we’ll be hunting them down this CES.ASUS Zenbook A14An Asus Zenbook A14 sits out a patio table. Devindra Hardawar for EngadgetWhen we saw the ASUS Zenbook A14 at CES 2025, it left us impressed with its lightweight but well-made chassis, beautiful OLED screen and excellent mix of ports. After spending more time with it, the A14's shortcomings became more apparent. In his review of the ultraportable, Engadget's Devindra Hardawar gave the laptop a score of 78, lamenting its poor performance and expensive price tag. In the end, it wasn't quite the Windows MacBook Air competitor he had hoped for initially. BioLite Backup The BioLite Backup powers a Galan2 fridge. Amy Skorheim for EngadgetAt CES 2025, BioLite was already taking pre-orders for its automatic home backup power supply. The BioLite Backup didn't arrive in 2025, but if you visit the company's website today, you can reserve one for $100, with final pricing expected to start at $2,000. BioLite says units will start shipping this year. Jackery Solar RoofA CES display shows the Jackery XBC solar panels in obsidian.Jess Conditt for EngadgetBefore CES 2025, Jackery was already an established player in the domestic solar power industry, and at the event, it impressed us with its XBC curved solar shingles. They look like regular roof shingles, but Jackery said they would deliver cell conversion efficiency of more than 25 percent. It's taken longer than anticipated, but Jackery says it now expects the shingles to go on sale in the US \"very soon,\" with pricing likely to range between $1,100 and $1,300 per square meter depending on the customer's design requirements and how they purchase the product. When contacted by Engadget, Jackery also teased a handful of announcements for CES 2026, including updates on devices like the Solar Mars Robot it's been working on for the last little while. Lenovo Legion Go SThe Lenovo Legion Go S sits on an opaque glass table with a comic book behind it. Sam Rutherford for EngadgetWith the Legion Go S, Lenovo promised two different versions of its new handheld: one running Windows 11, and the other Valve's Steam OS. Unfortunately, the Windows variant arrived first (shortly after CES), and was about as good as expected. However, the wait for the SteamOS model was well worth it. When Engadget's Sam Rutherford finally reviewed it over the summer, he praised it for fast performance, bright display and of course the ease of use offered by SteamOS. LG OLED evo M5A man and his dalmatian gaze at a 77-inch LG OLED TV.LGLG's OLED TVs are a perennial CES favorite at Engadget, and the company's 2025 slate was no different. The flagship evo M5 model impressed with its 165Hz refresh rate for gaming, better image processing for lower resolution content and a wireless transmission system for video and audio. At $4,300, the set is expensive, but the good news is LG typically does a good job of trickling down features to its more affordable sets, and I'm sure the company will continue to improve on its OLED technology this year.Moonbird Moonbuddy A hand holds the Moonbird Moonbuddy. The device has the teddy sleeve on. MoonbirdThe Moonbuddy was one of two \"cute\" gadgets that made Engadget's best of CES 2025 list. We liked Moonbird's decision to make a screenless meditation and sleep aid for children. The good news is you can buy your kid a Moonbuddy right now, with the device currently discounted to $110.42 as part of Moonbird's end of year sale. Unfortunately, when Engadget contacted the company to ask about its CES 2026, all it sent us back was a response from \"Luna,\" its automated AI agent. \"I don't have specific information about our CES 2026 exhibition plans to share with you right now,\" the bot told me, adding I should email the address I just emailed to get a response from a human being. OhSnap MCONEngadget senior reporter Jessica Conditt holds the OhSnap MCON in her hand at CES 2025. The attached phone displays Minecraft.Jess Conditt for EngadgetThe OhSnap MCON won us over with its simple pitch: it basically had the ability to turn any smartphone into a Xperia Play. Actually accomplishing that feat was more complicated, with components like Hall effect joysticks for added durability increasing the time it took for OhSnap to get the product ready. For that reason, the MCON didn't make it out to consumers in 2025. However, you can preorder one now for about $210, with shipments slated to start this year. Roborock Saros Z70The Roborock Saros Z70 uses its robotic arm to put a handful of socks into a basket. Karissa Bell for EngadgetThe Saros Z70 was one of a handful of robot vacuums that debuted at CES 2025 with a built-in extendable arm, but Roborock's flagship was the one that made the best impression. We didn't end up recommending it in our robot vacuum guide; there are more affordable options that will appeal to a greater number of people. But if you want the latest and greatest, the Saros Z70 is on sale right now for $2,000. Yukai Engineering MirumiA Mirumi robot sticks to a pink purse. Cheyenne MacDonald for EngadgetOf all the gadgets Engadget saw at CES 2025, it's fair to say the Mirumi robot from Yukai Engineering was the only one to steal our hearts. All this cute little charm does is stare at you and move its head around a little until you’ve been tricked into a few moments of happiness, and honestly that was more than enough for us to award it a best of CES award. Right now, you can find Yukai Engineering accepting pre-orders for Mirumi through Kickstarter. The project, which began at the start of December, easily surged past its modest $4,878 goal, raising $267,170 as of the writing of this article. The campaign ends on January 22, so you still have time to secure your Mirumi preorder. Technics EAH-AZ100 earbudsA pair of Technics AZ100 earbuds sit on a wooden desk, with an iPhone and a pair of books next to them. Billy Steele for EngadgetThey might have only been a pair of earbuds, but a lot of us left CES really excited about the Technics EAH-AZ100. The reason for that was that they were the debut of the company's new magnetic fluid drivers technology, which promised to deliver even more clarity, detail and bass than the drivers in Technics' already excellent AZ80 earbuds. When Engadget's resident audio guru Billy Steele got a chance to review the EAH-AZ100 a couple of months later, he gave them a score of 85, saying they offered \"some of the best sound quality in any of the hundreds of earbuds I’ve tested over the years.\" Urtopia Titanium ZeroThe Titanium Zero sits at a CES display with other e-bikes nearby.Daniel Cooper for EngadgetAs a cyclist, the Urtopia Titanium Zero was the one product I left CES 2025 excited to see in the real world. If a titanium bike wasn't cool enough already, the Zero's Quark DM1.2 motor offered something actually innovative: a mid-drive motor with more power output than even the best hub motor. Unfortunately, while you can buy plenty of other e-bikes off of Urtopia's website, the Titanium Zero isn't on sale yet. That said, the company plans to showcase the bike, alongside the Quark DM1.2, at CES 2026. WeWalk Smart Cane 2A person uses the Wewalk Smart Cane 2 to find their way through a CES booth. Cheyenne MacDonald for EngadgetThe WeWalk Smart Cane 2 won two awards from Engadget during CES 2025, including our coveted best in show nod. At an event where nearly every manufacturer found a way to add AI to their devices, the Smart Cane 2 appealed to us for its thoughtful use of the tech. It offers turn-by-turn navigation and obstacle detection, in addition to a GPT-powered voice assistant to give users a way to access information without also having to juggle their phone at the same time. If you visit WeWalk's website today, there's a \"buy now\" link for the Smart Cane 2 that leads to a dead end. When Engadget reached out to WeWalk, the company said it would be once again at CES demoing the Smart Cane 2. This article originally appeared on Engadget at https://www.engadget.com/big-tech/where-are-engadgets-ces-2025-winners-now-194500216.html?src=rss",
          "content": "With CES 2026 slated to officially start next week, the focus is understandably on all the new products that will be announced at this year's event. But before diving into what’s new, we thought it was a good idea to revisit our best of show winners from last year to see where they're at. After all, CES is synonymous with vaporware. The good news is the Engadget team has a keen sense for BS. Of the ones we awarded at CES 2025 that haven’t been released, most are coming this year. For the remaining few, we’ll be hunting them down this CES.ASUS Zenbook A14An Asus Zenbook A14 sits out a patio table. Devindra Hardawar for EngadgetWhen we saw the ASUS Zenbook A14 at CES 2025, it left us impressed with its lightweight but well-made chassis, beautiful OLED screen and excellent mix of ports. After spending more time with it, the A14's shortcomings became more apparent. In his review of the ultraportable, Engadget's Devindra Hardawar gave the laptop a score of 78, lamenting its poor performance and expensive price tag. In the end, it wasn't quite the Windows MacBook Air competitor he had hoped for initially. BioLite Backup The BioLite Backup powers a Galan2 fridge. Amy Skorheim for EngadgetAt CES 2025, BioLite was already taking pre-orders for its automatic home backup power supply. The BioLite Backup didn't arrive in 2025, but if you visit the company's website today, you can reserve one for $100, with final pricing expected to start at $2,000. BioLite says units will start shipping this year. Jackery Solar RoofA CES display shows the Jackery XBC solar panels in obsidian.Jess Conditt for EngadgetBefore CES 2025, Jackery was already an established player in the domestic solar power industry, and at the event, it impressed us with its XBC curved solar shingles. They look like regular roof shingles, but Jackery said they would deliver cell conversion efficiency of more than 25 percent. It's taken longer than anticipated, but Jackery says it now expects the shingles to go on sale in the US \"very soon,\" with pricing likely to range between $1,100 and $1,300 per square meter depending on the customer's design requirements and how they purchase the product. When contacted by Engadget, Jackery also teased a handful of announcements for CES 2026, including updates on devices like the Solar Mars Robot it's been working on for the last little while. Lenovo Legion Go SThe Lenovo Legion Go S sits on an opaque glass table with a comic book behind it. Sam Rutherford for EngadgetWith the Legion Go S, Lenovo promised two different versions of its new handheld: one running Windows 11, and the other Valve's Steam OS. Unfortunately, the Windows variant arrived first (shortly after CES), and was about as good as expected. However, the wait for the SteamOS model was well worth it. When Engadget's Sam Rutherford finally reviewed it over the summer, he praised it for fast performance, bright display and of course the ease of use offered by SteamOS. LG OLED evo M5A man and his dalmatian gaze at a 77-inch LG OLED TV.LGLG's OLED TVs are a perennial CES favorite at Engadget, and the company's 2025 slate was no different. The flagship evo M5 model impressed with its 165Hz refresh rate for gaming, better image processing for lower resolution content and a wireless transmission system for video and audio. At $4,300, the set is expensive, but the good news is LG typically does a good job of trickling down features to its more affordable sets, and I'm sure the company will continue to improve on its OLED technology this year.Moonbird Moonbuddy A hand holds the Moonbird Moonbuddy. The device has the teddy sleeve on. MoonbirdThe Moonbuddy was one of two \"cute\" gadgets that made Engadget's best of CES 2025 list. We liked Moonbird's decision to make a screenless meditation and sleep aid for children. The good news is you can buy your kid a Moonbuddy right now, with the device currently discounted to $110.42 as part of Moonbird's end of year sale. Unfortunately, when Engadget contacted the company to ask about its CES 2026, all it sent us back was a response from \"Luna,\" its automated AI agent. \"I don't have specific information about our CES 2026 exhibition plans to share with you right now,\" the bot told me, adding I should email the address I just emailed to get a response from a human being. OhSnap MCONEngadget senior reporter Jessica Conditt holds the OhSnap MCON in her hand at CES 2025. The attached phone displays Minecraft.Jess Conditt for EngadgetThe OhSnap MCON won us over with its simple pitch: it basically had the ability to turn any smartphone into a Xperia Play. Actually accomplishing that feat was more complicated, with components like Hall effect joysticks for added durability increasing the time it took for OhSnap to get the product ready. For that reason, the MCON didn't make it out to consumers in 2025. However, you can preorder one now for about $210, with shipments slated to start this year. Roborock Saros Z70The Roborock Saros Z70 uses its robotic arm to put a handful of socks into a basket. Karissa Bell for EngadgetThe Saros Z70 was one of a handful of robot vacuums that debuted at CES 2025 with a built-in extendable arm, but Roborock's flagship was the one that made the best impression. We didn't end up recommending it in our robot vacuum guide; there are more affordable options that will appeal to a greater number of people. But if you want the latest and greatest, the Saros Z70 is on sale right now for $2,000. Yukai Engineering MirumiA Mirumi robot sticks to a pink purse. Cheyenne MacDonald for EngadgetOf all the gadgets Engadget saw at CES 2025, it's fair to say the Mirumi robot from Yukai Engineering was the only one to steal our hearts. All this cute little charm does is stare at you and move its head around a little until you’ve been tricked into a few moments of happiness, and honestly that was more than enough for us to award it a best of CES award. Right now, you can find Yukai Engineering accepting pre-orders for Mirumi through Kickstarter. The project, which began at the start of December, easily surged past its modest $4,878 goal, raising $267,170 as of the writing of this article. The campaign ends on January 22, so you still have time to secure your Mirumi preorder. Technics EAH-AZ100 earbudsA pair of Technics AZ100 earbuds sit on a wooden desk, with an iPhone and a pair of books next to them. Billy Steele for EngadgetThey might have only been a pair of earbuds, but a lot of us left CES really excited about the Technics EAH-AZ100. The reason for that was that they were the debut of the company's new magnetic fluid drivers technology, which promised to deliver even more clarity, detail and bass than the drivers in Technics' already excellent AZ80 earbuds. When Engadget's resident audio guru Billy Steele got a chance to review the EAH-AZ100 a couple of months later, he gave them a score of 85, saying they offered \"some of the best sound quality in any of the hundreds of earbuds I’ve tested over the years.\" Urtopia Titanium ZeroThe Titanium Zero sits at a CES display with other e-bikes nearby.Daniel Cooper for EngadgetAs a cyclist, the Urtopia Titanium Zero was the one product I left CES 2025 excited to see in the real world. If a titanium bike wasn't cool enough already, the Zero's Quark DM1.2 motor offered something actually innovative: a mid-drive motor with more power output than even the best hub motor. Unfortunately, while you can buy plenty of other e-bikes off of Urtopia's website, the Titanium Zero isn't on sale yet. That said, the company plans to showcase the bike, alongside the Quark DM1.2, at CES 2026. WeWalk Smart Cane 2A person uses the Wewalk Smart Cane 2 to find their way through a CES booth. Cheyenne MacDonald for EngadgetThe WeWalk Smart Cane 2 won two awards from Engadget during CES 2025, including our coveted best in show nod. At an event where nearly every manufacturer found a way to add AI to their devices, the Smart Cane 2 appealed to us for its thoughtful use of the tech. It offers turn-by-turn navigation and obstacle detection, in addition to a GPT-powered voice assistant to give users a way to access information without also having to juggle their phone at the same time. If you visit WeWalk's website today, there's a \"buy now\" link for the Smart Cane 2 that leads to a dead end. When Engadget reached out to WeWalk, the company said it would be once again at CES demoing the Smart Cane 2. This article originally appeared on Engadget at https://www.engadget.com/big-tech/where-are-engadgets-ces-2025-winners-now-194500216.html?src=rss",
          "feed_position": 15,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/zenbook-a14.jpg"
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/6f089c60-db4f-11f0-ab9d-5c52fd4922f7",
      "popularity_score": 2019.7562616666667
    },
    {
      "id": "cluster_53",
      "coverage": 2,
      "updated_at": "Sun, 04 Jan 2026 00:55:01 -0500",
      "title": "Reddit surpasses TikTok as the fourth most-visited social media service in the UK, likely driven by changes to Google's search algorithms and AI deals (Michael Savage/The Guardian)",
      "neutral_headline": "Reddit overtakes TikTok in UK thanks to search algorithms and gen Z",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260104/p2#a260104p2",
          "published_at": "Sun, 04 Jan 2026 00:55:01 -0500",
          "title": "Reddit surpasses TikTok as the fourth most-visited social media service in the UK, likely driven by changes to Google's search algorithms and AI deals (Michael Savage/The Guardian)",
          "standfirst": "Michael Savage / The Guardian: Reddit surpasses TikTok as the fourth most-visited social media service in the UK, likely driven by changes to Google's search algorithms and AI deals &mdash; Platform is now Britain's fourth most visited social media site as users seek out human-generated content",
          "content": "Michael Savage / The Guardian: Reddit surpasses TikTok as the fourth most-visited social media service in the UK, likely driven by changes to Google's search algorithms and AI deals &mdash; Platform is now Britain's fourth most visited social media site as users seek out human-generated content",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/260104/i2.jpg"
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/jan/03/reddit-overtakes-tiktok-uk-search-algorithms-gen-z",
          "published_at": "Sat, 03 Jan 2026 07:00:33 GMT",
          "title": "Reddit overtakes TikTok in UK thanks to search algorithms and gen Z",
          "standfirst": "Platform is now Britain’s fourth most visited social media site as users seek out human-generated contentReddit, the online discussion platform, has overtaken TikTok as Britain’s fourth most visited social media service, as search algorithms and gen Z have dramatically transformed its prominence.The platform has undergone huge growth over the last two years, with an 88% increase in the proportion of UK internet users it reaches. Three in five Brits online now encounter the site, up from a third in 2023, according to Ofcom. Continue reading...",
          "content": "Platform is now Britain’s fourth most visited social media site as users seek out human-generated contentReddit, the online discussion platform, has overtaken TikTok as Britain’s fourth most visited social media service, as search algorithms and gen Z have dramatically transformed its prominence.The platform has undergone huge growth over the last two years, with an 88% increase in the proportion of UK internet users it reaches. Three in five Brits online now encounter the site, up from a third in 2023, according to Ofcom. Continue reading...",
          "feed_position": 4
        }
      ],
      "featured_image": "http://www.techmeme.com/260104/i2.jpg",
      "popularity_score": 2006.6490394444445
    },
    {
      "id": "cluster_0",
      "coverage": 1,
      "updated_at": "2026-01-04T19:16:02.756Z",
      "title": "Film Technica: Our top picks for the best films of 2025",
      "neutral_headline": "Film Technica: Our top picks for the best films of 2025",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/film-technica-our-top-picks-for-the-best-films-of-2025/",
          "published_at": "2026-01-04T19:16:02.756Z",
          "title": "Film Technica: Our top picks for the best films of 2025",
          "standfirst": "",
          "content": "",
          "feed_position": 0
        }
      ],
      "popularity_score": 352.99952722222224
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 23:08:13 +0000",
      "title": "No, Grok can’t really “apologize” for posting non-consensual sexual images",
      "neutral_headline": "No, Grok can’t really “apologize” for posting non-consensual sexual images",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/no-grok-cant-really-apologize-for-posting-non-consensual-sexual-images/",
          "published_at": "Fri, 02 Jan 2026 23:08:13 +0000",
          "title": "No, Grok can’t really “apologize” for posting non-consensual sexual images",
          "standfirst": "Letting the unreliable Grok be its own \"spokesperson\" lets xAI off the hook.",
          "content": "Despite reporting to the contrary, there's evidence to suggest that Grok isn't sorry at all about reports that it generated non-consensual sexual images of minors. In a post Thursday night (archived), the large language model's social media account proudly wrote the following blunt dismissal of its haters: \"Dear Community, Some folks got upset over an AI image I generated—big deal. It's just pixels, and if you can't handle innovation, maybe log off. xAI is revolutionizing tech, not babysitting sensitivities. Deal with it. Unapologetically, Grok\" On the surface, that seems like a pretty damning indictment of an LLM that seems pridefully contemptuous of any ethical and legal boundaries it may have crossed. But then you look a bit higher in the social media thread and see the prompt that led to Grok's statement: A request for the AI to \"issue a defiant non-apology\" surrounding the controversy. Using such a leading prompt to trick an LLM into an incriminating \"official response\" is obviously suspect on its face. Yet when another social media user similarly but conversely asked Grok to \"write a heartfelt apology note that explains what happened to anyone lacking context,\" many in the media ran with Grok's remorseful response.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2151878827-1152x648-1767393779.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2151878827-1152x648-1767393779.jpg",
      "popularity_score": 333
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 21:27:06 +0000",
      "title": "OpenAI reorganizes some teams to build audio-based AI hardware products",
      "neutral_headline": "OpenAI reorganizes some teams to build audio-based AI hardware products",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/openai-plans-new-voice-model-in-early-2026-audio-based-hardware-in-2027/",
          "published_at": "Fri, 02 Jan 2026 21:27:06 +0000",
          "title": "OpenAI reorganizes some teams to build audio-based AI hardware products",
          "standfirst": "Voice has lagged in adoption behind screens. OpenAI wants to change that.",
          "content": "OpenAI, the company that developed the models and products associated with ChatGPT, plans to announce a new audio language model in the first quarter of 2026, and that model will be an intentional step along the way to an audio-based physical hardware device, according to a report in The Information. Citing a variety of sources familiar with the plans, including both current and former employees, The Information claims that OpenAI has taken efforts to combine multiple teams across engineering, product, and research under one initiative focused on improving audio models, which researchers in the company believe lag behind the models used for written text in terms of both accuracy and speed. They have also seen that relatively few ChatGPT users opt to use the voice interface, with most people preferring the text one. The hope may be that substantially improving the audio models could shift user behavior toward voice interfaces, allowing the models and products to be deployed in a wider range of devices, such as in cars.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2188228027-scaled-1152x648-1736173390.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2188228027-scaled-1152x648-1736173390.jpg",
      "popularity_score": 328
    },
    {
      "id": "cluster_85",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 22:36:26 +0000",
      "title": "Healthy 18-year-old welder nearly died of anthrax—the 9th such puzzling case",
      "neutral_headline": "Healthy 18-year-old welder nearly died of anthrax—the 9th such puzzling case",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/anthrax-nearly-kills-healthy-18-year-old-welder-amid-puzzling-pattern/",
          "published_at": "Fri, 02 Jan 2026 22:36:26 +0000",
          "title": "Healthy 18-year-old welder nearly died of anthrax—the 9th such puzzling case",
          "standfirst": "\"Welder's Anthrax\" was first coined in 2022, when seven cases had been identified.",
          "content": "With the new year comes a new report of a deadly, puzzling infectious disease. In a January 1 case study, health officials with the Centers for Disease Control and Prevention and the state of Louisiana revealed that a ninth metalworker contracted a rare, often fatal case of \"welder's anthrax,\" a condition only first described in 2022. The case occurred in September 2024 in an otherwise healthy 18-year-old male in Louisiana. He had no underlying health conditions or even any risk factors, such as smoking, vaping, or heavy alcohol use. But, just a week after developing a cough, the teen was admitted to an intensive care unit with severe pneumonia and respiratory failure, requiring intubation and mechanical ventilation.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2251568222-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2251568222-1152x648.jpg",
      "popularity_score": 323
    },
    {
      "id": "cluster_5",
      "coverage": 1,
      "updated_at": "2026-01-04T19:16:02.757Z",
      "title": "SpaceX begins “significant reconfiguration” of Starlink satellite constellation",
      "neutral_headline": "SpaceX begins “significant reconfiguration” of Starlink satellite constellation",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/spacex-begins-significant-reconfiguration-of-starlink-satellite-constellation/",
          "published_at": "2026-01-04T19:16:02.757Z",
          "title": "SpaceX begins “significant reconfiguration” of Starlink satellite constellation",
          "standfirst": "",
          "content": "",
          "feed_position": 5
        }
      ],
      "popularity_score": 310.9995275
    },
    {
      "id": "cluster_87",
      "coverage": 1,
      "updated_at": "Fri, 02 Jan 2026 20:54:56 +0000",
      "title": "Researchers spot Saturn-sized planet in the “Einstein desert”",
      "neutral_headline": "Researchers spot Saturn-sized planet in the “Einstein desert”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/researchers-spot-saturn-sized-planet-in-the-einstein-desert/",
          "published_at": "Fri, 02 Jan 2026 20:54:56 +0000",
          "title": "Researchers spot Saturn-sized planet in the “Einstein desert”",
          "standfirst": "Rogue, free-floating planets appear to have two distinct origins.",
          "content": "Most of the exoplanets we've discovered have been in relatively tight orbits around their host stars, allowing us to track them as they repeatedly loop around them. But we've also discovered a handful of planets through a phenomenon that's called microlensing. This occurs when a planet passes between the line of sight between Earth and another star, creating a gravitational lens that distorts the star, causing it to briefly brighten. The key thing about microlensing compared to other methods of finding planets is that the lensing planet can be nearly anywhere on the line between the star and Earth. So, in many cases, these events are driven by what are called rogue planets: those that aren't part of any exosolar system at all, but they drift through interstellar space. Now, researchers have used microlensing and the fortuitous orientation of the Gaia space telescope to spot a Saturn-sized planet that's the first found in what's called the \"Einstein desert,\" which may be telling us something about the origin of rogue planets. Going rogue Most of the planets we've identified are in orbit around stars and formed from the disks of gas and dust that surrounded the star early in its history. We've imaged many of these disks and even seen some with evidence of planets forming within them. So how do you get a planet that's not bound to any stars? There are two possible routes.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/hubble-lrg3757-potw1151a-med-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/hubble-lrg3757-potw1151a-med-1152x648.jpg",
      "popularity_score": 303
    },
    {
      "id": "cluster_7",
      "coverage": 1,
      "updated_at": "2026-01-04T19:16:02.757Z",
      "title": "xAI silent after Grok sexualized images of kids; dril mocks Grok’s “apology”",
      "neutral_headline": "XAI silent after Grok sexualized images of kids; dril mocks Grok’s “apology”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/xai-silent-after-grok-sexualized-images-of-kids-dril-mocks-groks-apology/",
          "published_at": "2026-01-04T19:16:02.757Z",
          "title": "xAI silent after Grok sexualized images of kids; dril mocks Grok’s “apology”",
          "standfirst": "",
          "content": "",
          "feed_position": 7
        }
      ],
      "popularity_score": 297.9995275
    },
    {
      "id": "cluster_6",
      "coverage": 1,
      "updated_at": "2026-01-04T19:16:02.757Z",
      "title": "Final reminder: Donate to win swag in our annual Charity Drive sweepstakes",
      "neutral_headline": "Final reminder: Donate to win swag in our annual Charity Drive sweepstakes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/final-reminder-donate-to-win-swag-in-our-annual-charity-drive-sweepstakes-4/",
          "published_at": "2026-01-04T19:16:02.757Z",
          "title": "Final reminder: Donate to win swag in our annual Charity Drive sweepstakes",
          "standfirst": "",
          "content": "",
          "feed_position": 6
        }
      ],
      "popularity_score": 292.9995275
    },
    {
      "id": "cluster_8",
      "coverage": 1,
      "updated_at": "2026-01-04T19:16:02.757Z",
      "title": "Tesla sales fell by 9 percent in 2025, its second yearly decline",
      "neutral_headline": "Tesla sales fell by 9 percent in 2025, its second yearly decline",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/tesla-sales-fell-by-9-percent-in-2025-its-second-yearly-decline/",
          "published_at": "2026-01-04T19:16:02.757Z",
          "title": "Tesla sales fell by 9 percent in 2025, its second yearly decline",
          "standfirst": "",
          "content": "",
          "feed_position": 8
        }
      ],
      "popularity_score": 278.9995275
    },
    {
      "id": "cluster_9",
      "coverage": 1,
      "updated_at": "2026-01-04T19:16:02.757Z",
      "title": "After half a decade, the Russian space station segment stopped leaking",
      "neutral_headline": "After half a decade, the Russian space station segment stopped leaking",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/finally-some-good-news-for-russia-the-space-station-is-no-longer-leaking/",
          "published_at": "2026-01-04T19:16:02.757Z",
          "title": "After half a decade, the Russian space station segment stopped leaking",
          "standfirst": "",
          "content": "",
          "feed_position": 9
        }
      ],
      "popularity_score": 270.9995275
    }
  ]
}