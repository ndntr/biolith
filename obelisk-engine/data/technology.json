{
  "updated_at": "2026-01-07T11:20:38.048Z",
  "clusters": [
    {
      "id": "cluster_31",
      "coverage": 3,
      "updated_at": "Tue, 06 Jan 2026 23:15:00 -0500",
      "title": "Motorola unveils the Razr Fold, its first book-style foldable phone, with a 6.6\" front display and an 8.1\" 2K LTPO inner screen, expected to launch this summer (Chris Welch/Bloomberg)",
      "neutral_headline": "Motorola reveals the Razr Fold, a book-style foldable launching this summer",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260106/p42#a260106p42",
          "published_at": "Tue, 06 Jan 2026 23:15:00 -0500",
          "title": "Motorola unveils the Razr Fold, its first book-style foldable phone, with a 6.6\" front display and an 8.1\" 2K LTPO inner screen, expected to launch this summer (Chris Welch/Bloomberg)",
          "standfirst": "Chris Welch / Bloomberg: Motorola unveils the Razr Fold, its first book-style foldable phone, with a 6.6\" front display and an 8.1\" 2K LTPO inner screen, expected to launch this summer &mdash; Lenovo Group Ltd.'s Motorola unveiled its first folding phone that opens like a book or passport, a departure from the string &hellip;",
          "content": "Chris Welch / Bloomberg: Motorola unveils the Razr Fold, its first book-style foldable phone, with a 6.6\" front display and an 8.1\" 2K LTPO inner screen, expected to launch this summer &mdash; Lenovo Group Ltd.'s Motorola unveiled its first folding phone that opens like a book or passport, a departure from the string &hellip;",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/260106/i42.jpg"
        },
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/motorola-reveals-the-razr-fold-a-book-style-foldable-launching-this-summer/",
          "published_at": "Wed, 07 Jan 2026 01:00:06 +0000",
          "title": "Motorola reveals the Razr Fold, a book-style foldable launching this summer",
          "standfirst": "Motorola is light on details but heavy on hype for its first book-style foldable.",
          "content": "Motorola is no stranger to foldables, having revived the Razr as a flip-style foldable phone in 2020. Now that it has a few iterations of modern flip phones under its belt, Moto is embarking on a new challenge: big foldables. The new (and thoroughly leaked) Motorola Razr Fold is a book-style foldable like Samsung's Galaxy Z Fold and Google's Pixel Fold lines, offering a smartphone-sized external display with a big foldable panel inside. Motorola is taking the opportunity to reveal the phone at CES, but it's far from ready for launch. Currently, Motorola is aiming to release the Razr Fold this coming summer for an unknown amount of money—Motorola won't confirm pricing or really much of anything about the Razr Fold at this time. What we do know is the device will be about as big as other large foldable phones, featuring a 6.6-inch external display and an 8.1-inch internal one. Moto says the main foldable OLED panel will have a 2K resolution, which means roughly 2,000 pixels tall. Again, this is similar to existing foldables.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/razr-fold-1152x648.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/motorola-razr-fold-ces-2026/",
          "published_at": "Wed, 07 Jan 2026 01:00:00 +0000",
          "title": "Motorola Razr Fold Book-Style Foldable: Specs, Details, Release Date",
          "standfirst": "At CES 2026, the company also announced a new smartwatch, stylus, Bluetooth tracker, and even a weird AI pendant.",
          "content": "At CES 2026, the company also announced a new smartwatch, stylus, Bluetooth tracker, and even a weird AI pendant.",
          "feed_position": 13,
          "image_url": "https://media.wired.com/photos/695d5207b6493d17e530b8d0/master/pass/Motorola-Razr-Fold-Gear-Julian-Chokkattu(1).jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260106/i42.jpg",
      "popularity_score": 3012.9060977777776
    },
    {
      "id": "cluster_3",
      "coverage": 2,
      "updated_at": "Wed, 07 Jan 2026 10:47:32 +0000",
      "title": "Everything announced at CES 2026",
      "neutral_headline": "Everything announced at CES 2026",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/everything-announced-at-ces-2026-130124802.html",
          "published_at": "Wed, 07 Jan 2026 10:47:32 +0000",
          "title": "Everything announced at CES 2026",
          "standfirst": "It's the first week of a new year and there's no time for the tech world to slowly ease back into things following the holidays. That's because CES 2026 is in full swing, with all manner of companies descending on Las Vegas to reveal their latest innovations and what they're planning to bring your way in the near future. Many of the Engadget crew are on the ground to check out as much of the new tech as possible. Of course, we're keeping tabs on all of the major CES press conferences too. Samsung held its First Look presentation, which focuses on home products, while LG has shown off a wide array of TVs and Lego unveiled its new Smart Brick technology. We’ve heard from the major chipmakers, gone hands-on with Samsung’s trifold phone, checked out some funky laptops and seen some cute robots.You can catch up on all of the big CES 2026 announcements (and some of the more offbeat gizmos we’ve seen) right here. We'll be keeping this story updated throughout the week. Micro RGB TVs Samsung's 130-inch Micro RGB TV. Devindra Hardawar for EngadgetMicro RGB is a term you can expect to hear about quite a bit in the coming months and years, especially when you're shopping for your next TV. Micro RGB is a new tech that's similar to Mini LED, though it uses red, green and blue LEDs instead of white backlights. Contrast ratios aren't quite as high as those on Micro LED and OLED displays, since the pixels can't be turned on and off individually. However, Micro RGB units are said to be brighter and more color accurate than TVs that use other display tech, in part because the LEDs in these screens offer smaller, more customizable dimming zones. Read reporter Steve Dent’s explainer for a deeper dive into how Micro RGB differs from other types of display tech.We're seeing more of these TVs pop up at CES 2026, including a mammoth 130-inch concept model that Samsung brought to Las Vegas. The company unveiled its first Micro RGB TV in August, — that’s a 115-inch, $29,999 model. This year, you can expect it to start offering Micro RGB TVs in 55-, 65- and 75-inch sizes. There are also 85-, 100- and 115-inch models on the way.LG revealed its first Micro RGB set at CES as well. The largest variant is 100 inches, but there are 86- and 75-inch models too. Elsewhere, LG showed off its latest Wallpaper TV, which is a 100-inch OLED display. We also got a look at LG's new Gallery TV — The Gallery is the company's take on Samsung's Frame TV format.Other new TVs and OS updatesEmber Artline TV.AmazonWe’ve got another competitor to The Frame, as Amazon has entered that scene with the Ember Artline TV. The 4K OLED model has Amazon Photos integration and you can choose from 2,000 pieces of free art to show on the screen. The Ember Artline can switch on or off automatically when someone enters or leaves the room. It runs on the Fire TV platform and (of course) there’s Alexa+ integration, along with support for Dolby Vision, HDR10+ and Wi-Fi 6. The Ember Artline is expected to start shipping this spring. It starts at $899 for the 55-inch model.The rounder redesigned Fire TV UI.AmazonSpeaking of Fire TV, Amazon has revamped the platform’s user interface with rounded corners for show, movie and app tiles; a little more space for said tiles; and typography and color gradient changes. The company has reworked the platform’s codebase as well, and it says the Fire TV OS will deliver speed boosts of up to 20 to 30 percent. Amazon will start rolling out the updated UI next month.On the Google side of TV land, you can expect more Gemini-powered features. The company is bringing the ability to search Google Photos for certain moments and people to Google TV, along with the options to remix photos into different styles and create slideshows on the fly. The Veo and Nano Banana AI video and photo generation models are coming to Google TV as well. You can also expect the ability to adjust TV settings using your voice. These Gemini features are coming to Google TV-powered TCL models first, then other devices in the following months. In the meantime, you can check out senior reporter Amy Skorheim’s hands-on impressions of the Gemini updates.SamsungSamsung's Music Studio 5 speakers at CES 2026.Billy Steele for EngadgetSamsung being Samsung, the company had a lot more up its sleeve at CES than just TVs. In the leadup to the event, it announced its two new soundbars (we're had some hands-on time with one of those), the stylish Music Studio speakers (we've got some IRL impressions of those), a bunch of monitors, the refreshed FreeStyle+ projector (we've checked that out too). It also announced plans to bring Google Photos to TVs.At the First Look showcase on Sunday, Samsung talked up \"AI experiences everywhere. For everyone\" (sigh). Here, we saw more TVs, such as the thin S95H OLED, which has a zero-gap mount that allows you to position the unit flush against a wall. First Look has long been focused on home products. Naturally, Samsung execs discussed some features for the company's fridges, such as ​​recipe selection updates, AI cooling tech and Google Gemini-powered AI Vision that's said to be able to recognize more items and help you figure out what you need to buy without having to manually take inventory. FoodNote, meanwhile, is a weekly summary that breaks down what has gone in and out of your fridge.Moreover, Samsung highlighted the Samsung Bespoke AI Laundry Combo and its new AI wash cycle. With the new Air Dresser — which has an Auto Wrinkle Care feature — Samsung aims to do away with irons (thank you, Samsung). As for the Bespoke AI smart vacuum and mop, that can apparently keep an eye on your pets when you're not home.LGLG's CLOiD robot.LGLikewise, LG brought other non-TV tech to CES. The company is shining the spotlight on its CLOiD robot. Like the far creepier-looking 1X Neo, the CLOiD is designed to help with household tasks such as starting laundry cycles, folding clothes, unloading the dishwasher and serving food. This appears to be more of a concept than something you'll be able to buy anytime soon, but we should get a closer look at the CLOiD in person this week.The company also debuted the LG Sound Suite, a modular home audio system it developed in conjunction with Dolby to take on the likes of Sonos. Just ahead of CES, LG pulled back the curtain on a new batch of xboom speakers as well as some monitors and ultralight Gram laptops that are made with a material it's calling Aerominum. LegoLego introduced the Smart Brick at CES 2026.LegoIn its first CES appearance, Lego announced the Smart Brick, a standard-sized brick with a 4.1mm ASIC chip inside that’s designed to respond in different ways depending on what set you’re building and how you’re building it. Using what Lego calls the “Play Engine” and integrated copper coils, each brick can sense things like motion, orientation and magnetic fields, plus its own distance, direction and orientation in relation to other Smart Bricks. Each brick also has a teeny tiny speaker built in that will play audio “tied to live play actions” rather than only pre-recorded clips.Accompanying Smart Bricks are Smart Tags and Smart Minifigures, which have their own capabilities — one of which is letting Smart Bricks know what context they are being used in. All of these pieces tie together via a local wireless layer dubbed BrickNet that, in part, lets Smart Bricks know where they are placed in relation to other smart components. It all seems very neat and I'm looking forward to seeing what else Lego and fans can do with these Smart Bricks.The first “Smart Play” partner is, unsurprisingly, Star Wars, which will launch three “all-in-one” sets using Smart Bricks, Smart Tags and Smart Minifigures. The 473-piece Darth Vader TIE Fighter set will cost $70; the 584-piece Luke’s Red Five X-Wing set comes in at $100 and the 962-piece Throne Room Duel & A-wing set will set you back $160. The speakers in these sets can emit lightsaber swooshes, fighter sounds and The Imperial March.The chipmakersNVIDIA CEO Jensen Huang presents at CES 2026, wearing a black snakeskin-like jacket.NVIDIAIt's CES, so of course we're going to see a bunch of laptops and desktops, along with announcements about the tech that powers the new models. That means NVIDIA, Intel, AMD and Qualcomm are all in town to talk up their latest chips and other innovations.Given its lofty position in the industry (and the economy) NVIDIA’s CES press conference is always one to keep an eye on. This year’s edition was laregly a recap of the company’s recent moves, but it did have some news to share.NVIDIA announced Alpamayo, which is a group of open-source reasoning models designed to help autonomous vehicles handle difficult driving scenarios. The company also revealed that a super computer built on the Vera Rubin GPU architecture NVIDIA unveiled in 2024 is in production. Intel at CES 2026Sam Chapman for EngadgetThings haven’t exactly been going great for Intel for a while, but the company is surely hoping that its Core Ultra Series 3 chips can help it right the ship. These are the first chips to be built using Intel’s 18A (18 angstroms, which is just under 2nm) process. The company says they offer improved performance — 60 percent more than the previous-gen Lunar Lake processors — and battery life improvements for laptops. The Ultra Series 3 includes a new Arc B390 integrated GPU, with 50 percent more graphics cores, double the cache and 120 GPU TOPS of performance. Put all that together and these chips should deliver up to 77 percent faster gaming performance than Lunar Lake models, Intel said. To that end, the company teased a Ultra Series 3-powered gaming handheld for later this year.A screenshot from AMD's CES 2026 press conference showing a hellish vision of the future of gaming.AMDOf course, AMD wasn’t going to be left out of the CES party. The company announced several CPUs for laptops and desktops, while chillingly declaring that “AI is everywhere” and “changing the face of gaming.” Ick. There was a lot of AI chat during the two-hour(!) keynote, along with a “a jet-powered flying robot.” Illustration showing the Qualcomm Snapdragon X2 Plus on a stylized red circuit board.QualcommAnd then there’s Qualcomm. The company revealed the Snapdragon X2 Plus chip at the show. It’s more of a mid-range chip that isn’t quite as powerful as the higher end Snapdragon X2 Elite — it doesn’t have as many CPU cores, for one thing. Still, Qualcomm claims the X2 Plus offers as much as 35 percent faster single-core performance over the previous gen. The company also says the Adreno GPU offers a performance boost of up to 29 percent compared with the last generation.Laptops Samsung Galaxy Book 6 seriesMat Smith for EngadgetWhat would CES be without some new hardware that makes use of those new chips? As ever, laptop and desktop makers were at the show to offer up their latest models for your consideration. (Be sure to check out our dedicated roundup of all the laptops that grabbed our attention at this year’s show.)Samsung’s Galaxy Book 6 Ultra, Galaxy Book 6 Pro and Galaxy Book 6 boast Intel’s Core Ultra Series 3 chips and revamped designs that are said to improve heat management. You can read our story on the Galaxy Book 6 series for the specs of these laptops, though we don’t have pricing or a release window as yet.Dell realized it messed up by killing off the XPS name as part of a broader rebranding effort and we’re glad to see that the company is making a U-turn on that front. A full lineup of XPS laptops is coming this year, including an all-new XPS 13 (a long-time Engadget fave on the Windows ultraportable front). Dell also has 14- and 16-inch XPS models in the hopper, along with others it’s keeping under wraps for now.On top of having two displays, the Zephyrus Duo's screens also feature excellent brightness at up to 1,100 nits.We love an odd laptop and ASUS didn’t disappoint by bringing the ROG Zephyrus Duo to CES. This is a dual-screen gaming laptop with two 16-inch OLED panels, one of Intel’s new CPUs and up to an NVIDIA RTX 5090 GPU. The keyboard is detachable and can work wirelessly. A kickstand can help you set up the Zephyrus Duo in all kinds of orientations. You can even position the dual screens in an upside-down “V” tent mode. We don’t know the price of the Zephyrus Duo as yet, but it surely won’t be inexpensive.Marketing photo of a Kojima-inspired ROG Flow Z13 tabletASUSThat’s not all ASUS brought to the dance. The company made a special edition of the ROG Flow Z13 some that’s styled after the works of the famed game designer Hideo Kojima. The ROG Flow Z13-KJP has visual flair that’s draws from the likes of Death Stranding and Metal Gear. Kojima’s Ludens mascot is here too. There’s no pricing or release date for this variant or its matching accessories just yet.L'OrealA pair of transparent eye masks with wires and bulbs inside them.L'Oréal L'Oreal often brings some interesting beauty tech to CES and the company did so again this year with a trio of gadgets. The LED Eye Mask uses red light and near-infrared light to address the likes of puffiness, discoloration and fine lines.The LED Face Mask seems to be a more pliable version of masks that we've seen from the likes of Dr. Dennis Gross, Omnilux, Therabody and Shark in recent years. However, it's only in prototype form for now and it isn't expected to hit the market until next year. The Light Straight + Multi-styler uses infrared light to help dry and style hair in similar fashion to L'Oreal's AirLight Pro. It's said to have sensors that employ \"built-in proprietary algorithms and machine learning\" so they can adapt to your gestures and \"maximize individual experience.\" L'Oreal claims that while traditional straighteners can operate at 400°F or higher (temperatures that can damage hair), its latest innovation \"effectively straightens hair while never exceeding 320°F.\" You can expect the Light Straight to arrive in 2027 as well.MobileSamsung Galaxy Z TriFold EngadgetAt CES 2026, we had our first chance to go hands on with the Samsung Galaxy Z TriFold, which the company officially announced last month. Senior writer Sam Rutherford had qualms about the price (not confirmed yet for North America, but it costs around $2,500 in Korea) and bulkiness. However, after Sam opened it up, “my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness.” That extra real estate could come in very useful for many folks. Combined with a keyboard and perhaps a mouse, it could well be the laptop/tablet replacement many have been waiting for. Be sure to read Sam’s hands-on for his full initial impressions.Back at CES 2024, we got to try out a physical keyboard phone accessory from Clicks. Fast forward two years, and the brand is making its own Blackberry-esque phones, as well as a new physical phone keyboard accessory. The Android 16-based Clicks Communicator has a tactile keyboard with a fingerprint sensor in the spacebar, a 4-inch OLED display, a 3.5mm headphone jack (hooray!) and expandable microSD storage up to 2TB. You can reserve one now for $399 — the price will increase to $499 on February 27.As for the new accessory, Clicks is calling that the Power Keyboard. It connects to an iOS or Android phone via MagSafe or Qi2, and it can operate as a power bank in a pinch thanks to the 2,150 mAh battery. The Power Keyboard has Bluetooth functionality as well, so you can use it with devices like tablets, smart TVs and virtual reality headsets. Pre-orders are open now and the Power Keyboard is expected to ship in the spring. Early adopters can lock in a pre-order for $79 before the retail price jumps to $110.The Punkt MC03 phone.PunktThose who prefer their mobile phones to have fewer bells and whistles might be interested in the latest model from Punkt. The MC03 is a nifty-looking touchscreen model that runs on the privacy- and security-centric AphyOS, which is based on the Android Open Source Project. It has a UI that borrows a page out of the Light Phone's playbook, though you can still install any Android app. The MC03 will hit European markets this month for €699 / CHF699 / £610. There's a mandatory subscription, however. You get a year of access included with a phone purchase, then it's a €10 / CHF10 / £9 monthly fee (paying for a long-term plan up front can reduce the cost by up to 60 percent).Charging techAnker and Belkin feel like CES mainstays at this point. They each had some interesting charging gear to show off this year. Belkin offered up a refreshed Nintendo Switch 2 case that recharges the console via its 10,000mAh power bank (which delivers up to 30W of fast charging). The case has an LCD screen on the outside to show you at a glance how much juice it has left and there’s a built-in kickstand for you to prop the console up on. Belkin’s new Switch 2 charging case costs $100 and it’s available now. The company’s new $100 UltraCharge Pro Power Bank can recharge two devices simultaneously. You can get your hands on that next month. There’s also a very slim BoostCharge power bank that can fit into your pocket. That will run you $60 and it will ship later this year. Anker Nano Charger (45W, Smart Display, 180° Foldable)AnkerAnker unveiled its neat Nano Charger, which can seemingly identify the iPhone model you hook up to it and provide the appropriate level of charging power. This plug will arrive later this month for $40. The company announced a string of other products that can charge multiple devices at the same time. The $150 foldable Prime Wireless Charging Station can juice up your iPhone, Apple Watch and AirPods simultaneously, with up to 25W of Qi2 wireless power. That’ll arrive by the end of March. There’s also a 10-in-1 Nano Power Strip ($70, late January release) with 70W of output, surge protection and multiple USB-C ports, USB-A ports and AC outlets. Anker also showed off a 13-in-1 Nano Docking Station that you can snag right now for $150. Among other things, this supports up to three 4K displays, as much as 100W of upstream charging and 10 Gbps of data transfer between devices that are hooked up to it. Handy!AI Amazon introduced Alexa.com to Alexa+ Early Access customers.AmazonNo prizes for guessing that there's going to be a ton of AI-related news at CES this year. Amazon, for one, announced that it's rolling out a web-based version of Alexa+. That means you won't necessarily need to have an Amazon device to try out the generative AI-powered assistant. However, Alexa+ Early Access customers are getting first dibs on the web version.Two Sweekar devices are pictured on a table, one wearing a pink and blue snowboarder outfit and the other (behind it) wearing a cowboy hat and outfitKarissa Bell for EngadgetThere are a boatload of AI-powered devices on the CES show floor too. One that we saw early on is a Tamagotchi-style virtual pet from a startup called Takway. The Sweekar will remember your interactions with it (you'll need to feed and play with the pet to keep it healthy and happy). Once it's all grown up, the Sweekar will head off on virtual adventures and tell you about its exploits when it \"returns.\" Takway will soon start a Kickstarter campaign for the Sweekar, which will likely cost between $100 and $150.Ludens AI's Cocomo robot,Cheyenne MacDonald for EngadgetLudens AI, meanwhile, showed off a pair of AI companion robots that are admittedly pretty cute. Cocomo can react to your voice and touch interactions, follow you around your home and learn about you over time. It stays close to human body temps, so it feels cozy if you hug it. Inu, on the other hand, stays on your desktop. It, too, responds to your voice and touch. The Fraimic art display at CESAmy Skorheim for EngadgetWe also saw the Fraimic, an E Ink display that can tap into OpenAI to generate images. There's no subscription for the Fraimic (which costs $399 for the standard size, which has a 13-inch display) and you get 100 AI-generated images per year included with your purchase. Pre-orders are open now and the Fraimic is expected to start shipping in this spring.MindClip held in a hand.Daniel Cooper for EngadgetSome companies are still trying to make wearable AI devices happen. SwitchBot has a wearable mic called the AI MindClip, which can seemingly record and transcribe everything you say (no, thank you!). Anker’s Soundcore division got in on the mix too with its Work voice recorder.Plaid, meanwhile, brought its NotePin follow up to the dance. This time around, the NotePin S has a button that you can push to record conversations. You can also press the button to flag key moments for an AI-generated summary to focus on. The NotePin S is available now for $179, should you be enticed to buy such a thing. On a similar note, Bee provided an update on what it’s bee-n up to since Amazon bought the company last year. It has developed four features that it’s rolling out to its existing AI voice recording wearable devices, including one that draft an email when you say you need to send one, and another that highlights trends in what you say over a period of weeks or months. There’s also a voice notes feature, because that’s something you can’t do with your phone already.RobotsThe product version of Boston Dynamics' Atlas.Boston DynamicsBoston Dynamics’ Atlas robot is ready to roll. We’ve seen a few iterations of this machine over the last few years and now the company’s latest model is set to go into production. In addition, Boston Dynamics has teamed up with Google DeepMind to fuse Gemini Robotics AI foundation models into Atlas robots. Per a press release, the partnership \"will focus on enabling humanoids to complete a wide variety of industrial tasks and is expected to become a driving force of manufacturing transformation, beginning in the automotive industry.\" As it happens, Hyundai (Boston Dynamics’ majority shareholder) and DeepMind will be among the first to receive Atlas robots.TransportationSony Honda Mobility Afeela Press Conference at CES 2026 AfeelaSony and Honda brought the latest revision of their first Afeela EV to CES 2026. We already knew that you’d be able to play your PS5 remotely while the vehicle is parked, though we learned some new details from the companies’ presentation. The Afeela 1 will debut with an advanced hands-off, eyes-on driver assistance system. The aim is to eventually offer Level 4 autonomy via over-the-air updates. Sony and Honda to plan to start shipments at the tail end of 2026, first in California, then in Arizona.We also got our first look at a model that’s a further down the pike. The Afeela Prototype 2026 is a taller version of the first EV. Just don’t expect to be able to try it yourself until at least 2028.Gaming Slide from NVIDIA's CES 2026 presentation about DLSS 4.5NVIDIANVIDIA announced the latest version of its DLSS (Deep Learning Super Sampling) upscaling tech. DLSS 4.5 is said to offer sharper visuals thanks to the 2nd Generation Super Resolution Transformer, which is available now for all RTX GPUs. NVIDIA says this offers better temporal stability, reduced ghosting and improved anti-aliasing.On GeForce RTX 50 Series GPUs, DLSS 4.5 will be able to generate up to five extra frames for each traditionally rendered one and deliver up to 4K 240Hz path traced performance, NVIDIA says. The Dynamic 6x Frame Generation feature will be available for those graphics cards sometime this spring.NVIDIA also detailed a new version of its G-Sync variable refresh rate tech. It says that G-Sync Pulsar can minimize motion blur by effectively quadrupling your refresh rate. So 250 Hz gameplay will seemingly offer up a perceived effective motion clarity of over 1,000 Hz with G-Sync Pulsar enabled. You’ll need a G-Sync Pulsar-compatible display to use this feature. Most displays have a backlight that’s always on, so images fade from one frame to the next. On G-Sync Pulsar displays, there are several horizontal backlight sections. The backlights pulse from top to bottom. This is said to help the pixels in each frame stabilize before they’re backlit, resulting in lower motion blur. It’s interesting stuff. Acer, AOC, ASUS and MSI are each releasing a G-Sync Pulsar-compatible 27-inch monitor this week.8BitDo FlipPad8BitDoThe FlipPad is one of my favorite things I’ve seen coming out of CES this year. It’s an 8BitDo mobile game controller that’s designed for vertical use. There are a bunch of neat physical controllers for phones that are built for landscape mode. But many mobile games are played with the phone oriented to the vertical position. And that’s not to mention emulators that allow you to play the likes of Game Boy titles while your phone stands tall. So it’s neat to see 8BitDo offering a physical controller that’ll do the trick. The company also unveiled a new Xbox controller with swappable joysticks and button modules.AudioA speaker and a turntable.Victrola Victrola announced a pretty Bluetooth speaker that sits neatly underneath its turntables. You can use a cable to connect the two as well. Of course, you can play audio from other devices, including phones and tablets. I’ve had my eye on a Victrola turntable for a while thanks to its Sonos integration, and the Soundstage speaker is tempting too. The Soundstage will be available this summer for $350. The three sizes from the Cambridge Audio L/R speaker series. Green speakers in three sizes.Cambridge AudioSpeaking of pretty speakers, I really like the aesthetic of these three wireless bookshelf options from Cambridge Audio. The classy-lookin’ L/R Series speakers start at $549 for a 100W model with a 21mm hard-dome tweeter with a 3-inch long-throw woofer hut no support for Wi-Fi streaming (there is Bluetooth aptX HD, though). At the top end is the $2,299 L/R X, a 800W speaker that has a a 2.5-way acoustic design with a 28mm Torus tweeter and dual five-inch woofers. There’s even a touch of LED underlighting on this model and the $1,599 L/R M, which has 300W of power, smaller four-inch dual woofers and the same 28mm tweeter. All three speakers will be available later this year.This article originally appeared on Engadget at https://www.engadget.com/general/everything-announced-at-ces-2026-130124802.html?src=rss",
          "content": "It's the first week of a new year and there's no time for the tech world to slowly ease back into things following the holidays. That's because CES 2026 is in full swing, with all manner of companies descending on Las Vegas to reveal their latest innovations and what they're planning to bring your way in the near future. Many of the Engadget crew are on the ground to check out as much of the new tech as possible. Of course, we're keeping tabs on all of the major CES press conferences too. Samsung held its First Look presentation, which focuses on home products, while LG has shown off a wide array of TVs and Lego unveiled its new Smart Brick technology. We’ve heard from the major chipmakers, gone hands-on with Samsung’s trifold phone, checked out some funky laptops and seen some cute robots.You can catch up on all of the big CES 2026 announcements (and some of the more offbeat gizmos we’ve seen) right here. We'll be keeping this story updated throughout the week. Micro RGB TVs Samsung's 130-inch Micro RGB TV. Devindra Hardawar for EngadgetMicro RGB is a term you can expect to hear about quite a bit in the coming months and years, especially when you're shopping for your next TV. Micro RGB is a new tech that's similar to Mini LED, though it uses red, green and blue LEDs instead of white backlights. Contrast ratios aren't quite as high as those on Micro LED and OLED displays, since the pixels can't be turned on and off individually. However, Micro RGB units are said to be brighter and more color accurate than TVs that use other display tech, in part because the LEDs in these screens offer smaller, more customizable dimming zones. Read reporter Steve Dent’s explainer for a deeper dive into how Micro RGB differs from other types of display tech.We're seeing more of these TVs pop up at CES 2026, including a mammoth 130-inch concept model that Samsung brought to Las Vegas. The company unveiled its first Micro RGB TV in August, — that’s a 115-inch, $29,999 model. This year, you can expect it to start offering Micro RGB TVs in 55-, 65- and 75-inch sizes. There are also 85-, 100- and 115-inch models on the way.LG revealed its first Micro RGB set at CES as well. The largest variant is 100 inches, but there are 86- and 75-inch models too. Elsewhere, LG showed off its latest Wallpaper TV, which is a 100-inch OLED display. We also got a look at LG's new Gallery TV — The Gallery is the company's take on Samsung's Frame TV format.Other new TVs and OS updatesEmber Artline TV.AmazonWe’ve got another competitor to The Frame, as Amazon has entered that scene with the Ember Artline TV. The 4K OLED model has Amazon Photos integration and you can choose from 2,000 pieces of free art to show on the screen. The Ember Artline can switch on or off automatically when someone enters or leaves the room. It runs on the Fire TV platform and (of course) there’s Alexa+ integration, along with support for Dolby Vision, HDR10+ and Wi-Fi 6. The Ember Artline is expected to start shipping this spring. It starts at $899 for the 55-inch model.The rounder redesigned Fire TV UI.AmazonSpeaking of Fire TV, Amazon has revamped the platform’s user interface with rounded corners for show, movie and app tiles; a little more space for said tiles; and typography and color gradient changes. The company has reworked the platform’s codebase as well, and it says the Fire TV OS will deliver speed boosts of up to 20 to 30 percent. Amazon will start rolling out the updated UI next month.On the Google side of TV land, you can expect more Gemini-powered features. The company is bringing the ability to search Google Photos for certain moments and people to Google TV, along with the options to remix photos into different styles and create slideshows on the fly. The Veo and Nano Banana AI video and photo generation models are coming to Google TV as well. You can also expect the ability to adjust TV settings using your voice. These Gemini features are coming to Google TV-powered TCL models first, then other devices in the following months. In the meantime, you can check out senior reporter Amy Skorheim’s hands-on impressions of the Gemini updates.SamsungSamsung's Music Studio 5 speakers at CES 2026.Billy Steele for EngadgetSamsung being Samsung, the company had a lot more up its sleeve at CES than just TVs. In the leadup to the event, it announced its two new soundbars (we're had some hands-on time with one of those), the stylish Music Studio speakers (we've got some IRL impressions of those), a bunch of monitors, the refreshed FreeStyle+ projector (we've checked that out too). It also announced plans to bring Google Photos to TVs.At the First Look showcase on Sunday, Samsung talked up \"AI experiences everywhere. For everyone\" (sigh). Here, we saw more TVs, such as the thin S95H OLED, which has a zero-gap mount that allows you to position the unit flush against a wall. First Look has long been focused on home products. Naturally, Samsung execs discussed some features for the company's fridges, such as ​​recipe selection updates, AI cooling tech and Google Gemini-powered AI Vision that's said to be able to recognize more items and help you figure out what you need to buy without having to manually take inventory. FoodNote, meanwhile, is a weekly summary that breaks down what has gone in and out of your fridge.Moreover, Samsung highlighted the Samsung Bespoke AI Laundry Combo and its new AI wash cycle. With the new Air Dresser — which has an Auto Wrinkle Care feature — Samsung aims to do away with irons (thank you, Samsung). As for the Bespoke AI smart vacuum and mop, that can apparently keep an eye on your pets when you're not home.LGLG's CLOiD robot.LGLikewise, LG brought other non-TV tech to CES. The company is shining the spotlight on its CLOiD robot. Like the far creepier-looking 1X Neo, the CLOiD is designed to help with household tasks such as starting laundry cycles, folding clothes, unloading the dishwasher and serving food. This appears to be more of a concept than something you'll be able to buy anytime soon, but we should get a closer look at the CLOiD in person this week.The company also debuted the LG Sound Suite, a modular home audio system it developed in conjunction with Dolby to take on the likes of Sonos. Just ahead of CES, LG pulled back the curtain on a new batch of xboom speakers as well as some monitors and ultralight Gram laptops that are made with a material it's calling Aerominum. LegoLego introduced the Smart Brick at CES 2026.LegoIn its first CES appearance, Lego announced the Smart Brick, a standard-sized brick with a 4.1mm ASIC chip inside that’s designed to respond in different ways depending on what set you’re building and how you’re building it. Using what Lego calls the “Play Engine” and integrated copper coils, each brick can sense things like motion, orientation and magnetic fields, plus its own distance, direction and orientation in relation to other Smart Bricks. Each brick also has a teeny tiny speaker built in that will play audio “tied to live play actions” rather than only pre-recorded clips.Accompanying Smart Bricks are Smart Tags and Smart Minifigures, which have their own capabilities — one of which is letting Smart Bricks know what context they are being used in. All of these pieces tie together via a local wireless layer dubbed BrickNet that, in part, lets Smart Bricks know where they are placed in relation to other smart components. It all seems very neat and I'm looking forward to seeing what else Lego and fans can do with these Smart Bricks.The first “Smart Play” partner is, unsurprisingly, Star Wars, which will launch three “all-in-one” sets using Smart Bricks, Smart Tags and Smart Minifigures. The 473-piece Darth Vader TIE Fighter set will cost $70; the 584-piece Luke’s Red Five X-Wing set comes in at $100 and the 962-piece Throne Room Duel & A-wing set will set you back $160. The speakers in these sets can emit lightsaber swooshes, fighter sounds and The Imperial March.The chipmakersNVIDIA CEO Jensen Huang presents at CES 2026, wearing a black snakeskin-like jacket.NVIDIAIt's CES, so of course we're going to see a bunch of laptops and desktops, along with announcements about the tech that powers the new models. That means NVIDIA, Intel, AMD and Qualcomm are all in town to talk up their latest chips and other innovations.Given its lofty position in the industry (and the economy) NVIDIA’s CES press conference is always one to keep an eye on. This year’s edition was laregly a recap of the company’s recent moves, but it did have some news to share.NVIDIA announced Alpamayo, which is a group of open-source reasoning models designed to help autonomous vehicles handle difficult driving scenarios. The company also revealed that a super computer built on the Vera Rubin GPU architecture NVIDIA unveiled in 2024 is in production. Intel at CES 2026Sam Chapman for EngadgetThings haven’t exactly been going great for Intel for a while, but the company is surely hoping that its Core Ultra Series 3 chips can help it right the ship. These are the first chips to be built using Intel’s 18A (18 angstroms, which is just under 2nm) process. The company says they offer improved performance — 60 percent more than the previous-gen Lunar Lake processors — and battery life improvements for laptops. The Ultra Series 3 includes a new Arc B390 integrated GPU, with 50 percent more graphics cores, double the cache and 120 GPU TOPS of performance. Put all that together and these chips should deliver up to 77 percent faster gaming performance than Lunar Lake models, Intel said. To that end, the company teased a Ultra Series 3-powered gaming handheld for later this year.A screenshot from AMD's CES 2026 press conference showing a hellish vision of the future of gaming.AMDOf course, AMD wasn’t going to be left out of the CES party. The company announced several CPUs for laptops and desktops, while chillingly declaring that “AI is everywhere” and “changing the face of gaming.” Ick. There was a lot of AI chat during the two-hour(!) keynote, along with a “a jet-powered flying robot.” Illustration showing the Qualcomm Snapdragon X2 Plus on a stylized red circuit board.QualcommAnd then there’s Qualcomm. The company revealed the Snapdragon X2 Plus chip at the show. It’s more of a mid-range chip that isn’t quite as powerful as the higher end Snapdragon X2 Elite — it doesn’t have as many CPU cores, for one thing. Still, Qualcomm claims the X2 Plus offers as much as 35 percent faster single-core performance over the previous gen. The company also says the Adreno GPU offers a performance boost of up to 29 percent compared with the last generation.Laptops Samsung Galaxy Book 6 seriesMat Smith for EngadgetWhat would CES be without some new hardware that makes use of those new chips? As ever, laptop and desktop makers were at the show to offer up their latest models for your consideration. (Be sure to check out our dedicated roundup of all the laptops that grabbed our attention at this year’s show.)Samsung’s Galaxy Book 6 Ultra, Galaxy Book 6 Pro and Galaxy Book 6 boast Intel’s Core Ultra Series 3 chips and revamped designs that are said to improve heat management. You can read our story on the Galaxy Book 6 series for the specs of these laptops, though we don’t have pricing or a release window as yet.Dell realized it messed up by killing off the XPS name as part of a broader rebranding effort and we’re glad to see that the company is making a U-turn on that front. A full lineup of XPS laptops is coming this year, including an all-new XPS 13 (a long-time Engadget fave on the Windows ultraportable front). Dell also has 14- and 16-inch XPS models in the hopper, along with others it’s keeping under wraps for now.On top of having two displays, the Zephyrus Duo's screens also feature excellent brightness at up to 1,100 nits.We love an odd laptop and ASUS didn’t disappoint by bringing the ROG Zephyrus Duo to CES. This is a dual-screen gaming laptop with two 16-inch OLED panels, one of Intel’s new CPUs and up to an NVIDIA RTX 5090 GPU. The keyboard is detachable and can work wirelessly. A kickstand can help you set up the Zephyrus Duo in all kinds of orientations. You can even position the dual screens in an upside-down “V” tent mode. We don’t know the price of the Zephyrus Duo as yet, but it surely won’t be inexpensive.Marketing photo of a Kojima-inspired ROG Flow Z13 tabletASUSThat’s not all ASUS brought to the dance. The company made a special edition of the ROG Flow Z13 some that’s styled after the works of the famed game designer Hideo Kojima. The ROG Flow Z13-KJP has visual flair that’s draws from the likes of Death Stranding and Metal Gear. Kojima’s Ludens mascot is here too. There’s no pricing or release date for this variant or its matching accessories just yet.L'OrealA pair of transparent eye masks with wires and bulbs inside them.L'Oréal L'Oreal often brings some interesting beauty tech to CES and the company did so again this year with a trio of gadgets. The LED Eye Mask uses red light and near-infrared light to address the likes of puffiness, discoloration and fine lines.The LED Face Mask seems to be a more pliable version of masks that we've seen from the likes of Dr. Dennis Gross, Omnilux, Therabody and Shark in recent years. However, it's only in prototype form for now and it isn't expected to hit the market until next year. The Light Straight + Multi-styler uses infrared light to help dry and style hair in similar fashion to L'Oreal's AirLight Pro. It's said to have sensors that employ \"built-in proprietary algorithms and machine learning\" so they can adapt to your gestures and \"maximize individual experience.\" L'Oreal claims that while traditional straighteners can operate at 400°F or higher (temperatures that can damage hair), its latest innovation \"effectively straightens hair while never exceeding 320°F.\" You can expect the Light Straight to arrive in 2027 as well.MobileSamsung Galaxy Z TriFold EngadgetAt CES 2026, we had our first chance to go hands on with the Samsung Galaxy Z TriFold, which the company officially announced last month. Senior writer Sam Rutherford had qualms about the price (not confirmed yet for North America, but it costs around $2,500 in Korea) and bulkiness. However, after Sam opened it up, “my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness.” That extra real estate could come in very useful for many folks. Combined with a keyboard and perhaps a mouse, it could well be the laptop/tablet replacement many have been waiting for. Be sure to read Sam’s hands-on for his full initial impressions.Back at CES 2024, we got to try out a physical keyboard phone accessory from Clicks. Fast forward two years, and the brand is making its own Blackberry-esque phones, as well as a new physical phone keyboard accessory. The Android 16-based Clicks Communicator has a tactile keyboard with a fingerprint sensor in the spacebar, a 4-inch OLED display, a 3.5mm headphone jack (hooray!) and expandable microSD storage up to 2TB. You can reserve one now for $399 — the price will increase to $499 on February 27.As for the new accessory, Clicks is calling that the Power Keyboard. It connects to an iOS or Android phone via MagSafe or Qi2, and it can operate as a power bank in a pinch thanks to the 2,150 mAh battery. The Power Keyboard has Bluetooth functionality as well, so you can use it with devices like tablets, smart TVs and virtual reality headsets. Pre-orders are open now and the Power Keyboard is expected to ship in the spring. Early adopters can lock in a pre-order for $79 before the retail price jumps to $110.The Punkt MC03 phone.PunktThose who prefer their mobile phones to have fewer bells and whistles might be interested in the latest model from Punkt. The MC03 is a nifty-looking touchscreen model that runs on the privacy- and security-centric AphyOS, which is based on the Android Open Source Project. It has a UI that borrows a page out of the Light Phone's playbook, though you can still install any Android app. The MC03 will hit European markets this month for €699 / CHF699 / £610. There's a mandatory subscription, however. You get a year of access included with a phone purchase, then it's a €10 / CHF10 / £9 monthly fee (paying for a long-term plan up front can reduce the cost by up to 60 percent).Charging techAnker and Belkin feel like CES mainstays at this point. They each had some interesting charging gear to show off this year. Belkin offered up a refreshed Nintendo Switch 2 case that recharges the console via its 10,000mAh power bank (which delivers up to 30W of fast charging). The case has an LCD screen on the outside to show you at a glance how much juice it has left and there’s a built-in kickstand for you to prop the console up on. Belkin’s new Switch 2 charging case costs $100 and it’s available now. The company’s new $100 UltraCharge Pro Power Bank can recharge two devices simultaneously. You can get your hands on that next month. There’s also a very slim BoostCharge power bank that can fit into your pocket. That will run you $60 and it will ship later this year. Anker Nano Charger (45W, Smart Display, 180° Foldable)AnkerAnker unveiled its neat Nano Charger, which can seemingly identify the iPhone model you hook up to it and provide the appropriate level of charging power. This plug will arrive later this month for $40. The company announced a string of other products that can charge multiple devices at the same time. The $150 foldable Prime Wireless Charging Station can juice up your iPhone, Apple Watch and AirPods simultaneously, with up to 25W of Qi2 wireless power. That’ll arrive by the end of March. There’s also a 10-in-1 Nano Power Strip ($70, late January release) with 70W of output, surge protection and multiple USB-C ports, USB-A ports and AC outlets. Anker also showed off a 13-in-1 Nano Docking Station that you can snag right now for $150. Among other things, this supports up to three 4K displays, as much as 100W of upstream charging and 10 Gbps of data transfer between devices that are hooked up to it. Handy!AI Amazon introduced Alexa.com to Alexa+ Early Access customers.AmazonNo prizes for guessing that there's going to be a ton of AI-related news at CES this year. Amazon, for one, announced that it's rolling out a web-based version of Alexa+. That means you won't necessarily need to have an Amazon device to try out the generative AI-powered assistant. However, Alexa+ Early Access customers are getting first dibs on the web version.Two Sweekar devices are pictured on a table, one wearing a pink and blue snowboarder outfit and the other (behind it) wearing a cowboy hat and outfitKarissa Bell for EngadgetThere are a boatload of AI-powered devices on the CES show floor too. One that we saw early on is a Tamagotchi-style virtual pet from a startup called Takway. The Sweekar will remember your interactions with it (you'll need to feed and play with the pet to keep it healthy and happy). Once it's all grown up, the Sweekar will head off on virtual adventures and tell you about its exploits when it \"returns.\" Takway will soon start a Kickstarter campaign for the Sweekar, which will likely cost between $100 and $150.Ludens AI's Cocomo robot,Cheyenne MacDonald for EngadgetLudens AI, meanwhile, showed off a pair of AI companion robots that are admittedly pretty cute. Cocomo can react to your voice and touch interactions, follow you around your home and learn about you over time. It stays close to human body temps, so it feels cozy if you hug it. Inu, on the other hand, stays on your desktop. It, too, responds to your voice and touch. The Fraimic art display at CESAmy Skorheim for EngadgetWe also saw the Fraimic, an E Ink display that can tap into OpenAI to generate images. There's no subscription for the Fraimic (which costs $399 for the standard size, which has a 13-inch display) and you get 100 AI-generated images per year included with your purchase. Pre-orders are open now and the Fraimic is expected to start shipping in this spring.MindClip held in a hand.Daniel Cooper for EngadgetSome companies are still trying to make wearable AI devices happen. SwitchBot has a wearable mic called the AI MindClip, which can seemingly record and transcribe everything you say (no, thank you!). Anker’s Soundcore division got in on the mix too with its Work voice recorder.Plaid, meanwhile, brought its NotePin follow up to the dance. This time around, the NotePin S has a button that you can push to record conversations. You can also press the button to flag key moments for an AI-generated summary to focus on. The NotePin S is available now for $179, should you be enticed to buy such a thing. On a similar note, Bee provided an update on what it’s bee-n up to since Amazon bought the company last year. It has developed four features that it’s rolling out to its existing AI voice recording wearable devices, including one that draft an email when you say you need to send one, and another that highlights trends in what you say over a period of weeks or months. There’s also a voice notes feature, because that’s something you can’t do with your phone already.RobotsThe product version of Boston Dynamics' Atlas.Boston DynamicsBoston Dynamics’ Atlas robot is ready to roll. We’ve seen a few iterations of this machine over the last few years and now the company’s latest model is set to go into production. In addition, Boston Dynamics has teamed up with Google DeepMind to fuse Gemini Robotics AI foundation models into Atlas robots. Per a press release, the partnership \"will focus on enabling humanoids to complete a wide variety of industrial tasks and is expected to become a driving force of manufacturing transformation, beginning in the automotive industry.\" As it happens, Hyundai (Boston Dynamics’ majority shareholder) and DeepMind will be among the first to receive Atlas robots.TransportationSony Honda Mobility Afeela Press Conference at CES 2026 AfeelaSony and Honda brought the latest revision of their first Afeela EV to CES 2026. We already knew that you’d be able to play your PS5 remotely while the vehicle is parked, though we learned some new details from the companies’ presentation. The Afeela 1 will debut with an advanced hands-off, eyes-on driver assistance system. The aim is to eventually offer Level 4 autonomy via over-the-air updates. Sony and Honda to plan to start shipments at the tail end of 2026, first in California, then in Arizona.We also got our first look at a model that’s a further down the pike. The Afeela Prototype 2026 is a taller version of the first EV. Just don’t expect to be able to try it yourself until at least 2028.Gaming Slide from NVIDIA's CES 2026 presentation about DLSS 4.5NVIDIANVIDIA announced the latest version of its DLSS (Deep Learning Super Sampling) upscaling tech. DLSS 4.5 is said to offer sharper visuals thanks to the 2nd Generation Super Resolution Transformer, which is available now for all RTX GPUs. NVIDIA says this offers better temporal stability, reduced ghosting and improved anti-aliasing.On GeForce RTX 50 Series GPUs, DLSS 4.5 will be able to generate up to five extra frames for each traditionally rendered one and deliver up to 4K 240Hz path traced performance, NVIDIA says. The Dynamic 6x Frame Generation feature will be available for those graphics cards sometime this spring.NVIDIA also detailed a new version of its G-Sync variable refresh rate tech. It says that G-Sync Pulsar can minimize motion blur by effectively quadrupling your refresh rate. So 250 Hz gameplay will seemingly offer up a perceived effective motion clarity of over 1,000 Hz with G-Sync Pulsar enabled. You’ll need a G-Sync Pulsar-compatible display to use this feature. Most displays have a backlight that’s always on, so images fade from one frame to the next. On G-Sync Pulsar displays, there are several horizontal backlight sections. The backlights pulse from top to bottom. This is said to help the pixels in each frame stabilize before they’re backlit, resulting in lower motion blur. It’s interesting stuff. Acer, AOC, ASUS and MSI are each releasing a G-Sync Pulsar-compatible 27-inch monitor this week.8BitDo FlipPad8BitDoThe FlipPad is one of my favorite things I’ve seen coming out of CES this year. It’s an 8BitDo mobile game controller that’s designed for vertical use. There are a bunch of neat physical controllers for phones that are built for landscape mode. But many mobile games are played with the phone oriented to the vertical position. And that’s not to mention emulators that allow you to play the likes of Game Boy titles while your phone stands tall. So it’s neat to see 8BitDo offering a physical controller that’ll do the trick. The company also unveiled a new Xbox controller with swappable joysticks and button modules.AudioA speaker and a turntable.Victrola Victrola announced a pretty Bluetooth speaker that sits neatly underneath its turntables. You can use a cable to connect the two as well. Of course, you can play audio from other devices, including phones and tablets. I’ve had my eye on a Victrola turntable for a while thanks to its Sonos integration, and the Soundstage speaker is tempting too. The Soundstage will be available this summer for $350. The three sizes from the Cambridge Audio L/R speaker series. Green speakers in three sizes.Cambridge AudioSpeaking of pretty speakers, I really like the aesthetic of these three wireless bookshelf options from Cambridge Audio. The classy-lookin’ L/R Series speakers start at $549 for a 100W model with a 21mm hard-dome tweeter with a 3-inch long-throw woofer hut no support for Wi-Fi streaming (there is Bluetooth aptX HD, though). At the top end is the $2,299 L/R X, a 800W speaker that has a a 2.5-way acoustic design with a 28mm Torus tweeter and dual five-inch woofers. There’s even a touch of LED underlighting on this model and the $1,599 L/R M, which has 300W of power, smaller four-inch dual woofers and the same 28mm tweeter. All three speakers will be available later this year.This article originally appeared on Engadget at https://www.engadget.com/general/everything-announced-at-ces-2026-130124802.html?src=rss",
          "feed_position": 0,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Samsung_Micro_RGB-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/best-budgeting-apps-120036303.html",
          "published_at": "Wed, 07 Jan 2026 10:00:35 +0000",
          "title": "The best budgeting apps for 2025",
          "standfirst": "As a former Mint user, I had to find a new budgeting app not too long ago. Intuit, parent company of Mint, shut down the service in March 2024, and prompted users to transition to its other financial app, Credit Karma. However, after testing Credit Karma myself, I found it to be a poor Mint replacement — that meant I needed to branch out and look elsewhere for a trusted app to track all of my financial accounts, monitor my credit score, follow a monthly spending plan and set goals like building a rainy-day fund and paying down my mortgage faster.I tried out Mint's top competitors in the hopes that I'd be able to find a new budgeting app that could handle all of my financial needs. Hopefully my journey can help you find the best budgeting app for you and your money as well. Best budget apps of 2025 Other budgeting apps we tested PocketGuard PocketGuard used to be a solid free budget tracker, but the company has since limited its “free” version to just a free seven-day trial. Now, you’ll have to choose between two plans once the trial is over: a $13 monthly plan or a $75 annual plan. When I first tested it, I found it to be more restricted than NerdWallet, but still a decent option. The main overview screen shows you your net worth, total assets and debts; net income and total spending for the month; upcoming bills; a handy reminder of when your next paycheck lands; any debt payoff plan you have; and any goals. Like some other apps, including Quicken Simplifi, PocketGuard promotes an “after bills” approach, where you enter all of your recurring bills, and then PocketGuard shows you what’s left, and that’s what you’re supposed to be budgeting: your disposable income. Although PocketGuard’s UI is easy enough to understand, it lacks polish. The “accounts” tab is a little busy, and doesn’t show totals for categories like cash or investments. Seemingly small details like weirdly phrased or punctuated copy occasionally make the app feel janky. More than once, it prompted me to update the app when no updates were available. The web version, meanwhile, feels like the mobile app blown up to a larger format and doesn’t take advantage of the extra screen real estate. Ultimately, now that the free tier is gone, it just doesn’t present the same value proposition as it once did. How we test budgeting apps Before I dove in and started testing out budgeting apps, I had to do some research. To find a list of apps to try out, I consulted trusty ol’ Google (and even trustier Reddit); read reviews of popular apps on the App Store; and also asked friends and colleagues what budget tracking apps (or other budgeting methods) they might be using for money management. Some of the apps I found were free and these, of course, show loads of ads (excuse me, “offers”) to stay in business. But most of the available apps require paid subscriptions, with prices typically topping out around $100 a year, or $15 a month. (Spoiler: My top pick is cheaper than that.) All of the services I chose to test needed to do several things: import all of your account data into one place; offer budgeting tools; and track your spending, net worth and credit score. Except where noted, all of these apps are available for iOS, Android and on the web. Once I had my shortlist of six apps, I got to work setting them up. For the sake of thoroughly testing these apps, I made a point of adding every account to every budgeting app, no matter how small or immaterial the balance. What ensued was a veritable Groundhog Day of two-factor authentication. Just hours of entering passwords and one-time passcodes, for the same banks half a dozen times over. Hopefully, you only have to do this once. Budgeting app FAQs What is Plaid and how does it work? Each of the apps I tested uses the same underlying network, called Plaid, to pull in financial data, so it’s worth explaining what it is and how it works. Plaid was founded as a fintech startup in 2013 and is today the industry standard in connecting banks with third-party apps. Plaid works with over 12,000 financial institutions across the US, Canada and Europe. Additionally, more than 8,000 third-party apps and services rely on Plaid, the company claims. To be clear, you don’t need a dedicated Plaid app to use it; the technology is baked into a wide array of apps, including all of the budgeting apps listed in this guide. Once you find the “add an account” option in whichever one you’re using, you’ll see a menu of commonly used banks. There’s also a search field you can use to look yours up directly. Once you find yours, you’ll be prompted to enter your login credentials. If you have two-factor authentication set up, you’ll need to enter a one-time passcode as well. As the middleman, Plaid is a passthrough for information that may include your account balances, transaction history, account type and routing or account number. Plaid uses encryption, and says it has a policy of not selling or renting customer data to other companies. However, I would not be doing my job if I didn’t note that in 2022 Plaid was forced to pay $58 million to consumers in a class action suit for collecting “more financial data than was needed.” As part of the settlement, Plaid was compelled to change some of its business practices. In a statement provided to Engadget, a Plaid spokesperson said the company continues to deny the allegations underpinning the lawsuit and that “the crux of the non-financial terms in the settlement are focused on us accelerating workstreams already underway related to giving people more transparency into Plaid’s role in connecting their accounts, and ensuring that our workstreams around data minimization remain on track.” Why did Mint shut down? When parent company Intuit announced in December 2023 that it would shut down Mint, it did not provide a reason why it made the decision to do so. It did say that Mint's millions of users would be funneled over to its other finance app, Credit Karma. \"Credit Karma is thrilled to invite all Minters to continue their financial journey on Credit Karma, where they will have access to Credit Karma’s suite of features, products, tools and services, including some of Mint’s most popular features,\" Mint wrote on its product blog. In our testing, we found that Credit Karma isn't an exact replacement for Mint — so if you're still looking for a Mint alternative, you have some decent options. What about Rocket Money? Rocket Money is another free financial app that tracks spending and supports things like balance alerts and account linking. If you pay for the premium tier, the service can also help you cancel unwanted subscriptions. We did not test it for this guide, but we'll consider it in future updates.This article originally appeared on Engadget at https://www.engadget.com/apps/best-budgeting-apps-120036303.html?src=rss",
          "content": "As a former Mint user, I had to find a new budgeting app not too long ago. Intuit, parent company of Mint, shut down the service in March 2024, and prompted users to transition to its other financial app, Credit Karma. However, after testing Credit Karma myself, I found it to be a poor Mint replacement — that meant I needed to branch out and look elsewhere for a trusted app to track all of my financial accounts, monitor my credit score, follow a monthly spending plan and set goals like building a rainy-day fund and paying down my mortgage faster.I tried out Mint's top competitors in the hopes that I'd be able to find a new budgeting app that could handle all of my financial needs. Hopefully my journey can help you find the best budgeting app for you and your money as well. Best budget apps of 2025 Other budgeting apps we tested PocketGuard PocketGuard used to be a solid free budget tracker, but the company has since limited its “free” version to just a free seven-day trial. Now, you’ll have to choose between two plans once the trial is over: a $13 monthly plan or a $75 annual plan. When I first tested it, I found it to be more restricted than NerdWallet, but still a decent option. The main overview screen shows you your net worth, total assets and debts; net income and total spending for the month; upcoming bills; a handy reminder of when your next paycheck lands; any debt payoff plan you have; and any goals. Like some other apps, including Quicken Simplifi, PocketGuard promotes an “after bills” approach, where you enter all of your recurring bills, and then PocketGuard shows you what’s left, and that’s what you’re supposed to be budgeting: your disposable income. Although PocketGuard’s UI is easy enough to understand, it lacks polish. The “accounts” tab is a little busy, and doesn’t show totals for categories like cash or investments. Seemingly small details like weirdly phrased or punctuated copy occasionally make the app feel janky. More than once, it prompted me to update the app when no updates were available. The web version, meanwhile, feels like the mobile app blown up to a larger format and doesn’t take advantage of the extra screen real estate. Ultimately, now that the free tier is gone, it just doesn’t present the same value proposition as it once did. How we test budgeting apps Before I dove in and started testing out budgeting apps, I had to do some research. To find a list of apps to try out, I consulted trusty ol’ Google (and even trustier Reddit); read reviews of popular apps on the App Store; and also asked friends and colleagues what budget tracking apps (or other budgeting methods) they might be using for money management. Some of the apps I found were free and these, of course, show loads of ads (excuse me, “offers”) to stay in business. But most of the available apps require paid subscriptions, with prices typically topping out around $100 a year, or $15 a month. (Spoiler: My top pick is cheaper than that.) All of the services I chose to test needed to do several things: import all of your account data into one place; offer budgeting tools; and track your spending, net worth and credit score. Except where noted, all of these apps are available for iOS, Android and on the web. Once I had my shortlist of six apps, I got to work setting them up. For the sake of thoroughly testing these apps, I made a point of adding every account to every budgeting app, no matter how small or immaterial the balance. What ensued was a veritable Groundhog Day of two-factor authentication. Just hours of entering passwords and one-time passcodes, for the same banks half a dozen times over. Hopefully, you only have to do this once. Budgeting app FAQs What is Plaid and how does it work? Each of the apps I tested uses the same underlying network, called Plaid, to pull in financial data, so it’s worth explaining what it is and how it works. Plaid was founded as a fintech startup in 2013 and is today the industry standard in connecting banks with third-party apps. Plaid works with over 12,000 financial institutions across the US, Canada and Europe. Additionally, more than 8,000 third-party apps and services rely on Plaid, the company claims. To be clear, you don’t need a dedicated Plaid app to use it; the technology is baked into a wide array of apps, including all of the budgeting apps listed in this guide. Once you find the “add an account” option in whichever one you’re using, you’ll see a menu of commonly used banks. There’s also a search field you can use to look yours up directly. Once you find yours, you’ll be prompted to enter your login credentials. If you have two-factor authentication set up, you’ll need to enter a one-time passcode as well. As the middleman, Plaid is a passthrough for information that may include your account balances, transaction history, account type and routing or account number. Plaid uses encryption, and says it has a policy of not selling or renting customer data to other companies. However, I would not be doing my job if I didn’t note that in 2022 Plaid was forced to pay $58 million to consumers in a class action suit for collecting “more financial data than was needed.” As part of the settlement, Plaid was compelled to change some of its business practices. In a statement provided to Engadget, a Plaid spokesperson said the company continues to deny the allegations underpinning the lawsuit and that “the crux of the non-financial terms in the settlement are focused on us accelerating workstreams already underway related to giving people more transparency into Plaid’s role in connecting their accounts, and ensuring that our workstreams around data minimization remain on track.” Why did Mint shut down? When parent company Intuit announced in December 2023 that it would shut down Mint, it did not provide a reason why it made the decision to do so. It did say that Mint's millions of users would be funneled over to its other finance app, Credit Karma. \"Credit Karma is thrilled to invite all Minters to continue their financial journey on Credit Karma, where they will have access to Credit Karma’s suite of features, products, tools and services, including some of Mint’s most popular features,\" Mint wrote on its product blog. In our testing, we found that Credit Karma isn't an exact replacement for Mint — so if you're still looking for a Mint alternative, you have some decent options. What about Rocket Money? Rocket Money is another free financial app that tracks spending and supports things like balance alerts and account linking. If you pay for the premium tier, the service can also help you cancel unwanted subscriptions. We did not test it for this guide, but we'll consider it in future updates.This article originally appeared on Engadget at https://www.engadget.com/apps/best-budgeting-apps-120036303.html?src=rss",
          "feed_position": 2
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/dreames-latest-robot-vacuum-concept-has-slightly-terrifying-legs-that-can-climb-full-size-stairs-210000399.html",
          "published_at": "Wed, 07 Jan 2026 01:07:34 +0000",
          "title": "Dreame's latest robot vacuum concept has slightly terrifying legs that can climb full-size stairs",
          "standfirst": "Robot vacuum companies are once again out in full force at CES 2026, giving their devices a new set of intriguing — and sometimes unsettling — capabilities. This year, Chinese appliance maker Dreame is showing off a vacuum prototype with giant legs that can climb up and down an entire flight of stairs.The concept, called the Cyber X, was previewed last year at IFA in Berlin. The vacuum sports a somewhat terrifying set of legs with rubber treads that allow it to autonomously navigate multi-story environments. While Dreame has previously shown off vacuums that can move up smaller steps, it says the Cyber X can climb stairs up to 25cm (9.8 inches) high and slopes up to 42 degrees. It can manage both straight and curved staircases, and can climb a flight of steps in 27 seconds, according to the company.We got a chance to see the Cyber X and its stair-climbing abilities at Dreame’s CES booth, and the device was able to deftly crawl up and down a flight of stairs. The Cyber X didn’t use its “legs” to walk up the steps, though. Instead, it used the treads horizontally, moving a bit like a miniature, cleaning tank.Interestingly, the actual vacuum is separate from the climbing apparatus. As you can see in the image below, the larger device with legs has an opening where the actual robot vacuum can dock inside and sit while the Cyber X climbs stairs. That likely means the Cyber X isn’t able to clean the stairs themselves, though it does cleverly solve the problem of transporting the vacuum throughout multi-story environments. In addition to its legs, the Cyber X’s vacuum also has a built-in water tank to support mopping abilities, and a laser-powered navigation system to help it maneuver up stairs and around other obstacles. It also has a braking system that allows it to stay stable on floors and stairs, even if the battery dies. Dreame's Cyber X.Karissa Bell for EngadgetFor now, Dreame says Cyber X is just a research prototype and hasn't indicated if it plans to make it, or a robo vac like it, more widely available at some point in the future. But Dreame has a history of showing off innovative features at CES ahead of an actual release. Last year, the company had a prototype vacuum with a mechanical arm at its CES booth. This year, it announced a new vacuum with very similar abilities. The company also announced the Dreame X60 Max Ultra, its latest flagship robot vacuum that can roll up smaller steps. The X60 Max Ultra, which costs $1,699, can move over stairs up to 8.8cm (about 3.4 inches), a small improvement over last year's X50, which could clear heights of 6cm (about 2.4 inches). That's not enough to manage a full-size stair, which is typically around 7 inches, but it should make the X60 flexible enough to navigate threshold steps and other small obstacles.Update, January 6, 2026, 5:07PM PT: This post was updated with new photos and video and to add additional information about the Cyber X after seeing a live demonstration at Dreame’s CES booth. This article originally appeared on Engadget at https://www.engadget.com/home/dreames-latest-robot-vacuum-concept-has-slightly-terrifying-legs-that-can-climb-full-size-stairs-210000399.html?src=rss",
          "content": "Robot vacuum companies are once again out in full force at CES 2026, giving their devices a new set of intriguing — and sometimes unsettling — capabilities. This year, Chinese appliance maker Dreame is showing off a vacuum prototype with giant legs that can climb up and down an entire flight of stairs.The concept, called the Cyber X, was previewed last year at IFA in Berlin. The vacuum sports a somewhat terrifying set of legs with rubber treads that allow it to autonomously navigate multi-story environments. While Dreame has previously shown off vacuums that can move up smaller steps, it says the Cyber X can climb stairs up to 25cm (9.8 inches) high and slopes up to 42 degrees. It can manage both straight and curved staircases, and can climb a flight of steps in 27 seconds, according to the company.We got a chance to see the Cyber X and its stair-climbing abilities at Dreame’s CES booth, and the device was able to deftly crawl up and down a flight of stairs. The Cyber X didn’t use its “legs” to walk up the steps, though. Instead, it used the treads horizontally, moving a bit like a miniature, cleaning tank.Interestingly, the actual vacuum is separate from the climbing apparatus. As you can see in the image below, the larger device with legs has an opening where the actual robot vacuum can dock inside and sit while the Cyber X climbs stairs. That likely means the Cyber X isn’t able to clean the stairs themselves, though it does cleverly solve the problem of transporting the vacuum throughout multi-story environments. In addition to its legs, the Cyber X’s vacuum also has a built-in water tank to support mopping abilities, and a laser-powered navigation system to help it maneuver up stairs and around other obstacles. It also has a braking system that allows it to stay stable on floors and stairs, even if the battery dies. Dreame's Cyber X.Karissa Bell for EngadgetFor now, Dreame says Cyber X is just a research prototype and hasn't indicated if it plans to make it, or a robo vac like it, more widely available at some point in the future. But Dreame has a history of showing off innovative features at CES ahead of an actual release. Last year, the company had a prototype vacuum with a mechanical arm at its CES booth. This year, it announced a new vacuum with very similar abilities. The company also announced the Dreame X60 Max Ultra, its latest flagship robot vacuum that can roll up smaller steps. The X60 Max Ultra, which costs $1,699, can move over stairs up to 8.8cm (about 3.4 inches), a small improvement over last year's X50, which could clear heights of 6cm (about 2.4 inches). That's not enough to manage a full-size stair, which is typically around 7 inches, but it should make the X60 flexible enough to navigate threshold steps and other small obstacles.Update, January 6, 2026, 5:07PM PT: This post was updated with new photos and video and to add additional information about the Cyber X after seeing a live demonstration at Dreame’s CES booth. This article originally appeared on Engadget at https://www.engadget.com/home/dreames-latest-robot-vacuum-concept-has-slightly-terrifying-legs-that-can-climb-full-size-stairs-210000399.html?src=rss",
          "feed_position": 4,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/dreame_cyber_x_and_base.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/lenovos-14th-gen-thinkpad-x1-carbon-comes-with-a-new-space-frame-design-010000262.html",
          "published_at": "Wed, 07 Jan 2026 01:00:00 +0000",
          "title": "Lenovo's 14th-gen ThinkPad X1 Carbon comes with a new Space Frame design",
          "standfirst": "Lenovo has unveiled a bunch of new laptops and concepts at CES 2026, including its latest ThinkPad X1 models. The ThinkPad X1 Carbon Gen 14 Aura Edition and ThinkPad X1 2-in-1 Gen 11 Aura Edition come with a new design the company has dubbed “Space Frame.” Lenovo calls Space Frame an “engineering breakthrough” and describes it as a design that restructures the interior of a laptop, so that components are placed on both sides of the motherboard. This structure improves the computer’s cooling and, hence, enables higher sustained performance. It comes with replaceable USB ports, battery, keyboard speakers and fans for easier repairs, and it also gives Lenovo enough room to equip laptops with a larger haptic touchpad.In addition to having the Space Frame design, both ThinkPad X1 Carbon and X1 2-in-1 Aura Editions are Microsoft Copilot+ PCs powered by the new Intel Core Ultra X7 Series 3 processors, which also debuted at CES. The processors ship with 12Xe graphic cores and integrated NPUs for AI acceleration. Both models also introduce a new 10MP camera with a 110-degree-wide field of view that features advanced distortion correction. As for the ThinkPad X1 2-in-1, it ships with a new magnetically docked pen that was designed to be ergonomic. The company has announced the ThinkPad X9 15p Aura Edition at the event, as well. It’s a follow-up to last year’s X9 with an all-aluminum chassis, making it an alternative to Apple’s MacBooks. This model comes with a 15.3-inch 2.8K OLED display and ThinkPad’s largest haptic touchpad, and it’s powered by the new Intel Core Ultra X9 Series 3 processors.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/lenovos-14th-gen-thinkpad-x1-carbon-comes-with-a-new-space-frame-design-010000262.html?src=rss",
          "content": "Lenovo has unveiled a bunch of new laptops and concepts at CES 2026, including its latest ThinkPad X1 models. The ThinkPad X1 Carbon Gen 14 Aura Edition and ThinkPad X1 2-in-1 Gen 11 Aura Edition come with a new design the company has dubbed “Space Frame.” Lenovo calls Space Frame an “engineering breakthrough” and describes it as a design that restructures the interior of a laptop, so that components are placed on both sides of the motherboard. This structure improves the computer’s cooling and, hence, enables higher sustained performance. It comes with replaceable USB ports, battery, keyboard speakers and fans for easier repairs, and it also gives Lenovo enough room to equip laptops with a larger haptic touchpad.In addition to having the Space Frame design, both ThinkPad X1 Carbon and X1 2-in-1 Aura Editions are Microsoft Copilot+ PCs powered by the new Intel Core Ultra X7 Series 3 processors, which also debuted at CES. The processors ship with 12Xe graphic cores and integrated NPUs for AI acceleration. Both models also introduce a new 10MP camera with a 110-degree-wide field of view that features advanced distortion correction. As for the ThinkPad X1 2-in-1, it ships with a new magnetically docked pen that was designed to be ergonomic. The company has announced the ThinkPad X9 15p Aura Edition at the event, as well. It’s a follow-up to last year’s X9 with an all-aluminum chassis, making it an alternative to Apple’s MacBooks. This model comes with a 15.3-inch 2.8K OLED display and ThinkPad’s largest haptic touchpad, and it’s powered by the new Intel Core Ultra X9 Series 3 processors.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/lenovos-14th-gen-thinkpad-x1-carbon-comes-with-a-new-space-frame-design-010000262.html?src=rss",
          "feed_position": 8
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/ces-2026-the-lenovo-thinkbook-plus-gen-7-auto-twist-wont-let-you-out-of-it-sight-010000913.html",
          "published_at": "Wed, 07 Jan 2026 01:00:00 +0000",
          "title": "CES 2026: The Lenovo ThinkBook Plus Gen 7 Auto Twist won't let you out of it sight",
          "standfirst": "A couple years ago Lenovo showed off a concept laptop stand that used cameras and AI to follow you around. But now at CES 2026, the company has taken that idea and turned it into a full-fledged system that it’s actually going to sell. Dubbed the ThinkBook Plus Gen 7 Auto Twist, instead of a laptop stand, Lenovo created a standalone notebook with the same functionality, plus a little more. The impressive thing is that despite having a built-in motor that lets its display follow you around, the laptop’s design doesn't look all that outlandish. And after playing around with it a bit, I discovered a handful of other tricks it can do. Instead of using your fingers to open the lid like a luddite, all you have to do is knock a couple times and then the laptop’s display will pop up by itself. From there, you’re greeted with a surprisingly good-looking 14-inch 2.8K OLED display and a traditional keyboard that won’t upset longtime ThinkBook or ThinkPad aficionados. You also get solid specs including support for Intel’s new Core Ultra Series 3 processors, up to 32GB of RAM, 2TB of storage and a decently large 75Whr battery. The laptop also sports a strong selection of ports including two USB-C with Thunderbolt 4, two USB-A 3.2 Gen 2, a full-size HDMI jack and Wi-Fi 7. And all of this comes in a chassis that weighs 3.1 pounds, which is very reasonable for a 14-inch machine. As for its auto-twisting abilities, the main use case is during presentation and video calls, where the laptop can use its motor, 10-MP webcam and AI to track your face as you move around so you stay neatly in frame. Compared to the concept I saw before, the laptop pivots and rotates its display more smoothly (though it’s still a bit jerky) and if you want, you can even make it dance to music. Alternatively, the laptop can analyze your posture to position its screen in the optimal position to prevent slouching or automatically transform between laptop, tablet and presentation modes. While this is a really minor inclusion, my favorite thing about the Auto Twist is that when you turn the system off, the laptop will automatically close its own lid, as if it was tucking itself into bed. The other goal of this laptop is that Lenovo is touting it as a vertical AI solution for small businesses. Naturally this means that the system supports Microsoft’s Copilot+ features, though we also saw a demo of Lenovo’s own AI companion. Not only can you talk to it, ask it questions or use it to translate other languages like a regular digital assistant, the company created a friendly face that reacts to your queries and comments. The one odd inclusion, which probably won’t make it to retail units, was an AI feature designed to help you understand hidden meanings or subtext in other languages. However, in my experience (as seen in the video above), this turned into a weird excuse to get negged by AI or at the very least make yourself more paranoid about what your friends or coworkers are saying about you. My favorite thing about the Auto Twist is that if you shut it down, it will automatically close its own lid. Sam Rutherford for EngadgetIn the end, I’m still not sure I need a laptop with a display and a camera that can follow me around during video calls. But if you have happy feet during work meetings or like to express yourself through movement, the ThinkBook Plus Gen 7 Auto Twist might be the business notebook you need. Plus, considering it features relatively novel tech, its starting price of $1,649 is surprisingly approachable. You’ll just have to wait until it goes on sale sometime in June.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/ces-2026-the-lenovo-thinkbook-plus-gen-7-auto-twist-wont-let-you-out-of-it-sight-010000913.html?src=rss",
          "content": "A couple years ago Lenovo showed off a concept laptop stand that used cameras and AI to follow you around. But now at CES 2026, the company has taken that idea and turned it into a full-fledged system that it’s actually going to sell. Dubbed the ThinkBook Plus Gen 7 Auto Twist, instead of a laptop stand, Lenovo created a standalone notebook with the same functionality, plus a little more. The impressive thing is that despite having a built-in motor that lets its display follow you around, the laptop’s design doesn't look all that outlandish. And after playing around with it a bit, I discovered a handful of other tricks it can do. Instead of using your fingers to open the lid like a luddite, all you have to do is knock a couple times and then the laptop’s display will pop up by itself. From there, you’re greeted with a surprisingly good-looking 14-inch 2.8K OLED display and a traditional keyboard that won’t upset longtime ThinkBook or ThinkPad aficionados. You also get solid specs including support for Intel’s new Core Ultra Series 3 processors, up to 32GB of RAM, 2TB of storage and a decently large 75Whr battery. The laptop also sports a strong selection of ports including two USB-C with Thunderbolt 4, two USB-A 3.2 Gen 2, a full-size HDMI jack and Wi-Fi 7. And all of this comes in a chassis that weighs 3.1 pounds, which is very reasonable for a 14-inch machine. As for its auto-twisting abilities, the main use case is during presentation and video calls, where the laptop can use its motor, 10-MP webcam and AI to track your face as you move around so you stay neatly in frame. Compared to the concept I saw before, the laptop pivots and rotates its display more smoothly (though it’s still a bit jerky) and if you want, you can even make it dance to music. Alternatively, the laptop can analyze your posture to position its screen in the optimal position to prevent slouching or automatically transform between laptop, tablet and presentation modes. While this is a really minor inclusion, my favorite thing about the Auto Twist is that when you turn the system off, the laptop will automatically close its own lid, as if it was tucking itself into bed. The other goal of this laptop is that Lenovo is touting it as a vertical AI solution for small businesses. Naturally this means that the system supports Microsoft’s Copilot+ features, though we also saw a demo of Lenovo’s own AI companion. Not only can you talk to it, ask it questions or use it to translate other languages like a regular digital assistant, the company created a friendly face that reacts to your queries and comments. The one odd inclusion, which probably won’t make it to retail units, was an AI feature designed to help you understand hidden meanings or subtext in other languages. However, in my experience (as seen in the video above), this turned into a weird excuse to get negged by AI or at the very least make yourself more paranoid about what your friends or coworkers are saying about you. My favorite thing about the Auto Twist is that if you shut it down, it will automatically close its own lid. Sam Rutherford for EngadgetIn the end, I’m still not sure I need a laptop with a display and a camera that can follow me around during video calls. But if you have happy feet during work meetings or like to express yourself through movement, the ThinkBook Plus Gen 7 Auto Twist might be the business notebook you need. Plus, considering it features relatively novel tech, its starting price of $1,649 is surprisingly approachable. You’ll just have to wait until it goes on sale sometime in June.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/ces-2026-the-lenovo-thinkbook-plus-gen-7-auto-twist-wont-let-you-out-of-it-sight-010000913.html?src=rss",
          "feed_position": 10,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/auto-twist-lid-twisted.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/lenovo-goes-sci-fi-with-its-wild-xd-rollable-concept-at-ces-2026-010000817.html",
          "published_at": "Wed, 07 Jan 2026 01:00:00 +0000",
          "title": "Lenovo goes sci-fi with its wild XD Rollable Concept at CES 2026",
          "standfirst": "Lenovo has experimented more with laptops featuring rollable displays than pretty much any other PC maker and at CES 2026 it’s keeping that trend going with the XD Rollable Concept.Equipped with a 180-degree Gorilla Glass Victus 2 cover, the XD Rollable concept features a very futuristic design. However, underneath, it has the same basic engineering as last year’s ThinkBook Plus Gen 6. That means with the touch of a button, its 13.3-inch flexible OLED display can expand to 16 inches, which gives you around 50 percent extra screen space in just a few seconds. The main difference with Lenovo’s latest concept is that instead of hiding the unused section of its rollable display underneath its keyboard, the XD’s panel wraps up and over its lid to create a “world-facing” display around back. This allows people sitting on the other side of the laptop to see content, with the laptop capable of mirroring elements from its main display or using that space as a small secondary monitor. Now I will admit that after seeing the XD Rollable in person, its design does feel a bit gimmicky. Even though Lenovo’s space-themed animation that appears when the laptop’s display extends is pretty slick, I’m not sure how helpful that world-facing display really is. In normal use, you can’t even see it because it’s on the other side of the lid and while I suppose you could utilize that area for meetings or presentations, I think most people would be much better off simply connecting the notebook to a dedicated secondary monitor or projector. That said, I do like that contrary to the ThinkBook Plus Gen 6, by exposing the unused part of the XD Rollable’s display when it’s not extended, you get a little bit of extra value out of it. At the very least, it beats stashing the rest of the panel underneath the keyboard where it won’t be seen at all. On top of that, I like the look of having no bezel along the top of the display and you can even use touch controls on the edge of the display to control widgets or expand its flexible screen. Interestingly, the coolest part about the XD Rollable might not even be its screen, but the motors and rails that Lenovo uses to extend its display, which are easily seen beneath its glass design.Meanwhile, the rest of the XD Rollable is very down to earth with it featuring a comfy keyboard and a decent-sized touchpad. The main downsides are that its glass lid makes the concept a bit heavier than a more traditional 13-inch notebook and you only get two USB-C ports. But considering that Lenovo isn’t planning to put this thing into production, that lack of connectivity or info regarding its specs shouldn’t come as a big surprise.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/lenovo-goes-sci-fi-with-its-wild-xd-rollable-concept-at-ces-2026-010000817.html?src=rss",
          "content": "Lenovo has experimented more with laptops featuring rollable displays than pretty much any other PC maker and at CES 2026 it’s keeping that trend going with the XD Rollable Concept.Equipped with a 180-degree Gorilla Glass Victus 2 cover, the XD Rollable concept features a very futuristic design. However, underneath, it has the same basic engineering as last year’s ThinkBook Plus Gen 6. That means with the touch of a button, its 13.3-inch flexible OLED display can expand to 16 inches, which gives you around 50 percent extra screen space in just a few seconds. The main difference with Lenovo’s latest concept is that instead of hiding the unused section of its rollable display underneath its keyboard, the XD’s panel wraps up and over its lid to create a “world-facing” display around back. This allows people sitting on the other side of the laptop to see content, with the laptop capable of mirroring elements from its main display or using that space as a small secondary monitor. Now I will admit that after seeing the XD Rollable in person, its design does feel a bit gimmicky. Even though Lenovo’s space-themed animation that appears when the laptop’s display extends is pretty slick, I’m not sure how helpful that world-facing display really is. In normal use, you can’t even see it because it’s on the other side of the lid and while I suppose you could utilize that area for meetings or presentations, I think most people would be much better off simply connecting the notebook to a dedicated secondary monitor or projector. That said, I do like that contrary to the ThinkBook Plus Gen 6, by exposing the unused part of the XD Rollable’s display when it’s not extended, you get a little bit of extra value out of it. At the very least, it beats stashing the rest of the panel underneath the keyboard where it won’t be seen at all. On top of that, I like the look of having no bezel along the top of the display and you can even use touch controls on the edge of the display to control widgets or expand its flexible screen. Interestingly, the coolest part about the XD Rollable might not even be its screen, but the motors and rails that Lenovo uses to extend its display, which are easily seen beneath its glass design.Meanwhile, the rest of the XD Rollable is very down to earth with it featuring a comfy keyboard and a decent-sized touchpad. The main downsides are that its glass lid makes the concept a bit heavier than a more traditional 13-inch notebook and you only get two USB-C ports. But considering that Lenovo isn’t planning to put this thing into production, that lack of connectivity or info regarding its specs shouldn’t come as a big surprise.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/lenovo-goes-sci-fi-with-its-wild-xd-rollable-concept-at-ces-2026-010000817.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/ces-2026-the-lenovo-legion-pro-rollable-concept-goes-big-wide-at-the-touch-of-a-button-010000333.html",
          "published_at": "Wed, 07 Jan 2026 01:00:00 +0000",
          "title": "CES 2026: The Lenovo Legion Pro Rollable concept goes big wide at the touch of a button",
          "standfirst": "Lenovo might have the most concept devices of any company at CES 2026, but the wildest and most interesting one is almost certainly the Legion Pro Rollable which features a 16-inch flexible display that can expand to not one but two different sizes. To make the Legion Pro Rollable, Lenovo started out with a standard Legion Pro 7i and kept the bottom half including all of its ports and support for an RTX 5090 GPU. But then the company went a bit crazy: Instead of replacing the notebook’s original 16-inch OLED screen with a rollable variant that extends upwards like the Thinkbook Plus Gen 6 from 2025, Lenovo opted for one that expands outwards to either 21.5 inches or 23.8 inches This means instead of being restricted to a standard 16:10 aspect ratio, you also have the choice of 21:9 or an ultra-wide 24:9 with just the touch of a button. Or more like two buttons because to widen or shrink its display, you need to press FN plus one of its arrow keys.The Lenovo Legion Pro Rollable concept goes wide and wiiiider. #CES2026 pic.twitter.com/R5fJ0vU3NX— Sam Rutherford (@samrutherford) January 7, 2026 Admittedly that feels a bit clunky considering some of Lenovo’s other laptops with expandable displays have a dedicated button. But this is a concept device after all, which was immediately obvious when I got a chance to see this up close. The bottom of the laptop feels solid, as you’d probably expect because not much has changed there. However, the top of the laptop didn’t feel super sturdy, probably due to the display’s hinge not being able to fully support a heavier lid and the notebook’s bulkier rollable display. I also noticed that there were some faint lines left by the internal motors that allow the rollable display to do its thing and a bit of waviness from the panel due to it not being super taut. That said, from the side, I was impressed that even for a prototype, Lenovo did a halfway decent job of eliminating any huge panel gaps or empty spaces where the lid expands. The biggest bummer is that even though Lenovo had a handful of demo units on on site, there weren’t any games installed so I wasn’t able see the Legion Pro Rollable’s tech function in full glory. But if we’re being honest, none of that really matters on a gadget that’s meant to be a showcase and testbed for next-gen tech. The idea of a gaming laptop with a screen that can go from normal to ultra-wide at the touch of a button (or buttons) is super cool, especially if you play titles like flight sims, racing games or big open-world adventures that can take advantage of an extra wide screen. And out of all of the concepts I’ve seen at CES 2026, this one is at the top of the list of stuff that I hope eventually gets turned into a proper retail product. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/ces-2026-the-lenovo-legion-pro-rollable-concept-goes-big-wide-at-the-touch-of-a-button-010000333.html?src=rss",
          "content": "Lenovo might have the most concept devices of any company at CES 2026, but the wildest and most interesting one is almost certainly the Legion Pro Rollable which features a 16-inch flexible display that can expand to not one but two different sizes. To make the Legion Pro Rollable, Lenovo started out with a standard Legion Pro 7i and kept the bottom half including all of its ports and support for an RTX 5090 GPU. But then the company went a bit crazy: Instead of replacing the notebook’s original 16-inch OLED screen with a rollable variant that extends upwards like the Thinkbook Plus Gen 6 from 2025, Lenovo opted for one that expands outwards to either 21.5 inches or 23.8 inches This means instead of being restricted to a standard 16:10 aspect ratio, you also have the choice of 21:9 or an ultra-wide 24:9 with just the touch of a button. Or more like two buttons because to widen or shrink its display, you need to press FN plus one of its arrow keys.The Lenovo Legion Pro Rollable concept goes wide and wiiiider. #CES2026 pic.twitter.com/R5fJ0vU3NX— Sam Rutherford (@samrutherford) January 7, 2026 Admittedly that feels a bit clunky considering some of Lenovo’s other laptops with expandable displays have a dedicated button. But this is a concept device after all, which was immediately obvious when I got a chance to see this up close. The bottom of the laptop feels solid, as you’d probably expect because not much has changed there. However, the top of the laptop didn’t feel super sturdy, probably due to the display’s hinge not being able to fully support a heavier lid and the notebook’s bulkier rollable display. I also noticed that there were some faint lines left by the internal motors that allow the rollable display to do its thing and a bit of waviness from the panel due to it not being super taut. That said, from the side, I was impressed that even for a prototype, Lenovo did a halfway decent job of eliminating any huge panel gaps or empty spaces where the lid expands. The biggest bummer is that even though Lenovo had a handful of demo units on on site, there weren’t any games installed so I wasn’t able see the Legion Pro Rollable’s tech function in full glory. But if we’re being honest, none of that really matters on a gadget that’s meant to be a showcase and testbed for next-gen tech. The idea of a gaming laptop with a screen that can go from normal to ultra-wide at the touch of a button (or buttons) is super cool, especially if you play titles like flight sims, racing games or big open-world adventures that can take advantage of an extra wide screen. And out of all of the concepts I’ve seen at CES 2026, this one is at the top of the list of stuff that I hope eventually gets turned into a proper retail product. This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/ces-2026-the-lenovo-legion-pro-rollable-concept-goes-big-wide-at-the-touch-of-a-button-010000333.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/dreames-robot-vacuum-with-an-arm-is-back-at-ces-2026-and-it-can-do-more-than-pick-up-shoes-210000020.html",
          "published_at": "Wed, 07 Jan 2026 00:18:40 +0000",
          "title": "Dreame's robot vacuum with an arm is back at CES 2026 and it can do more than pick up shoes",
          "standfirst": "Last year at CES, Dreame showed off a robot vacuum prototype with a mechanical arm. But while we were able to see the arm extend and retract, we didn’t see the device, which was described as a prototype at the time, actually grab anything, which was a bit disappointing.This year, though, the company has made its arm-enabled vacuum a reality with the Cyber 10 Ultra. Dreame previewed it recently at IFA in Berlin, but has now confirmed it will be on sale later this year. The vacuum has an extendable arm that looks pretty similar to the prototype version we saw last year. It extends from the top of the vacuum and has a claw-like device at the end for scooping up objects. According to Dreame, it can pick up items that weigh up to 500 grams (about 1 pound) so it should be able to grab a wider variety of stuff than the Roborock vac we saw last year, which had a 300-gram weight limit for its arm. The arm can also do more than pick up stuff from the floor. It supports its own cleaning accessories, and can grab vacuum nozzles and brush attachments from its base station. This allows the arm to act as an extension of the vacuum itself so it can be used similarly to how you might use hose attachments to reach hard-to-get areas with a traditional vacuum. We were able to see a brief demo of the Cyber 10 arm in action on the CES show floor. It was able to pick up balls and place them in a basket. Unfortunately, we didn’t get to see it lift any heavier object or grab its cleaning attachments, but we were able to get a good look at the base station and the small cubbies where they will be stored.The base station that holds the attachments for the vacuum's arm.Karissa Bell for EngadgetAnd, like Dreame's other robot vacuums, the Cyber 10 Ultra also has mopping abilities and can climb up small steps up to 6cm (about 2.4 inches). That's not quite as impressive as the tank-like stair-climbing Cyber X prototype it also brought to CES, but should help the Cyber 10 reach a few extra places in the house. The company hasn't announced an exact release date, but says it's targeting August of this year and currently expects the Cyber 10 Ultra to cost around €1799 (about $2,100).Update, January 6, 2026, 4:17PM PT: This story was updated with new photos, a video and information about the Cyber 10 Ultra.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/dreames-robot-vacuum-with-an-arm-is-back-at-ces-2026-and-it-can-do-more-than-pick-up-shoes-210000020.html?src=rss",
          "content": "Last year at CES, Dreame showed off a robot vacuum prototype with a mechanical arm. But while we were able to see the arm extend and retract, we didn’t see the device, which was described as a prototype at the time, actually grab anything, which was a bit disappointing.This year, though, the company has made its arm-enabled vacuum a reality with the Cyber 10 Ultra. Dreame previewed it recently at IFA in Berlin, but has now confirmed it will be on sale later this year. The vacuum has an extendable arm that looks pretty similar to the prototype version we saw last year. It extends from the top of the vacuum and has a claw-like device at the end for scooping up objects. According to Dreame, it can pick up items that weigh up to 500 grams (about 1 pound) so it should be able to grab a wider variety of stuff than the Roborock vac we saw last year, which had a 300-gram weight limit for its arm. The arm can also do more than pick up stuff from the floor. It supports its own cleaning accessories, and can grab vacuum nozzles and brush attachments from its base station. This allows the arm to act as an extension of the vacuum itself so it can be used similarly to how you might use hose attachments to reach hard-to-get areas with a traditional vacuum. We were able to see a brief demo of the Cyber 10 arm in action on the CES show floor. It was able to pick up balls and place them in a basket. Unfortunately, we didn’t get to see it lift any heavier object or grab its cleaning attachments, but we were able to get a good look at the base station and the small cubbies where they will be stored.The base station that holds the attachments for the vacuum's arm.Karissa Bell for EngadgetAnd, like Dreame's other robot vacuums, the Cyber 10 Ultra also has mopping abilities and can climb up small steps up to 6cm (about 2.4 inches). That's not quite as impressive as the tank-like stair-climbing Cyber X prototype it also brought to CES, but should help the Cyber 10 reach a few extra places in the house. The company hasn't announced an exact release date, but says it's targeting August of this year and currently expects the Cyber 10 Ultra to cost around €1799 (about $2,100).Update, January 6, 2026, 4:17PM PT: This story was updated with new photos, a video and information about the Cyber 10 Ultra.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/dreames-robot-vacuum-with-an-arm-is-back-at-ces-2026-and-it-can-do-more-than-pick-up-shoes-210000020.html?src=rss",
          "feed_position": 15,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/dreame_base_station.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/metas-emg-wristband-is-moving-beyond-its-ar-glasses-120000503.html",
          "published_at": "Tue, 06 Jan 2026 23:40:58 +0000",
          "title": "Meta's EMG wristband is moving beyond its AR glasses",
          "standfirst": "Meta has been experimenting with EMG technology for years. In 2025, the company commercialized it for the first time in its Meta Ray-Ban Display glasses, which users control via a dedicated neural band that is able to interpret subtle muscle movements in the wrist.Now, at CES 2026, the company is offering its first look at how its neural band could be used to control devices outside of its smart glasses lineup. Meta has teamed up with Garmin, as well as a handful of research partners, to explore some intriguing use cases for its wrist-based controller.The social media company has previously worked with Garmin on fitness integrations for its glasses. But at CES, the companies were showing off a very early demo of how Meta's neural band inside of a car to control the built-in infotainment system. Some videos of Meta’s neural band controlling the screens in Garmin’s Unified Cabin at CES pic.twitter.com/2LcKEp1IRN— Karissa Bell (@karissabe) January 6, 2026 The experience is part of Garmin's \"Unified Cabin\" concept, which explores a bunch of AI-centric in-car experiences. The demo I tried was fairly limited: while wearing a neural band, I was able to navigate two apps on a touchscreen display in Garmin's cockpit setup. In one, I used pinch and swipe gestures to manipulate an onscreen model of a car, much like how I would use the band to zoom in and out of an image while wearing the display glasses. The second demo, somewhat bizarrely, was a game of 2048. I used the same swipe gestures to move the tiles around. Neither of those are the kinds of experiences you immediately think of when you imagine \"in-car entertainment,\" but Garmin, which works with a number of major car brands on infotainment systems, seems to be thinking about some more practical use cases too. The company told me that it will explore using the neural band to control vehicle functions like rolling down windows or unlocking doors. Elsewhere, Meta also announced a research collaboration with the University of Utah that will explore how its EMG tech can be used to help people who have ALS, muscular dystrophy and other conditions that affect the use of their hands.Researchers will work with Meta to test gestures that could enable people to control smart speakers, blinds, thermostats, locks and other household devices using the neural band. \"Meta Neural Band is sensitive enough to detect subtle muscle activity in the wrist — even for people who can’t move their hands,\" the company explains in a blog post. Researchers will also look at using the band for mobility use cases, like the University of Utah's TetraSki program, which currently uses a joystick or mouth-based controller to help participants ski. Update, Tuesday, January 6, 2026, 3:40PM PT: Added a video from garmin’s demo.This article originally appeared on Engadget at https://www.engadget.com/wearables/metas-emg-wristband-is-moving-beyond-its-ar-glasses-120000503.html?src=rss",
          "content": "Meta has been experimenting with EMG technology for years. In 2025, the company commercialized it for the first time in its Meta Ray-Ban Display glasses, which users control via a dedicated neural band that is able to interpret subtle muscle movements in the wrist.Now, at CES 2026, the company is offering its first look at how its neural band could be used to control devices outside of its smart glasses lineup. Meta has teamed up with Garmin, as well as a handful of research partners, to explore some intriguing use cases for its wrist-based controller.The social media company has previously worked with Garmin on fitness integrations for its glasses. But at CES, the companies were showing off a very early demo of how Meta's neural band inside of a car to control the built-in infotainment system. Some videos of Meta’s neural band controlling the screens in Garmin’s Unified Cabin at CES pic.twitter.com/2LcKEp1IRN— Karissa Bell (@karissabe) January 6, 2026 The experience is part of Garmin's \"Unified Cabin\" concept, which explores a bunch of AI-centric in-car experiences. The demo I tried was fairly limited: while wearing a neural band, I was able to navigate two apps on a touchscreen display in Garmin's cockpit setup. In one, I used pinch and swipe gestures to manipulate an onscreen model of a car, much like how I would use the band to zoom in and out of an image while wearing the display glasses. The second demo, somewhat bizarrely, was a game of 2048. I used the same swipe gestures to move the tiles around. Neither of those are the kinds of experiences you immediately think of when you imagine \"in-car entertainment,\" but Garmin, which works with a number of major car brands on infotainment systems, seems to be thinking about some more practical use cases too. The company told me that it will explore using the neural band to control vehicle functions like rolling down windows or unlocking doors. Elsewhere, Meta also announced a research collaboration with the University of Utah that will explore how its EMG tech can be used to help people who have ALS, muscular dystrophy and other conditions that affect the use of their hands.Researchers will work with Meta to test gestures that could enable people to control smart speakers, blinds, thermostats, locks and other household devices using the neural band. \"Meta Neural Band is sensitive enough to detect subtle muscle activity in the wrist — even for people who can’t move their hands,\" the company explains in a blog post. Researchers will also look at using the band for mobility use cases, like the University of Utah's TetraSki program, which currently uses a joystick or mouth-based controller to help participants ski. Update, Tuesday, January 6, 2026, 3:40PM PT: Added a video from garmin’s demo.This article originally appeared on Engadget at https://www.engadget.com/wearables/metas-emg-wristband-is-moving-beyond-its-ar-glasses-120000503.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/how-ralph-wiggum-went-from-the-simpsons-to-the-biggest-name-in-ai-right-now",
          "published_at": "Tue, 06 Jan 2026 20:11:00 GMT",
          "title": "How Ralph Wiggum went from 'The Simpsons' to the biggest name in AI right now",
          "standfirst": "In the fast-moving world of AI development, it is rare for a tool to be described as both \"a meme\" and AGI, artificial generalized intelligence, the \"holy grail\" of a model or system that can reliably outperform humans on economically valuable work. Yet, that is exactly where the Ralph Wiggum plugin for Claude Code now sits. Named after the infamously high-pitched, hapless yet persistent character on The Simpsons, this newish tool (released in summer 2025) — and the philosophy behind it — has set the developer community on X (formerly Twitter) into a tizzy of excitement over the last few weeks.For power users of Anthropic’s hit agentic, quasi-autonomous coding platform Claude Code, Wiggum represents a shift from \"chatting\" with AI to managing autonomous \"night shifts.\" It is a crude but effective step toward agentic coding, transforming the AI from a pair programmer into a relentless worker that doesn’t stop until the job is done.Origin Story: A Tale of Two RalphsTo understand the \"Ralph\" tool is to understand a new approach toward improving autonomous AI coding performance — one that relies on brute force, failure, and repetition as much as it does on raw intelligence and reasoning. Because Ralph Wiggum is not merely a Simpsons character anymore; it is a methodology born on a goat farm and refined in a San Francisco research lab, a divergence best documented in the conversations between its creator and the broader developer community.The story begins in roughly May 2025 with Geoffrey Huntley, a longtime open source software developer who pivoted to raising goats in rural Australia. Huntley was frustrated by a fundamental limitation in the agentic coding workflow: the \"human-in-the-loop\" bottleneck. He realized that while models were capable, they were hamstrung by the user’s need to manually review and re-prompt every error. Huntley’s solution was elegantly brutish. He wrote a 5-line Bash script that he jokingly named after Ralph Wiggum, the dim-witted but relentlessly optimistic and undeterred character from The Simpsons.As Huntley explained in his initial release blog post \"Ralph Wiggum as a &#x27;software engineer,&#x27;\" the idea relied on Context Engineering.By piping the model’s entire output—failures, stack traces, and hallucinations—back into its own input stream for the next iteration, Huntley created a \"contextual pressure cooker.\"This philosophy was further dissected in a recent conversation with Dexter Horthy, co-founder and CEO of the enterprise AI engineering firm HumanLayer, posted on YouTube.Horthy and Huntley argue that the power of the original Ralph wasn&#x27;t just in the looping, but in its \"naive persistence\" — the unsanitized feedback, in which the LLM isn&#x27;t protected from its own mess; it is forced to confront it. It embodies the philosophy that if you press the model hard enough against its own failures without a safety net, it will eventually \"dream\" a correct solution just to escape the loop.By late 2025, Anthropic’s Developer Relations team, led by Boris Cherny, formalized the hack into the official ralph-wiggum plugin. However, as noted by critics in the Horthy/Huntley discussion, the official release marked a shift in philosophy—a \"sterilization\" of the original chaotic concept.While Huntley’s script was about brute force, the official Anthropic plugin was designed around the principle that \"Failures Are Data.\" In the official documentation, the distinction is clear. The Anthropic implementation utilizes a specialized \"Stop Hook\"—a mechanism that intercepts the AI&#x27;s attempt to exit the CLI.Intercept the Exit: When Claude thinks it is done, the plugin pauses execution.Verify Promise: It checks for a specific \"Completion Promise\" (e.g., \"All tests passed\").Feedback Injection: If the promise isn&#x27;t met, the failure is formatted as a structured data object.The \"Tale of Two Ralphs\" offers a critical choice for modern power users:The \"Huntley Ralph\" (Bash Script/Community Forks): Best for chaotic, creative exploration where you want the AI to solve problems through sheer, unbridled persistence.The \"Official Ralph\" (Anthropic Plugin): The standard for enterprise workflows, strictly bound by token limits and safety hooks, designed to fix broken builds reliably without the risk of an infinite hallucination loop.In short: Huntley proved the loop was possible; Anthropic proved it could be safe.What It Offers: The Night Shift for CodersThe documentation is clear on where Ralph shines: new projects and tasks with automatic verification (like tests or linters). But for the \"boring stuff,\" the efficiency gains are becoming the stuff of legend. According to the official plugin documentation on GitHub, the technique has already logged some eye-watering wins. In one case, a developer reportedly completed a $50,000 contract for just $297 in API costs—essentially arbitraging the difference between an expensive human lawyer/coder and a relentless AI loop.The repository also highlights a Y Combinator hackathon stress test where the tool \"successfully generated 6 repositories overnight,\" effectively allowing a single developer to output a small team&#x27;s worth of boilerplate while asleep. Meanwhile, on X, community members like ynkzlk have shared screenshots of Ralph handling the kind of maintenance work engineers dread, such as a 14-hour autonomous session that upgraded a stale codebase from React v16 to v19 entirely without human input.To make this work safely, power users rely on a specific architecture. Matt Pocock, a prominent developer and educator who posted a recent YouTube video overview of why Ralph Wiggum is so powerful.As he states: \"One of the dreams of coding agents is that you can wake up in the morning to working code, that your coding agent has worked through your backlog and has just spit out a whole bunch of code for you to review and it works.\" In Pocock&#x27;s view, Wiggum (the plugin) is about as close as you can come to this dream. It&#x27;s \"a vast improvement over any other AI coding orchestration setup I&#x27;ve ever tried and allows you to actually ship working stuff with longrunning coding agents,\" he states.He advises using strong feedback loops like TypeScript and unit tests. If the code compiles and passes tests, the AI emits the completion promise; if not, the Stop Hook forces it to try again.The Core Innovation: The Stop HookAt its heart, the Ralph Wiggum technique is deceptively simple. As Huntley put it: \"Ralph is a Bash loop.\"However, the official plugin implements this in a clever, technically distinct way. Instead of just running a script on the outside, the plugin installs a \"Stop Hook\" inside your Claude session.You give Claude a task and a \"completion promise\" (e.g., <promise>COMPLETE</promise>).Claude works on the task and tries to exit when it thinks it&#x27;s done.The hook blocks the exit if the promise isn&#x27;t found, feeding the same prompt back into the system.This forces a \"self-referential feedback loop\" where Claude sees its previous work, reads the error logs or git history, and tries again.Pocock describes this as a shift from \"Waterfall\" planning to true \"Agile\" for AI. Instead of forcing the AI to follow a brittle, multi-step plan, Ralph allows the agent to simply \"grab a ticket off the board,\" finish it, and look for the next one.Community Reactions: &#x27;The Closest Thing to AGI&#x27;The reception among the AI builder and developer community on social media has been effusive. Dennison Bertram, CEO and founder of custom cryptocurrency and blockchain token creation platform Tally, posted on X on December 15: \"No joke, this might be the closest thing I&#x27;ve seen to AGI: This prompt is an absolute beast with Claude.\"Arvid Kahl, founder and CEO of automated podcast business intelligence extraction and brand detection tool Podscan, persuasively covered the benefits of Ralph&#x27;s persistent approach in his own X post yesterday:And as Chicago entrepreneur Hunter Hammonds put it: Opus 4.5 + Ralph Wiggum with XcodeBuild and playwright is going to mint millionaires. Mark my words. You’re not readyIn a meta-twist characteristic of the 2025 AI scene, the \"Ralph\" phenomenon didn&#x27;t just generate code—it generated a market.And earlier this week, someone — not Huntley, he says — launched a new $RALPH cryptocurrency token on the Solana blockchain to capitalize on the hype surrounding the plugin. The Catch: Costs and SafetyThe excitement comes with significant caveats. Software firm Better Stack warned users on X about the economic reality of infinite loops:\"The Ralph Wiggum plugin runs Claude Code in autonomous loops... But will those nonstop API calls break your token budget?\"Because the loop runs until success, the documentation advises using \"Escape Hatches.\" Users should always set a --max-iterations flag (e.g., 20 or 50) to prevent the AI from burning through cash on an impossible task.There is also a security dimension. To work effectively, Ralph often requires the --dangerously-skip-permissions flag, granting the AI full control over the terminal. Security experts strictly advise running Ralph sessions in sandboxed environments (like disposable cloud VMs) to prevent the AI from accidentally deleting local files.AvailabilityThe Ralph Wiggum technique is available now for Claude Code users:Official Plugin: Accessible inside Claude Code via /plugin ralph.Original Method: The \"OG\" bash scripts and community forks are available on GitHub.As 2026 begins, Ralph Wiggum has evolved from a Simpsons joke into a defining archetype for software development: Iteration > Perfection.",
          "content": "In the fast-moving world of AI development, it is rare for a tool to be described as both \"a meme\" and AGI, artificial generalized intelligence, the \"holy grail\" of a model or system that can reliably outperform humans on economically valuable work. Yet, that is exactly where the Ralph Wiggum plugin for Claude Code now sits. Named after the infamously high-pitched, hapless yet persistent character on The Simpsons, this newish tool (released in summer 2025) — and the philosophy behind it — has set the developer community on X (formerly Twitter) into a tizzy of excitement over the last few weeks.For power users of Anthropic’s hit agentic, quasi-autonomous coding platform Claude Code, Wiggum represents a shift from \"chatting\" with AI to managing autonomous \"night shifts.\" It is a crude but effective step toward agentic coding, transforming the AI from a pair programmer into a relentless worker that doesn’t stop until the job is done.Origin Story: A Tale of Two RalphsTo understand the \"Ralph\" tool is to understand a new approach toward improving autonomous AI coding performance — one that relies on brute force, failure, and repetition as much as it does on raw intelligence and reasoning. Because Ralph Wiggum is not merely a Simpsons character anymore; it is a methodology born on a goat farm and refined in a San Francisco research lab, a divergence best documented in the conversations between its creator and the broader developer community.The story begins in roughly May 2025 with Geoffrey Huntley, a longtime open source software developer who pivoted to raising goats in rural Australia. Huntley was frustrated by a fundamental limitation in the agentic coding workflow: the \"human-in-the-loop\" bottleneck. He realized that while models were capable, they were hamstrung by the user’s need to manually review and re-prompt every error. Huntley’s solution was elegantly brutish. He wrote a 5-line Bash script that he jokingly named after Ralph Wiggum, the dim-witted but relentlessly optimistic and undeterred character from The Simpsons.As Huntley explained in his initial release blog post \"Ralph Wiggum as a &#x27;software engineer,&#x27;\" the idea relied on Context Engineering.By piping the model’s entire output—failures, stack traces, and hallucinations—back into its own input stream for the next iteration, Huntley created a \"contextual pressure cooker.\"This philosophy was further dissected in a recent conversation with Dexter Horthy, co-founder and CEO of the enterprise AI engineering firm HumanLayer, posted on YouTube.Horthy and Huntley argue that the power of the original Ralph wasn&#x27;t just in the looping, but in its \"naive persistence\" — the unsanitized feedback, in which the LLM isn&#x27;t protected from its own mess; it is forced to confront it. It embodies the philosophy that if you press the model hard enough against its own failures without a safety net, it will eventually \"dream\" a correct solution just to escape the loop.By late 2025, Anthropic’s Developer Relations team, led by Boris Cherny, formalized the hack into the official ralph-wiggum plugin. However, as noted by critics in the Horthy/Huntley discussion, the official release marked a shift in philosophy—a \"sterilization\" of the original chaotic concept.While Huntley’s script was about brute force, the official Anthropic plugin was designed around the principle that \"Failures Are Data.\" In the official documentation, the distinction is clear. The Anthropic implementation utilizes a specialized \"Stop Hook\"—a mechanism that intercepts the AI&#x27;s attempt to exit the CLI.Intercept the Exit: When Claude thinks it is done, the plugin pauses execution.Verify Promise: It checks for a specific \"Completion Promise\" (e.g., \"All tests passed\").Feedback Injection: If the promise isn&#x27;t met, the failure is formatted as a structured data object.The \"Tale of Two Ralphs\" offers a critical choice for modern power users:The \"Huntley Ralph\" (Bash Script/Community Forks): Best for chaotic, creative exploration where you want the AI to solve problems through sheer, unbridled persistence.The \"Official Ralph\" (Anthropic Plugin): The standard for enterprise workflows, strictly bound by token limits and safety hooks, designed to fix broken builds reliably without the risk of an infinite hallucination loop.In short: Huntley proved the loop was possible; Anthropic proved it could be safe.What It Offers: The Night Shift for CodersThe documentation is clear on where Ralph shines: new projects and tasks with automatic verification (like tests or linters). But for the \"boring stuff,\" the efficiency gains are becoming the stuff of legend. According to the official plugin documentation on GitHub, the technique has already logged some eye-watering wins. In one case, a developer reportedly completed a $50,000 contract for just $297 in API costs—essentially arbitraging the difference between an expensive human lawyer/coder and a relentless AI loop.The repository also highlights a Y Combinator hackathon stress test where the tool \"successfully generated 6 repositories overnight,\" effectively allowing a single developer to output a small team&#x27;s worth of boilerplate while asleep. Meanwhile, on X, community members like ynkzlk have shared screenshots of Ralph handling the kind of maintenance work engineers dread, such as a 14-hour autonomous session that upgraded a stale codebase from React v16 to v19 entirely without human input.To make this work safely, power users rely on a specific architecture. Matt Pocock, a prominent developer and educator who posted a recent YouTube video overview of why Ralph Wiggum is so powerful.As he states: \"One of the dreams of coding agents is that you can wake up in the morning to working code, that your coding agent has worked through your backlog and has just spit out a whole bunch of code for you to review and it works.\" In Pocock&#x27;s view, Wiggum (the plugin) is about as close as you can come to this dream. It&#x27;s \"a vast improvement over any other AI coding orchestration setup I&#x27;ve ever tried and allows you to actually ship working stuff with longrunning coding agents,\" he states.He advises using strong feedback loops like TypeScript and unit tests. If the code compiles and passes tests, the AI emits the completion promise; if not, the Stop Hook forces it to try again.The Core Innovation: The Stop HookAt its heart, the Ralph Wiggum technique is deceptively simple. As Huntley put it: \"Ralph is a Bash loop.\"However, the official plugin implements this in a clever, technically distinct way. Instead of just running a script on the outside, the plugin installs a \"Stop Hook\" inside your Claude session.You give Claude a task and a \"completion promise\" (e.g., <promise>COMPLETE</promise>).Claude works on the task and tries to exit when it thinks it&#x27;s done.The hook blocks the exit if the promise isn&#x27;t found, feeding the same prompt back into the system.This forces a \"self-referential feedback loop\" where Claude sees its previous work, reads the error logs or git history, and tries again.Pocock describes this as a shift from \"Waterfall\" planning to true \"Agile\" for AI. Instead of forcing the AI to follow a brittle, multi-step plan, Ralph allows the agent to simply \"grab a ticket off the board,\" finish it, and look for the next one.Community Reactions: &#x27;The Closest Thing to AGI&#x27;The reception among the AI builder and developer community on social media has been effusive. Dennison Bertram, CEO and founder of custom cryptocurrency and blockchain token creation platform Tally, posted on X on December 15: \"No joke, this might be the closest thing I&#x27;ve seen to AGI: This prompt is an absolute beast with Claude.\"Arvid Kahl, founder and CEO of automated podcast business intelligence extraction and brand detection tool Podscan, persuasively covered the benefits of Ralph&#x27;s persistent approach in his own X post yesterday:And as Chicago entrepreneur Hunter Hammonds put it: Opus 4.5 + Ralph Wiggum with XcodeBuild and playwright is going to mint millionaires. Mark my words. You’re not readyIn a meta-twist characteristic of the 2025 AI scene, the \"Ralph\" phenomenon didn&#x27;t just generate code—it generated a market.And earlier this week, someone — not Huntley, he says — launched a new $RALPH cryptocurrency token on the Solana blockchain to capitalize on the hype surrounding the plugin. The Catch: Costs and SafetyThe excitement comes with significant caveats. Software firm Better Stack warned users on X about the economic reality of infinite loops:\"The Ralph Wiggum plugin runs Claude Code in autonomous loops... But will those nonstop API calls break your token budget?\"Because the loop runs until success, the documentation advises using \"Escape Hatches.\" Users should always set a --max-iterations flag (e.g., 20 or 50) to prevent the AI from burning through cash on an impossible task.There is also a security dimension. To work effectively, Ralph often requires the --dangerously-skip-permissions flag, granting the AI full control over the terminal. Security experts strictly advise running Ralph sessions in sandboxed environments (like disposable cloud VMs) to prevent the AI from accidentally deleting local files.AvailabilityThe Ralph Wiggum technique is available now for Claude Code users:Official Plugin: Accessible inside Claude Code via /plugin ralph.Original Method: The \"OG\" bash scripts and community forks are available on GitHub.As 2026 begins, Ralph Wiggum has evolved from a Simpsons joke into a defining archetype for software development: Iteration > Perfection.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4noz34EAOxR22KmaNc7jXi/ea6fa9616bdd66f61253b5b69f662527/INsm1_lvrE4rQPmTkgC_N.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/anker-unveils-a-new-lineup-of-chargers-and-docks-at-ces-2026-160021195.html",
          "published_at": "Tue, 06 Jan 2026 18:08:57 +0000",
          "title": "Anker unveils a new lineup of chargers and docks at CES 2026",
          "standfirst": "Anker dove into CES 2026 with a slew of announcements that bring new chargers and accessories under its umbrella. The new accessories include improved visual interfaces, faster Qi2 wireless charging and “upgraded ecosystems” that support the latest iPhones. Some of the latest devices are even available to buy right now. First up is the Anker Nano Charger with smart display, which features a tiny screen, 180-degree foldable prongs and provides up to 45W of power. The plug can identify the exact iPhone model connected and then deliver the right amount of power for your phone. Anker says the Nano uses three-stage power delivery and a \"Care Mode\" that the company claims keeps batteries cooler than some competing 45W chargers. It arrives in late January 2026 and will retail for $40. For fans of wireless charging stations, the Anker Prime Wireless Charging Station offers a 3-in-1 solution for iPhone, Apple Watch and AirPods. It uses a \"AirCool\" system for \"faster, safer performance\" and offers up to 25W of Qi2 wireless power. The design is also foldable for compact travel. It's set for release in Q1 2026 and will retail for $150. The company debuted a clamp-on 10-in-1 Nano Power Strip with 70W of output and built-in surge protection. It sports two USB-C ports, two USB-A ports and six AC outlets. The Nano Power Strip is getting a late January release, and it will sell for $70. Anker also unveiled a 13-in-1 Nano Docking Station. This serves as an all-in-one hub with support for up to three displays (with 4K resolution supported on a single display), up to 100W of upstream charging and 10 Gbps of data transfer between connected devices. It also features a removable 6-in-1 hub with SD and microSD card readers, a USB-A port and a 5 Gbps USB-C port. The Nano Docking Station is available now and retails for $150. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/anker-unveils-a-new-lineup-of-chargers-and-docks-at-ces-2026-160021195.html?src=rss",
          "content": "Anker dove into CES 2026 with a slew of announcements that bring new chargers and accessories under its umbrella. The new accessories include improved visual interfaces, faster Qi2 wireless charging and “upgraded ecosystems” that support the latest iPhones. Some of the latest devices are even available to buy right now. First up is the Anker Nano Charger with smart display, which features a tiny screen, 180-degree foldable prongs and provides up to 45W of power. The plug can identify the exact iPhone model connected and then deliver the right amount of power for your phone. Anker says the Nano uses three-stage power delivery and a \"Care Mode\" that the company claims keeps batteries cooler than some competing 45W chargers. It arrives in late January 2026 and will retail for $40. For fans of wireless charging stations, the Anker Prime Wireless Charging Station offers a 3-in-1 solution for iPhone, Apple Watch and AirPods. It uses a \"AirCool\" system for \"faster, safer performance\" and offers up to 25W of Qi2 wireless power. The design is also foldable for compact travel. It's set for release in Q1 2026 and will retail for $150. The company debuted a clamp-on 10-in-1 Nano Power Strip with 70W of output and built-in surge protection. It sports two USB-C ports, two USB-A ports and six AC outlets. The Nano Power Strip is getting a late January release, and it will sell for $70. Anker also unveiled a 13-in-1 Nano Docking Station. This serves as an all-in-one hub with support for up to three displays (with 4K resolution supported on a single display), up to 100W of upstream charging and 10 Gbps of data transfer between connected devices. It also features a removable 6-in-1 hub with SD and microSD card readers, a USB-A port and a 5 Gbps USB-C port. The Nano Docking Station is available now and retails for $150. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/anker-unveils-a-new-lineup-of-chargers-and-docks-at-ces-2026-160021195.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-ces-2026-press-day-174444560.html",
          "published_at": "Tue, 06 Jan 2026 17:44:45 +0000",
          "title": "The Morning After: Sony Honda’s new car, Lego’s first CES press event and more",
          "standfirst": "Welcome to your first CES edition of TMA, attempting (almost futilely) to distill the biggest product reveals and announcements. Despite two days of briefings and conferences, today is merely day one. However, we’ve already seen Sony Honda reveal its next car — and the Afeela 1 isn’t yet on sale. We’ve got a deep dive on what we’ve seen so far, right here. AMD announced new Ryzen AI 400 laptop processors and updated desktop chips, including the Ryzen 7 9850X3D, with a new focus broadly on AI processing improvements. NVIDIA had a lengthy, dense press conference showing off its dominance in AI tech, but it lacked major consumer announcements — until overnight, when it revealed next-gen G-Sync tech and an upgraded version of DLSS. The new tech can handle up to 4K 240Hz path traced performance. It also adds an improved version of Super Resolution Transformer, with more stability. This year’s wildcard CES press conference was… Lego? It revealed Smart Bricks, which adds sensors, audio and wireless communication to traditional Lego pieces. The system is launching with Star Wars sets later this year — and perhaps crucially, no smartphone or screen is needed to play. There’s also LG and Samsung to get into — more on those below! — Mat Smith The other big stories (and deals) this morning CES 2026 Day 0: Everything else Intel hopes its Core Ultra Series 3 chips are the start of a comeback Razer’s Project Madison concept chair has reactive lighting, immersive audio and multi-zone haptics It took guts for Dell to admit its mistake. Here’s how XPS will make its big comeback The Handy 2 Pro is an ‘overclockable’ sex toy Garmin had the nerve to launch a food-tracking feature in Las Vegas Samsung’s Galaxy Z Trifold gets me excited about foldables again Phone and tablet, together. Engadget After launching its double-folding smartphone in Korea, Samsung is giving its newest foldable the press tour at CES 2026 and, despite reservations, it’s slick. The key difference between the Z Trifold and the Z Fold series is a second fold-out wing, turning it from a traditional smartphone into a more tablet-like form factor, closer to what we’re used to. Farewell square-ish screens. This is what we were promised when foldables first appeared: a larger screen that offers greater utility than traditional smartphones, without compromise. Sam Rutherford tested one out. Read on for his impressions. Continue reading. Samsung’s giant 130-inch TV is here to make you want Micro RGB TVs In more wall-friendly sizes. Engadget The big reveal at Samsung’s First Look CES press conference was literally big: a flagship 130-inch Micro RGB TV framed by a giant metal easel with embedded speakers. It’s much more in the realm of concept than reality — no price, no release date. It works as a halo product for more realistic TV sets using Samsung’s new preferred display technology. This year it’ll be offering TVs in 55-, 65- and 75-inch sizes. And if you’re curious, we explain what Micro RGB TVs are. Continue reading. LG’s approach to TVs at CES 2026? Variety. Oh, and scale. Engadget CES 2026 marks the return of LG’s ultra-thin Wallpaper TV. The latest version sports a gorgeous OLED screen and wireless connectivity, and it’s about as thin as a pencil. We checked out the new Wallpaper TV during a CES preview event, along with LG’s Gallery and Micro RGB sets. If money were no object, I’d want a 100-inch LG Wallpaper TV. According to Devindra Hardawar, it looks “shockingly thin” in person. Continue reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-ces-2026-press-day-174444560.html?src=rss",
          "content": "Welcome to your first CES edition of TMA, attempting (almost futilely) to distill the biggest product reveals and announcements. Despite two days of briefings and conferences, today is merely day one. However, we’ve already seen Sony Honda reveal its next car — and the Afeela 1 isn’t yet on sale. We’ve got a deep dive on what we’ve seen so far, right here. AMD announced new Ryzen AI 400 laptop processors and updated desktop chips, including the Ryzen 7 9850X3D, with a new focus broadly on AI processing improvements. NVIDIA had a lengthy, dense press conference showing off its dominance in AI tech, but it lacked major consumer announcements — until overnight, when it revealed next-gen G-Sync tech and an upgraded version of DLSS. The new tech can handle up to 4K 240Hz path traced performance. It also adds an improved version of Super Resolution Transformer, with more stability. This year’s wildcard CES press conference was… Lego? It revealed Smart Bricks, which adds sensors, audio and wireless communication to traditional Lego pieces. The system is launching with Star Wars sets later this year — and perhaps crucially, no smartphone or screen is needed to play. There’s also LG and Samsung to get into — more on those below! — Mat Smith The other big stories (and deals) this morning CES 2026 Day 0: Everything else Intel hopes its Core Ultra Series 3 chips are the start of a comeback Razer’s Project Madison concept chair has reactive lighting, immersive audio and multi-zone haptics It took guts for Dell to admit its mistake. Here’s how XPS will make its big comeback The Handy 2 Pro is an ‘overclockable’ sex toy Garmin had the nerve to launch a food-tracking feature in Las Vegas Samsung’s Galaxy Z Trifold gets me excited about foldables again Phone and tablet, together. Engadget After launching its double-folding smartphone in Korea, Samsung is giving its newest foldable the press tour at CES 2026 and, despite reservations, it’s slick. The key difference between the Z Trifold and the Z Fold series is a second fold-out wing, turning it from a traditional smartphone into a more tablet-like form factor, closer to what we’re used to. Farewell square-ish screens. This is what we were promised when foldables first appeared: a larger screen that offers greater utility than traditional smartphones, without compromise. Sam Rutherford tested one out. Read on for his impressions. Continue reading. Samsung’s giant 130-inch TV is here to make you want Micro RGB TVs In more wall-friendly sizes. Engadget The big reveal at Samsung’s First Look CES press conference was literally big: a flagship 130-inch Micro RGB TV framed by a giant metal easel with embedded speakers. It’s much more in the realm of concept than reality — no price, no release date. It works as a halo product for more realistic TV sets using Samsung’s new preferred display technology. This year it’ll be offering TVs in 55-, 65- and 75-inch sizes. And if you’re curious, we explain what Micro RGB TVs are. Continue reading. LG’s approach to TVs at CES 2026? Variety. Oh, and scale. Engadget CES 2026 marks the return of LG’s ultra-thin Wallpaper TV. The latest version sports a gorgeous OLED screen and wireless connectivity, and it’s about as thin as a pencil. We checked out the new Wallpaper TV during a CES preview event, along with LG’s Gallery and Micro RGB sets. If money were no object, I’d want a 100-inch LG Wallpaper TV. According to Devindra Hardawar, it looks “shockingly thin” in person. Continue reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-ces-2026-press-day-174444560.html?src=rss",
          "feed_position": 31,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/d8f7a130-eb25-11f0-af7b-7907a9e6e088"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/the-asus-zenbook-duo-got-a-fantastic-redesign-for-ces-2026-173000392.html",
          "published_at": "Tue, 06 Jan 2026 17:30:00 +0000",
          "title": "The ASUS Zenbook Duo got a fantastic redesign for CES 2026",
          "standfirst": "The ASUS Zenbook Duo was easily one of my favorite laptops of 2024 as it was the first dual-screen notebook actually worth buying. But now at CES 2026, ASUS has given the second-gen model a complete revamp with practically all the upgrades and tweaks I’ve been hoping for. Like the rest of the Zenbook line, the 2026 Duo is getting ASUS’ Ceraluminum treatment on its lid, bottom and kickstand, which not only looks great but it adds an extra bit of durability and scratch resistance. There’s also an improved magnetic latch system and Bluetooth connection for its detachable keyboard to help keep it charged up and paired more reliably. However, the biggest upgrade is ASUS’ all-new \"hideaway\" hinge. Not only does it allow the system to unfold flat against a table, it also massively shrinks the gap between the laptop’s two 3K 144Hz Lumina Pro OLED displays to just 8.28 mm. That’s a reduction of 70 percent compared to the previous model and it makes the idea of using a dual screen laptop just that much more seamless and appealing than before. Another important upgrade is that despite having a significantly larger 99Whr battery (up from 75Whr on its predecessor), the overall footprint of the second-gen Zenbook Duo is actually five percent smaller than before. That makes it noticeably more compact without sacrificing on weight or thinness, which is staying pretty much the same at 3.6 pounds and 0.77 to 0.9 inches thick (depending on where you measure). Connectivity remains excellent as well, with ASUS including Wi-Fi 7, two USB-C with Thunderbolt 4, a USB-A 3.2 Gen 2 connector and even a full-size HDMI 2.1 jack. And for all the artists out there, the Zenbook Duo also supports stylus input via the ASUS Pen 3.0, so you can easily detach the wireless keyboard and use either screen as a built-in drawing tablet. That said, it’s currently unclear if the stylus comes included or not. Meanwhile on the inside, the Zenbook Duo features either an Intel Core Ultra 7 355 or Ultra 9 386H chip with up to 32GB of RAM and 2TB of storage. On top of that, ASUS increased the Duo’s TDP to 45 watts, which is another notable bump up over the original. So not only does it have a larger battery, its performance is getting a big boost as well, especially when combined with the much improved onboard graphics from Intel’s latest integrated Arc GPU. Here's how the new 2026 ASUS Zenbook duo (right) stacks up against the outgoing model (left). Sam Rutherford for EngadgetI know a lot of people out there still aren’t convinced that dual screen laptops need to be a thing, and that’s totally OK. But as the kind of person who feels like they are missing a limb when I’m traveling and away from my two monitors at home, the second-gen Zenbook Duo feels like a major refinement of an already great idea. It’s got a bigger battery, faster performance and a hugely streamlined design without gaining any bulkiness or weight. Out of all of the laptops I’ve seen at CES 2026, this is the one I most wish I could grab and start using right away. The one potential concern is that ASUS has yet to release pricing for the new Zenbook Duo or say when it will go on sale. So here’s hoping it won’t break the bank when it arrives sometime later this year. This article originally appeared on Engadget at https://www.engadget.com/computing/the-asus-zenbook-duo-got-a-fantastic-redesign-for-ces-2026-173000392.html?src=rss",
          "content": "The ASUS Zenbook Duo was easily one of my favorite laptops of 2024 as it was the first dual-screen notebook actually worth buying. But now at CES 2026, ASUS has given the second-gen model a complete revamp with practically all the upgrades and tweaks I’ve been hoping for. Like the rest of the Zenbook line, the 2026 Duo is getting ASUS’ Ceraluminum treatment on its lid, bottom and kickstand, which not only looks great but it adds an extra bit of durability and scratch resistance. There’s also an improved magnetic latch system and Bluetooth connection for its detachable keyboard to help keep it charged up and paired more reliably. However, the biggest upgrade is ASUS’ all-new \"hideaway\" hinge. Not only does it allow the system to unfold flat against a table, it also massively shrinks the gap between the laptop’s two 3K 144Hz Lumina Pro OLED displays to just 8.28 mm. That’s a reduction of 70 percent compared to the previous model and it makes the idea of using a dual screen laptop just that much more seamless and appealing than before. Another important upgrade is that despite having a significantly larger 99Whr battery (up from 75Whr on its predecessor), the overall footprint of the second-gen Zenbook Duo is actually five percent smaller than before. That makes it noticeably more compact without sacrificing on weight or thinness, which is staying pretty much the same at 3.6 pounds and 0.77 to 0.9 inches thick (depending on where you measure). Connectivity remains excellent as well, with ASUS including Wi-Fi 7, two USB-C with Thunderbolt 4, a USB-A 3.2 Gen 2 connector and even a full-size HDMI 2.1 jack. And for all the artists out there, the Zenbook Duo also supports stylus input via the ASUS Pen 3.0, so you can easily detach the wireless keyboard and use either screen as a built-in drawing tablet. That said, it’s currently unclear if the stylus comes included or not. Meanwhile on the inside, the Zenbook Duo features either an Intel Core Ultra 7 355 or Ultra 9 386H chip with up to 32GB of RAM and 2TB of storage. On top of that, ASUS increased the Duo’s TDP to 45 watts, which is another notable bump up over the original. So not only does it have a larger battery, its performance is getting a big boost as well, especially when combined with the much improved onboard graphics from Intel’s latest integrated Arc GPU. Here's how the new 2026 ASUS Zenbook duo (right) stacks up against the outgoing model (left). Sam Rutherford for EngadgetI know a lot of people out there still aren’t convinced that dual screen laptops need to be a thing, and that’s totally OK. But as the kind of person who feels like they are missing a limb when I’m traveling and away from my two monitors at home, the second-gen Zenbook Duo feels like a major refinement of an already great idea. It’s got a bigger battery, faster performance and a hugely streamlined design without gaining any bulkiness or weight. Out of all of the laptops I’ve seen at CES 2026, this is the one I most wish I could grab and start using right away. The one potential concern is that ASUS has yet to release pricing for the new Zenbook Duo or say when it will go on sale. So here’s hoping it won’t break the bank when it arrives sometime later this year. This article originally appeared on Engadget at https://www.engadget.com/computing/the-asus-zenbook-duo-got-a-fantastic-redesign-for-ces-2026-173000392.html?src=rss",
          "feed_position": 32,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Zenbook-duo-new-vs-old.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/pebbles-founder-might-be-just-the-right-person-to-make-an-ai-ring-170104222.html",
          "published_at": "Tue, 06 Jan 2026 17:01:04 +0000",
          "title": "Pebble's founder might be just the right person to make an AI ring",
          "standfirst": "Eric Migicovsky has been thinking a lot about friction. Specifically, he’s been thinking about how too much friction in the way of using a device can put people off wearing it altogether. The founder of Pebble is here at CES 2026 with a few new devices from the company he recently started to bring back the beloved smartwatch brand, including the Pebble Round 2 and the Index 01. That second one is a simple ring with a button on it that you push down to talk to Pebble’s AI whenever you want it to help you remember something. In the sea of AI gadgets that clutter the showfloors of CES (and the current tech industry in general), the Index 01 is refreshingly simple. The prototypes I saw here in Las Vegas weren’t connected to phones, so they weren’t actually working. They also seemed a little unfinished, like there was still some polishing to do. But I was able to put a few on and push their buttons. I also checked out the one Migicovsky wears — more on that in a bit.I have to caveat that the rings that Migicovsky and his team had for us to try on were way too large for me. I did manage to get sized and found out I was a Pebble size 7, while my colleague Dan Cooper was determined to be a size 11. These demo rings sat loosely on my finger — and Migicovsky was particular that I wear it on my index finger and not my thumb or middle finger. I suspect that has to do with how you reach for and press the button. It’s much easier to push the key if it’s closer to your thumb. Since the idea of the Index 01 began as an app on the Pebble watch, Migicovsky has been working hard to figure out how best to make it easy to access. Back when it was an app, “friction points were having to use your other hand” to press the screen, he said. “We also experimented with gestures and voice activation, wake words,” he added. But as many of us are painfully familiar with, those triggers don’t always work well. “The whole thing that drives this ring is it being something that you can rely on. It being something that you can incorporate into your… habits,” Migicovsky said. So putting a button right by your thumb not only makes sense, but might even be, in my opinion, a bit more accessible for people with, say, speech impediments or only one hand. I have to admit I initially found the Index 01’s design to be a bit bulky-looking, and the rubbery button protrudes a lot more than I expected from looking at it in its glamor shots. It’s like in place of a diamond or a gemstone on the ring, there’s a weird little nipple that you twiddle around until you want to push it. I did find the button easy to press, if that allays any of your concerns at all. But, really, the Index’s powers aren’t visible. It’s what happens after you push the button that matters. Using the Pebble Index 01 ringThe actual demo was brief. Migicovsky prefaced things by telling me what he was about to ask, held up his hand to his mouth, pushed the button and asked me “What’s your favorite book these days?” I explained I had recently been reading Kaiju Preservation Society by John Scalzi and then Migicovsky let go of the button. After a few starts and stops due to internet woes, the companion app on his phone responded, showing a transcription of what we said, followed by an answer “That sounds like a fun read! I can create a note about the book you are reading if you’d like.”I didn’t get to ask many more questions, and I think I’d need to live with an actual unit in my life to start to rely on it more. But I love the idea of a second brain or an AI assistant that’s always ready for my random thoughts at the push of a button. Migicovsky said the Index 01 is water resistant, so you never have to take it off, even in the shower. So for those times when you’re sudsing up and have a random stroke of inspiration about soap art, you can still tell the Index 01 to remember your Eureka moment.Migicovsky said you can also double click the button (and then hold it) to access a different side of the AI. Instead of simply remembering things you tell it, the AI can try to provide answers. Pebble’s AI is powered by Claude, so the usefulness of these results is going to be dependent on that model.Depending on how you use it, Migicovsky said the Index 01 can last for years — up to three if you’re not too heavy of a user. Since he doesn’t want for you to have to place the ring on a charger and forget to put it back on again, the device is not rechargeable. When you’re about a month away from running out of juice, the app will send you a warning and ask if you want to order a replacement. You’ll also be offered the option of sending it in for recycling.That still feels a bit wasteful and potentially expensive, but Migicovsky’s thinking is that if you still are using the ring enough after two years to be thinking about extending its battery life, the price might be justifiable to you.Why a Pebble AI ring instead of others?It’s things like this that make me think Migicovsky (and the Pebble team) have the right approach to making an AI ring. Though the hardware is not the most advanced and there is a quaint simplicity to the software, there is a level of thought and care that feels important to any product’s success. Migicovsky is quick to acknowledge that Pebble watches won’t be for everyone. That if you want a health-tracking device or something with a bright, colorful screen, you should consider something else. He’s even considering placing ads for other smartwatches on the website listing the new Pebble devices.“Look — I’m the first person to call myself out when I fail,” Migicovsky wrote in a blog he posted last November. And when he spoke with Engadget, he also recognized that Pebble at one point might have tried to do too much. These days, there are other companies making smart rings that are all about tracking your sleep and fitness, and the Index 01 is not that. “And Pebble is absolutely 100 percent not that company.” Maybe with a renewed focus on a sustainable business model, Pebble actually has a chance to survive and continue making its AI ring and other devices. Nowadays, Migicovsky just wants to make gadgets that will make you smile. And when I look at a cute little nyan cat wiggling about in its lo-fi, lo-res and low-frame-rate glory on the new Pebble smartwatches, I just feel warm inside. The Index 01 is available for pre-order now at an early bird price of $75 and will cost $100 after it starts shipping in May.This article originally appeared on Engadget at https://www.engadget.com/wearables/pebbles-founder-might-be-just-the-right-person-to-make-an-ai-ring-170104222.html?src=rss",
          "content": "Eric Migicovsky has been thinking a lot about friction. Specifically, he’s been thinking about how too much friction in the way of using a device can put people off wearing it altogether. The founder of Pebble is here at CES 2026 with a few new devices from the company he recently started to bring back the beloved smartwatch brand, including the Pebble Round 2 and the Index 01. That second one is a simple ring with a button on it that you push down to talk to Pebble’s AI whenever you want it to help you remember something. In the sea of AI gadgets that clutter the showfloors of CES (and the current tech industry in general), the Index 01 is refreshingly simple. The prototypes I saw here in Las Vegas weren’t connected to phones, so they weren’t actually working. They also seemed a little unfinished, like there was still some polishing to do. But I was able to put a few on and push their buttons. I also checked out the one Migicovsky wears — more on that in a bit.I have to caveat that the rings that Migicovsky and his team had for us to try on were way too large for me. I did manage to get sized and found out I was a Pebble size 7, while my colleague Dan Cooper was determined to be a size 11. These demo rings sat loosely on my finger — and Migicovsky was particular that I wear it on my index finger and not my thumb or middle finger. I suspect that has to do with how you reach for and press the button. It’s much easier to push the key if it’s closer to your thumb. Since the idea of the Index 01 began as an app on the Pebble watch, Migicovsky has been working hard to figure out how best to make it easy to access. Back when it was an app, “friction points were having to use your other hand” to press the screen, he said. “We also experimented with gestures and voice activation, wake words,” he added. But as many of us are painfully familiar with, those triggers don’t always work well. “The whole thing that drives this ring is it being something that you can rely on. It being something that you can incorporate into your… habits,” Migicovsky said. So putting a button right by your thumb not only makes sense, but might even be, in my opinion, a bit more accessible for people with, say, speech impediments or only one hand. I have to admit I initially found the Index 01’s design to be a bit bulky-looking, and the rubbery button protrudes a lot more than I expected from looking at it in its glamor shots. It’s like in place of a diamond or a gemstone on the ring, there’s a weird little nipple that you twiddle around until you want to push it. I did find the button easy to press, if that allays any of your concerns at all. But, really, the Index’s powers aren’t visible. It’s what happens after you push the button that matters. Using the Pebble Index 01 ringThe actual demo was brief. Migicovsky prefaced things by telling me what he was about to ask, held up his hand to his mouth, pushed the button and asked me “What’s your favorite book these days?” I explained I had recently been reading Kaiju Preservation Society by John Scalzi and then Migicovsky let go of the button. After a few starts and stops due to internet woes, the companion app on his phone responded, showing a transcription of what we said, followed by an answer “That sounds like a fun read! I can create a note about the book you are reading if you’d like.”I didn’t get to ask many more questions, and I think I’d need to live with an actual unit in my life to start to rely on it more. But I love the idea of a second brain or an AI assistant that’s always ready for my random thoughts at the push of a button. Migicovsky said the Index 01 is water resistant, so you never have to take it off, even in the shower. So for those times when you’re sudsing up and have a random stroke of inspiration about soap art, you can still tell the Index 01 to remember your Eureka moment.Migicovsky said you can also double click the button (and then hold it) to access a different side of the AI. Instead of simply remembering things you tell it, the AI can try to provide answers. Pebble’s AI is powered by Claude, so the usefulness of these results is going to be dependent on that model.Depending on how you use it, Migicovsky said the Index 01 can last for years — up to three if you’re not too heavy of a user. Since he doesn’t want for you to have to place the ring on a charger and forget to put it back on again, the device is not rechargeable. When you’re about a month away from running out of juice, the app will send you a warning and ask if you want to order a replacement. You’ll also be offered the option of sending it in for recycling.That still feels a bit wasteful and potentially expensive, but Migicovsky’s thinking is that if you still are using the ring enough after two years to be thinking about extending its battery life, the price might be justifiable to you.Why a Pebble AI ring instead of others?It’s things like this that make me think Migicovsky (and the Pebble team) have the right approach to making an AI ring. Though the hardware is not the most advanced and there is a quaint simplicity to the software, there is a level of thought and care that feels important to any product’s success. Migicovsky is quick to acknowledge that Pebble watches won’t be for everyone. That if you want a health-tracking device or something with a bright, colorful screen, you should consider something else. He’s even considering placing ads for other smartwatches on the website listing the new Pebble devices.“Look — I’m the first person to call myself out when I fail,” Migicovsky wrote in a blog he posted last November. And when he spoke with Engadget, he also recognized that Pebble at one point might have tried to do too much. These days, there are other companies making smart rings that are all about tracking your sleep and fitness, and the Index 01 is not that. “And Pebble is absolutely 100 percent not that company.” Maybe with a renewed focus on a sustainable business model, Pebble actually has a chance to survive and continue making its AI ring and other devices. Nowadays, Migicovsky just wants to make gadgets that will make you smile. And when I look at a cute little nyan cat wiggling about in its lo-fi, lo-res and low-frame-rate glory on the new Pebble smartwatches, I just feel warm inside. The Index 01 is available for pre-order now at an early bird price of $75 and will cost $100 after it starts shipping in May.This article originally appeared on Engadget at https://www.engadget.com/wearables/pebbles-founder-might-be-just-the-right-person-to-make-an-ai-ring-170104222.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/pebble-seeks-to-remedy-the-wearable-industrys-original-sin-170000834.html",
          "published_at": "Tue, 06 Jan 2026 17:00:00 +0000",
          "title": "Pebble seeks to remedy the wearable industry's original sin",
          "standfirst": "As soon as I held the Pebble Round 2 in my hand, I suddenly realized what I’d been missing for the better part of a decade. I’ve always felt smartwatches should supplement, rather than supplant, your phone, but that’s an attitude that feels almost quaint these days. After all, Apple and Samsung believe everyone wants a watch that can do almost everything your phone can do. But that wasn’t the prevailing opinion at the dawn of the smartwatch era, either philosophically or from limitations in the technology. Back then, companies like Pebble, Vector, Basis and others all built devices that added a second screen to the device in your pocket, and were all the better for it. Thankfully, Pebble founder Eric Migicovsky agrees, and if his project to revive the company is successful, perhaps we’ll once again see these alternative approaches flourish. The first step on this very long road is the Pebble Round 2, which aims to be the standard bearer for a new generation of comparatively less smart, but fundamentally more useful, smartwatches. Round 2 was announced on January 2, and is the second product in Core Devices’ (Migicovsky’s new company) lineup of revived Pebbles. The first was the revamped Time 2, aping the form of its more successful predecessor, while the Round 2 is an attempt to correct the mistakes of 2015’s Pebble Time Round. That watch, when it debuted, was met with disappointment from critics who loved its aesthetics but little else. Back then, building a Pebble with a round face required plenty of compromise, including a higher price, shorter battery life, fewer features and a massive bezel. A decade on, and the technology has come along sufficiently to render such compromises moot, making for a much better device overall. The new watch has a 1.3-inch color e-paper touchscreen which stretches to the end of the case. Its display has been bonded to the glass crystal, dramatically improving the viewing angles and reducing glare. You should expect to get two weeks of life on a single charge, but it remains just 8.1mm thick, and you can really feel that lack of heft when it’s in your hand. In fact, compared to so many of its smartwatch peers, you could almost unironically describe it as dainty, making its case size feel almost comically large. On the materials side, the case feels strong enough that I think it would withstand the rigors of daily life, and I’m quite smitten with both the polished rose gold and brushed silver finishes. On one hand, it’s hardly the major reason to buy a watch, but I’m deeply smitten by how much text the Round 2’s display can render. Even the fanciest of smartwatches aren’t that willing to display big reams of text for your ease of reading. I was tickled to read a lengthy Slack message which reminded me, again, of what I’ve been missing for all of these years. Perhaps that’s a sign of the broader benefits a device like this offers, which is the ability to tweak its UI to what you need, rather than being tied by the UI designers in Cupertino and Mountain View. There are plenty of omissions in the spec list, including no optical heart rate sensor, no GPS and no speaker. I’m not weeping over any of them: I’ve not used my smartwatch’s GPS in years and yes, and Pebble is swerving away from the health and fitness market. I don’t want to take calls from my wrist, either, and while the omitted heart rate sensor is harder to take given their ubiquity, it’s been done to ensure the watch is thinner than many of its competitors. Migicovsky is candid about Pebble’s failure, saying the company spent too much to become a global hardware brand. He invested heavily in inventory in anticipation of blockbuster sales that never came, similar to Peloton’s post-COVID slump. This time around, the focus is on ensuring the company remains sustainable over the long term and, hopefully, building a succession of products. Rather than big investments, he’ll make small batches of devices to cater to pre-orders and won’t water down his philosophy in the hope of attracting a broad user base. He even said the Pebble website may include recommendations for alternative smartwatches from other companies to ensure he’s only catering to the faithful. Three Pebble Indexes side by side on a table. Daniel Cooper for Engadget It’s his hope that this approach will give him the time and space to make more products, such as the already-announced Pebble Index 01. It’s a $75 ring equipped with a microphone, Bluetooth and a single push button, where users can record brief reminders to themselves. Rather than add weight and complexity with a rechargeable battery, each Index has a sealed-in cell that the company promises will last for up to two years. A month before the battery is due to expire, you’ll be asked if you want to buy a replacement, sending in the original for recycling. It’s an unusual arrangement but one that Migicovsky believes is more compelling than some others. After all, users aren’t saddled with any monthly subscription fees, and they only need to buy a new one if they’ve actually gotten the benefit out of their existing model. As with the revived Pebbles, the prevailing attitude is that nobody’s twisting your arm here. Image of the rear sides of the Pebble Round 2 Daniel Cooper for Engadget More broadly, Migicovsky has the time and money now to explore these product ideas free from the usual pressures. He has no investors or backers demanding instant returns and fast growth, giving him license to pursue his ideas as far as he wants to take them. And he is determined to return a small degree of whimsy to consumer electronics, building gadgets that are in some way fun. Let’s hope he succeeds, because the industry can’t survive another decade of homogeneity. This article originally appeared on Engadget at https://www.engadget.com/wearables/pebble-seeks-to-remedy-the-wearable-industrys-original-sin-170000834.html?src=rss",
          "content": "As soon as I held the Pebble Round 2 in my hand, I suddenly realized what I’d been missing for the better part of a decade. I’ve always felt smartwatches should supplement, rather than supplant, your phone, but that’s an attitude that feels almost quaint these days. After all, Apple and Samsung believe everyone wants a watch that can do almost everything your phone can do. But that wasn’t the prevailing opinion at the dawn of the smartwatch era, either philosophically or from limitations in the technology. Back then, companies like Pebble, Vector, Basis and others all built devices that added a second screen to the device in your pocket, and were all the better for it. Thankfully, Pebble founder Eric Migicovsky agrees, and if his project to revive the company is successful, perhaps we’ll once again see these alternative approaches flourish. The first step on this very long road is the Pebble Round 2, which aims to be the standard bearer for a new generation of comparatively less smart, but fundamentally more useful, smartwatches. Round 2 was announced on January 2, and is the second product in Core Devices’ (Migicovsky’s new company) lineup of revived Pebbles. The first was the revamped Time 2, aping the form of its more successful predecessor, while the Round 2 is an attempt to correct the mistakes of 2015’s Pebble Time Round. That watch, when it debuted, was met with disappointment from critics who loved its aesthetics but little else. Back then, building a Pebble with a round face required plenty of compromise, including a higher price, shorter battery life, fewer features and a massive bezel. A decade on, and the technology has come along sufficiently to render such compromises moot, making for a much better device overall. The new watch has a 1.3-inch color e-paper touchscreen which stretches to the end of the case. Its display has been bonded to the glass crystal, dramatically improving the viewing angles and reducing glare. You should expect to get two weeks of life on a single charge, but it remains just 8.1mm thick, and you can really feel that lack of heft when it’s in your hand. In fact, compared to so many of its smartwatch peers, you could almost unironically describe it as dainty, making its case size feel almost comically large. On the materials side, the case feels strong enough that I think it would withstand the rigors of daily life, and I’m quite smitten with both the polished rose gold and brushed silver finishes. On one hand, it’s hardly the major reason to buy a watch, but I’m deeply smitten by how much text the Round 2’s display can render. Even the fanciest of smartwatches aren’t that willing to display big reams of text for your ease of reading. I was tickled to read a lengthy Slack message which reminded me, again, of what I’ve been missing for all of these years. Perhaps that’s a sign of the broader benefits a device like this offers, which is the ability to tweak its UI to what you need, rather than being tied by the UI designers in Cupertino and Mountain View. There are plenty of omissions in the spec list, including no optical heart rate sensor, no GPS and no speaker. I’m not weeping over any of them: I’ve not used my smartwatch’s GPS in years and yes, and Pebble is swerving away from the health and fitness market. I don’t want to take calls from my wrist, either, and while the omitted heart rate sensor is harder to take given their ubiquity, it’s been done to ensure the watch is thinner than many of its competitors. Migicovsky is candid about Pebble’s failure, saying the company spent too much to become a global hardware brand. He invested heavily in inventory in anticipation of blockbuster sales that never came, similar to Peloton’s post-COVID slump. This time around, the focus is on ensuring the company remains sustainable over the long term and, hopefully, building a succession of products. Rather than big investments, he’ll make small batches of devices to cater to pre-orders and won’t water down his philosophy in the hope of attracting a broad user base. He even said the Pebble website may include recommendations for alternative smartwatches from other companies to ensure he’s only catering to the faithful. Three Pebble Indexes side by side on a table. Daniel Cooper for Engadget It’s his hope that this approach will give him the time and space to make more products, such as the already-announced Pebble Index 01. It’s a $75 ring equipped with a microphone, Bluetooth and a single push button, where users can record brief reminders to themselves. Rather than add weight and complexity with a rechargeable battery, each Index has a sealed-in cell that the company promises will last for up to two years. A month before the battery is due to expire, you’ll be asked if you want to buy a replacement, sending in the original for recycling. It’s an unusual arrangement but one that Migicovsky believes is more compelling than some others. After all, users aren’t saddled with any monthly subscription fees, and they only need to buy a new one if they’ve actually gotten the benefit out of their existing model. As with the revived Pebbles, the prevailing attitude is that nobody’s twisting your arm here. Image of the rear sides of the Pebble Round 2 Daniel Cooper for Engadget More broadly, Migicovsky has the time and money now to explore these product ideas free from the usual pressures. He has no investors or backers demanding instant returns and fast growth, giving him license to pursue his ideas as far as he wants to take them. And he is determined to return a small degree of whimsy to consumer electronics, building gadgets that are in some way fun. Let’s hope he succeeds, because the industry can’t survive another decade of homogeneity. This article originally appeared on Engadget at https://www.engadget.com/wearables/pebble-seeks-to-remedy-the-wearable-industrys-original-sin-170000834.html?src=rss",
          "feed_position": 36,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Rings.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/satechi-is-embracing-thunderbolt-5-at-ces-with-a-new-dock-and-cable-170000137.html",
          "published_at": "Tue, 06 Jan 2026 17:00:00 +0000",
          "title": "Satechi is embracing Thunderbolt 5 at CES with a new dock and cable",
          "standfirst": "Multiple of Satechi's Thunderbolt 4 docks are on Engadget's list of the best docking stations, so when the company announces a new accessory, it's usually worth a look. At CES 2026, Satechi is finally making the jump to Thunderbolt 5 with a new docking station and cable. The Thunderbolt 5 CubeDock with SSD Enclosure and Thunderbolt 5 Pro Cable leverage the faster speeds of Intel's cable tech, and in the case of the dock, also include extra benefits like space for SSD storage. The CubeDock is made from a block of solid aluminum and is clearly supposed to evoke Apple's desktop Macs, like the new Mac mini. Satechi already made a Mac mini hub that can do some of the same things as CubeDock, but that accessory was focused on Thunderbolt 4. With the Thunderbolt 5 on the CubeDock, the new docking station can offer support for multiple 8K monitors, 180W smart power delivery and up to 120 Gb/s transfer speeds. The back of a Satechi CubeDock displaying multiple types of ports. Satechi The dock also features a microSD card slot, SD card slots and headphone jack on the front, with multiple other input options on the back, including Thunderbolt 5 ports and an ethernet port. If you're interested in extra storage, you can also pop off the bottom of the CubeDock and add up to 8TB of SSD storage. To pair with the CubeDock, Satechi is also releasing its own Thunderbolt 5 cable. The Thunderbolt 5 Pro Cable supports up to 120 Gb/s uni-directional or 80 Gb/s bi-directional data transfers, 240W power delivery and either dual 8K/60Hz displays or a trio of 4K/144Hz displays. The Satechi Thunderbolt 5 Pro Cable coiled on a white background. Satechi Satechi says you can pre-order the Thunderbolt 5 CubeDock with SSD Enclosure on the company's website for $399.99, and it will ship in Q1 2026. The Thunderbolt 5 Pro Cable is available to order now for $39.99 from Satechi, Amazon and other retailers. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/satechi-is-embracing-thunderbolt-5-at-ces-with-a-new-dock-and-cable-170000137.html?src=rss",
          "content": "Multiple of Satechi's Thunderbolt 4 docks are on Engadget's list of the best docking stations, so when the company announces a new accessory, it's usually worth a look. At CES 2026, Satechi is finally making the jump to Thunderbolt 5 with a new docking station and cable. The Thunderbolt 5 CubeDock with SSD Enclosure and Thunderbolt 5 Pro Cable leverage the faster speeds of Intel's cable tech, and in the case of the dock, also include extra benefits like space for SSD storage. The CubeDock is made from a block of solid aluminum and is clearly supposed to evoke Apple's desktop Macs, like the new Mac mini. Satechi already made a Mac mini hub that can do some of the same things as CubeDock, but that accessory was focused on Thunderbolt 4. With the Thunderbolt 5 on the CubeDock, the new docking station can offer support for multiple 8K monitors, 180W smart power delivery and up to 120 Gb/s transfer speeds. The back of a Satechi CubeDock displaying multiple types of ports. Satechi The dock also features a microSD card slot, SD card slots and headphone jack on the front, with multiple other input options on the back, including Thunderbolt 5 ports and an ethernet port. If you're interested in extra storage, you can also pop off the bottom of the CubeDock and add up to 8TB of SSD storage. To pair with the CubeDock, Satechi is also releasing its own Thunderbolt 5 cable. The Thunderbolt 5 Pro Cable supports up to 120 Gb/s uni-directional or 80 Gb/s bi-directional data transfers, 240W power delivery and either dual 8K/60Hz displays or a trio of 4K/144Hz displays. The Satechi Thunderbolt 5 Pro Cable coiled on a white background. Satechi Satechi says you can pre-order the Thunderbolt 5 CubeDock with SSD Enclosure on the company's website for $399.99, and it will ship in Q1 2026. The Thunderbolt 5 Pro Cable is available to order now for $39.99 from Satechi, Amazon and other retailers. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/satechi-is-embracing-thunderbolt-5-at-ces-with-a-new-dock-and-cable-170000137.html?src=rss",
          "feed_position": 37,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Satechi-CubeDock.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/all-the-laptops-that-caught-our-eye-at-ces-2026-160610752.html",
          "published_at": "Tue, 06 Jan 2026 16:06:10 +0000",
          "title": "All the laptops that caught our eye at CES 2026",
          "standfirst": "CES remains a key stage for laptop makers to lay out their plans for the year ahead. At CES 2026, that meant new flagship productivity machines, reconsidered gaming notebooks and solid incremental updates across several major lineups. While we’re still seeing embargoes lift and hands-on time on the show floor, the announcements below reflect the most significant laptops we’ve seen so far. Plus, the list will grow as more companies reveal details throughout January 6 and beyond.Samsung Galaxy Book6 seriesNew Samsung Galaxy Book6 laptops offer NVIDIA RTX 50-series GPUs.Samsung announced the Galaxy Book6 family at CES 2026, introducing three new laptops built around Intel’s Panther Lake chips: the Galaxy Book6, Book6 Pro and Book6 Ultra. The focus this year is on slimmer designs, improved thermals and longer battery life, with Samsung claiming up to 30 hours of video playback on the Book6 Ultra and Pro.The 16-inch Galaxy Book6 Ultra sits at the top of the lineup, with configurations offering up to Intel Core Ultra X9 processors, Intel Arc graphics and NVIDIA RTX 50-series GPUs, including RTX 5070 and RTX 5060 options. Samsung says the Ultra delivers up to 1.6x better CPU performance and 1.7x improved graphics compared with the previous Galaxy Book generation, helped by a wider vapor chamber and a new dual-path fan system for GPU cooling.Both the Book6 Ultra and Book6 Pro feature upgraded 2,880 x 1,800 AMOLED 2X displays with touch support, adaptive refresh rates up to 120Hz and peak brightness of up to 1,000 nits. The laptops are thinner than their predecessors, with the Ultra measuring 15.4mm thick and the Pro coming in at 11.9mm — and Samsung has added haptic trackpads across the series for the first time. Pricing and release dates have not yet been announced.ASUS ROG Zephyrus DuoOn top of having two displays, the Zephyrus Duo's screens also feature excellent brightness at up to 1,100 nits.ASUS brought its dual-screen design into the gaming space at CES 2026 with the ROG Zephyrus Duo, a laptop that pairs two full-size 16-inch displays with high-end gaming hardware. Unlike productivity-focused dual-screen systems, the Zephyrus Duo is positioned as a hybrid machine designed to handle gaming, content creation and multitasking in a single portable setup.Both 16-inch Nebula OLED panels support HDR with up to 1,100 nits of peak brightness, NVIDIA G-SYNC, stylus input and high color accuracy. Performance comes from Intel’s latest Core Ultra processors paired with NVIDIA RTX 50-series GPUs, up to an RTX 5090. While the system’s 135W power budget means it won’t match the raw performance of some single-screen gaming laptops, ASUS is clearly prioritizing versatility over maximum output.The Zephyrus Duo includes a detachable wireless keyboard, a built-in kickstand and multiple usage modes, including stacked dual-screen layouts and drawing configurations. Despite weighing a whopping 6.28 pounds, ASUS has kept the chassis relatively slim at 0.77 inches and equipped it with a six-speaker system, vapor chamber cooling and a broad selection of ports including Thunderbolt 4, HDMI 2.1 and a full-size SD card slot. Pricing and availability have not yet been announced.MSI Stealth 16 AI+MSI's most powerful gaming laptop.MSIMSI updated its Stealth lineup at CES 2026 with the Stealth 16 AI+, a gaming laptop designed to balance performance and portability. The system measures just 16.6mm thick, weighs under two kilograms and is equipped with NVIDIA RTX 50-series graphics alongside Intel Core Ultra 200HX processors.Despite its slim profile, the Stealth 16 AI+ includes dual memory slots and dual SSD bays, giving it more upgrade flexibility than many thin gaming laptops. MSI is positioning it as a versatile machine for users who want gaming performance without the bulk typically associated with high-end hardware.MSI Crosshair 16 Max HXThe Crosshair 16 Max HX represents MSI’s more traditional gaming approach, pairing Intel Core Ultra 200HX processors with NVIDIA GeForce RTX 50-series GPUs. It sits below the company’s flagship Raider models but still targets players who want strong performance in a relatively streamlined chassis.Buyers can opt for an optional QHD+ OLED display with a 165Hz refresh rate, adding sharper visuals and smoother motion for gaming and media. Alongside the Max HX, MSI also announced a Crosshair 16 HX variant, giving the Crosshair line a broader range of configurations aimed at mid-to-high-end gaming buyers.HP OmniBook Ultra 14HP claims the Omnibook Ultra 14 has passed 20 different MIL-STD 810H tests for things like extreme temperature and shock resistance.HP used CES 2026 to debut its new flagship consumer laptop, the OmniBook Ultra 14. It’s a premium ultraportable built around an ultra-thin but durability-focused design. The laptop measures just 0.42 inches thick and weighs 2.8 pounds, yet HP says it passes 20 MIL-STD-810 tests for shock, drops and extreme temperatures. Rather than a traditional unibody chassis, HP uses a forge-stamped aluminum construction designed to improve strength and bend resistance.The OmniBook Ultra 14 features a 3K OLED display and can be configured with up to 64GB of memory and 2TB of storage. Buyers can choose between Intel Core Ultra processors or Qualcomm’s Snapdragon X2 Elite, with the Snapdragon version offering a more powerful NPU rated at up to 85 TOPS for AI workloads. HP has also added a vapor chamber for the first time in an OmniBook to support sustained performance in such a slim chassis.HP rounds things out with a large touchpad, quad speakers and three USB-C ports supporting Thunderbolt 4, DisplayPort 2.1 and fast charging. The OmniBook Ultra 14 is expected to go on sale later this month starting at $1,550.HP Omen Max 16HP also refreshed its gaming lineup at CES 2026 with the Omen Max 16, which the company describes as its most powerful 16-inch gaming laptop to date. The system is built around Intel Core Ultra 200HX processors and NVIDIA RTX 50-series GPUs, with configurations reaching the high end of HP’s mobile performance offerings.Designed for sustained gaming workloads, the Omen Max 16 features expanded thermal headroom and high-refresh-rate displays aimed at competitive players. HP is positioning the laptop as the flagship of its Omen lineup, sitting above refreshed Omen 15 and Omen 16 models that target more mainstream gaming buyers.Pricing and availability for the Omen Max 16 have not yet been announced, with HP expected to share more details later this year.Acer Swift 16 AIPromo photo of the Acer Swift 16 AI laptopAcerAcer expanded its flagship Swift lineup at CES 2026 with the Swift 16 AI, a large-screen ultraportable that leans heavily into input innovation and display quality. The standout feature is what Acer says is the world’s largest haptic touchpad, which supports MPP 2.5 stylus input and is designed to improve precision for creative and productivity tasks.The Swift 16 AI features a 16-inch 3K OLED WQXGA+ touchscreen with HDR support, a 120Hz refresh rate and full DCI-P3 color coverage. It can be configured with up to an Intel Core Ultra X9 388H processor and Intel Arc B390 graphics, with up to 32GB of memory and 2TB of storage. Despite the large display, the laptop measures just 14.9mm thick and weighs about 3.4 pounds.Acer says the Swift 16 AI is part of the Copilot+ PC program, positioning it around on-device AI features alongside performance and portability. Pricing and availability have not yet been announced.Dell XPS 13, XPS 14 and XPS 16Dell wouldn't let me take photos of the XPS 13 prototype model, but here's a teaser it provided for CES. DellHaving a bit of déjà vu? You’re not alone. Dell killed its XPS branding last year only to bring it back this year after admitting it had made a mistake. Instead of simplifying its product offering, the rebranding only bewildered consumers and tech journalists alike, both of which had come to know the XPS lineup to be synonymous with quality. Now, Dell is getting back to its roots and coming out with a whole refreshed lineup of XPS laptops, including new XPS 13, XPS 14 and XPS 16 machines. Specific details for each model still remain under wraps, and there’s no word yet on when they will hit the market.Alienware gaming laptopsAlienware used CES 2026 to tease a new ultra-slim gaming laptop designed to sit below the company’s Area-51 flagships. The laptop measures roughly 17mm, or about 0.67 inches, thick and will be offered in both 14-inch and 16-inch sizes.According to Alienware, the 16-inch version will feature NVIDIA discrete graphics paired with new, highly efficient CPUs. Rather than positioning it as a pure gaming machine, Alienware says the laptop is intended to balance gaming performance with creative work, productivity and everyday use.Alienware has not shared pricing, availability or full specifications, and it remains unclear how the 14-inch and 16-inch models will differ beyond size.Alienware also previewed a new entry-level gaming laptop aimed at expanding its reach to more budget-conscious players. While specs remain limited, the company says the system will deliver strong gaming performance at its most accessible price point yet.Alienware suggests pricing should come in below the $1,199 starting price of the Alienware 16 Aurora, potentially making it the most affordable gaming laptop the brand currently offers. As with the ultra-slim model, full details are expected later this year.Alienware Area-51 and AuroraAlongside its new teasers, Alienware announced updates to several existing laptops. The Alienware 16X Aurora and Alienware 16 Area-51 are gaining new anti-glare OLED panels with up to 620 nits of peak HDR brightness and a 0.2ms response time, as well as Intel Core Ultra 200HX processors.The Alienware 18 Area-51 is also being refreshed with the same CPUs. Alienware says the updated Alienware 16X Aurora, Alienware 16 Area-51 and Alienware 18 Area-51 laptops will be available in Q1 2026. Pricing has not yet been announced.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/all-the-laptops-that-caught-our-eye-at-ces-2026-160610752.html?src=rss",
          "content": "CES remains a key stage for laptop makers to lay out their plans for the year ahead. At CES 2026, that meant new flagship productivity machines, reconsidered gaming notebooks and solid incremental updates across several major lineups. While we’re still seeing embargoes lift and hands-on time on the show floor, the announcements below reflect the most significant laptops we’ve seen so far. Plus, the list will grow as more companies reveal details throughout January 6 and beyond.Samsung Galaxy Book6 seriesNew Samsung Galaxy Book6 laptops offer NVIDIA RTX 50-series GPUs.Samsung announced the Galaxy Book6 family at CES 2026, introducing three new laptops built around Intel’s Panther Lake chips: the Galaxy Book6, Book6 Pro and Book6 Ultra. The focus this year is on slimmer designs, improved thermals and longer battery life, with Samsung claiming up to 30 hours of video playback on the Book6 Ultra and Pro.The 16-inch Galaxy Book6 Ultra sits at the top of the lineup, with configurations offering up to Intel Core Ultra X9 processors, Intel Arc graphics and NVIDIA RTX 50-series GPUs, including RTX 5070 and RTX 5060 options. Samsung says the Ultra delivers up to 1.6x better CPU performance and 1.7x improved graphics compared with the previous Galaxy Book generation, helped by a wider vapor chamber and a new dual-path fan system for GPU cooling.Both the Book6 Ultra and Book6 Pro feature upgraded 2,880 x 1,800 AMOLED 2X displays with touch support, adaptive refresh rates up to 120Hz and peak brightness of up to 1,000 nits. The laptops are thinner than their predecessors, with the Ultra measuring 15.4mm thick and the Pro coming in at 11.9mm — and Samsung has added haptic trackpads across the series for the first time. Pricing and release dates have not yet been announced.ASUS ROG Zephyrus DuoOn top of having two displays, the Zephyrus Duo's screens also feature excellent brightness at up to 1,100 nits.ASUS brought its dual-screen design into the gaming space at CES 2026 with the ROG Zephyrus Duo, a laptop that pairs two full-size 16-inch displays with high-end gaming hardware. Unlike productivity-focused dual-screen systems, the Zephyrus Duo is positioned as a hybrid machine designed to handle gaming, content creation and multitasking in a single portable setup.Both 16-inch Nebula OLED panels support HDR with up to 1,100 nits of peak brightness, NVIDIA G-SYNC, stylus input and high color accuracy. Performance comes from Intel’s latest Core Ultra processors paired with NVIDIA RTX 50-series GPUs, up to an RTX 5090. While the system’s 135W power budget means it won’t match the raw performance of some single-screen gaming laptops, ASUS is clearly prioritizing versatility over maximum output.The Zephyrus Duo includes a detachable wireless keyboard, a built-in kickstand and multiple usage modes, including stacked dual-screen layouts and drawing configurations. Despite weighing a whopping 6.28 pounds, ASUS has kept the chassis relatively slim at 0.77 inches and equipped it with a six-speaker system, vapor chamber cooling and a broad selection of ports including Thunderbolt 4, HDMI 2.1 and a full-size SD card slot. Pricing and availability have not yet been announced.MSI Stealth 16 AI+MSI's most powerful gaming laptop.MSIMSI updated its Stealth lineup at CES 2026 with the Stealth 16 AI+, a gaming laptop designed to balance performance and portability. The system measures just 16.6mm thick, weighs under two kilograms and is equipped with NVIDIA RTX 50-series graphics alongside Intel Core Ultra 200HX processors.Despite its slim profile, the Stealth 16 AI+ includes dual memory slots and dual SSD bays, giving it more upgrade flexibility than many thin gaming laptops. MSI is positioning it as a versatile machine for users who want gaming performance without the bulk typically associated with high-end hardware.MSI Crosshair 16 Max HXThe Crosshair 16 Max HX represents MSI’s more traditional gaming approach, pairing Intel Core Ultra 200HX processors with NVIDIA GeForce RTX 50-series GPUs. It sits below the company’s flagship Raider models but still targets players who want strong performance in a relatively streamlined chassis.Buyers can opt for an optional QHD+ OLED display with a 165Hz refresh rate, adding sharper visuals and smoother motion for gaming and media. Alongside the Max HX, MSI also announced a Crosshair 16 HX variant, giving the Crosshair line a broader range of configurations aimed at mid-to-high-end gaming buyers.HP OmniBook Ultra 14HP claims the Omnibook Ultra 14 has passed 20 different MIL-STD 810H tests for things like extreme temperature and shock resistance.HP used CES 2026 to debut its new flagship consumer laptop, the OmniBook Ultra 14. It’s a premium ultraportable built around an ultra-thin but durability-focused design. The laptop measures just 0.42 inches thick and weighs 2.8 pounds, yet HP says it passes 20 MIL-STD-810 tests for shock, drops and extreme temperatures. Rather than a traditional unibody chassis, HP uses a forge-stamped aluminum construction designed to improve strength and bend resistance.The OmniBook Ultra 14 features a 3K OLED display and can be configured with up to 64GB of memory and 2TB of storage. Buyers can choose between Intel Core Ultra processors or Qualcomm’s Snapdragon X2 Elite, with the Snapdragon version offering a more powerful NPU rated at up to 85 TOPS for AI workloads. HP has also added a vapor chamber for the first time in an OmniBook to support sustained performance in such a slim chassis.HP rounds things out with a large touchpad, quad speakers and three USB-C ports supporting Thunderbolt 4, DisplayPort 2.1 and fast charging. The OmniBook Ultra 14 is expected to go on sale later this month starting at $1,550.HP Omen Max 16HP also refreshed its gaming lineup at CES 2026 with the Omen Max 16, which the company describes as its most powerful 16-inch gaming laptop to date. The system is built around Intel Core Ultra 200HX processors and NVIDIA RTX 50-series GPUs, with configurations reaching the high end of HP’s mobile performance offerings.Designed for sustained gaming workloads, the Omen Max 16 features expanded thermal headroom and high-refresh-rate displays aimed at competitive players. HP is positioning the laptop as the flagship of its Omen lineup, sitting above refreshed Omen 15 and Omen 16 models that target more mainstream gaming buyers.Pricing and availability for the Omen Max 16 have not yet been announced, with HP expected to share more details later this year.Acer Swift 16 AIPromo photo of the Acer Swift 16 AI laptopAcerAcer expanded its flagship Swift lineup at CES 2026 with the Swift 16 AI, a large-screen ultraportable that leans heavily into input innovation and display quality. The standout feature is what Acer says is the world’s largest haptic touchpad, which supports MPP 2.5 stylus input and is designed to improve precision for creative and productivity tasks.The Swift 16 AI features a 16-inch 3K OLED WQXGA+ touchscreen with HDR support, a 120Hz refresh rate and full DCI-P3 color coverage. It can be configured with up to an Intel Core Ultra X9 388H processor and Intel Arc B390 graphics, with up to 32GB of memory and 2TB of storage. Despite the large display, the laptop measures just 14.9mm thick and weighs about 3.4 pounds.Acer says the Swift 16 AI is part of the Copilot+ PC program, positioning it around on-device AI features alongside performance and portability. Pricing and availability have not yet been announced.Dell XPS 13, XPS 14 and XPS 16Dell wouldn't let me take photos of the XPS 13 prototype model, but here's a teaser it provided for CES. DellHaving a bit of déjà vu? You’re not alone. Dell killed its XPS branding last year only to bring it back this year after admitting it had made a mistake. Instead of simplifying its product offering, the rebranding only bewildered consumers and tech journalists alike, both of which had come to know the XPS lineup to be synonymous with quality. Now, Dell is getting back to its roots and coming out with a whole refreshed lineup of XPS laptops, including new XPS 13, XPS 14 and XPS 16 machines. Specific details for each model still remain under wraps, and there’s no word yet on when they will hit the market.Alienware gaming laptopsAlienware used CES 2026 to tease a new ultra-slim gaming laptop designed to sit below the company’s Area-51 flagships. The laptop measures roughly 17mm, or about 0.67 inches, thick and will be offered in both 14-inch and 16-inch sizes.According to Alienware, the 16-inch version will feature NVIDIA discrete graphics paired with new, highly efficient CPUs. Rather than positioning it as a pure gaming machine, Alienware says the laptop is intended to balance gaming performance with creative work, productivity and everyday use.Alienware has not shared pricing, availability or full specifications, and it remains unclear how the 14-inch and 16-inch models will differ beyond size.Alienware also previewed a new entry-level gaming laptop aimed at expanding its reach to more budget-conscious players. While specs remain limited, the company says the system will deliver strong gaming performance at its most accessible price point yet.Alienware suggests pricing should come in below the $1,199 starting price of the Alienware 16 Aurora, potentially making it the most affordable gaming laptop the brand currently offers. As with the ultra-slim model, full details are expected later this year.Alienware Area-51 and AuroraAlongside its new teasers, Alienware announced updates to several existing laptops. The Alienware 16X Aurora and Alienware 16 Area-51 are gaining new anti-glare OLED panels with up to 620 nits of peak HDR brightness and a 0.2ms response time, as well as Intel Core Ultra 200HX processors.The Alienware 18 Area-51 is also being refreshed with the same CPUs. Alienware says the updated Alienware 16X Aurora, Alienware 16 Area-51 and Alienware 18 Area-51 laptops will be available in Q1 2026. Pricing has not yet been announced.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/all-the-laptops-that-caught-our-eye-at-ces-2026-160610752.html?src=rss",
          "feed_position": 40,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/9dce55c0-eab9-11f0-bef9-b1978212f09b"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/lgs-ultragear-gx7-is-its-fastest-and-brightest-oled-gaming-monitor-to-date-160059443.html",
          "published_at": "Tue, 06 Jan 2026 16:00:59 +0000",
          "title": "LG's UltraGear GX7 is its fastest and brightest OLED gaming monitor to date",
          "standfirst": "LG just announced its fastest and brightest OLED gaming monitor yet at CES, the 27-inch UltraGear GX7. The new QHD display, which uses LG Display's 4th-gen RGB Tandem 2.0 OLED tech, can hit 335 nits typical brightness and is DisplayHDR True Black 500 certified. At the same time, it offers an outstanding 540Hz refresh rate at QHD (720Hz at HD) and a .002ms grey-to-grey (GtG) response time. So in other words, about 5,000 times faster than the best human reflexes. Though a gaming monitor by design, the GX7 would make an excellent content creation monitor too thanks to the true 10-bit panel that delivers 99.5 percent DCI-P3 color gamma coverage and Delta E<2 color accuracy. It's also UL certified for anti-glare, flicker-free, low blue light, reduced blue light and reduced circadian stimulating blue light. Finally, it carries VESA's ClearMR 21000 certification for the highest motion-clarity tier, eliminating the faint blur that can occur around fast moving objects. And as you'd expect, it's NVIDIA G-SYNC and AMD FreeSync Premium Pro compatible. Appearance wise, it's what LG calls \"virtually borderless\" and has adjustable height, tilt, swivel and pivot controls. For connectivity, you get Dual HDMI 2.1, DisplayPort 2.1 and Thunderbolt USB-C connectivity, along with two USB 3.0 downstream ports and a 4-pole headphone jack for audio and comms. The RGB Tandem OLED technology in the UltraGear GX7 is designed for speed and brightness and should not be confused with LG's RGB V-Stripe OLED technology. The latter tech maxes out at 240Hz and is oriented more toward clarity of text and other display elements. The UltraGear GX7 is now available for pre-order at LG.com and anyone who orders before February 1st will receive a $299 27-inch FHD 240Hz gaming monitor for free. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/lgs-ultragear-gx7-is-its-fastest-and-brightest-oled-gaming-monitor-to-date-160059443.html?src=rss",
          "content": "LG just announced its fastest and brightest OLED gaming monitor yet at CES, the 27-inch UltraGear GX7. The new QHD display, which uses LG Display's 4th-gen RGB Tandem 2.0 OLED tech, can hit 335 nits typical brightness and is DisplayHDR True Black 500 certified. At the same time, it offers an outstanding 540Hz refresh rate at QHD (720Hz at HD) and a .002ms grey-to-grey (GtG) response time. So in other words, about 5,000 times faster than the best human reflexes. Though a gaming monitor by design, the GX7 would make an excellent content creation monitor too thanks to the true 10-bit panel that delivers 99.5 percent DCI-P3 color gamma coverage and Delta E<2 color accuracy. It's also UL certified for anti-glare, flicker-free, low blue light, reduced blue light and reduced circadian stimulating blue light. Finally, it carries VESA's ClearMR 21000 certification for the highest motion-clarity tier, eliminating the faint blur that can occur around fast moving objects. And as you'd expect, it's NVIDIA G-SYNC and AMD FreeSync Premium Pro compatible. Appearance wise, it's what LG calls \"virtually borderless\" and has adjustable height, tilt, swivel and pivot controls. For connectivity, you get Dual HDMI 2.1, DisplayPort 2.1 and Thunderbolt USB-C connectivity, along with two USB 3.0 downstream ports and a 4-pole headphone jack for audio and comms. The RGB Tandem OLED technology in the UltraGear GX7 is designed for speed and brightness and should not be confused with LG's RGB V-Stripe OLED technology. The latter tech maxes out at 240Hz and is oriented more toward clarity of text and other display elements. The UltraGear GX7 is now available for pre-order at LG.com and anyone who orders before February 1st will receive a $299 27-inch FHD 240Hz gaming monitor for free. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/lgs-ultragear-gx7-is-its-fastest-and-brightest-oled-gaming-monitor-to-date-160059443.html?src=rss",
          "feed_position": 41
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-z-trifold-hands-on-flexing-is-believing-at-ces-2026-224343480.html",
          "published_at": "Tue, 06 Jan 2026 15:33:19 +0000",
          "title": "Samsung Galaxy Z TriFold hands-on: Flexing is believing at CES 2026",
          "standfirst": "When I first heard whispers about the Samsung Galaxy Z TriFold, I immediately felt conflicted. On one hand it felt like the natural evolution of bi-fold phones like the Z Fold 7. But on the other, all this fancy tech comes with an even higher price — around $2,500 based on current conversion rates from Korean won — not to mention the added bulk you get from a third folding panel. So even as someone who has used a foldable as my daily driver for almost a decade straight, it felt like Samsung’s latest high-end phone was going backwards in terms of both portability and affordability. But then at CES 2026, I got a chance to go hands-on with the Galaxy Z TriFold and all of my concerns pretty much instantly disappeared because with this thing, flexing is believing.My initial consternation comes in large part from using the Z Fold 7, which hit a major milestone this year thanks to a revamped design that doesn’t come with any added size or weight even when compared to comparable candybar-style phones like the Galaxy S25 Ultra. That’s a major breakthrough considering how hefty and chunky the original Galaxy Fold was back in 2019. And when you compare the Z Fold 7’s dimensions (7.58 ounces and 8.9mm thick when folded) to the new TriFold (10.9 ounces and 12.9mm when folded), there’s no doubt that Samsung’s new flagship foldable comes with a lot of extra bulk. To put things into context, we have to go back several generations to the Z Fold 5 just to find a comparable phone with similar thickness (13.4mm). And even then, that handset is still significantly lighter than the TriFold at 8.92 ounces. There's simply no denying that the Z TriFold (left) is a much bulkier device than the Z Fold 7 (right). Sam Rutherford for EngadgetBut then I opened it up and my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness. As a phone that can pull double duty as a tablet, the jump up from the Z Fold 7’s 8-inch main display cannot be understated. Not only does it make multitasking so much easier, when combined with Samsung’s DeX desktop mode, you basically get a miniature laptop experience from a device that fits in a pocket. Especially if you don’t mind carrying around a travel-friendly mouse and keyboard. Plus, you can connect the TriFold to an external display (either wired or wirelessly) to access even more screen space. Way more than with the Z Fold 7, I can honestly see myself leaving my PC at home and using the TriFold as my primary work device. Another important but easily overlooked upgrade on the Galaxy Z Trifold is the 4:3 aspect ratio for its 10-inch main display. Compared to the Z Fold 7 and its almost perfectly square screen, you just get so much extra room on the sides for widescreen movies and shows. I tested this out by watching the trailer for Christopher Nolan’s The Odyssey, and even though that movie uses a super wide aspect ratio due to being filmed entirely on IMAX cameras, the viewing experience was just so much better. Peak watchability is something the regular Z Fold line has sort of left by the wayside as the company moved to larger exterior displays, which resulted in the series’ primary screen becoming more square. The one downside though is that the TriFold may make you more of a resolution snob, as it’s a lot easier to tell the difference between 1080p and 2K or 4K on a larger 10-inch panel. The final pillar of the TriFold’s kit is all the engineering that Samsung put into making it easy to open and close. Simply moving from one hinge to two while adding a third folding panel undersells the complexity of its design. Samsung actually uses two different types of magnets that push or pull depending on where they are, which makes accessing the TriFold’s primary display practically just as easy as on the Z Fold 7. That’s no small feat. Opening and shutting this thing is just so satisfying on a tactile level, and that’s before you consider that there’s basically no downgrade in terms of image quality. While there’s only one way to unfurl the TriFold, which might seem confusing at first, Samsung addressed that too by throwing up a warning and making the whole phone vibrate if you try to do it wrong. And then there are components like the glass-reinforced carbon panels Samsung uses to add strength and durability to its chassis while keeping it as thin as possible. The one potential concern in the future is that unlike Samsung’s older foldables, there’s not as much room for improvement to shrink its dimensions much further, as the TriFold’s slimness is currently limited by the size of its USB-C jack. So if the next model wants to make big gains there, it may need to go completely portless.Here's what The Odyssey trailer looks like on the Z TriFold (right) compared to the Z Fold 7 (left). It's such a better experience. Sam Rutherford for EngadgetOn a certain level, I kind of hate how much I like the Galaxy Z TriFold. I really don’t want to go back to bigger, heavier phones that are even more bulky and expensive than the Z Fold 7. But the appeal is impossible to deny and for people who love a good multitasker, I can easily see how these tradeoffs are worth the upside of Samsung’s latest apex foldable. The Samsung Galaxy Z TriFold is currently on sale in South Korea, though we’re still waiting for official pricing and availability for the US and North American market.The Galaxy Z TriFold is one of many new technologies Samsung announced at CES 2026. On the home entertainment side of things, the company revealed updated OLED TVs and showed off a massive 130-inch Micro RGB TV, the latter of which representing a trend we’re seeing at the show this year. There’s also a new Samsung soundbar that offers impressive bass performance sans subwoofer. Samsung’s Music Studio 5 and 7 speakers have unique designs that could blend in nicely with your home decor, and the forthcoming Galaxy Book 6 series of laptops are thin-and-light notebooks powered by Intel Panther Lake chips.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-z-trifold-hands-on-flexing-is-believing-at-ces-2026-224343480.html?src=rss",
          "content": "When I first heard whispers about the Samsung Galaxy Z TriFold, I immediately felt conflicted. On one hand it felt like the natural evolution of bi-fold phones like the Z Fold 7. But on the other, all this fancy tech comes with an even higher price — around $2,500 based on current conversion rates from Korean won — not to mention the added bulk you get from a third folding panel. So even as someone who has used a foldable as my daily driver for almost a decade straight, it felt like Samsung’s latest high-end phone was going backwards in terms of both portability and affordability. But then at CES 2026, I got a chance to go hands-on with the Galaxy Z TriFold and all of my concerns pretty much instantly disappeared because with this thing, flexing is believing.My initial consternation comes in large part from using the Z Fold 7, which hit a major milestone this year thanks to a revamped design that doesn’t come with any added size or weight even when compared to comparable candybar-style phones like the Galaxy S25 Ultra. That’s a major breakthrough considering how hefty and chunky the original Galaxy Fold was back in 2019. And when you compare the Z Fold 7’s dimensions (7.58 ounces and 8.9mm thick when folded) to the new TriFold (10.9 ounces and 12.9mm when folded), there’s no doubt that Samsung’s new flagship foldable comes with a lot of extra bulk. To put things into context, we have to go back several generations to the Z Fold 5 just to find a comparable phone with similar thickness (13.4mm). And even then, that handset is still significantly lighter than the TriFold at 8.92 ounces. There's simply no denying that the Z TriFold (left) is a much bulkier device than the Z Fold 7 (right). Sam Rutherford for EngadgetBut then I opened it up and my concerns were quickly pushed aside because suddenly you’re greeted with 10 inches of vivid AMOLED goodness. As a phone that can pull double duty as a tablet, the jump up from the Z Fold 7’s 8-inch main display cannot be understated. Not only does it make multitasking so much easier, when combined with Samsung’s DeX desktop mode, you basically get a miniature laptop experience from a device that fits in a pocket. Especially if you don’t mind carrying around a travel-friendly mouse and keyboard. Plus, you can connect the TriFold to an external display (either wired or wirelessly) to access even more screen space. Way more than with the Z Fold 7, I can honestly see myself leaving my PC at home and using the TriFold as my primary work device. Another important but easily overlooked upgrade on the Galaxy Z Trifold is the 4:3 aspect ratio for its 10-inch main display. Compared to the Z Fold 7 and its almost perfectly square screen, you just get so much extra room on the sides for widescreen movies and shows. I tested this out by watching the trailer for Christopher Nolan’s The Odyssey, and even though that movie uses a super wide aspect ratio due to being filmed entirely on IMAX cameras, the viewing experience was just so much better. Peak watchability is something the regular Z Fold line has sort of left by the wayside as the company moved to larger exterior displays, which resulted in the series’ primary screen becoming more square. The one downside though is that the TriFold may make you more of a resolution snob, as it’s a lot easier to tell the difference between 1080p and 2K or 4K on a larger 10-inch panel. The final pillar of the TriFold’s kit is all the engineering that Samsung put into making it easy to open and close. Simply moving from one hinge to two while adding a third folding panel undersells the complexity of its design. Samsung actually uses two different types of magnets that push or pull depending on where they are, which makes accessing the TriFold’s primary display practically just as easy as on the Z Fold 7. That’s no small feat. Opening and shutting this thing is just so satisfying on a tactile level, and that’s before you consider that there’s basically no downgrade in terms of image quality. While there’s only one way to unfurl the TriFold, which might seem confusing at first, Samsung addressed that too by throwing up a warning and making the whole phone vibrate if you try to do it wrong. And then there are components like the glass-reinforced carbon panels Samsung uses to add strength and durability to its chassis while keeping it as thin as possible. The one potential concern in the future is that unlike Samsung’s older foldables, there’s not as much room for improvement to shrink its dimensions much further, as the TriFold’s slimness is currently limited by the size of its USB-C jack. So if the next model wants to make big gains there, it may need to go completely portless.Here's what The Odyssey trailer looks like on the Z TriFold (right) compared to the Z Fold 7 (left). It's such a better experience. Sam Rutherford for EngadgetOn a certain level, I kind of hate how much I like the Galaxy Z TriFold. I really don’t want to go back to bigger, heavier phones that are even more bulky and expensive than the Z Fold 7. But the appeal is impossible to deny and for people who love a good multitasker, I can easily see how these tradeoffs are worth the upside of Samsung’s latest apex foldable. The Samsung Galaxy Z TriFold is currently on sale in South Korea, though we’re still waiting for official pricing and availability for the US and North American market.The Galaxy Z TriFold is one of many new technologies Samsung announced at CES 2026. On the home entertainment side of things, the company revealed updated OLED TVs and showed off a massive 130-inch Micro RGB TV, the latter of which representing a trend we’re seeing at the show this year. There’s also a new Samsung soundbar that offers impressive bass performance sans subwoofer. Samsung’s Music Studio 5 and 7 speakers have unique designs that could blend in nicely with your home decor, and the forthcoming Galaxy Book 6 series of laptops are thin-and-light notebooks powered by Intel Panther Lake chips.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-z-trifold-hands-on-flexing-is-believing-at-ces-2026-224343480.html?src=rss",
          "feed_position": 42,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/TriFold-thickness.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/the-biggest-tv-announcements-at-ces-2026-190929976.html",
          "published_at": "Tue, 06 Jan 2026 15:27:35 +0000",
          "title": "The biggest TV announcements at CES 2026",
          "standfirst": "TVs are a staple of CES, and so far, manufacturers have not disappointed with their announcements at CES 2026. Companies including Samsung, LG and others came to the event ready to show off updates to existing display tech and some genuinely new technologies. OLED and Mini LED remain central to most lineups, while Micro RGB has emerged as one of the most talked-about developments at the show so far, especially at the higher end of the TV market. Below are the TV announcements that stood out most from the pre-show events and early press conferences, with more expected as CES continues. Samsung Micro RGB TVs Samsung's flagship Micro RGB TV Engadget Samsung’s Micro RGB push at CES 2026 isn’t just about big screens — it’s also about how the technology tries to redefine color accuracy and brightness in LCD-based TVs. Unlike traditional Mini LED backlights that rely on white LEDs and filters, Samsung’s Micro RGB TVs use microscopic red, green and blue LEDs in the backlight plane, which help deliver a wider color gamut and more precise local luminance control than conventional backlit LCDs. The standout of the lineup so far is the jaw-dropping 130-inch Micro RGB concept, shown suspended on a massive gallery-style stand at Samsung’s First Look event. It’s powered by Samsung’s Micro RGB AI Engine Pro, a processing suite that includes Micro RGB Color Booster Pro and Micro RGB HDR Pro to refine contrast and push color depth and detail frame by frame, with HDR10+ Advanced support built in. Compared with previous Micro RGB models, Samsung says this expanded family will start at more practical sizes — 55- and 65-inch — and go up to sizes as large as 75, 85 and 100 inches, all with next-gen AI-driven picture and sound features baked in. Samsung’s Micro RGB sets also carry the company’s Glare Free anti-reflection finish and tie into its broader Vision AI platform, which supports things like conversational search and contextual content discovery. While the 130-inch concept may remain more of a statement piece than a consumer product, the move underscores how Samsung continues to push next-gen TV tech forward. Samsung OLED TVs Samsung’s new 2026 OLED slate — including the S95H, S90H and S85H models — continues the brand’s use of quantum dot-enhanced OLED panels, bringing brighter highlights and richer colors than older WOLED approaches. These TVs also benefit from Samsung’s continued refinement of processing and anti-glare screen treatments, which make them more adaptable in bright living rooms than traditional OLEDs. The flagship S95H retains its position as the most premium, using a quantum dot layer to help improve brightness and color purity. Below that, the S90H brings glare-reducing optical layers and robust picture processing to a slightly more affordable price point, while the S85H is designed to offer core OLED benefits, like deep blacks and wide viewing angles, in a more accessible package that now includes a new 48-inch size for smaller spaces or gaming setups. Across the OLED family, Samsung’s Vision AI-powered tools such as AI Motion Enhancer Pro and AI Sound Controller (which dynamically adjusts audio based on content) are also part of the story, making these sets not just about panel tech but about richer, more adaptable viewing experiences. LG OLED evo W6 Wallpaper TV LG's 2026 Wallpaper wireless OLED TV Devindra Hardawar for Engadget LG’s OLED evo W6 Wallpaper TV makes a striking return at CES 2026, and this year’s version manages to blend design flair with high-end performance. The panel itself is an astonishing 9mm thick, designed to sit almost flush against a wall, and pairs with a Zero Connect Box that hosts all inputs and delivers wireless video feeds up to 10 meters away. Under the ultra-thin exterior, the W6 uses LG’s Hyper Radiant Color technology coupled with Brightness Booster Ultra to push improved brightness and color saturation compared with previous Wallpaper models. It also received Intertek’s “Reflection Free with Premium” certification, indicating some of the lowest reflectance levels yet on an OLED TV. Gaming shooters and fast action fans might appreciate support for up to 165Hz refresh rates and both G-SYNC and FreeSync Premium compatibility, making this one of the most technically ambitious Wallpaper designs LG has shown. LG Micro RGB evo TVs LG is also entering the premium RGB-backlit arena at CES with its Micro RGB evo lineup, bringing a similar focus on wider color gamut and intense brightness. Early coverage indicates the Micro RGB evo models will arrive in 75-, 86- and 100-inch sizes, and are built around LG’s α11 AI Processor Gen3, which handles advanced upscaling, local dimming and dynamic HDR optimization. LG’s Micro RGB evo TVs have been certified for full coverage of BT.2020, DCI-P3 and Adobe RGB color spaces, suggesting an exceptionally wide palette and precise color fidelity. Under the hood, the Micro Dimming Ultra system is said to deliver 1,000+ local dimming zones, which narrows the gap between LCD-based displays and self-emissive technologies like OLED in terms of contrast management. This early positioning of RGB LED tech by LG also highlights a growing industry shift, with multiple brands teasing similar systems designed to improve brightness and color performance on large screen sizes — especially where OLED’s peak luminance traditionally struggles. LG OLED TVs (C6 and C6H) OLED remains a core focus for LG, and CES 2026 brought updates to its popular C-series. The LG C6 OLED continues the company’s tradition of balancing performance and price, while the C6H OLED steps things up with a new Primary RGB Tandem panel designed to deliver higher brightness and improved color volume. These models are clearly aimed at buyers who want OLED’s deep blacks and wide viewing angles without jumping to LG’s most expensive designs, making them likely to be among the most popular TVs LG releases this year. TCL X11L SQD-Mini LED TV TCL used CES 2026 to make a strong case for Mini LED’s continued relevance with the X11L SQD-Mini LED TV, its new flagship model aimed squarely at large-screen home theater setups. Rather than chasing Micro RGB, TCL is refining its own approach with SQD, or Super Quantum Dot, technology, which combines an enhanced quantum dot layer with a dense Mini LED backlight to improve color purity and brightness. The headline number here is brightness. TCL claims the X11L can hit up to 10,000 nits peak brightness, putting it among the brightest TVs shown at CES this year. That’s paired with an extremely dense local dimming system, with up to 20,000 dimming zones, which is designed to improve contrast and keep blooming in check despite the extreme luminance. TCL also says the panel covers 100 percent of the BT.2020 color space, a bold claim that, if it holds up in real-world testing, would put it in rare company. The X11L is a 4K TV available in 75-inch, 85-inch and 98-inch sizes, with the largest models clearly intended to rival premium OLED and Micro RGB sets in dedicated home theaters. It supports a 144Hz refresh rate, making it appealing for gaming as well as fast-moving sports, and includes support for advanced HDR formats, including Dolby Vision, with further enhancements expected via software updates. With CES press day underway and the show floor opening on January 6, more TV announcements are expected from major manufacturers. As additional models are revealed or details are confirmed, we’ll continue updating this roundup with the latest information. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/the-biggest-tv-announcements-at-ces-2026-190929976.html?src=rss",
          "content": "TVs are a staple of CES, and so far, manufacturers have not disappointed with their announcements at CES 2026. Companies including Samsung, LG and others came to the event ready to show off updates to existing display tech and some genuinely new technologies. OLED and Mini LED remain central to most lineups, while Micro RGB has emerged as one of the most talked-about developments at the show so far, especially at the higher end of the TV market. Below are the TV announcements that stood out most from the pre-show events and early press conferences, with more expected as CES continues. Samsung Micro RGB TVs Samsung's flagship Micro RGB TV Engadget Samsung’s Micro RGB push at CES 2026 isn’t just about big screens — it’s also about how the technology tries to redefine color accuracy and brightness in LCD-based TVs. Unlike traditional Mini LED backlights that rely on white LEDs and filters, Samsung’s Micro RGB TVs use microscopic red, green and blue LEDs in the backlight plane, which help deliver a wider color gamut and more precise local luminance control than conventional backlit LCDs. The standout of the lineup so far is the jaw-dropping 130-inch Micro RGB concept, shown suspended on a massive gallery-style stand at Samsung’s First Look event. It’s powered by Samsung’s Micro RGB AI Engine Pro, a processing suite that includes Micro RGB Color Booster Pro and Micro RGB HDR Pro to refine contrast and push color depth and detail frame by frame, with HDR10+ Advanced support built in. Compared with previous Micro RGB models, Samsung says this expanded family will start at more practical sizes — 55- and 65-inch — and go up to sizes as large as 75, 85 and 100 inches, all with next-gen AI-driven picture and sound features baked in. Samsung’s Micro RGB sets also carry the company’s Glare Free anti-reflection finish and tie into its broader Vision AI platform, which supports things like conversational search and contextual content discovery. While the 130-inch concept may remain more of a statement piece than a consumer product, the move underscores how Samsung continues to push next-gen TV tech forward. Samsung OLED TVs Samsung’s new 2026 OLED slate — including the S95H, S90H and S85H models — continues the brand’s use of quantum dot-enhanced OLED panels, bringing brighter highlights and richer colors than older WOLED approaches. These TVs also benefit from Samsung’s continued refinement of processing and anti-glare screen treatments, which make them more adaptable in bright living rooms than traditional OLEDs. The flagship S95H retains its position as the most premium, using a quantum dot layer to help improve brightness and color purity. Below that, the S90H brings glare-reducing optical layers and robust picture processing to a slightly more affordable price point, while the S85H is designed to offer core OLED benefits, like deep blacks and wide viewing angles, in a more accessible package that now includes a new 48-inch size for smaller spaces or gaming setups. Across the OLED family, Samsung’s Vision AI-powered tools such as AI Motion Enhancer Pro and AI Sound Controller (which dynamically adjusts audio based on content) are also part of the story, making these sets not just about panel tech but about richer, more adaptable viewing experiences. LG OLED evo W6 Wallpaper TV LG's 2026 Wallpaper wireless OLED TV Devindra Hardawar for Engadget LG’s OLED evo W6 Wallpaper TV makes a striking return at CES 2026, and this year’s version manages to blend design flair with high-end performance. The panel itself is an astonishing 9mm thick, designed to sit almost flush against a wall, and pairs with a Zero Connect Box that hosts all inputs and delivers wireless video feeds up to 10 meters away. Under the ultra-thin exterior, the W6 uses LG’s Hyper Radiant Color technology coupled with Brightness Booster Ultra to push improved brightness and color saturation compared with previous Wallpaper models. It also received Intertek’s “Reflection Free with Premium” certification, indicating some of the lowest reflectance levels yet on an OLED TV. Gaming shooters and fast action fans might appreciate support for up to 165Hz refresh rates and both G-SYNC and FreeSync Premium compatibility, making this one of the most technically ambitious Wallpaper designs LG has shown. LG Micro RGB evo TVs LG is also entering the premium RGB-backlit arena at CES with its Micro RGB evo lineup, bringing a similar focus on wider color gamut and intense brightness. Early coverage indicates the Micro RGB evo models will arrive in 75-, 86- and 100-inch sizes, and are built around LG’s α11 AI Processor Gen3, which handles advanced upscaling, local dimming and dynamic HDR optimization. LG’s Micro RGB evo TVs have been certified for full coverage of BT.2020, DCI-P3 and Adobe RGB color spaces, suggesting an exceptionally wide palette and precise color fidelity. Under the hood, the Micro Dimming Ultra system is said to deliver 1,000+ local dimming zones, which narrows the gap between LCD-based displays and self-emissive technologies like OLED in terms of contrast management. This early positioning of RGB LED tech by LG also highlights a growing industry shift, with multiple brands teasing similar systems designed to improve brightness and color performance on large screen sizes — especially where OLED’s peak luminance traditionally struggles. LG OLED TVs (C6 and C6H) OLED remains a core focus for LG, and CES 2026 brought updates to its popular C-series. The LG C6 OLED continues the company’s tradition of balancing performance and price, while the C6H OLED steps things up with a new Primary RGB Tandem panel designed to deliver higher brightness and improved color volume. These models are clearly aimed at buyers who want OLED’s deep blacks and wide viewing angles without jumping to LG’s most expensive designs, making them likely to be among the most popular TVs LG releases this year. TCL X11L SQD-Mini LED TV TCL used CES 2026 to make a strong case for Mini LED’s continued relevance with the X11L SQD-Mini LED TV, its new flagship model aimed squarely at large-screen home theater setups. Rather than chasing Micro RGB, TCL is refining its own approach with SQD, or Super Quantum Dot, technology, which combines an enhanced quantum dot layer with a dense Mini LED backlight to improve color purity and brightness. The headline number here is brightness. TCL claims the X11L can hit up to 10,000 nits peak brightness, putting it among the brightest TVs shown at CES this year. That’s paired with an extremely dense local dimming system, with up to 20,000 dimming zones, which is designed to improve contrast and keep blooming in check despite the extreme luminance. TCL also says the panel covers 100 percent of the BT.2020 color space, a bold claim that, if it holds up in real-world testing, would put it in rare company. The X11L is a 4K TV available in 75-inch, 85-inch and 98-inch sizes, with the largest models clearly intended to rival premium OLED and Micro RGB sets in dedicated home theaters. It supports a 144Hz refresh rate, making it appealing for gaming as well as fast-moving sports, and includes support for advanced HDR formats, including Dolby Vision, with further enhancements expected via software updates. With CES press day underway and the show floor opening on January 6, more TV announcements are expected from major manufacturers. As additional models are revealed or details are confirmed, we’ll continue updating this roundup with the latest information. This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/the-biggest-tv-announcements-at-ces-2026-190929976.html?src=rss",
          "feed_position": 43,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/a087c5f0-e9f4-11f0-87f1-6f39e4849c7d.jpeg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/everything-nvidia-announced-at-ces-2026-225653684.html",
          "published_at": "Tue, 06 Jan 2026 14:30:50 +0000",
          "title": "Everything NVIDIA announced at CES 2026",
          "standfirst": "Jensen Huang took to the CES stage on Monday to share the latest from NVIDIA, and while the presentation was more a refresher of technologies the company has been working on for the past few years, there were a couple of notable announcements. NVIDIA announced Alpamayo, a family of open-source reasoning models designed to guide autonomous vehicles through difficult driving situations. The centerpiece of the release is Alpamayo 1 , a 10-billion parameter chain-of-thought system NVIDIA says is capable of approaching driving more like a human being would. The model works by breaking down unexpected driving situations into a smaller set of problems before finding the safest path forward. At each step of the way, the model can explain its reasoning. A sister model named AlpaSim allows developers to do closed-loop training for driving scenarios that are rarely encountered in real life. Huang said the 2025 Mercedes Benz CLA will be the first vehicle to ship with NVIDIA’s entire AV stack, including Alpamayo. \"Our vision is that someday, every single car, every single truck, will be autonomous,\" Huang said. Following the Alpamayo announcements, a pair of BD-1 droids from Star Wars Jedi: Fallen Order joined Huang on stage. We saw one join the executive at last year’s CES. After that, Huang turned to Vera Rubin. NVIDIA first announced the GPU architecture in 2024, and now the company has begun production on a super computer that makes use of the new tech. One Vera CPU has 88 custom Olympus cores and 1.5TB of system memory for a total of 227 billion transistors. Meanwhile, one Rubin GPU features 336 billion transistors. Each Vera Rubin supercomputer has a pair of both components. Following the presentation, NVIDIA held a separate briefing where it announced DLSS 4.5 and G-Sync Pulsar. The latest version of NVIDIA’s upscaling technology was trained on a second-generation transformer model, which should reduce ghosting and shimmering, leading to a more stable image, even when there’s a lot of movement on screen. As part of DLSS 4.5, NVIDIA is also adding support for 6x multi-frame and dynamic generation. The two features will arrive sometime in the spring. The former allows a 50-series GPU to generate five frames for every traditionally rendered frame. The idea here is to allow a powerful GPU like the RTX 5090 to saturate a 4K, 240HZ display with as many frames as possible. Dynamic frame generation, meanwhile, is exactly what it sounds like. DLSS 4.5 can dynamically scale the number of generated frames to fit the scenario. In demanding scenes, your 50-series GPU will generate more frames, while scaling back during less hectic ones so it only computes what it needs.As for G-Sync Pulsar, it’s the latest improvement to NVIDIA’s flicker reduction technology. By pulsing a display’s backlight, NVIDIA says it can deliver perceived motion clarity relative to 1,000Hz, leading to greater clarity. Those same displays will also ship with the ability to automatically adjust their brightness and color temperature to ambient lighting conditions. Pre-orders for the first batch of G-Sync Pulsar displays will open on January 7. Update 01/06/26 9:30AM: Added information about DLSS 4.5 and G-SYNC Pulsar. This article originally appeared on Engadget at https://www.engadget.com/ai/everything-nvidia-announced-at-ces-2026-225653684.html?src=rss",
          "content": "Jensen Huang took to the CES stage on Monday to share the latest from NVIDIA, and while the presentation was more a refresher of technologies the company has been working on for the past few years, there were a couple of notable announcements. NVIDIA announced Alpamayo, a family of open-source reasoning models designed to guide autonomous vehicles through difficult driving situations. The centerpiece of the release is Alpamayo 1 , a 10-billion parameter chain-of-thought system NVIDIA says is capable of approaching driving more like a human being would. The model works by breaking down unexpected driving situations into a smaller set of problems before finding the safest path forward. At each step of the way, the model can explain its reasoning. A sister model named AlpaSim allows developers to do closed-loop training for driving scenarios that are rarely encountered in real life. Huang said the 2025 Mercedes Benz CLA will be the first vehicle to ship with NVIDIA’s entire AV stack, including Alpamayo. \"Our vision is that someday, every single car, every single truck, will be autonomous,\" Huang said. Following the Alpamayo announcements, a pair of BD-1 droids from Star Wars Jedi: Fallen Order joined Huang on stage. We saw one join the executive at last year’s CES. After that, Huang turned to Vera Rubin. NVIDIA first announced the GPU architecture in 2024, and now the company has begun production on a super computer that makes use of the new tech. One Vera CPU has 88 custom Olympus cores and 1.5TB of system memory for a total of 227 billion transistors. Meanwhile, one Rubin GPU features 336 billion transistors. Each Vera Rubin supercomputer has a pair of both components. Following the presentation, NVIDIA held a separate briefing where it announced DLSS 4.5 and G-Sync Pulsar. The latest version of NVIDIA’s upscaling technology was trained on a second-generation transformer model, which should reduce ghosting and shimmering, leading to a more stable image, even when there’s a lot of movement on screen. As part of DLSS 4.5, NVIDIA is also adding support for 6x multi-frame and dynamic generation. The two features will arrive sometime in the spring. The former allows a 50-series GPU to generate five frames for every traditionally rendered frame. The idea here is to allow a powerful GPU like the RTX 5090 to saturate a 4K, 240HZ display with as many frames as possible. Dynamic frame generation, meanwhile, is exactly what it sounds like. DLSS 4.5 can dynamically scale the number of generated frames to fit the scenario. In demanding scenes, your 50-series GPU will generate more frames, while scaling back during less hectic ones so it only computes what it needs.As for G-Sync Pulsar, it’s the latest improvement to NVIDIA’s flicker reduction technology. By pulsing a display’s backlight, NVIDIA says it can deliver perceived motion clarity relative to 1,000Hz, leading to greater clarity. Those same displays will also ship with the ability to automatically adjust their brightness and color temperature to ambient lighting conditions. Pre-orders for the first batch of G-Sync Pulsar displays will open on January 7. Update 01/06/26 9:30AM: Added information about DLSS 4.5 and G-SYNC Pulsar. This article originally appeared on Engadget at https://www.engadget.com/ai/everything-nvidia-announced-at-ces-2026-225653684.html?src=rss",
          "feed_position": 44
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/ces-2026-day-0-the-biggest-news-you-missed-from-the-shows-monday-press-conferences-142811448.html",
          "published_at": "Tue, 06 Jan 2026 14:28:11 +0000",
          "title": "CES 2026 day 0: The biggest news you missed from the show's Monday press conferences",
          "standfirst": "CES 2026 officially opens today, but much of the show’s biggest announcements already landed during Monday’s press conferences and early events. AI was everywhere, chipmakers dominated the schedule and a handful of brands used the pre-show window to quietly drop meaningful hardware updates.Below are the biggest announcements and trends from January 5, plus a few standout hands-ons from Pepcom and CES Unveiled.LG doubles down on AILG's CLOiD robot.LGLG’s World Premiere keynote leaned hard into its vision of “Affectionate Intelligence,” with AI positioned as the connective tissue across TVs, appliances and even robotics. While most of the hardware was announced ahead of time, the company used the stage to show how its ideas fit together, including updated OLED TVs, Micro RGB panels and its ultra-thin Wallpaper TV.The most memorable moment, though, was CLOiD, LG’s humanoid home robot, which capped off the presentation with demos that were more theatrical than practical. As usual for LG at CES, the vision was ambitious, even if much of it still feels a few years away.NVIDIA pushes deeper into physical AINVIDIA CEO Jensen Huang presents at CES 2026, wearing a black snakeskin-like jacket.NVIDIANVIDIA’s CES keynote was long, dense and firmly focused on AI infrastructure rather than consumer GPUs. CEO Jensen Huang introduced the Vera Rubin supercomputer platform, alongside updates to NVIDIA’s open AI models, robotics tools and autonomous vehicle stack.Between discussions of “physical AI,” self-driving systems and massive data center hardware, NVIDIA made it clear it sees CES as a place to define the future of computing, not just sell graphics cards. If you were hoping for new GeForce news, this wasn’t the keynote for you.Intel tries to reset the PC narrativeImage of a Core Ultra Series 3IntelIntel’s press conference followed NVIDIA’s with a more focused pitch: the launch of Core Ultra Series 3 processors, also known as Panther Lake. Built on Intel’s 18A process — that’s less than 2nm — the chips are designed to power the next wave of AI PCs, with improved graphics, better efficiency and stronger local AI performance.The message was clear: Intel wants to convince partners and consumers that it’s back in the game for high-end laptops, even as competition from AMD, Qualcomm and Apple continues to intensify.AMD closes the night with AI-first siliconAMD Ryzen AI 400AMDAMD wrapped up press day with a keynote that mixed familiar AI rhetoric with meaningful chip announcements. Highlights included new Ryzen AI 400 laptop processors and updated desktop chips, including the Ryzen 7 9850X3D for enthusiasts.As with NVIDIA and Intel, AMD leaned heavily into AI across cloud, PCs and edge devices. The difference was execution. AMD’s announcements felt more immediately relevant to products shipping this year.Sony remains focused on AfeelaSony Honda Mobility Afeela Press Conference at CES 2026 AfeelaSony’s CES presence once again centered on Sony Honda Mobility and the Afeela electric vehicle. The company showed an updated prototype and shared progress updates, including expanded delivery plans and deeper entertainment integrations like PlayStation Remote Play.For longtime CES watchers, it was a familiar story — the Afeela was first showcased here in 2020, after all. Sony’s traditional consumer electronics took a back seat, while mobility and software remained the headline.Lego makes its CES debut with Smart BricksLego introduced the Smart Brick at CES 2026.LegoLego held its first-ever CES press conference and used it to unveil Smart Bricks, part of a new “Smart Play” initiative that adds sensors, audio and wireless communication to traditional Lego pieces.The system is launching with Star Wars sets later this year and is designed to work without apps or screens. It’s a notable shift for Lego and one of the more genuinely surprising announcements of the day.Other notable CES day 0 newsOutside of the main press conferences, several companies made quiet but notable announcements (though some was Sunday news that hit the wires after the East Coast midnight hour). Samsung continued its CES rollout with new TVs, speakers and laptops. Anker drew attention with updated chargers and power accessories. Amazon shared incremental updates tied to Alexa and smart home hardware.Meanwhile, Engadget’s team got hands-on with dozens of products at the Pepcom mini-show, from oddball gadgets to early looks at devices launching later this year.Press day may be over, but CES is just getting started. The show floor opens today, with Lenovo, automotive tech, smart home gear and plenty of unexpected demos still to come. We’ll be publishing hands-ons, deep dives and daily recaps all week.You can follow along with our CES 2026 liveblog or check back on Engadget for the latest updates as they happen.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-day-0-the-biggest-news-you-missed-from-the-shows-monday-press-conferences-142811448.html?src=rss",
          "content": "CES 2026 officially opens today, but much of the show’s biggest announcements already landed during Monday’s press conferences and early events. AI was everywhere, chipmakers dominated the schedule and a handful of brands used the pre-show window to quietly drop meaningful hardware updates.Below are the biggest announcements and trends from January 5, plus a few standout hands-ons from Pepcom and CES Unveiled.LG doubles down on AILG's CLOiD robot.LGLG’s World Premiere keynote leaned hard into its vision of “Affectionate Intelligence,” with AI positioned as the connective tissue across TVs, appliances and even robotics. While most of the hardware was announced ahead of time, the company used the stage to show how its ideas fit together, including updated OLED TVs, Micro RGB panels and its ultra-thin Wallpaper TV.The most memorable moment, though, was CLOiD, LG’s humanoid home robot, which capped off the presentation with demos that were more theatrical than practical. As usual for LG at CES, the vision was ambitious, even if much of it still feels a few years away.NVIDIA pushes deeper into physical AINVIDIA CEO Jensen Huang presents at CES 2026, wearing a black snakeskin-like jacket.NVIDIANVIDIA’s CES keynote was long, dense and firmly focused on AI infrastructure rather than consumer GPUs. CEO Jensen Huang introduced the Vera Rubin supercomputer platform, alongside updates to NVIDIA’s open AI models, robotics tools and autonomous vehicle stack.Between discussions of “physical AI,” self-driving systems and massive data center hardware, NVIDIA made it clear it sees CES as a place to define the future of computing, not just sell graphics cards. If you were hoping for new GeForce news, this wasn’t the keynote for you.Intel tries to reset the PC narrativeImage of a Core Ultra Series 3IntelIntel’s press conference followed NVIDIA’s with a more focused pitch: the launch of Core Ultra Series 3 processors, also known as Panther Lake. Built on Intel’s 18A process — that’s less than 2nm — the chips are designed to power the next wave of AI PCs, with improved graphics, better efficiency and stronger local AI performance.The message was clear: Intel wants to convince partners and consumers that it’s back in the game for high-end laptops, even as competition from AMD, Qualcomm and Apple continues to intensify.AMD closes the night with AI-first siliconAMD Ryzen AI 400AMDAMD wrapped up press day with a keynote that mixed familiar AI rhetoric with meaningful chip announcements. Highlights included new Ryzen AI 400 laptop processors and updated desktop chips, including the Ryzen 7 9850X3D for enthusiasts.As with NVIDIA and Intel, AMD leaned heavily into AI across cloud, PCs and edge devices. The difference was execution. AMD’s announcements felt more immediately relevant to products shipping this year.Sony remains focused on AfeelaSony Honda Mobility Afeela Press Conference at CES 2026 AfeelaSony’s CES presence once again centered on Sony Honda Mobility and the Afeela electric vehicle. The company showed an updated prototype and shared progress updates, including expanded delivery plans and deeper entertainment integrations like PlayStation Remote Play.For longtime CES watchers, it was a familiar story — the Afeela was first showcased here in 2020, after all. Sony’s traditional consumer electronics took a back seat, while mobility and software remained the headline.Lego makes its CES debut with Smart BricksLego introduced the Smart Brick at CES 2026.LegoLego held its first-ever CES press conference and used it to unveil Smart Bricks, part of a new “Smart Play” initiative that adds sensors, audio and wireless communication to traditional Lego pieces.The system is launching with Star Wars sets later this year and is designed to work without apps or screens. It’s a notable shift for Lego and one of the more genuinely surprising announcements of the day.Other notable CES day 0 newsOutside of the main press conferences, several companies made quiet but notable announcements (though some was Sunday news that hit the wires after the East Coast midnight hour). Samsung continued its CES rollout with new TVs, speakers and laptops. Anker drew attention with updated chargers and power accessories. Amazon shared incremental updates tied to Alexa and smart home hardware.Meanwhile, Engadget’s team got hands-on with dozens of products at the Pepcom mini-show, from oddball gadgets to early looks at devices launching later this year.Press day may be over, but CES is just getting started. The show floor opens today, with Lenovo, automotive tech, smart home gear and plenty of unexpected demos still to come. We’ll be publishing hands-ons, deep dives and daily recaps all week.You can follow along with our CES 2026 liveblog or check back on Engadget for the latest updates as they happen.This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-day-0-the-biggest-news-you-missed-from-the-shows-monday-press-conferences-142811448.html?src=rss",
          "feed_position": 45,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/cloid_laundry.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/dell-unveils-a-massive-52-inch-6k-ultrawide-monitor-at-ces-2026-140024029.html",
          "published_at": "Tue, 06 Jan 2026 14:00:24 +0000",
          "title": "Dell unveils a massive 52-inch 6K ultrawide monitor at CES 2026",
          "standfirst": "Dell has unveiled an ultrawide, curved 52-inch 6K monitor at CES 2026. This productivity behemoth is designed for stock traders, engineers and other data professionals. Dell claims the UltraSharp 52 Thunderbolt Hub Monitor is the world's first 52-inch ultrawide curved 6K monitor (but with that many qualifiers almost anything can be a world first). Given Dell’s experience in the monitor realm, this could be a dream display for professionals who handle vast data sets such as trading platforms, AutoCAD, 3D rendering software, spreadsheets and more. It sports a 120Hz refresh rate on an IPS Black panel and emits up to 60 percent less blue light when compared to competing monitors. It delivers an impressive 129 ppi (for comparison a 4K 32-inch monitor delivers 138 ppi) and an ambient light sensor helps avoid eye strain during long work sessions. Users can connect up to four PCs to the monitor simultaneously, which can use picture-by-picture to treat each partitioned screen as an individual monitor. It also features built-in KVM (keyboard, video, mouse) features that let users control all connected PCs via a single mouse and keyboard. The monitor can also charge your laptop with up to 140W of power via a Thunderbolt 4 connection. Dell also rolled out a new 32-inch 4K QD-OLED monitor with support for both True Black 500 HDR and Dolby Vision. It claims true-to-life color accuracy out of the box and excellent gamut coverage at 99 percent of DCI-P3. This monitor would be a strong fit for film and photo editing. The Dell UltraSharp 52 Thunderbolt Hub Monitor is priced at $2,900 with stand or $2,800 without. It will be widely available starting January 6. The Dell UltraSharp 32 4K QD-OLED Monitor comes in at $2,600 and will be available beginning February 24.This article originally appeared on Engadget at https://www.engadget.com/computing/dell-unveils-a-massive-52-inch-6k-ultrawide-monitor-at-ces-2026-140024029.html?src=rss",
          "content": "Dell has unveiled an ultrawide, curved 52-inch 6K monitor at CES 2026. This productivity behemoth is designed for stock traders, engineers and other data professionals. Dell claims the UltraSharp 52 Thunderbolt Hub Monitor is the world's first 52-inch ultrawide curved 6K monitor (but with that many qualifiers almost anything can be a world first). Given Dell’s experience in the monitor realm, this could be a dream display for professionals who handle vast data sets such as trading platforms, AutoCAD, 3D rendering software, spreadsheets and more. It sports a 120Hz refresh rate on an IPS Black panel and emits up to 60 percent less blue light when compared to competing monitors. It delivers an impressive 129 ppi (for comparison a 4K 32-inch monitor delivers 138 ppi) and an ambient light sensor helps avoid eye strain during long work sessions. Users can connect up to four PCs to the monitor simultaneously, which can use picture-by-picture to treat each partitioned screen as an individual monitor. It also features built-in KVM (keyboard, video, mouse) features that let users control all connected PCs via a single mouse and keyboard. The monitor can also charge your laptop with up to 140W of power via a Thunderbolt 4 connection. Dell also rolled out a new 32-inch 4K QD-OLED monitor with support for both True Black 500 HDR and Dolby Vision. It claims true-to-life color accuracy out of the box and excellent gamut coverage at 99 percent of DCI-P3. This monitor would be a strong fit for film and photo editing. The Dell UltraSharp 52 Thunderbolt Hub Monitor is priced at $2,900 with stand or $2,800 without. It will be widely available starting January 6. The Dell UltraSharp 32 4K QD-OLED Monitor comes in at $2,600 and will be available beginning February 24.This article originally appeared on Engadget at https://www.engadget.com/computing/dell-unveils-a-massive-52-inch-6k-ultrawide-monitor-at-ces-2026-140024029.html?src=rss",
          "feed_position": 46
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/nvidias-g-sync-pulsar-tech-can-minimize-motion-blur-for-gamers-140000058.html",
          "published_at": "Tue, 06 Jan 2026 14:00:00 +0000",
          "title": "NVIDIA's G-Sync Pulsar tech can minimize motion blur for gamers",
          "standfirst": "NVIDIA has unveiled the G-Sync Pulsar, which it calls the “latest evolution of [its] pioneering VRR (variable refresh rate) technology,” at CES 2026. The new tech promises a gaming experience that’s free of stutter with buttery smooth motion, which is made possible by pulsing the display’s backlight. G-Sync Pulsar displays have multiple horizontal backlight sections that are pulsed independently from top to bottom, unlike traditional displays whose backlight is always on. When the backlight is always active, the image fades from one frame to the next. The displays with the new tech give pixels in a frame enough time to stabilize before they’re backlit so that they’re shown in their right locations, effectively reducing monitor-based motion blur. The company says G-Sync Pulsar can effectively quadruple your refresh rate. If you’re playing at 250 fps, that means it can deliver a perceived effective motion clarity of over 1,000 Hz. That enables easier tracking and shooting in-game, making displays with the technology especially suited for esports. You can see the difference in motion in Counter-Strike 2 between a 360Hz monitor without G-Sync Pulsar and one with the technology switched on in the video below. The first four displays designed specifically to support G-Sync Pulsar and Ambient Adaptive Technology, which allows users to automatically adjust color temperature and brightness based on ambient lighting, will be available starting on January 7. Acer, AOC, ASUS and MSI will each be releasing a 27-inch 2,560 × 1,440 IPS display, which comes with a 360Hz refresh rate and 500 nits of peak brightness in HDR.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/nvidias-g-sync-pulsar-tech-can-minimize-motion-blur-for-gamers-140000058.html?src=rss",
          "content": "NVIDIA has unveiled the G-Sync Pulsar, which it calls the “latest evolution of [its] pioneering VRR (variable refresh rate) technology,” at CES 2026. The new tech promises a gaming experience that’s free of stutter with buttery smooth motion, which is made possible by pulsing the display’s backlight. G-Sync Pulsar displays have multiple horizontal backlight sections that are pulsed independently from top to bottom, unlike traditional displays whose backlight is always on. When the backlight is always active, the image fades from one frame to the next. The displays with the new tech give pixels in a frame enough time to stabilize before they’re backlit so that they’re shown in their right locations, effectively reducing monitor-based motion blur. The company says G-Sync Pulsar can effectively quadruple your refresh rate. If you’re playing at 250 fps, that means it can deliver a perceived effective motion clarity of over 1,000 Hz. That enables easier tracking and shooting in-game, making displays with the technology especially suited for esports. You can see the difference in motion in Counter-Strike 2 between a 360Hz monitor without G-Sync Pulsar and one with the technology switched on in the video below. The first four displays designed specifically to support G-Sync Pulsar and Ambient Adaptive Technology, which allows users to automatically adjust color temperature and brightness based on ambient lighting, will be available starting on January 7. Acer, AOC, ASUS and MSI will each be releasing a 27-inch 2,560 × 1,440 IPS display, which comes with a 360Hz refresh rate and 500 nits of peak brightness in HDR.This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/nvidias-g-sync-pulsar-tech-can-minimize-motion-blur-for-gamers-140000058.html?src=rss",
          "feed_position": 47
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/artificial-analysis-overhauls-its-ai-intelligence-index-replacing-popular",
          "published_at": "Tue, 06 Jan 2026 10:30:00 GMT",
          "title": "Artificial Analysis overhauls its AI Intelligence Index, replacing popular benchmarks with 'real-world' tests",
          "standfirst": "The arms race to build smarter AI models has a measurement problem: the tests used to rank them are becoming obsolete almost as quickly as the models improve. On Monday, Artificial Analysis, an independent AI benchmarking organization whose rankings are closely watched by developers and enterprise buyers, released a major overhaul to its Intelligence Index that fundamentally changes how the industry measures AI progress.The new Intelligence Index v4.0 incorporates 10 evaluations spanning agents, coding, scientific reasoning, and general knowledge. But the changes go far deeper than shuffling test names. The organization removed three staple benchmarks — MMLU-Pro, AIME 2025, and LiveCodeBench — that have long been cited by AI companies in their marketing materials. In their place, the new index introduces evaluations designed to measure whether AI systems can complete the kind of work that people actually get paid to do.type: embedded-entry-inline id: 1bCmRrroGCdUb07IuaHysL\"This index shift reflects a broader transition: intelligence is being measured less by recall and more by economically useful action,\" observed Aravind Sundar, a researcher who responded to the announcement on X (formerly Twitter).Why AI benchmarks are breaking: The problem with tests that top models have already masteredThe benchmark overhaul addresses a growing crisis in AI evaluation: the leading models have become so capable that traditional tests can no longer meaningfully differentiate between them. The new index deliberately makes the curve harder to climb. According to Artificial Analysis, top models now score 50 or below on the new v4.0 scale, compared to 73 on the previous version — a recalibration designed to restore headroom for future improvement.This saturation problem has plagued the industry for months. When every frontier model scores in the 90th percentile on a given test, the test loses its usefulness as a decision-making tool for enterprises trying to choose which AI system to deploy. The new methodology attempts to solve this by weighting four categories equally — Agents, Coding, Scientific Reasoning, and Genera l— while introducing evaluations where even the most advanced systems still struggle.The results under the new framework show OpenAI&#x27;s GPT-5.2 with extended reasoning effort claiming the top spot, followed closely by Anthropic&#x27;s Claude Opus 4.5 and Google&#x27;s Gemini 3 Pro. OpenAI describes GPT-5.2 as \"the most capable model series yet for professional knowledge work,\" while Anthropic&#x27;s Claude Opus 4.5 scores higher than GPT-5.2 on SWE-Bench Verified, a test set evaluating software coding abilities.GDPval-AA: The new benchmark testing whether AI can do your jobThe most significant addition to the new index is GDPval-AA, an evaluation based on OpenAI&#x27;s GDPval dataset that tests AI models on real-world economically valuable tasks across 44 occupations and 9 major industries. Unlike traditional benchmarks that ask models to solve abstract math problems or answer multiple-choice trivia, GDPval-AA measures whether AI can produce the deliverables that professionals actually create: documents, slides, diagrams, spreadsheets, and multimedia content.Models receive shell access and web browsing capabilities through what Artificial Analysis calls \"Stirrup,\" its reference agentic harness. Scores are derived from blind pairwise comparisons, with ELO ratings frozen at the time of evaluation to ensure index stability.Under this framework, OpenAI&#x27;s GPT-5.2 with extended reasoning leads with an ELO score of 1442, while Anthropic&#x27;s Claude Opus 4.5 non-thinking variant follows at 1403. Claude Sonnet 4.5 trails at 1259.On the original GDPval evaluation, GPT-5.2 beat or tied top industry professionals on 70.9% of well-specified tasks, according to OpenAI. The company claims GPT-5.2 \"outperforms industry professionals at well-specified knowledge work tasks spanning 44 occupations,\" with companies including Notion, Box, Shopify, Harvey, and Zoom observing \"state-of-the-art long-horizon reasoning and tool-calling performance.\"The emphasis on economically measurable output is a philosophical shift in how the industry thinks about AI capability. Rather than asking whether a model can pass a bar exam or solve competition math problems — achievements that generate headlines but don&#x27;t necessarily translate to workplace productivity — the new benchmarks ask whether AI can actually do jobs.Graduate-level physics problems expose the limits of today&#x27;s most advanced AI modelsWhile GDPval-AA measures practical productivity, another new evaluation called CritPT reveals just how far AI systems remain from true scientific reasoning. The benchmark tests language models on unpublished, research-level reasoning tasks across modern physics, including condensed matter, quantum physics, and astrophysics.CritPT was developed by more than 50 active physics researchers from over 30 leading institutions. Its 71 composite research challenges simulate full-scale research projects at the entry level — comparable to the warm-up exercises a hands-on principal investigator might assign to junior graduate students. Every problem is hand-curated to produce a guess-resistant, machine-verifiable answer.The results are sobering. Current state-of-the-art models remain far from reliably solving full research-scale challenges. GPT-5.2 with extended reasoning leads the CritPT leaderboard with a score of just 11.5%, followed by Google&#x27;s Gemini 3 Pro Preview and Anthropic&#x27;s Claude 4.5 Opus Thinking variant. These scores suggest that despite remarkable progress on consumer-facing tasks, AI systems still struggle with the kind of deep reasoning required for scientific discovery.AI hallucination rates: Why the most accurate models aren&#x27;t always the most trustworthyPerhaps the most revealing new evaluation is AA-Omniscience, which measures factual recall and hallucination across 6,000 questions covering 42 economically relevant topics within six domains: Business, Health, Law, Software Engineering, Humanities & Social Sciences, and Science/Engineering/Mathematics.The evaluation produces an Omniscience Index that rewards precise knowledge while penalizing hallucinated responses — providing insight into whether a model can distinguish what it knows from what it doesn&#x27;t. The findings expose an uncomfortable truth: high accuracy does not guarantee low hallucination. Models with the highest accuracy often fail to lead on the Omniscience Index because they tend to guess rather than abstain when uncertain.Google&#x27;s Gemini 3 Pro Preview leads the Omniscience Index with a score of 13, followed by Claude Opus 4.5 Thinking and Gemini 3 Flash Reasoning, both at 10. However, the breakdown between accuracy and hallucination rates reveals a more complex picture.On raw accuracy, Google&#x27;s two models lead with scores of 54% and 51% respectively, followed by Claude 4.5 Opus Thinking at 43%. But Google&#x27;s models also demonstrate higher hallucination rates than peer models, scoring 88% and 85%. Anthropic&#x27;s Claude 4.5 Sonnet Thinking and Claude Opus 4.5 Thinking show hallucination rates of 48% and 58% respectively, while GPT-5.1 with high reasoning effort achieves 51%—the second-lowest hallucination rate tested.Both Omniscience Accuracy and Hallucination Rate contribute 6.25% weighting each to the overall Intelligence Index v4.Inside the AI arms race: How OpenAI, Google, and Anthropic stack up under new testingThe benchmark reshuffling arrives at an especially turbulent moment in the AI industry. All three leading frontier model developers have launched major new models within just a few weeks — and Gemini 3 still holds the top spot on much of the leaderboards on LMArena, a widely cited benchmarking tool used to compare LLMs.Google&#x27;s November release of Gemini 3 prompted OpenAI to declare a \"code red\" effort to improve ChatGPT. OpenAI is counting on its GPT family of models to justify its $500 billion valuation and over $1.4 trillion in planned spending. \"We announced this code red to really signal to the company that we want to marshal resources in one particular area,\" said Fidji Simo, CEO of applications at OpenAI. Altman told CNBC he expected OpenAI to exit its code red by January.Anthropic responded with Claude Opus 4.5 on November 24, achieving an SWE-Bench Verified accuracy score of 80.9% — reclaiming the coding crown from both GPT-5.1-Codex-Max and Gemini 3. The launch marked Anthropic&#x27;s third major model release in two months. Microsoft and Nvidia have since announced multi-billion-dollar investments in Anthropic, boosting its valuation to about $350 billion.How Artificial Analysis tests AI models: A look at the independent benchmarking processArtificial Analysis emphasizes that all evaluations are run independently using a standardized methodology. The organization states that its \"methodology emphasizes fairness and real-world applicability,\" estimating a 95% confidence interval for the Intelligence Index of less than ±1% based on experiments with more than 10 repeats on certain models.The organization&#x27;s published methodology defines key terms that enterprise buyers should understand. According to the methodology documentation, Artificial Analysis considers an \"endpoint\" to be a hosted instance of a model accessible via an API — meaning a single model may have multiple endpoints across different providers. A \"provider\" is a company that hosts and provides access to one or more model endpoints or systems. Critically, Artificial Analysis distinguishes between \"open weights\" models, whose weights have been released publicly, and truly open-source models—noting that many open LLMs have been released with licenses that do not meet the full definition of open-source software.The methodology also clarifies how the organization standardizes token measurement: it uses OpenAI tokens as measured with OpenAI&#x27;s tiktoken package as a standard unit across all providers to enable fair comparisons.What the new AI Intelligence Index means for enterprise technology decisions in 2026For technical decision-makers evaluating AI systems, the Intelligence Index v4.0 provides a more nuanced picture of capability than previous benchmark compilations. The equal weighting across agents, coding, scientific reasoning, and general knowledge means that enterprises with specific use cases may want to examine category-specific scores rather than relying solely on the aggregate index.The introduction of hallucination measurement as a distinct, weighted factor addresses one of the most persistent concerns in enterprise AI adoption. A model that appears highly accurate but frequently hallucinates when uncertain poses significant risks in regulated industries like healthcare, finance, and law.The Artificial Analysis Intelligence Index is described as \"a text-only, English language evaluation suite.\" The organization benchmarks models for image inputs, speech inputs, and multilingual performance separately.The response to the announcement has been largely positive. \"It is great to see the index evolving to reduce saturation and focus more on agentic performance,\" wrote one commenter in an X.com post. \"Including real-world tasks like GDPval-AA makes the scores much more relevant for practical use.\"Others struck a more ambitious note. \"The new wave of models that is just about to come will leave them all behind,\" predicted one observer. \"By the end of the year the singularity will be undeniable.\"But whether that prediction proves prophetic or premature, one thing is already clear: the era of judging AI by how well it answers test questions is ending. The new standard is simpler and far more consequential — can it do the work?",
          "content": "The arms race to build smarter AI models has a measurement problem: the tests used to rank them are becoming obsolete almost as quickly as the models improve. On Monday, Artificial Analysis, an independent AI benchmarking organization whose rankings are closely watched by developers and enterprise buyers, released a major overhaul to its Intelligence Index that fundamentally changes how the industry measures AI progress.The new Intelligence Index v4.0 incorporates 10 evaluations spanning agents, coding, scientific reasoning, and general knowledge. But the changes go far deeper than shuffling test names. The organization removed three staple benchmarks — MMLU-Pro, AIME 2025, and LiveCodeBench — that have long been cited by AI companies in their marketing materials. In their place, the new index introduces evaluations designed to measure whether AI systems can complete the kind of work that people actually get paid to do.type: embedded-entry-inline id: 1bCmRrroGCdUb07IuaHysL\"This index shift reflects a broader transition: intelligence is being measured less by recall and more by economically useful action,\" observed Aravind Sundar, a researcher who responded to the announcement on X (formerly Twitter).Why AI benchmarks are breaking: The problem with tests that top models have already masteredThe benchmark overhaul addresses a growing crisis in AI evaluation: the leading models have become so capable that traditional tests can no longer meaningfully differentiate between them. The new index deliberately makes the curve harder to climb. According to Artificial Analysis, top models now score 50 or below on the new v4.0 scale, compared to 73 on the previous version — a recalibration designed to restore headroom for future improvement.This saturation problem has plagued the industry for months. When every frontier model scores in the 90th percentile on a given test, the test loses its usefulness as a decision-making tool for enterprises trying to choose which AI system to deploy. The new methodology attempts to solve this by weighting four categories equally — Agents, Coding, Scientific Reasoning, and Genera l— while introducing evaluations where even the most advanced systems still struggle.The results under the new framework show OpenAI&#x27;s GPT-5.2 with extended reasoning effort claiming the top spot, followed closely by Anthropic&#x27;s Claude Opus 4.5 and Google&#x27;s Gemini 3 Pro. OpenAI describes GPT-5.2 as \"the most capable model series yet for professional knowledge work,\" while Anthropic&#x27;s Claude Opus 4.5 scores higher than GPT-5.2 on SWE-Bench Verified, a test set evaluating software coding abilities.GDPval-AA: The new benchmark testing whether AI can do your jobThe most significant addition to the new index is GDPval-AA, an evaluation based on OpenAI&#x27;s GDPval dataset that tests AI models on real-world economically valuable tasks across 44 occupations and 9 major industries. Unlike traditional benchmarks that ask models to solve abstract math problems or answer multiple-choice trivia, GDPval-AA measures whether AI can produce the deliverables that professionals actually create: documents, slides, diagrams, spreadsheets, and multimedia content.Models receive shell access and web browsing capabilities through what Artificial Analysis calls \"Stirrup,\" its reference agentic harness. Scores are derived from blind pairwise comparisons, with ELO ratings frozen at the time of evaluation to ensure index stability.Under this framework, OpenAI&#x27;s GPT-5.2 with extended reasoning leads with an ELO score of 1442, while Anthropic&#x27;s Claude Opus 4.5 non-thinking variant follows at 1403. Claude Sonnet 4.5 trails at 1259.On the original GDPval evaluation, GPT-5.2 beat or tied top industry professionals on 70.9% of well-specified tasks, according to OpenAI. The company claims GPT-5.2 \"outperforms industry professionals at well-specified knowledge work tasks spanning 44 occupations,\" with companies including Notion, Box, Shopify, Harvey, and Zoom observing \"state-of-the-art long-horizon reasoning and tool-calling performance.\"The emphasis on economically measurable output is a philosophical shift in how the industry thinks about AI capability. Rather than asking whether a model can pass a bar exam or solve competition math problems — achievements that generate headlines but don&#x27;t necessarily translate to workplace productivity — the new benchmarks ask whether AI can actually do jobs.Graduate-level physics problems expose the limits of today&#x27;s most advanced AI modelsWhile GDPval-AA measures practical productivity, another new evaluation called CritPT reveals just how far AI systems remain from true scientific reasoning. The benchmark tests language models on unpublished, research-level reasoning tasks across modern physics, including condensed matter, quantum physics, and astrophysics.CritPT was developed by more than 50 active physics researchers from over 30 leading institutions. Its 71 composite research challenges simulate full-scale research projects at the entry level — comparable to the warm-up exercises a hands-on principal investigator might assign to junior graduate students. Every problem is hand-curated to produce a guess-resistant, machine-verifiable answer.The results are sobering. Current state-of-the-art models remain far from reliably solving full research-scale challenges. GPT-5.2 with extended reasoning leads the CritPT leaderboard with a score of just 11.5%, followed by Google&#x27;s Gemini 3 Pro Preview and Anthropic&#x27;s Claude 4.5 Opus Thinking variant. These scores suggest that despite remarkable progress on consumer-facing tasks, AI systems still struggle with the kind of deep reasoning required for scientific discovery.AI hallucination rates: Why the most accurate models aren&#x27;t always the most trustworthyPerhaps the most revealing new evaluation is AA-Omniscience, which measures factual recall and hallucination across 6,000 questions covering 42 economically relevant topics within six domains: Business, Health, Law, Software Engineering, Humanities & Social Sciences, and Science/Engineering/Mathematics.The evaluation produces an Omniscience Index that rewards precise knowledge while penalizing hallucinated responses — providing insight into whether a model can distinguish what it knows from what it doesn&#x27;t. The findings expose an uncomfortable truth: high accuracy does not guarantee low hallucination. Models with the highest accuracy often fail to lead on the Omniscience Index because they tend to guess rather than abstain when uncertain.Google&#x27;s Gemini 3 Pro Preview leads the Omniscience Index with a score of 13, followed by Claude Opus 4.5 Thinking and Gemini 3 Flash Reasoning, both at 10. However, the breakdown between accuracy and hallucination rates reveals a more complex picture.On raw accuracy, Google&#x27;s two models lead with scores of 54% and 51% respectively, followed by Claude 4.5 Opus Thinking at 43%. But Google&#x27;s models also demonstrate higher hallucination rates than peer models, scoring 88% and 85%. Anthropic&#x27;s Claude 4.5 Sonnet Thinking and Claude Opus 4.5 Thinking show hallucination rates of 48% and 58% respectively, while GPT-5.1 with high reasoning effort achieves 51%—the second-lowest hallucination rate tested.Both Omniscience Accuracy and Hallucination Rate contribute 6.25% weighting each to the overall Intelligence Index v4.Inside the AI arms race: How OpenAI, Google, and Anthropic stack up under new testingThe benchmark reshuffling arrives at an especially turbulent moment in the AI industry. All three leading frontier model developers have launched major new models within just a few weeks — and Gemini 3 still holds the top spot on much of the leaderboards on LMArena, a widely cited benchmarking tool used to compare LLMs.Google&#x27;s November release of Gemini 3 prompted OpenAI to declare a \"code red\" effort to improve ChatGPT. OpenAI is counting on its GPT family of models to justify its $500 billion valuation and over $1.4 trillion in planned spending. \"We announced this code red to really signal to the company that we want to marshal resources in one particular area,\" said Fidji Simo, CEO of applications at OpenAI. Altman told CNBC he expected OpenAI to exit its code red by January.Anthropic responded with Claude Opus 4.5 on November 24, achieving an SWE-Bench Verified accuracy score of 80.9% — reclaiming the coding crown from both GPT-5.1-Codex-Max and Gemini 3. The launch marked Anthropic&#x27;s third major model release in two months. Microsoft and Nvidia have since announced multi-billion-dollar investments in Anthropic, boosting its valuation to about $350 billion.How Artificial Analysis tests AI models: A look at the independent benchmarking processArtificial Analysis emphasizes that all evaluations are run independently using a standardized methodology. The organization states that its \"methodology emphasizes fairness and real-world applicability,\" estimating a 95% confidence interval for the Intelligence Index of less than ±1% based on experiments with more than 10 repeats on certain models.The organization&#x27;s published methodology defines key terms that enterprise buyers should understand. According to the methodology documentation, Artificial Analysis considers an \"endpoint\" to be a hosted instance of a model accessible via an API — meaning a single model may have multiple endpoints across different providers. A \"provider\" is a company that hosts and provides access to one or more model endpoints or systems. Critically, Artificial Analysis distinguishes between \"open weights\" models, whose weights have been released publicly, and truly open-source models—noting that many open LLMs have been released with licenses that do not meet the full definition of open-source software.The methodology also clarifies how the organization standardizes token measurement: it uses OpenAI tokens as measured with OpenAI&#x27;s tiktoken package as a standard unit across all providers to enable fair comparisons.What the new AI Intelligence Index means for enterprise technology decisions in 2026For technical decision-makers evaluating AI systems, the Intelligence Index v4.0 provides a more nuanced picture of capability than previous benchmark compilations. The equal weighting across agents, coding, scientific reasoning, and general knowledge means that enterprises with specific use cases may want to examine category-specific scores rather than relying solely on the aggregate index.The introduction of hallucination measurement as a distinct, weighted factor addresses one of the most persistent concerns in enterprise AI adoption. A model that appears highly accurate but frequently hallucinates when uncertain poses significant risks in regulated industries like healthcare, finance, and law.The Artificial Analysis Intelligence Index is described as \"a text-only, English language evaluation suite.\" The organization benchmarks models for image inputs, speech inputs, and multilingual performance separately.The response to the announcement has been largely positive. \"It is great to see the index evolving to reduce saturation and focus more on agentic performance,\" wrote one commenter in an X.com post. \"Including real-world tasks like GDPval-AA makes the scores much more relevant for practical use.\"Others struck a more ambitious note. \"The new wave of models that is just about to come will leave them all behind,\" predicted one observer. \"By the end of the year the singularity will be undeniable.\"But whether that prediction proves prophetic or premature, one thing is already clear: the era of judging AI by how well it answers test questions is ending. The new standard is simpler and far more consequential — can it do the work?",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/32qTcRzFDG1fc0szkgy7MZ/b52b9c93b0dfc85fa3380484c507e7c6/nuneybits_Vector_art_of_a_bar_chart_96738835-73bf-4231-a878-4dcdc76e73f6.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/new-test-time-training-method-lets-ai-keep-learning-without-exploding",
          "published_at": "Tue, 06 Jan 2026 00:00:00 GMT",
          "title": "New ‘Test-Time Training’ method lets AI keep learning without exploding inference costs",
          "standfirst": "A new study from researchers at Stanford University and Nvidia proposes a way for AI models to keep learning after deployment — without increasing inference costs. For enterprise agents that have to digest long docs, tickets, and logs, this is a bid to get “long memory” without paying attention costs that grow with context length.The approach, called “End-to-End Test-Time Training” (TTT-E2E), reframes language modeling as a continual learning problem: Instead of memorizing facts during pre-training, models learn how to adapt in real time as they process new information.The result is a Transformer that can match long-context accuracy of full attention models while running at near-RNN efficiency — a potential breakthrough for enterprise workloads where context length is colliding with cost.The accuracy-efficiency trade-offFor developers building AI systems for long-document tasks, the choice of model architecture often involves a painful trade-off between accuracy and efficiency.On one side are Transformers with full self-attention, currently the gold standard for accuracy. They are designed to scan through the keys and values of all previous tokens for every new token generated, providing them with lossless recall. However, this precision comes at a steep cost: The computational cost per token grows significantly with context length. On the other side are linear-time sequence models, which keep inference costs constant but struggle to retain information over very long contexts. Other approaches try to split the difference — sliding-window attention, hybrids that mix attention with recurrence, and other efficiency tricks — but they still tend to fall short of full attention on hard language modeling.The researchers’ bet is that the missing ingredient is compression: Instead of trying to recall every token exactly, models should distill what matters into a compact state.Test-Time TrainingThe core innovation of the paper is the application of Test-Time Training (TTT) to language modeling. This transforms the model from a static database into a flexible learner.In standard AI deployment, models are trained to minimize loss and then deployed as frozen artifacts. If you try to make a static model learn during deployment, it typically performs poorly because it was never trained to update itself efficiently.The researchers solve this by shifting from standard pre-training (teaching the model facts) to meta-learning (teaching the model how to learn). The goal is to optimize the model’s \"initialization\" so that it can absorb new information rapidly when it goes live. The process involves simulating inference-time learning during the training phase:Inner loop (learn): During training, the model treats text as a stream and performs small, temporary updates as it predicts the next token — simulating how it would adapt at inference.Outer loop (teach it to learn): The system then updates the model’s initialization so the next round of streaming adaptation becomes faster and more accurate.While the idea of a model changing its weights during deployment might sound risky to reliability focused enterprise leaders, co-author Yu Sun argues it is mathematically safer than it appears.“You should think of the model as an RNN with a huge hidden state,” Sun says. He notes that if an enterprise feels safe deploying standard Transformers or RNNs, the stability profile of TTT is comparable.Dual-memory architectureTo implement TTT-E2E, the researchers modified the standard Transformer architecture to support this new learning paradigm, creating a hierarchy that separates cheap short-term context handling from selective long-term memory updates.The model uses Sliding Window Attention rather than full attention. This acts as the model&#x27;s \"working memory,\" looking back only at a fixed window of recent tokens to handle immediate syntax and local references. This ensures the cost of processing a new token remains constant rather than growing as the context expands.The model employs “targeted weight updates.” While standard models have completely frozen weights during use, TTT-E2E designates specific sections (Multi-Layer Perceptron layers in the final 25% of the model&#x27;s blocks) to be mutable.The architecture uses a “dual-track storage” to prevent the model from forgetting its general training while learning a new document. Each updateable block contains two MLP components: one static layer that holds general pre-trained knowledge, and one dynamic layer that updates in real-time to store the current document&#x27;s context.The innovation lies in how the model handles information that falls out of the sliding window. In a standard sliding window model, once a token slides out of view, it is forgotten. TTT-E2E prevents this via compression. As the window moves, the model uses next-token prediction to \"compress\" the passing information directly into the weights of the dynamic MLP layers. This consolidates the gist and facts of the earlier parts of the document into the model&#x27;s structure, serving as a long-term memory.TTT-E2E in actionThe headline result: TTT-E2E continues improving as context length grows — matching or outperforming full attention — while efficient baselines plateau after ~32,000 tokens.To validate their approach, the researchers trained models ranging from 125 million to 3 billion parameters. They employed a two-stage training process: pre-training on 8,000-token contexts and fine-tuning on 128,000-token contexts. These models were tested against robust baselines, including Transformers with full attention, Transformers with Sliding Window Attention (SWA), hybrid models (Mamba 2 and Gated DeltaNet), and TTT-KVB (an earlier form of test-time training).The results highlight a significant breakthrough in scaling. The most critical experiment tested performance as the input document grew from 8,000 to 128,000 tokens. The Full Attention Transformer, the gold standard, continued to improve its performance (lower loss) as the context grew. In contrast, efficient baselines like Mamba 2, Gated DeltaNet, and SWA hit a ceiling, with their performance degrading or flattening out after 32,000 tokens.The new TTT-E2E method successfully scaled with context length, mimicking the behavior of Full Attention. In the experiments using 3B parameter models, TTT-E2E actually maintained a lower perplexity (better performance) than Full Attention throughout the context window.Critically, this performance did not come at the cost of speed. On inference latency, TTT-E2E matched the efficiency of RNNs. At a context length of 128k tokens, TTT-E2E was 2.7x faster than the Full-Attention Transformer on Nvidia H100 hardware.Crucially for adoption, Sun notes that TTT models can be deployed for inference today on standard Transformer infrastructure to achieve these speedups. However, he cautions that the training side of the equation (specifically the outer loop) is currently more complex and slower than standard methods, representing a hurdle that still needs engineering optimization.The benefits become even more drastic as data scales. Sun argues the advantage should widen further at million-token contexts, though those figures are projections rather than today’s benchmarked deployments.However, the approach does have specific limitations rooted in its design philosophy. The researchers performed a \"Needle in a Haystack\" test, which requires the model to retrieve a specific, isolated piece of information (like a passcode) hidden in a large block of text. In this evaluation, Full Attention dramatically outperformed all other methods, including TTT-E2E.This is because Full Attention relies on a cache that allows for nearly lossless recall of specific details, whereas TTT-E2E relies on compression. Compression captures the intuition and core information perfectly but may lose specific, random details that do not fit the learned patterns.This distinction has major implications for enterprise data pipelines, specifically RAG. Sun suggests that TTT won&#x27;t make RAG obsolete but will redefine it. He likens TTT to \"updating the human brain\" with general knowledge, while RAG will remain a necessary tool for precision, \"similar to how humans still need to write things down in a notepad.\" For enterprise teams, the takeaway is that TTT reduces how often you need retrieval — but doesn’t eliminate the need for exact external memory.While the technique was demonstrated on the Transformer architecture, the researchers note that “in principle, TTT can be applied to any baseline architecture” that allows for a separation of long-term and short-term memory components.“We believe that these two classes of memory will continue to complement each other,\" the researchers concluded. Looking ahead, Sun predicts a paradigm shift where the primary form of AI memory will be highly compressed rather than exact. While models will retain a \"reasonable\" perfect-recall window of around 128,000 tokens, he believes TTT architectures will eventually unlock a \"compressed memory of billions of tokens,\" fundamentally changing how enterprise agents balance recall, cost, and context length.",
          "content": "A new study from researchers at Stanford University and Nvidia proposes a way for AI models to keep learning after deployment — without increasing inference costs. For enterprise agents that have to digest long docs, tickets, and logs, this is a bid to get “long memory” without paying attention costs that grow with context length.The approach, called “End-to-End Test-Time Training” (TTT-E2E), reframes language modeling as a continual learning problem: Instead of memorizing facts during pre-training, models learn how to adapt in real time as they process new information.The result is a Transformer that can match long-context accuracy of full attention models while running at near-RNN efficiency — a potential breakthrough for enterprise workloads where context length is colliding with cost.The accuracy-efficiency trade-offFor developers building AI systems for long-document tasks, the choice of model architecture often involves a painful trade-off between accuracy and efficiency.On one side are Transformers with full self-attention, currently the gold standard for accuracy. They are designed to scan through the keys and values of all previous tokens for every new token generated, providing them with lossless recall. However, this precision comes at a steep cost: The computational cost per token grows significantly with context length. On the other side are linear-time sequence models, which keep inference costs constant but struggle to retain information over very long contexts. Other approaches try to split the difference — sliding-window attention, hybrids that mix attention with recurrence, and other efficiency tricks — but they still tend to fall short of full attention on hard language modeling.The researchers’ bet is that the missing ingredient is compression: Instead of trying to recall every token exactly, models should distill what matters into a compact state.Test-Time TrainingThe core innovation of the paper is the application of Test-Time Training (TTT) to language modeling. This transforms the model from a static database into a flexible learner.In standard AI deployment, models are trained to minimize loss and then deployed as frozen artifacts. If you try to make a static model learn during deployment, it typically performs poorly because it was never trained to update itself efficiently.The researchers solve this by shifting from standard pre-training (teaching the model facts) to meta-learning (teaching the model how to learn). The goal is to optimize the model’s \"initialization\" so that it can absorb new information rapidly when it goes live. The process involves simulating inference-time learning during the training phase:Inner loop (learn): During training, the model treats text as a stream and performs small, temporary updates as it predicts the next token — simulating how it would adapt at inference.Outer loop (teach it to learn): The system then updates the model’s initialization so the next round of streaming adaptation becomes faster and more accurate.While the idea of a model changing its weights during deployment might sound risky to reliability focused enterprise leaders, co-author Yu Sun argues it is mathematically safer than it appears.“You should think of the model as an RNN with a huge hidden state,” Sun says. He notes that if an enterprise feels safe deploying standard Transformers or RNNs, the stability profile of TTT is comparable.Dual-memory architectureTo implement TTT-E2E, the researchers modified the standard Transformer architecture to support this new learning paradigm, creating a hierarchy that separates cheap short-term context handling from selective long-term memory updates.The model uses Sliding Window Attention rather than full attention. This acts as the model&#x27;s \"working memory,\" looking back only at a fixed window of recent tokens to handle immediate syntax and local references. This ensures the cost of processing a new token remains constant rather than growing as the context expands.The model employs “targeted weight updates.” While standard models have completely frozen weights during use, TTT-E2E designates specific sections (Multi-Layer Perceptron layers in the final 25% of the model&#x27;s blocks) to be mutable.The architecture uses a “dual-track storage” to prevent the model from forgetting its general training while learning a new document. Each updateable block contains two MLP components: one static layer that holds general pre-trained knowledge, and one dynamic layer that updates in real-time to store the current document&#x27;s context.The innovation lies in how the model handles information that falls out of the sliding window. In a standard sliding window model, once a token slides out of view, it is forgotten. TTT-E2E prevents this via compression. As the window moves, the model uses next-token prediction to \"compress\" the passing information directly into the weights of the dynamic MLP layers. This consolidates the gist and facts of the earlier parts of the document into the model&#x27;s structure, serving as a long-term memory.TTT-E2E in actionThe headline result: TTT-E2E continues improving as context length grows — matching or outperforming full attention — while efficient baselines plateau after ~32,000 tokens.To validate their approach, the researchers trained models ranging from 125 million to 3 billion parameters. They employed a two-stage training process: pre-training on 8,000-token contexts and fine-tuning on 128,000-token contexts. These models were tested against robust baselines, including Transformers with full attention, Transformers with Sliding Window Attention (SWA), hybrid models (Mamba 2 and Gated DeltaNet), and TTT-KVB (an earlier form of test-time training).The results highlight a significant breakthrough in scaling. The most critical experiment tested performance as the input document grew from 8,000 to 128,000 tokens. The Full Attention Transformer, the gold standard, continued to improve its performance (lower loss) as the context grew. In contrast, efficient baselines like Mamba 2, Gated DeltaNet, and SWA hit a ceiling, with their performance degrading or flattening out after 32,000 tokens.The new TTT-E2E method successfully scaled with context length, mimicking the behavior of Full Attention. In the experiments using 3B parameter models, TTT-E2E actually maintained a lower perplexity (better performance) than Full Attention throughout the context window.Critically, this performance did not come at the cost of speed. On inference latency, TTT-E2E matched the efficiency of RNNs. At a context length of 128k tokens, TTT-E2E was 2.7x faster than the Full-Attention Transformer on Nvidia H100 hardware.Crucially for adoption, Sun notes that TTT models can be deployed for inference today on standard Transformer infrastructure to achieve these speedups. However, he cautions that the training side of the equation (specifically the outer loop) is currently more complex and slower than standard methods, representing a hurdle that still needs engineering optimization.The benefits become even more drastic as data scales. Sun argues the advantage should widen further at million-token contexts, though those figures are projections rather than today’s benchmarked deployments.However, the approach does have specific limitations rooted in its design philosophy. The researchers performed a \"Needle in a Haystack\" test, which requires the model to retrieve a specific, isolated piece of information (like a passcode) hidden in a large block of text. In this evaluation, Full Attention dramatically outperformed all other methods, including TTT-E2E.This is because Full Attention relies on a cache that allows for nearly lossless recall of specific details, whereas TTT-E2E relies on compression. Compression captures the intuition and core information perfectly but may lose specific, random details that do not fit the learned patterns.This distinction has major implications for enterprise data pipelines, specifically RAG. Sun suggests that TTT won&#x27;t make RAG obsolete but will redefine it. He likens TTT to \"updating the human brain\" with general knowledge, while RAG will remain a necessary tool for precision, \"similar to how humans still need to write things down in a notepad.\" For enterprise teams, the takeaway is that TTT reduces how often you need retrieval — but doesn’t eliminate the need for exact external memory.While the technique was demonstrated on the Transformer architecture, the researchers note that “in principle, TTT can be applied to any baseline architecture” that allows for a separation of long-term and short-term memory components.“We believe that these two classes of memory will continue to complement each other,\" the researchers concluded. Looking ahead, Sun predicts a paradigm shift where the primary form of AI memory will be highly compressed rather than exact. While models will retain a \"reasonable\" perfect-recall window of around 128,000 tokens, he believes TTT architectures will eventually unlock a \"compressed memory of billions of tokens,\" fundamentally changing how enterprise agents balance recall, cost, and context length.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/ajTBnP0XOPzBgpIXpo0D0/cbda5f89ad3db322e1c211f237b1c2af/Continual_learning.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/tiis-falcon-h1r-7b-can-out-reason-models-up-to-7x-its-size-and-its-mostly",
          "published_at": "Mon, 05 Jan 2026 20:27:00 GMT",
          "title": "TII’s Falcon H1R 7B can out-reason models up to 7x its size — and it’s (mostly) open",
          "standfirst": "For the last two years, the prevailing logic in generative AI has been one of brute force: if you want better reasoning, you need a bigger model. While \"small\" models (under 10 billion parameters) have become capable conversationalists, they have historically crumbled when asked to perform multi-step logical deduction or complex mathematical proofs.Today, the Technology Innovation Institute (TII) in Abu Dhabi is challenging that scaling law with the release of Falcon H1R 7B. By abandoning the pure Transformer orthodoxy in favor of a hybrid architecture, TII claims to have built a 7-billion parameter model that not only rivals but outperforms competitors nearly 7X its size — including the 32B and 47B variants of Alibaba&#x27;s Qwen and Nvidia&#x27;s Nemotron.The release marks a significant shift in the open-weight ecosystem, moving the battleground from raw parameter count to architectural efficiency and inference-time scaling.The full model code is available now at Hugging Face and can be tested by individuals in a live demo inference on Falcon Chat (a chatbot experience). TII further released a seemingly quite comprehensive technical report on the approach and training methodology for Falcon H1 7B, as well. Moving Beyond the Foundational LLM Tech, the TransformerThe defining feature of Falcon H1R 7B is its \"hybrid\" backbone. Most modern LLMs rely exclusively on the Transformer architecture, which scales predictably but suffers from high memory costs when processing long sequences. Falcon H1R 7B integrates Mamba, a state-space model (SSM) architecture, alongside standard Transformer attention layers.Originally developed by researchers Albert Gu and Tri Dao at Carnegie Mellon University and Princeton University, Mamba was first introduced in the paper \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\" published on December 1, 2023.The architecture processes data sequences differently than Transformers: while Transformers compare every piece of data to every other piece (quadratic scaling), Mamba processes tokens sequentially, allowing it to handle vast amounts of information with linear scaling and significantly reduced compute costs.This combination addresses one of the most persistent bottlenecks in deploying reasoning models: the cost of \"thinking.\" Reasoning models require generating long \"chains of thought\"—step-by-step internal monologues—before arriving at an answer. For standard Transformers, these long contexts explode computational costs.According to TII’s technical report, the hybrid approach allows Falcon H1R 7B to maintain high throughput even as response lengths grow. At a batch size of 64, the model processes approximately 1,500 tokens per second per GPU—nearly double the speed of the competing Qwen3 8B model.Benchmark Performance: Punching UpIn the benchmarks released by TII, the disparity between Falcon H1R 7B’s size and its performance is stark. On the AIME 2025 leaderboard—a rigorous test of mathematical reasoning—Falcon H1R 7B scored 83.1%, a result that disrupts the traditional hierarchy of model sizing.While the 7B model naturally trails massive proprietary frontiers like GPT-5.2 (99.0%) and Gemini 3 Flash (97.0%) on the separate Artificial Analysis index (run by the independent organization of the same name, which has not yet benchmarked Falcon H1R 7B yet), it has effectively collapsed the gap between \"efficient\" open weights and mid-tier proprietary systems.Beating Larger \"Thinkers\": Falcon H1R 7B (83.1%) outperforms the 15-billion parameter Apriel-v1.6-Thinker (82.7%) and the 32-billion parameter OLMo 3 Think (73.7%), validating TII&#x27;s claim that hybrid architectures can out-reason larger Transformers.Chasing Proprietary Leaders: It sits within striking distance of Claude 4.5 Sonnet (88.0%) and Amazon Nova 2.0 Lite (88.7%), suggesting that for specific math-heavy workflows, this 7B model is a viable, low-latency alternative to expensive commercial APIs.Outperforming Legacy Giants: On this specific reasoning metric, it decisively beats broadly capable but older architectures like Mistral Large 3 (38.0%) and Llama 4 Maverick (19.3%), highlighting how specialized reasoning training (\"Deep Think\") has become more critical than raw scale for logic tasks.Other key domain wins include:Coding: The model achieved 68.6% on the LCB v6 benchmark, a score TII claims is the highest among all tested models, including those four times its size.General Reasoning: While it dominates in math and code, its general reasoning score (49.48%) remains competitive, sitting just below the 14B and 15B parameter models but comfortably ahead of comparable 8B models.Training TechniquesFalcon H1R 7B’s performance is not just architectural; it stems from a rigorous, two-stage training pipeline designed to maximize reasoning density without inflating parameter count, according to TII&#x27;s technical report on the model.Stage 1: Cold-Start Supervised Fine-Tuning (SFT). The model underwent \"cold-start\" SFT on a curated dataset dominated by mathematics (56.8% of tokens) and code (29.8%), with response lengths stretching up to 48,000 tokens.Difficulty-Aware Weighting: TII rejected the standard practice of treating all data equally. Instead, they applied a weighting scheme where \"hard\" problems were up-weighted by 1.25x to 1.75x, while easy problems were down-weighted or removed entirely to prevent overfitting to trivial tasks.Single-Teacher Consistency: Ablation studies revealed that mixing reasoning traces from multiple \"teacher\" models actually degraded performance due to conflicting reasoning styles. Consequently, TII opted for a single-teacher approach to maintain coherent internal logic.Balanced Token Normalization: To handle the massive variance in sequence lengths (short instructions vs. massive reasoning chains), the team introduced a Balanced Data-Parallel Token Normalization strategy. This technique equalizes the gradient contribution of each token across GPUs, preventing ranks with shorter sequences from destabilizing the loss—a change that yielded a consistent 4-10% accuracy boost during training.Stage 2: Reinforcement Learning via Group Relative Policy Optimization (GRPO). Following SFT, the model was refined using GRPO a reinforcement learning algorithm that rewards correct outcomes without needing a separate value model.The \"No-KL\" Shift: In a deviation from standard RLHF, TII removed the KL-divergence penalty (beta=0) entirely. This allowed the model to drift significantly from its base SFT policy, encouraging aggressive exploration of novel reasoning paths.Math-Only Curriculum: Surprisingly, TII found that training exclusively on math problems during the RL stage yielded better generalization across all domains—including code and science—than mixed strategies. Ablations showed that \"code-only\" training improved coding scores but harmed general reasoning, whereas math-focused RL lifted performance globally.TII optimized the model specifically for Test-Time Scaling (TTS), a technique where a model generates multiple reasoning paths in parallel to find the best solution.The model utilizes Deep Think with Confidence (DeepConf), which leverages the model&#x27;s internal confidence scores to dynamically prune low-quality reasoning traces.Adaptive Pruning: During generation, the system initiates a \"warm-up\" phase with 16 traces to establish a confidence baseline. It then aggressively filters subsequent traces, terminating any chain that falls below the 10th percentile of the baseline confidence.Efficiency Gains: This method creates a new Pareto frontier for deployment. In benchmark tests, Falcon H1R 7B achieved 96.7% accuracy on AIME 25 while reducing token usage by 38% compared to the DeepSeek-R1-0528-Qwen3-8B baseline.Licensing: Open For Commercial Usage, But With Strings AttachedTII has released Falcon H1R 7B under the custom Falcon LLM License 1.0 based on Apache 2.0 — but with notable modifications — chiefly among them: not to litigate against TII, and also to always credit it.For developers and startups, the license is largely permissive:Royalty-Free: Users can run, modify, and distribute the model commercially without paying TII.Attribution: Any derivative work (including fine-tunes) must prominently state: \"[Name of work] is built using Falcon LLM technology from the Technology Innovation Institute\".However, unlike a pure Open Source Initiative (OSI) license, the Falcon license includes a strict Acceptable Use Policy (AUP). The license terminates automatically if the model is used to create work that conflicts with the AUP or if the user initiates patent litigation against TII. Specifically, the AUP prohibits using Falcon H1R 7B or its derivatives for:Violating Laws: Any use that violates applicable national, federal, state, local, or international laws or regulations.Harm to Minors or Living Beings: Exploiting, harming, or attempting to exploit or harm minors or any living beings.Disinformation: Generating or disseminating verifiably false information with the purpose of harming others.Harassment: Defaming, disparaging, or otherwise harassing others.The Hybrid Wave: Nvidia, IBM, AI21, and MistralTII is not alone in betting on this hybrid future; the industry is increasingly moving toward architectures that blend the strengths of SSMs and Transformers.Nvidia recently debuted the Nemotron 3 family on December 15, 2025, which utilizes a hybrid mixture-of-experts (MoE) and Mamba-Transformer design to drive efficient agentic AI.IBM launched its Granite 4.0 family on October 2, 2025, using a hybrid Mamba-Transformer architecture to cut memory requirements by over 70% while maintaining high performance on enterprise benchmarks.AI21 has pursued this path with its Jamba (Joint Attention and Mamba) models, releasing the Jamba 1.5 family on August 22, 2024, to boost agentic AI capabilities through a hybrid SSM-Transformer approach.Mistral entered the space early with Codestral Mamba on July 16, 2024, a model specifically optimized for faster, longer code generation.Falcon H1R 7B represents the latest evolution in this trend, specifically targeting dense reasoning tasks in a compact form factor.",
          "content": "For the last two years, the prevailing logic in generative AI has been one of brute force: if you want better reasoning, you need a bigger model. While \"small\" models (under 10 billion parameters) have become capable conversationalists, they have historically crumbled when asked to perform multi-step logical deduction or complex mathematical proofs.Today, the Technology Innovation Institute (TII) in Abu Dhabi is challenging that scaling law with the release of Falcon H1R 7B. By abandoning the pure Transformer orthodoxy in favor of a hybrid architecture, TII claims to have built a 7-billion parameter model that not only rivals but outperforms competitors nearly 7X its size — including the 32B and 47B variants of Alibaba&#x27;s Qwen and Nvidia&#x27;s Nemotron.The release marks a significant shift in the open-weight ecosystem, moving the battleground from raw parameter count to architectural efficiency and inference-time scaling.The full model code is available now at Hugging Face and can be tested by individuals in a live demo inference on Falcon Chat (a chatbot experience). TII further released a seemingly quite comprehensive technical report on the approach and training methodology for Falcon H1 7B, as well. Moving Beyond the Foundational LLM Tech, the TransformerThe defining feature of Falcon H1R 7B is its \"hybrid\" backbone. Most modern LLMs rely exclusively on the Transformer architecture, which scales predictably but suffers from high memory costs when processing long sequences. Falcon H1R 7B integrates Mamba, a state-space model (SSM) architecture, alongside standard Transformer attention layers.Originally developed by researchers Albert Gu and Tri Dao at Carnegie Mellon University and Princeton University, Mamba was first introduced in the paper \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\" published on December 1, 2023.The architecture processes data sequences differently than Transformers: while Transformers compare every piece of data to every other piece (quadratic scaling), Mamba processes tokens sequentially, allowing it to handle vast amounts of information with linear scaling and significantly reduced compute costs.This combination addresses one of the most persistent bottlenecks in deploying reasoning models: the cost of \"thinking.\" Reasoning models require generating long \"chains of thought\"—step-by-step internal monologues—before arriving at an answer. For standard Transformers, these long contexts explode computational costs.According to TII’s technical report, the hybrid approach allows Falcon H1R 7B to maintain high throughput even as response lengths grow. At a batch size of 64, the model processes approximately 1,500 tokens per second per GPU—nearly double the speed of the competing Qwen3 8B model.Benchmark Performance: Punching UpIn the benchmarks released by TII, the disparity between Falcon H1R 7B’s size and its performance is stark. On the AIME 2025 leaderboard—a rigorous test of mathematical reasoning—Falcon H1R 7B scored 83.1%, a result that disrupts the traditional hierarchy of model sizing.While the 7B model naturally trails massive proprietary frontiers like GPT-5.2 (99.0%) and Gemini 3 Flash (97.0%) on the separate Artificial Analysis index (run by the independent organization of the same name, which has not yet benchmarked Falcon H1R 7B yet), it has effectively collapsed the gap between \"efficient\" open weights and mid-tier proprietary systems.Beating Larger \"Thinkers\": Falcon H1R 7B (83.1%) outperforms the 15-billion parameter Apriel-v1.6-Thinker (82.7%) and the 32-billion parameter OLMo 3 Think (73.7%), validating TII&#x27;s claim that hybrid architectures can out-reason larger Transformers.Chasing Proprietary Leaders: It sits within striking distance of Claude 4.5 Sonnet (88.0%) and Amazon Nova 2.0 Lite (88.7%), suggesting that for specific math-heavy workflows, this 7B model is a viable, low-latency alternative to expensive commercial APIs.Outperforming Legacy Giants: On this specific reasoning metric, it decisively beats broadly capable but older architectures like Mistral Large 3 (38.0%) and Llama 4 Maverick (19.3%), highlighting how specialized reasoning training (\"Deep Think\") has become more critical than raw scale for logic tasks.Other key domain wins include:Coding: The model achieved 68.6% on the LCB v6 benchmark, a score TII claims is the highest among all tested models, including those four times its size.General Reasoning: While it dominates in math and code, its general reasoning score (49.48%) remains competitive, sitting just below the 14B and 15B parameter models but comfortably ahead of comparable 8B models.Training TechniquesFalcon H1R 7B’s performance is not just architectural; it stems from a rigorous, two-stage training pipeline designed to maximize reasoning density without inflating parameter count, according to TII&#x27;s technical report on the model.Stage 1: Cold-Start Supervised Fine-Tuning (SFT). The model underwent \"cold-start\" SFT on a curated dataset dominated by mathematics (56.8% of tokens) and code (29.8%), with response lengths stretching up to 48,000 tokens.Difficulty-Aware Weighting: TII rejected the standard practice of treating all data equally. Instead, they applied a weighting scheme where \"hard\" problems were up-weighted by 1.25x to 1.75x, while easy problems were down-weighted or removed entirely to prevent overfitting to trivial tasks.Single-Teacher Consistency: Ablation studies revealed that mixing reasoning traces from multiple \"teacher\" models actually degraded performance due to conflicting reasoning styles. Consequently, TII opted for a single-teacher approach to maintain coherent internal logic.Balanced Token Normalization: To handle the massive variance in sequence lengths (short instructions vs. massive reasoning chains), the team introduced a Balanced Data-Parallel Token Normalization strategy. This technique equalizes the gradient contribution of each token across GPUs, preventing ranks with shorter sequences from destabilizing the loss—a change that yielded a consistent 4-10% accuracy boost during training.Stage 2: Reinforcement Learning via Group Relative Policy Optimization (GRPO). Following SFT, the model was refined using GRPO a reinforcement learning algorithm that rewards correct outcomes without needing a separate value model.The \"No-KL\" Shift: In a deviation from standard RLHF, TII removed the KL-divergence penalty (beta=0) entirely. This allowed the model to drift significantly from its base SFT policy, encouraging aggressive exploration of novel reasoning paths.Math-Only Curriculum: Surprisingly, TII found that training exclusively on math problems during the RL stage yielded better generalization across all domains—including code and science—than mixed strategies. Ablations showed that \"code-only\" training improved coding scores but harmed general reasoning, whereas math-focused RL lifted performance globally.TII optimized the model specifically for Test-Time Scaling (TTS), a technique where a model generates multiple reasoning paths in parallel to find the best solution.The model utilizes Deep Think with Confidence (DeepConf), which leverages the model&#x27;s internal confidence scores to dynamically prune low-quality reasoning traces.Adaptive Pruning: During generation, the system initiates a \"warm-up\" phase with 16 traces to establish a confidence baseline. It then aggressively filters subsequent traces, terminating any chain that falls below the 10th percentile of the baseline confidence.Efficiency Gains: This method creates a new Pareto frontier for deployment. In benchmark tests, Falcon H1R 7B achieved 96.7% accuracy on AIME 25 while reducing token usage by 38% compared to the DeepSeek-R1-0528-Qwen3-8B baseline.Licensing: Open For Commercial Usage, But With Strings AttachedTII has released Falcon H1R 7B under the custom Falcon LLM License 1.0 based on Apache 2.0 — but with notable modifications — chiefly among them: not to litigate against TII, and also to always credit it.For developers and startups, the license is largely permissive:Royalty-Free: Users can run, modify, and distribute the model commercially without paying TII.Attribution: Any derivative work (including fine-tunes) must prominently state: \"[Name of work] is built using Falcon LLM technology from the Technology Innovation Institute\".However, unlike a pure Open Source Initiative (OSI) license, the Falcon license includes a strict Acceptable Use Policy (AUP). The license terminates automatically if the model is used to create work that conflicts with the AUP or if the user initiates patent litigation against TII. Specifically, the AUP prohibits using Falcon H1R 7B or its derivatives for:Violating Laws: Any use that violates applicable national, federal, state, local, or international laws or regulations.Harm to Minors or Living Beings: Exploiting, harming, or attempting to exploit or harm minors or any living beings.Disinformation: Generating or disseminating verifiably false information with the purpose of harming others.Harassment: Defaming, disparaging, or otherwise harassing others.The Hybrid Wave: Nvidia, IBM, AI21, and MistralTII is not alone in betting on this hybrid future; the industry is increasingly moving toward architectures that blend the strengths of SSMs and Transformers.Nvidia recently debuted the Nemotron 3 family on December 15, 2025, which utilizes a hybrid mixture-of-experts (MoE) and Mamba-Transformer design to drive efficient agentic AI.IBM launched its Granite 4.0 family on October 2, 2025, using a hybrid Mamba-Transformer architecture to cut memory requirements by over 70% while maintaining high performance on enterprise benchmarks.AI21 has pursued this path with its Jamba (Joint Attention and Mamba) models, releasing the Jamba 1.5 family on August 22, 2024, to boost agentic AI capabilities through a hybrid SSM-Transformer approach.Mistral entered the space early with Codestral Mamba on July 16, 2024, a model specifically optimized for faster, longer code generation.Falcon H1R 7B represents the latest evolution in this trend, specifically targeting dense reasoning tasks in a compact form factor.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6S3Um2MKMQJZavLvb5iEzH/7f8270446a2734c8c6a2d1150b2fc332/9-x0igmpkjXB7E9vru3gT.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/nvidias-cosmos-reason-2-aims-to-bring-reasoning-vlms-into-the-physical-world",
          "published_at": "Mon, 05 Jan 2026 20:00:00 GMT",
          "title": "Nvidia’s Cosmos Reason 2 aims to bring reasoning VLMs into the physical world",
          "standfirst": "Nvidia CEO Jensen Huang said last year that we are now entering the age of physical AI. While the company continues to offer LLMs for software use cases, Nvidia is increasingly positioning itself as a provider of AI models for fully AI-powered systems — including agentic AI in the physical world.At CES 2026, Nvidia announced a slate of new models designed to push AI agents beyond chat interfaces and into physical environments.Nvidia launched Cosmos Reason 2, the latest version of its vision-language model designed for embodied reasoning. Cosmos Reason 1, released last year, introduced a two-dimensional ontology for embodied reasoning and currently leads Hugging Face’s physical reasoning for video leaderboard.Cosmos Reason 2 builds on the same ontology while giving enterprises more flexibility to customize applications and enabling physical agents to plan their next actions, similar to how software-based agents reason through digital workflows.Nvidia also released a new version of Cosmos Transfer, a model that lets developers generate training simulations for robots.Other vision-language models, such as Google’s PaliGemma and Pixtral Large from Mistral, can process visual inputs, but not all commercially available VLMs support reasoning.“Robotics is at an inflection point. We are moving from specialist robots limited to single tasks to generalist specialist systems,” said Kari Briski, Nvidia vice president for generative AI software, in a briefing with reporters. She was referring to robots that combine broad foundational knowledge with deep task-specific skills. “These new robots combine broad fundamental knowledge with deep proficiency and complex tasks.”She added that Cosmos Reason 2 “enhances the reasoning capabilities that robots need to navigate the unpredictable physical world.”Moving to physical agentsBriski noted that Nvidia’s roadmap follows “the same pattern of assets across all of our open models.”“In building specialized AI agents, a digital workforce, or the physical embodiment of AI in robots and autonomous vehicles, more than just the model is needed,” Briski said. “First, the AI needs the compute resources to train, simulate the world around it. Data is the fuel for AI to learn and improve and we contribute to the world&#x27;s largest collection of open and diverse datasets, going beyond just opening the weights of the models. The open libraries and training scripts give developers the tools to purpose-build AI for their applications, and we publish blueprints and examples to help deploy AI as systems of models.”The company now has open models specifically for physical AI in Cosmos, robotics, with the open-reasoning vision-language-action (VLA) model Gr00t and its Nemotron models for agentic AI. Nvidia is making the case that open models across different branches of AI form a shared enterprise ecosystem that feeds data, training, and reasoning to agents in both the digital and physical worlds. Additions to the Nemotron familyBriski said Nvidia plans to continue expanding its open models, including its Nemotron family, beyond reasoning to include a new RAG and embeddings model to make information more readily available to agents. The company released Nemotron 3, the latest version of its agentic reasoning models, in December. Nvidia announced three new additions to the Nemotron family: Nemotron Speech, Nemotron RAG and Nemotron Safety. In a blog post, Nvidia said Nemotron Speech delivers “real-time low-latency speech recognition for live captions and speech AI applications” and is 10 times faster than other speech models. Nemotron RAG is technically comprised of two models: an embedding model and a rerank model, both of which can understand images to provide more multimodal insights that data agents will tap. “Nemotron RAG is on top of what we call the MMTab, or the Massive Multilingual Text Embedding Benchmark, with strong multilingual performance while using less computing power memory, so they are a good fit for systems that must handle a lot of requests very quickly and with low delay,” Briski said. Nemotron Safety detects sensitive data so AI agents do not accidentally unleash personally identifiable data.",
          "content": "Nvidia CEO Jensen Huang said last year that we are now entering the age of physical AI. While the company continues to offer LLMs for software use cases, Nvidia is increasingly positioning itself as a provider of AI models for fully AI-powered systems — including agentic AI in the physical world.At CES 2026, Nvidia announced a slate of new models designed to push AI agents beyond chat interfaces and into physical environments.Nvidia launched Cosmos Reason 2, the latest version of its vision-language model designed for embodied reasoning. Cosmos Reason 1, released last year, introduced a two-dimensional ontology for embodied reasoning and currently leads Hugging Face’s physical reasoning for video leaderboard.Cosmos Reason 2 builds on the same ontology while giving enterprises more flexibility to customize applications and enabling physical agents to plan their next actions, similar to how software-based agents reason through digital workflows.Nvidia also released a new version of Cosmos Transfer, a model that lets developers generate training simulations for robots.Other vision-language models, such as Google’s PaliGemma and Pixtral Large from Mistral, can process visual inputs, but not all commercially available VLMs support reasoning.“Robotics is at an inflection point. We are moving from specialist robots limited to single tasks to generalist specialist systems,” said Kari Briski, Nvidia vice president for generative AI software, in a briefing with reporters. She was referring to robots that combine broad foundational knowledge with deep task-specific skills. “These new robots combine broad fundamental knowledge with deep proficiency and complex tasks.”She added that Cosmos Reason 2 “enhances the reasoning capabilities that robots need to navigate the unpredictable physical world.”Moving to physical agentsBriski noted that Nvidia’s roadmap follows “the same pattern of assets across all of our open models.”“In building specialized AI agents, a digital workforce, or the physical embodiment of AI in robots and autonomous vehicles, more than just the model is needed,” Briski said. “First, the AI needs the compute resources to train, simulate the world around it. Data is the fuel for AI to learn and improve and we contribute to the world&#x27;s largest collection of open and diverse datasets, going beyond just opening the weights of the models. The open libraries and training scripts give developers the tools to purpose-build AI for their applications, and we publish blueprints and examples to help deploy AI as systems of models.”The company now has open models specifically for physical AI in Cosmos, robotics, with the open-reasoning vision-language-action (VLA) model Gr00t and its Nemotron models for agentic AI. Nvidia is making the case that open models across different branches of AI form a shared enterprise ecosystem that feeds data, training, and reasoning to agents in both the digital and physical worlds. Additions to the Nemotron familyBriski said Nvidia plans to continue expanding its open models, including its Nemotron family, beyond reasoning to include a new RAG and embeddings model to make information more readily available to agents. The company released Nemotron 3, the latest version of its agentic reasoning models, in December. Nvidia announced three new additions to the Nemotron family: Nemotron Speech, Nemotron RAG and Nemotron Safety. In a blog post, Nvidia said Nemotron Speech delivers “real-time low-latency speech recognition for live captions and speech AI applications” and is 10 times faster than other speech models. Nemotron RAG is technically comprised of two models: an embedding model and a rerank model, both of which can understand images to provide more multimodal insights that data agents will tap. “Nemotron RAG is on top of what we call the MMTab, or the Massive Multilingual Text Embedding Benchmark, with strong multilingual performance while using less computing power memory, so they are a good fit for systems that must handle a lot of requests very quickly and with low delay,” Briski said. Nemotron Safety detects sensitive data so AI agents do not accidentally unleash personally identifiable data.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2dOxvcQe247RRe0QqURNoc/4226294f75548d9fb351c7df254ff529/crimedy7_illustration_of_robots_learning_in_a_school_--ar_169_ff89c646-4604-4650-88d5-14713adf2cdc_3.png?w=300&q=30"
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Samsung_Micro_RGB-1.jpg",
      "popularity_score": 2019.44832
    },
    {
      "id": "cluster_49",
      "coverage": 2,
      "updated_at": "2026-01-06T20:00:00-05:00",
      "title": "Lenovo&#8217;s new concept rollable could be the ideal gaming laptop",
      "neutral_headline": "Lenovo&#8217;s new concept rollable could be the ideal gaming laptop",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/852352/lenovo-legion-pro-rollable-gaming-laptop-concept-ces-2026",
          "published_at": "2026-01-06T20:00:00-05:00",
          "title": "Lenovo&#8217;s new concept rollable could be the ideal gaming laptop",
          "standfirst": "Lenovo is at it again with wild laptop concepts for CES 2026, and the biggest one is the Legion Pro Rollable gaming laptop. It has a flexible OLED display that expands horizontally - as opposed to Lenovo's ThinkBook Plus Gen 6, which rolls up and down. The Legion Pro Rollable's screen goes from a conventional [&#8230;]",
          "content": "Wider is better. Lenovo is at it again with wild laptop concepts for CES 2026, and the biggest one is the Legion Pro Rollable gaming laptop. It has a flexible OLED display that expands horizontally - as opposed to Lenovo's ThinkBook Plus Gen 6, which rolls up and down. The Legion Pro Rollable's screen goes from a conventional 16-inch 16:10 aspect ratio to an extra-wide 21.5 inches, all the way to an ultrawide 24 inches. That's even bigger (diagonally, at least) than the ridiculous $9,000 21-inch gaming laptop Acer once made. The Pro Rollable concept is based on the Legion Pro 7i, and it'll come with an Intel Core Ultra processor and Nvidia's flagship RTX 50 … Read the full story at The Verge.",
          "feed_position": 7
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/852482/lenovo-thinkpad-rollable-xd-concept-laptop-ces-2026",
          "published_at": "2026-01-06T20:00:00-05:00",
          "title": "This ThinkPad laptop concept has a rollable display that wraps around its lid",
          "standfirst": "At CES 2026, Lenovo is announcing yet another new concept laptop with a transforming screen: the ThinkPad Rollable XD Concept. It's a ThinkPad, complete with its iconic red TrackPoint nub, but it features a flexible OLED display that wraps around to the outer part of its lid. Slide your finger along the folded spin of [&#8230;]",
          "content": "Watching this thing in action is pretty fun, thanks to that windowed lid. At CES 2026, Lenovo is announcing yet another new concept laptop with a transforming screen: the ThinkPad Rollable XD Concept. It's a ThinkPad, complete with its iconic red TrackPoint nub, but it features a flexible OLED display that wraps around to the outer part of its lid. Slide your finger along the folded spin of its touchscreen, and the laptop vertically expands from a 13.3-inch display to a taller 15.9-inch screen - offering more screen real estate for productivity work. It's a bit like Lenovo's already released ThinkBook Plus Gen 6 rollable, but the screen and motors are all in the lid as opposed to tucking the display into the chass … Read the full story at The Verge.",
          "feed_position": 8
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/lenovo-legion-pro-gaming-laptop-ultrawide-rollable-screen/",
          "published_at": "Wed, 07 Jan 2026 01:00:00 +0000",
          "title": "Lenovo’s Legion Pro Rollable Gaming Laptop Goes Ultrawide at the Press of a Key",
          "standfirst": "Lenovo brought a Legion gaming laptop to CES this year with a rollable OLED display that expands horizontally by six inches.",
          "content": "Lenovo brought a Legion gaming laptop to CES this year with a rollable OLED display that expands horizontally by six inches.",
          "feed_position": 12,
          "image_url": "https://media.wired.com/photos/695d520ac8fcfa0242b8cd5d/master/pass/legion-pro-rollable-top.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/695d520ac8fcfa0242b8cd5d/master/pass/legion-pro-rollable-top.jpg",
      "popularity_score": 2009.6560977777779
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 22:40:08 +0000",
      "title": "HP’s EliteBoard G1a is a Ryzen-powered Windows 11 PC in a membrane keyboard",
      "neutral_headline": "HP’s EliteBoard G1a is a Ryzen-powered Windows 11 PC in a membrane keyboard",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/hps-eliteboard-g1a-is-a-ryzen-powered-windows-11-pc-in-a-membrane-keyboard/",
          "published_at": "Tue, 06 Jan 2026 22:40:08 +0000",
          "title": "HP’s EliteBoard G1a is a Ryzen-powered Windows 11 PC in a membrane keyboard",
          "standfirst": "The most familiar, full-fledged PC experience you can get from a keyboard.",
          "content": "As a Windows system built inside of a functioning membrane keyboard, the HP EliteBoard G1a announced today is a more accessible alternative to other keyboard-PCs. The Commodore 64 made the keyboard-PC famous in the 1980s, but the keyboard-PC space has been dominated by the Raspberry Pi. In 2019, the single-board computer (SBC) maker released the Raspberry Pi 400, which is essentially a Raspberry Pi 4 SBC inside a case that also functions as a keyboard for the system. USB, HDMI, and Ethernet ports, plus a GPIO header and native Raspberry Pi OS Linux distribution add up to a low-end desktop computer experience that only costs $100. Then the Raspberry Pi 500 with a Pi 5 powered by a quad-core, 64-bit Arm Cortex-A76 inside, and the Pi 500+, which has NVMe SSD, instead of microSD, storage, and is built inside of a low-profile mechanical keyboard (it’s also twice as expensive at $200). The Pi 500+ keyboard-PC using RGB. Credit: Raspberry Pi But Raspberry Pis largely appeal to tinkerers, DIYers, and Linux fans, making Pi-as-a-desktop a niche product with a substantial learning curve for newcomers.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/eliteboard-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/eliteboard-1152x648.jpg",
      "popularity_score": 330.3249866666667
    },
    {
      "id": "cluster_63",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 21:56:18 +0000",
      "title": "With GeForce Super GPUs missing in action, Nvidia focuses on software upgrades",
      "neutral_headline": "With GeForce Super GPUs missing in action, Nvidia focuses on software upgrades",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/nvidia-leans-on-dlss-improvements-to-make-up-for-a-lack-of-gpus-at-ces/",
          "published_at": "Tue, 06 Jan 2026 21:56:18 +0000",
          "title": "With GeForce Super GPUs missing in action, Nvidia focuses on software upgrades",
          "standfirst": "Nvidia's only GeForce announcements this year were about software improvements.",
          "content": "For the first time in years, Nvidia declined to introduce new GeForce graphics card models at CES. CEO Jensen Huang's characteristically sprawling and under-rehearsed 90-minute keynote focused almost entirely on the company's dominant AI business, relegating the company's gaming-related announcements to a separate video posted later in the evening. Instead, the company focused on software improvements for its existing hardware. The biggest announcement in this vein is DLSS 4.5, which adds a handful of new features to Nvidia's basket of upscaling and frame generation technologies. DLSS upscaling is being improved by a new \"second-generation transformer model\" that Nvidia says has been \"trained on an expanded data set\" to improve its predictions when generating new pixels. According to Nvidia's Bryan Catanzaro, this is particularly beneficial for image quality in the Performance and Ultra Performance modes, where the upscaler has to do more guessing because it's working from a lower-resolution source image.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/consumer-ces-umbrella-blog-1280x680-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/consumer-ces-umbrella-blog-1280x680-1-1152x648.jpg",
      "popularity_score": 319.59443111111113
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 19:55:25 +0000",
      "title": "Dell’s XPS revival is a welcome reprieve from the “AI PC” fad",
      "neutral_headline": "Dell’s XPS revival is a welcome reprieve from the “AI PC” fad",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/dells-xps-revival-is-a-welcome-reprieve-from-the-ai-pc-fad/",
          "published_at": "Tue, 06 Jan 2026 19:55:25 +0000",
          "title": "Dell’s XPS revival is a welcome reprieve from the “AI PC” fad",
          "standfirst": "Dell moves from pushing \"AI PCs\" and back to what matters in laptops.",
          "content": "After making the obviously poor decision to kill its XPS laptops and desktops in January 2025, Dell started selling 16- and 14-inch XPS laptops again today. “It was obvious we needed to change,” Jeff Clarke, vice chairman and COO at Dell Technologies, said at a press event in New York City previewing Dell's CES 2026 announcements. A year ago, Dell abandoned XPS branding, as well as its Latitude, Inspiron, and Precision PC lineups. The company replaced the reputable brands with Dell Premium, Dell Pro, and Dell Pro Max. Each series included a base model, as well as “Plus” and “Premium.” Dell isn’t resurrecting its Latitude, Inspiron, or Precision series, and it will still sell “Dell Pro” models.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/XPS-16-1152x648-1767726799.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/XPS-16-1152x648-1767726799.jpeg",
      "popularity_score": 318.5797088888889
    },
    {
      "id": "cluster_64",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 21:11:54 +0000",
      "title": "Letting prisons jam contraband phones is a bad idea, phone companies tell FCC",
      "neutral_headline": "Letting prisons jam contraband phones is a bad idea, phone companies tell FCC",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/letting-prisons-jam-contraband-phones-is-a-bad-idea-phone-companies-tell-fcc/",
          "published_at": "Tue, 06 Jan 2026 21:11:54 +0000",
          "title": "Letting prisons jam contraband phones is a bad idea, phone companies tell FCC",
          "standfirst": "\"Jamming will block all communications,\" including 911 calls, CTIA tells FCC.",
          "content": "A Federal Communications Commission proposal to let state and local prisons jam contraband cell phones has support from Republican attorneys general and prison phone companies but faces opposition from wireless carriers that say it would disrupt lawful communications. Groups dedicated to Wi-Fi and GPS also raised concerns in comments to the FCC. \"Jamming will block all communications, not just communications from contraband devices,\" wireless lobby group CTIA said in December 29 comments in response to Chairman Brendan Carr's proposal. The CTIA said that \"jamming blocks all communications, including lawful communications such as 911 calling,\" and argued that the FCC \"has no authority to allow jamming.\" CTIA members AT&T and Verizon expressed their displeasure in separate comments to the FCC. \"The proposed legal framework is based on a flawed factual premise,\" AT&T wrote.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/prison-barbed-wire-1152x648-1767732268.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/prison-barbed-wire-1152x648-1767732268.jpg",
      "popularity_score": 308.8544311111111
    },
    {
      "id": "cluster_82",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 18:59:21 +0000",
      "title": "News orgs win fight to access 20M ChatGPT logs. Now they want more.",
      "neutral_headline": "News orgs win fight to access 20M ChatGPT logs. Now they want more.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/news-orgs-want-openai-to-dig-up-millions-of-deleted-chatgpt-logs/",
          "published_at": "Tue, 06 Jan 2026 18:59:21 +0000",
          "title": "News orgs win fight to access 20M ChatGPT logs. Now they want more.",
          "standfirst": "OpenAI's loss in privacy fight could lead to sharing even more deleted chats.",
          "content": "Not only does it appear that OpenAI has lost its fight to keep news organizations from digging through 20 million ChatGPT logs to find evidence of copyright infringement—but also OpenAI now faces calls for sanctions and demands to retrieve and share potentially millions of deleted chats long thought of as untouchable in the litigation. On Monday, US District Judge Sidney Stein denied objections that OpenAI raised, claiming that Magistrate Judge Ona Wang failed to adequately balance the privacy interests of ChatGPT users who are not involved in the litigation when ordering OpenAI to produce 20 million logs. Instead, OpenAI wanted Stein to agree that it would be much less burdensome to users if OpenAI ran search terms to find potentially infringing outputs in the sample. That way, news plaintiffs would only get access to chats that were relevant to its case, OpenAI suggested.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1322146218-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1322146218-1152x648.jpg",
      "popularity_score": 301.6452644444444
    },
    {
      "id": "cluster_90",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 18:05:05 +0000",
      "title": "Appeals court agrees that Congress blocked cuts to research costs",
      "neutral_headline": "Appeals court agrees that Congress blocked cuts to research costs",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/appeals-court-upholds-block-on-one-of-trumps-cuts-to-research-funds/",
          "published_at": "Tue, 06 Jan 2026 18:05:05 +0000",
          "title": "Appeals court agrees that Congress blocked cuts to research costs",
          "standfirst": "The Trump admin can't arbitrarily set university reimbursements to a low flat rate.",
          "content": "One of the first signs of what would become an ongoing attack on scientific research came when the Trump administration ordered the National Institutes of Health (NIH) to radically reduce research funding for universities. These funds, termed indirect costs, are awarded when researchers at an institution receive a grant. They cover costs that aren't directly associated with the research project, such as utilities, facilities for research animals, and building maintenance. Previously, these costs had been the subject of negotiations and audits, with indirect cost rates for universities in more expensive locations exceeding half the value of the portion of the grant that goes to the researcher. The Trump administration wanted to cut this to a flat rate of 15 percent for everyone, which would be crippling for many universities. A number of states, later joined by organizations representing a broad array of universities and medical schools, immediately sued to block the policy change. A district court temporarily blocked the new policy from being implemented and later issued a permanent injunction. The government appealed that decision, but on Monday, an appeals court rejected the effort because the first Trump administration had attempted the same move before—and Congress passed a rule to block it. Indirect research funding will remain intact unless the Supreme Court intervenes.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2247954039-1152x648-1767719824.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2247954039-1152x648-1767719824.jpg",
      "popularity_score": 275.74082
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 17:32:14 +0000",
      "title": "Nvidia’s new G-Sync Pulsar monitors target motion blur at the human retina level",
      "neutral_headline": "Nvidia’s new G-Sync Pulsar monitors target motion blur at the human retina level",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/nvidias-new-g-sync-pulsar-monitors-target-motion-blur-at-the-human-retina-level/",
          "published_at": "Tue, 06 Jan 2026 17:32:14 +0000",
          "title": "Nvidia’s new G-Sync Pulsar monitors target motion blur at the human retina level",
          "standfirst": "Four new monitors promise \"effective motion clarity of a theoretical 1,000 Hz monitor.\"",
          "content": "It's been almost exactly two years since Nvidia announced G-Sync Pulsar, its new backlight strobing technology designed to limit display motion blur caused by old images persisting on the viewer's retina. At the time, Nvidia said that technology would debut on Asus' ROG Swift PG27 Series monitors by the end of 2024. Nvidia now says the first four G-Sync Pulsar-powered monitors will be available at select retailers starting Wednesday. Those first Pulsar-equipped monitors will be: Acer's Predator XB273U F5 AOC's AGON PRO AG276QSG2 Asus' ROG Strix Pulsar XG27AQNGV MSI's MPG 272QRF X36 Making 360 Hz seem like more All four of the fresh Pulsar-enabled IPS monitors come in at 27 inches with 1440p resolution and up to 360 Hz refresh rates. But Nvidia says the integrated G-Sync Pulsar technology means each display has the \"effective motion clarity of a theoretical 1,000 Hz monitor.\"Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/pulsar2-1152x648-1767719933.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/pulsar2-1152x648-1767719933.png",
      "popularity_score": 271.19331999999997
    },
    {
      "id": "cluster_101",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 15:55:41 +0000",
      "title": "Ørsted seeks injunction against US government over project freeze",
      "neutral_headline": "Ørsted seeks injunction against US government over project freeze",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/orsted-seeks-injunction-against-us-government-over-project-freeze/",
          "published_at": "Tue, 06 Jan 2026 15:55:41 +0000",
          "title": "Ørsted seeks injunction against US government over project freeze",
          "standfirst": "Trump administration had suspended Danish group’s work on major wind farm off coast of Rhode Island.",
          "content": "Ørsted is seeking a court injunction against the Trump administration’s decision to suspend its work on a major wind farm project off the US northeast coast. In the latest salvo between the US government and the offshore wind industry, the Danish company filed a legal challenge against the suspension in the US District Court for the District of Columbia on Thursday. In a statement, Ørsted—the world’s largest offshore wind developer that is 50 percent owned by the Danish state—and its joint venture partner Skyborn Renewables, a unit of BlackRock’s Global Infrastructure Partners, said the US government’s order to suspend the lease on its Revolution Wind project was a violation of applicable law.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ftcms_ccff82e2-1b3f-4dd6-af31-3b7bbfffc992.avif"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ftcms_ccff82e2-1b3f-4dd6-af31-3b7bbfffc992.avif",
      "popularity_score": 268.58415333333335
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 15:49:36 +0000",
      "title": "Magneto, Xavier reunite in new Avengers: Doomsday teaser",
      "neutral_headline": "Magneto, Xavier reunite in new Avengers: Doomsday teaser",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/latest-avengers-doomsday-teaser-highlights-x-men/",
          "published_at": "Tue, 06 Jan 2026 15:49:36 +0000",
          "title": "Magneto, Xavier reunite in new Avengers: Doomsday teaser",
          "standfirst": "\"The question isn’t ‘are you prepared to die?’ The question is ‘who will you be when you close your eyes?’”",
          "content": "Marvel Studios continues to dribble out brief teasers promoting Avengers: Doomsday, which is slated for a December 2026 release—first playing in cinemas prior to Avatar: Fire and Ash screenings before becoming publicly available. We reported previously on the first, which featured Steve Rogers (Chris Evans), the former Captain America. Over the holidays, a second teaser highlighting Chris Hemsworth's Thor was released. Both are familiar faces in the MCU, but we now have a third teaser that brings in some new players. No, not Robert Downey Jr.'s Doctor Doom as rumored. Instead, we've got Magneto (Ian McKellen), Charles Xavier (Patrick Stewart), and Cyclops (James Marsden) from the X-Men franchise. The film takes place 14 months after the events of this year’s Thunderbolts*. In addition to Thor, we have the new Captain America (Anthony Mackie), Bucky Barnes (Sebastian Stan), Ant-Man (Paul Rudd), Falcon (Danny Ramirez), and Loki (Tom Hiddleston). Then there’s the Wakandan contingent: Shuri as the new Black Panther (Letitia Wright), M’Baku (Winston Duke), and Namor (Tenoch Huerta Mejia).Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/avenge2-1152x648-1767712126.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/avenge2-1152x648-1767712126.jpg",
      "popularity_score": 243.48276444444446
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 03:45:49 +0000",
      "title": "Intel launches Core Ultra Series 3 CPUs, made using its long-awaited 18A process",
      "neutral_headline": "Intel launches Core Ultra Series 3 CPUs, made using its long-awaited 18A process",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/intel-launches-core-ultra-series-3-cpus-made-using-its-long-awaited-18a-process/",
          "published_at": "Tue, 06 Jan 2026 03:45:49 +0000",
          "title": "Intel launches Core Ultra Series 3 CPUs, made using its long-awaited 18A process",
          "standfirst": "New chips launch \"this month,\" targeting high-end ultraportable PCs.",
          "content": "Intel will formally launch its first Core Ultra Series 3 laptop processors later this month, the company announced at its CES keynote today. Codenamed Panther Lake and targeted, at least for now, at high-end ultraportable PCs, the Core Ultra 3 chips will also be the first to use Intel's 18A manufacturing process, the company's effort to catch up with the chip manufacturing technology of Taiwan Semiconductor (TSMC). The launch will start with 14 chips across five product families, which Intel says will be used in \"over 200\" PC designs. The first of these will be available on January 27, with others following \"throughout the first half of this year.\" The Core Ultra X9 and Core Ultra X7 processors include all of Intel's latest CPU and GPU architectures, plus a fully enabled 12-core Intel Arc B390 integrated GPU and support for slightly faster LPDDR5x-9600. The Core Ultra 9 and 7 processors will use all of the same technologies, but with just four GPU cores and support for either LPDDR5x-8533 or DDR5-7200 DIMMs. But they will offer 20 PCI Express lanes, up from 12 for the X9 and X7, meaning they'll pair better with dedicated GPUs. The Core Ultra 5 chips are mostly lower-end models with fewer CPU cores, and either 4- or 2-core GPUs. But Intel being Intel, there is one oddball that muddies the waters: the Core Ultra 5 338H, which has 12 CPU cores and a 10-core Intel Arc B370 GPU. A Panther Lake refresher The higher-end Core Ultra Series 3 CPUs. Credit: Intel The Core Ultra 5 family encompasses a wide range of possible performance levels. Credit: Intel We wrote about the basic building blocks of Panther Lake when Intel released details late last year. In many ways the chip is a retreat from the Lunar Lake design, sold as Core Ultra 200V, which used chiplets manufactured mostly outside the company and on-package RAM rather than memory in a DIMM slot or soldered to the mainboard. At the time, Intel said these moves were made in the interest of saving power and extending battery life, as were decisions like removing Hyperthreading support from the P-cores.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Intel_CES_-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Intel_CES_-1152x648.jpeg",
      "popularity_score": 148
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 03:30:30 +0000",
      "title": "AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops",
      "neutral_headline": "AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/amd-reheats-last-years-ryzen-ai-and-x3d-cpus-for-2026s-laptops-and-desktops/",
          "published_at": "Tue, 06 Jan 2026 03:30:30 +0000",
          "title": "AMD reheats last year’s Ryzen AI and X3D CPUs for 2026’s laptops and desktops",
          "standfirst": "But it may become slightly cheaper to buy AMD's fastest integrated Radeon GPUs.",
          "content": "Intel, AMD, Nvidia, and other chip companies usually have some kind of news to announce at CES to kick off the year, but some of those announcements are more interesting than others. Sometimes you see new chips with significant speed boosts and other new technologies, and sometimes you get rebranded versions of old silicon meant to fill out a lineup or make an existing architecture seem newer and more exciting than it is. AMD's Ryzen CPU announcements this year fall firmly into the latter camp—these are all gently tweaked variants of chips that launched in 2024 and 2025. \"New,\" for certain values of \"new\" These Ryzen AI 400-series chips are slightly faster than, but otherwise functionally identical to, the Ryzen AI 300 series. Credit: AMD Slightly higher CPU clock speeds, NPU speeds, and supported RAM speeds will separate Ryzen AI 400 from Ryzen AI 300. Credit: AMD Core specs for the new-ish chips. Credit: AMD The corresponding Ryzen Pro chips for business PCs. Credit: AMD Let's start with the Ryzen AI 400 series. Officially the follow-up to the Ryzen AI 300 chips announced in June 2024, these processors offer some modest clock speed improvements and faster memory support. The new Ryzen AI 9 HX 470 has a peak boost clock speed of 5.2 GHz and support for LPDDR5x-8533, for example, up from 5.1 GHz and LPDDR5x-8000 for the Ryzen AI 9 HX 370, and its built-in neural processing unit (NPU) is capable of 60 trillion operations per second (TOPS) rather than 50 TOPS.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Ryzen-AI-400-Series_05-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Ryzen-AI-400-Series_05-1152x648.jpeg",
      "popularity_score": 148
    },
    {
      "id": "cluster_129",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 22:14:50 +0000",
      "title": "NASA’s science budget won’t be a train wreck after all",
      "neutral_headline": "NASA’s science budget won’t be a train wreck after all",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasas-science-budget-wont-be-a-train-wreck-after-all/",
          "published_at": "Mon, 05 Jan 2026 22:14:50 +0000",
          "title": "NASA’s science budget won’t be a train wreck after all",
          "standfirst": "\"There's very little to not like in this.\"",
          "content": "In June, the White House released a budget proposal for fiscal year 2026 that slashed funding for NASA's science programs by nearly 50 percent. Then, in July, the Trump administration began telling the leaders of dozens of space science missions to prepare \"closeout\" plans for their spacecraft. Things looked pretty grim for a while, but then Congress stepped in. Congress, of course, sets the federal government's budget. In many ways, Congress abdicated authority to the Trump administration last year. But not so, it turns out, with federal spending. Throughout the summer and fall, as the White House and Congress wrangled over various issues, lawmakers made it clear they intended to fund most of NASA's science portfolio. Preliminary efforts to shut down active missions were put on hold.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/05/50530415266_a67d907fac_b-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/05/50530415266_a67d907fac_b-1024x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 21:42:14 +0000",
      "title": "The nation’s strictest privacy law just took effect, to data brokers’ chagrin",
      "neutral_headline": "The nation’s strictest privacy law just took effect, to data brokers’ chagrin",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/data-broker-hoarding-is-rampant-new-law-lets-consumers-fight-back/",
          "published_at": "Mon, 05 Jan 2026 21:42:14 +0000",
          "title": "The nation’s strictest privacy law just took effect, to data brokers’ chagrin",
          "standfirst": "Californians can now submit demands requiring 500 brokers to delete their data.",
          "content": "Californians are getting a new, supercharged way to stop data brokers from hoarding and selling their personal information, as a recently enacted law that’s among the strictest in the nation took effect at the beginning of the year. According to the California Privacy Protection Agency, more than 500 companies actively scour all sorts of sources for scraps of information about individuals, then package and store it to sell to marketers, private investigators, and others. The nonprofit Consumer Watchdog said in 2024 that brokers trawl automakers, tech companies, junk-food restaurants, device makers, and others for financial info, purchases, family situations, eating, exercising, travel, entertainment habits, and just about any other imaginable information belonging to millions of people.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/04/data-leak-1000x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/04/data-leak-1000x648.jpeg",
      "popularity_score": 148
    },
    {
      "id": "cluster_133",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 20:38:48 +0000",
      "title": "Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy",
      "neutral_headline": "Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/annas-archive-loses-org-domain-says-suspension-likely-unrelated-to-spotify-piracy/",
          "published_at": "Mon, 05 Jan 2026 20:38:48 +0000",
          "title": "Anna’s Archive loses .org domain, says suspension likely unrelated to Spotify piracy",
          "standfirst": "\"We don't believe this has to do with our Spotify backup,\" Anna's Archive says.",
          "content": "The primary domain of Shadow library Anna's Archive was taken offline, with annas-archive.org being put under the serverHold status. While Anna's Archive recently made waves with a massive \"backup\" of Spotify, the shadow library's operator said the music pirating doesn't appear to be connected to the .org domain suspension. Anna's Archive remains available at several other domains. Anna's Archive launched in 2022 in response to the US Department of Justice seizure of domains used by e-book pirate site Z-Library. Acting as a shadow library and a search engine for other shadow libraries, Anna's Archive aims to archive books and other written materials and make them widely available via torrents. Its data sets have also been heavily used by AI companies to train large language models. In addition to mirroring shadow libraries such as Sci-Hub, Library Genesis, and Z-Library, Anna's Archive made a major move into music pirating two weeks ago with an announcement that it scraped Spotify and made a 300TB copy of the most streamed songs. Despite that development, the person behind Anna's Archive said the domain suspension doesn't seem to be related to the Spotify scraping.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spotify-logos-1152x648-1767642275.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/spotify-logos-1152x648-1767642275.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 13:49:02 +0000",
      "title": "Spot the difference: Sony’s electric car gets a crossover version",
      "neutral_headline": "Spot the difference: Sony’s electric car gets a crossover version",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/sony-wants-its-afeela-ev-to-be-heavy-on-ai-also-shows-crossover/",
          "published_at": "Tue, 06 Jan 2026 13:49:02 +0000",
          "title": "Spot the difference: Sony’s electric car gets a crossover version",
          "standfirst": "AI will help drive you and entertain you, according to Sony Honda Mobility.",
          "content": "Six years after Sony announced its automotive ambitions, everything is looking a lot more concrete. Production of the Afeela 1, the electric sedan developed by Sony Honda Mobility, is already underway in Ohio. Deliveries will begin later this year in California, expanding to Arizona and Japan in 2027. And last night, on the eve of this year's Consumer Electronics Show, it even showed off a crossover version. \"The way we are fusing diverse technologies to deliver a completely novel mobility experience is not limited to a single model type,\" said Sony Honda Mobility CEO Yasuhide Mizuno. We first saw a Sony electric vehicle at CES in 2020 when the consumer electronics company showed off the Vision-S, telling the world it was mostly just a showcase for things like sensors and infotainment. Then the world caught a hot case of electric vehicle fever. Tesla's stock price went vertical, and the auto industry focused on EV optimism, even as a pandemic rewrote everyone's working rules.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/SHM_Press_Conference_Yasuhide-Mizuno_1-1152x648-1767701711.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/SHM_Press_Conference_Yasuhide-Mizuno_1-1152x648-1767701711.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_134",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 20:28:06 +0000",
      "title": "Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87",
      "neutral_headline": "Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/stewart-cheifet-pbs-host-who-chronicled-the-pc-revolution-dies-at-87/",
          "published_at": "Mon, 05 Jan 2026 20:28:06 +0000",
          "title": "Stewart Cheifet, PBS host who chronicled the PC revolution, dies at 87",
          "standfirst": "Cheifet produced more than 400 episodes of TV tracing the rise of personal computing.",
          "content": "Stewart Cheifet, the television producer and host who documented the personal computer revolution for nearly two decades on PBS, died on December 28, 2025, at age 87 in Philadelphia. Cheifet created and hosted Computer Chronicles, which ran on the public television network from 1983 to 2002 and helped demystify a new tech medium for millions of American viewers. Computer Chronicles covered everything from the earliest IBM PCs and Apple Macintosh models to the rise of the World Wide Web and the dot-com boom. Cheifet conducted interviews with computing industry figures, including Bill Gates, Steve Jobs, and Jeff Bezos, while demonstrating hardware and software for a general audience. From 1983 to 1990, he co-hosted the show with Gary Kildall, the Digital Research founder who created the popular CP/M operating system that predated MS-DOS on early personal computer systems.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cheifet_obit-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cheifet_obit-1152x648.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Tue, 06 Jan 2026 12:15:31 +0000",
      "title": "Private equity deal shows just how far America’s legacy rocket industry has fallen",
      "neutral_headline": "Private equity deal shows just how far America’s legacy rocket industry has fallen",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/a-private-equity-deal-reviving-rocketdyne-seems-more-like-a-corporate-breakup/",
          "published_at": "Tue, 06 Jan 2026 12:15:31 +0000",
          "title": "Private equity deal shows just how far America’s legacy rocket industry has fallen",
          "standfirst": "After peaking in the Cold War, the relic of Rocketdyne has changed ownership four times in 20 years.",
          "content": "If you are a student of space history or tracked the space industry before billionaires and venture capital changed it forever, you probably know the name Rocketdyne. A half-century ago, Rocketdyne manufactured almost all of the large liquid-fueled rocket engines in the United States. The Saturn V rocket that boosted astronauts toward the Moon relied on powerful engines developed by Rocketdyne, as did the Space Shuttle, the Atlas, Thor, and Delta rockets, and the US military's earliest ballistic missiles. Rocketdyne's dominance began to erode after the end of the Cold War. The company started in 1955 as a division of North American Aviation, then became part of Rockwell International until Boeing acquired Rockwell's aerospace division in 1996. Rocketdyne continually designed and tested large new rocket engines from the 1950s through the 1980s. Since then, Rocketdyne has developed and qualified just one large engine design from scratch—the RS-68—and it retired from service in 2024.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/6761894orig-1152x648-1767654223.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/6761894orig-1152x648-1767654223.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 21:57:07 +0000",
      "title": "Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule",
      "neutral_headline": "Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/under-anti-vaccine-rfk-jr-cdc-slashes-childhood-vaccine-schedule/",
          "published_at": "Mon, 05 Jan 2026 21:57:07 +0000",
          "title": "Under anti-vaccine RFK Jr., CDC slashes childhood vaccine schedule",
          "standfirst": "The changes are modeled after a small country with universal health care.",
          "content": "Under anti-vaccine Health Secretary Robert F. Kennedy Jr., federal health officials on Monday announced a sweeping and unprecedented overhaul of federal vaccine recommendations, abruptly paring down recommended immunizations for children from 17 to 11. Officials claimed the rationale for the change was to align US vaccine recommendations more closely with those of other high-income countries, namely Denmark, a small, far less diverse country of around 6 million people (smaller than the population of New York City) that has universal health care. The officials also claim the change is necessary to address the decline in public trust in vaccinations, which has been driven by anti-vaccine activists, including Kennedy. \"This decision protects children, respects families, and rebuilds trust in public health,\" Kennedy said in a statement.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2252087162-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2252087162-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Mon, 05 Jan 2026 20:01:12 +0000",
      "title": "Amazon Alexa+ released to the general public via an early access website",
      "neutral_headline": "Amazon Alexa+ released to the general public via an early access website",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/amazon-alexa-released-to-the-general-public-via-an-early-access-website/",
          "published_at": "Mon, 05 Jan 2026 20:01:12 +0000",
          "title": "Amazon Alexa+ released to the general public via an early access website",
          "standfirst": "Amazon brings back browser-based Alexa but will eventually add a paywall.",
          "content": "Anyone can now try Alexa+, Amazon’s generative AI assistant, through a free early access program at Alexa.com. The website frees the AI, which Amazon released via early access in February, from hardware and makes it as easily accessible as more established chatbots, like OpenAI's ChatGPT and Google's Gemini. Until today, you needed a supporting device to access Alexa+. Amazon hasn’t said when the early access period will end, but when it does, Alexa+ will be included with Amazon Prime memberships, which start at $15 per month, or cost $20 per month on its own. The above pricing suggests that Amazon wants Alexa+ to drive people toward Prime subscriptions. By being interwoven with Amazon’s shopping ecosystem, including Amazon's e-commerce platform, grocery delivery business, and Whole Foods, Alexa+ can make more money for Amazon.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201505743-1024x648.jpg",
      "popularity_score": 133
    }
  ]
}