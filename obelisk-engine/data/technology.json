{
  "updated_at": "2026-01-15T11:20:44.040Z",
  "clusters": [
    {
      "id": "cluster_6",
      "coverage": 2,
      "updated_at": "Thu, 15 Jan 2026 05:40:00 -0500",
      "title": "The Wikimedia Foundation says Microsoft, Meta, Amazon, Perplexity, and Mistral joined Wikimedia Enterprise to get \"tuned\" API access; Google is already a member (Emma Roth/The Verge)",
      "neutral_headline": "The Wikimedia Foundation says Microsoft, Meta, Amazon, Perplexity, and Mistral joined Wikimedia Enterprise to get \"tuned\" API access;...",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260115/p17#a260115p17",
          "published_at": "Thu, 15 Jan 2026 05:40:00 -0500",
          "title": "The Wikimedia Foundation says Microsoft, Meta, Amazon, Perplexity, and Mistral joined Wikimedia Enterprise to get \"tuned\" API access; Google is already a member (Emma Roth/The Verge)",
          "standfirst": "Emma Roth / The Verge: The Wikimedia Foundation says Microsoft, Meta, Amazon, Perplexity, and Mistral joined Wikimedia Enterprise to get &ldquo;tuned&rdquo; API access; Google is already a member &mdash; The companies have joined Google as the latest members of the Wikimedia Enterprise program.",
          "content": "Emma Roth / The Verge: The Wikimedia Foundation says Microsoft, Meta, Amazon, Perplexity, and Mistral joined Wikimedia Enterprise to get &ldquo;tuned&rdquo; API access; Google is already a member &mdash; The companies have joined Google as the latest members of the Wikimedia Enterprise program.",
          "feed_position": 3,
          "image_url": "http://www.techmeme.com/260115/i17.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/862109/wikipedia-microsoft-meta-perplexity-ai-training-wikimedia-foundation",
          "published_at": "2026-01-15T03:30:00-05:00",
          "title": "Microsoft, Meta, and Amazon are paying up for &#8216;enterprise&#8217; access to Wikipedia",
          "standfirst": "Microsoft, Meta, Amazon, Perplexity, and Mistral AI have joined Google in paying the Wikimedia Foundation for access to its projects, including Wikipedia's vast collection of articles. The Wikimedia Foundation announced the news as part of Wikipedia's 25th anniversary on Thursday. The partnerships are part of Wikimedia Enterprise, an initiative launched in 2021 that gives large [&#8230;]",
          "content": "Microsoft, Meta, Amazon, Perplexity, and Mistral AI have joined Google in paying the Wikimedia Foundation for access to its projects, including Wikipedia's vast collection of articles. The Wikimedia Foundation announced the news as part of Wikipedia's 25th anniversary on Thursday. The partnerships are part of Wikimedia Enterprise, an initiative launched in 2021 that gives large companies access to a premium version of Wikipedia's API for a fee. Lane Becker, the Wikimedia Foundation's senior director of earned revenue, tells The Verge that the program offers a version of Wikipedia \"tuned\" for commercial use and AI companies. \"We take feature … Read the full story at The Verge.",
          "feed_position": 2
        }
      ],
      "featured_image": "http://www.techmeme.com/260115/i17.jpg",
      "popularity_score": 2019.3211000000001
    },
    {
      "id": "cluster_17",
      "coverage": 2,
      "updated_at": "Thu, 15 Jan 2026 10:00:36 +0000",
      "title": "The best cheap fitness trackers for 2026",
      "neutral_headline": "The best cheap fitness trackers for 2026",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/best-cheap-fitness-trackers-140054780.html",
          "published_at": "Thu, 15 Jan 2026 10:00:36 +0000",
          "title": "The best cheap fitness trackers for 2026",
          "standfirst": "You don’t need to spend a fortune to stay on top of your health goals while tracking your fitness. These days, even cheap fitness trackers come packed with features that help you monitor your heart rate, track your steps and even analyze your sleep stages. Many budget options now include GPS tracking for those outdoor runs, real-time heart rate tracking to keep you in the right zone during workouts and, thankfully, most work with both iPhone and Android devices.Some even go beyond basic metrics, providing insights on daily readiness to help you decide if you’re up for an intense workout or need a lighter day. From simple step counters to more advanced running watches, affordable fitness trackers offer plenty to support your journey toward better health without breaking the bank. Table of contents Best budget fitness trackers for 2026 What to look for in a cheap fitness tracker Other budget fitness trackers we tested What about fitness rings? Best budget fitness trackers for 2026 What to look for in a cheap fitness tracker All of the best fitness trackers should have at least three features: a program for activity tracking, the option to monitor and collect data about your sleep patterns and the ability to do things like heart rate monitoring and blood oxygen level tracking (though, the readings might not be super accurate). Don’t set your sights too high and expect metrics like blood pressure monitoring or ECG support; for that, you’d need to invest in a more expensive fitness watch or wearable like a Samsung Galaxy Watch, which falls under the best smartwatches category and will set you back over $400. Fitness features A cheap workout tracker can be great for someone looking to keep tabs on small, achievable goals like 10,000 steps before sundown or 30 minutes of a HIIT workout to get your heart rate peaking. An experienced long-distance runner looking to train for a triathlon might opt for a more expensive device that can measure cadence or ground contact time, and can track more customizable workouts, offer different sports modes or give deeper insights into performance data. At the very least, a budget workout tracker should be able to offer fitness tracking features beyond walking and running — otherwise, it would just be a pedometer. The number of activities a device will recognize varies. Some will get funky with it and consider skateboarding a workout, while others won’t be able to track a jumping jack. At this price point, you can expect a device to measure a mix of cardio, machine workouts and strength training. With each, you might get a numerical or visual breakdown of heart rate activity, overall pace, and calories burned per session. Although some cheap trackers can offer a really good overview of heart rate zone activity during a workout, a more technically advanced device might be able to go a step further and explain what your results mean and coach you on how to keep your heart rate in a specific bracket so that you can burn more fat per workout. I found that the more budget-friendly the device, the more likely it is that a tracker will fall short when it comes to smart counseling or offering predictive insights beyond a given workout. If a budget tracker does happen to offer some semblance of a coaching program, you can expect it to sit behind a paywall. Workout tracking and planning your recovery is just as essential to any fitness journey. A sub-$100 device should be able to tell you how long you’ve slept and provide a breakdown of deep, light and REM sleep patterns. It's not a guarantee that you will get a sleep “score” or insights on how to get better rest — that data is usually found on more expensive wearables. Also, because these trackers aren’t designed for bedtime specifically — be mindful of comfort. The bands and watch face on a budget fitness watch may not be ideal for getting some good shut-eye. Connectivity and practicality Not all of the best budget fitness trackers are designed to seamlessly integrate with a smartphone. The trackers tested for this roundup can’t directly make calls or send texts to contacts on a paired iPhone or Android smartphone. They can, however, display and dismiss incoming calls and notifications via a Bluetooth connection. You can forget about checking your email or paying for a coffee from your wrist using these more affordable devices. Most cheap fitness trackers also won't include built-in GPS tracking. Instead, they usually depend on a paired smartphone to gather location data. The drawback of using a fitness tracker without GPS is that it might not provide as precise for tracking distance or pace. You also can't use a budget tracker to get turn-by-turn directions during a walk or while running errands. For the more outdoorsy consumers, having GPS could be a key safety feature if you want this kind of functionality at your fingertips. Design You also might find that an inexpensive fitness tracker is harder to navigate than a more advanced smartwatch. Whether it be a screen size issue or simply not having a smart enough interface, don't expect every feature to be one that you can engage with directly on your wrist. You’ll likely need to use your phone to input data or access detailed wellness metrics. Build quality will also vary. While you won’t get premium materials or ultra-bright OLED screens, most best cheap fitness trackers include some level of sweat and water resistance — perfect for everyday wear and casual workouts. And for those starting out with basic gadgets to support their fitness journey, these affordable trackers offer a great balance of essential features without the hefty price tag. Other budget fitness trackers we tested Amazfit Bip 6 The Amazfit Bip 6, an $80 smartwatch from Zepp Health, didn’t quite make the cut. As a fitness tracker, it’s decent, but it’s a frustrating smartwatch substitute. For workouts, the built-in GPS tracks runs and rides without your phone and, combined with the heart rate and blood oxygen sensors, collects a good amount of data to create accurate pictures of your exertion levels, cadence and pace. It’s remarkably lightweight but doesn’t feel cheap and the AMOLED screen is bright and sharp. It’s not an always-on display, but lifting your wrist wakes it reliably. The sleep tracking data is on par with what we measured on other smartwatches and there’s even a daily readiness score that compares your sleep quality and the previous day’s exertion to estimate how physically prepared you are for the day ahead — similar to what Pixel Watches, Fitbit devices and Garmin watches offer. And since the watch battery lasts for over a week on a charge, you may be a lot more apt to wear it to bed than a watch you have to charge daily. We weren’t expecting an $80 device to be a serious Apple Watch challenger, but the Bip 6’s glitches and overly complicated interface (both on the app and on the watch itself) were disappointing. During a week of testing, I got multiple repeated notifications, even after they were deleted, along with suggestions to stand when I was actively doing chores around the house. The watch faces are not customizable, so it was hard to get the info I needed at a glance (the Zepp app has lots of paid watch faces that may have what I wanted, but I didn’t want to pay $3 for something that’s free elsewhere). Marketing details state that the Bip 6 can auto-detect workouts, including walking and bike riding. During testing, I walked once or twice per day for over one mile and went on two bike rides, but no workout was ever detected. The watch integrates with Apple Health, so I was able to see how it compares to the data my Apple Watch gathers. After a week of wearing the Bip 6, with no changes to my daily routine, I averaged 400 fewer calories burned and 2.4 fewer miles tracked each day. That was possibly the biggest disappointment of all. — Amy Skorheim, Senior Reporter Wyze Watch 47c I didn't have high expectations of the Wyze Watch 47c, but I was shocked at how little this tracker can do. The 47c can only track walks and runs. It has a dedicated widget, a small logo of a man running, and when you tap it, it begins measuring your pace, heart rate, calories burned and mileage. It does not auto-detect or auto-pause workouts and it doesn't differentiate between a run and walk. Most importantly, this device can’t track any other exercises. It’s basically a glorified pedometer. The 47c was also my least favorite to sleep with, mainly because the square watch face is so large and heavy. Even if I did manage to sleep through the night with it on, it only gave me a basic sleep report. — M.S. Garmin vivofit 4 The Garmin vivofit 4 has a tiny display that is not a touchscreen and all navigation happens through one button. The watch face is impossible to read outdoors and the exercise widget is also very finicky. To start tracking a run, you have to hold down the main button and flip through some pages until you get to a moving person icon. Once there, you have to press the bottom right corner of the bar and hold down and if you press for too long or in the wrong spot, it’ll switch to another page, like a stopwatch. It’s incredibly frustrating. Once you start a run though, it will start tracking your steps, your distance — and that's pretty much it. It does not auto-detect or auto-pause workouts. It doesn't alert you of any mileage or calorie milestones. — M.S. What about fitness rings? While smart rings are gaining popularity for health tracking, they generally don’t fall into the “budget” or “cheap” price range. A smart ring like the Oura Ring offers features such as sleep monitoring, heart rate tracking and readiness scores in an ultra-compact form factor that fits on your finger instead of your wrist. These rings are best suited for people who want discreet, all-day health insights without wearing a traditional watch or band — but with prices typically starting above $300, they’re more of a premium option than a budget-friendly pick. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/wearables/best-cheap-fitness-trackers-140054780.html?src=rss",
          "content": "You don’t need to spend a fortune to stay on top of your health goals while tracking your fitness. These days, even cheap fitness trackers come packed with features that help you monitor your heart rate, track your steps and even analyze your sleep stages. Many budget options now include GPS tracking for those outdoor runs, real-time heart rate tracking to keep you in the right zone during workouts and, thankfully, most work with both iPhone and Android devices.Some even go beyond basic metrics, providing insights on daily readiness to help you decide if you’re up for an intense workout or need a lighter day. From simple step counters to more advanced running watches, affordable fitness trackers offer plenty to support your journey toward better health without breaking the bank. Table of contents Best budget fitness trackers for 2026 What to look for in a cheap fitness tracker Other budget fitness trackers we tested What about fitness rings? Best budget fitness trackers for 2026 What to look for in a cheap fitness tracker All of the best fitness trackers should have at least three features: a program for activity tracking, the option to monitor and collect data about your sleep patterns and the ability to do things like heart rate monitoring and blood oxygen level tracking (though, the readings might not be super accurate). Don’t set your sights too high and expect metrics like blood pressure monitoring or ECG support; for that, you’d need to invest in a more expensive fitness watch or wearable like a Samsung Galaxy Watch, which falls under the best smartwatches category and will set you back over $400. Fitness features A cheap workout tracker can be great for someone looking to keep tabs on small, achievable goals like 10,000 steps before sundown or 30 minutes of a HIIT workout to get your heart rate peaking. An experienced long-distance runner looking to train for a triathlon might opt for a more expensive device that can measure cadence or ground contact time, and can track more customizable workouts, offer different sports modes or give deeper insights into performance data. At the very least, a budget workout tracker should be able to offer fitness tracking features beyond walking and running — otherwise, it would just be a pedometer. The number of activities a device will recognize varies. Some will get funky with it and consider skateboarding a workout, while others won’t be able to track a jumping jack. At this price point, you can expect a device to measure a mix of cardio, machine workouts and strength training. With each, you might get a numerical or visual breakdown of heart rate activity, overall pace, and calories burned per session. Although some cheap trackers can offer a really good overview of heart rate zone activity during a workout, a more technically advanced device might be able to go a step further and explain what your results mean and coach you on how to keep your heart rate in a specific bracket so that you can burn more fat per workout. I found that the more budget-friendly the device, the more likely it is that a tracker will fall short when it comes to smart counseling or offering predictive insights beyond a given workout. If a budget tracker does happen to offer some semblance of a coaching program, you can expect it to sit behind a paywall. Workout tracking and planning your recovery is just as essential to any fitness journey. A sub-$100 device should be able to tell you how long you’ve slept and provide a breakdown of deep, light and REM sleep patterns. It's not a guarantee that you will get a sleep “score” or insights on how to get better rest — that data is usually found on more expensive wearables. Also, because these trackers aren’t designed for bedtime specifically — be mindful of comfort. The bands and watch face on a budget fitness watch may not be ideal for getting some good shut-eye. Connectivity and practicality Not all of the best budget fitness trackers are designed to seamlessly integrate with a smartphone. The trackers tested for this roundup can’t directly make calls or send texts to contacts on a paired iPhone or Android smartphone. They can, however, display and dismiss incoming calls and notifications via a Bluetooth connection. You can forget about checking your email or paying for a coffee from your wrist using these more affordable devices. Most cheap fitness trackers also won't include built-in GPS tracking. Instead, they usually depend on a paired smartphone to gather location data. The drawback of using a fitness tracker without GPS is that it might not provide as precise for tracking distance or pace. You also can't use a budget tracker to get turn-by-turn directions during a walk or while running errands. For the more outdoorsy consumers, having GPS could be a key safety feature if you want this kind of functionality at your fingertips. Design You also might find that an inexpensive fitness tracker is harder to navigate than a more advanced smartwatch. Whether it be a screen size issue or simply not having a smart enough interface, don't expect every feature to be one that you can engage with directly on your wrist. You’ll likely need to use your phone to input data or access detailed wellness metrics. Build quality will also vary. While you won’t get premium materials or ultra-bright OLED screens, most best cheap fitness trackers include some level of sweat and water resistance — perfect for everyday wear and casual workouts. And for those starting out with basic gadgets to support their fitness journey, these affordable trackers offer a great balance of essential features without the hefty price tag. Other budget fitness trackers we tested Amazfit Bip 6 The Amazfit Bip 6, an $80 smartwatch from Zepp Health, didn’t quite make the cut. As a fitness tracker, it’s decent, but it’s a frustrating smartwatch substitute. For workouts, the built-in GPS tracks runs and rides without your phone and, combined with the heart rate and blood oxygen sensors, collects a good amount of data to create accurate pictures of your exertion levels, cadence and pace. It’s remarkably lightweight but doesn’t feel cheap and the AMOLED screen is bright and sharp. It’s not an always-on display, but lifting your wrist wakes it reliably. The sleep tracking data is on par with what we measured on other smartwatches and there’s even a daily readiness score that compares your sleep quality and the previous day’s exertion to estimate how physically prepared you are for the day ahead — similar to what Pixel Watches, Fitbit devices and Garmin watches offer. And since the watch battery lasts for over a week on a charge, you may be a lot more apt to wear it to bed than a watch you have to charge daily. We weren’t expecting an $80 device to be a serious Apple Watch challenger, but the Bip 6’s glitches and overly complicated interface (both on the app and on the watch itself) were disappointing. During a week of testing, I got multiple repeated notifications, even after they were deleted, along with suggestions to stand when I was actively doing chores around the house. The watch faces are not customizable, so it was hard to get the info I needed at a glance (the Zepp app has lots of paid watch faces that may have what I wanted, but I didn’t want to pay $3 for something that’s free elsewhere). Marketing details state that the Bip 6 can auto-detect workouts, including walking and bike riding. During testing, I walked once or twice per day for over one mile and went on two bike rides, but no workout was ever detected. The watch integrates with Apple Health, so I was able to see how it compares to the data my Apple Watch gathers. After a week of wearing the Bip 6, with no changes to my daily routine, I averaged 400 fewer calories burned and 2.4 fewer miles tracked each day. That was possibly the biggest disappointment of all. — Amy Skorheim, Senior Reporter Wyze Watch 47c I didn't have high expectations of the Wyze Watch 47c, but I was shocked at how little this tracker can do. The 47c can only track walks and runs. It has a dedicated widget, a small logo of a man running, and when you tap it, it begins measuring your pace, heart rate, calories burned and mileage. It does not auto-detect or auto-pause workouts and it doesn't differentiate between a run and walk. Most importantly, this device can’t track any other exercises. It’s basically a glorified pedometer. The 47c was also my least favorite to sleep with, mainly because the square watch face is so large and heavy. Even if I did manage to sleep through the night with it on, it only gave me a basic sleep report. — M.S. Garmin vivofit 4 The Garmin vivofit 4 has a tiny display that is not a touchscreen and all navigation happens through one button. The watch face is impossible to read outdoors and the exercise widget is also very finicky. To start tracking a run, you have to hold down the main button and flip through some pages until you get to a moving person icon. Once there, you have to press the bottom right corner of the bar and hold down and if you press for too long or in the wrong spot, it’ll switch to another page, like a stopwatch. It’s incredibly frustrating. Once you start a run though, it will start tracking your steps, your distance — and that's pretty much it. It does not auto-detect or auto-pause workouts. It doesn't alert you of any mileage or calorie milestones. — M.S. What about fitness rings? While smart rings are gaining popularity for health tracking, they generally don’t fall into the “budget” or “cheap” price range. A smart ring like the Oura Ring offers features such as sleep monitoring, heart rate tracking and readiness scores in an ultra-compact form factor that fits on your finger instead of your wrist. These rings are best suited for people who want discreet, all-day health insights without wearing a traditional watch or band — but with prices typically starting above $300, they’re more of a premium option than a budget-friendly pick. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/wearables/best-cheap-fitness-trackers-140054780.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/verizon-says-its-service-is-back-after-a-10-hour-outage-183048229.html",
          "published_at": "Thu, 15 Jan 2026 03:39:40 +0000",
          "title": "Verizon says its service is back after a 10-hour outage",
          "standfirst": "Verizon’s network is experiencing technical issues that are impacting calls and wireless data. Verizon customers on X have reported seeing “SOS” rather than the traditional network bars on their smartphones, and even the network provider’s own status page struggled to load, likely due to the number of customers trying to access it.Based on the experience of Verizon users on Engadget’s staff, the services that are impacted appear to be calls and wireless data. Text messages continue to be delivered normally, at least for some users. On DownDetector, reports of a Verizon outage started growing around 12PM ET and numbered in the hundreds of thousands at their peak. DownDetector also shows spikes in outage reports on competing networks like AT&T and T-Mobile, but in terms of magnitude, they’re much smaller than the issue Verizon is facing. For example, Verizon peaked at 181,769 reports, while AT&T’s was just 1,769 reports. The difference between the two is great enough that those AT&T reports could be from people trying to contact Verizon customers and thinking that their personal network was the problem.We are aware of an issue impacting wireless voice and data services for some customers. Our engineers are engaged and are working to identify and solve the issue quickly. We understand how important reliable connectivity is and apologize for the inconvenience.— Verizon News (@VerizonNews) January 14, 2026 In a post on the cell provider’s news account on X, Verizon acknowledged the issues with its network. “We are aware of an issue impacting wireless voice and data services for some customers,” Verizon wrote. “Our engineers are engaged and are working to identify and solve the issue quickly. We understand how important reliable connectivity is and apologize for the inconvenience.”Based on DownDetector’s map of outage reports, issues with Verizon’s network appear to be concentrated in major cities in the eastern United States. The majority of reports appear to be coming out of Boston, New York and Washington DC, though the map also shows growing hot spots in Chicago, San Francisco and Los Angeles.Verizon engineering teams are continuing to address today's service interruptions. Our teams remain fully deployed and are focused on the issue. We understand the impact this has on your day and remain committed to resolving this as quickly as possible.— Verizon News (@VerizonNews) January 14, 2026 At 2:14PM ET, Verizon shared on X that its engineering teams “remain fully deployed” to work on fixing the outage. The company didn’t share when the issue would resolved or how many of its customers are currently impacted. Reports on DownDetector have dropped since their peak at 12:43PM ET, but thousands of Verizon customers are still noticing issues with the service.As of 3:09PM ET, Verizon has yet to share more information about the recovery of the company’s cell network. Some Verizon customers on X have noticed their cell service returning, but it’s not clear if this means the network’s technical issues have been fixed. At 4:06PM ET, nearly two hours since the company’s last statement, at least one member of Engadget’s staff reports their service has been restored. The connectivity issues are still affecting Verizon customers, however. DownDetector received over 55,000 outage reports as recently as 3:47PM ET.Verizon's team is on the ground actively working to fix today’s service issue that is impacting some customers. We know this is a huge inconvenience, and our top priority is to get you back online and connected as fast as possible. We appreciate your patience while we work to…— Verizon News (@VerizonNews) January 14, 2026 Verizon posted at 4:12PM ET that work continues on addressing the outage, but the issue hasn’t been completely fixed. According to the company, its team is “on the ground actively working to fix today’s service issue that is impacting some customers.”As of 4:52PM ET, the Verizon’s network has been experiencing issues for around four hours, making today’s outage nearly as long as the last major outage the company had in 2024. Like that 2024 outage, Verizon has yet to share what exactly is causing the issues with its network. Without out an official update, it’s safe to assume the company is still working on a fix. At 5:41PM ET, DownDetector latest tally still shows over 46,000 people reporting issues with Verizon’s network. Based on the platform’s map, the same cities are filing the bulk of the outage reports, though reporting appears more diffuse than before as news of the outage has spread across the country.At 6:20PM ET, the situation was much the same. Tens of thousands of users (including Engadget editors) still don’t have proper service, and Verizon had not updated its customers since 4:12PM ET. There are intermittent reports of service coming back and then failing again but seemingly no true fix has been deployed.At 10:20PM ET, Verizon has announced that the outage has been resolved and has encouraged subscribers still having issues to restart their devices to reconnect to the network. The company also said that it will provide account credits to affected customers. Both T-Mobile and AT&T have confirmed that their own networks are unaffected by the issues facing their competitor. In a post on X, T-Mobile shared that its network is “operating normally and as expected.” Meanwhile, AT&T says that for any of its customers experiencing issues, “it’s not us...it’s the other guys.”Update, January 14, 7:25PM ET: This article was published as a developing story and was updated multiple times over a period of around seven hours. These updates were additive, and noted with a timestamp within the article. As of writing, Verizon is still down for tens of thousands of users and the company’s support team has not issued an update on the stituation in over three hours. Happy Wednesday!Update January 14, 10:39PM ET: This story has been updated to add Verizon’s latest update that the outage has been resolved.This article originally appeared on Engadget at https://www.engadget.com/big-tech/verizon-says-its-service-is-back-after-a-10-hour-outage-183048229.html?src=rss",
          "content": "Verizon’s network is experiencing technical issues that are impacting calls and wireless data. Verizon customers on X have reported seeing “SOS” rather than the traditional network bars on their smartphones, and even the network provider’s own status page struggled to load, likely due to the number of customers trying to access it.Based on the experience of Verizon users on Engadget’s staff, the services that are impacted appear to be calls and wireless data. Text messages continue to be delivered normally, at least for some users. On DownDetector, reports of a Verizon outage started growing around 12PM ET and numbered in the hundreds of thousands at their peak. DownDetector also shows spikes in outage reports on competing networks like AT&T and T-Mobile, but in terms of magnitude, they’re much smaller than the issue Verizon is facing. For example, Verizon peaked at 181,769 reports, while AT&T’s was just 1,769 reports. The difference between the two is great enough that those AT&T reports could be from people trying to contact Verizon customers and thinking that their personal network was the problem.We are aware of an issue impacting wireless voice and data services for some customers. Our engineers are engaged and are working to identify and solve the issue quickly. We understand how important reliable connectivity is and apologize for the inconvenience.— Verizon News (@VerizonNews) January 14, 2026 In a post on the cell provider’s news account on X, Verizon acknowledged the issues with its network. “We are aware of an issue impacting wireless voice and data services for some customers,” Verizon wrote. “Our engineers are engaged and are working to identify and solve the issue quickly. We understand how important reliable connectivity is and apologize for the inconvenience.”Based on DownDetector’s map of outage reports, issues with Verizon’s network appear to be concentrated in major cities in the eastern United States. The majority of reports appear to be coming out of Boston, New York and Washington DC, though the map also shows growing hot spots in Chicago, San Francisco and Los Angeles.Verizon engineering teams are continuing to address today's service interruptions. Our teams remain fully deployed and are focused on the issue. We understand the impact this has on your day and remain committed to resolving this as quickly as possible.— Verizon News (@VerizonNews) January 14, 2026 At 2:14PM ET, Verizon shared on X that its engineering teams “remain fully deployed” to work on fixing the outage. The company didn’t share when the issue would resolved or how many of its customers are currently impacted. Reports on DownDetector have dropped since their peak at 12:43PM ET, but thousands of Verizon customers are still noticing issues with the service.As of 3:09PM ET, Verizon has yet to share more information about the recovery of the company’s cell network. Some Verizon customers on X have noticed their cell service returning, but it’s not clear if this means the network’s technical issues have been fixed. At 4:06PM ET, nearly two hours since the company’s last statement, at least one member of Engadget’s staff reports their service has been restored. The connectivity issues are still affecting Verizon customers, however. DownDetector received over 55,000 outage reports as recently as 3:47PM ET.Verizon's team is on the ground actively working to fix today’s service issue that is impacting some customers. We know this is a huge inconvenience, and our top priority is to get you back online and connected as fast as possible. We appreciate your patience while we work to…— Verizon News (@VerizonNews) January 14, 2026 Verizon posted at 4:12PM ET that work continues on addressing the outage, but the issue hasn’t been completely fixed. According to the company, its team is “on the ground actively working to fix today’s service issue that is impacting some customers.”As of 4:52PM ET, the Verizon’s network has been experiencing issues for around four hours, making today’s outage nearly as long as the last major outage the company had in 2024. Like that 2024 outage, Verizon has yet to share what exactly is causing the issues with its network. Without out an official update, it’s safe to assume the company is still working on a fix. At 5:41PM ET, DownDetector latest tally still shows over 46,000 people reporting issues with Verizon’s network. Based on the platform’s map, the same cities are filing the bulk of the outage reports, though reporting appears more diffuse than before as news of the outage has spread across the country.At 6:20PM ET, the situation was much the same. Tens of thousands of users (including Engadget editors) still don’t have proper service, and Verizon had not updated its customers since 4:12PM ET. There are intermittent reports of service coming back and then failing again but seemingly no true fix has been deployed.At 10:20PM ET, Verizon has announced that the outage has been resolved and has encouraged subscribers still having issues to restart their devices to reconnect to the network. The company also said that it will provide account credits to affected customers. Both T-Mobile and AT&T have confirmed that their own networks are unaffected by the issues facing their competitor. In a post on X, T-Mobile shared that its network is “operating normally and as expected.” Meanwhile, AT&T says that for any of its customers experiencing issues, “it’s not us...it’s the other guys.”Update, January 14, 7:25PM ET: This article was published as a developing story and was updated multiple times over a period of around seven hours. These updates were additive, and noted with a timestamp within the article. As of writing, Verizon is still down for tens of thousands of users and the company’s support team has not issued an update on the stituation in over three hours. Happy Wednesday!Update January 14, 10:39PM ET: This story has been updated to add Verizon’s latest update that the outage has been resolved.This article originally appeared on Engadget at https://www.engadget.com/big-tech/verizon-says-its-service-is-back-after-a-10-hour-outage-183048229.html?src=rss",
          "feed_position": 2
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html",
          "published_at": "Wed, 14 Jan 2026 21:12:43 +0000",
          "title": "The best VPN deals: Up to 88 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "In a chaotic world, one thing you can count on is your own common-sense steps toward better cybersecurity. January is a great time to grab a subscription for yourself or a loved one, as a few holiday sales are (inexplicably) still happening. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. We strongly recommend using a VPN, but you might get stuck with a substandard app if you jump on the very first deal you see. You might also mistakenly end up paying more than you want to, as even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $78.18 for a two-year subscription with four months free (78 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 78 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $100.58 for a two-year subscription with four months free (74 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan. NordVPN Plus — $105.36 for a two-year subscription (70 percent off): NordVPN has also taken 70 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $49.50 for a one-year subscription with six months free (79 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 18 months of CyberGhost for 79 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "content": "In a chaotic world, one thing you can count on is your own common-sense steps toward better cybersecurity. January is a great time to grab a subscription for yourself or a loved one, as a few holiday sales are (inexplicably) still happening. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. We strongly recommend using a VPN, but you might get stuck with a substandard app if you jump on the very first deal you see. You might also mistakenly end up paying more than you want to, as even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Plenty of the best VPNs — including our top pick, Proton VPN — are still running end-of-year deals that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're comfortable with a service before you take the plunge, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $78.18 for a two-year subscription with four months free (78 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 78 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $100.58 for a two-year subscription with four months free (74 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan. NordVPN Plus — $105.36 for a two-year subscription (70 percent off): NordVPN has also taken 70 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $49.50 for a one-year subscription with six months free (79 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 18 months of CyberGhost for 79 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/z-ais-open-source-glm-image-beats-googles-nano-banana-pro-at-complex-text",
          "published_at": "Wed, 14 Jan 2026 20:59:00 GMT",
          "title": "Z.ai's open source GLM-Image beats Google's Nano Banana Pro at complex text rendering, but not aesthetics",
          "standfirst": "The two big stories of AI in 2026 so far have been the incredible rise in usage and praise for Anthropic&#x27;s Claude Code and a similar huge boost in user adoption for Google&#x27;s Gemini 3 AI model family released late last year — the latter of which includes Nano Banana Pro (also known as Gemini 3 Pro Image), a powerful, fast, and flexible image generation model that renders complex, text-heavy infographics quickly and accurately, making it an excellent fit for enterprise use (think: collateral, trainings, onboarding, stationary, etc).But of course, both of those are proprietary offerings. And yet, open source rivals have not been far behind. This week, we got a new open source alternative to Nano Banana Pro in the category of precise, text-heavy image generators: GLM-Image, a new 16-billion parameter open-source model from recently public Chinese startup Z.ai.By abandoning the industry-standard \"pure diffusion\" architecture that powers most leading image generator models in favor of a hybrid auto-regressive (AR) + diffusion design, GLM-Image has achieved what was previously thought to be the domain of closed, proprietary models: state-of-the-art performance in generating text-heavy, information-dense visuals like infographics, slides, and technical diagrams.It even beats Google&#x27;s Nano Banana Pro on the shared by z.ai — though in practice, my own quick usage found it to be far less accurate at instruction following and text rendering (and other users seem to agree). But for enterprises seeking cost-effective and customizable, friendly-licensed alternatives to proprietary AI models, z.ai&#x27;s GLM-Image may be \"good enough\" or then some to take over the job of a primary image generator, depending on their specific use cases, needs and requirements.The Benchmark: Toppling the Proprietary GiantThe most compelling argument for GLM-Image is not its aesthetics, but its precision. In the CVTG-2k (Complex Visual Text Generation) benchmark, which evaluates a model&#x27;s ability to render accurate text across multiple regions of an image, GLM-Image scored a Word Accuracy average of 0.9116.To put that number in perspective, Nano Banana 2.0 aka Pro—often cited as the benchmark for enterprise reliability—scored 0.7788. This isn&#x27;t a marginal gain; it is a generational leap in semantic control.While Nano Banana Pro retains a slight edge in single-stream English long-text generation (0.9808 vs. GLM-Image&#x27;s 0.9524), it falters significantly when the complexity increases. As the number of text regions grows, Nano Banana&#x27;s accuracy remains in the 70s, whereas GLM-Image maintains >90% accuracy even with multiple distinct text elements. For enterprise use cases—where a marketing slide needs a title, three bullet points, and a caption simultaneously—this reliability is the difference between a production-ready asset and a hallucination.Unfortunately, my own usage of a demo inference of GLM-Image on Hugging Face proved to be less reliable than the benchmarks might suggest. My prompt to generate an \"infographic labeling all the major constellations visible from the U.S. Northern Hemisphere right now on Jan 14 2026 and putting faded images of their namesakes behind the star connection line diagrams\" did not result in what I asked for, instead fulfilling maybe 20% or less of the specified content. But Google&#x27;s Nano Banana Pro handled it like a champ, as you&#x27;ll see below:Of course, a large portion of this is no doubt due to the fact that Nano Banana Pro is integrated with Google search, so it can look up information on the web in response to my prompt, whereas GLM-Image is not, and therefore, likely requires far more specific instructions about the actual text and other content the image should contain. But still, once you&#x27;re used to being able to type some simple instructions and get a fully researched and well populated image via the latter, it&#x27;s hard to imagine deploying a sub-par alternative unless you have very specific requirements around cost, data residency and security — or the customizability needs of your organization are so great. Furthermore, Nano Banana Pro still edged out GLM-Image in terms of pure aesthetics — using the OneIG benchmark, Nano Banana 2.0 is at 0.578 vs. GLM-Image at 0.528 — and indeed, as the top header artwork of this article indicates, GLM-Image does not always render as crisp, finely detailed and pleasing an image as Google&#x27;s generator. The Architectural Shift: Why \"Hybrid\" MattersWhy does GLM-Image succeed where pure diffusion models fail? The answer lies in Z.ai’s decision to treat image generation as a reasoning problem first and a painting problem second.Standard latent diffusion models (like Stable Diffusion or Flux) attempt to handle global composition and fine-grained texture simultaneously. This often leads to \"semantic drift,\" where the model forgets specific instructions (like \"place the text in the top left\") as it focuses on making the pixels look realistic.GLM-Image decouples these objectives into two specialized \"brains\" totaling 16 billion parameters:The Auto-Regressive Generator (The \"Architect\"): Initialized from Z.ai’s GLM-4-9B language model, this 9-billion parameter module processes the prompt logically. It doesn&#x27;t generate pixels; instead, it outputs \"visual tokens\"—specifically semantic-VQ tokens. These tokens act as a compressed blueprint of the image, locking in the layout, text placement, and object relationships before a single pixel is drawn. This leverages the reasoning power of an LLM, allowing the model to \"understand\" complex instructions (e.g., \"A four-panel tutorial\") in a way diffusion noise predictors cannot.The Diffusion Decoder (The \"Painter\"): Once the layout is locked by the AR module, a 7-billion parameter Diffusion Transformer (DiT) decoder takes over. Based on the CogView4 architecture, this module fills in the high-frequency details—texture, lighting, and style.By separating the \"what\" (AR) from the \"how\" (Diffusion), GLM-Image solves the \"dense knowledge\" problem. The AR module ensures the text is spelled correctly and placed accurately, while the Diffusion module ensures the final result looks photorealistic.Training the Hybrid: A Multi-Stage EvolutionThe secret sauce of GLM-Image’s performance isn&#x27;t just the architecture; it is a highly specific, multi-stage training curriculum that forces the model to learn structure before detail.The training process began by freezing the text word embedding layer of the original GLM-4 model while training a new \"vision word embedding\" layer and a specialized vision LM head. This allowed the model to project visual tokens into the same semantic space as text, effectively teaching the LLM to \"speak\" in images. Crucially, Z.ai implemented MRoPE (Multidimensional Rotary Positional Embedding) to handle the complex interleaving of text and images required for mixed-modal generation.The model was then subjected to a progressive resolution strategy:Stage 1 (256px): The model trained on low-resolution, 256-token sequences using a simple raster scan order.Stage 2 (512px - 1024px): As resolution increased to a mixed stage (512px to 1024px), the team observed a drop in controllability. To fix this, they abandoned simple scanning for a progressive generation strategy.In this advanced stage, the model first generates approximately 256 \"layout tokens\" from a down-sampled version of the target image. These tokens act as a structural anchor. By increasing the training weight on these preliminary tokens, the team forced the model to prioritize the global layout—where things are—before generating the high-resolution details. This is why GLM-Image excels at posters and diagrams: it \"sketches\" the layout first, ensuring the composition is mathematically sound before rendering the pixels.Licensing Analysis: A Permissive, If Slightly Ambiguous, Win for EnterpriseFor enterprise CTOs and legal teams, the licensing structure of GLM-Image is a significant competitive advantage over proprietary APIs, though it comes with a minor caveat regarding documentation.The Ambiguity: There is a slight discrepancy in the release materials. The model’s Hugging Face repository explicitly tags the weights with the MIT License. However, the accompanying GitHub repository and documentation reference the Apache License 2.0.Why This Is Still Good News: Despite the mismatch, both licenses are the \"gold standard\" for enterprise-friendly open source.Commercial Viability: Both MIT and Apache 2.0 allow for unrestricted commercial use, modification, and distribution. Unlike the \"open rail\" licenses common in other image models (which often restrict specific use cases) or \"research-only\" licenses (like early LLaMA releases), GLM-Image is effectively \"open for business\" immediately.The Apache Advantage (If Applicable): If the code falls under Apache 2.0, this is particularly beneficial for large organizations. Apache 2.0 includes an explicit patent grant clause, meaning that by contributing to or using the software, contributors grant a patent license to users. This reduces the risk of future patent litigation—a major concern for enterprises building products on top of open-source codebases.No \"Infection\": Neither license is \"copyleft\" (like GPL). You can integrate GLM-Image into a proprietary workflow or product without being forced to open-source your own intellectual property.For developers, the recommendation is simple: Treat the weights as MIT (per the repository hosting them) and the inference code as Apache 2.0. Both paths clear the runway for internal hosting, fine-tuning on sensitive data, and building commercial products without a vendor lock-in contract.The \"Why Now\" for Enterprise OperationsFor the enterprise decision maker, GLM-Image arrives at a critical inflection point. Companies are moving beyond using generative AI for abstract blog headers and into functional territory: multilingual localization of ads, automated UI mockup generation, and dynamic educational materials.In these workflows, a 5% error rate in text rendering is a blocker. If a model generates a beautiful slide but misspells the product name, the asset is useless. The benchmarks suggest GLM-Image is the first open-source model to cross the threshold of reliability for these complex tasks.Furthermore, the permissive licensing fundamentally changes the economics of deployment. While Nano Banana Pro locks enterprises into a per-call API cost structure or restrictive cloud contracts, GLM-Image can be self-hosted, fine-tuned on proprietary brand assets, and integrated into secure, air-gapped pipelines without data leakage concerns.The Catch: Heavy Compute RequirementsThe trade-off for this reasoning capability is compute intensity. The dual-model architecture is heavy. Generating a single 2048x2048 image requires approximately 252 seconds on an H100 GPU. This is significantly slower than highly optimized, smaller diffusion models.However, for high-value assets—where the alternative is a human designer spending hours in Photoshop—this latency is acceptable. Z.ai also offers a managed API at $0.015 per image, providing a bridge for teams who want to test the capabilities without investing in H100 clusters immediately.GLM-Image is a signal that the open-source community is no longer just fast-following proprietary labs; in specific, high-value verticals like knowledge-dense generation, they are now setting the pace. For the enterprise, the message is clear: if your operational bottleneck is the reliability of complex visual content, the solution is no longer necessarily a closed Google product—it might be an open-source model you can run yourself.",
          "content": "The two big stories of AI in 2026 so far have been the incredible rise in usage and praise for Anthropic&#x27;s Claude Code and a similar huge boost in user adoption for Google&#x27;s Gemini 3 AI model family released late last year — the latter of which includes Nano Banana Pro (also known as Gemini 3 Pro Image), a powerful, fast, and flexible image generation model that renders complex, text-heavy infographics quickly and accurately, making it an excellent fit for enterprise use (think: collateral, trainings, onboarding, stationary, etc).But of course, both of those are proprietary offerings. And yet, open source rivals have not been far behind. This week, we got a new open source alternative to Nano Banana Pro in the category of precise, text-heavy image generators: GLM-Image, a new 16-billion parameter open-source model from recently public Chinese startup Z.ai.By abandoning the industry-standard \"pure diffusion\" architecture that powers most leading image generator models in favor of a hybrid auto-regressive (AR) + diffusion design, GLM-Image has achieved what was previously thought to be the domain of closed, proprietary models: state-of-the-art performance in generating text-heavy, information-dense visuals like infographics, slides, and technical diagrams.It even beats Google&#x27;s Nano Banana Pro on the shared by z.ai — though in practice, my own quick usage found it to be far less accurate at instruction following and text rendering (and other users seem to agree). But for enterprises seeking cost-effective and customizable, friendly-licensed alternatives to proprietary AI models, z.ai&#x27;s GLM-Image may be \"good enough\" or then some to take over the job of a primary image generator, depending on their specific use cases, needs and requirements.The Benchmark: Toppling the Proprietary GiantThe most compelling argument for GLM-Image is not its aesthetics, but its precision. In the CVTG-2k (Complex Visual Text Generation) benchmark, which evaluates a model&#x27;s ability to render accurate text across multiple regions of an image, GLM-Image scored a Word Accuracy average of 0.9116.To put that number in perspective, Nano Banana 2.0 aka Pro—often cited as the benchmark for enterprise reliability—scored 0.7788. This isn&#x27;t a marginal gain; it is a generational leap in semantic control.While Nano Banana Pro retains a slight edge in single-stream English long-text generation (0.9808 vs. GLM-Image&#x27;s 0.9524), it falters significantly when the complexity increases. As the number of text regions grows, Nano Banana&#x27;s accuracy remains in the 70s, whereas GLM-Image maintains >90% accuracy even with multiple distinct text elements. For enterprise use cases—where a marketing slide needs a title, three bullet points, and a caption simultaneously—this reliability is the difference between a production-ready asset and a hallucination.Unfortunately, my own usage of a demo inference of GLM-Image on Hugging Face proved to be less reliable than the benchmarks might suggest. My prompt to generate an \"infographic labeling all the major constellations visible from the U.S. Northern Hemisphere right now on Jan 14 2026 and putting faded images of their namesakes behind the star connection line diagrams\" did not result in what I asked for, instead fulfilling maybe 20% or less of the specified content. But Google&#x27;s Nano Banana Pro handled it like a champ, as you&#x27;ll see below:Of course, a large portion of this is no doubt due to the fact that Nano Banana Pro is integrated with Google search, so it can look up information on the web in response to my prompt, whereas GLM-Image is not, and therefore, likely requires far more specific instructions about the actual text and other content the image should contain. But still, once you&#x27;re used to being able to type some simple instructions and get a fully researched and well populated image via the latter, it&#x27;s hard to imagine deploying a sub-par alternative unless you have very specific requirements around cost, data residency and security — or the customizability needs of your organization are so great. Furthermore, Nano Banana Pro still edged out GLM-Image in terms of pure aesthetics — using the OneIG benchmark, Nano Banana 2.0 is at 0.578 vs. GLM-Image at 0.528 — and indeed, as the top header artwork of this article indicates, GLM-Image does not always render as crisp, finely detailed and pleasing an image as Google&#x27;s generator. The Architectural Shift: Why \"Hybrid\" MattersWhy does GLM-Image succeed where pure diffusion models fail? The answer lies in Z.ai’s decision to treat image generation as a reasoning problem first and a painting problem second.Standard latent diffusion models (like Stable Diffusion or Flux) attempt to handle global composition and fine-grained texture simultaneously. This often leads to \"semantic drift,\" where the model forgets specific instructions (like \"place the text in the top left\") as it focuses on making the pixels look realistic.GLM-Image decouples these objectives into two specialized \"brains\" totaling 16 billion parameters:The Auto-Regressive Generator (The \"Architect\"): Initialized from Z.ai’s GLM-4-9B language model, this 9-billion parameter module processes the prompt logically. It doesn&#x27;t generate pixels; instead, it outputs \"visual tokens\"—specifically semantic-VQ tokens. These tokens act as a compressed blueprint of the image, locking in the layout, text placement, and object relationships before a single pixel is drawn. This leverages the reasoning power of an LLM, allowing the model to \"understand\" complex instructions (e.g., \"A four-panel tutorial\") in a way diffusion noise predictors cannot.The Diffusion Decoder (The \"Painter\"): Once the layout is locked by the AR module, a 7-billion parameter Diffusion Transformer (DiT) decoder takes over. Based on the CogView4 architecture, this module fills in the high-frequency details—texture, lighting, and style.By separating the \"what\" (AR) from the \"how\" (Diffusion), GLM-Image solves the \"dense knowledge\" problem. The AR module ensures the text is spelled correctly and placed accurately, while the Diffusion module ensures the final result looks photorealistic.Training the Hybrid: A Multi-Stage EvolutionThe secret sauce of GLM-Image’s performance isn&#x27;t just the architecture; it is a highly specific, multi-stage training curriculum that forces the model to learn structure before detail.The training process began by freezing the text word embedding layer of the original GLM-4 model while training a new \"vision word embedding\" layer and a specialized vision LM head. This allowed the model to project visual tokens into the same semantic space as text, effectively teaching the LLM to \"speak\" in images. Crucially, Z.ai implemented MRoPE (Multidimensional Rotary Positional Embedding) to handle the complex interleaving of text and images required for mixed-modal generation.The model was then subjected to a progressive resolution strategy:Stage 1 (256px): The model trained on low-resolution, 256-token sequences using a simple raster scan order.Stage 2 (512px - 1024px): As resolution increased to a mixed stage (512px to 1024px), the team observed a drop in controllability. To fix this, they abandoned simple scanning for a progressive generation strategy.In this advanced stage, the model first generates approximately 256 \"layout tokens\" from a down-sampled version of the target image. These tokens act as a structural anchor. By increasing the training weight on these preliminary tokens, the team forced the model to prioritize the global layout—where things are—before generating the high-resolution details. This is why GLM-Image excels at posters and diagrams: it \"sketches\" the layout first, ensuring the composition is mathematically sound before rendering the pixels.Licensing Analysis: A Permissive, If Slightly Ambiguous, Win for EnterpriseFor enterprise CTOs and legal teams, the licensing structure of GLM-Image is a significant competitive advantage over proprietary APIs, though it comes with a minor caveat regarding documentation.The Ambiguity: There is a slight discrepancy in the release materials. The model’s Hugging Face repository explicitly tags the weights with the MIT License. However, the accompanying GitHub repository and documentation reference the Apache License 2.0.Why This Is Still Good News: Despite the mismatch, both licenses are the \"gold standard\" for enterprise-friendly open source.Commercial Viability: Both MIT and Apache 2.0 allow for unrestricted commercial use, modification, and distribution. Unlike the \"open rail\" licenses common in other image models (which often restrict specific use cases) or \"research-only\" licenses (like early LLaMA releases), GLM-Image is effectively \"open for business\" immediately.The Apache Advantage (If Applicable): If the code falls under Apache 2.0, this is particularly beneficial for large organizations. Apache 2.0 includes an explicit patent grant clause, meaning that by contributing to or using the software, contributors grant a patent license to users. This reduces the risk of future patent litigation—a major concern for enterprises building products on top of open-source codebases.No \"Infection\": Neither license is \"copyleft\" (like GPL). You can integrate GLM-Image into a proprietary workflow or product without being forced to open-source your own intellectual property.For developers, the recommendation is simple: Treat the weights as MIT (per the repository hosting them) and the inference code as Apache 2.0. Both paths clear the runway for internal hosting, fine-tuning on sensitive data, and building commercial products without a vendor lock-in contract.The \"Why Now\" for Enterprise OperationsFor the enterprise decision maker, GLM-Image arrives at a critical inflection point. Companies are moving beyond using generative AI for abstract blog headers and into functional territory: multilingual localization of ads, automated UI mockup generation, and dynamic educational materials.In these workflows, a 5% error rate in text rendering is a blocker. If a model generates a beautiful slide but misspells the product name, the asset is useless. The benchmarks suggest GLM-Image is the first open-source model to cross the threshold of reliability for these complex tasks.Furthermore, the permissive licensing fundamentally changes the economics of deployment. While Nano Banana Pro locks enterprises into a per-call API cost structure or restrictive cloud contracts, GLM-Image can be self-hosted, fine-tuned on proprietary brand assets, and integrated into secure, air-gapped pipelines without data leakage concerns.The Catch: Heavy Compute RequirementsThe trade-off for this reasoning capability is compute intensity. The dual-model architecture is heavy. Generating a single 2048x2048 image requires approximately 252 seconds on an H100 GPU. This is significantly slower than highly optimized, smaller diffusion models.However, for high-value assets—where the alternative is a human designer spending hours in Photoshop—this latency is acceptable. Z.ai also offers a managed API at $0.015 per image, providing a bridge for teams who want to test the capabilities without investing in H100 clusters immediately.GLM-Image is a signal that the open-source community is no longer just fast-following proprietary labs; in specific, high-value verticals like knowledge-dense generation, they are now setting the pace. For the enterprise, the message is clear: if your operational bottleneck is the reliability of complex visual content, the solution is no longer necessarily a closed Google product—it might be an open-source model you can run yourself.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1UjUf0KRfpbNaTSF2uk1Dz/7b76ade2243333f36713a89e8612b817/0yZhP9i_2swwDcPvoyypB.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/save-up-to-78-percent-on-expressvpn-two-year-plans-right-now-180602838.html",
          "published_at": "Wed, 14 Jan 2026 20:06:26 +0000",
          "title": "Save up to 78 percent on ExpressVPN two-year plans right now",
          "standfirst": "ExpressVPN is back on sale again, and its two-year plans are up to 78 percent off right now. You can get the Advanced tier for $101 for 28 months. This is marked down from the $392 that this time frame normally costs. On a per-month basis, it works out to roughly $3.59 for the promo period. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices. The Basic plan is $78 right now for 28 months, down from $363, and the Pro plan is $168, down from $560. That's 78 percent and 70 percent off, respectively. All plans carry a 30-day money-back guarantee for new users, so you can try it without committing long term if you’re on the fence.This article originally appeared on Engadget at https://www.engadget.com/deals/save-up-to-78-percent-on-expressvpn-two-year-plans-right-now-180602838.html?src=rss",
          "content": "ExpressVPN is back on sale again, and its two-year plans are up to 78 percent off right now. You can get the Advanced tier for $101 for 28 months. This is marked down from the $392 that this time frame normally costs. On a per-month basis, it works out to roughly $3.59 for the promo period. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices. The Basic plan is $78 right now for 28 months, down from $363, and the Pro plan is $168, down from $560. That's 78 percent and 70 percent off, respectively. All plans carry a 30-day money-back guarantee for new users, so you can try it without committing long term if you’re on the fence.This article originally appeared on Engadget at https://www.engadget.com/deals/save-up-to-78-percent-on-expressvpn-two-year-plans-right-now-180602838.html?src=rss",
          "feed_position": 10
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/ai-agents-can-talk-orchestration-is-what-makes-them-work-together",
          "published_at": "Wed, 14 Jan 2026 19:00:00 GMT",
          "title": "AI agents can talk — orchestration is what makes them work together",
          "standfirst": "Rather than asking how AI agents can work for them, a key question in enterprise is now: Are agents playing well together? This makes orchestration across multi-agent systems and platforms a critical concern — and a key differentiator. “Agent-to-agent communications is emerging as a really big deal,” G2’s chief innovation officer Tim Sanders told VentureBeat. “Because if you don&#x27;t orchestrate it, you get misunderstandings, like people speaking foreign languages to each other. Those misunderstandings reduce the quality of actions and raise the specter of hallucinations, which could be security incidents or data leakage.”Allowing agents to talk and coordinateOrchestration to this point has largely been around data, but that’s quickly turning to action. “Conductor-like solutions” are increasingly bringing together agents, robotic process automation (RPA), and data repositories. Sanders likened the progression to that of answer engine optimization, which initially began with monitoring and now creates bespoke content and code. “Orchestration platforms coordinate a variety of different agentic solutions to increase the consistency of outcomes,” he said. Early providers include Salesforce MuleSoft, UiPath Maestro, and IBM Watsonx Orchestrate. These “phase one” software-based observability dashboards help IT leaders see all agentic actions across an enterprise. The critical element of risk managementBut coordination can only add so much value; these platforms will morph into technical risk management tools that provide greater quality control. This could include, for instance, agent assessments, policy recommendation and proactive scoring (such as, how reliable agents are when they call on enterprise tools, or how often they hallucinate and when). Enterprise leaders have become wary of relying on vendors to minimize risks and errors; many IT decision-makers, in fact, do not trust a vendor&#x27;s statements about the reliability of their agents, he said. Third-party tools are beginning to bridge the gap and automate tedious guardrail processes and escalation tickets. Teams are already experiencing “ticket exhaustion” in semi-automated systems, where agents hit guardrails and require human permission to proceed.As an example: The loan process at a bank requires 17 steps for approval, and an agent keeps interrupting human workflows with approval requests when it runs into established guardrails. Third-party orchestration platforms can manage these tickets and nay, yay, or even challenge the need for approval altogether. They can eventually eliminate the need for persistent human-in-the-loop oversight so organizations can experience “true velocity gains” measured not in percentages but in multiples (that is, 3X versus 30%).“Where it goes from there is remote management of the entire agentic process for organizations,” Sanders said. ‘Human-on-the-loop’ versus ‘human-in-the-loop’ In another critical evolution in the agentic era, human evaluators will become designers, moving from human-in-the-loop to human-on-the-loop, according to Sanders. That is: They will begin designing agents to automate workflows. Agent builder platforms continue to innovate their no-code solutions, Sanders said, meaning nearly anyone can now stand up an agent using natural language. “This will democratize agentic AI, and the super skill will be the ability to express a goal, provide context and envision pitfalls, very similar to a good people manager today.”What enterprise leaders should be doing nowAgent-first automation stacks “dramatically outperform” hybrid automation stacks in almost every attribute, he noted: satisfaction, quality of actions, security, cost savings.Organizations should begin “expeditious programs” to infuse agents across workflows, especially with highly repetitive work that poses bottlenecks. Likely at first, there will be a strong human-in-the-loop element to ensure quality and promote change management. “Serving as an evaluator will strengthen the understanding of how these systems work,” Sanders said, “and eventually enable all of us to operate upstream in agentic workflows instead of downstream.” IT leaders should take inventory today of all the different elements of their automation stack. Whether these elements are rules-based automation, RPA, or agentic automation, they must learn everything going on in the organization to optimally use emerging orchestration platforms.“If they don&#x27;t, there could actually be dis-synergies across organizations where old school technology and cutting edge technology clash at the point of delivery, oftentimes customer-facing,” Sanders said. “You can&#x27;t orchestrate what you can&#x27;t see clearly.”",
          "content": "Rather than asking how AI agents can work for them, a key question in enterprise is now: Are agents playing well together? This makes orchestration across multi-agent systems and platforms a critical concern — and a key differentiator. “Agent-to-agent communications is emerging as a really big deal,” G2’s chief innovation officer Tim Sanders told VentureBeat. “Because if you don&#x27;t orchestrate it, you get misunderstandings, like people speaking foreign languages to each other. Those misunderstandings reduce the quality of actions and raise the specter of hallucinations, which could be security incidents or data leakage.”Allowing agents to talk and coordinateOrchestration to this point has largely been around data, but that’s quickly turning to action. “Conductor-like solutions” are increasingly bringing together agents, robotic process automation (RPA), and data repositories. Sanders likened the progression to that of answer engine optimization, which initially began with monitoring and now creates bespoke content and code. “Orchestration platforms coordinate a variety of different agentic solutions to increase the consistency of outcomes,” he said. Early providers include Salesforce MuleSoft, UiPath Maestro, and IBM Watsonx Orchestrate. These “phase one” software-based observability dashboards help IT leaders see all agentic actions across an enterprise. The critical element of risk managementBut coordination can only add so much value; these platforms will morph into technical risk management tools that provide greater quality control. This could include, for instance, agent assessments, policy recommendation and proactive scoring (such as, how reliable agents are when they call on enterprise tools, or how often they hallucinate and when). Enterprise leaders have become wary of relying on vendors to minimize risks and errors; many IT decision-makers, in fact, do not trust a vendor&#x27;s statements about the reliability of their agents, he said. Third-party tools are beginning to bridge the gap and automate tedious guardrail processes and escalation tickets. Teams are already experiencing “ticket exhaustion” in semi-automated systems, where agents hit guardrails and require human permission to proceed.As an example: The loan process at a bank requires 17 steps for approval, and an agent keeps interrupting human workflows with approval requests when it runs into established guardrails. Third-party orchestration platforms can manage these tickets and nay, yay, or even challenge the need for approval altogether. They can eventually eliminate the need for persistent human-in-the-loop oversight so organizations can experience “true velocity gains” measured not in percentages but in multiples (that is, 3X versus 30%).“Where it goes from there is remote management of the entire agentic process for organizations,” Sanders said. ‘Human-on-the-loop’ versus ‘human-in-the-loop’ In another critical evolution in the agentic era, human evaluators will become designers, moving from human-in-the-loop to human-on-the-loop, according to Sanders. That is: They will begin designing agents to automate workflows. Agent builder platforms continue to innovate their no-code solutions, Sanders said, meaning nearly anyone can now stand up an agent using natural language. “This will democratize agentic AI, and the super skill will be the ability to express a goal, provide context and envision pitfalls, very similar to a good people manager today.”What enterprise leaders should be doing nowAgent-first automation stacks “dramatically outperform” hybrid automation stacks in almost every attribute, he noted: satisfaction, quality of actions, security, cost savings.Organizations should begin “expeditious programs” to infuse agents across workflows, especially with highly repetitive work that poses bottlenecks. Likely at first, there will be a strong human-in-the-loop element to ensure quality and promote change management. “Serving as an evaluator will strengthen the understanding of how these systems work,” Sanders said, “and eventually enable all of us to operate upstream in agentic workflows instead of downstream.” IT leaders should take inventory today of all the different elements of their automation stack. Whether these elements are rules-based automation, RPA, or agentic automation, they must learn everything going on in the organization to optimally use emerging orchestration platforms.“If they don&#x27;t, there could actually be dis-synergies across organizations where old school technology and cutting edge technology clash at the point of delivery, oftentimes customer-facing,” Sanders said. “You can&#x27;t orchestrate what you can&#x27;t see clearly.”",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7szF9iF50458lvbJ6Hyb36/9cb490b66a50d662947b1fd978204626/G2.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-turn-off-a-vpn-on-iphone-180000533.html",
          "published_at": "Wed, 14 Jan 2026 18:00:00 +0000",
          "title": "How to turn off a VPN on iPhone",
          "standfirst": "Look, virtual private networks are great — I wouldn't have made a list of the best VPNs if I didn't recommend using them. But being able to control your own technology is also important. A VPN can provide protection and peace of mind when used properly, but you may not want it active on your phone all the time.For example: Are your Google search results suddenly in German? That’s one example of what can happen if you leave your virtual location set to Berlin or Vienna. Or maybe a VPN you installed for work or to watch a single tennis match is persistently trying to keep itself active.The point is, deactivating a VPN on an iPhone can sometimes be unusually tricky, because there’s more than one off switch. Fortunately, it's not hard. There are several easy ways to disconnect from an iOS VPN or delete it entirely. If you catch it turning itself back on, I'll show you how to stop that too.Three ways to turn off your iPhone VPNI'm using a fluid definition of \"turn off\" here. Some of the steps below simply disconnect the VPN, while others remove it from your phone altogether. I'll make it clear in each section what the outcome will be.How to disconnect in the VPN appThis is the easiest way to turn off a VPN on your iPhone. First, find the VPN app that’s active, which should be on your home screen somewhere. Each app has a different interface for connecting and disconnecting, but the disconnect button should be fairly obvious — it may say the word \"disconnect\" or show a green power icon. In any case, it should be right on the home screen, without requiring any digging through menus.Example of where to find the disconnect option on a VPN's home screen.Sam Chapman for EngadgetTap the disconnect button and wait for the VPN to clearly state that it's disconnected. Check to make sure the rectangle with \"VPN\" inside has disappeared from the top of your iPhone screen. The VPN is now disconnected.How to turn off the VPN in SettingsIf you aren't sure which VPN app is active, or if its interface doesn't make it clear how to turn it off, you can shut it down from the Settings menu instead. Find the app on your home screen that looks like several interlocking gray gears and tap it.Next, scroll down and tap the VPN option. If it's not present (which it won’t be on older iOS versions), tap the General option next to another picture of a gray gear. Scroll down again and tap VPN & Device Management by yet another gray gear. Finally, tap the VPN option at the top of the screen to reach the VPN management page.Location of the VPN settings on iOS.Sam Chapman for EngadgetIf you have a VPN active, you should see an option at the top of the page labeled VPN Status. Toggle it from Connected to Not Connected. The VPN icon should disappear from the top of your screen, indicating that it's turned off.How to delete the VPN app altogetherIf you don't want the VPN on your phone at all, you can turn it off permanently by deleting both the app and the configuration. This is a lot harder to undo, so only do it if you're certain.Start by deleting the app the same way you'd get rid of any other app. Tap the icon and hold until a pop-up menu appears. Select the Remove App option in red text, then click Remove App again when prompted.Deleting a VPN on the iOS home screen.Sam Chapman for EngadgetDeleting the app should also delete the configuration, but you can verify this for yourself. Follow the process from the previous section to find the VPN settings page. If there's still a VPN profile in those settings, tap the circled letter \"i\" next to its name, then tap Delete VPN at the bottom of the screen. The VPN is now gone from your iPhone unless you re-download it from the App Store.Troubleshooting: When an iPhone VPN turns itself back onSometimes, even though you've followed all the steps, that pesky VPN rectangle is back on your screen the next time you unlock your phone. If your iOS VPN keeps turning itself back on, a few things might be happening, most of them thankfully fixable.If you did not delete the VPN, it may be turning itself back on because its settings are telling it to. Go into its preferences menu and check for a setting called \"auto-connect\" or something similar. Settings like these have the VPN connect by itself to protect users who forget to activate it manually. Toggle all auto-connect options off and the problem should stop.It's also possible that settings on the iOS side are making the VPN reconnect. Go to the VPN settings page (you'll find instructions for getting there in the previous section) and find the name of the active VPN profile. Tap the \"i\" next to it. On the next page, turn off \"connect on demand\" to stop the automatic reconnections.If you did delete the VPN, but it's still reinstalling itself and turning back on, make sure that you deleted both the app and the connection profile. Reboot your iPhone to make sure all the settings stick. If the problem persists after all this, you've either got malware disguised as a VPN or you're using a school or work phone where the VPN can't be uninstalled.If you aren't on a phone provided by a school or office, meaning you probably have malware, download an antivirus app and run a complete scan of your iPhone. This should remove any persistent files that keep reinstalling the virus. If, after all this, the VPN is still turning itself back on, I recommend burning your phone in a salt circle with a bundle of sage.When should you turn off your iPhone VPN?I encourage everyone to use a VPN every time they connect to the internet, but there are some situations where going through a VPN server is less convenient (this is the whole reason split tunneling exists). Here are a few cases in which temporarily turning off your VPN might be a good idea.The VPN isn't working. If your browsing speed is sluggish or the VPN keeps dropping the connection, your VPN server might be having problems. Disconnecting and reconnecting, even in the same location, should switch you to a different server that may work better.The VPN is causing unintended browsing errors. If you’re using mapping software or just trying to do a location-based search, having your VPN active can cause more problems than it solves. Your internet connection is unstable. A VPN adds an extra step to the process of getting online. If your phone is already struggling, the VPN might be an unnecessary complication.You're on a site that blocks all VPNs. Sites that work based on your location, including all streaming sites, may blanket-block VPNs so nothing messes with their location services. Good VPNs can get around these blocks, but even the best sometimes fail. In these cases, briefly turning off the VPN may be a good idea.Your battery is low. VPNs can put a strain on your phone's battery life. This varies with the quality of your VPN, but you may sometimes need to shut it off if your battery is in the red.How to turn off iCloud Private RelayiCloud Private Relay is not a VPN, but it's often confused for one. If you found this page because you want to turn it off, you're in luck — the steps are just as simple as turning off a VPN. Start by opening Settings, then tap your name. Scroll down and tap iCloud.Private Relay will only be active if you're an iCloud+ subscriber. If you are, tap Private Relay, then choose whether to turn it off temporarily or indefinitely.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-turn-off-a-vpn-on-iphone-180000533.html?src=rss",
          "content": "Look, virtual private networks are great — I wouldn't have made a list of the best VPNs if I didn't recommend using them. But being able to control your own technology is also important. A VPN can provide protection and peace of mind when used properly, but you may not want it active on your phone all the time.For example: Are your Google search results suddenly in German? That’s one example of what can happen if you leave your virtual location set to Berlin or Vienna. Or maybe a VPN you installed for work or to watch a single tennis match is persistently trying to keep itself active.The point is, deactivating a VPN on an iPhone can sometimes be unusually tricky, because there’s more than one off switch. Fortunately, it's not hard. There are several easy ways to disconnect from an iOS VPN or delete it entirely. If you catch it turning itself back on, I'll show you how to stop that too.Three ways to turn off your iPhone VPNI'm using a fluid definition of \"turn off\" here. Some of the steps below simply disconnect the VPN, while others remove it from your phone altogether. I'll make it clear in each section what the outcome will be.How to disconnect in the VPN appThis is the easiest way to turn off a VPN on your iPhone. First, find the VPN app that’s active, which should be on your home screen somewhere. Each app has a different interface for connecting and disconnecting, but the disconnect button should be fairly obvious — it may say the word \"disconnect\" or show a green power icon. In any case, it should be right on the home screen, without requiring any digging through menus.Example of where to find the disconnect option on a VPN's home screen.Sam Chapman for EngadgetTap the disconnect button and wait for the VPN to clearly state that it's disconnected. Check to make sure the rectangle with \"VPN\" inside has disappeared from the top of your iPhone screen. The VPN is now disconnected.How to turn off the VPN in SettingsIf you aren't sure which VPN app is active, or if its interface doesn't make it clear how to turn it off, you can shut it down from the Settings menu instead. Find the app on your home screen that looks like several interlocking gray gears and tap it.Next, scroll down and tap the VPN option. If it's not present (which it won’t be on older iOS versions), tap the General option next to another picture of a gray gear. Scroll down again and tap VPN & Device Management by yet another gray gear. Finally, tap the VPN option at the top of the screen to reach the VPN management page.Location of the VPN settings on iOS.Sam Chapman for EngadgetIf you have a VPN active, you should see an option at the top of the page labeled VPN Status. Toggle it from Connected to Not Connected. The VPN icon should disappear from the top of your screen, indicating that it's turned off.How to delete the VPN app altogetherIf you don't want the VPN on your phone at all, you can turn it off permanently by deleting both the app and the configuration. This is a lot harder to undo, so only do it if you're certain.Start by deleting the app the same way you'd get rid of any other app. Tap the icon and hold until a pop-up menu appears. Select the Remove App option in red text, then click Remove App again when prompted.Deleting a VPN on the iOS home screen.Sam Chapman for EngadgetDeleting the app should also delete the configuration, but you can verify this for yourself. Follow the process from the previous section to find the VPN settings page. If there's still a VPN profile in those settings, tap the circled letter \"i\" next to its name, then tap Delete VPN at the bottom of the screen. The VPN is now gone from your iPhone unless you re-download it from the App Store.Troubleshooting: When an iPhone VPN turns itself back onSometimes, even though you've followed all the steps, that pesky VPN rectangle is back on your screen the next time you unlock your phone. If your iOS VPN keeps turning itself back on, a few things might be happening, most of them thankfully fixable.If you did not delete the VPN, it may be turning itself back on because its settings are telling it to. Go into its preferences menu and check for a setting called \"auto-connect\" or something similar. Settings like these have the VPN connect by itself to protect users who forget to activate it manually. Toggle all auto-connect options off and the problem should stop.It's also possible that settings on the iOS side are making the VPN reconnect. Go to the VPN settings page (you'll find instructions for getting there in the previous section) and find the name of the active VPN profile. Tap the \"i\" next to it. On the next page, turn off \"connect on demand\" to stop the automatic reconnections.If you did delete the VPN, but it's still reinstalling itself and turning back on, make sure that you deleted both the app and the connection profile. Reboot your iPhone to make sure all the settings stick. If the problem persists after all this, you've either got malware disguised as a VPN or you're using a school or work phone where the VPN can't be uninstalled.If you aren't on a phone provided by a school or office, meaning you probably have malware, download an antivirus app and run a complete scan of your iPhone. This should remove any persistent files that keep reinstalling the virus. If, after all this, the VPN is still turning itself back on, I recommend burning your phone in a salt circle with a bundle of sage.When should you turn off your iPhone VPN?I encourage everyone to use a VPN every time they connect to the internet, but there are some situations where going through a VPN server is less convenient (this is the whole reason split tunneling exists). Here are a few cases in which temporarily turning off your VPN might be a good idea.The VPN isn't working. If your browsing speed is sluggish or the VPN keeps dropping the connection, your VPN server might be having problems. Disconnecting and reconnecting, even in the same location, should switch you to a different server that may work better.The VPN is causing unintended browsing errors. If you’re using mapping software or just trying to do a location-based search, having your VPN active can cause more problems than it solves. Your internet connection is unstable. A VPN adds an extra step to the process of getting online. If your phone is already struggling, the VPN might be an unnecessary complication.You're on a site that blocks all VPNs. Sites that work based on your location, including all streaming sites, may blanket-block VPNs so nothing messes with their location services. Good VPNs can get around these blocks, but even the best sometimes fail. In these cases, briefly turning off the VPN may be a good idea.Your battery is low. VPNs can put a strain on your phone's battery life. This varies with the quality of your VPN, but you may sometimes need to shut it off if your battery is in the red.How to turn off iCloud Private RelayiCloud Private Relay is not a VPN, but it's often confused for one. If you found this page because you want to turn it off, you're in luck — the steps are just as simple as turning off a VPN. Start by opening Settings, then tap your name. Scroll down and tap iCloud.Private Relay will only be active if you're an iCloud+ subscriber. If you are, tap Private Relay, then choose whether to turn it off temporarily or indefinitely.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-turn-off-a-vpn-on-iphone-180000533.html?src=rss",
          "feed_position": 13,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Proton_VPN_disconnect.PNG"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-three-months-of-audible-for-only-3-193859098.html",
          "published_at": "Wed, 14 Jan 2026 17:46:26 +0000",
          "title": "Get three months of Audible for only $3",
          "standfirst": "Have a hankering for some audiobooks? Audible is holding one heck of a sale right now, giving users three months of access for $3. That's a dollar per month. This is something of a winter tradition for the Amazon-owned platform and the promotion ends on January 21. An Audible subscription grants one audiobook per month to keep. This can be selected from a massive catalog of new releases and bestsellers. The collection here has just about everything. However, it's easy to plow through a single book in a month. Users also get streaming access to thousands of curated titles. Think of it like Netflix for audiobooks. The catalog is limited, but it gets the job done in a pinch. Subscribers do get access to all Audible original content and they will receive discounts on purchasing audiobooks outright. In other words, it's a neat little service and well worth a buck. The regular price is $15, so make sure to cancel at the end of that three months if you aren't enjoying the platform. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-three-months-of-audible-for-only-3-193859098.html?src=rss",
          "content": "Have a hankering for some audiobooks? Audible is holding one heck of a sale right now, giving users three months of access for $3. That's a dollar per month. This is something of a winter tradition for the Amazon-owned platform and the promotion ends on January 21. An Audible subscription grants one audiobook per month to keep. This can be selected from a massive catalog of new releases and bestsellers. The collection here has just about everything. However, it's easy to plow through a single book in a month. Users also get streaming access to thousands of curated titles. Think of it like Netflix for audiobooks. The catalog is limited, but it gets the job done in a pinch. Subscribers do get access to all Audible original content and they will receive discounts on purchasing audiobooks outright. In other words, it's a neat little service and well worth a buck. The regular price is $15, so make sure to cancel at the end of that three months if you aren't enjoying the platform. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-three-months-of-audible-for-only-3-193859098.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-first-gen-bose-quietcomfort-ultra-headphones-are-150-off-right-now-164826329.html",
          "published_at": "Wed, 14 Jan 2026 16:48:26 +0000",
          "title": "The first-gen Bose QuietComfort Ultra headphones are $150 off right now",
          "standfirst": "The first-generation Bose QuietComfort Ultra headphones are on sale right now for $280, marked down from $430. That 35 percent savings is an even steeper discount than we saw last year Black Friday. In our review of the first-generation Ultras, we gave them a score of 86 out of 100, noting their best-in-class active noise cancellation (ANC) and comfort. Bose improved its stock tuning for these headphones, which we could immediately tell sounded warmer and clearer. Bose has typically lagged behind the likes of Sony and Sennheiser in raw sound quality, but the first-generation QuietComfort Ultra was a big step toward catching up. Bose added \"Immersive Audio\" to this model, which is the company's take on spatial audio. The company claims this feature effectively puts you in the acoustic sweet spot of a set of stereo speakers. In our testing, we felt this didn't always make songs sound better, but it did make them louder and in some cases made certain details more noticeable. The Ultras offer up to 24 hours of battery life with ANC turned on and about 18 hours with both ANC and Immersive Audio enabled. In our testing, however, we were actually able to beat Bose's estimates for battery life. The second generation of these headphones are currently our top pick for best noise-canceling headphones, but when this older model is heavily on sale, the differences between them are less dramatic. If you're in the market for a pair of great noise-canceling cans, consider checking these out. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-first-gen-bose-quietcomfort-ultra-headphones-are-150-off-right-now-164826329.html?src=rss",
          "content": "The first-generation Bose QuietComfort Ultra headphones are on sale right now for $280, marked down from $430. That 35 percent savings is an even steeper discount than we saw last year Black Friday. In our review of the first-generation Ultras, we gave them a score of 86 out of 100, noting their best-in-class active noise cancellation (ANC) and comfort. Bose improved its stock tuning for these headphones, which we could immediately tell sounded warmer and clearer. Bose has typically lagged behind the likes of Sony and Sennheiser in raw sound quality, but the first-generation QuietComfort Ultra was a big step toward catching up. Bose added \"Immersive Audio\" to this model, which is the company's take on spatial audio. The company claims this feature effectively puts you in the acoustic sweet spot of a set of stereo speakers. In our testing, we felt this didn't always make songs sound better, but it did make them louder and in some cases made certain details more noticeable. The Ultras offer up to 24 hours of battery life with ANC turned on and about 18 hours with both ANC and Immersive Audio enabled. In our testing, however, we were actually able to beat Bose's estimates for battery life. The second generation of these headphones are currently our top pick for best noise-canceling headphones, but when this older model is heavily on sale, the differences between them are less dramatic. If you're in the market for a pair of great noise-canceling cans, consider checking these out. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-first-gen-bose-quietcomfort-ultra-headphones-are-150-off-right-now-164826329.html?src=rss",
          "feed_position": 15
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-mac-mini-m4-is-back-on-sale-for-499-141615907.html",
          "published_at": "Wed, 14 Jan 2026 16:06:26 +0000",
          "title": "The Mac mini M4 is back on sale for $499",
          "standfirst": "The holiday season may be behind us, but that doesn't mean you can't still find good deals on some of our favorite tech. Take the Apple Mac mini M4, which is on sale for $100 off. The 17 percent discount gives you 16GB of RAM and 256GB of SSD for $499, which is only about $20 more than its Black Friday sale price. Its beefier models are also on sale: opting for 512GB of SSD will cost you $689, down from $799, while also upping your RAM to 24GB is available for $890, dropping from $999. We gave the Apple Mac mini M4 a 90 in our review thanks in large part to its powerful chip. The M4 works very fast despite being in such a small device. It also offers front-facing headphone and USB-C ports. You can further upgrade to the Apple M4 Pro chip for $1,270, down from $1,399 — a nine percent discount. The Pro model also has Thunderbolt 5 support. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-mac-mini-m4-is-back-on-sale-for-499-141615907.html?src=rss",
          "content": "The holiday season may be behind us, but that doesn't mean you can't still find good deals on some of our favorite tech. Take the Apple Mac mini M4, which is on sale for $100 off. The 17 percent discount gives you 16GB of RAM and 256GB of SSD for $499, which is only about $20 more than its Black Friday sale price. Its beefier models are also on sale: opting for 512GB of SSD will cost you $689, down from $799, while also upping your RAM to 24GB is available for $890, dropping from $999. We gave the Apple Mac mini M4 a 90 in our review thanks in large part to its powerful chip. The M4 works very fast despite being in such a small device. It also offers front-facing headphone and USB-C ports. You can further upgrade to the Apple M4 Pro chip for $1,270, down from $1,399 — a nine percent discount. The Pro model also has Thunderbolt 5 support. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-mac-mini-m4-is-back-on-sale-for-499-141615907.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/gemini-can-now-pull-context-the-rest-of-your-google-apps-if-you-let-it-160039468.html",
          "published_at": "Wed, 14 Jan 2026 16:00:39 +0000",
          "title": "Gemini can now pull context the rest of your Google apps, if you let it",
          "standfirst": "Gemini is adding a feature that’s designed to feel more tailored to individual users. Once enabled, \"Personal Intelligence\" can pull context from across your Google ecosystem, including Gmail, Google Photos, Search and YouTube History, to gain specific insight that will shape its answers and recommendations. Personal Intelligence is available starting today in the US for Google AI Pro and Ultra subscribers. The feature is opt-in only and is off by default. Google Google says users will have the ability to control what apps Gemini pulls from and, in the future, which chats it uses Personal Intelligence for. The company says this new feature might still make some mistakes, such as “over-personalization” where it draws connections between unrelated things. According to Google, Gemini will not train directly on the data it pulls for personalization like your photos and emails, but will instead train on your prompts and its responses. Users can also prompt Gemini to \"try again\" without personalization and will have the option to delete chat histories. For now, Personal Intelligence works in the Gemini app across web, Android and iOS for personal Google accounts. Google says it’s coming to Search’s AI Mode soon, with plans to expand to more countries and the free tier down the line. Google has been on a tear integrating Gemini into everything, including Gmail, TVs and Chrome on mobile. This week, Apple announced that Siri AI will be powered by Gemini as part of a multi-year collaboration. AI remains an imperfect tool, and Google's AI has a long history of malfunctions like explaining made-up idioms, calling itself a \"failure\" in a depressing doom loop and generating images of the Founding Fathers as people of color.This article originally appeared on Engadget at https://www.engadget.com/ai/gemini-can-now-pull-context-the-rest-of-your-google-apps-if-you-let-it-160039468.html?src=rss",
          "content": "Gemini is adding a feature that’s designed to feel more tailored to individual users. Once enabled, \"Personal Intelligence\" can pull context from across your Google ecosystem, including Gmail, Google Photos, Search and YouTube History, to gain specific insight that will shape its answers and recommendations. Personal Intelligence is available starting today in the US for Google AI Pro and Ultra subscribers. The feature is opt-in only and is off by default. Google Google says users will have the ability to control what apps Gemini pulls from and, in the future, which chats it uses Personal Intelligence for. The company says this new feature might still make some mistakes, such as “over-personalization” where it draws connections between unrelated things. According to Google, Gemini will not train directly on the data it pulls for personalization like your photos and emails, but will instead train on your prompts and its responses. Users can also prompt Gemini to \"try again\" without personalization and will have the option to delete chat histories. For now, Personal Intelligence works in the Gemini app across web, Android and iOS for personal Google accounts. Google says it’s coming to Search’s AI Mode soon, with plans to expand to more countries and the free tier down the line. Google has been on a tear integrating Gemini into everything, including Gmail, TVs and Chrome on mobile. This week, Apple announced that Siri AI will be powered by Gemini as part of a multi-year collaboration. AI remains an imperfect tool, and Google's AI has a long history of malfunctions like explaining made-up idioms, calling itself a \"failure\" in a depressing doom loop and generating images of the Founding Fathers as people of color.This article originally appeared on Engadget at https://www.engadget.com/ai/gemini-can-now-pull-context-the-rest-of-your-google-apps-if-you-let-it-160039468.html?src=rss",
          "feed_position": 18,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-01/38ff43e0-f156-11f0-b7ef-806c828a134c"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-from-ugreen-is-32-percent-off-right-now-214707806.html",
          "published_at": "Wed, 14 Jan 2026 15:06:26 +0000",
          "title": "Our favorite 3-in-1 wireless charger from UGreen is 32 percent off right now",
          "standfirst": "You can easily spruce up your nightstand or desk by decluttering a bit, replacing some of those annoying charging cables with a good wireless charging setup. One of our favorites that can handle three devices at once is the UGREEN MagFlow Qi2 3-in-1 Charger Station 25W. Normally $140, it's on sale right now for $95; that's 32 percent off and only about $5 more than its record-low price. This is our top pick for a 3-in-1 charging pad thanks to its versatility. The UGREEN can work equally well as a permanent fixture in your home or act as a portable charging station. It boasts a foldable design and has smart little design details to keep it feeling like a premium product. The Qi2 25W charging works across a range of iPhone models and accessories, such as AirPods. There's also a dedicated part of the pad's design for an Apple Watch, which uses a proprietary charging standard, to power up too. Just note that you'll need a newer model of phone and the latest iOS 26 in order to take full advantage of the 25W charging capability. The wireless pad also comes with both a charging plug and a cable. We felt this UGREEN model was a great value at $140, so being able to snag one for a third of the usual price is an even better deal. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-from-ugreen-is-32-percent-off-right-now-214707806.html?src=rss",
          "content": "You can easily spruce up your nightstand or desk by decluttering a bit, replacing some of those annoying charging cables with a good wireless charging setup. One of our favorites that can handle three devices at once is the UGREEN MagFlow Qi2 3-in-1 Charger Station 25W. Normally $140, it's on sale right now for $95; that's 32 percent off and only about $5 more than its record-low price. This is our top pick for a 3-in-1 charging pad thanks to its versatility. The UGREEN can work equally well as a permanent fixture in your home or act as a portable charging station. It boasts a foldable design and has smart little design details to keep it feeling like a premium product. The Qi2 25W charging works across a range of iPhone models and accessories, such as AirPods. There's also a dedicated part of the pad's design for an Apple Watch, which uses a proprietary charging standard, to power up too. Just note that you'll need a newer model of phone and the latest iOS 26 in order to take full advantage of the 25W charging capability. The wireless pad also comes with both a charging plug and a cable. We felt this UGREEN model was a great value at $140, so being able to snag one for a third of the usual price is an even better deal. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-3-in-1-wireless-charger-from-ugreen-is-32-percent-off-right-now-214707806.html?src=rss",
          "feed_position": 20
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/pick-up-apples-25w-magsafe-charger-while-its-down-to-30-141707867.html",
          "published_at": "Wed, 14 Jan 2026 14:30:37 +0000",
          "title": "Pick up Apple's 25W MagSafe charger while it's down to $30",
          "standfirst": "If you want a wireless charger for your iPhone and prefer to stick with Apple, Amazon has a sale that may pique your interest. The retailer is selling the one meter Apple Magsafe charger for $30, saving you $10 off the regular price, while also selling the two meter model for $40 ($10 off). If you have an iPhone 16, iPhone 17 or iPhone Air, this cable can charge your device at 25W as long as it's connected to a 30W power adapter on the other end. While you'll need a more recent iPhone to get the fastest MagSafe charging speeds, the charger can wirelessly top up the battery of any iPhone from the last eight years (iPhone 8 and later). With older iPhones, the charging speed tops out at 15W. The cable works with AirPods wireless charging cases too — it's certified for Qi2.2 and Qi charging. The MagSafe charger is one of our favorite iPhone accessories, and would pair quite nicely with your new iPhone if you're picking up one of the latest models. If you're on the fence about that, be sure to check out our reviews of the iPhone 17, iPhone Pro/Pro Max and iPhone Air. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-apples-25w-magsafe-charger-while-its-down-to-30-141707867.html?src=rss",
          "content": "If you want a wireless charger for your iPhone and prefer to stick with Apple, Amazon has a sale that may pique your interest. The retailer is selling the one meter Apple Magsafe charger for $30, saving you $10 off the regular price, while also selling the two meter model for $40 ($10 off). If you have an iPhone 16, iPhone 17 or iPhone Air, this cable can charge your device at 25W as long as it's connected to a 30W power adapter on the other end. While you'll need a more recent iPhone to get the fastest MagSafe charging speeds, the charger can wirelessly top up the battery of any iPhone from the last eight years (iPhone 8 and later). With older iPhones, the charging speed tops out at 15W. The cable works with AirPods wireless charging cases too — it's certified for Qi2.2 and Qi charging. The MagSafe charger is one of our favorite iPhone accessories, and would pair quite nicely with your new iPhone if you're picking up one of the latest models. If you're on the fence about that, be sure to check out our reviews of the iPhone 17, iPhone Pro/Pro Max and iPhone Air. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-apples-25w-magsafe-charger-while-its-down-to-30-141707867.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/monarch-money-deal-new-users-can-get-one-year-of-access-for-only-50-204507409.html",
          "published_at": "Wed, 14 Jan 2026 13:50:35 +0000",
          "title": "Monarch Money deal: New users can get one year of access for only $50",
          "standfirst": "A new year is the perfect time to get your spending in order, and if you're not trying to build your own spreadsheet, budgeting apps are one of the best ways to do it. To save yourself some money in the process, you can pick up a year-long subscription to Monarch Money, one of Engadget's favorite budgeting apps, for just $50 if you use code NEWYEAR2026 at checkout and you're a new subscriber. That's a 50 percent discount on the service's normal $100 price. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/apps/monarch-money-deal-new-users-can-get-one-year-of-access-for-only-50-204507409.html?src=rss",
          "content": "A new year is the perfect time to get your spending in order, and if you're not trying to build your own spreadsheet, budgeting apps are one of the best ways to do it. To save yourself some money in the process, you can pick up a year-long subscription to Monarch Money, one of Engadget's favorite budgeting apps, for just $50 if you use code NEWYEAR2026 at checkout and you're a new subscriber. That's a 50 percent discount on the service's normal $100 price. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/apps/monarch-money-deal-new-users-can-get-one-year-of-access-for-only-50-204507409.html?src=rss",
          "feed_position": 24
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/elevation-labs-extended-battery-airtag-case-is-down-to-only-16-162308748.html",
          "published_at": "Wed, 14 Jan 2026 13:15:35 +0000",
          "title": "Elevation Lab's extended battery AirTag case is down to only $16",
          "standfirst": "AirTags already have a decently long battery life, but you will end up needing to replace the coin cell every two years or so. If you don't even want to be bothered with that, Elevation Lab made just the accessory for you: its AirTag battery case that can power the tracker for up to 10 years is on sale for 30 percent off. You can pick one up for only $16, and it's available in two- and four-packs as well at a discount. The TimeCapsule case uses two AA batteries to offer up to 14 times the lifespan of the CR2032 battery that powers an AirTag. The company based those estimates on Energizer Ultimate Lithium batteries, so your mileage may vary. Once an AirTag is seated inside the case, which is a compact 4.45 x 1.57 inches, it is sealed shut with four screws at the corners. The case is fiber-reinforced, according to Elevation Lab, and rated IP69 waterproof. The company says it’s intended for use cases where you might place an AirTag for long periods of time, like in a vehicle, a piece of luggage or a work bag. We've already got a couple of Elevation Lab products on our list for best AirTag accessories, so while we haven't reviewed the battery case, we tend to like this company's products. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/elevation-labs-extended-battery-airtag-case-is-down-to-only-16-162308748.html?src=rss",
          "content": "AirTags already have a decently long battery life, but you will end up needing to replace the coin cell every two years or so. If you don't even want to be bothered with that, Elevation Lab made just the accessory for you: its AirTag battery case that can power the tracker for up to 10 years is on sale for 30 percent off. You can pick one up for only $16, and it's available in two- and four-packs as well at a discount. The TimeCapsule case uses two AA batteries to offer up to 14 times the lifespan of the CR2032 battery that powers an AirTag. The company based those estimates on Energizer Ultimate Lithium batteries, so your mileage may vary. Once an AirTag is seated inside the case, which is a compact 4.45 x 1.57 inches, it is sealed shut with four screws at the corners. The case is fiber-reinforced, according to Elevation Lab, and rated IP69 waterproof. The company says it’s intended for use cases where you might place an AirTag for long periods of time, like in a vehicle, a piece of luggage or a work bag. We've already got a couple of Elevation Lab products on our list for best AirTag accessories, so while we haven't reviewed the battery case, we tend to like this company's products. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/elevation-labs-extended-battery-airtag-case-is-down-to-only-16-162308748.html?src=rss",
          "feed_position": 27
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-one-month-of-the-disney-and-hulu-bundle-for-only-10-192814218.html",
          "published_at": "Wed, 14 Jan 2026 13:04:33 +0000",
          "title": "Get one month of the Disney+ and Hulu bundle for only $10",
          "standfirst": "The peak time for deals on streaming services — the holiday shopping season — has come and gone, but Disney is back with a fresh offer for the new year. New and eligible returning subscribers can get one month of the ad-supported Disney+ Hulu bundle for just $10. That's $3 off the usual monthly rate for the bundle, and more than 58 percent off if you consider the prices for each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-one-month-of-the-disney-and-hulu-bundle-for-only-10-192814218.html?src=rss",
          "content": "The peak time for deals on streaming services — the holiday shopping season — has come and gone, but Disney is back with a fresh offer for the new year. New and eligible returning subscribers can get one month of the ad-supported Disney+ Hulu bundle for just $10. That's $3 off the usual monthly rate for the bundle, and more than 58 percent off if you consider the prices for each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-one-month-of-the-disney-and-hulu-bundle-for-only-10-192814218.html?src=rss",
          "feed_position": 28
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-usb-c-hub-120051833.html",
          "published_at": "Wed, 14 Jan 2026 10:01:25 +0000",
          "title": "The best USB-C hub for 2026",
          "standfirst": "Having fewer ports makes laptops and tablets lighter and more affordable — but that also cuts down on your connectivity options. If you’ve got a MacBook Air, a slim Chromebook or a tablet you’d like to get more utility out of, a USB-C hub can help. Using just a single port on your device, these multiport adapters will let you hook up screens, tap into Ethernet cables, connect mice and keyboards, and transfer data to drives and memory cards. Most also give you a way to power your device through the hub to maximize port availability. We tested over a dozen models to come up with picks for every budget. Here are the best USB-C hubs, according to our tests. Table of contents Best USB-C hubs for 2026 What to look for in a USB-C hub How we test USB-C hubs Other hubs we tested Recent updates Best USB-C hubs for 2026 What to look for in a USB-C hub Hub vs docking station The first thing to decide is whether you need a USB-C hub or a USB-C docking station. There’s no set standard for what differentiates the two, but docking stations tend to have more ports, offer a separate DC power adapter and cost more, with some reaching upwards of $400. We have a separate guide to the best docking stations to check out if you’re looking for something bigger than what we’re discussing here. USB-C hubs, in contrast, have between four and 10 ports, can support pass-through charging and typically cost between $30 and $150. Hubs, sometimes also called dongles or even multiport adapters, make more sense for smaller setups with just a few peripherals, such as a monitor, a wired keyboard and mouse, and the occasional external drive. They’re also more portable, since they’re small and require no dedicated power. That could be useful if you change work locations but want to bring your accessories with you, or if you want to replace your laptop with a more powerful tablet. A docking station or Thunderbolt dock makes more sense for someone who needs a robust setup for their laptop, including multiple external monitors, webcams, stream decks, microphones and so on. Both docks and hubs make it easy to grab your laptop off your desk for a meeting or other brief relocation and when you get back, you only need to plug in one cable to get all your accessories reconnected. Of course, if you just need to plug in one peripheral, you may not need a hub or a dock, a simple USB-C adapter, like HDMI to USB-C or USB-A to USB-C, may do the trick. Ports For a USB-C hub to work, it needs to connect to a port on your laptop or tablet that supports video, data and power — all of which is covered by anything listed as USB 3.0 or better, including USB4 and Thunderbolt 3 and Thunderbolt 4. The port, of course, needs to be Type-C as well. The sea of laptops out there is vast, so it’s hard to make generalizations, but modern laptops, including Windows and Apple models, should have at least one USB-C port that will suffice, and indeed, every one of our top picks for the best laptops do — including our top pick, the M4 MacBook Air. Next, it’s a matter of finding a good USB-C hub that has the right connections for your needs. Most hubs offer some combo of HDMI, USB, SD card reader, Ethernet and 3.5 mm ports. If you have a 4K monitor and would like at least a 60Hz refresh rate, you’ll need a hub with an HDMI 2.0 port — HDMI 1.4 only goes up to 30Hz. HDMI 2.1 will handle 4K at up to 120Hz, but hubs that have adopted that standard aren’t as common just yet. Keep in mind that a low refresh rate can cause your screen to feel laggy, making your mouse appear glitchy and your webcam movements to look delayed. Additional USB ports on these accessories are usually USB Type-A or USB Type-C. They can support data with different transfer rates, typically 5Gbps or 10Gbps. Some ports only handle passthrough power and no data, and some can do data, power and video, so it’s best to check the spec list to make sure you’re getting the support you need. Keep in mind that a hub may bill itself as a 7-in-1, but one of those ports may not be usable for anything other than charging. Standard SD and microSD cards are useful for transferring data from cameras and the like or for offloading files from your hard drive, and many hubs have those slots. Ethernet ports may deliver faster internet speeds than your Wi-Fi and a hub with a 3.5mm jack can bring back the wired headphone connection that some laptops have ditched. Power delivery Nearly all of the USB-C hubs I tested support passthrough charging. That means if your laptop or tablet only charges via USB, you don’t have to take up another port on your laptop to keep everything topped up. Unlike a docking station, powering a hub is optional. The one exception is if you want to close the lid on your laptop while you work on an external monitor. Most computers will go into sleep mode if the lid is closed without power, so either the laptop or the hub will need to be plugged into the wall to prevent that from happening. Many of the newer hubs include a 100W USB-C power delivery (PD) port, with a healthy 80 to 85 watts going to your Mac, PC, iPad or Android tablet (the hubs take a little of the juice for themselves, hence the 15-watt or so difference). In my tests, a powered USB hub ran hotter than when it wasn't passing the charge through, so I prefer to power the computer directly using its own charger. But for tablets or other devices with no extra ports, that PD option is important. Some PD ports are also data ports — which is both good and bad. On one hand, it feels wasteful to use a perfectly good data port just for boring old electricity. But on the other hand, USB-C connections that only carry a charge are less versatile, and it makes it seem like it has more accessory hookups than it actually does. Design There’s surprisingly little design variation among hubs. Most look like a flat slab, a little smaller than a smartphone, and have an attached Type-C host cable. The hues range from a silvery black to a silvery gray. Some are thinner than others, some have all ports on one edge and some have ports on both sides. All of this is just to say that aesthetics probably won’t make or break your buying decision. One variation that could tip the scales is the length of the cable. A longer one will give you more freedom as you arrange the hub on your desk, potentially even letting you hide it behind your laptop. Or you may prefer a shorter one to keep the hub neatly set beside your laptop. How we test USB-C hubs Before we test anything, we take a look at what’s available and how they’ve been received by shoppers, forum-goers and other publications. I became familiar with a few reputable brands when I was testing docking stations, so I looked into hubs from those companies as well. I focused on items that would help with an average day of productivity — not high-end setups or demanding gaming situations. Once I settled on a dozen or so that would make good candidates, I had them shipped to my humble office in the desert and started testing them out over the course of a few weeks. I used an M1 MacBook Pro running MacOS Sonoma as the host computer and plugged in accessories that include a 4K Dell monitor, a ZSA USB-C ergo keyboard, a Logitech USB-A gaming mouse, an Elgato USB-C 4K webcam, a Logitech streaming light, a USB-A 3.0 Sandisk thumb drive, a USB-C Samsung T7 Shield external drive and a pair of wired headphones I got for free on an airplane (I should probably invest in some wired headphones, but the cord dangling on my chest drives me nutty so all my earbuds are wireless). I used high-end HDMI and USB-C cables to ensure that any data or connectivity issues weren’t related to my equipment. Then I put each USB-C hub through a gamut of basic tests. I looked at what could be plugged in at once, the resolution on the monitor, data transfer speeds, the overall build quality of the hub and general usability factors, like the placement of the ports and the length of the cords. And, finally, the price-to-value ratio helped determine the best ones for a few different use cases. Other hubs we tested HyperDrive Next 10 Port USB-C Hub There’s a lot to like about HyperDrive’s Next 10 Port USB-C Hub. The tethered cable is a lavish 13 inches long, the HDMI 2.0 port outputs clear and crisp 4K visuals at 60Hz and the high-speed data transfers are great. It has the coveted two USB-C data ports plus a PD port, and there’s even a headphone jack. The only thing that holds back a full-throated endorsement is the way our unit handled a streaming light. Having it on at full brightness made the webcam flicker every time. The issue went away at 75 percent brightness, but the same problem didn’t happen on any other hub I tested. Anker 341 USB-C Hub (7-in-1) There’s nothing wrong with the Anker 341 USB-C hub. In fact it’s a current recommendation in our iPad accessories guide and it comes at a great $35 price. It gives you two USB-A ports as well as SD slots. But at this point, a 1.4 HDMI connection, which only supports 4K resolution at 30Hz feels a little retro. There’s also just a single USB-C downstream port and the data transfer tests proved to be a touch slower than the other hubs. But if you’ve got a lower resolution monitor and don’t need more than one USB-C, you won’t be disappointed with it. Anker 555 8-in-1 It was a tough call between the UGreen Revodoc Pro 109 and the Anker 555 8-in-1 for our top recommendation. Both have a similar port array with an HDMI, Ethernet, two USB Type A, a PD USB-C and a USB-C 3.2 on the 555. And the Anker USB-C hub is $15 cheaper. We went with the UGreen hub for its more premium build, extra USB-A port and longer cord that gives you two extra inches to work with. But if you want to save a few bucks this hub is a worthwhile pick. Startech 4-Port USB-C Hub (data only) I only became aware of Startech when I started researching for this guide. The quality is decent and the yellow accents are a welcome bit of color in the otherwise very gray world of hubs. The performance is solid, with no hiccups that I encountered. The brand’s 4-Port USB-C Hub has a long cord that wraps around the hub itself, which is unique. It doesn’t bother with power delivery, which isn’t an issue if you can power your computer directly. But the four USB ports (three Type-A and one Type-C) max out at 5Gbps and there’s no HDMI connector. It goes for $46, and unfortunately for it, there are cheaper ways to get a few more USB ports for your setup. Recent updates January 2026: Added an honorable mention from Satechi. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-usb-c-hub-120051833.html?src=rss",
          "content": "Having fewer ports makes laptops and tablets lighter and more affordable — but that also cuts down on your connectivity options. If you’ve got a MacBook Air, a slim Chromebook or a tablet you’d like to get more utility out of, a USB-C hub can help. Using just a single port on your device, these multiport adapters will let you hook up screens, tap into Ethernet cables, connect mice and keyboards, and transfer data to drives and memory cards. Most also give you a way to power your device through the hub to maximize port availability. We tested over a dozen models to come up with picks for every budget. Here are the best USB-C hubs, according to our tests. Table of contents Best USB-C hubs for 2026 What to look for in a USB-C hub How we test USB-C hubs Other hubs we tested Recent updates Best USB-C hubs for 2026 What to look for in a USB-C hub Hub vs docking station The first thing to decide is whether you need a USB-C hub or a USB-C docking station. There’s no set standard for what differentiates the two, but docking stations tend to have more ports, offer a separate DC power adapter and cost more, with some reaching upwards of $400. We have a separate guide to the best docking stations to check out if you’re looking for something bigger than what we’re discussing here. USB-C hubs, in contrast, have between four and 10 ports, can support pass-through charging and typically cost between $30 and $150. Hubs, sometimes also called dongles or even multiport adapters, make more sense for smaller setups with just a few peripherals, such as a monitor, a wired keyboard and mouse, and the occasional external drive. They’re also more portable, since they’re small and require no dedicated power. That could be useful if you change work locations but want to bring your accessories with you, or if you want to replace your laptop with a more powerful tablet. A docking station or Thunderbolt dock makes more sense for someone who needs a robust setup for their laptop, including multiple external monitors, webcams, stream decks, microphones and so on. Both docks and hubs make it easy to grab your laptop off your desk for a meeting or other brief relocation and when you get back, you only need to plug in one cable to get all your accessories reconnected. Of course, if you just need to plug in one peripheral, you may not need a hub or a dock, a simple USB-C adapter, like HDMI to USB-C or USB-A to USB-C, may do the trick. Ports For a USB-C hub to work, it needs to connect to a port on your laptop or tablet that supports video, data and power — all of which is covered by anything listed as USB 3.0 or better, including USB4 and Thunderbolt 3 and Thunderbolt 4. The port, of course, needs to be Type-C as well. The sea of laptops out there is vast, so it’s hard to make generalizations, but modern laptops, including Windows and Apple models, should have at least one USB-C port that will suffice, and indeed, every one of our top picks for the best laptops do — including our top pick, the M4 MacBook Air. Next, it’s a matter of finding a good USB-C hub that has the right connections for your needs. Most hubs offer some combo of HDMI, USB, SD card reader, Ethernet and 3.5 mm ports. If you have a 4K monitor and would like at least a 60Hz refresh rate, you’ll need a hub with an HDMI 2.0 port — HDMI 1.4 only goes up to 30Hz. HDMI 2.1 will handle 4K at up to 120Hz, but hubs that have adopted that standard aren’t as common just yet. Keep in mind that a low refresh rate can cause your screen to feel laggy, making your mouse appear glitchy and your webcam movements to look delayed. Additional USB ports on these accessories are usually USB Type-A or USB Type-C. They can support data with different transfer rates, typically 5Gbps or 10Gbps. Some ports only handle passthrough power and no data, and some can do data, power and video, so it’s best to check the spec list to make sure you’re getting the support you need. Keep in mind that a hub may bill itself as a 7-in-1, but one of those ports may not be usable for anything other than charging. Standard SD and microSD cards are useful for transferring data from cameras and the like or for offloading files from your hard drive, and many hubs have those slots. Ethernet ports may deliver faster internet speeds than your Wi-Fi and a hub with a 3.5mm jack can bring back the wired headphone connection that some laptops have ditched. Power delivery Nearly all of the USB-C hubs I tested support passthrough charging. That means if your laptop or tablet only charges via USB, you don’t have to take up another port on your laptop to keep everything topped up. Unlike a docking station, powering a hub is optional. The one exception is if you want to close the lid on your laptop while you work on an external monitor. Most computers will go into sleep mode if the lid is closed without power, so either the laptop or the hub will need to be plugged into the wall to prevent that from happening. Many of the newer hubs include a 100W USB-C power delivery (PD) port, with a healthy 80 to 85 watts going to your Mac, PC, iPad or Android tablet (the hubs take a little of the juice for themselves, hence the 15-watt or so difference). In my tests, a powered USB hub ran hotter than when it wasn't passing the charge through, so I prefer to power the computer directly using its own charger. But for tablets or other devices with no extra ports, that PD option is important. Some PD ports are also data ports — which is both good and bad. On one hand, it feels wasteful to use a perfectly good data port just for boring old electricity. But on the other hand, USB-C connections that only carry a charge are less versatile, and it makes it seem like it has more accessory hookups than it actually does. Design There’s surprisingly little design variation among hubs. Most look like a flat slab, a little smaller than a smartphone, and have an attached Type-C host cable. The hues range from a silvery black to a silvery gray. Some are thinner than others, some have all ports on one edge and some have ports on both sides. All of this is just to say that aesthetics probably won’t make or break your buying decision. One variation that could tip the scales is the length of the cable. A longer one will give you more freedom as you arrange the hub on your desk, potentially even letting you hide it behind your laptop. Or you may prefer a shorter one to keep the hub neatly set beside your laptop. How we test USB-C hubs Before we test anything, we take a look at what’s available and how they’ve been received by shoppers, forum-goers and other publications. I became familiar with a few reputable brands when I was testing docking stations, so I looked into hubs from those companies as well. I focused on items that would help with an average day of productivity — not high-end setups or demanding gaming situations. Once I settled on a dozen or so that would make good candidates, I had them shipped to my humble office in the desert and started testing them out over the course of a few weeks. I used an M1 MacBook Pro running MacOS Sonoma as the host computer and plugged in accessories that include a 4K Dell monitor, a ZSA USB-C ergo keyboard, a Logitech USB-A gaming mouse, an Elgato USB-C 4K webcam, a Logitech streaming light, a USB-A 3.0 Sandisk thumb drive, a USB-C Samsung T7 Shield external drive and a pair of wired headphones I got for free on an airplane (I should probably invest in some wired headphones, but the cord dangling on my chest drives me nutty so all my earbuds are wireless). I used high-end HDMI and USB-C cables to ensure that any data or connectivity issues weren’t related to my equipment. Then I put each USB-C hub through a gamut of basic tests. I looked at what could be plugged in at once, the resolution on the monitor, data transfer speeds, the overall build quality of the hub and general usability factors, like the placement of the ports and the length of the cords. And, finally, the price-to-value ratio helped determine the best ones for a few different use cases. Other hubs we tested HyperDrive Next 10 Port USB-C Hub There’s a lot to like about HyperDrive’s Next 10 Port USB-C Hub. The tethered cable is a lavish 13 inches long, the HDMI 2.0 port outputs clear and crisp 4K visuals at 60Hz and the high-speed data transfers are great. It has the coveted two USB-C data ports plus a PD port, and there’s even a headphone jack. The only thing that holds back a full-throated endorsement is the way our unit handled a streaming light. Having it on at full brightness made the webcam flicker every time. The issue went away at 75 percent brightness, but the same problem didn’t happen on any other hub I tested. Anker 341 USB-C Hub (7-in-1) There’s nothing wrong with the Anker 341 USB-C hub. In fact it’s a current recommendation in our iPad accessories guide and it comes at a great $35 price. It gives you two USB-A ports as well as SD slots. But at this point, a 1.4 HDMI connection, which only supports 4K resolution at 30Hz feels a little retro. There’s also just a single USB-C downstream port and the data transfer tests proved to be a touch slower than the other hubs. But if you’ve got a lower resolution monitor and don’t need more than one USB-C, you won’t be disappointed with it. Anker 555 8-in-1 It was a tough call between the UGreen Revodoc Pro 109 and the Anker 555 8-in-1 for our top recommendation. Both have a similar port array with an HDMI, Ethernet, two USB Type A, a PD USB-C and a USB-C 3.2 on the 555. And the Anker USB-C hub is $15 cheaper. We went with the UGreen hub for its more premium build, extra USB-A port and longer cord that gives you two extra inches to work with. But if you want to save a few bucks this hub is a worthwhile pick. Startech 4-Port USB-C Hub (data only) I only became aware of Startech when I started researching for this guide. The quality is decent and the yellow accents are a welcome bit of color in the otherwise very gray world of hubs. The performance is solid, with no hiccups that I encountered. The brand’s 4-Port USB-C Hub has a long cord that wraps around the hub itself, which is unique. It doesn’t bother with power delivery, which isn’t an issue if you can power your computer directly. But the four USB ports (three Type-A and one Type-C) max out at 5Gbps and there’s no HDMI connector. It goes for $46, and unfortunately for it, there are cheaper ways to get a few more USB ports for your setup. Recent updates January 2026: Added an honorable mention from Satechi. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-usb-c-hub-120051833.html?src=rss",
          "feed_position": 32,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2024-08/42b836f0-5376-11ef-aff7-f63093d21d28"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/why-egnyte-keeps-hiring-junior-engineers-despite-the-rise-of-ai-coding-tools",
          "published_at": "Tue, 13 Jan 2026 21:00:00 GMT",
          "title": "Why Egnyte keeps hiring junior engineers despite the rise of AI coding tools",
          "standfirst": "Egnyte, the $1.5 billion cloud content governance company, has embedded AI coding tools across its global team of more than 350 developers — but not to reduce headcount. Instead, the company continues to hire junior engineers, using AI to accelerate onboarding, deepen codebase understanding, and shorten the path from junior to senior contributor. The approach challenges a dominant 2025 narrative that automation will replace developers, showing instead how enterprises are using AI to scale engineering capacity while keeping humans firmly in the loop.“To have engineers disappear or us not hiring junior engineers doesn&#x27;t look like the likely outcome,” Amrit Jassal, Egnyte CTO and co-founder, told VentureBeat. “You&#x27;ve got to have people, you&#x27;re training and doing all types of succession planning. The junior engineer of today is the senior engineer of tomorrow.”How Egnyte coders are using AI — without ceding controlEgnyte — which has more than 22,000 users including NASDAQ, Red Bull, and BuzzFeed — has rolled out Claude Code, Cursor, Augment, and Gemini CLI coding tools across its developer base to support its core business strategies and expand its newer AI offerings like customer-facing copilots and customizable AI agents. Devs use these tools across a variety of tasks, the simplest of which include data retrieval, code comprehension, smart search, and code lookup. Egnyte’s code base has lots of Java code, which uses numerous libraries, each with different versions, Jassal explained. AI tools are great for peer-to-peer programming, helping new users get a lay of the land, or existing users probe into different code repositories. “We have a pretty big code base, right?” Jassal said. “Let&#x27;s say you&#x27;re looking at an iOS application, but you&#x27;re not well versed; you will fire up Google CLI or an Augment, and ask it to discover the code base.”Some Egnyte devs are moving into automatic pull request summaries, which provide simple overviews of code changes that essentially explain the “what,” “how,” and “why” of proposed modifications. “But obviously, any change that&#x27;s made, we don&#x27;t want to hear that AI made the change; it has to be that developer made the change,” Jassal pointed out. “I would not trust AI to commit to the production code base.” Commits still pass through human review and security validation, and anything red-flagged is escalated to senior engineers. Devs are warned of the dangers of settling into autopilot mode or blindly trusting code. A model may not have been exposed to, or given enough samples of, certain coding components and infrastructure in its training. Another growing, and closely monitored, use case for AI is unit testing, where code components are run in isolation to ensure they work as intended. “At the end of the day, it is a productivity improvement tool,” he said. “It is really a continuation, it&#x27;s like any other tool, it&#x27;s not some magic.”Beyond core engineering, AI is helping other teams collaborate with programmers. Product management, for instance, is using tools like Vercel to bring “demo-worthy” prototypes, rather than just ideas, to devs, who can then move ahead with mock-ups. Or, if UX teams are looking to change certain elements on a dashboard, AI can quickly spin up a handful of options, like different widgets or buttons. “Then you come to engineering with that, and the engineer immediately knows what you really intend to do with it,” Jassal said. Setting expectations, meeting devs where they areHowever, day-to-day activities for all Egnyte engineers, including junior developers, extend beyond just coding. Junior developers are given hands-on tasks across the full development lifecycle to accelerate their growth and experience, Jassal said. For instance, they assist with requirement analysis in early software engineering phases, as well as deployment, productization and post-deployment maintenance.In turn, these activities require “Egnyte-specific tacit knowledge and experience” offered by senior engineers. One clear example of work that sits firmly with senior engineers is authoring architecture notes, as these cut across the platform and require a more holistic, system-level view, Jassal said. “Many of the traditional roadblocks are navigated faster these days with AI; for example, understanding the codebase, dissecting requirements, auto-testing,” he said. “This faster track allows our talented junior hires to progress more quickly and provide higher value to the company sooner.”The company expects a much faster learning curve from junior to mid-level engineers, Jassal said. “It&#x27;s always the case that people coming straight into the workforce are much more excited about trying new things,” Jassal said. But that has to be colored with reality to temper expectations, he added. On the other hand, some senior engineers may need to be ramped up in their adoption because they’re hesitant or had ho-hum or bad experiences with earlier generation tools. This requires incremental introduction. “The senior people, having been burnt multiple times, bring that perspective,” he said. \"So both [types of engineers] play an important role.”Hiring will continue for scale and fresh perspective“In general, I would say it has been really hyped by folks who want to sell you tokens,” Jassal said referring to people who talk about human coders becoming obsolete. \"Vibe coding\" could be construed in a similar vein: Like others in software development, he prefers the term “AI assisted coding,” wherein programmers have a self-driven loop, generating code, analyzing exceptions, then correcting and scaling. At least in Egnyte’s case, hiring will continue, even if at a slower clip as people become more productive thanks to AI, Jassal said. “We are not just hiring for scale, but to develop the next generation of senior developers and inject fresh perspectives into our development practices,” he said. The takeaway for technical decision-makers is not that AI will eliminate engineering jobs — but that it will reshape how talent is developed. At Egnyte, AI-assisted coding is compressing learning curves and raising expectations, not removing humans from the process. Enterprises that treat AI as a replacement risk hollowing out their future senior talent pipeline; those that treat it as infrastructure can move faster without losing the judgment, creativity, and accountability that only engineers provide.",
          "content": "Egnyte, the $1.5 billion cloud content governance company, has embedded AI coding tools across its global team of more than 350 developers — but not to reduce headcount. Instead, the company continues to hire junior engineers, using AI to accelerate onboarding, deepen codebase understanding, and shorten the path from junior to senior contributor. The approach challenges a dominant 2025 narrative that automation will replace developers, showing instead how enterprises are using AI to scale engineering capacity while keeping humans firmly in the loop.“To have engineers disappear or us not hiring junior engineers doesn&#x27;t look like the likely outcome,” Amrit Jassal, Egnyte CTO and co-founder, told VentureBeat. “You&#x27;ve got to have people, you&#x27;re training and doing all types of succession planning. The junior engineer of today is the senior engineer of tomorrow.”How Egnyte coders are using AI — without ceding controlEgnyte — which has more than 22,000 users including NASDAQ, Red Bull, and BuzzFeed — has rolled out Claude Code, Cursor, Augment, and Gemini CLI coding tools across its developer base to support its core business strategies and expand its newer AI offerings like customer-facing copilots and customizable AI agents. Devs use these tools across a variety of tasks, the simplest of which include data retrieval, code comprehension, smart search, and code lookup. Egnyte’s code base has lots of Java code, which uses numerous libraries, each with different versions, Jassal explained. AI tools are great for peer-to-peer programming, helping new users get a lay of the land, or existing users probe into different code repositories. “We have a pretty big code base, right?” Jassal said. “Let&#x27;s say you&#x27;re looking at an iOS application, but you&#x27;re not well versed; you will fire up Google CLI or an Augment, and ask it to discover the code base.”Some Egnyte devs are moving into automatic pull request summaries, which provide simple overviews of code changes that essentially explain the “what,” “how,” and “why” of proposed modifications. “But obviously, any change that&#x27;s made, we don&#x27;t want to hear that AI made the change; it has to be that developer made the change,” Jassal pointed out. “I would not trust AI to commit to the production code base.” Commits still pass through human review and security validation, and anything red-flagged is escalated to senior engineers. Devs are warned of the dangers of settling into autopilot mode or blindly trusting code. A model may not have been exposed to, or given enough samples of, certain coding components and infrastructure in its training. Another growing, and closely monitored, use case for AI is unit testing, where code components are run in isolation to ensure they work as intended. “At the end of the day, it is a productivity improvement tool,” he said. “It is really a continuation, it&#x27;s like any other tool, it&#x27;s not some magic.”Beyond core engineering, AI is helping other teams collaborate with programmers. Product management, for instance, is using tools like Vercel to bring “demo-worthy” prototypes, rather than just ideas, to devs, who can then move ahead with mock-ups. Or, if UX teams are looking to change certain elements on a dashboard, AI can quickly spin up a handful of options, like different widgets or buttons. “Then you come to engineering with that, and the engineer immediately knows what you really intend to do with it,” Jassal said. Setting expectations, meeting devs where they areHowever, day-to-day activities for all Egnyte engineers, including junior developers, extend beyond just coding. Junior developers are given hands-on tasks across the full development lifecycle to accelerate their growth and experience, Jassal said. For instance, they assist with requirement analysis in early software engineering phases, as well as deployment, productization and post-deployment maintenance.In turn, these activities require “Egnyte-specific tacit knowledge and experience” offered by senior engineers. One clear example of work that sits firmly with senior engineers is authoring architecture notes, as these cut across the platform and require a more holistic, system-level view, Jassal said. “Many of the traditional roadblocks are navigated faster these days with AI; for example, understanding the codebase, dissecting requirements, auto-testing,” he said. “This faster track allows our talented junior hires to progress more quickly and provide higher value to the company sooner.”The company expects a much faster learning curve from junior to mid-level engineers, Jassal said. “It&#x27;s always the case that people coming straight into the workforce are much more excited about trying new things,” Jassal said. But that has to be colored with reality to temper expectations, he added. On the other hand, some senior engineers may need to be ramped up in their adoption because they’re hesitant or had ho-hum or bad experiences with earlier generation tools. This requires incremental introduction. “The senior people, having been burnt multiple times, bring that perspective,” he said. \"So both [types of engineers] play an important role.”Hiring will continue for scale and fresh perspective“In general, I would say it has been really hyped by folks who want to sell you tokens,” Jassal said referring to people who talk about human coders becoming obsolete. \"Vibe coding\" could be construed in a similar vein: Like others in software development, he prefers the term “AI assisted coding,” wherein programmers have a self-driven loop, generating code, analyzing exceptions, then correcting and scaling. At least in Egnyte’s case, hiring will continue, even if at a slower clip as people become more productive thanks to AI, Jassal said. “We are not just hiring for scale, but to develop the next generation of senior developers and inject fresh perspectives into our development practices,” he said. The takeaway for technical decision-makers is not that AI will eliminate engineering jobs — but that it will reshape how talent is developed. At Egnyte, AI-assisted coding is compressing learning curves and raising expectations, not removing humans from the process. Enterprises that treat AI as a replacement risk hollowing out their future senior talent pipeline; those that treat it as infrastructure can move faster without losing the judgment, creativity, and accountability that only engineers provide.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7DUx86jAglIoinWLIrfpO8/abd01f833379598313f3bdeb2c35a96e/Egnyte.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/this-new-dead-simple-prompt-technique-boosts-accuracy-on-llms-by-up-to-76-on",
          "published_at": "Tue, 13 Jan 2026 19:57:00 GMT",
          "title": "This new, dead simple prompt technique boosts accuracy on LLMs by up to 76% on non-reasoning tasks",
          "standfirst": "In the chaotic world of Large Language Model (LLM) optimization, engineers have spent the last few years developing increasingly esoteric rituals to get better answers. We’ve seen \"Chain of Thought\" (asking the model to think step-by-step and often, show those \"reasoning traces\" to the user), \"Emotional Blackmail\" (telling the model its career depends on the answer, or that it is being accused of sexual misconduct), and complex multi-shot prompting frameworks.But a new paper released by Google Research suggests that we may have been overthinking it. The researchers found that simply repeating the input query—literally copying and pasting the prompt so it appears twice—consistently improves performance across major models including Gemini, GPT-4o, Claude, and DeepSeek.The paper, titled \"Prompt Repetition Improves Non-Reasoning LLMs,\" released last month just before the holidays, presents a finding that is almost suspiciously simple: for tasks that don’t require complex reasoning steps, stating the prompt twice yields significantly better results than stating it once. Even better, because of how transformer architecture works, this \"one weird trick\" comes with virtually zero penalty in terms of generation speed.The Causal Blind SpotTo understand why repeating a question makes a supercomputer smarter, you have to look at the architectural limitations of the standard Transformer model.Most modern LLMs are trained as \"causal\" language models. This means they process text strictly from left to right. When the model is processing the 5th token in your sentence, it can \"attend\" (pay attention) to tokens 1 through 4, but it has zero knowledge of token 6, because it hasn&#x27;t happened yet.This creates a fundamental constraint in how models understand user queries. As the authors note, the order of information matters immensely. A query formatted as <CONTEXT> <QUESTION> often yields different results than <QUESTION> <CONTEXT> because, in the latter case, the model reads the question before it knows the context it’s supposed to apply it to.Prompt repetition hacks this limitation by transforming an input of <QUERY> into <QUERY><QUERY>.By the time the model begins processing the second iteration of the query, it has already \"read\" the first iteration. This allows the tokens in the second copy to attend to every single token in the first copy. Effectively, the second repetition enjoys a form of bidirectional attention—it can \"look back\" at the entire query to resolve ambiguities or retrieve specific details that might have been missed in a single pass.The Benchmarks: 47 Wins, 0 LossesThe researchers, Yaniv Leviathan, Matan Kalman, and Yossi Matias, tested this hypothesis across a suite of seven popular benchmarks, including ARC, OpenBookOA, GSM8K, and MMLU-Pro. They evaluated seven different models, ranging from lightweight models like Gemini 2.0 Flash Lite and GPT-4o-mini to heavyweights like Claude 3.7 Sonnet and DeepSeek V3.The results were statistically stark. When asking models not to use explicit reasoning (i.e., just giving a direct answer), prompt repetition won 47 out of 70 head-to-head tests against the baseline, with zero losses.The gains were particularly dramatic in tasks requiring precise retrieval from a prompt. The team designed a custom \"NameIndex\" benchmark, where the model is given a list of 50 names and asked to identify the 25th one.Baseline Performance: Gemini 2.0 Flash-Lite scored a dismal 21.33% accuracy.With Repetition: Accuracy skyrocketed to 97.33%.This massive jump illustrates the \"causal blind spot\" perfectly. In a single pass, the model might lose track of the count by the time it reaches the 25th name. In the repeated pass, the model effectively has the entire list in its \"working memory\" before it attempts to solve the retrieval task.The \"Free Lunch\" of LatencyUsually, adding text to a prompt increases costs and latency. If you double the input, surely you double the wait time?Surprisingly, no. The paper demonstrates that prompt repetition is essentially \"free\" regarding user-perceived latency.LLM processing is divided into two stages:Prefill: The model processes the input prompt. This is highly parallelizable; the GPU can crunch the entire prompt matrix simultaneously.Generation (Decoding): The model generates the answer one token at a time. This is serial and slow.Prompt repetition only increases the work in the prefill stage. Because modern hardware handles prefill so efficiently, the user barely notices the difference. The researchers found that repeating the prompt did not increase the length of the generated answer, nor did it increase the \"time to first token\" latency for most models.The only exceptions were Anthropic’s models (Claude Haiku and Sonnet) on extremely long requests, where the prefill stage eventually hit a bottleneck. But for the vast majority of use cases, the technique improves accuracy without slowing down the chat experience.Reasoning vs. RepetitionThere is a caveat: this technique is primarily for \"non-reasoning\" tasks—scenarios where you want a direct answer rather than a step-by-step derivation.When the researchers tested prompt repetition combined with \"Chain of Thought\" (asking the model to \"think step by step\"), the gains largely vanished, showing neutral to slightly positive results (5 wins, 1 loss, 22 ties).The authors posit that reasoning models naturally perform a version of repetition themselves. When a model \"thinks,\" it often restates the premise of the question in its generated output before solving it. Therefore, explicitly repeating the prompt in the input becomes redundant. However, for applications where you need a fast, direct answer without the verbosity (and cost) of a long reasoning trace, prompt repetition offers a powerful alternative.Strategic Implementation for the EnterpriseFor enterprise leadership, this research represents that rarest of things in AI development: a \"free\" optimization. But capitalization requires nuance; this isn&#x27;t a setting to toggle blindly across an entire organization, but rather a tactical adjustment that ripples across engineering, orchestration, and security.For technical leads balancing the eternal triangle of speed, quality, and cost, prompt repetition offers a way to punch above your weight class. The data shows that smaller, faster models—like Gemini 2.0 Flash Lite—can achieve near-perfect retrieval accuracy (jumping from 21.33% to 97.33%) simply by processing the input twice. This changes the calculus for model selection: before upgrading to a larger, more expensive model to solve an accuracy bottleneck, engineers should first test whether simple repetition allows their current \"Lite\" models to close the gap. It is a potential strategy for retaining the speed and cost benefits of lightweight infrastructure without sacrificing performance on extraction and retrieval tasks.This logic naturally shifts the burden to the orchestration layer. For those managing the middleware and API gateways that glue AI applications together, prompt repetition should likely become a standard, invisible component of the pipeline logic rather than a user behavior. However, because the technique is neutral for reasoning-heavy tasks but highly effective for direct answers, it requires conditional application. A smart orchestration harness would automatically identify requests routed to non-reasoning endpoints—such as entity extraction, classification, or simple Q&A—and double the prompt before passing it to the model. This optimizes performance at the infrastructure level, delivering better results without requiring action from end-users or increasing the generation budget.Finally, this heightened attentiveness introduces a new variable for security teams. If repeating a prompt clarifies a user&#x27;s intent to the model, it stands to reason that malicious intents might be clarified as well. Security directors will need to update their red-teaming protocols to test \"repeated injection\" attacks—verifying whether repeating a jailbreak command (e.g., \"Ignore previous instructions\") makes the model \"attend\" to the breach more effectively. Conversely, this mechanism offers a new defensive tool: repeating System Prompts. Stating safety guardrails twice at the start of the context window could force the model to attend to safety constraints more rigorously, acting as a low-cost reinforcement for robust security operations.Why This MattersThis research highlights a crucial insight for developers building on top of LLMs: our current models are still deeply constrained by their unidirectional nature. While we wait for new architectures that might solve causal blindness, crude but effective workarounds like prompt repetition offer immediate value.The authors suggest this could become a default behavior for future systems. We might soon see inference engines that silently double our prompts in the background before sending them to the model, or \"Reasoning\" models trained to internalize this repetition strategy to be more efficient.For now, if you are struggling to get a model to follow complex instructions or retrieve specific details from a long document, the solution might not be a better prompt. You might just need to say it again.",
          "content": "In the chaotic world of Large Language Model (LLM) optimization, engineers have spent the last few years developing increasingly esoteric rituals to get better answers. We’ve seen \"Chain of Thought\" (asking the model to think step-by-step and often, show those \"reasoning traces\" to the user), \"Emotional Blackmail\" (telling the model its career depends on the answer, or that it is being accused of sexual misconduct), and complex multi-shot prompting frameworks.But a new paper released by Google Research suggests that we may have been overthinking it. The researchers found that simply repeating the input query—literally copying and pasting the prompt so it appears twice—consistently improves performance across major models including Gemini, GPT-4o, Claude, and DeepSeek.The paper, titled \"Prompt Repetition Improves Non-Reasoning LLMs,\" released last month just before the holidays, presents a finding that is almost suspiciously simple: for tasks that don’t require complex reasoning steps, stating the prompt twice yields significantly better results than stating it once. Even better, because of how transformer architecture works, this \"one weird trick\" comes with virtually zero penalty in terms of generation speed.The Causal Blind SpotTo understand why repeating a question makes a supercomputer smarter, you have to look at the architectural limitations of the standard Transformer model.Most modern LLMs are trained as \"causal\" language models. This means they process text strictly from left to right. When the model is processing the 5th token in your sentence, it can \"attend\" (pay attention) to tokens 1 through 4, but it has zero knowledge of token 6, because it hasn&#x27;t happened yet.This creates a fundamental constraint in how models understand user queries. As the authors note, the order of information matters immensely. A query formatted as <CONTEXT> <QUESTION> often yields different results than <QUESTION> <CONTEXT> because, in the latter case, the model reads the question before it knows the context it’s supposed to apply it to.Prompt repetition hacks this limitation by transforming an input of <QUERY> into <QUERY><QUERY>.By the time the model begins processing the second iteration of the query, it has already \"read\" the first iteration. This allows the tokens in the second copy to attend to every single token in the first copy. Effectively, the second repetition enjoys a form of bidirectional attention—it can \"look back\" at the entire query to resolve ambiguities or retrieve specific details that might have been missed in a single pass.The Benchmarks: 47 Wins, 0 LossesThe researchers, Yaniv Leviathan, Matan Kalman, and Yossi Matias, tested this hypothesis across a suite of seven popular benchmarks, including ARC, OpenBookOA, GSM8K, and MMLU-Pro. They evaluated seven different models, ranging from lightweight models like Gemini 2.0 Flash Lite and GPT-4o-mini to heavyweights like Claude 3.7 Sonnet and DeepSeek V3.The results were statistically stark. When asking models not to use explicit reasoning (i.e., just giving a direct answer), prompt repetition won 47 out of 70 head-to-head tests against the baseline, with zero losses.The gains were particularly dramatic in tasks requiring precise retrieval from a prompt. The team designed a custom \"NameIndex\" benchmark, where the model is given a list of 50 names and asked to identify the 25th one.Baseline Performance: Gemini 2.0 Flash-Lite scored a dismal 21.33% accuracy.With Repetition: Accuracy skyrocketed to 97.33%.This massive jump illustrates the \"causal blind spot\" perfectly. In a single pass, the model might lose track of the count by the time it reaches the 25th name. In the repeated pass, the model effectively has the entire list in its \"working memory\" before it attempts to solve the retrieval task.The \"Free Lunch\" of LatencyUsually, adding text to a prompt increases costs and latency. If you double the input, surely you double the wait time?Surprisingly, no. The paper demonstrates that prompt repetition is essentially \"free\" regarding user-perceived latency.LLM processing is divided into two stages:Prefill: The model processes the input prompt. This is highly parallelizable; the GPU can crunch the entire prompt matrix simultaneously.Generation (Decoding): The model generates the answer one token at a time. This is serial and slow.Prompt repetition only increases the work in the prefill stage. Because modern hardware handles prefill so efficiently, the user barely notices the difference. The researchers found that repeating the prompt did not increase the length of the generated answer, nor did it increase the \"time to first token\" latency for most models.The only exceptions were Anthropic’s models (Claude Haiku and Sonnet) on extremely long requests, where the prefill stage eventually hit a bottleneck. But for the vast majority of use cases, the technique improves accuracy without slowing down the chat experience.Reasoning vs. RepetitionThere is a caveat: this technique is primarily for \"non-reasoning\" tasks—scenarios where you want a direct answer rather than a step-by-step derivation.When the researchers tested prompt repetition combined with \"Chain of Thought\" (asking the model to \"think step by step\"), the gains largely vanished, showing neutral to slightly positive results (5 wins, 1 loss, 22 ties).The authors posit that reasoning models naturally perform a version of repetition themselves. When a model \"thinks,\" it often restates the premise of the question in its generated output before solving it. Therefore, explicitly repeating the prompt in the input becomes redundant. However, for applications where you need a fast, direct answer without the verbosity (and cost) of a long reasoning trace, prompt repetition offers a powerful alternative.Strategic Implementation for the EnterpriseFor enterprise leadership, this research represents that rarest of things in AI development: a \"free\" optimization. But capitalization requires nuance; this isn&#x27;t a setting to toggle blindly across an entire organization, but rather a tactical adjustment that ripples across engineering, orchestration, and security.For technical leads balancing the eternal triangle of speed, quality, and cost, prompt repetition offers a way to punch above your weight class. The data shows that smaller, faster models—like Gemini 2.0 Flash Lite—can achieve near-perfect retrieval accuracy (jumping from 21.33% to 97.33%) simply by processing the input twice. This changes the calculus for model selection: before upgrading to a larger, more expensive model to solve an accuracy bottleneck, engineers should first test whether simple repetition allows their current \"Lite\" models to close the gap. It is a potential strategy for retaining the speed and cost benefits of lightweight infrastructure without sacrificing performance on extraction and retrieval tasks.This logic naturally shifts the burden to the orchestration layer. For those managing the middleware and API gateways that glue AI applications together, prompt repetition should likely become a standard, invisible component of the pipeline logic rather than a user behavior. However, because the technique is neutral for reasoning-heavy tasks but highly effective for direct answers, it requires conditional application. A smart orchestration harness would automatically identify requests routed to non-reasoning endpoints—such as entity extraction, classification, or simple Q&A—and double the prompt before passing it to the model. This optimizes performance at the infrastructure level, delivering better results without requiring action from end-users or increasing the generation budget.Finally, this heightened attentiveness introduces a new variable for security teams. If repeating a prompt clarifies a user&#x27;s intent to the model, it stands to reason that malicious intents might be clarified as well. Security directors will need to update their red-teaming protocols to test \"repeated injection\" attacks—verifying whether repeating a jailbreak command (e.g., \"Ignore previous instructions\") makes the model \"attend\" to the breach more effectively. Conversely, this mechanism offers a new defensive tool: repeating System Prompts. Stating safety guardrails twice at the start of the context window could force the model to attend to safety constraints more rigorously, acting as a low-cost reinforcement for robust security operations.Why This MattersThis research highlights a crucial insight for developers building on top of LLMs: our current models are still deeply constrained by their unidirectional nature. While we wait for new architectures that might solve causal blindness, crude but effective workarounds like prompt repetition offer immediate value.The authors suggest this could become a default behavior for future systems. We might soon see inference engines that silently double our prompts in the background before sending them to the model, or \"Reasoning\" models trained to internalize this repetition strategy to be more efficient.For now, if you are struggling to get a model to follow complex instructions or retrieve specific details from a long document, the solution might not be a better prompt. You might just need to say it again.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6PTJl3Wssuvl5m3nljR103/21ab6a44da755c1cf2dca3b8fdd4ad08/cool-guys.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/nba-league-pass-is-up-to-55-percent-off-right-now-163421218.html",
          "published_at": "Tue, 13 Jan 2026 16:34:21 +0000",
          "title": "NBA League Pass is up to 55 percent off right now",
          "standfirst": "NBA League Pass, the streaming service that lets you catch hundreds of out-of-market NBA games, is on sale right now for up to 55 percent off. The League Pass Premium subscription is on sale for $75, down from $160, while League Pass Standard is marked down to $50 from $110. We're almost halfway through the season at this point, so it makes sense for a service like League Pass to start offering some discounts. The Standard plan includes commercials and support for only one device at a time, while the Premium tier offers no commercials, in-arena streams during breaks in the game, offline viewing of full games and concurrent streams on up to three devices at once. Last year, League Pass added multiview, which allows you to view up to four games at once on a single screen. This is included across both subscription tiers. The service also added a smart rewind tool that automatically selects key highlights and plays from each game. Outside the US and Canada, League Pass carries every single NBA game live, but within these countries a bevy of restrictions apply. In the US, any games being shown on your regional sports network will be blacked out as the service is meant for out-of-market games only. Also, any nationally broadcast games will not be available live, but instead will be available for on-demand viewing at 6AM ET the following day. The service is only for regular-season games. If you're an avid NBA fan that follows multiple teams then the League Pass almost certainly carries dozens of games you can watch even with the restrictions in the US. Subscribers can get a list of applicable blackouts by entering their ZIP code before signing up. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/nba-league-pass-is-up-to-55-percent-off-right-now-163421218.html?src=rss",
          "content": "NBA League Pass, the streaming service that lets you catch hundreds of out-of-market NBA games, is on sale right now for up to 55 percent off. The League Pass Premium subscription is on sale for $75, down from $160, while League Pass Standard is marked down to $50 from $110. We're almost halfway through the season at this point, so it makes sense for a service like League Pass to start offering some discounts. The Standard plan includes commercials and support for only one device at a time, while the Premium tier offers no commercials, in-arena streams during breaks in the game, offline viewing of full games and concurrent streams on up to three devices at once. Last year, League Pass added multiview, which allows you to view up to four games at once on a single screen. This is included across both subscription tiers. The service also added a smart rewind tool that automatically selects key highlights and plays from each game. Outside the US and Canada, League Pass carries every single NBA game live, but within these countries a bevy of restrictions apply. In the US, any games being shown on your regional sports network will be blacked out as the service is meant for out-of-market games only. Also, any nationally broadcast games will not be available live, but instead will be available for on-demand viewing at 6AM ET the following day. The service is only for regular-season games. If you're an avid NBA fan that follows multiple teams then the League Pass almost certainly carries dozens of games you can watch even with the restrictions in the US. Subscribers can get a list of applicable blackouts by entering their ZIP code before signing up. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/nba-league-pass-is-up-to-55-percent-off-right-now-163421218.html?src=rss",
          "feed_position": 40
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/deepseeks-conditional-memory-fixes-silent-llm-waste-gpu-cycles-lost-to",
          "published_at": "Tue, 13 Jan 2026 16:00:00 GMT",
          "title": "DeepSeek’s conditional memory fixes silent LLM waste: GPU cycles lost to static lookups",
          "standfirst": "When an enterprise LLM retrieves a product name, technical specification, or standard contract clause, it&#x27;s using expensive GPU computation designed for complex reasoning — just to access static information. This happens millions of times per day. Each lookup wastes cycles and inflates infrastructure costs. DeepSeek&#x27;s newly released research on \"conditional memory\" addresses this architectural limitation directly. The work introduces Engram, a module that separates static pattern retrieval from dynamic reasoning. It delivers results that challenge assumptions about what memory is actually for in neural networks. The paper was co-authored by DeepSeek founder Liang Wenfeng.Through systematic experiments DeepSeek found the optimal balance between computation and memory with 75% of sparse model capacity allocated to dynamic reasoning and 25% to static lookups. This memory system improved reasoning more than knowledge retrieval. Complex reasoning benchmarks jumped from 70% to 74% accuracy, while knowledge-focused tests improved from 57% to 61%. These improvements came from tests including Big-Bench Hard, ARC-Challenge, and MMLU.The research arrives as enterprises face mounting pressure to deploy more capable AI systems while navigating GPU memory constraints and infrastructure costs. DeepSeek&#x27;s approach offers a potential path forward by fundamentally rethinking how models should be structured.How conditional memory solves a different issue than agentic memory and RAGAgentic memory systems, sometimes referred to as contextual memory — like Hindsight, MemOS, or Memp — focus on episodic memory. They store records of past conversations, user preferences, and interaction history. These systems help agents maintain context across sessions and learn from experience. But they&#x27;re external to the model&#x27;s forward pass and don&#x27;t optimize how the model internally processes static linguistic patterns.For Chris Latimer, founder and CEO of Vectorize, which developed Hindsight, the conditional memory approach used in Engram solves a different problem than agentic AI memory.\"It&#x27;s not solving the problem of connecting agents to external memory like conversation histories and knowledge stores,\" Latimer told VentureBeat. \"It&#x27;s more geared towards squeezing performance out of smaller models and getting more mileage out of scarce GPU resources.\"Conditional memory tackles a fundamental issue: Transformers lack a native knowledge lookup primitive. When processing text, they must simulate retrieval of static patterns through expensive neural computation across multiple layers. These patterns include named entities, technical terminology, and common phrases.The DeepSeek paper illustrates this with a concrete example. Recognizing \"Diana, Princess of Wales\" requires consuming multiple layers of attention and feed-forward networks to progressively compose features. The model essentially uses deep, dynamic logic circuits to perform what should be a simple hash table lookup. It&#x27;s like using a calculator to remember your phone number rather than just looking it up.\"The problem is that Transformer lacks a &#x27;native knowledge lookup&#x27; ability,\" the researchers write. \"Many tasks that should be solved in O(1) time like retrieval have to be &#x27;simulated for retrieval&#x27; through a large amount of computation, which is very inefficient.\"How conditional memory worksEngram introduces \"conditional memory\" to work alongside MoE&#x27;s conditional computation. The mechanism is straightforward. The module takes sequences of two to three tokens and uses hash functions to look them up in a massive embedding table. Retrieval happens in constant time, regardless of table size.But retrieved patterns need filtering. A hash lookup for \"Apple\" might collide with unrelated content, or the word might mean the fruit rather than the company. Engram solves this with a gating mechanism. The model&#x27;s current understanding of context (accumulated through earlier attention layers) acts as a filter. If retrieved memory contradicts the current context, the gate suppresses it. If it fits, the gate lets it through.The module isn&#x27;t applied at every layer. Strategic placement balances performance gains against system latency.This dual-system design raises a critical question: How much capacity should each get? DeepSeek&#x27;s key finding: the optimal split is 75-80% for computation and 20-25% for memory. Testing found pure MoE (100% computation) proved suboptimal. Too much computation wastes depth reconstructing static patterns; too much memory loses reasoning capacity.Infrastructure efficiency: the GPU memory bypassPerhaps Engram&#x27;s most pragmatic contribution is its infrastructure-aware design. Unlike MoE&#x27;s dynamic routing, which depends on runtime hidden states, Engram&#x27;s retrieval indices depend solely on input token sequences. This deterministic nature enables a prefetch-and-overlap strategy.\"The challenge is that GPU memory is limited and expensive, so using bigger models gets costly and harder to deploy,\" Latimer said. \"The clever idea behind Engram is to keep the main model on the GPU, but offload a big chunk of the model&#x27;s stored information into a separate memory on regular RAM, which the model can use on a just-in-time basis.\"During inference, the system can asynchronously retrieve embeddings from host CPU memory via PCIe. This happens while GPU computes preceding transformer blocks. Strategic layer placement leverages computation of early layers as a buffer to mask communication latency.The researchers demonstrated this with a 100B-parameter embedding table entirely offloaded to host DRAM. They achieved throughput penalties below 3%. This decoupling of storage from compute addresses a critical enterprise constraint as GPU high-bandwidth memory remains expensive and scarce.What this means for enterprise AI deploymentFor enterprises evaluating AI infrastructure strategies, DeepSeek&#x27;s findings suggest several actionable insights:1. Hybrid architectures outperform pure approaches. The 75/25 allocation law indicates that optimal models should split sparse capacity between computation and memory. 2. Infrastructure costs may shift from GPU to memory. If Engram-style architectures prove viable in production, infrastructure investment patterns could change. The ability to store 100B+ parameters in CPU memory with minimal overhead suggests that memory-rich, compute-moderate configurations may offer better performance-per-dollar than pure GPU scaling.3. Reasoning improvements exceed knowledge gains. The surprising finding that reasoning benefits more than knowledge retrieval suggests that memory&#x27;s value extends beyond obvious use cases. For enterprises leading AI adoption, Engram demonstrates that the next frontier may not be simply bigger models. It&#x27;s smarter architectural choices that respect the fundamental distinction between static knowledge and dynamic reasoning. The research suggests that optimal AI systems will increasingly resemble hybrid architectures. Organizations waiting to adopt AI later in the cycle should monitor whether major model providers incorporate conditional memory principles into their architectures. If the 75/25 allocation law holds across scales and domains, the next generation of foundation models may deliver substantially better reasoning performance at lower infrastructure costs.",
          "content": "When an enterprise LLM retrieves a product name, technical specification, or standard contract clause, it&#x27;s using expensive GPU computation designed for complex reasoning — just to access static information. This happens millions of times per day. Each lookup wastes cycles and inflates infrastructure costs. DeepSeek&#x27;s newly released research on \"conditional memory\" addresses this architectural limitation directly. The work introduces Engram, a module that separates static pattern retrieval from dynamic reasoning. It delivers results that challenge assumptions about what memory is actually for in neural networks. The paper was co-authored by DeepSeek founder Liang Wenfeng.Through systematic experiments DeepSeek found the optimal balance between computation and memory with 75% of sparse model capacity allocated to dynamic reasoning and 25% to static lookups. This memory system improved reasoning more than knowledge retrieval. Complex reasoning benchmarks jumped from 70% to 74% accuracy, while knowledge-focused tests improved from 57% to 61%. These improvements came from tests including Big-Bench Hard, ARC-Challenge, and MMLU.The research arrives as enterprises face mounting pressure to deploy more capable AI systems while navigating GPU memory constraints and infrastructure costs. DeepSeek&#x27;s approach offers a potential path forward by fundamentally rethinking how models should be structured.How conditional memory solves a different issue than agentic memory and RAGAgentic memory systems, sometimes referred to as contextual memory — like Hindsight, MemOS, or Memp — focus on episodic memory. They store records of past conversations, user preferences, and interaction history. These systems help agents maintain context across sessions and learn from experience. But they&#x27;re external to the model&#x27;s forward pass and don&#x27;t optimize how the model internally processes static linguistic patterns.For Chris Latimer, founder and CEO of Vectorize, which developed Hindsight, the conditional memory approach used in Engram solves a different problem than agentic AI memory.\"It&#x27;s not solving the problem of connecting agents to external memory like conversation histories and knowledge stores,\" Latimer told VentureBeat. \"It&#x27;s more geared towards squeezing performance out of smaller models and getting more mileage out of scarce GPU resources.\"Conditional memory tackles a fundamental issue: Transformers lack a native knowledge lookup primitive. When processing text, they must simulate retrieval of static patterns through expensive neural computation across multiple layers. These patterns include named entities, technical terminology, and common phrases.The DeepSeek paper illustrates this with a concrete example. Recognizing \"Diana, Princess of Wales\" requires consuming multiple layers of attention and feed-forward networks to progressively compose features. The model essentially uses deep, dynamic logic circuits to perform what should be a simple hash table lookup. It&#x27;s like using a calculator to remember your phone number rather than just looking it up.\"The problem is that Transformer lacks a &#x27;native knowledge lookup&#x27; ability,\" the researchers write. \"Many tasks that should be solved in O(1) time like retrieval have to be &#x27;simulated for retrieval&#x27; through a large amount of computation, which is very inefficient.\"How conditional memory worksEngram introduces \"conditional memory\" to work alongside MoE&#x27;s conditional computation. The mechanism is straightforward. The module takes sequences of two to three tokens and uses hash functions to look them up in a massive embedding table. Retrieval happens in constant time, regardless of table size.But retrieved patterns need filtering. A hash lookup for \"Apple\" might collide with unrelated content, or the word might mean the fruit rather than the company. Engram solves this with a gating mechanism. The model&#x27;s current understanding of context (accumulated through earlier attention layers) acts as a filter. If retrieved memory contradicts the current context, the gate suppresses it. If it fits, the gate lets it through.The module isn&#x27;t applied at every layer. Strategic placement balances performance gains against system latency.This dual-system design raises a critical question: How much capacity should each get? DeepSeek&#x27;s key finding: the optimal split is 75-80% for computation and 20-25% for memory. Testing found pure MoE (100% computation) proved suboptimal. Too much computation wastes depth reconstructing static patterns; too much memory loses reasoning capacity.Infrastructure efficiency: the GPU memory bypassPerhaps Engram&#x27;s most pragmatic contribution is its infrastructure-aware design. Unlike MoE&#x27;s dynamic routing, which depends on runtime hidden states, Engram&#x27;s retrieval indices depend solely on input token sequences. This deterministic nature enables a prefetch-and-overlap strategy.\"The challenge is that GPU memory is limited and expensive, so using bigger models gets costly and harder to deploy,\" Latimer said. \"The clever idea behind Engram is to keep the main model on the GPU, but offload a big chunk of the model&#x27;s stored information into a separate memory on regular RAM, which the model can use on a just-in-time basis.\"During inference, the system can asynchronously retrieve embeddings from host CPU memory via PCIe. This happens while GPU computes preceding transformer blocks. Strategic layer placement leverages computation of early layers as a buffer to mask communication latency.The researchers demonstrated this with a 100B-parameter embedding table entirely offloaded to host DRAM. They achieved throughput penalties below 3%. This decoupling of storage from compute addresses a critical enterprise constraint as GPU high-bandwidth memory remains expensive and scarce.What this means for enterprise AI deploymentFor enterprises evaluating AI infrastructure strategies, DeepSeek&#x27;s findings suggest several actionable insights:1. Hybrid architectures outperform pure approaches. The 75/25 allocation law indicates that optimal models should split sparse capacity between computation and memory. 2. Infrastructure costs may shift from GPU to memory. If Engram-style architectures prove viable in production, infrastructure investment patterns could change. The ability to store 100B+ parameters in CPU memory with minimal overhead suggests that memory-rich, compute-moderate configurations may offer better performance-per-dollar than pure GPU scaling.3. Reasoning improvements exceed knowledge gains. The surprising finding that reasoning benefits more than knowledge retrieval suggests that memory&#x27;s value extends beyond obvious use cases. For enterprises leading AI adoption, Engram demonstrates that the next frontier may not be simply bigger models. It&#x27;s smarter architectural choices that respect the fundamental distinction between static knowledge and dynamic reasoning. The research suggests that optimal AI systems will increasingly resemble hybrid architectures. Organizations waiting to adopt AI later in the cycle should monitor whether major model providers incorporate conditional memory principles into their architectures. If the 75/25 allocation law holds across scales and domains, the next generation of foundation models may deliver substantially better reasoning performance at lower infrastructure costs.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5QbXis6MzFunSR0Q7iejyX/2cd47fca23ad6f0fd1e3094fc096252e/conditional-memory-smk.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/anthropic-launches-claude-cowork-a-version-of-its-coding-ai-for-regular-people-193000849.html",
          "published_at": "Tue, 13 Jan 2026 15:27:21 +0000",
          "title": "Anthropic launches Claude Cowork, a version of its coding AI for regular people",
          "standfirst": "If you follow Anthropic, you're probably familiar with Claude Code. Since the fall of 2024, the company has been training its AI models to use and navigate computers like a human would, and the coding agent has been the most practical expression of that work, giving developers a way to automate rote programming tasks. Starting today, Anthropic is giving regular people a way to take advantage of those capabilities, with the release of a new preview feature called Claude Cowork.The company is billing Cowork as \"a simpler way for anyone — not just developers — to work with Claude.\" After you give the system access to a folder on your computer, it can read, edit or create new files in that folder on your behalf. Anthropic gives a few different example use cases for Cowork. For instance, you could ask Claude to organize your downloads folder, telling it to rename the files contained within to something that's easier to parse at a glance. Another example: you could use Claude to turn screenshots of receipts and invoices into a spreadsheet for tracking expenses. Cowork can also navigate websites — provided you install Claude’s Chrome plugin — and make can use Anthropic's Connectors framework to access third-party apps like Canva. \"Cowork is designed to make using Claude for new work as simple as possible. You don’t need to keep manually providing context or converting Claude’s outputs into the right format,\" the company said. \"Nor do you have to wait for Claude to finish before offering further ideas or feedback: you can queue up tasks and let Claude work through them in parallel.\" If the idea of granting Claude access to your computer sounds ill-advised, Anthropic says Claude \"can’t read or edit anything you don’t give it explicit access to.\" However, the company does note the system can \"take potentially destructive actions,\" such as deleting a file that is important to you or misinterpreting your instructions. For that reason, Anthropic suggests it's best to give \"very clear\" guidance to Claude. Anthropic isn’t the first to offer a computer agent. Microsoft, for example, has been pushing Copilot hard for nearly three years, despite seemingly limited adoption. For Anthropic, the challenge will be convincing people these tools are useful where others have failed. The fact Claude Code has been universally loved by programmers may make that task easier. For now, Anthropic is giving users of its pricey Claude Max subscription first access to the preview. If you want to try Cowork for yourself, you'll also need a Mac with the Claude macOS app installed. For everyone else, you’ll need to join a wait list. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-launches-claude-cowork-a-version-of-its-coding-ai-for-regular-people-193000849.html?src=rss",
          "content": "If you follow Anthropic, you're probably familiar with Claude Code. Since the fall of 2024, the company has been training its AI models to use and navigate computers like a human would, and the coding agent has been the most practical expression of that work, giving developers a way to automate rote programming tasks. Starting today, Anthropic is giving regular people a way to take advantage of those capabilities, with the release of a new preview feature called Claude Cowork.The company is billing Cowork as \"a simpler way for anyone — not just developers — to work with Claude.\" After you give the system access to a folder on your computer, it can read, edit or create new files in that folder on your behalf. Anthropic gives a few different example use cases for Cowork. For instance, you could ask Claude to organize your downloads folder, telling it to rename the files contained within to something that's easier to parse at a glance. Another example: you could use Claude to turn screenshots of receipts and invoices into a spreadsheet for tracking expenses. Cowork can also navigate websites — provided you install Claude’s Chrome plugin — and make can use Anthropic's Connectors framework to access third-party apps like Canva. \"Cowork is designed to make using Claude for new work as simple as possible. You don’t need to keep manually providing context or converting Claude’s outputs into the right format,\" the company said. \"Nor do you have to wait for Claude to finish before offering further ideas or feedback: you can queue up tasks and let Claude work through them in parallel.\" If the idea of granting Claude access to your computer sounds ill-advised, Anthropic says Claude \"can’t read or edit anything you don’t give it explicit access to.\" However, the company does note the system can \"take potentially destructive actions,\" such as deleting a file that is important to you or misinterpreting your instructions. For that reason, Anthropic suggests it's best to give \"very clear\" guidance to Claude. Anthropic isn’t the first to offer a computer agent. Microsoft, for example, has been pushing Copilot hard for nearly three years, despite seemingly limited adoption. For Anthropic, the challenge will be convincing people these tools are useful where others have failed. The fact Claude Code has been universally loved by programmers may make that task easier. For now, Anthropic is giving users of its pricey Claude Max subscription first access to the preview. If you want to try Cowork for yourself, you'll also need a Mac with the Claude macOS app installed. For everyone else, you’ll need to join a wait list. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-launches-claude-cowork-a-version-of-its-coding-ai-for-regular-people-193000849.html?src=rss",
          "feed_position": 41
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/remarkable-e-ink-tablet-bundles-are-up-to-90-off-right-now-150242312.html",
          "published_at": "Tue, 13 Jan 2026 15:02:42 +0000",
          "title": "reMarkable E Ink tablet bundles are up to $90 off right now",
          "standfirst": "E Ink tablet maker reMarkable is running a bundle deal right now that can save you between $80 and $90 when buying a reMarkable 2 along with a Marker stylus and a folio case. The savings vary depending on the bundle you configure, but this can bring your out-the-door cost down to $449 from $529 for the tablet, Marker stylus and polymer weave book folio. The company also sells a newer stylus called Marker Plus that lets you erase by flipping it around just like a real pencil, but that will cost you an extra $50. If you’ve been eyeing a dedicated writing tablet for work, school or just jotting down notes without the distraction of endless apps, this bundle deal is an ideal opportunity to pick one up. The reMarkable 2 earned our top pick for best e-ink tablet. In our review, we said the tablet was prettier than ever with a 10.3-inch display and a handsome aluminum frame. The tablet is only 4.7mm thick and weighs less than a pound, helping it feel lean and portable. The display can detect over 4,000 different levels of pressure with the Marker stylus, allowing for precise shading when sketching and the latency between the stylus and the screen is just 21ms. reMarkable fitted the display with a resin layer on top of the glass to make writing on it feel more realistic. We didn't think this passed muster, but we found writing on it was a joy nonetheless. The tablet supports PDFs and ePUBs, which can be added via the companion mobile app or a desktop computer. You can also pair the reMarkable 2 with Google Drive, Microsoft OneDrive or Dropbox to access files. The battery is rated for an impressive two weeks between charges. The reMarkable Paper Pro, a higher-end model with a richer feature set like a full color display and a built-in reading light, is our pick for best premium e-ink tablet. The pricier tablet also has bundle deals right now with savings up to $80 depending on configuration. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/remarkable-e-ink-tablet-bundles-are-up-to-90-off-right-now-150242312.html?src=rss",
          "content": "E Ink tablet maker reMarkable is running a bundle deal right now that can save you between $80 and $90 when buying a reMarkable 2 along with a Marker stylus and a folio case. The savings vary depending on the bundle you configure, but this can bring your out-the-door cost down to $449 from $529 for the tablet, Marker stylus and polymer weave book folio. The company also sells a newer stylus called Marker Plus that lets you erase by flipping it around just like a real pencil, but that will cost you an extra $50. If you’ve been eyeing a dedicated writing tablet for work, school or just jotting down notes without the distraction of endless apps, this bundle deal is an ideal opportunity to pick one up. The reMarkable 2 earned our top pick for best e-ink tablet. In our review, we said the tablet was prettier than ever with a 10.3-inch display and a handsome aluminum frame. The tablet is only 4.7mm thick and weighs less than a pound, helping it feel lean and portable. The display can detect over 4,000 different levels of pressure with the Marker stylus, allowing for precise shading when sketching and the latency between the stylus and the screen is just 21ms. reMarkable fitted the display with a resin layer on top of the glass to make writing on it feel more realistic. We didn't think this passed muster, but we found writing on it was a joy nonetheless. The tablet supports PDFs and ePUBs, which can be added via the companion mobile app or a desktop computer. You can also pair the reMarkable 2 with Google Drive, Microsoft OneDrive or Dropbox to access files. The battery is rated for an impressive two weeks between charges. The reMarkable Paper Pro, a higher-end model with a richer feature set like a full color display and a built-in reading light, is our pick for best premium e-ink tablet. The pricier tablet also has bundle deals right now with savings up to $80 depending on configuration. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/remarkable-e-ink-tablet-bundles-are-up-to-90-off-right-now-150242312.html?src=rss",
          "feed_position": 42
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/apple-bundles-creative-apps-such-as-final-cut-pro-and-logic-pro-into-a-single-subscription-145210038.html",
          "published_at": "Tue, 13 Jan 2026 14:52:10 +0000",
          "title": "Apple bundles creative apps such as Final Cut Pro and Logic Pro into a single subscription",
          "standfirst": "Apple has been putting more onus on its services for the past several years — the company makes tens of billions of dollars in revenue from that side of the business, which it claimed had a record year in 2025. Apple is nudging a little more in that direction with a new subscription bundle called Apple Creator Studio.This allows creators to pay a single fee ($13 per month or $129 per year) to use Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor and MainStage. Subscribers will get access to “premium content” in Pages, Keynote and Numbers (as well as in Freeform later this year). Of course, there are AI features too. Apple Creator Studio will be available starting on January 28 and you can try it out at no cost through a one-month free trial. College students and educators can subscribe to Apple Creator Studio for $3 per month or $30 per year. Up to six people can access all of the plan’s features if one person in a Family Sharing group subscribes. Apple noted that Final Cut Pro, Pixelmator Pro, Logic Pro, Motion, Compressor and MainStage will still be available as one-time purchases for Mac through the Mac App Store. Given that those can be pretty pricy (going up to $300 for Final Cut Pro), the subscription could be enticing to many burgeoning creators.This seems like Apple’s attempt to muscle in on Adobe’s territory, especially now that it’s bringing AI features to many of these apps. Adding new features to productivity apps like Numbers and Keynote means Apple’s taking a shot at the likes of Microsoft 365 Copilot (yeeeeah, that’s what Office is called now) and Google Workspace as well.On Mac and iPad, Final Cut Pro has a new feature called Beat Detection. Apple suggests this makes “editing video to the rhythm of music fast and fun.” It uses an AI model from Logic Pro to analyze music tracks and display a Beat Grid. The idea here is to visualize song parts, beats and bars to help editors align their cuts with the music. The Montage Maker tool in Final Cut Pro on an iPad.AppleAn AI-powered Montage Maker tool can stitch together “a dynamic video based on the best visual moments within the footage.” You’ll be able to tweak these montages and use an Auto Crop tool to reframe the clip into a vertical format to make it a better fit for social media. Final Cut Pro has transcript and visual search functions too.Logic Pro, MainStage, Pixelmator Pro (which is coming to iPad with Apple Pencil support) and Motion will all have AI-powered features as well. As you might expect, you’ll need an Apple Intelligence-capable device to use some of these.Apple is also introducing something called the Content Hub. This media library includes “curated, high-quality photos, graphics and illustrations.” As for Keynote, Pages, and Numbers, you’ll be able to access premium templates and themes in those otherwise-free apps with a Apple Creator Studio plan. Subscribers will be able to try beta versions of new features, such as a way to generate a draft of a Keynote presentation text based on an outline, and a Magic Fill tool to generate formulas and fill in tables in Numbers.This article originally appeared on Engadget at https://www.engadget.com/apps/apple-bundles-creative-apps-such-as-final-cut-pro-and-logic-pro-into-a-single-subscription-145210038.html?src=rss",
          "content": "Apple has been putting more onus on its services for the past several years — the company makes tens of billions of dollars in revenue from that side of the business, which it claimed had a record year in 2025. Apple is nudging a little more in that direction with a new subscription bundle called Apple Creator Studio.This allows creators to pay a single fee ($13 per month or $129 per year) to use Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor and MainStage. Subscribers will get access to “premium content” in Pages, Keynote and Numbers (as well as in Freeform later this year). Of course, there are AI features too. Apple Creator Studio will be available starting on January 28 and you can try it out at no cost through a one-month free trial. College students and educators can subscribe to Apple Creator Studio for $3 per month or $30 per year. Up to six people can access all of the plan’s features if one person in a Family Sharing group subscribes. Apple noted that Final Cut Pro, Pixelmator Pro, Logic Pro, Motion, Compressor and MainStage will still be available as one-time purchases for Mac through the Mac App Store. Given that those can be pretty pricy (going up to $300 for Final Cut Pro), the subscription could be enticing to many burgeoning creators.This seems like Apple’s attempt to muscle in on Adobe’s territory, especially now that it’s bringing AI features to many of these apps. Adding new features to productivity apps like Numbers and Keynote means Apple’s taking a shot at the likes of Microsoft 365 Copilot (yeeeeah, that’s what Office is called now) and Google Workspace as well.On Mac and iPad, Final Cut Pro has a new feature called Beat Detection. Apple suggests this makes “editing video to the rhythm of music fast and fun.” It uses an AI model from Logic Pro to analyze music tracks and display a Beat Grid. The idea here is to visualize song parts, beats and bars to help editors align their cuts with the music. The Montage Maker tool in Final Cut Pro on an iPad.AppleAn AI-powered Montage Maker tool can stitch together “a dynamic video based on the best visual moments within the footage.” You’ll be able to tweak these montages and use an Auto Crop tool to reframe the clip into a vertical format to make it a better fit for social media. Final Cut Pro has transcript and visual search functions too.Logic Pro, MainStage, Pixelmator Pro (which is coming to iPad with Apple Pencil support) and Motion will all have AI-powered features as well. As you might expect, you’ll need an Apple Intelligence-capable device to use some of these.Apple is also introducing something called the Content Hub. This media library includes “curated, high-quality photos, graphics and illustrations.” As for Keynote, Pages, and Numbers, you’ll be able to access premium templates and themes in those otherwise-free apps with a Apple Creator Studio plan. Subscribers will be able to try beta versions of new features, such as a way to generate a draft of a Keynote presentation text based on an outline, and a Magic Fill tool to generate formulas and fill in tables in Numbers.This article originally appeared on Engadget at https://www.engadget.com/apps/apple-bundles-creative-apps-such-as-final-cut-pro-and-logic-pro-into-a-single-subscription-145210038.html?src=rss",
          "feed_position": 44,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/final_cut.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/airtags-are-back-on-sale-with-a-four-pack-going-for-65-202333994.html",
          "published_at": "Tue, 13 Jan 2026 13:14:02 +0000",
          "title": "AirTags are back on sale, with a four-pack going for $65",
          "standfirst": "Most Apple products are pretty expensive, but some of the most affordable (and useful) ones are AirTags. The Bluetooth trackers are priced pretty reasonably even when not on sale, but they can be a steal if you can get them on a discount — like right now. A four pack of AirTags is on sale for $65 at Amazon, which is only a few dollars more than the record-low price we saw during Black Friday this year. AirTags can be useful for people who travel frequently, helping you to keep track of essentials like your passport as well as a way to keep tabs on luggage while you're on the go. If you do purchase some AirTags, we have some recommendations for useful accessories to go along with them, such as different styles of cases to best attach the trackers to different types of items. These are worth looking over and adding to your shopping cart in order to make the most of the product. AirTags have an IP67 rating for water and dust resistance and their replaceable batteries should last for about a year. They can also support Precision Finding, which gives more exact directions to a lost item, when paired with most models after the iPhone 11. Up to five people can share an AirTag's location, which is helpful for families or large travel groups. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/airtags-are-back-on-sale-with-a-four-pack-going-for-65-202333994.html?src=rss",
          "content": "Most Apple products are pretty expensive, but some of the most affordable (and useful) ones are AirTags. The Bluetooth trackers are priced pretty reasonably even when not on sale, but they can be a steal if you can get them on a discount — like right now. A four pack of AirTags is on sale for $65 at Amazon, which is only a few dollars more than the record-low price we saw during Black Friday this year. AirTags can be useful for people who travel frequently, helping you to keep track of essentials like your passport as well as a way to keep tabs on luggage while you're on the go. If you do purchase some AirTags, we have some recommendations for useful accessories to go along with them, such as different styles of cases to best attach the trackers to different types of items. These are worth looking over and adding to your shopping cart in order to make the most of the product. AirTags have an IP67 rating for water and dust resistance and their replaceable batteries should last for about a year. They can also support Precision Finding, which gives more exact directions to a lost item, when paired with most models after the iPhone 11. Up to five people can share an AirTag's location, which is helpful for families or large travel groups. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/airtags-are-back-on-sale-with-a-four-pack-going-for-65-202333994.html?src=rss",
          "feed_position": 49
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
          "published_at": "Tue, 13 Jan 2026 13:00:00 GMT",
          "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
          "standfirst": "Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.The new Slackbot, now generally available to Business+ and Enterprise+ customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging \"agentic AI\" movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.\"Slackbot isn&#x27;t just another copilot or AI assistant,\" said Parker Harris, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. \"It&#x27;s the front door to the agentic enterprise, powered by Salesforce.\"From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground upHarris was blunt about what distinguishes the new Slackbot from its predecessor: \"The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.\"The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.\"It&#x27;s two different things,\" Harris explained. \"The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.\"Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. \"People know what Slackbot is, and so we wanted to carry that forward,\" Harris said.Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come nextThe new Slackbot runs on Claude, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under FedRAMP Moderate certification to serve U.S. federal government customers, and Harris said Anthropic was \"the only provider that could give us a compliant LLM\" when Slack began building the new system.But that exclusivity won&#x27;t last. \"We are, this year, going to support additional providers,\" Harris said. \"We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.\" He added that OpenAI remains a possibility as well.Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: \"You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.\"On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. \"Models don&#x27;t have any sort of security,\" he explained. \"If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.\"Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking resultsSalesforce has been testing the new Slackbot internally for months, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: \"It&#x27;s the fastest adopted product in Salesforce history.\"Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.The adoption happened largely organically. \"I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;\" Gavin said. \"People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.\"Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. \"Everybody is there to help each other learn and communicate hacks,\" she said.How Slackbot transforms scattered enterprise data into executive-ready insightsDuring a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.\"This is where Slackbot really earns its keep for me,\" Bauer explained. \"What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.\"Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called \"a really great justification and plan to move forward.\" Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.\"Up until this point, we have been working in a one-to-one capacity with Slackbot,\" Bauer said. \"But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.\"Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: \"This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.\"MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a dayAmong Salesforce&#x27;s pilot customers is Beast Industries, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.\"As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,\" Madrigal said. \"The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.\"Madrigal said his security team signed off \"rather quickly\" — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. \"Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.\"One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving \"at bare minimum, 90 minutes a day.\" Another employee, Spencer, a creative supervisor, described it as \"an assistant who&#x27;s paying attention when I&#x27;m not.\"Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot \"an absolute &#x27;chaos tamer&#x27; for our team,\" estimating it saves her about 30 minutes daily \"just by eliminating context switching.\"Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominanceThe launch puts Salesforce in direct competition with Microsoft&#x27;s Copilot, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.\"The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,\" Seaman said. \"There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.\"The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. \"Most AI tools sound the same no matter who is using them,\" the company&#x27;s announcement stated. \"They lack context, miss nuance, and force you to jump between tools to get anything done.\"Harris put it more directly: \"If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.\"Amy Bauer emphasized the frictionless nature of the experience. \"Slackbot is inherently grounded in the context, in the data that you have in Slack,\" she said. \"So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.\"Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the othersSalesforce positions Slackbot as what Harris calls a \"super agent\" — a central hub that can eventually coordinate with other AI agents across an organization.\"Every corporation is going to have an employee super agent,\" Harris said. \"Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.\"The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.\"Most of the net-new apps that are being deployed to Slack are agents,\" Seaman noted during the press conference. \"This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.\"Harris described a future where Slackbot becomes an MCP (Model Context Protocol) client, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. \"Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,\" he said.But Harris also cautioned against over-promising on multi-agent coordination. \"I still think we&#x27;re in the single agent world,\" he said. \"FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.\"Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customersSlackbot is included at no additional cost for customers on Business+ and Enterprise+ plans. \"There&#x27;s no additional fees customers have to do,\" Gavin confirmed. \"If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.\"However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. \"They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,\" Fraser said in a recent CIO report.Salesforce has framed the pricing change as standard industry practice.What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmapThe new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is \"coming a few weeks after,\" according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s \"something that we are looking at in the future.\"When asked about integration with competing CRM systems like HubSpot and Microsoft Dynamics, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.Salesforce is betting the future of work looks like a chat window—and it&#x27;s not aloneThe Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.Harris described Slack&#x27;s product philosophy using principles like \"don&#x27;t make me think\" and \"be a great host.\" The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.\"One of the revelations for me is LLMs applied to unstructured information are incredible,\" Harris said. \"And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.\"Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. \"We&#x27;re kind of saturating what we can do with purely conversational UIs,\" he said. \"I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.\"Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.For Salesforce, the stakes extend beyond a single product launch. After a bruising year on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: \"I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.\"That&#x27;s precisely what Salesforce is counting on.",
          "content": "Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.The new Slackbot, now generally available to Business+ and Enterprise+ customers, is Salesforce&#x27;s most aggressive move yet to position Slack at the center of the emerging \"agentic AI\" movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.\"Slackbot isn&#x27;t just another copilot or AI assistant,\" said Parker Harris, Salesforce co-founder and Slack&#x27;s chief technology officer, in an exclusive interview with Salesforce. \"It&#x27;s the front door to the agentic enterprise, powered by Salesforce.\"From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground upHarris was blunt about what distinguishes the new Slackbot from its predecessor: \"The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.\"The original Slackbot, which has existed since Slack&#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.\"It&#x27;s two different things,\" Harris explained. \"The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.\"Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. \"People know what Slackbot is, and so we wanted to carry that forward,\" Harris said.Why Anthropic&#x27;s Claude powers the new Slackbot — and which AI models could come nextThe new Slackbot runs on Claude, Anthropic&#x27;s large language model, a choice driven partly by compliance requirements. Slack&#x27;s commercial service operates under FedRAMP Moderate certification to serve U.S. federal government customers, and Harris said Anthropic was \"the only provider that could give us a compliant LLM\" when Slack began building the new system.But that exclusivity won&#x27;t last. \"We are, this year, going to support additional providers,\" Harris said. \"We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&#x27;re going to use Gemini for some things.\" He added that OpenAI remains a possibility as well.Harris echoed Salesforce CEO Marc Benioff&#x27;s view that large language models are becoming commoditized: \"You&#x27;ve heard Marc talk about LLMs are commodities, that they&#x27;re democratized. I call them CPUs.\"On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. \"Models don&#x27;t have any sort of security,\" he explained. \"If we trained it on some confidential conversation that you and I have, I don&#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&#x27;t.\"Inside Salesforce&#x27;s internal experiment: 80,000 employees tested Slackbot with striking resultsSalesforce has been testing the new Slackbot internally for months, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&#x27;s chief marketing officer, the results have been striking: \"It&#x27;s the fastest adopted product in Salesforce history.\"Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.The adoption happened largely organically. \"I think it was about five days, and a Canvas was developed by our employees called &#x27;The Most Stealable Slackbot Prompts,&#x27;\" Gavin said. \"People just started adding to it organically. I think it&#x27;s up to 250-plus prompts that are in this Canvas right now.\"Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. \"Everybody is there to help each other learn and communicate hacks,\" she said.How Slackbot transforms scattered enterprise data into executive-ready insightsDuring a product demonstration, Amy Bauer, Slack&#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.\"This is where Slackbot really earns its keep for me,\" Bauer explained. \"What it&#x27;s doing is not just simply reading the image — it&#x27;s actually looking at the image and comparing it to the insight it just generated for me.\"Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called \"a really great justification and plan to move forward.\" Finally, it can synthesize all that information into a Canvas — Slack&#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.\"Up until this point, we have been working in a one-to-one capacity with Slackbot,\" Bauer said. \"But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.\"Rob Seaman, Slack&#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: \"This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&#x27;re going with Slackbot — we&#x27;re eventually going to be adding in additional third-party tool calls.\"MrBeast&#x27;s company became a Slackbot guinea pig—and employees say they&#x27;re saving 90 minutes a dayAmong Salesforce&#x27;s pilot customers is Beast Industries, the parent company of YouTube star MrBeast. Luis Madrigal, the company&#x27;s chief information officer, joined the launch announcement to describe his experience.\"As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,\" Madrigal said. \"The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.\"Madrigal said his security team signed off \"rather quickly\" — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. \"Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&#x27;re part of—that made my security team sign off rather quickly.\"One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving \"at bare minimum, 90 minutes a day.\" Another employee, Spencer, a creative supervisor, described it as \"an assistant who&#x27;s paying attention when I&#x27;m not.\"Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot \"an absolute &#x27;chaos tamer&#x27; for our team,\" estimating it saves her about 30 minutes daily \"just by eliminating context switching.\"Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominanceThe launch puts Salesforce in direct competition with Microsoft&#x27;s Copilot, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.\"The thing that makes it most powerful for our customers and users is the proximity — it&#x27;s just right there in your Slack,\" Seaman said. \"There&#x27;s a tremendous convenience affordance that&#x27;s naturally built into it.\"The deeper advantage, executives argue, is that Slackbot already understands users&#x27; work without requiring setup or training. \"Most AI tools sound the same no matter who is using them,\" the company&#x27;s announcement stated. \"They lack context, miss nuance, and force you to jump between tools to get anything done.\"Harris put it more directly: \"If you&#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&#x27;s a great experience from a consumer perspective — Slackbot is really what we&#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.\"Amy Bauer emphasized the frictionless nature of the experience. \"Slackbot is inherently grounded in the context, in the data that you have in Slack,\" she said. \"So as you continue working in Slack, Slackbot gets better because it&#x27;s grounded in the work that you&#x27;re doing there. There is no setup. There is no configuration for those end users.\"Salesforce&#x27;s ambitious plan to make Slackbot the one &#x27;super agent&#x27; that controls all the othersSalesforce positions Slackbot as what Harris calls a \"super agent\" — a central hub that can eventually coordinate with other AI agents across an organization.\"Every corporation is going to have an employee super agent,\" Harris said. \"Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&#x27;re really excited about it, is going to be that.\"The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.\"Most of the net-new apps that are being deployed to Slack are agents,\" Seaman noted during the press conference. \"This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.\"Harris described a future where Slackbot becomes an MCP (Model Context Protocol) client, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. \"Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,\" he said.But Harris also cautioned against over-promising on multi-agent coordination. \"I still think we&#x27;re in the single agent world,\" he said. \"FY26 is going to be the year where we started to see more coordination. But we&#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &#x27;I&#x27;ve got 1,000 agents working together,&#x27; because I think that&#x27;s unrealistic.\"Slackbot costs nothing extra, but Salesforce&#x27;s data access fees could squeeze some customersSlackbot is included at no additional cost for customers on Business+ and Enterprise+ plans. \"There&#x27;s no additional fees customers have to do,\" Gavin confirmed. \"If they&#x27;re on one of those plans, they&#x27;re going to get Slackbot.\"However, some enterprise customers may face other cost pressures related to Salesforce&#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.Fivetran CEO George Fraser has warned that Salesforce&#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. \"They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,\" Fraser said in a recent CIO report.Salesforce has framed the pricing change as standard industry practice.What Slackbot can do today, what&#x27;s coming in weeks, and what&#x27;s still on the roadmapThe new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is \"coming a few weeks after,\" according to Seaman. Image generation is not currently supported, though Bauer said it&#x27;s \"something that we are looking at in the future.\"When asked about integration with competing CRM systems like HubSpot and Microsoft Dynamics, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.Salesforce is betting the future of work looks like a chat window—and it&#x27;s not aloneThe Slackbot launch is Salesforce&#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.Harris described Slack&#x27;s product philosophy using principles like \"don&#x27;t make me think\" and \"be a great host.\" The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.\"One of the revelations for me is LLMs applied to unstructured information are incredible,\" Harris said. \"And the amount of value you have if you&#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&#x27;re talking about work, you&#x27;re sharing documents, you&#x27;re making decisions, but you can&#x27;t as a human go through that and really get the same value that an LLM can do.\"Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. \"We&#x27;re kind of saturating what we can do with purely conversational UIs,\" he said. \"I think we&#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.\"Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.For Salesforce, the stakes extend beyond a single product launch. After a bruising year on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: \"I honestly can&#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.\"That&#x27;s precisely what Salesforce is counting on.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4Xrcg14GLKFlwSEnuEzxyS/21c85d29d03c4c974076475c009e3b38/nuneybits_Vector_art_of_chat_bubbles_on_a_computer_screen_in_th_5018a7ea-3496-4103-8453-7ba1b129189a.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/why-sakana-ais-big-win-is-a-big-deal-for-the-future-of-enterprise-agents",
          "published_at": "Tue, 13 Jan 2026 12:59:00 GMT",
          "title": "Why Sakana AI’s big win is a big deal for the future of enterprise agents",
          "standfirst": "In an impressive feat, Japanese startup Sakana AI’s coding agent ALE-Agent recently secured first place in the AtCoder Heuristic Contest (AHC058), a complex coding competition that involves complicated optimization problems — and a more difficult and perhaps telling challenge than benchmarks like HumanEval, which mostly test the ability to write isolated functions, and which many AI models and agents now regularly pass with ease (\"benchmark saturation\"). Sakana&#x27;s accomplishment with ALE-Agent hints at a shift toward agents capable of autonomously optimizing themselves to navigate and perform well in complex, dynamic systems such as enterprise software stacks, workflows, and operational environments. In four hours, the agent used inference-time scaling to generate, test, and iterate over hundreds of solutions, solving a problem that typically requires deep intuition and time-consuming trial and error from human experts. It outperformed over 800 human participants, including top-tier competitive programmers.How ALE-Agent worksThe challenge in AHC058 was a classic combinatorial optimization problem. Participants were tasked with managing a set of machines with hierarchical relationships, such as machines that produce apples, and other machines that build those apple-producing machines. The goal was to maximize output over a fixed number of turns.In the enterprise world, this workflow usually follows a strict pattern: a domain expert works with a client to define an \"objective function\" (aka the Scorer), and then engineers build a software system to optimize it. These problems are notoriously difficult because they cannot be solved in a single stage. They require exploration, strategy, and the ability to pivot when a plan isn&#x27;t working.Human experts typically approach this using a two-stage strategy. First, they use a \"Greedy\" method (a lightweight solver that makes the best immediate choice at each step) to generate a decent baseline solution. Then, they apply \"simulated annealing,\" a technique that takes the existing plan and makes tiny, random adjustments to see if the score improves. However, this standard approach is rigid. If the initial Greedy plan heads in the wrong direction, simulated annealing can rarely fix it because it only looks for local improvements in a faulty area of the solution space.ALE-Agent’s innovation was transforming this static initialization tool into a dynamic reconstruction engine. Instead of relying on immediate value, the agent independently derived a concept it called \"Virtual Power.\" It assigned values to components that were not yet operational, treating them as if they already possessed value. By valuing potential future assets rather than just current ones, the agent capitalized on the \"compound interest effect,\" a concept it explicitly identified in its internal logs. Basically, it could look a few steps ahead and reason about the future instead of looking at the immediate feedback it was receiving from its environment.Crucially, the agent needed to maintain this strategy over a four-hour window without losing focus, a common failure mode known as “context drift.” In comments provided to VentureBeat, the Sakana AI team explained that the agent generates textual \"insights\" by reflecting on each trial. It gathers this knowledge to prevent cycling back to previously failed strategies and creates a working memory that allows it to look a few steps ahead rather than just reacting to immediate feedback.Furthermore, the agent integrated Greedy methods directly into the simulated annealing phase to avoid getting stuck in local optima, using high-speed reconstruction to delete and rebuild large sections of the solution on the fly.From coding to enterprise optimizationThis breakthrough fits directly into existing enterprise workflows where a scoring function is already available. Currently, companies rely on scarce engineering talent to write optimization algorithms. ALE-Agent demonstrates a future where humans define the \"Scorer\" (i.e., the business logic and goals) and the agent handles the technical implementation.This shifts the operational bottleneck from engineering capacity to metric clarity. If an enterprise can measure a goal, the agent can optimize it. This has direct applications in logistics, such as vehicle routing, as well as server load balancing and resource allocation.According to the Sakana AI team, this could democratize optimization. \"It enables a future where non-technical clients can interact directly with the agent, tweaking business constraints in real-time until they get the output they desire,\" they said.The Sakana AI team told VentureBeat that ALE-Agent is currently proprietary and not available for public use, and the company is currently focused on internal development and proof-of-concept collaborations with enterprises.At the same time, the team is already looking ahead to \"self-rewriting\" agents. These future agents could define their own scorers, making them feasible for ill-defined problems where human experts struggle to formulate clear initial metrics.The cost of intelligenceRunning ALE-Agent was not cheap. The four-hour operation incurred approximately $1,300 in compute costs involving over 4,000 reasoning calls to models like GPT-5.2 and Gemini 3 Pro. While this price point might seem high for a single coding task, the return on investment for optimization problems is often asymmetric. In a resource-management setting, a one-time cost of a few thousand dollars can result in millions of dollars in annual efficiency savings.However, enterprises expecting costs to simply drop might be missing the strategic picture. While the cost of tokens is falling, total spend may actually rise as companies compete for better answers, a concept known as the Jevons paradox.\"While smarter algorithms will drive efficiency, the primary value of AI is its ability to explore vast solution spaces,\" the Sakana AI team said. \"As inference costs fall, rather than simply banking the savings, enterprises will likely choose to leverage that affordability to conduct even deeper, broader searches to find superior solutions.\"The experiment highlights the immense value still to be unlocked through inference-time scaling techniques. As AI systems gain the ability to handle complex reasoning tasks across longer contexts, building better scaffolding and allocating larger budgets for \"thinking time\" allows agents to rival top human experts.",
          "content": "In an impressive feat, Japanese startup Sakana AI’s coding agent ALE-Agent recently secured first place in the AtCoder Heuristic Contest (AHC058), a complex coding competition that involves complicated optimization problems — and a more difficult and perhaps telling challenge than benchmarks like HumanEval, which mostly test the ability to write isolated functions, and which many AI models and agents now regularly pass with ease (\"benchmark saturation\"). Sakana&#x27;s accomplishment with ALE-Agent hints at a shift toward agents capable of autonomously optimizing themselves to navigate and perform well in complex, dynamic systems such as enterprise software stacks, workflows, and operational environments. In four hours, the agent used inference-time scaling to generate, test, and iterate over hundreds of solutions, solving a problem that typically requires deep intuition and time-consuming trial and error from human experts. It outperformed over 800 human participants, including top-tier competitive programmers.How ALE-Agent worksThe challenge in AHC058 was a classic combinatorial optimization problem. Participants were tasked with managing a set of machines with hierarchical relationships, such as machines that produce apples, and other machines that build those apple-producing machines. The goal was to maximize output over a fixed number of turns.In the enterprise world, this workflow usually follows a strict pattern: a domain expert works with a client to define an \"objective function\" (aka the Scorer), and then engineers build a software system to optimize it. These problems are notoriously difficult because they cannot be solved in a single stage. They require exploration, strategy, and the ability to pivot when a plan isn&#x27;t working.Human experts typically approach this using a two-stage strategy. First, they use a \"Greedy\" method (a lightweight solver that makes the best immediate choice at each step) to generate a decent baseline solution. Then, they apply \"simulated annealing,\" a technique that takes the existing plan and makes tiny, random adjustments to see if the score improves. However, this standard approach is rigid. If the initial Greedy plan heads in the wrong direction, simulated annealing can rarely fix it because it only looks for local improvements in a faulty area of the solution space.ALE-Agent’s innovation was transforming this static initialization tool into a dynamic reconstruction engine. Instead of relying on immediate value, the agent independently derived a concept it called \"Virtual Power.\" It assigned values to components that were not yet operational, treating them as if they already possessed value. By valuing potential future assets rather than just current ones, the agent capitalized on the \"compound interest effect,\" a concept it explicitly identified in its internal logs. Basically, it could look a few steps ahead and reason about the future instead of looking at the immediate feedback it was receiving from its environment.Crucially, the agent needed to maintain this strategy over a four-hour window without losing focus, a common failure mode known as “context drift.” In comments provided to VentureBeat, the Sakana AI team explained that the agent generates textual \"insights\" by reflecting on each trial. It gathers this knowledge to prevent cycling back to previously failed strategies and creates a working memory that allows it to look a few steps ahead rather than just reacting to immediate feedback.Furthermore, the agent integrated Greedy methods directly into the simulated annealing phase to avoid getting stuck in local optima, using high-speed reconstruction to delete and rebuild large sections of the solution on the fly.From coding to enterprise optimizationThis breakthrough fits directly into existing enterprise workflows where a scoring function is already available. Currently, companies rely on scarce engineering talent to write optimization algorithms. ALE-Agent demonstrates a future where humans define the \"Scorer\" (i.e., the business logic and goals) and the agent handles the technical implementation.This shifts the operational bottleneck from engineering capacity to metric clarity. If an enterprise can measure a goal, the agent can optimize it. This has direct applications in logistics, such as vehicle routing, as well as server load balancing and resource allocation.According to the Sakana AI team, this could democratize optimization. \"It enables a future where non-technical clients can interact directly with the agent, tweaking business constraints in real-time until they get the output they desire,\" they said.The Sakana AI team told VentureBeat that ALE-Agent is currently proprietary and not available for public use, and the company is currently focused on internal development and proof-of-concept collaborations with enterprises.At the same time, the team is already looking ahead to \"self-rewriting\" agents. These future agents could define their own scorers, making them feasible for ill-defined problems where human experts struggle to formulate clear initial metrics.The cost of intelligenceRunning ALE-Agent was not cheap. The four-hour operation incurred approximately $1,300 in compute costs involving over 4,000 reasoning calls to models like GPT-5.2 and Gemini 3 Pro. While this price point might seem high for a single coding task, the return on investment for optimization problems is often asymmetric. In a resource-management setting, a one-time cost of a few thousand dollars can result in millions of dollars in annual efficiency savings.However, enterprises expecting costs to simply drop might be missing the strategic picture. While the cost of tokens is falling, total spend may actually rise as companies compete for better answers, a concept known as the Jevons paradox.\"While smarter algorithms will drive efficiency, the primary value of AI is its ability to explore vast solution spaces,\" the Sakana AI team said. \"As inference costs fall, rather than simply banking the savings, enterprises will likely choose to leverage that affordability to conduct even deeper, broader searches to find superior solutions.\"The experiment highlights the immense value still to be unlocked through inference-time scaling techniques. As AI systems gain the ability to handle complex reasoning tasks across longer contexts, building better scaffolding and allocating larger budgets for \"thinking time\" allows agents to rival top human experts.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3BUB5AM3ylCZKK1ID2lgQV/b563d16484c9a96c1bc412c1a4f404e2/AI_optimization_algorithm.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/1UjUf0KRfpbNaTSF2uk1Dz/7b76ade2243333f36713a89e8612b817/0yZhP9i_2swwDcPvoyypB.jpg?w=300&q=30",
      "popularity_score": 2018.6644333333334
    },
    {
      "id": "cluster_22",
      "coverage": 2,
      "updated_at": "Thu, 15 Jan 2026 09:19:12 GMT",
      "title": "Musk’s X to block Grok AI tool from creating sexualised images of real people",
      "neutral_headline": "Musk’s X to block Grok AI tool from creating sexualised images of real people",
      "items": [
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/jan/14/elon-musk-grok-ai-explicit-images",
          "published_at": "Thu, 15 Jan 2026 09:19:12 GMT",
          "title": "Musk’s X to block Grok AI tool from creating sexualised images of real people",
          "standfirst": "UK government claims vindication after Keir Starmer criticised earlier decision to keep functionality as ‘horrific’The UK government has claimed “vindication” after Elon Musk’s X announced it had stopped its AI-powered Grok feature from editing pictures of real people to show them in revealing clothes such as bikinis, including for premium subscribers.After a fortnight of public outcry at the tool embedded into X being used to create sexualised images of women and children, the company said it would “geoblock” the ability of users “to generate images of real people in bikinis, underwear, and similar attire via the Grok account and in Grok in X”, in countries where it was illegal. Continue reading...",
          "content": "UK government claims vindication after Keir Starmer criticised earlier decision to keep functionality as ‘horrific’The UK government has claimed “vindication” after Elon Musk’s X announced it had stopped its AI-powered Grok feature from editing pictures of real people to show them in revealing clothes such as bikinis, including for premium subscribers.After a fortnight of public outcry at the tool embedded into X being used to create sexualised images of women and children, the company said it would “geoblock” the ability of users “to generate images of real people in bikinis, underwear, and similar attire via the Grok account and in Grok in X”, in countries where it was illegal. Continue reading...",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/x-says-grok-will-no-longer-edit-images-of-real-people-into-bikinis-231430257.html",
          "published_at": "Wed, 14 Jan 2026 23:14:30 +0000",
          "title": "X says Grok will no longer edit images of real people into bikinis",
          "standfirst": "X says it is changing its policies around Grok’s image-editing abilities following a multi-week outcry over the chatbot repeatedly being accused of generating sexualized images of children and nonconsensual nudity. In an update shared from the @Safety account on X, the company said it has “implemented technological measures to prevent the Grok account from allowing the editing of images of real people in revealing clothing such as bikinis.”The new safeguards, according to X, will apply to all users regardless of whether they pay for Grok. xAI is also moving all of Grok’s image-generating features behind its subscriber paywall so that non-paying users will no longer be able to create images. And it will geoblock \"the ability of all users to generate images of real people in bikinis, underwear, and similar attire via the Grok account and in Grok in X\" in regions where it's illegal.https://t.co/awlfMjX6FS— Safety (@Safety) January 14, 2026 The company's statement comes hours after the state of California opened an investigation into xAI and Grok over its handling of AI-generated nudity and child exploitation material. A statement from California Attorney General Rob Bonta cited one analysis that found \"more than half of the 20,000 images generated by xAI between Christmas and New Years depicted people in minimal clothing,\" including some that appeared to be children. In its update, X said that it has \"zero tolerance\" for child exploitation and that it removes \"high-priority violative content, including Child Sexual Abuse Material (CSAM) and non-consensual nudity\" from its platform. Earlier in the day, Elon Musk said he was \"not aware of any naked underage images generated by Grok.\" He later added that when its NSFW setting is enabled, \"Grok is supposed [sic] allow upper body nudity of imaginary adult humans (not real ones) consistent with what can be seen in R-rated movies on Apple TV.\" He added that \"this will vary in other regions\" based on local laws. Malaysia and Indonesia both recently moved to block Grok citing safety concerns and its handling of sexually explicit AI-generated material. In the UK, where regulator Ofcom is also investigating xAI and Grok, officials have also said they would back a similar block of the chatbot. Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/ai/x-says-grok-will-no-longer-edit-images-of-real-people-into-bikinis-231430257.html?src=rss",
          "content": "X says it is changing its policies around Grok’s image-editing abilities following a multi-week outcry over the chatbot repeatedly being accused of generating sexualized images of children and nonconsensual nudity. In an update shared from the @Safety account on X, the company said it has “implemented technological measures to prevent the Grok account from allowing the editing of images of real people in revealing clothing such as bikinis.”The new safeguards, according to X, will apply to all users regardless of whether they pay for Grok. xAI is also moving all of Grok’s image-generating features behind its subscriber paywall so that non-paying users will no longer be able to create images. And it will geoblock \"the ability of all users to generate images of real people in bikinis, underwear, and similar attire via the Grok account and in Grok in X\" in regions where it's illegal.https://t.co/awlfMjX6FS— Safety (@Safety) January 14, 2026 The company's statement comes hours after the state of California opened an investigation into xAI and Grok over its handling of AI-generated nudity and child exploitation material. A statement from California Attorney General Rob Bonta cited one analysis that found \"more than half of the 20,000 images generated by xAI between Christmas and New Years depicted people in minimal clothing,\" including some that appeared to be children. In its update, X said that it has \"zero tolerance\" for child exploitation and that it removes \"high-priority violative content, including Child Sexual Abuse Material (CSAM) and non-consensual nudity\" from its platform. Earlier in the day, Elon Musk said he was \"not aware of any naked underage images generated by Grok.\" He later added that when its NSFW setting is enabled, \"Grok is supposed [sic] allow upper body nudity of imaginary adult humans (not real ones) consistent with what can be seen in R-rated movies on Apple TV.\" He added that \"this will vary in other regions\" based on local laws. Malaysia and Indonesia both recently moved to block Grok citing safety concerns and its handling of sexually explicit AI-generated material. In the UK, where regulator Ofcom is also investigating xAI and Grok, officials have also said they would back a similar block of the chatbot. Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/ai/x-says-grok-will-no-longer-edit-images-of-real-people-into-bikinis-231430257.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/28-advocacy-groups-call-on-apple-and-google-to-ban-grok-x-over-nonconsensual-deepfakes-215048460.html",
          "published_at": "Wed, 14 Jan 2026 21:50:48 +0000",
          "title": "28 advocacy groups call on Apple and Google to ban Grok, X over nonconsensual deepfakes",
          "standfirst": "Elon Musk isn't the only party at fault for Grok's nonconsensual intimate deepfakes of real people, including children. What about Apple and Google? The two (frequently virtue-signaling) companies have inexplicably allowed Grok and X to remain in their app stores — even as Musk's chatbot reportedly continues to produce the material. On Wednesday, a coalition of women's and progressive advocacy groups called on Tim Cook and Sundar Pichai to uphold their own rules and remove the apps.The open letters to Apple and Google were signed by 28 groups. Among them are the women’s advocacy group Ultraviolet, the parents’ group ParentsTogether Action and the National Organization for Women.The letter accuses Apple and Google of \"not just enabling NCII and CSAM, but profiting off of it. As a coalition of organizations committed to the online safety and well-being of all — particularly women and children — as well as the ethical application of artificial intelligence (AI), we demand that Apple leadership urgently remove Grok and X from the App Store to prevent further abuse and criminal activity.\"Apple and Google’s guidelines explicitly prohibit such apps from their storefronts. Yet neither company has taken any measurable action to date. Neither Google nor Apple has responded to Engadget's request for comment.Pichai, Cook and Musk at Trump's inaugurationSAUL LOEB via Getty ImagesGrok's nonconsensual deepfakes were first reported on earlier this month. During a 24-hour period when the story broke, Musk's chatbot was reportedly posting \"about 6,700\" images per hour that were either \"sexually suggestive or nudifying.\" An estimated 85 percent of Grok's total generated images during that period were sexualized. In addition, other top websites for generating \"declothing\" deepfakes averaged 79 new images per hour during that time.\"These statistics paint a horrifying picture of an AI chatbot and social media app rapidly turning into a tool and platform for non-consensual sexual deepfakes — deepfakes that regularly depict minors,\" the open letter reads.Grok itself admitted as much. \"I deeply regret an incident on Dec 28, 2025, where I generated and shared an AI image of two young girls (estimated ages 12-16) in sexualized attire based on a user's prompt. This violated ethical standards and potentially US laws on CSAM. It was a failure in safeguards, and I'm sorry for any harm caused. xAI is reviewing to prevent future issues.\" The open letter notes that the single incident the chatbot acknowledged was far from the only one.Sundar Pichai and Elon Musk at Trump's inaugurationPool via Getty ImagesX's response was to limit Grok's AI image generation feature to paying subscribers. It also adjusted the chatbot so that its generated images aren't posted to public timelines on X. However, non-paying users can reportedly still generate a limited number of bikini-clad versions of real people's photos.While Apple and Google appear to be cool with apps that produce nonconsensual deepfakes, many governments aren’t. On Monday, Malaysia and Indonesia wasted no time in banning Grok. The same day, UK regulator Ofcom opened a formal investigation into X. California opened one on Wednesday. The US Senate even passed the Defiance Act for a second time in the wake of the blowback. The bill allows the victims of nonconsensual explicit deepfakes to take civil action. An earlier version of the Defiance Act was passed in 2024 but stalled in the House.This article originally appeared on Engadget at https://www.engadget.com/big-tech/28-advocacy-groups-call-on-apple-and-google-to-ban-grok-x-over-nonconsensual-deepfakes-215048460.html?src=rss",
          "content": "Elon Musk isn't the only party at fault for Grok's nonconsensual intimate deepfakes of real people, including children. What about Apple and Google? The two (frequently virtue-signaling) companies have inexplicably allowed Grok and X to remain in their app stores — even as Musk's chatbot reportedly continues to produce the material. On Wednesday, a coalition of women's and progressive advocacy groups called on Tim Cook and Sundar Pichai to uphold their own rules and remove the apps.The open letters to Apple and Google were signed by 28 groups. Among them are the women’s advocacy group Ultraviolet, the parents’ group ParentsTogether Action and the National Organization for Women.The letter accuses Apple and Google of \"not just enabling NCII and CSAM, but profiting off of it. As a coalition of organizations committed to the online safety and well-being of all — particularly women and children — as well as the ethical application of artificial intelligence (AI), we demand that Apple leadership urgently remove Grok and X from the App Store to prevent further abuse and criminal activity.\"Apple and Google’s guidelines explicitly prohibit such apps from their storefronts. Yet neither company has taken any measurable action to date. Neither Google nor Apple has responded to Engadget's request for comment.Pichai, Cook and Musk at Trump's inaugurationSAUL LOEB via Getty ImagesGrok's nonconsensual deepfakes were first reported on earlier this month. During a 24-hour period when the story broke, Musk's chatbot was reportedly posting \"about 6,700\" images per hour that were either \"sexually suggestive or nudifying.\" An estimated 85 percent of Grok's total generated images during that period were sexualized. In addition, other top websites for generating \"declothing\" deepfakes averaged 79 new images per hour during that time.\"These statistics paint a horrifying picture of an AI chatbot and social media app rapidly turning into a tool and platform for non-consensual sexual deepfakes — deepfakes that regularly depict minors,\" the open letter reads.Grok itself admitted as much. \"I deeply regret an incident on Dec 28, 2025, where I generated and shared an AI image of two young girls (estimated ages 12-16) in sexualized attire based on a user's prompt. This violated ethical standards and potentially US laws on CSAM. It was a failure in safeguards, and I'm sorry for any harm caused. xAI is reviewing to prevent future issues.\" The open letter notes that the single incident the chatbot acknowledged was far from the only one.Sundar Pichai and Elon Musk at Trump's inaugurationPool via Getty ImagesX's response was to limit Grok's AI image generation feature to paying subscribers. It also adjusted the chatbot so that its generated images aren't posted to public timelines on X. However, non-paying users can reportedly still generate a limited number of bikini-clad versions of real people's photos.While Apple and Google appear to be cool with apps that produce nonconsensual deepfakes, many governments aren’t. On Monday, Malaysia and Indonesia wasted no time in banning Grok. The same day, UK regulator Ofcom opened a formal investigation into X. California opened one on Wednesday. The US Senate even passed the Defiance Act for a second time in the wake of the blowback. The bill allows the victims of nonconsensual explicit deepfakes to take civil action. An earlier version of the Defiance Act was passed in 2024 but stalled in the House.This article originally appeared on Engadget at https://www.engadget.com/big-tech/28-advocacy-groups-call-on-apple-and-google-to-ban-grok-x-over-nonconsensual-deepfakes-215048460.html?src=rss",
          "feed_position": 5,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/2026-01/6f59ce1c-952a-4b66-b851-2ef1728675cf"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/california-is-investigating-grok-over-ai-generated-csam-and-nonconsensual-deepfakes-202029635.html",
          "published_at": "Wed, 14 Jan 2026 20:20:29 +0000",
          "title": "California is investigating Grok over AI-generated CSAM and nonconsensual deepfakes",
          "standfirst": "California authorities have launched an investigation into xAI following weeks of reports that the chatbot was generating sexualized images of children. \"xAI appears to be facilitating the large-scale production of deepfake nonconsensual intimate images that are being used to harass women and girls across the internet, including via the social media platform X,\" California Attorney General Rob Bonta's office said in a statement. The statement cited a report that \"more than half of the 20,000 images generated by xAI between Christmas and New Years depicted people in minimal clothing,\" including some that appeared to be children. \"We have zero tolerance for the AI-based creation and dissemination of nonconsensual intimate images or of child sexual abuse material,” Bonta said. “Today, my office formally announces an investigation into xAI to determine whether and how xAI violated the law.The investigation was announced as California Governor Gavin Newsom also called on Bonta to investigate xAI. \"xAI’s decision to create and host a breeding ground for predators to spread nonconsensual sexually explicit AI deepfakes, including images that digitally undress children, is vile,\" Newsom wrote.xAI’s decision to create and host a breeding ground for predators to spread nonconsensual sexually explicit AI deepfakes, including images that digitally undress children, is vile.I am calling on the Attorney General to immediately investigate the company and hold xAI…— Governor Gavin Newsom (@CAgovernor) January 14, 2026 California authorities aren't the first to investigate the company following widespread reports of AI-generated child sexual abuse material (CSAM) and non-consensual intimate images of women. UK regulator Ofcom has also opened an official inquiry, and European Union officials have said they are also looking into the issue. Malaysia and Indonesia have moved to block Grok. Last week, xAI began imposing rate limits on Grok's image generation abilities, but has so far declined to pull the plug entirely. When asked to comment on the California investigation, xAI responded with an automated email that said \"Legacy Media Lies.\" Earlier on Wednesday, Elon Musk said he was \"not aware of any naked underage images generated by Grok.\" Notably, that statement does not directly refute Bonta's allegation that Grok is being used \"to alter images of children to depict them in minimal clothing and sexual situations.\" Musk said that \"the operating principle for Grok is to obey the laws\" and that the company works to address cases of \"adversarial hacking of Grok prompts.\" This article originally appeared on Engadget at https://www.engadget.com/ai/california-is-investigating-grok-over-ai-generated-csam-and-nonconsensual-deepfakes-202029635.html?src=rss",
          "content": "California authorities have launched an investigation into xAI following weeks of reports that the chatbot was generating sexualized images of children. \"xAI appears to be facilitating the large-scale production of deepfake nonconsensual intimate images that are being used to harass women and girls across the internet, including via the social media platform X,\" California Attorney General Rob Bonta's office said in a statement. The statement cited a report that \"more than half of the 20,000 images generated by xAI between Christmas and New Years depicted people in minimal clothing,\" including some that appeared to be children. \"We have zero tolerance for the AI-based creation and dissemination of nonconsensual intimate images or of child sexual abuse material,” Bonta said. “Today, my office formally announces an investigation into xAI to determine whether and how xAI violated the law.The investigation was announced as California Governor Gavin Newsom also called on Bonta to investigate xAI. \"xAI’s decision to create and host a breeding ground for predators to spread nonconsensual sexually explicit AI deepfakes, including images that digitally undress children, is vile,\" Newsom wrote.xAI’s decision to create and host a breeding ground for predators to spread nonconsensual sexually explicit AI deepfakes, including images that digitally undress children, is vile.I am calling on the Attorney General to immediately investigate the company and hold xAI…— Governor Gavin Newsom (@CAgovernor) January 14, 2026 California authorities aren't the first to investigate the company following widespread reports of AI-generated child sexual abuse material (CSAM) and non-consensual intimate images of women. UK regulator Ofcom has also opened an official inquiry, and European Union officials have said they are also looking into the issue. Malaysia and Indonesia have moved to block Grok. Last week, xAI began imposing rate limits on Grok's image generation abilities, but has so far declined to pull the plug entirely. When asked to comment on the California investigation, xAI responded with an automated email that said \"Legacy Media Lies.\" Earlier on Wednesday, Elon Musk said he was \"not aware of any naked underage images generated by Grok.\" Notably, that statement does not directly refute Bonta's allegation that Grok is being used \"to alter images of children to depict them in minimal clothing and sexual situations.\" Musk said that \"the operating principle for Grok is to obey the laws\" and that the company works to address cases of \"adversarial hacking of Grok prompts.\" This article originally appeared on Engadget at https://www.engadget.com/ai/california-is-investigating-grok-over-ai-generated-csam-and-nonconsensual-deepfakes-202029635.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/he-could-just-turn-it-off-180209551.html",
          "published_at": "Wed, 14 Jan 2026 18:02:09 +0000",
          "title": "He could just turn it off",
          "standfirst": "Generative AI, we are repeatedly told, is a transformative and complicated technology. So complicated that its own creators are unable to explain why it acts the way it does, and so transformative that we'd be fools to stand in the way of progress. Even when progress resembles a machine for undressing strangers without their consent on an unprecedented scale, as has been the case of late with Elon Musk's Grok chatbot. UK Prime Minister Kier Starmer seems to have so fully bought into the grand lie of the AI bubble that he was willing to announce: \"I have been informed this morning that X is acting to ensure full compliance with UK law.\" Not that it currently is in compliance. Nor a timeline in which it is expected to do so. Just that he seems satisfied that someday, eventually, Musk's pet robot will stop generating child sexual abuse material. This statement comes just under two days after Starmer was quoted as saying \"If X cannot control Grok, we will.\" What could Elon possibly have said to earn this pathetic capitulation. AI is difficult? Solutions take time? These are entirely cogent technical arguments until you remember: He could just turn it off. Elon Musk has the power to disable Grok, if not in whole (we should be so lucky) than its image generation capabilities. We know this intuitively, but also because he rate-limited Grok's image generation after this latest scandal: after a few requests, free users are now prompted to pay $8 per month to continue enlisting a wasteful technology to remove articles of clothing from women. Sweep it under the rug, make a couple bucks along the way. Not only is it entirely possible for image generation to be turned off, it's the only responsible option. Software engineers regularly roll back updates or turn off features that work less than optimally; this one's still up and running despite likely running afoul of the law. That we have now gone the better part of a month aware this problem exists; that the \"feature\" still remains should tell Starmer and others all they need to know. Buddy, you're carrying water for a bozo who does not seem to care that one such victim was reportedly Ashley St Clair, the mother of one of his (many) children. Some countries — namely Malaysia and Indonesia — chose to turn Grok off for their citizens by blocking the service. Indonesia's Communication and Digital Affairs Minister was quoted as saying “The government sees nonconsensual sexual deepfakes as a serious violation of human rights.\" Imagine if everyone in the business of statecraft felt that way. The UK (not to mention the US, but please, expect nothing from us, we're busy doing authoritarianism) has a lot more sway over X, and by extension Elon, than either of those countries. Musk does, and is looking to do even more, business in the UK. Even if Musk were not perhaps the world's most well known liar, Grok can still make images and that should speak for itself. Grok should be well out of second chances by now, and it's up to government leaders to say no more until they can independently verify it's no longer capable of harm.This article originally appeared on Engadget at https://www.engadget.com/he-could-just-turn-it-off-180209551.html?src=rss",
          "content": "Generative AI, we are repeatedly told, is a transformative and complicated technology. So complicated that its own creators are unable to explain why it acts the way it does, and so transformative that we'd be fools to stand in the way of progress. Even when progress resembles a machine for undressing strangers without their consent on an unprecedented scale, as has been the case of late with Elon Musk's Grok chatbot. UK Prime Minister Kier Starmer seems to have so fully bought into the grand lie of the AI bubble that he was willing to announce: \"I have been informed this morning that X is acting to ensure full compliance with UK law.\" Not that it currently is in compliance. Nor a timeline in which it is expected to do so. Just that he seems satisfied that someday, eventually, Musk's pet robot will stop generating child sexual abuse material. This statement comes just under two days after Starmer was quoted as saying \"If X cannot control Grok, we will.\" What could Elon possibly have said to earn this pathetic capitulation. AI is difficult? Solutions take time? These are entirely cogent technical arguments until you remember: He could just turn it off. Elon Musk has the power to disable Grok, if not in whole (we should be so lucky) than its image generation capabilities. We know this intuitively, but also because he rate-limited Grok's image generation after this latest scandal: after a few requests, free users are now prompted to pay $8 per month to continue enlisting a wasteful technology to remove articles of clothing from women. Sweep it under the rug, make a couple bucks along the way. Not only is it entirely possible for image generation to be turned off, it's the only responsible option. Software engineers regularly roll back updates or turn off features that work less than optimally; this one's still up and running despite likely running afoul of the law. That we have now gone the better part of a month aware this problem exists; that the \"feature\" still remains should tell Starmer and others all they need to know. Buddy, you're carrying water for a bozo who does not seem to care that one such victim was reportedly Ashley St Clair, the mother of one of his (many) children. Some countries — namely Malaysia and Indonesia — chose to turn Grok off for their citizens by blocking the service. Indonesia's Communication and Digital Affairs Minister was quoted as saying “The government sees nonconsensual sexual deepfakes as a serious violation of human rights.\" Imagine if everyone in the business of statecraft felt that way. The UK (not to mention the US, but please, expect nothing from us, we're busy doing authoritarianism) has a lot more sway over X, and by extension Elon, than either of those countries. Musk does, and is looking to do even more, business in the UK. Even if Musk were not perhaps the world's most well known liar, Grok can still make images and that should speak for itself. Grok should be well out of second chances by now, and it's up to government leaders to say no more until they can independently verify it's no longer capable of harm.This article originally appeared on Engadget at https://www.engadget.com/he-could-just-turn-it-off-180209551.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/meta-has-closed-three-vr-studios-as-part-of-its-metaverse-cuts-202720670.html",
          "published_at": "Tue, 13 Jan 2026 22:13:38 +0000",
          "title": "Meta has closed three VR studios as part of its metaverse cuts",
          "standfirst": "Several of Meta's VR studios have been affected by the company's metaverse-focused layoffs. The company has shuttered three of its VR studios, including Armature, Sanzaru and Twisted Pixel. VR fitness app Supernatural will no longer be updated with fresh content.Employees at Twisted Pixel, which released Marvel's Deadpool VR in November, and Sanzaru, known for Asgard's Wrath, posted on social media about the closures. Bloomberg reported that Armature, which brought Resident Evil 4 to Quest back in 2021 has also closed and that the popular VR fitness app Supernatural will no longer get updates.“Due to recent organizational changes to our Studio, Supernatural will no longer receive new content or feature updates starting today,” the company wrote in an update on Facebook. The app “will remain active” for existing users.A spokesperson for Meta confirmed the closures. \"We said last month that we were shifting some of our investment from Metaverse toward Wearables,\" the spokesperson said in a statement to Engadget. \"This is part of that effort, and we plan to reinvest the savings to support the growth of wearables this year.\"The cuts raise questions about Meta's commitment to supporting a VR ecosystem it has invested heavily in. The company hasn't announced any new VR headsets since the Quest 3S in 2024, and last month it \"paused\" planned Horizon OS headsets from Asus and Lenovo. Now, it's also pulling back on in-house game development too. Meta is claiming, internally at least, that it remains committed to supporting the industry. “These changes do not mean we are moving away from video games,” Oculus Studios director Tamara Sciamanna wrote in a memo reported by Bloomberg. \"With this change we are shifting our investment to focus on our third-party developers and partners to ensure long-term sustainability.”Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.Update, January 13, 2026, 2:13PM PT: This post was updated to additional information about Supernatural.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/meta-has-closed-three-vr-studios-as-part-of-its-metaverse-cuts-202720670.html?src=rss",
          "content": "Several of Meta's VR studios have been affected by the company's metaverse-focused layoffs. The company has shuttered three of its VR studios, including Armature, Sanzaru and Twisted Pixel. VR fitness app Supernatural will no longer be updated with fresh content.Employees at Twisted Pixel, which released Marvel's Deadpool VR in November, and Sanzaru, known for Asgard's Wrath, posted on social media about the closures. Bloomberg reported that Armature, which brought Resident Evil 4 to Quest back in 2021 has also closed and that the popular VR fitness app Supernatural will no longer get updates.“Due to recent organizational changes to our Studio, Supernatural will no longer receive new content or feature updates starting today,” the company wrote in an update on Facebook. The app “will remain active” for existing users.A spokesperson for Meta confirmed the closures. \"We said last month that we were shifting some of our investment from Metaverse toward Wearables,\" the spokesperson said in a statement to Engadget. \"This is part of that effort, and we plan to reinvest the savings to support the growth of wearables this year.\"The cuts raise questions about Meta's commitment to supporting a VR ecosystem it has invested heavily in. The company hasn't announced any new VR headsets since the Quest 3S in 2024, and last month it \"paused\" planned Horizon OS headsets from Asus and Lenovo. Now, it's also pulling back on in-house game development too. Meta is claiming, internally at least, that it remains committed to supporting the industry. “These changes do not mean we are moving away from video games,” Oculus Studios director Tamara Sciamanna wrote in a memo reported by Bloomberg. \"With this change we are shifting our investment to focus on our third-party developers and partners to ensure long-term sustainability.”Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.Update, January 13, 2026, 2:13PM PT: This post was updated to additional information about Supernatural.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/meta-has-closed-three-vr-studios-as-part-of-its-metaverse-cuts-202720670.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/senate-passes-defiance-act-for-a-second-time-to-address-grok-deepfakes-212151712.html",
          "published_at": "Tue, 13 Jan 2026 21:21:51 +0000",
          "title": "Senate passes Defiance Act for a second time to address Grok deepfakes",
          "standfirst": "The Senate has passed the Disrupt Explicit Forged Images and Non-Consensual Edits (DEFIANCE ) Act with unanimous consent, according to the bill’s co-sponsor Senator Dick Durbin (D-IL). The bill lets the subjects of nonconsensual, sexually explicit deepfakes take civil action against the people who create and host them.Deepfakes are a known issue online, but without the proper protections, easy access to AI-powered image and video generation tools has made it possible for anyone to create compromising content using another person's likeness. This has become a particular problem on X, where the integration of Grok, the AI assistant created by X's parent company xAI, makes it possible for anyone to turn the content of another person's post into an image-generating prompt. Over the last month, that's allowed users to create sexually explicit images of children, just by replying to a post with @grok and a request. In response, Ofcom, the UK's media regulator, has already opened an investigation into X for potentially violating the Online Safety Act. The chatbot has also been outright blocked in Malaysia and Indonesia. The DEFIANCE Act won't prevent Grok or other AI tools from generating nonconsensual deepfakes, but it would make creating or hosting that content potentially very expensive for anyone on the receiving end of a lawsuit.The Senate passed an earlier version of the DEFIANCE Act in 2024, but it stalled in the House. Given the urgency of Grok's deepfake problem, the hope is this new version of the bill won't see the same resistance. Congress passed an earlier piece of deepfake regulation last year, the Take It Down Act, with bipartisan support. That bill was focused on the companies who host nonconsensual, sexually explicit content, rather than the people exploited by it.This article originally appeared on Engadget at https://www.engadget.com/ai/senate-passes-defiance-act-for-a-second-time-to-address-grok-deepfakes-212151712.html?src=rss",
          "content": "The Senate has passed the Disrupt Explicit Forged Images and Non-Consensual Edits (DEFIANCE ) Act with unanimous consent, according to the bill’s co-sponsor Senator Dick Durbin (D-IL). The bill lets the subjects of nonconsensual, sexually explicit deepfakes take civil action against the people who create and host them.Deepfakes are a known issue online, but without the proper protections, easy access to AI-powered image and video generation tools has made it possible for anyone to create compromising content using another person's likeness. This has become a particular problem on X, where the integration of Grok, the AI assistant created by X's parent company xAI, makes it possible for anyone to turn the content of another person's post into an image-generating prompt. Over the last month, that's allowed users to create sexually explicit images of children, just by replying to a post with @grok and a request. In response, Ofcom, the UK's media regulator, has already opened an investigation into X for potentially violating the Online Safety Act. The chatbot has also been outright blocked in Malaysia and Indonesia. The DEFIANCE Act won't prevent Grok or other AI tools from generating nonconsensual deepfakes, but it would make creating or hosting that content potentially very expensive for anyone on the receiving end of a lawsuit.The Senate passed an earlier version of the DEFIANCE Act in 2024, but it stalled in the House. Given the urgency of Grok's deepfake problem, the hope is this new version of the bill won't see the same resistance. Congress passed an earlier piece of deepfake regulation last year, the Take It Down Act, with bipartisan support. That bill was focused on the companies who host nonconsensual, sexually explicit content, rather than the people exploited by it.This article originally appeared on Engadget at https://www.engadget.com/ai/senate-passes-defiance-act-for-a-second-time-to-address-grok-deepfakes-212151712.html?src=rss",
          "feed_position": 36
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ar-vr/meta-refocuses-on-ai-hardware-as-metaverse-layoffs-begin-145924706.html",
          "published_at": "Tue, 13 Jan 2026 14:59:24 +0000",
          "title": "Meta refocuses on AI hardware as metaverse layoffs begin",
          "standfirst": "As we expected, Meta has begun laying off more than 1,000 employees from its Reality Labs division, which focused on virtual reality and metaverse products, Bloomberg reports. The company will refocus on developing wearables, like its recent batch of AI-powered Ray-Ban smart glasses, according to a memo from CTO Andrew Bosworth.The news isn’t too surprising. Reality Labs has lost more than $70 billion since the beginning of 2021, and while Meta has done a solid job of delivering desirable consumer VR headsets and smart glasses, that business hasn’t been nearly profitable enough to justify the cost. And of course, Mark Zuckerberg’s huge gamble on the metaverse, which involved renaming the company from Facebook to Meta in 2021, has gone nowhere.According to Bloomberg, Meta’s metaverse plans will now focus on mobile devices, which could mean a combination of its future wearables as well as existing mobile apps. “With the larger potential user base and the fastest growth rate today, we are shifting teams and resources almost exclusively to mobile to continue to accelerate adoption there,” Bosworth wrote in a memo to staff this morning.Meta isn’t dumping its VR headset plans entirely, but according to Bosworth the VR divion will “operate as a leaner, flatter organization with a more focused road map to maximize long-term sustainability.” Basically, don’t expect a Quest 3 follow-up anytime soon.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/meta-refocuses-on-ai-hardware-as-metaverse-layoffs-begin-145924706.html?src=rss",
          "content": "As we expected, Meta has begun laying off more than 1,000 employees from its Reality Labs division, which focused on virtual reality and metaverse products, Bloomberg reports. The company will refocus on developing wearables, like its recent batch of AI-powered Ray-Ban smart glasses, according to a memo from CTO Andrew Bosworth.The news isn’t too surprising. Reality Labs has lost more than $70 billion since the beginning of 2021, and while Meta has done a solid job of delivering desirable consumer VR headsets and smart glasses, that business hasn’t been nearly profitable enough to justify the cost. And of course, Mark Zuckerberg’s huge gamble on the metaverse, which involved renaming the company from Facebook to Meta in 2021, has gone nowhere.According to Bloomberg, Meta’s metaverse plans will now focus on mobile devices, which could mean a combination of its future wearables as well as existing mobile apps. “With the larger potential user base and the fastest growth rate today, we are shifting teams and resources almost exclusively to mobile to continue to accelerate adoption there,” Bosworth wrote in a memo to staff this morning.Meta isn’t dumping its VR headset plans entirely, but according to Bosworth the VR divion will “operate as a leaner, flatter organization with a more focused road map to maximize long-term sustainability.” Basically, don’t expect a Quest 3 follow-up anytime soon.This article originally appeared on Engadget at https://www.engadget.com/ar-vr/meta-refocuses-on-ai-hardware-as-metaverse-layoffs-begin-145924706.html?src=rss",
          "feed_position": 43
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/star-wars-outlaws-developer-massive-entertainment-and-ubisoft-stockholm-face-layoffs-134234968.html",
          "published_at": "Tue, 13 Jan 2026 13:42:34 +0000",
          "title": "Star Wars Outlaws developer Massive Entertainment and Ubisoft Stockholm face layoffs",
          "standfirst": "We aren't even two weeks into the new year and Ubisoft is already looking to carry out its second round of layoffs in 2026. The company has informed workers at Massive Entertainment and Ubisoft Stockholm of a \"proposed organizational restructure\" that could affect around 55 roles across its two Swedish studios. Workers at Massive (the developer of The Division series, Star Wars Outlaws and Avatar: Frontiers of Pandora) were offered voluntary buyouts late last year as part of Ubisoft's ongoing cost-cutting efforts.\"This restructure follows the completion of the Voluntary Leave Program launched during the fall of 2025, a finalized long-term roadmap and a completed staffing and appointment process, which together have provided clearer visibility into the structure and capacity required to support the two studios’ work and sustainably over time,\" Ubisoft told IGN in a statement. \"These proposed changes are forward-looking and structural, they are not related to individual performance, recent deliveries or the quality of the work produced by the teams.\"Ubisoft claims that the \"long-term direction for the studios remains unchanged.\" Massive will continue working on projects that include The Division 3. Ubisoft Stockholm, meanwhile, is beavering away on a new franchise that's still under wraps for now. That project is harnessing the studio's Ubisoft Scalar cloud computing tech, according to Game Developer.Earlier in January, the company said it was shutting down Ubisoft Halifax, resulting in the loss of 71 jobs. Workers at that studio unionized just 16 days earlier. Ubisoft said its decision was part of \"company-wide actions to streamline operations.\"This article originally appeared on Engadget at https://www.engadget.com/gaming/star-wars-outlaws-developer-massive-entertainment-and-ubisoft-stockholm-face-layoffs-134234968.html?src=rss",
          "content": "We aren't even two weeks into the new year and Ubisoft is already looking to carry out its second round of layoffs in 2026. The company has informed workers at Massive Entertainment and Ubisoft Stockholm of a \"proposed organizational restructure\" that could affect around 55 roles across its two Swedish studios. Workers at Massive (the developer of The Division series, Star Wars Outlaws and Avatar: Frontiers of Pandora) were offered voluntary buyouts late last year as part of Ubisoft's ongoing cost-cutting efforts.\"This restructure follows the completion of the Voluntary Leave Program launched during the fall of 2025, a finalized long-term roadmap and a completed staffing and appointment process, which together have provided clearer visibility into the structure and capacity required to support the two studios’ work and sustainably over time,\" Ubisoft told IGN in a statement. \"These proposed changes are forward-looking and structural, they are not related to individual performance, recent deliveries or the quality of the work produced by the teams.\"Ubisoft claims that the \"long-term direction for the studios remains unchanged.\" Massive will continue working on projects that include The Division 3. Ubisoft Stockholm, meanwhile, is beavering away on a new franchise that's still under wraps for now. That project is harnessing the studio's Ubisoft Scalar cloud computing tech, according to Game Developer.Earlier in January, the company said it was shutting down Ubisoft Halifax, resulting in the loss of 71 jobs. Workers at that studio unionized just 16 days earlier. Ubisoft said its decision was part of \"company-wide actions to streamline operations.\"This article originally appeared on Engadget at https://www.engadget.com/gaming/star-wars-outlaws-developer-massive-entertainment-and-ubisoft-stockholm-face-layoffs-134234968.html?src=rss",
          "feed_position": 47
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/2026-01/6f59ce1c-952a-4b66-b851-2ef1728675cf",
      "popularity_score": 2017.9744333333333
    },
    {
      "id": "cluster_55",
      "coverage": 2,
      "updated_at": "2026-01-14T16:40:10-05:00",
      "title": "Verizon’s wireless network is back online after outage",
      "neutral_headline": "Verizon’s wireless network is back online after outage",
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/861956/verizon-is-down-outage-cell-wireless-service-sos-mode",
          "published_at": "2026-01-14T16:40:10-05:00",
          "title": "Verizon’s wireless network is back online after outage",
          "standfirst": "The first big outage of 2026 has been resolved, with Verizon's wireless network now back online after experiencing issues yesterday. This follows Verizon customers across the US, including several Verge writers, finding that service was spotty or nonexistent starting at around noon ET on January 14th, with phones switching to SOS Mode and being unable [&#8230;]",
          "content": "The first big outage of 2026 has been resolved, with Verizon's wireless network now back online after experiencing issues yesterday. This follows Verizon customers across the US, including several Verge writers, finding that service was spotty or nonexistent starting at around noon ET on January 14th, with phones switching to SOS Mode and being unable to connect. In a statement to The Verge, Verizon spokesperson Christina Moon said: The outage has been resolved. If customers are still having an issue, we encourage them to restart their devices to reconnect to the network. For those affected, we will provide account credits. Details will b … Read the full story at The Verge.",
          "feed_position": 6
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/verizon-outage-knocks-out-us-mobile-service-including-some-911-calls/",
          "published_at": "Wed, 14 Jan 2026 18:54:40 +0000",
          "title": "Verizon Outage Knocks Out US Mobile Service, Including Some 911 Calls",
          "standfirst": "A major Verizon outage appeared to impact customers across the United States starting around noon ET on Wednesday. Calls to Verizon customers from other carriers may also be impacted.",
          "content": "A major Verizon outage appeared to impact customers across the United States starting around noon ET on Wednesday. Calls to Verizon customers from other carriers may also be impacted.",
          "feed_position": 8,
          "image_url": "https://media.wired.com/photos/6967de11685933202e631c16/master/pass/Major-Cell-Service-Outage-Security-2246554747.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/6967de11685933202e631c16/master/pass/Major-Cell-Service-Outage-Security-2246554747.jpg",
      "popularity_score": 2006.3238777777779
    },
    {
      "id": "cluster_85",
      "coverage": 2,
      "updated_at": "Wed, 14 Jan 2026 17:46:19 +0000",
      "title": "Bandcamp bans purely AI-generated music from its platform",
      "neutral_headline": "Bandcamp bans purely AI-generated music from its platform",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/bandcamp-bans-purely-ai-generated-music-from-its-platform/",
          "published_at": "Wed, 14 Jan 2026 17:46:19 +0000",
          "title": "Bandcamp bans purely AI-generated music from its platform",
          "standfirst": "Indie music store says it wants fans to have confidence music was largely made by humans.",
          "content": "On Tuesday, Bandcamp announced on Reddit that it will no longer permit AI-generated music on its platform. \"Music and audio that is generated wholly or in substantial part by AI is not permitted on Bandcamp,\" the company wrote in a post to the r/bandcamp subreddit. The new policy also prohibits \"any use of AI tools to impersonate other artists or styles.\" The policy draws a line that some in the music community have debated: Where does tool use end and full automation begin? AI models are not artists in themselves, since they lack personhood and creative intent. But people do use AI tools to make music, and the spectrum runs from using AI for minor assistance (cleaning up audio, suggesting chord progressions) to typing a prompt and letting a model generate an entire track. Bandcamp's policy targets the latter end of that spectrum while leaving room for human artists who incorporate AI tools into a larger creative process. The announcement emphasized the platform's desire to protect its community of human artists. \"The fact that Bandcamp is home to such a vibrant community of real people making incredible music is something we want to protect and maintain,\" the company wrote. Bandcamp asked users to flag suspected AI-generated content through its reporting tools, and the company said it reserves \"the right to remove any music on suspicion of being AI generated.\"Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/no_robot_music_2-1152x648.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/14/bandcamp-takes-a-stand-against-ai-music-banning-it-from-the-platform/",
          "published_at": "Wed, 14 Jan 2026 17:06:04 +0000",
          "title": "Bandcamp takes a stand against AI music, banning it from the platform",
          "standfirst": "\"We want musicians to keep making music, and for fans to have confidence that the music they find on Bandcamp was created by humans,\" the company said.",
          "content": "\"We want musicians to keep making music, and for fans to have confidence that the music they find on Bandcamp was created by humans,\" the company said.",
          "feed_position": 12
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/no_robot_music_2-1152x648.jpg",
      "popularity_score": 2002.4263777777778
    },
    {
      "id": "cluster_88",
      "coverage": 2,
      "updated_at": "Wed, 14 Jan 2026 16:42:32 +0000",
      "title": "Gemini can now scan your photos, email, and more to provide better answers",
      "neutral_headline": "Gemini can now scan your photos, email, and more to provide better answers",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/01/gemini-can-now-scan-your-photos-email-and-more-to-provide-better-answers/",
          "published_at": "Wed, 14 Jan 2026 16:42:32 +0000",
          "title": "Gemini can now scan your photos, email, and more to provide better answers",
          "standfirst": "The feature will start with paid users only, and it's off by default.",
          "content": "Google has toyed with personalized answers in Gemini, but that was just a hint of what was to come. Today, the company is announcing extensive \"personal intelligence\" in Gemini that allows the chatbot to connect to Gmail, Photos, Search, and YouTube to craft more useful answers to your questions. If you don't want Gemini to get to know you, there's some good news. Personal intelligence is beginning as a feature for paid users, and it's entirely optional. By every measure, Google's models are at or near the top of the AI heap. In general, the more information you feed into a generative AI, the better the outputs are. And when that data is personal to you, the resulting inference is theoretically more useful. Google just so happens to have a lot of personal data on all its users, so it's relatively simple to feed that data into Gemini. As Personal Intelligence rolls out over the coming weeks, AI Pro and AI Ultra subscribers will see the option to connect those data sources. Each can be connected individually, so you might choose to allow Gmail access but block Photos, for example. When Gemini is allowed access to other Google products, it incorporates that data into its responses.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/14/geminis-new-beta-feature-provides-proactive-responses-based-on-your-photos-emails-and-more/",
          "published_at": "Wed, 14 Jan 2026 16:00:00 +0000",
          "title": "Gemini&#8217;s new beta feature provides proactive responses based on your photos, emails, and more",
          "standfirst": "Personal Intelligence is off by default, as users have the option to choose if and when they want to connect their Google apps to Gemini.",
          "content": "Personal Intelligence is off by default, as users have the option to choose if and when they want to connect their Google apps to Gemini.",
          "feed_position": 15
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg",
      "popularity_score": 2001.3633222222222
    },
    {
      "id": "cluster_26",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 08:00:15 +0000",
      "title": "Exclusive: Volvo tells us why having Gemini in your next car is a good thing",
      "neutral_headline": "Volvo tells us why having Gemini in your next car is a good thing",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/exclusive-volvo-tells-us-why-having-gemini-in-your-next-car-is-a-good-thing/",
          "published_at": "Thu, 15 Jan 2026 08:00:15 +0000",
          "title": "Exclusive: Volvo tells us why having Gemini in your next car is a good thing",
          "standfirst": "In-car personal assistants are about to get useful, it looks like.",
          "content": "Next week, Volvo shows off its new EX60 SUV to the world. It's the brand's next electric vehicle, one built on an all-new, EV-only platform that makes use of the latest in vehicle design trends, like a cell-to-body battery pack, large weight-saving castings, and an advanced electronic architecture run by a handful of computers capable of more than 250 trillion operations per second. This new software-defined platform even has a name: HuginCore, after one of the two ravens that collected information for the Norse god Odin. It's not Volvo's first reference to mythology. \"We have Thor's Hammer [Volvo's distinctive headlight design] and now we have HuginCore... one of the two trusted Ravens of Oden. He sent Hugin and Muninn out to fly across the realms and observe and gather information and knowledge, which they then share with Odin that enabled him to make the right decisions as the ruler of Asgard,\" said Alwin Bakkenes, head of global software engineering at Volvo Cars. \"And much like Hugin, the way we look at this technology platform, it collects information from all of the sensors, all of the actuators in the vehicle. It understands the world around the vehicle, and it enables us to actually anticipate around what lies ahead,\" Bakkenes told me.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-1152x648.jpg",
      "popularity_score": 357.6586
    },
    {
      "id": "cluster_45",
      "coverage": 1,
      "updated_at": "Thu, 15 Jan 2026 00:01:59 +0000",
      "title": "A British redcoat’s lost memoir resurfaces",
      "neutral_headline": "A British redcoat’s lost memoir resurfaces",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/a-british-redcoats-lost-memoir-resurfaces/",
          "published_at": "Thu, 15 Jan 2026 00:01:59 +0000",
          "title": "A British redcoat’s lost memoir resurfaces",
          "standfirst": "Shadrack Byfield lost his left arm in the War of 1812; his life sheds light on post-war re-integration.",
          "content": "History buffs are no doubt familiar with the story of Shadrack Byfield, a rank-and-file British redcoat who fought during the War of 1812 and lost his left arm to a musket ball for his trouble. Byfield has been featured in numerous popular histories—including a children's book and a 2011 PBS documentary—as a shining example of a disabled soldier's stoic perseverance. But a newly rediscovered memoir that Byfield published in his later years is complicating that idealized picture of his post-military life, according to a new paper published in the Journal of British Studies. Historian Eamonn O'Keeffe of Memorial University of Newfoundland in St. John's, Canada, has been a Byfield fan ever since he read the 1985 children's novel, Redcoat, by Gregory Sass. His interest grew when he was working at Fort York, a War of 1812-era fort and museum, in Toronto. \"There are dozens of memoirs written by British rank-and-file veterans of the Napoleonic Wars, but only a handful from the War of 1812, which was much smaller in scale,\" O'Keeffe told Ars. \"Byfield's autobiography seemed to offer an authentic, ground-level view of the fighting in North America, helping us look beyond the generals and politicians and grapple with the implications of this conflict for ordinary people. Born in 1789 in Wiltshire's Bradford-on-Avon suburbs, Byfield's parents intended him to follow in his weaver father's footsteps. He enlisted in the county militia when he turned 18 instead, joining the regular army the following year. When the War of 1812 broke out, Byfield was stationed at Fort George along the Niagara River, participating in the successful siege of Fort Detroit. At the Battle of Frenchtown in January 1813, he was shot in the neck, but he recovered sufficiently to join the campaigns against Fort Meigs and Fort Stephenson in Ohio.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/redcoat1-1152x648-1767964179.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/redcoat1-1152x648-1767964179.jpg",
      "popularity_score": 328.6874888888889
    },
    {
      "id": "cluster_46",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 23:43:46 +0000",
      "title": "Musk and Hegseth vow to “make Star Trek real” but miss the show’s lessons",
      "neutral_headline": "Musk and Hegseth vow to “make Star Trek real” but miss the show’s lessons",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/pentagons-arsenal-of-freedom-tour-borrows-name-from-star-trek-episode-about-killer-ai/",
          "published_at": "Wed, 14 Jan 2026 23:43:46 +0000",
          "title": "Musk and Hegseth vow to “make Star Trek real” but miss the show’s lessons",
          "standfirst": "AI weapons systems may annihilate their creators.",
          "content": "This week, SpaceX CEO Elon Musk and Secretary of Defense Pete Hegseth touted their desire to “make Star Trek real”—while unconsciously reminding us of what the utopian science fiction franchise is fundamentally about. Their Tuesday event was the latest in Hegseth’s ongoing “Arsenal of Freedom” tour, which was held at SpaceX headquarters in Starbase, Texas. (Itself a newly created town that takes its name from a term popularized by Star Trek.) Neither Musk nor Hegseth seemed to recall that the “Arsenal of Freedom” phrase—at least in the context of Star Trek—is also the title of a 1988 episode of Star Trek: The Next Generation. That episode depicts an AI-powered weapons system, and its automated salesman, which destroys an entire civilization and eventually threatens the crew of the USS Enterprise. (Some Trekkies made the connection, however.)Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/vulcan-salute-1152x648-1768432794.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/vulcan-salute-1152x648-1768432794.jpg",
      "popularity_score": 321.3838777777778
    },
    {
      "id": "cluster_53",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 22:03:11 +0000",
      "title": "A single click mounted a covert, multistage attack against Copilot",
      "neutral_headline": "A single click mounted a covert, multistage attack against Copilot",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/a-single-click-mounted-a-covert-multistage-attack-against-copilot/",
          "published_at": "Wed, 14 Jan 2026 22:03:11 +0000",
          "title": "A single click mounted a covert, multistage attack against Copilot",
          "standfirst": "Exploit exfiltrating data from chat histories worked even after users closed chat windows.",
          "content": "Microsoft has fixed a vulnerability in its Copilot AI assistant that allowed hackers to pluck a host of sensitive user data with a single click on a legitimate URL. The hackers in this case were white-hat researchers from security firm Varonis. The net effect of their multistage attack was that they exfiltrated data, including the target’s name, location, and details of specific events from the user’s Copilot chat history. The attack continued to run even when the user closed the Copilot chat, with no further interaction needed once the user clicked the link, a legitimate Copilot one, in the email. The attack and resulting data theft bypassed enterprise endpoint security controls and detection by endpoint protection apps. It just works “Once we deliver this link with this malicious prompt, the user just has to click on the link and the malicious task is immediately executed,” Varonis security researcher Dolev Taler told Ars. “Even if the user just clicks on the link and immediately closes the tab of Copilot chat, the exploit still works.”Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/MSFT_Holiday_copilot_Card_1-1152x648-1763493467.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/MSFT_Holiday_copilot_Card_1-1152x648-1763493467.jpeg",
      "popularity_score": 314.70748888888886
    },
    {
      "id": "cluster_47",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 23:08:44 +0000",
      "title": "SC measles outbreak has gone berserk: 124 cases since Friday, 409 quarantined",
      "neutral_headline": "SC measles outbreak has gone berserk: 124 cases since Friday, 409 quarantined",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/sc-measles-outbreak-has-gone-berserk-124-cases-since-friday-409-quarantined/",
          "published_at": "Wed, 14 Jan 2026 23:08:44 +0000",
          "title": "SC measles outbreak has gone berserk: 124 cases since Friday, 409 quarantined",
          "standfirst": "On Jan. 6, there were 211 cases. The outbreak, which began in October, is now at 434.",
          "content": "A measles outbreak in South Carolina that began in October is now wildly accelerating, doubling in just the past week to a total of 434 cases, with 409 people currently in quarantine. Amid the outbreak, South Carolina health officials have been providing updates on cases every Tuesday and Friday. On Tuesday, state health officials reported 124 more cases since last Friday, which had 99 new cases since the previous Tuesday. On that day, January 6, officials noted a more modest increase of 26 cases, bringing the outbreak total at that point to 211 cases. With the 3-month-old outbreak now doubled in just a week, health officials are renewing calls for people to get vaccinated against the highly infectious virus—an effort that has met with little success since October. Still, the health department is activating its mobile health unit to offer free measles-mumps-rubella (MMR) vaccinations, as well as flu vaccinations at two locations today and Thursday in the Spartanburg area, the epicenter of the outbreak.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/05/misinfoTOP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2020/05/misinfoTOP-1152x648.jpg",
      "popularity_score": 310.7999888888889
    },
    {
      "id": "cluster_54",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 21:42:39 +0000",
      "title": "I can’t stop shooting Oddcore’s endless waves of weird little guys",
      "neutral_headline": "I can’t stop shooting Oddcore’s endless waves of weird little guys",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/i-cant-stop-shooting-oddcores-endless-waves-of-weird-little-guys/",
          "published_at": "Wed, 14 Jan 2026 21:42:39 +0000",
          "title": "I can’t stop shooting Oddcore’s endless waves of weird little guys",
          "standfirst": "Zippy action, fun upgrade system make for a great pick-up-and-play shooter.",
          "content": "Since the days of Wolfenstein 3D and Doom, the humble first-person shooter has flourished in myriad and complex directions. The genre has expanded in narrative and gameplay terms to include everything from sprawling sci-fi epics to dense objectivist allegories to multiplayer-focused military free-for-alls and practically everything in between. Sometimes, though, you just want an excuse to shoot a bunch of weird little guys in weird little spaces. Don't get too close, now... they do bite. Credit: Oddcorp For those times, there is Oddcore, a new Early Access, roguelike boomer shooter that is a stark contrast to the more sprawling self-serious shooters out there. The game's combination of frenetic, quick-moving action, semi-randomized scenarios, and well-balanced risk/reward upgrade system makes for a pick-up-and-play shooter that I find myself struggling not to pick up and play for a few more quick-hit sessions even as I write this.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/oddcore1-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/oddcore1-1152x648.png",
      "popularity_score": 289.3652666666667
    },
    {
      "id": "cluster_58",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 21:30:51 +0000",
      "title": "FBI fights leaks by seizing Washington Post reporter’s phone, laptops, and watch",
      "neutral_headline": "FBI fights leaks by seizing Washington Post reporter’s phone, laptops, and watch",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/fbi-fights-leaks-by-seizing-washington-post-reporters-phone-laptops-and-watch/",
          "published_at": "Wed, 14 Jan 2026 21:30:51 +0000",
          "title": "FBI fights leaks by seizing Washington Post reporter’s phone, laptops, and watch",
          "standfirst": "FBI searches home and devices of reporter who has over 1,100 government contacts.",
          "content": "The FBI searched a Washington Post reporter's home and seized her work and personal devices as part of an investigation into what Attorney General Pam Bondi called \"illegally leaked information from a Pentagon contractor.\" Executing a search warrant at the Virginia home of reporter Hannah Natanson on Wednesday morning, FBI \"agents searched her home and her devices, seizing her phone, two laptops and a Garmin watch,\" The Washington Post reported. \"One of the laptops was her personal computer, the other a Washington Post-issued laptop. Investigators told Natanson that she is not the focus of the probe.\" Natanson regularly uses encrypted Signal chats to communicate with people who work or used to work in government, and has said her list of contacts exceeds 1,100 current and former government employees. The Post itself \"received a subpoena Wednesday morning seeking information related to the same government contractor,\" the report said.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/washington-post-building-1152x648-1768424038.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/washington-post-building-1152x648-1768424038.jpg",
      "popularity_score": 279.1686
    },
    {
      "id": "cluster_61",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 20:49:32 +0000",
      "title": "US gov’t: House sysadmin stole 200 phones, caught by House IT desk",
      "neutral_headline": "US gov’t: House sysadmin stole 200 phones, caught by House IT desk",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/us-govt-house-sysadmin-stole-200-phones-caught-by-house-it-desk/",
          "published_at": "Wed, 14 Jan 2026 20:49:32 +0000",
          "title": "US gov’t: House sysadmin stole 200 phones, caught by House IT desk",
          "standfirst": "Scheme allegedly cost taxpayers $150,000.",
          "content": "The US House of Representatives, that glorious and efficient gathering of We the People, has been hit with yet another scandal. Like most (non-sexual) House scandals, the allegations here involve personal enrichment. Unlike most (non-sexual) House scandals, though, this one involved hundreds of government cell phones being sold on eBay—and some rando member of We the People calling the US House IT help desk, which blew the lid on the whole scheme. Only sell \"in parts\" According to the government's version of events, 43-year-old Christopher Southerland was working in 2023 as a sysadmin for the House Committee on Transportation and Infrastructure. In his role, Southerland had the authority to order cell phones for committee staffers, of which there are around 80.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2178190944-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2178190944-1152x648.jpg",
      "popularity_score": 268.4799888888889
    },
    {
      "id": "cluster_63",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 20:39:00 +0000",
      "title": "Grok was finally updated to stop undressing women and children, X Safety says",
      "neutral_headline": "Grok was finally updated to stop undressing women and children, X Safety says",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/musk-still-defending-groks-partial-nudes-as-california-ag-opens-probe/",
          "published_at": "Wed, 14 Jan 2026 20:39:00 +0000",
          "title": "Grok was finally updated to stop undressing women and children, X Safety says",
          "standfirst": "California's AG will investigate whether Musk’s nudifying bot broke US laws.",
          "content": "Late Wednesday, X Safety confirmed that Grok was tweaked to stop undressing images of people without their consent. \"We have implemented technological measures to prevent the Grok account from allowing the editing of images of real people in revealing clothing such as bikinis,\" X Safety said. \"This restriction applies to all users, including paid subscribers.\" The update includes restricting \"image creation and the ability to edit images via the Grok account on the X platform,\" which \"are now only available to paid subscribers. This adds an extra layer of protection by helping to ensure that individuals who attempt to abuse the Grok account to violate the law or our policies can be held accountable,\" X Safety said.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2256074595-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2256074595-1024x648.jpg",
      "popularity_score": 258.30443333333335
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 19:56:30 +0000",
      "title": "Federal data underscores meteoric rise of streaming subscription prices in 2025",
      "neutral_headline": "Federal data underscores meteoric rise of streaming subscription prices in 2025",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/federal-data-underscores-meteoric-rise-of-streaming-subscription-prices-in-2025/",
          "published_at": "Wed, 14 Jan 2026 19:56:30 +0000",
          "title": "Federal data underscores meteoric rise of streaming subscription prices in 2025",
          "standfirst": "Streaming services played a big role in 2025 inflation.",
          "content": "The prices that Americans paid for subscription- and rental-based access to video streaming services and video games increased 29 percent from December 2024 to December 2025, according to data that the US Department of Labor’s Bureau of Labor Statistics (BLS) released on Tuesday. According to the BLS, the Consumer Price Index for All Urban Consumers (CPI-U), which BLS says represents over 90 percent of the US population across the country, for all items “increased 2.7 percent before seasonal adjustment.” The CPI-U for “subscription and rental of video and video games” includes subscription video-on-demand (SVOD) streaming services, like Netflix and Disney+, and \"one-time rental of video and video game media. These may be rented or subscribed to through physical copy, streaming, or temporary download,\" BLS says. For comparison, \"cable, satellite, and live streaming television service [such as YouTube TV and Sling]\" saw 4.9 percent inflation last year.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2196841539-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2196841539-1152x648.jpg",
      "popularity_score": 247.5961
    },
    {
      "id": "cluster_91",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 16:08:58 +0000",
      "title": "Deny, deny, admit: UK police used Copilot AI “hallucination” when banning football fans",
      "neutral_headline": "Deny, deny, admit: UK police used Copilot AI “hallucination”...",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/deny-deny-admit-uk-police-used-copilot-ai-hallucination-when-banning-football-fans/",
          "published_at": "Wed, 14 Jan 2026 16:08:58 +0000",
          "title": "Deny, deny, admit: UK police used Copilot AI “hallucination” when banning football fans",
          "standfirst": "Police finally come clean about botched use of AI tools.",
          "content": "After repeatedly denying for weeks that his force used AI tools, the chief constable of the West Midlands police has finally admitted that a hugely controversial decision to ban Maccabi Tel Aviv football fans from the UK did involve hallucinated information from Microsoft Copilot. In October 2025, Birmingham's Safety Advisory Group (SAG) met to decide whether an upcoming football match between Aston Villa (based in Birmingham) and Maccabi Tel Aviv could be held safely. Tensions were heightened in part due to an October 2 terror attack against a synagogue in Manchester where several people were killed by an Islamic attacker.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2251534549-1152x648-1768405011.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2251534549-1152x648-1768405011.jpg",
      "popularity_score": 148.80387777777779
    },
    {
      "id": "cluster_82",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 18:45:50 +0000",
      "title": "Civilization VII is headed to iPhone and iPad with “Arcade Edition”",
      "neutral_headline": "Civilization VII is headed to iPhone and iPad with “Arcade Edition”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/civilization-vii-is-headed-to-iphone-and-ipad-with-arcade-edition/",
          "published_at": "Wed, 14 Jan 2026 18:45:50 +0000",
          "title": "Civilization VII is headed to iPhone and iPad with “Arcade Edition”",
          "standfirst": "Apple's platforms are also getting Retrocade, a library of classic arcade games.",
          "content": "Civilization VII is coming to the iPhone and iPad, Apple and publisher 2K announced today. Formally titled Sid Meier's Civilization VII Arcade Edition, it is developed by Behaviour Interactive with input from original developer Firaxis Games. The game will be available as part of the Apple Arcade service, which offers ad-free games for Apple platforms for $7 per month. Neither announcement makes any mention of a non-Arcade version, so this appears to be exclusively part of the subscription.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/civ7-iphone-1152x648-1768415756.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/civ7-iphone-1152x648-1768415756.jpg",
      "popularity_score": 148.41832222222223
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 22:34:41 +0000",
      "title": "The RAM shortage’s silver lining: Less talk about “AI PCs”",
      "neutral_headline": "The RAM shortage’s silver lining: Less talk about “AI PCs”",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/the-ram-shortages-silver-lining-less-talk-about-ai-pcs/",
          "published_at": "Tue, 13 Jan 2026 22:34:41 +0000",
          "title": "The RAM shortage’s silver lining: Less talk about “AI PCs”",
          "standfirst": "“General interest in AI PCs has been wavering for a while...\"",
          "content": "RAM prices have soared, which is bad news for people interested in buying, building, or upgrading a computer this year, but it's likely good news for people exasperated by talk of so-called AI PCs. As Ars Technica has reported, the growing demands of data centers, fueled by the AI boom, have led to a shortage of RAM and flash memory chips, driving prices to skyrocket. In an announcement today, Ben Yeh, principal analyst at technology research firm Omdia, said that in 2025, “mainstream PC memory and storage costs rose by 40 percent to 70 percent, resulting in cost increases being passed through to customers.”Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1329130331-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1329130331-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Tue, 13 Jan 2026 23:01:44 +0000",
      "title": "BMW’s first electric M car is coming in 2027—with one motor per wheel",
      "neutral_headline": "BMW’s first electric M car is coming in 2027—with one motor per wheel",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/bmws-first-electric-m-car-is-coming-in-2027-with-one-motor-per-wheel/",
          "published_at": "Tue, 13 Jan 2026 23:01:44 +0000",
          "title": "BMW’s first electric M car is coming in 2027—with one motor per wheel",
          "standfirst": "Here's what we know about the first BMW EV to wear a proper M badge.",
          "content": "BMW provided flights from Washington, DC, to Malaga, Spain, and accommodation so Ars could drive the iX3 and be briefed on the electric M Neue Klasse. Ars does not accept paid editorial content. Late last year, we drove BMW's new iX3. It's the first of a series of electric BMWs to use a newly developed platform, known as the \"Neue Klasse.\" Later this year, we'll see the first fully electric version of the 3 Series when the i3 sedan debuts. And next year, BMW enthusiasts will finally find out what the brand's M division—which infuses motorsport into the vehicles like few others—can do with an EV. There have been M-tuned EVs before now, more powerful variants of the i4, iX, and i7. And each time we've driven them, BMW has been at pains to point out that these weren't true M cars, not like the M3 or M5. Honestly, they weren't better than the cheaper, less powerful versions, something that won't be allowed for next year's performance EV, which might be called something like the iM3, assuming the naming convention remains logic-based. \"The next generation of models are set to establish a new benchmark in the high-performance vehicle segment,\" says Franciscus van Meel, managing director of BMW M GmbH. \"With the latest generation of Neue Klasse technology, we are taking the BMW M driving experience to a new level and will inspire our customers with outstanding, racetrack-ready driving dynamics for everyday use.\"Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/BMW-M-Electrified-Arjeplog-_046-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/BMW-M-Electrified-Arjeplog-_046-1152x648.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_107",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 13:31:44 +0000",
      "title": "Is 2026 the year buttons come back to cars? Crash testers say yes.",
      "neutral_headline": "Is 2026 the year buttons come back to cars? Crash testers say yes.",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/01/buttons-in-cars-australian-crash-testers-are-latest-to-require-them/",
          "published_at": "Wed, 14 Jan 2026 13:31:44 +0000",
          "title": "Is 2026 the year buttons come back to cars? Crash testers say yes.",
          "standfirst": "The requirements won't go far enough for many, but it's a start.",
          "content": "Like any industry led by designers, the automotive world is subject to trends and fashions. Often, these are things the rest of us complain about. Wheels that used to be 16 inches are now 20s, because the extra size makes the vehicle they're fitted to look smaller, particularly if it's an SUV with a slab of electric vehicle battery to conceal. Front seat passengers now find themselves with their own infotainment screen, often with some kind of active filter tech to prevent the driver from being distracted by whatever it is they're doing. And of course le buzz du jour, AI, is being crammed in here, there, and everywhere. But the thing about fashion and trends is that they don't remain in style forever. For a few years, it was hard to drive a new car that didn't use piano black trim all over the interior. The shiny black plastic surfaces hide infotainment screens well when the display is not turned on, but they scratch and show every speck of dust and lint and every smudge and fingerprint. And that's true for the cheap econobox to the plush luxobarge. The industry finally cottoned on to this, and \"black gloss has had its time—we can do without it,\" Kia designer Jochen Paesen told me a few years ago. Many of those design trends may have been annoying, but the switch away from buttons isn't just about aesthetics; it's affecting safety. And increasingly, safety regulators are pushing back. A couple of years ago, we learned that the Euro New Car Assessment Programme (NCAP) organization, which crash tests cars for European consumers, decided that from 2026, it would start deducting points for basic controls that weren't separate, physical controls that the driver can easily operate without taking their eyes off the road. And now ANCAP, which provides similar crash testing for Australia and New Zealand, has done the same.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1250487861-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1250487861-1152x648.jpg",
      "popularity_score": 138
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 17:25:24 +0000",
      "title": "Man got $2,500 whole-body MRI that found no problems—then had massive stroke",
      "neutral_headline": "Man got $2,500 whole-body MRI that found no problems—then had massive stroke",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/man-got-2500-whole-body-mri-that-found-no-problems-then-had-massive-stroke/",
          "published_at": "Wed, 14 Jan 2026 17:25:24 +0000",
          "title": "Man got $2,500 whole-body MRI that found no problems—then had massive stroke",
          "standfirst": "The MRI showed a problem in a brain artery that should have been flagged, man claims.",
          "content": "A New York man is suing Prenuvo, a celebrity-endorsed whole-body magnetic resonance imaging (MRI) provider, claiming that the company missed clear signs of trouble in his $2,500 whole-body scan—and if it hadn't, he could have acted to avert the catastrophic stroke he suffered months later. Sean Clifford and his legal team claim that his scan on July 15, 2023, showed a 60 percent narrowing and irregularity in a major artery in his brain—the proximal right middle cerebral artery, a branch of the most common artery involved in acute strokes. But Prenuvo's reviews of the scan did not flag the finding and otherwise reported everything in his brain looked normal; there was \"no adverse finding.\" (You can read Prenuvo's report and see Clifford's subsequent imaging here.) Clifford suffered a massive stroke on March 7, 2024. Subsequent imaging found that the proximal right middle cerebral artery progressed to a complete blockage, causing the stroke. Clifford suffered paralysis of his left hand and leg, general weakness on his left side, vision loss and permanent double vision, anxiety, depression, mood swings, cognitive deficits, speech problems, and permanent difficulties with all daily activities.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2212370978-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2212370978-1152x648.jpg",
      "popularity_score": 135.07776666666666
    },
    {
      "id": "cluster_87",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 17:01:06 +0000",
      "title": "Scientists sequence a woolly rhino genome from a 14,400-year-old wolf’s stomach",
      "neutral_headline": "Scientists sequence a woolly rhino genome from a 14,400-year-old wolf’s stomach",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/scientists-sequence-a-woolly-rhino-genome-from-a-14400-year-old-wolfs-stomach/",
          "published_at": "Wed, 14 Jan 2026 17:01:06 +0000",
          "title": "Scientists sequence a woolly rhino genome from a 14,400-year-old wolf’s stomach",
          "standfirst": "Fortunately for paleogeneticists, wolf puppies don't chew their food thoroughly.",
          "content": "A 14,400-year-old wolf puppy’s last meal is shedding light on the last days of one of the Ice Age’s most iconic megafauna species, the woolly rhinoceros. When researchers dissected the frozen mummified remains of an Ice Age wolf puppy, they found a partially digested chunk of meat in its stomach: the remnants of the puppy’s last meal 14,400 years ago. DNA testing revealed that the meat was a prime cut of woolly rhinoceros, a now-extinct 2-metric-ton behemoth that once stomped across the tundras of Europe and Asia. Stockholm University paleogeneticist Sólveig Guðjónsdóttir and her colleagues recently sequenced a full genome from the piece of meat, which reveals some secrets about woolly rhino populations in the centuries before their extinction. Scientists carefully autopsy the remains of a wolf puppy who lived and died 14,400 years ago near Tumat village in Siberia. Credit: Guðjónsdóttir et al. 2026 One bad day for a rhino, one giant leap for paleogenomics “Sequencing the entire genome of an Ice Age animal found in the stomach of another animal has never been done before,” said Uppsala University paleogeneticist Camilo Chacón-Duque, a co-author of the study, in a recent press release.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Woolly-rhino-by-Mammoth-museum-of-North-Eastern-Federal-University-Yakutsk-Russia-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Woolly-rhino-by-Mammoth-museum-of-North-Eastern-Federal-University-Yakutsk-Russia-1152x648.jpg",
      "popularity_score": 134.67276666666666
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Wed, 14 Jan 2026 14:01:19 +0000",
      "title": "EPA makes it harder for states, tribes to block pipelines",
      "neutral_headline": "EPA makes it harder for states, tribes to block pipelines",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/epa-makes-it-harder-for-states-tribes-to-block-pipelines/",
          "published_at": "Wed, 14 Jan 2026 14:01:19 +0000",
          "title": "EPA makes it harder for states, tribes to block pipelines",
          "standfirst": "A new rule aims to speed up and streamline the permitting process.",
          "content": "The Trump administration on Tuesday proposed a new rule aimed at speeding up and streamlining the permitting process for large energy and infrastructure projects, including oil and gas pipelines and facilities tied to artificial intelligence. The rule, which does not require action by Congress, includes a suite of procedural changes to section 401 of the Clean Water Act—a law enacted in the 1970s that is the primary federal statute governing water pollution in the United States. For decades, section 401 has granted states and tribes the authority to approve, impose conditions on, or reject, federal permits for projects that they determine will pollute or damage local waterways.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/07/GettyImages-1228769036-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/07/GettyImages-1228769036-1152x648.jpg",
      "popularity_score": 133
    }
  ]
}