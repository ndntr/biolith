{
  "updated_at": "2026-01-19T23:21:06.656Z",
  "clusters": [
    {
      "id": "cluster_1",
      "coverage": 2,
      "updated_at": "Mon, 19 Jan 2026 17:20:02 -0500",
      "title": "Q&A with Razer CEO Min-Liang Tan on the use of AI in game development, the gaming community's pushback against AI, partnering with Grok, and more (Nilay Patel/The Verge)",
      "neutral_headline": "Q&A with Razer CEO Min-Liang Tan on the use of AI in game development, the gaming community's pushback against...",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260119/p23#a260119p23",
          "published_at": "Mon, 19 Jan 2026 17:20:02 -0500",
          "title": "Q&A with Razer CEO Min-Liang Tan on the use of AI in game development, the gaming community's pushback against AI, partnering with Grok, and more (Nilay Patel/The Verge)",
          "standfirst": "Nilay Patel / The Verge: Q&A with Razer CEO Min-Liang Tan on the use of AI in game development, the gaming community's pushback against AI, partnering with Grok, and more &mdash; We're back to start the year off with a very special live interview with Razer CEO Min-Liang Tan, which we taped in front of a terrific audience &hellip;",
          "content": "Nilay Patel / The Verge: Q&A with Razer CEO Min-Liang Tan on the use of AI in game development, the gaming community's pushback against AI, partnering with Grok, and more &mdash; We're back to start the year off with a very special live interview with Razer CEO Min-Liang Tan, which we taped in front of a terrific audience &hellip;",
          "feed_position": 1,
          "image_url": "http://www.techmeme.com/260119/i23.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/podcast/863361/razer-ceo-min-liang-tan-ces-2026-ai-gaming-project-ava-interview",
          "published_at": "2026-01-19T10:00:00-05:00",
          "title": "Gamers love AI in game dev — they just don&#8217;t know it yet, says Razer&#8217;s CEO",
          "standfirst": "We’re back to start the year off with a very special live interview with Razer CEO Min-Liang Tan, which we taped in front of a terrific audience at Brooklyn Bowl in Las Vegas during CES.&#160; Razer is obviously best known for making mice, keyboards, and gaming PCs in its signature black and bright green, with [&#8230;]",
          "content": "We’re back to start the year off with a very special live interview with Razer CEO Min-Liang Tan, which we taped in front of a terrific audience at Brooklyn Bowl in Las Vegas during CES. Razer is obviously best known for making mice, keyboards, and gaming PCs in its signature black and bright green, with a smattering of RGB LEDs to set everything off. But the company always makes splashy announcements at CES, and this year was no different — and along with the hype, there was plenty of controversy. This year, Razer earned those splashy headlines and more than a little controversy for something it calls Project Ava, an AI companion that has a physical presence in the real world as an anime hologram that sits in a jar on your desk. Ava is powered by, you guessed it, Elon Musk’s Grok. Verge subscribers, don&#8217;t forget you get exclusive access to ad-free Decoder wherever you get your podcasts. Head here. Not a subscriber? You can sign up here. There are a lot of choices bundled up in all of that, and Razer can’t really fall back on the “it’s just a prototype” defense. It’s taking $20 “reservations” and entirely expects to ship this thing, potentially even this year. So I spent a good chunk of time in this interview asking Min some very obvious questions, to which I’m not sure I got very satisfying answers. I really wanted to know if Min and Razer had really thought through the implications of building AI companions, after a string of stories detailing the mental health issues chatbots have caused for so many people. And of course, I wanted to know why Min and Razer had chosen Grok, which is facing outrage around the world for allowing users to create deepfaked pornographic images of real women and children. Min says they chose Grok for its conversational capabilities. But he was also not very convinced by the notion that products like this always end up being turned into creepy sexual objects, despite an entire year of headlines about AI psychosis and people turning chatbots into romantic partners. That exchange really set the tone for the rest of my conversation with Min, which focused on why exactly he’s pushing Razer so hard into AI when it does not seem at all clear that the core gamer demographic wants any of this. The gaming community at large has been absolutely rocked by the AI art debate that’s ripped through the broader industry in the past 12 months, with concerns over labor, copyright, and even just experimental AI use in game development putting some of the industry’s most beloved studios into full-blown crisis mode. Gamers themselves are fairly hostile toward AI, which you can see in the comments on Razer’s own CES AI posts. So I asked Min about that, and how he would know if he had made the right bet here in the face of all this pushback. As you can tell, there was a lot of back and forth here, and this was a really good conversation. Min and I really dug into some of the biggest issues in tech and gaming, themes that are going to be central throughout 2026. It’s also great to do these kinds of episodes live in front of an audience. I think it’s going to give you a lot to think about. Okay: Razer CEO Min-Liang Tan. Here we go. This interview has been lightly edited for length and clarity. Hello, welcome to Decoder. I&#8217;m Nilay Patel, editor-in-chief of The Verge, and Decoder is my show about big ideas and other problems. Today, I&#8217;m talking with Razer CEO Min-Liang Tan. Welcome, Min. Thank you for having me. Nailed it. Thank you to our audience. We are live at Brooklyn Bowl at CES. I&#8217;m very excited to be doing this in front of a live audience. You&#8217;re going to hear them throughout the show because Min has no shortage of extremely controversial things to say. We&#8217;ll see, we&#8217;ll see. I was promised “extremely controversial.” Oh, is that right? I mean, that&#8217;s what they told me. Let&#8217;s get into it. You’ve made a bunch of announcements here at CES. You&#8217;ve obviously been with Razer for a long time. You founded Razer, and you&#8217;re over 20 years into the job. The gaming industry is undergoing a lot of turmoil lately because of AI. You&#8217;re making huge investments in AI. There&#8217;s a hologram waifu we should talk about that you&#8217;ve introduced throughout the show. I actually wanna start with something very basic. I&#8217;ve been covering CES for about 20 years as well. Razer loves CES. You love CES. We love it. Every year, there is a huge suite of Razer products announced. There are weird projects and concepts. Why are you so invested in CES? Of all the companies, I think Razer has the most consistent enthusiasm for this show in particular. It&#8217;s odd, and we were just talking about it yesterday. It&#8217;s over 20 years at this point in time, and I think we&#8217;ve been at CES maybe 15 years or so. And from the very early days at Razer, I remember Pepcom, a massive hall with a little table there, talking about gaming products. Back then, I think we were probably one of the few, if not the only, gaming equipment providers. It&#8217;s really grown for us. I think what has happened is we have a huge online community, people are very passionate about things that we come up with, what&#8217;s the latest and greatest, and we&#8217;ve really grown this community, and we have all been kind of invested in what we&#8217;re gonna be launching at CES. So it kind of started a couple of years ago when we said, &#8220;Okay, why don&#8217;t we not just bring the stuff that we&#8217;re gonna launch, but some of the things that we&#8217;ve got cooking in the Razer labs and stuff.&#8221; We brought it to CES, it has been a hit, and we said every year, &#8220;Why don&#8217;t we bring more of our concept products? Some of which will come to market, some of which do not, and let&#8217;s see what the community thinks.&#8221; So we&#8217;re a company that is for gamers, by gamers. We really like to hear what the community would like to say about our product, and it gives us an opportunity to present the stuff that we&#8217;ve got, get the feedback, and then we go back and polish it a little bit. Well, I&#8217;m curious. I mean, this is kind of a meta question about how this show in particular has changed so much over the years. The idea of even having a big tech trade show has gone in and out of favor. If you look at where a lot of the action is this week in Vegas, it&#8217;s actually in the Aria and Vdara, where the ad tech people are doing whatever weird stuff they&#8217;re doing. I don&#8217;t even know what&#8217;s going on over there, man. It&#8217;s goofy. This is about getting attention, right? I mean, you launch things at trade shows because the press and creators are here, and you can get a lot of attention. Razer doesn&#8217;t need help getting attention. Why still do it here? Well, it&#8217;s an opportunity, I think, for us also to catch up with our partners, friends, and show a little bit of what we have been working on under the hood. But it&#8217;s been a tradition of sorts. I think the community expects us to be here. I&#8217;d love to see more of these in-person events right now, especially post-pandemic, and what has happened. From a gaming perspective, we&#8217;ve also lost a couple of big events in the year. So it&#8217;s a great way to kind of kick it off. It&#8217;s a little early in the year for us, though. We wish it would be maybe mid-January or something like that. But it&#8217;s a bit of a tradition for us. I hope it continues, I hope it gets bigger along the way, and it&#8217;s massive right now. But it&#8217;s good fun. Do you think you&#8217;re still getting the same amount of attention from this kind of thing as you would if you just had your own events? Well, we have our own events, pretty much, but it&#8217;s a good opportunity just to catch up with partners. I think that&#8217;s been a real opportunity for us. And it&#8217;s also a good opportunity for us to kind of bring the rest of our audience along, from the gaming community, who may not necessarily be keen so much on all tech, but they really wanna see what&#8217;s the latest and greatest in gaming tech. And that&#8217;s what we do. So let me ask you about the announcements here. There&#8217;s an AI headset called Project Motoko. Yes. You&#8217;ve got AI PCs for software developers, which is really interesting. I wanna talk to you about that. And then there&#8217;s Project Ava, which is a spinning hologram. Yes. We&#8217;ve got Madison also, which is a project that we&#8217;ve brought across, which showcases the latest and greatest in immersion technology. We&#8217;ve put it into a gaming chair, so that&#8217;s a setup for games. I can&#8217;t believe I forgot the chair. The most important. Yeah, the chair, it&#8217;s getting a lot of traction. And a whole lot more, and not just hardware, but software. So how do you decide what is going to be a real product you&#8217;re gonna ship? The AI PCs, I think, are real products you&#8217;re definitely gonna ship. That&#8217;s just happening. And then here&#8217;s the concept, just to get attention and feedback. How do you make that kind of choice? Actually, we&#8217;ve got a labs team internally, which charts and pretty much looks at things far out, in terms of the industry, where we think the industry&#8217;s going, and how we can build toward that. In essence, the decision to green-light a project to an actual product is really like, &#8220;Is this cool? Do we think it&#8217;s gonna do well?&#8221; We kind of started with that, with the gaming mouse, right? We very rarely sit down with the finance people and say, &#8220;Oh, do we do projections and things like that?&#8221; It&#8217;s really more of a “by the seat of our pants” kind of thing. It&#8217;s cool, we like it, it&#8217;s gonna be fun, we want it for ourselves. I think the real kind of trigger there is, do we want it for ourselves? And if we really want it for ourselves, and we think it&#8217;s cool, we&#8217;ll bring it to market. Every year, there&#8217;s always some project; some of them come out, some of them don&#8217;t come out. One year, you announced a respirator that got you into a lot of trouble, and you had to recall the product. How do you make the call of, “Okay, this project, it&#8217;s out, it&#8217;s successful, it&#8217;s doing what we want it to do, we&#8217;re gonna keep investing,” versus “this was a one-off.” What&#8217;s the metric of success there? Well, scaling it. I think scaling it is definitely something that we would like to do. And sometimes we&#8217;re really early. For example, I think over a decade ago we built a complete gaming PC in a handheld. For that matter, we brought it to market at the same time. Today, we&#8217;ve seen handhelds out there, and we haven&#8217;t launched our handheld, for example, at this point. Do you have one? We might. We will see. But not today. So you got claps for that already. I think for us, when we launch a product, we look at the attraction for it. You know, is this something that we want? Do we wanna invest in the next generation? Do we wanna kind of provide a roadmap across to it? So we essentially work very closely with the community. We keep talking about “for gamers, by gamers,” but we really believe in that. We&#8217;ve got a really big fan base that’s very passionate. Everyone&#8217;s got an opinion. We love hearing opinions. We&#8217;ve got social media, we chat with them often, so on and so forth. That&#8217;s what really guides us, and we really let the community guide what we build for the future. All right, so now I have to ask you about Project Ava. Sure. Did you say to your team, &#8220;I want a holographic anime waifu on my desk&#8221;? You say that the metric is “what we want.” Who was like, &#8220;I want this&#8221;? Sure. So actually, yeah, somewhat. Well, not so much in the specific words, &#8220;I want an anime waifu,&#8221; and things like that. But we did hack together a holographic projector to have a character there. We had ideas like that in the past, where we&#8217;ve created holographic projectors for game companies. But back in the day, to say, &#8220;Hey, look, is there a way that we can do a holographic representation of some of your latest characters?&#8221; and stuff like that. With AI, we were now able to get that personality there and have conversational AI coming through. I think the tipping point for us was really not just making great hardware, and not just having great software, but also, now with great intelligence, I think, coming out together with it. And it&#8217;s that premise of being able to have a semi-physical representation of an avatar, to me being able to chat, as opposed to clicking a button or typing on something, and having a little thing over there. It&#8217;s really exciting in our imaginations for ourselves, you know? It&#8217;s cool. We&#8217;ve always had that, whether it&#8217;s a game like a super AI in Halo, like Cortana, for example. So it&#8217;s a little bit of sci-fi, us growing up always wanting something cool like that, and so we said, &#8220;Hey, it&#8217;s a great concept,” and I think the community loves it. Are you aware of the very common trope about actually building superintelligence from sci-fi movies? The one that’s “you should not build the Torment Nexus?” Well, for us, I think in this case it&#8217;s more… Well, I&#8217;m familiar with that, of course. [Laughs] Just checking. Yeah, yeah. But, I mean, with the guardrails… That is also, I think, on a broader level, from an AI discussion and things like that, trust and safety is one of the things that we do look at internally at the company. But specifically for Ava, it was just cool. It was just awesome to be able to have a product like that, and hopefully we will. So is Ava going to come out? Because I think that my understanding, or my reaction to this product, changes based on whether it&#8217;s actually coming out or if this is just a concept that people can react to. But you&#8217;re taking pre-orders for it. It&#8217;s like 20 bucks to pre-order it. Yes, we&#8217;re taking reservations for it at this point in time. It seems like it&#8217;s going to come out. We plan to put it out, but we do want to get as much feedback, to hear what the concerns are, right? Are there things that we can do better? What&#8217;s cool? What are the characters that we would like to get on? We&#8217;d also like to get the feedback from many of the game partners, at the same time, to do really specific character models, so on and so forth. And then finally, I think on the trust and safety part, we also wanna make sure that we take that into consideration. Are there things that we need to know? We&#8217;re working with our model partners at the same time. So the model partner with Ava is Grok. Yes. I would say that there&#8217;s a pretty significant disconnect between saying you care about trust and safety and partnering with Grok, which is in the middle of a deepfake porn scandal. As we speak, as we&#8217;re sitting here, Grok is undressing people left and right. I&#8217;m confident that we will be undressed by the end of this podcast. But Grok has the best– Can you care about trust and safety, and also partner with Grok? Well, I think for Grok, you know… We picked Grok also because it&#8217;s got the best conversational AI at this point, for us. At least from a conversation, personality side of things, and that&#8217;s one of the things that we looked at from a tech perspective. Now, ultimately, however, we do see Ava as an open platform, right? If somebody wants to be able to use a different model, it&#8217;s one of the things that we&#8217;re taking into consideration. And we are multi-model, right? But I think from a perspective of an avatar, from a conversational AI for CES, we feel that Grok has a really great conversational AI model at this point. So that&#8217;s one of the reasons why we picked Grok. Grok, also made by Elon Musk, who has his own anime waifu ideas, I would say. There&#8217;s something there that is, you know, not necessarily just trust and safety. The idea that you would have a pet on your desk that looks like a person, that can talk to you, that&#8217;s a big door to open for a lot of people. Are you worried about that at all? Well, the doors have been open since Tamagotchi. I think there&#8217;s a pretty big step difference between… Like my daughter has a Tamagotchi. I&#8217;m never worried that this thing is alive. Right. The Tamagotchi has not driven anyone into psychosis. Sure. But from a virtual perspective, and as a gamer, we&#8217;ve interacted with NPCs and stuff like that. And of course, NPCs are getting smarter with AI, and I do hope they get smarter. It gets more engaging. And I think we&#8217;re still in the early days. Now, the question, I think, where it&#8217;s going to lead to is something that we need to discover, right? And, of course, we need to discover it in a responsible manner to figure out how we do that, and put the right guardrails in. What do we do in terms of AI, in terms of this? That&#8217;s something that we&#8217;re learning. So building great hardware, I think, is part of it. Grok is powering this for us at this point in time, and this is something that we feel, from a conversational perspective, they do an incredible job at. Now, over and above what else can we do to ensure that, ultimately, when we do launch the product, how do we make sure that it&#8217;s going to do the right things and be able to converse and be the great companion that we want it to be? This is very much what I mean by saying I react to it differently when it&#8217;s just a concept, and it opens the door to these conversations, versus you are going to sell this thing to people. And I think when you sell it to people, the responsibility skyrockets. We&#8217;ve all looked at what&#8217;s happened with OpenAI models over the last year or so. People have fallen in love with them. Famously, Bing proposed to journalist Kevin Roose on the front page of The New York Times. People are having relationships with these products. They are being driven to very negative outcomes. Do you think that you have to do something else to make sure that doesn&#8217;t happen with Ava, who will be represented in human-like form on your desk? Like the opportunity to have a relationship is gonna change, right? And from what I have been told, from our reporters, Razer people are saying, &#8220;We don&#8217;t want this to be a companion in that way.&#8221; OpenAI said that about ChatGPT, and yet, here we are. So what have you learned from that already? So we work closely with the model providers. I think this is something that we work closely on with them, with respect to that. We do talk to them often about what the plans are for the future, with respect to this. But I think what is clear is that these are still early days, right? It is still new for us to discover. I&#8217;m sure that there will be concerns or issues that will come about, and evolving what&#8217;s happening for technology is something that we do. Now, maybe it&#8217;s even a hardware lock that we need to put in. We don&#8217;t know, right? Or it&#8217;s more software guardrails that we have to put into place at this point in time. That&#8217;s one of the reasons why we decided to put it as a concept first out there, to get the feedback. And we&#8217;re not gonna be able to think of everything, but we would like to be able to get as much thought, concern, and care into the product before we actually launch it, which is why we&#8217;ve also intentionally, in a very intentional and deliberate manner, said, &#8220;We don&#8217;t know when we&#8217;re gonna launch this.&#8221; We really do not. I would suspect, for us, it will be a phased approach to a certain extent, with dev kits out there first to be able to discover more. Someone&#8217;s gonna be able to do more with it, perhaps, to load up different models and to have it say things that we may not necessarily want it to say, and we&#8217;ll find out. And then, accordingly, we&#8217;ll just grow the product. I understand all this, but you&#8217;re taking the money, right? You&#8217;re taking the pre-orders. Why take pre-orders if you don&#8217;t think you&#8217;re ready? So what we have actually said is that these are reservations. They&#8217;re not pre-orders, per se. So, ultimately, when we do launch the product, and it could be a long way out, by then, because of the specs… We have not disclosed the actual specs of the product, and even, for example, which character models, or even which model it&#8217;s gonna be running at this point in time. We&#8217;re leaving that absolutely open. And of course, at the end of the day, if somebody says, &#8220;Look, this isn&#8217;t the product that I thought it was going to be,&#8221; that’s fine. Cancel the reservation, and we&#8217;ll remain open and see how the product evolves at that point in time. Are you ready for a customer, a few years from now, falling in love with their hologram on your desk that you have provided? I don&#8217;t think that&#8217;s how we would want to design the product. It&#8217;s going to happen. We don&#8217;t know. That&#8217;s what happens with all these tools. I suppose we literally do not know, right? I use the example when I play a game, and I&#8217;m really invested in the game, I really enjoy it, and I feel a sense of loss&#8230; Well, I wouldn&#8217;t call it unhappiness, but loss when I finish a game. But it&#8217;s a great game. I&#8217;m fully invested in a movie, I&#8217;m fully invested in a game. Is that how we see it? Perhaps, right? We want to create products that people care about, whether that&#8217;s a gaming mouse, a laptop, or whatever software platforms. We want people to care about it. I don&#8217;t necessarily think that we want somebody to fall in love with one of our products and marry them. It might happen. Who knows? It could. There are other CEOs who come on this show, they&#8217;re like, &#8220;You should marry my AI,&#8221; and straightforwardly say these things to me. Really? All the time. Okay. The reality is, some people are having their romantic lives rocked because a cloud service got deprecated, and then you&#8217;re gonna have to deal with that. I&#8217;m just saying, these are the questions that are coming for you once you put a character that people can have an emotional relationship with. Well, I would say that potentially that could happen, but that&#8217;s definitely not something we plan to build the product toward. I mean, we have, for example, people really passionate about Razer products, right? Some of them have come to me, and they have said, &#8220;Look, I&#8217;m so passionate about this product, it&#8217;s part of my life. I&#8217;m gonna tattoo the product on myself,&#8221; and things like that. We didn&#8217;t plan to do that. But we did, however, plan to make the best possible product. We put incredible amounts of care and concern, I think, in terms of design. And that&#8217;s what we plan to do with Ava at the same time, or Motoko, or Madison, or any of the products that we bring to the market. One more question on this, and then I&#8217;m gonna ask you the Decoder questions and talk about the rest of your AI investment, which is pretty substantial. You said you&#8217;re working with the model partners, and that is how you&#8217;re thinking about trust and safety. Is xAI a good partner when it comes to trust and safety, as it relates to Grok? Because I&#8217;m looking at the product you&#8217;re shipping today, and I would say, &#8220;No.&#8221; Sure. So I think, and I speak broadly, I think, for all of the partners that we&#8217;ve got. I think for the vast majority of all the models out there, I think there&#8217;s, of course, a lot of focus in terms of intelligence, really trying to get to that point, but trust and safety really is one of the things that pretty much all our partners really do care about. And that&#8217;s one of the reasons why… Each model, I think, excels in different ways at the same time. And I think for us, we really wanna find the best possible model. And ultimately, in what shape or form we ship at the end of the day, that&#8217;s one of the things that we will take into consideration. Is xAI a good partner when it comes to trust and safety? Specifically, I don&#8217;t really like to comment on that at this point in time because I don&#8217;t have enough information, I think, right now. I really don&#8217;t. My focus to date has been more in terms of what&#8217;s the best conversational model that we&#8217;ve got, and they&#8217;re great, they&#8217;re fantastic. Again, I suspect we&#8217;ll be undressed within the next 45 minutes. They&#8217;ve got one idea, and they&#8217;re good at it. Let me ask you the Decoder questions. If you&#8217;ve got a trick, you gotta play the hits, you know? Let me ask the Decoder questions &#8217;cause I think that&#8217;s gonna lead into some of the big investments you&#8217;re making, and the change that&#8217;s coming to Razer as a company over the next few years. You&#8217;re really invested in design. You&#8217;re a product designer, that&#8217;s some of your background. How is Razer structured in a way that lets you stay focused on design? So I focus on product at the company. We&#8217;ve got a really pretty flat structure at Razer. I&#8217;ve got about 40, 50 direct reports. We really work as a team. And the entire company is really focused, I think, in terms of product first. You know, that has always been the mantra for the organization, but we&#8217;ve got a really great team, very talented team members. And everyone has worked together for a while. We&#8217;ve got team members who have been there for the last 20 years together with us, growing alongside us. I would say that the guiding north star for us is just about the gamers. We&#8217;ve been consistent in that respect, despite the fact that in the very early days, gaming or gamers were not considered a big industry or demographic. But we&#8217;ve been laser-focused in terms of that as we&#8217;ve grown. Even with the industry growing at this point in time, the opportunities for us to go like, &#8220;Hey, why don&#8217;t you do productivity at the same time? Why don&#8217;t we go into this other area?&#8221; And stuff like that. We&#8217;ve just said, &#8220;Look, we know what we&#8217;re good at.&#8221; We remain focused on it. We align the team members all the time, and that&#8217;s how we are structured. How many people are at Razer? About 2000. When I say structure, I mean literally organized. Does everybody report to you? Where do all those 2000 people go? No. In the traditional structure, we&#8217;ve got our operations and supply chain. We&#8217;ve got legal, so on and so forth. But we&#8217;ve got a pretty flat, I think, management team structure, and we don&#8217;t have multiple layers from that perspective. And we consistently keep a very single-minded focus to say that, &#8220;Look, the product&#8217;s always the most important. The customer, in our case, the gamer, is always the most important for us.&#8221; And pretty much we ask ourselves the question, right? If there&#8217;s no direction or management mandate when it comes down to this, just figure it out. Like, what would the customer want, what would the gamer want? That&#8217;s what we do. You&#8217;re primarily based in Singapore. I know you come back and forth a lot. Where is most of the company based? Well, we&#8217;re everywhere. A third of our business is in the US, a third in Europe, and a third in Asia at this point in time. So we&#8217;ve got team members spread out. We&#8217;ve got close to 20 offices worldwide. We&#8217;re dual headquartered in Irvine and Singapore. When I think about the market of gamers, we&#8217;re here, obviously, in the United States. It&#8217;s very obviously focused on what this market wants. Gaming is growing in China at a high rate, right? We&#8217;re adding more gamers in other places. When you say, &#8220;We&#8217;re focused on the gamers,&#8221; the gamers in different regions want different things. How do you make those decisions? How do you decide which needs are gonna drive your roadmaps or your design ideas? Exactly that. You know, the gamers from, or the needs from, every country or region that we&#8217;ve got… We&#8217;ve got team members from design in each of the various regions, and we do focus on pretty much two constituents, the way that we see it. The first of which would be the game developers. That&#8217;s who we work with, very closely with. And then on the other end of the spectrum, we&#8217;ve got the gamers. And what we do is focus on what the gamers want, what the game developers want, and we see ourselves as the link in between. And we keep both as happy as we can. This brings me to the other Decoder question I ask everybody on the show. How do you make decisions? Do you have a framework? Do you have an organized way of making decisions? I think we are dictated by what we feel the customer wants. That&#8217;s what dictates our decisions at any point in time. We talk to the gamers, and when we say “talk to the gamers,” it could be directly through social media, it could be through our customer base, it could be through our sales and marketing team, and things like that. And anecdotally, we figure out, is this what we want? And if this is something that they are keen or passionate about, we then make the decision to say, &#8220;Okay, cool.&#8221; And we have a very quick, flexible, and… We&#8217;re very nimble, I would say, at Razer, wherein we try to do as little as possible, but to scale as fast as possible just for our customer base. This is gonna lead me to the big decision. You have announced you&#8217;re investing $600 million into AI over the next few years. You&#8217;re gonna hire 150 AI engineers, I think. The gamers hate it. The gamers, I think, are in open revolt against AI coming into their games, into their platforms. Certainly, developers are very worried about what&#8217;s gonna happen to software development. We&#8217;ve seen game studios rocked by AI. That&#8217;s a pretty big disconnect. Even, I think, in the announcement of the CES tag line for Razer at CES, which is, &#8220;AI is the future of gaming.&#8221; I looked at the Instagram comments. If you&#8217;re listening to the gamers, you&#8217;d be like, &#8220;Well, we&#8217;re done with this.&#8221; How are you reconciling that gap? So, I would say that the question is, “What are we unhappy with?” When I say we, I mean us as gamers. I think we&#8217;re unhappy with generative AI slop, right? Just to put it out there. And that&#8217;s something that I&#8217;m unhappy with. Like any gamer, when I play a game, I want to be engaged, I wanna be immersed, I wanna be able to be competitive. I don&#8217;t want to be served character models with extra fingers and stuff like that, or shoddily written storylines, so on and so forth. I think for us, we&#8217;re all aligned against gen AI slop that is just churned out from a couple of prompts and stuff like that. What we aren&#8217;t against, at least, from my perspective, are tools that help augment or support, and help game developers make great games. And I think that&#8217;s fundamentally what we are talking about at Razer, right? So if we&#8217;ve got AI tools that can help game developers QA their games faster, better, and weed out the bugs, I think, along the way, we&#8217;re all aligned, and we would love that. If we could get game developers to have the opportunity to create better, to check through typos and things like that, to create better games, I think we all want that. So I think that&#8217;s the way that we see it. One of the things that we&#8217;re building, for example, at Razer is what we call a QA companion. So QA tends to be an expensive endeavor. Like the gamer doesn&#8217;t see it at the end of the day, but it can take up like 30 to 40 percent of the cost, or delay games for the longest time. Now, what we&#8217;ve done is create a companion, a tool that works with the human QA tester to be able to automatically fill in forms, to say, &#8220;Okay, if this is…” Say the form is a Jira ticket, to say “this is a bug that is identified, there&#8217;s a graphical bug, there&#8217;s a performance bug.” All that&#8217;s logged very quickly, so it&#8217;s sent to the developer at the same time. The developer then can go in and say, &#8220;Okay, this is how I&#8217;ll fix the bug,&#8221; or, &#8220;These are suggestions on how I fix the bug.&#8221; The way that we see it is that AI is a tool to help game developers make better games. In this case, rather than replacing human creativity — and that&#8217;s something I personally feel very passionately about — we want to figure out how we use AI in the gaming industry to get AI to do things better. In the broader scheme of things, I think that&#8217;s what we have been focused on. But there are other reasons why I think gamers are unhappy with AI, and I agree with them. I don&#8217;t like slop either, right? That&#8217;s one. Two, is it raising the cost of RAM? It is also raising the cost of RAM. I don&#8217;t like that at the same time. Back in the day, there was the GPUs versus crypto situation and things like that, and this is the same thing. So I do think, however, that all gamers would love better games, more fun games, more engaging games, and if AI can help create that by doing better QA, I mean, I&#8217;m all for it. I want to poke at that a little bit harder, but let me just ask you: is Razer feeling the RAM crunch and the GPU crunch like everybody else? Oh, yes, absolutely. Because we make laptops and things like that. How badly has that affected you? I mean, we haven&#8217;t announced the prices for the next round of laptops, for example, and this is something that concerns me because the RAM prices are going up, and we want to be able to make sure our laptops remain affordable and within the reach of gamers out there. But it has been moving. It is such a volatile situation at this point in time that it&#8217;s hard for us to even figure out what the pricing is at this junction. Do you think you&#8217;ll be able to pick a number and be confident in that number by the time the laptops have to come out? I don&#8217;t know if I can pick a number right now as I speak with you, and by the end of the podcast. Yeah, that&#8217;s bad. It is bad. It is bad right now. You have competitors in the PC industry like Apple, Microsoft, and others. They can move their margins around. They have services, businesses, and stuff that attach to these laptops. Maybe they&#8217;ll take a hit on the RAM because you&#8217;re gonna have to pay for iCloud for the rest of your life, or whatever it is you&#8217;re gonna do. You don&#8217;t have that kind of secondary business. Is that more of a danger to you? Well, we do have a secondary business of sorts. So hardware is a big part of our business. We actually have a services payments business where we do payments for a lot of the game companies out there, and that&#8217;s one of the strategies that we use to try to make our products more available to everyone. That&#8217;s the way that we kind of see it. We are an ecosystem of sorts. We do great hardware, I think, for game developers and the gamers out there. But we&#8217;ve got a software platform that we are able to bring across to all the gamers out there. And of course, it’s a services business at the same time. But the RAM situation, at the end of the day, is still an evolving situation right now. Do you think it will cap out, and do you think we&#8217;ll have enough data center capacity, and things will go back to normal? I wish I knew. I really don&#8217;t. Is there a point at which the price of RAM, or the price of a marginal Nvidia GPU, becomes too high for you to sustainably do laptops at your scale? I would say I&#8217;m hoping that it doesn&#8217;t come to that, right? I think, in short, we&#8217;ve seen this happen with the industry multiple times in the past, spiked in terms of pricing. What&#8217;s great is that as long as manufacturing kicks in, and we are able to kind of keep up, it&#8217;s just economics at the end of the day. There is a spike in terms of pricing. We believe that at some point it will come down. What goes up must come down, and what goes down at some point goes up, too. Let me come back to what you&#8217;re saying about AI and development. AI is the future of gaming. You&#8217;ve announced products here, and we&#8217;ve talked about Ava, the headset with the cameras and the AI stuff in it. That’s consumer AI products, right? Those are consumer products. And you&#8217;re saying your bet is on AI helping developers make better games faster. There&#8217;s a gap there, right? AI is the future of gaming is an all-encompassing tag line. It means a lot of things to a lot of people, but it sounds like your bet is very specifically in sort of the more enterprise side of the house, helping developers do games better. Is it correct that it&#8217;s much narrower than what people are perceiving? Well, I think the tag line&#8217;s very broad, but it&#8217;s easier to do a catchier tag line when it&#8217;s a broad tag line, as opposed to when it’s hardware we look at or software and stuff like that. But in short, for us, we run an ecosystem. We&#8217;ve got hardware, we&#8217;ve got software with services. Starting with the hardware, I think we do see that AI is going to be part of the whole kind of conversation. The way that we look at it would be things like whether it&#8217;s AI companions, or whether it&#8217;s making smart headphones, like with Motoko. We see all of this as augmenting what&#8217;s happening today, not replacing it. So it&#8217;s not a gen AI conversation that we&#8217;ve got. It&#8217;s about how we bring the smarts, where we design products, and how we bring additional value to our users. For example, using our gaming headphones, all of a sudden, we can provide additional AI capabilities. Is that great? Absolutely. So, that&#8217;s one of the things that we&#8217;re looking at from a hardware perspective. Now, from a software and services perspective, as we work with the game developers and publishers, and so on and so forth, we look at additional tools that can make their games better. We can work closely with them on a QA companion basis, for example. And then some of these core technologies, as we provide for them, can then make better games, over and above. So I believe that at some point, it&#8217;s not just games, but AI is just gonna be so prevalent or ubiquitous that every single vertical, healthcare, gaming, and entertainment, is gonna have some elements of AI there. And we are just going along with it. I&#8217;ve heard this pitch a lot, and I have a lot of reactions to it. But I guess the simplest way of asking this question is, what have you seen that makes the bet worth it? Because I&#8217;ve evaluated a lot of these AI products, the merch team has reviewed a ton of them. We have literally just tried to do the things that Microsoft says you can do in the ads, and the products don&#8217;t work. Right? There&#8217;s this massive gap between what everyone says is gonna happen, or should be happening, and what is actually happening in the products. You know, to be a cynic about it for the sake of getting a laugh out of this audience, I will tell you the products are best at convincing you that you should love them, and doing crimes, and they&#8217;re not so good at identifying what&#8217;s on your screen and helping you get a task done. They are really good at that in the domain of software development, right? I can see why you&#8217;re pushing there with game developers. It&#8217;s obvious that Claude Code has ushered in some kind of revolution, and Cursor has ushered in some kind of revolution. In your vertical, you have something to offer that is different. But in the broad sense, this belief that it&#8217;s all just gonna happen, I think, has come up against the reality of what the products can do today. So what have you seen that suggests we will overcome that gap that makes you so confident? Well, occasionally I go on podcasts where the guy is more concerned that someone&#8217;s gonna fall in love with my product in the long run. And I think maybe there&#8217;s something there. No, but you see, it&#8217;s early days. It could completely be the worst possible idea. It could completely go off the rails and become off the spectrum, where it&#8217;s just the most phenomenal product that somebody completely falls in love with, so on and so forth, right? And I think the reality is gonna be something in between. The way that we see it, it&#8217;s probably closer to bringing more value to people, and that&#8217;s what we want to be able to do. We want to be able to get to the point where AI is going to be helpful to all customers, all users. And that&#8217;s also one good example where, at CES… I was just looking at some of the stats, and they said, &#8220;What&#8217;s the biggest buzz at CES?&#8221; And there were a lot, like Ava, Motoko, and things like that. And for what it&#8217;s worth, we&#8217;ve literally just put vision capabilities, audio capabilities on a headphone, and combined it with AI. It&#8217;s not a quantum leap from a hardware design perspective, but it has captured so much imagination at this point in time. People are going, &#8220;Oh, wow. Now I can bring AI on the go with me at any point in time.&#8221; It&#8217;s truly something revolutionary at this juncture. So the way that we see it, and maybe that&#8217;s something that– Wait. Yeah. Can we just hit pause on that? What specifically do you think is revolutionary about having the AI and the cameras in the headphones with you all the time? Well, I would say that, first off, we are really looking at being able to have an unobtrusive universal form factor to enable AI smarts. I think the whole industry is looking for this one factor, right? This is like when I hear about the platform shift, you suddenly had this massive input device paradigm shift, right? We&#8217;re going from touchscreens or mice to voice and vision. I get that. No one has sorted out that form factor, so your bet is headphones. Our bet is on headphones in the sense that we don&#8217;t necessarily have to retrain human beings as a whole with an entirely new form factor. And so I don&#8217;t have to change any behavior of sorts. Boom, tomorrow we can get you AI smarts immediately. And that, I think, is the promise. There&#8217;s a disconnect today with the possibility of AI and what it could be, and that&#8217;s where we see ourselves as designers, having that responsibility, or the opportunity, so to speak, to be able to design in such a way that we don&#8217;t necessarily have to change the entire behavior. For what it&#8217;s worth, in the very early days, it could be, for that matter, a mouse. It&#8217;s just a mouse. Why is a mouse so important that today we&#8217;ve brought it from a mouse all the way to a gaming mouse, and now the gaming mouse is a broader category than productivity, right? Gaming mice right now dominate the mouse category at this point in time. And right now, we can call it a smart headphone, and that&#8217;s the way we see it. We don&#8217;t necessarily have to retrain everybody to say, &#8220;Oh, you&#8217;ve gotta put on glasses. You&#8217;ve gotta be able to bear with the weight,&#8221; and things like that. So that is one of the things that we&#8217;re doing with Motoko, and a lot of the work that we do is actually on the software side of things, right? How do we ensure that we get context faster? How do we ensure that we are able to do all of that? So it&#8217;s both hardware/software fusion and a sense of fusion at the same time, that we are really focused on in terms of bringing the experience over. That&#8217;s something that we believe is the reason why people go, &#8220;Oh, I absolutely get it, right now, why I would want something like that.” So the model in the Motoko that I saw is ChatGPT. It is ChatGPT. Why&#8217;d you pick ChatGPT for the headphones and Grok for Ava? So, ChatGPT for the headphones was primarily more from the premise that we think it&#8217;s a good assistant, in terms of CV capabilities, identifying things, and being able to give very quick feedback at the same time. But it could very well run Grok also at the same time. And the way that we are kind of presenting this is that whether it&#8217;s for Ava, or whether it&#8217;s for Motoko, or any of our other products, we are multi-model. That was one of the things that we wanted to be able to do. We believe that at some point in time, you see Gemini doing really well. We see Grok doing really, really well. We see ChatGPT having advances in various aspects. This race to intelligence is just great for all of us as consumers, right? When I mention that Grok has great conversational AI, I think it is the best for conversational AI at this point in time. ChatGPT&#8217;s doing great, I think, in terms of it as an assistant, for reasoning and things like that. And that&#8217;s what we see ourselves. We see ourselves as owning the vertical from a gaming perspective, being able to work with all the best intelligence or the AI out there, and then bringing and designing a product or service tailored for our users, and within the gaming vertical. So the vision is that I&#8217;m wearing headphones that have cameras, microphones, and speakers. I&#8217;m walking through the airport, and I&#8217;m just asking it, &#8220;Where is my gate?&#8221; and it&#8217;s telling me the answer from ChatGPT. Or is it more that I&#8217;m sitting at my desk playing a game and it&#8217;s helping me through the game? All of the above. You can literally do that with Motoko at this point in time. But this is what I mean about the capability gap. I think if I walk through the airport and I ask ChatGPT where my gate is, it would not get that right at this point in time. Like, there&#8217;s a model capability gap there. I believe that if you use ChatGPT today and you&#8217;re providing snapshots with some context, like, let&#8217;s say, location, to a certain extent, you could. I would be messaging on my phone with ChatGPT, for example, and it could give me the reasoning to be able to bring me there, to a great extent. I’ll give an example, right? I would literally use ChatGPT for a whole bunch of day-to-day tasks and stuff like that. It&#8217;s got great reasoning; it&#8217;s able to do that. And now we are layering on vision capabilities, and that&#8217;s just another level of input. Over and above, we&#8217;ve got far-field microphones. So audio capabilities also come to bear. With all of this, we&#8217;re able to give a lot more information across to ChatGPT, which does all the reasoning, I think, for us. And that&#8217;s where we see it coming through. So constantly, the smart or intelligence is part of how we see us designing AI hardware, at this point in time. It seems like you have a pretty big reliance on the models themselves, right? You&#8217;re obviously not training your own models. You wanna be multi-model, you wanna let people choose. Are you thinking of yourself more as being the best at the hardware, the form factor, and having the best microphones and cameras, and that will let people use the models more conveniently? Well, we are an ecosystem, but I think for gamers. It&#8217;s not just, I think, in terms of the hardware, but most of our work is actually done at the software side. If I use CES as an example, if I&#8217;ve got Ava, when I wake up, it&#8217;s giving me information like what&#8217;s happening in the day and what my day is gonna be today, so on and so forth. When I get out of my apartment, and I go out into the street, to the subway, et cetera, then I&#8217;ve got Motoko at the same time. But with persistent memory, it will know exactly what has been happening in the home. Ava is somewhat following me everywhere in my day. I&#8217;m not gonna fall in love with it yet. But in short, it&#8217;s following my day, I&#8217;m going around, I&#8217;m looking at it, I&#8217;m asking for directions. When I get to the office, I could literally still be with Motoko, which is another form factor. So the way that we see it is that the intelligence is persistent, and it follows you. The form factors that are presented are hardware form factors. It’s a little bit like how we&#8217;ve designed our product at this point in time. We have a singular software platform where we are able to give you a great gaming experience, over and above. You could be using one of our mice, our keyboards, and so on and so forth, a laptop. These are just representations, at the end of the day. And that&#8217;s how we designed it, and there are particular problems that we need to solve that the models don&#8217;t provide for us. You know, context. So that&#8217;s one of the things that our AI scientists do really well. We&#8217;ve got advanced retrieval augmented generation (RAG), we&#8217;ve got context, and we really focus on that. Persistent memory is something that we are very good at, at the same time. And these are fundamental problems that AI scientists need to solve. These are the things that our team does, so we work with the best models out there. And we also have the capabilities of creating physical representations, and that&#8217;s something that we&#8217;ve got a huge advantage at. Doesn&#8217;t a lot of the value here just accrue back to these models? And yet, even if you&#8217;re building all this stuff above the models and around the models to make them work the way you want, it seems like, “Okay, my Ava is gonna be powered by ChatGPT no matter what.” If I want that unified experience, I&#8217;m just kind of, at the end of the day, talking to an instantiation of ChatGPT all day long, right? Because then I have Grok over here and ChatGPT in the headphones, you can&#8217;t unify that. So at the end of the day, it&#8217;s all Gemini, or whatever model I choose. So, can you provide enough value to charge a premium on top of the ChatGPT subscription to make that work? So that&#8217;s, I think, where our angle is, from the software perspective. We believe that we can bring enough value of persistence across to the user, and progressively we will see even more users who will say, &#8220;Look, this is what I want, to be able to go from one model to another,&#8221; for example. Or if I&#8217;m happy with just a single model, and if I&#8217;m a techie and I&#8217;m happy to just go directly and play around with it, we provide that open platform. So being open is one of the things that we truly believe in. One of the things you notice when you cover AI enough is the idea that the AI startups are just wrappers on OpenAI, and then eventually OpenAI will just eat them as the models get more incapable. We&#8217;ve seen that play out already a little bit. You obviously have hardware. Razer&#8217;s a different business, but you can see that dynamic here, where the core model capability might start to get the memory you&#8217;re talking about, where the core model capability might start to get the persistent personality across devices that you&#8217;re talking about. OpenAI is making hardware, we are told. There&#8217;s a competition with the core provider that is coming in different dimensions. How are you thinking about that? Well, I think the entire tech industry has always been wrappers, for that matter, not necessarily from an AI perspective, but it&#8217;s the question of when you build a wrapper, do you provide enough value from the wrapper that you build? And that&#8217;s the thing, where it&#8217;s also very hard for anyone to be all things to all people. And I don&#8217;t think OpenAI wants to be all things to all people. I don&#8217;t think Grok wants to be all things to all people. For us, we tend to be very focused on our vertical. We are not tempted to try to produce something else different at any point in time. And our vertical is really for the gamers. This is something we&#8217;ve got huge domain knowledge in terms of what the gamers want, what the game developers want. We&#8217;ve got distribution; we&#8217;ve got about 70,000 game developers using our SDK. We&#8217;ve got 150 million gamers on our software platform. We&#8217;ve got distribution, I think, across to that. Can the models go out there and try to build the distribution? Yes, but do they prefer to partner? And I think the answer is they do prefer to partner. Fundamentally, we have a huge amount of data, I think, on the gamers, their preferences, what they want, what they like, and that we can bring that across to the models at the same time, which is our IP, for that matter. I think with that in mind, as I say, having all these verticals, you may call it building wrappers of sorts, but these are very deep wrappers that we have to build. A lot of customization, a lot of building, and it&#8217;s more than just hardware, right? It&#8217;s not hardware. As I say, the hardware is just part of the equation. It&#8217;s the software part that we need to do. It&#8217;s the R and D work that we need to do, for example, to get persistence in this space and context. So to get the context for our users, that&#8217;s where our data comes in at the same time, to be able to kind of pivot and focus on that. I think one of the reasons people like companies like Razer, and like dealing with products that Razer makes, is that you just buy them and you&#8217;re done. Like you can just buy the mouse, and then you own it, and it&#8217;s fine. You can just buy the laptop. I&#8217;m not in an ongoing subscription relationship with you, unless I want to be. Sure. One of your competitors, Hanneke Faber from Logitech, came on the show a year or two ago, and she was like, &#8220;I wanna build a forever mouse,&#8221; and what she meant was a subscription mouse, and she&#8217;s never coming back on the show again, I think, based on the reaction to that. That&#8217;s my understanding of how they felt about that interview. All the things you&#8217;re talking about are ongoing relationships, ongoing development costs. I hear it, and I hear the promise. I also hear, &#8220;I&#8217;m gonna have to pay a fee every month.&#8221; Like this is where that comes from. You need to pay the developers, you need to pay for cloud uptime to make the AI system alive. How much are you gonna charge for all of that? Well, we&#8217;ve always had an ongoing relationship with our customer. That&#8217;s the thing, right? The way that we see it from Razer is that when somebody buys a Razer mouse, they tend to buy another Razer mouse in the future. They expand the devices that they own from us. So we&#8217;ve always had a long-term relationship with our customer, from that perspective. At some point in time, as we think through the whole AI uptime, so on and so forth… I mean, we&#8217;ve had cloud costs also in the past, maintaining profiles in clouds. For us, I think that&#8217;s one of the things that we want to figure out. What can we do to ensure that we bring value? I think that&#8217;s our obsession. If there is no value, our customers won&#8217;t pay for it, we won&#8217;t pay for it ourselves, right? So to that end, that&#8217;s our focus, I think, in respect of it. And it could be through… We build into the hardware cost, for that matter, if that makes sense, and I&#8217;ll be candid: We have literally not thought through this in great detail. But the way that we see it is, how do we identify that value to the user? And from there we are very clear, we message this. This is the value that we see out of this, and we&#8217;ll let the market decide. I look at that reaction from gamers, probably, to AI in the industry. There&#8217;s slop. I think there&#8217;s a lot of reaction to slop, and there&#8217;s a lot of reaction to game studios being in whatever amount of crisis the game studios appear to be in. There’s whatever reaction to consolidation. And then there&#8217;s the relentless fee seeking from the games industry, that everything is gonna be a subscription, everything is gonna be free to play with DLC, everything is gonna be an ongoing, recurring cost, over and over and over again. The industry&#8217;s really moved to that model across the board, and I think people are feeling that pain. So then they hear AI, and they say, &#8220;Okay, someone else is gonna ask me for 10 bucks a month, or 20 bucks a month.&#8221; Can you avoid that? Can you just price it into the hardware? Is that going to be inevitable? So, as I mentioned, I don&#8217;t know if we&#8217;re gonna price it into the hardware. We are still figuring it out. But I would say that, at the end of the day, the question is how much value are you getting on it, right? I mean, I pay for Spotify because I see the value in paying for Spotify. I get a whole library of music, and so on, and with Xbox Game Pass, so on and so forth. There are times when I would prefer&#8230; I mean, I look back, and I go like, &#8220;Oh, I wish I could just pay one time for this title.&#8221; There are microtransactions, there are subscription fees. But at the end of the day, I think, myself as a consumer, myself as a gamer, I would say… I would just look at anything. I would say if it&#8217;s worth that amount of money to me, I would pay for it. Otherwise, I&#8217;ll vote with my wallet. That&#8217;s the way I see it. Are you seeing signs that the AI stuff is gonna be worth paying for that way? I mean, this is the bubble. We&#8217;re gonna spend all this money, we&#8217;ll forward invest in all this infrastructure. We&#8217;re gonna skyrocket the price of RAM and GPUs, and then at the end of the day, people are going to say, &#8220;That&#8217;s not actually worth the 20 bucks a month.&#8221; I don&#8217;t necessarily see it as AI, per se, but I see the kind of value that I get out of it. So, for example, a ChatGPT subscription, or a Grok subscription, for that matter. I do see value in it, and that&#8217;s why I pay for it. And that&#8217;s the way I see it. I don&#8217;t see myself as paying for AI, per se. I see it as what am I getting out of a chatbot, for example, that can advise me on travel matters, health matters, whatever it is, my day-to-day, and stuff like that. Is that worth 20 bucks to me? Because you&#8217;re a billionaire, right? Sure. I&#8217;m just saying, the marginal cost is meaningless to you. 20 bucks is still 20 bucks, that&#8217;s right. I&#8217;m just saying. Right. I think for a lot of people, that is meaningful, especially stacked on top of all the other money they pay. Basically, I&#8217;m saying, do you see that critique of AI as a bubble? That the investment has not yet delivered the value that will make it so obvious that the investment&#8217;s worth it? So I see that. I mean, huge amounts of investments are going into it. We are investing in AI, I think, as we speak. But I do see the potential at this point. In many cases, I mean, look at the number of paid subscribers for ChatGPT, for example. People do see the value in terms of whether it&#8217;s a chatbot AI, so on and so forth. I do think the potential is going to be realized. Now, in many cases, I think there will be AI slop. I mean, I&#8217;ve paid for subscriptions that, at the start, I thought were gonna be great, but I&#8217;ve canceled them. But I do believe that in many cases, and in some cases that we have not even envisaged yet, the potential will be realized. Let me ask you broadly, I mean, you obviously talk a lot to game developers. You and I actually were just talking backstage about the nature of art in the age of AI, and the nature of craft. That industry is going through an enormous amount of turmoil right now. What do you think the outcome looks like? What do you think makes that all feel good at the end? I would say that the outcome that we see, and I think it&#8217;s gonna be the likely outcome, is that AI tools are gonna be helping human developers develop faster and better. And I think that&#8217;s the natural outcome, where we&#8217;re talking about graduating, whether it&#8217;s an analog kind of way of creating art versus digital. And I think it&#8217;s gonna be the same thing. We&#8217;re going to see human artists use AI tools to kind of really bring their vision to life. We&#8217;ll see new forms of artists, artists of whom may not necessarily have been so adept in terms of using a paint brush or using Photoshop, now being able to kind of wordsmith and craft great pieces of art with prompts throughout. So that&#8217;s, I think, what&#8217;s going to happen, where we will see even more human creators, now with the help of more tools. Maybe I&#8217;m an optimist, but I really, truly see that AI tools will come to fall, because at some point in time, we&#8217;re going to see so much slop out there that we&#8217;re going to crave for really great art, really great design. And that&#8217;s what&#8217;s gonna happen. We&#8217;ve seen a cycle go over and over and over again. So, with the amount of slop out there, we&#8217;re going to see some level of art rise to the top, and that kind of art may still be created with the same tools that created the slop, but with great care, with great discernment, to be able to do something truly different. The difference will come from human ingenuity, not from countless prompt mashing, so to speak. So I feel like I have to ask you this now. What games are you playing right now? Oh, it depends. What meets the bar? What meets the bar? I play a lot of single-player games at this point in time, like Civilization and stuff like that. I still do a lot of that. I do play some MMOs of sorts, shooters, and I still play a lot of the battle royale genre. So things like that. You just named genres. What games are you playing that meet the bar? That meet which bar? You&#8217;re talking about human ingenuity and creativity. What games are you playing right now that meet the bar? Oh, well, I play random stuff. If you&#8217;re talking about human ingenuity… I even play some of the Roblox games at this point in time, right? But a lot of the games, and maybe I talked broadly in terms of genres primarily because I appreciate the human ingenuity that&#8217;s gone into the genres themselves. One hundred people dropped on an island with a circle that comes through. I mean, while I enjoy the game itself, I also appreciate the mechanics, the thought that has gone into them, and the premise that the designer has figured out. In PUBG, for example, it&#8217;s this primal instinct of humans to be the last man standing, so to speak. So it&#8217;s things like that that I appreciate, and I think it’s art. Okay. What&#8217;s next for Razer? What should people be looking for? More of the same, I would say, in the sense. When I say more of the same, I&#8217;d say nothing has changed from day one for us, and that has always been our mantra. And we used to say, all the time, that the mantra for us… Our “for gamers, by gamers” mantra has really followed us from day one, where the gaming industry didn&#8217;t really exist as an industry, even the hardware industry or software, and so on and so forth. We believe that we&#8217;ve designed products for ourselves that we enjoy, that I enjoy using at any point in time, and that tomorrow, when the gaming industry grows dramatically, we will still be focused on games. Even though there are multiple opportunities for us to kind of expand out there. And even now, when we talk about the gaming industry in somewhat of a doldrums at this juncture, I believe that we&#8217;re gonna see the next great genre come through, right? Whether it&#8217;s MMOs in the early days, MOBAs, and then battle royales, we&#8217;re gonna see the next great genre. We&#8217;re hoping to see Grand Theft Auto VI at some point in time, right? So all that, we look forward to, but we&#8217;re just pretty much laser-focused. It&#8217;s just that the demographic has really changed. The word gamer has also changed through the years. The games have changed through the years, right? For us, we&#8217;re just sitting here, very focused, and designing great products for ourselves. Min, this has been great. Thank you so much for joining us on Decoder. Thank you. Questions or comments about this episode? Hit us up at decoder@theverge.com. We really do read every email!",
          "feed_position": 4
        }
      ],
      "featured_image": "http://www.techmeme.com/260119/i23.jpg",
      "popularity_score": 2018.9820402777777
    },
    {
      "id": "cluster_2",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 22:01:52 +0000",
      "title": "NASA’s Artemis II rocket rolls to launch pad, but key test looms ahead",
      "neutral_headline": "NASA’s Artemis II rocket rolls to launch pad, but key test looms ahead",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasas-artemis-ii-rocket-rolls-to-launch-pad-but-key-test-looms-ahead/",
          "published_at": "Mon, 19 Jan 2026 22:01:52 +0000",
          "title": "NASA’s Artemis II rocket rolls to launch pad, but key test looms ahead",
          "standfirst": "After a remarkably smooth launch campaign, Artemis II reached its last stop before the Moon.",
          "content": "KENNEDY SPACE CENTER, Florida—Preparations for the first human spaceflight to the Moon in more than 50 years took a big step forward this weekend with the rollout of the Artemis II rocket to its launch pad. The rocket reached a top speed of just 1 mph on the four-mile, 12-hour journey from the Vehicle Assembly Building to Launch Complex 39B at NASA's Kennedy Space Center in Florida. At the end of its nearly 10-day tour through cislunar space, the Orion capsule on top of the rocket will exceed 25,000 mph as it plunges into the atmosphere to bring its four-person crew back to Earth. \"This is the start of a very long journey,\" said NASA Administrator Jared Isaacman. \"We ended our last human exploration of the moon on Apollo 17.\"Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_0127-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_0127-1-1152x648.jpg",
      "popularity_score": 356.6792625
    },
    {
      "id": "cluster_13",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 19:04:18 +0000",
      "title": "Elon Musk accused of making up math to squeeze $134B from OpenAI, Microsoft",
      "neutral_headline": "Elon Musk accused of making up math to squeeze $134B from OpenAI, Microsoft",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/elon-musk-accused-of-making-up-math-to-squeeze-134b-from-openai-microsoft/",
          "published_at": "Mon, 19 Jan 2026 19:04:18 +0000",
          "title": "Elon Musk accused of making up math to squeeze $134B from OpenAI, Microsoft",
          "standfirst": "Musk's math reduced ChatGPT inventors' contributions to \"zero,\" OpenAI argued.",
          "content": "Elon Musk is going for some substantial damages in his lawsuit accusing OpenAI of abandoning its nonprofit mission and \"making a fool out of him\" as an early investor. On Friday, Musk filed a notice on remedies sought in the lawsuit, confirming that he's seeking damages between $79 billion and $134 billion from OpenAI and its largest backer, co-defendant Microsoft. Musk hired an expert he has never used before, C. Paul Wazzan, who reached this estimate by concluding that Musk's early contributions to OpenAI generated 50 to 75 percent of the nonprofit's current value. He got there by analyzing four factors: Musk's total financial contributions before he left OpenAI in 2018, Musk's proposed equity stake in OpenAI in 2017, Musk's current equity stake in xAI, and Musk's nonmonetary contributions to OpenAI (like investing time or lending his reputation).Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2087343447-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2087343447-1024x648.jpg",
      "popularity_score": 345.71981805555555
    },
    {
      "id": "cluster_4",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 21:07:55 +0000",
      "title": "The first new Marathon game in decades will launch on March 5",
      "neutral_headline": "The first new Marathon game in decades will launch on March 5",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/bungies-delayed-marathon-revival-will-finally-launch-march-5/",
          "published_at": "Mon, 19 Jan 2026 21:07:55 +0000",
          "title": "The first new Marathon game in decades will launch on March 5",
          "standfirst": "Development hasn't exactly been smooth since the extraction shooter's 2023 announcement.",
          "content": "It's been nearly three years now since Destiny maker (and Sony subsidiary) Bungie formally announced a revival of the storied Marathon FPS franchise. And it has been about seven months since the game's original announced release date of September 23, 2025 was pushed back indefinitely after a reportedly poor response to the game's first Alpha test. But today, in a post on the PlayStation Blog, Bungie revealed that the new Marathon would finally be hitting PS5, Windows, and Xbox Series X|S on March 5, narrowing down the month-long March release window announced back in December. Today's pre-rder trailer revealing the Marathon release date. Unlike Destiny 2, which transitioned to a free-to-play model in 2019, the new Marathon sells for $40 in a Standard Edition or a $60 Deluxe Edition that includes some digital rewards and cosmetics. That mirrors the pricing of the somewhat similar Arc Raiders, which recently hit 12 million sales in less than 12 weeks.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/marathon-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/marathon-1152x648.png",
      "popularity_score": 340.78009583333335
    },
    {
      "id": "cluster_10",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 19:52:22 +0000",
      "title": "Signs point to a sooner-rather-than-later M5 MacBook Pro refresh",
      "neutral_headline": "Signs point to a sooner-rather-than-later M5 MacBook Pro refresh",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/signs-point-to-a-sooner-rather-than-later-m5-macbook-pro-refresh/",
          "published_at": "Mon, 19 Jan 2026 19:52:22 +0000",
          "title": "Signs point to a sooner-rather-than-later M5 MacBook Pro refresh",
          "standfirst": "Delayed shipping times for current models sometimes means an update is imminent.",
          "content": "Mac power users waiting on new high-end MacBook Pro models may have been disappointed last fall, when Apple released an M5 upgrade for the low-end 14-inch MacBook Pro without touching the M4 Pro or Max versions of the laptop. But the wait for M5 Pro and M5 Max models may be nearing its end. The tea-leaf readers at MacRumors noticed that shipping times for a handful of high-end MacBook Pro configurations have slipped into mid-to-late February, rather than being available immediately as most Mac models are. This is often, though not always, a sign that Apple has slowed down or stopped production of an existing product in anticipation of an update. Currently, the shipping delays affect the M4 Max versions of both the 14-inch and 16-inch MacBook Pros. If you order them today, these models will arrive sometime between February 3 and February 24, depending on the configuration you choose; many M4 Pro versions are still available for same-day shipping, though adding a nano-texture display or upgrading RAM can still add a week or so to the shipping time.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_6215-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/IMG_6215-1152x648.jpeg",
      "popularity_score": 329.5209291666667
    },
    {
      "id": "cluster_21",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 17:16:38 +0000",
      "title": "Reports of ad-supported Xbox game streams show Microsoft's lack of imagination",
      "neutral_headline": "Reports of ad-supported Xbox game streams show Microsoft's lack of imagination",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/reports-of-ad-supported-xbox-game-streams-show-microsofts-lack-of-imagination/",
          "published_at": "Mon, 19 Jan 2026 17:16:38 +0000",
          "title": "Reports of ad-supported Xbox game streams show Microsoft's lack of imagination",
          "standfirst": "Xbox maker needs some fresher ideas for expanding access to cloud gaming.",
          "content": "Currently, Microsoft's long-running Cloud Gaming service is limited to players that have a Microsoft's Game Pass subscription. Now, new reporting suggests Microsoft is planning to offer non-subscribers access to game streams paid for by advertising in the near future, but only in extremely limited circumstances. The latest wave of rumors was set off late last week when The Verge's Tom Warren shared an Xbox Cloud Gaming loading screen with a message mentioning \"1 hour of ad supported playtime per session.\" That leaked message comes after Windows Central reported last summer that Microsoft has been \"exploring video ads for free games for quite some time,\" à la the two-minute sponsorships that appear before free-tier game streams on Nvidia's GeForce Now service. Don't get your hopes up for easy, free, ad-supported access to the entire Xbox Cloud Gaming library, though. Windows Central now reports that Microsoft will be using ads merely to slightly expand access to its \"Stream your own game\" program. That program currently offers subscribers to the Xbox Game Pass Essentials tier (or higher) the privilege of streaming versions of some of the Xbox games they've already purchased digitally. Windows Central's unnamed sources suggest a \"session-based ad-supported access tier\" to stream those purchased games will be offered to non-subscribers as soon as \"this year.\"Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/06/Cloud-Gaming_iPadSurfaceiPhone-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/06/Cloud-Gaming_iPadSurfaceiPhone-1152x648.jpg",
      "popularity_score": 308.9253733333333
    },
    {
      "id": "cluster_15",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 18:24:49 +0000",
      "title": "Asus confirms its smartphone business is on indefinite hiatus",
      "neutral_headline": "Asus confirms its smartphone business is on indefinite hiatus",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/asus-confirms-its-smartphone-business-is-on-indefinite-hiatus/",
          "published_at": "Mon, 19 Jan 2026 18:24:49 +0000",
          "title": "Asus confirms its smartphone business is on indefinite hiatus",
          "standfirst": "Asus chairman Jonney Shih sees AI applications as the company's main focus going forward.",
          "content": "An unconfirmed report early this month suggested Asus was pulling back on its smartphone plans, but the company declined to comment at the time. Asus chairman Jonney Shih has now confirmed the wind-down of its smartphone business during an event in Taiwan. Instead, Asus will focus on AI products like robots and smart glasses. Shih addressed the company's future plans during a 2026 kick-off event in Taiwan, as reported by Inside. \"Asus will no longer add new mobile phone models in the future,\" said Shih (machine translated). So don't expect a new Zenfone or ROG Phone from Asus in 2026. That said, very few phone buyers were keeping tabs on the latest Asus phones anyway, which is probably why Asus is throwing in the towel. Shih isn't saying Asus won't ever release a new phone, but the company will take an \"indefinite wait-and-see\" approach. Again, this is a translation and could be interpreted in multiple ways.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ROG-2-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ROG-2-1-1152x648.jpg",
      "popularity_score": 308.0617622222222
    },
    {
      "id": "cluster_22",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 17:06:28 +0000",
      "title": "The race to build a super-large ground telescope is likely down to two competitors",
      "neutral_headline": "The race to build a super-large ground telescope is likely down to two competitors",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/as-europes-large-ground-telescope-project-advances-how-is-its-us-competitor-faring/",
          "published_at": "Mon, 19 Jan 2026 17:06:28 +0000",
          "title": "The race to build a super-large ground telescope is likely down to two competitors",
          "standfirst": "Ars checks in with the new president of the Giant Magellan Telescope.",
          "content": "I have been writing about the Giant Magellan Telescope for a long time. Nearly two decades ago, for example, I wrote that time was \"running out\" in the race to build the next great optical telescope on the ground. At the time the proposed telescope was one of three contenders to make a giant leap in mirror size from the roughly 10-meter diameter instruments that existed then, to approximately 30 meters. This represented a huge increase in light-gathering potential, allowing astronomers to see much further into the universe—and therefore back into time—with far greater clarity. Since then the projects have advanced at various rates. An international consortium to build the Thirty Meter Telescope in Hawaii ran into local protests that have bogged down development. Its future came further into question when the US National Science Foundation dropped support for the project in favor of the Giant Magellan Telescope. Meanwhile the European Extremely Large Telescope (ELT) has advanced on a faster schedule, and this 39.5-meter telescope could observe its first light in 2029.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GMT-Rendering-IDOM-Enclosure-2024-1-scaled-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GMT-Rendering-IDOM-Enclosure-2024-1-scaled-1-1152x648.jpg",
      "popularity_score": 286.7559288888889
    },
    {
      "id": "cluster_54",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 12:00:45 +0000",
      "title": "10 things I learned from burning myself out with AI coding agents",
      "neutral_headline": "10 things I learned from burning myself out with AI coding agents",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2026/01/10-things-i-learned-from-burning-myself-out-with-ai-coding-agents/",
          "published_at": "Mon, 19 Jan 2026 12:00:45 +0000",
          "title": "10 things I learned from burning myself out with AI coding agents",
          "standfirst": "Opinion: As software power tools, AI agents may make people busier than ever before.",
          "content": "If you've ever used a 3D printer, you may recall the wondrous feeling when you first printed something you could have never sculpted or built yourself. Download a model file, load some plastic filament, push a button, and almost like magic, a three-dimensional object appears. But the result isn't polished and ready for mass production, and creating a novel shape requires more skills than just pushing a button. Interestingly, today's AI coding agents feel much the same way. Since November, I have used Claude Code and Claude Opus 4.5 through a personal Claude Max account to extensively experiment with AI-assisted software development (I have also used OpenAI's Codex in a similar way, though not as frequently). Fifty projects later, I'll be frank: I have not had this much fun with a computer since I learned BASIC on my Apple II Plus when I was 9 years old. This opinion comes not as an endorsement but as personal experience: I voluntarily undertook this project, and I paid out of pocket for both OpenAI and Anthropic's premium AI plans. Throughout my life, I have dabbled in programming as a utilitarian coder, writing small tools or scripts when needed. In my web development career, I wrote some small tools from scratch, but I primarily modified other people's code for my needs. Since 1990, I've programmed in BASIC, C, Visual Basic, PHP, ASP, Perl, Python, Ruby, MUSHcode, and some others. I am not an expert in any of these languages—I learned just enough to get the job done. I have developed my own hobby games over the years using BASIC, Torque Game Engine, and Godot, so I have some idea of what makes a good architecture for a modular program that can be expanded over time.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/super-programmer-hes-heating-up-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/super-programmer-hes-heating-up-1152x648.jpg",
      "popularity_score": 276.6606511111111
    },
    {
      "id": "cluster_27",
      "coverage": 1,
      "updated_at": "Mon, 19 Jan 2026 16:00:27 +0000",
      "title": "Meet Veronika, the tool-using cow",
      "neutral_headline": "Meet Veronika, the tool-using cow",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/meet-veronika-the-tool-using-cow/",
          "published_at": "Mon, 19 Jan 2026 16:00:27 +0000",
          "title": "Meet Veronika, the tool-using cow",
          "standfirst": "Veronika uses sticks to scratch herself, suggesting scientists have underestimated cow cognition",
          "content": "Far Side fans might recall a classic 1982 cartoon called \"Cow Tools,\" featuring a cow standing next to a jumble of strange objects—the joke being that cows don't use tools. That's why a pet Swiss brown cow in Austria named Veronika has caused a bit of a sensation: she likes to pick up random sticks and use them to scratch herself. According to a new paper published in the journal Current Biology, this is a form of multipurpose tool use and suggests that the cognitive capabilities of cows have been underestimated by scientists. As previously reported, tool use was once thought to be one of the defining features of humans, but examples of it were eventually observed in primates and other mammals. Dolphins can toss objects as a form of play which some scientists consider to be a type of tool use, particularly when it involves another member of the same species. Potential purposes include a means of communication, social bonding, or aggressiveness. (Octopuses have also been observed engaging in similar throwing behavior.) But the biggest surprise came when birds were observed using tools in the wild. After all, birds are the only surviving dinosaurs, and mammals and dinosaurs hadn’t shared a common ancestor for hundreds of millions of years. In the wild, observed tool use has been limited to the corvids (crows and jays), which show a variety of other complex behaviors—they’ll remember your face and recognize the passing of their dead.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cowtool1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/cowtool1-1152x648.jpg",
      "popularity_score": 272.6556511111111
    },
    {
      "id": "cluster_87",
      "coverage": 1,
      "updated_at": "Sun, 18 Jan 2026 12:00:56 +0000",
      "title": "Ocean damage nearly doubles the cost of climate change",
      "neutral_headline": "Ocean damage nearly doubles the cost of climate change",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/ocean-damage-nearly-doubles-the-cost-of-climate-change/",
          "published_at": "Sun, 18 Jan 2026 12:00:56 +0000",
          "title": "Ocean damage nearly doubles the cost of climate change",
          "standfirst": "Ignoring the blue economy has left a multi-trillion-dollar blind spot in climate finance.",
          "content": "The global cost of greenhouse gas emissions is nearly double what scientists previously thought, according to a study published Thursday by researchers at the University of California, San Diego’s Scripps Institution of Oceanography. It is the first time a social cost of carbon (SCC) assessment—a key measure of economic harm caused by climate change—has included damages to the ocean. Global coral loss, fisheries disruption, and coastal infrastructure destruction are estimated to cost nearly $2 trillion annually, fundamentally changing how we measure climate finance. “For decades, we’ve been estimating the economic cost of climate change while effectively assigning a value of zero to the ocean,” said Bernardo Bastien-Olvera, who led the study during his postdoctoral fellowship at Scripps. “Ocean loss is not just an environmental issue, but a central part of the economic story of climate change.”Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2245161347-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2245161347-1152x648.jpg",
      "popularity_score": 251
    }
  ]
}