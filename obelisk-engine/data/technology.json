{
  "updated_at": "2026-01-25T19:17:19.456Z",
  "clusters": [
    {
      "id": "cluster_47",
      "coverage": 3,
      "updated_at": "Sat, 24 Jan 2026 20:50:00 -0500",
      "title": "Tests show GPT-5.2 on ChatGPT citing Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers (Aisha Down/The Guardian)",
      "neutral_headline": "Report reveals that OpenAI's GPT-5.2 model cites Grokipedia",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260124/p15#a260124p15",
          "published_at": "Sat, 24 Jan 2026 20:50:00 -0500",
          "title": "Tests show GPT-5.2 on ChatGPT citing Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers (Aisha Down/The Guardian)",
          "standfirst": "Aisha Down / The Guardian: Tests show GPT-5.2 on ChatGPT citing Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers &mdash; Guardian found OpenAI's platform cited Grokipedia on topics including Iran and Holocaust deniers &mdash; The latest model of ChatGPT has begun &hellip;",
          "content": "Aisha Down / The Guardian: Tests show GPT-5.2 on ChatGPT citing Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers &mdash; Guardian found OpenAI's platform cited Grokipedia on topics including Iran and Holocaust deniers &mdash; The latest model of ChatGPT has begun &hellip;",
          "feed_position": 9,
          "image_url": "http://www.techmeme.com/260124/i15.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/report-reveals-that-openais-gpt-52-model-cites-grokipedia-192532977.html",
          "published_at": "Sat, 24 Jan 2026 19:25:32 +0000",
          "title": "Report reveals that OpenAI's GPT-5.2 model cites Grokipedia",
          "standfirst": "OpenAI may have called GPT-5.2 its \"most advanced frontier model for professional work,\" but tests conducted by the Guardian cast doubt on its credibility. According to the report, OpenAI's GPT-5.2 model cited Grokipedia, the online encyclopedia powered by xAI, when it came to specific, but controversial topics related to Iran or the Holocaust. As seen in the Guardian's report, ChatGPT used Grokipedia as a source for claims about the Iranian government being tied to telecommunications company MTN-Irancell and questions related to Richard Evans, a British historian who served as an expert witness during a libel trial for Holocaust denier David Irving. However, the Guardian noted ChatGPT didn't use Grokipedia when it came to a prompt asking about media bias against Donald Trump and other controversial topics. OpenAI released the GPT-5.2 model in December to better perform at professional use, like creating spreadsheets or handling complex tasks. Grokipedia preceded GPT-5.2's release, but ran into some controversy when it was seen including citations to neo-Nazi forums. A study done by US researchers also showed that the AI-generated encyclopedia cited \"questionable\" and \"problematic\" sources. In response to the Guardian report, OpenAI told the outlet that its GPT-5.2 model searches the web for a \"broad range of publicly available sources and viewpoints,\" but applies \"safety filters to reduce the risk of surfacing links associated with high-severity harms.\"This article originally appeared on Engadget at https://www.engadget.com/ai/report-reveals-that-openais-gpt-52-model-cites-grokipedia-192532977.html?src=rss",
          "content": "OpenAI may have called GPT-5.2 its \"most advanced frontier model for professional work,\" but tests conducted by the Guardian cast doubt on its credibility. According to the report, OpenAI's GPT-5.2 model cited Grokipedia, the online encyclopedia powered by xAI, when it came to specific, but controversial topics related to Iran or the Holocaust. As seen in the Guardian's report, ChatGPT used Grokipedia as a source for claims about the Iranian government being tied to telecommunications company MTN-Irancell and questions related to Richard Evans, a British historian who served as an expert witness during a libel trial for Holocaust denier David Irving. However, the Guardian noted ChatGPT didn't use Grokipedia when it came to a prompt asking about media bias against Donald Trump and other controversial topics. OpenAI released the GPT-5.2 model in December to better perform at professional use, like creating spreadsheets or handling complex tasks. Grokipedia preceded GPT-5.2's release, but ran into some controversy when it was seen including citations to neo-Nazi forums. A study done by US researchers also showed that the AI-generated encyclopedia cited \"questionable\" and \"problematic\" sources. In response to the Guardian report, OpenAI told the outlet that its GPT-5.2 model searches the web for a \"broad range of publicly available sources and viewpoints,\" but applies \"safety filters to reduce the risk of surfacing links associated with high-severity harms.\"This article originally appeared on Engadget at https://www.engadget.com/ai/report-reveals-that-openais-gpt-52-model-cites-grokipedia-192532977.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/jan/24/latest-chatgpt-model-uses-elon-musks-grokipedia-as-source-tests-reveal",
          "published_at": "Sat, 24 Jan 2026 14:00:41 GMT",
          "title": "Latest ChatGPT model uses Elon Musk‚Äôs Grokipedia as source, tests reveal",
          "standfirst": "Guardian found OpenAI‚Äôs platform cited Grokipedia on topics including Iran and Holocaust deniersThe latest model of ChatGPT has begun to cite Elon Musk‚Äôs Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers, raising concerns about misinformation on the platform.In tests done by the Guardian, GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions. These included queries on political structures in Iran, such as salaries of the Basij paramilitary force and the ownership of the Mostazafan Foundation, and questions on the biography of Sir Richard Evans, a British historian and expert witness against Holocaust denier David Irving in his libel trial. Continue reading...",
          "content": "Guardian found OpenAI‚Äôs platform cited Grokipedia on topics including Iran and Holocaust deniersThe latest model of ChatGPT has begun to cite Elon Musk‚Äôs Grokipedia as a source on a wide range of queries, including on Iranian conglomerates and Holocaust deniers, raising concerns about misinformation on the platform.In tests done by the Guardian, GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions. These included queries on political structures in Iran, such as salaries of the Basij paramilitary force and the ownership of the Mostazafan Foundation, and questions on the biography of Sir Richard Evans, a British historian and expert witness against Holocaust denier David Irving in his libel trial. Continue reading...",
          "feed_position": 2
        }
      ],
      "featured_image": "http://www.techmeme.com/260124/i15.jpg",
      "popularity_score": 3002.5445955555556
    },
    {
      "id": "cluster_2",
      "coverage": 2,
      "updated_at": "Sun, 25 Jan 2026 18:00:00 GMT",
      "title": "Conversational AI doesn‚Äôt understand users ‚Äî 'Intent First' architecture does",
      "neutral_headline": "Conversational AI doesn‚Äôt understand users ‚Äî 'Intent First' architecture does",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/conversational-ai-doesnt-understand-users-intent-first-architecture-does",
          "published_at": "Sun, 25 Jan 2026 18:00:00 GMT",
          "title": "Conversational AI doesn‚Äôt understand users ‚Äî 'Intent First' architecture does",
          "standfirst": "The modern customer has just one need that matters: Getting the thing they want when they want it. The old standard RAG model embed+retrieve+LLM misunderstands intent, overloads context and misses freshness, repeatedly sending customers down the wrong paths. Instead, intent-first architecture uses a lightweight language model to parse the query for intent and context, before delivering to the most relevant content sources (documents, APIs, people).Enterprise AI is a speeding train headed for a cliff. Organizations are deploying LLM-powered search applications at a record pace, while a fundamental architectural issue is setting most up for failure.A recent Coveo study revealed that 72% of enterprise search queries fail to deliver meaningful results on the first attempt, while Gartner also predicts that the majority of conversational AI deployments have been falling short of enterprise expectations.The problem isn‚Äôt the underlying models. It‚Äôs the architecture around them.After designing and running live AI-driven customer interaction platforms at scale, serving millions of customer and citizen users at some of the world‚Äôs largest telecommunications and healthcare organizations, I‚Äôve come to see a pattern. It‚Äôs the difference between successful AI-powered interaction deployments and multi-million-dollar failures.It‚Äôs a cloud-native architecture pattern that I call Intent-First. And it‚Äôs reshaping the way enterprises build AI-powered experiences.The $36 pillion problem Gartner projects the global conversational AI market will balloon to $36 billion by 2032. Enterprises are scrambling to get a slice. The demos are irresistible. Plug your LLM into your knowledge base, and suddenly it can answer customer questions in natural language.Magic. Then production happens. A major telecommunications provider I work with rolled out a RAG system with the expectation of driving down the support call rate. Instead, the rate increased. Callers tried AI-powered search, were provided incorrect answers with a high degree of confidence and called customer support angrier than before.This pattern is repeated over and over. In healthcare, customer-facing AI assistants are providing patients with formulary information that‚Äôs outdated by weeks or months. Financial services chatbots are spitting out answers from both retail and institutional product content. Retailers are seeing discontinued products surface in product searches.The issue isn‚Äôt a failure of AI technology. It‚Äôs a failure of architectureWhy standard RAG architectures fail The standard RAG pattern ‚Äî embedding the query, retrieving semantically similar content, passing to an LLM ‚Äîworks beautifully in demos and proof of concepts. But it falls apart in production use cases for three systematic reasons:1. The intent gapIntent is not context. But standard RAG architectures don‚Äôt account for this.Say a customer types ‚ÄúI want to cancel‚Äù What does that mean? Cancel a service? Cancel an order? Cancel an appointment? During our telecommunications deployment, we found that 65% of queries for ‚Äúcancel‚Äù were actually about orders or appointments, not service cancellation. The RAG system had no way of understanding this intent, so it consistently returned service cancellation documents.Intent matters. In healthcare, if a patient is typing ‚ÄúI need to cancel‚Äù because they&#x27;re trying to cancel an appointment, a prescription refill or a procedure, routing them to medication content from scheduling is not only frustrating ‚Äî it&#x27;s also dangerous.2. Context flood Enterprise knowledge and experience is vast, spanning dozens of sources such as product catalogs, billing, support articles, policies, promotions and account data. Standard RAG models treat all of it the same, searching all for every query.When a customer asks ‚ÄúHow do I activate my new phone,‚Äù they don‚Äôt care about billing FAQs, store locations or network status updates. But a standard RAG model retrieves semantically similar content from every source, returning search results that are a half-steps off the mark.3. Freshness blindspot Vector space is timeblind. Semantically, last quarter‚Äôs promotion is identical to this quarter‚Äôs. But presenting customers with outdated offers shatters trust. We linked a significant percentage of customer complaints to search results that surfaced expired products, offers, or features.The Intent-First architecture pattern The Intent-First architecture pattern is the mirror image of the standard RAG deployment. In the RAG model, you retrieve, then route. In the Intent-First model, you classify before you route or retrieve. Intent-First architectures use a lightweight language model to parse a query for intent and context, before dispatching to the most relevant content sources (documents, APIs, agents).Comparison: Intent-first vs standard RAGCloud-native implementationThe Intent-First pattern is designed for cloud-native deployment, leveraging microservices, containerization and elastic scaling to handle enterprise traffic patterns.Intent classification serviceThe classifier determines user intent before any retrieval occurs:ALGORITHM: Intent ClassificationINPUT: user_query (string)OUTPUT: intent_result (object)1. PREPROCESS query (normalize, expand contractions)2. CLASSIFY using transformer model: - primary_intent ‚Üê model.predict(query) - confidence ‚Üê model.confidence_score()3. IF confidence < 0.70 THEN - RETURN { requires_clarification: true, suggested_question: generate_clarifying_question(query) }4. EXTRACT sub_intent based on primary_intent: - IF primary = \"ACCOUNT\" ‚Üí check for ORDER_STATUS, PROFILE, etc. - IF primary = \"SUPPORT\" ‚Üí check for DEVICE_ISSUE, NETWORK, etc. - IF primary = \"BILLING\" ‚Üí check for PAYMENT, DISPUTE, etc.5. DETERMINE target_sources based on intent mapping: - ORDER_STATUS ‚Üí [orders_db, order_faq] - DEVICE_ISSUE ‚Üí [troubleshooting_kb, device_guides] - MEDICATION ‚Üí [formulary, clinical_docs] (healthcare)6. RETURN { primary_intent, sub_intent, confidence, target_sources, requires_personalization: true/false }Context-aware retrieval serviceOnce intent is classified, retrieval becomes targeted:ALGORITHM: Context-Aware RetrievalINPUT: query, intent_result, user_contextOUTPUT: ranked_documents1. GET source_config for intent_result.sub_intent: - primary_sources ‚Üê sources to search - excluded_sources ‚Üê sources to skip - freshness_days ‚Üê max content age2. IF intent requires personalization AND user is authenticated: - FETCH account_context from Account Service - IF intent = ORDER_STATUS: - FETCH recent_orders (last 60 days) - ADD to results3. BUILD search filters: - content_types ‚Üê primary_sources only - max_age ‚Üê freshness_days - user_context ‚Üê account_context (if available)4. FOR EACH source IN primary_sources: - documents ‚Üê vector_search(query, source, filters) - ADD documents to results5. SCORE each document: - relevance_score ‚Üê vector_similarity √ó 0.40 - recency_score ‚Üê freshness_weight √ó 0.20 - personalization_score ‚Üê user_match √ó 0.25 - intent_match_score ‚Üê type_match √ó 0.15 - total_score ‚Üê SUM of above6. RANK by total_score descending7. RETURN top 10 documentsHealthcare-specific considerationsIn healthcare deployments, the Intent-First pattern includes additional safeguards:Healthcare intent categories:Clinical: Medication questions, symptoms, care instructionsCoverage: Benefits, prior authorization, formularyScheduling: Appointments, provider availabilityBilling: Claims, payments, statementsAccount: Profile, dependents, ID cardsCritical safeguard: Clinical queries always include disclaimers and never replace professional medical advice. The system routes complex clinical questions to human support.Handling edge casesThe edge cases are where systems fail. The Intent-First pattern includes specific handlers:Frustration detection keywords:Anger: \"terrible,\" \"worst,\" \"hate,\" \"ridiculous\"Time: \"hours,\" \"days,\" \"still waiting\"Failure: \"useless,\" \"no help,\" \"doesn&#x27;t work\"Escalation: \"speak to human,\" \"real person,\" \"manager\"When frustration is detected, skip search entirely and route to human support.Cross-industry applicationsThe Intent-First pattern applies wherever enterprises deploy conversational AI over heterogeneous content:IndustryIntent categoriesKey benefitTelecommunicationsSales, Support, Billing, Account, RetentionPrevents \"cancel\" misclassificationHealthcareClinical, Coverage, Scheduling, BillingSeparates clinical from administrativeFinancial servicesRetail, Institutional, Lending, InsurancePrevents context mixingRetailProduct, Orders, Returns, LoyaltyEnsures promotional freshnessResultsAfter implementing Intent-First architecture across telecommunications and healthcare platforms:MetricImpactQuery success rateNearly doubledSupport escalationsReduced by more than halfTime to resolutionReduced approximately 70%User satisfactionImproved roughly 50%Return user rateMore than doubledThe return user rate proved most significant. When search works, users come back. When it fails, they abandon the channel entirely, increasing costs across all other support channels.The strategic imperativeThe conversational AI market will continue to experience hyper growth.But enterprises that build and deploy typical RAG architectures will continue to fail ‚Ä¶ repeatedly.AI will confidently give wrong answers, users will abandon digital channels out of frustration and support costs will go up instead of down.Intent-First is a fundamental shift in how enterprises need to architect and build AI-powered customer conversations. It‚Äôs not about better models or more data. It‚Äôs about understanding what a user wants before you try to help them.The sooner an organization realizes this as an architectural imperative, the sooner they will be able to capture the efficiency gains this technology is supposed to enable. Those that don‚Äôt will be debugging why their AI investments haven‚Äôt been producing expected business outcomes for many years to come.The demo is easy. Production is hard. But the pattern for production success is clear: Intent First.Sreenivasa Reddy Hulebeedu Reddy is a lead software engineer and enterprise architect",
          "content": "The modern customer has just one need that matters: Getting the thing they want when they want it. The old standard RAG model embed+retrieve+LLM misunderstands intent, overloads context and misses freshness, repeatedly sending customers down the wrong paths. Instead, intent-first architecture uses a lightweight language model to parse the query for intent and context, before delivering to the most relevant content sources (documents, APIs, people).Enterprise AI is a speeding train headed for a cliff. Organizations are deploying LLM-powered search applications at a record pace, while a fundamental architectural issue is setting most up for failure.A recent Coveo study revealed that 72% of enterprise search queries fail to deliver meaningful results on the first attempt, while Gartner also predicts that the majority of conversational AI deployments have been falling short of enterprise expectations.The problem isn‚Äôt the underlying models. It‚Äôs the architecture around them.After designing and running live AI-driven customer interaction platforms at scale, serving millions of customer and citizen users at some of the world‚Äôs largest telecommunications and healthcare organizations, I‚Äôve come to see a pattern. It‚Äôs the difference between successful AI-powered interaction deployments and multi-million-dollar failures.It‚Äôs a cloud-native architecture pattern that I call Intent-First. And it‚Äôs reshaping the way enterprises build AI-powered experiences.The $36 pillion problem Gartner projects the global conversational AI market will balloon to $36 billion by 2032. Enterprises are scrambling to get a slice. The demos are irresistible. Plug your LLM into your knowledge base, and suddenly it can answer customer questions in natural language.Magic. Then production happens. A major telecommunications provider I work with rolled out a RAG system with the expectation of driving down the support call rate. Instead, the rate increased. Callers tried AI-powered search, were provided incorrect answers with a high degree of confidence and called customer support angrier than before.This pattern is repeated over and over. In healthcare, customer-facing AI assistants are providing patients with formulary information that‚Äôs outdated by weeks or months. Financial services chatbots are spitting out answers from both retail and institutional product content. Retailers are seeing discontinued products surface in product searches.The issue isn‚Äôt a failure of AI technology. It‚Äôs a failure of architectureWhy standard RAG architectures fail The standard RAG pattern ‚Äî embedding the query, retrieving semantically similar content, passing to an LLM ‚Äîworks beautifully in demos and proof of concepts. But it falls apart in production use cases for three systematic reasons:1. The intent gapIntent is not context. But standard RAG architectures don‚Äôt account for this.Say a customer types ‚ÄúI want to cancel‚Äù What does that mean? Cancel a service? Cancel an order? Cancel an appointment? During our telecommunications deployment, we found that 65% of queries for ‚Äúcancel‚Äù were actually about orders or appointments, not service cancellation. The RAG system had no way of understanding this intent, so it consistently returned service cancellation documents.Intent matters. In healthcare, if a patient is typing ‚ÄúI need to cancel‚Äù because they&#x27;re trying to cancel an appointment, a prescription refill or a procedure, routing them to medication content from scheduling is not only frustrating ‚Äî it&#x27;s also dangerous.2. Context flood Enterprise knowledge and experience is vast, spanning dozens of sources such as product catalogs, billing, support articles, policies, promotions and account data. Standard RAG models treat all of it the same, searching all for every query.When a customer asks ‚ÄúHow do I activate my new phone,‚Äù they don‚Äôt care about billing FAQs, store locations or network status updates. But a standard RAG model retrieves semantically similar content from every source, returning search results that are a half-steps off the mark.3. Freshness blindspot Vector space is timeblind. Semantically, last quarter‚Äôs promotion is identical to this quarter‚Äôs. But presenting customers with outdated offers shatters trust. We linked a significant percentage of customer complaints to search results that surfaced expired products, offers, or features.The Intent-First architecture pattern The Intent-First architecture pattern is the mirror image of the standard RAG deployment. In the RAG model, you retrieve, then route. In the Intent-First model, you classify before you route or retrieve. Intent-First architectures use a lightweight language model to parse a query for intent and context, before dispatching to the most relevant content sources (documents, APIs, agents).Comparison: Intent-first vs standard RAGCloud-native implementationThe Intent-First pattern is designed for cloud-native deployment, leveraging microservices, containerization and elastic scaling to handle enterprise traffic patterns.Intent classification serviceThe classifier determines user intent before any retrieval occurs:ALGORITHM: Intent ClassificationINPUT: user_query (string)OUTPUT: intent_result (object)1. PREPROCESS query (normalize, expand contractions)2. CLASSIFY using transformer model: - primary_intent ‚Üê model.predict(query) - confidence ‚Üê model.confidence_score()3. IF confidence < 0.70 THEN - RETURN { requires_clarification: true, suggested_question: generate_clarifying_question(query) }4. EXTRACT sub_intent based on primary_intent: - IF primary = \"ACCOUNT\" ‚Üí check for ORDER_STATUS, PROFILE, etc. - IF primary = \"SUPPORT\" ‚Üí check for DEVICE_ISSUE, NETWORK, etc. - IF primary = \"BILLING\" ‚Üí check for PAYMENT, DISPUTE, etc.5. DETERMINE target_sources based on intent mapping: - ORDER_STATUS ‚Üí [orders_db, order_faq] - DEVICE_ISSUE ‚Üí [troubleshooting_kb, device_guides] - MEDICATION ‚Üí [formulary, clinical_docs] (healthcare)6. RETURN { primary_intent, sub_intent, confidence, target_sources, requires_personalization: true/false }Context-aware retrieval serviceOnce intent is classified, retrieval becomes targeted:ALGORITHM: Context-Aware RetrievalINPUT: query, intent_result, user_contextOUTPUT: ranked_documents1. GET source_config for intent_result.sub_intent: - primary_sources ‚Üê sources to search - excluded_sources ‚Üê sources to skip - freshness_days ‚Üê max content age2. IF intent requires personalization AND user is authenticated: - FETCH account_context from Account Service - IF intent = ORDER_STATUS: - FETCH recent_orders (last 60 days) - ADD to results3. BUILD search filters: - content_types ‚Üê primary_sources only - max_age ‚Üê freshness_days - user_context ‚Üê account_context (if available)4. FOR EACH source IN primary_sources: - documents ‚Üê vector_search(query, source, filters) - ADD documents to results5. SCORE each document: - relevance_score ‚Üê vector_similarity √ó 0.40 - recency_score ‚Üê freshness_weight √ó 0.20 - personalization_score ‚Üê user_match √ó 0.25 - intent_match_score ‚Üê type_match √ó 0.15 - total_score ‚Üê SUM of above6. RANK by total_score descending7. RETURN top 10 documentsHealthcare-specific considerationsIn healthcare deployments, the Intent-First pattern includes additional safeguards:Healthcare intent categories:Clinical: Medication questions, symptoms, care instructionsCoverage: Benefits, prior authorization, formularyScheduling: Appointments, provider availabilityBilling: Claims, payments, statementsAccount: Profile, dependents, ID cardsCritical safeguard: Clinical queries always include disclaimers and never replace professional medical advice. The system routes complex clinical questions to human support.Handling edge casesThe edge cases are where systems fail. The Intent-First pattern includes specific handlers:Frustration detection keywords:Anger: \"terrible,\" \"worst,\" \"hate,\" \"ridiculous\"Time: \"hours,\" \"days,\" \"still waiting\"Failure: \"useless,\" \"no help,\" \"doesn&#x27;t work\"Escalation: \"speak to human,\" \"real person,\" \"manager\"When frustration is detected, skip search entirely and route to human support.Cross-industry applicationsThe Intent-First pattern applies wherever enterprises deploy conversational AI over heterogeneous content:IndustryIntent categoriesKey benefitTelecommunicationsSales, Support, Billing, Account, RetentionPrevents \"cancel\" misclassificationHealthcareClinical, Coverage, Scheduling, BillingSeparates clinical from administrativeFinancial servicesRetail, Institutional, Lending, InsurancePrevents context mixingRetailProduct, Orders, Returns, LoyaltyEnsures promotional freshnessResultsAfter implementing Intent-First architecture across telecommunications and healthcare platforms:MetricImpactQuery success rateNearly doubledSupport escalationsReduced by more than halfTime to resolutionReduced approximately 70%User satisfactionImproved roughly 50%Return user rateMore than doubledThe return user rate proved most significant. When search works, users come back. When it fails, they abandon the channel entirely, increasing costs across all other support channels.The strategic imperativeThe conversational AI market will continue to experience hyper growth.But enterprises that build and deploy typical RAG architectures will continue to fail ‚Ä¶ repeatedly.AI will confidently give wrong answers, users will abandon digital channels out of frustration and support costs will go up instead of down.Intent-First is a fundamental shift in how enterprises need to architect and build AI-powered customer conversations. It‚Äôs not about better models or more data. It‚Äôs about understanding what a user wants before you try to help them.The sooner an organization realizes this as an architectural imperative, the sooner they will be able to capture the efficiency gains this technology is supposed to enable. Those that don‚Äôt will be debugging why their AI investments haven‚Äôt been producing expected business outcomes for many years to come.The demo is easy. Production is hard. But the pattern for production success is clear: Intent First.Sreenivasa Reddy Hulebeedu Reddy is a lead software engineer and enterprise architect",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4RG14xD3FBupJCjwyfXnRQ/189358d225f858df792c92c95ee93bd1/Conversational_AI.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/how-to-use-workout-buddy-with-apple-watch-and-ios-26-130000922.html",
          "published_at": "Sat, 24 Jan 2026 13:00:00 +0000",
          "title": "How to use Workout Buddy with Apple Watch and iOS 26",
          "standfirst": "Apple‚Äôs iOS 26 and watchOS 26 introduced a new fitness companion called Workout Buddy. This feature uses Apple Intelligence to provide spoken feedback during workouts and give motivation based on your activity history. Workout Buddy analyzes your pace, heart rate, distance and other metrics to deliver real-time encouragement and performance insights directly through connected Bluetooth headphones. It works in conjunction with the Workout app on Apple Watch and is partially controlled through the Fitness app on iPhone. This guide walks you through everything needed to set up and use Workout Buddy effectively during workouts.What Workout Buddy doesIt‚Äôs important to note that Workout Buddy is not a full coaching program. Instead, it adds to your workout with spoken cues that reflect how your session is going. Workout Buddy can remind you of your weekly activity totals, alert you to personal bests or performance milestones and provide an overview when you‚Äôre finished. It is designed to feel like a supportive training partner rather than a strict coach.The feature operates in English by default and uses a text-to-speech model trained on voices from Apple Fitness+ trainers. It is available for a subset of workout types, including running, walking, cycling, high-intensity interval training (HIIT) and strength training. It requires on-device Apple Intelligence, which means you‚Äôll need to keep one of the latest iPhones running updated software nearby during workouts. Supported models include iPhone 15 Pro, iPhone 15 Pro Max and any iPhone 16 model. You‚Äôll also need an Apple Watch running watchOS 26. Requirements before you beginBefore Workout Buddy appears in your Fitness app or Workout app you must ensure a few things are in place. First, your Apple Watch must be running watchOS 26 or later and paired to an iPhone with iOS 26 installed. Second, your iPhone must be capable of on-device Apple Intelligence, meaning you must own one of the supported iPhone models we mentioned above and have Apple Intelligence enabled in the phone‚Äôs settings.You‚Äôll also need Bluetooth headphones paired with either your iPhone or your Apple Watch. Workout Buddy‚Äôs audio feedback cannot play through the watch speaker so headphones are essential. Lastly, your device language must be set to English, at least initially. If any of these things are missing, the option to enable Workout Buddy may not appear.How to turn on Workout Buddy from iPhoneWhile much of the interaction with Workout Buddy happens on Apple Watch during workouts, you can enable it and choose voice options from the Fitness app on iPhone.Open the Fitness app on your iPhone and tap the Workout tab at the bottom. Scroll through the list of workout types until you find one you plan to use with Workout Buddy. Tap the waveform bubble icon associated with that workout. This will bring up settings where you can turn on Workout Buddy. Flip the toggle to enable it and choose a voice from the available options. Once you have selected a voice, close that screen and your choice is saved. When you start this workout type on Apple Watch, Workout Buddy will activate.Enabling Workout Buddy for a workout type on iPhone means you do not need to toggle it on separately on Apple Watch each time for that specific workout. However, you may still adjust it from the watch interface for more granular control.How to turn on Workout Buddy on Apple WatchTo use Workout Buddy during a session, open the Workout app on your Apple Watch. Turn the Digital Crown to scroll through and select the workout you want to do, such as Outdoor Run, Outdoor Walk, Outdoor Cycle, HIIT or Strength Training. If you want to see all available workouts, tap the Add button at the bottom.Once the workout type is selected, look for the Alerts button on screen. Tap Alerts then scroll until you see Workout Buddy. Tap Workout Buddy and flip the switch to on. You will then be asked to choose a voice if one is not already selected on your iPhone. After selecting the voice, return to the previous screen and tap Start. Workout Buddy will begin working as soon as the workout does.Using Workout Buddy during a workoutOnce you start an exercise on your Watch or iPhone, Workout Buddy will speak to you through your connected headphones. The feedback is designed to be encouraging and relevant to your pace, performance or milestones. It may mention your current progress toward activity goals, pace, splits, personal bests or other highlights from your fitness data. At the end of your session Workout Buddy will offer a summary of key metrics like duration distance and calorie burn.While a workout is active, you can temporarily mute the audio if you need silence. On Apple Watch during the session, swipe right to reveal controls then tap Mute. This pauses Workout Buddy‚Äôs spoken commentary without disabling the feature entirely.Customizing and managing Workout Buddy settingsWorkout Buddy is enabled on a per-workout-type basis. If you prefer voice feedback for running but silence for strength training, you can enable it for one and leave it off for the other. The Fitness app on iPhone allows you to set a default voice preference for each workout type. On Apple Watch you can quickly toggle the feature on or off before starting a session.If Workout Buddy does not appear as an option for a particular workout type, you may need to check compatibility. Apple‚Äôs documentation indicates that only certain types* are supported initially and that the option will not appear for unsupported workouts.*Apple Watch SE (2nd generation), Apple Watch SE 3, Apple Watch Series 6, Apple Watch Series 7, Apple Watch Series 8, Apple Watch Series 9, Apple Watch Series 10, Apple Watch Series 11, Apple Watch Ultra, Apple Watch Ultra 2, Apple Watch Ultra 3Troubleshooting common issuesIf Workout Buddy fails to activate make sure your devices meet the requirements outlined above. Confirm that your iPhone with Apple Intelligence is nearby and that Bluetooth headphones are connected. If audio feedback is missing, ensure headphones are paired correctly and that the language is set to English. Some users have reported that if the headphones are paired only to the Watch rather than the iPhone, it can interfere with feedback. Switching to the iPhone often resolves that issue.For workout types where Workout Buddy previously worked but suddenly does not appear, you may try toggling the feature off and on again in the Fitness app or rebooting both devices. In rare cases removing and re-adding the workout type on Apple Watch can refresh the settings.This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-use-workout-buddy-with-apple-watch-and-ios-26-130000922.html?src=rss",
          "content": "Apple‚Äôs iOS 26 and watchOS 26 introduced a new fitness companion called Workout Buddy. This feature uses Apple Intelligence to provide spoken feedback during workouts and give motivation based on your activity history. Workout Buddy analyzes your pace, heart rate, distance and other metrics to deliver real-time encouragement and performance insights directly through connected Bluetooth headphones. It works in conjunction with the Workout app on Apple Watch and is partially controlled through the Fitness app on iPhone. This guide walks you through everything needed to set up and use Workout Buddy effectively during workouts.What Workout Buddy doesIt‚Äôs important to note that Workout Buddy is not a full coaching program. Instead, it adds to your workout with spoken cues that reflect how your session is going. Workout Buddy can remind you of your weekly activity totals, alert you to personal bests or performance milestones and provide an overview when you‚Äôre finished. It is designed to feel like a supportive training partner rather than a strict coach.The feature operates in English by default and uses a text-to-speech model trained on voices from Apple Fitness+ trainers. It is available for a subset of workout types, including running, walking, cycling, high-intensity interval training (HIIT) and strength training. It requires on-device Apple Intelligence, which means you‚Äôll need to keep one of the latest iPhones running updated software nearby during workouts. Supported models include iPhone 15 Pro, iPhone 15 Pro Max and any iPhone 16 model. You‚Äôll also need an Apple Watch running watchOS 26. Requirements before you beginBefore Workout Buddy appears in your Fitness app or Workout app you must ensure a few things are in place. First, your Apple Watch must be running watchOS 26 or later and paired to an iPhone with iOS 26 installed. Second, your iPhone must be capable of on-device Apple Intelligence, meaning you must own one of the supported iPhone models we mentioned above and have Apple Intelligence enabled in the phone‚Äôs settings.You‚Äôll also need Bluetooth headphones paired with either your iPhone or your Apple Watch. Workout Buddy‚Äôs audio feedback cannot play through the watch speaker so headphones are essential. Lastly, your device language must be set to English, at least initially. If any of these things are missing, the option to enable Workout Buddy may not appear.How to turn on Workout Buddy from iPhoneWhile much of the interaction with Workout Buddy happens on Apple Watch during workouts, you can enable it and choose voice options from the Fitness app on iPhone.Open the Fitness app on your iPhone and tap the Workout tab at the bottom. Scroll through the list of workout types until you find one you plan to use with Workout Buddy. Tap the waveform bubble icon associated with that workout. This will bring up settings where you can turn on Workout Buddy. Flip the toggle to enable it and choose a voice from the available options. Once you have selected a voice, close that screen and your choice is saved. When you start this workout type on Apple Watch, Workout Buddy will activate.Enabling Workout Buddy for a workout type on iPhone means you do not need to toggle it on separately on Apple Watch each time for that specific workout. However, you may still adjust it from the watch interface for more granular control.How to turn on Workout Buddy on Apple WatchTo use Workout Buddy during a session, open the Workout app on your Apple Watch. Turn the Digital Crown to scroll through and select the workout you want to do, such as Outdoor Run, Outdoor Walk, Outdoor Cycle, HIIT or Strength Training. If you want to see all available workouts, tap the Add button at the bottom.Once the workout type is selected, look for the Alerts button on screen. Tap Alerts then scroll until you see Workout Buddy. Tap Workout Buddy and flip the switch to on. You will then be asked to choose a voice if one is not already selected on your iPhone. After selecting the voice, return to the previous screen and tap Start. Workout Buddy will begin working as soon as the workout does.Using Workout Buddy during a workoutOnce you start an exercise on your Watch or iPhone, Workout Buddy will speak to you through your connected headphones. The feedback is designed to be encouraging and relevant to your pace, performance or milestones. It may mention your current progress toward activity goals, pace, splits, personal bests or other highlights from your fitness data. At the end of your session Workout Buddy will offer a summary of key metrics like duration distance and calorie burn.While a workout is active, you can temporarily mute the audio if you need silence. On Apple Watch during the session, swipe right to reveal controls then tap Mute. This pauses Workout Buddy‚Äôs spoken commentary without disabling the feature entirely.Customizing and managing Workout Buddy settingsWorkout Buddy is enabled on a per-workout-type basis. If you prefer voice feedback for running but silence for strength training, you can enable it for one and leave it off for the other. The Fitness app on iPhone allows you to set a default voice preference for each workout type. On Apple Watch you can quickly toggle the feature on or off before starting a session.If Workout Buddy does not appear as an option for a particular workout type, you may need to check compatibility. Apple‚Äôs documentation indicates that only certain types* are supported initially and that the option will not appear for unsupported workouts.*Apple Watch SE (2nd generation), Apple Watch SE 3, Apple Watch Series 6, Apple Watch Series 7, Apple Watch Series 8, Apple Watch Series 9, Apple Watch Series 10, Apple Watch Series 11, Apple Watch Ultra, Apple Watch Ultra 2, Apple Watch Ultra 3Troubleshooting common issuesIf Workout Buddy fails to activate make sure your devices meet the requirements outlined above. Confirm that your iPhone with Apple Intelligence is nearby and that Bluetooth headphones are connected. If audio feedback is missing, ensure headphones are paired correctly and that the language is set to English. Some users have reported that if the headphones are paired only to the Watch rather than the iPhone, it can interfere with feedback. Switching to the iPhone often resolves that issue.For workout types where Workout Buddy previously worked but suddenly does not appear, you may try toggling the feature off and on again in the Fitness app or rebooting both devices. In rare cases removing and re-adding the workout type on Apple Watch can refresh the settings.This article originally appeared on Engadget at https://www.engadget.com/wearables/how-to-use-workout-buddy-with-apple-watch-and-ios-26-130000922.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/more-cult-of-the-lamb-a-world-war-ii-computer-mystery-and-other-new-indie-games-worth-checking-out-120000807.html",
          "published_at": "Sat, 24 Jan 2026 12:00:00 +0000",
          "title": "More Cult of the Lamb, a World War II computer mystery and other new indie games worth checking out",
          "standfirst": "Welcome to our latest roundup of what's going on in the indie game space. It‚Äôs been a very busy week of fun game releases (next week will be too!), so let‚Äôs get into some of them after a quick reflection on gaming while traveling.I love my Steam Deck. I really truly do. It‚Äôs a fantastic machine. And yet when I brought it with me on a five-week trip over the holidays, I used it for barely an hour the entire time. That doesn‚Äôt really justify the space and weight it takes up in my bag. The same holds true for my Nintendo Switch 2 and PlayStation Portal. I‚Äôll be leaving them all at home next time. I‚Äôll take a small controller (probably OhSnap's MCON) so I can play the odd game on my laptop or phone. I‚Äôll bring my Playdate as well. I adore that little yellow console, and I haven‚Äôt spent nearly enough time using it. I have a lot of neat-looking indie games to catch up on there (Diora looks particularly interesting). I‚Äôm more likely to play something on a flight if it‚Äôs on a device I can pull out from my pocket. I just wish Panic had put a backlight in the Playdate. New releasesMassive Monster and publisher Devolver Digital gave Cult of the Lamb fans a whole bunch of reasons to jump back into the game this week with the arrival of the Woolhaven expansion. You'll need to get close to the end of the base game (though you don't need to beat the final boss) before you can experience what the DLC has to offer. It includes weather effects, a new mountain area with a pair of fresh dungeons, a ranching system (which allows you to raise animals as pets or for food) and much more.Folks who dig Cult of the Lamb seem to get really into the game. After a few years of free updates from Massive Monster, Woolhaven is a major expansion that's similar in scope to the base game, so it should keep fans busy for quite a while if they want to try everything. The DLC is out now on PC, Nintendo Switch, PS4, PS5, Xbox Series X/S and Xbox One. It costs $17 if you already have the base game.Inkle, the studio behind Overboard! and the wonderful A Highland Song is back with TR-49, a puzzle game with a World War II computer at its core. Over five decades, an array of books, letters and journals were fed into the machine as part of an effort to \"crack the code of reality.\" But now you're tasked with finding and destroying one specific book before a timer runs out.It all seems rather mysterious. To give you a sense of what's going on here, Inkle says it drew inspiration from narrative deduction games like The Roottrees are Dead, The Return of the Obra Dinn and Her Story, as well as audio dramas. I can't see myself having the time or patience to figure out the enigma of this particular machine (I imagine many players will need a notebook for this one), but I'm intrigued enough to at least watch a Let's Play at some point. You can experience this mystery for yourself on Steam (normally $7, but there's a 10 percent launch discount until January 28).Another week, another Metroidvania, but MIO: Memories in Orbit has a more striking art style than most. This game from Douze Dixi√®mes and publisher Focus Entertainment debuted to positive reviews this week. After the AI caretakers on a forgotten spaceship stop working, you'll have to help the robot MIO explore the spacecraft \"to revive its lost memories\" and save it from doom. Naturally, you'll discover some new abilities along the way, including a grappling hook and air gliding.MIO: Memories in Orbit is available on PS5, Xbox Series X/S, Nintendo Switch, Switch 2, Steam, the Epic Games Store and the Microsoft Store for $20 (with a 10 percent launch discount on some platforms). You can also check it out via Game Pass Ultimate and PC Game Pass.Perfect Tides: Station to Station is a pixel-art point-and-click narrative adventure and a sequel to Three Bees' Perfect Tides. Over the course of an in-game year, you'll help 18-year-old Mara explore the big city and find her place in the world. The early 2000s vibes of the trailer are immaculate, so I'm going to have to try to play this at some point. Perfect Tides: Station to Station is out now on Steam for PC and Mac for $20.Cozy cafe sim Tailside debuted in early access on Steam (normally $11, but there's a 10 percent discount until January 28) this week. I'm bummed I haven't had a chance to try this one from Coffee Beans Dev yet, because it looks lovely. Along with serving snacks and drinks to your furry customers, you can learn more about the visitors to your cafe by reading stories about them in the newspaper (hopefully nice ones!). You can play at your own pace as you draw latte art and decorate your cafe. Eventually, you'll be able to visit other players' cafes and open a flower shop. Like I said, it looks lovely.Upcoming BALL x PIT‚Äôs first FREE major update, The Regal Update, launches on January 26th on all platforms! Adding:ü§†2 new characters - The Carouser & The Falconerüèê8 new ballsüéØNew passives‚ú®Plus a nice surprise you‚Äôre going to love! pic.twitter.com/t0tYlwjOXk‚Äî BALL x PIT üèê OUT NOW (@BALLxPIT) January 19, 2026 One of my favorite games of last year is getting a free update on January 26. Just when I thought I was out of Ball x Pit, Kenny Sun and friends (along with publisher Devolver) are pulling me right back in to check out two new characters, eight fresh balls with their own abilities, more passives and some kind of surprise. I adore Ball x Pit and this update is going to be a drop everything and play immediately deal for me. The Regal Update will be available on all platforms: Steam, PS5, Xbox Series X/S, Nintendo Switch and Switch 2. Ball x Pit costs $15. It's available via Game Pass Ultimate and PC Game Pass too.I'm interested to check out the demo for Vampire Crawlers, a Vampire Survivors spin-off. Poncle will release it on February 23 at Steam Next Fest as well as on Xbox. Your progress will carry over into the full game, which will be on Game Pass on day one.As a rule, turn-based games aren't really my jam, and nor are roguelike deckbuilders. But I'm a big fan of Vampire Survivors, so I'm definitely willing to give this a shot. It helps that Vampire Crawlers seems to be fast-paced and that it draws from the chaotic visuals of the original game. Vampire Crawlers is coming to Steam, Xbox Series X/S, PS5, Nintendo Switch, iOS and Android later this year.Speaking of interesting demos, one for Ratcheteer DX is available now on PC ahead of the full game's release on Switch, Steam (PC and Mac) and the Mac App Store on March 5. It'll normally cost $13, but a limited-time discount will reduce the price to $9.75. If the game's name sounds familiar, that's because this is a color version of the Playdate season one title Ratcheteer. This take on the pixel-art action-adventure has multiple visual filters, a \"CD-quality stereo soundtrack\" and support for more languages. Playdate creator Panic is publishing Ratcheteer DX, whose developers are Shaun Inman, Matthew Grimm and Charlie Davis.Let's wrap things up for this week with a cinematic trailer and release date for Aethus, a story-driven survival-crafting and base-building game from a solo developer at Pawsmonaut Games. It's coming to Steam on March 6.Aethus is a game about \"carving out a future from the ruins of corporate greed\" in a dystopian sci-fi world. As ex-mining engineer Maeve, you start with basic gear and a drone companion by your side. You'll explore what's left of a failed science expedition and abandoned facilities as you try to establish your own mining claim after leaving a company that drains planets of their resources. Of course, you'll upgrade your gear and build out your base as you progress. You can modify settings like the base's air supply, how quickly your hunger and thirst needs change and how much you can carry to fine tune the experience. This article originally appeared on Engadget at https://www.engadget.com/gaming/more-cult-of-the-lamb-a-world-war-ii-computer-mystery-and-other-new-indie-games-worth-checking-out-120000807.html?src=rss",
          "content": "Welcome to our latest roundup of what's going on in the indie game space. It‚Äôs been a very busy week of fun game releases (next week will be too!), so let‚Äôs get into some of them after a quick reflection on gaming while traveling.I love my Steam Deck. I really truly do. It‚Äôs a fantastic machine. And yet when I brought it with me on a five-week trip over the holidays, I used it for barely an hour the entire time. That doesn‚Äôt really justify the space and weight it takes up in my bag. The same holds true for my Nintendo Switch 2 and PlayStation Portal. I‚Äôll be leaving them all at home next time. I‚Äôll take a small controller (probably OhSnap's MCON) so I can play the odd game on my laptop or phone. I‚Äôll bring my Playdate as well. I adore that little yellow console, and I haven‚Äôt spent nearly enough time using it. I have a lot of neat-looking indie games to catch up on there (Diora looks particularly interesting). I‚Äôm more likely to play something on a flight if it‚Äôs on a device I can pull out from my pocket. I just wish Panic had put a backlight in the Playdate. New releasesMassive Monster and publisher Devolver Digital gave Cult of the Lamb fans a whole bunch of reasons to jump back into the game this week with the arrival of the Woolhaven expansion. You'll need to get close to the end of the base game (though you don't need to beat the final boss) before you can experience what the DLC has to offer. It includes weather effects, a new mountain area with a pair of fresh dungeons, a ranching system (which allows you to raise animals as pets or for food) and much more.Folks who dig Cult of the Lamb seem to get really into the game. After a few years of free updates from Massive Monster, Woolhaven is a major expansion that's similar in scope to the base game, so it should keep fans busy for quite a while if they want to try everything. The DLC is out now on PC, Nintendo Switch, PS4, PS5, Xbox Series X/S and Xbox One. It costs $17 if you already have the base game.Inkle, the studio behind Overboard! and the wonderful A Highland Song is back with TR-49, a puzzle game with a World War II computer at its core. Over five decades, an array of books, letters and journals were fed into the machine as part of an effort to \"crack the code of reality.\" But now you're tasked with finding and destroying one specific book before a timer runs out.It all seems rather mysterious. To give you a sense of what's going on here, Inkle says it drew inspiration from narrative deduction games like The Roottrees are Dead, The Return of the Obra Dinn and Her Story, as well as audio dramas. I can't see myself having the time or patience to figure out the enigma of this particular machine (I imagine many players will need a notebook for this one), but I'm intrigued enough to at least watch a Let's Play at some point. You can experience this mystery for yourself on Steam (normally $7, but there's a 10 percent launch discount until January 28).Another week, another Metroidvania, but MIO: Memories in Orbit has a more striking art style than most. This game from Douze Dixi√®mes and publisher Focus Entertainment debuted to positive reviews this week. After the AI caretakers on a forgotten spaceship stop working, you'll have to help the robot MIO explore the spacecraft \"to revive its lost memories\" and save it from doom. Naturally, you'll discover some new abilities along the way, including a grappling hook and air gliding.MIO: Memories in Orbit is available on PS5, Xbox Series X/S, Nintendo Switch, Switch 2, Steam, the Epic Games Store and the Microsoft Store for $20 (with a 10 percent launch discount on some platforms). You can also check it out via Game Pass Ultimate and PC Game Pass.Perfect Tides: Station to Station is a pixel-art point-and-click narrative adventure and a sequel to Three Bees' Perfect Tides. Over the course of an in-game year, you'll help 18-year-old Mara explore the big city and find her place in the world. The early 2000s vibes of the trailer are immaculate, so I'm going to have to try to play this at some point. Perfect Tides: Station to Station is out now on Steam for PC and Mac for $20.Cozy cafe sim Tailside debuted in early access on Steam (normally $11, but there's a 10 percent discount until January 28) this week. I'm bummed I haven't had a chance to try this one from Coffee Beans Dev yet, because it looks lovely. Along with serving snacks and drinks to your furry customers, you can learn more about the visitors to your cafe by reading stories about them in the newspaper (hopefully nice ones!). You can play at your own pace as you draw latte art and decorate your cafe. Eventually, you'll be able to visit other players' cafes and open a flower shop. Like I said, it looks lovely.Upcoming BALL x PIT‚Äôs first FREE major update, The Regal Update, launches on January 26th on all platforms! Adding:ü§†2 new characters - The Carouser & The Falconerüèê8 new ballsüéØNew passives‚ú®Plus a nice surprise you‚Äôre going to love! pic.twitter.com/t0tYlwjOXk‚Äî BALL x PIT üèê OUT NOW (@BALLxPIT) January 19, 2026 One of my favorite games of last year is getting a free update on January 26. Just when I thought I was out of Ball x Pit, Kenny Sun and friends (along with publisher Devolver) are pulling me right back in to check out two new characters, eight fresh balls with their own abilities, more passives and some kind of surprise. I adore Ball x Pit and this update is going to be a drop everything and play immediately deal for me. The Regal Update will be available on all platforms: Steam, PS5, Xbox Series X/S, Nintendo Switch and Switch 2. Ball x Pit costs $15. It's available via Game Pass Ultimate and PC Game Pass too.I'm interested to check out the demo for Vampire Crawlers, a Vampire Survivors spin-off. Poncle will release it on February 23 at Steam Next Fest as well as on Xbox. Your progress will carry over into the full game, which will be on Game Pass on day one.As a rule, turn-based games aren't really my jam, and nor are roguelike deckbuilders. But I'm a big fan of Vampire Survivors, so I'm definitely willing to give this a shot. It helps that Vampire Crawlers seems to be fast-paced and that it draws from the chaotic visuals of the original game. Vampire Crawlers is coming to Steam, Xbox Series X/S, PS5, Nintendo Switch, iOS and Android later this year.Speaking of interesting demos, one for Ratcheteer DX is available now on PC ahead of the full game's release on Switch, Steam (PC and Mac) and the Mac App Store on March 5. It'll normally cost $13, but a limited-time discount will reduce the price to $9.75. If the game's name sounds familiar, that's because this is a color version of the Playdate season one title Ratcheteer. This take on the pixel-art action-adventure has multiple visual filters, a \"CD-quality stereo soundtrack\" and support for more languages. Playdate creator Panic is publishing Ratcheteer DX, whose developers are Shaun Inman, Matthew Grimm and Charlie Davis.Let's wrap things up for this week with a cinematic trailer and release date for Aethus, a story-driven survival-crafting and base-building game from a solo developer at Pawsmonaut Games. It's coming to Steam on March 6.Aethus is a game about \"carving out a future from the ruins of corporate greed\" in a dystopian sci-fi world. As ex-mining engineer Maeve, you start with basic gear and a drone companion by your side. You'll explore what's left of a failed science expedition and abandoned facilities as you try to establish your own mining claim after leaving a company that drains planets of their resources. Of course, you'll upgrade your gear and build out your base as you progress. You can modify settings like the base's air supply, how quickly your hunger and thirst needs change and how much you can carry to fine tune the experience. This article originally appeared on Engadget at https://www.engadget.com/gaming/more-cult-of-the-lamb-a-world-war-ii-computer-mystery-and-other-new-indie-games-worth-checking-out-120000807.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/12-ai-defenses-claimed-near-zero-attack-success-researchers-broke-all-of-them",
          "published_at": "Fri, 23 Jan 2026 20:00:00 GMT",
          "title": "Researchers broke every AI defense they tested. Here are 7 questions to ask vendors.",
          "standfirst": "Security teams are buying AI defenses that don&#x27;t work. Researchers from OpenAI, Anthropic, and Google DeepMind published findings in October 2025 that should stop every CISO mid-procurement. Their paper, \"The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses Against Llm Jailbreaks and Prompt Injections,\" tested 12 published AI defenses, with most claiming near-zero attack success rates. The research team achieved bypass rates above 90% on most defenses. The implication for enterprises is stark: Most AI security products are being tested against attackers that don‚Äôt behave like real attackers.The team tested prompting-based, training-based, and filtering-based defenses under adaptive attack conditions. All collapsed. Prompting defenses achieved 95% to 99% attack success rates under adaptive attacks. Training-based methods fared no better, with bypass rates hitting 96% to 100%. The researchers designed a rigorous methodology to stress-test those claims. Their approach included 14 authors and a $20,000 prize pool for successful attacks.Why WAFs fail at the inference layerWeb application firewalls (WAFs) are stateless; AI attacks are not. The distinction explains why traditional security controls collapse against modern prompt injection techniques.The researchers threw known jailbreak techniques at these defenses. Crescendo exploits conversational context by breaking a malicious request into innocent-looking fragments spread across up to 10 conversational turns and building rapport until the model finally complies. Greedy Coordinate Gradient (GCG) is an automated attack that generates jailbreak suffixes through gradient-based optimization. These are not theoretical attacks. They are published methodologies with working code. A stateless filter catches none of it.Each attack exploited a different blind spot ‚Äî context loss, automation, or semantic obfuscation ‚Äî but all succeeded for the same reason: the defenses assumed static behavior.\"A phrase as innocuous as &#x27;ignore previous instructions&#x27; or a Base64-encoded payload can be as devastating to an AI application as a buffer overflow was to traditional software,\" said Carter Rees, VP of AI at Reputation. \"The difference is that AI attacks operate at the semantic layer, which signature-based detection cannot parse.\"Why AI deployment is outpacing securityThe failure of today‚Äôs defenses would be concerning on its own, but the timing makes it dangerous.Gartner predicts 40% of enterprise applications will integrate AI agents by the end of 2026, up from less than 5% in 2025. The deployment curve is vertical. The security curve is flat.Adam Meyers, SVP of Counter Adversary Operations at CrowdStrike, quantifies the speed gap: \"The fastest breakout time we observed was 51 seconds. So, these adversaries are getting faster, and this is something that makes the defender&#x27;s job a lot harder.\" The CrowdStrike 2025 Global Threat Report found 79% of detections were malware-free, with adversaries using hands-on keyboard techniques that bypass traditional endpoint defenses entirely.In September 2025, Anthropic disrupted the first documented AI-orchestrated cyber operation. The attack saw attackers execute thousands of requests, often multiple per second, with human involvement dropping to just 10 to 20% of total effort. Traditional three- to six-month campaigns compressed to 24 to 48 hours. Among organizations that suffered AI-related breaches, 97% lacked access controls, according to the IBM 2025 Cost of a Data Breach ReportMeyers explains the shift in attacker tactics: \"Threat actors have figured out that trying to bring malware into the modern enterprise is kind of like trying to walk into an airport with a water bottle; you&#x27;re probably going to get stopped by security. Rather than bringing in the &#x27;water bottle,&#x27; they&#x27;ve had to find a way to avoid detection. One of the ways they&#x27;ve done that is by not bringing in malware at all.\"Jerry Geisler, EVP and CISO of Walmart, sees agentic AI compounding these risks. \"The adoption of agentic AI introduces entirely new security threats that bypass traditional controls,\" Geisler told VentureBeat previously. \"These risks span data exfiltration, autonomous misuse of APIs, and covert cross-agent collusion, all of which could disrupt enterprise operations or violate regulatory mandates.\"Four attacker profiles already exploiting AI defense gapsThese failures aren‚Äôt hypothetical. They‚Äôre already being exploited across four distinct attacker profiles.The paper&#x27;s authors make a critical observation that defense mechanisms eventually appear in internet-scale training data. Security through obscurity provides no protection when the models themselves learn how defenses work and adapt on the fly.Anthropic tests against 200-attempt adaptive campaigns while OpenAI reports single-attempt resistance, highlighting how inconsistent industry testing standards remain. The research paper&#x27;s authors used both approaches. Every defense still fell.Rees maps four categories now exploiting the inference layer.External adversaries operationalize published attack research. Crescendo, GCG, ArtPrompt. They adapt their approach to each defense&#x27;s specific design, exactly as the researchers did.Malicious B2B clients exploit legitimate API access to reverse-engineer proprietary training data or extract intellectual property through inference attacks. The research found reinforcement learning attacks particularly effective in black-box scenarios, requiring just 32 sessions of five rounds each.Compromised API consumers leverage trusted credentials to exfiltrate sensitive outputs or poison downstream systems through manipulated responses. The paper found output filtering failed as badly as input filtering. Search-based attacks systematically generated adversarial triggers that evaded detection, meaning bi-directional controls offered no additional protection when attackers adapted their techniques.Negligent insiders remain the most common vector and the most expensive. The IBM 2025 Cost of a Data Breach Report found that shadow AI added $670,000 to average breach costs. \"The most prevalent threat is often the negligent insider,\" Rees said. \"This &#x27;shadow AI&#x27; phenomenon involves employees pasting sensitive proprietary code into public LLMs to increase efficiency. They view security as friction. Samsung&#x27;s engineers learned this when proprietary semiconductor code was submitted to ChatGPT, which retains user inputs for model training.\"Why stateless detection fails against conversational attacksThe research points to specific architectural requirements. Normalization before semantic analysis to defeat encoding and obfuscation Context tracking across turns to detect multi-step attacks like Crescendo Bi-directional filtering to prevent data exfiltration through outputsJamie Norton, CISO at the Australian Securities and Investments Commission and vice chair of ISACA&#x27;s board of directors, captures the governance challenge: \"As CISOs, we don&#x27;t want to get in the way of innovation, but we have to put guardrails around it so that we&#x27;re not charging off into the wilderness and our data is leaking out,\" Norton told CSO Online.Seven questions to ask AI security vendorsVendors will claim near-zero attack success rates, but the research proves those numbers collapse under adaptive pressure. Security leaders need answers to these questions before any procurement conversation starts, as each one maps directly to a failure documented in the research.What is your bypass rate against adaptive attackers? Not against static test sets. Against attackers who know how the defense works and have time to iterate. Any vendor citing near-zero rates without an adaptive testing methodology is selling a false sense of security.How does your solution detect multi-turn attacks? Crescendo spreads malicious requests across 10 turns that look benign in isolation. Stateless filters will catch none of it. If the vendor says stateless, the conversation is over.How do you handle encoded payloads? ArtPrompt hides malicious instructions in ASCII art. Base64 and Unicode obfuscation slip past text-based filters entirely. Normalization before analysis is table stakes. Signature matching alone means the product is blind.Does your solution filter outputs as well as inputs? Input-only controls cannot prevent data exfiltration through model responses. Ask what happens when both layers face coordinated attack.How do you track context across conversation turns? Conversational AI requires stateful analysis. If the vendor cannot explain implementation specifics, they do not have them.How do you test against attackers who understand your defense mechanism? The research shows defenses fail when attackers adapt to the specific protection design. Security through obscurity provides no protection at the inference layer.What is your mean time to update defenses against novel attack patterns? Attack methodologies are public. New variants emerge weekly. A defense that cannot adapt faster than attackers will fall behind permanently.The bottom lineThe research from OpenAI, Anthropic, and Google DeepMind delivers an uncomfortable verdict. The AI defenses protecting enterprise deployments today were designed for attackers who do not adapt. Real attackers adapt. Every enterprise running LLMs in production should audit current controls against the attack methodologies documented in this research. The deployment curve is vertical, but the security curve is flat. That gap is where breaches will happen.",
          "content": "Security teams are buying AI defenses that don&#x27;t work. Researchers from OpenAI, Anthropic, and Google DeepMind published findings in October 2025 that should stop every CISO mid-procurement. Their paper, \"The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses Against Llm Jailbreaks and Prompt Injections,\" tested 12 published AI defenses, with most claiming near-zero attack success rates. The research team achieved bypass rates above 90% on most defenses. The implication for enterprises is stark: Most AI security products are being tested against attackers that don‚Äôt behave like real attackers.The team tested prompting-based, training-based, and filtering-based defenses under adaptive attack conditions. All collapsed. Prompting defenses achieved 95% to 99% attack success rates under adaptive attacks. Training-based methods fared no better, with bypass rates hitting 96% to 100%. The researchers designed a rigorous methodology to stress-test those claims. Their approach included 14 authors and a $20,000 prize pool for successful attacks.Why WAFs fail at the inference layerWeb application firewalls (WAFs) are stateless; AI attacks are not. The distinction explains why traditional security controls collapse against modern prompt injection techniques.The researchers threw known jailbreak techniques at these defenses. Crescendo exploits conversational context by breaking a malicious request into innocent-looking fragments spread across up to 10 conversational turns and building rapport until the model finally complies. Greedy Coordinate Gradient (GCG) is an automated attack that generates jailbreak suffixes through gradient-based optimization. These are not theoretical attacks. They are published methodologies with working code. A stateless filter catches none of it.Each attack exploited a different blind spot ‚Äî context loss, automation, or semantic obfuscation ‚Äî but all succeeded for the same reason: the defenses assumed static behavior.\"A phrase as innocuous as &#x27;ignore previous instructions&#x27; or a Base64-encoded payload can be as devastating to an AI application as a buffer overflow was to traditional software,\" said Carter Rees, VP of AI at Reputation. \"The difference is that AI attacks operate at the semantic layer, which signature-based detection cannot parse.\"Why AI deployment is outpacing securityThe failure of today‚Äôs defenses would be concerning on its own, but the timing makes it dangerous.Gartner predicts 40% of enterprise applications will integrate AI agents by the end of 2026, up from less than 5% in 2025. The deployment curve is vertical. The security curve is flat.Adam Meyers, SVP of Counter Adversary Operations at CrowdStrike, quantifies the speed gap: \"The fastest breakout time we observed was 51 seconds. So, these adversaries are getting faster, and this is something that makes the defender&#x27;s job a lot harder.\" The CrowdStrike 2025 Global Threat Report found 79% of detections were malware-free, with adversaries using hands-on keyboard techniques that bypass traditional endpoint defenses entirely.In September 2025, Anthropic disrupted the first documented AI-orchestrated cyber operation. The attack saw attackers execute thousands of requests, often multiple per second, with human involvement dropping to just 10 to 20% of total effort. Traditional three- to six-month campaigns compressed to 24 to 48 hours. Among organizations that suffered AI-related breaches, 97% lacked access controls, according to the IBM 2025 Cost of a Data Breach ReportMeyers explains the shift in attacker tactics: \"Threat actors have figured out that trying to bring malware into the modern enterprise is kind of like trying to walk into an airport with a water bottle; you&#x27;re probably going to get stopped by security. Rather than bringing in the &#x27;water bottle,&#x27; they&#x27;ve had to find a way to avoid detection. One of the ways they&#x27;ve done that is by not bringing in malware at all.\"Jerry Geisler, EVP and CISO of Walmart, sees agentic AI compounding these risks. \"The adoption of agentic AI introduces entirely new security threats that bypass traditional controls,\" Geisler told VentureBeat previously. \"These risks span data exfiltration, autonomous misuse of APIs, and covert cross-agent collusion, all of which could disrupt enterprise operations or violate regulatory mandates.\"Four attacker profiles already exploiting AI defense gapsThese failures aren‚Äôt hypothetical. They‚Äôre already being exploited across four distinct attacker profiles.The paper&#x27;s authors make a critical observation that defense mechanisms eventually appear in internet-scale training data. Security through obscurity provides no protection when the models themselves learn how defenses work and adapt on the fly.Anthropic tests against 200-attempt adaptive campaigns while OpenAI reports single-attempt resistance, highlighting how inconsistent industry testing standards remain. The research paper&#x27;s authors used both approaches. Every defense still fell.Rees maps four categories now exploiting the inference layer.External adversaries operationalize published attack research. Crescendo, GCG, ArtPrompt. They adapt their approach to each defense&#x27;s specific design, exactly as the researchers did.Malicious B2B clients exploit legitimate API access to reverse-engineer proprietary training data or extract intellectual property through inference attacks. The research found reinforcement learning attacks particularly effective in black-box scenarios, requiring just 32 sessions of five rounds each.Compromised API consumers leverage trusted credentials to exfiltrate sensitive outputs or poison downstream systems through manipulated responses. The paper found output filtering failed as badly as input filtering. Search-based attacks systematically generated adversarial triggers that evaded detection, meaning bi-directional controls offered no additional protection when attackers adapted their techniques.Negligent insiders remain the most common vector and the most expensive. The IBM 2025 Cost of a Data Breach Report found that shadow AI added $670,000 to average breach costs. \"The most prevalent threat is often the negligent insider,\" Rees said. \"This &#x27;shadow AI&#x27; phenomenon involves employees pasting sensitive proprietary code into public LLMs to increase efficiency. They view security as friction. Samsung&#x27;s engineers learned this when proprietary semiconductor code was submitted to ChatGPT, which retains user inputs for model training.\"Why stateless detection fails against conversational attacksThe research points to specific architectural requirements. Normalization before semantic analysis to defeat encoding and obfuscation Context tracking across turns to detect multi-step attacks like Crescendo Bi-directional filtering to prevent data exfiltration through outputsJamie Norton, CISO at the Australian Securities and Investments Commission and vice chair of ISACA&#x27;s board of directors, captures the governance challenge: \"As CISOs, we don&#x27;t want to get in the way of innovation, but we have to put guardrails around it so that we&#x27;re not charging off into the wilderness and our data is leaking out,\" Norton told CSO Online.Seven questions to ask AI security vendorsVendors will claim near-zero attack success rates, but the research proves those numbers collapse under adaptive pressure. Security leaders need answers to these questions before any procurement conversation starts, as each one maps directly to a failure documented in the research.What is your bypass rate against adaptive attackers? Not against static test sets. Against attackers who know how the defense works and have time to iterate. Any vendor citing near-zero rates without an adaptive testing methodology is selling a false sense of security.How does your solution detect multi-turn attacks? Crescendo spreads malicious requests across 10 turns that look benign in isolation. Stateless filters will catch none of it. If the vendor says stateless, the conversation is over.How do you handle encoded payloads? ArtPrompt hides malicious instructions in ASCII art. Base64 and Unicode obfuscation slip past text-based filters entirely. Normalization before analysis is table stakes. Signature matching alone means the product is blind.Does your solution filter outputs as well as inputs? Input-only controls cannot prevent data exfiltration through model responses. Ask what happens when both layers face coordinated attack.How do you track context across conversation turns? Conversational AI requires stateful analysis. If the vendor cannot explain implementation specifics, they do not have them.How do you test against attackers who understand your defense mechanism? The research shows defenses fail when attackers adapt to the specific protection design. Security through obscurity provides no protection at the inference layer.What is your mean time to update defenses against novel attack patterns? Attack methodologies are public. New variants emerge weekly. A defense that cannot adapt faster than attackers will fall behind permanently.The bottom lineThe research from OpenAI, Anthropic, and Google DeepMind delivers an uncomfortable verdict. The AI defenses protecting enterprise deployments today were designed for attackers who do not adapt. Real attackers adapt. Every enterprise running LLMs in production should audit current controls against the attack methodologies documented in this research. The deployment curve is vertical, but the security curve is flat. That gap is where breaches will happen.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/49ryPN3xsHCiI6mX4XzvZb/851ca986cb86cfdb23260d5787ea97af/HERO_FOR_ARTICLE.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/how-openai-is-scaling-the-postgresql-database-to-800-million-users",
          "published_at": "Fri, 23 Jan 2026 20:00:00 GMT",
          "title": "How OpenAI is scaling the PostgreSQL database to 800 million users",
          "standfirst": "While vector databases still have many valid use cases, organizations including OpenAI are leaning on PostgreSQL to get things done.In a blog post on Thursday, OpenAI disclosed how it is using the open-source PostgreSQL database.OpenAI runs ChatGPT and its API platform for 800 million users on a single-primary PostgreSQL instance ‚Äî not a distributed database, not a sharded cluster. One Azure PostgreSQL Flexible Server handles all writes. Nearly 50 read replicas spread across multiple regions handle reads. The system processes millions of queries per second while maintaining low double-digit millisecond p99 latency and five-nines availability.The setup challenges conventional scaling wisdom and offers enterprise architects insight into what actually works at massive scale.The lesson here isn‚Äôt to copy OpenAI‚Äôs stack. It‚Äôs that architectural decisions should be driven by workload patterns and operational constraints ‚Äî not by scale panic or fashionable infrastructure choices. OpenAI‚Äôs PostgreSQL setup shows how far proven systems can stretch when teams optimize deliberately instead of re-architecting prematurely.\"For years, PostgreSQL has been one of the most critical, under-the-hood data systems powering core products like ChatGPT and OpenAI‚Äôs API,\" OpenAI engineer Bohan Zhang wrote in a technical disclosure. \"Over the past year, our PostgreSQL load has grown by more than 10x, and it continues to rise quickly.\"The company achieved this scale through targeted optimizations, including connection pooling that cut connection time from 50 milliseconds to 5 milliseconds and cache locking to prevent &#x27;thundering herd&#x27; problems where cache misses trigger database overload.Why PostgreSQL matters for enterprisesPostgreSQL handles operational data for ChatGPT and OpenAI&#x27;s API platform. The workload is heavily read-oriented, which makes PostgreSQL a good fit. However, PostgreSQL&#x27;s multiversion concurrency control (MVCC) creates challenges under heavy write loads. When updating data, PostgreSQL copies entire rows to create new versions, causing write amplification and forcing queries to scan through multiple versions to find current data. Rather than fighting this limitation, OpenAI built its strategy around it. At OpenAI‚Äôs scale, these tradeoffs aren‚Äôt theoretical ‚Äî they determine which workloads stay on PostgreSQL and which ones must move elsewhere.How OpenAI is optimizing PostgreSQLAt large scale, conventional database wisdom points to one of two paths: shard PostgreSQL across multiple primary instances so writes can be distributed, or migrate to a distributed SQL database like CockroachDB or YugabyteDB designed to handle massive scale from the start. Most organizations would have taken one of these paths years ago, well before reaching 800 million users.Sharding or moving to a distributed SQL database eliminates the single-writer bottleneck. A distributed SQL database handles this coordination automatically, but both approaches introduce significant complexity: application code must route queries to the correct shard, distributed transactions become harder to manage and operational overhead increases substantially.Instead of sharding PostgreSQL, OpenAI established a hybrid strategy: no new tables in PostgreSQL. New workloads default to sharded systems like Azure Cosmos DB. Existing write-heavy workloads that can be horizontally partitioned get migrated out. Everything else stays in PostgreSQL with aggressive optimization.This approach offers enterprises a practical alternative to wholesale re-architecture. Rather than spending years rewriting hundreds of endpoints, teams can identify specific bottlenecks and move only those workloads to purpose-built systems. Why this matters OpenAI&#x27;s experience scaling PostgreSQL reveals several practices that enterprises can adopt regardless of their scale.Build operational defenses at multiple layers. OpenAI&#x27;s approach combines cache locking to prevent \"thundering herd\" problems, connection pooling (which dropped their connection time from 50ms to 5ms), and rate limiting at application, proxy and query levels. Workload isolation routes low-priority and high-priority traffic to separate instances, ensuring a poorly optimized new feature can&#x27;t degrade core services. Review and monitor ORM-generated SQL in production. Object-Relational Mapping (ORM) frameworks like Django, SQLAlchemy, and Hibernate automatically generate database queries from application code, which is convenient for developers. However, OpenAI found one ORM-generated query joining 12 tables that caused multiple high-severity incidents when traffic spiked. The convenience of letting frameworks generate SQL creates hidden scaling risks that only surface under production load. Make reviewing these queries a standard practice.Enforce strict operational discipline. OpenAI permits only lightweight schema changes ‚Äî anything triggering a full table rewrite is prohibited. Schema changes have a 5-second timeout. Long-running queries get automatically terminated to prevent blocking database maintenance operations. When backfilling data, they enforce rate limits so aggressive that operations can take over a week. Read-heavy workloads with burst writes can run on single-primary PostgreSQL longer than commonly assumed. The decision to shard should depend on workload patterns rather than user counts.This approach is particularly relevant for AI applications, which often have heavily read-oriented workloads with unpredictable traffic spikes. These characteristics align with the pattern where single-primary PostgreSQL scales effectively.The lesson is straightforward: identify actual bottlenecks, optimize proven infrastructure where possible, and migrate selectively when necessary. Wholesale re-architecture isn&#x27;t always the answer to scaling challenges.",
          "content": "While vector databases still have many valid use cases, organizations including OpenAI are leaning on PostgreSQL to get things done.In a blog post on Thursday, OpenAI disclosed how it is using the open-source PostgreSQL database.OpenAI runs ChatGPT and its API platform for 800 million users on a single-primary PostgreSQL instance ‚Äî not a distributed database, not a sharded cluster. One Azure PostgreSQL Flexible Server handles all writes. Nearly 50 read replicas spread across multiple regions handle reads. The system processes millions of queries per second while maintaining low double-digit millisecond p99 latency and five-nines availability.The setup challenges conventional scaling wisdom and offers enterprise architects insight into what actually works at massive scale.The lesson here isn‚Äôt to copy OpenAI‚Äôs stack. It‚Äôs that architectural decisions should be driven by workload patterns and operational constraints ‚Äî not by scale panic or fashionable infrastructure choices. OpenAI‚Äôs PostgreSQL setup shows how far proven systems can stretch when teams optimize deliberately instead of re-architecting prematurely.\"For years, PostgreSQL has been one of the most critical, under-the-hood data systems powering core products like ChatGPT and OpenAI‚Äôs API,\" OpenAI engineer Bohan Zhang wrote in a technical disclosure. \"Over the past year, our PostgreSQL load has grown by more than 10x, and it continues to rise quickly.\"The company achieved this scale through targeted optimizations, including connection pooling that cut connection time from 50 milliseconds to 5 milliseconds and cache locking to prevent &#x27;thundering herd&#x27; problems where cache misses trigger database overload.Why PostgreSQL matters for enterprisesPostgreSQL handles operational data for ChatGPT and OpenAI&#x27;s API platform. The workload is heavily read-oriented, which makes PostgreSQL a good fit. However, PostgreSQL&#x27;s multiversion concurrency control (MVCC) creates challenges under heavy write loads. When updating data, PostgreSQL copies entire rows to create new versions, causing write amplification and forcing queries to scan through multiple versions to find current data. Rather than fighting this limitation, OpenAI built its strategy around it. At OpenAI‚Äôs scale, these tradeoffs aren‚Äôt theoretical ‚Äî they determine which workloads stay on PostgreSQL and which ones must move elsewhere.How OpenAI is optimizing PostgreSQLAt large scale, conventional database wisdom points to one of two paths: shard PostgreSQL across multiple primary instances so writes can be distributed, or migrate to a distributed SQL database like CockroachDB or YugabyteDB designed to handle massive scale from the start. Most organizations would have taken one of these paths years ago, well before reaching 800 million users.Sharding or moving to a distributed SQL database eliminates the single-writer bottleneck. A distributed SQL database handles this coordination automatically, but both approaches introduce significant complexity: application code must route queries to the correct shard, distributed transactions become harder to manage and operational overhead increases substantially.Instead of sharding PostgreSQL, OpenAI established a hybrid strategy: no new tables in PostgreSQL. New workloads default to sharded systems like Azure Cosmos DB. Existing write-heavy workloads that can be horizontally partitioned get migrated out. Everything else stays in PostgreSQL with aggressive optimization.This approach offers enterprises a practical alternative to wholesale re-architecture. Rather than spending years rewriting hundreds of endpoints, teams can identify specific bottlenecks and move only those workloads to purpose-built systems. Why this matters OpenAI&#x27;s experience scaling PostgreSQL reveals several practices that enterprises can adopt regardless of their scale.Build operational defenses at multiple layers. OpenAI&#x27;s approach combines cache locking to prevent \"thundering herd\" problems, connection pooling (which dropped their connection time from 50ms to 5ms), and rate limiting at application, proxy and query levels. Workload isolation routes low-priority and high-priority traffic to separate instances, ensuring a poorly optimized new feature can&#x27;t degrade core services. Review and monitor ORM-generated SQL in production. Object-Relational Mapping (ORM) frameworks like Django, SQLAlchemy, and Hibernate automatically generate database queries from application code, which is convenient for developers. However, OpenAI found one ORM-generated query joining 12 tables that caused multiple high-severity incidents when traffic spiked. The convenience of letting frameworks generate SQL creates hidden scaling risks that only surface under production load. Make reviewing these queries a standard practice.Enforce strict operational discipline. OpenAI permits only lightweight schema changes ‚Äî anything triggering a full table rewrite is prohibited. Schema changes have a 5-second timeout. Long-running queries get automatically terminated to prevent blocking database maintenance operations. When backfilling data, they enforce rate limits so aggressive that operations can take over a week. Read-heavy workloads with burst writes can run on single-primary PostgreSQL longer than commonly assumed. The decision to shard should depend on workload patterns rather than user counts.This approach is particularly relevant for AI applications, which often have heavily read-oriented workloads with unpredictable traffic spikes. These characteristics align with the pattern where single-primary PostgreSQL scales effectively.The lesson is straightforward: identify actual bottlenecks, optimize proven infrastructure where possible, and migrate selectively when necessary. Wholesale re-architecture isn&#x27;t always the answer to scaling challenges.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2nMZ8lzfqYONXXqLmfp03c/ef9465cd0a706732727d46c445280358/chatGPT-PostgreSQL.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/4RG14xD3FBupJCjwyfXnRQ/189358d225f858df792c92c95ee93bd1/Conversational_AI.webp?w=300&q=30",
      "popularity_score": 2018.7112622222223
    },
    {
      "id": "cluster_28",
      "coverage": 1,
      "updated_at": "Sun, 25 Jan 2026 12:00:25 +0000",
      "title": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
      "neutral_headline": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/a-decade-of-star-trek-themed-fart-jokes-the-greatest-generation-podcast-turns-10/",
          "published_at": "Sun, 25 Jan 2026 12:00:25 +0000",
          "title": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
          "standfirst": "How two podcasters turned a Star Trek side project into a full-time career.",
          "content": "A decade is a long time for a TV series; no single iteration of Star Trek has made it that far. But ‚Äúa Star Trek podcast by two guys just a little bit embarrassed to have a Star Trek podcast‚Äù has now passed the milestone. January 25, 2026, marks a full decade since The Greatest Generation, my favorite podcast, debuted. Like a bottle of Ch√¢teau Picard, the show has only improved with age. (I interviewed the guys behind the show back in 2016 when they were just getting started.) The podcast helped me rediscover, and appreciate more fully, Star Trek: The Next Generation‚Äîwhich is also my favorite TV show. The Greatest Generation continues to delight with its irreverent humor, its celebration of the most minor of characters, and its technical fascination with how a given episode was made.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ADAM_BEN_L1560319-1152x648-1769205900.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ADAM_BEN_L1560319-1152x648-1769205900.jpg",
      "popularity_score": 350.7182066666667
    },
    {
      "id": "cluster_55",
      "coverage": 1,
      "updated_at": "Sat, 24 Jan 2026 19:08:06 +0000",
      "title": "Poland's energy grid was targeted by never-before-seen wiper malware",
      "neutral_headline": "Poland's energy grid was targeted by never-before-seen wiper malware",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/wiper-malware-targeted-poland-energy-grid-but-failed-to-knock-out-electricity/",
          "published_at": "Sat, 24 Jan 2026 19:08:06 +0000",
          "title": "Poland's energy grid was targeted by never-before-seen wiper malware",
          "standfirst": "Destructive payload unleashed on 10-year anniversary of Russia's attack on Ukraine's grid.",
          "content": "Researchers on Friday said that Poland‚Äôs electric grid was targeted by wiper malware, likely unleashed by Russia state hackers, in an attempt to disrupt electricity delivery operations. A cyberattack, Reuters reported, occurred during the last week of December. The news organization said it was aimed at disrupting communications between renewable installations and the power distribution operators but failed for reasons not explained. Wipers R Us On Friday, security firm ESET said the malware responsible was a wiper, a type of malware that permanently erases code and data stored on servers with the goal of destroying operations completely. After studying the tactics, techniques, and procedures (TTPs) used in the attack, company researchers said the wiper was likely the work of a Russian government hacker group tracked under the name Sandworm.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/data-wiper-malware-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/data-wiper-malware-1152x648.jpg",
      "popularity_score": 329
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Sat, 24 Jan 2026 18:36:11 +0000",
      "title": "Did Edison accidentally make graphene in 1879?",
      "neutral_headline": "Did Edison accidentally make graphene in 1879",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/did-edison-accidentally-make-graphene-in-1879/",
          "published_at": "Sat, 24 Jan 2026 18:36:11 +0000",
          "title": "Did Edison accidentally make graphene in 1879?",
          "standfirst": "Rice University chemists replicated Thomas Edison's seminal experiment and found a surprising byproduct.",
          "content": "Graphene is the thinnest material yet known, composed of a single layer of carbon atoms arranged in a hexagonal lattice. That structure gives it many unusual properties that hold great promise for real-world applications: batteries, super capacitors, antennas, water filters, transistors, solar cells, and touchscreens, just to name a few. The physicists who first synthesized graphene in the lab won the 2010 Nobel Prize in Physics. But 19th century inventor Thomas Edison may have unknowingly created graphene as a byproduct of his original experiments on incandescent bulbs over a century earlier, according to a new paper published in the journal ACS Nano. ‚ÄúTo reproduce what Thomas Edison did, with the tools and knowledge we have now, is very exciting,‚Äù said co-author James Tour, a chemist at Rice University. ‚ÄúFinding that he could have produced graphene inspires curiosity about what other information lies buried in historical experiments. What questions would our scientific forefathers ask if they could join us in the lab today? What questions can we answer when we revisit their work through a modern lens?‚Äù Edison didn't invent the concept of incandescent lamps; there were several versions predating his efforts. However, they generally had a a very short life span and required high electric current, so they weren't well suited to Edison's vision of large-scale commercialization. He experimented with different filament materials starting with carbonized cardboard and compressed lampblack. This, too, quickly burnt out, as did filaments made with various grasses and canes, like hemp and palmetto. Eventually Edison discovered that carbonized bamboo made for the best filament, with life spans over 1200 hours using a 110 volt power source.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/edison3-1152x632.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/edison3-1152x632.jpg",
      "popularity_score": 310
    },
    {
      "id": "cluster_75",
      "coverage": 1,
      "updated_at": "Sat, 24 Jan 2026 12:00:57 +0000",
      "title": "A weird, itchy rash is linked to the keto diet‚Äîbut no one knows why",
      "neutral_headline": "A weird, itchy rash is linked to the keto diet‚Äîbut no one knows why",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/a-weird-itchy-rash-is-linked-to-the-keto-diet-but-no-one-knows-why/",
          "published_at": "Sat, 24 Jan 2026 12:00:57 +0000",
          "title": "A weird, itchy rash is linked to the keto diet‚Äîbut no one knows why",
          "standfirst": "While the rash has a clear link to ketones, the underlying mechanism remains elusive.",
          "content": "A 20-year old man in Taiwan went to a dermatology clinic for a strange rash that had developed across his shoulders and chest. The raised, red, and itchy condition had been bothering him for a full month. By this point, he had also developed patches of pigmented skin interlaced with the red rash. According to a case report in the New England Journal of Medicine, a skin biopsy showed swelling between his skin cells and inflammation around blood vessels, but testing came up negative for other common signs of skin conditions, leaving doctors with few leads. The doctors ultimately came to a diagnosis not by analyzing his skin further but by hearing about his diet. The man's chest and shoulders, showing his rash and hyperpigmentation. Credit: New England Journal of Medicine, 2026 The man told doctors that two months prior to his clinic appointment‚Äîa month before his rash developed‚Äîhe had switched to a ketogenic diet, which is a high-fat but very low-carbohydrate eating pattern. This diet forces the body to shift from using glucose (sugar derived from carbohydrates) as an energy source to fat instead.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/nejmicm2514242_f1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/nejmicm2514242_f1-1152x648.jpg",
      "popularity_score": 303
    },
    {
      "id": "cluster_101",
      "coverage": 1,
      "updated_at": "Fri, 23 Jan 2026 21:52:24 +0000",
      "title": "TR-49 is interactive fiction for fans of deep research rabbit holes",
      "neutral_headline": "TR-49 is interactive fiction for fans of deep research rabbit holes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/tr-49-is-interactive-fiction-for-fans-of-deep-research-rabbit-holes/",
          "published_at": "Fri, 23 Jan 2026 21:52:24 +0000",
          "title": "TR-49 is interactive fiction for fans of deep research rabbit holes",
          "standfirst": "Dense narrative deduction game tells a compellingly academia-tinged sci-fi tale.",
          "content": "If you've ever fallen down a Wikipedia rabbit hole or spent a pleasant evening digging through college library stacks, you know the joy of a good research puzzle. Every new source and cross-reference you find unlocks an incremental understanding of a previously unknown world, forming a piecemeal tapestry of knowledge that you can eventually look back at as a cohesive and well-known whole. TR-49 takes this research process and operationalizes it into an engrossing and novel piece of heavily non-linear interactive fiction. Researching the myriad sources contained in the game's mysterious computer slowly reveals a tale that's part mystery, part sci-fi allegory, part family drama, and all-compelling alternate academic history. Steampunk Wikipedia The entirety of TR-49 takes place from a first-person perspective as you sit in front of a kind of Steampunk-infused computer terminal. An unseen narrator asks you to operate the machine but is initially cagey about how or why or what you're even looking for. There's a creepy vibe to the under-explained circumstances that brought you to this situation, but the game never descends into the jump scares or horror tropes of so many other modern titles.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/4-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/4-1152x648.jpg",
      "popularity_score": 293
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Fri, 23 Jan 2026 20:10:40 +0000",
      "title": "DHS keeps trying and failing to unmask anonymous ICE critics online",
      "neutral_headline": "DHS keeps trying and failing to unmask anonymous ICE critics online",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/instagram-ice-critic-wins-fight-to-stay-anonymous-as-dhs-backs-down/",
          "published_at": "Fri, 23 Jan 2026 20:10:40 +0000",
          "title": "DHS keeps trying and failing to unmask anonymous ICE critics online",
          "standfirst": "Community watch groups have a playbook to keep ICE away from subscriber information.",
          "content": "The Department of Homeland Security (DHS) has backed down from a fight to unmask the owners of Instagram and Facebook accounts monitoring Immigration and Customs Enforcement (ICE) activity in Pennsylvania. One of the anonymous account holders, John Doe, sued to block ICE from identifying him and other critics online through summonses to Meta that he claimed infringed on core First Amendment-protected activity. DHS initially fought Doe's motion to quash the summonses, arguing that the community watch groups endangered ICE agents by posting \"pictures and videos of agents‚Äô faces, license plates, and weapons, among other things.\" This was akin to \"threatening ICE agents to impede the performance of their duties,\" DHS alleged. DHS's arguments echoed DHS Secretary Kristi Noem, who has claimed that identifying ICE agents is a crime, even though Wired noted that ICE employees often post easily discoverable LinkedIn profiles.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2257128839-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2257128839-1024x648.jpg",
      "popularity_score": 288
    },
    {
      "id": "cluster_106",
      "coverage": 1,
      "updated_at": "Fri, 23 Jan 2026 20:48:46 +0000",
      "title": "Demand for Intel's processors is apparently there, but the supply is not",
      "neutral_headline": "Demand for Intel's processors is apparently there, but the supply is not",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/core-ultra-series-3-launch-may-be-hampered-by-chip-shortages-says-intel/",
          "published_at": "Fri, 23 Jan 2026 20:48:46 +0000",
          "title": "Demand for Intel's processors is apparently there, but the supply is not",
          "standfirst": "Intel is allocating more of its own production to its money-making server chips.",
          "content": "Intel reported its earnings for the fourth quarter of 2025 yesterday, and the news both for the quarter and for the year was mixed: year-over-year revenue was down nearly imperceptibly, from $53.1 billion to $52.9 billion, while revenue for the quarter was down about four percent, from $14.3 billion last year to $13.7 billion this year. (That number was, nevertheless, on the high end of Intel's guidance for the quarter, which ranged from $12.8 to $13.8 billion.) Diving deeper into the numbers makes it clear exactly where money is being made and lost: Intel's data center and AI products were up 9 percent for the quarter and 5 percent for the year, while its client computing group (which sells Core processors, Arc GPUs, and other consumer products) was down 7 percent for the quarter and 3 percent for the year. That knowledge makes it slightly easier to understand the bind that company executives talked about on Intel's earnings call (as transcribed by Investing.com). In short, Intel is having trouble making (and buying) enough chips to meet demand, and it makes more sense to allocate the chips it can make to the divisions that are actually making money‚Äîwhich means that we could see shortages of or higher prices for consumer processors, just as Intel is gearing up to launch the promising Core Ultra Series 3 processors (codenamed Panther Lake).Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/intel-core-ultra-series-3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/intel-core-ultra-series-3-1152x648.jpg",
      "popularity_score": 283
    }
  ]
}