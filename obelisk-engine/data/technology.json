{
  "updated_at": "2026-01-27T04:07:38.842Z",
  "clusters": [
    {
      "id": "cluster_18",
      "coverage": 2,
      "updated_at": "Tue, 27 Jan 2026 00:30:00 GMT",
      "title": "MCP shipped without authentication. Clawdbot shows why that's a problem.",
      "neutral_headline": "MCP shipped without authentication. Clawdbot shows why that's a problem.",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/mcp-shipped-without-authentication-clawdbot-shows-why-thats-a-problem",
          "published_at": "Tue, 27 Jan 2026 00:30:00 GMT",
          "title": "MCP shipped without authentication. Clawdbot shows why that's a problem.",
          "standfirst": "Model Context Protocol has a security problem that won&#x27;t go away.When VentureBeat first reported on MCP&#x27;s vulnerabilities last October, the data was already alarming. Pynt&#x27;s research showed that deploying just 10 MCP plug-ins creates a 92% probability of exploitation — with meaningful risk even from a single plug-in.The core flaw hasn&#x27;t changed: MCP shipped without mandatory authentication. Authorization frameworks arrived six months after widespread deployment. As Merritt Baer, chief security officer at Enkrypt AI, warned at the time: \"MCP is shipping with the same mistake we&#x27;ve seen in every major protocol rollout: insecure defaults. If we don&#x27;t build authentication and least privilege in from day one, we&#x27;ll be cleaning up breaches for the next decade.\"Three months later, the cleanup has already begun — and it&#x27;s worse than expected.Clawdbot changed the threat model. The viral personal AI assistant that can clear inboxes and write code overnight runs entirely on MCP. Every developer who spun up a Clawdbot on a VPS without reading the security docs just exposed their company to the protocol&#x27;s full attack surface.Itamar Golan saw it coming. He sold Prompt Security to SentinelOne for an estimated $250 million last year. This week, he posted a warning on X: \"Disaster is coming. Thousands of Clawdbots are live right now on VPSs … with open ports to the internet … and zero authentication. This is going to get ugly.\"He&#x27;s not exaggerating. When Knostic scanned the internet, they found 1,862 MCP servers exposed with no authentication. They tested 119. Every server responded without requiring credentials.Anything Clawdbot can automate, attackers can weaponize.Three CVEs are exposing the same architectural flawThe vulnerabilities aren&#x27;t edge cases. They&#x27;re direct consequences of MCP&#x27;s design decisions. Here’s a brief description of the workflows that expose each of the following CVEs:CVE-2025-49596 (CVSS 9.4): Anthropic’s MCP Inspector exposed unauthenticated access between its web UI and proxy server, allowing full system compromise via a malicious webpage.CVE-2025-6514 (CVSS 9.6): Command injection in mcp-remote, an OAuth proxy with 437,000 downloads, enabled attackers to take over systems by connecting to a malicious MCP server.CVE-2025-52882 (CVSS 8.8): Popular Claude Code extensions exposed unauthenticated WebSocket servers, enabling arbitrary file access and code execution.Three critical vulnerabilities in six months. Three different attack vectors. One root cause: MCP&#x27;s authentication was always optional, and developers treated optional as unnecessary.The attack surface keeps expandingEquixly recently analyzed popular MCP implementations and also found several vulnerabilities: 43% contained command injection flaws, 30% permitted unrestricted URL fetching, and 22% leaked files outside intended directories. Forrester analyst Jeff Pollard described the risk in a blog post: \"From a security perspective, it looks like a very effective way to drop a new and very powerful actor into your environment with zero guardrails.\"That&#x27;s not an exaggeration. An MCP server with shell access can be weaponized for lateral movement, credential theft, and ransomware deployment, all triggered by a prompt injection hidden in a document the AI was asked to process.Known vulnerabilities, deferred fixesSecurity researcher Johann Rehberger disclosed a file exfiltration vulnerability last October. Prompt injection could trick AI agents into transmitting sensitive files to attacker accounts. Anthropic launched Cowork this month; it expands MCP-based agents to a broader, less security-aware audience. Same vulnerability, and this time it&#x27;s immediately exploitable. PromptArmor demonstrated a malicious document that manipulated the agent into uploading sensitive financial data.Anthropic&#x27;s mitigation guidance: Users should watch for \"suspicious actions that may indicate prompt injection.\"a16z partner Olivia Moore spent a weekend using Clawdbot and captured the disconnect: \"You&#x27;re giving an AI agent access to your accounts. It can read your messages, send texts on your behalf, access your files, and execute code on your machine. You need to actually understand what you&#x27;re authorizing.\"Most users don&#x27;t. Most developers don&#x27;t either. And MCP&#x27;s design never required them to.Five actions for security leadersInventory your MCP exposure now. Traditional endpoint detection sees node or Python processes started by legitimate applications. It doesn&#x27;t flag them as threats. You need tooling that identifies MCP servers specifically. Treat authentication as mandatory. The MCP specification recommends OAuth 2.1. The SDK includes no built-in authentication. Every MCP server touching production systems needs auth enforced at deployment, not after the incident.Restrict network exposure. Bind MCP servers to localhost unless remote access is explicitly required and authenticated. The 1,862 exposed servers Knostic found suggest most exposures are accidental. Assume prompt injection attacks are coming and will be successful. MCP servers inherit the blast radius of the tools they wrap. Server wraps cloud credentials, filesystems, or deployment pipelines? Design access controls assuming the agent will be compromised.Force human approval for high-risk actions. Require explicit confirmation before agents send external email, delete data, or access sensitive information. Treat the agent like a fast but literal junior employee who will do exactly what you say, including things you didn&#x27;t mean.The governance gap is wide openSecurity vendors moved early to monetize MCP risk, but most enterprises didn’t move nearly as fast.Clawdbot adoption exploded in Q4 2025. Most 2026 security roadmaps have zero AI agent controls. The gap between developer enthusiasm and security governance is measured in months. The window for attackers is wide open.Golan is right. This is going to get ugly. The question is whether organizations will secure their MCP exposure before someone else exploits it.",
          "content": "Model Context Protocol has a security problem that won&#x27;t go away.When VentureBeat first reported on MCP&#x27;s vulnerabilities last October, the data was already alarming. Pynt&#x27;s research showed that deploying just 10 MCP plug-ins creates a 92% probability of exploitation — with meaningful risk even from a single plug-in.The core flaw hasn&#x27;t changed: MCP shipped without mandatory authentication. Authorization frameworks arrived six months after widespread deployment. As Merritt Baer, chief security officer at Enkrypt AI, warned at the time: \"MCP is shipping with the same mistake we&#x27;ve seen in every major protocol rollout: insecure defaults. If we don&#x27;t build authentication and least privilege in from day one, we&#x27;ll be cleaning up breaches for the next decade.\"Three months later, the cleanup has already begun — and it&#x27;s worse than expected.Clawdbot changed the threat model. The viral personal AI assistant that can clear inboxes and write code overnight runs entirely on MCP. Every developer who spun up a Clawdbot on a VPS without reading the security docs just exposed their company to the protocol&#x27;s full attack surface.Itamar Golan saw it coming. He sold Prompt Security to SentinelOne for an estimated $250 million last year. This week, he posted a warning on X: \"Disaster is coming. Thousands of Clawdbots are live right now on VPSs … with open ports to the internet … and zero authentication. This is going to get ugly.\"He&#x27;s not exaggerating. When Knostic scanned the internet, they found 1,862 MCP servers exposed with no authentication. They tested 119. Every server responded without requiring credentials.Anything Clawdbot can automate, attackers can weaponize.Three CVEs are exposing the same architectural flawThe vulnerabilities aren&#x27;t edge cases. They&#x27;re direct consequences of MCP&#x27;s design decisions. Here’s a brief description of the workflows that expose each of the following CVEs:CVE-2025-49596 (CVSS 9.4): Anthropic’s MCP Inspector exposed unauthenticated access between its web UI and proxy server, allowing full system compromise via a malicious webpage.CVE-2025-6514 (CVSS 9.6): Command injection in mcp-remote, an OAuth proxy with 437,000 downloads, enabled attackers to take over systems by connecting to a malicious MCP server.CVE-2025-52882 (CVSS 8.8): Popular Claude Code extensions exposed unauthenticated WebSocket servers, enabling arbitrary file access and code execution.Three critical vulnerabilities in six months. Three different attack vectors. One root cause: MCP&#x27;s authentication was always optional, and developers treated optional as unnecessary.The attack surface keeps expandingEquixly recently analyzed popular MCP implementations and also found several vulnerabilities: 43% contained command injection flaws, 30% permitted unrestricted URL fetching, and 22% leaked files outside intended directories. Forrester analyst Jeff Pollard described the risk in a blog post: \"From a security perspective, it looks like a very effective way to drop a new and very powerful actor into your environment with zero guardrails.\"That&#x27;s not an exaggeration. An MCP server with shell access can be weaponized for lateral movement, credential theft, and ransomware deployment, all triggered by a prompt injection hidden in a document the AI was asked to process.Known vulnerabilities, deferred fixesSecurity researcher Johann Rehberger disclosed a file exfiltration vulnerability last October. Prompt injection could trick AI agents into transmitting sensitive files to attacker accounts. Anthropic launched Cowork this month; it expands MCP-based agents to a broader, less security-aware audience. Same vulnerability, and this time it&#x27;s immediately exploitable. PromptArmor demonstrated a malicious document that manipulated the agent into uploading sensitive financial data.Anthropic&#x27;s mitigation guidance: Users should watch for \"suspicious actions that may indicate prompt injection.\"a16z partner Olivia Moore spent a weekend using Clawdbot and captured the disconnect: \"You&#x27;re giving an AI agent access to your accounts. It can read your messages, send texts on your behalf, access your files, and execute code on your machine. You need to actually understand what you&#x27;re authorizing.\"Most users don&#x27;t. Most developers don&#x27;t either. And MCP&#x27;s design never required them to.Five actions for security leadersInventory your MCP exposure now. Traditional endpoint detection sees node or Python processes started by legitimate applications. It doesn&#x27;t flag them as threats. You need tooling that identifies MCP servers specifically. Treat authentication as mandatory. The MCP specification recommends OAuth 2.1. The SDK includes no built-in authentication. Every MCP server touching production systems needs auth enforced at deployment, not after the incident.Restrict network exposure. Bind MCP servers to localhost unless remote access is explicitly required and authenticated. The 1,862 exposed servers Knostic found suggest most exposures are accidental. Assume prompt injection attacks are coming and will be successful. MCP servers inherit the blast radius of the tools they wrap. Server wraps cloud credentials, filesystems, or deployment pipelines? Design access controls assuming the agent will be compromised.Force human approval for high-risk actions. Require explicit confirmation before agents send external email, delete data, or access sensitive information. Treat the agent like a fast but literal junior employee who will do exactly what you say, including things you didn&#x27;t mean.The governance gap is wide openSecurity vendors moved early to monetize MCP risk, but most enterprises didn’t move nearly as fast.Clawdbot adoption exploded in Q4 2025. Most 2026 security roadmaps have zero AI agent controls. The gap between developer enthusiasm and security governance is measured in months. The window for attackers is wide open.Golan is right. This is going to get ugly. The question is whether organizations will secure their MCP exposure before someone else exploits it.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3bkJOPIyWcL3MD20sP4ZT8/74ebf0c216dcfefb690df6a5971f0bbf/2026-01-26_14-51-12.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/a-tiktok-us-power-outage-caused-a-cascading-systems-failure-leading-to-multiple-bugs-173426490.html",
          "published_at": "Tue, 27 Jan 2026 00:18:58 +0000",
          "title": "A TikTok US power outage caused a 'cascading systems failure' leading to multiple bugs",
          "standfirst": "If your TikTok feed has felt a little off lately, it's not just you. TikTok says is still working to fix its service in the US following a power outage at one of its data centers that's caused “multiple bugs” in the app. TikTok users have reported problems logging in and uploading videos, as well as strange behavior from the \"for you\" algorithm. Creators have also noticed that new uploads are seemingly getting o views or likes and that in-app earnings have disappeared. \"Since yesterday we’ve been working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate,\" the company wrote in a statement Monday. \"We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.\"Since yesterday we’ve been working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate. We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.— TikTok USDS Joint Venture (@tiktokusdsjv) January 26, 2026In a subsequent update several hours later, the company said that the power outage had caused a “cascading systems failure” that is still affecting the app and leading to “multiple bugs,” including those affecting view counts and load times. “Creators may temporarily see ‘0’ views or likes on videos, and your earnings may look like they're missing,” the company wrote in an update on X. “This is a display error caused by server timeouts; your actual data and engagement are safe.”An update on our work to restore and stabilize TikTok. pic.twitter.com/PZzsuFeZmj— TikTok USDS Joint Venture (@tiktokusdsjv) January 26, 2026 The statement didn’t directly address reported issues with the app’s recommendation algorithm. Since Sunday, users have reported seeing a wave of generic videos flood their feeds, which are typically hyper-personalized. Other users have reported seeing the same few videos repeated over and over again. The issues come just days after TikTok finalized a deal to spin off its US business into a separate entity largely controlled by US investors. That timing hasn't gone unnoticed by users, many of whom are already suspicious of the company pushing a terms of service and privacy policy in the hours after the deal was finalized. The problems affecting the app's recommendation algorithm have also raised questions about TikTok USDS Joint Venture's plans to \"retrain\" TikTok's central feature. Update, January 26, 2026, 4:18PM PT: This post has been updated to include additional information from TikTok about the outage and bugs affecting users.This article originally appeared on Engadget at https://www.engadget.com/social-media/a-tiktok-us-power-outage-caused-a-cascading-systems-failure-leading-to-multiple-bugs-173426490.html?src=rss",
          "content": "If your TikTok feed has felt a little off lately, it's not just you. TikTok says is still working to fix its service in the US following a power outage at one of its data centers that's caused “multiple bugs” in the app. TikTok users have reported problems logging in and uploading videos, as well as strange behavior from the \"for you\" algorithm. Creators have also noticed that new uploads are seemingly getting o views or likes and that in-app earnings have disappeared. \"Since yesterday we’ve been working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate,\" the company wrote in a statement Monday. \"We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.\"Since yesterday we’ve been working to restore our services following a power outage at a U.S. data center impacting TikTok and other apps we operate. We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.— TikTok USDS Joint Venture (@tiktokusdsjv) January 26, 2026In a subsequent update several hours later, the company said that the power outage had caused a “cascading systems failure” that is still affecting the app and leading to “multiple bugs,” including those affecting view counts and load times. “Creators may temporarily see ‘0’ views or likes on videos, and your earnings may look like they're missing,” the company wrote in an update on X. “This is a display error caused by server timeouts; your actual data and engagement are safe.”An update on our work to restore and stabilize TikTok. pic.twitter.com/PZzsuFeZmj— TikTok USDS Joint Venture (@tiktokusdsjv) January 26, 2026 The statement didn’t directly address reported issues with the app’s recommendation algorithm. Since Sunday, users have reported seeing a wave of generic videos flood their feeds, which are typically hyper-personalized. Other users have reported seeing the same few videos repeated over and over again. The issues come just days after TikTok finalized a deal to spin off its US business into a separate entity largely controlled by US investors. That timing hasn't gone unnoticed by users, many of whom are already suspicious of the company pushing a terms of service and privacy policy in the hours after the deal was finalized. The problems affecting the app's recommendation algorithm have also raised questions about TikTok USDS Joint Venture's plans to \"retrain\" TikTok's central feature. Update, January 26, 2026, 4:18PM PT: This post has been updated to include additional information from TikTok about the outage and bugs affecting users.This article originally appeared on Engadget at https://www.engadget.com/social-media/a-tiktok-us-power-outage-caused-a-cascading-systems-failure-leading-to-multiple-bugs-173426490.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/qwen3-max-thinking-beats-gemini-3-pro-and-gpt-5-2-on-humanitys-last-exam",
          "published_at": "Mon, 26 Jan 2026 23:42:00 GMT",
          "title": "Qwen3-Max Thinking beats Gemini 3 Pro and GPT-5.2 on Humanity's Last Exam (with search)",
          "standfirst": "Chinese AI and tech firms continue to impress with their development of cutting-edge, state-of-the-art AI language models.Today, the one drawing eyeballs is Alibaba Cloud&#x27;s Qwen Team of AI researchers and its unveiling of a new proprietary language reasoning model, Qwen3-Max-Thinking.You may recall, as VentureBeat covered last year, that Qwen has made a name for itself in the fast-moving global AI marketplace by shipping a variety of powerful, open source models in various modalities, from text to image to spoken audio. The company even earned an endorsement from U.S. tech lodgings giant Airbnb, whose CEO and co-founder Brian Chesky said the company was relying on Qwen&#x27;s free, open source models as a more affordable alternative to U.S. offerings like those of OpenAI.Now, with the proprietary Qwen3-Max-Thinking, the Qwen Team is aiming to match and, in some cases, outpace the reasoning capabilities of GPT-5.2 and Gemini 3 Pro through architectural efficiency and agentic autonomy.The release comes at a critical juncture. Western labs have largely defined the \"reasoning\" category (often dubbed \"System 2\" logic), but Qwen’s latest benchmarks suggest the gap has closed. In addition, the company&#x27;s relatively affordable API pricing strategy aggressively targets enterprise adoption. However, as it is a Chinese model, some U.S. firms with strict national security requirements and considerations may be wary of adopting it.The Architecture: \"Test-Time Scaling\" RedefinedThe core innovation driving Qwen3-Max-Thinking is a departure from standard inference methods. While most models generate tokens linearly, Qwen3 utilizes a \"heavy mode\" driven by a technique known as \"Test-time scaling.\"In simple terms, this technique allows the model to trade compute for intelligence. But unlike naive \"best-of-N\" sampling—where a model might generate 100 answers and pick the best one — Qwen3-Max-Thinking employs an experience-cumulative, multi-round strategy.This approach mimics human problem-solving. When the model encounters a complex query, it doesn&#x27;t just guess; it engages in iterative self-reflection. It uses a proprietary \"take-experience\" mechanism to distill insights from previous reasoning steps. This allows the model to:Identify Dead Ends: Recognize when a line of reasoning is failing without needing to fully traverse it.Focus Compute: Redirect processing power toward \"unresolved uncertainties\" rather than re-deriving known conclusions.The efficiency gains are tangible. By avoiding redundant reasoning, the model integrates richer historical context into the same window. The Qwen team reports that this method drove massive performance jumps without exploding token costs:GPQA (PhD-level science): Scores improved from 90.3 to 92.8.LiveCodeBench v6: Performance jumped from 88.0 to 91.4.Beyond Pure Thought: Adaptive ToolingWhile \"thinking\" models are powerful, they have historically been siloed — great at math, but poor at browsing the web or running code. Qwen3-Max-Thinking bridges this gap by effectively integrating \"thinking and non-thinking modes\".The model features adaptive tool-use capabilities, meaning it autonomously selects the right tool for the job without manual user prompting. It can seamlessly toggle between:Web Search & Extraction: For real-time factual queries.Memory: To store and recall user-specific context.Code Interpreter: To write and execute Python snippets for computational tasks.In \"Thinking Mode,\" the model supports these tools simultaneously. This capability is critical for enterprise applications where a model might need to verify a fact (Search), calculate a projection (Code Interpreter), and then reason about the strategic implication (Thinking) all in one turn.Empirically, the team notes that this combination \"effectively mitigates hallucinations,\" as the model can ground its reasoning in verifiable external data rather than relying solely on its training weights.Benchmark Analysis: The Data StoryQwen is not shy about direct comparisons. On HMMT Feb 25, a rigorous reasoning benchmark, Qwen3-Max-Thinking scored 98.0, edging out Gemini 3 Pro (97.5) and significantly leading DeepSeek V3.2 (92.5).However, the most significant signal for developers is arguably Agentic Search. On \"Humanity&#x27;s Last Exam\" (HLE) — the benchmark that measures performance on 3,000 \"Google-proof\" graduate-level questions across math, science, computer science, humanities and engineering — Qwen3-Max-Thinking, equipped with web search tools, scored 49.8, beating both Gemini 3 Pro (45.8) and GPT-5.2-Thinking (45.5) . This suggests that Qwen3-Max-Thinking’s architecture is uniquely suited for complex, multi-step agentic workflows where external data retrieval is necessary. In coding tasks, the model also shines. On Arena-Hard v2, it posted a score of 90.2, leaving competitors like Claude-Opus-4.5 (76.7) far behind.The Economics of Reasoning: Pricing BreakdownFor the first time, we have a clear look at the economics of Qwen&#x27;s top-tier reasoning model. Alibaba Cloud has positioned qwen3-max-2026-01-23 as a premium but accessible offering on its API.Input: $1.20 per 1 million tokens (for standard contexts <= 32k).Output: $6.00 per 1 million tokens.On a base level, here&#x27;s how Qwen3-Max-Thinking stacks up:ModelInput (/1M)Output (/1M)Total CostSourceQwen 3 Turbo$0.05$0.20$0.25Alibaba CloudGrok 4.1 Fast (reasoning)$0.20$0.50$0.70xAIGrok 4.1 Fast (non-reasoning)$0.20$0.50$0.70xAIdeepseek-chat (V3.2-Exp)$0.28$0.42$0.70DeepSeekdeepseek-reasoner (V3.2-Exp)$0.28$0.42$0.70DeepSeekQwen 3 Plus$0.40$1.20$1.60Alibaba CloudERNIE 5.0$0.85$3.40$4.25QianfanGemini 3 Flash Preview$0.50$3.00$3.50GoogleClaude Haiku 4.5$1.00$5.00$6.00AnthropicQwen3-Max Thinking (2026-01-23)$1.20$6.00$7.20Alibaba CloudGemini 3 Pro (≤200K)$2.00$12.00$14.00GoogleGPT-5.2$1.75$14.00$15.75OpenAIClaude Sonnet 4.5$3.00$15.00$18.00AnthropicGemini 3 Pro (>200K)$4.00$18.00$22.00GoogleClaude Opus 4.5$5.00$25.00$30.00AnthropicGPT-5.2 Pro$21.00$168.00$189.00OpenAIThis pricing structure is aggressive, undercutting many legacy flagship models while offering state-of-the-art performance. However, developers should note the granular pricing for the new agentic capabilities, as Qwen separates the cost of \"thinking\" (tokens) from the cost of \"doing\" (tool use).Agent Search Strategy: Both standard search_strategy:agent and the more advanced search_strategy:agent_max are priced at $10 per 1,000 calls.Note: The agent_max strategy is currently marked as a \"Limited Time Offer,\" suggesting its price may rise later.Web Search: Priced at $10 per 1,000 calls via the Responses API.Promotional Free Tier:To encourage adoption of its most advanced features, Alibaba Cloud is currently offering two key tools for free for a limited time:Web Extractor: Free (Limited Time).Code Interpreter: Free (Limited Time).This pricing model (low token cost + à la carte tool pricing) allows developers to build complex agents that are cost-effective for text processing, while paying a premium only when external actions—like a live web search—are explicitly triggered.Developer EcosystemRecognizing that performance is useless without integration, Alibaba Cloud has ensured Qwen3-Max-Thinking is drop-in ready.OpenAI Compatibility: The API supports the standard OpenAI format, allowing teams to switch models by simply changing the base_url and model name.Anthropic Compatibility: In a savvy move to capture the coding market, the API also supports the Anthropic protocol. This makes Qwen3-Max-Thinking compatible with Claude Code, a popular agentic coding environment.The VerdictQwen3-Max-Thinking represents a maturation of the AI market in 2026. It moves the conversation beyond \"who has the smartest chatbot\" to \"who has the most capable agent.\" By combining high-efficiency reasoning with adaptive, autonomous tool use—and pricing it to move—Qwen has firmly established itself as a top-tier contender for the enterprise AI throne.For developers and enterprises, the \"Limited Time Free\" windows on Code Interpreter and Web Extractor suggest now is the time to experiment. The reasoning wars are far from over, but Qwen has just deployed a very heavy hitter.",
          "content": "Chinese AI and tech firms continue to impress with their development of cutting-edge, state-of-the-art AI language models.Today, the one drawing eyeballs is Alibaba Cloud&#x27;s Qwen Team of AI researchers and its unveiling of a new proprietary language reasoning model, Qwen3-Max-Thinking.You may recall, as VentureBeat covered last year, that Qwen has made a name for itself in the fast-moving global AI marketplace by shipping a variety of powerful, open source models in various modalities, from text to image to spoken audio. The company even earned an endorsement from U.S. tech lodgings giant Airbnb, whose CEO and co-founder Brian Chesky said the company was relying on Qwen&#x27;s free, open source models as a more affordable alternative to U.S. offerings like those of OpenAI.Now, with the proprietary Qwen3-Max-Thinking, the Qwen Team is aiming to match and, in some cases, outpace the reasoning capabilities of GPT-5.2 and Gemini 3 Pro through architectural efficiency and agentic autonomy.The release comes at a critical juncture. Western labs have largely defined the \"reasoning\" category (often dubbed \"System 2\" logic), but Qwen’s latest benchmarks suggest the gap has closed. In addition, the company&#x27;s relatively affordable API pricing strategy aggressively targets enterprise adoption. However, as it is a Chinese model, some U.S. firms with strict national security requirements and considerations may be wary of adopting it.The Architecture: \"Test-Time Scaling\" RedefinedThe core innovation driving Qwen3-Max-Thinking is a departure from standard inference methods. While most models generate tokens linearly, Qwen3 utilizes a \"heavy mode\" driven by a technique known as \"Test-time scaling.\"In simple terms, this technique allows the model to trade compute for intelligence. But unlike naive \"best-of-N\" sampling—where a model might generate 100 answers and pick the best one — Qwen3-Max-Thinking employs an experience-cumulative, multi-round strategy.This approach mimics human problem-solving. When the model encounters a complex query, it doesn&#x27;t just guess; it engages in iterative self-reflection. It uses a proprietary \"take-experience\" mechanism to distill insights from previous reasoning steps. This allows the model to:Identify Dead Ends: Recognize when a line of reasoning is failing without needing to fully traverse it.Focus Compute: Redirect processing power toward \"unresolved uncertainties\" rather than re-deriving known conclusions.The efficiency gains are tangible. By avoiding redundant reasoning, the model integrates richer historical context into the same window. The Qwen team reports that this method drove massive performance jumps without exploding token costs:GPQA (PhD-level science): Scores improved from 90.3 to 92.8.LiveCodeBench v6: Performance jumped from 88.0 to 91.4.Beyond Pure Thought: Adaptive ToolingWhile \"thinking\" models are powerful, they have historically been siloed — great at math, but poor at browsing the web or running code. Qwen3-Max-Thinking bridges this gap by effectively integrating \"thinking and non-thinking modes\".The model features adaptive tool-use capabilities, meaning it autonomously selects the right tool for the job without manual user prompting. It can seamlessly toggle between:Web Search & Extraction: For real-time factual queries.Memory: To store and recall user-specific context.Code Interpreter: To write and execute Python snippets for computational tasks.In \"Thinking Mode,\" the model supports these tools simultaneously. This capability is critical for enterprise applications where a model might need to verify a fact (Search), calculate a projection (Code Interpreter), and then reason about the strategic implication (Thinking) all in one turn.Empirically, the team notes that this combination \"effectively mitigates hallucinations,\" as the model can ground its reasoning in verifiable external data rather than relying solely on its training weights.Benchmark Analysis: The Data StoryQwen is not shy about direct comparisons. On HMMT Feb 25, a rigorous reasoning benchmark, Qwen3-Max-Thinking scored 98.0, edging out Gemini 3 Pro (97.5) and significantly leading DeepSeek V3.2 (92.5).However, the most significant signal for developers is arguably Agentic Search. On \"Humanity&#x27;s Last Exam\" (HLE) — the benchmark that measures performance on 3,000 \"Google-proof\" graduate-level questions across math, science, computer science, humanities and engineering — Qwen3-Max-Thinking, equipped with web search tools, scored 49.8, beating both Gemini 3 Pro (45.8) and GPT-5.2-Thinking (45.5) . This suggests that Qwen3-Max-Thinking’s architecture is uniquely suited for complex, multi-step agentic workflows where external data retrieval is necessary. In coding tasks, the model also shines. On Arena-Hard v2, it posted a score of 90.2, leaving competitors like Claude-Opus-4.5 (76.7) far behind.The Economics of Reasoning: Pricing BreakdownFor the first time, we have a clear look at the economics of Qwen&#x27;s top-tier reasoning model. Alibaba Cloud has positioned qwen3-max-2026-01-23 as a premium but accessible offering on its API.Input: $1.20 per 1 million tokens (for standard contexts <= 32k).Output: $6.00 per 1 million tokens.On a base level, here&#x27;s how Qwen3-Max-Thinking stacks up:ModelInput (/1M)Output (/1M)Total CostSourceQwen 3 Turbo$0.05$0.20$0.25Alibaba CloudGrok 4.1 Fast (reasoning)$0.20$0.50$0.70xAIGrok 4.1 Fast (non-reasoning)$0.20$0.50$0.70xAIdeepseek-chat (V3.2-Exp)$0.28$0.42$0.70DeepSeekdeepseek-reasoner (V3.2-Exp)$0.28$0.42$0.70DeepSeekQwen 3 Plus$0.40$1.20$1.60Alibaba CloudERNIE 5.0$0.85$3.40$4.25QianfanGemini 3 Flash Preview$0.50$3.00$3.50GoogleClaude Haiku 4.5$1.00$5.00$6.00AnthropicQwen3-Max Thinking (2026-01-23)$1.20$6.00$7.20Alibaba CloudGemini 3 Pro (≤200K)$2.00$12.00$14.00GoogleGPT-5.2$1.75$14.00$15.75OpenAIClaude Sonnet 4.5$3.00$15.00$18.00AnthropicGemini 3 Pro (>200K)$4.00$18.00$22.00GoogleClaude Opus 4.5$5.00$25.00$30.00AnthropicGPT-5.2 Pro$21.00$168.00$189.00OpenAIThis pricing structure is aggressive, undercutting many legacy flagship models while offering state-of-the-art performance. However, developers should note the granular pricing for the new agentic capabilities, as Qwen separates the cost of \"thinking\" (tokens) from the cost of \"doing\" (tool use).Agent Search Strategy: Both standard search_strategy:agent and the more advanced search_strategy:agent_max are priced at $10 per 1,000 calls.Note: The agent_max strategy is currently marked as a \"Limited Time Offer,\" suggesting its price may rise later.Web Search: Priced at $10 per 1,000 calls via the Responses API.Promotional Free Tier:To encourage adoption of its most advanced features, Alibaba Cloud is currently offering two key tools for free for a limited time:Web Extractor: Free (Limited Time).Code Interpreter: Free (Limited Time).This pricing model (low token cost + à la carte tool pricing) allows developers to build complex agents that are cost-effective for text processing, while paying a premium only when external actions—like a live web search—are explicitly triggered.Developer EcosystemRecognizing that performance is useless without integration, Alibaba Cloud has ensured Qwen3-Max-Thinking is drop-in ready.OpenAI Compatibility: The API supports the standard OpenAI format, allowing teams to switch models by simply changing the base_url and model name.Anthropic Compatibility: In a savvy move to capture the coding market, the API also supports the Anthropic protocol. This makes Qwen3-Max-Thinking compatible with Claude Code, a popular agentic coding environment.The VerdictQwen3-Max-Thinking represents a maturation of the AI market in 2026. It moves the conversation beyond \"who has the smartest chatbot\" to \"who has the most capable agent.\" By combining high-efficiency reasoning with adaptive, autonomous tool use—and pricing it to move—Qwen has firmly established itself as a top-tier contender for the enterprise AI throne.For developers and enterprises, the \"Limited Time Free\" windows on Code Interpreter and Web Extractor suggest now is the time to experiment. The reasoning wars are far from over, but Qwen has just deployed a very heavy hitter.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/18aw75O5te6dE6Vt8qmKbg/77c7c117fb58e73b76f2e46a916039fc/Carl_Franzen_vibrant_lush_pop_line_art_vector_art_flat_with_gra_363afe34-53fa-448f-9565-a5d5bc70ce43.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/people-are-uninstalling-tiktok-and-downloading-an-indie-competitor-233345222.html",
          "published_at": "Mon, 26 Jan 2026 23:33:45 +0000",
          "title": "People are uninstalling TikTok and downloading an indie competitor",
          "standfirst": "TikTok's newly formed US entity is off to a very bumpy start. As the app continues to face technical issues affecting the recommendation algorithm, view counts and other features, TikTok is also seeing a wave of frustrated users uninstalling it, according to new data.Analytics firm Sensor Tower, which tracks downloads and other app store-related metrics, told CNBC that there has been a 150 percent rise in uninstalls of the TikTok app in the United States compared with the last three months. An analyst at Sensor Tower told Engadget that TikTok's US daily active users (DAUs) have increased about 2 percent in the same time period, and are flat week-over-week. TikTok has blamed a power outage at a data center for “multiple bugs,” including those affecting view counts and load times. The company hasn't said when users can expect a fix.At the same time, an independent app called UpScrolled has seen a surge in interest over the last few days. The app is currently the ninth most-downloaded app in the US App Store and the second most popular social app (Meta's Threads is currently in the number one spot for social apps). The app has also reached the top five in the UK and Australian app stores. In the United States, its sudden popularity seems to be closely tied to recent changes at TikTok. UpScrolled has seen 41,000 total downloads between Thursday (the day the US joint venture was formalized) and Saturday, according to estimates from App Figures. The app, which was first released last June, has been downloaded about 140,000 times between Apple and Google's app stores, according to App Figures. Prior to last Thursday, the app was averaging less than 500 downloads a day, according to the company. The rapid increase in downloads has apparently caused some issues for the company which asked users to \"bear with us\" on Monday.Well, this is new...You showed up so fast our servers tapped out. Frustrating? Yes. Emotional? Also yes.We're a tiny team building what Big Tech stopped being. Right now we're scaling on caffeine to keep up with what YOU started.Bear with us. We're on it. pic.twitter.com/OAlYcN6t5q— UpScrolled (@realUpScrolled) January 26, 2026Created by an Australian developer, UpScrolled looks a bit like Instagram. Users can share photos and shortform videos. The app defaults to a chronological \"following\" feed, though it does also recommend content to users. The app is \"privately funded by its founder, Issam Hijazi, together with a small group of individual investors who share our mission and values,\" according to an FAQ on UpScrolled's website. It currently has no ads, though the company says it \"probably\" will in the future. This isn't the first time turmoil at TikTok has benefitted a previously little-known app. Chinese app RedNote briefly became the top app in the United States early last year as TikTok faced a potential ban. RedNote's popularity proved to be short-lived, though, as the 2025 TikTok \"ban\" ended up lasting only a couple of hours. But with new owners at TikTok and growing frustration over technical issues with the app, there could be an opportunity for a new shortform video service that's not controlled by a huge corporation. And that's what UpScrolled seems to be betting on. \"Too often, users are left uncertain about whether their voices will be heard or quietly suppressed,\" the company writes on its website. \"UpScrolled changes that by ensuring every post has a fair chance to be seen, creating an environment that is authentic, unfiltered, and equitable for all.\"Update, January 26, 2026, 4:28PM PT: This post was updated to reflect the latest details from TikTok about the ongoing issues affecting the US version of the app.This article originally appeared on Engadget at https://www.engadget.com/social-media/people-are-uninstalling-tiktok-and-downloading-an-indie-competitor-233345222.html?src=rss",
          "content": "TikTok's newly formed US entity is off to a very bumpy start. As the app continues to face technical issues affecting the recommendation algorithm, view counts and other features, TikTok is also seeing a wave of frustrated users uninstalling it, according to new data.Analytics firm Sensor Tower, which tracks downloads and other app store-related metrics, told CNBC that there has been a 150 percent rise in uninstalls of the TikTok app in the United States compared with the last three months. An analyst at Sensor Tower told Engadget that TikTok's US daily active users (DAUs) have increased about 2 percent in the same time period, and are flat week-over-week. TikTok has blamed a power outage at a data center for “multiple bugs,” including those affecting view counts and load times. The company hasn't said when users can expect a fix.At the same time, an independent app called UpScrolled has seen a surge in interest over the last few days. The app is currently the ninth most-downloaded app in the US App Store and the second most popular social app (Meta's Threads is currently in the number one spot for social apps). The app has also reached the top five in the UK and Australian app stores. In the United States, its sudden popularity seems to be closely tied to recent changes at TikTok. UpScrolled has seen 41,000 total downloads between Thursday (the day the US joint venture was formalized) and Saturday, according to estimates from App Figures. The app, which was first released last June, has been downloaded about 140,000 times between Apple and Google's app stores, according to App Figures. Prior to last Thursday, the app was averaging less than 500 downloads a day, according to the company. The rapid increase in downloads has apparently caused some issues for the company which asked users to \"bear with us\" on Monday.Well, this is new...You showed up so fast our servers tapped out. Frustrating? Yes. Emotional? Also yes.We're a tiny team building what Big Tech stopped being. Right now we're scaling on caffeine to keep up with what YOU started.Bear with us. We're on it. pic.twitter.com/OAlYcN6t5q— UpScrolled (@realUpScrolled) January 26, 2026Created by an Australian developer, UpScrolled looks a bit like Instagram. Users can share photos and shortform videos. The app defaults to a chronological \"following\" feed, though it does also recommend content to users. The app is \"privately funded by its founder, Issam Hijazi, together with a small group of individual investors who share our mission and values,\" according to an FAQ on UpScrolled's website. It currently has no ads, though the company says it \"probably\" will in the future. This isn't the first time turmoil at TikTok has benefitted a previously little-known app. Chinese app RedNote briefly became the top app in the United States early last year as TikTok faced a potential ban. RedNote's popularity proved to be short-lived, though, as the 2025 TikTok \"ban\" ended up lasting only a couple of hours. But with new owners at TikTok and growing frustration over technical issues with the app, there could be an opportunity for a new shortform video service that's not controlled by a huge corporation. And that's what UpScrolled seems to be betting on. \"Too often, users are left uncertain about whether their voices will be heard or quietly suppressed,\" the company writes on its website. \"UpScrolled changes that by ensuring every post has a fair chance to be seen, creating an environment that is authentic, unfiltered, and equitable for all.\"Update, January 26, 2026, 4:28PM PT: This post was updated to reflect the latest details from TikTok about the ongoing issues affecting the US version of the app.This article originally appeared on Engadget at https://www.engadget.com/social-media/people-are-uninstalling-tiktok-and-downloading-an-indie-competitor-233345222.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/claude-codes-tasks-update-lets-agents-work-longer-and-coordinate-across",
          "published_at": "Mon, 26 Jan 2026 19:34:00 GMT",
          "title": "Claude Code's 'Tasks' update lets agents work longer and coordinate across sessions",
          "standfirst": "One of the biggest constraints currently facing AI builders who want to deploy agents in service of their individual or enterprise goals is the \"working memory\" required to manage complex, multi-stage engineering projects.Typically, when a AI agent operates purely on a stream of text or voice-based conversation, it lacks the structural permanence to handle dependencies. It knows what to do, but it often forgets why it is doing it, or in what order.With the release of Tasks for Claude Code (introduced in v2.1.16) last week, Anthropic has introduced a solution that is less about \"AI magic\" and more about sound software engineering principles. By moving from ephemeral \"To-dos\" to persistent \"Tasks,\" the company is fundamentally re-architecting how the model interacts with time, complexity, and system resources.This update transforms the tool from a reactive coding assistant into a state-aware project manager, creating the infrastructure necessary to execute the sophisticated workflows outlined in Anthropic&#x27;s just-released Best Practices guide, while recent changelog updates (v2.1.19) signal a focus on the stability required for enterprise adoption.The architecture of agency: from ephemeral to persistentTo understand the significance of this release for engineering teams, we must look at the mechanical differences between the old \"To-do\" system and the new \"Task\" primitive.Previously, Claude Code utilized a \"To-do\" list—a lightweight, chat-resident checklist. As Anthropic engineer Thariq Shihipar wrote in an article on X: \"Todos (orange) = &#x27;help Claude remember what to do&#x27;.\" These were effective for single-session scripts but fragile for actual engineering. If the session ended, the terminal crashed, or the context window drifted, the plan evaporated.Tasks (Green) introduce a new layer of abstraction designed for \"coordinating work across sessions, subagents, and context windows.\" This is achieved through three key architectural decisions:Dependency Graphs vs. Linear Lists: Unlike a flat Todo list, Tasks support directed acyclic graphs (DAGs). A task can explicitly \"block\" another. As seen in community demonstrations, the system can determine that Task 3 (Run Tests) cannot start until Task 1 (Build API) and Task 2 (Configure Auth) are complete. This enforcement prevents the \"hallucinated completion\" errors common in LLM workflows, where a model attempts to test code it hasn&#x27;t written yet.Filesystem Persistence & Durability: Anthropic chose a \"UNIX-philosophy\" approach to state management. Rather than locking project state inside a proprietary cloud database, Claude Code writes tasks directly to the user&#x27;s local filesystem (~/.claude/tasks). This creates durable state. A developer can shut down their terminal, switch machines, or recover from a system crash, and the agent reloads the exact state of the project. For enterprise teams, this persistence is critical—it means the \"plan\" is now an artifact that can be audited, backed up, or version-controlled, independent of the active session.Orchestration via Environment Variables: The most potent technical unlock is the ability to share state across sessions. By setting the CLAUDE_CODE_TASK_LIST_ID environment variable, developers can point multiple instances of Claude at the same task list. This allows updates to be \"broadcast\" to all active sessions, enabling a level of coordination that was previously impossible without external orchestration tools.Enabling the &#x27;swarm&#x27;: parallelism and subagentsThe release of Tasks makes the \"Parallel Sessions\" described in Anthropic&#x27;s Best Practices guide practical. The documentation suggests a Writer/Reviewer pattern that leverages this shared state:Session A (Writer) picks up Task #1 (\"Implement Rate Limiter\").Session A marks it complete.Session B (Reviewer), observing the shared state update, sees Task #2 (\"Review Rate Limiter\") is now unblocked.Session B begins the review in a clean context, unbiased by the generation process.This aligns with the guide&#x27;s advice to \"fan out\" work across files, using scripts to loop through tasks and call Claude in parallel. Crucially, patch v2.1.17 fixed \"out-of-memory crashes when resuming sessions with heavy subagent usage,\" indicating that Anthropic is actively optimizing the runtime for these high-load, multi-agent scenarios.Enterprise readiness: stability, CI/CD, and controlFor decision-makers evaluating Claude Code for production pipelines, the recent changelogs (v2.1.16–v2.1.19) reveal a focus on reliability and integration.The Best Practices guide explicitly endorses running Claude in Headless Mode (claude -p). This allows engineering teams to integrate the agent into CI/CD pipelines, pre-commit hooks, or data processing scripts.For example, a nightly cron job could instantiate a Claude session to \"Analyze the day&#x27;s log files for anomalies,\" using a Task list to track progress through different log shards.The move to autonomous agents introduces new failure modes, which recent patches have addressed:Dangling Processes: v2.1.19 fixed an issue where Claude Code processes would hang when the terminal closed; the system now catches EIO errors and ensures a clean exit (using SIGKILL as a fallback).Hardware Compatibility: Fixes for crashes on processors without AVX support ensure broader deployment compatibility.Git Worktrees: Fixes for resume functionality when working across different directories or git worktrees ensure that the \"state\" follows the code, not just the shell session.Recognizing that enterprise workflows cannot turn on a dime, Anthropic introduced the CLAUDE_CODE_ENABLE_TASKS environment variable (v2.1.19). Setting this to false allows teams to opt-out of the new system temporarily, preserving existing workflows while they migrate to the Task-based architecture.The builder&#x27;s workflow: managing the context economyFor the individual developer, the Task system solves the \"context economy\" problem. Anthropic&#x27;s documentation warns that \"Claude&#x27;s context window... is the most important resource to manage,\" and that performance degrades as it fills.Before Tasks, clearing the context was dangerous—you wiped the agent&#x27;s memory of the overall plan. Now, because the plan is stored on disk, users can follow the best practice of \"aggressive context management.\" Developers can run /clear or /compact to free up tokens for the model&#x27;s reasoning, without losing the project roadmap.The changelog also highlights quality-of-life improvements for power users building complex scripts:Shorthand Arguments: Users can now access custom command arguments via $0, $1, etc., making it easier to script reusable \"Skills\" (e.g., a /refactor command that takes a filename as an argument).Keybindings: Fully customizable keyboard shortcuts (/keybindings) allow for faster interaction loops.What Tasks means for Claude Code usersWith the introduction of Tasks, Anthropic is signaling that the future of coding agents is a project management.By giving Claude Code a persistent memory, a way to understand dependency, and the stability fixes required for long-running processes, they have moved the tool from a \"copilot\" that sits next to you to a \"subagent\" that can be trusted to run in the background — especially when powered by Anthropic&#x27;s most performant model, Claude Opus 4.5.It is a technical evolution that acknowledges a simple truth: in the enterprise, the code is cheap; it is the context, the plan, and the reliability that are precious.",
          "content": "One of the biggest constraints currently facing AI builders who want to deploy agents in service of their individual or enterprise goals is the \"working memory\" required to manage complex, multi-stage engineering projects.Typically, when a AI agent operates purely on a stream of text or voice-based conversation, it lacks the structural permanence to handle dependencies. It knows what to do, but it often forgets why it is doing it, or in what order.With the release of Tasks for Claude Code (introduced in v2.1.16) last week, Anthropic has introduced a solution that is less about \"AI magic\" and more about sound software engineering principles. By moving from ephemeral \"To-dos\" to persistent \"Tasks,\" the company is fundamentally re-architecting how the model interacts with time, complexity, and system resources.This update transforms the tool from a reactive coding assistant into a state-aware project manager, creating the infrastructure necessary to execute the sophisticated workflows outlined in Anthropic&#x27;s just-released Best Practices guide, while recent changelog updates (v2.1.19) signal a focus on the stability required for enterprise adoption.The architecture of agency: from ephemeral to persistentTo understand the significance of this release for engineering teams, we must look at the mechanical differences between the old \"To-do\" system and the new \"Task\" primitive.Previously, Claude Code utilized a \"To-do\" list—a lightweight, chat-resident checklist. As Anthropic engineer Thariq Shihipar wrote in an article on X: \"Todos (orange) = &#x27;help Claude remember what to do&#x27;.\" These were effective for single-session scripts but fragile for actual engineering. If the session ended, the terminal crashed, or the context window drifted, the plan evaporated.Tasks (Green) introduce a new layer of abstraction designed for \"coordinating work across sessions, subagents, and context windows.\" This is achieved through three key architectural decisions:Dependency Graphs vs. Linear Lists: Unlike a flat Todo list, Tasks support directed acyclic graphs (DAGs). A task can explicitly \"block\" another. As seen in community demonstrations, the system can determine that Task 3 (Run Tests) cannot start until Task 1 (Build API) and Task 2 (Configure Auth) are complete. This enforcement prevents the \"hallucinated completion\" errors common in LLM workflows, where a model attempts to test code it hasn&#x27;t written yet.Filesystem Persistence & Durability: Anthropic chose a \"UNIX-philosophy\" approach to state management. Rather than locking project state inside a proprietary cloud database, Claude Code writes tasks directly to the user&#x27;s local filesystem (~/.claude/tasks). This creates durable state. A developer can shut down their terminal, switch machines, or recover from a system crash, and the agent reloads the exact state of the project. For enterprise teams, this persistence is critical—it means the \"plan\" is now an artifact that can be audited, backed up, or version-controlled, independent of the active session.Orchestration via Environment Variables: The most potent technical unlock is the ability to share state across sessions. By setting the CLAUDE_CODE_TASK_LIST_ID environment variable, developers can point multiple instances of Claude at the same task list. This allows updates to be \"broadcast\" to all active sessions, enabling a level of coordination that was previously impossible without external orchestration tools.Enabling the &#x27;swarm&#x27;: parallelism and subagentsThe release of Tasks makes the \"Parallel Sessions\" described in Anthropic&#x27;s Best Practices guide practical. The documentation suggests a Writer/Reviewer pattern that leverages this shared state:Session A (Writer) picks up Task #1 (\"Implement Rate Limiter\").Session A marks it complete.Session B (Reviewer), observing the shared state update, sees Task #2 (\"Review Rate Limiter\") is now unblocked.Session B begins the review in a clean context, unbiased by the generation process.This aligns with the guide&#x27;s advice to \"fan out\" work across files, using scripts to loop through tasks and call Claude in parallel. Crucially, patch v2.1.17 fixed \"out-of-memory crashes when resuming sessions with heavy subagent usage,\" indicating that Anthropic is actively optimizing the runtime for these high-load, multi-agent scenarios.Enterprise readiness: stability, CI/CD, and controlFor decision-makers evaluating Claude Code for production pipelines, the recent changelogs (v2.1.16–v2.1.19) reveal a focus on reliability and integration.The Best Practices guide explicitly endorses running Claude in Headless Mode (claude -p). This allows engineering teams to integrate the agent into CI/CD pipelines, pre-commit hooks, or data processing scripts.For example, a nightly cron job could instantiate a Claude session to \"Analyze the day&#x27;s log files for anomalies,\" using a Task list to track progress through different log shards.The move to autonomous agents introduces new failure modes, which recent patches have addressed:Dangling Processes: v2.1.19 fixed an issue where Claude Code processes would hang when the terminal closed; the system now catches EIO errors and ensures a clean exit (using SIGKILL as a fallback).Hardware Compatibility: Fixes for crashes on processors without AVX support ensure broader deployment compatibility.Git Worktrees: Fixes for resume functionality when working across different directories or git worktrees ensure that the \"state\" follows the code, not just the shell session.Recognizing that enterprise workflows cannot turn on a dime, Anthropic introduced the CLAUDE_CODE_ENABLE_TASKS environment variable (v2.1.19). Setting this to false allows teams to opt-out of the new system temporarily, preserving existing workflows while they migrate to the Task-based architecture.The builder&#x27;s workflow: managing the context economyFor the individual developer, the Task system solves the \"context economy\" problem. Anthropic&#x27;s documentation warns that \"Claude&#x27;s context window... is the most important resource to manage,\" and that performance degrades as it fills.Before Tasks, clearing the context was dangerous—you wiped the agent&#x27;s memory of the overall plan. Now, because the plan is stored on disk, users can follow the best practice of \"aggressive context management.\" Developers can run /clear or /compact to free up tokens for the model&#x27;s reasoning, without losing the project roadmap.The changelog also highlights quality-of-life improvements for power users building complex scripts:Shorthand Arguments: Users can now access custom command arguments via $0, $1, etc., making it easier to script reusable \"Skills\" (e.g., a /refactor command that takes a filename as an argument).Keybindings: Fully customizable keyboard shortcuts (/keybindings) allow for faster interaction loops.What Tasks means for Claude Code usersWith the introduction of Tasks, Anthropic is signaling that the future of coding agents is a project management.By giving Claude Code a persistent memory, a way to understand dependency, and the stability fixes required for long-running processes, they have moved the tool from a \"copilot\" that sits next to you to a \"subagent\" that can be trusted to run in the background — especially when powered by Anthropic&#x27;s most performant model, Claude Opus 4.5.It is a technical evolution that acknowledges a simple truth: in the enterprise, the code is cheap; it is the context, the plan, and the reliability that are precious.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/JDzxrrsQ9lmwENyqvgTLy/95df12dea2055587e5325b88244003cc/Gemini_Generated_Image_3ni3xj3ni3xj3ni3.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/how-to-generate-ai-images-using-chatgpt-120000560.html",
          "published_at": "Mon, 26 Jan 2026 18:05:00 +0000",
          "title": "How to generate AI images using ChatGPT",
          "standfirst": "Since March 2025, ChatGPT has been capable of generating images. Following a period where it briefly wasn't available to free users, you now don't even pay for one of OpenAI's subscriptions to use this feature. And while making images inside of ChatGPT is easy, there are some nuances worth explaining. For example, did you know you can ask ChatGPT to edit photos you've taken? It's more powerful than you might think. Here’s everything you need to know about generating AI images with ChatGPT. How to create images with ChatGPT using text prompts To begin making an image in ChatGPT, you can start by typing in the prompt bar. Igor Bonifacic for EngadgetYou can start generating images in ChatGPT simply by typing in the prompt bar what you want to see. There's no need to overthink things; as long as you have some version of \"generate an image\" followed by a description of your idea, ChatGPT will do the rest. Depending on the complexity of the prompt and whether you pay for ChatGPT, it may take a minute or two for the chatbot to complete your image request. Sometimes the process can take longer if OpenAI's servers are experiencing greater traffic than usual.At the end of last year, OpenAI updated the model powering image generation to make it faster, as well as better at rendering text and following instructions. At the same time, it added a dedicated \"Images\" section to ChatGPT's sidebar. Here you can see all the images you've made, alongside sample prompts and suggestions for styles to try out, making it a great place to start if you've never used an image generator before. How to create images with ChatGPT using existing photosYou can also upload images to ChatGPT.Igor Bonifacic for EngadgetIn addition to generating images from text prompts, ChatGPT can modify existing photos or images you upload. This is my preferred way of making images with ChatGPT; I don't need to describe the composition, I can use an existing one to guide the chatbot. To use an existing image as a starting point for a new generation, follow these steps: Tap the \"+\" icon, located to the left of the prompt bar. Select Add photos & files. Select the image you want ChatGPT to edit. If uploading an image from your phone, you'll first need to grant ChatGPT access to your camera roll. Write a prompt describing the changes you want. If generating from the Images section, tap \"Add photos\" instead.Keep in mind any photos you upload to OpenAI's servers may be used by the company to train future models. You can opt out of allowing your data to be used for training by following these steps: Open the sidebar menu. On mobile, tap the two lines on the top left of the interface; on desktop, click instead on the OpenAI logo.Tap your name to access account settings. Tap Data controls.Toggle off Improve the model for everyone. How to edit the images ChatGPT generatesChatGPT gives you a few different ways to edit images.Igor Bonifacic for EngadgetIf you're unhappy with ChatGPT's output, you have two options. You can either prompt it to create an entirely new image, or edit parts of the picture it just generated. As always, the process for both involves simply typing what you want in the prompt bar. On mobile, OpenAI gives users a few different ways of accomplishing the same task.To generate an entirely new image: Tap the three dots icon below the image ChatGPT created. Select Retry. To edit part of an existing image generation: Tap the image ChatGPT created. Tap Select area.Use your finger to mask the section of the image you want ChatGPT to tweak. The slider on the left allows you to adjust the size of the masking brush. On desktop, masking is also available if you click on an image and then click on the paintbrush icon on the top right. Describe what you want ChatGPT to add, remove or replace through the prompt bar.ChatGPT can also blend one of your photos with an image it has generated. To do this: Tap an image ChatGPT created.Tap Blend in a photo.Upload the photo you wish Like all AI systems, ChatGPT is non-deterministic, meaning even if you prompt it in the same way multiple times, it won't generate the exact same response each time. Tips to create better images with ChatGPTThe best advice I can offer is to be specific when prompting ChatGPT. The more detail you can provide when describing what you want from it, the better the results. And remember: ChatGPT can hallucinate — as you may have noticed from one of the example pictures I included above. In the image of the tortoiseshell cat, not only is the tortie not sitting on the window sill as instructed, it's sitting on a table that doesn't make much sense. So, most of all, be patient. Prompting an AI model is not exact science, and it can take a few tries before it creates the result you want. FAQsHow do you access ChatGPT?ChatGPT is available on the web, desktop and mobile. To access it on your computer, open your preferred browser and navigate to chatgpt.com. OpenAI also offers dedicated Mac and Windows apps you can download from the company's website. On iOS and Android, you'll need to download the ChatGPT app from either the App Store or Google Play before you can start using the chatbot. Since ChatGPT runs on OpenAI's servers, as long as you can access the chatbot, you'll be able to use it to create images no matter the age of your phone or computer. Can ChatGPT generate images for free? Yes, ChatGPT can generate images for free, as long as you create an OpenAI account. However, there is a daily rate cap and GPT-5 will take longer to make a free image. Following March 27, 2025, OpenAI briefly limited free users to three image generations per day. The company has since relaxed that restriction, though it doesn't list a specific limit on its website. In my experience, you'll be able to generate about six to seven images every 24 hours.OpenAI offers three different subscription plans, each with their own set of image generation perks. ChatGPT Go, which costs $8 per month, offers \"more image creation.\" ChatGPT Plus, which costs $20 per month, offers \"expanded and faster image creation.\"ChatGPT Pro, which costs $200 per month, offers \"unlimited and faster image creation.\" Note: ChatGPT Go will be included in OpenAI's forthcoming ads pilot, which will see the company display sponsored content alongside organic responses from ChatGPT. The company does not plan to display ads to Plus and Pro users. Can ChatGPT generate an existing photo? No. For copyright reasons, ChatGPT can't replicate photos or exact real world events. For example, when I asked it to recreate the photo of Zinedine Zidane's iconic 2006 World Cup headbutt, ChatGPT refused. \"I can make an artistic reinterpretation inspired by the emotion or energy of that moment — for example, a stylized painting showing the tension and intensity of competition, without depicting real individuals,\" it told me. This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-generate-ai-images-using-chatgpt-120000560.html?src=rss",
          "content": "Since March 2025, ChatGPT has been capable of generating images. Following a period where it briefly wasn't available to free users, you now don't even pay for one of OpenAI's subscriptions to use this feature. And while making images inside of ChatGPT is easy, there are some nuances worth explaining. For example, did you know you can ask ChatGPT to edit photos you've taken? It's more powerful than you might think. Here’s everything you need to know about generating AI images with ChatGPT. How to create images with ChatGPT using text prompts To begin making an image in ChatGPT, you can start by typing in the prompt bar. Igor Bonifacic for EngadgetYou can start generating images in ChatGPT simply by typing in the prompt bar what you want to see. There's no need to overthink things; as long as you have some version of \"generate an image\" followed by a description of your idea, ChatGPT will do the rest. Depending on the complexity of the prompt and whether you pay for ChatGPT, it may take a minute or two for the chatbot to complete your image request. Sometimes the process can take longer if OpenAI's servers are experiencing greater traffic than usual.At the end of last year, OpenAI updated the model powering image generation to make it faster, as well as better at rendering text and following instructions. At the same time, it added a dedicated \"Images\" section to ChatGPT's sidebar. Here you can see all the images you've made, alongside sample prompts and suggestions for styles to try out, making it a great place to start if you've never used an image generator before. How to create images with ChatGPT using existing photosYou can also upload images to ChatGPT.Igor Bonifacic for EngadgetIn addition to generating images from text prompts, ChatGPT can modify existing photos or images you upload. This is my preferred way of making images with ChatGPT; I don't need to describe the composition, I can use an existing one to guide the chatbot. To use an existing image as a starting point for a new generation, follow these steps: Tap the \"+\" icon, located to the left of the prompt bar. Select Add photos & files. Select the image you want ChatGPT to edit. If uploading an image from your phone, you'll first need to grant ChatGPT access to your camera roll. Write a prompt describing the changes you want. If generating from the Images section, tap \"Add photos\" instead.Keep in mind any photos you upload to OpenAI's servers may be used by the company to train future models. You can opt out of allowing your data to be used for training by following these steps: Open the sidebar menu. On mobile, tap the two lines on the top left of the interface; on desktop, click instead on the OpenAI logo.Tap your name to access account settings. Tap Data controls.Toggle off Improve the model for everyone. How to edit the images ChatGPT generatesChatGPT gives you a few different ways to edit images.Igor Bonifacic for EngadgetIf you're unhappy with ChatGPT's output, you have two options. You can either prompt it to create an entirely new image, or edit parts of the picture it just generated. As always, the process for both involves simply typing what you want in the prompt bar. On mobile, OpenAI gives users a few different ways of accomplishing the same task.To generate an entirely new image: Tap the three dots icon below the image ChatGPT created. Select Retry. To edit part of an existing image generation: Tap the image ChatGPT created. Tap Select area.Use your finger to mask the section of the image you want ChatGPT to tweak. The slider on the left allows you to adjust the size of the masking brush. On desktop, masking is also available if you click on an image and then click on the paintbrush icon on the top right. Describe what you want ChatGPT to add, remove or replace through the prompt bar.ChatGPT can also blend one of your photos with an image it has generated. To do this: Tap an image ChatGPT created.Tap Blend in a photo.Upload the photo you wish Like all AI systems, ChatGPT is non-deterministic, meaning even if you prompt it in the same way multiple times, it won't generate the exact same response each time. Tips to create better images with ChatGPTThe best advice I can offer is to be specific when prompting ChatGPT. The more detail you can provide when describing what you want from it, the better the results. And remember: ChatGPT can hallucinate — as you may have noticed from one of the example pictures I included above. In the image of the tortoiseshell cat, not only is the tortie not sitting on the window sill as instructed, it's sitting on a table that doesn't make much sense. So, most of all, be patient. Prompting an AI model is not exact science, and it can take a few tries before it creates the result you want. FAQsHow do you access ChatGPT?ChatGPT is available on the web, desktop and mobile. To access it on your computer, open your preferred browser and navigate to chatgpt.com. OpenAI also offers dedicated Mac and Windows apps you can download from the company's website. On iOS and Android, you'll need to download the ChatGPT app from either the App Store or Google Play before you can start using the chatbot. Since ChatGPT runs on OpenAI's servers, as long as you can access the chatbot, you'll be able to use it to create images no matter the age of your phone or computer. Can ChatGPT generate images for free? Yes, ChatGPT can generate images for free, as long as you create an OpenAI account. However, there is a daily rate cap and GPT-5 will take longer to make a free image. Following March 27, 2025, OpenAI briefly limited free users to three image generations per day. The company has since relaxed that restriction, though it doesn't list a specific limit on its website. In my experience, you'll be able to generate about six to seven images every 24 hours.OpenAI offers three different subscription plans, each with their own set of image generation perks. ChatGPT Go, which costs $8 per month, offers \"more image creation.\" ChatGPT Plus, which costs $20 per month, offers \"expanded and faster image creation.\"ChatGPT Pro, which costs $200 per month, offers \"unlimited and faster image creation.\" Note: ChatGPT Go will be included in OpenAI's forthcoming ads pilot, which will see the company display sponsored content alongside organic responses from ChatGPT. The company does not plan to display ads to Plus and Pro users. Can ChatGPT generate an existing photo? No. For copyright reasons, ChatGPT can't replicate photos or exact real world events. For example, when I asked it to recreate the photo of Zinedine Zidane's iconic 2006 World Cup headbutt, ChatGPT refused. \"I can make an artistic reinterpretation inspired by the emotion or energy of that moment — for example, a stylized painting showing the tension and intensity of competition, without depicting real individuals,\" it told me. This article originally appeared on Engadget at https://www.engadget.com/ai/how-to-generate-ai-images-using-chatgpt-120000560.html?src=rss",
          "feed_position": 5,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/chatgpt-how-to-3.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/anthropic-embeds-slack-figma-and-asana-inside-claude-turning-ai-chat-into-a",
          "published_at": "Mon, 26 Jan 2026 18:00:00 GMT",
          "title": "Anthropic embeds Slack, Figma and Asana inside Claude, turning AI chat into a workplace command center",
          "standfirst": "Anthropic announced Monday that users can now open and interact with popular business applications directly inside Claude, the company&#x27;s AI assistant—a significant expansion that transforms the chatbot from a conversational tool into an integrated workspace where employees can build project timelines, draft Slack messages, create presentations, and visualize data without switching browser tabs.The rollout, which goes live today, includes integrations with Amplitude, Asana, Box, Canva, Clay, Figma, Hex, Monday.com, and Slack. Salesforce integration is coming soon. The feature marks a new chapter in Anthropic&#x27;s aggressive push to dominate enterprise AI, arriving just days after the company&#x27;s CEO made headlines at Davos with bold predictions about AI replacing white-collar workers.\"MCP Apps are an extension to the core MCP protocol and are part of the open source MCP ecosystem,\" Sean Strong, Anthropic&#x27;s product manager for MCP Apps, told VentureBeat in an exclusive interview. \"Within Claude.ai, connectors require a paid Claude plan — Pro, Max, Team, or Enterprise — but there is no additional charge associated with using connectors.\"That pricing decision is notable. Rather than monetizing integrations separately or charging partners for distribution, Anthropic is bundling interactive tools into existing subscription tiers — a strategy designed to accelerate adoption and deepen Claude&#x27;s foothold in corporate environments where the company reportedly already leads OpenAI.Inside MCP Apps, the open-source technology that lets Claude control your favorite work toolsThe technical foundation is what Anthropic calls \"MCP Apps,\" a new extension to the Model Context Protocol, the open standard for connecting external tools to AI applications that Anthropic open-sourced last year. MCP Apps allow any MCP server to deliver an interactive user interface within any supporting AI product—meaning the technology isn&#x27;t limited to Claude.In practice, the integrations allow for surprisingly granular control. Users can build analytics charts in Amplitude and adjust parameters interactively to explore trends. They can turn conversations into Asana projects with tasks and timelines that sync automatically. They can prompt Claude to generate flowcharts or Gantt charts in Figma&#x27;s collaborative whiteboard tool, FigJam. They can draft Slack messages, preview formatting, and review before posting.The Hex integration may prove particularly valuable for data teams: users can ask data questions in natural language and receive answers complete with interactive charts, tables, and citations — effectively turning Claude into a business intelligence interface.\"We open sourced MCP to give the ecosystem a universal way to connect tools to AI,\" the company said in its announcement blog. \"Now we&#x27;re extending MCP further so developers can build interactive UI on top of it, wherever their users are.\"What happens when AI can send messages and create projects on your behalfWith AI systems increasingly capable of taking real-world actions — sending messages, creating projects, publishing content — the question of guardrails becomes critical. Can an employee accidentally send an unreviewed Slack message or publish an incomplete Canva presentation?Strong addressed this directly. \"Most major MCP clients, including Claude, provide consent prompts that help users determine if they want to take an action via a MCP server,\" he said.For enterprise deployments, IT administrators retain control. \"Team and Enterprise admins have the ability to control which MCP servers users in their organizations have the ability to use,\" Strong explained.The consent-prompt approach is a middle ground between full autonomy and cumbersome approval workflows. But it also places significant responsibility on individual users to review actions before confirming them — a design choice that may draw scrutiny as AI agents become capable of more consequential decisions.The security concerns are not hypothetical. As Fortune reported last week, Anthropic&#x27;s Claude Code product faces vulnerabilities including \"prompt injections,\" where attackers hide malicious instructions in web content to manipulate AI behavior. The company has implemented multiple security layers, including running some features in virtual machines and adding deletion protection after users accidentally removed files. \"Agent safety—that is, the task of securing Claude&#x27;s real-world actions—is still an active area of development in the industry,\" Anthropic has acknowledged.Claude Code&#x27;s viral success set the stage for Anthropic&#x27;s enterprise ambitionsThe interactive tools announcement arrives at a moment of unusual momentum for Anthropic. Claude Code, the company&#x27;s coding assistant released in February 2024, has become a viral hit that has captured attention far beyond its intended developer audience.Originally built for software developers, Claude Code has captured attention far beyond its intended audience. Non-programmers have deployed it to book theater tickets, file taxes, and monitor tomato plants. Nvidia CEO Jensen Huang called it \"incredible.\" Even Microsoft, which sells the competing GitHub Copilot, has widely adopted Claude Code internally, with non-developers reportedly encouraged to use it.Boris Cherny, Anthropic&#x27;s head of Claude Code, told Fortune that his team built Cowork — a user-friendly version of the coding product for non-programmers — in approximately a week and a half, largely using Claude Code itself. \"Engineers just feel unshackled, that they don&#x27;t have to work on all the tedious stuff anymore,\" Cherny said.Claude Code is now used by Uber, Netflix, Spotify, Salesforce, Accenture, and Snowflake, according to Anthropic. Claude&#x27;s total web audience has more than doubled since December 2024, and daily unique visitors on desktop are up 12% globally year-to-date, according to data from Similarweb and Sensor Tower published by The Wall Street Journal.The company is also reportedly planning a $10 billion fundraising round that would value Anthropic at $350 billion — a staggering figure that reflects investor confidence in the company&#x27;s enterprise traction.Anthropic&#x27;s CEO stirred controversy at Davos with predictions about AI replacing workersThe interactive tools launch also arrives against a backdrop of intense debate about AI&#x27;s impact on employment — a debate that Anthropic&#x27;s own CEO helped intensify at the World Economic Forum in Davos last week.Dario Amodei told a Davos audience that AI models would replace the work of all software developers within a year and would reach \"Nobel-level\" scientific research in multiple fields within two years. He predicted that 50% of white-collar jobs would disappear within five years.\"I have engineers within Anthropic who say &#x27;I don&#x27;t write any code anymore. I just let the model write the code, I edit it,&#x27;\" Amodei said. \"We might be six to 12 months away from when the model is doing most, maybe all of what software engineers do end-to-end.\"Not everyone agrees with that timeline. Demis Hassabis, the Nobel Prize-winning CEO of Google DeepMind, said at the same conference that today&#x27;s AI systems are \"nowhere near\" human-level artificial general intelligence. Yann LeCun, the Turing Award-winning AI pioneer who recently left Meta to found Advanced Machine Intelligence Labs, went further, arguing that large language models \"will never be able to achieve humanlike intelligence\" and that a completely different approach is needed.Why embedding AI into daily workflows could create powerful lock-in for enterprisesAnthropic&#x27;s integration strategy reflects a broader shift in enterprise AI competition. The battleground is moving from model benchmarks and capability demonstrations toward workflow integration — the degree to which AI systems become embedded in how companies actually operate.By making Claude the interface through which employees interact with Asana, Slack, Figma, and other daily tools, Anthropic is positioning itself not merely as an AI provider but as a workflow orchestration layer. The more actions that flow through Claude, the harder it becomes for enterprises to switch to a competitor.This approach mirrors strategies that proved successful for earlier generations of enterprise software. Salesforce built its dominance partly by becoming the system of record for customer data. Slack grew by centralizing workplace communication. Anthropic appears to be betting that AI assistants can occupy a similar position — the default starting point for work itself.The open-source foundation of MCP may accelerate this strategy. By making the protocol available to any developer, Anthropic encourages a broad ecosystem of integrations that all funnel through MCP-compatible clients — of which Claude is the most prominent. The company benefits from network effects even as it maintains the standard is open.The race to become the operating system for AI-powered work is just getting startedThe launch notably excludes some major enterprise platforms. Salesforce integration is listed as \"coming soon,\" and there&#x27;s no mention of Microsoft 365, Google Workspace, or other productivity suites that dominate corporate environments. Those gaps may limit initial adoption in organizations heavily invested in those ecosystems.The feature is available on web and desktop for paid Claude plans, with support for Claude Cowork — the file management agent launched last week — coming later. Mobile support was not mentioned in the announcement.For enterprises evaluating Claude against OpenAI&#x27;s offerings and other competitors, the interactive integrations represent a tangible differentiator. The ability to take action within business tools — rather than simply generating text that users must copy elsewhere — addresses a persistent friction point in AI adoption.Whether that advantage proves durable depends on how quickly competitors respond. OpenAI has its own enterprise ambitions and partnerships. Google is integrating Gemini across its productivity suite. Microsoft continues to deepen Copilot&#x27;s presence in Office applications.But the larger significance may be what today&#x27;s announcement signals about where enterprise software is headed. For decades, the default unit of work has been the application — the spreadsheet, the project tracker, the messaging platform. Anthropic is wagering that the future belongs to the AI layer that sits above them all.If the company is right, the question for every enterprise software vendor becomes uncomfortably simple: Do you want to be the tool, or the thing that controls the tools?",
          "content": "Anthropic announced Monday that users can now open and interact with popular business applications directly inside Claude, the company&#x27;s AI assistant—a significant expansion that transforms the chatbot from a conversational tool into an integrated workspace where employees can build project timelines, draft Slack messages, create presentations, and visualize data without switching browser tabs.The rollout, which goes live today, includes integrations with Amplitude, Asana, Box, Canva, Clay, Figma, Hex, Monday.com, and Slack. Salesforce integration is coming soon. The feature marks a new chapter in Anthropic&#x27;s aggressive push to dominate enterprise AI, arriving just days after the company&#x27;s CEO made headlines at Davos with bold predictions about AI replacing white-collar workers.\"MCP Apps are an extension to the core MCP protocol and are part of the open source MCP ecosystem,\" Sean Strong, Anthropic&#x27;s product manager for MCP Apps, told VentureBeat in an exclusive interview. \"Within Claude.ai, connectors require a paid Claude plan — Pro, Max, Team, or Enterprise — but there is no additional charge associated with using connectors.\"That pricing decision is notable. Rather than monetizing integrations separately or charging partners for distribution, Anthropic is bundling interactive tools into existing subscription tiers — a strategy designed to accelerate adoption and deepen Claude&#x27;s foothold in corporate environments where the company reportedly already leads OpenAI.Inside MCP Apps, the open-source technology that lets Claude control your favorite work toolsThe technical foundation is what Anthropic calls \"MCP Apps,\" a new extension to the Model Context Protocol, the open standard for connecting external tools to AI applications that Anthropic open-sourced last year. MCP Apps allow any MCP server to deliver an interactive user interface within any supporting AI product—meaning the technology isn&#x27;t limited to Claude.In practice, the integrations allow for surprisingly granular control. Users can build analytics charts in Amplitude and adjust parameters interactively to explore trends. They can turn conversations into Asana projects with tasks and timelines that sync automatically. They can prompt Claude to generate flowcharts or Gantt charts in Figma&#x27;s collaborative whiteboard tool, FigJam. They can draft Slack messages, preview formatting, and review before posting.The Hex integration may prove particularly valuable for data teams: users can ask data questions in natural language and receive answers complete with interactive charts, tables, and citations — effectively turning Claude into a business intelligence interface.\"We open sourced MCP to give the ecosystem a universal way to connect tools to AI,\" the company said in its announcement blog. \"Now we&#x27;re extending MCP further so developers can build interactive UI on top of it, wherever their users are.\"What happens when AI can send messages and create projects on your behalfWith AI systems increasingly capable of taking real-world actions — sending messages, creating projects, publishing content — the question of guardrails becomes critical. Can an employee accidentally send an unreviewed Slack message or publish an incomplete Canva presentation?Strong addressed this directly. \"Most major MCP clients, including Claude, provide consent prompts that help users determine if they want to take an action via a MCP server,\" he said.For enterprise deployments, IT administrators retain control. \"Team and Enterprise admins have the ability to control which MCP servers users in their organizations have the ability to use,\" Strong explained.The consent-prompt approach is a middle ground between full autonomy and cumbersome approval workflows. But it also places significant responsibility on individual users to review actions before confirming them — a design choice that may draw scrutiny as AI agents become capable of more consequential decisions.The security concerns are not hypothetical. As Fortune reported last week, Anthropic&#x27;s Claude Code product faces vulnerabilities including \"prompt injections,\" where attackers hide malicious instructions in web content to manipulate AI behavior. The company has implemented multiple security layers, including running some features in virtual machines and adding deletion protection after users accidentally removed files. \"Agent safety—that is, the task of securing Claude&#x27;s real-world actions—is still an active area of development in the industry,\" Anthropic has acknowledged.Claude Code&#x27;s viral success set the stage for Anthropic&#x27;s enterprise ambitionsThe interactive tools announcement arrives at a moment of unusual momentum for Anthropic. Claude Code, the company&#x27;s coding assistant released in February 2024, has become a viral hit that has captured attention far beyond its intended developer audience.Originally built for software developers, Claude Code has captured attention far beyond its intended audience. Non-programmers have deployed it to book theater tickets, file taxes, and monitor tomato plants. Nvidia CEO Jensen Huang called it \"incredible.\" Even Microsoft, which sells the competing GitHub Copilot, has widely adopted Claude Code internally, with non-developers reportedly encouraged to use it.Boris Cherny, Anthropic&#x27;s head of Claude Code, told Fortune that his team built Cowork — a user-friendly version of the coding product for non-programmers — in approximately a week and a half, largely using Claude Code itself. \"Engineers just feel unshackled, that they don&#x27;t have to work on all the tedious stuff anymore,\" Cherny said.Claude Code is now used by Uber, Netflix, Spotify, Salesforce, Accenture, and Snowflake, according to Anthropic. Claude&#x27;s total web audience has more than doubled since December 2024, and daily unique visitors on desktop are up 12% globally year-to-date, according to data from Similarweb and Sensor Tower published by The Wall Street Journal.The company is also reportedly planning a $10 billion fundraising round that would value Anthropic at $350 billion — a staggering figure that reflects investor confidence in the company&#x27;s enterprise traction.Anthropic&#x27;s CEO stirred controversy at Davos with predictions about AI replacing workersThe interactive tools launch also arrives against a backdrop of intense debate about AI&#x27;s impact on employment — a debate that Anthropic&#x27;s own CEO helped intensify at the World Economic Forum in Davos last week.Dario Amodei told a Davos audience that AI models would replace the work of all software developers within a year and would reach \"Nobel-level\" scientific research in multiple fields within two years. He predicted that 50% of white-collar jobs would disappear within five years.\"I have engineers within Anthropic who say &#x27;I don&#x27;t write any code anymore. I just let the model write the code, I edit it,&#x27;\" Amodei said. \"We might be six to 12 months away from when the model is doing most, maybe all of what software engineers do end-to-end.\"Not everyone agrees with that timeline. Demis Hassabis, the Nobel Prize-winning CEO of Google DeepMind, said at the same conference that today&#x27;s AI systems are \"nowhere near\" human-level artificial general intelligence. Yann LeCun, the Turing Award-winning AI pioneer who recently left Meta to found Advanced Machine Intelligence Labs, went further, arguing that large language models \"will never be able to achieve humanlike intelligence\" and that a completely different approach is needed.Why embedding AI into daily workflows could create powerful lock-in for enterprisesAnthropic&#x27;s integration strategy reflects a broader shift in enterprise AI competition. The battleground is moving from model benchmarks and capability demonstrations toward workflow integration — the degree to which AI systems become embedded in how companies actually operate.By making Claude the interface through which employees interact with Asana, Slack, Figma, and other daily tools, Anthropic is positioning itself not merely as an AI provider but as a workflow orchestration layer. The more actions that flow through Claude, the harder it becomes for enterprises to switch to a competitor.This approach mirrors strategies that proved successful for earlier generations of enterprise software. Salesforce built its dominance partly by becoming the system of record for customer data. Slack grew by centralizing workplace communication. Anthropic appears to be betting that AI assistants can occupy a similar position — the default starting point for work itself.The open-source foundation of MCP may accelerate this strategy. By making the protocol available to any developer, Anthropic encourages a broad ecosystem of integrations that all funnel through MCP-compatible clients — of which Claude is the most prominent. The company benefits from network effects even as it maintains the standard is open.The race to become the operating system for AI-powered work is just getting startedThe launch notably excludes some major enterprise platforms. Salesforce integration is listed as \"coming soon,\" and there&#x27;s no mention of Microsoft 365, Google Workspace, or other productivity suites that dominate corporate environments. Those gaps may limit initial adoption in organizations heavily invested in those ecosystems.The feature is available on web and desktop for paid Claude plans, with support for Claude Cowork — the file management agent launched last week — coming later. Mobile support was not mentioned in the announcement.For enterprises evaluating Claude against OpenAI&#x27;s offerings and other competitors, the interactive integrations represent a tangible differentiator. The ability to take action within business tools — rather than simply generating text that users must copy elsewhere — addresses a persistent friction point in AI adoption.Whether that advantage proves durable depends on how quickly competitors respond. OpenAI has its own enterprise ambitions and partnerships. Google is integrating Gemini across its productivity suite. Microsoft continues to deepen Copilot&#x27;s presence in Office applications.But the larger significance may be what today&#x27;s announcement signals about where enterprise software is headed. For decades, the default unit of work has been the application — the spreadsheet, the project tracker, the messaging platform. Anthropic is wagering that the future belongs to the AI layer that sits above them all.If the company is right, the question for every enterprise software vendor becomes uncomfortably simple: Do you want to be the tool, or the thing that controls the tools?",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1p8ftZpSuS4Melgo35eWGo/c8a0c84c233a5c28bf4e49321e2602e0/nuneybits_Vector_art_of_a_glowing_burnt_orange_orb_at_center_wi_838c3333-89a8-4df4-b2bd-8d6a829836b2.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/trump-admin-reportedly-plans-to-use-ai-to-write-federal-regulations-175155111.html",
          "published_at": "Mon, 26 Jan 2026 17:51:56 +0000",
          "title": "Trump admin reportedly plans to use AI to write federal regulations",
          "standfirst": "The Trump administration is planning on using Google Gemini to draft important federal regulations, as reported by ProPublica. This is starting with the Department of Transportation, according to interviews with agency staffers. Regulations created by the DOT help keep us safe when traveling. The plan was initially presented to DOT staffers last month, with agency attorney Daniel Cohen writing to colleagues about AI's \"potential to revolutionize the way we draft rulemakings.\" Gregory Zerzan, the agency's general counsel, has indicated that President Donald Trump is \"very excited by this initiative\" and that DOT will be \"the first agency that is fully enabled to use AI to draft rules.\" This does suggest a pilot program of sorts, with eventual plans to bring AI to other departments. NEW: The Trump administration is planning to use AI to write federal regulations despite the risk of hallucinations.“We don't even need a very good rule,” @USDOT’s top lawyer said of the plan, per meeting notes reviewed by ProPublica. “We want good enough.” 🧵 pic.twitter.com/YKGvmlkMCt— Jesse Coburn (@Jesse_Coburn) January 26, 2026 Oddly, Zerzan doesn't seem that interested in high-quality regulations. ProPublica received transcripts of a meeting in which he declared that \"we don't need the perfect rule on XYZ. We don't even need a very good rule on XYZ.\" He went on to say that \"we want good enough\" and that \"we're flooding the zone.\" Let me remind you that DOT regulates the safety standards of commercial aircraft, along with rules involving the transport of hazardous materials and driver qualifications. The agency's rules touch on every aspect of transportation safety. Why would the federal government rely on a new technology that's notorious for making mistakes? AI “hallucinations” eg false/made-up info now becoming a problem in scientific publications. Kudos to @alexcdot et al on building an AI hallucination detector and finding that certain journals/authors have used LLMs to generate papers that also made it through peer review. Here’s… pic.twitter.com/i4Be1lS8xq— Daphne Zohar (@daphnezohar) January 22, 2026 The answer is speed. Writing and revising complex federal regulations can take months, but Google Gemini can spit something out in minutes. A DOT employee giving a presentation on the program suggested that many parts of these regulations are just \"word salad\" anyways, so AI should be able to do just fine. \"It shouldn’t take you more than 20 minutes to get a draft rule out of Gemini,\" Zerzan said. The plan is to compress the timeline in which transportation regulations are written and reviewed. The department has already used AI to draft an unpublished Federal Aviation Administration rule. Federal agencies have used AI for years, but not to actually write regulations. It's primarily been used for the purpose of translating documents, analyzing data and categorizing public comments. Trump, however, is a huge proponent of the technology. He has released multiple executive orders in support of AI and once shared an AI-created video in which he flew a fighter jet and dropped what appears to be feces on American citizens. Skeptics say that large language models like Gemini shouldn't be in charge of drafting complicated and consequential regulations that impact millions of everyday Americans. Mistakes could lead to lawsuits and even injuries and deaths. Mike Horton, DOT’s former acting chief artificial intelligence officer, said using Gemini to draft regulations was like “having a high school intern that’s doing your rulemaking.” He also said that agency leaders under Trump \"want to go fast and break things, but going fast and breaking things means people are going to get hurt.\" \"Just because these tools can produce a lot of words doesn’t mean that those words add up to a high-quality government decision,” said Bridget Dooling, a professor at Ohio State University who studies administrative law. “It’s so tempting to try to figure out how to use these tools, and I think it would make sense to try. But I think it should be done with a lot of skepticism.\" DOT has experienced a net loss of more than 4,000 employees since Trump started his second term. This includes over 100 attorneys.This article originally appeared on Engadget at https://www.engadget.com/ai/trump-admin-reportedly-plans-to-use-ai-to-write-federal-regulations-175155111.html?src=rss",
          "content": "The Trump administration is planning on using Google Gemini to draft important federal regulations, as reported by ProPublica. This is starting with the Department of Transportation, according to interviews with agency staffers. Regulations created by the DOT help keep us safe when traveling. The plan was initially presented to DOT staffers last month, with agency attorney Daniel Cohen writing to colleagues about AI's \"potential to revolutionize the way we draft rulemakings.\" Gregory Zerzan, the agency's general counsel, has indicated that President Donald Trump is \"very excited by this initiative\" and that DOT will be \"the first agency that is fully enabled to use AI to draft rules.\" This does suggest a pilot program of sorts, with eventual plans to bring AI to other departments. NEW: The Trump administration is planning to use AI to write federal regulations despite the risk of hallucinations.“We don't even need a very good rule,” @USDOT’s top lawyer said of the plan, per meeting notes reviewed by ProPublica. “We want good enough.” 🧵 pic.twitter.com/YKGvmlkMCt— Jesse Coburn (@Jesse_Coburn) January 26, 2026 Oddly, Zerzan doesn't seem that interested in high-quality regulations. ProPublica received transcripts of a meeting in which he declared that \"we don't need the perfect rule on XYZ. We don't even need a very good rule on XYZ.\" He went on to say that \"we want good enough\" and that \"we're flooding the zone.\" Let me remind you that DOT regulates the safety standards of commercial aircraft, along with rules involving the transport of hazardous materials and driver qualifications. The agency's rules touch on every aspect of transportation safety. Why would the federal government rely on a new technology that's notorious for making mistakes? AI “hallucinations” eg false/made-up info now becoming a problem in scientific publications. Kudos to @alexcdot et al on building an AI hallucination detector and finding that certain journals/authors have used LLMs to generate papers that also made it through peer review. Here’s… pic.twitter.com/i4Be1lS8xq— Daphne Zohar (@daphnezohar) January 22, 2026 The answer is speed. Writing and revising complex federal regulations can take months, but Google Gemini can spit something out in minutes. A DOT employee giving a presentation on the program suggested that many parts of these regulations are just \"word salad\" anyways, so AI should be able to do just fine. \"It shouldn’t take you more than 20 minutes to get a draft rule out of Gemini,\" Zerzan said. The plan is to compress the timeline in which transportation regulations are written and reviewed. The department has already used AI to draft an unpublished Federal Aviation Administration rule. Federal agencies have used AI for years, but not to actually write regulations. It's primarily been used for the purpose of translating documents, analyzing data and categorizing public comments. Trump, however, is a huge proponent of the technology. He has released multiple executive orders in support of AI and once shared an AI-created video in which he flew a fighter jet and dropped what appears to be feces on American citizens. Skeptics say that large language models like Gemini shouldn't be in charge of drafting complicated and consequential regulations that impact millions of everyday Americans. Mistakes could lead to lawsuits and even injuries and deaths. Mike Horton, DOT’s former acting chief artificial intelligence officer, said using Gemini to draft regulations was like “having a high school intern that’s doing your rulemaking.” He also said that agency leaders under Trump \"want to go fast and break things, but going fast and breaking things means people are going to get hurt.\" \"Just because these tools can produce a lot of words doesn’t mean that those words add up to a high-quality government decision,” said Bridget Dooling, a professor at Ohio State University who studies administrative law. “It’s so tempting to try to figure out how to use these tools, and I think it would make sense to try. But I think it should be done with a lot of skepticism.\" DOT has experienced a net loss of more than 4,000 employees since Trump started his second term. This includes over 100 attorneys.This article originally appeared on Engadget at https://www.engadget.com/ai/trump-admin-reportedly-plans-to-use-ai-to-write-federal-regulations-175155111.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/browser-security-gap-ciso-enterprise-breaches",
          "published_at": "Mon, 26 Jan 2026 17:00:00 GMT",
          "title": "Browser-based attacks hit 95% of enterprises — and traditional security tools never saw them coming",
          "standfirst": "Your web gateway can&#x27;t see it. Your cloud access broker can&#x27;t see it. Your endpoint protection can&#x27;t see it. And yet 95% of organizations experienced browser-based attacks last year, according to Omdia research conducted across more than 1,000 IT and security leaders.Still, three campaigns in 12 months are making the threat more concrete. ShadyPanda infected 4.3 million users through extensions that had been legitimate for seven years. Cyberhaven&#x27;s security extension was weaponized against 400,000 corporate customers on Christmas Eve. Trust Wallet lost $8.5 million from 2,520 wallets in 48 hours. None triggered traditional alerts.The pattern is consistent: Attackers aren’t exploiting zero-days or bypassing perimeter defenses. They’re operating inside trusted browser sessions — where traditional security tools lose visibility after login.\"Let&#x27;s be honest, people are using a browser the majority of their day anyway,\" said Sam Evans, CISO of Clearwater Analytics. \"Having the major security component in the browser has made our lives very simple.\" That convenience is exactly what makes the browser the highest-risk execution environment enterprises still treat as infrastructure, not attack surface.VentureBeat recently spoke with Elia Zaitsev, CTO of CrowdStrike, about what&#x27;s driving these attacks. \"The browser has become a prime target because modern adversaries don&#x27;t break in, they log in,\" he said. He added that as work, communication, and AI usage move into the browser, attackers increasingly operate inside trusted sessions, abusing valid identities, tokens, and access. Traditional security controls were never designed to stop this kind of activity because they assume \"trust-once\" access is granted and lack visibility into what happens inside live browser sessions.What traditional security architectures missTraditional enterprise security stacks were built to inspect traffic before authentication, not behavior after access is granted. Interviews with CISOs already running browser-layer controls reveal six operational patterns that consistently reduce exposure — assuming identity and endpoint foundations are in place.The Omdia research quantifies the gap: 64% of encrypted traffic goes uninspected, and 65% of organizations lack control over data shared in AI tools, according to the study. LayerX&#x27;s Enterprise Browser Extension Security Report 2025 found that 99% of enterprise users have at least one browser extension, 53% with high or critical permissions granting access to cookies, passwords, and page content. Another 17% come from non-official stores, and 26% were sideloaded without IT knowing.\"Traditional endpoint detection products were using some machine learning, and they would get to a probability of maybe 85%,\" Evans told VentureBeat. \"This could be a threat, but we&#x27;re not really sure. How do we take action? Should I pull the fire alarm?\"\"At the end of the day, it&#x27;s the device the person uses day in and day out that carries the highest risk,\" he said.\"For a long time, the browser was treated as a window, not an execution layer,\" Zaitsev said. \"It was designed for searches and static web access, not for running core business applications or autonomous AI workflows. That&#x27;s changed dramatically. Today, SaaS applications, cloud identities, AI tools, and agentic workflows all run through the browser, making it the first line of enterprise execution and defense.\"Browser isolation from Menlo Security, Cloudflare, and Symantec addresses rendering threats by executing web content in remote containers. But thousands of extensions now run locally with privileged access, GenAI tools create new exfiltration paths, and session-based attacks hijack authenticated tokens. Isolation protects users before authentication — not after attackers inherit valid sessions, tokens, and extension privileges.Three attack patterns worth understandingTrust can be accumulated over years — then weaponized overnight.The long game. ShadyPanda submitted clean extensions to Chrome and Edge stores in 2018, accumulated Google&#x27;s \"Featured\" and \"Verified\" badges, then weaponized them seven years later. Clean Master became a remote code execution backdoor running hourly JavaScript downloads — not malware with a fixed function, but a backdoor letting attackers decide what comes next.The credential hijack. Browser auto-updates function as a software supply chain — and inherit its risks. Cyberhaven attackers phished one developer&#x27;s credentials in 2024. The Chrome Web Store approved the malicious upload. Within 48 hours, 400,000 corporate customers had auto-updated to compromised code.The API key leak. Control planes are attack surfaces, not internal safeguards. Trust Wallet attackers used a leaked Chrome Web Store API key to push malicious updates, bypassing all internal release controls. Around $8.5 million had been drained from wallets by attackers within a couple days. No phishing required. No zero-days. Just the auto-update mechanism doing what it was designed to do.Why detection fails when attackers have valid credentials\"Nation-state actors typically exploit browser access for long-term, covert intelligence collection, while financially motivated e-crime groups prioritize speed, using browser-based attacks to harvest credentials, session tokens, and sensitive data for rapid monetization or resale,\" Zaitsev said. \"Despite different objectives, both rely on the same browser-layer blind spot to operate inside trusted sessions and bypass traditional detection.\"Session hijacking illustrates why this matters. The most important signals are behavioral and contextual, not credentials themselves. That includes how a user interacts with the browser in real-time, whether actions align with expected behavior, how data is being accessed or moved, and whether the session context suddenly changes in ways that indicate abuse.Once attackers capture a valid token, they replay it from anywhere. Authentication already happened, and MFA already passed. Zaitsev argues that detecting session hijacking early requires correlating in-session browser behavior with identity posture, endpoint signals, and threat intelligence. When those signals are unified, distinguishing a legitimate user from a hijacker becomes possible. That&#x27;s something siloed enterprise browsers and legacy security tools can&#x27;t see.When productivity tools become exfiltration pathsGenAI traffic surged 890% in 2024, with organizations now averaging 66 GenAI applications, according to Palo Alto Networks&#x27; State of Generative AI 2025 report. GenAI-related data loss incidents more than doubled, accounting for 14% of all data security incidents.Evans remembers the board conversation that started it all. \"In October 2023, they asked, &#x27;What are your thoughts on ChatGPT?&#x27; I said it&#x27;s an incredible productivity tool, however, I don&#x27;t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it or our source code.\"Legitimate GenAI use and data exfiltration look identical at the network level. Both are encrypted browser sessions sending data to approved SaaS endpoints, often involving copy-and-paste into browser-based tools. The distinction only becomes clear at the browser layer, where you can see what data is being pasted, whether the destination is approved, and whether the behavior matches normal work patterns.Evans found a balance. \"If somebody goes to chatgpt.com, we allow them to use it. They just can&#x27;t copy and paste anything into it. They can&#x27;t upload any files, but they can ask questions and compare answers with our corporate version.\" Employees get AI for research without risking customer data in model training.\"It seems like there&#x27;s a new one every five minutes,\" Evans said. \"Browser-layer controls maintain those categories, so if a new tool shows up, we can feel pretty good that employees won&#x27;t be able to copy and paste or upload our data.\"The billion-dollar browser betCrowdStrike acquired Seraphic Security and SGNL for a combined $1.16 billion in January 2026, signaling how seriously vendors are betting on the browser layer. Palo Alto Networks bought Talon in 2023. Two camps are emerging. Island wants enterprises to replace Chrome and Edge entirely with a purpose-built browser, and has reached a $4.8 billion valuation (March, 2025). Menlo Security bets most enterprises won&#x27;t switch browsers, so it layers protection on top of whatever employees already use. The tradeoff is real. Replacement browsers offer deeper control but require adoption. Security layers preserve user choice but see less. Both are winning deals.Zaitsev says neither approach works without tying browser activity to identity. Authentication tells you who logged in. It doesn&#x27;t tell you if that session gets hijacked 10 minutes later, or if the user starts exfiltrating data to an unauthorized GenAI tool. Catching that requires correlating browser behavior with endpoint and identity signals in real time — something most enterprises can&#x27;t do yet.For buyers, the decision isn’t about vendors — it’s about whether browser activity is tied into identity, endpoint, and SOC workflows, or left as a standalone control plane.Six patterns from productionSecuring the browser that employees actually use matters more than which enterprise browser to deploy. Today&#x27;s workforce moves across multiple browsers and managed and unmanaged devices. What matters is visibility and control inside live sessions without breaking how people work.Evans put it more simply: \"I wanted security closer to the end user, on the device they use every day. Having security in the browser made our lives simple. Road warriors dealing with hotel captive portals that normally get blocked by edge products? We don&#x27;t worry about that anymore.\"Based on interviews with CISOs running browser-layer controls in production, six patterns keep showing up. One caveat: These assume you already have mature identity and endpoint infrastructure. If you don&#x27;t, start there.Build a complete extension inventory. Use browser management APIs to enumerate every extension, flag anything requesting sensitive permissions, and cross-reference against known-malicious hashes.Break the auto-update kill chain. Fast patching reduces exposure to known vulnerabilities but creates supply chain risk. Implement version pinning with 48- to 72-hour delays. The Cyberhaven attack was detected in roughly 25 hours. A staged rollout would have contained it.Move data protection to where data moves. \"DLP is where we got the biggest win,\" Evans said. \"Customer data exfiltration can happen through social media, personal file shares, and web-based email. Being able to block copy-paste into certain site categories, block file uploads was incredibly powerful.\"Eliminate browser sprawl. \"It does no good to deploy an enterprise browser when someone can download Opera, or Frank&#x27;s browser of the month, and bypass all the controls,\" Evans said. Every unmanaged browser is a policy-free zone.Extend identity into sessions, treat GenAI as unvetted, feed signals to the SOC. Session hijackers inherit valid credentials but not normal behavior patterns. Watch for impossible travel, permission escalation, and bulk access anomalies. Evans found that browser-layer blocking surfaced shadow AI tools employees actually wanted, which IT could then enable properly. And browser telemetry should flow into existing SOC workflows. \"The AI does initial triage,\" Evans said, \"telling analysts where to look based on what we&#x27;ve seen before.\"Show the board a working demo. \"I didn&#x27;t just come with concerns,\" Evans said. \"I came with a solution. When I explained how enterprise browsers work, the board said, &#x27;Can you really do it?&#x27; At our July 2024 audit committee, they asked how it was going. I said, &#x27;Let me show you.&#x27; Pulled up a screenshot — here I am on ChatGPT, tried to paste something, got: &#x27;Policy prevents this.&#x27; They said, &#x27;Wow.&#x27; That calmed their nerves.\"The bottom lineThe browser security gap is real. The fix isn&#x27;t necessarily a new platform purchase. Start by assessing what you have: inventory extensions, delay auto-updates, and enforce data policies at the browser layer with existing tools.\"No security tool is 100% perfect,\" Evans said. \"But with browser-layer controls deployed, we sleep a lot easier.\"Breach rates won’t improve by stacking more perimeter tools onto architectures that assume trust ends at login. Outcomes improve when you treat the browser as what it&#x27;s become: the primary execution environment for enterprise work.",
          "content": "Your web gateway can&#x27;t see it. Your cloud access broker can&#x27;t see it. Your endpoint protection can&#x27;t see it. And yet 95% of organizations experienced browser-based attacks last year, according to Omdia research conducted across more than 1,000 IT and security leaders.Still, three campaigns in 12 months are making the threat more concrete. ShadyPanda infected 4.3 million users through extensions that had been legitimate for seven years. Cyberhaven&#x27;s security extension was weaponized against 400,000 corporate customers on Christmas Eve. Trust Wallet lost $8.5 million from 2,520 wallets in 48 hours. None triggered traditional alerts.The pattern is consistent: Attackers aren’t exploiting zero-days or bypassing perimeter defenses. They’re operating inside trusted browser sessions — where traditional security tools lose visibility after login.\"Let&#x27;s be honest, people are using a browser the majority of their day anyway,\" said Sam Evans, CISO of Clearwater Analytics. \"Having the major security component in the browser has made our lives very simple.\" That convenience is exactly what makes the browser the highest-risk execution environment enterprises still treat as infrastructure, not attack surface.VentureBeat recently spoke with Elia Zaitsev, CTO of CrowdStrike, about what&#x27;s driving these attacks. \"The browser has become a prime target because modern adversaries don&#x27;t break in, they log in,\" he said. He added that as work, communication, and AI usage move into the browser, attackers increasingly operate inside trusted sessions, abusing valid identities, tokens, and access. Traditional security controls were never designed to stop this kind of activity because they assume \"trust-once\" access is granted and lack visibility into what happens inside live browser sessions.What traditional security architectures missTraditional enterprise security stacks were built to inspect traffic before authentication, not behavior after access is granted. Interviews with CISOs already running browser-layer controls reveal six operational patterns that consistently reduce exposure — assuming identity and endpoint foundations are in place.The Omdia research quantifies the gap: 64% of encrypted traffic goes uninspected, and 65% of organizations lack control over data shared in AI tools, according to the study. LayerX&#x27;s Enterprise Browser Extension Security Report 2025 found that 99% of enterprise users have at least one browser extension, 53% with high or critical permissions granting access to cookies, passwords, and page content. Another 17% come from non-official stores, and 26% were sideloaded without IT knowing.\"Traditional endpoint detection products were using some machine learning, and they would get to a probability of maybe 85%,\" Evans told VentureBeat. \"This could be a threat, but we&#x27;re not really sure. How do we take action? Should I pull the fire alarm?\"\"At the end of the day, it&#x27;s the device the person uses day in and day out that carries the highest risk,\" he said.\"For a long time, the browser was treated as a window, not an execution layer,\" Zaitsev said. \"It was designed for searches and static web access, not for running core business applications or autonomous AI workflows. That&#x27;s changed dramatically. Today, SaaS applications, cloud identities, AI tools, and agentic workflows all run through the browser, making it the first line of enterprise execution and defense.\"Browser isolation from Menlo Security, Cloudflare, and Symantec addresses rendering threats by executing web content in remote containers. But thousands of extensions now run locally with privileged access, GenAI tools create new exfiltration paths, and session-based attacks hijack authenticated tokens. Isolation protects users before authentication — not after attackers inherit valid sessions, tokens, and extension privileges.Three attack patterns worth understandingTrust can be accumulated over years — then weaponized overnight.The long game. ShadyPanda submitted clean extensions to Chrome and Edge stores in 2018, accumulated Google&#x27;s \"Featured\" and \"Verified\" badges, then weaponized them seven years later. Clean Master became a remote code execution backdoor running hourly JavaScript downloads — not malware with a fixed function, but a backdoor letting attackers decide what comes next.The credential hijack. Browser auto-updates function as a software supply chain — and inherit its risks. Cyberhaven attackers phished one developer&#x27;s credentials in 2024. The Chrome Web Store approved the malicious upload. Within 48 hours, 400,000 corporate customers had auto-updated to compromised code.The API key leak. Control planes are attack surfaces, not internal safeguards. Trust Wallet attackers used a leaked Chrome Web Store API key to push malicious updates, bypassing all internal release controls. Around $8.5 million had been drained from wallets by attackers within a couple days. No phishing required. No zero-days. Just the auto-update mechanism doing what it was designed to do.Why detection fails when attackers have valid credentials\"Nation-state actors typically exploit browser access for long-term, covert intelligence collection, while financially motivated e-crime groups prioritize speed, using browser-based attacks to harvest credentials, session tokens, and sensitive data for rapid monetization or resale,\" Zaitsev said. \"Despite different objectives, both rely on the same browser-layer blind spot to operate inside trusted sessions and bypass traditional detection.\"Session hijacking illustrates why this matters. The most important signals are behavioral and contextual, not credentials themselves. That includes how a user interacts with the browser in real-time, whether actions align with expected behavior, how data is being accessed or moved, and whether the session context suddenly changes in ways that indicate abuse.Once attackers capture a valid token, they replay it from anywhere. Authentication already happened, and MFA already passed. Zaitsev argues that detecting session hijacking early requires correlating in-session browser behavior with identity posture, endpoint signals, and threat intelligence. When those signals are unified, distinguishing a legitimate user from a hijacker becomes possible. That&#x27;s something siloed enterprise browsers and legacy security tools can&#x27;t see.When productivity tools become exfiltration pathsGenAI traffic surged 890% in 2024, with organizations now averaging 66 GenAI applications, according to Palo Alto Networks&#x27; State of Generative AI 2025 report. GenAI-related data loss incidents more than doubled, accounting for 14% of all data security incidents.Evans remembers the board conversation that started it all. \"In October 2023, they asked, &#x27;What are your thoughts on ChatGPT?&#x27; I said it&#x27;s an incredible productivity tool, however, I don&#x27;t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it or our source code.\"Legitimate GenAI use and data exfiltration look identical at the network level. Both are encrypted browser sessions sending data to approved SaaS endpoints, often involving copy-and-paste into browser-based tools. The distinction only becomes clear at the browser layer, where you can see what data is being pasted, whether the destination is approved, and whether the behavior matches normal work patterns.Evans found a balance. \"If somebody goes to chatgpt.com, we allow them to use it. They just can&#x27;t copy and paste anything into it. They can&#x27;t upload any files, but they can ask questions and compare answers with our corporate version.\" Employees get AI for research without risking customer data in model training.\"It seems like there&#x27;s a new one every five minutes,\" Evans said. \"Browser-layer controls maintain those categories, so if a new tool shows up, we can feel pretty good that employees won&#x27;t be able to copy and paste or upload our data.\"The billion-dollar browser betCrowdStrike acquired Seraphic Security and SGNL for a combined $1.16 billion in January 2026, signaling how seriously vendors are betting on the browser layer. Palo Alto Networks bought Talon in 2023. Two camps are emerging. Island wants enterprises to replace Chrome and Edge entirely with a purpose-built browser, and has reached a $4.8 billion valuation (March, 2025). Menlo Security bets most enterprises won&#x27;t switch browsers, so it layers protection on top of whatever employees already use. The tradeoff is real. Replacement browsers offer deeper control but require adoption. Security layers preserve user choice but see less. Both are winning deals.Zaitsev says neither approach works without tying browser activity to identity. Authentication tells you who logged in. It doesn&#x27;t tell you if that session gets hijacked 10 minutes later, or if the user starts exfiltrating data to an unauthorized GenAI tool. Catching that requires correlating browser behavior with endpoint and identity signals in real time — something most enterprises can&#x27;t do yet.For buyers, the decision isn’t about vendors — it’s about whether browser activity is tied into identity, endpoint, and SOC workflows, or left as a standalone control plane.Six patterns from productionSecuring the browser that employees actually use matters more than which enterprise browser to deploy. Today&#x27;s workforce moves across multiple browsers and managed and unmanaged devices. What matters is visibility and control inside live sessions without breaking how people work.Evans put it more simply: \"I wanted security closer to the end user, on the device they use every day. Having security in the browser made our lives simple. Road warriors dealing with hotel captive portals that normally get blocked by edge products? We don&#x27;t worry about that anymore.\"Based on interviews with CISOs running browser-layer controls in production, six patterns keep showing up. One caveat: These assume you already have mature identity and endpoint infrastructure. If you don&#x27;t, start there.Build a complete extension inventory. Use browser management APIs to enumerate every extension, flag anything requesting sensitive permissions, and cross-reference against known-malicious hashes.Break the auto-update kill chain. Fast patching reduces exposure to known vulnerabilities but creates supply chain risk. Implement version pinning with 48- to 72-hour delays. The Cyberhaven attack was detected in roughly 25 hours. A staged rollout would have contained it.Move data protection to where data moves. \"DLP is where we got the biggest win,\" Evans said. \"Customer data exfiltration can happen through social media, personal file shares, and web-based email. Being able to block copy-paste into certain site categories, block file uploads was incredibly powerful.\"Eliminate browser sprawl. \"It does no good to deploy an enterprise browser when someone can download Opera, or Frank&#x27;s browser of the month, and bypass all the controls,\" Evans said. Every unmanaged browser is a policy-free zone.Extend identity into sessions, treat GenAI as unvetted, feed signals to the SOC. Session hijackers inherit valid credentials but not normal behavior patterns. Watch for impossible travel, permission escalation, and bulk access anomalies. Evans found that browser-layer blocking surfaced shadow AI tools employees actually wanted, which IT could then enable properly. And browser telemetry should flow into existing SOC workflows. \"The AI does initial triage,\" Evans said, \"telling analysts where to look based on what we&#x27;ve seen before.\"Show the board a working demo. \"I didn&#x27;t just come with concerns,\" Evans said. \"I came with a solution. When I explained how enterprise browsers work, the board said, &#x27;Can you really do it?&#x27; At our July 2024 audit committee, they asked how it was going. I said, &#x27;Let me show you.&#x27; Pulled up a screenshot — here I am on ChatGPT, tried to paste something, got: &#x27;Policy prevents this.&#x27; They said, &#x27;Wow.&#x27; That calmed their nerves.\"The bottom lineThe browser security gap is real. The fix isn&#x27;t necessarily a new platform purchase. Start by assessing what you have: inventory extensions, delay auto-updates, and enforce data policies at the browser layer with existing tools.\"No security tool is 100% perfect,\" Evans said. \"But with browser-layer controls deployed, we sleep a lot easier.\"Breach rates won’t improve by stacking more perimeter tools onto architectures that assume trust ends at login. Outcomes improve when you treat the browser as what it&#x27;s become: the primary execution environment for enterprise work.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5L4OH5idEk7QcVSOUFllsM/8d834f158372e78f94c6f12fca684d7f/hero_image_95-_of_Enterprises_Got_Breached_Through_Their_Browsers_And_Their_Security_Stacks_Never_Saw_It_2.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/resident-evil-requiem-preview-150000849.html",
          "published_at": "Mon, 26 Jan 2026 15:00:00 +0000",
          "title": "Resident Evil Requiem gives series fans the best of both action and survival horror",
          "standfirst": "The ninth mainline Resident Evil is trying to split the difference between the series’ action-heavy entries and the stress-inducing hide-and-seek episodes. During a four-hour playthrough of some early parts of Resident Evil Requiem, I spent time with both of the two main characters, Grace and series mainstay Leon. They offer distinctly different playstyles, talents, strengths, and weaknesses. While it isn't an entirely new premise for the survival horror series (in the original, playing as Chris Redfield offered more challenge than playing as Jill Valentine) it’s never been this pronounced. I started playing as Leon, entering a medical facility he seemed to have been invited to. With a cavernous main hall, it feels like yet another iconic Resident Evil hub, immediately reminding me of Raccoon City's Police Precinct and even the original's cavernous manor. Wings to explore? Check. Suspiciously quiet and empty central area that will almost definitely get overrun by zombies at some point? Probably.Both Grace and Leon’s parts can be played in either third- or first-person perspective, though Leon’s segments seem better suited to the third-person view, since there's just a lot more shooting. Grace's segments were tense and demanded my full attention, more akin to Resident Evil 7. During this early part of the game, there is a lot of hiding, plenty of ammo conservation and a lot more learning from dumb mistakes. The parts of the game I played with Leon reminded me more of Resident Evil 4 (or 5 or 6 – but let’s gloss over those).Once you take control of him, Leon is immediately attacked and has to fend off roughly 15 infected doctors, nurses and patients. It’s a significant tone shift from Grace skulking around the facility, hiding behind plants and sometimes just hoping for the best. Leon faces off against a chainsaw-wielding doctor zombie. Best cut that arm off.CapcomLeon, fortunately, arrives with several weapons, including a new melee option, a hatchet. Using this, he can make targeted attacks to lop off limbs and aim at the head to deliver more damage. At least on these basic zombies, I found relentless slashing more effective than more targeted efforts – I’m sure future enemies will demand more… nuanced approaches. A later enemy must be decapitated to kill it. After a set number of swings, you will need to retreat and sharpen the blade, which adds to the jeopardy while not disrupting the chaos. The hatchet can even be used to parry attacks – if you get the timing down. Leon even gets to wield a chainsaw during this initial encounter, but only after claiming it from one particularly industrious zombie that seemed to find it inside a hospital. It was crucial to both disarm this zombie and grab the chainsaw before another corpse could take a turn on it. However, just because the chainsaw gets dropped doesn’t mean it’s turned off. I suffered significant damage when I repeatedly rushed into the spinning power tool. The zombies in Requiem are also a little more nuanced compared to previous games – if a zombie can have nuance. While nearly all of the zombies will attack you on sight, they can be distracted or delayed based on the person they were before they turned. For example, the chef zombie (a hardy, bigger zombie than the ones you’ve come across until that point) will only chase you around his kitchen. Step out into the corridor and he’ll leave you alone. Elsewhere, a zombie (attached to an IV, cute) has his eyes bandaged and will react aggressively to any noise. I used this to my advantage, hurling an empty bottle at another zombie who stood nearby. The IV zombie killed him immediately. Another time, a senior exec who’s been turned is firing an employee of his… by killing them, moaning “You’re fired” as he does so. This little vignette gave me enough time to dim the lights and hide when he left his office. In Requiem, players are expected to exploit individual zombie behaviors to outmaneuver them. It’s also a welcome dose of humor to the survival horror series, reminding me a little of the camp moments in Dead Rising, another zombie-centric Capcom series. Leon doesn’t have to strategize quite as much, arriving with a particularly powerful handgun, the Requiem, that he eventually passes over to Grace. This is capable of stopping pretty much (but not all) enemies you come across, although it initially comes with only a single bullet, so you really have to make it count. During a set-piece battle against a towering, swollen former patient, I got to test Requiem’s action-horror controls under pressure. Leon finds a shotgun and has to flank (and outrun) his “hungry” attacker. The environment in the rafters of the building is designed so it’s easy to figure out where you need to go and how to stop the giant zombie from cornering you. Ammo, at least during this fight, was scattered around, which was a relief after struggling to find bullets during Grace’s segment.Despite the lack of traditional weapons, Grace eventually finds a blood injector (and its companion blood analysis system). These turn into Requiem’s crafting system. Powered by literal buckets and puddles of blood (you have to draw up infected blood from certain parts of the environment and enemies), samples can be combined with scraps, herbs and more to create high-powered first-aid shots, injectable explosive blood, ammunition and a lot of other things. Analysing different blood types (and solving some light puzzles) adds further crafting options. Oh he's not going to help you.CapcomDuring the preview, the infected blood injector was exclusively for Grace’s use. It’ll be intriguing if only one character gets to benefit from the crafting system, although Capcom teased customizable weapons for Leon, which might better suit his playstyle. Grace might also be handicapped by the typewriter save system popularized in the first few RE games. This could mean you’ll only be able to save if you have an ink ribbon on you, a very stressful part of inventory management early on in the series — she really can’t catch a break. However, it appears to be adjustable in difficulty settings. According to Capcom’s Resident Evil showcase last week, infected blood will apparently play a strong role in Requiem, touching on both Leon’s past (he’s apparently suffering from a mystery ailment) and the circumstances surrounding the death of Grace's mother. And it wouldn’t be a Resident Evil game with mystery, buckets of blood, and a pulpy villain. Capcom has primed another fascinating villain with Requiem’s Dr. Gideon, a former Umbrella virologist who was seemingly written for an actor to go full camp baddie – if the doctor’s hooded snakeskin trenchcoat wasn’t a giveaway. Resident Evil Requiem will be released on February 27, 2026 for PC, PS5 and Xbox Series X|S.This article originally appeared on Engadget at https://www.engadget.com/gaming/resident-evil-requiem-preview-150000849.html?src=rss",
          "content": "The ninth mainline Resident Evil is trying to split the difference between the series’ action-heavy entries and the stress-inducing hide-and-seek episodes. During a four-hour playthrough of some early parts of Resident Evil Requiem, I spent time with both of the two main characters, Grace and series mainstay Leon. They offer distinctly different playstyles, talents, strengths, and weaknesses. While it isn't an entirely new premise for the survival horror series (in the original, playing as Chris Redfield offered more challenge than playing as Jill Valentine) it’s never been this pronounced. I started playing as Leon, entering a medical facility he seemed to have been invited to. With a cavernous main hall, it feels like yet another iconic Resident Evil hub, immediately reminding me of Raccoon City's Police Precinct and even the original's cavernous manor. Wings to explore? Check. Suspiciously quiet and empty central area that will almost definitely get overrun by zombies at some point? Probably.Both Grace and Leon’s parts can be played in either third- or first-person perspective, though Leon’s segments seem better suited to the third-person view, since there's just a lot more shooting. Grace's segments were tense and demanded my full attention, more akin to Resident Evil 7. During this early part of the game, there is a lot of hiding, plenty of ammo conservation and a lot more learning from dumb mistakes. The parts of the game I played with Leon reminded me more of Resident Evil 4 (or 5 or 6 – but let’s gloss over those).Once you take control of him, Leon is immediately attacked and has to fend off roughly 15 infected doctors, nurses and patients. It’s a significant tone shift from Grace skulking around the facility, hiding behind plants and sometimes just hoping for the best. Leon faces off against a chainsaw-wielding doctor zombie. Best cut that arm off.CapcomLeon, fortunately, arrives with several weapons, including a new melee option, a hatchet. Using this, he can make targeted attacks to lop off limbs and aim at the head to deliver more damage. At least on these basic zombies, I found relentless slashing more effective than more targeted efforts – I’m sure future enemies will demand more… nuanced approaches. A later enemy must be decapitated to kill it. After a set number of swings, you will need to retreat and sharpen the blade, which adds to the jeopardy while not disrupting the chaos. The hatchet can even be used to parry attacks – if you get the timing down. Leon even gets to wield a chainsaw during this initial encounter, but only after claiming it from one particularly industrious zombie that seemed to find it inside a hospital. It was crucial to both disarm this zombie and grab the chainsaw before another corpse could take a turn on it. However, just because the chainsaw gets dropped doesn’t mean it’s turned off. I suffered significant damage when I repeatedly rushed into the spinning power tool. The zombies in Requiem are also a little more nuanced compared to previous games – if a zombie can have nuance. While nearly all of the zombies will attack you on sight, they can be distracted or delayed based on the person they were before they turned. For example, the chef zombie (a hardy, bigger zombie than the ones you’ve come across until that point) will only chase you around his kitchen. Step out into the corridor and he’ll leave you alone. Elsewhere, a zombie (attached to an IV, cute) has his eyes bandaged and will react aggressively to any noise. I used this to my advantage, hurling an empty bottle at another zombie who stood nearby. The IV zombie killed him immediately. Another time, a senior exec who’s been turned is firing an employee of his… by killing them, moaning “You’re fired” as he does so. This little vignette gave me enough time to dim the lights and hide when he left his office. In Requiem, players are expected to exploit individual zombie behaviors to outmaneuver them. It’s also a welcome dose of humor to the survival horror series, reminding me a little of the camp moments in Dead Rising, another zombie-centric Capcom series. Leon doesn’t have to strategize quite as much, arriving with a particularly powerful handgun, the Requiem, that he eventually passes over to Grace. This is capable of stopping pretty much (but not all) enemies you come across, although it initially comes with only a single bullet, so you really have to make it count. During a set-piece battle against a towering, swollen former patient, I got to test Requiem’s action-horror controls under pressure. Leon finds a shotgun and has to flank (and outrun) his “hungry” attacker. The environment in the rafters of the building is designed so it’s easy to figure out where you need to go and how to stop the giant zombie from cornering you. Ammo, at least during this fight, was scattered around, which was a relief after struggling to find bullets during Grace’s segment.Despite the lack of traditional weapons, Grace eventually finds a blood injector (and its companion blood analysis system). These turn into Requiem’s crafting system. Powered by literal buckets and puddles of blood (you have to draw up infected blood from certain parts of the environment and enemies), samples can be combined with scraps, herbs and more to create high-powered first-aid shots, injectable explosive blood, ammunition and a lot of other things. Analysing different blood types (and solving some light puzzles) adds further crafting options. Oh he's not going to help you.CapcomDuring the preview, the infected blood injector was exclusively for Grace’s use. It’ll be intriguing if only one character gets to benefit from the crafting system, although Capcom teased customizable weapons for Leon, which might better suit his playstyle. Grace might also be handicapped by the typewriter save system popularized in the first few RE games. This could mean you’ll only be able to save if you have an ink ribbon on you, a very stressful part of inventory management early on in the series — she really can’t catch a break. However, it appears to be adjustable in difficulty settings. According to Capcom’s Resident Evil showcase last week, infected blood will apparently play a strong role in Requiem, touching on both Leon’s past (he’s apparently suffering from a mystery ailment) and the circumstances surrounding the death of Grace's mother. And it wouldn’t be a Resident Evil game with mystery, buckets of blood, and a pulpy villain. Capcom has primed another fascinating villain with Requiem’s Dr. Gideon, a former Umbrella virologist who was seemingly written for an actor to go full camp baddie – if the doctor’s hooded snakeskin trenchcoat wasn’t a giveaway. Resident Evil Requiem will be released on February 27, 2026 for PC, PS5 and Xbox Series X|S.This article originally appeared on Engadget at https://www.engadget.com/gaming/resident-evil-requiem-preview-150000849.html?src=rss",
          "feed_position": 14,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/requiem1_2.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/asana-launches-claude-integration-says-ai-models-are-context-starved-without",
          "published_at": "Mon, 26 Jan 2026 09:00:00 GMT",
          "title": "Asana launches Claude integration, says AI models are 'context-starved' without enterprise data",
          "standfirst": "When Anthropic announced Monday that it was embedding nine workplace applications directly inside Claude, transforming its AI chatbot into what I earlier described as a \"workplace command center,\" Asana was among the headliners.But while the broader launch signals a new era of AI-native productivity tools, Asana&#x27;s participation reflects a deeper strategic bet — one that positions the project management company not as an AI competitor, but as the essential context layer that makes any AI model more useful.In an exclusive interview with VentureBeat, Arnab Bose, Asana&#x27;s Chief Product Officer, explained the thinking behind the partnership and why the company chose to embrace external AI providers rather than build proprietary models.\"The AI landscape is advancing at a breakneck pace,\" Bose said. \"We believe our customers are best served when they have access to the latest, most powerful reasoning capabilities from best-in-class providers like Anthropic, rather than being locked into a single, proprietary model that may fall behind quickly.\"The integration arrives at a pivotal moment for Asana: the company is navigating a leadership transition after co-founder Dustin Moskovitz&#x27;s retirement, competing against rivals racing to embed AI into productivity software, and betting that its proprietary \"Work Graph\" — the company&#x27;s mapping of how tasks, people, and goals connect inside organizations — can differentiate it in an increasingly crowded market.Asana&#x27;s chief product officer argues that raw AI power matters less than business contextThe strategic logic Bose outlined goes beyond simply offering Claude users another tool to connect. At its core, Asana is making a bet about where value will accrue in the AI era — and the company believes context will matter more than raw model capability.\"An LLM in isolation is context-starved,\" Bose told VentureBeat. \"It knows how to write, but it doesn&#x27;t know your business—your goals, your knowledge, your specific approvals, or your historical relationships. Asana provides the scaffolding—the Work Graph data model—that grounds those external models in the reality of how your company actually operates.\"It&#x27;s a framing that positions Asana as essential infrastructure rather than a replaceable application. If Bose is right, then even as AI models from Anthropic, OpenAI, and Google grow more powerful, they will remain fundamentally limited without deep integration into how organizations actually function.\"Most errors happen because models are context-starved,\" Bose said. \"Asana solves this with context that is unique to each business.\"The argument has implications beyond Asana. It suggests a future where AI capability becomes increasingly commoditized, while the companies that control rich organizational data — project histories, approval workflows, team relationships — become the essential partners that make AI useful in enterprise settings.The integration transforms natural language conversations into structured project plansIn practice, the Claude integration allows users to create and manage Asana projects entirely through natural conversation. When a user connects their Asana account via OAuth authentication, Claude gains the ability to read project data, create new tasks, and build entire project structures based on natural language instructions.A marketing team discussing a product launch in Claude can simply say: \"Create a Q2 product launch project with phases for creative development, partner outreach, press kit, and launch day.\" Claude then generates the project structure, complete with sections and tasks, which the user can review before pushing it live to Asana.\"When you use Claude to explore a new initiative, like brainstorming a campaign structure, outlining a project plan, or mapping out a cross-functional launch, you can turn that thinking into real, structured work in Asana without breaking your flow,\" the company said in its press release announcing the integration.The synchronization runs in real time. Changes made through Claude appear immediately in Asana, and status updates from Asana can be pulled into Claude conversations for on-the-fly reporting. Users can ask questions like \"What&#x27;s behind schedule in our marketing campaigns right now?\" and receive answers grounded in their actual project data.Human approval remains mandatory before Claude can create or modify any work in AsanaOne of the key design decisions in the integration is a strict requirement for human oversight. Bose emphasized that Claude cannot act autonomously within Asana — every consequential action requires explicit user approval.\"Our architecture follows a strict human-in-the-loop philosophy where AI actions—from drafting project plans to summarizing risks—has a human in the loop to course correct, check quality, and ultimately give final sign-off when working with AI,\" Bose told VentureBeat. \"Users review and approve before tasks are created and projects are built.\"When asked whether Claude could potentially access projects or tasks that a user wouldn&#x27;t normally have permission to see, Bose was direct: \"No. Users need to authenticate via OAuth with their Asana credentials to use this integration, and Claude respects their permissions and access.\"The approach is an increasingly common pattern in enterprise AI — giving artificial intelligence significant capabilities while maintaining human control over final decisions. It addresses one of the core anxieties around AI in workplace settings: the fear that automated systems will make mistakes that propagate through organizations before anyone notices.When asked about audit capabilities for enterprise administrators, Bose said admins can monitor usage information about Claude in Asana&#x27;s Admin App Management portal, with deeper audit log visibility potentially coming based on customer feedback.Asana is building integrations with ChatGPT and Google Gemini to avoid platform lock-inNotably, Asana is not betting exclusively on Claude. Bose emphasized the company&#x27;s commitment to working with multiple AI providers, positioning Asana as a neutral platform that works with whichever AI systems its customers prefer.\"Our philosophy is to meet users where they want to work,\" Bose said. \"We are building the work platform for today and the future which means being the best front-end for any vendor&#x27;s agents.\"He confirmed that Asana offers \"foundational connectors\" with both ChatGPT and Google Gemini and is working to deepen those integrations. The company is also committed to emerging industry standards for AI agent interoperability, including the Agent-to-Agent protocol and MCP.\"We want to be the best front-end for agents from any vendor,\" Bose said, describing a vision where Asana becomes the coordination layer through which various AI systems — whether from Anthropic, OpenAI, Google, or others — can operate within enterprise workflows.This multi-provider approach differs from companies that have tied themselves exclusively to a single AI partner. It reflects both a pragmatic recognition that the AI landscape remains volatile and a strategic bet that Asana&#x27;s value lies in its data and workflow capabilities rather than any particular AI model.The announcement comes as Asana navigates a major leadership transitionThe Claude integration arrives as Asana navigates significant organizational change. Dustin Moskovitz, the company&#x27;s co-founder and longtime CEO, retired earlier this year after announcing his departure during Asana&#x27;s fourth-quarter earnings report in March. Moskovitz&#x27;s departure triggered immediate market reaction, with Asana&#x27;s stock dropping more than 25 percent in after-hours trading following the announcement.The company subsequently hired Dan Rogers — formerly CEO of software startup LaunchDarkly and previously president of Rubrik and marketing chief at ServiceNow — to take over as chief executive. Rogers started in July, with Moskovitz transitioning to the role of board chairman.In a recent appearance on the Stratechery podcast, Moskovitz reflected candidly on his tenure. \"I don&#x27;t like to manage teams, and it wasn&#x27;t my intention when we started Asana,\" he said. \"I&#x27;d intended to be more of a independent or head of engineering or something again. Then one thing led to another and I was CEO for 13 years and I just found it quite exhausting.\"Moskovitz — who co-founded Facebook alongside Mark Zuckerberg before leaving to start Asana in 2008 — retains approximately 39 percent of outstanding Asana shares. He said he plans to focus more on his philanthropic endeavors, including Good Ventures and Open Philanthropy, which lists \"potential risks from advanced AI\" among its focus areas.Bose envisions AI handling orchestration while humans retain control over strategic decisionsWhen asked about the long-term trajectory of AI in Asana, Bose outlined a vision that balances automation with human judgment — what he described as a \"self-driving\" organization where humans nonetheless remain at the wheel.\"Our vision is for customers to work however suits them best, alongside AI agents that actually have the context to be helpful and productive,\" he said. \"But the goal is not for agents to make important decisions on their own. That is where humans provide value: having the judgment, relationships, and nuance to make complex decisions.\"He described a future in which AI handles \"orchestration\" — spotting patterns, flagging risks, managing follow-ups — while humans retain authority over strategy and trade-offs. As an example, Bose pointed to Asana&#x27;s AI Teammates feature, which the company introduced in beta last year.\"Asana AI Teammates — built on the Work Graph, so they understand who is doing what, by when, and why — can flag that three teams are behind on dependencies for a launch and draft a mitigation plan,\" Bose said. \"But a human reviews it, adjusts based on business priorities, and makes the call on what happens next.\"The question is whether that boundary will hold as AI capabilities advance. Anthropic and OpenAI are both racing to build more capable \"agentic\" systems that can execute multi-step tasks with less human oversight. If those systems become reliable enough, the human-in-the-loop requirement may shift from necessity to preference — a transition Asana appears to be preparing for, even as it emphasizes human control today.How to access the Asana integration in ClaudeThe Asana integration in Claude is available immediately to all Asana customers who have a paid Claude subscription. Users can connect Asana through Claude&#x27;s app directory or request that their administrator enable the integration for their workspace.The interactive app feature is available on Claude&#x27;s web and desktop applications for Pro, Max, Team, and Enterprise subscribers. Once connected, users can mention Asana in any Claude conversation to start creating projects, assigning tasks, or pulling status updates from their existing work.",
          "content": "When Anthropic announced Monday that it was embedding nine workplace applications directly inside Claude, transforming its AI chatbot into what I earlier described as a \"workplace command center,\" Asana was among the headliners.But while the broader launch signals a new era of AI-native productivity tools, Asana&#x27;s participation reflects a deeper strategic bet — one that positions the project management company not as an AI competitor, but as the essential context layer that makes any AI model more useful.In an exclusive interview with VentureBeat, Arnab Bose, Asana&#x27;s Chief Product Officer, explained the thinking behind the partnership and why the company chose to embrace external AI providers rather than build proprietary models.\"The AI landscape is advancing at a breakneck pace,\" Bose said. \"We believe our customers are best served when they have access to the latest, most powerful reasoning capabilities from best-in-class providers like Anthropic, rather than being locked into a single, proprietary model that may fall behind quickly.\"The integration arrives at a pivotal moment for Asana: the company is navigating a leadership transition after co-founder Dustin Moskovitz&#x27;s retirement, competing against rivals racing to embed AI into productivity software, and betting that its proprietary \"Work Graph\" — the company&#x27;s mapping of how tasks, people, and goals connect inside organizations — can differentiate it in an increasingly crowded market.Asana&#x27;s chief product officer argues that raw AI power matters less than business contextThe strategic logic Bose outlined goes beyond simply offering Claude users another tool to connect. At its core, Asana is making a bet about where value will accrue in the AI era — and the company believes context will matter more than raw model capability.\"An LLM in isolation is context-starved,\" Bose told VentureBeat. \"It knows how to write, but it doesn&#x27;t know your business—your goals, your knowledge, your specific approvals, or your historical relationships. Asana provides the scaffolding—the Work Graph data model—that grounds those external models in the reality of how your company actually operates.\"It&#x27;s a framing that positions Asana as essential infrastructure rather than a replaceable application. If Bose is right, then even as AI models from Anthropic, OpenAI, and Google grow more powerful, they will remain fundamentally limited without deep integration into how organizations actually function.\"Most errors happen because models are context-starved,\" Bose said. \"Asana solves this with context that is unique to each business.\"The argument has implications beyond Asana. It suggests a future where AI capability becomes increasingly commoditized, while the companies that control rich organizational data — project histories, approval workflows, team relationships — become the essential partners that make AI useful in enterprise settings.The integration transforms natural language conversations into structured project plansIn practice, the Claude integration allows users to create and manage Asana projects entirely through natural conversation. When a user connects their Asana account via OAuth authentication, Claude gains the ability to read project data, create new tasks, and build entire project structures based on natural language instructions.A marketing team discussing a product launch in Claude can simply say: \"Create a Q2 product launch project with phases for creative development, partner outreach, press kit, and launch day.\" Claude then generates the project structure, complete with sections and tasks, which the user can review before pushing it live to Asana.\"When you use Claude to explore a new initiative, like brainstorming a campaign structure, outlining a project plan, or mapping out a cross-functional launch, you can turn that thinking into real, structured work in Asana without breaking your flow,\" the company said in its press release announcing the integration.The synchronization runs in real time. Changes made through Claude appear immediately in Asana, and status updates from Asana can be pulled into Claude conversations for on-the-fly reporting. Users can ask questions like \"What&#x27;s behind schedule in our marketing campaigns right now?\" and receive answers grounded in their actual project data.Human approval remains mandatory before Claude can create or modify any work in AsanaOne of the key design decisions in the integration is a strict requirement for human oversight. Bose emphasized that Claude cannot act autonomously within Asana — every consequential action requires explicit user approval.\"Our architecture follows a strict human-in-the-loop philosophy where AI actions—from drafting project plans to summarizing risks—has a human in the loop to course correct, check quality, and ultimately give final sign-off when working with AI,\" Bose told VentureBeat. \"Users review and approve before tasks are created and projects are built.\"When asked whether Claude could potentially access projects or tasks that a user wouldn&#x27;t normally have permission to see, Bose was direct: \"No. Users need to authenticate via OAuth with their Asana credentials to use this integration, and Claude respects their permissions and access.\"The approach is an increasingly common pattern in enterprise AI — giving artificial intelligence significant capabilities while maintaining human control over final decisions. It addresses one of the core anxieties around AI in workplace settings: the fear that automated systems will make mistakes that propagate through organizations before anyone notices.When asked about audit capabilities for enterprise administrators, Bose said admins can monitor usage information about Claude in Asana&#x27;s Admin App Management portal, with deeper audit log visibility potentially coming based on customer feedback.Asana is building integrations with ChatGPT and Google Gemini to avoid platform lock-inNotably, Asana is not betting exclusively on Claude. Bose emphasized the company&#x27;s commitment to working with multiple AI providers, positioning Asana as a neutral platform that works with whichever AI systems its customers prefer.\"Our philosophy is to meet users where they want to work,\" Bose said. \"We are building the work platform for today and the future which means being the best front-end for any vendor&#x27;s agents.\"He confirmed that Asana offers \"foundational connectors\" with both ChatGPT and Google Gemini and is working to deepen those integrations. The company is also committed to emerging industry standards for AI agent interoperability, including the Agent-to-Agent protocol and MCP.\"We want to be the best front-end for agents from any vendor,\" Bose said, describing a vision where Asana becomes the coordination layer through which various AI systems — whether from Anthropic, OpenAI, Google, or others — can operate within enterprise workflows.This multi-provider approach differs from companies that have tied themselves exclusively to a single AI partner. It reflects both a pragmatic recognition that the AI landscape remains volatile and a strategic bet that Asana&#x27;s value lies in its data and workflow capabilities rather than any particular AI model.The announcement comes as Asana navigates a major leadership transitionThe Claude integration arrives as Asana navigates significant organizational change. Dustin Moskovitz, the company&#x27;s co-founder and longtime CEO, retired earlier this year after announcing his departure during Asana&#x27;s fourth-quarter earnings report in March. Moskovitz&#x27;s departure triggered immediate market reaction, with Asana&#x27;s stock dropping more than 25 percent in after-hours trading following the announcement.The company subsequently hired Dan Rogers — formerly CEO of software startup LaunchDarkly and previously president of Rubrik and marketing chief at ServiceNow — to take over as chief executive. Rogers started in July, with Moskovitz transitioning to the role of board chairman.In a recent appearance on the Stratechery podcast, Moskovitz reflected candidly on his tenure. \"I don&#x27;t like to manage teams, and it wasn&#x27;t my intention when we started Asana,\" he said. \"I&#x27;d intended to be more of a independent or head of engineering or something again. Then one thing led to another and I was CEO for 13 years and I just found it quite exhausting.\"Moskovitz — who co-founded Facebook alongside Mark Zuckerberg before leaving to start Asana in 2008 — retains approximately 39 percent of outstanding Asana shares. He said he plans to focus more on his philanthropic endeavors, including Good Ventures and Open Philanthropy, which lists \"potential risks from advanced AI\" among its focus areas.Bose envisions AI handling orchestration while humans retain control over strategic decisionsWhen asked about the long-term trajectory of AI in Asana, Bose outlined a vision that balances automation with human judgment — what he described as a \"self-driving\" organization where humans nonetheless remain at the wheel.\"Our vision is for customers to work however suits them best, alongside AI agents that actually have the context to be helpful and productive,\" he said. \"But the goal is not for agents to make important decisions on their own. That is where humans provide value: having the judgment, relationships, and nuance to make complex decisions.\"He described a future in which AI handles \"orchestration\" — spotting patterns, flagging risks, managing follow-ups — while humans retain authority over strategy and trade-offs. As an example, Bose pointed to Asana&#x27;s AI Teammates feature, which the company introduced in beta last year.\"Asana AI Teammates — built on the Work Graph, so they understand who is doing what, by when, and why — can flag that three teams are behind on dependencies for a launch and draft a mitigation plan,\" Bose said. \"But a human reviews it, adjusts based on business priorities, and makes the call on what happens next.\"The question is whether that boundary will hold as AI capabilities advance. Anthropic and OpenAI are both racing to build more capable \"agentic\" systems that can execute multi-step tasks with less human oversight. If those systems become reliable enough, the human-in-the-loop requirement may shift from necessity to preference — a transition Asana appears to be preparing for, even as it emphasizes human control today.How to access the Asana integration in ClaudeThe Asana integration in Claude is available immediately to all Asana customers who have a paid Claude subscription. Users can connect Asana through Claude&#x27;s app directory or request that their administrator enable the integration for their workspace.The interactive app feature is available on Claude&#x27;s web and desktop applications for Pro, Max, Team, and Enterprise subscribers. Once connected, users can mention Asana in any Claude conversation to start creating projects, assigning tasks, or pulling status updates from their existing work.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3QWm2CYDCePIzDZeHbm7EH/fd8e9abd6ba6d29d62297a20ee7fecd4/nuneybits_Vector_art_of_chat_bubble_becoming_Gantt_chart._08078c57-22e8-4a42-afc6-b3cba7e3608a.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/why-enterprise-ai-pilots-fail-and-how-to-move-to-scaled-execution",
          "published_at": "Mon, 26 Jan 2026 05:00:00 GMT",
          "title": "Why enterprise AI pilots fail — and how to move to scaled execution",
          "standfirst": "Presented by Insight EnterprisesOrganizations today are trapped in proof-of-concept purgatory because yesterday’s models don’t work for today’s AI challenges.Everyone’s racing to prove what AI could do. But the real winners are those who have realized that AI deployment is not a technology project — it is a core operational capability. Success depends on execution, not just far-reaching visions of optimization.At Insight, we’ve seen this cycle before. For more than 35 years, from our roots as a Value-Added Reseller (VAR) to our evolution as the leading Solutions Integrator, we’ve helped clients cut through the hype and make emerging technology actually work.AI is following the same pattern. But this time, the stakes are higher, and the timelines are tighter. The organizations making real progress aren’t chasing pilots. They’re building the muscle to deploy, turning experiments and early momentum into measurable outcomes for the business.What every technology “era” has taught us about AI successMIT research estimates that 95% of enterprise AI initiatives fail to deliver measurable business value. This isn’t a failure of ambition. It’s a failure of deployment.Too often, leaders are stuck in the “what”, obsessing over which model to use or how fast they can automate a single task. They get locked into long, costly discovery phases with traditional consultants that are all about theory and very little action. We know this because we’ve lived it. When Insight first began experimenting with generative AI, our early pilots suffered from the same issues we see in the market: they looked great on slides but failed to scale.We also hit cultural resistance and skills gaps. To overcome this, we had to stop treating AI as a “tool” and start treating it as a “capability.” We started asking questions like, “Where will AI truly change how our people work and how our business performs — and how do we get there now?” OR “Given the AI tech advances, what is the art of the possible? How can we re-imagine our business processes and the work our people do to drive 10x improvement?Now, 93% of our 14,000+ teammates are using generative AI tools in their daily work, saving more than 8,500 hours every week through automation and productivity gains.Building AI that actually delivers valueIf there’s one thing we’ve learned from decades of transformation, it’s that success isn’t born from strategy decks or proofs of concept.It’s earned in the details.As we brought together our AI experts from across our business, we saw that the most successful client engagements shared three common traits, but not the kind that fit neatly into a diagram. They’re about how work gets done:Fees tied to outcomes. The old model of billing for time and material is broken. Commercial models need to put skin in the game. We win when you see measurable business value, not when we complete project. Use tech to accelerate past theory. Instead of manual, multi-month discovery phases, look for partners who can accelerate your journey. We do this by providing our clients with an inventory of high-value use cases on day zero, so our consulting engagement starts with a roadmap to action, not just a listening tour. Look at internal transformation. You cannot successfully deploy for your customers what you haven&#x27;t mastered internally. At Insight, we built our suite of AI offerings by first transforming our own business. Our internal story isn’t just a data point. It’s our proof of concept for cultural and operational change. It’s how we break the old perceptions and prove we understand the human side of deployment. In our 2024 survey of IT leaders, 44% identified skills gaps as a top barrier to transformation, and 74% said they have focused time and budget on building custom AI tools. Yet most still lack the deployment discipline to embed them.That’s the real craft of deployment. It’s not theory, and it’s not hype. It is execution at scale.And over the past few years, we’ve built on those lessons to give organizations a clear roadmap from ideation to ROI. Real success comes from connecting expertise, tools, and a robust delivery engine to get beyond vision and experimentation.The 70% that separates talk from transformationI love this concept from Boston Consulting Group (BCG) called the 10-20-70 rule.10% of success comes from algorithms, 20% from data and technology, and 70% from people, process, and culture.Most companies invest nearly all their energy in the first 30%. But the real advantage (yes, the durable kind) lives in the 70%. That’s where execution happens.At Insight, we’ve built our entire business around that principle. From cloud to AI, our mission hasn’t changed. We turn technology into a capability that clients can scale and continuously improve.Turning AI potential into real-world resultsThe “AI theory” era is ending. This next chapter belongs to the doers. To organizations ready to apply intelligence the same way they operationalized cloud or digital transformation.It requires a delicate balance of innovation and governance, and certainly bold ideas with disciplined execution.In fact, that philosophy is exactly what inspired Prism, our way of helping organizations bring clarity to complexity. Clients can get a full inventory of AI use cases for their entire business on day zero, skipping the months-long discovery phase of traditional consulting and prioritizing opportunities for immediate impact.We know that transformation doesn’t begin with algorithms. It begins with mastery, and it’s the kind we’ve earned through decades of deploying and scaling what’s next.How are you moving from hype to how?Joyce Mullen is President & CEO at Insight Enterprises.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Insight EnterprisesOrganizations today are trapped in proof-of-concept purgatory because yesterday’s models don’t work for today’s AI challenges.Everyone’s racing to prove what AI could do. But the real winners are those who have realized that AI deployment is not a technology project — it is a core operational capability. Success depends on execution, not just far-reaching visions of optimization.At Insight, we’ve seen this cycle before. For more than 35 years, from our roots as a Value-Added Reseller (VAR) to our evolution as the leading Solutions Integrator, we’ve helped clients cut through the hype and make emerging technology actually work.AI is following the same pattern. But this time, the stakes are higher, and the timelines are tighter. The organizations making real progress aren’t chasing pilots. They’re building the muscle to deploy, turning experiments and early momentum into measurable outcomes for the business.What every technology “era” has taught us about AI successMIT research estimates that 95% of enterprise AI initiatives fail to deliver measurable business value. This isn’t a failure of ambition. It’s a failure of deployment.Too often, leaders are stuck in the “what”, obsessing over which model to use or how fast they can automate a single task. They get locked into long, costly discovery phases with traditional consultants that are all about theory and very little action. We know this because we’ve lived it. When Insight first began experimenting with generative AI, our early pilots suffered from the same issues we see in the market: they looked great on slides but failed to scale.We also hit cultural resistance and skills gaps. To overcome this, we had to stop treating AI as a “tool” and start treating it as a “capability.” We started asking questions like, “Where will AI truly change how our people work and how our business performs — and how do we get there now?” OR “Given the AI tech advances, what is the art of the possible? How can we re-imagine our business processes and the work our people do to drive 10x improvement?Now, 93% of our 14,000+ teammates are using generative AI tools in their daily work, saving more than 8,500 hours every week through automation and productivity gains.Building AI that actually delivers valueIf there’s one thing we’ve learned from decades of transformation, it’s that success isn’t born from strategy decks or proofs of concept.It’s earned in the details.As we brought together our AI experts from across our business, we saw that the most successful client engagements shared three common traits, but not the kind that fit neatly into a diagram. They’re about how work gets done:Fees tied to outcomes. The old model of billing for time and material is broken. Commercial models need to put skin in the game. We win when you see measurable business value, not when we complete project. Use tech to accelerate past theory. Instead of manual, multi-month discovery phases, look for partners who can accelerate your journey. We do this by providing our clients with an inventory of high-value use cases on day zero, so our consulting engagement starts with a roadmap to action, not just a listening tour. Look at internal transformation. You cannot successfully deploy for your customers what you haven&#x27;t mastered internally. At Insight, we built our suite of AI offerings by first transforming our own business. Our internal story isn’t just a data point. It’s our proof of concept for cultural and operational change. It’s how we break the old perceptions and prove we understand the human side of deployment. In our 2024 survey of IT leaders, 44% identified skills gaps as a top barrier to transformation, and 74% said they have focused time and budget on building custom AI tools. Yet most still lack the deployment discipline to embed them.That’s the real craft of deployment. It’s not theory, and it’s not hype. It is execution at scale.And over the past few years, we’ve built on those lessons to give organizations a clear roadmap from ideation to ROI. Real success comes from connecting expertise, tools, and a robust delivery engine to get beyond vision and experimentation.The 70% that separates talk from transformationI love this concept from Boston Consulting Group (BCG) called the 10-20-70 rule.10% of success comes from algorithms, 20% from data and technology, and 70% from people, process, and culture.Most companies invest nearly all their energy in the first 30%. But the real advantage (yes, the durable kind) lives in the 70%. That’s where execution happens.At Insight, we’ve built our entire business around that principle. From cloud to AI, our mission hasn’t changed. We turn technology into a capability that clients can scale and continuously improve.Turning AI potential into real-world resultsThe “AI theory” era is ending. This next chapter belongs to the doers. To organizations ready to apply intelligence the same way they operationalized cloud or digital transformation.It requires a delicate balance of innovation and governance, and certainly bold ideas with disciplined execution.In fact, that philosophy is exactly what inspired Prism, our way of helping organizations bring clarity to complexity. Clients can get a full inventory of AI use cases for their entire business on day zero, skipping the months-long discovery phase of traditional consulting and prioritizing opportunities for immediate impact.We know that transformation doesn’t begin with algorithms. It begins with mastery, and it’s the kind we’ve earned through decades of deploying and scaling what’s next.How are you moving from hype to how?Joyce Mullen is President & CEO at Insight Enterprises.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/63J74zmVaeVdS6W23KAGlJ/24f615ce998516ae141e83d2f2eec38b/AdobeStock_598539417.jpeg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/outside-parties-is-the-creepiest-playdate-game-yet-and-im-kind-of-obsessed-213142541.html",
          "published_at": "Sun, 25 Jan 2026 21:31:42 +0000",
          "title": "Outside Parties is the creepiest Playdate game yet, and I'm kind of obsessed",
          "standfirst": "Never underestimate the chilling powers of grainy grayscale imagery and ethereal whooshing sounds. Outside Parties asks, \"What if I Spy, but in an alien hell dimension?\", and it is impressively unnerving despite the fact that nothing's really happening at any given time. It goes all in on atmosphere, to great effect. This is the Playdate horror game that I've been waiting for. Adams Immersive's Outside Parties is a sort of scavenger hunt across a massive image of a realm called the Outside, which can only be visited by astral travel, according to the lore. There are lots of unknowns about what or where it really is, though explorers have mapped it fairly extensively through out-of-body excursions and they've encountered thousands of different entities there, including the spirits of the dead. As the player, you have come across a Hellscryer K5 — the communication device, psychic camera and recorder used for these trips — and now you're combing through the mission logs, getting sucked into the mystery of it all. Think of the K5 as your Playdate, except powered by blood and runes. At the center of Outside Parties is a 1.44 gigapixel, 360-degree panoramic HDR image which has dozens of eerie scenes hidden within it: skeletons of human, animal and paranormal origin; scary robed figures and occult symbols etched all around; what appear to be fountains and rivers of blood; a Stonehenge of teeth. These are the targets you're meant to track down, and as you hone in and check them off your list, voice signals attached to each one will reveal more and more of the explorer's spellbinding story. But this isn't a straightforward \"find the object\" puzzle game by any means. When you first look at the zoomed-out photo, it's akin to a strip of TV static with some heavily shadowed areas throughout. You can zoom to up to 64 times magnification to get a better look at specific zones, but you also have to adjust the image brightness using the crank to improve the clarity of the objects. Making it brighter or darker will reveal more objects in certain spots while simultaneously obscuring others. There are 150 targets according to the developer, which should take players somewhere from 10-20 hours to complete. I've been at it for hours and still have plenty left to find. (If you're stuck, you can turn to the helpful target lookup page, which provides hints with varying degrees of specificity.) All the while as you're hunched over your Playdate, laser-focused on the screen to find targets that are buried in a sea of fuzz, unsettling audio transmissions are cutting in and out, disturbing images are flashing on-screen at random and a constant atmospheric whooshing is playing in your ear. The sound design of this game is seriously brilliant — it's worth playing for that alone, not to mention all the other cool stuff. From the startup page to the menus where you'll find bits of a background story, to the creepy clips of people wailing and ominously reciting numbers, the sounds of Outside Parties make for a truly immersive, disconcerting experience that I previously wouldn't have thought possible on a Playdate. It's really something special. Outside Parties also comes with a screensaver that once again makes me yearn for the Playdate Stereo Dock. Pop on the Void Monitor, sit back, and enjoy the horrifying sights and sounds of the Outside. This article originally appeared on Engadget at https://www.engadget.com/gaming/outside-parties-is-the-creepiest-playdate-game-yet-and-im-kind-of-obsessed-213142541.html?src=rss",
          "content": "Never underestimate the chilling powers of grainy grayscale imagery and ethereal whooshing sounds. Outside Parties asks, \"What if I Spy, but in an alien hell dimension?\", and it is impressively unnerving despite the fact that nothing's really happening at any given time. It goes all in on atmosphere, to great effect. This is the Playdate horror game that I've been waiting for. Adams Immersive's Outside Parties is a sort of scavenger hunt across a massive image of a realm called the Outside, which can only be visited by astral travel, according to the lore. There are lots of unknowns about what or where it really is, though explorers have mapped it fairly extensively through out-of-body excursions and they've encountered thousands of different entities there, including the spirits of the dead. As the player, you have come across a Hellscryer K5 — the communication device, psychic camera and recorder used for these trips — and now you're combing through the mission logs, getting sucked into the mystery of it all. Think of the K5 as your Playdate, except powered by blood and runes. At the center of Outside Parties is a 1.44 gigapixel, 360-degree panoramic HDR image which has dozens of eerie scenes hidden within it: skeletons of human, animal and paranormal origin; scary robed figures and occult symbols etched all around; what appear to be fountains and rivers of blood; a Stonehenge of teeth. These are the targets you're meant to track down, and as you hone in and check them off your list, voice signals attached to each one will reveal more and more of the explorer's spellbinding story. But this isn't a straightforward \"find the object\" puzzle game by any means. When you first look at the zoomed-out photo, it's akin to a strip of TV static with some heavily shadowed areas throughout. You can zoom to up to 64 times magnification to get a better look at specific zones, but you also have to adjust the image brightness using the crank to improve the clarity of the objects. Making it brighter or darker will reveal more objects in certain spots while simultaneously obscuring others. There are 150 targets according to the developer, which should take players somewhere from 10-20 hours to complete. I've been at it for hours and still have plenty left to find. (If you're stuck, you can turn to the helpful target lookup page, which provides hints with varying degrees of specificity.) All the while as you're hunched over your Playdate, laser-focused on the screen to find targets that are buried in a sea of fuzz, unsettling audio transmissions are cutting in and out, disturbing images are flashing on-screen at random and a constant atmospheric whooshing is playing in your ear. The sound design of this game is seriously brilliant — it's worth playing for that alone, not to mention all the other cool stuff. From the startup page to the menus where you'll find bits of a background story, to the creepy clips of people wailing and ominously reciting numbers, the sounds of Outside Parties make for a truly immersive, disconcerting experience that I previously wouldn't have thought possible on a Playdate. It's really something special. Outside Parties also comes with a screensaver that once again makes me yearn for the Playdate Stereo Dock. Pop on the Void Monitor, sit back, and enjoy the horrifying sights and sounds of the Outside. This article originally appeared on Engadget at https://www.engadget.com/gaming/outside-parties-is-the-creepiest-playdate-game-yet-and-im-kind-of-obsessed-213142541.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/google-says-its-working-to-fix-gmail-issue-thats-led-to-flooded-inboxes-and-increased-spam-warnings-183358654.html",
          "published_at": "Sun, 25 Jan 2026 14:53:52 +0000",
          "title": "Google says it's fixed the Gmail issue that led to flooded inboxes and increased spam warnings",
          "standfirst": "Your Gmail inbox should now be back to normal after Saturday’s hiccups. Google said in an update on X on Saturday night that the issue, which affected the automatic filters that keep Gmail users’ inboxes free from the clutter of promotional emails, non-urgent updates and spam, “is now fully resolved for all users.” On its Workspace status dashboard, it added that an investigation is underway, and an analysis will be published once complete. Gmail users on Saturday reported that their inboxes were flooded with promotional emails that had not been properly sorted out of the main tab, and some said they were seeing notices that emails had not been scanned for spam. On social media and DownDetector, some Gmail users also reported delays in receiving messages, leading to issues with two-factor authentication logins. After confirming the issue, Google noted in an update on its Workspace dashboard that the problem resulted in the \"misclassification of emails in their inbox and additional spam warnings,\" including a banner that says, “Be careful with this message. Gmail hasn't scanned this message for spam, unverified senders, or harmful software.” In a statement to Engadget, a Google spokesperson echoed the message from its dashboard, saying, \"We are actively working to resolve the issue. As always, we encourage users to follow standard best practices when engaging with messages from unknown senders.\" Update, January 25 2026, 9:53AM ET: This story has been updated to reflect that the issue has been resolved. This article originally appeared on Engadget at https://www.engadget.com/apps/google-says-its-working-to-fix-gmail-issue-thats-led-to-flooded-inboxes-and-increased-spam-warnings-183358654.html?src=rss",
          "content": "Your Gmail inbox should now be back to normal after Saturday’s hiccups. Google said in an update on X on Saturday night that the issue, which affected the automatic filters that keep Gmail users’ inboxes free from the clutter of promotional emails, non-urgent updates and spam, “is now fully resolved for all users.” On its Workspace status dashboard, it added that an investigation is underway, and an analysis will be published once complete. Gmail users on Saturday reported that their inboxes were flooded with promotional emails that had not been properly sorted out of the main tab, and some said they were seeing notices that emails had not been scanned for spam. On social media and DownDetector, some Gmail users also reported delays in receiving messages, leading to issues with two-factor authentication logins. After confirming the issue, Google noted in an update on its Workspace dashboard that the problem resulted in the \"misclassification of emails in their inbox and additional spam warnings,\" including a banner that says, “Be careful with this message. Gmail hasn't scanned this message for spam, unverified senders, or harmful software.” In a statement to Engadget, a Google spokesperson echoed the message from its dashboard, saying, \"We are actively working to resolve the issue. As always, we encourage users to follow standard best practices when engaging with messages from unknown senders.\" Update, January 25 2026, 9:53AM ET: This story has been updated to reflect that the issue has been resolved. This article originally appeared on Engadget at https://www.engadget.com/apps/google-says-its-working-to-fix-gmail-issue-thats-led-to-flooded-inboxes-and-increased-spam-warnings-183358654.html?src=rss",
          "feed_position": 27
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/3bkJOPIyWcL3MD20sP4ZT8/74ebf0c216dcfefb690df6a5971f0bbf/2026-01-26_14-51-12.jpg?w=300&q=30",
      "popularity_score": 2016.372543888889
    },
    {
      "id": "cluster_20",
      "coverage": 2,
      "updated_at": "Mon, 26 Jan 2026 19:20:10 -0500",
      "title": "Khosla Ventures' Vinod Khosla and Ethan Choi disavow Keith Rabois' comments on an ICE shooting; Rabois said the man killed by agents was committing a \"felony\" (Julie Bort/TechCrunch)",
      "neutral_headline": "Vinod Khosla publicly disavows Keith Rabois&#8217; comments on ICE shooting",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260126/p43#a260126p43",
          "published_at": "Mon, 26 Jan 2026 19:20:10 -0500",
          "title": "Khosla Ventures' Vinod Khosla and Ethan Choi disavow Keith Rabois' comments on an ICE shooting; Rabois said the man killed by agents was committing a \"felony\" (Julie Bort/TechCrunch)",
          "standfirst": "Julie Bort / TechCrunch: Khosla Ventures' Vinod Khosla and Ethan Choi disavow Keith Rabois' comments on an ICE shooting; Rabois said the man killed by agents was committing a &ldquo;felony&rdquo; &mdash; To understand the stance of an unwavering Trump loyalist after United States Custom and Enforcement shocked the nation &hellip;",
          "content": "Julie Bort / TechCrunch: Khosla Ventures' Vinod Khosla and Ethan Choi disavow Keith Rabois' comments on an ICE shooting; Rabois said the man killed by agents was committing a &ldquo;felony&rdquo; &mdash; To understand the stance of an unwavering Trump loyalist after United States Custom and Enforcement shocked the nation &hellip;",
          "feed_position": 3,
          "image_url": "http://www.techmeme.com/260126/i43.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/26/vinod-khosla-publicly-disavows-keith-rabois-comments-on-ice-shooting/",
          "published_at": "Mon, 26 Jan 2026 21:49:12 +0000",
          "title": "Vinod Khosla publicly disavows Keith Rabois&#8217; comments on ICE shooting",
          "standfirst": "Unwavering Trump loyalist and VC Keith Rabois caused his colleague and his firm's founder to distance themselves from his comments on ICE.",
          "content": "Unwavering Trump loyalist and VC Keith Rabois caused his colleague and his firm's founder to distance themselves from his comments on ICE.",
          "feed_position": 6
        }
      ],
      "featured_image": "http://www.techmeme.com/260126/i43.jpg",
      "popularity_score": 2016.208655
    },
    {
      "id": "cluster_69",
      "coverage": 2,
      "updated_at": "Mon, 26 Jan 2026 13:20:01 -0500",
      "title": "Anthropic rolls out a new extension to MCP to let users interact with apps directly inside the Claude chatbot, with support for Asana, Figma, Slack, and others (Robert Hart/The Verge)",
      "neutral_headline": "MCP unites Claude chat with apps like Slack, Figma, and Canva",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260126/p32#a260126p32",
          "published_at": "Mon, 26 Jan 2026 13:20:01 -0500",
          "title": "Anthropic rolls out a new extension to MCP to let users interact with apps directly inside the Claude chatbot, with support for Asana, Figma, Slack, and others (Robert Hart/The Verge)",
          "standfirst": "Robert Hart / The Verge: Anthropic rolls out a new extension to MCP to let users interact with apps directly inside the Claude chatbot, with support for Asana, Figma, Slack, and others &mdash; &#65279;Anthropic's one step closer to having an everything app. &hellip; Anthropic's Claude got a bit livelier today thanks &hellip;",
          "content": "Robert Hart / The Verge: Anthropic rolls out a new extension to MCP to let users interact with apps directly inside the Claude chatbot, with support for Asana, Figma, Slack, and others &mdash; &#65279;Anthropic's one step closer to having an everything app. &hellip; Anthropic's Claude got a bit livelier today thanks &hellip;",
          "feed_position": 14,
          "image_url": "http://www.techmeme.com/260126/i32.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/867673/claude-mcp-app-interactive-slack-figma-canva",
          "published_at": "2026-01-26T13:00:00-05:00",
          "title": "MCP unites Claude chat with apps like Slack, Figma, and Canva",
          "standfirst": "Anthropic's Claude got a bit livelier today thanks to a new extension to MCP, the open-source protocol that allows AI agents to easily access tools and data across the internet. Users will now be able to interact with apps directly inside the Claude chatbot, letting you draft and format Slack messages to colleagues and create [&#8230;]",
          "content": "Anthropic's Claude got a bit livelier today thanks to a new extension to MCP, the open-source protocol that allows AI agents to easily access tools and data across the internet. Users will now be able to interact with apps directly inside the Claude chatbot, letting you draft and format Slack messages to colleagues and create presentations for clients in Canva without having to switch tabs. As of today, Anthropic said tools like Asana, Figma, Slack, and Canva will \"open as interactive apps right inside of chat.\" While users could previously connect tools like Slack and Asana to the AI assistant, doing so meant getting text back. The company … Read the full story at The Verge.",
          "feed_position": 8
        }
      ],
      "featured_image": "http://www.techmeme.com/260126/i32.jpg",
      "popularity_score": 2010.206155
    },
    {
      "id": "cluster_25",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 23:05:17 +0000",
      "title": "OpenAI spills technical details about how its AI coding agent works",
      "neutral_headline": "OpenAI spills technical details about how its AI coding agent works",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/01/openai-spills-technical-details-about-how-its-ai-coding-agent-works/",
          "published_at": "Mon, 26 Jan 2026 23:05:17 +0000",
          "title": "OpenAI spills technical details about how its AI coding agent works",
          "standfirst": "Unusually detailed post explains how OpenAI handles the Codex agent loop.",
          "content": "On Friday, OpenAI engineer Michael Bolin published a detailed technical breakdown of how the company's Codex CLI coding agent works internally, offering developers insight into AI coding tools that can write code, run tests, and fix bugs with human supervision. It complements our article in December on how AI agents work by filling in technical details on how OpenAI implements its \"agentic loop.\" AI coding agents are having something of a \"ChatGPT moment,\" where Claude Code with Opus 4.5 and Codex with GPT-5.2 have reached a new level of usefulness for rapidly coding up prototypes, interfaces, and churning out boilerplate code. The timing of OpenAI's post details the design philosophy behind Codex just as AI agents are becoming more practical tools for everyday work. These tools aren't perfect and remain controversial for some software developers. While OpenAI has previously told Ars Technica that it uses Codex as a coding tool to help develop the Codex product itself, we also discovered, through hands-on experience, that these tools can be astonishingly fast at simple tasks but remain brittle beyond their training data and require human oversight for production work. The rough framework of a project tends to come fast and feels magical, but filling in the details involves tedious debugging and workarounds for limitations the agent cannot overcome on its own.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/coding_robots_agents-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/coding_robots_agents-1152x648.jpg",
      "popularity_score": 362.9605994444444
    },
    {
      "id": "cluster_44",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 20:18:02 +0000",
      "title": "Apple's AirTag 2 is easier to find thanks to new chip",
      "neutral_headline": "Apple's AirTag 2 is easier to find thanks to new chip",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/apple-introduces-new-airtag-with-better-range-and-a-louder-speaker/",
          "published_at": "Mon, 26 Jan 2026 20:18:02 +0000",
          "title": "Apple's AirTag 2 is easier to find thanks to new chip",
          "standfirst": "This is the first major upgrade since Apple introduced AirTags five years ago.",
          "content": "Apple is introducing a new version of its AirTag tracking device—simply dubbed \"the new AirTag\"—and claims it offers substantial improvements thanks to a new Bluetooth chip. The original AirTag came out five years ago now, and it became popular in a variety of contexts. There were some problems, though—there was real concern about unwanted tracking and stalking with the devices, based on real stories of it being used for that. The company gradually introduced new features and protections against that, getting it to a much better place. This new version is focused on making the device more effective in general. Thanks to the inclusion of the second-generation Ultra Wideband chip (the same one found in other recently released Apple devices like the iPhone 17), Apple says the new AirTag can work with the Precision Finding feature in the Find My app to direct users to the AirTag (and whatever lost item it's stored with or attached to) from up to 50 percent farther away.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-2-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-2-1152x648.png",
      "popularity_score": 342.17309944444446
    },
    {
      "id": "cluster_37",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 21:31:13 +0000",
      "title": "Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot",
      "neutral_headline": "Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/do-we-really-need-polio-shots-deep-thoughts-by-rfk-jr-advisor-get-dragged/",
          "published_at": "Mon, 26 Jan 2026 21:31:13 +0000",
          "title": "Doctors face-palm as RFK Jr.’s top vaccine advisor questions need for polio shot",
          "standfirst": "Kirk Milhoan's comments come as federal vaccine policy slides to insignificance.",
          "content": "The chair of a federal vaccine advisory panel under anti-vaccine Health Secretary Robert F. Kennedy Jr. made his stance clear on vaccines in a podcast last week—and that stance was so alarming that the American Medical Association was compelled to respond with a scathing statement. Kirk Milhoan, who was named chair of the Advisory Committee on Immunization Practices for the Centers for Disease Control and Prevention in December, appeared on the aptly named podcast \"Why Should I Trust You.\" In the hour-long interview, Milhoan made a wide range of comments that have concerned medical experts and raised eyebrows. Early into the discussion, Milhoan, a pediatric cardiologist, declared, \"I don't like established science,\" and that \"science is what I observe.\" He lambasted the evidence-based methodology that previous ACIP panels used to carefully and transparently craft vaccine policy.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2235571142-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2235571142-1152x648.jpg",
      "popularity_score": 336.3928216666667
    },
    {
      "id": "cluster_38",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 21:02:26 +0000",
      "title": "Why has Microsoft been routing example.com traffic to a company in Japan?",
      "neutral_headline": "Why has Microsoft been routing example.com traffic to a company in Japan",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2026/01/odd-anomaly-caused-microsofts-network-to-mishandle-example-com-traffic/",
          "published_at": "Mon, 26 Jan 2026 21:02:26 +0000",
          "title": "Why has Microsoft been routing example.com traffic to a company in Japan?",
          "standfirst": "Company's autodiscover caused users' test credentials to be sent outside Microsoft networks.",
          "content": "From the Department of Bizarre Anomalies: Microsoft has suppressed an unexplained anomaly on its network that was routing traffic destined to example.com—a domain reserved for testing purposes—to a maker of electronics cables located in Japan. Under the RFC2606—an official standard maintained by the Internet Engineering Task Force—example.com isn't obtainable by any party. Instead it resolves to IP addresses assigned to Internet Assiged Names Authority. The designation is intended to prevent third parties from being bombarded with traffic when developers, penetration testers, and others need a domain for testing or discussing technical issues. Instead of naming an Internet-routable domain, they are to choose example.com or two others, example.net and example.org. Misconfig gone, but is it fixed? Output from the terminal command cURL shows that devices inside Azure and other Microsoft networks have been routing some traffic to subdomains of sei.co.jp, a domain belonging to Sumitomo Electric. Most of the resulting text is exactly what’s expected. The exception is the JSON-based response. Here’s the JSON output from Friday:Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/08/error-message-1000x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/08/error-message-1000x648.jpg",
      "popularity_score": 332.91309944444447
    },
    {
      "id": "cluster_45",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 20:13:47 +0000",
      "title": "“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns",
      "neutral_headline": "“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/wildly-irresponsible-dots-use-of-ai-to-draft-safety-rules-sparks-concerns/",
          "published_at": "Mon, 26 Jan 2026 20:13:47 +0000",
          "title": "“Wildly irresponsible”: DOT's use of AI to draft safety rules sparks concerns",
          "standfirst": "Staffers warn DOT's use of Gemini to draft rules could cause injuries and deaths.",
          "content": "The US Department of Transportation apparently thinks it's a good idea to use artificial intelligence to draft rules impacting the safety of airplanes, cars, and pipelines, a ProPublica investigation revealed Monday. It could be a problem if DOT becomes the first agency to use AI to draft rules, ProPublica pointed out, since AI is known to confidently get things wrong and hallucinate fabricated information. Staffers fear that any failure to catch AI errors could result in flawed laws, leading to lawsuits, injuries, or even deaths in the transportation system. But the DOT's top lawyer, Gregory Zerzan, isn't worried about that, December meeting notes revealed, because the point isn't for AI to be perfect. It's for AI to help speed up the rulemaking process, so that rules that take weeks or months to draft can instead be written within 30 days. According to Zerzan, DOT's preferred tool, Google Gemini, can draft rules in under 30 minutes.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1438737819-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1438737819-1152x648.jpg",
      "popularity_score": 320.10226611111113
    },
    {
      "id": "cluster_66",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 18:29:08 +0000",
      "title": "How to encrypt your PC's disk without giving the keys to Microsoft",
      "neutral_headline": "How to encrypt your PC's disk without giving the keys to Microsoft",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/how-to-encrypt-your-pcs-disk-without-giving-the-keys-to-microsoft/",
          "published_at": "Mon, 26 Jan 2026 18:29:08 +0000",
          "title": "How to encrypt your PC's disk without giving the keys to Microsoft",
          "standfirst": "Storing recovery keys with Microsoft allows the company to unlock your disk.",
          "content": "In early 2025, Forbes reports, investigators at the FBI served Microsoft with a warrant seeking the BitLocker encryption recovery keys for several laptops it believed held evidence of fraud in Guam's COVID-19 unemployment assistance program. And Microsoft complied with the FBI's request. BitLocker is the name of the full-disk encryption technology that has been part of Windows for nearly two decades. Though initially only available to owners of the Pro editions of Windows who turned it on manually, during the Windows 8 era Microsoft began using BitLocker to encrypt local disks automatically for all Windows 11 Home and Pro PCs that signed in with a Microsoft account. Using BitLocker in this way also uploads a recovery key for your device to Microsoft's servers—this makes it possible to unlock your disk so you don't lose data if something goes wrong with your system, or if you install a CPU upgrade or some other hardware change that breaks BitLocker. But it also (apparently) makes it possible for Microsoft to unlock your disk, too. A Microsoft rep said that the company handled \"around 20\" similar BitLocker recovery key requests from government authorities per year, and that these requests often fail because users haven't stored their recovery keys on Microsoft's servers. Microsoft and other tech companies have generally refused requests to install universal encryption backdoors for law enforcement purposes, and some companies (like Apple) claim to store device encryption keys using another layer of encryption that renders the keys inaccessible to the company.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/win11-pc-2023-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/win11-pc-2023-1152x648.jpeg",
      "popularity_score": 305.35809944444446
    },
    {
      "id": "cluster_70",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 18:05:50 +0000",
      "title": "The brothers meet Yoshi in Super Mario Galaxy Movie trailer",
      "neutral_headline": "The brothers meet Yoshi in Super Mario Galaxy Movie trailer",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/yoshi-joins-the-fun-in-latest-super-mario-galaxy-movie-trailer/",
          "published_at": "Mon, 26 Jan 2026 18:05:50 +0000",
          "title": "The brothers meet Yoshi in Super Mario Galaxy Movie trailer",
          "standfirst": "Toad: \"So some dinosaur just shows up and he's now part of the group. Cool.\"",
          "content": "Universal Pictures and Illumination dropped a new trailer for the upcoming Super Mario Galaxy Movie, and gaming fans will no doubt be delighted at the news that Yoshi, the little green dinosaur, features prominently, along with plenty of other Easter eggs for sharp-eyed fans. As previously reported, the first attempt at a Super Mario movie adaptation in 1993 was notoriously a dismal failure, although it still has its ’90s-nostalgic fans. But 2023’s Super Mario Bros. Movie won over gaming fans who were skeptical about another adaptation—including Ars Senior Gaming Editor Kyle Orland. The 2023 film reintroduced Mario and Luigi, two tight-knit but struggling Brooklyn plumbers who got separated when they unexpectedly fell into the fantastical Mushroom Kingdom. Mario sought Princess Peach’s help to rescue his brother from the evil clutches of Bowser, ruler of the Dark Lands, who was keen to marry Peach and threatened to destroy the Mushroom Kingdom with a Super Star if she refused him. So Peach led Mario on a quest to recruit allies and stop Bowser for good. They succeeded, shrinking Bowser and imprisoning him in a jar. Mario and Luigi moved to the Mushroom Kingdom and continued their plumbing work there.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/mario2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/mario2-1152x648.jpg",
      "popularity_score": 297.9697661111111
    },
    {
      "id": "cluster_84",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 16:23:48 +0000",
      "title": "TikTok explained why some US creators are seeing posts with \"0 views\"",
      "neutral_headline": "TikTok explained why some US creators are seeing posts with \"0 views\"",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/tiktok-glitches-caused-by-data-center-power-outage-us-joint-venture-says/",
          "published_at": "Mon, 26 Jan 2026 16:23:48 +0000",
          "title": "TikTok explained why some US creators are seeing posts with \"0 views\"",
          "standfirst": "US TikTok users experienced a wide range of errors, sparking conspiracies.",
          "content": "TikTok has been glitching for US users since Sunday, and TikTok's new US owners finally confirmed the cause: a power outage at a US data center. \"Since yesterday we’ve been working to restore our services following a power outage at a US data center impacting TikTok and other apps we operate,\" the TikTok USDS Joint Venture posted on X on Monday morning. \"We're working with our data center partner to stabilize our service. We're sorry for this disruption and hope to resolve it soon.\" By Monday evening, the issues had not been resolved, with the TikTok USDS account posting an update warning users to expect \"bugs, slower load times, or timed-out requests, including when posting new content.\" The X post directly confronted creator concerns about receiving \"0 views\" on new videos and/or missing earnings. The glitch is temporary, TikTok USDS said, \"your actual data and engagement are safe.\"Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2257704765-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2257704765-1024x648.jpg",
      "popularity_score": 286.26921055555556
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 16:13:22 +0000",
      "title": "How to get Doom running on a pair of earbuds",
      "neutral_headline": "How to get Doom running on a pair of earbuds",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/how-to-get-doom-running-on-a-pair-of-earbuds/",
          "published_at": "Mon, 26 Jan 2026 16:13:22 +0000",
          "title": "How to get Doom running on a pair of earbuds",
          "standfirst": "No display? No problem for the UART-to-web-server \"Doombuds\" project.",
          "content": "Over the years, hackers and modders at large have made it their mission to port classic first-person shooter Doom to practically anything with a display. Recently, though, coder Arin Sarkisan has taken the \"Can it Run Doom?\" idea in an unlikely direction: wireless earbuds that aren't designed to output graphics at all. To be clear, this hack doesn't apply to any generic set of earbuds. The \"Doombuds\" project is designed specifically for the PineBuds Pro, which are unique in featuring completely open source firmware and a community-maintained SDK. That means Sarkisan was able to code up a JavaScript interface that uses the earbuds' UART contact pads to send a heavily compressed MJPEG video stream to a web server (via a serial server). The 2.4 MB/s data stream from the UART connection can put out about 22 to 27 frames per second in this format, which is more than enough for a CPU that can only run the game at a maximum of 18 fps anyway.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/PineBuds-Pro-4-1152x648-1769443386.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/PineBuds-Pro-4-1152x648-1769443386.jpg",
      "popularity_score": 273.0953216666667
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 14:17:46 +0000",
      "title": "EU launches formal investigation of xAI over Grok's sexualized deepfakes",
      "neutral_headline": "EU launches formal investigation of xAI over Grok's sexualized deepfakes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/eu-launches-formal-investigation-of-xai-over-groks-sexualized-deepfakes/",
          "published_at": "Mon, 26 Jan 2026 14:17:46 +0000",
          "title": "EU launches formal investigation of xAI over Grok's sexualized deepfakes",
          "standfirst": "Elon Musk's company faces fines of up to 6 percent of its daily turnover.",
          "content": "The EU has launched a formal investigation into Elon Musk’s xAI following a public outcry over how its Grok chatbot spread sexualized images of women and children. The billionaire entrepreneur has come under scrutiny from regulators around the world this month after people began using Grok to generate deepfakes of people without consent. The images were posted on the X social network as well as the separate Grok app, both of which are run by xAI. The probe, announced on Monday under the EU’s Digital Services Act, will assess if xAI tried to mitigate the risks of deploying Grok’s tools on X and the proliferation of content that “may amount to child sexual abuse material.”Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/xai-grok-1152x648-1752596823.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/xai-grok-1152x648-1752596823.jpg",
      "popularity_score": 264.168655
    },
    {
      "id": "cluster_96",
      "coverage": 1,
      "updated_at": "Mon, 26 Jan 2026 12:00:57 +0000",
      "title": "Former astronaut on lunar spacesuits: \"I don't think they're great right now\"",
      "neutral_headline": "Former astronaut on lunar spacesuits: \"I don't think they're great right now\"",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/former-astronaut-on-lunar-spacesuits-i-dont-think-theyre-great-right-now/",
          "published_at": "Mon, 26 Jan 2026 12:00:57 +0000",
          "title": "Former astronaut on lunar spacesuits: \"I don't think they're great right now\"",
          "standfirst": "\"These are just the difficulties of designing a spacesuit for the lunar environment.\"",
          "content": "Crew members traveling to the lunar surface on NASA's Artemis missions should be gearing up for a grind. They will wear heavier spacesuits than those worn by the Apollo astronauts, and NASA will ask them to do more than the first Moonwalkers did more than 50 years ago. The Moonwalking experience will amount to an \"extreme physical event\" for crews selected for the Artemis program's first lunar landings, a former NASA astronaut told a panel of researchers, physicians, and engineers convened by the National Academies. Kate Rubins, who retired from the space agency last year, presented the committee with her views on the health risks for astronauts on lunar missions. She outlined the concerns NASA officials often talk about: radiation exposure, muscle and bone atrophy, reduced cardiovascular and immune function, and other adverse medical effects of spaceflight.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/jsc2025e077725-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/jsc2025e077725-1152x648.jpg",
      "popularity_score": 144.88837722222223
    },
    {
      "id": "cluster_112",
      "coverage": 1,
      "updated_at": "Sun, 25 Jan 2026 12:00:25 +0000",
      "title": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
      "neutral_headline": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/a-decade-of-star-trek-themed-fart-jokes-the-greatest-generation-podcast-turns-10/",
          "published_at": "Sun, 25 Jan 2026 12:00:25 +0000",
          "title": "A decade of Star Trek-themed fart jokes: The Greatest Generation podcast turns 10",
          "standfirst": "How two podcasters turned a Star Trek side project into a full-time career.",
          "content": "A decade is a long time for a TV series; no single iteration of Star Trek has made it that far. But “a Star Trek podcast by two guys just a little bit embarrassed to have a Star Trek podcast” has now passed the milestone. January 25, 2026, marks a full decade since The Greatest Generation, my favorite podcast, debuted. Like a bottle of Château Picard, the show has only improved with age. (I interviewed the guys behind the show back in 2016 when they were just getting started.) The podcast helped me rediscover, and appreciate more fully, Star Trek: The Next Generation—which is also my favorite TV show. The Greatest Generation continues to delight with its irreverent humor, its celebration of the most minor of characters, and its technical fascination with how a given episode was made.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ADAM_BEN_L1560319-1152x648-1769205900.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ADAM_BEN_L1560319-1152x648-1769205900.jpg",
      "popularity_score": 138
    }
  ]
}