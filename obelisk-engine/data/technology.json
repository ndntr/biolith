{
  "updated_at": "2025-12-29T19:16:45.361Z",
  "clusters": [
    {
      "id": "cluster_22",
      "coverage": 2,
      "updated_at": "Mon, 29 Dec 2025 16:03:00 +0000",
      "title": "CES 2026: What to expect from tech’s biggest conference in January",
      "neutral_headline": "CES 2026: What to expect from tech’s biggest conference in January",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/ces-2026-what-to-expect-from-techs-biggest-conference-in-january-120000369.html",
          "published_at": "Mon, 29 Dec 2025 16:03:00 +0000",
          "title": "CES 2026: What to expect from tech’s biggest conference in January",
          "standfirst": "CES is the January trade show where the tech industry kicks off the year with a bevy of new and notable announcements — and it’s less than a week away. The CES 2026 show floor is officially open from January 6 through 9, but the fun kicks off with events on Sunday January 4 and a host of press conferences on Monday. As always, product demos, announcements and networking will be happening at the Las Vegas Convention Center and other hotels all over the city. As usual, Engadget will be covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements are already trickling out as CES approaches, and thanks to the CTA’s schedule we also do know what companies will be hosting press conferences. We’re also using our experience and expertise to predict what tech trends could rear their heads at the show.The CES 2026 schedulePress conferences and show floor booths are the bread and butter of CES. The Consumer Technology Association has already published a searchable directory of who will have a presence at the show, along with a schedule of every official panel and presentation.On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" Ahead of that, though, Samsung has already outlined a variety of more specifics. That'll be followed by multiple press conferences throughout Monday, January 5. LG is hosting its \"Innovation in Tune with You\" presentation to share \"its vision for elevating daily life through Affectionate Intelligence\" at the start of the day, Intel is launching its new Core Ultra Series 3 processors in the afternoon, Sony Honda Mobility is holding a press conference offering yet more details on its first car and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day.On the week of December 15, the CTA added a keynote by NVIDIA CEO Jensen Huang to its schedule. The event will take place on January 5 at 1PM PT (4PM ET) and, according to the website, will last about 90 minutes. Based on the description on the listing, the presentation will “showcase the latest NVIDIA solutions driving innovation and productivity across industries.”Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at the Las Vegas Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\" It’s worth noting that Lenovo is the parent company of Motorola, which still makes phones and foldables that feature AI tools, so it’s possible those devices feature in the presentation as well. Samsung and LG vie for pre-show publicityAs they typically do, some companies have already gotten a head start on the CES news by publicly sharing their announcements in the weeks leading up to January. LG, for example, has said it will debut its first Micro RGB television at CES. While details are scarce, the company’s press release for the LG Micro RGB evo did confirm it has received certifications by Intertek for 100 percent color gamut coverage in DCI-P3 an Adobe RGB, and that it has more than a thousand dimming zones for brightness control. And if PC gaming displays are more your speed, LG will have that covered, too, with a new line of 5K-capable gaming monitors on deck with built-in AI upscaling.But LG’s not just showing off displays. The Korean multinational will also introduce a Dolby-powered modular home audio system and flex its automation muscles with a humanoid home automation robot named CLOiD. Of course, Samsung refuses to be outdone by its hometown rival, and has also released a pre-CES press release document dump. Samsung will be launching its own lineup of Micro RGB TVs at CES, for starters. The company already introduced its first Micro RGB TV at CES 2025, which was a 115-inch model available for a cool $30,000. Next year, Samsung is expanding the range with 55-, 65-, 75-, 85-, 100- and 115-inch models that use the next evolution of the company’s Micro RGB technology. Samsung is also countering LG’s 5K monitors with a 6K model that aims to deliver glasses-free 3D (another long-time CES staple). It’ll be one of several new displays in the company’s Odyssey gaming line.And on the audio front, Samsung has teased several new soundbars and speakers, including Sonos-style Wi-Fi streaming models call the Music Studio 5 and Studio 7.Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensAs noted above, Samsung and LG appear to be going all-in on Micro RGB display tech for TVs. Expect that to be a huge buzzword at CES, with Hisense and Sony debuting new models, too.Sony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.And maybe your future TV won’t need a power cord, either: Displace will be showing off a mounting option that includes a 15,000mAh battery to juice up whatever giant TV screen you choose to attach.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots — like LG’s aforementioned CLOiD — competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!Update, December 11 2025, 11:03AM ET: This story has been updated to include detail on Lenovo being Motorola’s parent company and how the latter might have a part in the Tuesday presentation.Update, December 16 2025, 1:33PM ET: This story has been updated to include the NVIDIA press conference, which was added to the CTA schedule within the last two days.Update, December 23 2025, 7:28AM ET: This story has been updated to include LG and Samsung’s Micro RGB TV announcements, which were made public in the past seven days. The intro was also tweaked to reflect how soon CES is at this point.Update, December 29 2025, 11:03AM ET: This story has been updated to include additional details on pre-announcements from Samsung, LG and Displace. This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-what-to-expect-from-techs-biggest-conference-in-january-120000369.html?src=rss",
          "content": "CES is the January trade show where the tech industry kicks off the year with a bevy of new and notable announcements — and it’s less than a week away. The CES 2026 show floor is officially open from January 6 through 9, but the fun kicks off with events on Sunday January 4 and a host of press conferences on Monday. As always, product demos, announcements and networking will be happening at the Las Vegas Convention Center and other hotels all over the city. As usual, Engadget will be covering the event in-person and remotely, bringing you news and hands-ons straight from the show floor.More specific details and pre-announcements are already trickling out as CES approaches, and thanks to the CTA’s schedule we also do know what companies will be hosting press conferences. We’re also using our experience and expertise to predict what tech trends could rear their heads at the show.The CES 2026 schedulePress conferences and show floor booths are the bread and butter of CES. The Consumer Technology Association has already published a searchable directory of who will have a presence at the show, along with a schedule of every official panel and presentation.On Sunday, January 4, Samsung will kick-off CES with \"The First Look,\" a presentation hosted by TM Roh, the CEO of Samsung's DX Division, on the company's \"vision for the DX (Device eXperience) Division in 2026, along with new AI-driven customer experiences.\" Ahead of that, though, Samsung has already outlined a variety of more specifics. That'll be followed by multiple press conferences throughout Monday, January 5. LG is hosting its \"Innovation in Tune with You\" presentation to share \"its vision for elevating daily life through Affectionate Intelligence\" at the start of the day, Intel is launching its new Core Ultra Series 3 processors in the afternoon, Sony Honda Mobility is holding a press conference offering yet more details on its first car and AMD CEO Lisa Su will cover AMD's upcoming chip announcements at a keynote address that closes out the day.On the week of December 15, the CTA added a keynote by NVIDIA CEO Jensen Huang to its schedule. The event will take place on January 5 at 1PM PT (4PM ET) and, according to the website, will last about 90 minutes. Based on the description on the listing, the presentation will “showcase the latest NVIDIA solutions driving innovation and productivity across industries.”Finally, on Tuesday, January 6, Lenovo CEO Yuanqing Yang will host Lenovo's Tech World Conference at the Las Vegas Sphere, using the large and decidedly curved screen to share the company's \"commitment to delivering smarter AI for all by constantly redefining how technology can engage, inspire, and empower.\" It’s worth noting that Lenovo is the parent company of Motorola, which still makes phones and foldables that feature AI tools, so it’s possible those devices feature in the presentation as well. Samsung and LG vie for pre-show publicityAs they typically do, some companies have already gotten a head start on the CES news by publicly sharing their announcements in the weeks leading up to January. LG, for example, has said it will debut its first Micro RGB television at CES. While details are scarce, the company’s press release for the LG Micro RGB evo did confirm it has received certifications by Intertek for 100 percent color gamut coverage in DCI-P3 an Adobe RGB, and that it has more than a thousand dimming zones for brightness control. And if PC gaming displays are more your speed, LG will have that covered, too, with a new line of 5K-capable gaming monitors on deck with built-in AI upscaling.But LG’s not just showing off displays. The Korean multinational will also introduce a Dolby-powered modular home audio system and flex its automation muscles with a humanoid home automation robot named CLOiD. Of course, Samsung refuses to be outdone by its hometown rival, and has also released a pre-CES press release document dump. Samsung will be launching its own lineup of Micro RGB TVs at CES, for starters. The company already introduced its first Micro RGB TV at CES 2025, which was a 115-inch model available for a cool $30,000. Next year, Samsung is expanding the range with 55-, 65-, 75-, 85-, 100- and 115-inch models that use the next evolution of the company’s Micro RGB technology. Samsung is also countering LG’s 5K monitors with a 6K model that aims to deliver glasses-free 3D (another long-time CES staple). It’ll be one of several new displays in the company’s Odyssey gaming line.And on the audio front, Samsung has teased several new soundbars and speakers, including Sonos-style Wi-Fi streaming models call the Music Studio 5 and Studio 7.Outside of the formal introduction of new products and initiatives, reading the tea leaves of what was announced last year and what companies are reportedly working on, we can make some educated guesses at what we could see at CES 2026.New chips from AMD, Intel and QualcommCES is frequently the start of a cascade of new chip announcements for a given year, and one of the first places new silicon appears in real consumer products. AMD will likely use its keynote to introduce new versions of its Ryzen chips, including the recently spotted Ryzen 7 9850X3D, which is expected to offer better single-threaded performance, and the Ryzen 9000G series, which could be built with AMD's Zen 5 architecture. The company might also use its CES stage to go over its new FSR Redstone AI upscaling tech.Intel has already publicly announced that it'll launch its Panther Lake chips at CES 2026. The officially titled Intel Core Ultra Series 3 chips fit into Intel's overall \"AI PC\" push, but are specifically meant for premium laptops. Based on a preview from October 2025, Intel says the first chip made with its 2-nanometer 18A process will offer 50 percent more processing performance than previous generations and for the chip's Arc GPU, a 50 percent performance bump from last generation.Qualcomm is also rumored to be targeting laptops at the show, building on the work it's done moving its Snapdragon chips out of phones and tablets and into other types of computers. The company's Snapdragon X2 Elite and X2 Elite Premium chips should start appearing in laptops at CES 2026, offering a look at the improved speed and AI performance the company promised in 2025.Brighter, \"truer\" screensAs noted above, Samsung and LG appear to be going all-in on Micro RGB display tech for TVs. Expect that to be a huge buzzword at CES, with Hisense and Sony debuting new models, too.Sony announced a collection of new Bravia TVs in April 2025, replacing the company's flagship, filling in its midrange options and adding a new budget model to the mix. The star of this updated Bravia lineup is the Bravia 9, which features a QD-OLED panel, but Sony appears to be prepping entirely new display tech for 2026. In March 2025, Sony introduced a new RGB LED panel that uses individual Mini LED backlights colored in red, green and blue to produce even brighter, more accurate colors. In contrast to a QD-OLED, which filters a layer of blue organic light emitting diodes through quantum dots that change color, Sony's \"General RGB LED Backlight Technology\" can get as bright as a Mini LED panel without needing an extra filter layer or worrying about OLED's problems with burn-in. The company has already trademarked the name \"True RGB,\" which could end up being what Sony calls this new flavor of display if it decides to show them off at CES. It seems entirely likely, because CES is nothing if not a TV show — it’s a sure bet that we’ll see new TVs from the likes of LG and Samsung in addition to Sony. If the company doesn't introduce new display tech for its TVs, it does have a new 240Hz PlayStation monitor coming in 2026 that it could show off at CES instead.Sony isn't the only company hyped on bright screens. Samsung is reportedly pushing an updated version of the HDR10 and HDR10+ standards that could be ready to demo at CES 2026. The new HDR10+ Advanced standard would be Samsung's answer to Dolby Vision 2, which includes support for things bi-directional tone mapping and intelligent features that automatically adapt sports and gaming content. Samsung's take will reportedly offer improved brightness, genre-based tone mapping and intelligent motion smoothing options, among other improvements.And maybe your future TV won’t need a power cord, either: Displace will be showing off a mounting option that includes a 15,000mAh battery to juice up whatever giant TV screen you choose to attach.Ballie Watch 2026The ball-shaped yellow robot lovingly known as \"Ballie\" has been announced twice, first in 2020 and then again in 2024 with a projector in tow. Samsung said Ballie would go on sale in 2025 at CES last year and then shared in April 2025 that Ballie would ship this summer with Google's Gemini onboard. But it's nearly 2026, and Ballie is nowhere to be seen. It's possible Samsung could make a third attempt at announcing its robot at CES 2026, but whether or not it does, robotics will still be a big part of the show.Robot vacuums and mops were a major highlight of CES 2025, and it's safe to expect notable improvements from the new models that are announced at CES 2026. Not every company will adopt the retractable arm of the Roborock Saros Z70, but robot vacuums with legs for rising over small ledges like the Dreame X50 seem like they could become the norm. Roborock could also show off its new Roborock Qrevo Curv 2 Flow, the first of its robot vacuums to feature a retractable roller mop.Beyond just traversing spaces more efficiently, improving robots' navigation could also be a major concern at the show. Prominent members of the AI industry are turning their attention from large language models to world models, which aim to give AI a deep understanding of physical space. Those world models could be the key to making robots — like LG’s aforementioned CLOiD — competent at navigating homes and workplaces, and will likely be a significant talking point at CES 2026.We’ll be updating this article throughout the month as more rumors surface and new products are confirmed — stay tuned for future updates!Update, December 11 2025, 11:03AM ET: This story has been updated to include detail on Lenovo being Motorola’s parent company and how the latter might have a part in the Tuesday presentation.Update, December 16 2025, 1:33PM ET: This story has been updated to include the NVIDIA press conference, which was added to the CTA schedule within the last two days.Update, December 23 2025, 7:28AM ET: This story has been updated to include LG and Samsung’s Micro RGB TV announcements, which were made public in the past seven days. The intro was also tweaked to reflect how soon CES is at this point.Update, December 29 2025, 11:03AM ET: This story has been updated to include additional details on pre-announcements from Samsung, LG and Displace. This article originally appeared on Engadget at https://www.engadget.com/big-tech/ces-2026-what-to-expect-from-techs-biggest-conference-in-january-120000369.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-wireless-charger-140036359.html",
          "published_at": "Mon, 29 Dec 2025 08:00:36 +0000",
          "title": "The best wireless chargers for 2026",
          "standfirst": "Imagine never having to fumble with a charging cable again. That's the magic of a wireless charger. Not only does going wireless clear up your space and make charging as simple as setting your phone down, but it’s also surprisingly versatile. Whether you’re looking for a sleek charging pad for your nightstand, a stand that keeps your phone propped up on your desk or even a foldable charger for convenient travel, there's a wireless charger designed to fit your lifestyle. Some can even double as a car charger, keeping your phone powered up on the go without the hassle of cables to plug in. With so many convenient options, it's easy to see why more people are ditching their wired chargers and embracing the effortlessness of wireless. These are the best wireless chargers we've tested so far. Table of contents Best wireless chargers for 2026 What to look for in a wireless charger Where and how will you use your charger? Wireless charging performance Quality and box contents Wireless chargers FAQs Best wireless chargers for 2026 What to look for in a wireless charger While it’s tempting to buy a wireless charging pad optimized for the specific phone you have now, resist that urge. Instead, think about the types of devices (phones included) that you could see yourself using in the near future. If you’re sure you’ll use iPhones for a long time, an Apple MagSafe-compatible magnetic wireless charger will be faster and more convenient. If you use Android phones or think you might switch sides, however, you’ll want a more universal design. If you have other accessories like wireless earbuds or a smartwatch that supports wireless charging, maybe you’d be better off with a 3-in-1 wireless charger or full wireless charging station. Where and how will you use your charger? Odds are that you have a specific use case in mind for your charger. You may want it by your bedside on your nightstand for a quick charge in the morning, or on your desk for at-a-glance notifications. You might even keep it in your bag for convenient travel charging instead of bulky portable chargers or power banks. Think about where you want to use this accessory and what you want to do with the device(s) it charges while it’s powering up. For example, a wireless charging pad might be better for bedside use if you just want to be able to drop your phone down at the end of a long day and know it’ll be powered up in the morning. However, a stand will be better if you have an iPhone and want to make use of the Standby feature during the nighttime hours. For a desk wireless charger, a stand lets you more easily glance at phone notifications throughout the day. For traveling, undoubtedly, a puck-style charging pad is best since it will take up much less space in your bag than a stand would. Many power banks also include wireless charging pads built in, so one of those might make even more sense for those who are always on the go. Some foldable chargers are also designed for travel, collapsing flat to take up less space. Wireless charging performance Although wireless charging is usually slower than its wired equivalent, speed and wattage are still important considerations. A fast charger can supply enough power for a long night out in the time it takes to change outfits. Look for options that promise faster charging and support standards like Qi2 certified charging for the best balance of efficiency and compatibility. In general, a 15W charger is more than quick enough for most situations, and you’ll need a MagSafe-compatible charger to extract that level of performance from an iPhone. With that said, even the slower 7.5W and 10W chargers are fast enough for an overnight power-up. If anything, you’ll want to worry more about support for cases. While many models can deliver power through a reasonably thick case (typically 3mm to 5mm), you’ll occasionally run into examples that only work with naked phones. There are some proprietary chargers that smash the 15W barrier if you have the right phone. Apple’s latest MagSafe charging pad can provide up to 25W of wireless power to compatible iPhones when paired with a 30W or 35W adapter — the latter being another component you’ll have to get right to make sure the whole equation works as fast as it possibly can. Quality and box contents Pay attention to what’s included in the box. Some wireless chargers don’t include power adapters, and others may even ask you to reuse your phone’s USB-C charging cable. What may seem to be a bargain may prove expensive if you have to buy extras just to use it properly. As mentioned above, you’ll want to make sure all of the components needed to use the wireless charger can provide the level of power you need — you’re only as strong (or in this case, fast) as your weakest link. Fit and finish is also worth considering. You’re likely going to use your wireless charger every day, so even small differences in build quality could make the difference between joy and frustration. If your charger doesn’t use MagSafe-compatible tech, textured surfaces like fabric or rubberized plastic are more likely to keep your phone in place. The base should be grippy or weighty enough that the charger won’t slide around. Also double check that the wireless charger you’re considering can support phones outfitted with cases — the specifications are usually listed in the charger’s description or specs. You’ll also want to think about the minor conveniences. Status lights are useful for indicating correct phone placement, but an overly bright light can be distracting. Ideally, the light dims or shuts off after a certain period of time. And while we caution against lips and trays that limit compatibility, you may still want some barriers to prevent your device falling off its perch on the charging station. Wireless chargers FAQs Do wireless chargers work if you have a phone case? Many wireless chargers do work if you leave the case on your phone. Generally, a case up to 3mm thick should be compatible with most wireless chargers. However, you should check the manufacturer’s guide to ensure a case is supported. How do I know if my phone supports wireless charging? Checking the phone’s specification should tell you if your phone is compatible with wireless charging. You might see words like “Qi wireless charging” or “wireless charging compatible.” Do cords charge your phone faster? Most often, wired charging will be faster than wireless charging. However, wired charging also depends on what the charging cable’s speed is and how much power it’s designed to carry. A quick-charging cable that can transmit up to 120W of power is going to be faster than a wireless charger.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-wireless-charger-140036359.html?src=rss",
          "content": "Imagine never having to fumble with a charging cable again. That's the magic of a wireless charger. Not only does going wireless clear up your space and make charging as simple as setting your phone down, but it’s also surprisingly versatile. Whether you’re looking for a sleek charging pad for your nightstand, a stand that keeps your phone propped up on your desk or even a foldable charger for convenient travel, there's a wireless charger designed to fit your lifestyle. Some can even double as a car charger, keeping your phone powered up on the go without the hassle of cables to plug in. With so many convenient options, it's easy to see why more people are ditching their wired chargers and embracing the effortlessness of wireless. These are the best wireless chargers we've tested so far. Table of contents Best wireless chargers for 2026 What to look for in a wireless charger Where and how will you use your charger? Wireless charging performance Quality and box contents Wireless chargers FAQs Best wireless chargers for 2026 What to look for in a wireless charger While it’s tempting to buy a wireless charging pad optimized for the specific phone you have now, resist that urge. Instead, think about the types of devices (phones included) that you could see yourself using in the near future. If you’re sure you’ll use iPhones for a long time, an Apple MagSafe-compatible magnetic wireless charger will be faster and more convenient. If you use Android phones or think you might switch sides, however, you’ll want a more universal design. If you have other accessories like wireless earbuds or a smartwatch that supports wireless charging, maybe you’d be better off with a 3-in-1 wireless charger or full wireless charging station. Where and how will you use your charger? Odds are that you have a specific use case in mind for your charger. You may want it by your bedside on your nightstand for a quick charge in the morning, or on your desk for at-a-glance notifications. You might even keep it in your bag for convenient travel charging instead of bulky portable chargers or power banks. Think about where you want to use this accessory and what you want to do with the device(s) it charges while it’s powering up. For example, a wireless charging pad might be better for bedside use if you just want to be able to drop your phone down at the end of a long day and know it’ll be powered up in the morning. However, a stand will be better if you have an iPhone and want to make use of the Standby feature during the nighttime hours. For a desk wireless charger, a stand lets you more easily glance at phone notifications throughout the day. For traveling, undoubtedly, a puck-style charging pad is best since it will take up much less space in your bag than a stand would. Many power banks also include wireless charging pads built in, so one of those might make even more sense for those who are always on the go. Some foldable chargers are also designed for travel, collapsing flat to take up less space. Wireless charging performance Although wireless charging is usually slower than its wired equivalent, speed and wattage are still important considerations. A fast charger can supply enough power for a long night out in the time it takes to change outfits. Look for options that promise faster charging and support standards like Qi2 certified charging for the best balance of efficiency and compatibility. In general, a 15W charger is more than quick enough for most situations, and you’ll need a MagSafe-compatible charger to extract that level of performance from an iPhone. With that said, even the slower 7.5W and 10W chargers are fast enough for an overnight power-up. If anything, you’ll want to worry more about support for cases. While many models can deliver power through a reasonably thick case (typically 3mm to 5mm), you’ll occasionally run into examples that only work with naked phones. There are some proprietary chargers that smash the 15W barrier if you have the right phone. Apple’s latest MagSafe charging pad can provide up to 25W of wireless power to compatible iPhones when paired with a 30W or 35W adapter — the latter being another component you’ll have to get right to make sure the whole equation works as fast as it possibly can. Quality and box contents Pay attention to what’s included in the box. Some wireless chargers don’t include power adapters, and others may even ask you to reuse your phone’s USB-C charging cable. What may seem to be a bargain may prove expensive if you have to buy extras just to use it properly. As mentioned above, you’ll want to make sure all of the components needed to use the wireless charger can provide the level of power you need — you’re only as strong (or in this case, fast) as your weakest link. Fit and finish is also worth considering. You’re likely going to use your wireless charger every day, so even small differences in build quality could make the difference between joy and frustration. If your charger doesn’t use MagSafe-compatible tech, textured surfaces like fabric or rubberized plastic are more likely to keep your phone in place. The base should be grippy or weighty enough that the charger won’t slide around. Also double check that the wireless charger you’re considering can support phones outfitted with cases — the specifications are usually listed in the charger’s description or specs. You’ll also want to think about the minor conveniences. Status lights are useful for indicating correct phone placement, but an overly bright light can be distracting. Ideally, the light dims or shuts off after a certain period of time. And while we caution against lips and trays that limit compatibility, you may still want some barriers to prevent your device falling off its perch on the charging station. Wireless chargers FAQs Do wireless chargers work if you have a phone case? Many wireless chargers do work if you leave the case on your phone. Generally, a case up to 3mm thick should be compatible with most wireless chargers. However, you should check the manufacturer’s guide to ensure a case is supported. How do I know if my phone supports wireless charging? Checking the phone’s specification should tell you if your phone is compatible with wireless charging. You might see words like “Qi wireless charging” or “wireless charging compatible.” Do cords charge your phone faster? Most often, wired charging will be faster than wireless charging. However, wired charging also depends on what the charging cable’s speed is and how much power it’s designed to carry. A quick-charging cable that can transmit up to 120W of power is going to be faster than a wireless charger.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-wireless-charger-140036359.html?src=rss",
          "feed_position": 8,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-02/c9a24a20-b7a0-11ed-b3cd-16d5d607f8d1"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/new-framework-simplifies-the-complex-landscape-of-agentic-ai",
          "published_at": "Mon, 29 Dec 2025 08:00:00 GMT",
          "title": "New framework simplifies the complex landscape of agentic AI",
          "standfirst": "With the ecosystem of agentic tools and frameworks exploding in size, navigating the many options for building AI systems is becoming increasingly difficult, leaving developers confused and paralyzed when choosing the right tools and models for their applications.In a new study, researchers from multiple institutions present a comprehensive framework to untangle this complex web. They categorize agentic frameworks based on their area of focus and tradeoffs, providing a practical guide for developers to choose the right tools and strategies for their applications.For enterprise teams, this reframes agentic AI from a model-selection problem into an architectural decision about where to spend training budget, how much modularity to preserve, and what tradeoffs they’re willing to make between cost, flexibility, and risk.Agent vs. tool adaptationThe researchers divide the landscape into two primary dimensions: agent adaptation and tool adaptation.Agent adaptation involves modifying the foundation model that underlies the agentic system. This is done by updating the agent’s internal parameters or policies through methods like fine-tuning or reinforcement learning to better align with specific tasks.Tool adaptation, on the other hand, shifts the focus to the environment surrounding the agent. Instead of retraining the large, expensive foundation model, developers optimize the external tools such as search retrievers, memory modules, or sub-agents. In this strategy, the main agent remains \"frozen\" (unchanged). This approach allows the system to evolve without the massive computational cost of retraining the core model.The study further breaks these down into four distinct strategies:A1: Tool execution signaled: In this strategy, the agent learns by doing. It is optimized using verifiable feedback directly from a tool&#x27;s execution, such as a code compiler interacting with a script or a database returning search results. This teaches the agent the \"mechanics\" of using a tool correctly.A prime example is DeepSeek-R1, where the model was trained through reinforcement learning with verifiable rewards to generate code that successfully executes in a sandbox. The feedback signal is binary and objective (did the code run, or did it crash?). This method builds strong low-level competence in stable, verifiable domains like coding or SQL.A2: Agent output Signaled: Here, the agent is optimized based on the quality of its final answer, regardless of the intermediate steps and number of tool calls it makes. This teaches the agent how to orchestrate various tools to reach a correct conclusion.An example is Search-R1, an agent that performs multi-step retrieval to answer questions. The model receives a reward only if the final answer is correct, implicitly forcing it to learn better search and reasoning strategies to maximize that reward. A2 is ideal for system-level orchestration, enabling agents to handle complex workflows.T1: Agent-agnostic: In this category, tools are trained independently on broad data and then \"plugged in\" to a frozen agent. Think of classic dense retrievers used in RAG systems. A standard retriever model is trained on generic search data. A powerful frozen LLM can use this retriever to find information, even though the retriever wasn&#x27;t designed specifically for that LLM.T2: Agent-supervised: This strategy involves training tools specifically to serve a frozen agent. The supervision signal comes from the agent’s own output, creating a symbiotic relationship where the tool learns to provide exactly what the agent needs.For example, the s3 framework trains a small \"searcher\" model to retrieve documents. This small model is rewarded based on whether a frozen \"reasoner\" (a large LLM) can answer the question correctly using those documents. The tool effectively adapts to fill the specific knowledge gaps of the main agent.Complex AI systems might use a combination of these adaptation paradigms. For example, a deep research system might employ T1-style retrieval tools (pre-trained dense retrievers), T2-style adaptive search agents (trained via frozen LLM feedback), and A1-style reasoning agents (fine-tuned with execution feedback) in a broader orchestrated system.The hidden costs and tradeoffsFor enterprise decision-makers, choosing between these strategies often comes down to three factors: cost, generalization, and modularity.Cost vs. flexibility: Agent adaptation (A1/A2) offers maximum flexibility because you are rewiring the agent&#x27;s brain. However, the costs are steep. For instance, Search-R1 (an A2 system) required training on 170,000 examples to internalize search capabilities. This requires massive compute and specialized datasets. On the other hand, the models can be much more efficient at inference time because they are much smaller than generalist models.In contrast, Tool adaptation (T1/T2) is far more efficient. The s3 system (T2) trained a lightweight searcher using only 2,400 examples (roughly 70 times less data than Search-R1) while achieving comparable performance. By optimizing the ecosystem rather than the agent, enterprises can achieve high performance at a lower cost. However, this comes with an overhead cost inference time since s3 requires coordination with a larger model.Generalization: A1 and A2 methods risk \"overfitting,\" where an agent becomes so specialized in one task that it loses general capabilities. The study found that while Search-R1 excelled at its training tasks, it struggled with specialized medical QA, achieving only 71.8% accuracy. This is not a problem when your agent is designed to perform a very specific set of tasks. Conversely, the s3 system (T2), which used a general-purpose frozen agent assisted by a trained tool, generalized better, achieving 76.6% accuracy on the same medical tasks. The frozen agent retained its broad world knowledge, while the tool handled the specific retrieval mechanics. However, T1/T2 systems rely on the knowledge of the frozen agent, and if the underlying model can’t handle the specific task, they will be useless. Modularity: T1/T2 strategies enable \"hot-swapping.\" You can upgrade a memory module or a searcher without touching the core reasoning engine. For example, Memento optimizes a memory module to retrieve past cases; if requirements change, you update the module, not the planner.A1 and A2 systems are monolithic. Teaching an agent a new skill (like coding) via fine-tuning can cause \"catastrophic forgetting,\" where it degrades on previously learned skills (like math) because its internal weights are overwritten.A strategic framework for enterprise adoptionBased on the study, developers should view these strategies as a progressive ladder, moving from low-risk, modular solutions to high-resource customization.Start with T1 (agent-agnostic tools): Equip a frozen, powerful model (like Gemini or Claude) with off-the-shelf tools such as a dense retriever or an MCP connector. This requires zero training and is perfect for prototyping and general applications. It is the low-hanging fruit that can take you very far for most tasks.Move to T2 (agent-supervised tools): If the agent struggles to use generic tools, don&#x27;t retrain the main model. Instead, train a small, specialized sub-agent (like a searcher or memory manager) to filter and format data exactly how the main agent likes it. This is highly data-efficient and suitable for proprietary enterprise data and applications that are high-volume and cost-sensitive.Use A1 (tool execution signaled) for specialization: If the agent fundamentally fails at technical tasks (e.g., writing non-functional code or wrong API calls) you must rewire its understanding of the tool&#x27;s \"mechanics.\" A1 is best for creating specialists in verifiable domains like SQL or Python or your proprietary tools. For example, you can optimize a small model for your specific toolset and then use it as a T1 plugin for a generalist model.Reserve A2 (agent output signaled) as the \"nuclear option\": Only train a monolithic agent end-to-end if you need it to internalize complex strategy and self-correction. This is resource-intensive and rarely necessary for standard enterprise applications. In reality, you rarely need to get involved in training your own model.As the AI landscape matures, the focus is shifting from building one giant, perfect model to constructing a smart ecosystem of specialized tools around a stable core. For most enterprises, the most effective path to agentic AI isn&#x27;t building a bigger brain but giving the brain better tools.",
          "content": "With the ecosystem of agentic tools and frameworks exploding in size, navigating the many options for building AI systems is becoming increasingly difficult, leaving developers confused and paralyzed when choosing the right tools and models for their applications.In a new study, researchers from multiple institutions present a comprehensive framework to untangle this complex web. They categorize agentic frameworks based on their area of focus and tradeoffs, providing a practical guide for developers to choose the right tools and strategies for their applications.For enterprise teams, this reframes agentic AI from a model-selection problem into an architectural decision about where to spend training budget, how much modularity to preserve, and what tradeoffs they’re willing to make between cost, flexibility, and risk.Agent vs. tool adaptationThe researchers divide the landscape into two primary dimensions: agent adaptation and tool adaptation.Agent adaptation involves modifying the foundation model that underlies the agentic system. This is done by updating the agent’s internal parameters or policies through methods like fine-tuning or reinforcement learning to better align with specific tasks.Tool adaptation, on the other hand, shifts the focus to the environment surrounding the agent. Instead of retraining the large, expensive foundation model, developers optimize the external tools such as search retrievers, memory modules, or sub-agents. In this strategy, the main agent remains \"frozen\" (unchanged). This approach allows the system to evolve without the massive computational cost of retraining the core model.The study further breaks these down into four distinct strategies:A1: Tool execution signaled: In this strategy, the agent learns by doing. It is optimized using verifiable feedback directly from a tool&#x27;s execution, such as a code compiler interacting with a script or a database returning search results. This teaches the agent the \"mechanics\" of using a tool correctly.A prime example is DeepSeek-R1, where the model was trained through reinforcement learning with verifiable rewards to generate code that successfully executes in a sandbox. The feedback signal is binary and objective (did the code run, or did it crash?). This method builds strong low-level competence in stable, verifiable domains like coding or SQL.A2: Agent output Signaled: Here, the agent is optimized based on the quality of its final answer, regardless of the intermediate steps and number of tool calls it makes. This teaches the agent how to orchestrate various tools to reach a correct conclusion.An example is Search-R1, an agent that performs multi-step retrieval to answer questions. The model receives a reward only if the final answer is correct, implicitly forcing it to learn better search and reasoning strategies to maximize that reward. A2 is ideal for system-level orchestration, enabling agents to handle complex workflows.T1: Agent-agnostic: In this category, tools are trained independently on broad data and then \"plugged in\" to a frozen agent. Think of classic dense retrievers used in RAG systems. A standard retriever model is trained on generic search data. A powerful frozen LLM can use this retriever to find information, even though the retriever wasn&#x27;t designed specifically for that LLM.T2: Agent-supervised: This strategy involves training tools specifically to serve a frozen agent. The supervision signal comes from the agent’s own output, creating a symbiotic relationship where the tool learns to provide exactly what the agent needs.For example, the s3 framework trains a small \"searcher\" model to retrieve documents. This small model is rewarded based on whether a frozen \"reasoner\" (a large LLM) can answer the question correctly using those documents. The tool effectively adapts to fill the specific knowledge gaps of the main agent.Complex AI systems might use a combination of these adaptation paradigms. For example, a deep research system might employ T1-style retrieval tools (pre-trained dense retrievers), T2-style adaptive search agents (trained via frozen LLM feedback), and A1-style reasoning agents (fine-tuned with execution feedback) in a broader orchestrated system.The hidden costs and tradeoffsFor enterprise decision-makers, choosing between these strategies often comes down to three factors: cost, generalization, and modularity.Cost vs. flexibility: Agent adaptation (A1/A2) offers maximum flexibility because you are rewiring the agent&#x27;s brain. However, the costs are steep. For instance, Search-R1 (an A2 system) required training on 170,000 examples to internalize search capabilities. This requires massive compute and specialized datasets. On the other hand, the models can be much more efficient at inference time because they are much smaller than generalist models.In contrast, Tool adaptation (T1/T2) is far more efficient. The s3 system (T2) trained a lightweight searcher using only 2,400 examples (roughly 70 times less data than Search-R1) while achieving comparable performance. By optimizing the ecosystem rather than the agent, enterprises can achieve high performance at a lower cost. However, this comes with an overhead cost inference time since s3 requires coordination with a larger model.Generalization: A1 and A2 methods risk \"overfitting,\" where an agent becomes so specialized in one task that it loses general capabilities. The study found that while Search-R1 excelled at its training tasks, it struggled with specialized medical QA, achieving only 71.8% accuracy. This is not a problem when your agent is designed to perform a very specific set of tasks. Conversely, the s3 system (T2), which used a general-purpose frozen agent assisted by a trained tool, generalized better, achieving 76.6% accuracy on the same medical tasks. The frozen agent retained its broad world knowledge, while the tool handled the specific retrieval mechanics. However, T1/T2 systems rely on the knowledge of the frozen agent, and if the underlying model can’t handle the specific task, they will be useless. Modularity: T1/T2 strategies enable \"hot-swapping.\" You can upgrade a memory module or a searcher without touching the core reasoning engine. For example, Memento optimizes a memory module to retrieve past cases; if requirements change, you update the module, not the planner.A1 and A2 systems are monolithic. Teaching an agent a new skill (like coding) via fine-tuning can cause \"catastrophic forgetting,\" where it degrades on previously learned skills (like math) because its internal weights are overwritten.A strategic framework for enterprise adoptionBased on the study, developers should view these strategies as a progressive ladder, moving from low-risk, modular solutions to high-resource customization.Start with T1 (agent-agnostic tools): Equip a frozen, powerful model (like Gemini or Claude) with off-the-shelf tools such as a dense retriever or an MCP connector. This requires zero training and is perfect for prototyping and general applications. It is the low-hanging fruit that can take you very far for most tasks.Move to T2 (agent-supervised tools): If the agent struggles to use generic tools, don&#x27;t retrain the main model. Instead, train a small, specialized sub-agent (like a searcher or memory manager) to filter and format data exactly how the main agent likes it. This is highly data-efficient and suitable for proprietary enterprise data and applications that are high-volume and cost-sensitive.Use A1 (tool execution signaled) for specialization: If the agent fundamentally fails at technical tasks (e.g., writing non-functional code or wrong API calls) you must rewire its understanding of the tool&#x27;s \"mechanics.\" A1 is best for creating specialists in verifiable domains like SQL or Python or your proprietary tools. For example, you can optimize a small model for your specific toolset and then use it as a T1 plugin for a generalist model.Reserve A2 (agent output signaled) as the \"nuclear option\": Only train a monolithic agent end-to-end if you need it to internalize complex strategy and self-correction. This is resource-intensive and rarely necessary for standard enterprise applications. In reality, you rarely need to get involved in training your own model.As the AI landscape matures, the focus is shifting from building one giant, perfect model to constructing a smart ecosystem of specialized tools around a stable core. For most enterprises, the most effective path to agentic AI isn&#x27;t building a bigger brain but giving the brain better tools.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/53m6rZtTh6hIfzAH13MKNV/89e1099161b1bb44ed708399eb1e06fb/Agentic_adaptation_strategies.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/inside-microsoft-ignite-how-microsoft-and-nvidia-are-redefining-the-ai-stack",
          "published_at": "Mon, 29 Dec 2025 05:00:00 GMT",
          "title": "Inside Microsoft Ignite: How Microsoft and NVIDIA are redefining the AI stack",
          "standfirst": "Presented by Microsoft and NVIDIAAs the world’s leading platform providers and champions for advancing AI globally, NVIDIA and Microsoft continue to deliver unequaled value for organizations investing in and deploying AI. The companies’ collaborative efforts at the 2025 Microsoft Ignite conference offered tangible proof, introducing practitioners and decision-makers to new and expanded AI infrastructure and cloud solutions for accelerating enterprise transformation and real-world impact with AI agents.IT and business leaders across industries gathered at Microsoft Ignite, November 18 to 21 in San Francisco. The theme for this year’s conference centered on accelerating success with AI, with a strong topical focus around developing and scaling agentic and physical AI and digital twins. NVIDIA and Microsoft event presence underscored the expansive nature of their collaboration, from silicon to services, as attendees experienced first-hand the full-stack AI solutions now available and heard exciting announcements on new integrations and expanded partnership solutions.NVIDIA sessions from Microsoft Ignite — available on demandLearning sessions at Microsoft Ignite are tailored each year to deliver timely technical and strategic insights for attendees across roles. In-depth learning on the powerful integrations between Microsoft Azure and the NVIDIA platform made up a sizable quotient of this year’s catalog, with over 40 sessions highlighting NVIDIA solutions and capabilities. Now, 15 of these sessions are available on demand for a limited time.Available sessions cover many of the latest integrations available from NVIDIA and Microsoft Azure — some so recent as to be announced during the event. For in-person session attendees and post-event viewers leveraging the on-demand catalog, NVIDIA’s and Microsoft’s presentations during Microsoft Ignite engage customers with the most up-to-date information on what they can get from Microsoft Azure, with NVIDIA integrations to power and elevate their AI journeys. Integrations for next-generation AI NVIDIA Blackwell powers Azure NCv6 for accelerating complex AI workloadsNVIDIA continues to evolve its Blackwell platform for the AI era as a new NVIDIA Blackwell platform expansion brings the new Azure NCv6 Series Virtual Machines with NVIDIA RTX PRO 6000 Blackwell GPUs into public preview. This expansion allows the Blackwell platform to right-size acceleration for converged AI and visual computing workloads spanning digital twins and NVIDIA Omniverse simulation, agentic AI, 3D rendering, LLM inference and retrieval-augmented generation (RAG) on small-to-medium models, and scientific visualization. Ultimately, this solution offers customers a seamless upgrade path, enabling Blackwell performance that supports complex AI tasks with greater efficiency. NVIDIA Omniverse libraries are also now available on Microsoft Azure. These solutions, together with Azure Local for deployment, create unparalleled flexibility and unification from edge to cloud for enterprises looking to develop, deploy, and manage innovative AI solutions for transforming industrial workflows. NVIDIA Omniverse technology on Azure featured heavily at Ignite — NVIDIA, Microsoft, and Ansys convened for the session “Transform manufacturing with digital twins and real-time simulation,” available now on demand, discussing how Omniverse, along with other NVIDIA solutions on Azure, helps accelerate time to insight and optimize manufacturing processes. For more on NVIDIA Blackwell architecture integration with Microsoft Azure and purpose-built capabilities for a wide range of use cases, watch the on-demand session “Power next-generation AI workloads with NVIDIA Blackwell on Azure.” Learn about benefits in cost and energy efficiency, innovative developer tools from NVIDIA, and case studies showcasing the powerful synergy between NVIDIA and Microsoft Azure for customers. You can also watch Microsoft’s session “What’s new in Azure Local” to learn more about integration with NVIDIA RTX PRO 6000 GPUs for computing at the edge.Microsoft Agent 365 with NVIDIA NeMo Agent Toolkit elevates agentic AI utility As agentic AI’s prominence in the workplace continues to grow, Microsoft and NVIDIA are elevating the utility of workplace agents with integration between the NVIDIA NeMo Agent Toolkit and Microsoft Agent 365. This integration allows developers to create and deliver compliant, secure, and tailored workplace agents across Microsoft 365 productivity apps including Outlook, Teams, Word, and SharePoint, empowering customers with tailored agents built to meet their organizations’ unique needs. Microsoft Foundry has also made NVIDIA Nemotron models available as secure NVIDIA NIM microservices to power these new enterprise agents and other digital AI. NVIDIA Cosmos models are available for powering physical AI. These models will enable developers to build enterprise-grade agents with capabilities spanning multimodal intelligence and multilingual reasoning, math, coding, and more.More on NVIDIA’s enterprise strategy and core technologies enabling the promise of agentic AI is available in the NVIDIA Ignite presentation “From prompt to production: Scale agentic AI with NVIDIA and Azure.” Solutions covered include NVIDIA NIM microservices, NVIDIA NeMo Agent Toolkit, NVIDIA CUDA libraries, and the Nemotron model family.SQL Server integrations enable AI-ready enterprise databasesNVIDIA and Microsoft integrations also offer a new solution for building scalable AI on enterprise data. SQL Server 2025 now connects with NVIDIA Nemotron RAG models deployed as NVIDIA NIM microservices. With this integration, customers can streamline AI deployment, overcoming major hurdles in data volumes, data privacy, and security and avoiding the bottlenecks associated with traditional CPU infrastructure.With GPU-accelerated RAG workflows implemented on Azure Cloud or Azure Local, organizations can build high-performance, secure AI applications wherever their data lives, whether in the cloud or on-premises — while preserving full data sovereignty. This integration makes it easy to bring AI directly to the data, without the complexity of managing data pipelines.Watch NVIDIA sessions from Microsoft Ignite nowLearn more about the integrations between NVIDIA and Microsoft technologies and see how frontier firms are driving success with real-world AI use cases. Explore these topics further in the many additional on-demand NVIDIA sessions available from Microsoft Ignite. Topics include agentic AI, robotics simulation, and infrastructure for AI workloads. These sessions will only be available for a limited time, so watch the presentations that match your interests now.Browse available sessions in the catalog here. Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Microsoft and NVIDIAAs the world’s leading platform providers and champions for advancing AI globally, NVIDIA and Microsoft continue to deliver unequaled value for organizations investing in and deploying AI. The companies’ collaborative efforts at the 2025 Microsoft Ignite conference offered tangible proof, introducing practitioners and decision-makers to new and expanded AI infrastructure and cloud solutions for accelerating enterprise transformation and real-world impact with AI agents.IT and business leaders across industries gathered at Microsoft Ignite, November 18 to 21 in San Francisco. The theme for this year’s conference centered on accelerating success with AI, with a strong topical focus around developing and scaling agentic and physical AI and digital twins. NVIDIA and Microsoft event presence underscored the expansive nature of their collaboration, from silicon to services, as attendees experienced first-hand the full-stack AI solutions now available and heard exciting announcements on new integrations and expanded partnership solutions.NVIDIA sessions from Microsoft Ignite — available on demandLearning sessions at Microsoft Ignite are tailored each year to deliver timely technical and strategic insights for attendees across roles. In-depth learning on the powerful integrations between Microsoft Azure and the NVIDIA platform made up a sizable quotient of this year’s catalog, with over 40 sessions highlighting NVIDIA solutions and capabilities. Now, 15 of these sessions are available on demand for a limited time.Available sessions cover many of the latest integrations available from NVIDIA and Microsoft Azure — some so recent as to be announced during the event. For in-person session attendees and post-event viewers leveraging the on-demand catalog, NVIDIA’s and Microsoft’s presentations during Microsoft Ignite engage customers with the most up-to-date information on what they can get from Microsoft Azure, with NVIDIA integrations to power and elevate their AI journeys. Integrations for next-generation AI NVIDIA Blackwell powers Azure NCv6 for accelerating complex AI workloadsNVIDIA continues to evolve its Blackwell platform for the AI era as a new NVIDIA Blackwell platform expansion brings the new Azure NCv6 Series Virtual Machines with NVIDIA RTX PRO 6000 Blackwell GPUs into public preview. This expansion allows the Blackwell platform to right-size acceleration for converged AI and visual computing workloads spanning digital twins and NVIDIA Omniverse simulation, agentic AI, 3D rendering, LLM inference and retrieval-augmented generation (RAG) on small-to-medium models, and scientific visualization. Ultimately, this solution offers customers a seamless upgrade path, enabling Blackwell performance that supports complex AI tasks with greater efficiency. NVIDIA Omniverse libraries are also now available on Microsoft Azure. These solutions, together with Azure Local for deployment, create unparalleled flexibility and unification from edge to cloud for enterprises looking to develop, deploy, and manage innovative AI solutions for transforming industrial workflows. NVIDIA Omniverse technology on Azure featured heavily at Ignite — NVIDIA, Microsoft, and Ansys convened for the session “Transform manufacturing with digital twins and real-time simulation,” available now on demand, discussing how Omniverse, along with other NVIDIA solutions on Azure, helps accelerate time to insight and optimize manufacturing processes. For more on NVIDIA Blackwell architecture integration with Microsoft Azure and purpose-built capabilities for a wide range of use cases, watch the on-demand session “Power next-generation AI workloads with NVIDIA Blackwell on Azure.” Learn about benefits in cost and energy efficiency, innovative developer tools from NVIDIA, and case studies showcasing the powerful synergy between NVIDIA and Microsoft Azure for customers. You can also watch Microsoft’s session “What’s new in Azure Local” to learn more about integration with NVIDIA RTX PRO 6000 GPUs for computing at the edge.Microsoft Agent 365 with NVIDIA NeMo Agent Toolkit elevates agentic AI utility As agentic AI’s prominence in the workplace continues to grow, Microsoft and NVIDIA are elevating the utility of workplace agents with integration between the NVIDIA NeMo Agent Toolkit and Microsoft Agent 365. This integration allows developers to create and deliver compliant, secure, and tailored workplace agents across Microsoft 365 productivity apps including Outlook, Teams, Word, and SharePoint, empowering customers with tailored agents built to meet their organizations’ unique needs. Microsoft Foundry has also made NVIDIA Nemotron models available as secure NVIDIA NIM microservices to power these new enterprise agents and other digital AI. NVIDIA Cosmos models are available for powering physical AI. These models will enable developers to build enterprise-grade agents with capabilities spanning multimodal intelligence and multilingual reasoning, math, coding, and more.More on NVIDIA’s enterprise strategy and core technologies enabling the promise of agentic AI is available in the NVIDIA Ignite presentation “From prompt to production: Scale agentic AI with NVIDIA and Azure.” Solutions covered include NVIDIA NIM microservices, NVIDIA NeMo Agent Toolkit, NVIDIA CUDA libraries, and the Nemotron model family.SQL Server integrations enable AI-ready enterprise databasesNVIDIA and Microsoft integrations also offer a new solution for building scalable AI on enterprise data. SQL Server 2025 now connects with NVIDIA Nemotron RAG models deployed as NVIDIA NIM microservices. With this integration, customers can streamline AI deployment, overcoming major hurdles in data volumes, data privacy, and security and avoiding the bottlenecks associated with traditional CPU infrastructure.With GPU-accelerated RAG workflows implemented on Azure Cloud or Azure Local, organizations can build high-performance, secure AI applications wherever their data lives, whether in the cloud or on-premises — while preserving full data sovereignty. This integration makes it easy to bring AI directly to the data, without the complexity of managing data pipelines.Watch NVIDIA sessions from Microsoft Ignite nowLearn more about the integrations between NVIDIA and Microsoft technologies and see how frontier firms are driving success with real-world AI use cases. Explore these topics further in the many additional on-demand NVIDIA sessions available from Microsoft Ignite. Topics include agentic AI, robotics simulation, and infrastructure for AI workloads. These sessions will only be available for a limited time, so watch the presentations that match your interests now.Browse available sessions in the catalog here. Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5saN39AIaBHdzXvxzFIskd/a47daf35dddd9da13b6afea6cfb1c803/VB-NVIDIA-Ignite-Article-D-updated.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2023-02/c9a24a20-b7a0-11ed-b3cd-16d5d607f8d1",
      "popularity_score": 2016.7707330555556
    },
    {
      "id": "cluster_52",
      "coverage": 2,
      "updated_at": "Mon, 29 Dec 2025 13:05:00 GMT",
      "title": "You may finally be able to fix your embarrassing Gmail address - here's how",
      "neutral_headline": "You may finally be able to fix your embarrassing Gmail address - here's how",
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/how-to-change-gmail-email-address/",
          "published_at": "Mon, 29 Dec 2025 13:05:00 GMT",
          "title": "You may finally be able to fix your embarrassing Gmail address - here's how",
          "standfirst": "Official documents indicate a long-awaited change might be coming.",
          "content": "Official documents indicate a long-awaited change might be coming.",
          "feed_position": 18
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/28/you-may-soon-be-able-to-change-your-gmail-address/",
          "published_at": "Sun, 28 Dec 2025 21:29:59 +0000",
          "title": "You may soon be able to change your Gmail address",
          "standfirst": "Good news for anyone tired of or embarrassed by their current Gmail address.",
          "content": "Good news for anyone tired of or embarrassed by their current Gmail address.",
          "feed_position": 10
        }
      ],
      "popularity_score": 2013.804066388889
    },
    {
      "id": "cluster_17",
      "coverage": 1,
      "updated_at": "Mon, 29 Dec 2025 16:30:45 +0000",
      "title": "China drafts world’s strictest rules to end AI-encouraged suicide, violence",
      "neutral_headline": "China drafts world’s strictest rules to end AI-encouraged suicide, violence",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/china-drafts-worlds-strictest-rules-to-end-ai-encouraged-suicide-violence/",
          "published_at": "Mon, 29 Dec 2025 16:30:45 +0000",
          "title": "China drafts world’s strictest rules to end AI-encouraged suicide, violence",
          "standfirst": "China wants a human to intervene and notify guardians if suicide is ever mentioned.",
          "content": "China drafted landmark rules to stop AI chatbots from emotionally manipulating users, including what could become the strictest policy worldwide intended to prevent AI-supported suicides, self-harm, and violence. China's Cyberspace Administration proposed the rules on Saturday. If finalized, they would apply to any AI products or services publicly available in China that use text, images, audio, video, or \"other means\" to simulate engaging human conversation. Winston Ma, adjunct professor at NYU School of Law, told CNBC that the \"planned rules would mark the world’s first attempt to regulate AI with human or anthropomorphic characteristics\" at a time when companion bot usage is rising globally. Growing awareness of problems In 2025, researchers flagged major harms of AI companions, including promotion of self-harm, violence, and terrorism. Beyond that, chatbots shared harmful misinformation, made unwanted sexual advances, encouraged substance abuse, and verbally abused users. Some psychiatrists are increasingly ready to link psychosis to chatbot use, the Wall Street Journal reported this weekend, while the most popular chatbot in the world, ChatGPT, has triggered lawsuits over outputs linked to child suicide and murder-suicide.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2175706470-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2175706470-1152x648.jpg",
      "popularity_score": 370.23323305555556
    },
    {
      "id": "cluster_2",
      "coverage": 1,
      "updated_at": "Mon, 29 Dec 2025 19:00:42 +0000",
      "title": "Researchers make “neuromorphic” artificial skin for robots",
      "neutral_headline": "Researchers make “neuromorphic” artificial skin for robots",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/science/2025/12/researchers-make-neuromorphic-artificial-skin-for-robots/",
          "published_at": "Mon, 29 Dec 2025 19:00:42 +0000",
          "title": "Researchers make “neuromorphic” artificial skin for robots",
          "standfirst": "Information from sensors is transmitted using neural-style activity spikes.",
          "content": "The nervous system does an astonishing job of tracking sensory information, and does so using signals that would drive many computer scientists insane: a noisy stream of activity spikes that may be transmitted to hundreds of additional neurons, where they are integrated with similar spike trains coming from still other neurons. Now, researchers have used spiking circuitry to build an artificial robotic skin, adopting some of the principles of how signals from our sensory neurons are transmitted and integrated. While the system relies on a few decidedly not-neural features, it has the advantage that we have chips that can run neural networks using spiking signals, which would allow this system to integrate smoothly with some energy-efficient hardware to run AI-based control software. Location via spikes The nervous system in our skin is remarkably complex. It has specialized sensors for different sensations: heat, cold, pressure, pain, and more. In most areas of the body, these feed into the spinal column, where some preliminary processing takes place, allowing reflex reactions to be triggered without even involving the brain. But signals do make their way along specialized neurons into the brain, allowing further processing and (potentially) conscious awareness.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1179602916-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1179602916-1152x648.jpg",
      "popularity_score": 352.7323997222222
    },
    {
      "id": "cluster_25",
      "coverage": 1,
      "updated_at": "Mon, 29 Dec 2025 15:30:52 +0000",
      "title": "A quirky guide to myths and lore based in actual science",
      "neutral_headline": "A quirky guide to myths and lore based in actual science",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/a-quirky-guide-to-myths-and-lore-based-in-actual-science/",
          "published_at": "Mon, 29 Dec 2025 15:30:52 +0000",
          "title": "A quirky guide to myths and lore based in actual science",
          "standfirst": "Folklorist/historian Adrienne Mayor on her new book Mythopedia: A Brief Compendium of Natural History Lore",
          "content": "Earthquakes, volcanic eruption, eclipses, meteor showers, and many other natural phenomena have always been part of life on Earth. In ancient cultures that predated science, such events were often memorialized in myths and legends. There is a growing body of research that strives to connect those ancient stories with the real natural events that inspired them. Folklorist and historian Adrienne Mayor has put together a fascinating short compendium of such insights with Mythopedia: A Brief Compendium of Natural History Lore, from dry quicksand and rains of frogs to burning lakes, paleoburrows, and Scandinavian \"endless winters.\" Mayor's work has long straddled multiple disciplines, but one of her specialities is best described as geomythology, a term coined in 1968 by Indiana University geologist Dorothy Vitaliano, who was interested in classical legends about Atlantis and other civilizations that were lost due to natural disasters. Her interest resulted in Vitaliano's 1973 book Legends of the Earth: Their Geologic Origins. Mayor herself became interested in the field when she came across Greek and Roman descriptions of fossils, and that interest expanded over the years to incorporate other examples of \"folk science\" in cultures around the world. Her books include The Poison King: The Life and Legend of Mithradates, Rome's Deadliest Enemy (2009), as well as Greek Fire, Poison Arrows, & the Scorpion Bombs (2022), exploring the origins of biological and chemical warfare. Her 2018 book, Gods and Robots: Myths, Machines, and Ancient Dreams of Technology, explored ancient myths and folklore about creating automation, artificial life, and AI, connecting them to the robots and other ingenious mechanical devices actually designed and built during that era.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/myth1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/myth1-1152x648.jpg",
      "popularity_score": 339.2351775
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Mon, 29 Dec 2025 15:10:16 +0000",
      "title": "GPS is vulnerable to jamming—here’s how we might fix it",
      "neutral_headline": "GPS is vulnerable to jamming—here’s how we might fix it",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2025/12/gps-is-vulnerable-to-jamming-heres-how-we-might-fix-it/",
          "published_at": "Mon, 29 Dec 2025 15:10:16 +0000",
          "title": "GPS is vulnerable to jamming—here’s how we might fix it",
          "standfirst": "GPS jamming has gotten cheap and easy, but there are potential solutions.",
          "content": "In September 2025, a Widerøe Airlines flight was trying to land in Vardø, Norway, which sits in the country’s far eastern arm, some 40 miles from the Russian coast. The cloud deck was low, and so was visibility. In such gray situations, pilots use GPS technology to help them land on a runway and not the side of a mountain. But on this day, GPS systems weren’t working correctly, the airwaves jammed with signals that prevented airplanes from accessing navigation information. The Widerøe flight had taken off during one of Russia’s frequent wargames, in which the country’s military simulates conflict as a preparation exercise. This one involved an imaginary war with a country. It was nicknamed Zapad-2025—translating to “West-2025”—and was happening just across the fjord from Vardø. According to European officials, GPS interference was frequent in the runup to the exercise. Russian forces, they suspected, were using GPS-signal-smashing technology, a tactic used in non-pretend conflict, too. (Russia has denied some allegations of GPS interference in the past.) Without that guidance from space, and with the cloudy weather, the Widerøe plane had to abort its landing and continue down the coast away from Russia, to Båtsfjord, a fishing village.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1316617936-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1316617936-1152x648.jpg",
      "popularity_score": 328.89184416666666
    },
    {
      "id": "cluster_53",
      "coverage": 1,
      "updated_at": "Mon, 29 Dec 2025 13:00:01 +0000",
      "title": "Remembering what Windows 10 did right—and how it made modern Windows more annoying",
      "neutral_headline": "Remembering what Windows 10 did right—and how it made modern Windows more annoying",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/remembering-the-best-and-worst-about-windows-10-on-the-year-it-technically-died/",
          "published_at": "Mon, 29 Dec 2025 13:00:01 +0000",
          "title": "Remembering what Windows 10 did right—and how it made modern Windows more annoying",
          "standfirst": "Remembering Windows 10's rollout can help diagnose what ails Windows 11.",
          "content": "If you've been following our coverage for the last few years, you'll already know that 2025 is the year that Windows 10 died. Technically. \"Died,\" because Microsoft's formal end-of-support date came and went on October 14, as the company had been saying for years. \"Technically,\" because it's trivial for home users to get another free year of security updates with a few minutes of effort, and schools and businesses can get an additional two years of updates on top of that, and because load-bearing system apps like Edge and Windows Defender will keep getting updates through at least 2028 regardless. But 2025 was undoubtedly a tipping point for the so-called \"last version of Windows.\" StatCounter data says Windows 11 has overtaken Windows 10 as the most-used version of Windows both in the US (February 2025) and worldwide (July 2025). Its market share slid from just over 44 percent to just under 31 percent in the Steam Hardware Survey. And now that Microsoft's support for the OS has formally ended, games, apps, and drivers are already beginning the gradual process of ending or scaling back official Windows 10 support.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/10/win10-wallpaper-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/10/win10-wallpaper-1152x648.jpg",
      "popularity_score": 316.7210108333333
    },
    {
      "id": "cluster_57",
      "coverage": 1,
      "updated_at": "Mon, 29 Dec 2025 12:45:50 +0000",
      "title": "I switched to eSIM in 2025, and I am full of regret",
      "neutral_headline": "I switched to eSIM in 2025, and I am full of regret",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/i-switched-to-esim-in-2025-and-i-am-full-of-regret/",
          "published_at": "Mon, 29 Dec 2025 12:45:50 +0000",
          "title": "I switched to eSIM in 2025, and I am full of regret",
          "standfirst": "Swapping SIM cards used to be easy, and then came eSIM.",
          "content": "SIM cards, the small slips of plastic that have held your mobile subscriber information since time immemorial, are on the verge of extinction. In an effort to save space for other components, device makers are finally dropping the SIM slot, and Google is the latest to move to embedded SIMs with the Pixel 10 series. After long avoiding eSIM, I had no choice but to take the plunge when the time came to review Google's new phones. And boy, do I regret it. The journey to eSIM SIM cards have existed in some form since the '90s. Back then, they were credit card-sized chunks of plastic that occupied a lot of space inside the clunky phones of the era. They slimmed down over time, going through the miniSIM, microSIM, and finally nanoSIM eras. A modern nanoSIM is about the size of your pinky nail, but space is at a premium inside smartphones. Enter, eSIM. The eSIM standard was introduced in 2016, slowly gaining support as a secondary option in smartphones. Rather than holding your phone number on a removable card, an eSIM is a programmable, non-removable component soldered to the circuit board. This allows you to store multiple SIMs and swap between them in software, and no one can swipe your SIM card from the phone. They also take up half as much space compared to a removable card, which is why OEMs have begun dropping the physical slot.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/nanoSIM-card-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/nanoSIM-card-1152x648.jpg",
      "popularity_score": 306.4846219444444
    },
    {
      "id": "cluster_61",
      "coverage": 1,
      "updated_at": "Mon, 29 Dec 2025 12:00:29 +0000",
      "title": "Big Tech basically took Trump’s unpredictable trade war lying down",
      "neutral_headline": "Big Tech basically took Trump’s unpredictable trade war lying down",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/big-tech-basically-took-trumps-unpredictable-trade-war-lying-down/",
          "published_at": "Mon, 29 Dec 2025 12:00:29 +0000",
          "title": "Big Tech basically took Trump’s unpredictable trade war lying down",
          "standfirst": "From Apple gifting a gold statue to the US taking a stake in Intel.",
          "content": "As the first year of Donald Trump's chaotic trade war winds down, the tech industry is stuck scratching its head, with no practical way to anticipate what twists and turns to expect in 2026. Tech companies may have already grown numb to Trump's unpredictable moves. Back in February, Trump warned Americans to expect \"a little pain\" after he issued executive orders imposing 10–25 percent tariffs on imports from America’s biggest trading partners, including Canada, China, and Mexico. Immediately, industry associations sounded the alarm, warning that the costs of consumer tech could increase significantly. By April, Trump had ordered tariffs on all US trade partners to correct claimed trade deficits, using odd math that critics suspected came from a chatbot. (Those tariffs bizarrely targeted uninhabited islands that exported nothing and were populated by penguins.) Costs of tariffs only got higher as the year wore on. But the tech industry has done very little to push back against them. Instead, some of the biggest companies made their own surprising moves after Trump's trade war put them in deeply uncomfortable positions.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/trump-tariffs-triton-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/trump-tariffs-triton-1152x648.jpg",
      "popularity_score": 295.7287886111111
    }
  ]
}