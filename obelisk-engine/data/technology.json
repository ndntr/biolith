{
  "updated_at": "2025-10-21T19:16:48.412Z",
  "clusters": [
    {
      "id": "cluster_2",
      "coverage": 3,
      "updated_at": "Tue, 21 Oct 2025 19:06:41 +0000",
      "title": "OpenAI's Atlas Browser Takes Direct Aim at Google Chrome",
      "neutral_headline": "OpenAI's Atlas Browser Takes Direct Aim at Google Chrome",
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/openai-atlas-browser-chrome-agents-web-browsing/",
          "published_at": "Tue, 21 Oct 2025 19:06:41 +0000",
          "title": "OpenAI's Atlas Browser Takes Direct Aim at Google Chrome",
          "standfirst": "The new ChatGPT-powered web browser is OpenAI's boldest play yet to reinvent how people use the web.",
          "content": "The new ChatGPT-powered web browser is OpenAI's boldest play yet to reinvent how people use the web.",
          "feed_position": 0,
          "image_url": "https://media.wired.com/photos/68f7cbcc6fc0dea09153cfd9/master/pass/business_openai_browser.jpg"
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/is-openais-atlas-browser-the-chrome-killer-weve-been-waiting-for-try-it-for-yourself/",
          "published_at": "Tue, 21 Oct 2025 18:10:00 GMT",
          "title": "Is OpenAI's Atlas browser the Chrome killer we've been waiting for? Try it for yourself",
          "standfirst": "Here's everything OpenAI's ChatGPT-powered browser can do, and how to access it.",
          "content": "Here's everything OpenAI's ChatGPT-powered browser can do, and how to access it.",
          "feed_position": 3
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/21/openai-launches-an-ai-powered-browser-chatgpt-atlas/",
          "published_at": "Tue, 21 Oct 2025 17:15:40 +0000",
          "title": "OpenAI launches an AI-powered browser: ChatGPT Atlas",
          "standfirst": "OpenAI is launching an AI-powered browser, its latest challenge to Google as the main way people find information online.",
          "content": "OpenAI is launching an AI-powered browser, its latest challenge to Google as the main way people find information online.",
          "feed_position": 5
        }
      ],
      "featured_image": "https://media.wired.com/photos/68f7cbcc6fc0dea09153cfd9/master/pass/business_openai_browser.jpg",
      "popularity_score": 3019.8312744444443,
      "ai_summary": [
        "OpenAI is launching a new web browser called Atlas.",
        "The browser is powered by ChatGPT.",
        "It aims to change how people use the internet.",
        "OpenAI's move challenges Google's dominance.",
        "The browser is OpenAI's latest innovation."
      ]
    },
    {
      "id": "cluster_20",
      "coverage": 2,
      "updated_at": "Tue, 21 Oct 2025 18:32:00 GMT",
      "title": "Qwen's new Deep Research update lets you turn its reports into webpages, podcasts in seconds",
      "neutral_headline": "Alibaba's Qwen AI tool adds webpage and podcast features",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/qwens-new-deep-research-update-lets-you-turn-its-reports-into-webpages",
          "published_at": "Tue, 21 Oct 2025 18:32:00 GMT",
          "title": "Qwen's new Deep Research update lets you turn its reports into webpages, podcasts in seconds",
          "standfirst": "Chinese e-commerce giant Alibaba’s famously prolific Qwen Team of AI model researchers and engineers has introduced a major expansion to its Qwen Deep Research tool, which is available as an optional modality the user can activate on the web-based Qwen Chat (a competitor to ChatGPT).The update lets users generate not only comprehensive research reports with well-organized citations, but also interactive web pages and multi-speaker podcasts — all within 1-2 clicks.This functionality is part of a proprietary release, distinct from many of Qwen’s previous open-source model offerings. While the feature relies on the open-source models Qwen3-Coder, Qwen-Image, and Qwen3-TTS to power its core capabilities, the end-to-end experience — including research execution, web deployment, and audio generation — is hosted and operated by Qwen. This means users benefit from a managed, integrated workflow without needing to configure infrastructure. That said, developers with access to the open-source models could theoretically replicate similar functionality on private or commercial systems.The update was announced via the team’s official X account (@Alibaba_Qwen) today, October 21, 2025, stating:“Qwen Deep Research just got a major upgrade. It now creates not only the report, but also a live webpage and a podcast — powered by Qwen3-Coder, Qwen-Image, and Qwen3-TTS. Your insights, now visual and audible.”Multi-Format Research OutputThe core workflow begins with a user request inside the Qwen Chat interface. From there, Qwen collaborates by asking clarifying questions to shape the research scope, pulls data from the web and official sources, and analyzes or resolves any inconsistencies it finds — even generating custom code when needed.A demo video posted by Qwen on X walks through this process on Qwen Chat using the U.S. SaaS market as an example. In it, Qwen retrieves data from multiple industry sources, identifies discrepancies in market size estimates (e.g., $206 billion vs. $253 billion), and highlights ambiguities in the U.S. share of global figures. The assistant comments on differences in scope between sources and calculates a compound annual growth rate (CAGR) of 19.8% from 2020 to 2023, providing contextual analysis to back up the raw numbers.Once the research is complete, users can click on the \"eyeball\" icon below the output result (see screenshot), which will bring up a PDF-style report in the right hand pane.Then, when viewing the report in the right-hand pane, the user can click the \"Create\" button in the upper-right hand corner and select from the following two options:\"Web Dev\" which produces a live, professional-grade web page, automatically deployed and hosted by Qwen, using Qwen3-Coder for structure and Qwen-Image for visuals.\"Podcast,\" which, as it states, produces an audio podcast, featuring dynamic, multi-speaker narration generated by Qwen3-TTS, also hosted by Qwen for easy sharing and playback.This enables users to quickly convert a single research project into multiple forms of content — written, visual, and audible — with minimal extra input.The website includes inline graphics generated by Qwen Image, making it suitable for use in public presentations, classrooms, or publishing. The podcast feature allows users to select between 17 different speaker names as the host and 7 as the co-host, though I wasn&#x27;t able to find a way to preview the voice outputs before selecting them. It appears designed for deep listening on the go. There was no way to change the language output that I could see, so mine came out in English, like my reports and initial prompts, though the Qwen LLMs are multi-modal. The voices were slightly more robotic than other AI tools I&#x27;ve used.Here&#x27;s an example of a web page I generated on commonalities in authoritarian regimes throughout history, another one on UFO or UAP sightings, and below this paragraph, a podcast on UFO or UAP sightings. While the website is hosted via a public link, the podcast must be downloaded by the user and can&#x27;t be linked to publicly, from what I could tell in my brief usage so far.Note the podcast is much different than the actual report — not just a straight read-through audio version of it, rather, a new format of two hosts discussing and bantering about the subject using the report as the jumping off point. The web page versions of the report also include new graphics not found in the PDF report.Comparisons to Google&#x27;s NotebookLMWhile the new capabilities have been well received by many early users, comparisons to other research assistants have surfaced — particularly Google’s NotebookLM, which recently exited beta.AI commentator and newsletter writer Chubby (@kimmonismus) noted on X:“I am really grateful that Qwen provides regular updates. That’s great.But the attempt to build a NotebookLM clone inside Qwen-3-max doesn’t sound very promising compared to Google’s version.”While NotebookLM is built around organizing and querying existing documents and web pages, Qwen Deep Research focuses more on generating new research content from scratch, aggregating sources from the open web, and presenting it across multiple modalities. The comparison suggests that while the two tools overlap in general concept — AI-assisted research — they diverge in approach and target user experience.AvailabilityQwen Deep Research is now live and available through the Qwen Chat app. The feature can be accessed with the following URL.No pricing details have been provided for Qwen3-Max or the specific Deep Research capabilities as of this writing.What&#x27;s Next For Qwen Deep Research?By combining research guidance, data analysis, and multi-format content creation into a single tool, Qwen Deep Research aims to streamline the path from idea to publishable output. The integration of code, visuals, and voice makes it especially attractive to content creators, educators, and independent analysts who want to scale their research into web- or podcast-friendly forms without switching platforms.Still, comparisons to more specialized offerings like NotebookLM raise questions about how Qwen’s generalized approach stacks up on depth, precision, and refinement. Whether the strength of its multi-format execution outweighs those concerns may come down to user priorities — and whether they value single-click publishing over tight integration with existing notes and materials.For now, Qwen is signaling that research doesn’t end with a document — it begins with one.Let me know if you want this repackaged into something shorter or tailored to a particular audience — newsletter, press-style blog, internal team explainer, etc.",
          "content": "Chinese e-commerce giant Alibaba’s famously prolific Qwen Team of AI model researchers and engineers has introduced a major expansion to its Qwen Deep Research tool, which is available as an optional modality the user can activate on the web-based Qwen Chat (a competitor to ChatGPT).The update lets users generate not only comprehensive research reports with well-organized citations, but also interactive web pages and multi-speaker podcasts — all within 1-2 clicks.This functionality is part of a proprietary release, distinct from many of Qwen’s previous open-source model offerings. While the feature relies on the open-source models Qwen3-Coder, Qwen-Image, and Qwen3-TTS to power its core capabilities, the end-to-end experience — including research execution, web deployment, and audio generation — is hosted and operated by Qwen. This means users benefit from a managed, integrated workflow without needing to configure infrastructure. That said, developers with access to the open-source models could theoretically replicate similar functionality on private or commercial systems.The update was announced via the team’s official X account (@Alibaba_Qwen) today, October 21, 2025, stating:“Qwen Deep Research just got a major upgrade. It now creates not only the report, but also a live webpage and a podcast — powered by Qwen3-Coder, Qwen-Image, and Qwen3-TTS. Your insights, now visual and audible.”Multi-Format Research OutputThe core workflow begins with a user request inside the Qwen Chat interface. From there, Qwen collaborates by asking clarifying questions to shape the research scope, pulls data from the web and official sources, and analyzes or resolves any inconsistencies it finds — even generating custom code when needed.A demo video posted by Qwen on X walks through this process on Qwen Chat using the U.S. SaaS market as an example. In it, Qwen retrieves data from multiple industry sources, identifies discrepancies in market size estimates (e.g., $206 billion vs. $253 billion), and highlights ambiguities in the U.S. share of global figures. The assistant comments on differences in scope between sources and calculates a compound annual growth rate (CAGR) of 19.8% from 2020 to 2023, providing contextual analysis to back up the raw numbers.Once the research is complete, users can click on the \"eyeball\" icon below the output result (see screenshot), which will bring up a PDF-style report in the right hand pane.Then, when viewing the report in the right-hand pane, the user can click the \"Create\" button in the upper-right hand corner and select from the following two options:\"Web Dev\" which produces a live, professional-grade web page, automatically deployed and hosted by Qwen, using Qwen3-Coder for structure and Qwen-Image for visuals.\"Podcast,\" which, as it states, produces an audio podcast, featuring dynamic, multi-speaker narration generated by Qwen3-TTS, also hosted by Qwen for easy sharing and playback.This enables users to quickly convert a single research project into multiple forms of content — written, visual, and audible — with minimal extra input.The website includes inline graphics generated by Qwen Image, making it suitable for use in public presentations, classrooms, or publishing. The podcast feature allows users to select between 17 different speaker names as the host and 7 as the co-host, though I wasn&#x27;t able to find a way to preview the voice outputs before selecting them. It appears designed for deep listening on the go. There was no way to change the language output that I could see, so mine came out in English, like my reports and initial prompts, though the Qwen LLMs are multi-modal. The voices were slightly more robotic than other AI tools I&#x27;ve used.Here&#x27;s an example of a web page I generated on commonalities in authoritarian regimes throughout history, another one on UFO or UAP sightings, and below this paragraph, a podcast on UFO or UAP sightings. While the website is hosted via a public link, the podcast must be downloaded by the user and can&#x27;t be linked to publicly, from what I could tell in my brief usage so far.Note the podcast is much different than the actual report — not just a straight read-through audio version of it, rather, a new format of two hosts discussing and bantering about the subject using the report as the jumping off point. The web page versions of the report also include new graphics not found in the PDF report.Comparisons to Google&#x27;s NotebookLMWhile the new capabilities have been well received by many early users, comparisons to other research assistants have surfaced — particularly Google’s NotebookLM, which recently exited beta.AI commentator and newsletter writer Chubby (@kimmonismus) noted on X:“I am really grateful that Qwen provides regular updates. That’s great.But the attempt to build a NotebookLM clone inside Qwen-3-max doesn’t sound very promising compared to Google’s version.”While NotebookLM is built around organizing and querying existing documents and web pages, Qwen Deep Research focuses more on generating new research content from scratch, aggregating sources from the open web, and presenting it across multiple modalities. The comparison suggests that while the two tools overlap in general concept — AI-assisted research — they diverge in approach and target user experience.AvailabilityQwen Deep Research is now live and available through the Qwen Chat app. The feature can be accessed with the following URL.No pricing details have been provided for Qwen3-Max or the specific Deep Research capabilities as of this writing.What&#x27;s Next For Qwen Deep Research?By combining research guidance, data analysis, and multi-format content creation into a single tool, Qwen Deep Research aims to streamline the path from idea to publishable output. The integration of code, visuals, and voice makes it especially attractive to content creators, educators, and independent analysts who want to scale their research into web- or podcast-friendly forms without switching platforms.Still, comparisons to more specialized offerings like NotebookLM raise questions about how Qwen’s generalized approach stacks up on depth, precision, and refinement. Whether the strength of its multi-format execution outweighs those concerns may come down to user priorities — and whether they value single-click publishing over tight integration with existing notes and materials.For now, Qwen is signaling that research doesn’t end with a document — it begins with one.Let me know if you want this repackaged into something shorter or tailored to a particular audience — newsletter, press-style blog, internal team explainer, etc.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5Joxz8qhvStlvnHybvWBpG/5dcda997ed99a05e52cc929b825d01d5/cfr0z3n_realistic_graphic_novel_art_hyperdetailed_overhead_isom_7a652de4-81e1-4145-848c-4a9c6c0969e4.png"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/deepseek-drops-open-source-model-that-compresses-text-10x-through-images",
          "published_at": "Tue, 21 Oct 2025 18:30:00 GMT",
          "title": "DeepSeek drops open-source model that compresses text 10x through images, defying conventions",
          "standfirst": "DeepSeek, the Chinese artificial intelligence research company that has repeatedly challenged assumptions about AI development costs, has released a new model that fundamentally reimagines how large language models process information—and the implications extend far beyond its modest branding as an optical character recognition tool.The company&#x27;s DeepSeek-OCR model, released Monday with full open-source code and weights, achieves what researchers describe as a paradigm inversion: compressing text through visual representation up to 10 times more efficiently than traditional text tokens. The finding challenges a core assumption in AI development and could pave the way for language models with dramatically expanded context windows, potentially reaching tens of millions of tokens.\"We present DeepSeek-OCR as an initial investigation into the feasibility of compressing long contexts via optical 2D mapping,\" the research team wrote in their technical paper. \"Experiments show that when the number of text tokens is within 10 times that of vision tokens (i.e., a compression ratio < 10×), the model can achieve decoding (OCR) precision of 97%.\"The implications have resonated across the AI research community. Andrej Karpathy, co-founder of OpenAI and former director of AI at Tesla, said in a post that the work raises fundamental questions about how AI systems should process information. \"Maybe it makes more sense that all inputs to LLMs should only ever be images,\" Karpathy wrote. \"Even if you happen to have pure text input, maybe you&#x27;d prefer to render it and then feed that in.\"How DeepSeek achieved 10x compression by treating text as imagesWhile DeepSeek marketed the release as an OCR model — a technology for converting images of text into digital characters — the research paper reveals more ambitious goals. The model demonstrates that visual representations can serve as a superior compression medium for textual information, inverting the conventional hierarchy where text tokens were considered more efficient than vision tokens.\"Traditionally, vision LLM tokens almost seemed like an afterthought or &#x27;bolt on&#x27; to the LLM paradigm,\" wrote Jeffrey Emanuel, an AI researcher, in a detailed analysis of the paper. \"And 10k words of English would take up far more space in a multimodal LLM when expressed as intelligible pixels than when expressed as tokens...But that gets inverted now from the ideas in this paper.\"The model&#x27;s architecture consists of two primary components: DeepEncoder, a novel 380-million-parameter vision encoder, and a 3-billion-parameter mixture-of-experts language decoder with 570 million activated parameters. DeepEncoder combines Meta&#x27;s Segment Anything Model (SAM) for local visual perception with OpenAI&#x27;s CLIP model for global visual understanding, connected through a 16x compression module.To validate their compression claims, DeepSeek researchers tested the model on the Fox benchmark, a dataset of diverse document layouts. The results were striking: using just 100 vision tokens, the model achieved 97.3% accuracy on documents containing 700-800 text tokens — representing an effective compression ratio of 7.5x. Even at compression ratios approaching 20x, accuracy remained around 60%.The practical impact: Processing 200,000 pages per day on a single GPUThe efficiency gains translate directly to production capabilities. According to the company, a single Nvidia A100-40G GPU can process more than 200,000 pages per day using DeepSeek-OCR. Scaling to a cluster of 20 servers with eight GPUs each, throughput reaches 33 million pages daily — sufficient to rapidly construct training datasets for other AI models.On OmniDocBench, a comprehensive document parsing benchmark, DeepSeek-OCR outperformed GOT-OCR2.0 (which uses 256 tokens per page) while using only 100 vision tokens. More dramatically, it surpassed MinerU2.0 — which requires more than 6,000 tokens per page on average — while using fewer than 800 vision tokens.DeepSeek designed the model to support five distinct resolution modes, each optimized for different compression ratios and use cases. The \"Tiny\" mode operates at 512×512 resolution with just 64 vision tokens, while \"Gundam\" mode combines multiple resolutions dynamically for complex documents. \"Gundam mode consists of n×640×640 tiles (local views) and a 1024×1024 global view,\" the researchers wrote.Why this breakthrough could unlock 10 million token context windowsThe compression breakthrough has immediate implications for one of the most pressing challenges in AI development: expanding the context windows that determine how much information language models can actively consider. Current state-of-the-art models typically handle context windows measured in hundreds of thousands of tokens. DeepSeek&#x27;s approach suggests a path to windows ten times larger.\"The potential of getting a frontier LLM with a 10 or 20 million token context window is pretty exciting,\" Emanuel wrote. \"You could basically cram all of a company&#x27;s key internal documents into a prompt preamble and cache this with OpenAI and then just add your specific query or prompt on top of that and not have to deal with search tools and still have it be fast and cost-effective.\"The researchers explicitly frame their work in terms of context compression for language models. \"Through DeepSeek-OCR, we demonstrate that vision-text compression can achieve significant token reduction (7-20×) for different historical context stages, offering a promising direction for addressing long-context challenges in large language models,\" they wrote.The paper includes a speculative but intriguing diagram illustrating how the approach could implement memory decay mechanisms similar to human cognition. Older conversation rounds could be progressively downsampled to lower resolutions, consuming fewer tokens while maintaining key information — a form of computational forgetting that mirrors biological memory.How visual processing could eliminate the &#x27;ugly&#x27; tokenizer problemBeyond compression, Karpathy highlighted how the approach challenges fundamental assumptions about how language models should process text. Traditional tokenizers—the systems that break text into units for processing—have long been criticized for their complexity and limitations.\"I already ranted about how much I dislike the tokenizer,\" Karpathy wrote. \"Tokenizers are ugly, separate, not end-to-end stage. It &#x27;imports&#x27; all the ugliness of Unicode, byte encodings, it inherits a lot of historical baggage, security/jailbreak risk (e.g. continuation bytes). It makes two characters that look identical to the eye look as two completely different tokens internally in the network.\"Visual processing of text could eliminate these issues while enabling new capabilities. The approach naturally handles formatting information lost in pure text representations: bold text, colors, layout, embedded images. \"Input can now be processed with bidirectional attention easily and as default, not autoregressive attention - a lot more powerful,\" Karpathy noted.The implications resonate with human cognitive science. Emanuel drew a parallel to Hans Bethe, the renowned physicist who memorized vast amounts of reference data: \"Having vast amounts of task-specific knowledge in your working memory is extremely useful. This seems like a very clever and additive approach to potentially expanding that memory bank by 10x or more.\"The model&#x27;s training: 30 million PDF pages across 100 languagesThe model&#x27;s capabilities rest on an extensive training regimen using diverse data sources. DeepSeek collected 30 million PDF pages covering approximately 100 languages, with Chinese and English accounting for 25 million pages. The training data spans nine document types — academic papers, financial reports, textbooks, newspapers, handwritten notes, and others.Beyond document OCR, the training incorporated what the researchers call \"OCR 2.0\" data: 10 million synthetic charts, 5 million chemical formulas, and 1 million geometric figures. The model also received 20% general vision data for tasks like image captioning and object detection, plus 10% text-only data to maintain language capabilities.The training process employed pipeline parallelism across 160 Nvidia A100-40G GPUs (20 nodes with 8 GPUs each), with the vision encoder divided between two pipeline stages and the language model split across two others. \"For multimodal data, the training speed is 70B tokens/day,\" the researchers reported.Open source release accelerates research and raises competitive questionsTrue to DeepSeek&#x27;s pattern of open development, the company released the complete model weights, training code, and inference scripts on GitHub and Hugging Face. The GitHub repository gained over 4,000 stars within 24 hours of release, according to Dataconomy.The breakthrough raises questions about whether other AI labs have developed similar techniques but kept them proprietary. Emanuel speculated that Google&#x27;s Gemini models, which feature large context windows and strong OCR performance, might employ comparable approaches. \"For all we know, Google could have already figured out something like this, which could explain why Gemini has such a huge context size and is so good and fast at OCR tasks,\" Emanuel wrote.Google&#x27;s Gemini 2.5 Pro offers a 1-million-token context window, with plans to expand to 2 million, though the company has not publicly detailed the technical approaches enabling this capability. OpenAI&#x27;s GPT-5 supports 400,000 tokens, while Anthropic&#x27;s Claude 4.5 offers 200,000 tokens, with a 1-million-token window available in beta for eligible organizations.The unanswered question: Can AI reason over compressed visual tokens?While the compression results are impressive, researchers acknowledge important open questions. \"It&#x27;s not clear how exactly this interacts with the other downstream cognitive functioning of an LLM,\" Emanuel noted. \"Can the model reason as intelligently over those compressed visual tokens as it can using regular text tokens? Does it make the model less articulate by forcing it into a more vision-oriented modality?\"The DeepSeek paper focuses primarily on the compression-decompression capability, measured through OCR accuracy, rather than downstream reasoning performance. This leaves open whether language models could reason effectively over large contexts represented primarily as compressed visual tokens.The researchers acknowledge their work represents \"an initial exploration into the boundaries of vision-text compression.\" They note that \"OCR alone is insufficient to fully validate true context optical compression\" and plan future work including \"digital-optical text interleaved pretraining, needle-in-a-haystack testing, and other evaluations.\"DeepSeek has established a pattern of achieving competitive results with dramatically lower computational resources than Western AI labs. The company&#x27;s earlier DeepSeek-V3 model reportedly cost just $5.6 million to train—though this figure represents only the final training run and excludes R&D and infrastructure costs—compared to hundreds of millions for comparable models from OpenAI and Anthropic.Industry analysts have questioned the $5.6 million figure, with some estimates placing the company&#x27;s total infrastructure and operational costs closer to $1.3 billion, though still lower than American competitors&#x27; spending.The bigger picture: Should language models process text as images?DeepSeek-OCR poses a fundamental question for AI development: should language models process text as text, or as images of text? The research demonstrates that, at least for compression purposes, visual representation offers significant advantages. Whether this translates to effective reasoning over vast contexts remains to be determined.\"From another perspective, optical contexts compression still offers substantial room for research and improvement, representing a promising new direction,\" the researchers concluded in their paper.For the AI industry, the work adds another dimension to the race for longer context windows — a competition that has intensified as language models are applied to increasingly complex tasks requiring vast amounts of information. The open-source release ensures the technique will be widely explored, tested, and potentially integrated into future AI systems.As Karpathy framed the deeper implication: \"OCR is just one of many useful vision -> text tasks. And text -> text tasks can be made to be vision ->text tasks. Not vice versa.\" In other words, the path forward for AI might not run through better tokenizers — it might bypass text tokens altogether.",
          "content": "DeepSeek, the Chinese artificial intelligence research company that has repeatedly challenged assumptions about AI development costs, has released a new model that fundamentally reimagines how large language models process information—and the implications extend far beyond its modest branding as an optical character recognition tool.The company&#x27;s DeepSeek-OCR model, released Monday with full open-source code and weights, achieves what researchers describe as a paradigm inversion: compressing text through visual representation up to 10 times more efficiently than traditional text tokens. The finding challenges a core assumption in AI development and could pave the way for language models with dramatically expanded context windows, potentially reaching tens of millions of tokens.\"We present DeepSeek-OCR as an initial investigation into the feasibility of compressing long contexts via optical 2D mapping,\" the research team wrote in their technical paper. \"Experiments show that when the number of text tokens is within 10 times that of vision tokens (i.e., a compression ratio < 10×), the model can achieve decoding (OCR) precision of 97%.\"The implications have resonated across the AI research community. Andrej Karpathy, co-founder of OpenAI and former director of AI at Tesla, said in a post that the work raises fundamental questions about how AI systems should process information. \"Maybe it makes more sense that all inputs to LLMs should only ever be images,\" Karpathy wrote. \"Even if you happen to have pure text input, maybe you&#x27;d prefer to render it and then feed that in.\"How DeepSeek achieved 10x compression by treating text as imagesWhile DeepSeek marketed the release as an OCR model — a technology for converting images of text into digital characters — the research paper reveals more ambitious goals. The model demonstrates that visual representations can serve as a superior compression medium for textual information, inverting the conventional hierarchy where text tokens were considered more efficient than vision tokens.\"Traditionally, vision LLM tokens almost seemed like an afterthought or &#x27;bolt on&#x27; to the LLM paradigm,\" wrote Jeffrey Emanuel, an AI researcher, in a detailed analysis of the paper. \"And 10k words of English would take up far more space in a multimodal LLM when expressed as intelligible pixels than when expressed as tokens...But that gets inverted now from the ideas in this paper.\"The model&#x27;s architecture consists of two primary components: DeepEncoder, a novel 380-million-parameter vision encoder, and a 3-billion-parameter mixture-of-experts language decoder with 570 million activated parameters. DeepEncoder combines Meta&#x27;s Segment Anything Model (SAM) for local visual perception with OpenAI&#x27;s CLIP model for global visual understanding, connected through a 16x compression module.To validate their compression claims, DeepSeek researchers tested the model on the Fox benchmark, a dataset of diverse document layouts. The results were striking: using just 100 vision tokens, the model achieved 97.3% accuracy on documents containing 700-800 text tokens — representing an effective compression ratio of 7.5x. Even at compression ratios approaching 20x, accuracy remained around 60%.The practical impact: Processing 200,000 pages per day on a single GPUThe efficiency gains translate directly to production capabilities. According to the company, a single Nvidia A100-40G GPU can process more than 200,000 pages per day using DeepSeek-OCR. Scaling to a cluster of 20 servers with eight GPUs each, throughput reaches 33 million pages daily — sufficient to rapidly construct training datasets for other AI models.On OmniDocBench, a comprehensive document parsing benchmark, DeepSeek-OCR outperformed GOT-OCR2.0 (which uses 256 tokens per page) while using only 100 vision tokens. More dramatically, it surpassed MinerU2.0 — which requires more than 6,000 tokens per page on average — while using fewer than 800 vision tokens.DeepSeek designed the model to support five distinct resolution modes, each optimized for different compression ratios and use cases. The \"Tiny\" mode operates at 512×512 resolution with just 64 vision tokens, while \"Gundam\" mode combines multiple resolutions dynamically for complex documents. \"Gundam mode consists of n×640×640 tiles (local views) and a 1024×1024 global view,\" the researchers wrote.Why this breakthrough could unlock 10 million token context windowsThe compression breakthrough has immediate implications for one of the most pressing challenges in AI development: expanding the context windows that determine how much information language models can actively consider. Current state-of-the-art models typically handle context windows measured in hundreds of thousands of tokens. DeepSeek&#x27;s approach suggests a path to windows ten times larger.\"The potential of getting a frontier LLM with a 10 or 20 million token context window is pretty exciting,\" Emanuel wrote. \"You could basically cram all of a company&#x27;s key internal documents into a prompt preamble and cache this with OpenAI and then just add your specific query or prompt on top of that and not have to deal with search tools and still have it be fast and cost-effective.\"The researchers explicitly frame their work in terms of context compression for language models. \"Through DeepSeek-OCR, we demonstrate that vision-text compression can achieve significant token reduction (7-20×) for different historical context stages, offering a promising direction for addressing long-context challenges in large language models,\" they wrote.The paper includes a speculative but intriguing diagram illustrating how the approach could implement memory decay mechanisms similar to human cognition. Older conversation rounds could be progressively downsampled to lower resolutions, consuming fewer tokens while maintaining key information — a form of computational forgetting that mirrors biological memory.How visual processing could eliminate the &#x27;ugly&#x27; tokenizer problemBeyond compression, Karpathy highlighted how the approach challenges fundamental assumptions about how language models should process text. Traditional tokenizers—the systems that break text into units for processing—have long been criticized for their complexity and limitations.\"I already ranted about how much I dislike the tokenizer,\" Karpathy wrote. \"Tokenizers are ugly, separate, not end-to-end stage. It &#x27;imports&#x27; all the ugliness of Unicode, byte encodings, it inherits a lot of historical baggage, security/jailbreak risk (e.g. continuation bytes). It makes two characters that look identical to the eye look as two completely different tokens internally in the network.\"Visual processing of text could eliminate these issues while enabling new capabilities. The approach naturally handles formatting information lost in pure text representations: bold text, colors, layout, embedded images. \"Input can now be processed with bidirectional attention easily and as default, not autoregressive attention - a lot more powerful,\" Karpathy noted.The implications resonate with human cognitive science. Emanuel drew a parallel to Hans Bethe, the renowned physicist who memorized vast amounts of reference data: \"Having vast amounts of task-specific knowledge in your working memory is extremely useful. This seems like a very clever and additive approach to potentially expanding that memory bank by 10x or more.\"The model&#x27;s training: 30 million PDF pages across 100 languagesThe model&#x27;s capabilities rest on an extensive training regimen using diverse data sources. DeepSeek collected 30 million PDF pages covering approximately 100 languages, with Chinese and English accounting for 25 million pages. The training data spans nine document types — academic papers, financial reports, textbooks, newspapers, handwritten notes, and others.Beyond document OCR, the training incorporated what the researchers call \"OCR 2.0\" data: 10 million synthetic charts, 5 million chemical formulas, and 1 million geometric figures. The model also received 20% general vision data for tasks like image captioning and object detection, plus 10% text-only data to maintain language capabilities.The training process employed pipeline parallelism across 160 Nvidia A100-40G GPUs (20 nodes with 8 GPUs each), with the vision encoder divided between two pipeline stages and the language model split across two others. \"For multimodal data, the training speed is 70B tokens/day,\" the researchers reported.Open source release accelerates research and raises competitive questionsTrue to DeepSeek&#x27;s pattern of open development, the company released the complete model weights, training code, and inference scripts on GitHub and Hugging Face. The GitHub repository gained over 4,000 stars within 24 hours of release, according to Dataconomy.The breakthrough raises questions about whether other AI labs have developed similar techniques but kept them proprietary. Emanuel speculated that Google&#x27;s Gemini models, which feature large context windows and strong OCR performance, might employ comparable approaches. \"For all we know, Google could have already figured out something like this, which could explain why Gemini has such a huge context size and is so good and fast at OCR tasks,\" Emanuel wrote.Google&#x27;s Gemini 2.5 Pro offers a 1-million-token context window, with plans to expand to 2 million, though the company has not publicly detailed the technical approaches enabling this capability. OpenAI&#x27;s GPT-5 supports 400,000 tokens, while Anthropic&#x27;s Claude 4.5 offers 200,000 tokens, with a 1-million-token window available in beta for eligible organizations.The unanswered question: Can AI reason over compressed visual tokens?While the compression results are impressive, researchers acknowledge important open questions. \"It&#x27;s not clear how exactly this interacts with the other downstream cognitive functioning of an LLM,\" Emanuel noted. \"Can the model reason as intelligently over those compressed visual tokens as it can using regular text tokens? Does it make the model less articulate by forcing it into a more vision-oriented modality?\"The DeepSeek paper focuses primarily on the compression-decompression capability, measured through OCR accuracy, rather than downstream reasoning performance. This leaves open whether language models could reason effectively over large contexts represented primarily as compressed visual tokens.The researchers acknowledge their work represents \"an initial exploration into the boundaries of vision-text compression.\" They note that \"OCR alone is insufficient to fully validate true context optical compression\" and plan future work including \"digital-optical text interleaved pretraining, needle-in-a-haystack testing, and other evaluations.\"DeepSeek has established a pattern of achieving competitive results with dramatically lower computational resources than Western AI labs. The company&#x27;s earlier DeepSeek-V3 model reportedly cost just $5.6 million to train—though this figure represents only the final training run and excludes R&D and infrastructure costs—compared to hundreds of millions for comparable models from OpenAI and Anthropic.Industry analysts have questioned the $5.6 million figure, with some estimates placing the company&#x27;s total infrastructure and operational costs closer to $1.3 billion, though still lower than American competitors&#x27; spending.The bigger picture: Should language models process text as images?DeepSeek-OCR poses a fundamental question for AI development: should language models process text as text, or as images of text? The research demonstrates that, at least for compression purposes, visual representation offers significant advantages. Whether this translates to effective reasoning over vast contexts remains to be determined.\"From another perspective, optical contexts compression still offers substantial room for research and improvement, representing a promising new direction,\" the researchers concluded in their paper.For the AI industry, the work adds another dimension to the race for longer context windows — a competition that has intensified as language models are applied to increasingly complex tasks requiring vast amounts of information. The open-source release ensures the technique will be widely explored, tested, and potentially integrated into future AI systems.As Karpathy framed the deeper implication: \"OCR is just one of many useful vision -> text tasks. And text -> text tasks can be made to be vision ->text tasks. Not vice versa.\" In other words, the path forward for AI might not run through better tokenizers — it might bypass text tokens altogether.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5e39eq2QQIBDorTJB70Tw8/4a8d11981b981c2e3cf3b504304d424c/nuneybits_Vector_art_of_whale_surfing_data_streams_932353ff-5fc4-4cc9-bb53-0b9658f59281.webp"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/googles-new-vibe-coding-ai-studio-experience-lets-anyone-build-deploy-apps",
          "published_at": "Tue, 21 Oct 2025 17:45:00 GMT",
          "title": "Google's new vibe coding AI Studio experience lets anyone build, deploy apps live in minutes",
          "standfirst": "Google AI Studio has gotten a big vibe coding upgrade with a new interface, buttons, suggestions and community features that allow anyone with an idea for an app — even complete novices, laypeople, or non-developers like yours truly — to bring it into existence and deploy it live, on the web, for anyone to use, within minutes.The updated Build tab is available now at ai.studio/build, and it’s free to start. Users can experiment with building applications without needing to enter payment information upfront, though certain advanced features like Veo 3.1 and Cloud Run deployment require a paid API key.The new features appear to me to make Google&#x27;s AI models and offerings even more competitive, perhaps preferred, for many general users to dedicated AI startup rivals like Anthropic&#x27;s Claude Code and OpenAI&#x27;s Codex, respectively, two \"vibe coding\" focused products that are beloved by developers — but seem to have a higher barrier to entry or may require more technical know-how.A Fresh Start: Redesigned Build ModeThe updated Build tab serves as the entry point to vibe coding. It introduces a new layout and workflow where users can select from Google’s suite of AI models and features to power their applications. The default is Gemini 2.5 Pro, which is great for most cases.Once selections are made, users simply describe what they want to build, and the system automatically assembles the necessary components using Gemini’s APIs.This mode supports mixing capabilities like Nano Banana (a lightweight AI model), Veo (for video understanding), Imagine (for image generation), Flashlight (for performance-optimized inference), and Google Search.Patrick Löber, Developer Relations at Google DeepMind, highlighted that the experience is meant to help users “supercharge your apps with AI” using a simple prompt-to-app pipeline.In a video demo he posted on X and LinedIn, he showed how just a few clicks led to the automatic generation of a garden planning assistant app, complete with layouts, visuals, and a conversational interface.From Prompt to Production: Building and Editing in Real TimeOnce an app is generated, users land in a fully interactive editor. On the left, there’s a traditional code-assist interface where developers can chat with the AI model for help or suggestions. On the right, a code editor displays the full source of the app.Each component—such as React entry points, API calls, or styling files—can be edited directly. Tooltips help users understand what each file does, which is especially useful for those less familiar with TypeScript or frontend frameworks.Apps can be saved to GitHub, downloaded locally, or shared directly. Deployment is possible within the Studio environment or via Cloud Run if advanced scaling or hosting is needed.Inspiration on Demand: The ‘I’m Feeling Lucky’ ButtonOne standout feature in this update is the “I’m Feeling Lucky” button. Designed for users who need a creative jumpstart, it generates randomized app concepts and configures the app setup accordingly. Each press yields a different idea, complete with suggested AI features and components.Examples produced during demos include:An interactive map-based chatbot powered by Google Search and conversational AI.A dream garden designer using image generation and advanced planning tools.A trivia game app with an AI host whose personality users can define, integrating both Imagine and Flashlight with Gemini 2.5 Pro for conversation and reasoning.Logan Kilpatrick, Lead of Product for Google AI Studio and Gemini AI, noted in a demo video of his own that this feature encourages discovery and experimentation. “You get some really, really cool, different experiences,” he said, emphasizing its role in helping users find novel ideas quickly.Hands-On Test: From Prompt to App in 65 SecondsTo test the new workflow, I prompted Gemini with:A randomized dice rolling web application where the user can select between common dice sizes (6 sides, 10 sides, etc) and then see an animated die rolling and choose the color of their die as well.Within 65 seconds (just over a minute) AI Studio returned a fully working web app featuring:Dice size selector (d4, d6, d8, d10, d12, d20)Color customization options for the dieAnimated rolling effect with randomized resultsClean, modern UI built with React, TypeScript, and Tailwind CSSThe platform also generated a complete set of structured files, including App.tsx, constants.ts, and separate components for dice logic and controls. After generation, it was easy to iterate: adding sound effects for each interaction (rolling, choosing a die, changing color) required only a single follow-up prompt to the built-in assistant. This was also suggested by Gemini, too, by the way. From there, the app can be previewed live or exported using built-in controls to:Save to GitHubDownload the full codebaseCopy the project for remixingDeploy via integrated toolsMy brief, hands-on test showed just how quickly even small utility apps can go from idea to interactive prototype—without leaving the browser or writing boilerplate code manually.AI-Suggested Enhancements and Feature RefinementIn addition to code generation, Google AI Studio now offers context-aware feature suggestions. These recommendations, generated by Gemini’s Flashlight capability, analyze the current app and propose relevant improvements.In one example, the system suggested implementing a feature that displays the history of previously generated images in an image studio tab. These iterative enhancements allow builders to expand app functionality over time without starting from scratch.Kilpatrick emphasized that users can continue to refine their projects as they go, combining both automatic generation and manual adjustments. “You can go in and continue to edit and sort of refine the experience that you want iteratively,” he said.Free to Start, Flexible to GrowThe new experience is available at no cost for users who want to experiment, prototype, or build lightweight apps. There’s no requirement to enter credit card information to begin using vibe coding.However, more powerful capabilities — such as using models like Veo 3.1 or deploying through Cloud Run — do require switching to a paid API key.This pricing structure is intended to lower the barrier to entry for experimentation while providing a clear path to scale when needed.Built for All Skill LevelsOne of the central goals of the vibe coding launch is to make AI app development accessible to more people. The system supports both high-level visual builders and low-level code editing, creating a workflow that works for developers across experience levels.Kilpatrick mentioned that while he’s more familiar with Python than TypeScript, he still found the editor useful because of the helpful file descriptions and intuitive layout. This focus on usability could make AI Studio a compelling option for developers exploring AI for the first time.More to Come: A Week of LaunchesThe launch of vibe coding is the first in a series of announcements expected throughout the week. While specific future features haven’t been revealed yet, both Kilpatrick and Löber hinted that additional updates are on the way.With this update, Google AI Studio positions itself as a flexible, user-friendly environment for building AI-powered applications—whether for fun, prototyping, or production deployment. The focus is clear: make the power of Gemini’s APIs accessible without unnecessary complexity.",
          "content": "Google AI Studio has gotten a big vibe coding upgrade with a new interface, buttons, suggestions and community features that allow anyone with an idea for an app — even complete novices, laypeople, or non-developers like yours truly — to bring it into existence and deploy it live, on the web, for anyone to use, within minutes.The updated Build tab is available now at ai.studio/build, and it’s free to start. Users can experiment with building applications without needing to enter payment information upfront, though certain advanced features like Veo 3.1 and Cloud Run deployment require a paid API key.The new features appear to me to make Google&#x27;s AI models and offerings even more competitive, perhaps preferred, for many general users to dedicated AI startup rivals like Anthropic&#x27;s Claude Code and OpenAI&#x27;s Codex, respectively, two \"vibe coding\" focused products that are beloved by developers — but seem to have a higher barrier to entry or may require more technical know-how.A Fresh Start: Redesigned Build ModeThe updated Build tab serves as the entry point to vibe coding. It introduces a new layout and workflow where users can select from Google’s suite of AI models and features to power their applications. The default is Gemini 2.5 Pro, which is great for most cases.Once selections are made, users simply describe what they want to build, and the system automatically assembles the necessary components using Gemini’s APIs.This mode supports mixing capabilities like Nano Banana (a lightweight AI model), Veo (for video understanding), Imagine (for image generation), Flashlight (for performance-optimized inference), and Google Search.Patrick Löber, Developer Relations at Google DeepMind, highlighted that the experience is meant to help users “supercharge your apps with AI” using a simple prompt-to-app pipeline.In a video demo he posted on X and LinedIn, he showed how just a few clicks led to the automatic generation of a garden planning assistant app, complete with layouts, visuals, and a conversational interface.From Prompt to Production: Building and Editing in Real TimeOnce an app is generated, users land in a fully interactive editor. On the left, there’s a traditional code-assist interface where developers can chat with the AI model for help or suggestions. On the right, a code editor displays the full source of the app.Each component—such as React entry points, API calls, or styling files—can be edited directly. Tooltips help users understand what each file does, which is especially useful for those less familiar with TypeScript or frontend frameworks.Apps can be saved to GitHub, downloaded locally, or shared directly. Deployment is possible within the Studio environment or via Cloud Run if advanced scaling or hosting is needed.Inspiration on Demand: The ‘I’m Feeling Lucky’ ButtonOne standout feature in this update is the “I’m Feeling Lucky” button. Designed for users who need a creative jumpstart, it generates randomized app concepts and configures the app setup accordingly. Each press yields a different idea, complete with suggested AI features and components.Examples produced during demos include:An interactive map-based chatbot powered by Google Search and conversational AI.A dream garden designer using image generation and advanced planning tools.A trivia game app with an AI host whose personality users can define, integrating both Imagine and Flashlight with Gemini 2.5 Pro for conversation and reasoning.Logan Kilpatrick, Lead of Product for Google AI Studio and Gemini AI, noted in a demo video of his own that this feature encourages discovery and experimentation. “You get some really, really cool, different experiences,” he said, emphasizing its role in helping users find novel ideas quickly.Hands-On Test: From Prompt to App in 65 SecondsTo test the new workflow, I prompted Gemini with:A randomized dice rolling web application where the user can select between common dice sizes (6 sides, 10 sides, etc) and then see an animated die rolling and choose the color of their die as well.Within 65 seconds (just over a minute) AI Studio returned a fully working web app featuring:Dice size selector (d4, d6, d8, d10, d12, d20)Color customization options for the dieAnimated rolling effect with randomized resultsClean, modern UI built with React, TypeScript, and Tailwind CSSThe platform also generated a complete set of structured files, including App.tsx, constants.ts, and separate components for dice logic and controls. After generation, it was easy to iterate: adding sound effects for each interaction (rolling, choosing a die, changing color) required only a single follow-up prompt to the built-in assistant. This was also suggested by Gemini, too, by the way. From there, the app can be previewed live or exported using built-in controls to:Save to GitHubDownload the full codebaseCopy the project for remixingDeploy via integrated toolsMy brief, hands-on test showed just how quickly even small utility apps can go from idea to interactive prototype—without leaving the browser or writing boilerplate code manually.AI-Suggested Enhancements and Feature RefinementIn addition to code generation, Google AI Studio now offers context-aware feature suggestions. These recommendations, generated by Gemini’s Flashlight capability, analyze the current app and propose relevant improvements.In one example, the system suggested implementing a feature that displays the history of previously generated images in an image studio tab. These iterative enhancements allow builders to expand app functionality over time without starting from scratch.Kilpatrick emphasized that users can continue to refine their projects as they go, combining both automatic generation and manual adjustments. “You can go in and continue to edit and sort of refine the experience that you want iteratively,” he said.Free to Start, Flexible to GrowThe new experience is available at no cost for users who want to experiment, prototype, or build lightweight apps. There’s no requirement to enter credit card information to begin using vibe coding.However, more powerful capabilities — such as using models like Veo 3.1 or deploying through Cloud Run — do require switching to a paid API key.This pricing structure is intended to lower the barrier to entry for experimentation while providing a clear path to scale when needed.Built for All Skill LevelsOne of the central goals of the vibe coding launch is to make AI app development accessible to more people. The system supports both high-level visual builders and low-level code editing, creating a workflow that works for developers across experience levels.Kilpatrick mentioned that while he’s more familiar with Python than TypeScript, he still found the editor useful because of the helpful file descriptions and intuitive layout. This focus on usability could make AI Studio a compelling option for developers exploring AI for the first time.More to Come: A Week of LaunchesThe launch of vibe coding is the first in a series of announcements expected throughout the week. While specific future features haven’t been revealed yet, both Kilpatrick and Löber hinted that additional updates are on the way.With this update, Google AI Studio positions itself as a flexible, user-friendly environment for building AI-powered applications—whether for fun, prototyping, or production deployment. The focus is clear: make the power of Gemini’s APIs accessible without unnecessary complexity.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4kXCoAPJEcNYeIiP3L6Oyd/e2ced747533b5cf5f7b84e9fc7578ace/cfr0z3n_fix_hand_--chaos_35_--ar_9151_--raw_--profile_h57q96c_u_79d5871e-80b7-4587-8fc5-cd2407d695ac.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openais-ai-powered-browser-chatgpt-atlas-launches-on-macos-today-170735742.html",
          "published_at": "Tue, 21 Oct 2025 17:07:35 +0000",
          "title": "OpenAI's AI-powered browser, ChatGPT Atlas, launches on macOS today",
          "standfirst": "OpenAI's long-rumored browser has a name, and you can try it out today — provided you're an Apple user. ChatGPT Atlas is available to download on macOS, with the company promising to bring it to Windows, Android and iOS soon. Atlas integrates ChatGPT directly within the browser interface, allowing users to engage with the chatbot while they're surfing the web — no need to jump between different tabs or copy and paste content. When you select a text field, an icon will appear that allows you to prompt ChatGPT. OpenAI demoed this feature in Gmail where an employee asked the chatbot to polish an email he was writing to a colleague. Naturally, a prompt bar will also appear when you open a new tab, and you can open a sidebar where you can converse with ChatGPT at any time. The more you use Atlas, the more ChatGPT will \"remember\" about your preferences. One of the benefits of this is that you'll be able to more easily filter through your search history. For instance, you can write \"re-open the shoes I looked at yesterday,\" and ChatGPT will know the specific website you want to look at again. Browser memories are optional, and if you decide to enable the feature, you can manage them through the settings menu, and just like any other browser, you can delete your history or go surf the web using an incognito mode. OpenAI also says it won't use the content users browse to train its future models. Atlas also includes an agent mode where ChatGPT can surf the web for you and complete tasks. The feature builds on the Operator tech debuted at the start of the year, and is currently available as a preview within the browser that Plus, Pro and Business accounts can try out. \"It can help you book reservations or flights or even just edit a document that you’re working on,” said Adam Fry, product lead for ChatGPT Search, during the livestream where OpenAI announced Atlas. \"Tabs are great but we haven't seen a lot of browser innovation since then,\" OpenAI CEO Sam Altman at the start of the livestream. “This is just a great browser all-around — it’s smooth, it’s quick, it’s really nice to use.” Rumors that OpenAI was working on its own web browser first surfaced in July. With today's announcement, the company joins an already competitive market. A number of companies, including Opera and Perplexity, released their own \"agentic\" browsers earlier this year. Of course, then there's also Google, which plans to integrate its Gemini AI assistant more deeply into Chrome, the world's most popular browser, over the coming months. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-ai-powered-browser-chatgpt-atlas-launches-on-macos-today-170735742.html?src=rss",
          "content": "OpenAI's long-rumored browser has a name, and you can try it out today — provided you're an Apple user. ChatGPT Atlas is available to download on macOS, with the company promising to bring it to Windows, Android and iOS soon. Atlas integrates ChatGPT directly within the browser interface, allowing users to engage with the chatbot while they're surfing the web — no need to jump between different tabs or copy and paste content. When you select a text field, an icon will appear that allows you to prompt ChatGPT. OpenAI demoed this feature in Gmail where an employee asked the chatbot to polish an email he was writing to a colleague. Naturally, a prompt bar will also appear when you open a new tab, and you can open a sidebar where you can converse with ChatGPT at any time. The more you use Atlas, the more ChatGPT will \"remember\" about your preferences. One of the benefits of this is that you'll be able to more easily filter through your search history. For instance, you can write \"re-open the shoes I looked at yesterday,\" and ChatGPT will know the specific website you want to look at again. Browser memories are optional, and if you decide to enable the feature, you can manage them through the settings menu, and just like any other browser, you can delete your history or go surf the web using an incognito mode. OpenAI also says it won't use the content users browse to train its future models. Atlas also includes an agent mode where ChatGPT can surf the web for you and complete tasks. The feature builds on the Operator tech debuted at the start of the year, and is currently available as a preview within the browser that Plus, Pro and Business accounts can try out. \"It can help you book reservations or flights or even just edit a document that you’re working on,” said Adam Fry, product lead for ChatGPT Search, during the livestream where OpenAI announced Atlas. \"Tabs are great but we haven't seen a lot of browser innovation since then,\" OpenAI CEO Sam Altman at the start of the livestream. “This is just a great browser all-around — it’s smooth, it’s quick, it’s really nice to use.” Rumors that OpenAI was working on its own web browser first surfaced in July. With today's announcement, the company joins an already competitive market. A number of companies, including Opera and Perplexity, released their own \"agentic\" browsers earlier this year. Of course, then there's also Google, which plans to integrate its Gemini AI assistant more deeply into Chrome, the world's most popular browser, over the coming months. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-ai-powered-browser-chatgpt-atlas-launches-on-macos-today-170735742.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/google-fi-will-start-using-ai-to-make-calls-sound-better-170025805.html",
          "published_at": "Tue, 21 Oct 2025 17:00:25 +0000",
          "title": "Google Fi will start using AI to make calls sound better",
          "standfirst": "Google just announced several updates for its digital telecom provider, Google Fi. It's introducing AI-enhanced audio for better sound quality during calls. The company says this will ensure \"optimized audio quality for every call, so you can confidently take calls from a windy park or busy cafe.\" This feature rolls out sometime in November. Google Fi is getting HD/HD+ calling, which should also improve the overall audio quality. The service will soon automatically connect to Wi-Fi when available, with the company touting \"seamless, secure switching.\" As for security, each call and text goes through a VPN. There's no extra cost for this service and it doesn't count against the pre-existing data allocation. The platform will also soon let users make calls and send texts from any web browser. This is coming in December and will feature a new interface with full RCS support, allowing folks to add hi-res photos and videos to message threads. Finally, Google is integrating Gemini into the platform to create an AI-powered billing summary. The company says this offers \"simple, easy explanations of all your billing statements.\" The feature has been in a beta for a while and Google says users have given it \"high positive sentiment.\" These tools are accompanied by a limited-time promo for new subscribers, amounting to 50 percent off for 15 months when bringing in a phone. The discount is only available for the Unlimited Premium and Unlimited Standard plans.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/google-fi-will-start-using-ai-to-make-calls-sound-better-170025805.html?src=rss",
          "content": "Google just announced several updates for its digital telecom provider, Google Fi. It's introducing AI-enhanced audio for better sound quality during calls. The company says this will ensure \"optimized audio quality for every call, so you can confidently take calls from a windy park or busy cafe.\" This feature rolls out sometime in November. Google Fi is getting HD/HD+ calling, which should also improve the overall audio quality. The service will soon automatically connect to Wi-Fi when available, with the company touting \"seamless, secure switching.\" As for security, each call and text goes through a VPN. There's no extra cost for this service and it doesn't count against the pre-existing data allocation. The platform will also soon let users make calls and send texts from any web browser. This is coming in December and will feature a new interface with full RCS support, allowing folks to add hi-res photos and videos to message threads. Finally, Google is integrating Gemini into the platform to create an AI-powered billing summary. The company says this offers \"simple, easy explanations of all your billing statements.\" The feature has been in a beta for a while and Google says users have given it \"high positive sentiment.\" These tools are accompanied by a limited-time promo for new subscribers, amounting to 50 percent off for 15 months when bringing in a phone. The discount is only available for the Unlimited Premium and Unlimited Standard plans.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/google-fi-will-start-using-ai-to-make-calls-sound-better-170025805.html?src=rss",
          "feed_position": 8
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/apple-macbook-pro-m5-14-inch-review-a-huge-graphics-upgrade-for-creators-and-gamers-170009179.html",
          "published_at": "Tue, 21 Oct 2025 17:00:09 +0000",
          "title": "Apple MacBook Pro M5 14-inch review: A huge graphics upgrade for creators and gamers",
          "standfirst": "There was no massive event announcing the M5 MacBook Pro, not even a short promotional video for social media. Instead, Apple dumped all of its new M5 devices on us with a few press releases, a clear sign that there's not much to celebrate this year. But while the new 14-inch MacBook Pro appears to be more of the same on the surface, it also features an impressive graphics upgrade that makes it a decent choice for gaming. And it retains everything I already love about the MacBook Pro: It's still a well-designed machine that's sturdy, fast and offers tons of battery life. What's new in the M5 MacBook Pro The star of the show is Apple's new M5 chip, which sports a 10-core CPU, 10-core GPU and 16 Neural Engine cores. While the company claims it's 20 percent faster than the M4 for multi-threaded applications, the biggest upgrade is the GPU, which is up to 60 percent faster when it comes to games and professional apps. The M4 was no slouch when it came to gaming and media rendering, but the M5 is a more tempting upgrade for anyone using an M1 MacBook Pro or older. Otherwise, it's like I said: more of the same. There's the 14.2-inch Liquid Retina XDR display which offers up to 1,000 nits of full-screen brightness and 1,600 nits of HDR, as well as ProMotion’s smooth 120Hz refresh rate. (Unfortunately, we’ll likely have to wait until next year for an OLED option.) The aluminum case is still rock solid, and the excellent keyboard and trackpad haven't changed a bit. Last year's 12MP Center Stage webcam also makes a return, along with the superb six-speaker sound system. The port situation is also solid. On top of the MagSafe 3 charging connection, there are three Thunderbolt 4 USB-C ports, a full-sized SDXC card reader, HDMI and a headphone jack. (It would be nice to see a gigabit Ethernet port though. That's the one accessory I still regularly connect to almost every laptop.) Devindra Hardawar for Engadget In use: The best gets even better Before I get to the benchmarks and other performance metrics, it's worth pointing out just how pleasant the 14-inch MacBook is to use. Its aluminum frame is smooth to the touch, its screen is bright enough to use in direct sunlight and it always feels blazing fast. While its 3.4-pound frame is noticeably heavier than the 2.7-pound MacBook Air, it's still easy to travel with. And you can certainly tell that the additional weight translates into raw power, especially as you start to stress the MacBook Pro and hear its fans gently spin up. While the MacBook Air is built to be as thin as possible, the MacBook Pro is built to get work done (and look good while doing so). Based on my testing with popular benchmarks and a few games, the M5 MacBook Pro is noticeably faster than the M4 model in tasks that rely on the GPU and NPU. Otherwise, though, it's hard to tell a difference when it comes to basic tasks like booting into macOS, browsing the web and dealing with email. My review unit was equipped with 32GB of RAM, so it had a bit more breathing room than the base model with 16GB of memory. (Pro tip: If you're planning to keep the MacBook Pro for four years or more, it makes sense to get at least 32GB of RAM. You can't upgrade the memory down the line like older laptops, since it's baked directly into the M5 chip.) Computer Geekbench 6 Geekbench 6 GPU Cinebench 2024 Apple MacBook Pro 14-inch (M5, 2025) 4,310/18,003 48,840 197/1,034 | GPU: 6,143 Apple MacBook Pro 14-inch (M4, 2024) 3,797/14,571 37,869 172/979 GPU: 3,770 Apple MacBook Pro 16-inch (M4 Pro, 2024) 3,925/22,456 70,197 178/1,689 GPU 9,295 Apple MacBook Pro 16-inch (M3 Max, 2024) 3,202/21,312 92,344 143/1,686 GPU 13,182 In Geekbench 6, the M5 MacBook Pro was around 500 points faster than the M4 model in single-threaded tasks, and nearly 3,500 points faster for complex multi-threaded work like video rendering. Thanks to the M5's new graphics hardware, it also tested far better in the Geekbench 6 GPU test, reaching around 11,00 points faster than the M4. I noticed a similar result in Cinebench 2024: The M5 MacBook Pro's CPU scores were slightly better than before, but the GPU score was nearly twice as fast as the M4. For real-world gaming performance, I turned to Lies of P, which also surprised me with some major leaps. With the M4 MacBook Pro, I could only get a steady 60 fps with the highest graphics settings in 1080p. With this M5 model, I was able to play at the highest resolution (3024 by 1890) between 70 and 75 fps. It was even smoother as I scaled down the resolution: The MacBook Pro hit 85 to 95 fps in 1,440p and up to 140 fps in 1080p. Those results are in line with what I'd expect from a gaming notebook that costs well over $2,000, which is in line with the $2,200 retail cost of our review unit. Devindra Hardawar for Engadget I still wouldn't recommend a MacBook Pro for anyone who wants to play tons of games, but it's heartening to see Apple making progress on that front. There are more new AAA games hitting the app store, and the M-series chips are fast enough to run most of them well. But the M5 is the first time I'd consider Apple's hardware equivalent to a PC running a video card like NVIDIA's RTX 5070. The M5 MacBook Pro retains the impressive battery life from the previous model, reaching 34 hours and 30 minutes while looping an HD video. I could also use it for more than two full days of work with nothing much stressing the GPU. And once again, the MacBook Pro never feels very hot, even under an intensive workload. The fans are audible, but they don’t get as annoying as the helicopter-like fans from the old Intel MacBook Pros. Devindra Hardawar for Engadget Should you buy the M5 MacBook Pro? If you're looking for a powerful laptop that can handle most heavy-duty workloads, the MacBook Pro will certainly suit your needs. But the difficult choice now is deciding between this 14-inch M5 model, the existing M4 Pro and Max systems, or waiting a few months for the upcoming M5 Pro and M5 Max chips. If you're rendering video and 3D content all day, you're likely better off working with Pro and Max chips, but you'll have to wait several months to see the new M5 options. If you absolutely need a workhorse MacBook Pro today, you'll have to settle for the M4 Pro and M4 Max (which are still far faster than the base M5 chip). But for most creatives, the M5 MacBook Pro offers an impressive balance of power and portability.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apple-macbook-pro-m5-14-inch-review-a-huge-graphics-upgrade-for-creators-and-gamers-170009179.html?src=rss",
          "content": "There was no massive event announcing the M5 MacBook Pro, not even a short promotional video for social media. Instead, Apple dumped all of its new M5 devices on us with a few press releases, a clear sign that there's not much to celebrate this year. But while the new 14-inch MacBook Pro appears to be more of the same on the surface, it also features an impressive graphics upgrade that makes it a decent choice for gaming. And it retains everything I already love about the MacBook Pro: It's still a well-designed machine that's sturdy, fast and offers tons of battery life. What's new in the M5 MacBook Pro The star of the show is Apple's new M5 chip, which sports a 10-core CPU, 10-core GPU and 16 Neural Engine cores. While the company claims it's 20 percent faster than the M4 for multi-threaded applications, the biggest upgrade is the GPU, which is up to 60 percent faster when it comes to games and professional apps. The M4 was no slouch when it came to gaming and media rendering, but the M5 is a more tempting upgrade for anyone using an M1 MacBook Pro or older. Otherwise, it's like I said: more of the same. There's the 14.2-inch Liquid Retina XDR display which offers up to 1,000 nits of full-screen brightness and 1,600 nits of HDR, as well as ProMotion’s smooth 120Hz refresh rate. (Unfortunately, we’ll likely have to wait until next year for an OLED option.) The aluminum case is still rock solid, and the excellent keyboard and trackpad haven't changed a bit. Last year's 12MP Center Stage webcam also makes a return, along with the superb six-speaker sound system. The port situation is also solid. On top of the MagSafe 3 charging connection, there are three Thunderbolt 4 USB-C ports, a full-sized SDXC card reader, HDMI and a headphone jack. (It would be nice to see a gigabit Ethernet port though. That's the one accessory I still regularly connect to almost every laptop.) Devindra Hardawar for Engadget In use: The best gets even better Before I get to the benchmarks and other performance metrics, it's worth pointing out just how pleasant the 14-inch MacBook is to use. Its aluminum frame is smooth to the touch, its screen is bright enough to use in direct sunlight and it always feels blazing fast. While its 3.4-pound frame is noticeably heavier than the 2.7-pound MacBook Air, it's still easy to travel with. And you can certainly tell that the additional weight translates into raw power, especially as you start to stress the MacBook Pro and hear its fans gently spin up. While the MacBook Air is built to be as thin as possible, the MacBook Pro is built to get work done (and look good while doing so). Based on my testing with popular benchmarks and a few games, the M5 MacBook Pro is noticeably faster than the M4 model in tasks that rely on the GPU and NPU. Otherwise, though, it's hard to tell a difference when it comes to basic tasks like booting into macOS, browsing the web and dealing with email. My review unit was equipped with 32GB of RAM, so it had a bit more breathing room than the base model with 16GB of memory. (Pro tip: If you're planning to keep the MacBook Pro for four years or more, it makes sense to get at least 32GB of RAM. You can't upgrade the memory down the line like older laptops, since it's baked directly into the M5 chip.) Computer Geekbench 6 Geekbench 6 GPU Cinebench 2024 Apple MacBook Pro 14-inch (M5, 2025) 4,310/18,003 48,840 197/1,034 | GPU: 6,143 Apple MacBook Pro 14-inch (M4, 2024) 3,797/14,571 37,869 172/979 GPU: 3,770 Apple MacBook Pro 16-inch (M4 Pro, 2024) 3,925/22,456 70,197 178/1,689 GPU 9,295 Apple MacBook Pro 16-inch (M3 Max, 2024) 3,202/21,312 92,344 143/1,686 GPU 13,182 In Geekbench 6, the M5 MacBook Pro was around 500 points faster than the M4 model in single-threaded tasks, and nearly 3,500 points faster for complex multi-threaded work like video rendering. Thanks to the M5's new graphics hardware, it also tested far better in the Geekbench 6 GPU test, reaching around 11,00 points faster than the M4. I noticed a similar result in Cinebench 2024: The M5 MacBook Pro's CPU scores were slightly better than before, but the GPU score was nearly twice as fast as the M4. For real-world gaming performance, I turned to Lies of P, which also surprised me with some major leaps. With the M4 MacBook Pro, I could only get a steady 60 fps with the highest graphics settings in 1080p. With this M5 model, I was able to play at the highest resolution (3024 by 1890) between 70 and 75 fps. It was even smoother as I scaled down the resolution: The MacBook Pro hit 85 to 95 fps in 1,440p and up to 140 fps in 1080p. Those results are in line with what I'd expect from a gaming notebook that costs well over $2,000, which is in line with the $2,200 retail cost of our review unit. Devindra Hardawar for Engadget I still wouldn't recommend a MacBook Pro for anyone who wants to play tons of games, but it's heartening to see Apple making progress on that front. There are more new AAA games hitting the app store, and the M-series chips are fast enough to run most of them well. But the M5 is the first time I'd consider Apple's hardware equivalent to a PC running a video card like NVIDIA's RTX 5070. The M5 MacBook Pro retains the impressive battery life from the previous model, reaching 34 hours and 30 minutes while looping an HD video. I could also use it for more than two full days of work with nothing much stressing the GPU. And once again, the MacBook Pro never feels very hot, even under an intensive workload. The fans are audible, but they don’t get as annoying as the helicopter-like fans from the old Intel MacBook Pros. Devindra Hardawar for Engadget Should you buy the M5 MacBook Pro? If you're looking for a powerful laptop that can handle most heavy-duty workloads, the MacBook Pro will certainly suit your needs. But the difficult choice now is deciding between this 14-inch M5 model, the existing M4 Pro and Max systems, or waiting a few months for the upcoming M5 Pro and M5 Max chips. If you're rendering video and 3D content all day, you're likely better off working with Pro and Max chips, but you'll have to wait several months to see the new M5 options. If you absolutely need a workhorse MacBook Pro today, you'll have to settle for the M4 Pro and M4 Max (which are still far faster than the base M5 chip). But for most creatives, the M5 MacBook Pro offers an impressive balance of power and portability.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apple-macbook-pro-m5-14-inch-review-a-huge-graphics-upgrade-for-creators-and-gamers-170009179.html?src=rss",
          "feed_position": 9,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/01d16580-aded-11f0-a7fe-9a2d2eb17ce5"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/amazons-aws-outage-has-knocked-services-like-alexa-snapchat-fortnite-venmo-and-more-offline-142935812.html",
          "published_at": "Tue, 21 Oct 2025 15:18:46 +0000",
          "title": "Amazon's AWS outage on October 20 knocked services like Alexa, Snapchat, Fortnite, Venmo and more offline for hours",
          "standfirst": "It felt like half of the internet was dealing with a severe hangover on October 20. A severe Amazon Web Services outage took out many, many websites, apps, games and other services that rely on Amazon’s cloud division to stay up and running. That included a long list of popular software like Venmo, Snapchat, Canva and Fortnite. Even Amazon's own assistant Alexa stuttered, and if you were wondering why the internet seemed to be against you — you weren't imagining it. The good news is that, Amazon announced by 6:53PM ET on October 20 that it resolved the \"increased error rates and latencies for AWS Services.\" The company said it \"identified the trigger of the event as DNS resolution issues for the regional DynamoDB service endpoints.\" It ran into more problems as it tried to solve the outage, but it was eventually able to fix everything. \"By 3:01 PM [PT], all AWS services returned to normal operations,\" it said. At about 4:30PM ET on October 20, things seemed to be returning back to normal. Apps like Venmo and Lyft, which were either slow to respond or completely nonresponsive before, were appearing to behave smoothly. As of 1:15PM ET on October 20, multiple services were unavailable, including asking Alexa for the weather or to turn off lights in your home. The Lyft app was also slower to respond than usual, and Venmo transactions were not completing. According to the AWS service health page at the time, Amazon was looking into \"increased error rates and latencies for multiple AWS services\" in the US-EAST-1 region (i.e. data centers in Northern Virginia) as of 3:11AM ET on Monday. By 5:01AM, AWS had figured out that a DNS resolution issue with its DynamoDB API was the cause of the outage. DynamoDB is a database that holds info for AWS clients. At about 12:08PM ET, the company posted a small statement that reiterated the above and added that the \"underlying DNS issue was fully mitigated at 2:24 AM PDT.\" According to the notice, some Amazon \"customers still continue to experience increased error rates with AWS services in the N. Virginia (us-east-1) Region due to issues with launching new EC2 instances.\" Amazon also said Amazon.com and Amazon subsidiaries, as well as AWS customer service support operations have been impacted. “Amazon had the data safely stored, but nobody else could find it for several hours, leaving apps temporarily separated from their data,” Mike Chapple, a teaching professor of IT, analytics and operations at University of Notre Dame, told CNN. “It’s as if large portions of the internet suffered temporary amnesia.” As of 6:35AM, AWS said it had fully mitigated the DNS issue and that \"most AWS Service operations are succeeding normally now.\" However, the knock-on effect caused issues with other AWS services, including EC2, a virtual machine service on which many companies build online applications. At 8:48AM, AWS said it was \"making progress on resolving the issue with new EC2 instance launches in the US-EAST-1 Region.\" It recommended that clients not tie new deployments to specific Availability Zones (i.e. one or more data centers in a given region) \"so that EC2 has flexibility\" in picking a zone that may be a better option. At 9:42AM, Amazon noted on the status page that although it had applied \"multiple mitigations\" across several Availability Zones in US-EAST-1, it was \"still experiencing elevated errors for new EC2 instance launches.\" As such, AWS was \"rate limiting new instance launches to aid recovery.\" The company added at 10:14AM that it was seeing \"significant API errors and connectivity issues across multiple services in the US-EAST-1 Region.\" Even once all the issues are resolved, AWS will have a significant backlog of requests and other factors to process, so it'll take some time for everything to recover. Many, many, many companies use US-EAST-1 for their AWS deployments, which is why it felt like half of the internet was knocked offline on Monday morning. As of mid-morning, tons of websites and other services were sluggish or offering up error messages. Outage reports for a broad swathe of services spiked on Down Detector. Along with Amazon's own services, users reported issues with the likes of banks, airlines, Disney+, Snapchat, Reddit, Lyft, Apple Music, Pinterest, Fortnite, Roblox and The New York Times — sorry to anyone whose Wordle streaks may be at risk. Sites like Reddit have posted their own status updates, and though they don't explicitly mention AWS, it's possible that the services' paths may cross somewhere in the pipelines. AWS offers a lot of useful features to clients, such as the ability for websites and apps to automatically scale compute and server capacity up and down as needed to handle ebbs and flows in traffic. It also has data centers around the world. That kind of infrastructure is attractive to companies that serve a global audience and need to stay online around the clock. As of mid-2025, it was estimated that AWS' share of the worldwide cloud infrastructure market was 30 percent. But incidents such as this highlight that relying on just a few providers to be the backbone of much of the internet is a bit of a problem. Websites affected by Amazon Web Services outage Sites and services that were affected by the AWS outage include: Amazon Amazon Alexa Bank of America Snapchat Reddit Lyft Apple Music Apple TV Pinterest Fortnite Roblox The New York Times Disney+ Venmo Doordash Hulu Grubhub PlayStation Zoom Update, Oct 20 2025, 10:57AM ET: This story has been updated to include a short list of services affected in the intro. Update, Oct 20 2025, 11:17AM ET: This story has been updated to include a reference to Reddit's own status update website. Update, Oct 20 2025, 1:15PM ET: This story has been updated to include a paragraph reflecting the status of popular services like Lyft, Venmo and Alexa, based on our editors' personal experiences as of this time. Update, Oct 20 2025, 3:15PM ET: This story has been updated to include a short statement from Amazon describing a timeline of events, when the underlying issue was mitigated and what parts of Amazon have been impacted. Update, Oct 20 2025, 4:30PM ET: This story has been updated to reflect the status of services like Venmo and Lyft as of Monday afternoon. Update October 20, 2025, 9:21PM ET: This story has been updated with Amazon's latest update that says the issue has been resolved. Update, Oct 21, 2025, 11:18AM ET: Added a list of sites and services confirmed to have been affected by the AWS outage. This article originally appeared on Engadget at https://www.engadget.com/big-tech/amazons-aws-outage-has-knocked-services-like-alexa-snapchat-fortnite-venmo-and-more-offline-142935812.html?src=rss",
          "content": "It felt like half of the internet was dealing with a severe hangover on October 20. A severe Amazon Web Services outage took out many, many websites, apps, games and other services that rely on Amazon’s cloud division to stay up and running. That included a long list of popular software like Venmo, Snapchat, Canva and Fortnite. Even Amazon's own assistant Alexa stuttered, and if you were wondering why the internet seemed to be against you — you weren't imagining it. The good news is that, Amazon announced by 6:53PM ET on October 20 that it resolved the \"increased error rates and latencies for AWS Services.\" The company said it \"identified the trigger of the event as DNS resolution issues for the regional DynamoDB service endpoints.\" It ran into more problems as it tried to solve the outage, but it was eventually able to fix everything. \"By 3:01 PM [PT], all AWS services returned to normal operations,\" it said. At about 4:30PM ET on October 20, things seemed to be returning back to normal. Apps like Venmo and Lyft, which were either slow to respond or completely nonresponsive before, were appearing to behave smoothly. As of 1:15PM ET on October 20, multiple services were unavailable, including asking Alexa for the weather or to turn off lights in your home. The Lyft app was also slower to respond than usual, and Venmo transactions were not completing. According to the AWS service health page at the time, Amazon was looking into \"increased error rates and latencies for multiple AWS services\" in the US-EAST-1 region (i.e. data centers in Northern Virginia) as of 3:11AM ET on Monday. By 5:01AM, AWS had figured out that a DNS resolution issue with its DynamoDB API was the cause of the outage. DynamoDB is a database that holds info for AWS clients. At about 12:08PM ET, the company posted a small statement that reiterated the above and added that the \"underlying DNS issue was fully mitigated at 2:24 AM PDT.\" According to the notice, some Amazon \"customers still continue to experience increased error rates with AWS services in the N. Virginia (us-east-1) Region due to issues with launching new EC2 instances.\" Amazon also said Amazon.com and Amazon subsidiaries, as well as AWS customer service support operations have been impacted. “Amazon had the data safely stored, but nobody else could find it for several hours, leaving apps temporarily separated from their data,” Mike Chapple, a teaching professor of IT, analytics and operations at University of Notre Dame, told CNN. “It’s as if large portions of the internet suffered temporary amnesia.” As of 6:35AM, AWS said it had fully mitigated the DNS issue and that \"most AWS Service operations are succeeding normally now.\" However, the knock-on effect caused issues with other AWS services, including EC2, a virtual machine service on which many companies build online applications. At 8:48AM, AWS said it was \"making progress on resolving the issue with new EC2 instance launches in the US-EAST-1 Region.\" It recommended that clients not tie new deployments to specific Availability Zones (i.e. one or more data centers in a given region) \"so that EC2 has flexibility\" in picking a zone that may be a better option. At 9:42AM, Amazon noted on the status page that although it had applied \"multiple mitigations\" across several Availability Zones in US-EAST-1, it was \"still experiencing elevated errors for new EC2 instance launches.\" As such, AWS was \"rate limiting new instance launches to aid recovery.\" The company added at 10:14AM that it was seeing \"significant API errors and connectivity issues across multiple services in the US-EAST-1 Region.\" Even once all the issues are resolved, AWS will have a significant backlog of requests and other factors to process, so it'll take some time for everything to recover. Many, many, many companies use US-EAST-1 for their AWS deployments, which is why it felt like half of the internet was knocked offline on Monday morning. As of mid-morning, tons of websites and other services were sluggish or offering up error messages. Outage reports for a broad swathe of services spiked on Down Detector. Along with Amazon's own services, users reported issues with the likes of banks, airlines, Disney+, Snapchat, Reddit, Lyft, Apple Music, Pinterest, Fortnite, Roblox and The New York Times — sorry to anyone whose Wordle streaks may be at risk. Sites like Reddit have posted their own status updates, and though they don't explicitly mention AWS, it's possible that the services' paths may cross somewhere in the pipelines. AWS offers a lot of useful features to clients, such as the ability for websites and apps to automatically scale compute and server capacity up and down as needed to handle ebbs and flows in traffic. It also has data centers around the world. That kind of infrastructure is attractive to companies that serve a global audience and need to stay online around the clock. As of mid-2025, it was estimated that AWS' share of the worldwide cloud infrastructure market was 30 percent. But incidents such as this highlight that relying on just a few providers to be the backbone of much of the internet is a bit of a problem. Websites affected by Amazon Web Services outage Sites and services that were affected by the AWS outage include: Amazon Amazon Alexa Bank of America Snapchat Reddit Lyft Apple Music Apple TV Pinterest Fortnite Roblox The New York Times Disney+ Venmo Doordash Hulu Grubhub PlayStation Zoom Update, Oct 20 2025, 10:57AM ET: This story has been updated to include a short list of services affected in the intro. Update, Oct 20 2025, 11:17AM ET: This story has been updated to include a reference to Reddit's own status update website. Update, Oct 20 2025, 1:15PM ET: This story has been updated to include a paragraph reflecting the status of popular services like Lyft, Venmo and Alexa, based on our editors' personal experiences as of this time. Update, Oct 20 2025, 3:15PM ET: This story has been updated to include a short statement from Amazon describing a timeline of events, when the underlying issue was mitigated and what parts of Amazon have been impacted. Update, Oct 20 2025, 4:30PM ET: This story has been updated to reflect the status of services like Venmo and Lyft as of Monday afternoon. Update October 20, 2025, 9:21PM ET: This story has been updated with Amazon's latest update that says the issue has been resolved. Update, Oct 21, 2025, 11:18AM ET: Added a list of sites and services confirmed to have been affected by the AWS outage. This article originally appeared on Engadget at https://www.engadget.com/big-tech/amazons-aws-outage-has-knocked-services-like-alexa-snapchat-fortnite-venmo-and-more-offline-142935812.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/hbo-max-is-getting-even-more-expensive-starting-today-143939446.html",
          "published_at": "Tue, 21 Oct 2025 14:39:39 +0000",
          "title": "HBO Max is getting even more expensive starting today",
          "standfirst": "Yet another streaming platform is asking people to dig deeper into their wallets and pay more to keep using the service. Warner Bros. Discovery (WBD) has jacked up the prices of all HBO Max plans, 16 months after the last increase to the ad-free offerings. The entry-level, ad-supported plan is now $11 per month (an extra $1) or $110 per year ($10 more). HBO Max Standard will run you an extra $1.50 per month at $18.49 or $15 per year at $185 for the annual plan. As for the HBO Max Premium option, subscribers will now have to pay $23 per month (up by $2) or $230 for an annual plan (an increase of $20).The new prices kick in immediately for newcomers. Existing monthly subscribers will start paying more as of November 20 (whenever their next billing cycle starts on or after that date). Yearly subscribers will be notified about the price changes 30 days before their plan renews.WBD CEO David Zaslav suggested in September that price increases were on the way, along with a stricter crackdown on password sharing. \"The fact that this is quality — and that’s true across our company, motion picture, TV production and streaming quality — we all think that gives us a chance to raise prices,\" Zaslav said. \"We think we’re way underpriced.\"The company announced the price increases on the same day that Disney is making several Disney+ plans more expensive. As it happens, some of the Disney+ bundles that are going up in price include HBO Max. News of the price hikes comes just as WBD sticks a For Sale sign out on its lawn. It was reported this month that the company turned down an acquisition offer from Paramount Skydance for being too low. WBD has now confirmed that \"multiple parties\" have expressed interest in buying some or all of the company, and that it's now conducting \"a review of strategic alternatives to maximize shareholder value.\"In June, WBD announced plans to split into two companies. As things stand, Warner Bros. will retain the namesake film, TV and game studios, as well as New Line Cinema, DC Studios, HBO and HBO Max. Discovery Global will have all of the other live cable channels, such as CNN, HGTV, Cartoon Network, Discovery and TLC (it will also be saddled with the lion's share of WBD's debt). That split is slated to take place by mid-2026, but WBD said on Tuesday it would consider other options. \"The Warner Bros. Discovery Board will evaluate a broad range of strategic options, which will include continuing to advance the company's planned separation to completion by mid-2026, a transaction for the entire company or separate transactions for its Warner Bros. and/or Discovery Global businesses,\" WBD said in a press release. \"As part of the review, the company will also consider an alternative separation structure that would enable a merger of Warner Bros. and spin-off of Discovery Global to our shareholders.\" WBD hasn't set a deadline or timetable for completing this review. But given the whole HBO Max naming debacle, it might take the board quite a while to make its mind up.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/hbo-max-is-getting-even-more-expensive-starting-today-143939446.html?src=rss",
          "content": "Yet another streaming platform is asking people to dig deeper into their wallets and pay more to keep using the service. Warner Bros. Discovery (WBD) has jacked up the prices of all HBO Max plans, 16 months after the last increase to the ad-free offerings. The entry-level, ad-supported plan is now $11 per month (an extra $1) or $110 per year ($10 more). HBO Max Standard will run you an extra $1.50 per month at $18.49 or $15 per year at $185 for the annual plan. As for the HBO Max Premium option, subscribers will now have to pay $23 per month (up by $2) or $230 for an annual plan (an increase of $20).The new prices kick in immediately for newcomers. Existing monthly subscribers will start paying more as of November 20 (whenever their next billing cycle starts on or after that date). Yearly subscribers will be notified about the price changes 30 days before their plan renews.WBD CEO David Zaslav suggested in September that price increases were on the way, along with a stricter crackdown on password sharing. \"The fact that this is quality — and that’s true across our company, motion picture, TV production and streaming quality — we all think that gives us a chance to raise prices,\" Zaslav said. \"We think we’re way underpriced.\"The company announced the price increases on the same day that Disney is making several Disney+ plans more expensive. As it happens, some of the Disney+ bundles that are going up in price include HBO Max. News of the price hikes comes just as WBD sticks a For Sale sign out on its lawn. It was reported this month that the company turned down an acquisition offer from Paramount Skydance for being too low. WBD has now confirmed that \"multiple parties\" have expressed interest in buying some or all of the company, and that it's now conducting \"a review of strategic alternatives to maximize shareholder value.\"In June, WBD announced plans to split into two companies. As things stand, Warner Bros. will retain the namesake film, TV and game studios, as well as New Line Cinema, DC Studios, HBO and HBO Max. Discovery Global will have all of the other live cable channels, such as CNN, HGTV, Cartoon Network, Discovery and TLC (it will also be saddled with the lion's share of WBD's debt). That split is slated to take place by mid-2026, but WBD said on Tuesday it would consider other options. \"The Warner Bros. Discovery Board will evaluate a broad range of strategic options, which will include continuing to advance the company's planned separation to completion by mid-2026, a transaction for the entire company or separate transactions for its Warner Bros. and/or Discovery Global businesses,\" WBD said in a press release. \"As part of the review, the company will also consider an alternative separation structure that would enable a merger of Warner Bros. and spin-off of Discovery Global to our shareholders.\" WBD hasn't set a deadline or timetable for completing this review. But given the whole HBO Max naming debacle, it might take the board quite a while to make its mind up.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/hbo-max-is-getting-even-more-expensive-starting-today-143939446.html?src=rss",
          "feed_position": 16
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/perplexity-made-a-tv-app-and-its-coming-to-samsung-sets-143000479.html",
          "published_at": "Tue, 21 Oct 2025 14:30:00 +0000",
          "title": "Perplexity made a TV app and it’s coming to Samsung sets",
          "standfirst": "Samsung is partnering with Perplexity to bring the startup’s AI Search engine to its smart TVs. If you own a 2025 Samsung TV, you can start using the app today. The company will bring the software to older 2024 and 2023 sets later this year via an OTA update. As part of today’s announcement, Perplexity is also offering free 12-month subscriptions to its Pro plan. To redeem the offer, you’ll need to scan the QR code that appears within the new app. As mentioned, Perplexity is an AI search engine. Before OpenAI, Anthropic and others added similar capabilities to their chatbots, Perplexity’s offering was novel, giving users a way to search the web more deeply than even Google allowed at the time. Things have gotten even more competitive in recent months, with Google going all in on AI Mode in Search. Still, if you want to try different, it’s worth seeing what Perplexity has to offer. The company’s Samsung TV app allows users to both type and use their voice to ask questions. No matter how you slice it, this is a curious partnership. Perplexity doesn’t have a great reputation, even when you consider the broader AI industry. In August, Cloudflare accused the company of scraping websites it wasn’t supposed to be. Later that same month, two of Japan’s largest media companies sued the company for copyright infringement, alleging it not only stole information from them but also attributed falsehoods to them. And just last month, Merriam-Webster sued Perplexity as well, again alleging copyright infringement. This article originally appeared on Engadget at https://www.engadget.com/ai/perplexity-made-a-tv-app-and-its-coming-to-samsung-sets-143000479.html?src=rss",
          "content": "Samsung is partnering with Perplexity to bring the startup’s AI Search engine to its smart TVs. If you own a 2025 Samsung TV, you can start using the app today. The company will bring the software to older 2024 and 2023 sets later this year via an OTA update. As part of today’s announcement, Perplexity is also offering free 12-month subscriptions to its Pro plan. To redeem the offer, you’ll need to scan the QR code that appears within the new app. As mentioned, Perplexity is an AI search engine. Before OpenAI, Anthropic and others added similar capabilities to their chatbots, Perplexity’s offering was novel, giving users a way to search the web more deeply than even Google allowed at the time. Things have gotten even more competitive in recent months, with Google going all in on AI Mode in Search. Still, if you want to try different, it’s worth seeing what Perplexity has to offer. The company’s Samsung TV app allows users to both type and use their voice to ask questions. No matter how you slice it, this is a curious partnership. Perplexity doesn’t have a great reputation, even when you consider the broader AI industry. In August, Cloudflare accused the company of scraping websites it wasn’t supposed to be. Later that same month, two of Japan’s largest media companies sued the company for copyright infringement, alleging it not only stole information from them but also attributed falsehoods to them. And just last month, Merriam-Webster sued Perplexity as well, again alleging copyright infringement. This article originally appeared on Engadget at https://www.engadget.com/ai/perplexity-made-a-tv-app-and-its-coming-to-samsung-sets-143000479.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/ipad-pro-m5-review-speed-boost-130046249.html",
          "published_at": "Tue, 21 Oct 2025 13:00:46 +0000",
          "title": "iPad Pro M5 review: Speed boost",
          "standfirst": "Apple is back with the latest version of the iPad Pro, and like the iPad Air earlier this year the surface-level changes are minimal. Like that iPad Air, there’s a new chip on board here. It’s the M5, which was also added to the 14-inch MacBook Pro and Vision Pro. There are new Apple-designed networking chips: the N1 handles Wi-Fi 7, Bluetooth 6 and Thread, while the C1X handles 5G connectivity. Both of those chips debuted in the iPhone Air last month, so this is the first time they’re in an iPad. Finally, the iPad Pro supports fast charging for the first time; you can get to a 50 percent charge in about 30 minutes using a 60W power adaptor. Compared to the redesign Apple introduced with the M4 iPad Pro in 2024, this is very much a minor spec bump. It makes sense for Apple to ensure the iPad Pro has its most performant chips as soon as they are released. If you’re charging customers upwards of $1,000 for an iPad Pro, it had better be on the bleeding edge. (The 13-inch iPad Pro I'm testing with 1TB of storage and 5G connectivity costs $2,099, plus the $349 Magic Keyboard.) As such, the iPad Pro M5 is fairly easy to understand. Want a new iPad Pro? You’re now getting exactly what Apple offered a week ago, plus some impressive performance gains for specific tasks. Almost no one who bought an M4 iPad Pro should upgrade to this one, but anyone using an older model will find a ton to appreciate here. And while the hardware hasn’t radically changed, iPadOS has. The recent iPadOS 26 release introduced an entirely new multitasking system, a significantly improved Files app and more support for background processes, to name just a few of the highlights. Those things are best appreciated on a powerful device with a large screen like the 13-inch iPad Pro M5 I’m reviewing here. For years, the question that has dogged the iPad Pro is when its software would match up to its undeniably impressive hardware. I think the combo of iPadOS 26 paired with this hardware is a winner, but as always the price is going to be a sticking point. M5 As mentioned, the M5 chip is the big change for the iPad Pro, and if you’re coming from a device older than last year’s M4 model you can expect a big performance increase when you start pushing the envelope of what you can do. Before getting into the nitty gritty, here’s a rundown of what’s different from last year. Probably the most significant change is that the M5’s GPU now includes a “neural accelerator” on each of its 10 cores, an architectural tweak that’ll unsurprisingly give the chip more muscle when using the GPU for AI-related tasks. Beyond the neural accelerators, the GPU is also up to 30 percent faster in graphics performance, and the third-generation ray-tracing engine here is up to 45 percent faster in apps using ray tracing. Nathan Ingraham for Engadget The standard CPU cores (four performance, six efficiency) are also faster than last year’s model, though less dramatically so. That’s not a surprise, as each successive M-series chip has gotten similar modest performance gains over the years. (Note that the iPad Pros with 256GB or 512GB of storage only get three performance cores. They also come with 12GB of RAM compared to the 16GB in configurations with more storage, but that’s more than the 8GB of RAM in the last generation’s equivalent options.) The Neural Engine has been upgraded, as well. Apple is also promising big gains in memory bandwidth, which now hits 153GB/s (nearly 30 percent higher than on the M4). Finally, read/write speeds to storage are up to two times faster than in last year’s model. Doing some benchmarking with the Geekbench 6 and Geekbench AI apps show the expected major gains for GPU and AI performance. Single-core and multi-core CPU tests with Geekbench 6 come in at about 15 percent and 10 percent better than the iPad Pro M4, but GPU performance has increased more than 32 percent. Things are more dramatic when you look specifically at the Geekbench AI results. The app offers three scores (single precision, half precision and quantized) and can be run on three different chip backends (CPU, GPU and Neural Engine). When running the CPU- and Neural Engine-based benchmarks, the M5 only bested the M4 by single-digit percentages. But when using the GPU, the M5’s single-precision score was 22.4 percent better than the M4. Half precision and quantized performance was even more impressive — the M5 scored 85 percent and 101 percent better than the M4, respectively. The story this tells is that unless you’re hitting your GPU hard with AI tasks, the M5 isn’t massively better than the M4. Not a huge surprise, and most people who shelled out for an iPad Pro in the last 18 months should still be plenty happy with their purchases. But those GPU scores show off exactly where the M5 can stretch its wings compared to its predecessor. As I’ve only had the iPad Pro M5 for less than a week, I’m still comparing the M4 to M5 iPad Pro on specific AI-focused tasks and in certain apps and will update this review with more details later this week. The caveat with all of this is that while the M5 is incredibly powerful, it’s also overkill for most things that people are going to use an iPad for. An iPad Pro with the M2 chip from 2022 still feels plenty responsive for most standard tasks that don’t require exceptional speed or power. Yes, there are definitely people buying an iPad Pro and maxing out its impressive capabilities, and those who do so will appreciate the performance here. But for everyone else, the M5 alone isn’t going to change how you use the iPad Pro on a day-to-day basis. Apple's 13-inch iPad Pro M5 is on the left; the 11-inch iPad Pro M4 is on the right. Nathan Ingraham for Engadget Hardware and display are still stunning Anyone upgrading from an iPad Pro older than last year’s M4 model is in for a treat far beyond sheer performance. The iPad Pro M5 is physically identical to the prior one, but that doesn’t matter because I think this is still the single most impressive device Apple makes. I went deep into the many changes Apple made last year in my review of the iPad Pro M4, and everything I said there still applies. But to recap, the iPad Pro is extremely portable despite its performance chops. Apple made it about 20 percent thinner and about a quarter-pound lighter than the iPad Pro models Apple sold from 2018 through 2023. This radically improves the experience of using it. If you’re holding it like a tablet, the 13-inch model is now light and thin enough to be comfortable for extended use without having to put it down. Doing anything with the on-screen keyboard while holding it is still pretty awkward and the 11-inch option still feels like the best size for hand-held tasks. But the 13-inch iPad Pro I’m reviewing is noticeably easier to hold than the iPad Air because of its reduced weight and slimmer profile. The only complaint I might have about that thinness is it prevents Apple from shoving a bigger battery in here. The iPad Pro M5 gets the same 10-hour battery life rating (for surfing the web or watching videos) that every iPad has gotten since the tablet was released in 2010. But in recent years, Apple has, to some degree, stopped focusing on making every device as thin as possible at the potential expense of things like performance or battery life. Clearly, performance isn’t an issue here. But the same people who value extended battery life in a thicker device when using things like the MacBook Pro might feel the same here. Nathan Ingraham for Engadget That’s a valid opinion, but a tablet is meant to be held in your hands and carried around with you even more so than a laptop, so I understand why Apple values portability over extending the iPad Pro’s battery life. Plus, the iPad Pro M5’s fast-charging capabilities make it pretty easy to extend its life. Using Apple's new 40W Dynamic Charger that can automatically step up to 60W, I got from 23 percent to 70 percent in 35 minutes. That’s a tad slower than the 50 percent charge in 30 minutes Apple claims, but we’re well within the “close enough” range. One thing I didn’t get to test last year with the iPad Pro M4 was its durability. The tablet’s extremely thin design reminded people of past Apple devices that had had some issues with flexing. After over a year with the previous iPad Pro, I’m not at all worried about this one. I’ve taken an iPad Pro M4 all around the US and internationally with no issues. Granted, it’s usually in its keyboard case, but I’ve also traveled with it in the basic Smart Folio Apple sells and have seen no evidence of bending. I also don’t remember seeing any reports about durability issues from owners over the last 18 months, so I wouldn’t worry about its long-term durability. I don’t have a great read on how long the iPad Pro M5 lasts away from its charger just yet — in the first few days with a new device it’s often downloading a lot of data from backups and doing some optimizing, thus not giving you a great feel for how long it’ll usually last. But so far, performance seems similar to the iPad Air M3 and iPad Pro M4 I’ve reviewed recently. I was getting between seven and eight hours while using the Magic Keyboard, and I’m guessing that I’ll blow past the 10-hour estimate when watching locally-stored video. More details on that to come. Nathan Ingraham for Engadget Performance, check. Design, check. The third thing that continues to impress me about the iPad Pro is its screen. It quite simply has the nicest display I have ever seen on a portable device, be it a laptop, phone or tablet. Apple’s tandem OLED display (two OLED panels layered on top of each other) is the same in all respects as it was last year. That means the 13-inch screen has a 2,752 x 2,064 resolution (264 ppi) and standard brightness that can hit 1,000 nits, or up to 1,600 nits peak for HDR content. Aside from the OLED display, the only display improvements the iPad Pro has that the iPad Air doesn’t is ProMotion support for 120Hz refresh rates as well as a nano-texture glass option for the 1TB and 2TB models. To be clear, though, the iPad Pro’s screen is in a completely different ballpark than the one on the iPad Air. Between the much faster refresh rate, high brightness levels, completely dark blacks and wonderful contrast, there’s no question this screen far surpasses what you’ll find on any other iPad. Professionals who do detailed work in video, photography, drawing with the Apple Pencil Pro or graphic design will appreciate all of these features. But it also makes something like kicking back on a plane to watch a movie more enjoyable. Nathan Ingraham for Engadget iPadOS 26 In last year’s iPad Pro M4 review, I wrote: “Apple has shown no indication it’s going to make iPadOS more like a Mac.” As such, I recommended people not buy an iPad Pro unless they were happy with the limitations that have been inherent to iPadOS for a long time. It took Apple until this summer, but its latest updates rendered my earlier words invalid. With iPadOS 26, Apple pretty much said “screw it” and addressed nearly every big software complaint users have had. As a quick refresher: apps still open in full screen by default, but you can now grab the corner and resize it to any shape you see fit; you can then stack up as many windows as you want in that view. Apps are also much better at remembering their size and position on your screen than ever before. If you swipe up and dismiss all the apps you’re working with and then re-open one, it’s right in the same place you left it. If you want to throw something back in full-screen, the familiar “stoplight” controls from the Mac are available for easy window management. You can swipe up and hold for a second from the bottom of the screen to enter Expose, which shows every open window in your view. Swiping right shows all the full-screen apps you have open. If you have an app in full screen, you can switch back to a windowed app that’ll just float on top of what you’re working in. There’s also a menu bar at the top of the screen that makes it easy to access advanced controls for whatever you’re using. As I said when I first started testing out iPadOS 26 in the summer, the end result of all these changes is that your iPad (no matter which kind) will feel significantly more capable with this software update. And there are other features that power users will appreciate, like a significantly improved Files app. Since it’s easier to have multiple windows, moving things around or dragging and dropping things into apps is a lot simpler. And there are improved sorting options as well, while PDFs finally open in the new Preview app rather than within Files . Background task capabilities have also been significantly expanded. For example, Final Cut Pro can now render video in the background, whereas before, switching to a different app would put the lengthy and intensive process on pause. And developers can tap into this API to use it for their own apps, too. I can’t say for sure that this will answer all the complaints of various iPad Pro owners out there, but I think Apple has gotten about as close as it can without just putting macOS on the device and calling it a day. Even with the big updates to iPadOS, an iPad Pro isn’t for everyone. Plenty of people will still choose a traditional laptop. But the iPad has always offered a pretty unique blend of power and portability, and with better software it’s a more viable option than ever. Nathan Ingraham for Engadget Wrap-up My viewpoint on the iPad Pro hasn’t changed since last year. I still find it a wildly impressive device that is unlike much else you can buy. Just like the last model, it has Apple’s newest chip, the best display Apple has made (aside from its $5,000 Pro XDR monitor) and a physical design that feels almost impossible given how much technology is crammed inside. It’s truly delightful, and it’s even more capable than before thanks to the combination of iPadOS 26 and the M5 chip. However, I still can’t stomach that price. $1,299 for a 13-inch iPad with 256GB of storage, no 5G connectivity and no Magic Keyboard is a lot of money, even if it is as capable as a similarly-priced laptop. Given the incredible technology inside of the iPad Pro, I can understand why it’s so expensive. And it's powerful enough that some buyers will be able to use it for three, four, even five years before they feel the need to update, which makes the up-front investment a little less burdensome. It's not the kind of device you need to replace annually, that's for sure. But unless you are going to use it as your main computer — all day, every day — and know exactly what benefits you’ll get from the iPad over a more traditional laptop, you’re probably better off buying an iPad Air and saving yourself a lot of money.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/ipad-pro-m5-review-speed-boost-130046249.html?src=rss",
          "content": "Apple is back with the latest version of the iPad Pro, and like the iPad Air earlier this year the surface-level changes are minimal. Like that iPad Air, there’s a new chip on board here. It’s the M5, which was also added to the 14-inch MacBook Pro and Vision Pro. There are new Apple-designed networking chips: the N1 handles Wi-Fi 7, Bluetooth 6 and Thread, while the C1X handles 5G connectivity. Both of those chips debuted in the iPhone Air last month, so this is the first time they’re in an iPad. Finally, the iPad Pro supports fast charging for the first time; you can get to a 50 percent charge in about 30 minutes using a 60W power adaptor. Compared to the redesign Apple introduced with the M4 iPad Pro in 2024, this is very much a minor spec bump. It makes sense for Apple to ensure the iPad Pro has its most performant chips as soon as they are released. If you’re charging customers upwards of $1,000 for an iPad Pro, it had better be on the bleeding edge. (The 13-inch iPad Pro I'm testing with 1TB of storage and 5G connectivity costs $2,099, plus the $349 Magic Keyboard.) As such, the iPad Pro M5 is fairly easy to understand. Want a new iPad Pro? You’re now getting exactly what Apple offered a week ago, plus some impressive performance gains for specific tasks. Almost no one who bought an M4 iPad Pro should upgrade to this one, but anyone using an older model will find a ton to appreciate here. And while the hardware hasn’t radically changed, iPadOS has. The recent iPadOS 26 release introduced an entirely new multitasking system, a significantly improved Files app and more support for background processes, to name just a few of the highlights. Those things are best appreciated on a powerful device with a large screen like the 13-inch iPad Pro M5 I’m reviewing here. For years, the question that has dogged the iPad Pro is when its software would match up to its undeniably impressive hardware. I think the combo of iPadOS 26 paired with this hardware is a winner, but as always the price is going to be a sticking point. M5 As mentioned, the M5 chip is the big change for the iPad Pro, and if you’re coming from a device older than last year’s M4 model you can expect a big performance increase when you start pushing the envelope of what you can do. Before getting into the nitty gritty, here’s a rundown of what’s different from last year. Probably the most significant change is that the M5’s GPU now includes a “neural accelerator” on each of its 10 cores, an architectural tweak that’ll unsurprisingly give the chip more muscle when using the GPU for AI-related tasks. Beyond the neural accelerators, the GPU is also up to 30 percent faster in graphics performance, and the third-generation ray-tracing engine here is up to 45 percent faster in apps using ray tracing. Nathan Ingraham for Engadget The standard CPU cores (four performance, six efficiency) are also faster than last year’s model, though less dramatically so. That’s not a surprise, as each successive M-series chip has gotten similar modest performance gains over the years. (Note that the iPad Pros with 256GB or 512GB of storage only get three performance cores. They also come with 12GB of RAM compared to the 16GB in configurations with more storage, but that’s more than the 8GB of RAM in the last generation’s equivalent options.) The Neural Engine has been upgraded, as well. Apple is also promising big gains in memory bandwidth, which now hits 153GB/s (nearly 30 percent higher than on the M4). Finally, read/write speeds to storage are up to two times faster than in last year’s model. Doing some benchmarking with the Geekbench 6 and Geekbench AI apps show the expected major gains for GPU and AI performance. Single-core and multi-core CPU tests with Geekbench 6 come in at about 15 percent and 10 percent better than the iPad Pro M4, but GPU performance has increased more than 32 percent. Things are more dramatic when you look specifically at the Geekbench AI results. The app offers three scores (single precision, half precision and quantized) and can be run on three different chip backends (CPU, GPU and Neural Engine). When running the CPU- and Neural Engine-based benchmarks, the M5 only bested the M4 by single-digit percentages. But when using the GPU, the M5’s single-precision score was 22.4 percent better than the M4. Half precision and quantized performance was even more impressive — the M5 scored 85 percent and 101 percent better than the M4, respectively. The story this tells is that unless you’re hitting your GPU hard with AI tasks, the M5 isn’t massively better than the M4. Not a huge surprise, and most people who shelled out for an iPad Pro in the last 18 months should still be plenty happy with their purchases. But those GPU scores show off exactly where the M5 can stretch its wings compared to its predecessor. As I’ve only had the iPad Pro M5 for less than a week, I’m still comparing the M4 to M5 iPad Pro on specific AI-focused tasks and in certain apps and will update this review with more details later this week. The caveat with all of this is that while the M5 is incredibly powerful, it’s also overkill for most things that people are going to use an iPad for. An iPad Pro with the M2 chip from 2022 still feels plenty responsive for most standard tasks that don’t require exceptional speed or power. Yes, there are definitely people buying an iPad Pro and maxing out its impressive capabilities, and those who do so will appreciate the performance here. But for everyone else, the M5 alone isn’t going to change how you use the iPad Pro on a day-to-day basis. Apple's 13-inch iPad Pro M5 is on the left; the 11-inch iPad Pro M4 is on the right. Nathan Ingraham for Engadget Hardware and display are still stunning Anyone upgrading from an iPad Pro older than last year’s M4 model is in for a treat far beyond sheer performance. The iPad Pro M5 is physically identical to the prior one, but that doesn’t matter because I think this is still the single most impressive device Apple makes. I went deep into the many changes Apple made last year in my review of the iPad Pro M4, and everything I said there still applies. But to recap, the iPad Pro is extremely portable despite its performance chops. Apple made it about 20 percent thinner and about a quarter-pound lighter than the iPad Pro models Apple sold from 2018 through 2023. This radically improves the experience of using it. If you’re holding it like a tablet, the 13-inch model is now light and thin enough to be comfortable for extended use without having to put it down. Doing anything with the on-screen keyboard while holding it is still pretty awkward and the 11-inch option still feels like the best size for hand-held tasks. But the 13-inch iPad Pro I’m reviewing is noticeably easier to hold than the iPad Air because of its reduced weight and slimmer profile. The only complaint I might have about that thinness is it prevents Apple from shoving a bigger battery in here. The iPad Pro M5 gets the same 10-hour battery life rating (for surfing the web or watching videos) that every iPad has gotten since the tablet was released in 2010. But in recent years, Apple has, to some degree, stopped focusing on making every device as thin as possible at the potential expense of things like performance or battery life. Clearly, performance isn’t an issue here. But the same people who value extended battery life in a thicker device when using things like the MacBook Pro might feel the same here. Nathan Ingraham for Engadget That’s a valid opinion, but a tablet is meant to be held in your hands and carried around with you even more so than a laptop, so I understand why Apple values portability over extending the iPad Pro’s battery life. Plus, the iPad Pro M5’s fast-charging capabilities make it pretty easy to extend its life. Using Apple's new 40W Dynamic Charger that can automatically step up to 60W, I got from 23 percent to 70 percent in 35 minutes. That’s a tad slower than the 50 percent charge in 30 minutes Apple claims, but we’re well within the “close enough” range. One thing I didn’t get to test last year with the iPad Pro M4 was its durability. The tablet’s extremely thin design reminded people of past Apple devices that had had some issues with flexing. After over a year with the previous iPad Pro, I’m not at all worried about this one. I’ve taken an iPad Pro M4 all around the US and internationally with no issues. Granted, it’s usually in its keyboard case, but I’ve also traveled with it in the basic Smart Folio Apple sells and have seen no evidence of bending. I also don’t remember seeing any reports about durability issues from owners over the last 18 months, so I wouldn’t worry about its long-term durability. I don’t have a great read on how long the iPad Pro M5 lasts away from its charger just yet — in the first few days with a new device it’s often downloading a lot of data from backups and doing some optimizing, thus not giving you a great feel for how long it’ll usually last. But so far, performance seems similar to the iPad Air M3 and iPad Pro M4 I’ve reviewed recently. I was getting between seven and eight hours while using the Magic Keyboard, and I’m guessing that I’ll blow past the 10-hour estimate when watching locally-stored video. More details on that to come. Nathan Ingraham for Engadget Performance, check. Design, check. The third thing that continues to impress me about the iPad Pro is its screen. It quite simply has the nicest display I have ever seen on a portable device, be it a laptop, phone or tablet. Apple’s tandem OLED display (two OLED panels layered on top of each other) is the same in all respects as it was last year. That means the 13-inch screen has a 2,752 x 2,064 resolution (264 ppi) and standard brightness that can hit 1,000 nits, or up to 1,600 nits peak for HDR content. Aside from the OLED display, the only display improvements the iPad Pro has that the iPad Air doesn’t is ProMotion support for 120Hz refresh rates as well as a nano-texture glass option for the 1TB and 2TB models. To be clear, though, the iPad Pro’s screen is in a completely different ballpark than the one on the iPad Air. Between the much faster refresh rate, high brightness levels, completely dark blacks and wonderful contrast, there’s no question this screen far surpasses what you’ll find on any other iPad. Professionals who do detailed work in video, photography, drawing with the Apple Pencil Pro or graphic design will appreciate all of these features. But it also makes something like kicking back on a plane to watch a movie more enjoyable. Nathan Ingraham for Engadget iPadOS 26 In last year’s iPad Pro M4 review, I wrote: “Apple has shown no indication it’s going to make iPadOS more like a Mac.” As such, I recommended people not buy an iPad Pro unless they were happy with the limitations that have been inherent to iPadOS for a long time. It took Apple until this summer, but its latest updates rendered my earlier words invalid. With iPadOS 26, Apple pretty much said “screw it” and addressed nearly every big software complaint users have had. As a quick refresher: apps still open in full screen by default, but you can now grab the corner and resize it to any shape you see fit; you can then stack up as many windows as you want in that view. Apps are also much better at remembering their size and position on your screen than ever before. If you swipe up and dismiss all the apps you’re working with and then re-open one, it’s right in the same place you left it. If you want to throw something back in full-screen, the familiar “stoplight” controls from the Mac are available for easy window management. You can swipe up and hold for a second from the bottom of the screen to enter Expose, which shows every open window in your view. Swiping right shows all the full-screen apps you have open. If you have an app in full screen, you can switch back to a windowed app that’ll just float on top of what you’re working in. There’s also a menu bar at the top of the screen that makes it easy to access advanced controls for whatever you’re using. As I said when I first started testing out iPadOS 26 in the summer, the end result of all these changes is that your iPad (no matter which kind) will feel significantly more capable with this software update. And there are other features that power users will appreciate, like a significantly improved Files app. Since it’s easier to have multiple windows, moving things around or dragging and dropping things into apps is a lot simpler. And there are improved sorting options as well, while PDFs finally open in the new Preview app rather than within Files . Background task capabilities have also been significantly expanded. For example, Final Cut Pro can now render video in the background, whereas before, switching to a different app would put the lengthy and intensive process on pause. And developers can tap into this API to use it for their own apps, too. I can’t say for sure that this will answer all the complaints of various iPad Pro owners out there, but I think Apple has gotten about as close as it can without just putting macOS on the device and calling it a day. Even with the big updates to iPadOS, an iPad Pro isn’t for everyone. Plenty of people will still choose a traditional laptop. But the iPad has always offered a pretty unique blend of power and portability, and with better software it’s a more viable option than ever. Nathan Ingraham for Engadget Wrap-up My viewpoint on the iPad Pro hasn’t changed since last year. I still find it a wildly impressive device that is unlike much else you can buy. Just like the last model, it has Apple’s newest chip, the best display Apple has made (aside from its $5,000 Pro XDR monitor) and a physical design that feels almost impossible given how much technology is crammed inside. It’s truly delightful, and it’s even more capable than before thanks to the combination of iPadOS 26 and the M5 chip. However, I still can’t stomach that price. $1,299 for a 13-inch iPad with 256GB of storage, no 5G connectivity and no Magic Keyboard is a lot of money, even if it is as capable as a similarly-priced laptop. Given the incredible technology inside of the iPad Pro, I can understand why it’s so expensive. And it's powerful enough that some buyers will be able to use it for three, four, even five years before they feel the need to update, which makes the up-front investment a little less burdensome. It's not the kind of device you need to replace annually, that's for sure. But unless you are going to use it as your main computer — all day, every day — and know exactly what benefits you’ll get from the iPad over a more traditional laptop, you’re probably better off buying an iPad Air and saving yourself a lot of money.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/ipad-pro-m5-review-speed-boost-130046249.html?src=rss",
          "feed_position": 18,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/d1c1d911-ae0f-11f0-adf6-237a61d04241"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-111553740.html",
          "published_at": "Tue, 21 Oct 2025 11:15:53 +0000",
          "title": "The Morning After: Amazon broke the internet (for a bit)",
          "standfirst": "A decent-sized chunk of the internet stopped working after a fairly massive Amazon Web Services (AWS) outage. This included Venmo, Snapchat, Canva and Fortnite — even Amazon’s own products went on the fritz. Your humble narrator’s Ring Chimes started turning their night lights on and off entirely at random, with no prompting from yours truly. The company has already fixed the DNS issue that caused the outage, but a failure like this, which knocks out so damn much of the internet, should serve as a reminder. After all, having so many critical systems in the same basket means that when something goes wrong, a lot of the internet stops working. All at once. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Atari just announced the Intellivision Spirit, a revamp of the iconic 1980s gaming consoleComplete with games you’ll probably try once then never again. 8BitDo drops an NES-inspired collection for the console’s 40th anniversaryIncluding our favorite Switch controller. China claims the NSA conducted cyberattacks on its national time centerThis is fine, honestly, totally fine. Meta Ray-Ban Display review: Chunky frames with impressive abilities The next generation of smart glasses has arrived. Karissa Bell for Engadget It’s teeth-grindingly frustrating that Meta seems to be the company that has worked out how to make a truly transformative pair of smart glasses. Karissa Bell has reviewed its new Ray-Ban Display and has plenty of praise for so much of what it can do. You should read her exhaustive review to learn more, but the biggest barriers to adoption are size and price. But you can bet your bottom dollar the second or third generation of these are going to be a smash hit. At least until Meta gets rocked by another scandal that prompts people to deactivate their accounts. Continue Reading. Amazon reveals what one of the US’ first modular nuclear reactors will look like It’s an anonymous-looking warehouse. Amazon Last year, Amazon announced it would bankroll construction of a small nuclear reactor (SMR) plant in Washington state. Now, the company is showing off renders of the Hanford facility, which look like any other anonymous-looking modern warehouse. If you’re curious, the SMRs in question will use high-temperature gas-cooled reactors, each one with a maximum output of 80 megawatts. Continue Reading. Beats Powerbeats Fit review: Déjà vu, in a good way A few small tweaks add up to a nicer package. Valentina Palladino for Engadget Apple has updated the Beats Fit Pro with more flexible wingtips, a smaller charging case and the added benefits of Apple’s H1 chip. Valentina Palladino has been testing them out and can tell you the good, the bad and the ugly about these updated earbuds. And, if I’m honest, there’s not much that’s bad or ugly about them. Maybe the battery life could be a bit longer. Continue Reading. Apple is the new home for F1 in the US starting in 2026 It’s a pretty sweet deal given what’s thrown in. Apple In what can only be described as the least surprising sports rights streaming TV deal ever, Apple TV is the new home of F1 in the US. The five-year pact starts next year, with every practice, qualifying, sprint and race streaming live on Apple TV. Even better is that F1’s own excellent streaming platform, F1 TV Premium, will be a free perk for Apple TV subscribers. Continue Reading. Bose QuietComfort Ultra Headphones (2nd gen) review: Impactful upgrades to a familiar formula Sony finally has a worthy rival. Billy Steele for Engadget Bose opted for evolution over revolution for its 2025 series of QuietComfort Ultra products and is garnering rave reviews. Billy Steele is effusive with praise, calling them “the best noise canceling headphones you can buy right now.” It looks as if someone has finally been able to lay a finger on Sony’s previously imperious XM series, even if Bose’s glossy finish is a bit much. Continue Reading. Samsung Galaxy S25 FE review: Iterative to a fault A swing and a miss for Samsung. Igor Bonafacic for Engadget Samsung follows each flagship phone launch with a Fan Edition, which trims the spec list to get the price down. Igor Bonifacic has reviewed the S25 FE and found a phone designed for an older paradigm, before cheaper rivals like the Nothing 3a Pro and Pixel 10 came along. His recommendation? Buy last year’s full-fat model during a sale and swerve the compromises. Continue Reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111553740.html?src=rss",
          "content": "A decent-sized chunk of the internet stopped working after a fairly massive Amazon Web Services (AWS) outage. This included Venmo, Snapchat, Canva and Fortnite — even Amazon’s own products went on the fritz. Your humble narrator’s Ring Chimes started turning their night lights on and off entirely at random, with no prompting from yours truly. The company has already fixed the DNS issue that caused the outage, but a failure like this, which knocks out so damn much of the internet, should serve as a reminder. After all, having so many critical systems in the same basket means that when something goes wrong, a lot of the internet stops working. All at once. — Dan Cooper Get Engadget's newsletter delivered direct to your inbox. Subscribe right here! The news you might have missed Atari just announced the Intellivision Spirit, a revamp of the iconic 1980s gaming consoleComplete with games you’ll probably try once then never again. 8BitDo drops an NES-inspired collection for the console’s 40th anniversaryIncluding our favorite Switch controller. China claims the NSA conducted cyberattacks on its national time centerThis is fine, honestly, totally fine. Meta Ray-Ban Display review: Chunky frames with impressive abilities The next generation of smart glasses has arrived. Karissa Bell for Engadget It’s teeth-grindingly frustrating that Meta seems to be the company that has worked out how to make a truly transformative pair of smart glasses. Karissa Bell has reviewed its new Ray-Ban Display and has plenty of praise for so much of what it can do. You should read her exhaustive review to learn more, but the biggest barriers to adoption are size and price. But you can bet your bottom dollar the second or third generation of these are going to be a smash hit. At least until Meta gets rocked by another scandal that prompts people to deactivate their accounts. Continue Reading. Amazon reveals what one of the US’ first modular nuclear reactors will look like It’s an anonymous-looking warehouse. Amazon Last year, Amazon announced it would bankroll construction of a small nuclear reactor (SMR) plant in Washington state. Now, the company is showing off renders of the Hanford facility, which look like any other anonymous-looking modern warehouse. If you’re curious, the SMRs in question will use high-temperature gas-cooled reactors, each one with a maximum output of 80 megawatts. Continue Reading. Beats Powerbeats Fit review: Déjà vu, in a good way A few small tweaks add up to a nicer package. Valentina Palladino for Engadget Apple has updated the Beats Fit Pro with more flexible wingtips, a smaller charging case and the added benefits of Apple’s H1 chip. Valentina Palladino has been testing them out and can tell you the good, the bad and the ugly about these updated earbuds. And, if I’m honest, there’s not much that’s bad or ugly about them. Maybe the battery life could be a bit longer. Continue Reading. Apple is the new home for F1 in the US starting in 2026 It’s a pretty sweet deal given what’s thrown in. Apple In what can only be described as the least surprising sports rights streaming TV deal ever, Apple TV is the new home of F1 in the US. The five-year pact starts next year, with every practice, qualifying, sprint and race streaming live on Apple TV. Even better is that F1’s own excellent streaming platform, F1 TV Premium, will be a free perk for Apple TV subscribers. Continue Reading. Bose QuietComfort Ultra Headphones (2nd gen) review: Impactful upgrades to a familiar formula Sony finally has a worthy rival. Billy Steele for Engadget Bose opted for evolution over revolution for its 2025 series of QuietComfort Ultra products and is garnering rave reviews. Billy Steele is effusive with praise, calling them “the best noise canceling headphones you can buy right now.” It looks as if someone has finally been able to lay a finger on Sony’s previously imperious XM series, even if Bose’s glossy finish is a bit much. Continue Reading. Samsung Galaxy S25 FE review: Iterative to a fault A swing and a miss for Samsung. Igor Bonafacic for Engadget Samsung follows each flagship phone launch with a Fan Edition, which trims the spec list to get the price down. Igor Bonifacic has reviewed the S25 FE and found a phone designed for an older paradigm, before cheaper rivals like the Nothing 3a Pro and Pixel 10 came along. His recommendation? Buy last year’s full-fat model during a sale and swerve the compromises. Continue Reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-111553740.html?src=rss",
          "feed_position": 21,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/97b73640-ae62-11f0-8df9-30df1506b776"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/yelp-is-getting-more-ai-including-an-upgraded-chatbot-110051320.html",
          "published_at": "Tue, 21 Oct 2025 11:00:51 +0000",
          "title": "Yelp is getting more AI, including an upgraded chatbot",
          "standfirst": "AI is the star of Yelp's fall product update. The review site has updated Yelp Assistant, its chatbot to answer users' questions, rolling the tool out for all business categories. Its responses will draw on information from the business' website as well as posts by other Yelp users. The chatbot will also remember past queries and preferences when it's used for finding services. Saved information can be managed in the Yelp app under Yelp Assistant memory settings. Yelp has been pushing more artificial intelligence into its platform, adding Review Insights in December and announcing calling features in April. The AI-powered calling is rolling out in the company's fall update as Yelp Host and Yelp Receptionist. Yelp Host is specifically for table-service restaurants, and promises the ability to take reservations, change bookings and capture special requests. It is available now starting at $149 a month, or $99 a month for customers with a Yelp Guest Manager plan. Yelp Receptionist can manage calls for any \"eligible local businesses.\" Subscriptions to this AI-powered service start at $99 a month and will begin rolling out this week. There are several other updates from Yelp, but one of the more interesting ones is Menu Vision. With this resource, pointing your camera at a restaurant's menu will show photos of the dish in question along with reviews about that particular item. Menu Vision will arrive on the iOS and Android apps this week.This article originally appeared on Engadget at https://www.engadget.com/ai/yelp-is-getting-more-ai-including-an-upgraded-chatbot-110051320.html?src=rss",
          "content": "AI is the star of Yelp's fall product update. The review site has updated Yelp Assistant, its chatbot to answer users' questions, rolling the tool out for all business categories. Its responses will draw on information from the business' website as well as posts by other Yelp users. The chatbot will also remember past queries and preferences when it's used for finding services. Saved information can be managed in the Yelp app under Yelp Assistant memory settings. Yelp has been pushing more artificial intelligence into its platform, adding Review Insights in December and announcing calling features in April. The AI-powered calling is rolling out in the company's fall update as Yelp Host and Yelp Receptionist. Yelp Host is specifically for table-service restaurants, and promises the ability to take reservations, change bookings and capture special requests. It is available now starting at $149 a month, or $99 a month for customers with a Yelp Guest Manager plan. Yelp Receptionist can manage calls for any \"eligible local businesses.\" Subscriptions to this AI-powered service start at $99 a month and will begin rolling out this week. There are several other updates from Yelp, but one of the more interesting ones is Menu Vision. With this resource, pointing your camera at a restaurant's menu will show photos of the dish in question along with reviews about that particular item. Menu Vision will arrive on the iOS and Android apps this week.This article originally appeared on Engadget at https://www.engadget.com/ai/yelp-is-getting-more-ai-including-an-upgraded-chatbot-110051320.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/best-action-camera-130017459.html",
          "published_at": "Tue, 21 Oct 2025 09:00:35 +0000",
          "title": "The best action cameras for 2025",
          "standfirst": "Whether you’re into adventure sports or just want to log your day-to-day activities, an action camera is the way to go. On top of regular models from the likes of GoPro, DJI and Insta360, you can film your adventures with 360-degree models and a new class of tiny cams that can even be attached to kids or pets. In other words, there are more options than ever for types of action shooting or vlogging.With all the new choices, which have the best features for your personal exploits? Engadget has been testing action cameras for more than 16 years and with that experience, we can help you find the right model for your budget and needs. Best action cameras for 2025 What to consider before choosing an action camera Action cameras have certain traits that separate them from regular cameras or smartphones. The most important is ruggedness that makes them resistant to water, dust and shocks. Most models are now waterproof without the need for a separate enclosure. At the same time, you can purchase housing accessories to make them waterproof to even greater depths. Video quality is also key. Every model we recommend goes to at least 4K 60fps, but some models like GoPro’s latest Hero 13 boost resolution up to 5.3K 60fps, or even 8K 30fps with the Insta360 Ace Pro 2. That allows you to crop in on shots and capture vertical video at higher resolutions for social media. And for slow-mo, you’ll want at least 120 fps video, preferably at 4K or at least 2.7K. Another nice feature is log video that improves dynamic range when filming on sunny, contrasty days. And if you film in dim environments, you’ll want the largest sensor possible for the best low-light performance. Next is the question of flat versus 360 video. 360 cams have become incredibly popular lately because they capture video all around the camera, even above and below. Then, you can reframe the shots in post, cutting from a cool bike trick to your reaction, for example. Or, you can post the entire 360 video online and let the audience choose which angle they want to see. For activities with bumps and jolts like mountain biking, stabilization is incredibly important. You want your video to look smooth, but still convey the thrill and speed of the action. Cameras from DJI, GoPro and Insta360 are all good in this regard, but GoPro’s Hero 13 still tops the list. Some action cameras are easier to handle and use, so take that into account as well. You’ll want bright and colorful displays both front and back, buttons you won’t have to fumble to find and easy-to-use menus. Remote control is another factor that can ease operation. And you’ll want to check which software is available to improve stabilization, edit video, remove selfie sticks and more. Size has also become a factor, with tiny cameras having become an all-new category recently. Mini sized models like Insta360’s Go 3S and Go Ultra, along with DJI’s new Osmo Nano, let you separate the camera from the display for maximum portability. Whether it’s mounted on a hat or your chest, you’ll barely notice it’s there. Then there are accessories. Do you need helmet or chest mounts, waterproof housings or battery charger? GoPro has the largest number as it’s been around the longest, but DJI and Insta360 now have a solid accessory lineup and both make handy wireless mics that connect directly with their cameras. And of course, battery life is critical for action shooting as it’s hard to change one when you’re out surfing.This article originally appeared on Engadget at https://www.engadget.com/cameras/best-action-camera-130017459.html?src=rss",
          "content": "Whether you’re into adventure sports or just want to log your day-to-day activities, an action camera is the way to go. On top of regular models from the likes of GoPro, DJI and Insta360, you can film your adventures with 360-degree models and a new class of tiny cams that can even be attached to kids or pets. In other words, there are more options than ever for types of action shooting or vlogging.With all the new choices, which have the best features for your personal exploits? Engadget has been testing action cameras for more than 16 years and with that experience, we can help you find the right model for your budget and needs. Best action cameras for 2025 What to consider before choosing an action camera Action cameras have certain traits that separate them from regular cameras or smartphones. The most important is ruggedness that makes them resistant to water, dust and shocks. Most models are now waterproof without the need for a separate enclosure. At the same time, you can purchase housing accessories to make them waterproof to even greater depths. Video quality is also key. Every model we recommend goes to at least 4K 60fps, but some models like GoPro’s latest Hero 13 boost resolution up to 5.3K 60fps, or even 8K 30fps with the Insta360 Ace Pro 2. That allows you to crop in on shots and capture vertical video at higher resolutions for social media. And for slow-mo, you’ll want at least 120 fps video, preferably at 4K or at least 2.7K. Another nice feature is log video that improves dynamic range when filming on sunny, contrasty days. And if you film in dim environments, you’ll want the largest sensor possible for the best low-light performance. Next is the question of flat versus 360 video. 360 cams have become incredibly popular lately because they capture video all around the camera, even above and below. Then, you can reframe the shots in post, cutting from a cool bike trick to your reaction, for example. Or, you can post the entire 360 video online and let the audience choose which angle they want to see. For activities with bumps and jolts like mountain biking, stabilization is incredibly important. You want your video to look smooth, but still convey the thrill and speed of the action. Cameras from DJI, GoPro and Insta360 are all good in this regard, but GoPro’s Hero 13 still tops the list. Some action cameras are easier to handle and use, so take that into account as well. You’ll want bright and colorful displays both front and back, buttons you won’t have to fumble to find and easy-to-use menus. Remote control is another factor that can ease operation. And you’ll want to check which software is available to improve stabilization, edit video, remove selfie sticks and more. Size has also become a factor, with tiny cameras having become an all-new category recently. Mini sized models like Insta360’s Go 3S and Go Ultra, along with DJI’s new Osmo Nano, let you separate the camera from the display for maximum portability. Whether it’s mounted on a hat or your chest, you’ll barely notice it’s there. Then there are accessories. Do you need helmet or chest mounts, waterproof housings or battery charger? GoPro has the largest number as it’s been around the longest, but DJI and Insta360 now have a solid accessory lineup and both make handy wireless mics that connect directly with their cameras. And of course, battery life is critical for action shooting as it’s hard to change one when you’re out surfing.This article originally appeared on Engadget at https://www.engadget.com/cameras/best-action-camera-130017459.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/openai-releases-chatgpt-atlas-an-ai-enabled-web-browser-to-challenge-google",
          "published_at": "Tue, 21 Oct 2025 04:00:00 GMT",
          "title": "OpenAI announces ChatGPT Atlas, an AI-enabled web browser to challenge Google Chrome",
          "standfirst": "OpenAI is entering the browser world with the launch of ChatGPT Atlas, an AI-enabled browser. Atlas, now available globally, can be accessed through Apple’s macOS, with support for Windows, iOS, and Android coming soon. The announcement comes several months after rumors in July that OpenAI would release a web browser that would challenge the dominance of Google’s Chrome. OpenAI will make a formal announcement via livestream with CEO Sam Altman presenting Atlas.With more people using AI models and chat platforms for web searches, launching an AI-enabled browser has become another battleground for model providers. Of course, as Chrome has become more popular, it has slowly added AI capabilities thanks to the Gemini models. But companies like Perplexity, with its Comet browser, hoped to take on Chrome. Opera, long a Chrome competitor, also repositioned itself as an AI-powered browser by embedding AI features into its platform.",
          "content": "OpenAI is entering the browser world with the launch of ChatGPT Atlas, an AI-enabled browser. Atlas, now available globally, can be accessed through Apple’s macOS, with support for Windows, iOS, and Android coming soon. The announcement comes several months after rumors in July that OpenAI would release a web browser that would challenge the dominance of Google’s Chrome. OpenAI will make a formal announcement via livestream with CEO Sam Altman presenting Atlas.With more people using AI models and chat platforms for web searches, launching an AI-enabled browser has become another battleground for model providers. Of course, as Chrome has become more popular, it has slowly added AI capabilities thanks to the Gemini models. But companies like Perplexity, with its Comet browser, hoped to take on Chrome. Opera, long a Chrome competitor, also repositioned itself as an AI-powered browser by embedding AI features into its platform.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4EJUoAdNGN4myXdb69GnMD/f8ab6aaf2305a72ad84dcc5e4afb1beb/agentic_context_engineering.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/the-unexpected-benefits-of-ai-pcs-why-creativity-could-be-the-new",
          "published_at": "Tue, 21 Oct 2025 04:00:00 GMT",
          "title": "The unexpected benefits of AI PCs: why creativity could be the new productivity",
          "standfirst": "Presented by HPCreativity is quickly becoming the new measure of productivity. While AI is often framed as a tool for efficiency and automation, new research from MIT Sloan School of Management shows that generative AI enhances human creativity — when employees have the right tools and skills to use it effectively. That’s where AI PCs come in. These next-generation laptops combine local AI processing with powerful Neural Processing Units (NPUs), delivering the speed and security that knowledge workers expect while also unlocking new creative possibilities. By handling AI tasks directly on the device, AI PCs minimize latency, protect sensitive data, and lower energy consumption.Teams are already proving the impact. Marketing teams are using AI PCs to generate campaign assets in hours instead of weeks. Engineers are shortening design and prototyping cycles. Sales reps are creating personalized proposals onsite, even without cloud access. In each case, AI PCs are not just accelerating workflows — they’re sparking fresh ideas, faster iteration, and more engaged teams.The payoff is clear: creativity that translates into measurable business outcomes, from faster time-to-market and stronger compliance to deeper customer engagement. Still, adoption is uneven, and the benefits aren’t yet reaching the wider workforce.Early creative benefits, but a divide remainsNew Morning Consult and HP research shows nearly half of IT decision makers (45%) already use AI PCs for creative assistance, with almost a third (29%) using them for tasks like image generation and editing. That’s not just about efficiency — it’s about bringing imagination into everyday workflows.According to HP’s 2025 Work Relationship Index, fulfillment is the single biggest driver of a healthy work relationship, outranking even leadership. Give employees tools that let them create, not just execute tasks, and you unlock productivity, satisfaction, retention, and optimism. The same instinct that drives workers to build outside the office is the one companies can harness inside it.The challenge is that among broader knowledge workers, adoption is still low, just 29% for creative assistance and just 19% for image generation. This creative divide means the full potential of AI PCs hasn’t reached the wider workforce. For CIOs, the opportunity isn’t just deploying faster machines — it’s fostering a workplace culture where creativity drives measurable business value. Creative benefits of AI PCsSo when you put AI PCs in front of the employees who embrace the possibilities, what does that look like in practice? Early adopters are already seeing AI PCs reshape how creative work gets done. Teams dream up fresh ideas, faster. AI PCs can spark new perspectives and out-of-the-box solutions, enhancing human creativity rather than replacing it. With dedicated NPUs handling AI workloads, employees stay in flow without interruptions. Battery life is extended, latency drops, and performance improves — allowing teams to focus on ideas, not wait times.On-device AI is opening new creative mediums, from visual design to video production to music editing, and videos, photos, and presentations that can be generated, edited, and refined in real time. Plus, AI workloads like summarization, transcription, and code generation run instantly without relying on cloud APIs. That means employees can work productively in low-bandwidth or disconnected environments, removing downtime risks, especially for mobile workforces and global deployments.And across the organization, AI PCs mean real-world, measurable business outcomes. Marketing: AI PCs enable creative teams to generate ad variations, social content, and campaign assets in minutes instead of days, reducing dependence on external agencies. And that leads to faster campaign launches, reduced external vendor spend, and increased pipeline velocity.Product and engineering: Designers/engineers can prototype in CAD, generate 3D mockups, or run simulations locally with on-device AI accelerators, shortening feedback loops. That means reduced iteration cycles, faster prototyping, and faster time-to-market.Sales/customer engagement: Reps can use AI PCs to generate real-time proposals, personalized presentations, or analyze contracts offline at client sites, even without cloud connection. This generates faster deal cycles, higher client engagement, and a shorter sales turnaround.From efficiency to fulfillmentAI PCs are more than just a performance upgrade. They’re reshaping how people approach and experience work. By giving employees tools that spark creativity as well as productivity, organizations can unlock faster innovation, deeper engagement, and stronger retention. For CIOs, the opportunity goes beyond efficiency gains. The true value of AI PCs won’t be measured in speed or specs, but in how they open new possibilities for creation, collaboration, and competition — helping teams not just work faster, but work more creatively and productively.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by HPCreativity is quickly becoming the new measure of productivity. While AI is often framed as a tool for efficiency and automation, new research from MIT Sloan School of Management shows that generative AI enhances human creativity — when employees have the right tools and skills to use it effectively. That’s where AI PCs come in. These next-generation laptops combine local AI processing with powerful Neural Processing Units (NPUs), delivering the speed and security that knowledge workers expect while also unlocking new creative possibilities. By handling AI tasks directly on the device, AI PCs minimize latency, protect sensitive data, and lower energy consumption.Teams are already proving the impact. Marketing teams are using AI PCs to generate campaign assets in hours instead of weeks. Engineers are shortening design and prototyping cycles. Sales reps are creating personalized proposals onsite, even without cloud access. In each case, AI PCs are not just accelerating workflows — they’re sparking fresh ideas, faster iteration, and more engaged teams.The payoff is clear: creativity that translates into measurable business outcomes, from faster time-to-market and stronger compliance to deeper customer engagement. Still, adoption is uneven, and the benefits aren’t yet reaching the wider workforce.Early creative benefits, but a divide remainsNew Morning Consult and HP research shows nearly half of IT decision makers (45%) already use AI PCs for creative assistance, with almost a third (29%) using them for tasks like image generation and editing. That’s not just about efficiency — it’s about bringing imagination into everyday workflows.According to HP’s 2025 Work Relationship Index, fulfillment is the single biggest driver of a healthy work relationship, outranking even leadership. Give employees tools that let them create, not just execute tasks, and you unlock productivity, satisfaction, retention, and optimism. The same instinct that drives workers to build outside the office is the one companies can harness inside it.The challenge is that among broader knowledge workers, adoption is still low, just 29% for creative assistance and just 19% for image generation. This creative divide means the full potential of AI PCs hasn’t reached the wider workforce. For CIOs, the opportunity isn’t just deploying faster machines — it’s fostering a workplace culture where creativity drives measurable business value. Creative benefits of AI PCsSo when you put AI PCs in front of the employees who embrace the possibilities, what does that look like in practice? Early adopters are already seeing AI PCs reshape how creative work gets done. Teams dream up fresh ideas, faster. AI PCs can spark new perspectives and out-of-the-box solutions, enhancing human creativity rather than replacing it. With dedicated NPUs handling AI workloads, employees stay in flow without interruptions. Battery life is extended, latency drops, and performance improves — allowing teams to focus on ideas, not wait times.On-device AI is opening new creative mediums, from visual design to video production to music editing, and videos, photos, and presentations that can be generated, edited, and refined in real time. Plus, AI workloads like summarization, transcription, and code generation run instantly without relying on cloud APIs. That means employees can work productively in low-bandwidth or disconnected environments, removing downtime risks, especially for mobile workforces and global deployments.And across the organization, AI PCs mean real-world, measurable business outcomes. Marketing: AI PCs enable creative teams to generate ad variations, social content, and campaign assets in minutes instead of days, reducing dependence on external agencies. And that leads to faster campaign launches, reduced external vendor spend, and increased pipeline velocity.Product and engineering: Designers/engineers can prototype in CAD, generate 3D mockups, or run simulations locally with on-device AI accelerators, shortening feedback loops. That means reduced iteration cycles, faster prototyping, and faster time-to-market.Sales/customer engagement: Reps can use AI PCs to generate real-time proposals, personalized presentations, or analyze contracts offline at client sites, even without cloud connection. This generates faster deal cycles, higher client engagement, and a shorter sales turnaround.From efficiency to fulfillmentAI PCs are more than just a performance upgrade. They’re reshaping how people approach and experience work. By giving employees tools that spark creativity as well as productivity, organizations can unlock faster innovation, deeper engagement, and stronger retention. For CIOs, the opportunity goes beyond efficiency gains. The true value of AI PCs won’t be measured in speed or specs, but in how they open new possibilities for creation, collaboration, and competition — helping teams not just work faster, but work more creatively and productively.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7mR1kld6Y3tDOhKAT0kylM/0aa331e0105f915b2bc3bcf96001101d/FY25C2_HP_EliteBook_X_Flip_G1i_14_inch_Notebook_Next_Gen_AI_PC_MasadaNX_14_Silver_FEATURE1_Killer_Claim_2000x1400_4204007__1.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ais-financial-blind-spot-why-long-term-success-depends-on-cost-transparency",
          "published_at": "Tue, 21 Oct 2025 04:00:00 GMT",
          "title": "AI’s financial blind spot: Why long-term success depends on cost transparency",
          "standfirst": "Presented by Apptio, an IBM companyWhen a technology with revolutionary potential comes on the scene, it’s easy for companies to let enthusiasm outpace fiscal discipline. Bean counting can seem short-sighted in the face of exciting opportunities for business transformation and competitive dominance. But money is always an object. And when the tech is AI, those beans can add up fast.AI’s value is becoming evident in areas like operational efficiency, worker productivity, and customer satisfaction. However, this comes at a cost. The key to long-term success is understanding the relationship between the two — so you can ensure that the potential of AI translates into real, positive impact for your business. The AI acceleration paradoxWhile AI is helping to transform business operations, its own financial footprint often remains obscure. If you can’t connect costs to impact, how can you be sure your AI investments will drive meaningful ROI? This uncertainty makes it no surprise that in the 2025 Gartner® Hype Cycle™ for Artificial Intelligence, GenAI has moved into the “Trough of Disillusionment” . Effective strategic planning depends on clarity. In its absence, decision-making falls back on guesswork and gut instinct. And there’s a lot riding on these decisions. According to Apptio research, 68% of technology leaders surveyed expect to increase their AI budgets, and 39% believe AI will be their departments’ biggest driver of future budget growth. But bigger budgets don’t guarantee better outcomes. Gartner® also reveals that “despite an average spend of $1.9 million on GenAI initiatives in 2024, fewer than 30% of AI leaders say their CEOs are satisfied with the return on investment.” If there’s no clear link between cost and outcome, organizations risk scaling investments without scaling the value they’re meant to create.To move forward with well-founded confidence, business leaders in finance, IT, and tech must collaborate to gain visibility into AI’s financial blind spot.The hidden financial risks of AIThe runaway costs of AI can give IT leaders flashbacks to the early days of public cloud. When it’s easy for DevOps teams and business units to procure their own resources on an OpEx basis, costs and inefficiencies can quickly spiral. In fact, AI projects are avid consumers of cloud infrastructure — while incurring additional costs for data platforms and engineering resources. And that’s on top of the tokens used for each query. The decentralized nature of these costs makes them particularly difficult to attribute to business outcomes. As with the cloud, the ease of AI procurement quickly leads to AI sprawl. And finite budgets mean that every dollar spent represents an unconscious tradeoff with other needs. People worry that AI will take their job. But it’s just as likely that AI will take their department’s budget. Meanwhile, according to Gartner®, “Over 40% of agentic AI projects will be canceled by end of 2027, due to escalating costs, unclear business value or inadequate rish controls”. But are those the right projects to cancel? Lacking a way to connect investment to impact, how can business leaders know whether those rising costs are justified by proportionally greater ROI? ? Without transparency into AI costs, companies risk overspending, under-delivering, and missing out on better opportunities to drive value. Why traditional financial planning can&#x27;t handle AIAs we learned with cloud, we see that traditional static budget models are poorly suited for dynamic workloads and rapidly scaling resources. The key to cloud cost management has been tagging and telemetry, which help companies attribute each dollar of cloud spend to specific business outcomes. AI cost management will require similar practices. But the scope of the challenge goes much further. On top of costs for storage, compute, and data transfer, each AI project brings its own set of requirements — from prompt optimization and model routing to data preparation, regulatory compliance, security, and personnel.This complex mix of ever-shifting factors makes it understandable that finance and business teams lack granular visibility into AI-related spend — and IT teams struggle to reconcile usage with business outcomes. But it’s impossible to precisely and accurately track ROI without these connections.The strategic value of cost transparencyCost transparency empowers smarter decisions — from resource allocation to talent deployment. Connecting specific AI resources with the projects that they support helps technology decision-makers ensure that the most high-value projects are given what they need to succeed. Setting the right priorities is especially critical when top talent is in short supply. If your highly compensated engineers and data scientists are spread across too many interesting but unessential pilots, it’ll be hard to staff the next strategic — and perhaps pressing — pivot.FinOps best practices apply equally to AI. Cost insights can surface opportunities to optimize infrastructure and address waste whether by right-sizing performance and latency to match workload requirements, or by selecting a smaller, more cost-effective model instead of defaulting to the latest large language model (LLM). As work proceeds, tracking can flag rising costs so leaders can pivot quickly in more-promising directions as needed. A project that makes sense at X cost might not be worthwhile at 2X cost. Companies that adopt a structured, transparent, and well-governed approach to AI costs are more likely to spend the right money in the right ways and see optimal ROI from their investment. TBM: An enterprise framework for AI cost managementTransparency and control over AI costs depend on three practices:IT financial management (ITFM): Managing IT costs and investments in alignment with business prioritiesFinOps: Optimizing cloud costs and ROI through financial accountability and operational efficiency Strategic portfolio management (SPM): Prioritizing and managing projects to better ensure they deliver maximum value for the businessCollectively, these three disciplines make up Technology Business Management (TBM) — a structured framework that helps technology, business, and finance leaders connect technology investments to business outcomes for better financial transparency and decision-making. Most companies are already on the road to TBM, whether they realize it or not. They may have adopted some form of FinOps or cloud cost management. Or they might be developing strong financial expertise for IT. Or they may rely on Enterprise Agile Planning or Strategic Portfolio Management project management to deliver initiatives more successfully. AI can draw on — and impact — all of these areas. By unifying them under one umbrella with a common model and vocabulary, TBM brings essential clarity to AI costs and the business impact they enable.AI success depends on value — not just velocity. The cost transparency that TBM provides offers a road map that can help business and IT leaders make the right investments, deliver them cost-effectively, scale them responsibly, and turn AI from a costly mistake into a measurable business asset and strategic driver. Sources : Gartner® Press Release, Gartner® Predicts Over 40% of Agentic AI Projects Will Be Canceled by End of 2027, June 25, 2025 https://www.Gartner®.com/en/newsroom/press-releases/2025-06-25-Gartner®-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027 GARTNER® is a registered trademark and service mark of Gartner®, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.Ajay Patel is General Manager, Apptio and IT Automation at IBM.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Apptio, an IBM companyWhen a technology with revolutionary potential comes on the scene, it’s easy for companies to let enthusiasm outpace fiscal discipline. Bean counting can seem short-sighted in the face of exciting opportunities for business transformation and competitive dominance. But money is always an object. And when the tech is AI, those beans can add up fast.AI’s value is becoming evident in areas like operational efficiency, worker productivity, and customer satisfaction. However, this comes at a cost. The key to long-term success is understanding the relationship between the two — so you can ensure that the potential of AI translates into real, positive impact for your business. The AI acceleration paradoxWhile AI is helping to transform business operations, its own financial footprint often remains obscure. If you can’t connect costs to impact, how can you be sure your AI investments will drive meaningful ROI? This uncertainty makes it no surprise that in the 2025 Gartner® Hype Cycle™ for Artificial Intelligence, GenAI has moved into the “Trough of Disillusionment” . Effective strategic planning depends on clarity. In its absence, decision-making falls back on guesswork and gut instinct. And there’s a lot riding on these decisions. According to Apptio research, 68% of technology leaders surveyed expect to increase their AI budgets, and 39% believe AI will be their departments’ biggest driver of future budget growth. But bigger budgets don’t guarantee better outcomes. Gartner® also reveals that “despite an average spend of $1.9 million on GenAI initiatives in 2024, fewer than 30% of AI leaders say their CEOs are satisfied with the return on investment.” If there’s no clear link between cost and outcome, organizations risk scaling investments without scaling the value they’re meant to create.To move forward with well-founded confidence, business leaders in finance, IT, and tech must collaborate to gain visibility into AI’s financial blind spot.The hidden financial risks of AIThe runaway costs of AI can give IT leaders flashbacks to the early days of public cloud. When it’s easy for DevOps teams and business units to procure their own resources on an OpEx basis, costs and inefficiencies can quickly spiral. In fact, AI projects are avid consumers of cloud infrastructure — while incurring additional costs for data platforms and engineering resources. And that’s on top of the tokens used for each query. The decentralized nature of these costs makes them particularly difficult to attribute to business outcomes. As with the cloud, the ease of AI procurement quickly leads to AI sprawl. And finite budgets mean that every dollar spent represents an unconscious tradeoff with other needs. People worry that AI will take their job. But it’s just as likely that AI will take their department’s budget. Meanwhile, according to Gartner®, “Over 40% of agentic AI projects will be canceled by end of 2027, due to escalating costs, unclear business value or inadequate rish controls”. But are those the right projects to cancel? Lacking a way to connect investment to impact, how can business leaders know whether those rising costs are justified by proportionally greater ROI? ? Without transparency into AI costs, companies risk overspending, under-delivering, and missing out on better opportunities to drive value. Why traditional financial planning can&#x27;t handle AIAs we learned with cloud, we see that traditional static budget models are poorly suited for dynamic workloads and rapidly scaling resources. The key to cloud cost management has been tagging and telemetry, which help companies attribute each dollar of cloud spend to specific business outcomes. AI cost management will require similar practices. But the scope of the challenge goes much further. On top of costs for storage, compute, and data transfer, each AI project brings its own set of requirements — from prompt optimization and model routing to data preparation, regulatory compliance, security, and personnel.This complex mix of ever-shifting factors makes it understandable that finance and business teams lack granular visibility into AI-related spend — and IT teams struggle to reconcile usage with business outcomes. But it’s impossible to precisely and accurately track ROI without these connections.The strategic value of cost transparencyCost transparency empowers smarter decisions — from resource allocation to talent deployment. Connecting specific AI resources with the projects that they support helps technology decision-makers ensure that the most high-value projects are given what they need to succeed. Setting the right priorities is especially critical when top talent is in short supply. If your highly compensated engineers and data scientists are spread across too many interesting but unessential pilots, it’ll be hard to staff the next strategic — and perhaps pressing — pivot.FinOps best practices apply equally to AI. Cost insights can surface opportunities to optimize infrastructure and address waste whether by right-sizing performance and latency to match workload requirements, or by selecting a smaller, more cost-effective model instead of defaulting to the latest large language model (LLM). As work proceeds, tracking can flag rising costs so leaders can pivot quickly in more-promising directions as needed. A project that makes sense at X cost might not be worthwhile at 2X cost. Companies that adopt a structured, transparent, and well-governed approach to AI costs are more likely to spend the right money in the right ways and see optimal ROI from their investment. TBM: An enterprise framework for AI cost managementTransparency and control over AI costs depend on three practices:IT financial management (ITFM): Managing IT costs and investments in alignment with business prioritiesFinOps: Optimizing cloud costs and ROI through financial accountability and operational efficiency Strategic portfolio management (SPM): Prioritizing and managing projects to better ensure they deliver maximum value for the businessCollectively, these three disciplines make up Technology Business Management (TBM) — a structured framework that helps technology, business, and finance leaders connect technology investments to business outcomes for better financial transparency and decision-making. Most companies are already on the road to TBM, whether they realize it or not. They may have adopted some form of FinOps or cloud cost management. Or they might be developing strong financial expertise for IT. Or they may rely on Enterprise Agile Planning or Strategic Portfolio Management project management to deliver initiatives more successfully. AI can draw on — and impact — all of these areas. By unifying them under one umbrella with a common model and vocabulary, TBM brings essential clarity to AI costs and the business impact they enable.AI success depends on value — not just velocity. The cost transparency that TBM provides offers a road map that can help business and IT leaders make the right investments, deliver them cost-effectively, scale them responsibly, and turn AI from a costly mistake into a measurable business asset and strategic driver. Sources : Gartner® Press Release, Gartner® Predicts Over 40% of Agentic AI Projects Will Be Canceled by End of 2027, June 25, 2025 https://www.Gartner®.com/en/newsroom/press-releases/2025-06-25-Gartner®-predicts-over-40-percent-of-agentic-ai-projects-will-be-canceled-by-end-of-2027 GARTNER® is a registered trademark and service mark of Gartner®, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.Ajay Patel is General Manager, Apptio and IT Automation at IBM.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2GoMirWsXnSuZjapMQusnu/8efdafab45e1ad3f5c233f53b35287b2/AdobeStock_1726411808.jpeg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/new-markovian-thinking-technique-unlocks-a-path-to-million-token-ai",
          "published_at": "Mon, 20 Oct 2025 23:00:00 GMT",
          "title": "New 'Markovian Thinking' technique unlocks a path to million-token AI reasoning",
          "standfirst": "Researchers at Mila have proposed a new technique that makes large language models (LLMs) vastly more efficient when performing complex reasoning. Called Markovian Thinking, the approach allows LLMs to engage in lengthy reasoning without incurring the prohibitive computational costs that currently limit such tasks.The team’s implementation, an environment named Delethink, structures the reasoning chain into fixed-size chunks, breaking the scaling problem that plagues very long LLM responses. Initial estimates show that for a 1.5B parameter model, this method can cut the costs of training by more than two-thirds compared to standard approaches.The quadratic curse of long-chain reasoningFor an LLM to solve a complex problem, it often needs to generate a long series of intermediate “thinking” tokens, often referred to as chain-of-thought (CoT). In recent years, researchers have found that using reinforcement learning (RL) to train models to produce longer CoTs (sometimes referred to as LongCoT) has significantly improved their reasoning capabilities.However, the standard method for this has a critical flaw: The AI&#x27;s \"state\" (the prompt plus all the reasoning tokens it has generated thus far in its processing) grows with every new reasoning token. For modern transformer-based models, this means the computational cost explodes quadratically as the reasoning chain gets longer, making it prohibitively expensive to train models for very complex tasks.Most current attempts to manage this cost focus on limiting how much thinking the model does, implicitly preferring shorter solutions or terminating the process early. While these methods offer some relief, the Mila researchers still operate within the LongCoT framework and are thus fundamentally bound by its quadratic nature.Instead of trying to control the computational growth, Mila created an RL environment that avoids the quadratic problem altogether. As co-author Amirhossein Kazemnejad explained, the goal is to enable capabilities like multi-week reasoning and scientific discovery. \"That regime (and the RL needed to enable such capabilities) is not supported by the current LongCoT paradigm, because of quadratic compute cost,\" he said.Thinking in chunks with DelethinkThe researchers&#x27; solution is a paradigm they call the \"Markovian Thinker,\" where the model reasons while keeping the size of its reasoning context window constant. The core idea is to change the RL setup to separate \"how long the model thinks\" from \"how much context it must process.\" If done correctly, a Markovian Thinker turns the quadratic growth problem into linear compute and fixed memory requirements for LLM reasoning.The researchers put this paradigm into practice through Delethink, which forces the model to reason in a sequence of fixed-size chunks, such as 8,000 tokens at a time. Within each chunk, the model reasons as it normally would, using the classic attention mechanism. But when it reaches the limit of the chunk, the environment resets the context, creating a new prompt that includes the original query plus a short \"carryover\" from the previous chunk. For example, the carryover could be the last few tokens of the previous chunk of CoT or a summary of the most important results.This rearrangement of the problem forces the model to learn how to embed a summary of its progress, or a \"textual Markovian state,\" into this carryover to continue its reasoning in the next chunk. This addresses the common concern of whether the model can remember important details from earlier steps. According to Kazemnejad, the model learns what to remember. \"With training... the model is forced to learn to carry forward the task-critical state,\" he explained. He added crucial clarification for practical use: The original input prompt is not modified, including the documents or contextual data added to it. “Our approach is aimed at the reasoning phase and does not modify the prompt,\" he said.Delethink in actionTo test their approach, the researchers trained R1-Distill-1.5B with Delethink on a dataset of competition-level math problems, then evaluated it against several benchmarks. The model was trained to reason for up to 24,000 tokens but with fixed 8,000-token chunks. The researchers compared this to models trained with the standard LongCoT-RL method. Their findings indicate that the model trained with Delethink could reason up to 24,000 tokens, and matched or surpassed a LongCoT model trained with the same 24,000-token budget on math benchmarks. On other tasks like coding and PhD-level questions, Delethink also matched or slightly beat its LongCoT counterpart. “Overall, these results indicate that Delethink uses its thinking tokens as effectively as LongCoT-RL with reduced compute,” the researchers write.The benefits become even more pronounced when scaling beyond the training budget. While models trained with LongCoT quickly plateaued at their training limits, the Delethink-trained model continued to improve its performance. For instance, some math problems were only solved after the model reasoned for up to 140,000 tokens, far beyond its 24,000-token training budget. This linear compute advantage is substantial for enterprise applications. The researchers estimate that training a model to an average thinking length of 96,000 tokens would require 27 H100-GPU-months with LongCoT, versus just 7 with Delethink.This efficiency extends directly to inference, the primary operational cost for most enterprises. \"Models trained in Markovian Thinking use the same inference style (delethink-tracing) during test time, which provides the same advantages of linear compute and constant memory after training,\" said Kazemnejad. He offered a practical example: An AI agent could \"debug a large codebase and think for a long time... which of course reduces the cost significantly compared to the conventional LongCoT approach.\"Interestingly, the researchers found that off-the-shelf reasoning models, even without any specific training, already exhibit some ability to think in a Markovian way. This finding has immediate practical implications for developers. \"In practice, this means that — without Delethink-RL— these models can already run a delethink-tracing wrapper and perform competitively with LongCoT on our benchmarked tasks,\" Kazemnejad said.Their experiments with larger models such as GPT-OSS 120B showed robust performance with Delethink across a range of complex tasks. This latent ability provides a strong starting point for RL training, helping explain why the method is so effective. “Together, these results suggest that Delethink is compatible and scales with state-of-the-art models,” the researchers conclude.The success of Markovian Thinking shows it may be possible for \"next-generation reasoning models to think for millions of tokens,\" the researchers note. This opens the door to fundamentally new AI capabilities, moving beyond current constraints. \"Markovian Thinking... opens the path for models that can &#x27;think&#x27; for very long horizons, which we view as a necessary step toward eventual scientific discovery,\" Kazemnejad said. \"Our approach removes a key bottleneck and can allow training for much longer horizon tasks, which enables next-gen capabilities.\"",
          "content": "Researchers at Mila have proposed a new technique that makes large language models (LLMs) vastly more efficient when performing complex reasoning. Called Markovian Thinking, the approach allows LLMs to engage in lengthy reasoning without incurring the prohibitive computational costs that currently limit such tasks.The team’s implementation, an environment named Delethink, structures the reasoning chain into fixed-size chunks, breaking the scaling problem that plagues very long LLM responses. Initial estimates show that for a 1.5B parameter model, this method can cut the costs of training by more than two-thirds compared to standard approaches.The quadratic curse of long-chain reasoningFor an LLM to solve a complex problem, it often needs to generate a long series of intermediate “thinking” tokens, often referred to as chain-of-thought (CoT). In recent years, researchers have found that using reinforcement learning (RL) to train models to produce longer CoTs (sometimes referred to as LongCoT) has significantly improved their reasoning capabilities.However, the standard method for this has a critical flaw: The AI&#x27;s \"state\" (the prompt plus all the reasoning tokens it has generated thus far in its processing) grows with every new reasoning token. For modern transformer-based models, this means the computational cost explodes quadratically as the reasoning chain gets longer, making it prohibitively expensive to train models for very complex tasks.Most current attempts to manage this cost focus on limiting how much thinking the model does, implicitly preferring shorter solutions or terminating the process early. While these methods offer some relief, the Mila researchers still operate within the LongCoT framework and are thus fundamentally bound by its quadratic nature.Instead of trying to control the computational growth, Mila created an RL environment that avoids the quadratic problem altogether. As co-author Amirhossein Kazemnejad explained, the goal is to enable capabilities like multi-week reasoning and scientific discovery. \"That regime (and the RL needed to enable such capabilities) is not supported by the current LongCoT paradigm, because of quadratic compute cost,\" he said.Thinking in chunks with DelethinkThe researchers&#x27; solution is a paradigm they call the \"Markovian Thinker,\" where the model reasons while keeping the size of its reasoning context window constant. The core idea is to change the RL setup to separate \"how long the model thinks\" from \"how much context it must process.\" If done correctly, a Markovian Thinker turns the quadratic growth problem into linear compute and fixed memory requirements for LLM reasoning.The researchers put this paradigm into practice through Delethink, which forces the model to reason in a sequence of fixed-size chunks, such as 8,000 tokens at a time. Within each chunk, the model reasons as it normally would, using the classic attention mechanism. But when it reaches the limit of the chunk, the environment resets the context, creating a new prompt that includes the original query plus a short \"carryover\" from the previous chunk. For example, the carryover could be the last few tokens of the previous chunk of CoT or a summary of the most important results.This rearrangement of the problem forces the model to learn how to embed a summary of its progress, or a \"textual Markovian state,\" into this carryover to continue its reasoning in the next chunk. This addresses the common concern of whether the model can remember important details from earlier steps. According to Kazemnejad, the model learns what to remember. \"With training... the model is forced to learn to carry forward the task-critical state,\" he explained. He added crucial clarification for practical use: The original input prompt is not modified, including the documents or contextual data added to it. “Our approach is aimed at the reasoning phase and does not modify the prompt,\" he said.Delethink in actionTo test their approach, the researchers trained R1-Distill-1.5B with Delethink on a dataset of competition-level math problems, then evaluated it against several benchmarks. The model was trained to reason for up to 24,000 tokens but with fixed 8,000-token chunks. The researchers compared this to models trained with the standard LongCoT-RL method. Their findings indicate that the model trained with Delethink could reason up to 24,000 tokens, and matched or surpassed a LongCoT model trained with the same 24,000-token budget on math benchmarks. On other tasks like coding and PhD-level questions, Delethink also matched or slightly beat its LongCoT counterpart. “Overall, these results indicate that Delethink uses its thinking tokens as effectively as LongCoT-RL with reduced compute,” the researchers write.The benefits become even more pronounced when scaling beyond the training budget. While models trained with LongCoT quickly plateaued at their training limits, the Delethink-trained model continued to improve its performance. For instance, some math problems were only solved after the model reasoned for up to 140,000 tokens, far beyond its 24,000-token training budget. This linear compute advantage is substantial for enterprise applications. The researchers estimate that training a model to an average thinking length of 96,000 tokens would require 27 H100-GPU-months with LongCoT, versus just 7 with Delethink.This efficiency extends directly to inference, the primary operational cost for most enterprises. \"Models trained in Markovian Thinking use the same inference style (delethink-tracing) during test time, which provides the same advantages of linear compute and constant memory after training,\" said Kazemnejad. He offered a practical example: An AI agent could \"debug a large codebase and think for a long time... which of course reduces the cost significantly compared to the conventional LongCoT approach.\"Interestingly, the researchers found that off-the-shelf reasoning models, even without any specific training, already exhibit some ability to think in a Markovian way. This finding has immediate practical implications for developers. \"In practice, this means that — without Delethink-RL— these models can already run a delethink-tracing wrapper and perform competitively with LongCoT on our benchmarked tasks,\" Kazemnejad said.Their experiments with larger models such as GPT-OSS 120B showed robust performance with Delethink across a range of complex tasks. This latent ability provides a strong starting point for RL training, helping explain why the method is so effective. “Together, these results suggest that Delethink is compatible and scales with state-of-the-art models,” the researchers conclude.The success of Markovian Thinking shows it may be possible for \"next-generation reasoning models to think for millions of tokens,\" the researchers note. This opens the door to fundamentally new AI capabilities, moving beyond current constraints. \"Markovian Thinking... opens the path for models that can &#x27;think&#x27; for very long horizons, which we view as a necessary step toward eventual scientific discovery,\" Kazemnejad said. \"Our approach removes a key bottleneck and can allow training for much longer horizon tasks, which enables next-gen capabilities.\"",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1Nt9gogMKGFRD9qvf1lziG/bd8cf13e043d0d9341611055b70556e0/Markovian_thinking.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/xs-handle-marketplace-will-sell-some-rare-usernames-for-millions-of-dollars-224852740.html",
          "published_at": "Mon, 20 Oct 2025 22:48:52 +0000",
          "title": "X's handle marketplace will sell some 'rare' usernames for millions of dollars",
          "standfirst": "X is finally following through on its long-rumored plans to sell old user handles, and some of the most sought-after usernames could fetch millions of dollars. The company shared more details about and opened a waitlist for its \"handle marketplace,\" that will enable paying subscribers to request and buy \"inactive\" handles. According to the company, X will make two types of \"inactive' handles available: \"priority\" usernames that may include \"full names, multi-word phrases, or alphanumeric combinations\" and \"rare\" handles that consist of \"short, generic, or culturally significant names.\" Subscribers to X's Premium+ and Premium Business tiers will eventually be able to request some \"priority\" handles as part of their subscription. The company says @PizzaEater and @GabrielJones are possible examples of such handles. Notably, this process requires what essentially amounts to an indefinite subscription to X Premium, as the company says it will revoke priority handles if an account's subscription lapses. The X Handle Marketplace is our industry-first solution to redistribute handles that are no longer in use. Eligible Premium subscribers will be able to search and make requests, with both complimentary and paid options available.— Handle Marketplace (@XHandles) October 19, 2025 The process for acquiring a \"rare\" handle is a lot less clear. X says that it will offer some rare handles through \"public drops\" and that those will be given away for free \"based on merit\" and that multiple users will be able to apply. X will take a user's engagement and \"past contributions\" to the platform into account when deciding who gets these handles. The company will also make some handles available for sale via an invitation-only process. These prices will be \"fixed\" and \"determined by a number of factors including popularity of word, character length, and cultural significance.\" These usernames could include common one-word usernames like @one, @fly or @compute, according to examples provided by X. They could also be incredibly expensive. \"Some handles are included with a Premium+ or Premium Business subscription,\" X wrote in an FAQ. \"Others – especially Rare handles – may be priced anywhere from $2,500 to over seven figures, depending on demand and uniqueness.\" People who buy a supposedly rare handle will need to have a Premium+ or Premium Business subscription in order to start the process, but won't be required to maintain one in order to keep the handle. In a separate \"handle transfer agreement,\" X describes its handle-buying scheme as an \"evolving initiative\" that it hopes will be adopted by other social media companies in the future. \"We are establishing a new standard for social media handles—a framework we hope the broader industry will adopt, similar to how Community Notes has influenced online transparency,\" the company wrote. Andrew Allemann, the publisher of Domain Name Wire, a publication that tracks the domain name industry, says that there are some similarities between X's plan to sell handles and the marketplace for expired domains. \"For a long time, people have been buying and selling handles off of X, and X hasn't been getting a cut of that,\" he told Engadget. \"So in some ways, I think this will get some of the better handles to be more used on the platform.\" But he said he would have concerns about some of the terms in X's policies, which allow it to \"reclaim'' handles if they become inactive. The company's current \"inactive account policy\" defines an inactive account as one that hasn't been logged into for 30 days. \"I would definitely want a firmer contract if I were to pay money for a handle,\" Allemann says. \"I would want some rights baked into a contract that says it can't just be taken away. I certainly want a longer period of inactivity before it can be taken away.\" X also has a history of commandeering desirable handles from users that were actively using them. The company took the @X handle from a San Francisco photographer in 2023 without compensating him, though he was offered \"merch\" and a tour of X's headquarters. That same year, it also took the @music handle from a longtime user with more than a half million followers. Last year, the company swiped the @America handle from a reported Donald Trump critic. The handle is now used by Musk's super PAC. X's plan to give away handles based on \"merit\" raises additional questions about who the platform could decide to reward and penalize. The company didn't immediately respond to a request for comment. Allemann says that all social media users should remember they don't own any of the content they publish on company platforms. \"If you create your website, you control it, and people can always come to it. On social media, the single billionaire owner of it could decide they don't like you, and it's pretty much within their rights to kick you off, or demote you, or change the algorithm to impact you as well.\" Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/social-media/xs-handle-marketplace-will-sell-some-rare-usernames-for-millions-of-dollars-224852740.html?src=rss",
          "content": "X is finally following through on its long-rumored plans to sell old user handles, and some of the most sought-after usernames could fetch millions of dollars. The company shared more details about and opened a waitlist for its \"handle marketplace,\" that will enable paying subscribers to request and buy \"inactive\" handles. According to the company, X will make two types of \"inactive' handles available: \"priority\" usernames that may include \"full names, multi-word phrases, or alphanumeric combinations\" and \"rare\" handles that consist of \"short, generic, or culturally significant names.\" Subscribers to X's Premium+ and Premium Business tiers will eventually be able to request some \"priority\" handles as part of their subscription. The company says @PizzaEater and @GabrielJones are possible examples of such handles. Notably, this process requires what essentially amounts to an indefinite subscription to X Premium, as the company says it will revoke priority handles if an account's subscription lapses. The X Handle Marketplace is our industry-first solution to redistribute handles that are no longer in use. Eligible Premium subscribers will be able to search and make requests, with both complimentary and paid options available.— Handle Marketplace (@XHandles) October 19, 2025 The process for acquiring a \"rare\" handle is a lot less clear. X says that it will offer some rare handles through \"public drops\" and that those will be given away for free \"based on merit\" and that multiple users will be able to apply. X will take a user's engagement and \"past contributions\" to the platform into account when deciding who gets these handles. The company will also make some handles available for sale via an invitation-only process. These prices will be \"fixed\" and \"determined by a number of factors including popularity of word, character length, and cultural significance.\" These usernames could include common one-word usernames like @one, @fly or @compute, according to examples provided by X. They could also be incredibly expensive. \"Some handles are included with a Premium+ or Premium Business subscription,\" X wrote in an FAQ. \"Others – especially Rare handles – may be priced anywhere from $2,500 to over seven figures, depending on demand and uniqueness.\" People who buy a supposedly rare handle will need to have a Premium+ or Premium Business subscription in order to start the process, but won't be required to maintain one in order to keep the handle. In a separate \"handle transfer agreement,\" X describes its handle-buying scheme as an \"evolving initiative\" that it hopes will be adopted by other social media companies in the future. \"We are establishing a new standard for social media handles—a framework we hope the broader industry will adopt, similar to how Community Notes has influenced online transparency,\" the company wrote. Andrew Allemann, the publisher of Domain Name Wire, a publication that tracks the domain name industry, says that there are some similarities between X's plan to sell handles and the marketplace for expired domains. \"For a long time, people have been buying and selling handles off of X, and X hasn't been getting a cut of that,\" he told Engadget. \"So in some ways, I think this will get some of the better handles to be more used on the platform.\" But he said he would have concerns about some of the terms in X's policies, which allow it to \"reclaim'' handles if they become inactive. The company's current \"inactive account policy\" defines an inactive account as one that hasn't been logged into for 30 days. \"I would definitely want a firmer contract if I were to pay money for a handle,\" Allemann says. \"I would want some rights baked into a contract that says it can't just be taken away. I certainly want a longer period of inactivity before it can be taken away.\" X also has a history of commandeering desirable handles from users that were actively using them. The company took the @X handle from a San Francisco photographer in 2023 without compensating him, though he was offered \"merch\" and a tour of X's headquarters. That same year, it also took the @music handle from a longtime user with more than a half million followers. Last year, the company swiped the @America handle from a reported Donald Trump critic. The handle is now used by Musk's super PAC. X's plan to give away handles based on \"merit\" raises additional questions about who the platform could decide to reward and penalize. The company didn't immediately respond to a request for comment. Allemann says that all social media users should remember they don't own any of the content they publish on company platforms. \"If you create your website, you control it, and people can always come to it. On social media, the single billionaire owner of it could decide they don't like you, and it's pretty much within their rights to kick you off, or demote you, or change the algorithm to impact you as well.\" Have a tip for Karissa? You can reach her by email, on X, Bluesky, Threads, or send a message to @karissabe.51 to chat confidentially on Signal.This article originally appeared on Engadget at https://www.engadget.com/social-media/xs-handle-marketplace-will-sell-some-rare-usernames-for-millions-of-dollars-224852740.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/microsoft-has-ended-windows-10-support-but-heres-how-to-get-an-extra-year-for-free-125118044.html",
          "published_at": "Mon, 20 Oct 2025 18:54:24 +0000",
          "title": "Microsoft has ended Windows 10 support, but here's how to get an extra year for free",
          "standfirst": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) Are you still using Windows 10 on your desktop or laptop? If so, you need to know this: As of October 14, Microsoft moved the software to its \"end of life\" phase. What that means is that while Windows 10 PCs will continue to work, they'll stop getting important security updates by default. That leaves you with three options to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. The third option is easier than it sounds — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to use your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/microsoft-has-ended-windows-10-support-but-heres-how-to-get-an-extra-year-for-free-125118044.html?src=rss",
          "content": "You'll get access to Windows 10 a little longer by doing this. (Getty Images) Are you still using Windows 10 on your desktop or laptop? If so, you need to know this: As of October 14, Microsoft moved the software to its \"end of life\" phase. What that means is that while Windows 10 PCs will continue to work, they'll stop getting important security updates by default. That leaves you with three options to make sure your computer remains secure: You can choose to upgrade to Windows 11 for free if your computer is compatible. You can buy a new PC that already has Windows 11 pre-installed (or opt for an alternative, like a Mac or a Chromebook). Forget about Windows 11 right now and sign up for the Extended Security Updates (ESU), which lets you kick the can down the road for a year. The third option is easier than it sounds — and can now be done for free in many cases — so we'll focus on that one here. We'll walk you through the steps of keeping Windows 10 on your PC… for now, at least. How to sign up for Windows 10 Extended Security Updates on your computer We can question Microsoft's motives for killing off Windows 10, even though it works perfectly well on most older PCs. But without those periodic security updates, your PC will become increasingly susceptible to malware with each passing week. To that end, enrolling in Extended Security Updates (ESU) will give you another year of using Windows 10 securely. At one point, Microsoft suggested the 12-month extension would require a $30 fee. While that's still an option, there's now a free path for Windows 10 users in the US. Here's how to make it happen. Step 1: Make sure your PC is up to date You can find out if your computer is up-to-date by going into your Settings > System > About, then scroll down to see what version you're running. If not, you'll want to make sure you also install all the Windows 10 updates available. Step 2: Make sure you're using an administrator account If you share a computer with multiple people in your household, make sure you're signed in to the administrator account. Typically, it's the first account created on the computer. You'll know it's the right one when you see \"Administrator\" under the name. (You can double-check under Settings > Your Info.) Step 3: Verify if your PC is eligible to upgrade to Windows 11 (or not) If you see an option to upgrade to Windows 11, just do that. It's free and it keeps you in the Windows loop. Otherwise, continue following the steps below so you can keep your computer safe with security updates. Step 4: Enroll in Extended Security Updates Sign up for ESU by selecting Update & Security from the Settings menu. Click the \"Enroll Now\" sign-up link, as pictured below. Again, you may see an option to download Windows 11 if your computer meets the requirements (again, definitely do that if you see it). Find out if you need to update your computer. (Screenshot/Engadget) If you're not seeing the \"Enroll now\" link, you probably need to update and install the latest Windows 10 updates (as noted above). By enrolling in Extended Security Updates, you'll have another year before you need to upgrade to Windows 11. (Screenshots/Engadget) Step 5: Choose your upgrade method Next up is choosing how you want to enroll, and you have a few options. The easiest way is to back up your PC settings. It's free, but it takes a little bit of time since you'll need to back up your data. Again, you'll need to use your administrator account to get started. Back up your PC before you enroll in ESU. (ExplainingComputers via YouTube) That said, the free option here comes with two catches, at least for users in the US. (European users will get the free option with no strings attached.) The first is that you'll be linking your Windows login to Microsoft's cloud-based online service. Most users have likely already done this (if they're using CoPilot, Office 365, GamePass, OneDrive or one of Microsoft's other various online services). But if you've specifically opted for a local login to Windows, the price you're paying for this \"free\" extension is joining the cloud-connected Microsoft universe. The other potential issue is that the free backup only applies to the first 5 GB of storage. Anything more, and you’ll need to pay up for Microsoft's OneDrive services. But thankfully, you can turn off anything you don't want to back up by going to Settings > OneDrive and toggling off options like Documents, Pictures and Videos to get in under the free threshold to start. Once you're signed in, a window will pop up that says \"Add this device to receive Extended Security Updates.\" Click Add Device to enroll it. Click Done. A note: Thanks to YouTube's Explaining Computers channel, where we grabbed the screenshot above (since our test PC was already signed up for cloud backups, and didn't provide the splash screen to choose options). You can watch their full video if you'd like a deeper dive into the process. That's it, you're done! (Until next year) You've got 12 more months to figure out an alternative upgrade path to Windows 11. If anything changes next year, we'll update this story with what your next steps are. You did it right if you see this window. (Screenshot/Engadget) This article originally appeared on Engadget at https://www.engadget.com/computing/microsoft-has-ended-windows-10-support-but-heres-how-to-get-an-extra-year-for-free-125118044.html?src=rss",
          "feed_position": 27,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/c836b6e0-a60d-11f0-aff0-71a091f199fd"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-s25-fe-review-iterative-to-a-fault-183026577.html",
          "published_at": "Mon, 20 Oct 2025 18:30:26 +0000",
          "title": "Samsung Galaxy S25 FE review: Iterative to a fault",
          "standfirst": "Five years after the release of the Galaxy S20 FE, Samsung has settled into a predictable pattern with its \"Fan Edition\" line of phones. Each new phone doesn't offer much new or different from its immediate predecessor, with the company opting to offer iterative updates instead. That might have been fine before, but with the arrival of the Nothing Phone 3a Pro and Pixel 10 — devices that changed the value proposition in their respective categories — the S25 FE feels woefully out of touch with a market that's changing to meet people's demands. There's not much here that makes the new Galaxy S25 FE stand out, and any \"upgrades\" aren't substantive. Hardware and display Igor Bonifacic for Engadget When I first took the S25 FE out of the box, I thought Samsung had played a cruel trick on me. The phone looks identical to its predecessor, sporting the same brushed aluminum frame that's been the company's go-to for years now. I had to dig the S24 FE out of my gadgets drawer to compare the two phones before I confirmed they were in fact different devices. The physical differences are minor. Samsung has tweaked the dimensions of the new phone, making it slightly shorter, wider and thinner. Specifically, the S25 FE measures in at 6.35 x 3.02 x 0.29 inches, while its predecessor was 6.38 x 3.04 x 0.31 inches. The new phone is also protected by Samsung's \"enhanced Armor\" aluminum frame. More noticeable is that the S25 FE is lighter than last year's model, coming in at 6.7 ounces, down from 7.51 ounces. This is despite the fact the new device has a higher-capacity 4,900mAh battery. Together, these changes don't make the S25 FE easier to hold if you have small hands (just ask my girlfriend), but it does feel better balanced than its predecessor. One issue with the size of the S25 FE is the placement of the in-display fingerprint sensor. It's right at the bottom of the screen. I found this made it awkward to unlock the phone with my thumb — and I'm someone with big hands. Another slight difference is the finish on the back of the phone. This time around, Samsung has gone with a matte coating, instead of the glossy finish it used on the S24 FE. It's a welcome change since it makes the new model less prone to smudging and attracting fingerprints. I just wish Samsung had decided to offer the S25 FE in more fun colors. At release, it's available in four colorways: white, icy blue, jet black and navy (pictured). So, if you don't like blue, I'm sorry. Amid the slight design tweaks, Samsung has gone with the same screen it did last year. The S25 FE has a 6.7-inch AMOLED display, with a panel that offers a 120Hz refresh rate and 1080p resolution. The S24 FE's vibrant screen was one of the best parts of last year's model, and it's the same with S25 FE. It's easy to see the screen in bright sunlight, thanks to the fact it can push 1,900 nits of peak brightness. It's also vibrant, and with HDR10 support included, great for watching videos on YouTube, Netflix and elsewhere. Cameras Igor Bonifacic for Engadget Samsung made a single tweak to the Galaxy S25 FE's camera hardware. Like last year's model, the new phone has a 50-megapixel main camera with optical image stabilization (OIS) and a fast f/1.8 aperture lens. Once again, it also has an 8MP telephoto camera with a 3x optical zoom and a 12MP ultrawide angle that offers a 123-degree field of view. The one addition is a higher resolution 12MP front-facing camera with a faster f/2.2 aperture lens. For selfies, the S24 FE made do with a 10MP sensor and f/2.4 lens. If the new front-facing camera included phase detection autofocus (PDAF), it would be the same one that's available on the Galaxy S25. Unfortunately, it doesn't and that's a shame because PDAF greatly increases the likelihood your photos will come out sharp and in focus. It's also a shame Samsung decided not to update the FE's telephoto camera. Before the Nothing 3a Pro, that was one of the features that made the S24 FE stand out in its price range. In 2025, however, the S25 FE's telephoto feels outdated. It doesn't offer the 5x optical zoom of the Pixel 10 nor the 50MP of resolution and periscope zoom you get with the 3a Pro. Coming from the former, the FE's telephoto camera felt limiting. With only 8MP of resolution, trying to snap a photo at anything beyond 5x zoom was pointless; it would just turn out a blurry mess. As for FE's other cameras, they're decent if uninspiring. The 50MP camera is the best of the bunch, capable of capturing detailed, good-looking photos even in low light. The ultrawide, meanwhile, is mostly forgettable. It does an okay job of capturing big scenes, but it's lacking in dynamic range and detail. The selfie camera is a noticeable upgrade from the one that came with last year's model, and produces pleasing photos that are on par with what you can expect from the S25's front-facing camera. Otherwise, snapping pictures with the S25 FE feels like using a flagship phone from a few years ago. The one thing that saves it from being a complete blast from the past is the inclusion of Samsung's generative photo editing software, which you can use to remove distracting objects from photos. Of the AI photo apps I've tested, Samsung's is among the best at editing out objects without smearing the background. You can also use the generative edit to add things to a photo, but as you might expect, this doesn't work as well as removing them. Performance and battery life Igor Bonifacic for Engadget On paper, the S25 FE should offer better performance than its predecessor, thanks to Samsung's decision to equip the phone with its Exynos 2400 chipset over the cut-down Exynos 2400e it used on last year's model. In practice the two are about on par with one another. On Geekbench's processor test, the Exynos 2400 delivered a 2,144 single-core score and a 7,059 multi-core score. That's not much better than the 2,140 and 6,690 I recorded last fall on the S24 FE. Still, it's a more impressive showing than either the Pixel 9a and Nothing 3a Pro had when my colleague Sam Rutherford and I put their Tensor G4 and Snapdragon 7s Gen 3 chips through Geekbench earlier this year. For comparison, the former delivered a modest 1,665 on single-core performance and 4,294 on multi-core performance. The latter scored an even less impressive 1,115 and 3,082 respectively. In real-world use, the Exynos 2400 feels snappy. Scrolling is fast and fluid, as is opening apps and switching between them. Gaming performance is also impressive, with the chip able to handle the 60 fps modes in graphically demanding games like Diablo Immortal and League of Legends: Wild Rift without dropping frames. Last year, Samsung said it redesigned the S24 FE's vapor chamber to make it bigger and improve cooling. With the S25 FE, that component is an additional 10 percent larger. However, if the new vapor chamber made a difference to the phone's thermals, I had a hard time telling. Both the S25 FE and S24 FE got warm after about 15 to 20 minutes of gaming. The new phone never got hot to the point I couldn't hold it anymore, but it also didn't feel noticeably cooler than the S24 FE running the same games. As mentioned at the top, the S25 FE has a larger 4,900mAh battery. That's about four percent more capacity than the S24 FE offered. As a result, any difference in battery life is minimal. I'm sure there are some scenarios the S25 FE may last longer than its predecessor, but in my testing the two phones were equal in terms of longevity. With three to four hours of active screentime, I managed to get a full day of battery life from the S25 FE, with enough power left over to get the phone through the night before charging it in the morning. That's similar to the experience I had last year. Speaking of charging, the S24 FE, with a 25 watt wired limit, was painfully slow at it. Going into this review, my hope was the S25 FE would do better and I had good reason to be hopeful. Samsung lists the new phone as capable of charging at 45 watts. However, in my testing the S25 FE was only slightly faster than its predecessor. Plugged into a 130 watt Razer GaN charger, it took the phone about an hour and 14 minutes to charge to full from a battery at 10 percent life. When I replicated that same test with a 25 watt charger, it took the S25 FE just over an hour-and-a-half to charge back up. Either way, if battery life is important to you, the Nothing 3a Pro and Pixel 9a are better bets. Both come with bigger batteries (5,000 and 5,100mAh, respectively), and with the former, you also get 50 watt charging. Software Igor Bonifacic for Engadget The S25 FE ships with Android 16 and Samsung's One UI 8 out of the box. Samsung has promised to support the phone with at least seven generations of platform updates, so it should stay current with Google's yearly release schedule up until at least Android 23 in 2032. Notably, this means the S25 FE may end up on a more recent version of Android than the S25, S25 Edge and S25 Ultra, all of which released with Android 15. With One UI 8, the S25 FE has access to all of the latest AI features from both Samsung and Google. Some of these tools are useful; others replicate functionality that has been present in Android for a long time. For example, Google's Circle to Search is great. It makes it easy to do a visual search of anything on the phone's screen. On the other hand, I could do without Samsung's Now Brief, which offers much of the same utility you'll find on Android's Discover page (a feature that comes standard on every Android phone). Each S25 FE also comes with six months of free access to Google AI Pro. Normally priced at $20 per month, the service gives you access to some of the company's best models, including Gemini 2.5 Pro, inside of the Gemini app. Within Flow, Google's AI filmmaking app, you also get limited access to Veo 3.1, Google's latest video generation system. Some other perks include 2TB of cloud storage and higher rate limits when using NotebookLM. Wrap-up Igor Bonifacic for Engadget With changes that amount to window dressing, I can't recommend anyone buy the S25 FE at full price. There's just enough here to justify spending $650 on a phone that is barely an upgrade over its predecessor. If you're a Samsung fan, I'm sure the S25 FE will be frequently discounted, but why reward the company for a lazy effort? Besides, the S25, following a $200 discount for Prime Day, was only $10 more than the FE earlier this month. Over the past few years, Google and Nothing have shown midrange phones don't need to be boring, iterative affairs. For Samsung, I think it's time to rethink its FE strategy. If these phones offered something different — say actual fan favorite features like a headphone jack — there could be compelling reasons to recommend them. But as things stand, there's just no reason to buy a new FE phone when the company's flagships see steep price discounts within months of their release.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s25-fe-review-iterative-to-a-fault-183026577.html?src=rss",
          "content": "Five years after the release of the Galaxy S20 FE, Samsung has settled into a predictable pattern with its \"Fan Edition\" line of phones. Each new phone doesn't offer much new or different from its immediate predecessor, with the company opting to offer iterative updates instead. That might have been fine before, but with the arrival of the Nothing Phone 3a Pro and Pixel 10 — devices that changed the value proposition in their respective categories — the S25 FE feels woefully out of touch with a market that's changing to meet people's demands. There's not much here that makes the new Galaxy S25 FE stand out, and any \"upgrades\" aren't substantive. Hardware and display Igor Bonifacic for Engadget When I first took the S25 FE out of the box, I thought Samsung had played a cruel trick on me. The phone looks identical to its predecessor, sporting the same brushed aluminum frame that's been the company's go-to for years now. I had to dig the S24 FE out of my gadgets drawer to compare the two phones before I confirmed they were in fact different devices. The physical differences are minor. Samsung has tweaked the dimensions of the new phone, making it slightly shorter, wider and thinner. Specifically, the S25 FE measures in at 6.35 x 3.02 x 0.29 inches, while its predecessor was 6.38 x 3.04 x 0.31 inches. The new phone is also protected by Samsung's \"enhanced Armor\" aluminum frame. More noticeable is that the S25 FE is lighter than last year's model, coming in at 6.7 ounces, down from 7.51 ounces. This is despite the fact the new device has a higher-capacity 4,900mAh battery. Together, these changes don't make the S25 FE easier to hold if you have small hands (just ask my girlfriend), but it does feel better balanced than its predecessor. One issue with the size of the S25 FE is the placement of the in-display fingerprint sensor. It's right at the bottom of the screen. I found this made it awkward to unlock the phone with my thumb — and I'm someone with big hands. Another slight difference is the finish on the back of the phone. This time around, Samsung has gone with a matte coating, instead of the glossy finish it used on the S24 FE. It's a welcome change since it makes the new model less prone to smudging and attracting fingerprints. I just wish Samsung had decided to offer the S25 FE in more fun colors. At release, it's available in four colorways: white, icy blue, jet black and navy (pictured). So, if you don't like blue, I'm sorry. Amid the slight design tweaks, Samsung has gone with the same screen it did last year. The S25 FE has a 6.7-inch AMOLED display, with a panel that offers a 120Hz refresh rate and 1080p resolution. The S24 FE's vibrant screen was one of the best parts of last year's model, and it's the same with S25 FE. It's easy to see the screen in bright sunlight, thanks to the fact it can push 1,900 nits of peak brightness. It's also vibrant, and with HDR10 support included, great for watching videos on YouTube, Netflix and elsewhere. Cameras Igor Bonifacic for Engadget Samsung made a single tweak to the Galaxy S25 FE's camera hardware. Like last year's model, the new phone has a 50-megapixel main camera with optical image stabilization (OIS) and a fast f/1.8 aperture lens. Once again, it also has an 8MP telephoto camera with a 3x optical zoom and a 12MP ultrawide angle that offers a 123-degree field of view. The one addition is a higher resolution 12MP front-facing camera with a faster f/2.2 aperture lens. For selfies, the S24 FE made do with a 10MP sensor and f/2.4 lens. If the new front-facing camera included phase detection autofocus (PDAF), it would be the same one that's available on the Galaxy S25. Unfortunately, it doesn't and that's a shame because PDAF greatly increases the likelihood your photos will come out sharp and in focus. It's also a shame Samsung decided not to update the FE's telephoto camera. Before the Nothing 3a Pro, that was one of the features that made the S24 FE stand out in its price range. In 2025, however, the S25 FE's telephoto feels outdated. It doesn't offer the 5x optical zoom of the Pixel 10 nor the 50MP of resolution and periscope zoom you get with the 3a Pro. Coming from the former, the FE's telephoto camera felt limiting. With only 8MP of resolution, trying to snap a photo at anything beyond 5x zoom was pointless; it would just turn out a blurry mess. As for FE's other cameras, they're decent if uninspiring. The 50MP camera is the best of the bunch, capable of capturing detailed, good-looking photos even in low light. The ultrawide, meanwhile, is mostly forgettable. It does an okay job of capturing big scenes, but it's lacking in dynamic range and detail. The selfie camera is a noticeable upgrade from the one that came with last year's model, and produces pleasing photos that are on par with what you can expect from the S25's front-facing camera. Otherwise, snapping pictures with the S25 FE feels like using a flagship phone from a few years ago. The one thing that saves it from being a complete blast from the past is the inclusion of Samsung's generative photo editing software, which you can use to remove distracting objects from photos. Of the AI photo apps I've tested, Samsung's is among the best at editing out objects without smearing the background. You can also use the generative edit to add things to a photo, but as you might expect, this doesn't work as well as removing them. Performance and battery life Igor Bonifacic for Engadget On paper, the S25 FE should offer better performance than its predecessor, thanks to Samsung's decision to equip the phone with its Exynos 2400 chipset over the cut-down Exynos 2400e it used on last year's model. In practice the two are about on par with one another. On Geekbench's processor test, the Exynos 2400 delivered a 2,144 single-core score and a 7,059 multi-core score. That's not much better than the 2,140 and 6,690 I recorded last fall on the S24 FE. Still, it's a more impressive showing than either the Pixel 9a and Nothing 3a Pro had when my colleague Sam Rutherford and I put their Tensor G4 and Snapdragon 7s Gen 3 chips through Geekbench earlier this year. For comparison, the former delivered a modest 1,665 on single-core performance and 4,294 on multi-core performance. The latter scored an even less impressive 1,115 and 3,082 respectively. In real-world use, the Exynos 2400 feels snappy. Scrolling is fast and fluid, as is opening apps and switching between them. Gaming performance is also impressive, with the chip able to handle the 60 fps modes in graphically demanding games like Diablo Immortal and League of Legends: Wild Rift without dropping frames. Last year, Samsung said it redesigned the S24 FE's vapor chamber to make it bigger and improve cooling. With the S25 FE, that component is an additional 10 percent larger. However, if the new vapor chamber made a difference to the phone's thermals, I had a hard time telling. Both the S25 FE and S24 FE got warm after about 15 to 20 minutes of gaming. The new phone never got hot to the point I couldn't hold it anymore, but it also didn't feel noticeably cooler than the S24 FE running the same games. As mentioned at the top, the S25 FE has a larger 4,900mAh battery. That's about four percent more capacity than the S24 FE offered. As a result, any difference in battery life is minimal. I'm sure there are some scenarios the S25 FE may last longer than its predecessor, but in my testing the two phones were equal in terms of longevity. With three to four hours of active screentime, I managed to get a full day of battery life from the S25 FE, with enough power left over to get the phone through the night before charging it in the morning. That's similar to the experience I had last year. Speaking of charging, the S24 FE, with a 25 watt wired limit, was painfully slow at it. Going into this review, my hope was the S25 FE would do better and I had good reason to be hopeful. Samsung lists the new phone as capable of charging at 45 watts. However, in my testing the S25 FE was only slightly faster than its predecessor. Plugged into a 130 watt Razer GaN charger, it took the phone about an hour and 14 minutes to charge to full from a battery at 10 percent life. When I replicated that same test with a 25 watt charger, it took the S25 FE just over an hour-and-a-half to charge back up. Either way, if battery life is important to you, the Nothing 3a Pro and Pixel 9a are better bets. Both come with bigger batteries (5,000 and 5,100mAh, respectively), and with the former, you also get 50 watt charging. Software Igor Bonifacic for Engadget The S25 FE ships with Android 16 and Samsung's One UI 8 out of the box. Samsung has promised to support the phone with at least seven generations of platform updates, so it should stay current with Google's yearly release schedule up until at least Android 23 in 2032. Notably, this means the S25 FE may end up on a more recent version of Android than the S25, S25 Edge and S25 Ultra, all of which released with Android 15. With One UI 8, the S25 FE has access to all of the latest AI features from both Samsung and Google. Some of these tools are useful; others replicate functionality that has been present in Android for a long time. For example, Google's Circle to Search is great. It makes it easy to do a visual search of anything on the phone's screen. On the other hand, I could do without Samsung's Now Brief, which offers much of the same utility you'll find on Android's Discover page (a feature that comes standard on every Android phone). Each S25 FE also comes with six months of free access to Google AI Pro. Normally priced at $20 per month, the service gives you access to some of the company's best models, including Gemini 2.5 Pro, inside of the Gemini app. Within Flow, Google's AI filmmaking app, you also get limited access to Veo 3.1, Google's latest video generation system. Some other perks include 2TB of cloud storage and higher rate limits when using NotebookLM. Wrap-up Igor Bonifacic for Engadget With changes that amount to window dressing, I can't recommend anyone buy the S25 FE at full price. There's just enough here to justify spending $650 on a phone that is barely an upgrade over its predecessor. If you're a Samsung fan, I'm sure the S25 FE will be frequently discounted, but why reward the company for a lazy effort? Besides, the S25, following a $200 discount for Prime Day, was only $10 more than the FE earlier this month. Over the past few years, Google and Nothing have shown midrange phones don't need to be boring, iterative affairs. For Samsung, I think it's time to rethink its FE strategy. If these phones offered something different — say actual fan favorite features like a headphone jack — there could be compelling reasons to recommend them. But as things stand, there's just no reason to buy a new FE phone when the company's flagships see steep price discounts within months of their release.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s25-fe-review-iterative-to-a-fault-183026577.html?src=rss",
          "feed_position": 28,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/adf88820-add9-11f0-a6f7-9b48f1e9c328"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/claude-code-comes-to-web-and-mobile-letting-devs-launch-parallel-jobs-on",
          "published_at": "Mon, 20 Oct 2025 18:15:00 GMT",
          "title": "Claude Code comes to web and mobile, letting devs launch parallel jobs on Anthropic’s managed infra",
          "standfirst": "Vibe coding is evolving and with it are the leading AI-powered coding services and tools, including Anthropic’s Claude Code. As of today, the service will be available via the web and, in preview, on the Claude iOS app, giving developers access to additional asynchronous capabilities. Previously, it was available through the terminal on developers&#x27; PCs with support for Git, Docker, Kubernetes, npm, pip, AWS CLI, etc., and as an extension for Microsoft&#x27;s open source VS Code editor and other JetBrains-powered integrated development environments (IDEs) via Claude Agent. “Claude Code on the web lets you kick off coding sessions without opening your terminal,” Anthropic said in a blog post. “Connect your GitHub repositories, describe what you need, and Claude handles the implementation. Each session runs in its own isolated environment with real-time progress tracking, and you can actively steer Claude to adjust course as it’s working through tasks.”This allows users to run coding projects asynchronously, a trend that many enterprises are looking for. The web version of Claude Code, currently in research preview, will be available to Pro and Max users. However, web Claude Code will be subject to the same rate limits as other versions. Anthropic throttled rate limits to Claude and Claude Code after the unexpected popularity of the coding tool in July, which enabled some users to run Claude Code overnight. Anthropic is now ensuring Claude Code comes closer to matching the availability of rival OpenAI&#x27;s Codex AI coding platform, powered by a variant of GPT-5, which launches on mobile and the web back in mid September 2025.Parallel usageAnthropic said running Claude Code in the cloud means teams can “now run multiple tasks in parallel across different repositories from a single interface and ship faster with automatic PR creation and clear change summaries.”One of the big draws of coding agents is giving developers the ability to run multiple coding projects, such as bugfixes, at the same time. Google’s two coding agents, Jules and Code Assist, both offer asynchronous code generation and checks. Codex from OpenAI also lets people work in parallel. Anthropic said bringing Claude Code to the web won’t disrupt workflows, but noted running tasks in the cloud work best for tasks such as answering questions around projects and how repositories are mapped, bugfixes and for routine, well-defined tasks, and backend changes to verify any adjustments. While most developers will likely prefer to use Claude Code on a desktop, Anthropic said the mobile version could encourage more users to “explore coding with Claude on the go.”Isolated environments Anthropic insisted that Claude Code tasks on the cloud will have the same level of security as the earlier version. It runs on an “isolated sandbox environment with network and filesystem restrictions.” Interactions go through a secure proxy service, which the company said ensures the model only accesses authorized repositories.Enterprise users can customize which domains Claude Code can connect to. Claude Code is powered by Claude Sonnet 4.5, which Anthropic claims is the best coding model around. The company recently made Claude Haiku 4.5, a smaller version of Claude that also has strong coding capabilities, available to all Claude subscribers, including free users.",
          "content": "Vibe coding is evolving and with it are the leading AI-powered coding services and tools, including Anthropic’s Claude Code. As of today, the service will be available via the web and, in preview, on the Claude iOS app, giving developers access to additional asynchronous capabilities. Previously, it was available through the terminal on developers&#x27; PCs with support for Git, Docker, Kubernetes, npm, pip, AWS CLI, etc., and as an extension for Microsoft&#x27;s open source VS Code editor and other JetBrains-powered integrated development environments (IDEs) via Claude Agent. “Claude Code on the web lets you kick off coding sessions without opening your terminal,” Anthropic said in a blog post. “Connect your GitHub repositories, describe what you need, and Claude handles the implementation. Each session runs in its own isolated environment with real-time progress tracking, and you can actively steer Claude to adjust course as it’s working through tasks.”This allows users to run coding projects asynchronously, a trend that many enterprises are looking for. The web version of Claude Code, currently in research preview, will be available to Pro and Max users. However, web Claude Code will be subject to the same rate limits as other versions. Anthropic throttled rate limits to Claude and Claude Code after the unexpected popularity of the coding tool in July, which enabled some users to run Claude Code overnight. Anthropic is now ensuring Claude Code comes closer to matching the availability of rival OpenAI&#x27;s Codex AI coding platform, powered by a variant of GPT-5, which launches on mobile and the web back in mid September 2025.Parallel usageAnthropic said running Claude Code in the cloud means teams can “now run multiple tasks in parallel across different repositories from a single interface and ship faster with automatic PR creation and clear change summaries.”One of the big draws of coding agents is giving developers the ability to run multiple coding projects, such as bugfixes, at the same time. Google’s two coding agents, Jules and Code Assist, both offer asynchronous code generation and checks. Codex from OpenAI also lets people work in parallel. Anthropic said bringing Claude Code to the web won’t disrupt workflows, but noted running tasks in the cloud work best for tasks such as answering questions around projects and how repositories are mapped, bugfixes and for routine, well-defined tasks, and backend changes to verify any adjustments. While most developers will likely prefer to use Claude Code on a desktop, Anthropic said the mobile version could encourage more users to “explore coding with Claude on the go.”Isolated environments Anthropic insisted that Claude Code tasks on the cloud will have the same level of security as the earlier version. It runs on an “isolated sandbox environment with network and filesystem restrictions.” Interactions go through a secure proxy service, which the company said ensures the model only accesses authorized repositories.Enterprise users can customize which domains Claude Code can connect to. Claude Code is powered by Claude Sonnet 4.5, which Anthropic claims is the best coding model around. The company recently made Claude Haiku 4.5, a smaller version of Claude that also has strong coding capabilities, available to all Claude subscribers, including free users.",
          "feed_position": 7,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/479x9yR2m3sOxcfXEPnxI/dd6f7e7281ced692395996331a3b5646/crimedy7_illustration_of_a_robot_coding_a_program_--ar_169_--_7dafd9d4-817a-4c5c-abbe-fb9112e639c7_0.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/anthropic-brings-claude-code-to-ios-and-the-web-180023611.html",
          "published_at": "Mon, 20 Oct 2025 18:00:23 +0000",
          "title": "Anthropic brings Claude Code to iOS and the web",
          "standfirst": "At the end of February, Anthropic announced Claude Code. In the eight months since then, the coding agent has arguably become the company's most important product, helping it carve out a niche for itself in the highly competitive AI market. Now, Anthropic is making it easier for developers to use Claude Code in more places with a new web interface for accessing the agent. To get started, you'll need connect Claude to your GitHub repositories. From there, the process of using the agent is the same as if it had direct terminal access. Describe what you need from it, and the agent will take it from there. Claude will provide progress updates while it works, and you can even steer it in real-time with additional prompts. Through the web interface, it's also possible to assign Claude multiple coding tasks to run in parallel. \"Every Claude Code task runs in an isolated sandbox environment with network and filesystem restrictions. Git interactions are handled through a secure proxy service that ensures Claude can only access authorized repositories — helping keep your code and credentials protected throughout the entire workflow,\" said Anthropic. In addition to making Claude Code available on the web, Anthropic is releasing a preview of the agent inside of its iOS app. The company warns the integration is early, and that it hopes \"to quickly refine the mobile experience based on your feedback.\" Pro and Max users can start using Claude Code on the web today. Anthropic notes any cloud sessions share the same rate limits with all other Claude Code usage. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-brings-claude-code-to-ios-and-the-web-180023611.html?src=rss",
          "content": "At the end of February, Anthropic announced Claude Code. In the eight months since then, the coding agent has arguably become the company's most important product, helping it carve out a niche for itself in the highly competitive AI market. Now, Anthropic is making it easier for developers to use Claude Code in more places with a new web interface for accessing the agent. To get started, you'll need connect Claude to your GitHub repositories. From there, the process of using the agent is the same as if it had direct terminal access. Describe what you need from it, and the agent will take it from there. Claude will provide progress updates while it works, and you can even steer it in real-time with additional prompts. Through the web interface, it's also possible to assign Claude multiple coding tasks to run in parallel. \"Every Claude Code task runs in an isolated sandbox environment with network and filesystem restrictions. Git interactions are handled through a secure proxy service that ensures Claude can only access authorized repositories — helping keep your code and credentials protected throughout the entire workflow,\" said Anthropic. In addition to making Claude Code available on the web, Anthropic is releasing a preview of the agent inside of its iOS app. The company warns the integration is early, and that it hopes \"to quickly refine the mobile experience based on your feedback.\" Pro and Max users can start using Claude Code on the web today. Anthropic notes any cloud sessions share the same rate limits with all other Claude Code usage. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-brings-claude-code-to-ios-and-the-web-180023611.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-to-cancel-nordvpn-and-get-your-money-back-173008588.html",
          "published_at": "Mon, 20 Oct 2025 17:30:08 +0000",
          "title": "How to cancel NordVPN and get your money back",
          "standfirst": "There's a lot to like about NordVPN, as I covered in my full NordVPN review. It's one of the fastest among the best VPNs, and it's got a bunch of cool, specialized servers for various VPN tasks. But the apps can be frustrating, and beyond that, no VPN is perfect for everyone. If you've decided NordVPN isn't for you, here's how to cancel your subscription and get your money back. How to turn off auto-renewal on NordVPN Even though you've decided to part ways with NordVPN, you may want to keep your subscription active while you pick out a replacement service. If that's the case, you can simply cancel automatic renewal and let your subscription expire at the end of the billing period. If you change your mind before then, you can turn auto-renew back on. Here's how to do it. Go to my.nordaccount.com. Click Log in to Nord Account and enter your email address and password. You'll arrive at the account overview page. In the left-hand column, click on Billing. On the list of subscriptions that appears, find NordVPN. Find the line that says \"Auto-renewal: ON,\" and click the Cancel link next to it. A warning message will appear. Click Cancel auto-renewal at the bottom-right. Sam Chapman for Engadget This will turn auto-renewal off. If you decide to turn it back on, just go back to the billing tab of your Nord account overview, find your NordVPN subscription and click Enable auto-renewal. How to cancel if you subscribed through an app store If you paid for NordVPN on a mobile device through Google Play or the Apple app store, you'll need to go to the relevant app store to cancel the subscription. On Android, sign in to Google Play, touch your profile picture, tap Payments & subscriptions and tap Subscriptions. Scroll until you find NordVPN, tap it and hit Cancel subscription. If you want a refund, follow the instructions in \"How to get a refund from NordVPN\" below. On iOS, open the settings app, touch your profile picture, then tap Subscription. Scroll down to NordVPN, tap it and hit Cancel subscription. To get a refund for an Apple purchase, contact the Apple support team instead of the NordVPN team. How to delete your NordVPN account On the other hand, if you're sick of NordVPN and already have another VPN lined up, you can cancel immediately by deleting your Nord account altogether. This will also cut you off from any other Nord Security products you might be using, including NordPass and NordLocker. Go to my.nordaccount.com, click Log in to Nord Account and enter your credentials. At the top-right of the account overview page, click your email address. In the dropdown menu, click Account settings. Look at the bottom of the page to find the account deletion controls. Click Delete account. Nord will send an authentication code to your account's email address. Enter it. Follow the onscreen prompts to confirm deletion. Sam Chapman for Engadget How to get a refund from NordVPN NordVPN has a standard 30-day money-back guarantee. As long as you bought your subscription in the last 30 days, you can get a full refund. To do so, you'll need to first cancel auto-renewal on your plan as described above, then contact support to ask for the refund. You can reach NordVPN support by going to the help center at support.nordvpn.com. To reach the live chat and email ticket options, you'll need to work your way down to a bottom-level help center article, then scroll down until you reach the section titled \"Still having issues?\" It's frustrating, but you can get there by just clicking the first link on every page (or just follow this link and scroll down). Sam Chapman for Engadget Once you've found the buttons, either start a live chat or open the email form. Whichever you choose, explain that you've cancelled your subscription and would like a refund. Make sure not to end the interaction until you've received confirmation that your refund will be processed. Afterwards, it'll take up to 10 business days for your reimbursement to go through. NordVPN alternatives With NordVPN cancelled, you may be in the market for another VPN. I've collected several on my best VPN list (linked at the start of the article), but here's a few specific recommendations: Proton VPN is the best overall, Surfshark is the fastest and ExpressVPN is good for beginners and great at streaming. Good luck in your quest for a VPN that meets your needs.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-nordvpn-and-get-your-money-back-173008588.html?src=rss",
          "content": "There's a lot to like about NordVPN, as I covered in my full NordVPN review. It's one of the fastest among the best VPNs, and it's got a bunch of cool, specialized servers for various VPN tasks. But the apps can be frustrating, and beyond that, no VPN is perfect for everyone. If you've decided NordVPN isn't for you, here's how to cancel your subscription and get your money back. How to turn off auto-renewal on NordVPN Even though you've decided to part ways with NordVPN, you may want to keep your subscription active while you pick out a replacement service. If that's the case, you can simply cancel automatic renewal and let your subscription expire at the end of the billing period. If you change your mind before then, you can turn auto-renew back on. Here's how to do it. Go to my.nordaccount.com. Click Log in to Nord Account and enter your email address and password. You'll arrive at the account overview page. In the left-hand column, click on Billing. On the list of subscriptions that appears, find NordVPN. Find the line that says \"Auto-renewal: ON,\" and click the Cancel link next to it. A warning message will appear. Click Cancel auto-renewal at the bottom-right. Sam Chapman for Engadget This will turn auto-renewal off. If you decide to turn it back on, just go back to the billing tab of your Nord account overview, find your NordVPN subscription and click Enable auto-renewal. How to cancel if you subscribed through an app store If you paid for NordVPN on a mobile device through Google Play or the Apple app store, you'll need to go to the relevant app store to cancel the subscription. On Android, sign in to Google Play, touch your profile picture, tap Payments & subscriptions and tap Subscriptions. Scroll until you find NordVPN, tap it and hit Cancel subscription. If you want a refund, follow the instructions in \"How to get a refund from NordVPN\" below. On iOS, open the settings app, touch your profile picture, then tap Subscription. Scroll down to NordVPN, tap it and hit Cancel subscription. To get a refund for an Apple purchase, contact the Apple support team instead of the NordVPN team. How to delete your NordVPN account On the other hand, if you're sick of NordVPN and already have another VPN lined up, you can cancel immediately by deleting your Nord account altogether. This will also cut you off from any other Nord Security products you might be using, including NordPass and NordLocker. Go to my.nordaccount.com, click Log in to Nord Account and enter your credentials. At the top-right of the account overview page, click your email address. In the dropdown menu, click Account settings. Look at the bottom of the page to find the account deletion controls. Click Delete account. Nord will send an authentication code to your account's email address. Enter it. Follow the onscreen prompts to confirm deletion. Sam Chapman for Engadget How to get a refund from NordVPN NordVPN has a standard 30-day money-back guarantee. As long as you bought your subscription in the last 30 days, you can get a full refund. To do so, you'll need to first cancel auto-renewal on your plan as described above, then contact support to ask for the refund. You can reach NordVPN support by going to the help center at support.nordvpn.com. To reach the live chat and email ticket options, you'll need to work your way down to a bottom-level help center article, then scroll down until you reach the section titled \"Still having issues?\" It's frustrating, but you can get there by just clicking the first link on every page (or just follow this link and scroll down). Sam Chapman for Engadget Once you've found the buttons, either start a live chat or open the email form. Whichever you choose, explain that you've cancelled your subscription and would like a refund. Make sure not to end the interaction until you've received confirmation that your refund will be processed. Afterwards, it'll take up to 10 business days for your reimbursement to go through. NordVPN alternatives With NordVPN cancelled, you may be in the market for another VPN. I've collected several on my best VPN list (linked at the start of the article), but here's a few specific recommendations: Proton VPN is the best overall, Surfshark is the fastest and ExpressVPN is good for beginners and great at streaming. Good luck in your quest for a VPN that meets your needs.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-to-cancel-nordvpn-and-get-your-money-back-173008588.html?src=rss",
          "feed_position": 31,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/813933f0-ab92-11f0-befe-8b86b84e993e"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/the-best-new-computers-to-replace-your-old-windows-10-pc-134500000.html",
          "published_at": "Mon, 20 Oct 2025 14:24:36 +0000",
          "title": "The best new computers to replace your old Windows 10 PC",
          "standfirst": "It’s official: Microsoft has officially ended support for Windows 10. Thankfully, there’s a free and easy way to get another year’s worth of Extended Security Updates (which will take you to mid-October 2026). But even if your computer meets the minimum system requirements for a free Windows 11 upgrade, anything older than a year won't be able to take advantage of Microsoft's Copilot+ AI PC features, like Windows Recall or Studio Effects for video chats. So if you've already been feeling that your current aging PC is on the verge of dying — slow performance, whining fans, batteries that barely keep a charge — it's probably time to consider replacing it with a new system. We've already done the legwork of researching and selecting new hardware in our best laptop and best Windows notebook guides (we've also covered more powerful gaming and schoolwork systems), but here are some suggestions if you're just looking to snap up something quickly. The best Windows 10 laptop replacements Surface Laptop 13.8-inch In many ways, the Snapdragon-powered Surface Laptop is emblematic of where Windows PCs are headed. It's incredibly light, surprisingly powerful for something with a mobile chip and its battery lasted over 17-and-a-half hours in our testing. While you may run into some compatibility issues if you're running ancient Windows programs, for most people the Surface Laptop is one of the best PC experiences they can have today. If you're looking for something smaller and cheaper, there's also a $700 13-inch model, and the $1,200 15-inch version is worth it if you need a bigger screen. (Check out our full review of the Surface Laptop 13.8-inch.) Dell 14 Premium laptop Sam Rutherford for Engadget Dell 14 Premium We loved last year's XPS 14, and now that it’s been renamed as the Dell 14 Premium, it’s still a fantastic machine. It looks and feels luxurious, and it has one of the best screens around. You may just need some time getting used to its invisible trackpad (which is blended into the palm rest), and its capacitive function key row. (Check out our full Editor’s Choice review of the Dell 14 Premium.) ASUS ZenBook S 14 The ZenBook S14 wowed us with its powerful hardware, excellent battery life (of over 16 hours) and solid construction. It's a sign of how far ASUS has come from simply copying Apple. The S14 is also lighter than the MacBook Air, and it includes more useful ports (two USB-C, one USB-A, HDMI and a headphone jack). Its Ceraluminum case (a unique ceramic material) also feels surprisingly polished, and its OLED screen looks simply amazing. (Check out our full review of the ASUS ZenBook S 14.) Apple MacBook Air Don't yell at me — Apple's new computers are so good that Windows users should seriously consider jumping ship to Macs. While the software may take some getting used to, it's worth the struggle for the speed and incredible battery life from Apple's M-series chips. The MacBook Air remains one of the best computers around, with an incredibly thin and fan-less case and far more power than you'd think. And if you're an iPhone user, you'll also have access to features like phone mirroring that are tough to replicate on Windows. (Check out our full review of the M4 MacBook Air.) Dell Slim Desktop Dell The best Windows 10 desktop replacements Dell Slim desktop If you're just looking for a basic desktop replacement, it's hard to go wrong with the Dell Slim. While we haven't reviewed this specific model, the specs on even the entry-level configuration have all of the power you need for basic computing, despite housing everything in a frame that's notably smaller than older tower PCs. And if you need a bit more performance, consider the slightly more expensive Dell Pro, which can squeeze in up to 32GB of RAM and a handful of dedicated graphics cards. Apple Mac Mini Apple's Mac mini is one of the most powerful mini-desktops around, it's adorably small and it starts at just $599 (look for the frequent sales that drop the price by as much as $100). Just as I argued above for the MacBook Air, it's worth considering the jump to MacOS simply because Apple's hardware is so impressive now. And don't worry, you can connect any monitor to it, and you won't have to replace your existing PC keyboard and mouse. Geekom A6 Mini While I haven't tested the Geekom A6 Mini yet, it's widely considered one of the best Windows mini-desktops around $400 to $500. The A6 Mini features a very capable AMD Ryzen 7 6800H processor with a bit of gaming power, 16GB of RAM and a 512GB SSD. You honestly don't need much more for basic productivity work. Frequently Asked Questions Do I need to upgrade to a new computer if my current Windows 10 PC still works fine for me? Your computer will still continue to run following the Microsoft’s termination of default support for Windows 10 on October 15, 2025, but that’s not a wise longterm strategy. The free Extended Security Updates will buy you another year, but that's effectively a limited life support: After that, Windows 10 PCs won’t receive security updates or any sort of improvements, so they’ll be vulnerable to hacking and malware. And if you’ve still got an old Windows 10 machine, there’s a good chance that its components may wear out soon. If you choose to continue using a Windows 10 PC, be sure to back up your important data and try not to rely on it for critical tasks. Can a Mac run native Windows software? Virtualization software like VMWare and Parallels can let you run Windows apps inside of macOS, but be aware that also involves buying a copy of Windows and dedicating a large chunk of disk space for it. These days, most major apps are available across both platforms, so be sure to check if there’s a Mac version of your favorite Windows app. Can a Chromebook or iPad replace a Windows 10 PC? Chromebooks and iPads both have very specific purposes: Chromebooks are great budget-friendly machines for accessing the web and running online apps. iPads are a handy way to upgrade your mobile internet experiences, since their large screens are better for browsing the web, running apps and watching media. But neither are ideal replacements for a Windows 10 PC, which can access the full breadth of Windows software in addition to the web. If either one works for you, great; but we think the options listed above are better full-service PC replacements. I have a ton of PC games. What's my best upgrade option? It’s easy to find a decent gaming desktop from a reliable computer maker these days, just make sure you’re equipped with at least 32GB of RAM (new titles can be pretty memory intensive), and an NVIDIA RTX 40-series or AMD Radeon RX 9000-series GPU. As for CPUs, I’d recommend sticking with Intel’s 13th-gen chips or AMD’s Ryzen 8000-series processors at a minimum. Don’t count out gaming laptops either, as they’ve come a long way over the last decade. It’s not hard to find a gaming notebook that’s powerful, portable and useful for multimedia and productivity work as well. Update, October 20 2025, 9:30AM ET: This story has been updated to reflect that the Windows 10 end of support date has now passed, and we’ve included a link to an explainer on how to extend support for another year for free. This article originally appeared on Engadget at https://www.engadget.com/computing/the-best-new-computers-to-replace-your-old-windows-10-pc-134500000.html?src=rss",
          "content": "It’s official: Microsoft has officially ended support for Windows 10. Thankfully, there’s a free and easy way to get another year’s worth of Extended Security Updates (which will take you to mid-October 2026). But even if your computer meets the minimum system requirements for a free Windows 11 upgrade, anything older than a year won't be able to take advantage of Microsoft's Copilot+ AI PC features, like Windows Recall or Studio Effects for video chats. So if you've already been feeling that your current aging PC is on the verge of dying — slow performance, whining fans, batteries that barely keep a charge — it's probably time to consider replacing it with a new system. We've already done the legwork of researching and selecting new hardware in our best laptop and best Windows notebook guides (we've also covered more powerful gaming and schoolwork systems), but here are some suggestions if you're just looking to snap up something quickly. The best Windows 10 laptop replacements Surface Laptop 13.8-inch In many ways, the Snapdragon-powered Surface Laptop is emblematic of where Windows PCs are headed. It's incredibly light, surprisingly powerful for something with a mobile chip and its battery lasted over 17-and-a-half hours in our testing. While you may run into some compatibility issues if you're running ancient Windows programs, for most people the Surface Laptop is one of the best PC experiences they can have today. If you're looking for something smaller and cheaper, there's also a $700 13-inch model, and the $1,200 15-inch version is worth it if you need a bigger screen. (Check out our full review of the Surface Laptop 13.8-inch.) Dell 14 Premium laptop Sam Rutherford for Engadget Dell 14 Premium We loved last year's XPS 14, and now that it’s been renamed as the Dell 14 Premium, it’s still a fantastic machine. It looks and feels luxurious, and it has one of the best screens around. You may just need some time getting used to its invisible trackpad (which is blended into the palm rest), and its capacitive function key row. (Check out our full Editor’s Choice review of the Dell 14 Premium.) ASUS ZenBook S 14 The ZenBook S14 wowed us with its powerful hardware, excellent battery life (of over 16 hours) and solid construction. It's a sign of how far ASUS has come from simply copying Apple. The S14 is also lighter than the MacBook Air, and it includes more useful ports (two USB-C, one USB-A, HDMI and a headphone jack). Its Ceraluminum case (a unique ceramic material) also feels surprisingly polished, and its OLED screen looks simply amazing. (Check out our full review of the ASUS ZenBook S 14.) Apple MacBook Air Don't yell at me — Apple's new computers are so good that Windows users should seriously consider jumping ship to Macs. While the software may take some getting used to, it's worth the struggle for the speed and incredible battery life from Apple's M-series chips. The MacBook Air remains one of the best computers around, with an incredibly thin and fan-less case and far more power than you'd think. And if you're an iPhone user, you'll also have access to features like phone mirroring that are tough to replicate on Windows. (Check out our full review of the M4 MacBook Air.) Dell Slim Desktop Dell The best Windows 10 desktop replacements Dell Slim desktop If you're just looking for a basic desktop replacement, it's hard to go wrong with the Dell Slim. While we haven't reviewed this specific model, the specs on even the entry-level configuration have all of the power you need for basic computing, despite housing everything in a frame that's notably smaller than older tower PCs. And if you need a bit more performance, consider the slightly more expensive Dell Pro, which can squeeze in up to 32GB of RAM and a handful of dedicated graphics cards. Apple Mac Mini Apple's Mac mini is one of the most powerful mini-desktops around, it's adorably small and it starts at just $599 (look for the frequent sales that drop the price by as much as $100). Just as I argued above for the MacBook Air, it's worth considering the jump to MacOS simply because Apple's hardware is so impressive now. And don't worry, you can connect any monitor to it, and you won't have to replace your existing PC keyboard and mouse. Geekom A6 Mini While I haven't tested the Geekom A6 Mini yet, it's widely considered one of the best Windows mini-desktops around $400 to $500. The A6 Mini features a very capable AMD Ryzen 7 6800H processor with a bit of gaming power, 16GB of RAM and a 512GB SSD. You honestly don't need much more for basic productivity work. Frequently Asked Questions Do I need to upgrade to a new computer if my current Windows 10 PC still works fine for me? Your computer will still continue to run following the Microsoft’s termination of default support for Windows 10 on October 15, 2025, but that’s not a wise longterm strategy. The free Extended Security Updates will buy you another year, but that's effectively a limited life support: After that, Windows 10 PCs won’t receive security updates or any sort of improvements, so they’ll be vulnerable to hacking and malware. And if you’ve still got an old Windows 10 machine, there’s a good chance that its components may wear out soon. If you choose to continue using a Windows 10 PC, be sure to back up your important data and try not to rely on it for critical tasks. Can a Mac run native Windows software? Virtualization software like VMWare and Parallels can let you run Windows apps inside of macOS, but be aware that also involves buying a copy of Windows and dedicating a large chunk of disk space for it. These days, most major apps are available across both platforms, so be sure to check if there’s a Mac version of your favorite Windows app. Can a Chromebook or iPad replace a Windows 10 PC? Chromebooks and iPads both have very specific purposes: Chromebooks are great budget-friendly machines for accessing the web and running online apps. iPads are a handy way to upgrade your mobile internet experiences, since their large screens are better for browsing the web, running apps and watching media. But neither are ideal replacements for a Windows 10 PC, which can access the full breadth of Windows software in addition to the web. If either one works for you, great; but we think the options listed above are better full-service PC replacements. I have a ton of PC games. What's my best upgrade option? It’s easy to find a decent gaming desktop from a reliable computer maker these days, just make sure you’re equipped with at least 32GB of RAM (new titles can be pretty memory intensive), and an NVIDIA RTX 40-series or AMD Radeon RX 9000-series GPU. As for CPUs, I’d recommend sticking with Intel’s 13th-gen chips or AMD’s Ryzen 8000-series processors at a minimum. Don’t count out gaming laptops either, as they’ve come a long way over the last decade. It’s not hard to find a gaming notebook that’s powerful, portable and useful for multimedia and productivity work as well. Update, October 20 2025, 9:30AM ET: This story has been updated to reflect that the Windows 10 end of support date has now passed, and we’ve included a link to an explainer on how to extend support for another year for free. This article originally appeared on Engadget at https://www.engadget.com/computing/the-best-new-computers-to-replace-your-old-windows-10-pc-134500000.html?src=rss",
          "feed_position": 34,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/99233ff0-7236-11f0-babc-58c1851dbde8.jpeg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/adobe-foundry-wants-to-rebuild-firefly-for-your-brand-not-just-tweak-it",
          "published_at": "Mon, 20 Oct 2025 13:00:00 GMT",
          "title": "Adobe Foundry wants to rebuild Firefly for your brand — not just tweak it",
          "standfirst": "Hoping to attract more enterprise teams to its ecosystem, Adobe launched a new model customization service called Adobe AI Foundry, which would create bespoke versions of its flagship AI model, Firefly.Adobe AI Foundry will work with enterprise customers to rearchitect and retrain Firefly models specific to the client. AI Foundry version models are different from custom Firefly models in that Foundry models understand multiple concepts compared to custom models with only a single concept. These models will also be multimodal, offering a wider use case than custom Firefly models, which can only ingest and respond with images. Adobe AI Foundry models, with Firefly at its base, will know a company’s brand tone, image and video style, products and services and all its IP. The models will generate content based on this information for any use case the company wants. Hannah Elsakr, vice president, GenAI New Business Ventures at Adobe, told VentureBeat that the idea to set up AI Foundry came because enterprise customers wanted more sophisticated custom versions of Firefly. But with how complex the needs of enterprises are, Adobe will be doing the rearchitecting rather than handing the reins over to customers. “We will retrain our own Firefly commercially safe models with the enterprise IP. We keep that IP separate. We never take that back into the base model, and the enterprise itself owns that output,” Elsakr said. Adobe will deploy the Foundry version of Firefly through its API solution, Firefly Services. Elsakr likened AI Foundry to an advisory service, since Adobe will have teams working directly with enterprise customers to retrain the model. Deep tuningElsakr refers to Foundry as a deep tuning method because it goes further than simply fine-tuning a model.“The way we think about it, maybe more layman&#x27;s terms, is that we&#x27;re surgically reopening the Firefly-based models,” Elsakr said. “So you get the benefit of all the world&#x27;s knowledge from our image model or a video model. We&#x27;re going back in time and are bringing in the IP from the enterprise, like a brand. It could be footage from a shot style, whatever they have a license to contribute. We then retrain. We call this continuous pre-training, where we overweigh the model to dial some things differently. So we&#x27;re literally retraining our base model, and that&#x27;s why we call it deep tuning instead of fine-tuning.”Part of the training pipeline involves Adobe’s embedded teams working with the company to identify the data they would need. Then the data is securely transferred and ingested before being tagged. It is fed to the base model, and then Adobe begins a pre-training model run. Elsakr maintains the Foundry versions of Firefly will not be small or distilled models. Often, the additional data from companies expands the parameters of Firefly.Two early customers of Adobe AI Foundry are Home Depot and Walt Disney Imagineering, the research and development arm of Disney for its theme parks. “We are always exploring innovative ways to enhance our customer experience and streamline our creative workflows. Adobe’s AI Foundry represents an exciting step forward in embracing cutting-edge technologies to deepen customer engagement and deliver impactful content across our digital channels,” said Molly Battin, senior vice president and chief marketing officer at The Home Depot.More customizationEnterprises often turn to fine-tuning and model customization to bring large language models with their vast external knowledge closer to their company’s needs. Fine-tuning also enables enterprise users to utilize models only in the context of their organization’s data, so the model doesn’t respond with text wholly unrelated to the business.Most organizations, however, do the fine-tuning themselves. They connect to the model’s API and begin retraining it to answer based on their ground truth or their preferences. Several methods for fine-tuning exist, including some that can be done with just a prompt. Other model providers also try to make it easier for their customers to fine-tune models, such as OpenAI with its o4-mini reasoning model. Elsakr said she expects some companies will have three versions of Firefly: the Foundry version for most projects, a custom Firefly for specific single-concept use cases, and the base Firefly because some teams want a model less encumbered by corporate knowledge.",
          "content": "Hoping to attract more enterprise teams to its ecosystem, Adobe launched a new model customization service called Adobe AI Foundry, which would create bespoke versions of its flagship AI model, Firefly.Adobe AI Foundry will work with enterprise customers to rearchitect and retrain Firefly models specific to the client. AI Foundry version models are different from custom Firefly models in that Foundry models understand multiple concepts compared to custom models with only a single concept. These models will also be multimodal, offering a wider use case than custom Firefly models, which can only ingest and respond with images. Adobe AI Foundry models, with Firefly at its base, will know a company’s brand tone, image and video style, products and services and all its IP. The models will generate content based on this information for any use case the company wants. Hannah Elsakr, vice president, GenAI New Business Ventures at Adobe, told VentureBeat that the idea to set up AI Foundry came because enterprise customers wanted more sophisticated custom versions of Firefly. But with how complex the needs of enterprises are, Adobe will be doing the rearchitecting rather than handing the reins over to customers. “We will retrain our own Firefly commercially safe models with the enterprise IP. We keep that IP separate. We never take that back into the base model, and the enterprise itself owns that output,” Elsakr said. Adobe will deploy the Foundry version of Firefly through its API solution, Firefly Services. Elsakr likened AI Foundry to an advisory service, since Adobe will have teams working directly with enterprise customers to retrain the model. Deep tuningElsakr refers to Foundry as a deep tuning method because it goes further than simply fine-tuning a model.“The way we think about it, maybe more layman&#x27;s terms, is that we&#x27;re surgically reopening the Firefly-based models,” Elsakr said. “So you get the benefit of all the world&#x27;s knowledge from our image model or a video model. We&#x27;re going back in time and are bringing in the IP from the enterprise, like a brand. It could be footage from a shot style, whatever they have a license to contribute. We then retrain. We call this continuous pre-training, where we overweigh the model to dial some things differently. So we&#x27;re literally retraining our base model, and that&#x27;s why we call it deep tuning instead of fine-tuning.”Part of the training pipeline involves Adobe’s embedded teams working with the company to identify the data they would need. Then the data is securely transferred and ingested before being tagged. It is fed to the base model, and then Adobe begins a pre-training model run. Elsakr maintains the Foundry versions of Firefly will not be small or distilled models. Often, the additional data from companies expands the parameters of Firefly.Two early customers of Adobe AI Foundry are Home Depot and Walt Disney Imagineering, the research and development arm of Disney for its theme parks. “We are always exploring innovative ways to enhance our customer experience and streamline our creative workflows. Adobe’s AI Foundry represents an exciting step forward in embracing cutting-edge technologies to deepen customer engagement and deliver impactful content across our digital channels,” said Molly Battin, senior vice president and chief marketing officer at The Home Depot.More customizationEnterprises often turn to fine-tuning and model customization to bring large language models with their vast external knowledge closer to their company’s needs. Fine-tuning also enables enterprise users to utilize models only in the context of their organization’s data, so the model doesn’t respond with text wholly unrelated to the business.Most organizations, however, do the fine-tuning themselves. They connect to the model’s API and begin retraining it to answer based on their ground truth or their preferences. Several methods for fine-tuning exist, including some that can be done with just a prompt. Other model providers also try to make it easier for their customers to fine-tune models, such as OpenAI with its o4-mini reasoning model. Elsakr said she expects some companies will have three versions of Firefly: the Foundry version for most projects, a custom Firefly for specific single-concept use cases, and the base Firefly because some teams want a model less encumbered by corporate knowledge.",
          "feed_position": 8,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1Hg97nt1wacQ4K8pE0NfX7/5dba45daa25b361ac777c18695b45898/crimedy7_illustration_of_a_sculptor_creating_a_robot_from_a_p_501bf165-0b44-4bb1-9608-1025a42400b7_2.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/tv-movies/the-new-apple-tv-and-peacock-streaming-bundle-is-officially-available-170403587.html",
          "published_at": "Mon, 20 Oct 2025 12:18:26 +0000",
          "title": "The new Apple TV and Peacock streaming bundle is officially available",
          "standfirst": "There's yet another streaming bundle in town, and it will be ideal for fans of Ted Lasso and The Office. Apple and Peacock have teamed up to provide both of their streaming services together in a bundle starting at $15 per month. The new Apple TV + Peacock bundle is officially available now for $15 monthly for the ad-supported tier. This is a mighty fine deal, given that Apple TV recently changed both its name and price. The platform costs $13 per month now on its own. Peacock starts at $11 per month. In other words, this is a discount of around $9 each month. In this economy, we'll take any savings we can get. As mentioned previously, the only caveat is that the base tier includes ads. The subscription shoots up to $20 per month for an ad-free version. However, a standalone subscription to ad-free Peacock is $17 on its own. Additionally, Apple One subscribers will get a 35 percent discount on Peacock Premium Plus plans. It's always nice when two lonely corporations find friendship, isn't it? For the uninitiated, Apple TV is the company's big-wig streaming platform. It's primarily known for sci-fi like Severance, For All Mankind and the upcoming Pluribus. The platform is also host to plenty of comedy, like The Studio, Shrinking and Ted Lasso. Peacock is NBC's streaming service. It streams old-school network programming like The Office, Grimm and Superstore. The service features a stable of original programming like Poker Face, Twisted Metal and the underrated Mrs. Davis. The platform also recently premiered a little show called The Paper, which is a spinoff of The Office. Against all odds, this is actually a great little sitcom and a worthy successor to the original. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/the-new-apple-tv-and-peacock-streaming-bundle-is-officially-available-170403587.html?src=rss",
          "content": "There's yet another streaming bundle in town, and it will be ideal for fans of Ted Lasso and The Office. Apple and Peacock have teamed up to provide both of their streaming services together in a bundle starting at $15 per month. The new Apple TV + Peacock bundle is officially available now for $15 monthly for the ad-supported tier. This is a mighty fine deal, given that Apple TV recently changed both its name and price. The platform costs $13 per month now on its own. Peacock starts at $11 per month. In other words, this is a discount of around $9 each month. In this economy, we'll take any savings we can get. As mentioned previously, the only caveat is that the base tier includes ads. The subscription shoots up to $20 per month for an ad-free version. However, a standalone subscription to ad-free Peacock is $17 on its own. Additionally, Apple One subscribers will get a 35 percent discount on Peacock Premium Plus plans. It's always nice when two lonely corporations find friendship, isn't it? For the uninitiated, Apple TV is the company's big-wig streaming platform. It's primarily known for sci-fi like Severance, For All Mankind and the upcoming Pluribus. The platform is also host to plenty of comedy, like The Studio, Shrinking and Ted Lasso. Peacock is NBC's streaming service. It streams old-school network programming like The Office, Grimm and Superstore. The service features a stable of original programming like Poker Face, Twisted Metal and the underrated Mrs. Davis. The platform also recently premiered a little show called The Paper, which is a spinoff of The Office. Against all odds, this is actually a great little sitcom and a worthy successor to the original. This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/the-new-apple-tv-and-peacock-streaming-bundle-is-officially-available-170403587.html?src=rss",
          "feed_position": 36
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/beats-powerbeats-fit-review-deja-vu-in-a-good-way-120058332.html",
          "published_at": "Mon, 20 Oct 2025 12:00:58 +0000",
          "title": "Beats Powerbeats Fit review: Déjà vu, in a good way",
          "standfirst": "Beats devices have been the more colorful, full-of-personality complements to Apple’s clean-and-minimal gear ever since Apple bought the company back in 2014. Beats earbuds and speakers are the more flexible alternatives to things like AirPods and HomePods, and the new Beats Powerbeats Fit keep that tradition alive. Some six months after the Powerbeats Pro 2 debuted earlier this year, Beats now has an updated version of the Fit Pro to offer folks looking for many of the conveniences of an Apple device in something with slightly more character and versatility. Rather than reinventing the wheel, Beats made small changes on the Powerbeats Fit that ultimately make for a more polished version of its predecessor. What’s new If you’re familiar with the Beats Fit Pro, you’ll be familiar with the Powerbeats Fit. Beats kept much of what worked with its previous $200 earbuds here (including the price), making very minor changes to improve the comfort and the overall design. The new buds have 20 percent more flexible wingtips and the charging case is 17 percent more compact than that of the Beats Fit Pro. More on the wingtips in a moment, but first I have to commend Beats for making the charging case feel ever so slightly more premium this time around — and since it’s smaller than before, it’s less cumbersome to tuck in your back pocket. The buds also fit snugly into the charging case with a satisfying snap every time; they always align properly to recharge, something I cannot say about past pairs of the AirPods Pro I’ve owned. When it comes to the wingtips on the Powerbeats Fit, they appear to be a hair shorter than those on the Beats Fit Pro, and certainly more malleable. I felt the biggest difference in flexibility at the base of the wingtip where it meets the earbud — those on the Powerbeats Fit have a bit more give than those on its predecessor. These small changes make it easy to pop the Powerbeats Fit into your ears and really not fuss with the wingtips at all. They’re present just to provide a more secure fit during intense workouts, and they do just that. I wore them during strength training, 5K runs and leisurely walks and I didn’t have to adjust them at all once I popped them in. When Beats announced these new buds, the company claimed its design tweaks would also make the Powerbeats Fit more comfortable to wear all day long, not just during workouts. I’ll admit that I didn’t find the previous Beats Fit Pro uncomfortable to wear when not at the gym or on the trail. Yes, the Powerbeats Fit are marginally more comfortable now and the wingtips are more supple, but the change is subtle. If you jibe with the wingtip design to begin with, you’ll safely be able to use the Powerbeats Fit as daily drivers in addition to workout companions. Notably, the Powerbeats Fit come with one extra pair of eartips in the box (four instead of the previous three), so once you find the eartips that are your best fit, you’ll be off to the races. There are also two new bold colors to choose from, orange and pink, in addition to gray and black. Valentina Palladino for Engadget What’s the same Thankfully, Beats didn’t mess with all of the good things about the Fit Pro when developing the Powerbeats Fit. The new buds have an IPX4 water resistance rating, which isn’t the highest level of protection out there, but more than enough to withstand your sweatiest training sessions. Onboard controls in the form of physical buttons remain the same, although I didn’t accidentally trigger the buttons on the Powerbeats Fit nearly as much as I did with the Fit Pro. That might be because all the small changes Beats made in the design paid off — I didn’t fuss with the new buds in my ears as much as before, therefore I didn’t accidentally press the buttons as much. The Powerbeats Fit also have Apple’s H1 chip inside, which enables features like hands-free Siri, automatic switching between devices, Adaptive EQ, Audio Sharing and Personalized Spatial Audio with dynamic head tracking. Transparency mode returns here as well, and it remains one of the standout features of any Apple-associated wireless earbuds. And if you do decide to wear the Powerbeats Fit all day long, you’ll likely make even more use of transparency mode as you need to jump in and out of conversations happening around you. In addition, you can keep track of the new earbuds in Apple’s Find My app. Beats didn’t bill any improvements in sound quality on the Powerbeats Fit, and after listening to them alongside the Beats Fit Pro, I can say they sound almost identical. While listening to some tracks with the Powerbeats Fit, I noticed an almost imperceptible increase in the clarity of vocals, but that’s about it. Bass remains punchy and strong, and the buds get decently loud. Active noise cancellation (ANC) is also the same on the new buds: strong enough to block out ambient noise around you and people’s voices. While running outside, I still heard the loudest disturbances like passing trucks and oddly sonorous cackling of nearby wildlife, but that’s arguably for the best. If you’re exercising outside, be it in a park or on city streets, you should be at least somewhat aware of your surroundings. Valentina Palladino for Engadget Battery life is consistent here as well, with Beats promising up to seven hours on a single charge (or six with ANC turned on) and up to 30 hours total when employing the Powerbeats Fit charging case. Anecdotally, after a week of using the Powerbeats Fit for an average of one hour each day, the charging case still had 75 percent battery left. If you’re using these all day, every day, you’ll obviously need to power it up more frequently. But if these are primarily your workout companions, you could get a week or two before needing to plug them in. Wrap-up The Powerbeats Fit are a fitting update to the Beats Fit Pro. The latter was one of the best devices in the Beats lineup to begin with, and the latest model only improves upon the winning formula. They offer a solid balance of a comfortable, secure design, good sound quality and ANC and handy additional features at a decent price. The latter is arguably just as important as the buds’ ability to withstand a sweaty training session: folks looking for many of the conveniences found in AirPods will find them here in an alternative design, and in a pair of buds that also works just as well with Android devices. If you’re willing to pay more, you could shell out $250 for either the Powerbeats Pro 2 to get that full over-ear hook style, or AirPods Pro 3 — both of which have built-in heart rate tracking But that feature in particular will be more of a nice-to-have than a necessity for most.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/beats-powerbeats-fit-review-deja-vu-in-a-good-way-120058332.html?src=rss",
          "content": "Beats devices have been the more colorful, full-of-personality complements to Apple’s clean-and-minimal gear ever since Apple bought the company back in 2014. Beats earbuds and speakers are the more flexible alternatives to things like AirPods and HomePods, and the new Beats Powerbeats Fit keep that tradition alive. Some six months after the Powerbeats Pro 2 debuted earlier this year, Beats now has an updated version of the Fit Pro to offer folks looking for many of the conveniences of an Apple device in something with slightly more character and versatility. Rather than reinventing the wheel, Beats made small changes on the Powerbeats Fit that ultimately make for a more polished version of its predecessor. What’s new If you’re familiar with the Beats Fit Pro, you’ll be familiar with the Powerbeats Fit. Beats kept much of what worked with its previous $200 earbuds here (including the price), making very minor changes to improve the comfort and the overall design. The new buds have 20 percent more flexible wingtips and the charging case is 17 percent more compact than that of the Beats Fit Pro. More on the wingtips in a moment, but first I have to commend Beats for making the charging case feel ever so slightly more premium this time around — and since it’s smaller than before, it’s less cumbersome to tuck in your back pocket. The buds also fit snugly into the charging case with a satisfying snap every time; they always align properly to recharge, something I cannot say about past pairs of the AirPods Pro I’ve owned. When it comes to the wingtips on the Powerbeats Fit, they appear to be a hair shorter than those on the Beats Fit Pro, and certainly more malleable. I felt the biggest difference in flexibility at the base of the wingtip where it meets the earbud — those on the Powerbeats Fit have a bit more give than those on its predecessor. These small changes make it easy to pop the Powerbeats Fit into your ears and really not fuss with the wingtips at all. They’re present just to provide a more secure fit during intense workouts, and they do just that. I wore them during strength training, 5K runs and leisurely walks and I didn’t have to adjust them at all once I popped them in. When Beats announced these new buds, the company claimed its design tweaks would also make the Powerbeats Fit more comfortable to wear all day long, not just during workouts. I’ll admit that I didn’t find the previous Beats Fit Pro uncomfortable to wear when not at the gym or on the trail. Yes, the Powerbeats Fit are marginally more comfortable now and the wingtips are more supple, but the change is subtle. If you jibe with the wingtip design to begin with, you’ll safely be able to use the Powerbeats Fit as daily drivers in addition to workout companions. Notably, the Powerbeats Fit come with one extra pair of eartips in the box (four instead of the previous three), so once you find the eartips that are your best fit, you’ll be off to the races. There are also two new bold colors to choose from, orange and pink, in addition to gray and black. Valentina Palladino for Engadget What’s the same Thankfully, Beats didn’t mess with all of the good things about the Fit Pro when developing the Powerbeats Fit. The new buds have an IPX4 water resistance rating, which isn’t the highest level of protection out there, but more than enough to withstand your sweatiest training sessions. Onboard controls in the form of physical buttons remain the same, although I didn’t accidentally trigger the buttons on the Powerbeats Fit nearly as much as I did with the Fit Pro. That might be because all the small changes Beats made in the design paid off — I didn’t fuss with the new buds in my ears as much as before, therefore I didn’t accidentally press the buttons as much. The Powerbeats Fit also have Apple’s H1 chip inside, which enables features like hands-free Siri, automatic switching between devices, Adaptive EQ, Audio Sharing and Personalized Spatial Audio with dynamic head tracking. Transparency mode returns here as well, and it remains one of the standout features of any Apple-associated wireless earbuds. And if you do decide to wear the Powerbeats Fit all day long, you’ll likely make even more use of transparency mode as you need to jump in and out of conversations happening around you. In addition, you can keep track of the new earbuds in Apple’s Find My app. Beats didn’t bill any improvements in sound quality on the Powerbeats Fit, and after listening to them alongside the Beats Fit Pro, I can say they sound almost identical. While listening to some tracks with the Powerbeats Fit, I noticed an almost imperceptible increase in the clarity of vocals, but that’s about it. Bass remains punchy and strong, and the buds get decently loud. Active noise cancellation (ANC) is also the same on the new buds: strong enough to block out ambient noise around you and people’s voices. While running outside, I still heard the loudest disturbances like passing trucks and oddly sonorous cackling of nearby wildlife, but that’s arguably for the best. If you’re exercising outside, be it in a park or on city streets, you should be at least somewhat aware of your surroundings. Valentina Palladino for Engadget Battery life is consistent here as well, with Beats promising up to seven hours on a single charge (or six with ANC turned on) and up to 30 hours total when employing the Powerbeats Fit charging case. Anecdotally, after a week of using the Powerbeats Fit for an average of one hour each day, the charging case still had 75 percent battery left. If you’re using these all day, every day, you’ll obviously need to power it up more frequently. But if these are primarily your workout companions, you could get a week or two before needing to plug them in. Wrap-up The Powerbeats Fit are a fitting update to the Beats Fit Pro. The latter was one of the best devices in the Beats lineup to begin with, and the latest model only improves upon the winning formula. They offer a solid balance of a comfortable, secure design, good sound quality and ANC and handy additional features at a decent price. The latter is arguably just as important as the buds’ ability to withstand a sweaty training session: folks looking for many of the conveniences found in AirPods will find them here in an alternative design, and in a pair of buds that also works just as well with Android devices. If you’re willing to pay more, you could shell out $250 for either the Powerbeats Pro 2 to get that full over-ear hook style, or AirPods Pro 3 — both of which have built-in heart rate tracking But that feature in particular will be more of a nice-to-have than a necessity for most.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/beats-powerbeats-fit-review-deja-vu-in-a-good-way-120058332.html?src=rss",
          "feed_position": 38,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-10/7c269cf0-ab64-11f0-ac9b-105ce8eedd80"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/best-smartphones-140004900.html",
          "published_at": "Mon, 20 Oct 2025 09:01:27 +0000",
          "title": "The best smartphones to buy in 2025",
          "standfirst": "You might already have a good idea of which smartphone you want to be your next one. But there are more solid options available now than ever before, making the decision not as cut-and-dry as it used to be. While the decision is a bit easier if you know you want an iPhone, there's even enough variation between those new models that you may have to think about it longer than you anticipated. If you’re an Android person, you have even more options to choose from — including foldables — and more questions to answer before you spend any money.At Engadget, we review phones regularly and have tested dozens over the years. Whether you’ve had your eye on one of our current top picks, one of Samsung's Galaxy S25 phones, a cheap phone or another device, we’re here to help you decide which is the best phone to buy this year. Table of contents Best smartphones for 2025 Other smartphones we've tested What to look for in a smartphone Smartphone FAQs Recent updates Best smartphones for 2025 Other smartphones we've tested iPhone Air At just 5.6mm, the iPhone Air is the thinnest iPhone ever made. But it’s so much more than that. It’s beautifully crafted and thanks to a titanium frame, Ceramic Shield 2 screen and an IP68 rating for dust and water resistance, it’s surprisingly durable too. The Air also has a gorgeous 6.5-inch display with ProMotion support and an A19 Pro processor, so it delivers nearly the same performance as you get from the iPhone 17 Pro line. And despite its super thin chassis not leaving a ton of room for a big power cell, battery life isn’t an issue. In short, this is the iPhone design that everyone wants. However, with the Air only having a single rear camera, the question you need to answer is if you’re willing to give up some extra lenses to get the most exquisitely engineered iPhone and all of its style and sleekness. — S.R. Google Pixel 10 Pro Fold While the design and performance of the Galaxy Z Fold 7 is so good that we had to pick it as our favorite foldable of this generation, the Pixel 10 Pro Fold isn’t that far behind. Sure, it’s bigger and bulkier, but it still has the best cameras on any foldable phone along with better software and a larger battery. But perhaps most importantly, it now has a proper IP68 rating for dust and water resistance — something you won’t find on any of its rivals. This could save the phone from an early demise and prevent a lot of headaches if you frequent the beach or pretty much anywhere with little particles that could threaten the insides of your device. — S.R. OnePlus 13 While the OnePlus 13 features some basic AI features like Google’s Circle to Search and Gemini assistant, it’s really just an old-fashioned flagship in all the best ways. That’s because instead of focusing on machine learning, OnePlus crammed the phone with tons of top-notch hardware. It sports a 6.8-inch OLED display with an incredible peak brightness of up to 4,500 nits. The OP13 also offers excellent performance thanks to Qualcomm’s Snapdragon 8 Elite chip, along with 16GB of RAM and 512GB of storage. There are also three 50-MP rear cameras including one with a 3x telephoto zoom and a massive 6,000 mAh battery that’s bigger than what you get in practically all of its competitors. OnePlus didn’t skimp on the phone’s design either, as the OP13 still comes with the company’s signature Alert Slider. Plus, if you opt for the blue or white variants, you’ll get a durable and very touchable vegan leather back that helps the phone stand out among all its glass brick rivals. But the best part is that starting at $900, it costs less than an equivalent Galaxy S25+ too. What to look for in a smartphone Android or iOS? When you're searching for the best smartphone, it becomes clear that each OS has its pros and cons. Apple’s tight-knit ecosystem makes it super easy to share data between iPhones, iPads and Macs or seamlessly hand-off phone calls or music from one device to another. At the same time, you’re effectively locked in, as services like Apple Messages aren’t available on other platforms. As for Android, there’s a much wider range of handsets from companies like Google, Samsung, Sony and more. However, Android phones don’t enjoy that same length of software support and often have lower trade-in values. In short, there’s no wrong answer. However, you will want to consider how your phone will fit in with the rest of your devices. So unless you’re really fed up with one OS and willing to learn another, it probably doesn’t make a lot of sense to switch from an iPhone to an Android phone (or vice versa) – especially if everyone else in your household is using the same platform. Cameras Since your cell phone often pulls double duty as your primary camera, figuring out what kind of photo tools you want is key. Nowadays, practically every mobile phone can take a great picture in bright light. But if you want a long optical zoom, you’ll probably have to upgrade to a more expensive device. Mid-range phones often only have two rear cameras (a primary wide-angle lens and a secondary ultra-wide camera) and can sometimes struggle in low-light situations. Each phone maker also has various features that might be a better fit for your style, with Apple offering four different color presets on the latest iPhones, while Google’s Pixel 9 Pro comes with neat tools like dedicated long exposure and Action Pan modes. Will you get mmWave 5G or Wi-Fi 7? The good news is that in 2025, most phones have at least Wi-Fi 6 or Wi-Fi 6e and support for some kind of 5G connectivity. However, if you want the fastest wireless speeds possible, it’s going to cost you a little extra. For example, on certain networks, mmWave 5G offers up to gigabit download speeds, less latency and better bandwidth. But mmWave 5G also requires more sophisticated (and pricier) modems, which means support for it is often missing on less expensive devices. On the bright side, mmWave 5G isn’t as widely available as other versions of 5G, so depending on where you live and what network you’re on, you may not be missing out on much right now if you buy a phone that doesn’t support it. It’s a similar situation for Wi-Fi 7, which is available on some high-end handsets like the Galaxy S25, but harder to find on cheaper devices. Wi-Fi 7 also requires you to have a compatible router, so unless you know you need it or have a specific use case in mind, the lack of support for mmWave 5G or Wi-Fi 7 shouldn’t be a dealbreaker when looking for a new phone. Other features to consider Because not everyone agrees on what makes the best phone, you should think about any other specs that might be extra important for you. Mobile gamers will almost certainly appreciate the 120Hz refresh rates you get on phones like the Samsung Galaxy S25 or the Apple iPhone 17 Pro. Alternatively, if long battery life is important, you’ll probably want to go with a larger iPhone or an Android phone with a battery that’s between 4,000 and 5,000 mAh in size. Meanwhile, if you find yourself juggling a lot of devices, it can be really nice to have a phone that supports reverse wireless charging, which on Samsung phones even lets you recharge the company’s Galaxy Watches. Smartphone FAQs How do I know which smartphone is the best for me? While choosing the best smartphone can be challenging, it mostly comes down to how you plan on using the device. All of the best phones available now get the basics right — you’ll be able to make calls, text and access the internet without many hiccups. If your smartphone is your most used gadget, you may want to consider paying for a device on the higher end of the price spectrum. That will get you better overall performance, higher-quality cameras and a phone that will last for many years. If you don’t use your phone for everything, you may be able to compromise on performance and extra perks and spend less on a still-capable handset. How much is a smartphone? Smartphones range in price from $300 to over $1,500. The best budget phones available now will usually compromise on overall performance, design, camera prowess and extra features to keep costs down. On the flip side, the most expensive phones will have powerful processors, triple-camera arrays and even flip or fold designs. Most people will find a phone that fits their needs somewhere in the middle of that wide price range — we’ve found that most of the best smartphones available right now cost between $500 and $1,000. What can you do on a smartphone? Smartphones are essentially small, portable computers that let you do things like check email, browse social media, follow map directions, make contactless payments and more. This is all on top of the basics like making phone calls and texting, which we’ve come to expect in all modern cell phones. Smartphones have also mostly replaced compact cameras thanks to their high-quality, built-in shooters, and the fact that most smartphones today as just as portable, if not more so, as compact cameras. How long do smartphones last? Smartphones can last years and people are holding on to their phones longer now than ever before. Software updates and battery life are two of the biggest factors that can affect phone longevity. Apple promises five years worth of software updates for its latest iPhones, and Google promises the same for its Pixel phones. Samsung phones will get four years worth of Android updates from the time they launch. As for charging speeds and battery life, your phone can deteriorate over time as you use and recharge your phone on a regular basis. Recent updates September 2025: Updated to include the iPhone 17 Pro. August 2025: Updated to include the Google Pixel 10 Pro. July 2025: Updated to include the Samsung Galaxy Z Fold 7. April 2025: Updated to include the Google Pixel 9a. February 2025: Updated to include the iPhone 16e. January 2025: Updated to include details about Samsung's latest Galaxy S-series phones.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-smartphones-140004900.html?src=rss",
          "content": "You might already have a good idea of which smartphone you want to be your next one. But there are more solid options available now than ever before, making the decision not as cut-and-dry as it used to be. While the decision is a bit easier if you know you want an iPhone, there's even enough variation between those new models that you may have to think about it longer than you anticipated. If you’re an Android person, you have even more options to choose from — including foldables — and more questions to answer before you spend any money.At Engadget, we review phones regularly and have tested dozens over the years. Whether you’ve had your eye on one of our current top picks, one of Samsung's Galaxy S25 phones, a cheap phone or another device, we’re here to help you decide which is the best phone to buy this year. Table of contents Best smartphones for 2025 Other smartphones we've tested What to look for in a smartphone Smartphone FAQs Recent updates Best smartphones for 2025 Other smartphones we've tested iPhone Air At just 5.6mm, the iPhone Air is the thinnest iPhone ever made. But it’s so much more than that. It’s beautifully crafted and thanks to a titanium frame, Ceramic Shield 2 screen and an IP68 rating for dust and water resistance, it’s surprisingly durable too. The Air also has a gorgeous 6.5-inch display with ProMotion support and an A19 Pro processor, so it delivers nearly the same performance as you get from the iPhone 17 Pro line. And despite its super thin chassis not leaving a ton of room for a big power cell, battery life isn’t an issue. In short, this is the iPhone design that everyone wants. However, with the Air only having a single rear camera, the question you need to answer is if you’re willing to give up some extra lenses to get the most exquisitely engineered iPhone and all of its style and sleekness. — S.R. Google Pixel 10 Pro Fold While the design and performance of the Galaxy Z Fold 7 is so good that we had to pick it as our favorite foldable of this generation, the Pixel 10 Pro Fold isn’t that far behind. Sure, it’s bigger and bulkier, but it still has the best cameras on any foldable phone along with better software and a larger battery. But perhaps most importantly, it now has a proper IP68 rating for dust and water resistance — something you won’t find on any of its rivals. This could save the phone from an early demise and prevent a lot of headaches if you frequent the beach or pretty much anywhere with little particles that could threaten the insides of your device. — S.R. OnePlus 13 While the OnePlus 13 features some basic AI features like Google’s Circle to Search and Gemini assistant, it’s really just an old-fashioned flagship in all the best ways. That’s because instead of focusing on machine learning, OnePlus crammed the phone with tons of top-notch hardware. It sports a 6.8-inch OLED display with an incredible peak brightness of up to 4,500 nits. The OP13 also offers excellent performance thanks to Qualcomm’s Snapdragon 8 Elite chip, along with 16GB of RAM and 512GB of storage. There are also three 50-MP rear cameras including one with a 3x telephoto zoom and a massive 6,000 mAh battery that’s bigger than what you get in practically all of its competitors. OnePlus didn’t skimp on the phone’s design either, as the OP13 still comes with the company’s signature Alert Slider. Plus, if you opt for the blue or white variants, you’ll get a durable and very touchable vegan leather back that helps the phone stand out among all its glass brick rivals. But the best part is that starting at $900, it costs less than an equivalent Galaxy S25+ too. What to look for in a smartphone Android or iOS? When you're searching for the best smartphone, it becomes clear that each OS has its pros and cons. Apple’s tight-knit ecosystem makes it super easy to share data between iPhones, iPads and Macs or seamlessly hand-off phone calls or music from one device to another. At the same time, you’re effectively locked in, as services like Apple Messages aren’t available on other platforms. As for Android, there’s a much wider range of handsets from companies like Google, Samsung, Sony and more. However, Android phones don’t enjoy that same length of software support and often have lower trade-in values. In short, there’s no wrong answer. However, you will want to consider how your phone will fit in with the rest of your devices. So unless you’re really fed up with one OS and willing to learn another, it probably doesn’t make a lot of sense to switch from an iPhone to an Android phone (or vice versa) – especially if everyone else in your household is using the same platform. Cameras Since your cell phone often pulls double duty as your primary camera, figuring out what kind of photo tools you want is key. Nowadays, practically every mobile phone can take a great picture in bright light. But if you want a long optical zoom, you’ll probably have to upgrade to a more expensive device. Mid-range phones often only have two rear cameras (a primary wide-angle lens and a secondary ultra-wide camera) and can sometimes struggle in low-light situations. Each phone maker also has various features that might be a better fit for your style, with Apple offering four different color presets on the latest iPhones, while Google’s Pixel 9 Pro comes with neat tools like dedicated long exposure and Action Pan modes. Will you get mmWave 5G or Wi-Fi 7? The good news is that in 2025, most phones have at least Wi-Fi 6 or Wi-Fi 6e and support for some kind of 5G connectivity. However, if you want the fastest wireless speeds possible, it’s going to cost you a little extra. For example, on certain networks, mmWave 5G offers up to gigabit download speeds, less latency and better bandwidth. But mmWave 5G also requires more sophisticated (and pricier) modems, which means support for it is often missing on less expensive devices. On the bright side, mmWave 5G isn’t as widely available as other versions of 5G, so depending on where you live and what network you’re on, you may not be missing out on much right now if you buy a phone that doesn’t support it. It’s a similar situation for Wi-Fi 7, which is available on some high-end handsets like the Galaxy S25, but harder to find on cheaper devices. Wi-Fi 7 also requires you to have a compatible router, so unless you know you need it or have a specific use case in mind, the lack of support for mmWave 5G or Wi-Fi 7 shouldn’t be a dealbreaker when looking for a new phone. Other features to consider Because not everyone agrees on what makes the best phone, you should think about any other specs that might be extra important for you. Mobile gamers will almost certainly appreciate the 120Hz refresh rates you get on phones like the Samsung Galaxy S25 or the Apple iPhone 17 Pro. Alternatively, if long battery life is important, you’ll probably want to go with a larger iPhone or an Android phone with a battery that’s between 4,000 and 5,000 mAh in size. Meanwhile, if you find yourself juggling a lot of devices, it can be really nice to have a phone that supports reverse wireless charging, which on Samsung phones even lets you recharge the company’s Galaxy Watches. Smartphone FAQs How do I know which smartphone is the best for me? While choosing the best smartphone can be challenging, it mostly comes down to how you plan on using the device. All of the best phones available now get the basics right — you’ll be able to make calls, text and access the internet without many hiccups. If your smartphone is your most used gadget, you may want to consider paying for a device on the higher end of the price spectrum. That will get you better overall performance, higher-quality cameras and a phone that will last for many years. If you don’t use your phone for everything, you may be able to compromise on performance and extra perks and spend less on a still-capable handset. How much is a smartphone? Smartphones range in price from $300 to over $1,500. The best budget phones available now will usually compromise on overall performance, design, camera prowess and extra features to keep costs down. On the flip side, the most expensive phones will have powerful processors, triple-camera arrays and even flip or fold designs. Most people will find a phone that fits their needs somewhere in the middle of that wide price range — we’ve found that most of the best smartphones available right now cost between $500 and $1,000. What can you do on a smartphone? Smartphones are essentially small, portable computers that let you do things like check email, browse social media, follow map directions, make contactless payments and more. This is all on top of the basics like making phone calls and texting, which we’ve come to expect in all modern cell phones. Smartphones have also mostly replaced compact cameras thanks to their high-quality, built-in shooters, and the fact that most smartphones today as just as portable, if not more so, as compact cameras. How long do smartphones last? Smartphones can last years and people are holding on to their phones longer now than ever before. Software updates and battery life are two of the biggest factors that can affect phone longevity. Apple promises five years worth of software updates for its latest iPhones, and Google promises the same for its Pixel phones. Samsung phones will get four years worth of Android updates from the time they launch. As for charging speeds and battery life, your phone can deteriorate over time as you use and recharge your phone on a regular basis. Recent updates September 2025: Updated to include the iPhone 17 Pro. August 2025: Updated to include the Google Pixel 10 Pro. July 2025: Updated to include the Samsung Galaxy Z Fold 7. April 2025: Updated to include the Google Pixel 9a. February 2025: Updated to include the iPhone 16e. January 2025: Updated to include details about Samsung's latest Galaxy S-series phones.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-smartphones-140004900.html?src=rss",
          "feed_position": 40,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2021-10/91a42bf0-305d-11ec-9f9f-636d29742095"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/agentic-ai-security-breaches-are-coming-7-ways-to-make-sure-its-not-your",
          "published_at": "Mon, 20 Oct 2025 07:00:00 GMT",
          "title": "Agentic AI security breaches are coming: 7 ways to make sure it's not your firm",
          "standfirst": "AI agents – task-specific models designed to operate autonomously or semi-autonomously given instructions — are being widely implemented across enterprises (up to 79% of all surveyed for a PwC report earlier this year). But they&#x27;re also introducing new security risks. When an agentic AI security breach happens, companies may be quick to fire employees and assign blame, but slower to identify and fix the systemic failures that enabled it.Forrester’s Predictions 2026: Cybersecurity and Risk predicts that the first agentic AI breach will lead to dismissals, adding that geopolitical turmoil and the pressure being put on CISOs and CIOs to deploy agentic AI quickly, while minimizing the risks.CISOs are in for a challenging 2026Those in organizations who compete globally are in for an especially tough next twelve months as governments move to more tightly regulate and outright control critical communication infrastructure. Forrester also predicts the EU will establish its own known exploited vulnerability database, which translates into immediate demand for regionalized security pros that CISOs will also need to find, recruit, and hire fast if this prediction happens.Forrester also predicts that quantum‑security spending will exceed 5% of overall IT security budgets, a plausible outcome given researchers’ steady progress toward quantum‑resistant cryptography and enterprises’ urgency to pre‑empt the ‘harvest now, decrypt later’ threat.”Of the five major challenges CISOs will face in 2026, none is more lethal and has the potential to completely reorder the threat landscape as agentic AI breaches and the next generation of weaponized AI.How CISOs are tacking agentic AI threats head-on “The adoption of agentic AI introduces entirely new security threats that bypass traditional controls. These risks span data exfiltration, autonomous misuse of APIs, and covert cross-agent collusion, all of which could disrupt enterprise operations or violate regulatory mandates,” Jerry R. Geisler III, Executive Vice President and Chief Information Security Officer at Walmart Inc., told VentureBeat in a recent interview.Geisler continued, articulating Walmart’s direction. “Our strategy is to build robust, proactive security controls using advanced AI Security Posture Management (AI-SPM), ensuring continuous risk monitoring, data protection, regulatory compliance and operational trust.”Implicit in agentic AI are the risks of what happens when agents don’t get along, compete for resources, or worse, lack the basic architecture to ensure minimum viable security (MVS). Forrester defines MVS as an approach to integrate security , writing that “in early-stage concept testing, without slowing down the product team. As the product evolves from early-stage concept testing to an alpha release to a beta release and onward, MVS security activities also evolve, until it is time to leave MVS behind.”Sam Evans, CISO of Clearwater Analytics provided insights into how he addressed the challenge in a recent VentureBeat interview. “I remember when one of the first board meetings I was in, they asked me, \"So what are your thoughts on ChatGPT?\" I said, \"Well, it&#x27;s an incredible productivity tool. However, I don&#x27;t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it, or our source code, which is our intellectual property.\"Evans’ company manages $8.8 trillion in assets. \"The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don&#x27;t manage,\" Evans told VentureBeat. \"The employee not knowing any different or trying to solve a problem for a customer...that data helps train the model.\"Evans elaborated, “But I didn&#x27;t just come to the board with my concerns and problems. I said, &#x27;Well, here&#x27;s my solution. I don&#x27;t want to stop people from being productive, but I also want to protect it.&#x27; When I came to the board and explained how these enterprise browsers work, they&#x27;re like, &#x27;Okay, that makes much sense, but can you really do it?&#x27; Following the board meeting, Evans and his team began an in-depth and comprehensive due diligence process that resulted in Clearwater choosing Island.Boardrooms are handing CISOs a clear, urgent mandate: secure the latest wave of AI and agentic‑AI apps, tools and platforms so organizations can unlock productivity gains immediately without sacrificing security or slowing innovation.The velocity of agent deployments across enterprises has pushed the pressure to deliver value at breakneck speed higher than it’s ever been. As George Kurtz, CEO and founder of CrowdStrike, said in a recent interview: “The speed of today’s cyberattacks requires security teams to rapidly analyze massive amounts of data to detect, investigate, and respond faster. Adversaries are setting records, with breakout times of just over two minutes, leaving no room for delay.”Productivity and security are no longer separate lanes; they’re the same road. Move fast or the competition and the adversaries will move past you is the message boards are delivering to CISOs today.Walmart’s CISO keeps the intensity up on innovation Geisler puts a high priority on keeping a continual pipeline of innovative new ideas flowing at Walmart.“An environment of our size requires a tailor-made approach, and interestingly enough, a startup mindset. Our team often takes a step back and asks, \"If we were a new company and building from ground zero, what would we build?\" Geisler continued, “Identity & access management (IAM) has gone through many iterations over the past 30+ years, and our main focus is on how to modernize our IAM stack to simplify it. While related to yet different from Zero Trust, our principle of least privilege won&#x27;t change.”Walmart has turned innovation into a practical, pragmatic strategy for continually hardening its defenses while reducing risk, all while making major contributions to the growth of the business. Having created a process that can do this at scale in an agentic AI era is one of the many ways cybersecurity delivers business value to the company.VentureBeat continues to see companies, including Clearwater Analytics, Walmart, and many others, putting cyberdefenses in place to counter agentic AI cyberattacks. Of the many interviews we’ve had with CISOs and enterprise security teams, seven battle-tested ways emerge of how enterprises are securing themselves against potential agentic AI attacks.Seven ways CISOs are securing their firms nowFrom in-depth conversations with CISOs and security leaders, seven proven strategies emerge for protecting enterprises against imminent agentic AI threats:1. Visibility is the first line of defense. “The rising use of multi‑agent systems will introduce new attack vectors and vulnerabilities that could be exploited if they aren’t secured properly from the start,” Nicole Carignan, VP Strategic Cyber AI at Darktrace, told VentureBeat earlier this year. An accurate, real‑time inventory that identifies every deployed system, tracks decision and system interdependencies to the agentic level, while also mapping unintended interactions at the agentic level, is now foundational to enterprise resilience.2. Reinforce API security now and develop muscle memory organizationally to keep them secure. Security and risk management professionals from financial services, retail and banking who spoke with VentureBeat on condition of anonymity emphasized the importance of continuously monitoring risk at API layers, stating their strategy is to leverage advanced AI Security Posture Management (AI-SPM) to maintain visibility, enforce regulatory compliance, and operational trust across complex environment. APIs represent the front lines of agentic risk, and strengthening their security transforms them from integration points into strategic enforcement layers.3. Manage autonomous identities as a strategic priority. “Identity is now the control plane for AI security. When an AI agent suddenly accesses systems outside its established pattern, we treat it identically to a compromised employee credential,” said Adam Meyers, Head of Counter‑Adversary Operations at CrowdStrike during a recent interview with VentureBeat. In the era of agentic AI, the traditional IAM playbook is obsolete. Enterprises must deploy IAM frameworks that scale to millions of dynamic identities, enforce least‑privilege continuously, integrate behavioral analytics for machines and humans alike, and revoke access in real time. Only by elevating identity management from an operational cost center to a strategic control plane will organizations tame the velocity, complexity and risk of autonomous systems.4. Upgrade to real-time observability for rapid threat detection. Static logging belongs to another era of cybersecurity. In an agentic environment, observability must evolve into a live, continuously streaming intelligence layer that captures the full scope of system behavior. The enterprises that fuse telemetry, analytics, and automated response into a single, adaptive feedback loop capable of spotting and containing anomalies in seconds rather than hours stand the best chance of thwarting an agentic AI attack.5. Embed proactive oversight to balance innovation with control. No enterprise ever excelled against its growth targets by ignoring the guardrails of the latest technologies they were using to get there. For agentic AI that’s core to the future of getting the most value possible out of this technology. CISOs who lead effectively in this new landscape ensure human-in-the-middle workflows are designed in from the beginning. Oversight at the human level also helps create clear decision points that surface issues early before they spiral. The result? Innovation can run at full throttle, knowing proactive oversight will tap the brakes just enough to keep the enterprise safely on track.6. Make governance adaptive to match AI’s rapid deployment. Static, inflexible governance might as well be yesterday’s newspaper because outdated the moment it&#x27;s printed. In an agentic world moving at machine-speed, compliance policies must adapt continuously, embedded in real-time operational workflows rather than stored on dusty shelves. The CISOs making the most impact understand governance isn&#x27;t just paperwork; it’s code, it’s culture, it’s integrated directly into the heartbeat of the enterprise to keep pace with every new deployment.7. Engineer incident response ahead of machine-speed threats. The worst time to plan your incident response? When your Active Directory and other core systems have been compromised by an agentic AI breach. Forward-thinking CISOs build, test, and refine their response playbooks before agentic threats hit, integrating automated processes that respond at the speed of attacks themselves. Incident readiness isn’t a fire drill; it needs to be muscle memory or an always-on discipline, woven into the enterprise’s operational fabric to make sure when threats inevitably arrive, the team is calm, coordinated, and already one step ahead.Agentic AI is reordering the threat landscape in real-time right nowAs Forrester predicts, the first major agentic breach won’t just claim jobs; it’ll expose every organization that chose inertia over initiative, shining a harsh spotlight on overlooked gaps in governance, API security, identity management, and real-time observability. Meanwhile, quantum threats are driving budget allocations higher, forcing security leaders to act urgently before their defenses become obsolete overnight.The CISOs who win this race are already mapping their systems in real-time, embedding governance into their operational core, and weaving proactive incident responses into the fabric of their daily operations. Enterprises that embrace this proactive stance will turn risk management into a strategic advantage, staying steps ahead of both competitors and adversaries.",
          "content": "AI agents – task-specific models designed to operate autonomously or semi-autonomously given instructions — are being widely implemented across enterprises (up to 79% of all surveyed for a PwC report earlier this year). But they&#x27;re also introducing new security risks. When an agentic AI security breach happens, companies may be quick to fire employees and assign blame, but slower to identify and fix the systemic failures that enabled it.Forrester’s Predictions 2026: Cybersecurity and Risk predicts that the first agentic AI breach will lead to dismissals, adding that geopolitical turmoil and the pressure being put on CISOs and CIOs to deploy agentic AI quickly, while minimizing the risks.CISOs are in for a challenging 2026Those in organizations who compete globally are in for an especially tough next twelve months as governments move to more tightly regulate and outright control critical communication infrastructure. Forrester also predicts the EU will establish its own known exploited vulnerability database, which translates into immediate demand for regionalized security pros that CISOs will also need to find, recruit, and hire fast if this prediction happens.Forrester also predicts that quantum‑security spending will exceed 5% of overall IT security budgets, a plausible outcome given researchers’ steady progress toward quantum‑resistant cryptography and enterprises’ urgency to pre‑empt the ‘harvest now, decrypt later’ threat.”Of the five major challenges CISOs will face in 2026, none is more lethal and has the potential to completely reorder the threat landscape as agentic AI breaches and the next generation of weaponized AI.How CISOs are tacking agentic AI threats head-on “The adoption of agentic AI introduces entirely new security threats that bypass traditional controls. These risks span data exfiltration, autonomous misuse of APIs, and covert cross-agent collusion, all of which could disrupt enterprise operations or violate regulatory mandates,” Jerry R. Geisler III, Executive Vice President and Chief Information Security Officer at Walmart Inc., told VentureBeat in a recent interview.Geisler continued, articulating Walmart’s direction. “Our strategy is to build robust, proactive security controls using advanced AI Security Posture Management (AI-SPM), ensuring continuous risk monitoring, data protection, regulatory compliance and operational trust.”Implicit in agentic AI are the risks of what happens when agents don’t get along, compete for resources, or worse, lack the basic architecture to ensure minimum viable security (MVS). Forrester defines MVS as an approach to integrate security , writing that “in early-stage concept testing, without slowing down the product team. As the product evolves from early-stage concept testing to an alpha release to a beta release and onward, MVS security activities also evolve, until it is time to leave MVS behind.”Sam Evans, CISO of Clearwater Analytics provided insights into how he addressed the challenge in a recent VentureBeat interview. “I remember when one of the first board meetings I was in, they asked me, \"So what are your thoughts on ChatGPT?\" I said, \"Well, it&#x27;s an incredible productivity tool. However, I don&#x27;t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it, or our source code, which is our intellectual property.\"Evans’ company manages $8.8 trillion in assets. \"The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don&#x27;t manage,\" Evans told VentureBeat. \"The employee not knowing any different or trying to solve a problem for a customer...that data helps train the model.\"Evans elaborated, “But I didn&#x27;t just come to the board with my concerns and problems. I said, &#x27;Well, here&#x27;s my solution. I don&#x27;t want to stop people from being productive, but I also want to protect it.&#x27; When I came to the board and explained how these enterprise browsers work, they&#x27;re like, &#x27;Okay, that makes much sense, but can you really do it?&#x27; Following the board meeting, Evans and his team began an in-depth and comprehensive due diligence process that resulted in Clearwater choosing Island.Boardrooms are handing CISOs a clear, urgent mandate: secure the latest wave of AI and agentic‑AI apps, tools and platforms so organizations can unlock productivity gains immediately without sacrificing security or slowing innovation.The velocity of agent deployments across enterprises has pushed the pressure to deliver value at breakneck speed higher than it’s ever been. As George Kurtz, CEO and founder of CrowdStrike, said in a recent interview: “The speed of today’s cyberattacks requires security teams to rapidly analyze massive amounts of data to detect, investigate, and respond faster. Adversaries are setting records, with breakout times of just over two minutes, leaving no room for delay.”Productivity and security are no longer separate lanes; they’re the same road. Move fast or the competition and the adversaries will move past you is the message boards are delivering to CISOs today.Walmart’s CISO keeps the intensity up on innovation Geisler puts a high priority on keeping a continual pipeline of innovative new ideas flowing at Walmart.“An environment of our size requires a tailor-made approach, and interestingly enough, a startup mindset. Our team often takes a step back and asks, \"If we were a new company and building from ground zero, what would we build?\" Geisler continued, “Identity & access management (IAM) has gone through many iterations over the past 30+ years, and our main focus is on how to modernize our IAM stack to simplify it. While related to yet different from Zero Trust, our principle of least privilege won&#x27;t change.”Walmart has turned innovation into a practical, pragmatic strategy for continually hardening its defenses while reducing risk, all while making major contributions to the growth of the business. Having created a process that can do this at scale in an agentic AI era is one of the many ways cybersecurity delivers business value to the company.VentureBeat continues to see companies, including Clearwater Analytics, Walmart, and many others, putting cyberdefenses in place to counter agentic AI cyberattacks. Of the many interviews we’ve had with CISOs and enterprise security teams, seven battle-tested ways emerge of how enterprises are securing themselves against potential agentic AI attacks.Seven ways CISOs are securing their firms nowFrom in-depth conversations with CISOs and security leaders, seven proven strategies emerge for protecting enterprises against imminent agentic AI threats:1. Visibility is the first line of defense. “The rising use of multi‑agent systems will introduce new attack vectors and vulnerabilities that could be exploited if they aren’t secured properly from the start,” Nicole Carignan, VP Strategic Cyber AI at Darktrace, told VentureBeat earlier this year. An accurate, real‑time inventory that identifies every deployed system, tracks decision and system interdependencies to the agentic level, while also mapping unintended interactions at the agentic level, is now foundational to enterprise resilience.2. Reinforce API security now and develop muscle memory organizationally to keep them secure. Security and risk management professionals from financial services, retail and banking who spoke with VentureBeat on condition of anonymity emphasized the importance of continuously monitoring risk at API layers, stating their strategy is to leverage advanced AI Security Posture Management (AI-SPM) to maintain visibility, enforce regulatory compliance, and operational trust across complex environment. APIs represent the front lines of agentic risk, and strengthening their security transforms them from integration points into strategic enforcement layers.3. Manage autonomous identities as a strategic priority. “Identity is now the control plane for AI security. When an AI agent suddenly accesses systems outside its established pattern, we treat it identically to a compromised employee credential,” said Adam Meyers, Head of Counter‑Adversary Operations at CrowdStrike during a recent interview with VentureBeat. In the era of agentic AI, the traditional IAM playbook is obsolete. Enterprises must deploy IAM frameworks that scale to millions of dynamic identities, enforce least‑privilege continuously, integrate behavioral analytics for machines and humans alike, and revoke access in real time. Only by elevating identity management from an operational cost center to a strategic control plane will organizations tame the velocity, complexity and risk of autonomous systems.4. Upgrade to real-time observability for rapid threat detection. Static logging belongs to another era of cybersecurity. In an agentic environment, observability must evolve into a live, continuously streaming intelligence layer that captures the full scope of system behavior. The enterprises that fuse telemetry, analytics, and automated response into a single, adaptive feedback loop capable of spotting and containing anomalies in seconds rather than hours stand the best chance of thwarting an agentic AI attack.5. Embed proactive oversight to balance innovation with control. No enterprise ever excelled against its growth targets by ignoring the guardrails of the latest technologies they were using to get there. For agentic AI that’s core to the future of getting the most value possible out of this technology. CISOs who lead effectively in this new landscape ensure human-in-the-middle workflows are designed in from the beginning. Oversight at the human level also helps create clear decision points that surface issues early before they spiral. The result? Innovation can run at full throttle, knowing proactive oversight will tap the brakes just enough to keep the enterprise safely on track.6. Make governance adaptive to match AI’s rapid deployment. Static, inflexible governance might as well be yesterday’s newspaper because outdated the moment it&#x27;s printed. In an agentic world moving at machine-speed, compliance policies must adapt continuously, embedded in real-time operational workflows rather than stored on dusty shelves. The CISOs making the most impact understand governance isn&#x27;t just paperwork; it’s code, it’s culture, it’s integrated directly into the heartbeat of the enterprise to keep pace with every new deployment.7. Engineer incident response ahead of machine-speed threats. The worst time to plan your incident response? When your Active Directory and other core systems have been compromised by an agentic AI breach. Forward-thinking CISOs build, test, and refine their response playbooks before agentic threats hit, integrating automated processes that respond at the speed of attacks themselves. Incident readiness isn’t a fire drill; it needs to be muscle memory or an always-on discipline, woven into the enterprise’s operational fabric to make sure when threats inevitably arrive, the team is calm, coordinated, and already one step ahead.Agentic AI is reordering the threat landscape in real-time right nowAs Forrester predicts, the first major agentic breach won’t just claim jobs; it’ll expose every organization that chose inertia over initiative, shining a harsh spotlight on overlooked gaps in governance, API security, identity management, and real-time observability. Meanwhile, quantum threats are driving budget allocations higher, forcing security leaders to act urgently before their defenses become obsolete overnight.The CISOs who win this race are already mapping their systems in real-time, embedding governance into their operational core, and weaving proactive incident responses into the fabric of their daily operations. Enterprises that embrace this proactive stance will turn risk management into a strategic advantage, staying steps ahead of both competitors and adversaries.",
          "feed_position": 9,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3M3EB5A9yedEhijwMzlWx/34de6f2a40e9dc37698cfdb59c1b9840/HERO_FOR_THE_FORRESTER_ARTICLE.png"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/5Joxz8qhvStlvnHybvWBpG/5dcda997ed99a05e52cc929b825d01d5/cfr0z3n_realistic_graphic_novel_art_hyperdetailed_overhead_isom_7a652de4-81e1-4145-848c-4a9c6c0969e4.png",
      "popularity_score": 2019.2532188888888,
      "ai_summary": [
        "Qwen's Deep Research tool now generates interactive webpages and multi-speaker podcasts.",
        "The update uses Qwen3-Coder, Qwen-Image, and Qwen3-TTS open-source models.",
        "The end-to-end experience is hosted and operated by Qwen, offering a managed workflow.",
        "Users can request research within Qwen Chat, shaping the scope with clarifying questions.",
        "A demo video shows the process using the U.S. SaaS market as an example."
      ]
    },
    {
      "id": "cluster_37",
      "coverage": 2,
      "updated_at": "Tue, 21 Oct 2025 13:25:01 -0400",
      "title": "ChatGPT Atlas will feature an agent mode to let ChatGPT take actions; clicking a search link will show a split-screen with the webpage and a ChatGPT transcript (Hayden Field/The Verge)",
      "neutral_headline": "OpenAI Launches AI-Powered Web Browser, ChatGPT Atlas",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251021/p33#a251021p33",
          "published_at": "Tue, 21 Oct 2025 13:25:01 -0400",
          "title": "ChatGPT Atlas will feature an agent mode to let ChatGPT take actions; clicking a search link will show a split-screen with the webpage and a ChatGPT transcript (Hayden Field/The Verge)",
          "standfirst": "Hayden Field / The Verge: ChatGPT Atlas will feature an agent mode to let ChatGPT take actions; clicking a search link will show a split-screen with the webpage and a ChatGPT transcript &mdash; ChatGPT is the &ldquo;beating heart of Atlas,&rdquo; according to employees on the livestream. &hellip; OpenAI's next move in its battle against Google is an AI-powered web browser.",
          "content": "Hayden Field / The Verge: ChatGPT Atlas will feature an agent mode to let ChatGPT take actions; clicking a search link will show a split-screen with the webpage and a ChatGPT transcript &mdash; ChatGPT is the &ldquo;beating heart of Atlas,&rdquo; according to employees on the livestream. &hellip; OpenAI's next move in its battle against Google is an AI-powered web browser.",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/251021/i33.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/ai-artificial-intelligence/803475/openais-ai-powered-browser-chatgpt-atlas-google-chrome-competition-agent",
          "published_at": "2025-10-21T13:06:50-04:00",
          "title": "OpenAI’s AI-powered browser, ChatGPT Atlas, is here",
          "standfirst": "OpenAI’s next move in its battle against Google is an AI-powered web browser. The tool, dubbed ChatGPT Atlas, is out today. The company announced it in a livestream after teasing it earlier Tuesday via a mysterious video of browser tabs on a white screen. ChatGPT Atlas is available “globally” on macOS starting today, while access [&#8230;]",
          "content": "OpenAI’s next move in its battle against Google is an AI-powered web browser. The tool, dubbed ChatGPT Atlas, is out today. The company announced it in a livestream after teasing it earlier Tuesday via a mysterious video of browser tabs on a white screen. ChatGPT Atlas is available “globally” on macOS starting today, while access for Windows, iOS, and Android is “coming soon,” per the company. But its “agent mode” is only available to ChatGPT Plus and Pro users for now, OpenAI CEO Sam Altman said on the livestream. “The way that we hope people will use the internet in the future… the chat experience in a web browser can be a great analog,” Altman said. Besides Altman, the livestream featured OpenAI employees Will Ellsworth, who works on post-training research; Adam Fry, the product lead for ChatGPT Search; Ben Goodger, a staff member who in previous roles helped develop Google Chrome and Mozilla Firefox; Ryan O’Rouke, an interface designer; Justin Rushing, who previously worked at Apple; and Pranav Vishnu. Fry said one of the browser’s best features is memory — making the browser “more personalized and more helpful to you,” as well as an agent mode, meaning that “in Atlas, ChatGPT can now take actions for you… It can help you book reservations or flights or even just edit a document that you’re working on.” Users can see and manage the browser’s “memories” in settings, employees said, as well as open incognito windows. The browser’s agent mode clearly builds on OpenAI’s past forays into agentic AI, such as its Operator tool, an early version of a tool allowing ChatGPT to use a computer on a user’s behalf, and ChatGPT Agent, the next iteration, which was designed to be able to complete more complex tasks, shop, and more (though it wasn’t always successful in that realm). Whenever you click a link from a search result in Atlas, it’ll by default show a split-screen with the webpage and the ChatGPT transcript, with the goal being to display a “companion” at all times, employees said, though a user can turn off the split-screen if they’d rather. On the livestream, employees also demonstrated the browser’s summarization features for webpages, as well as selecting text from an email and clicking a button to have ChatGPT tidy up the sentence in-line — the latter feature is called “cursor chat.” “This is just a great browser all-around — it’s smooth, it’s quick, it’s really nice to use,” Altman said. The AI browser wars have been heating up for a while — OpenAI announced a prototype of its search engine, dubbed SearchGPT, all the way back in July 2024. But in recent months, AI-fueled browsers have felt like the latest frontier in AI hype. This summer, Perplexity launched its buzzy Comet browser, an AI-powered solution aiming to simplify the way people browse the web and complete tasks. Instead of a laundry list of Google Search results, you get a Perplexity “answer engine,” which offers a few links to relevant websites and generates an answer to your query. It can also scan all your open tabs, summarize videos, declutter your email inbox, and even make purchases on Amazon. In September, Google announced that it would more deeply embed its Gemini AI assistant into Chrome, and that in the coming months, it plans to allow Gemini in Chrome to be able to do “tedious tasks” on your behalf, such as grocery shop, schedule appointments, book reservations, and more — although Google declined to specify a launch date.",
          "feed_position": 3
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/803481/openai-web-browser-ai-announcement-teaser",
          "published_at": "2025-10-21T11:25:02-04:00",
          "title": "OpenAI is about to launch its new AI web browser, ChatGPT Atlas",
          "standfirst": "OpenAI has started teasing a livestream today for its rumored web browser. A mysterious teaser with a set of browser tabs appeared on OpenAI’s X account today, signaling that a livestream will reveal all at 1PM ET / 10AM PT today. OpenAI CEO Sam Altman says the announcement is about “a new product I&#8217;m quite [&#8230;]",
          "content": "OpenAI has started teasing a livestream today for its rumored web browser. A mysterious teaser with a set of browser tabs appeared on OpenAI’s X account today, signaling that a livestream will reveal all at 1PM ET / 10AM PT today. OpenAI CEO Sam Altman says the announcement is about “a new product I&#8217;m quite excited about!” The livestream link itself reveals that the browser is called ChatGPT Atlas and will be available globally on macOS today, with Windows, iOS, and Android versions coming soon. Reuters reported in July that OpenAI was preparing to launch an AI web browser, with the company’s Operator AI agent built into the browser. Such a feature would allow Operator to book restaurant reservations, automatically fill out forms, and complete other browser actions. pic.twitter.com/kbcsk1khlO&mdash; OpenAI (@OpenAI) October 21, 2025 OpenAI’s web browser is also expected to include a ChatGPT interface to allow people to interact directly with the chatbot through the browser instead of having to open the ChatGPT website. The browser is also likely to run on Chromium, the same engine that powers Chrome, Microsoft Edge, and Opera. The AI browser wars are starting to heat up. Google has Gemini in Chrome, Perplexity has its Comet AI browser, The Browser Company got acquired by Atlassian for $610 million earlier this year, and Microsoft has been building an AI-powered Copilot Mode into its Edge browser. All of these browsers look like they’ll now have to compete with a dedicated product from OpenAI. Microsoft, OpenAI’s strategic AI partner, has already ruled out creating its own dedicated AI browser. Microsoft AI CEO Mustafa Suleyman told me last month that Microsoft’s path to an AI browser involves evolving its Edge browser to “become a true agentic browser,” instead of an overhauled AI web browser like The Browser Company has tried to do with Dia. Update, October 21st: Article updated with the browser name and details.",
          "feed_position": 7
        }
      ],
      "featured_image": "http://www.techmeme.com/251021/i33.jpg",
      "popularity_score": 2018.13683,
      "ai_summary": [
        "ChatGPT Atlas, an AI-powered web browser, is now available on macOS.",
        "The browser features an agent mode allowing ChatGPT to take actions.",
        "Clicking a search link in Atlas shows a split-screen with the webpage and transcript.",
        "OpenAI announced the browser during a livestream after a teaser video.",
        "The company is competing with Google in the AI-powered web browser space."
      ]
    },
    {
      "id": "cluster_39",
      "coverage": 2,
      "updated_at": "Tue, 21 Oct 2025 13:15:01 -0400",
      "title": "Apple MacBook Pro 14 (M5) review: feels the same as M4 with a speed upgrade and still good value for money with great battery life, but only a modest update (Antonio G. Di Benedetto/The Verge)",
      "neutral_headline": "Apple MacBook Pro 14 (M5) Review: Modest Update",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251021/p32#a251021p32",
          "published_at": "Tue, 21 Oct 2025 13:15:01 -0400",
          "title": "Apple MacBook Pro 14 (M5) review: feels the same as M4 with a speed upgrade and still good value for money with great battery life, but only a modest update (Antonio G. Di Benedetto/The Verge)",
          "standfirst": "Antonio G. Di Benedetto / The Verge: Apple MacBook Pro 14 (M5) review: feels the same as M4 with a speed upgrade and still good value for money with great battery life, but only a modest update &mdash; Last year's entry-level MacBook Pro was an impressive return to form for Apple's Pro laptop. Between the M4 chip, increased RAM &hellip;",
          "content": "Antonio G. Di Benedetto / The Verge: Apple MacBook Pro 14 (M5) review: feels the same as M4 with a speed upgrade and still good value for money with great battery life, but only a modest update &mdash; Last year's entry-level MacBook Pro was an impressive return to form for Apple's Pro laptop. Between the M4 chip, increased RAM &hellip;",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/251021/i32.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/803349/apple-macbook-pro-14-m5-2025-review",
          "published_at": "2025-10-21T13:00:00-04:00",
          "title": "Apple MacBook Pro M5 review: new chip, same greatness",
          "standfirst": "Last year's entry-level MacBook Pro was an impressive return to form for Apple's Pro laptop. Between the M4 chip, increased RAM, improved webcam, and a third Thunderbolt 4 port, the most affordable MacBook Pro was also one of the best deals in Apple's lineup. The M5 sequel is mostly a copy-paste of the same machine [&#8230;]",
          "content": "I promise I photographed the M5 model. But the M4 could stand in as a stunt double just fine. Last year's entry-level MacBook Pro was an impressive return to form for Apple's Pro laptop. Between the M4 chip, increased RAM, improved webcam, and a third Thunderbolt 4 port, the most affordable MacBook Pro was also one of the best deals in Apple's lineup. The M5 sequel is mostly a copy-paste of the same machine - an annual Madden NFL release in laptop form. But instead of a glorified roster update, you get a slightly faster chip and much faster storage, potentially speeding things up when working on big project files and cutting down on time looking at progress bars. That's mostly it. The screen, design, ports, speakers, webcam, and ju … Read the full story at The Verge.",
          "feed_position": 4
        }
      ],
      "featured_image": "http://www.techmeme.com/251021/i32.jpg",
      "popularity_score": 2017.9701633333334,
      "ai_summary": [
        "The M5 MacBook Pro 14 offers a speed upgrade compared to the M4 model.",
        "It maintains good value and battery life, according to the review.",
        "The M5 is largely similar to the previous generation MacBook Pro.",
        "The M4 chip, RAM, webcam, and Thunderbolt 4 port were already impressive.",
        "The review suggests the M5 is a copy-paste of the same machine."
      ]
    },
    {
      "id": "cluster_53",
      "coverage": 2,
      "updated_at": "Tue, 21 Oct 2025 12:25:01 -0400",
      "title": "Samsung rolls out a Perplexity TV app, which works alongside Samsung's Vision AI Companion, on its 2025 TVs; 2023 and 2024 TV models will get it later this year (Artie Beaty/ZDNET)",
      "neutral_headline": "Samsung TV App Integrates Perplexity AI",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251021/p30#a251021p30",
          "published_at": "Tue, 21 Oct 2025 12:25:01 -0400",
          "title": "Samsung rolls out a Perplexity TV app, which works alongside Samsung's Vision AI Companion, on its 2025 TVs; 2023 and 2024 TV models will get it later this year (Artie Beaty/ZDNET)",
          "standfirst": "Artie Beaty / ZDNET: Samsung rolls out a Perplexity TV app, which works alongside Samsung's Vision AI Companion, on its 2025 TVs; 2023 and 2024 TV models will get it later this year &mdash; ZDNET's key takeaways &mdash; Samsung is introducing a new Perplexity TV app. &mdash; 2025 models get the app now, 2024 and 2023 models later this year.",
          "content": "Artie Beaty / ZDNET: Samsung rolls out a Perplexity TV app, which works alongside Samsung's Vision AI Companion, on its 2025 TVs; 2023 and 2024 TV models will get it later this year &mdash; ZDNET's key takeaways &mdash; Samsung is introducing a new Perplexity TV app. &mdash; 2025 models get the app now, 2024 and 2023 models later this year.",
          "feed_position": 10,
          "image_url": "http://www.techmeme.com/251021/i30.jpg"
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/how-to-get-perplexity-ai-pro-for-free-on-your-samsung-tv-and-what-it-can-do/",
          "published_at": "Tue, 21 Oct 2025 14:30:33 GMT",
          "title": "How to get Perplexity AI Pro for free on your Samsung TV - and what it can do",
          "standfirst": "The new Perplexity TV app is rolling out to Samsung's 2025 TVs first, with older models getting it later this year.",
          "content": "The new Perplexity TV app is rolling out to Samsung's 2025 TVs first, with older models getting it later this year.",
          "feed_position": 18
        }
      ],
      "featured_image": "http://www.techmeme.com/251021/i30.jpg",
      "popularity_score": 2017.13683,
      "ai_summary": [
        "Samsung is rolling out a Perplexity TV app for its 2025 TV models.",
        "The app works alongside Samsung's Vision AI Companion.",
        "2023 and 2024 TV models will receive the app later this year.",
        "The app allows users to access Perplexity AI features on their TVs.",
        "ZDNet highlights key takeaways about the new app's functionality."
      ]
    },
    {
      "id": "cluster_57",
      "coverage": 2,
      "updated_at": "Tue, 21 Oct 2025 12:15:01 -0400",
      "title": "YouTube launches its likeness detection tech, letting eligible creators in its Partner Program request the removal of AI-generated content with their likeness (Lauren Forristal/TechCrunch)",
      "neutral_headline": "YouTube Launches Likeness Detection Technology",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251021/p29#a251021p29",
          "published_at": "Tue, 21 Oct 2025 12:15:01 -0400",
          "title": "YouTube launches its likeness detection tech, letting eligible creators in its Partner Program request the removal of AI-generated content with their likeness (Lauren Forristal/TechCrunch)",
          "standfirst": "Lauren Forristal / TechCrunch: YouTube launches its likeness detection tech, letting eligible creators in its Partner Program request the removal of AI-generated content with their likeness &mdash; YouTube revealed on Tuesday that its likeness-detection technology has officially rolled out to eligible creators in the YouTube Partner Program, following a pilot phase.",
          "content": "Lauren Forristal / TechCrunch: YouTube launches its likeness detection tech, letting eligible creators in its Partner Program request the removal of AI-generated content with their likeness &mdash; YouTube revealed on Tuesday that its likeness-detection technology has officially rolled out to eligible creators in the YouTube Partner Program, following a pilot phase.",
          "feed_position": 11,
          "image_url": "http://www.techmeme.com/251021/i29.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/10/21/youtubes-likeness-detection-technology-has-officially-launched/",
          "published_at": "Tue, 21 Oct 2025 15:57:18 +0000",
          "title": "YouTube’s likeness-detection technology has officially launched",
          "standfirst": "YouTube’s detection technology identifies and manages AI-generated content featuring the likeness of creators, such as their face and voice.",
          "content": "YouTube’s detection technology identifies and manages AI-generated content featuring the likeness of creators, such as their face and voice.",
          "feed_position": 6
        }
      ],
      "featured_image": "http://www.techmeme.com/251021/i29.jpg",
      "popularity_score": 2016.9701633333334,
      "ai_summary": [
        "YouTube's likeness detection tech is available to eligible Partner Program creators.",
        "The technology helps manage AI-generated content featuring creator likenesses.",
        "The launch follows a pilot phase of the likeness detection technology.",
        "Creators can request removal of AI content using their likeness.",
        "The technology identifies and manages AI-generated content."
      ]
    },
    {
      "id": "cluster_5",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 19:02:10 +0000",
      "title": "OpenAI’s new Atlas web browser wants to let you “chat with a page”",
      "neutral_headline": "OpenAI’s new Atlas web browser wants to let you “chat with a page”",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/ai/2025/10/openais-new-atlas-web-browser-wants-to-let-you-chat-with-a-page/",
          "published_at": "Tue, 21 Oct 2025 19:02:10 +0000",
          "title": "OpenAI’s new Atlas web browser wants to let you “chat with a page”",
          "standfirst": "MacOS version launches today, includes Agent Mode preview to \"use the Internet for you.\"",
          "content": "Back in 2008, Google launched the Chrome browser to help better integrate its industry-leading search engine into the web-browsing experience. Today, OpenAI announced the Atlas browser that it hopes will do something similar for its ChatGPT Large Language Model, answering the question “What if I could chat with a browser?” as the OpenAI team put it. OpenAI Founder and CEO Sam Altman said in a livestreamed announcement that Atlas will let users “chat with a page,” helping ChatGPT become a core way that users interact with the place where “a ton of work and life happens” online. “The way that we hope people will use the Internet in the future… is that the chat experience and a web browser can be a great analogue,” he said. The new browser is available for download now on MacOS, and Altman promised Windows and mobile versions would be rolled out “as quick as we can.”Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/atlaslogo.jpg",
      "popularity_score": 367.75599666666665,
      "ai_summary": [
        "OpenAI's Atlas web browser is launching on macOS today.",
        "The browser includes an Agent Mode preview.",
        "Agent Mode is designed to \"use the Internet for you\"."
      ]
    },
    {
      "id": "cluster_13",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:46:42 +0000",
      "title": "YouTube’s likeness detection has arrived to help stop AI doppelgängers",
      "neutral_headline": "YouTube’s likeness detection has arrived to help stop AI doppelgängers",
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/google/2025/10/youtube-rolls-out-likeness-detection-to-help-creators-combat-ai-fakes/",
          "published_at": "Tue, 21 Oct 2025 18:46:42 +0000",
          "title": "YouTube’s likeness detection has arrived to help stop AI doppelgängers",
          "standfirst": "Likeness detection will flag possible AI fakes, but Google doesn't guarantee removal.",
          "content": "AI content has proliferated across the Internet over the past few years, but those early confabulations with mutated hands have evolved into synthetic images and videos that can be hard to differentiate from reality. Having helped to create this problem, Google has some responsibility to keep AI video in check on YouTube. To that end, the company has started rolling out its promised likeness detection system for creators. Google’s powerful and freely available AI models have helped fuel the rise of AI content, some of which is aimed at spreading misinformation and harassing individuals. Creators and influencers fear their brands could be tainted by a flood of AI videos that show them saying and doing things that never happened—even lawmakers are fretting about this. Google has placed a large bet on the value of AI content, so banning AI from YouTube, as many want, simply isn’t happening. Earlier this year, YouTube promised tools that would flag face-stealing AI content on the platform. The likeness detection tool, which is similar to the site’s copyright detection system, has now expanded beyond the initial small group of testers. YouTube says the first batch of eligible creators have been notified that they can use likeness detection, but interested parties will need to hand Google even more personal information to get protection from AI fakes.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/06/youtube-1152x648.jpg",
      "popularity_score": 357.4982188888889
    },
    {
      "id": "cluster_21",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:30:11 +0000",
      "title": "Satellite operators will soon join airlines in using Starlink in-flight Wi-Fi",
      "neutral_headline": "Satellite operators will soon join airlines in using Starlink in-flight Wi-Fi",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/satellite-operators-will-soon-join-airlines-in-using-starlink-in-flight-wi-fi/",
          "published_at": "Tue, 21 Oct 2025 18:30:11 +0000",
          "title": "Satellite operators will soon join airlines in using Starlink in-flight Wi-Fi",
          "standfirst": "\"This starts to enable a whole new category of capabilities.\"",
          "content": "A little over a year ago, one of SpaceX’s Crew Dragon spacecraft flew a team of four private astronauts to orbit on a mission that made history with the first fully commercial spacewalk. Jared Isaacman and Sarah Gillis briefly floated out the door of the Dragon capsule, wearing SpaceX-built pressure suits to protect them against the hostile environment of space. It was the first time anyone ventured outside of their spacecraft without the involvement of a government space agency. The mission, named Polaris Dawn, made an important contribution in another area. It was the first space mission to connect with SpaceX’s Starlink broadband network, using laser links between the Dragon spacecraft and Starlink satellites to communicate with the Earth.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink_laser-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlink_laser-1152x648.jpg",
      "popularity_score": 357.22294111111114
    },
    {
      "id": "cluster_29",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:02:36 +0000",
      "title": "Cards Against Humanity lawsuit forced SpaceX to vacate land on US/Mexico border",
      "neutral_headline": "Cards Against Humanity lawsuit forced SpaceX to vacate land on US/Mexico border",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/cards-against-humanity-gets-settlement-from-spacex-plans-pack-of-elon-musk-cards/",
          "published_at": "Tue, 21 Oct 2025 18:02:36 +0000",
          "title": "Cards Against Humanity lawsuit forced SpaceX to vacate land on US/Mexico border",
          "standfirst": "CAH: Trespassing lawsuit forced SpaceX to \"pack up the space garbage\" and leave.",
          "content": "A year after suing SpaceX for “invading” a plot of land on the US/Mexico border, Cards Against Humanity says it has obtained a settlement and will provide supporters with a new pack of cards about Elon Musk. The party-game company bought the land in 2017 in an attempt to stymie President Trump’s wall-building project, but alleged that SpaceX illegally took over the land and filled it with construction equipment and materials. A September 2024 lawsuit filed against SpaceX in Cameron County District Court in Texas sought up to $15 million to cover the cost of restoring the property and other damages. Cards Against Humanity, which bought the property with donations from supporters, told Ars today that “we’ve been in negotiations with SpaceX for much of the last year. We held out for the best settlement we could get—almost until the trial was supposed to start—and unfortunately part of that negotiation was that we’re not allowed to discuss specific settlement terms. They did admit to trespassing during the discovery phase, which was very validating.”Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/cards-against-elon-musk-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/cards-against-elon-musk-1152x648.jpg",
      "popularity_score": 344.7632188888889
    },
    {
      "id": "cluster_25",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 18:12:07 +0000",
      "title": "“Butt breathing” might soon be a real medical treatment",
      "neutral_headline": "“Butt breathing” might soon be a real medical treatment",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/butt-breathing-might-soon-be-a-real-medical-treatment/",
          "published_at": "Tue, 21 Oct 2025 18:12:07 +0000",
          "title": "“Butt breathing” might soon be a real medical treatment",
          "standfirst": "Ig Nobel-winning research could one day be used to treat people with blocked airways or clogged lungs.",
          "content": "Last year, a group of researchers won the 2024 Ig Nobel Prize in Physiology for discovering that many mammals are capable of breathing through their anus. But as with many Ig Nobel awards, there is a serious side to the seeming silliness. The same group has conducted a new study on the feasibility of adapting this method to treat people with blocked airways or clogged lungs, with promising results that bring rectal oxygen delivery one step closer to medical reality. As previously reported, this is perhaps one of the more unusual research developments to come out of the COVID-19 pandemic and its associated shortages of ventilators and artificial lungs to assist patients’ breathing and prevent respiratory failure. The Cincinnati Children’s Hospital Medical Center team took their inspiration from the humble loach, a freshwater bottom-dwelling fish found throughout Eurasia and northern Africa. The loach (along with sea cucumbers) employs intestinal breathing (i.e., through the anus) rather than gills to survive under hypoxic conditions, thanks to having lots of capillary vessels in its intestine. The technical term is enteral ventilation via anus (EVA). Would such a novel breathing method work in mammals? The team thought it might be possible and undertook experiments with mice and micro-pigs to test that hypothesis. They drew upon earlier research by Leland Clark, also of Cincinnati Children’s Hospital, who invented a perfluorocarbon liquid called Oxycyte as a possible form of artificial blood. That vision never materialized, although it did provide a handy plot point for the 1989 film The Abyss, in which a rat is able to “breathe” in a similar liquid.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/ignobel3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/ignobel3-1152x648.jpg",
      "popularity_score": 331.92183,
      "ai_summary": [
        "Research could be used to treat people with blocked airways.",
        "Research could be used to treat people with clogged lungs.",
        "The research won an Ig Nobel prize."
      ]
    },
    {
      "id": "cluster_34",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 17:52:42 +0000",
      "title": "M5 iPad Pro tested: Stop me if you’ve heard this one before",
      "neutral_headline": "M5 iPad Pro tested: Stop me if you’ve heard this one before",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/testing-apples-m5-ipad-pro-future-proofing-for-apples-perennial-overkill-tablet/",
          "published_at": "Tue, 21 Oct 2025 17:52:42 +0000",
          "title": "M5 iPad Pro tested: Stop me if you’ve heard this one before",
          "standfirst": "It's a gorgeous tablet, but what does an iPad need with more processing power?",
          "content": "This year’s iPad Pro is what you might call a “chip refresh” or an “internal refresh.” These refreshes are what Apple generally does for its products for one or two or more years after making a larger external design change. Leaving the physical design alone preserves compatibility with the accessory ecosystem. For the Mac, chip refreshes are still pretty exciting to me, because many people who use a Mac will, very occasionally, assign it some kind of task where they need it to work as hard and fast as it can, for an extended period of time. You could be a developer compiling a large and complex app, or you could be a podcaster or streamer editing or exporting an audio or video file, or maybe you’re just playing a game. The power and flexibility of the operating system, and first- and third-party apps made to take advantage of that power and flexibility, mean that “more speed” is still exciting, even if it takes a few years for that speed to add up to something users will consistently notice and appreciate. And then there’s the iPad Pro. Especially since Apple shifted to using the same M-series chips that it uses in Macs, most iPad Pro reviews contain some version of “this is great hardware that is much faster than it needs to be for anything the iPad does.” To wit, our review of the M4 iPad Pro from May 2024:Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6198-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6198-1152x648.jpeg",
      "popularity_score": 316.5982188888889
    },
    {
      "id": "cluster_43",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 17:00:45 +0000",
      "title": "MacBook Pro review: Apple’s most awkward laptop is the first to show off Apple M5",
      "neutral_headline": "MacBook Pro review: Apple’s most awkward laptop is the first to show off Apple M5",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/m5-macbook-pro-review-fifth-generation-apple-silicon-in-a-familiar-wrapper/",
          "published_at": "Tue, 21 Oct 2025 17:00:45 +0000",
          "title": "MacBook Pro review: Apple’s most awkward laptop is the first to show off Apple M5",
          "standfirst": "Apple M5 trades blows with Pro and Max chips from older generations.",
          "content": "When I’m asked to recommend a Mac laptop for people, Apple’s low-end 14-inch MacBook Pro usually gets lost in the shuffle. It competes with the 13- and 15-inch MacBook Air, significantly cheaper computers that meet or exceed the “good enough” boundary for the vast majority of computer users. The basic MacBook Pro also doesn’t have the benefit of Apple’s Pro or Max-series chips, which come with many more CPU cores, substantially better graphics performance, and higher memory capacity for true professionals and power users. But the low-end Pro makes sense for a certain type of power user. At $1,599, it’s the cheapest way to get Apple’s best laptop screen, with mini LED technology, a higher 120 Hz ProMotion refresh rate for smoother scrolling and animations, and the optional but lovely nano-texture (read: matte) finish. Unlike the MacBook Air, it comes with a cooling fan, which has historically meant meaningfully better sustained performance and less performance throttling. And it’s also Apple’s cheapest laptop with three Thunderbolt ports, an HDMI port, and an SD card slot, all genuinely useful for people who want to plug lots of things in without having multiple dongles or a bulky dock competing for the Air’s two available ports. If you don’t find any of those arguments in the basic MacBook Pro’s favor convincing, that’s fine. The new M5 version makes almost no changes to the laptop other than the chip, so it’s unlikely to change your calculus if you already looked at the M3 or M4 version and passed it up. But it is the first Mac to ship with the M5, the first chip in Apple’s fifth-generation chip family and a preview of what’s to come for (almost?) every other Mac in the lineup. So you can at least be interested in the 14-inch MacBook Pro as a showcase for a new processor, if not as a retail product in and of itself.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6215-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/IMG_6215-1152x648.jpeg",
      "popularity_score": 313.73238555555554
    },
    {
      "id": "cluster_45",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 17:00:13 +0000",
      "title": "Google Fi is getting enhanced web calls and messaging, AI bill summaries",
      "neutral_headline": "Google Fi is getting enhanced web calls and messaging, AI bill summaries",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/google-fi-is-getting-enhanced-web-calls-and-messaging-ai-bill-summaries/",
          "published_at": "Tue, 21 Oct 2025 17:00:13 +0000",
          "title": "Google Fi is getting enhanced web calls and messaging, AI bill summaries",
          "standfirst": "Google's MVNO gets better web support, clearer audio, and yes, more AI.",
          "content": "Google’s Fi cellular service is getting an upgrade, and since this is 2025, there’s plenty of AI involved. You’ll be able to ask Google AI questions about your bill, and a different variation of AI will improve call quality. AI haters need not despair—there are also some upgrades to connectivity and Fi web features. As part of this update, a new Gemini-powered chatbot will soon be turned loose on your billing statements. The idea is that you can get bill summaries and ask specific questions of the robot without waiting for a real person. Google claims that testers have had positive experiences with the AI billing bot, so it’s rolling the feature out widely. Next month, Google also plans to flip the switch on an AI audio enhancement. The new “optimized audio” will use AI to filter out background sounds like wind or crowd noise. If you’re using a Pixel, you already have a similar feature for your end of the call. However, this update will reduce background noise on the other end as well. Google’s MVNO has also added support for HD and HD+ calling on supported connections.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2019/09/Google-Fi-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2019/09/Google-Fi-1152x648.png",
      "popularity_score": 307.7234966666667,
      "ai_summary": [
        "Google Fi is getting better web support.",
        "Google Fi is getting clearer audio.",
        "Google Fi is getting AI bill summaries."
      ]
    },
    {
      "id": "cluster_38",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 17:20:10 +0000",
      "title": "HBO Max prices increase by up to $20 today",
      "neutral_headline": "HBO Max prices increase by up to $20 today",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/warner-bros-discovery-raises-hbo-max-prices-as-it-puts-itself-up-for-sale/",
          "published_at": "Tue, 21 Oct 2025 17:20:10 +0000",
          "title": "HBO Max prices increase by up to $20 today",
          "standfirst": "HBO Max subscription fees have risen every year for the past three years.",
          "content": "HBO Max subscriptions are getting up to 10 percent more expensive, owner Warner Bros. Discovery (WBD) revealed today. HBO Max’s ad plan is going from $10 per month to $11/month. The ad-free plan is going from $17/month to $18.49/month. And the premium ad-free plan (which adds 4K support, Dolby Atmos, and the ability to download more content) is increasing from $21 to $23. Meanwhile, prices for HBO Max’s annual plans are increasing from $100 to $110 with ads, $170 to $185 without ads, and $210 to $230 for the premium tier.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/02/peacemakerTOP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/02/peacemakerTOP-1152x648.jpg",
      "popularity_score": 298.05599666666666
    },
    {
      "id": "cluster_54",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 16:21:12 +0000",
      "title": "Amazon’s DNS problem knocked out half the web, likely costing billions",
      "neutral_headline": "Amazon’s DNS problem knocked out half the web, likely costing billions",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/amazons-dns-problem-knocked-out-half-the-web-likely-costing-billions/",
          "published_at": "Tue, 21 Oct 2025 16:21:12 +0000",
          "title": "Amazon’s DNS problem knocked out half the web, likely costing billions",
          "standfirst": "Amazon’s outage is over. But backlash over billions in losses has just started.",
          "content": "On Monday afternoon, Amazon confirmed that an outage affecting Amazon Web Services’ cloud hosting, which had impacted millions across the Internet, had been resolved. Considered the worst outage since last year’s CrowdStrike chaos, Amazon’s outage caused “global turmoil,” Reuters reported. AWS is the world’s largest cloud provider and, therefore, the “backbone of much of the Internet,” ZDNet noted. Ultimately, more than 28 AWS services were disrupted, causing perhaps billions in damages, one analyst estimated for CNN. Popular apps like Snapchat, Signal, and Reddit went dark. Flights got delayed. Banks and financial services went down. Massive games like Fortnite could not be accessed. Some of Amazon’s own services were hit, too, including its e-commerce platform, Alexa, and Prime Video. Ultimately, millions of businesses simply stopped operating, unable to log employees into their systems or accept payments for their goods.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2241879469-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2241879469-1024x648.jpg",
      "popularity_score": 270.0732188888889
    },
    {
      "id": "cluster_79",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 14:43:20 +0000",
      "title": "Even with protections, wolves still fear humans",
      "neutral_headline": "European Wolves Flee Humans Faster Than Dogs' Barking",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/even-with-protections-wolves-still-fear-humans/",
          "published_at": "Tue, 21 Oct 2025 14:43:20 +0000",
          "title": "Even with protections, wolves still fear humans",
          "standfirst": "European wolves flee human conversation faster than dogs' barking.",
          "content": "In May 2025, the European Parliament changed the status of wolves in the EU from “strictly protected” to “protected,” which opened the way for its member states to allow hunting under certain conditions, such as protecting livestock. One of the arguments behind this change was that the “tolerance of modern society towards wolves” led to the emergence of “fearless wolves” that are no longer afraid of people. “Regulators made it clear, though, that there is no scientific evidence to back this up,” says Michael Clinchy, a zoologist at Western University in London, Canada. “So we did the first-of-its-kind study to find out if wolves have really lost their fear of humans. We proved there is no such thing as a fearless wolf.” Red riding hood The big bad wolf trope is found in plenty of our myths and fables, with Little Red Riding Hood being probably the most famous example. This mythical fear of wolves, combined with real damage to livestock, led to extensive hunting. By the mid-20th century, we’d pushed wolves to the verge of extinction in Western and Central Europe. Human-wolf encounters became very rare, and the big bad wolf myth faded away. But starting in the 1970s, wolves became a protected species across Europe and North America, which caused wolf populations to bounce back and reoccupy some of their old habitats.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2206876894-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2206876894-1024x648.jpg",
      "popularity_score": 261.4421077777778,
      "ai_summary": [
        "Wolves in Europe exhibit a stronger fear response to human conversation than to dog barking.",
        "Researchers observed wolves fleeing human speech more quickly than they fled dog barks.",
        "This behavior suggests wolves perceive humans as a greater threat than domestic dogs.",
        "The study highlights the impact of human presence on wolf behavior and survival.",
        "The findings were published in a recent scientific study on wolf behavior."
      ]
    },
    {
      "id": "cluster_108",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 02:54:29 +0000",
      "title": "It wasn’t space debris that struck a United Airlines plane—it was a weather balloon",
      "neutral_headline": "Weather Balloon Caused United Airlines Plane Damage",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/the-mystery-object-that-struck-a-plane-in-flight-it-was-probably-a-weather-balloon/",
          "published_at": "Tue, 21 Oct 2025 02:54:29 +0000",
          "title": "It wasn’t space debris that struck a United Airlines plane—it was a weather balloon",
          "standfirst": "WindBorne says its balloons are compliant with all applicable airspace regulations.",
          "content": "The mysterious impact of a United Airlines aircraft in flight last week has sparked plenty of theories as to its cause, from space debris to high-flying birds. However the question of what happened to flight 1093, and its severely damaged front window, appears to be answered in the form of a weather balloon. “I think this was a WindBorne balloon,” Kai Marshland, co-founder of the weather prediction company WindBorne Systems, told Ars in an email on Monday evening. “We learned about UA1093 and the potential that it was related to one of our balloons at 11 pm PT on Sunday and immediately looked into it. At 6 am PT, we sent our preliminary investigation to both NTSB and FAA, and are working with both of them to investigate further.”Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/68a6ba53499bdd827f510e35_54fca9353dfe2c2a33bb46167c61cd64_payload-block3-957x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/68a6ba53499bdd827f510e35_54fca9353dfe2c2a33bb46167c61cd64_payload-block3-957x648.png",
      "popularity_score": 154.6279411111111,
      "ai_summary": [
        "A weather balloon, not space debris, struck a United Airlines plane.",
        "WindBorne, the balloon's operator, confirmed its compliance with airspace regulations.",
        "The incident highlights the potential hazards posed by weather balloons.",
        "The plane sustained damage, but the exact extent is currently unknown.",
        "WindBorne's balloons are used for weather data collection and research."
      ]
    },
    {
      "id": "cluster_113",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 20:14:29 +0000",
      "title": "Google reportedly searching for 15 Pixel “Superfans” to test unreleased phones",
      "neutral_headline": "Google Seeks Pixel Superfans for Unreleased Phone Testing",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/10/google-reportedly-searching-for-15-pixel-superfans-to-test-unreleased-phones/",
          "published_at": "Mon, 20 Oct 2025 20:14:29 +0000",
          "title": "Google reportedly searching for 15 Pixel “Superfans” to test unreleased phones",
          "standfirst": "Selected testers will have to sign an NDA and use a disguised case.",
          "content": "It took awhile, but Google’s Pixel line of smartphones has established itself as a mainstay of Android after 10 generations. The company has long operated a “Superfans” group to help promote Pixels, but now members have a slim chance to get their hands on Google’s next phones ahead of time. Google is reportedly looking for some lucky Superfans to test and provide feedback on unreleased devices, but they’ll have to promise not to leak anything. It’s not unheard of for companies to have loyal customers help test new products, but it’s not usually big companies like Google with well-established products like Pixel. Google usually keeps its circle of hardware testers small and limited to employees. According to Bloomberg, Google is running a contest among Superfans to find 15 non-employees suited to test in-development hardware. An official document reviewed by Bloomberg describes the program as a chance to “provide feedback and help shape a Pixel phone currently in development.” To apply, interested Superfans have to prove they are more super than the rest. They must demonstrate deep knowledge of the Pixel product family and suggest ways the phones can be improved. However, Google is asking this of its biggest supporters—people who still care enough about their smartphones to seek out a group specifically to talk about how much they care about their phones. Is Google going to get gushing praise or constructive criticism?Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Pixel-10-Pro-Fold-4-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Pixel-10-Pro-Fold-4-1152x648.jpg",
      "popularity_score": 150,
      "ai_summary": [
        "Google is reportedly searching for fifteen Pixel \"Superfans\" to test unreleased phones.",
        "Selected testers will be required to sign a non-disclosure agreement.",
        "Testers will be required to use a disguised case to conceal the phone.",
        "The program aims to gather feedback on new Pixel devices before release.",
        "The application process and selection criteria are not yet public."
      ]
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Tue, 21 Oct 2025 13:11:27 +0000",
      "title": "Big Tech may fall short of green energy targets due to proposed rule changes",
      "neutral_headline": "Big Tech May Miss Green Energy Targets Due to Rule Changes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/big-tech-may-fall-short-of-green-energy-targets-due-to-proposed-rule-changes/",
          "published_at": "Tue, 21 Oct 2025 13:11:27 +0000",
          "title": "Big Tech may fall short of green energy targets due to proposed rule changes",
          "standfirst": "Goal is to create a \"credible link\" between companies and power they invest in.",
          "content": "The world’s leading authority on carbon accounting has proposed stricter disclosure rules that are set to make it more challenging for large power users such as Amazon and Meta to hit their climate targets. The EU, California, and the International Financial Reporting Standards all draw on the voluntary Greenhouse Gas Protocol oversight body in their guidelines on how companies should disclose their carbon footprints. This week, the Protocol proposed the first update in a decade to how it measures power-sector emissions, in a move that would upend the way many tech, industrial, and utilities groups account for clean energy investments.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bigtechgreen-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/bigtechgreen-1152x648.jpg",
      "popularity_score": 146.91071888888888,
      "ai_summary": [
        "Proposed rule changes could hinder Big Tech's ability to meet green energy goals.",
        "The goal is to establish a \"credible link\" between companies and their energy investments.",
        "The changes may impact how companies can claim renewable energy credits.",
        "The new rules could affect the financial viability of green energy projects.",
        "The proposed changes are currently under review by relevant regulatory bodies."
      ]
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 17:55:31 +0000",
      "title": "Musk’s $1 trillion Tesla pay plan draws some protest ahead of likely approval",
      "neutral_headline": "Tesla Pay Plan Faces Protest Before Likely Approval",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/musks-1-trillion-pay-plan-doesnt-force-him-to-keep-focus-on-tesla-critics-say/",
          "published_at": "Mon, 20 Oct 2025 17:55:31 +0000",
          "title": "Musk’s $1 trillion Tesla pay plan draws some protest ahead of likely approval",
          "standfirst": "Proxy firm says plan doesn't ensure that Musk's \"focus and time remain on Tesla.\"",
          "content": "Tesla shareholders should reject a compensation plan that could pay Elon Musk more than $1 trillion over the next decade, proxy advisory firm Institutional Shareholder Services (ISS) said in a report Friday. The plan is designed “to retain Musk and keep his time and attention on Tesla instead of his other business ventures,” but “there are no prescriptive elements within the award to ensure his focus and time remain on Tesla as opposed to his other ventures, undermining the award’s primary rationale,” the advisory firm said in a report for its clients. The “astronomical grant value” awarded to Musk could dilute value for other shareholders “due to the extreme value and number of shares being granted,” and it is questionable whether the award “is necessary or appropriate to further align his interests [with Tesla] when he currently holds a 19.8 percent ownership stake in the company,” ISS said.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/musk-cybertruck-1152x648-1760980565.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/musk-cybertruck-1152x648-1760980565.jpg",
      "popularity_score": 144,
      "ai_summary": [
        "Elon Musk's $1 trillion Tesla pay plan is facing some opposition.",
        "A proxy firm expressed concerns that the plan does not ensure Musk's focus on Tesla.",
        "The plan is expected to be approved by shareholders despite the protests.",
        "The pay plan is a significant component of Musk's compensation package.",
        "The vote on the plan is scheduled for an upcoming shareholder meeting."
      ]
    },
    {
      "id": "cluster_114",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 20:01:59 +0000",
      "title": "Breaking down rare earth element magnets for recycling",
      "neutral_headline": "New Method Recycles Rare Earth Element Magnets",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/breaking-down-rare-earth-element-magnets-for-recycling/",
          "published_at": "Mon, 20 Oct 2025 20:01:59 +0000",
          "title": "Breaking down rare earth element magnets for recycling",
          "standfirst": "New method extracts desirable elements from waste magnets using less energy and acid.",
          "content": "All the world’s discarded phones, bricked laptops, and other trashed electronics are collectively a treasure trove of rare earth elements (REEs). But separating out and recovering these increasingly sought-after materials is no easy task. However, a team of researchers says it has developed a way of separating REEs from waste—magnets, in this case—that is relatively easy, uses less energy, and isn’t nearly as emissions and pollution intensive as current methods. The team published a paper describing this method in the Proceedings of the National Academy of Sciences. In short, this process involves using an electric current to heat waste magnets to very high temperatures very fast, and using chlorine gas to react with the non-REEs in the mix, keeping them in the vapor phase. James Tour, one of the authors and a professor of materials science and nanoengineering at Rice University, says that the research can help the United States meet its growing need for these elements.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1359528962-e1760988838500-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1359528962-e1760988838500-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "A new method extracts rare earth elements from waste magnets.",
        "The process uses less energy and acid compared to existing methods.",
        "The method aims to improve the sustainability of magnet recycling.",
        "The extracted elements can be reused in various manufacturing processes.",
        "The research was published in a recent scientific journal."
      ]
    },
    {
      "id": "cluster_120",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 18:38:02 +0000",
      "title": "SpaceX launches 10,000th Starlink satellite, with no sign of slowing down",
      "neutral_headline": "SpaceX Launches 10,000th Starlink Satellite",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/spacex-launches-10000th-starlink-satellite-with-no-sign-of-slowing-down/",
          "published_at": "Mon, 20 Oct 2025 18:38:02 +0000",
          "title": "SpaceX launches 10,000th Starlink satellite, with no sign of slowing down",
          "standfirst": "Sunday was not a day of rest for SpaceX.",
          "content": "Two Falcon 9 rockets lifted off from spaceports in Florida and California on Sunday afternoon, adding 56 more satellites to SpaceX’s Starlink broadband network. The second of these two launches—originating from Vandenberg Space Force Base, California—propelled SpaceX’s Starlink program past a notable milestone. With the satellites added to the constellation Sunday, the company has delivered more than 10,000 mass-produced Starlink spacecraft to low-Earth orbit. The exact figure stands at 10,006 satellites, according to a tabulation by Jonathan McDowell, an astrophysicist who expertly tracks comings and goings between Earth and space. This number includes dozens of Starlink demo satellites, but not the dummy spacecraft carried on SpaceX’s recent Starship test flights.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlinkstack-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/starlinkstack-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "SpaceX launched its 10,000th Starlink satellite into orbit.",
        "The launch occurred without any reported delays or issues.",
        "SpaceX continues to expand its Starlink satellite constellation.",
        "The company aims to provide global internet access through Starlink.",
        "The launch took place on a recent Sunday, a day of continued activity."
      ]
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 22:18:22 +0000",
      "title": "NSO permanently barred from targeting WhatsApp users with Pegasus spyware",
      "neutral_headline": "NSO Barred From Targeting WhatsApp Users",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/10/nso-permanently-barred-from-targeting-whatsapp-users-with-pegasus-spyware/",
          "published_at": "Mon, 20 Oct 2025 22:18:22 +0000",
          "title": "NSO permanently barred from targeting WhatsApp users with Pegasus spyware",
          "standfirst": "Ruling holds that defeating end-to-end encryption in WhatsApp harms Meta's business.",
          "content": "A federal judge has ordered spyware maker NSO to stop using its Pegasus app to target or infect users of WhatsApp. The ruling, issued Friday by Phyllis J. Hamilton of the US District Court of the District of Northern California, grants a permanent injunction sought by WhatsApp owner Meta in a case it brought against NSO in 2019. The lawsuit alleged that Meta caught NSO trying to surreptitiously infect about 1,400 mobile phones—many belonging to attorneys, journalists, human-rights activists, political dissidents, diplomats, and senior foreign government officials—with Pegasus. As part of the campaign, NSO created fake WhatsApp accounts and targeted Meta infrastructure. The suit sought monetary awards and an injunction against the practice. Setting a precedent Friday’s ruling ordered NSO to permanently cease targeting WhatsApp users, attempting to infect their devices, or intercepting WhatsApp messages, which are end-to-end encrypted using the open source Signal Protocol. Hamilton also ruled that NSO must delete any data it obtained when targeting the WhatsApp users.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/whatsapp-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/whatsapp-1024x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "NSO Group is permanently barred from targeting WhatsApp users.",
        "The ruling determined that Pegasus spyware harms Meta's business.",
        "The ruling cited the damage to end-to-end encryption on WhatsApp.",
        "The ban is a result of legal action taken by Meta.",
        "The decision has implications for cybersecurity and privacy."
      ]
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 21:53:54 +0000",
      "title": "Why did NASA’s chief just shake up the agency’s plans to land on the Moon?",
      "neutral_headline": "NASA Chief Changes Moon Landing Plans",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/nasas-acting-leader-seeks-to-keep-his-job-with-new-lunar-lander-announcement/",
          "published_at": "Mon, 20 Oct 2025 21:53:54 +0000",
          "title": "Why did NASA’s chief just shake up the agency’s plans to land on the Moon?",
          "standfirst": "\"The president wants to make sure we beat the Chinese.\"",
          "content": "NASA acting Administrator Sean Duffy made two television appearances on Monday morning in which he shook up the space agency’s plans to return humans to the Moon. Speaking on Fox News, where the secretary of transportation frequently appears in his acting role as NASA chief, Duffy said SpaceX has fallen behind in its efforts to develop the Starship vehicle as a lunar lander. Duffy also indirectly acknowledged that NASA’s projected target of a 2027 crewed lunar landing is no longer achievable. Accordingly, he said he intended to expand the competition to develop a lander capable of carrying humans down to the Moon from lunar orbit and back. “They’re behind schedule, and so the President wants to make sure we beat the Chinese,” Duffy said of SpaceX. “He wants to get there in his term. So I’m in the process of opening that contract up. I think we’ll see companies like Blue [Origin] get involved, and maybe others. We’re going to have a space race in regard to American companies competing to see who can actually lead us back to the Moon first.”Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/NHQ202507310028medium-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/NHQ202507310028medium-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "NASA's chief has altered the agency's plans for landing on the Moon.",
        "The change is reportedly influenced by a desire to compete with China.",
        "The revised plans may involve accelerating the timeline for lunar missions.",
        "The agency is under pressure to maintain its leadership in space exploration.",
        "The details of the revised plans are expected to be announced soon."
      ]
    },
    {
      "id": "cluster_112",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 20:45:26 +0000",
      "title": "Claude Code gets a web version—but it’s the new sandboxing that really matters",
      "neutral_headline": "Claude Code Gets Web Version, Sandboxing Matters",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/",
          "published_at": "Mon, 20 Oct 2025 20:45:26 +0000",
          "title": "Claude Code gets a web version—but it’s the new sandboxing that really matters",
          "standfirst": "Sandboxing lessens hassle, but fire-and-forget agentic tools still pose risks.",
          "content": "Anthropic has added web and mobile interfaces for Claude Code, its immensely popular command-line interface (CLI) agentic AI coding tool. The web interface appears to be well-baked at launch, but the mobile version is limited to iOS and is in an earlier stage of development. The web version of Claude Code can be given access to a GitHub repository. Once that’s done, developers can give it general marching orders like “add real-time inventory tracking to the dashboard.” As with the CLI version, it gets to work, with updates along the way approximating where it’s at and what it’s doing. The web interface supports the recently implemented Claude Code capability to take suggestions or requested changes while it’s in the middle of working on a task. (Previously, if you saw it doing something wrong or missing something, you often had to cancel and start over.)Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-3.36.24-PM.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-3.36.24-PM.png",
      "popularity_score": 133,
      "ai_summary": [
        "Claude Code now has a web version available for users.",
        "The new sandboxing feature is considered particularly important.",
        "Sandboxing reduces the potential for security risks.",
        "Agentic tools still pose risks despite the new features.",
        "The web version offers improved accessibility for users."
      ]
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Mon, 20 Oct 2025 19:15:24 +0000",
      "title": "Do animals fall for optical illusions? It’s complicated.",
      "neutral_headline": "Animals and Optical Illusions: A Complicated Relationship",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/do-animals-fall-for-optical-illusions-its-complicated/",
          "published_at": "Mon, 20 Oct 2025 19:15:24 +0000",
          "title": "Do animals fall for optical illusions? It’s complicated.",
          "standfirst": "Guppies are highly susceptible to the Ebbinghaus illusion. Ring doves? Not so much.",
          "content": "Chances are you’ve encountered some version of the “Ebbinghaus illusion,” in which a central circle appears to be smaller when encircled by larger circles and seems larger when surrounded by smaller circles. It’s an example of context-dependent size perception. But is this unique to humans or are some animals susceptible as well? According to a new paper published in the journal Frontiers in Psychology, it might depend on the specific sensory environment, since the illusion relies on contextual clues to be effective. Prior research has produced mixed results on the question of animals and their susceptibility to optical illusions, per the authors. Dolphins, chicks, and redtail splitfins seem to be susceptible, for example, while pigeons, baboons, and gray bamboo snakes are not. Perhaps the best-known example is cats’ undeniable love of boxes and squares—the “if it fits, I sits” phenomenon documented all over the Internet. This behavior is generally attributed to the fact that cats feel safer when squeezed into small spaces, but it also tells us something about feline visual perception. A 1988 study and a 2021 study concluded that cats are susceptible to the Kanizsa square illusion, suggesting that they perceive subjective contours much like humans.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/illusion1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/illusion1-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Research explores whether animals are susceptible to optical illusions.",
        "Guppies are highly susceptible to the Ebbinghaus illusion.",
        "Ring doves do not appear to be affected by the same illusion.",
        "The study highlights differences in visual perception across species.",
        "The findings contribute to understanding animal cognition."
      ]
    }
  ]
}