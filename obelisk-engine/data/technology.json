{
  "updated_at": "2025-12-11T07:24:27.764Z",
  "clusters": [
    {
      "id": "cluster_7",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 23:15:02 -0500",
      "title": "Operation Bluebird, a Virginia-based startup planning a \"Twitter.new\" social network, has petitioned the USPTO to cancel X Corp.'s \"abandoned\" trademarks (Cyrus Farivar/Ars Technica)",
      "neutral_headline": "Operation Bluebird wants to reclaim Twitter’s ‘abandoned’ trademarks for...",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251210/p69#a251210p69",
          "published_at": "Wed, 10 Dec 2025 23:15:02 -0500",
          "title": "Operation Bluebird, a Virginia-based startup planning a \"Twitter.new\" social network, has petitioned the USPTO to cancel X Corp.'s \"abandoned\" trademarks (Cyrus Farivar/Ars Technica)",
          "standfirst": "Cyrus Farivar / Ars Technica: Operation Bluebird, a Virginia-based startup planning a &ldquo;Twitter.new&rdquo; social network, has petitioned the USPTO to cancel X Corp.'s &ldquo;abandoned&rdquo; trademarks &mdash; A Virginia startup calling itself &ldquo;Operation Bluebird&rdquo; announced this week that it has filed a formal petition &hellip;",
          "content": "Cyrus Farivar / Ars Technica: Operation Bluebird, a Virginia-based startup planning a &ldquo;Twitter.new&rdquo; social network, has petitioned the USPTO to cancel X Corp.'s &ldquo;abandoned&rdquo; trademarks &mdash; A Virginia startup calling itself &ldquo;Operation Bluebird&rdquo; announced this week that it has filed a formal petition &hellip;",
          "feed_position": 4,
          "image_url": "http://www.techmeme.com/251210/i69.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/report/841994/operation-bluebird-twitter-trademarks-petition",
          "published_at": "2025-12-10T16:31:24-05:00",
          "title": "Operation Bluebird wants to reclaim Twitter’s ‘abandoned’ trademarks for a new social network",
          "standfirst": "A startup called Operation Bluebird is trying to reclaim Twitter's branding, as reported earlier by Ars Technica and Reuters. Last week, Operation Bluebird filed a petition that asks the US Patent and Trademark Office (USPTO) to cancel X Corp.'s ownership of the \"Twitter\" and \"Tweet\" trademarks, claiming they've been \"abandoned\" by the Elon Musk-owned company. [&#8230;]",
          "content": "A startup called Operation Bluebird is trying to reclaim Twitter's branding, as reported earlier by Ars Technica and Reuters. Last week, Operation Bluebird filed a petition that asks the US Patent and Trademark Office (USPTO) to cancel X Corp.'s ownership of the \"Twitter\" and \"Tweet\" trademarks, claiming they've been \"abandoned\" by the Elon Musk-owned company. Operation Bluebird is led by founder Michael Peroff, an Illinois trademark and brand protection attorney, along with Stephen Coates, a trademark attorney who worked as Twitter's associate director of trademarks, domain names, and marketing from 2014 to 2016. The startup also filed a t … Read the full story at The Verge.",
          "feed_position": 3
        }
      ],
      "featured_image": "http://www.techmeme.com/251210/i69.jpg",
      "popularity_score": 2016.8428436111112
    },
    {
      "id": "cluster_15",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 20:15:01 -0500",
      "title": "A group of state AGs sent a letter to Meta, Microsoft, Google, Apple, and others warning their chatbots' \"delusional outputs\" could be violating state laws (Courtney Rozen/Reuters)",
      "neutral_headline": "A group of state AGs sent a letter to Meta, Microsoft, Google, Apple, and others warning their chatbots'...",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251210/p64#a251210p64",
          "published_at": "Wed, 10 Dec 2025 20:15:01 -0500",
          "title": "A group of state AGs sent a letter to Meta, Microsoft, Google, Apple, and others warning their chatbots' \"delusional outputs\" could be violating state laws (Courtney Rozen/Reuters)",
          "standfirst": "Courtney Rozen / Reuters: A group of state AGs sent a letter to Meta, Microsoft, Google, Apple, and others warning their chatbots' &ldquo;delusional outputs&rdquo; could be violating state laws &mdash; Microsoft, Meta, Google and Apple were among the 13 companies that received a warning from a bipartisan group of state attorneys general &hellip;",
          "content": "Courtney Rozen / Reuters: A group of state AGs sent a letter to Meta, Microsoft, Google, Apple, and others warning their chatbots' &ldquo;delusional outputs&rdquo; could be violating state laws &mdash; Microsoft, Meta, Google and Apple were among the 13 companies that received a warning from a bipartisan group of state attorneys general &hellip;",
          "feed_position": 9,
          "image_url": "http://www.techmeme.com/251210/i64.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/10/state-attorneys-general-warn-microsoft-openai-google-and-other-ai-giants-to-fix-delusional-outputs/",
          "published_at": "Thu, 11 Dec 2025 00:13:43 +0000",
          "title": "State attorneys general warn Microsoft, OpenAI, Google, and other AI giants to fix &#8216;delusional&#8217; outputs",
          "standfirst": "The letter demanded companies institute new safeguards to keep users safe from harmful psychological impacts.",
          "content": "The letter demanded companies institute new safeguards to keep users safe from harmful psychological impacts.",
          "feed_position": 2
        }
      ],
      "featured_image": "http://www.techmeme.com/251210/i64.jpg",
      "popularity_score": 2013.8425658333333
    },
    {
      "id": "cluster_16",
      "coverage": 2,
      "updated_at": "Thu, 11 Dec 2025 01:10:04 +0000",
      "title": "Google&#8217;s answer to the AI arms race — promote the guy behind its data center tech",
      "neutral_headline": "Google&#8217;s answer to the AI arms race — promote the guy...",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/10/googles-answer-to-the-ai-arms-race-promote-the-guy-behind-its-data-center-tech/",
          "published_at": "Thu, 11 Dec 2025 01:10:04 +0000",
          "title": "Google&#8217;s answer to the AI arms race — promote the guy behind its data center tech",
          "standfirst": "Amin Vahdat has been promoted to chief technologist for AI infrastructure, a newly created position reporting directly to CEO Sundar Pichai.",
          "content": "Amin Vahdat has been promoted to chief technologist for AI infrastructure, a newly created position reporting directly to CEO Sundar Pichai.",
          "feed_position": 1
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251210/p60#a251210p60",
          "published_at": "Wed, 10 Dec 2025 18:20:00 -0500",
          "title": "Internal memo: Google is naming Amin Vahdat, who leads the company's AI and infrastructure team, to the new role of chief technologist for AI infrastructure (Reed Albergotti/Semafor)",
          "standfirst": "Reed Albergotti / Semafor: Internal memo: Google is naming Amin Vahdat, who leads the company's AI and infrastructure team, to the new role of chief technologist for AI infrastructure &mdash; THE SCOOP &mdash; With the rapid buildout of infrastructure taking center stage in the tight AI race between tech giants &hellip;",
          "content": "Reed Albergotti / Semafor: Internal memo: Google is naming Amin Vahdat, who leads the company's AI and infrastructure team, to the new role of chief technologist for AI infrastructure &mdash; THE SCOOP &mdash; With the rapid buildout of infrastructure taking center stage in the tight AI race between tech giants &hellip;",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/251210/i60.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251210/i60.jpg",
      "popularity_score": 2013.7600658333333
    },
    {
      "id": "cluster_20",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 19:20:01 -0500",
      "title": "Google tests AI-powered overviews on some publications' Google News pages; publishers like Der Spiegel, El País, and WaPo in commercial partnerships get paid (Aisha Malik/TechCrunch)",
      "neutral_headline": "Google is testing AI-powered article overviews on select...",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251210/p62#a251210p62",
          "published_at": "Wed, 10 Dec 2025 19:20:01 -0500",
          "title": "Google tests AI-powered overviews on some publications' Google News pages; publishers like Der Spiegel, El País, and WaPo in commercial partnerships get paid (Aisha Malik/TechCrunch)",
          "standfirst": "Aisha Malik / TechCrunch: Google tests AI-powered overviews on some publications' Google News pages; publishers like Der Spiegel, El Pa&iacute;s, and WaPo in commercial partnerships get paid &mdash; Google is testing AI-powered article overviews on participating publications' Google News pages as part of a new pilot program, the search giant announced on Wednesday.",
          "content": "Aisha Malik / TechCrunch: Google tests AI-powered overviews on some publications' Google News pages; publishers like Der Spiegel, El Pa&iacute;s, and WaPo in commercial partnerships get paid &mdash; Google is testing AI-powered article overviews on participating publications' Google News pages as part of a new pilot program, the search giant announced on Wednesday.",
          "feed_position": 11,
          "image_url": "http://www.techmeme.com/251210/i62.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/10/google-is-testing-ai-powered-article-overviews-on-select-publications-google-news-pages/",
          "published_at": "Wed, 10 Dec 2025 17:00:00 +0000",
          "title": "Google is testing AI-powered article overviews on select publications’ Google News pages",
          "standfirst": "By adding AI-powered article overviews, Google says users will get more context before they click through to read an article.",
          "content": "By adding AI-powered article overviews, Google says users will get more context before they click through to read an article.",
          "feed_position": 12
        }
      ],
      "featured_image": "http://www.techmeme.com/251210/i62.jpg",
      "popularity_score": 2012.9258991666666
    },
    {
      "id": "cluster_29",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 23:00:00 GMT",
      "title": "The 70% factuality ceiling: why Google’s new ‘FACTS’ benchmark is a wake-up call for enterprise AI",
      "neutral_headline": "12 steps you can take right now to be safer online",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/the-70-factuality-ceiling-why-googles-new-facts-benchmark-is-a-wake-up-call",
          "published_at": "Wed, 10 Dec 2025 23:00:00 GMT",
          "title": "The 70% factuality ceiling: why Google’s new ‘FACTS’ benchmark is a wake-up call for enterprise AI",
          "standfirst": "There&#x27;s no shortage of generative AI benchmarks designed to measure the performance and accuracy of a given model on completing various helpful enterprise tasks — from coding to instruction following to agentic web browsing and tool use. But many of these benchmarks have one major shortcoming: they measure the AI&#x27;s ability to complete specific problems and requests, not how factual the model is in its outputs — how well it generates objectively correct information tied to real-world data — especially when dealing with information contained in imagery or graphics.For industries where accuracy is paramount — legal, finance, and medical — the lack of a standardized way to measure factuality has been a critical blind spot.That changes today: Google’s FACTS team and its data science unit Kaggle released the FACTS Benchmark Suite, a comprehensive evaluation framework designed to close this gap. The associated research paper reveals a more nuanced definition of the problem, splitting \"factuality\" into two distinct operational scenarios: \"contextual factuality\" (grounding responses in provided data) and \"world knowledge factuality\" (retrieving information from memory or the web).While the headline news is Gemini 3 Pro’s top-tier placement, the deeper story for builders is the industry-wide \"factuality wall.\"According to the initial results, no model—including Gemini 3 Pro, GPT-5, or Claude 4.5 Opus—managed to crack a 70% accuracy score across the suite of problems. For technical leaders, this is a signal: the era of \"trust but verify\" is far from over.Deconstructing the BenchmarkThe FACTS suite moves beyond simple Q&A. It is composed of four distinct tests, each simulating a different real-world failure mode that developers encounter in production:Parametric Benchmark (Internal Knowledge): Can the model accurately answer trivia-style questions using only its training data?Search Benchmark (Tool Use): Can the model effectively use a web search tool to retrieve and synthesize live information?Multimodal Benchmark (Vision): Can the model accurately interpret charts, diagrams, and images without hallucinating?Grounding Benchmark v2 (Context): Can the model stick strictly to the provided source text?Google has released 3,513 examples to the public, while Kaggle holds a private set to prevent developers from training on the test data—a common issue known as \"contamination.\"The Leaderboard: A Game of InchesThe initial run of the benchmark places Gemini 3 Pro in the lead with a comprehensive FACTS Score of 68.8%, followed by Gemini 2.5 Pro (62.1%) and OpenAI’s GPT-5 (61.8%).However, a closer look at the data reveals where the real battlegrounds are for engineering teams.ModelFACTS Score (Avg)Search (RAG Capability)Multimodal (Vision)Gemini 3 Pro68.883.846.1Gemini 2.5 Pro62.163.946.9GPT-561.877.744.1Grok 453.675.325.7Claude 4.5 Opus51.373.239.2Data sourced from the FACTS Team release notes.For Builders: The \"Search\" vs. \"Parametric\" GapFor developers building RAG (Retrieval-Augmented Generation) systems, the Search Benchmark is the most critical metric.The data shows a massive discrepancy between a model&#x27;s ability to \"know\" things (Parametric) and its ability to \"find\" things (Search). For instance, Gemini 3 Pro scores a high 83.8% on Search tasks but only 76.4% on Parametric tasks. This validates the current enterprise architecture standard: do not rely on a model&#x27;s internal memory for critical facts.If you are building an internal knowledge bot, the FACTS results suggest that hooking your model up to a search tool or vector database is not optional—it is the only way to push accuracy toward acceptable production levels.The Multimodal WarningThe most alarming data point for product managers is the performance on Multimodal tasks. The scores here are universally low. Even the category leader, Gemini 2.5 Pro, only hit 46.9% accuracy.The benchmark tasks included reading charts, interpreting diagrams, and identifying objects in nature. With less than 50% accuracy across the board, this suggests that Multimodal AI is not yet ready for unsupervised data extraction. Bottom line: If your product roadmap involves having an AI automatically scrape data from invoices or interpret financial charts without human-in-the-loop review, you are likely introducing significant error rates into your pipeline.Why This Matters for Your StackThe FACTS Benchmark is likely to become a standard reference point for procurement. When evaluating models for enterprise use, technical leaders should look beyond the composite score and drill into the specific sub-benchmark that matches their use case:Building a Customer Support Bot? Look at the Grounding score to ensure the bot sticks to your policy documents. (Gemini 2.5 Pro actually outscored Gemini 3 Pro here, 74.2 vs 69.0).Building a Research Assistant? Prioritize Search scores.Building an Image Analysis Tool? Proceed with extreme caution.As the FACTS team noted in their release, \"All evaluated models achieved an overall accuracy below 70%, leaving considerable headroom for future progress.\"For now, the message to the industry is clear: The models are getting smarter, but they aren&#x27;t yet infallible. Design your systems with the assumption that, roughly one-third of the time, the raw model might just be wrong.",
          "content": "There&#x27;s no shortage of generative AI benchmarks designed to measure the performance and accuracy of a given model on completing various helpful enterprise tasks — from coding to instruction following to agentic web browsing and tool use. But many of these benchmarks have one major shortcoming: they measure the AI&#x27;s ability to complete specific problems and requests, not how factual the model is in its outputs — how well it generates objectively correct information tied to real-world data — especially when dealing with information contained in imagery or graphics.For industries where accuracy is paramount — legal, finance, and medical — the lack of a standardized way to measure factuality has been a critical blind spot.That changes today: Google’s FACTS team and its data science unit Kaggle released the FACTS Benchmark Suite, a comprehensive evaluation framework designed to close this gap. The associated research paper reveals a more nuanced definition of the problem, splitting \"factuality\" into two distinct operational scenarios: \"contextual factuality\" (grounding responses in provided data) and \"world knowledge factuality\" (retrieving information from memory or the web).While the headline news is Gemini 3 Pro’s top-tier placement, the deeper story for builders is the industry-wide \"factuality wall.\"According to the initial results, no model—including Gemini 3 Pro, GPT-5, or Claude 4.5 Opus—managed to crack a 70% accuracy score across the suite of problems. For technical leaders, this is a signal: the era of \"trust but verify\" is far from over.Deconstructing the BenchmarkThe FACTS suite moves beyond simple Q&A. It is composed of four distinct tests, each simulating a different real-world failure mode that developers encounter in production:Parametric Benchmark (Internal Knowledge): Can the model accurately answer trivia-style questions using only its training data?Search Benchmark (Tool Use): Can the model effectively use a web search tool to retrieve and synthesize live information?Multimodal Benchmark (Vision): Can the model accurately interpret charts, diagrams, and images without hallucinating?Grounding Benchmark v2 (Context): Can the model stick strictly to the provided source text?Google has released 3,513 examples to the public, while Kaggle holds a private set to prevent developers from training on the test data—a common issue known as \"contamination.\"The Leaderboard: A Game of InchesThe initial run of the benchmark places Gemini 3 Pro in the lead with a comprehensive FACTS Score of 68.8%, followed by Gemini 2.5 Pro (62.1%) and OpenAI’s GPT-5 (61.8%).However, a closer look at the data reveals where the real battlegrounds are for engineering teams.ModelFACTS Score (Avg)Search (RAG Capability)Multimodal (Vision)Gemini 3 Pro68.883.846.1Gemini 2.5 Pro62.163.946.9GPT-561.877.744.1Grok 453.675.325.7Claude 4.5 Opus51.373.239.2Data sourced from the FACTS Team release notes.For Builders: The \"Search\" vs. \"Parametric\" GapFor developers building RAG (Retrieval-Augmented Generation) systems, the Search Benchmark is the most critical metric.The data shows a massive discrepancy between a model&#x27;s ability to \"know\" things (Parametric) and its ability to \"find\" things (Search). For instance, Gemini 3 Pro scores a high 83.8% on Search tasks but only 76.4% on Parametric tasks. This validates the current enterprise architecture standard: do not rely on a model&#x27;s internal memory for critical facts.If you are building an internal knowledge bot, the FACTS results suggest that hooking your model up to a search tool or vector database is not optional—it is the only way to push accuracy toward acceptable production levels.The Multimodal WarningThe most alarming data point for product managers is the performance on Multimodal tasks. The scores here are universally low. Even the category leader, Gemini 2.5 Pro, only hit 46.9% accuracy.The benchmark tasks included reading charts, interpreting diagrams, and identifying objects in nature. With less than 50% accuracy across the board, this suggests that Multimodal AI is not yet ready for unsupervised data extraction. Bottom line: If your product roadmap involves having an AI automatically scrape data from invoices or interpret financial charts without human-in-the-loop review, you are likely introducing significant error rates into your pipeline.Why This Matters for Your StackThe FACTS Benchmark is likely to become a standard reference point for procurement. When evaluating models for enterprise use, technical leaders should look beyond the composite score and drill into the specific sub-benchmark that matches their use case:Building a Customer Support Bot? Look at the Grounding score to ensure the bot sticks to your policy documents. (Gemini 2.5 Pro actually outscored Gemini 3 Pro here, 74.2 vs 69.0).Building a Research Assistant? Prioritize Search scores.Building an Image Analysis Tool? Proceed with extreme caution.As the FACTS team noted in their release, \"All evaluated models achieved an overall accuracy below 70%, leaving considerable headroom for future progress.\"For now, the message to the industry is clear: The models are getting smarter, but they aren&#x27;t yet infallible. Design your systems with the assumption that, roughly one-third of the time, the raw model might just be wrong.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1P96HBSOE22cfl5djgDueT/df9398cb8f464a8f6519d964da86026c/mRfmh7TAQtPYv7mwcN551.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/music/spotifys-new-playlist-feature-gives-users-more-control-over-their-recommendation-algorithm-203237903.html",
          "published_at": "Wed, 10 Dec 2025 20:32:37 +0000",
          "title": "Spotify's new playlist feature gives users more control over their recommendation algorithm",
          "standfirst": "Spotify is attempting to give users more control over the music the streaming service recommends with a new playlist feature called \"Prompted Playlist.\" The beta feature is rolling out in New Zealand starting on December 11, and will let users write a custom prompt that Spotify can use — alongside their listening history — to create a playlist of new music.By tapping on Prompted Playlist, Spotify subscribers participating in the beta will be presented with a prompt field where they can type exactly what they want to hear and how they want Spotify's algorithm to respond. And while past AI features took users' individual taste into consideration, Spotify claims Prompted Playlist \"taps into your entire Spotify listening history, all the way back to day one.\" Prompted Playlist will exist alongside Spotify's other playlist features.SpotifyPrompts can be as broad or specific as users want, and Spotify says playlists can also be set to automatically update with new songs on a specific cadence. An \"Ideas\" tab in the Prompted Playlist setup screen can provide suggestions for users who need inspiration for their prompt. And interestingly, Spotify says each song in the playlist will be presented with a short description explaining why the algorithm chose it, which could help direct future fine-tuning.If this all sounds familiar, it's because Spotify has already tried AI-generated playlists in the past. The difference here, besides Spotify framing the new feature as giving users more \"control,\" is the detail of the prompts, the depth of user data Spotify is applying and the options users will have to keep playlists up-to-date. Prompted Playlist is only available in English for now, but Spotify says the feature will evolve as it adds more users.Spotify isn't the first company to offer users more direct control over how content is recommended to them. Meta has recently started experimenting with algorithm-tuning options in Threads and Instagram, and TikTok lets users completely reset their For You page to start fresh. The irony of all these features is that algorithm-driven feeds were supposed to be able to recommend good music, posts and videos without additional prompting. Now that prompting is being pitched as a feature, rather than extra work.This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-new-playlist-feature-gives-users-more-control-over-their-recommendation-algorithm-203237903.html?src=rss",
          "content": "Spotify is attempting to give users more control over the music the streaming service recommends with a new playlist feature called \"Prompted Playlist.\" The beta feature is rolling out in New Zealand starting on December 11, and will let users write a custom prompt that Spotify can use — alongside their listening history — to create a playlist of new music.By tapping on Prompted Playlist, Spotify subscribers participating in the beta will be presented with a prompt field where they can type exactly what they want to hear and how they want Spotify's algorithm to respond. And while past AI features took users' individual taste into consideration, Spotify claims Prompted Playlist \"taps into your entire Spotify listening history, all the way back to day one.\" Prompted Playlist will exist alongside Spotify's other playlist features.SpotifyPrompts can be as broad or specific as users want, and Spotify says playlists can also be set to automatically update with new songs on a specific cadence. An \"Ideas\" tab in the Prompted Playlist setup screen can provide suggestions for users who need inspiration for their prompt. And interestingly, Spotify says each song in the playlist will be presented with a short description explaining why the algorithm chose it, which could help direct future fine-tuning.If this all sounds familiar, it's because Spotify has already tried AI-generated playlists in the past. The difference here, besides Spotify framing the new feature as giving users more \"control,\" is the detail of the prompts, the depth of user data Spotify is applying and the options users will have to keep playlists up-to-date. Prompted Playlist is only available in English for now, but Spotify says the feature will evolve as it adds more users.Spotify isn't the first company to offer users more direct control over how content is recommended to them. Meta has recently started experimenting with algorithm-tuning options in Threads and Instagram, and TikTok lets users completely reset their For You page to start fresh. The irony of all these features is that algorithm-driven feeds were supposed to be able to recommend good music, posts and videos without additional prompting. Now that prompting is being pitched as a feature, rather than extra work.This article originally appeared on Engadget at https://www.engadget.com/entertainment/music/spotifys-new-playlist-feature-gives-users-more-control-over-their-recommendation-algorithm-203237903.html?src=rss",
          "feed_position": 4,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Prompted-Playlist-GIF-102924.gif"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/the-world-premieres-and-other-hotness-from-the-game-awards-2025-day-of-the-devs-stream-200000447.html",
          "published_at": "Wed, 10 Dec 2025 20:00:00 +0000",
          "title": "The world premieres and other hotness from The Game Awards 2025 Day of the Devs stream",
          "standfirst": "You gotta love that post-Day of the Devs showcase feeling. The organization, founded by Double Fine Productions and iam8bit, consistently highlights top-tier games from independent developers across the globe, providing space for creators to share their stories in both online and in-person events. This year’s Day of the Devs: The Game Awards Digital Showcase was an hour-long celebration of 22 upcoming indie games, including six world premieres and three release date announcements.Settle in and bask in the afterglow with us:World PremieresVirtue and a Sledgehammer - DeconstructeamDeconstructeam is a small Spanish studio that’s responsible for some of the most cerebral, sexy and darkly philosophical games around, including Gods Will Be Watching, The Red Strings Club and The Cosmic Wheel Sisterhood. The team’s next project is Virtue and a Sledgehammer, and it represents a new look with 3D, cel-shaded animations and a third-person perspective rather than the studio’s typical pixelated planar fare. The vibes are just as sinister and introspective as expected, though.Virtue and a Sledgehammer is a moody coming-of-age experience set in a wooded ghost town dotted with robots and lost locals. Spend quiet moments with old friends and then swing the sledgehammer to raze your hometown and uncover memories that can help you move on. The game’s buildings and objects are highly reactive, which can only help with the catharsis of it all.Virtue and a Sledgehammer is due to hit Steam in 2026, published by Devolver Digital.UN:Me - Shueisha GamesNow, this is a horror game. UN:Me comes from Japanese publisher Shueisha Games and developer Historia, and it’s a creepy, mind-bending exploration of primal fear. It stars a young woman with four souls trapped inside of her body, fighting for control of her consciousness. She wanders sterile, illogical hallways and encounters grotesque horrors representing common human fears like heights, authority figures and confined spaces. The souls switch randomly, each one manifesting a specific anxiety. As she wanders, the player has to choose souls to eliminate until only one remains. Whether it’s her real soul or a fake isn’t disclosed until the very end.UN:Me is available to wishlist now on Steam.Scramble Knights Royale - Funktronic LabsFunktronic Labs is mainly known as a VR studio, with games like Cosmic Trip, Fujii and The Light Brigade under its belt, but its latest project doesn’t require a headset at all. Scramble Knights Royale is coming to PC and Xbox in 2026, and it’s a battle royale with adventure game twists. You begin on a boat with 30 to 40 other online players, make your way to land on the back of a turtle, and then it’s essentially Naked and Afraid from there. Find resources, fight creatures, upgrade your gear and play your own game, only battling other players when you encounter them in the wild.Don’t let the sweet, clay-like animations fool you, either — Funktronic says the combat mechanics are incredibly deep and finely honed. Scramble Knights Royale also supports local split-screen. Mirria - MografiMografi made a name for itself with the adorable Jenny LeClue detective game, but now it’s time for something different. Mirria is an atmospheric puzzle experience from ISLANDS: Non-Places artist Carl Burton, published by Mografi, and it looks like a delicious mix of Kentucky Route Zero and Monument Valley. In Mirria, you explore mirror worlds and attempt to make the two realities match, paying attention to small details and making minute adjustments until the unsettling environments are perfect reflections. It looks and sounds like soul-soothing stuff.Mirria is due out in 2026 on Steam.CorgiSpace - FinjiIn recent years, Finji founder Adam Saltsman has been involved in high-profile indie games like Overlands, Night in the Woods, Tunic and Usual June, but his new project taps into his simplistic and mechanics-driven Canabalt roots. Corgispace is a collection of 8-bit games with off-kilter premises, including the soulslike Rat Dreams where you can only dodgeroll, the no-jumping platformer Skeleton Jeleton, and Prince of Prussia, an adventure where you stab Nazis “but in a fun new way,” according to Saltsman. Also, he says there are no secrets in this game, which leads us to believe there is at least one secret in this game.Corgispace is out now (!) on Steam and Itch.io.Frog Sqwad - Panic StationsIf the former Fall Guys developers at Panic Stations know how to do one thing, it’s make a silly-physics multiplayer game, so that’s exactly what they’re doing. Frog Sqwad is a co-op experience where you and your fellow frogs search the sewers for food in order to satiate the swamp king. You can eat food to grow bigger and become the mega frog, vomit to shrink, and use your long sticky tongue to swing, hang and slingshot your friends. The sewer levels are procedurally generated, so your froggy playground will always be different, and each run gets harder as the swamp king requires more food.Frog Sqwad is coming to Steam in 2026, with a playtest beforehand.Release datesDogpile by Studio Folly, Toot Games and Foot: Today, like literally right nowBig Hops by Luckhsot Games: January 12, 2026Demon Tides by Fabraz: February 19, 2026And the restThe stream featured a dozen other in-development titles, including the super spooky Lucid Falls, a 90s-grunge-band rhythm game called Rockbeasts, the soothing alien musicality of Soundgrass, an impressive-looking follow-up to The Invincible called Into the Fire, and Unshine Arcade, a creepy game about the secret lives of tamagotchis and claw machines. Day of the Devs: The Game Awards Digital Showcase 2025 wrapped up with a neat little announcement. Day of the Devs partnered with the Video Game History Foundation to release Xcavator 2025, a finished version of a long-lost game from legendary programmer Chris Oberth. It was originally developed by Big Buck Hunter studio Incredible Technologies but never found a publisher. It’s been revived by Mega Cat Studios, Retrotainment Games and iam8bit, and an NES cartridge of Xcavator 2025 is available to pre-order now on iam8bit. Proceeds will benefit the Video Game History Foundation.This article originally appeared on Engadget at https://www.engadget.com/gaming/the-world-premieres-and-other-hotness-from-the-game-awards-2025-day-of-the-devs-stream-200000447.html?src=rss",
          "content": "You gotta love that post-Day of the Devs showcase feeling. The organization, founded by Double Fine Productions and iam8bit, consistently highlights top-tier games from independent developers across the globe, providing space for creators to share their stories in both online and in-person events. This year’s Day of the Devs: The Game Awards Digital Showcase was an hour-long celebration of 22 upcoming indie games, including six world premieres and three release date announcements.Settle in and bask in the afterglow with us:World PremieresVirtue and a Sledgehammer - DeconstructeamDeconstructeam is a small Spanish studio that’s responsible for some of the most cerebral, sexy and darkly philosophical games around, including Gods Will Be Watching, The Red Strings Club and The Cosmic Wheel Sisterhood. The team’s next project is Virtue and a Sledgehammer, and it represents a new look with 3D, cel-shaded animations and a third-person perspective rather than the studio’s typical pixelated planar fare. The vibes are just as sinister and introspective as expected, though.Virtue and a Sledgehammer is a moody coming-of-age experience set in a wooded ghost town dotted with robots and lost locals. Spend quiet moments with old friends and then swing the sledgehammer to raze your hometown and uncover memories that can help you move on. The game’s buildings and objects are highly reactive, which can only help with the catharsis of it all.Virtue and a Sledgehammer is due to hit Steam in 2026, published by Devolver Digital.UN:Me - Shueisha GamesNow, this is a horror game. UN:Me comes from Japanese publisher Shueisha Games and developer Historia, and it’s a creepy, mind-bending exploration of primal fear. It stars a young woman with four souls trapped inside of her body, fighting for control of her consciousness. She wanders sterile, illogical hallways and encounters grotesque horrors representing common human fears like heights, authority figures and confined spaces. The souls switch randomly, each one manifesting a specific anxiety. As she wanders, the player has to choose souls to eliminate until only one remains. Whether it’s her real soul or a fake isn’t disclosed until the very end.UN:Me is available to wishlist now on Steam.Scramble Knights Royale - Funktronic LabsFunktronic Labs is mainly known as a VR studio, with games like Cosmic Trip, Fujii and The Light Brigade under its belt, but its latest project doesn’t require a headset at all. Scramble Knights Royale is coming to PC and Xbox in 2026, and it’s a battle royale with adventure game twists. You begin on a boat with 30 to 40 other online players, make your way to land on the back of a turtle, and then it’s essentially Naked and Afraid from there. Find resources, fight creatures, upgrade your gear and play your own game, only battling other players when you encounter them in the wild.Don’t let the sweet, clay-like animations fool you, either — Funktronic says the combat mechanics are incredibly deep and finely honed. Scramble Knights Royale also supports local split-screen. Mirria - MografiMografi made a name for itself with the adorable Jenny LeClue detective game, but now it’s time for something different. Mirria is an atmospheric puzzle experience from ISLANDS: Non-Places artist Carl Burton, published by Mografi, and it looks like a delicious mix of Kentucky Route Zero and Monument Valley. In Mirria, you explore mirror worlds and attempt to make the two realities match, paying attention to small details and making minute adjustments until the unsettling environments are perfect reflections. It looks and sounds like soul-soothing stuff.Mirria is due out in 2026 on Steam.CorgiSpace - FinjiIn recent years, Finji founder Adam Saltsman has been involved in high-profile indie games like Overlands, Night in the Woods, Tunic and Usual June, but his new project taps into his simplistic and mechanics-driven Canabalt roots. Corgispace is a collection of 8-bit games with off-kilter premises, including the soulslike Rat Dreams where you can only dodgeroll, the no-jumping platformer Skeleton Jeleton, and Prince of Prussia, an adventure where you stab Nazis “but in a fun new way,” according to Saltsman. Also, he says there are no secrets in this game, which leads us to believe there is at least one secret in this game.Corgispace is out now (!) on Steam and Itch.io.Frog Sqwad - Panic StationsIf the former Fall Guys developers at Panic Stations know how to do one thing, it’s make a silly-physics multiplayer game, so that’s exactly what they’re doing. Frog Sqwad is a co-op experience where you and your fellow frogs search the sewers for food in order to satiate the swamp king. You can eat food to grow bigger and become the mega frog, vomit to shrink, and use your long sticky tongue to swing, hang and slingshot your friends. The sewer levels are procedurally generated, so your froggy playground will always be different, and each run gets harder as the swamp king requires more food.Frog Sqwad is coming to Steam in 2026, with a playtest beforehand.Release datesDogpile by Studio Folly, Toot Games and Foot: Today, like literally right nowBig Hops by Luckhsot Games: January 12, 2026Demon Tides by Fabraz: February 19, 2026And the restThe stream featured a dozen other in-development titles, including the super spooky Lucid Falls, a 90s-grunge-band rhythm game called Rockbeasts, the soothing alien musicality of Soundgrass, an impressive-looking follow-up to The Invincible called Into the Fire, and Unshine Arcade, a creepy game about the secret lives of tamagotchis and claw machines. Day of the Devs: The Game Awards Digital Showcase 2025 wrapped up with a neat little announcement. Day of the Devs partnered with the Video Game History Foundation to release Xcavator 2025, a finished version of a long-lost game from legendary programmer Chris Oberth. It was originally developed by Big Buck Hunter studio Incredible Technologies but never found a publisher. It’s been revived by Mega Cat Studios, Retrotainment Games and iam8bit, and an NES cartridge of Xcavator 2025 is available to pre-order now on iam8bit. Proceeds will benefit the Video Game History Foundation.This article originally appeared on Engadget at https://www.engadget.com/gaming/the-world-premieres-and-other-hotness-from-the-game-awards-2025-day-of-the-devs-stream-200000447.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/12-steps-you-can-take-right-now-to-be-safer-online-130008335.html",
          "published_at": "Wed, 10 Dec 2025 19:08:43 +0000",
          "title": "12 steps you can take right now to be safer online",
          "standfirst": "There's a fundamental question you can ask of both the internet and real life: \"How do I enjoy my time here without taking unnecessary risks?\" In grass-touching meatspace, you can cut out processed foods, carry pepper spray and avoid skydiving without a partner. But the best methods for staying safe online aren't as intuitive. The internet is a massive town square where people are constantly bellowing deeply personal facts about themselves. It's no surprise that it's become a breeding ground for scams, theft and other criminal activity. Given the breadth of dangers, it may feel easier to throw up your hands and say that whatever happens will happen. I'm here to tell you, though, that cybersecurity doesn't have to be complex, difficult or time-consuming. You don't need to be a hacker to foil a hacker — you only have to take advantage of simple tips and free apps designed to make you safer online. Whether you commit to all 12 detailed here or only focus on one, you'll be much more secure for it. 1. Install security updates immediately One of the most important things you can do to ensure your digital security is to install all software updates as soon as they become available on your devices. When you see the notification, don't wait — train yourself to download the update immediately. Not all software updates are about security, but the ones that are form your best line of defense against technical hacks. When developers discover a flaw that can be exploited, they ship an update to fix it. By the time the flaw gets patched, chances are very high that hackers also know about it, so any time lost means you could be the next to get exploited. As you go down this list, you'll learn that cybersecurity threats are less technical than you think. To counter the ones that are, however, there's nothing more important you can do than install security updates. 2. Use strong passwords Weak, easily guessed passwords are one of the most frequent causes of data breaches and malware attacks. If a password is one of the ten or so most common, an attacker may be able to guess it with no other information. If it's connected to you — your birthday, say, or mother's maiden name — it may be guessable from information anyone can look up online. Even if your password is a random string of characters, it might still be guessable if it's too short. Hackers can use programs to guess all possible combinations and try each one on a target account. The longer a password is, the more exponentially difficult it is to guess. SEAN GLADWELL via Getty Images That means you need passwords that are both long and meaningless to you. You might rightly complain that these are bastards to remember, but you're in luck: password managers can do that for you. A password manager app or browser extension can create passwords when you need them, store them securely and fill them in automatically. All you have to remember is the one master password that unlocks all the others. 3. Set up two-factor authentication Even the strongest password might get revealed through no fault of your own, like if it's stored without encryption and leaked in a data breach. That's why it helps to have two-factor authentication (2FA), also known as multi-factor authentication (MFA), as a second secure layer on every account. You probably already know 2FA as the irritating extra step that makes you go get your phone — but that's not the only way to do it. Many apps, including Google and Apple, now let you log in through passkeys. These not only don't require you to enter a code or password, but use asymmetric encryption, sharing credentials between your device and the service that runs the passkeys. It's a lot quicker for you, and leaves nothing to steal. 4. Back everything up Ransomware and its cousins are a growth industry within the cybercrime economy. These attacks corrupt your files or lock you out of them until you pay a fee to get them back. The easiest way to foil a ransomware attack, or to clear any other kind of malware off a device, is to restore the entire system from the most recent backup. To make sure you actually have a backup, experts recommend the 3-2-1 rule: three different backups, on two different types of storage, with at least one physically distant from the main system. For example, you could have one backup on another device in your house, one in the cloud and one on a portable hard drive. Automatic backup services can save disk images for you at set intervals so you don't have to remember to do it yourself. 5. Learn to spot social engineering Despite all the technobabble flying around the cybersecurity world, a great many scams and hacks are accomplished through methods a 19th-century con artist would recognize. Scammers pose as experts or authority figures to gain your trust, and use frightening language to bypass your critical thinking. Ticking clocks, emotional manipulation and fake identities are all in the toolbox. Alex Cristi via Getty Images Take phishing, in which hackers trick you into giving up your information willingly. A typical phishing email might pose as a bank, credit bureau or other authoritative service. In red letters, it may demand your bank password or social security number to immediately fix an irregularity with your account. Other common approaches include warning you about speeding tickets you never incurred or sending receipts for subscriptions you never bought. Social engineering attacks are constantly evolving, but they often fall back on the same strategies. The best way to foil them is to take a deep breath every time you receive a frightening email or text message, then research it in detail: look up the email address, check the visual design to make sure the sender is who they claim to be, and ask yourself if there's any way the message could be true. I highly recommend working through this phishing quiz — it's tough, but fair, and extremely educational. 6. Always check links before clicking This is a companion to the previous tip. Social engineering scams don't always try to get you to give up information yourself. They also get you to click on links that put secret malware on your device — like keyloggers that watch you type your passwords or ransomware programs that corrupt your files. If you're ever not sure about an email attachment or a link you're being asked to click, copy the link (without opening it) and paste it into a URL checker like this one from NordVPN. These free tools can tell you if a link is associated with any known malware domains. Sam Chapman for Engadget You can also mouse over any link, then look at the bottom-left of your browser to see what URL it will take you to. If an email is from your bank, any links within it should go to your bank's website. If it's going anywhere else, especially to an unidentifiable string of characters, be suspicious. A related tip is to never copy and paste something into your URL bar if you aren't absolutely sure of what it will do. Social engineering doesn't always get you to click the link — sometimes attackers leave it un-hyperlinked so mousing over it doesn't reveal anything. This also goes for the command modules on desktop and laptop computers. In a recent documented attack, hackers convinced AI chatbots to suggest a command that gave them root access to the victim's device. Never copy-paste anything into the command window without verifying it first, especially if an AI told you to do it. 7. Don't overshare Over the last two decades, lots of us have gotten into the habit of dumping all sorts of personal information on social media. This trend has supercharged the scam economy. It may seem harmless to broadcast the names of your kids or the dates you'll be on vacation, but every piece of data you put into the world makes it easier for a stranger to get hooks into you. For example, \"grandparent scams\" are on the rise right now. Grifters contact a target, usually a senior, pretending to be their grandchild. They'll claim to be in a crisis and need money fast. The more information they have on their target, the more convincing their tale of woe will be. Social media is a prime place to study a potential victim. Oversharing can also be a compounding problem. If you use weak passwords, your public information can be used to guess your credentials or answer your security questions. So, if you don't have a password manager yet, think twice before you engage with that quiz post on Facebook that asks for the name of your childhood pet. 8. Use a VPN I'm a big booster of virtual private networks (VPNs), but it's important to be realistic about what they can and can't do. Even the best VPNs aren't total cybersecurity solutions — you can't just set one and assume you're safe forever. A VPN can't protect you if you use easily guessed passwords, for example, or click on a malware link. It's about hiding your identity, not making you invulnerable. So what can a VPN do? In short, it replaces your IP address (a fingerprint that identifies you online) with another IP address, belonging to a server owned by the VPN. The VPN server does business with the internet on your behalf, while its conversations with your device are encrypted so it can't be traced back to you. Sam Chapman for Engadget This means no third party can connect your online actions with your real-world identity. Nobody will be harvesting data on the websites you visit to sell to advertisers, nor building a file on you that an unscrupulous government might misuse. VPNs also protect you from fake public Wi-Fi networks set up by cybercriminals — even if a hacker tricks you with a man-in-the-middle attack, they can't do much without your real IP address. Many top VPNs, including my top pick Proton VPN, include ad blockers that can also keep cookies and tracking pixels from latching onto you. So, even if a VPN can't do everything, you'll be far safer and more private with one than without one. If you don’t want to pay for a new subscription right now, I've also compiled a list of the best free VPNs that are actually safe to use. 9. Run regular virus scans The most important time to look for malware is when you're downloading a file from the internet. Not only can unwanted apps hitch rides on seemingly safe files, but links can start downloads in secret, even if you don't think they're meant to be downloading anything. A solid antivirus program can catch malware as it arrives on your system, and if it's uncertain, can lock suspicious files in quarantine until it knows whether they're safe or not. Dedicated antivirus apps are sometimes even capable of catching malware that hasn't been seen or used yet. AV software uses machine learning to identify the common patterns of malware, filtering out new viruses that behave like old ones. But what about malware that's already gotten through the perimeter? An antivirus app can also check your computer at set intervals in search of unwanted apps, including those that might be masquerading as system files. Windows computers now come pre-installed with Windows Defender, which is enough to handle most of these tasks, but I recommend at least one anti-malware program on any device. 10. Use email maskers and private search engines If you're concerned about your information being misused or mishandled, remember that the less you put out into the world, the less danger you're in. Keeping your private data off social media is one important step, but there are other ways your data gets disseminated — and other options for responding. For example, you often need an email address to sign up for an online account. If you use your real email, your contact information is now floating around online, increasing the chance of someone using it to scam you (or at least adding you to mailing lists you never signed up for). To stay safe, use an email masker. These services give you a fake email address you can use to create accounts, which automatically forwards messages to your real address. Sam Chapman for Engadget Search engines, especially Google, are also notorious for building profiles on users by watching the terms they search for. You can dodge that by switching to a private search engine like DuckDuckGo, which doesn't track anything you do — it's funded by non-targeted ad sales on its search results pages, not by selling your data to brokers. 11. Use a data removal service Speaking of data brokers: unfortunately, if you've been on the internet at any point in the last 10 years without taking intense precautions, your data is probably in the hands of at least one business that makes money by hoarding and selling it. These data brokers range from public-facing, people-search sites to private backend dealers. Data brokers are poorly regulated and lax about safety. The longer one has your personal information, the more likely it is to leak. The good news is that most brokers (though not all of them) are legally required to delete your data if you ask them to. However, there are a lot of data brokers out there, and they really want to keep your data. Each one makes opting out harder than uninstalling a Norton product — and hundreds of them may have files on you. To make the process easier, you can use a data removal service like DeleteMe or Surfshark VPN's partner service Incogni. 12. Practice physical security Let's close out the list by getting a little old school. I've already discussed how many online scams depend on classic con artistry to work. By the same token, physical infiltration and smash-and-grab tactics still pose a threat to cybersecurity. It doesn't take too much imagination to see how this could work. If you leave your laptop or phone unattended in public, for example, someone might insert a flash drive that loads malware onto the system. In one illustrative case, a thief in the Minneapolis area would loiter in bars, watch people unlock their phones, then steal those phones and unlock them himself. I'm not saying you need to be paranoid every second you're in public. Just use the same level of caution you'd use to protect your car. Lock your phone with a biometric key so only you can open it, and make sure not to leave any device lying around if it can access your online accounts. And at work, be careful not to let anyone into a secure area if they don't have the proper credentials.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/12-steps-you-can-take-right-now-to-be-safer-online-130008335.html?src=rss",
          "content": "There's a fundamental question you can ask of both the internet and real life: \"How do I enjoy my time here without taking unnecessary risks?\" In grass-touching meatspace, you can cut out processed foods, carry pepper spray and avoid skydiving without a partner. But the best methods for staying safe online aren't as intuitive. The internet is a massive town square where people are constantly bellowing deeply personal facts about themselves. It's no surprise that it's become a breeding ground for scams, theft and other criminal activity. Given the breadth of dangers, it may feel easier to throw up your hands and say that whatever happens will happen. I'm here to tell you, though, that cybersecurity doesn't have to be complex, difficult or time-consuming. You don't need to be a hacker to foil a hacker — you only have to take advantage of simple tips and free apps designed to make you safer online. Whether you commit to all 12 detailed here or only focus on one, you'll be much more secure for it. 1. Install security updates immediately One of the most important things you can do to ensure your digital security is to install all software updates as soon as they become available on your devices. When you see the notification, don't wait — train yourself to download the update immediately. Not all software updates are about security, but the ones that are form your best line of defense against technical hacks. When developers discover a flaw that can be exploited, they ship an update to fix it. By the time the flaw gets patched, chances are very high that hackers also know about it, so any time lost means you could be the next to get exploited. As you go down this list, you'll learn that cybersecurity threats are less technical than you think. To counter the ones that are, however, there's nothing more important you can do than install security updates. 2. Use strong passwords Weak, easily guessed passwords are one of the most frequent causes of data breaches and malware attacks. If a password is one of the ten or so most common, an attacker may be able to guess it with no other information. If it's connected to you — your birthday, say, or mother's maiden name — it may be guessable from information anyone can look up online. Even if your password is a random string of characters, it might still be guessable if it's too short. Hackers can use programs to guess all possible combinations and try each one on a target account. The longer a password is, the more exponentially difficult it is to guess. SEAN GLADWELL via Getty Images That means you need passwords that are both long and meaningless to you. You might rightly complain that these are bastards to remember, but you're in luck: password managers can do that for you. A password manager app or browser extension can create passwords when you need them, store them securely and fill them in automatically. All you have to remember is the one master password that unlocks all the others. 3. Set up two-factor authentication Even the strongest password might get revealed through no fault of your own, like if it's stored without encryption and leaked in a data breach. That's why it helps to have two-factor authentication (2FA), also known as multi-factor authentication (MFA), as a second secure layer on every account. You probably already know 2FA as the irritating extra step that makes you go get your phone — but that's not the only way to do it. Many apps, including Google and Apple, now let you log in through passkeys. These not only don't require you to enter a code or password, but use asymmetric encryption, sharing credentials between your device and the service that runs the passkeys. It's a lot quicker for you, and leaves nothing to steal. 4. Back everything up Ransomware and its cousins are a growth industry within the cybercrime economy. These attacks corrupt your files or lock you out of them until you pay a fee to get them back. The easiest way to foil a ransomware attack, or to clear any other kind of malware off a device, is to restore the entire system from the most recent backup. To make sure you actually have a backup, experts recommend the 3-2-1 rule: three different backups, on two different types of storage, with at least one physically distant from the main system. For example, you could have one backup on another device in your house, one in the cloud and one on a portable hard drive. Automatic backup services can save disk images for you at set intervals so you don't have to remember to do it yourself. 5. Learn to spot social engineering Despite all the technobabble flying around the cybersecurity world, a great many scams and hacks are accomplished through methods a 19th-century con artist would recognize. Scammers pose as experts or authority figures to gain your trust, and use frightening language to bypass your critical thinking. Ticking clocks, emotional manipulation and fake identities are all in the toolbox. Alex Cristi via Getty Images Take phishing, in which hackers trick you into giving up your information willingly. A typical phishing email might pose as a bank, credit bureau or other authoritative service. In red letters, it may demand your bank password or social security number to immediately fix an irregularity with your account. Other common approaches include warning you about speeding tickets you never incurred or sending receipts for subscriptions you never bought. Social engineering attacks are constantly evolving, but they often fall back on the same strategies. The best way to foil them is to take a deep breath every time you receive a frightening email or text message, then research it in detail: look up the email address, check the visual design to make sure the sender is who they claim to be, and ask yourself if there's any way the message could be true. I highly recommend working through this phishing quiz — it's tough, but fair, and extremely educational. 6. Always check links before clicking This is a companion to the previous tip. Social engineering scams don't always try to get you to give up information yourself. They also get you to click on links that put secret malware on your device — like keyloggers that watch you type your passwords or ransomware programs that corrupt your files. If you're ever not sure about an email attachment or a link you're being asked to click, copy the link (without opening it) and paste it into a URL checker like this one from NordVPN. These free tools can tell you if a link is associated with any known malware domains. Sam Chapman for Engadget You can also mouse over any link, then look at the bottom-left of your browser to see what URL it will take you to. If an email is from your bank, any links within it should go to your bank's website. If it's going anywhere else, especially to an unidentifiable string of characters, be suspicious. A related tip is to never copy and paste something into your URL bar if you aren't absolutely sure of what it will do. Social engineering doesn't always get you to click the link — sometimes attackers leave it un-hyperlinked so mousing over it doesn't reveal anything. This also goes for the command modules on desktop and laptop computers. In a recent documented attack, hackers convinced AI chatbots to suggest a command that gave them root access to the victim's device. Never copy-paste anything into the command window without verifying it first, especially if an AI told you to do it. 7. Don't overshare Over the last two decades, lots of us have gotten into the habit of dumping all sorts of personal information on social media. This trend has supercharged the scam economy. It may seem harmless to broadcast the names of your kids or the dates you'll be on vacation, but every piece of data you put into the world makes it easier for a stranger to get hooks into you. For example, \"grandparent scams\" are on the rise right now. Grifters contact a target, usually a senior, pretending to be their grandchild. They'll claim to be in a crisis and need money fast. The more information they have on their target, the more convincing their tale of woe will be. Social media is a prime place to study a potential victim. Oversharing can also be a compounding problem. If you use weak passwords, your public information can be used to guess your credentials or answer your security questions. So, if you don't have a password manager yet, think twice before you engage with that quiz post on Facebook that asks for the name of your childhood pet. 8. Use a VPN I'm a big booster of virtual private networks (VPNs), but it's important to be realistic about what they can and can't do. Even the best VPNs aren't total cybersecurity solutions — you can't just set one and assume you're safe forever. A VPN can't protect you if you use easily guessed passwords, for example, or click on a malware link. It's about hiding your identity, not making you invulnerable. So what can a VPN do? In short, it replaces your IP address (a fingerprint that identifies you online) with another IP address, belonging to a server owned by the VPN. The VPN server does business with the internet on your behalf, while its conversations with your device are encrypted so it can't be traced back to you. Sam Chapman for Engadget This means no third party can connect your online actions with your real-world identity. Nobody will be harvesting data on the websites you visit to sell to advertisers, nor building a file on you that an unscrupulous government might misuse. VPNs also protect you from fake public Wi-Fi networks set up by cybercriminals — even if a hacker tricks you with a man-in-the-middle attack, they can't do much without your real IP address. Many top VPNs, including my top pick Proton VPN, include ad blockers that can also keep cookies and tracking pixels from latching onto you. So, even if a VPN can't do everything, you'll be far safer and more private with one than without one. If you don’t want to pay for a new subscription right now, I've also compiled a list of the best free VPNs that are actually safe to use. 9. Run regular virus scans The most important time to look for malware is when you're downloading a file from the internet. Not only can unwanted apps hitch rides on seemingly safe files, but links can start downloads in secret, even if you don't think they're meant to be downloading anything. A solid antivirus program can catch malware as it arrives on your system, and if it's uncertain, can lock suspicious files in quarantine until it knows whether they're safe or not. Dedicated antivirus apps are sometimes even capable of catching malware that hasn't been seen or used yet. AV software uses machine learning to identify the common patterns of malware, filtering out new viruses that behave like old ones. But what about malware that's already gotten through the perimeter? An antivirus app can also check your computer at set intervals in search of unwanted apps, including those that might be masquerading as system files. Windows computers now come pre-installed with Windows Defender, which is enough to handle most of these tasks, but I recommend at least one anti-malware program on any device. 10. Use email maskers and private search engines If you're concerned about your information being misused or mishandled, remember that the less you put out into the world, the less danger you're in. Keeping your private data off social media is one important step, but there are other ways your data gets disseminated — and other options for responding. For example, you often need an email address to sign up for an online account. If you use your real email, your contact information is now floating around online, increasing the chance of someone using it to scam you (or at least adding you to mailing lists you never signed up for). To stay safe, use an email masker. These services give you a fake email address you can use to create accounts, which automatically forwards messages to your real address. Sam Chapman for Engadget Search engines, especially Google, are also notorious for building profiles on users by watching the terms they search for. You can dodge that by switching to a private search engine like DuckDuckGo, which doesn't track anything you do — it's funded by non-targeted ad sales on its search results pages, not by selling your data to brokers. 11. Use a data removal service Speaking of data brokers: unfortunately, if you've been on the internet at any point in the last 10 years without taking intense precautions, your data is probably in the hands of at least one business that makes money by hoarding and selling it. These data brokers range from public-facing, people-search sites to private backend dealers. Data brokers are poorly regulated and lax about safety. The longer one has your personal information, the more likely it is to leak. The good news is that most brokers (though not all of them) are legally required to delete your data if you ask them to. However, there are a lot of data brokers out there, and they really want to keep your data. Each one makes opting out harder than uninstalling a Norton product — and hundreds of them may have files on you. To make the process easier, you can use a data removal service like DeleteMe or Surfshark VPN's partner service Incogni. 12. Practice physical security Let's close out the list by getting a little old school. I've already discussed how many online scams depend on classic con artistry to work. By the same token, physical infiltration and smash-and-grab tactics still pose a threat to cybersecurity. It doesn't take too much imagination to see how this could work. If you leave your laptop or phone unattended in public, for example, someone might insert a flash drive that loads malware onto the system. In one illustrative case, a thief in the Minneapolis area would loiter in bars, watch people unlock their phones, then steal those phones and unlock them himself. I'm not saying you need to be paranoid every second you're in public. Just use the same level of caution you'd use to protect your car. Lock your phone with a biometric key so only you can open it, and make sure not to leave any device lying around if it can access your online accounts. And at work, be careful not to let anyone into a secure area if they don't have the proper credentials.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/12-steps-you-can-take-right-now-to-be-safer-online-130008335.html?src=rss",
          "feed_position": 9,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-05/953644c0-f013-11ed-8bdf-a2cfeb7310a6"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/hackers-tricked-chatgpt-grok-and-google-into-helping-them-install-malware-185711492.html",
          "published_at": "Wed, 10 Dec 2025 18:57:11 +0000",
          "title": "Hackers tricked ChatGPT, Grok and Google into helping them install malware",
          "standfirst": "Ever since reporting earlier this year on how easy it is to trick an agentic browser, I've been following the intersections between modern AI and old-school scams. Now, there's a new convergence on the horizon: hackers are apparently using AI prompts to seed Google search results with dangerous commands. When executed by unknowing users, these commands prompt computers to give the hackers the access they need to install malware. The warning comes by way of a recent report from detection-and-response firm Huntress. Here's how it works. First, the threat actor has a conversation with an AI assistant about a common search term, during which they prompt the AI to suggest pasting a certain command into a computer's terminal. They make the chat publicly visible and pay to boost it on Google. From then on, whenever someone searches for the term, the malicious instructions will show up high on the first page of results. Huntress ran tests on both ChatGPT and Grok after discovering that a Mac-targeting data exfiltration attack called AMOS had originated from a simple Google search. The user of the infected device had searched \"clear disk space on Mac,\" clicked a sponsored ChatGPT link and — lacking the training to see that the advice was hostile — executed the command. This let the attackers install the AMOS malware. The testers discovered that both chatbots replicated the attack vector. As Huntress points out, the evil genius of this attack is that it bypasses almost all the traditional red flags we've been taught to look for. The victim doesn't have to download a file, install a suspicious executable or even click a shady link. The only things they have to trust are Google and ChatGPT, which they've either used before or heard about nonstop for the last several years. They're primed to trust what those sources tell them. Even worse, while the link to the ChatGPT conversation has since been taken off Google, it was up for at least half a day after Huntress published their blog post. This news comes at a time that's already fraught for both AIs. Grok has been getting dunked on for sucking up to Elon Musk in despicable ways, while ChatGPT creator OpenAI has been falling behind the competition. It's not yet clear if the attack can be replicated with other chatbots, but for now, I strongly recommend using caution. Alongside your other common-sense cybersecurity steps, make sure to never paste anything into your command terminal or your browser URL bar if you aren't certain of what it will do.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/hackers-tricked-chatgpt-grok-and-google-into-helping-them-install-malware-185711492.html?src=rss",
          "content": "Ever since reporting earlier this year on how easy it is to trick an agentic browser, I've been following the intersections between modern AI and old-school scams. Now, there's a new convergence on the horizon: hackers are apparently using AI prompts to seed Google search results with dangerous commands. When executed by unknowing users, these commands prompt computers to give the hackers the access they need to install malware. The warning comes by way of a recent report from detection-and-response firm Huntress. Here's how it works. First, the threat actor has a conversation with an AI assistant about a common search term, during which they prompt the AI to suggest pasting a certain command into a computer's terminal. They make the chat publicly visible and pay to boost it on Google. From then on, whenever someone searches for the term, the malicious instructions will show up high on the first page of results. Huntress ran tests on both ChatGPT and Grok after discovering that a Mac-targeting data exfiltration attack called AMOS had originated from a simple Google search. The user of the infected device had searched \"clear disk space on Mac,\" clicked a sponsored ChatGPT link and — lacking the training to see that the advice was hostile — executed the command. This let the attackers install the AMOS malware. The testers discovered that both chatbots replicated the attack vector. As Huntress points out, the evil genius of this attack is that it bypasses almost all the traditional red flags we've been taught to look for. The victim doesn't have to download a file, install a suspicious executable or even click a shady link. The only things they have to trust are Google and ChatGPT, which they've either used before or heard about nonstop for the last several years. They're primed to trust what those sources tell them. Even worse, while the link to the ChatGPT conversation has since been taken off Google, it was up for at least half a day after Huntress published their blog post. This news comes at a time that's already fraught for both AIs. Grok has been getting dunked on for sucking up to Elon Musk in despicable ways, while ChatGPT creator OpenAI has been falling behind the competition. It's not yet clear if the attack can be replicated with other chatbots, but for now, I strongly recommend using caution. Alongside your other common-sense cybersecurity steps, make sure to never paste anything into your command terminal or your browser URL bar if you aren't certain of what it will do.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/hackers-tricked-chatgpt-grok-and-google-into-helping-them-install-malware-185711492.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html",
          "published_at": "Wed, 10 Dec 2025 17:29:06 +0000",
          "title": "The best VPN deals: Up to 88 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "With a good virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart those online trackers that watch you sleep and show you weird personalized ads. Although we strongly recommend using a VPN, you shouldn't jump on just any deal — a bit of comparison shopping goes a long way in this market. The pricing you see on VPN websites is often not an accurate portrayal of what you'll actually pay. Even so, there are some great bargains on the table. Black Friday and Cyber Monday may be over, but lots of the best VPNs — including our top pick, Proton VPN — have end-of-year deals live that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're sure you like the service, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals below follow that pattern, so make sure you're comfortable with a service before you take the plunge. Read on for the best VPN deals live this week. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This holiday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another holiday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "content": "With a good virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart those online trackers that watch you sleep and show you weird personalized ads. Although we strongly recommend using a VPN, you shouldn't jump on just any deal — a bit of comparison shopping goes a long way in this market. The pricing you see on VPN websites is often not an accurate portrayal of what you'll actually pay. Even so, there are some great bargains on the table. Black Friday and Cyber Monday may be over, but lots of the best VPNs — including our top pick, Proton VPN — have end-of-year deals live that can save you anywhere from 67 to 88 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but as long as you're sure you like the service, committing actually makes sense. You pay more at the start, but if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals below follow that pattern, so make sure you're comfortable with a service before you take the plunge. Read on for the best VPN deals live this week. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This holiday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another holiday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "feed_position": 15
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openais-house-of-cards-seems-primed-to-collapse-170000900.html",
          "published_at": "Wed, 10 Dec 2025 17:00:00 +0000",
          "title": "OpenAI's house of cards seems primed to collapse",
          "standfirst": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago. Back in 2022, the sudden popularity of ChatGPT sent Google into a panic. The company was so worried about the possibility of the upstart chatbot disrupting its Search business, executives sounded a \"code red\" alert inside of the company and called Sergey Brin and Larry Page out of retirement to help it formulate a response to OpenAI. It then rushed out Bard, announcing its first commercial chatbot on February 6, 2023. Google's stock tanked days later when the AI incorrectly answered a question about NASA's James Webb Space Telescope during a public demo. But it wasn't just Google that wanted a piece of OpenAI, while the search giant sought to compete with it, others — including Microsoft and Apple — made deals with the company to bring its technology to their products and services, all the promise that AI would eventually revolutionize every facet of the economy. Since then, OpenAI has seen its lead against Google and much of the AI industry evaporate, culminating in a series of successive blows throughout 2025. On January 20, the same day Altman was busy rubbing shoulders with other tech oligarchs at Donald Trump’s inauguration, China’s DeepSeek quietly released its R1 chain-of-thought model. A week later, the startup's chatbot surpassed ChatGPT as the most-download free app on the US App Store. The overnight success of DeepSeek eliminated $1 trillion worth of stock market value, and almost certainly left OpenAI blindsided.In response, the company showed a newfound urgency. In one week, for instance, OpenAI released both o3-mini and Deep Research. It even went so far as to announce the latter on a Sunday evening. But for all its new urgency, OpenAI's biggest, most important release of the year was a miss. It's safe to say GPT-5 hasn't lived up to anyone's expectations, including OpenAI's own. The company touted the system as smarter, faster and better than all of its previous models, but after users got their hands on it, they complained of a chatbot that made surprisingly dumb mistakes and didn't have much of a personality. For many, GPT-5 felt like a downgrade compared to the older, simpler GPT-4o. That's a position no AI company wants to be in, let alone one that has taken on as much investment as OpenAI. Anthropic was quick to take advantage of the weakness, signing a deal with Microsoft to bring its Claude models to Copilot 365. Previously, Microsoft depended exclusively on OpenAI for partner models in Copilot. Before the company announced the integration, reporting from The Information said Microsoft made the decision based on the strength of Anthropic's Sonnet 4.0 model, judging it \"perform[ed] better in subtle but important ways\" relative to OpenAI's offerings. However, what will likely go down as the defining moment occurred a few short weeks after OpenAI announced the conclusion of its restructuring. On November 18, Google released Gemini 3 Pro, and immediately the new model leap-frogged the competition, including GPT-5. As of the writing of this article, Google's new model is at the top of LMArena, the site where humans compare outputs from different AI systems and vote on the best one. GPT-5, by contrast, is currently ranked sixth overall, behind models from Anthropic and Elon Musk's xAI. According to a December 2 report from The Wall Street Journal, Sam Altman sent a companywide memo following the release of Gemini 3 Pro. Echoing the words Google used to describe the situation it found itself against OpenAI in 2023, he called for a \"code red\" effort to improve ChatGPT. Altman reportedly told employees there would be temporary reassignments and that the company would delay some products, all in an effort to catch up to Google and Anthropic. The few numbers these companies are willing to share don't paint a promising picture for OpenAI. Each month, about 800 million people use ChatGPT. On paper, that's impressive, but Google is catching up there too. In October, the company said the Gemini app had 650 million users, up from 450 million just a few months earlier in July, thanks to the popularity of its Nano Banana Pro image generator. More importantly, OpenAI has an inherent disadvantage against Google. For the search giant, AI may touch everything the company does now, but Gemini is just one product in an extensive portfolio that includes many other popular services. Google can fund its AI advancements with money it makes elsewhere. OpenAI cannot say the same. The company is constantly raising money to stay afloat, and according to a financial roadmap obtained by The Journal, it will need its revenue to grow to about $200 billion annually to become profitable by 2030. In November, Altman said on X the company was on track to hit above $20 billion in annualized revenue this year. In an effort to grow revenue, Altman and company have adopted an incredibly risky strategy. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals in a bid to outscale the competition that is already beating it. Many of those agreements can only be described as circular, and I think the fears about a financial bubble are real. In the first half of 2025, investment in data centers accounted for nearly all of US GDP growth. Even if there's not a repeat of the 2008 housing market crisis or the dot-com crash, the AI boom is at the very least poised to make everyday electronics (and utilities) more expensive for regular people in the short term.Since late October, demand for server-grade computer components, including memory and storage, has sent the price of consumer PC parts skyrocketing as manufacturers devote more of their production capacity and wafers to high-margin customers like OpenAI and Google. Since late October, the cost of most RAM kits has doubled and tripled. In November, the price of some SSDs went up by as much as 60 percent. Next year, the cost of LPDDR5X memory, which is used in both smartphones and NVIDIA servers, is expected to climb as well. \"Be it carmakers, smartphones or consumer electronics, everyone that uses memory is facing pressure from price hikes and supply constraints in the coming year,\" Zhao Haijun, the co-CEO of memory manufacturer SMIC told analysts, per Bloomberg.Gita Gopinath, former chief economist for the International Monetary Fund, recently estimated that if the AI bubble were to burst, it would wipe out $20 trillion in wealth held by American households. The Great Recession, considered the worst financial meltdown since the Great Depression, reduced US household net worth by $11.5 trillion, and it took years before for American families to rebuild their wealth to pre-recession levels. The modern AI bubble may have been started by ChatGPT, but given the crowded field of chatbots and LLMs, it won't necessarily pop should OpenAI go bust. With novelty and technical prowess no longer on its side though, it's now on Altman to prove in short order why his company still deserves such unprecedented levels of investment. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-house-of-cards-seems-primed-to-collapse-170000900.html?src=rss",
          "content": "OpenAI is in a far less commanding position than it was following the public release of ChatGPT a few short years ago. Back in 2022, the sudden popularity of ChatGPT sent Google into a panic. The company was so worried about the possibility of the upstart chatbot disrupting its Search business, executives sounded a \"code red\" alert inside of the company and called Sergey Brin and Larry Page out of retirement to help it formulate a response to OpenAI. It then rushed out Bard, announcing its first commercial chatbot on February 6, 2023. Google's stock tanked days later when the AI incorrectly answered a question about NASA's James Webb Space Telescope during a public demo. But it wasn't just Google that wanted a piece of OpenAI, while the search giant sought to compete with it, others — including Microsoft and Apple — made deals with the company to bring its technology to their products and services, all the promise that AI would eventually revolutionize every facet of the economy. Since then, OpenAI has seen its lead against Google and much of the AI industry evaporate, culminating in a series of successive blows throughout 2025. On January 20, the same day Altman was busy rubbing shoulders with other tech oligarchs at Donald Trump’s inauguration, China’s DeepSeek quietly released its R1 chain-of-thought model. A week later, the startup's chatbot surpassed ChatGPT as the most-download free app on the US App Store. The overnight success of DeepSeek eliminated $1 trillion worth of stock market value, and almost certainly left OpenAI blindsided.In response, the company showed a newfound urgency. In one week, for instance, OpenAI released both o3-mini and Deep Research. It even went so far as to announce the latter on a Sunday evening. But for all its new urgency, OpenAI's biggest, most important release of the year was a miss. It's safe to say GPT-5 hasn't lived up to anyone's expectations, including OpenAI's own. The company touted the system as smarter, faster and better than all of its previous models, but after users got their hands on it, they complained of a chatbot that made surprisingly dumb mistakes and didn't have much of a personality. For many, GPT-5 felt like a downgrade compared to the older, simpler GPT-4o. That's a position no AI company wants to be in, let alone one that has taken on as much investment as OpenAI. Anthropic was quick to take advantage of the weakness, signing a deal with Microsoft to bring its Claude models to Copilot 365. Previously, Microsoft depended exclusively on OpenAI for partner models in Copilot. Before the company announced the integration, reporting from The Information said Microsoft made the decision based on the strength of Anthropic's Sonnet 4.0 model, judging it \"perform[ed] better in subtle but important ways\" relative to OpenAI's offerings. However, what will likely go down as the defining moment occurred a few short weeks after OpenAI announced the conclusion of its restructuring. On November 18, Google released Gemini 3 Pro, and immediately the new model leap-frogged the competition, including GPT-5. As of the writing of this article, Google's new model is at the top of LMArena, the site where humans compare outputs from different AI systems and vote on the best one. GPT-5, by contrast, is currently ranked sixth overall, behind models from Anthropic and Elon Musk's xAI. According to a December 2 report from The Wall Street Journal, Sam Altman sent a companywide memo following the release of Gemini 3 Pro. Echoing the words Google used to describe the situation it found itself against OpenAI in 2023, he called for a \"code red\" effort to improve ChatGPT. Altman reportedly told employees there would be temporary reassignments and that the company would delay some products, all in an effort to catch up to Google and Anthropic. The few numbers these companies are willing to share don't paint a promising picture for OpenAI. Each month, about 800 million people use ChatGPT. On paper, that's impressive, but Google is catching up there too. In October, the company said the Gemini app had 650 million users, up from 450 million just a few months earlier in July, thanks to the popularity of its Nano Banana Pro image generator. More importantly, OpenAI has an inherent disadvantage against Google. For the search giant, AI may touch everything the company does now, but Gemini is just one product in an extensive portfolio that includes many other popular services. Google can fund its AI advancements with money it makes elsewhere. OpenAI cannot say the same. The company is constantly raising money to stay afloat, and according to a financial roadmap obtained by The Journal, it will need its revenue to grow to about $200 billion annually to become profitable by 2030. In November, Altman said on X the company was on track to hit above $20 billion in annualized revenue this year. In an effort to grow revenue, Altman and company have adopted an incredibly risky strategy. In recent months, OpenAI has signed more than $1.4 trillion worth of infrastructure deals in a bid to outscale the competition that is already beating it. Many of those agreements can only be described as circular, and I think the fears about a financial bubble are real. In the first half of 2025, investment in data centers accounted for nearly all of US GDP growth. Even if there's not a repeat of the 2008 housing market crisis or the dot-com crash, the AI boom is at the very least poised to make everyday electronics (and utilities) more expensive for regular people in the short term.Since late October, demand for server-grade computer components, including memory and storage, has sent the price of consumer PC parts skyrocketing as manufacturers devote more of their production capacity and wafers to high-margin customers like OpenAI and Google. Since late October, the cost of most RAM kits has doubled and tripled. In November, the price of some SSDs went up by as much as 60 percent. Next year, the cost of LPDDR5X memory, which is used in both smartphones and NVIDIA servers, is expected to climb as well. \"Be it carmakers, smartphones or consumer electronics, everyone that uses memory is facing pressure from price hikes and supply constraints in the coming year,\" Zhao Haijun, the co-CEO of memory manufacturer SMIC told analysts, per Bloomberg.Gita Gopinath, former chief economist for the International Monetary Fund, recently estimated that if the AI bubble were to burst, it would wipe out $20 trillion in wealth held by American households. The Great Recession, considered the worst financial meltdown since the Great Depression, reduced US household net worth by $11.5 trillion, and it took years before for American families to rebuild their wealth to pre-recession levels. The modern AI bubble may have been started by ChatGPT, but given the crowded field of chatbots and LLMs, it won't necessarily pop should OpenAI go bust. With novelty and technical prowess no longer on its side though, it's now on Altman to prove in short order why his company still deserves such unprecedented levels of investment. This article originally appeared on Engadget at https://www.engadget.com/ai/openais-house-of-cards-seems-primed-to-collapse-170000900.html?src=rss",
          "feed_position": 18
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/the-ai-that-scored-95-until-consultants-learned-it-was-ai",
          "published_at": "Wed, 10 Dec 2025 15:00:00 GMT",
          "title": "The AI that scored 95% — until consultants learned it was AI",
          "standfirst": "Presented by SAPWhen SAP ran a quiet internal experiment to gauge consultant attitudes toward AI, the results were striking. Five teams were asked to validate answers to more than 1,000 business requirements completed by SAP’s AI co-pilot, Joule for Consultants — a workload that would normally take several weeks.Four teams were told the analysis had been completed by junior interns fresh out of school. They reviewed the material, found it impressive, and rated the work about 95% accurate.The fifth team was told the very same answers had come from AI.They rejected almost everything.Only when asked to validate each answer one by one did they discover that the AI was, in fact, highly accurate — surfacing detailed insights the consultants had initially dismissed. The overall accuracy? Again, about 95%.“The lesson learned here is that we need to be very cautious as we introduce AI — especially in how we communicate with senior consultants about its possibilities and how to integrate it into their workflows,” says Guillermo B. Vazquez Mendez, chief architect, RI business transformation and architecture, SAP America Inc.The experiment has since become a revealing starting point for SAP’s push toward the consultant of 2030: a practitioner who is deeply human, enabled by AI, and no longer weighed down by the technical grunt work of the past.Overcoming AI skepticismResistance isn’t surprising, Vazquez notes. Consultants with two or three decades of experience carry enormous institutional knowledge — and an understandable degree of caution.But AI copilots like Joule for Consultants are not replacing expertise. They’re amplifying it.“What Joule really does is make their very expensive time far more effective,” Vazquez says. “It removes the clerical work, so they can focus on turning out high-quality answers in a fraction of the time.”He emphasizes this message constantly: “AI is not replacing you. It’s a tool for you. Human oversight is always required. But now, instead of spending your time looking for documentation, you’re gaining significant time and boosting the effectiveness and detail of your answers.”The consultant time-shift: from tech execution to business insightHistorically, consultants spent about 80% of their time understanding technical systems — how processes run, how data flows, how functions execute. Customers, by contrast, spend 80% of their time focused on their business.That mismatch is exactly where Joule steps in.“There’s a gap there — and the bridge is AI,” Vazquez says. “It flips the time equation, enabling consultants to invest more of their energy in understanding the customer’s industry and business goals. AI takes on the heavy technical lift, so consultants can focus on driving the right business outcomes.”Bringing new consultants up to speedAI is also transforming how new hires learn.“We’re excited to see Joule acting as a bridge between senior consultants, who are adapting more slowly, and interns and new consultants who are already technically savvy,” Vazquez says.Junior consultants ramp up faster because Joule helps them operate independently. Seniors, meanwhile, engage where their insight matters most.This is also where many consultants learn the fundamentals of today’s AI copilots. Much of the work depends on prompt engineering — for instance, instructing Joule to act as a senior chief technology architect specializing in finance and SAP S/4HANA 2023, then asking it to analyze business requirements and deliver the output as tables or PowerPoint slides.Once they grasp how to frame prompts, consultants consistently get higher-quality, more structured answers.New architects are also able to communicate more clearly with their more experienced counterparts. They know what they don’t know and can ask targeted questions, which makes mentorship far smoother. It’s created a real synergy, Vazquez adds — senior consultants see how quickly new hires are adapting and learning with AI, and that momentum encourages them to keep pace and adopt the technology themselves.Looking ahead to the future of AI copilots“We’re still in the baby steps of AI — we’re toddlers,” Vazquez says. “Right now, copilots depend on prompt engineering to get good answers. The better you prompt, the better the answer you get.”But that represents only the earliest phase of what these systems will eventually do. As copilots mature, they’ll move beyond responding to prompts and start interpreting entire business processes — understanding the sequence of steps, identifying where human intervention is needed, and spotting where an AI agent could take over. That shift is what leads directly into agentic AI.SAP’s depth of process knowledge is what makes that evolution possible. The company has mapped more than 3,500 business processes across industries — a repository Vazquez calls “some of the most valuable, rigorously tested processes developed in the last 50 years.” Every day, SAP systems support roughly $7.3 trillion in global commerce, giving these emerging AI agents a rich foundation to navigate and reason over.“With that level of process insight and data, we can take a real leap forward,” he says, “equipping our consultants with agentic AI that can solve complex challenges and push us toward increasingly autonomous systems.” Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by SAPWhen SAP ran a quiet internal experiment to gauge consultant attitudes toward AI, the results were striking. Five teams were asked to validate answers to more than 1,000 business requirements completed by SAP’s AI co-pilot, Joule for Consultants — a workload that would normally take several weeks.Four teams were told the analysis had been completed by junior interns fresh out of school. They reviewed the material, found it impressive, and rated the work about 95% accurate.The fifth team was told the very same answers had come from AI.They rejected almost everything.Only when asked to validate each answer one by one did they discover that the AI was, in fact, highly accurate — surfacing detailed insights the consultants had initially dismissed. The overall accuracy? Again, about 95%.“The lesson learned here is that we need to be very cautious as we introduce AI — especially in how we communicate with senior consultants about its possibilities and how to integrate it into their workflows,” says Guillermo B. Vazquez Mendez, chief architect, RI business transformation and architecture, SAP America Inc.The experiment has since become a revealing starting point for SAP’s push toward the consultant of 2030: a practitioner who is deeply human, enabled by AI, and no longer weighed down by the technical grunt work of the past.Overcoming AI skepticismResistance isn’t surprising, Vazquez notes. Consultants with two or three decades of experience carry enormous institutional knowledge — and an understandable degree of caution.But AI copilots like Joule for Consultants are not replacing expertise. They’re amplifying it.“What Joule really does is make their very expensive time far more effective,” Vazquez says. “It removes the clerical work, so they can focus on turning out high-quality answers in a fraction of the time.”He emphasizes this message constantly: “AI is not replacing you. It’s a tool for you. Human oversight is always required. But now, instead of spending your time looking for documentation, you’re gaining significant time and boosting the effectiveness and detail of your answers.”The consultant time-shift: from tech execution to business insightHistorically, consultants spent about 80% of their time understanding technical systems — how processes run, how data flows, how functions execute. Customers, by contrast, spend 80% of their time focused on their business.That mismatch is exactly where Joule steps in.“There’s a gap there — and the bridge is AI,” Vazquez says. “It flips the time equation, enabling consultants to invest more of their energy in understanding the customer’s industry and business goals. AI takes on the heavy technical lift, so consultants can focus on driving the right business outcomes.”Bringing new consultants up to speedAI is also transforming how new hires learn.“We’re excited to see Joule acting as a bridge between senior consultants, who are adapting more slowly, and interns and new consultants who are already technically savvy,” Vazquez says.Junior consultants ramp up faster because Joule helps them operate independently. Seniors, meanwhile, engage where their insight matters most.This is also where many consultants learn the fundamentals of today’s AI copilots. Much of the work depends on prompt engineering — for instance, instructing Joule to act as a senior chief technology architect specializing in finance and SAP S/4HANA 2023, then asking it to analyze business requirements and deliver the output as tables or PowerPoint slides.Once they grasp how to frame prompts, consultants consistently get higher-quality, more structured answers.New architects are also able to communicate more clearly with their more experienced counterparts. They know what they don’t know and can ask targeted questions, which makes mentorship far smoother. It’s created a real synergy, Vazquez adds — senior consultants see how quickly new hires are adapting and learning with AI, and that momentum encourages them to keep pace and adopt the technology themselves.Looking ahead to the future of AI copilots“We’re still in the baby steps of AI — we’re toddlers,” Vazquez says. “Right now, copilots depend on prompt engineering to get good answers. The better you prompt, the better the answer you get.”But that represents only the earliest phase of what these systems will eventually do. As copilots mature, they’ll move beyond responding to prompts and start interpreting entire business processes — understanding the sequence of steps, identifying where human intervention is needed, and spotting where an AI agent could take over. That shift is what leads directly into agentic AI.SAP’s depth of process knowledge is what makes that evolution possible. The company has mapped more than 3,500 business processes across industries — a repository Vazquez calls “some of the most valuable, rigorously tested processes developed in the last 50 years.” Every day, SAP systems support roughly $7.3 trillion in global commerce, giving these emerging AI agents a rich foundation to navigate and reason over.“With that level of process insight and data, we can take a real leap forward,” he says, “equipping our consultants with agentic AI that can solve complex challenges and push us toward increasingly autonomous systems.” Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7IoiYyTs0K9D4WfYDzJvhy/f6bb93584c65f055662926cf6ed9d467/AdobeStock_571280209.jpeg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/projectors-won-us-over-in-2025-143655492.html",
          "published_at": "Wed, 10 Dec 2025 14:36:55 +0000",
          "title": "Projectors won us over in 2025",
          "standfirst": "Not long ago, you may have thought of projectors as complicated, unreliable or just too expensive. In 2025, though, consumer sentiment started to flip. Companies like Anker and Valerion made the projector experience more practical and immersive, helping drive consumer interest and, ultimately, sales. This shift has been quite a few years in the making. LG helped kickstart the projector renaissance back at CES 2018 when it introduced its unusual-looking CineBeam HU80K projector that could provide a 150-inch image. The next year at CES saw the dawn of the ultra short-throw (UST) laser projector that could create a similarly large display while sitting just inches from your wall. Another big technological upgrade over the following years was the bright and long-lasting laser light engines that replaced weaker, more fragile bulbs. The timing couldn’t have been better for projector manufacturers. When COVID shut down theaters in 2020, consumers were forced to get their entertainment at home. Many wanted something akin to a movie theater experience — both indoors and out — and thus interest in projectors started to take off. In 2025, though, projectors really entered the zeitgeist thanks to two new products. The first was Anker’s SoundCore Nebula X1, the highest-rated home theater product Engadget reviewed this year. It comes with a triple-laser engine that allows for 3,500 lumens of brightness — enough that you can watch it during the day. It also uses liquid cooling to reduce annoying fan noise and offers color-accurate picture quality with support for Dolby Vision HDR. Even better, it can be carried outside easily via the retractable handle and used for movie nights under the stars. If you splurge for the Soundcore Nebula X1 Pro version that comes with huge party speakers, you can even expect excellent sound quality. It also looks sleek and modern, unlike the plasticky models normally aimed at mid-range buyers. However, the most interesting feature — which is new for a projector in this price range — is the motorized tilting lens that automatically fits the picture to your screen or surface. That allows buyers to set up the Nebula X1 themselves in just a few minutes, rather than hours. That also makes it easy to move the projector around and use in another location. Valerion The other model that captured our imagination was the Valerion VisionMaster Max. This projector shares many traits of the Nebula X1, like Dolby Vision, a triple laser system and automatic setup. It’s also a nice-looking, modern product. However, it has two other innovations that made it extra interesting. The first is the dynamic iris and its Enhanced Black Level technology. That had reviewers raving about its deep black levels that were comparable to projectors like JVC’s NZ8 that cost twice as much. The other is the so-called anti-rainbow technology, which eliminates most of the rainbow-hued strobing that appears with models using Texas Instruments DLP chips. This resolves a common complaint with mid-range projectors. For a similar price as a good quality TV ($1,500 - $3,000), these models can beam an image double the size. And to install one, you just need to position the projector in front of the screen, roughly center it and hit “calibrate” to get a perfect image. Both the X1 and VisionMaster Max were first announced on Kickstarter and became the top two projectors ever sold on the site. Plus, several projector models, particularly from Anker/Soundcore, appeared on Google’s gadget search trends. All of that is helping the home projector market increase to the point that it’s, well, projected to nearly double by 2030. As people researched these products, they may have noticed the other advantages. Along with movies, they’re also great for gaming and sports, particularly if you have a big group of people. In fact, they actually take up less room than a TV if both the projector and screen are ceiling mounted. And many models are portable, battery-powered and bright enough to use outside for parties and camping. Steve Dent for Engadget A prime example of a recent projector convert is Engadget editor and cinema podcaster Devindra Hardawar, who explained why he decided to make the leap. “I know big TVs have gotten cheaper, but they still can't reach the massive 120-inch screen size of my Formovie ultra-short throw projector,” he said. “It makes watching anything feel truly cinematic, and not like I'm just staring at another screen.” Even though projectors are gaining some ground, they won’t replace TVs for most people. Mid-range televisions still cost less at around $1,000. TVs are obviously easier to install and more convenient to use, as all projectors need time to warm up. TVs are much brighter, too: even dim models put out at least 500 nits of brightness, compared to 200 to 300 nits max for very bright projectors. However, even though projector setups are less tricky than before, you still need to buy and install a screen for optimal performance, which adds cost and complexity. How much more can projectors improve? I think they’ll continue to get brighter, more color accurate and even easier to install. Another piece of technology with potential to reduce complexity and improve image quality is the roll-up screen. If those come down in price enough, they may convince some buyers to replace their TVs with a projector. They’re still likely to remain a niche product, but for cinephiles who want a theater-like experience, projectors are now a more compelling option.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/projectors-won-us-over-in-2025-143655492.html?src=rss",
          "content": "Not long ago, you may have thought of projectors as complicated, unreliable or just too expensive. In 2025, though, consumer sentiment started to flip. Companies like Anker and Valerion made the projector experience more practical and immersive, helping drive consumer interest and, ultimately, sales. This shift has been quite a few years in the making. LG helped kickstart the projector renaissance back at CES 2018 when it introduced its unusual-looking CineBeam HU80K projector that could provide a 150-inch image. The next year at CES saw the dawn of the ultra short-throw (UST) laser projector that could create a similarly large display while sitting just inches from your wall. Another big technological upgrade over the following years was the bright and long-lasting laser light engines that replaced weaker, more fragile bulbs. The timing couldn’t have been better for projector manufacturers. When COVID shut down theaters in 2020, consumers were forced to get their entertainment at home. Many wanted something akin to a movie theater experience — both indoors and out — and thus interest in projectors started to take off. In 2025, though, projectors really entered the zeitgeist thanks to two new products. The first was Anker’s SoundCore Nebula X1, the highest-rated home theater product Engadget reviewed this year. It comes with a triple-laser engine that allows for 3,500 lumens of brightness — enough that you can watch it during the day. It also uses liquid cooling to reduce annoying fan noise and offers color-accurate picture quality with support for Dolby Vision HDR. Even better, it can be carried outside easily via the retractable handle and used for movie nights under the stars. If you splurge for the Soundcore Nebula X1 Pro version that comes with huge party speakers, you can even expect excellent sound quality. It also looks sleek and modern, unlike the plasticky models normally aimed at mid-range buyers. However, the most interesting feature — which is new for a projector in this price range — is the motorized tilting lens that automatically fits the picture to your screen or surface. That allows buyers to set up the Nebula X1 themselves in just a few minutes, rather than hours. That also makes it easy to move the projector around and use in another location. Valerion The other model that captured our imagination was the Valerion VisionMaster Max. This projector shares many traits of the Nebula X1, like Dolby Vision, a triple laser system and automatic setup. It’s also a nice-looking, modern product. However, it has two other innovations that made it extra interesting. The first is the dynamic iris and its Enhanced Black Level technology. That had reviewers raving about its deep black levels that were comparable to projectors like JVC’s NZ8 that cost twice as much. The other is the so-called anti-rainbow technology, which eliminates most of the rainbow-hued strobing that appears with models using Texas Instruments DLP chips. This resolves a common complaint with mid-range projectors. For a similar price as a good quality TV ($1,500 - $3,000), these models can beam an image double the size. And to install one, you just need to position the projector in front of the screen, roughly center it and hit “calibrate” to get a perfect image. Both the X1 and VisionMaster Max were first announced on Kickstarter and became the top two projectors ever sold on the site. Plus, several projector models, particularly from Anker/Soundcore, appeared on Google’s gadget search trends. All of that is helping the home projector market increase to the point that it’s, well, projected to nearly double by 2030. As people researched these products, they may have noticed the other advantages. Along with movies, they’re also great for gaming and sports, particularly if you have a big group of people. In fact, they actually take up less room than a TV if both the projector and screen are ceiling mounted. And many models are portable, battery-powered and bright enough to use outside for parties and camping. Steve Dent for Engadget A prime example of a recent projector convert is Engadget editor and cinema podcaster Devindra Hardawar, who explained why he decided to make the leap. “I know big TVs have gotten cheaper, but they still can't reach the massive 120-inch screen size of my Formovie ultra-short throw projector,” he said. “It makes watching anything feel truly cinematic, and not like I'm just staring at another screen.” Even though projectors are gaining some ground, they won’t replace TVs for most people. Mid-range televisions still cost less at around $1,000. TVs are obviously easier to install and more convenient to use, as all projectors need time to warm up. TVs are much brighter, too: even dim models put out at least 500 nits of brightness, compared to 200 to 300 nits max for very bright projectors. However, even though projector setups are less tricky than before, you still need to buy and install a screen for optimal performance, which adds cost and complexity. How much more can projectors improve? I think they’ll continue to get brighter, more color accurate and even easier to install. Another piece of technology with potential to reduce complexity and improve image quality is the roll-up screen. If those come down in price enough, they may convince some buyers to replace their TVs with a projector. They’re still likely to remain a niche product, but for cinephiles who want a theater-like experience, projectors are now a more compelling option.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/projectors-won-us-over-in-2025-143655492.html?src=rss",
          "feed_position": 24,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/036c16c0-d5ce-11f0-b7db-e63439d1da6a"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/openai-report-reveals-a-6x-productivity-gap-between-ai-power-users-and",
          "published_at": "Wed, 10 Dec 2025 14:30:00 GMT",
          "title": "OpenAI report reveals a 6x productivity gap between AI power users and everyone else",
          "standfirst": "The tools are available to everyone. The subscription is company-wide. The training sessions have been held. And yet, in offices from Wall Street to Silicon Valley, a stark divide is opening between workers who have woven artificial intelligence into the fabric of their daily work and colleagues who have barely touched it.The gap is not small. According to a new report from OpenAI analyzing usage patterns across its more than one million business customers, workers at the 95th percentile of AI adoption are sending six times as many messages to ChatGPT as the median employee at the same companies. For specific tasks, the divide is even more dramatic: frontier workers send 17 times as many coding-related messages as their typical peers, and among data analysts, the heaviest users engage the data analysis tool 16 times more frequently than the median.This is not a story about access. It is a story about a new form of workplace stratification emerging in real time — one that may be reshaping who gets ahead, who falls behind, and what it means to be a skilled worker in the age of artificial intelligence.Everyone has the same tools, but not everyone is using themPerhaps the most striking finding in the OpenAI report is how little access explains. ChatGPT Enterprise is now deployed across more than 7 million workplace seats globally, a nine-fold increase from a year ago. The tools are the same for everyone. The capabilities are identical. And yet usage varies by orders of magnitude.Among monthly active users — people who have logged in at least once in the past 30 days — 19 percent have never tried the data analysis feature. Fourteen percent have never used reasoning capabilities. Twelve percent have never used search. These are not obscure features buried in submenus; they are core functionality that OpenAI highlights as transformative for knowledge work.The pattern inverts among daily users. Only 3 percent of people who use ChatGPT every day have never tried data analysis; just 1 percent have skipped reasoning or search. The implication is clear: the divide is not between those who have access and those who don&#x27;t, but between those who have made AI a daily habit and those for whom it remains an occasional novelty.Employees who experiment more are saving dramatically more timeThe OpenAI report suggests that AI productivity gains are not evenly distributed across all users but concentrated among those who use the technology most intensively. Workers who engage across approximately seven distinct task types — data analysis, coding, image generation, translation, writing, and others — report saving five times as much time as those who use only four. Employees who save more than 10 hours per week consume eight times more AI credits than those who report no time savings at all.This creates a compounding dynamic. Workers who experiment broadly discover more uses. More uses lead to greater productivity gains. Greater productivity gains presumably lead to better performance reviews, more interesting assignments, and faster advancement—which in turn provides more opportunity and incentive to deepen AI usage further.Seventy-five percent of surveyed workers report being able to complete tasks they previously could not perform, including programming support, spreadsheet automation, and technical troubleshooting. For workers who have embraced these capabilities, the boundaries of their roles are expanding. For those who have not, the boundaries may be contracting by comparison.The corporate AI paradox: $40 billion spent, 95 percent seeing no returnThe individual usage gap documented by OpenAI mirrors a broader pattern identified by a separate study from MIT&#x27;s Project NANDA. Despite $30 billion to $40 billion invested in generative AI initiatives, only 5 percent of organizations are seeing transformative returns. The researchers call this the \"GenAI Divide\" — a gap separating the few organizations that succeed in transforming processes with adaptive AI systems from the majority that remain stuck in pilots.The MIT report found limited disruption across industries: only two of nine major sectors—technology and media—show material business transformation from generative AI use. Large firms lead in pilot volume but lag in successful deployment.The pattern is consistent across both studies. Organizations and individuals are buying the technology. They are launching pilots. They are attending training sessions. But somewhere between adoption and transformation, most are getting stuck.While official AI projects stall, a shadow economy is thrivingThe MIT study reveals a striking disconnect: while only 40 percent of companies have purchased official LLM subscriptions, employees in over 90 percent of companies regularly use personal AI tools for work. Nearly every respondent reported using LLMs in some form as part of their regular workflow.\"This &#x27;shadow AI&#x27; often delivers better ROI than formal initiatives and reveals what actually works for bridging the divide,\" MIT&#x27;s Project NANDA found.The shadow economy offers a clue to what&#x27;s happening at the individual level within organizations. Employees who take initiative — who sign up for personal subscriptions, who experiment on their own time, who figure out how to integrate AI into their workflows without waiting for IT approval — are pulling ahead of colleagues who wait for official guidance that may never come.These shadow systems, largely unsanctioned, often deliver better performance and faster adoption than corporate tools. Worker sentiment reveals a preference for flexible, responsive tools — precisely the kind of experimentation that separates OpenAI&#x27;s frontier workers from the median.The biggest gaps show up in technical work that used to require specialistsThe largest relative gaps between frontier and median workers appear in coding, writing, and analysis — precisely the task categories where AI capabilities have advanced most rapidly. Frontier workers are not just doing the same work faster; they appear to be doing different work entirely, expanding into technical domains that were previously inaccessible to them.Among ChatGPT Enterprise users outside of engineering, IT, and research, coding-related messages have grown 36 percent over the past six months. Someone in marketing or HR who learns to write scripts and automate workflows is becoming a categorically different employee than a peer who has not — even if they hold the same title and started with the same skills.The academic research on AI and productivity offers a complicated picture. Several studies cited in the OpenAI report find that AI has an \"equalizing effect,\" disproportionately helping lower-performing workers close the gap with their higher-performing peers. But the equalizing effect may apply only within the population of workers who actually use AI regularly. A meaningful share of workers are not in that group at all. They remain light users or non-users, even as their more adventurous colleagues pull away.Companies are divided too, and the gap is widening by the monthThe divide is not only between individual workers. It exists between entire organizations.Frontier firms — those at the 95th percentile of adoption intensity — generate approximately twice as many AI messages per employee as the median enterprise. For messages routed through custom GPTs, purpose-built tools that automate specific workflows, the gap widens to seven-fold.These numbers suggest fundamentally different operating models. At median companies, AI may be a productivity tool that individual workers use at their discretion. At frontier firms, AI appears to be embedded in core infrastructure: standardized workflows, persistent custom tools, systematic integration with internal data systems.The OpenAI report notes that roughly one in four enterprises still has not enabled connectors that give AI access to company data—a basic step that dramatically increases the technology&#x27;s utility. The MIT study found that companies that purchased AI tools from specialized vendors succeeded 67 percent of the time, while internal builds had only a one-in-three success rate. For many organizations, the AI era has technically arrived but has not yet begun in practice.The technology is no longer the problem — organizations areFor executives, the data presents an uncomfortable challenge. The technology is no longer the constraint. OpenAI notes that it releases a new feature or capability roughly every three days; the models are advancing faster than most organizations can absorb. The bottleneck has shifted from what AI can do to whether organizations are structured to take advantage of it.\"The dividing line isn&#x27;t intelligence,\" the MIT authors write. The problems with enterprise AI have to do with memory, adaptability, and learning capability. Problems stem less from regulations or model performance, and more from tools that fail to learn or adapt.Leading firms, according to the OpenAI report, consistently invest in executive sponsorship, data readiness, workflow standardization, and deliberate change management. They build cultures where custom AI tools are created, shared, and refined across teams. They track performance and run evaluations. They make AI adoption a strategic priority rather than an individual choice.The rest are leaving it to chance — hoping that workers will discover the tools on their own, experiment on their own time, and somehow propagate best practices without infrastructure or incentive. The six-fold gap suggests this approach is not working.The window to catch up is closing faster than most companies realizeWith enterprise contracts locking in over the next 18 months, there&#x27;s a shrinking window for vendors and adopters to cross the divide.The GenAI Divide identified by the MIT report is not going to last forever. But the organizations that figure out a way across it soonest will be the ones that define the next era of business.Both reports carry caveats. The OpenAI data comes from a company with an obvious interest in promoting AI adoption. The productivity figures are self-reported by customers already paying for the product. The MIT study, while independent, relies on interviews and surveys rather than direct measurement. The long-term effects of this technology on employment, wages, and workplace dynamics remain uncertain.But the core finding — that access alone does not produce adoption, and that adoption varies enormously even within organizations that have made identical tools available to all — is consistent with how previous technologies have diffused through the economy. Spreadsheets, email, and the internet all created similar divides before eventually becoming universal. The question is how long the current gap persists, who benefits during the transition, and what happens to workers who find themselves on the wrong side of it.For now, the divide is stark. Ninety percent of users said they prefer humans for \"mission-critical work,\" while AI has \"won the war for simple work.\" The workers who are pulling ahead are not doing so because they have access their colleagues lack. They are pulling ahead because they decided to use what everyone already has—and kept using it until they figured out what it could do.The 6x gap is not about technology. It is about behavior. And behavior, unlike software, cannot be deployed with a company-wide rollout.",
          "content": "The tools are available to everyone. The subscription is company-wide. The training sessions have been held. And yet, in offices from Wall Street to Silicon Valley, a stark divide is opening between workers who have woven artificial intelligence into the fabric of their daily work and colleagues who have barely touched it.The gap is not small. According to a new report from OpenAI analyzing usage patterns across its more than one million business customers, workers at the 95th percentile of AI adoption are sending six times as many messages to ChatGPT as the median employee at the same companies. For specific tasks, the divide is even more dramatic: frontier workers send 17 times as many coding-related messages as their typical peers, and among data analysts, the heaviest users engage the data analysis tool 16 times more frequently than the median.This is not a story about access. It is a story about a new form of workplace stratification emerging in real time — one that may be reshaping who gets ahead, who falls behind, and what it means to be a skilled worker in the age of artificial intelligence.Everyone has the same tools, but not everyone is using themPerhaps the most striking finding in the OpenAI report is how little access explains. ChatGPT Enterprise is now deployed across more than 7 million workplace seats globally, a nine-fold increase from a year ago. The tools are the same for everyone. The capabilities are identical. And yet usage varies by orders of magnitude.Among monthly active users — people who have logged in at least once in the past 30 days — 19 percent have never tried the data analysis feature. Fourteen percent have never used reasoning capabilities. Twelve percent have never used search. These are not obscure features buried in submenus; they are core functionality that OpenAI highlights as transformative for knowledge work.The pattern inverts among daily users. Only 3 percent of people who use ChatGPT every day have never tried data analysis; just 1 percent have skipped reasoning or search. The implication is clear: the divide is not between those who have access and those who don&#x27;t, but between those who have made AI a daily habit and those for whom it remains an occasional novelty.Employees who experiment more are saving dramatically more timeThe OpenAI report suggests that AI productivity gains are not evenly distributed across all users but concentrated among those who use the technology most intensively. Workers who engage across approximately seven distinct task types — data analysis, coding, image generation, translation, writing, and others — report saving five times as much time as those who use only four. Employees who save more than 10 hours per week consume eight times more AI credits than those who report no time savings at all.This creates a compounding dynamic. Workers who experiment broadly discover more uses. More uses lead to greater productivity gains. Greater productivity gains presumably lead to better performance reviews, more interesting assignments, and faster advancement—which in turn provides more opportunity and incentive to deepen AI usage further.Seventy-five percent of surveyed workers report being able to complete tasks they previously could not perform, including programming support, spreadsheet automation, and technical troubleshooting. For workers who have embraced these capabilities, the boundaries of their roles are expanding. For those who have not, the boundaries may be contracting by comparison.The corporate AI paradox: $40 billion spent, 95 percent seeing no returnThe individual usage gap documented by OpenAI mirrors a broader pattern identified by a separate study from MIT&#x27;s Project NANDA. Despite $30 billion to $40 billion invested in generative AI initiatives, only 5 percent of organizations are seeing transformative returns. The researchers call this the \"GenAI Divide\" — a gap separating the few organizations that succeed in transforming processes with adaptive AI systems from the majority that remain stuck in pilots.The MIT report found limited disruption across industries: only two of nine major sectors—technology and media—show material business transformation from generative AI use. Large firms lead in pilot volume but lag in successful deployment.The pattern is consistent across both studies. Organizations and individuals are buying the technology. They are launching pilots. They are attending training sessions. But somewhere between adoption and transformation, most are getting stuck.While official AI projects stall, a shadow economy is thrivingThe MIT study reveals a striking disconnect: while only 40 percent of companies have purchased official LLM subscriptions, employees in over 90 percent of companies regularly use personal AI tools for work. Nearly every respondent reported using LLMs in some form as part of their regular workflow.\"This &#x27;shadow AI&#x27; often delivers better ROI than formal initiatives and reveals what actually works for bridging the divide,\" MIT&#x27;s Project NANDA found.The shadow economy offers a clue to what&#x27;s happening at the individual level within organizations. Employees who take initiative — who sign up for personal subscriptions, who experiment on their own time, who figure out how to integrate AI into their workflows without waiting for IT approval — are pulling ahead of colleagues who wait for official guidance that may never come.These shadow systems, largely unsanctioned, often deliver better performance and faster adoption than corporate tools. Worker sentiment reveals a preference for flexible, responsive tools — precisely the kind of experimentation that separates OpenAI&#x27;s frontier workers from the median.The biggest gaps show up in technical work that used to require specialistsThe largest relative gaps between frontier and median workers appear in coding, writing, and analysis — precisely the task categories where AI capabilities have advanced most rapidly. Frontier workers are not just doing the same work faster; they appear to be doing different work entirely, expanding into technical domains that were previously inaccessible to them.Among ChatGPT Enterprise users outside of engineering, IT, and research, coding-related messages have grown 36 percent over the past six months. Someone in marketing or HR who learns to write scripts and automate workflows is becoming a categorically different employee than a peer who has not — even if they hold the same title and started with the same skills.The academic research on AI and productivity offers a complicated picture. Several studies cited in the OpenAI report find that AI has an \"equalizing effect,\" disproportionately helping lower-performing workers close the gap with their higher-performing peers. But the equalizing effect may apply only within the population of workers who actually use AI regularly. A meaningful share of workers are not in that group at all. They remain light users or non-users, even as their more adventurous colleagues pull away.Companies are divided too, and the gap is widening by the monthThe divide is not only between individual workers. It exists between entire organizations.Frontier firms — those at the 95th percentile of adoption intensity — generate approximately twice as many AI messages per employee as the median enterprise. For messages routed through custom GPTs, purpose-built tools that automate specific workflows, the gap widens to seven-fold.These numbers suggest fundamentally different operating models. At median companies, AI may be a productivity tool that individual workers use at their discretion. At frontier firms, AI appears to be embedded in core infrastructure: standardized workflows, persistent custom tools, systematic integration with internal data systems.The OpenAI report notes that roughly one in four enterprises still has not enabled connectors that give AI access to company data—a basic step that dramatically increases the technology&#x27;s utility. The MIT study found that companies that purchased AI tools from specialized vendors succeeded 67 percent of the time, while internal builds had only a one-in-three success rate. For many organizations, the AI era has technically arrived but has not yet begun in practice.The technology is no longer the problem — organizations areFor executives, the data presents an uncomfortable challenge. The technology is no longer the constraint. OpenAI notes that it releases a new feature or capability roughly every three days; the models are advancing faster than most organizations can absorb. The bottleneck has shifted from what AI can do to whether organizations are structured to take advantage of it.\"The dividing line isn&#x27;t intelligence,\" the MIT authors write. The problems with enterprise AI have to do with memory, adaptability, and learning capability. Problems stem less from regulations or model performance, and more from tools that fail to learn or adapt.Leading firms, according to the OpenAI report, consistently invest in executive sponsorship, data readiness, workflow standardization, and deliberate change management. They build cultures where custom AI tools are created, shared, and refined across teams. They track performance and run evaluations. They make AI adoption a strategic priority rather than an individual choice.The rest are leaving it to chance — hoping that workers will discover the tools on their own, experiment on their own time, and somehow propagate best practices without infrastructure or incentive. The six-fold gap suggests this approach is not working.The window to catch up is closing faster than most companies realizeWith enterprise contracts locking in over the next 18 months, there&#x27;s a shrinking window for vendors and adopters to cross the divide.The GenAI Divide identified by the MIT report is not going to last forever. But the organizations that figure out a way across it soonest will be the ones that define the next era of business.Both reports carry caveats. The OpenAI data comes from a company with an obvious interest in promoting AI adoption. The productivity figures are self-reported by customers already paying for the product. The MIT study, while independent, relies on interviews and surveys rather than direct measurement. The long-term effects of this technology on employment, wages, and workplace dynamics remain uncertain.But the core finding — that access alone does not produce adoption, and that adoption varies enormously even within organizations that have made identical tools available to all — is consistent with how previous technologies have diffused through the economy. Spreadsheets, email, and the internet all created similar divides before eventually becoming universal. The question is how long the current gap persists, who benefits during the transition, and what happens to workers who find themselves on the wrong side of it.For now, the divide is stark. Ninety percent of users said they prefer humans for \"mission-critical work,\" while AI has \"won the war for simple work.\" The workers who are pulling ahead are not doing so because they have access their colleagues lack. They are pulling ahead because they decided to use what everyone already has—and kept using it until they figured out what it could do.The 6x gap is not about technology. It is about behavior. And behavior, unlike software, cannot be deployed with a company-wide rollout.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2bLHfbnsHmBo88bpiWCXw9/e35290d2729e57b19a3bfff2cb96f47f/nuneybits_purple_gradient_sky_with_city_lights_in_dots_pattern__7c85a503-0251-4c67-9ddc-4341ea63314b.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/kindle-scribe-colorsoft-review-a-very-particular-set-of-skills-for-a-price-140014961.html",
          "published_at": "Wed, 10 Dec 2025 14:00:14 +0000",
          "title": "Kindle Scribe Colorsoft review: A very particular set of skills, for a price",
          "standfirst": "In a world where notifications persistently compete for our attention, distraction-free ereaders and writing tablets have found an audience. Putting your phone, laptop or iPad aside and curling up with a Kindle or a reMarkable tablet have become an almost ironic way for the tech-savvy to disconnect from online noise and focus on reading and writing. It’s debatable how broad the appeal of these devices is, but even in what appears to be a relatively small slice of the industry, the competition is fierce. Amazon is arguably the biggest name in the space, with its Kindles dominating the ereader market for years. When it introduced the Kindle Scribe in 2022, the company made a play for the burgeoning E Ink writing tablet category, and just last year it launched its first color ereader with the Kindle Colorsoft. Put all those features — reading, writing and color — together, and you’ve got the ingredients for Amazon’s latest contender: the Kindle Scribe Colorsoft. This time, Amazon expanded the Scribe line by releasing three new Scribes at once. The entry-level model is the black-and-white tablet without a front light, which costs $430. For $70 more, you’ll get the front light, and then the Colorsoft version goes for $630. There are upgrades from last year’s Scribe across the trio, and for this review we’ll be looking mostly at the Colorsoft, which has all of the new features. Like with previous models of the Scribe, Amazon doesn’t indicate the generation number in the name, simply calling this lineup the “all-new Kindle Scribe,” attaching the word Colorsoft to the edition that renders colors. To avoid confusion, I’ll occasionally be referring to this generation of the device as the Scribe 3, and the version from last year as the Scribe 2. Editor’s note: As I only received the Kindle Scribe Colorsoft on December 7 due to shipping delays, I won’t be assigning a score to this device until I have had more time to test it. My colleague Valentina Palladino received the new Kindle Scribe a few days before that, and has contributed testing and impressions to this review. It’s also worth noting that some new features, like “Send to Alexa+,” “Story so far” and “Ask this book” aren’t available to test yet. We will update this review with a score after spending more time with it so we can better gauge things like battery life and the usefulness of some software features. What’s new with the Kindle Scribe Colorsoft Aside from the obvious, which is that the Colorsoft can now render colors, the latest Kindle Scribes also feature a refined design, improved front light system, updated screen architecture, new quad-core chip, more memory and Oxide display technology. It has a larger 11-inch screen compared to the 10.2-inch display on its predecessor, and still manages to weigh 33 grams less at 400 grams (0.88 pounds). There’s also a revamped Home page that houses a Quick Note for easier access to the writing interface as well as some software and AI tools that aren’t available to test yet. A lot of the hardware tweaks translated to a snappier, more responsive device overall. In my testing, the Scribe Colorsoft’s AI summarization and handwriting refinements took a bit less time than the Scribe 2, which I attribute most to the processor, but I also noticed improved fluidity in the writing experience. Drawing on the Scribe Colorsoft brings me right back to my younger days testing out pens at bookstores. Amazon’s stylus feels like a pen with ink that flows more freely and consistently onto the page than others, and between the nib and the texture of the page there is a lack of resistance and overall smoothness that is very satisfying. Cherlynn Low for Engadget Amazon said that the Premium Pen that comes with the Scribes has been refined with a thicker and more rounded silhouette. With its latest Oxide display, the Scribe Colorsoft’s screen response rate of 14 milliseconds and the non-Colorsoft Scribe 3’s rates of 12ms are both much higher than the 20-21ms for the Scribe 2. Together, this probably is the main reason that the new Scribe feels more responsive in general, and why writing on it seems so smooth. Although, that new front light system might also be contributing to the overall feeling of freshness. Speaking of, I put the Scribe 2 and Scribe Colorsoft side by side in my friend’s living room and the difference was stark. When I brought both devices next to the window, under direct sunlight, they both seemed similarly bright, with the typical glare-free finish you’d expect of ereaders. But when I took them into a darkened bedroom, the auto-adjusting panel on the Colorsoft lit up its screen and made it easier to read. Colors popped, and while I felt that there was a slight blue tinge to the light, it wasn’t something I would’ve noticed without a side-by-side comparison. It’s not an issue though because you can also adjust the warmth here like you can on other Kindles. One of my complaints in my review of the Scribe 2 was the flimsy attachment method of magnets holding the pen to the tablet. While Amazon hasn’t built an onboard slot or holder for the stylus, it did increase the magnetic force on the Scribe 3. This was already noticeable during my hands-on with the device back in October, and in real-world use I appreciated this upgrade in keeping the Premium Pen tightly attached to the Scribe Colorsoft. I would still prefer a more secure approach, since I still do worry about the stylus getting lost in my purse and don’t want to have to buy a case just for this purpose. But it’s a small quibble and my concerns have largely been allayed with the increased magnetism. Cherlynn Low for Engadget I still need to test some software features like Send to Alexa+, Ask This Book and Story So Far, but they’re not available yet. I’ve been focusing my testing on the Notebook section and need to spend more time marking up and annotating books to better evaluate that use case. But not much has changed there since Amazon rolled out the collapsible margins in February, and you can read my review of the Scribe 2 for my impressions there. The new home page and AI-powered Notebook search At the moment, I can speak to one of the new features: AI-powered Notebook search. The Search bar at the top of the Scribe can now answer questions about the contents of all your Notebooks (and books). At the time of the Scribe’s announcement, I thought this would be helpful in pulling together all the tasks I’d assigned to specific team members across the to-do lists I drew up for various events. When I asked the Scribe “what tasks have I assigned Sam,” its results page showed six categories, pulling information from my library, notebooks, the Kindle Store, the Audible Store, Goodreads and text within books. Only the second one had any findings. Under “Results in your notebooks,” there was a label “AI-powered insights” followed by a header “Sam’s Assigned Tasks.” Below that was a bulleted list, which I’ll transcribe and include an image of here: Add content to CES sheet Handle KPBP company set Track Samsung mobile developments Handle OnePlus 13 Review device during CES Attend meetings with: - Dell & ASUS on Thursday, MSI, Razer, HP, Lenovo, Potentially Sony Ateela Work on Sam Qi 2 Best-Sam host responsibilities Cherlynn Low for Engadget I quickly realized that I’d need to fine-tune my requests to get results that made more sense, since random tasks divorced from their parent documents made little sense without context. Thankfully, there was a button below the results that prompted me to “Ask Notebooks” about “these insights, or ask something else.” However, tapping that only brought me to a different page showing the same list but with a new section to see the notes they were sourced from. I’ll also point out that this list of tasks for Sam was not the same result I got from a query about “where do I mention Sam?” In addition to the two to-do lists that I created in December 2023 and January of this year, the Scribe told me “Sam appears on a Christmas shopping list as one of the checked-off friends.” That’s fairly impressive, since that list did have Sam under a handwritten header “Friends,” as opposed to other pages titled “Gym” or “Neighbors.” But it appeared to only be able to determine that Sam’s name was checked off thanks to the template I used for the notebook. Other check marks I made outside the predefined boxes in that background weren’t deemed as checks and instead misrecognized as dashes. So later when I asked where my friend Michelle appeared in all my notebooks, the Scribe noted an entry for “Michelle-scart” in a different holiday shopping page. Retrying the same question did yield more accurate results, though, with a subsequent search correctly stating “Michelle appears in a list with ‘scarf’ noted next to her name.” And whether it’s my overly messy handwriting to blame or Amazon’s technological deficiencies, there were still some words or sentences that it misidentified, like “Michelle-callin” instead of “Michelle — Callie.” So far, the AI-powered Search feels like a hit-or-miss update. Sometimes, like when I took the bait and asked the questions it suggested, I would get shockingly accurate answers. “Try asking ‘which Ariana song is mentioned in the list,’” the Scribe prompted. Or “When is the HOA meeting occurring?” For the former, it told me that the song “Bang Bang” was on a list of karaoke songs, while the latter simply told me the date and time it had found in a note titled “Appointments Dec 2022.” I’ll need more time to think of better ways to use this feature, but for now I can’t decide if it’s actually helpful without some extra work. Cherlynn Low for Engadget I already spent some time testing the Summarize and Refine tools introduced in the last Kindle Scribe, so I’ll just say that refining the handwriting of a to-do list on the Scribe Colorsoft was largely the same as before, just a tad faster. I didn’t really use either AI tool in the year since I reviewed the Scribe 2, so I was right last year in thinking I wouldn’t find much use for them in daily practice. What I thought would be more practical is the redesigned Home screen and the Quick Note that takes up the top left corner of this page. Again, I’d need to spend much more time to understand how I’d navigate the device over weeks and months, but for the most part I find it easy to just hop in and out of notes I want without first going to the Home section. I’d prefer a hardware shortcut like Montblanc offers in its Digital Paper writing tablet. On that device, you can program the buttons on the pen so that a double click starts a new note, adds a blank page or brings you back home. While you can customize the button on Amazon’s Premium Pen, your options are limited to switching between tools like the highlighter, pen, shader or eraser for use while you’re writing. (And yes, like before, you can still use the top of the Premium Pen to erase content — no need to push any button.) One last thing to note about the home page (for now) is that seeing the rows of book covers in color is a delight, and though it’s not something that impacts the function of the device, it certainly adds a layer of visual pleasure. How does the Kindle Scribe Colorsoft compare to the competition? One of the Scribe Colorsoft’s main competitors is the reMarkable Paper Pro. The latter has a larger 11.8-inch screen and, correspondingly, weighs a lot more at 525 grams (1.16 pounds). Though I prefer the sharp lines of the reMarkable to the rounded edges and corners of the Scribe, I find the Kindle’s size much more manageable, especially when I’m writing for more than five minutes. Importantly, the Kindle Scribe Colorsoft simply has a better screen than the reMarkable. It delivers brighter, more saturated colors, and supports more hues, too. Plus, when I placed them next to each other, the Paper Pro seemed to have a yellow cast and a dimmer screen overall (even at maximum brightness). And when I use the highlight function on each, the reMarkable device “flashes” — meaning you have to give it a second for the color to appear in its final form after you put the stylus to the screen. Meanwhile, the color that shows up on the Colorsoft’s panel as soon as you write on it doesn’t change — no flashing takes place. Cherlynn Low for Engadget The Scribe’s other strengths are its superior performance and Amazon’s ecosystem of books (for those like me who already have large Kindle libraries, anyway). Though it does offer AI features that reMarkable doesn’t, I’m generally leery of those tools, and, as already detailed in this review, they don’t usually help me. However, the reMarkable remains the winner when it comes to writing software. It’s way more versatile than Amazon in this respect, especially with its ability to have handwritten and typed text coexist within the same document. You can also edit a note from reMarkable’s app on your phone, typing in any last-minute additions to your shopping list and bolding, italicizing or formatting them if you like. And if you’re a power user, getting your favorite ebooks onto the reMarkable tablet isn’t too difficult, provided you have the EPUB files. The main problem for me here is that you'll need to pay $3 a month for its Connect subscription to continue having access to a lot of these features. I’ll also shout out companies like Kobo and Boox, who also make color-rendering ereaders that you can write on. Boox’s Note Air 5c starts at $530 and includes the stylus and a magnetic case for that price. It supports apps via the Google Play Store, but, as our deputy editor Valentina Palladino cautions, isn’t the most beginner-friendly product. Kobo, on the other hand, makes color ereaders like the Libra Color. Although it does support stylus input, it is much smaller with its 7-inch display. And for those who aren’t too fussed about color, there are plenty of black-and-white E Ink writing tablets, including the $905 Montblanc Digital Paper, which I’ve been testing for a few weeks. I’m finishing up my review but that one is clearly a luxury product targeted at a much more niche audience than the already limited target market for this category of devices. If your budget is tight, I’d recommend skipping the Colorsoft model unless it’s crucial to your process. $500 is a much easier price to stomach. Who should get the Kindle Scribe Colorsoft? I hesitate to recommend anyone buy anything before I’ve had enough time to assign a score, since things like battery life take longer to evaluate. And while I continue to test the device to get a better sense for its battery life, I’ve already noticed that like the Scribes before it, this version doesn’t last as long as other Kindles. Amazon promises weeks of reading and writing per charge, which could be anything between two and ten (or more) weeks. In my experience so far, the Kindle Scribe Colorsoft dropped about 20 percent in two days, which, mathematically, means it would struggle to even last a week, not to mention multiple weeks. But because the Scribe 2 showed similar battery drain during my review (with heavier use) and manages to stay charged for at least a month when I’m not testing it all day every day, I’m willing to believe Amazon’s promise of greater runtime. Aside from my reservations about battery life, the Kindle Scribe Colorsoft is a competent device that delivers on most of its promises so far. The biggest knock against it is its price. At $500 for the monochrome model and $630 for color, this is one Amazon product that can be more expensive than the competition. But it’s not without its strengths. I’d think of the Kindle Scribe 3 (and Colorsoft) as an E Ink tablet that is more of a notebook than a portal for textbooks you can mark up, with a robust library of Kindle titles to boot. The AI features are not crucial to the experience, but they also stay out of the way. For those looking for a more sophisticated and versatile writing tablet that is less of a book replacement, the reMarkable Paper Pro is the superior device. And for people who don’t mind the notifications, apps and alerts that these purpose-driven tablets keep from distracting you, there’s always the option of buying an iPad or an Android tablet with a stylus. Just install minimal apps or block all notifications, and you might even save hundreds of dollars in the process. Cherlynn Low for Engadget Wrap-up I hate to admit it, but Amazon’s devices and services chief Panos Panay was right in calling the Kindle Scribe a 2-in-1. But the two functions it serves are very specific. I think of the Scribe devices as Kindles first and foremost. That means they’re ereaders, capable of substituting stacks of books thanks to their digital libraries and eye-friendly screens. The second role the Scribe plays well is that of a notebook substitute. It is a place to hold endless slips of digital paper, and its search function can competently help you find what you jotted down in a random note years ago. But Amazon has not yet found a way to deliver on features like annotating and marking up ebooks that feels like pen-and-paper. Trying to mark up a digital textbook on the Scribe still feels unintuitive, involving virtual sticky notes, collapsible margins and inserting boxes within lines of text. And you won’t be able to easily edit your notes if you’re away from your Scribe, unlike how you can on a reMarkable product. So the Kindle Scribe 3 is not a three- or four-in-one. I don’t have a problem with that, especially without the extra cost that comes with the color capabilities. While the Colorsoft model is superior to the competition at the moment, it also comes at a premium. If you’re looking for the best color E Ink writing tablet available and are willing to splurge, the Kindle Scribe Colorsoft is worth consideration.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/kindle-scribe-colorsoft-review-a-very-particular-set-of-skills-for-a-price-140014961.html?src=rss",
          "content": "In a world where notifications persistently compete for our attention, distraction-free ereaders and writing tablets have found an audience. Putting your phone, laptop or iPad aside and curling up with a Kindle or a reMarkable tablet have become an almost ironic way for the tech-savvy to disconnect from online noise and focus on reading and writing. It’s debatable how broad the appeal of these devices is, but even in what appears to be a relatively small slice of the industry, the competition is fierce. Amazon is arguably the biggest name in the space, with its Kindles dominating the ereader market for years. When it introduced the Kindle Scribe in 2022, the company made a play for the burgeoning E Ink writing tablet category, and just last year it launched its first color ereader with the Kindle Colorsoft. Put all those features — reading, writing and color — together, and you’ve got the ingredients for Amazon’s latest contender: the Kindle Scribe Colorsoft. This time, Amazon expanded the Scribe line by releasing three new Scribes at once. The entry-level model is the black-and-white tablet without a front light, which costs $430. For $70 more, you’ll get the front light, and then the Colorsoft version goes for $630. There are upgrades from last year’s Scribe across the trio, and for this review we’ll be looking mostly at the Colorsoft, which has all of the new features. Like with previous models of the Scribe, Amazon doesn’t indicate the generation number in the name, simply calling this lineup the “all-new Kindle Scribe,” attaching the word Colorsoft to the edition that renders colors. To avoid confusion, I’ll occasionally be referring to this generation of the device as the Scribe 3, and the version from last year as the Scribe 2. Editor’s note: As I only received the Kindle Scribe Colorsoft on December 7 due to shipping delays, I won’t be assigning a score to this device until I have had more time to test it. My colleague Valentina Palladino received the new Kindle Scribe a few days before that, and has contributed testing and impressions to this review. It’s also worth noting that some new features, like “Send to Alexa+,” “Story so far” and “Ask this book” aren’t available to test yet. We will update this review with a score after spending more time with it so we can better gauge things like battery life and the usefulness of some software features. What’s new with the Kindle Scribe Colorsoft Aside from the obvious, which is that the Colorsoft can now render colors, the latest Kindle Scribes also feature a refined design, improved front light system, updated screen architecture, new quad-core chip, more memory and Oxide display technology. It has a larger 11-inch screen compared to the 10.2-inch display on its predecessor, and still manages to weigh 33 grams less at 400 grams (0.88 pounds). There’s also a revamped Home page that houses a Quick Note for easier access to the writing interface as well as some software and AI tools that aren’t available to test yet. A lot of the hardware tweaks translated to a snappier, more responsive device overall. In my testing, the Scribe Colorsoft’s AI summarization and handwriting refinements took a bit less time than the Scribe 2, which I attribute most to the processor, but I also noticed improved fluidity in the writing experience. Drawing on the Scribe Colorsoft brings me right back to my younger days testing out pens at bookstores. Amazon’s stylus feels like a pen with ink that flows more freely and consistently onto the page than others, and between the nib and the texture of the page there is a lack of resistance and overall smoothness that is very satisfying. Cherlynn Low for Engadget Amazon said that the Premium Pen that comes with the Scribes has been refined with a thicker and more rounded silhouette. With its latest Oxide display, the Scribe Colorsoft’s screen response rate of 14 milliseconds and the non-Colorsoft Scribe 3’s rates of 12ms are both much higher than the 20-21ms for the Scribe 2. Together, this probably is the main reason that the new Scribe feels more responsive in general, and why writing on it seems so smooth. Although, that new front light system might also be contributing to the overall feeling of freshness. Speaking of, I put the Scribe 2 and Scribe Colorsoft side by side in my friend’s living room and the difference was stark. When I brought both devices next to the window, under direct sunlight, they both seemed similarly bright, with the typical glare-free finish you’d expect of ereaders. But when I took them into a darkened bedroom, the auto-adjusting panel on the Colorsoft lit up its screen and made it easier to read. Colors popped, and while I felt that there was a slight blue tinge to the light, it wasn’t something I would’ve noticed without a side-by-side comparison. It’s not an issue though because you can also adjust the warmth here like you can on other Kindles. One of my complaints in my review of the Scribe 2 was the flimsy attachment method of magnets holding the pen to the tablet. While Amazon hasn’t built an onboard slot or holder for the stylus, it did increase the magnetic force on the Scribe 3. This was already noticeable during my hands-on with the device back in October, and in real-world use I appreciated this upgrade in keeping the Premium Pen tightly attached to the Scribe Colorsoft. I would still prefer a more secure approach, since I still do worry about the stylus getting lost in my purse and don’t want to have to buy a case just for this purpose. But it’s a small quibble and my concerns have largely been allayed with the increased magnetism. Cherlynn Low for Engadget I still need to test some software features like Send to Alexa+, Ask This Book and Story So Far, but they’re not available yet. I’ve been focusing my testing on the Notebook section and need to spend more time marking up and annotating books to better evaluate that use case. But not much has changed there since Amazon rolled out the collapsible margins in February, and you can read my review of the Scribe 2 for my impressions there. The new home page and AI-powered Notebook search At the moment, I can speak to one of the new features: AI-powered Notebook search. The Search bar at the top of the Scribe can now answer questions about the contents of all your Notebooks (and books). At the time of the Scribe’s announcement, I thought this would be helpful in pulling together all the tasks I’d assigned to specific team members across the to-do lists I drew up for various events. When I asked the Scribe “what tasks have I assigned Sam,” its results page showed six categories, pulling information from my library, notebooks, the Kindle Store, the Audible Store, Goodreads and text within books. Only the second one had any findings. Under “Results in your notebooks,” there was a label “AI-powered insights” followed by a header “Sam’s Assigned Tasks.” Below that was a bulleted list, which I’ll transcribe and include an image of here: Add content to CES sheet Handle KPBP company set Track Samsung mobile developments Handle OnePlus 13 Review device during CES Attend meetings with: - Dell & ASUS on Thursday, MSI, Razer, HP, Lenovo, Potentially Sony Ateela Work on Sam Qi 2 Best-Sam host responsibilities Cherlynn Low for Engadget I quickly realized that I’d need to fine-tune my requests to get results that made more sense, since random tasks divorced from their parent documents made little sense without context. Thankfully, there was a button below the results that prompted me to “Ask Notebooks” about “these insights, or ask something else.” However, tapping that only brought me to a different page showing the same list but with a new section to see the notes they were sourced from. I’ll also point out that this list of tasks for Sam was not the same result I got from a query about “where do I mention Sam?” In addition to the two to-do lists that I created in December 2023 and January of this year, the Scribe told me “Sam appears on a Christmas shopping list as one of the checked-off friends.” That’s fairly impressive, since that list did have Sam under a handwritten header “Friends,” as opposed to other pages titled “Gym” or “Neighbors.” But it appeared to only be able to determine that Sam’s name was checked off thanks to the template I used for the notebook. Other check marks I made outside the predefined boxes in that background weren’t deemed as checks and instead misrecognized as dashes. So later when I asked where my friend Michelle appeared in all my notebooks, the Scribe noted an entry for “Michelle-scart” in a different holiday shopping page. Retrying the same question did yield more accurate results, though, with a subsequent search correctly stating “Michelle appears in a list with ‘scarf’ noted next to her name.” And whether it’s my overly messy handwriting to blame or Amazon’s technological deficiencies, there were still some words or sentences that it misidentified, like “Michelle-callin” instead of “Michelle — Callie.” So far, the AI-powered Search feels like a hit-or-miss update. Sometimes, like when I took the bait and asked the questions it suggested, I would get shockingly accurate answers. “Try asking ‘which Ariana song is mentioned in the list,’” the Scribe prompted. Or “When is the HOA meeting occurring?” For the former, it told me that the song “Bang Bang” was on a list of karaoke songs, while the latter simply told me the date and time it had found in a note titled “Appointments Dec 2022.” I’ll need more time to think of better ways to use this feature, but for now I can’t decide if it’s actually helpful without some extra work. Cherlynn Low for Engadget I already spent some time testing the Summarize and Refine tools introduced in the last Kindle Scribe, so I’ll just say that refining the handwriting of a to-do list on the Scribe Colorsoft was largely the same as before, just a tad faster. I didn’t really use either AI tool in the year since I reviewed the Scribe 2, so I was right last year in thinking I wouldn’t find much use for them in daily practice. What I thought would be more practical is the redesigned Home screen and the Quick Note that takes up the top left corner of this page. Again, I’d need to spend much more time to understand how I’d navigate the device over weeks and months, but for the most part I find it easy to just hop in and out of notes I want without first going to the Home section. I’d prefer a hardware shortcut like Montblanc offers in its Digital Paper writing tablet. On that device, you can program the buttons on the pen so that a double click starts a new note, adds a blank page or brings you back home. While you can customize the button on Amazon’s Premium Pen, your options are limited to switching between tools like the highlighter, pen, shader or eraser for use while you’re writing. (And yes, like before, you can still use the top of the Premium Pen to erase content — no need to push any button.) One last thing to note about the home page (for now) is that seeing the rows of book covers in color is a delight, and though it’s not something that impacts the function of the device, it certainly adds a layer of visual pleasure. How does the Kindle Scribe Colorsoft compare to the competition? One of the Scribe Colorsoft’s main competitors is the reMarkable Paper Pro. The latter has a larger 11.8-inch screen and, correspondingly, weighs a lot more at 525 grams (1.16 pounds). Though I prefer the sharp lines of the reMarkable to the rounded edges and corners of the Scribe, I find the Kindle’s size much more manageable, especially when I’m writing for more than five minutes. Importantly, the Kindle Scribe Colorsoft simply has a better screen than the reMarkable. It delivers brighter, more saturated colors, and supports more hues, too. Plus, when I placed them next to each other, the Paper Pro seemed to have a yellow cast and a dimmer screen overall (even at maximum brightness). And when I use the highlight function on each, the reMarkable device “flashes” — meaning you have to give it a second for the color to appear in its final form after you put the stylus to the screen. Meanwhile, the color that shows up on the Colorsoft’s panel as soon as you write on it doesn’t change — no flashing takes place. Cherlynn Low for Engadget The Scribe’s other strengths are its superior performance and Amazon’s ecosystem of books (for those like me who already have large Kindle libraries, anyway). Though it does offer AI features that reMarkable doesn’t, I’m generally leery of those tools, and, as already detailed in this review, they don’t usually help me. However, the reMarkable remains the winner when it comes to writing software. It’s way more versatile than Amazon in this respect, especially with its ability to have handwritten and typed text coexist within the same document. You can also edit a note from reMarkable’s app on your phone, typing in any last-minute additions to your shopping list and bolding, italicizing or formatting them if you like. And if you’re a power user, getting your favorite ebooks onto the reMarkable tablet isn’t too difficult, provided you have the EPUB files. The main problem for me here is that you'll need to pay $3 a month for its Connect subscription to continue having access to a lot of these features. I’ll also shout out companies like Kobo and Boox, who also make color-rendering ereaders that you can write on. Boox’s Note Air 5c starts at $530 and includes the stylus and a magnetic case for that price. It supports apps via the Google Play Store, but, as our deputy editor Valentina Palladino cautions, isn’t the most beginner-friendly product. Kobo, on the other hand, makes color ereaders like the Libra Color. Although it does support stylus input, it is much smaller with its 7-inch display. And for those who aren’t too fussed about color, there are plenty of black-and-white E Ink writing tablets, including the $905 Montblanc Digital Paper, which I’ve been testing for a few weeks. I’m finishing up my review but that one is clearly a luxury product targeted at a much more niche audience than the already limited target market for this category of devices. If your budget is tight, I’d recommend skipping the Colorsoft model unless it’s crucial to your process. $500 is a much easier price to stomach. Who should get the Kindle Scribe Colorsoft? I hesitate to recommend anyone buy anything before I’ve had enough time to assign a score, since things like battery life take longer to evaluate. And while I continue to test the device to get a better sense for its battery life, I’ve already noticed that like the Scribes before it, this version doesn’t last as long as other Kindles. Amazon promises weeks of reading and writing per charge, which could be anything between two and ten (or more) weeks. In my experience so far, the Kindle Scribe Colorsoft dropped about 20 percent in two days, which, mathematically, means it would struggle to even last a week, not to mention multiple weeks. But because the Scribe 2 showed similar battery drain during my review (with heavier use) and manages to stay charged for at least a month when I’m not testing it all day every day, I’m willing to believe Amazon’s promise of greater runtime. Aside from my reservations about battery life, the Kindle Scribe Colorsoft is a competent device that delivers on most of its promises so far. The biggest knock against it is its price. At $500 for the monochrome model and $630 for color, this is one Amazon product that can be more expensive than the competition. But it’s not without its strengths. I’d think of the Kindle Scribe 3 (and Colorsoft) as an E Ink tablet that is more of a notebook than a portal for textbooks you can mark up, with a robust library of Kindle titles to boot. The AI features are not crucial to the experience, but they also stay out of the way. For those looking for a more sophisticated and versatile writing tablet that is less of a book replacement, the reMarkable Paper Pro is the superior device. And for people who don’t mind the notifications, apps and alerts that these purpose-driven tablets keep from distracting you, there’s always the option of buying an iPad or an Android tablet with a stylus. Just install minimal apps or block all notifications, and you might even save hundreds of dollars in the process. Cherlynn Low for Engadget Wrap-up I hate to admit it, but Amazon’s devices and services chief Panos Panay was right in calling the Kindle Scribe a 2-in-1. But the two functions it serves are very specific. I think of the Scribe devices as Kindles first and foremost. That means they’re ereaders, capable of substituting stacks of books thanks to their digital libraries and eye-friendly screens. The second role the Scribe plays well is that of a notebook substitute. It is a place to hold endless slips of digital paper, and its search function can competently help you find what you jotted down in a random note years ago. But Amazon has not yet found a way to deliver on features like annotating and marking up ebooks that feels like pen-and-paper. Trying to mark up a digital textbook on the Scribe still feels unintuitive, involving virtual sticky notes, collapsible margins and inserting boxes within lines of text. And you won’t be able to easily edit your notes if you’re away from your Scribe, unlike how you can on a reMarkable product. So the Kindle Scribe 3 is not a three- or four-in-one. I don’t have a problem with that, especially without the extra cost that comes with the color capabilities. While the Colorsoft model is superior to the competition at the moment, it also comes at a premium. If you’re looking for the best color E Ink writing tablet available and are willing to splurge, the Kindle Scribe Colorsoft is worth consideration.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/kindle-scribe-colorsoft-review-a-very-particular-set-of-skills-for-a-price-140014961.html?src=rss",
          "feed_position": 25,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/64d18df0-d56a-11f0-bbcf-fdfdc8e1f0aa"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/quilters-ai-just-designed-an-843-part-linux-computer-that-booted-on-the",
          "published_at": "Wed, 10 Dec 2025 14:00:00 GMT",
          "title": "Quilter's AI just designed an 843‑part Linux computer that booted on the first try. Hardware will never be the same.",
          "standfirst": "A Los Angeles-based startup has demonstrated what it calls a breakthrough in hardware development: an artificial intelligence system that designed a fully functional Linux computer in one week — a process that would typically consume nearly three months of skilled engineering labor.Quilter, which has raised more than $40 million from investors including Benchmark, Index Ventures, and Coatue, used its physics-driven AI to automate the design of a two-board computer system that booted successfully on its first attempt, requiring no costly revisions. The project, internally dubbed \"Project Speedrun,\" required just 38.5 hours of human labor compared to the 428 hours that professional PCB designers quoted for the same task.The announcement also marks the first public disclosure that Tony Fadell, the engineer who led development of the iPod and iPhone at Apple and later founded Nest, has invested in the company and serves as an advisor.\"We didn&#x27;t teach Quilter to draw; we taught it to think in physics,\" said Sergiy Nesterenko, Quilter&#x27;s chief executive and a former SpaceX engineer, in an exclusive interview with VentureBeat. \"The result wasn&#x27;t a simulation — it was a working computer.\"Circuit board design remains the forgotten bottleneck that delays nearly every hardware productThe announcement shines a light on an unglamorous but critical chokepoint in technology development: printed circuit board layout. While semiconductors and software have received enormous attention and investment, the green fiberglass boards that connect chips, memory, and components in virtually every electronic device remain stubbornly manual to design.\"Besides auto-routers, the technology really hadn&#x27;t changed since the early &#x27;90s,\" Fadell told VentureBeat. \"The best boards are still made by hand. You go to Apple, they&#x27;ve got the tools, and these guys are just pushing traces, checking everything, doing flood fills—and you&#x27;re like, there&#x27;s got to be a better way.\"The PCB design process typically unfolds in three stages. Engineers first create a schematic — a logical diagram showing how components connect. Then a specialist manually draws the physical layout in CAD software, placing components and routing thousands of copper traces across multiple layers. Finally, the design goes to a manufacturer for fabrication.That middle step — the layout — creates a persistent bottleneck. For a board of moderate complexity, the process typically consumes four to eight weeks. For sophisticated systems like computers or automotive electronics, timelines stretch to three months or longer.\"The timeline was always this elastic thing—they&#x27;d say, &#x27;Yeah, that&#x27;s two weeks minimum,&#x27;\" Fadell recalled of his experience at Apple and Nest. \"And we&#x27;d say, &#x27;No, no. Work day and night. It&#x27;s two weeks.&#x27; But it was always this fixed bottleneck.\"The consequences ripple through hardware organizations. Firmware teams sit idle waiting for physical boards to test their code. Validation engineers cannot begin debugging. Product launches slip. According to Quilter&#x27;s research, only about 10 percent of first board revisions work correctly, forcing expensive and time-consuming respins.Project Speedrun put Quilter&#x27;s AI to the test with an 843-component computer that booted on the first tryProject Speedrun was designed to push the technology to its limits while producing an easily understood result: a working computer that could boot Linux, browse the internet, and run applications.The system consists of two boards based on NXP&#x27;s i.MX 8M Mini reference platform, a processor architecture used in automotive infotainment, industrial automation, and machine vision applications.The main system-on-module contains a quad-core ARM processor running at 1.8 gigahertz, 2 gigabytes of LPDDR4 memory, and 32 gigabytes of eMMC storage. A companion baseboard provides connectivity including Ethernet, USB, HDMI, and audio.Together, the boards incorporate 843 components and 5,141 electrical connections, or \"pins,\" routed across eight-layer circuit board stackups manufactured by Sierra Circuits in California. The minimum trace geometry reached 2 mils (two-thousandths of an inch) on the system-on-module — fine enough to require advanced high-density interconnect manufacturing techniques.Quilter&#x27;s AI completed the layout with approximately 98 percent routing coverage and zero design rule violations. Both boards passed power-on testing and successfully booted Debian Linux on the first attempt.\"We made an entire computer to demonstrate that this technology works,\" Nesterenko said. \"We took something that&#x27;s typically quoted at 400 to 450 hours, automated the vast majority of it, and reduced it to about 30 to 40 hours of cleanup time.\"The cleanup time is work that human engineers still perform: reviewing the AI&#x27;s output, fixing any issues, and preparing final fabrication files. But even with that overhead, the total elapsed time from schematic to fabricated boards collapsed from the typical 11 weeks to a single week.Unlike ChatGPT, Quilter&#x27;s AI learns by playing billions of games against the laws of physicsQuilter&#x27;s technical approach differs fundamentally from the large language models that have dominated recent AI headlines. Where systems like GPT-5 or Claude learn to predict text based on massive training datasets of human writing, Quilter&#x27;s AI learns by playing what amounts to an elaborate game against the laws of physics.\"Language models don&#x27;t apply to us because this is not a language problem,\" Nesterenko explained. \"If you ask it to actually create a blueprint, it has no training data for that. It has no context for that.\"The company also rejected the seemingly obvious approach of training on examples of human-designed boards. Nesterenko cited three reasons: humans make frequent errors (explaining why most boards require revisions), the best designs are locked inside large companies unwilling to share proprietary data, and training on human examples would cap the AI&#x27;s performance at human levels.Instead, Quilter built what Nesterenko describes as a \"game\" where the AI agent makes sequential decisions — place this component here, route this trace there — and receives feedback based on whether the resulting design satisfies electromagnetic, thermal, and manufacturing constraints.\"What you&#x27;re really changing is not the probability of getting a very specific outcome of the model, but the probability of choosing a certain action based on that experience,\" Nesterenko said.The approach mirrors DeepMind&#x27;s progression with its Go-playing systems. The original AlphaGo learned from human games, but its successor AlphaZero learned purely through self-play and ultimately surpassed human capability. Quilter harbors similar ambitions.\"In the long term, to come up with better designs for circuit boards than humans have ever tried to do,\" Nesterenko said.Fadell drew a parallel to an earlier technological transition: \"I remember this with assembly. You had assembly and compilers, and engineers would say, &#x27;I can&#x27;t trust the compiler. I&#x27;m going to do the loop unrolling myself.&#x27; Now very, very few people write any assembly.\"He expects PCB design to follow a similar arc: \"I hope the same thing happens with PCB design. Sure, a few people will hold out, but these tools are going to get so good that everyone else will move on.\"Fadell and Nesterenko spent months solving a delicate problem: how to automate design without stripping engineers of controlAutomating a task that skilled professionals have performed manually for decades raises an obvious question: how do engineers maintain control over designs that will ultimately ship in products where reliability matters?Fadell said he spent significant time with Nesterenko working through this tension. The solution, he said, lies in allowing users to choose their level of involvement at each stage of the process.\"If you&#x27;re a control freak, you can be a control freak. If you want to say &#x27;just do it for me,&#x27; you can do that too—and everything in between,\" Fadell said. \"You can walk through each phase of the design and get involved wherever you want, or let the AI handle it.\"The workflow breaks into three phases: setup, where engineers define constraints and requirements; execution, where the AI generates candidate layouts; and cleanup, where humans review and refine the output. Engineers can intervene at any point, adjusting constraints and regenerating designs until they&#x27;re satisfied.\"This is something Tony and I talk about a lot,\" Nesterenko said. \"How do we give users control while still automating most of the work?\"Quilter&#x27;s technology has clear boundaries: 10,000 pins and 10 gigahertz mark the current limitsThe technology has clear limitations. Quilter currently handles boards with up to roughly 10,000 pins — sufficient for a wide range of applications but well short of the most complex designs, which can exceed 100,000 connections.Physics complexity also creates boundaries. The system handles high-speed communications up to approximately 10 gigahertz, covering typical consumer electronics and many industrial applications. But advanced systems like sophisticated radar, which can operate at 100 gigahertz, exceed current capabilities.\"There are boards where Quilter won&#x27;t make enough progress to make the cleanup time worthwhile,\" Nesterenko acknowledged. \"We&#x27;re just not that helpful yet with the most advanced, sophisticated designs.\"The company has focused initially on categories where speed matters more than extreme complexity: test fixtures, evaluation boards, design validation boards, and environmental test hardware. These boards often sit in long queues behind higher-priority production designs, delaying engineering programs.The company bets that engineers will pay the same price for a 10x speed improvementQuilter prices its service by pin count, matching the billing conventions that already exist when companies hire outside layout specialists. The pitch to customers is cost neutrality with a ten-fold improvement in speed.\"We&#x27;re going to charge you roughly the same that you would pay for the pins that you would with a person,\" Nesterenko said. \"But the reason you choose us is that we do this 10 times faster.\"For a company waiting three months for a board layout, receiving it in a week fundamentally changes what&#x27;s possible. Engineering teams can run multiple design experiments in parallel. Firmware developers get hardware faster. Products reach the market sooner.The company offers free access for hobbyists, students, and small businesses with less than $50,000 in revenue — a strategy to build familiarity while targeting enterprise customers for commercial revenue.The iPod creator waited years to attach his name to Quilter — until he could prove the technology actually worksFadell said he chose this moment to publicly acknowledge his investment because the Project Speedrun demonstration provides concrete evidence that the technology works.\"It&#x27;s not about being comfortable—I was always comfortable with the team,\" he said. \"This was about waiting until we had something you could hang your hat on. Now I can say, &#x27;I&#x27;ve used the tool. I&#x27;ve seen it.&#x27;\"He contrasted his approach with typical investor announcements: \"Every investor goes, I invested in this, it&#x27;s gonna change the world. It&#x27;s like, no, I know better. I&#x27;ve used the tool. I know people who use it. I asked my startups to use the tool.\"Fadell&#x27;s involvement goes beyond capital. He described email exchanges running to \"a dozen pages of details\" covering product design, user experience, enterprise sales, and technical architecture.\"Of all the investors I work with, Tony by far goes deepest with me on the product side,\" Nesterenko said.If Quilter succeeds, it could unlock a new generation of hardware startups that were never economically viable beforeThe stakes extend far beyond one company&#x27;s product roadmap. If Quilter&#x27;s technology scales, it could fundamentally alter the economics of building physical products.Fadell argued that hardware development has historically moved slowly because each step in the process — schematic design, PCB layout, manufacturing, assembly — created friction. Other innovations have already smoothed schematic tools and manufacturing. Layout remained the stubborn holdout.\"Once you shrink that from weeks to hours, you can iterate so much faster because all the other friction in the chain has been reduced,\" Fadell said.He predicted the technology would eventually extend upstream into schematic design itself, with AI that understands both logical connections and physical constraints helping engineers avoid problems earlier in the process.At MIT, where Fadell now spends time, he encounters would-be founders who have abandoned hardware ambitions because the process seemed insurmountable.\"I talk to professors and startup founders, and they say, &#x27;I&#x27;m never doing hardware. It&#x27;s too hard,&#x27;\" he said. \"I hope we can make it easier for more people to jump in and try things.\"Industry veterans remain skeptical. Auto-routing tools — previous attempts at automation — became notorious for producing unusable results, spawning T-shirts proclaiming engineers would \"never trust the auto-router.\"Nesterenko has seen the skepticism dissolve in real time. He described a recent meeting with executives from a major customer who came to discuss Quilter&#x27;s capabilities. As the conversation unfolded, one executive picked up the Project Speedrun boards and began photographing them from every angle, turning them over in his hands.\"He was just fascinated by the fact that this is possible now,\" Nesterenko said.The question is no longer whether AI can design circuit boards. A working Linux computer, assembled from 843 components and booted on the first attempt, answers that definitively. The question now is what engineers will build when layout stops being the bottleneck — when hardware, as Fadell put it, finally \"moves at the speed of thought.\"On that point, Nesterenko offered a prediction. \"If you ask the average electrical engineer today whether automation or AI could at all help with the board of this complexity, they would say no,\" he said. For decades, they would have been right. As of last week, they&#x27;re not.",
          "content": "A Los Angeles-based startup has demonstrated what it calls a breakthrough in hardware development: an artificial intelligence system that designed a fully functional Linux computer in one week — a process that would typically consume nearly three months of skilled engineering labor.Quilter, which has raised more than $40 million from investors including Benchmark, Index Ventures, and Coatue, used its physics-driven AI to automate the design of a two-board computer system that booted successfully on its first attempt, requiring no costly revisions. The project, internally dubbed \"Project Speedrun,\" required just 38.5 hours of human labor compared to the 428 hours that professional PCB designers quoted for the same task.The announcement also marks the first public disclosure that Tony Fadell, the engineer who led development of the iPod and iPhone at Apple and later founded Nest, has invested in the company and serves as an advisor.\"We didn&#x27;t teach Quilter to draw; we taught it to think in physics,\" said Sergiy Nesterenko, Quilter&#x27;s chief executive and a former SpaceX engineer, in an exclusive interview with VentureBeat. \"The result wasn&#x27;t a simulation — it was a working computer.\"Circuit board design remains the forgotten bottleneck that delays nearly every hardware productThe announcement shines a light on an unglamorous but critical chokepoint in technology development: printed circuit board layout. While semiconductors and software have received enormous attention and investment, the green fiberglass boards that connect chips, memory, and components in virtually every electronic device remain stubbornly manual to design.\"Besides auto-routers, the technology really hadn&#x27;t changed since the early &#x27;90s,\" Fadell told VentureBeat. \"The best boards are still made by hand. You go to Apple, they&#x27;ve got the tools, and these guys are just pushing traces, checking everything, doing flood fills—and you&#x27;re like, there&#x27;s got to be a better way.\"The PCB design process typically unfolds in three stages. Engineers first create a schematic — a logical diagram showing how components connect. Then a specialist manually draws the physical layout in CAD software, placing components and routing thousands of copper traces across multiple layers. Finally, the design goes to a manufacturer for fabrication.That middle step — the layout — creates a persistent bottleneck. For a board of moderate complexity, the process typically consumes four to eight weeks. For sophisticated systems like computers or automotive electronics, timelines stretch to three months or longer.\"The timeline was always this elastic thing—they&#x27;d say, &#x27;Yeah, that&#x27;s two weeks minimum,&#x27;\" Fadell recalled of his experience at Apple and Nest. \"And we&#x27;d say, &#x27;No, no. Work day and night. It&#x27;s two weeks.&#x27; But it was always this fixed bottleneck.\"The consequences ripple through hardware organizations. Firmware teams sit idle waiting for physical boards to test their code. Validation engineers cannot begin debugging. Product launches slip. According to Quilter&#x27;s research, only about 10 percent of first board revisions work correctly, forcing expensive and time-consuming respins.Project Speedrun put Quilter&#x27;s AI to the test with an 843-component computer that booted on the first tryProject Speedrun was designed to push the technology to its limits while producing an easily understood result: a working computer that could boot Linux, browse the internet, and run applications.The system consists of two boards based on NXP&#x27;s i.MX 8M Mini reference platform, a processor architecture used in automotive infotainment, industrial automation, and machine vision applications.The main system-on-module contains a quad-core ARM processor running at 1.8 gigahertz, 2 gigabytes of LPDDR4 memory, and 32 gigabytes of eMMC storage. A companion baseboard provides connectivity including Ethernet, USB, HDMI, and audio.Together, the boards incorporate 843 components and 5,141 electrical connections, or \"pins,\" routed across eight-layer circuit board stackups manufactured by Sierra Circuits in California. The minimum trace geometry reached 2 mils (two-thousandths of an inch) on the system-on-module — fine enough to require advanced high-density interconnect manufacturing techniques.Quilter&#x27;s AI completed the layout with approximately 98 percent routing coverage and zero design rule violations. Both boards passed power-on testing and successfully booted Debian Linux on the first attempt.\"We made an entire computer to demonstrate that this technology works,\" Nesterenko said. \"We took something that&#x27;s typically quoted at 400 to 450 hours, automated the vast majority of it, and reduced it to about 30 to 40 hours of cleanup time.\"The cleanup time is work that human engineers still perform: reviewing the AI&#x27;s output, fixing any issues, and preparing final fabrication files. But even with that overhead, the total elapsed time from schematic to fabricated boards collapsed from the typical 11 weeks to a single week.Unlike ChatGPT, Quilter&#x27;s AI learns by playing billions of games against the laws of physicsQuilter&#x27;s technical approach differs fundamentally from the large language models that have dominated recent AI headlines. Where systems like GPT-5 or Claude learn to predict text based on massive training datasets of human writing, Quilter&#x27;s AI learns by playing what amounts to an elaborate game against the laws of physics.\"Language models don&#x27;t apply to us because this is not a language problem,\" Nesterenko explained. \"If you ask it to actually create a blueprint, it has no training data for that. It has no context for that.\"The company also rejected the seemingly obvious approach of training on examples of human-designed boards. Nesterenko cited three reasons: humans make frequent errors (explaining why most boards require revisions), the best designs are locked inside large companies unwilling to share proprietary data, and training on human examples would cap the AI&#x27;s performance at human levels.Instead, Quilter built what Nesterenko describes as a \"game\" where the AI agent makes sequential decisions — place this component here, route this trace there — and receives feedback based on whether the resulting design satisfies electromagnetic, thermal, and manufacturing constraints.\"What you&#x27;re really changing is not the probability of getting a very specific outcome of the model, but the probability of choosing a certain action based on that experience,\" Nesterenko said.The approach mirrors DeepMind&#x27;s progression with its Go-playing systems. The original AlphaGo learned from human games, but its successor AlphaZero learned purely through self-play and ultimately surpassed human capability. Quilter harbors similar ambitions.\"In the long term, to come up with better designs for circuit boards than humans have ever tried to do,\" Nesterenko said.Fadell drew a parallel to an earlier technological transition: \"I remember this with assembly. You had assembly and compilers, and engineers would say, &#x27;I can&#x27;t trust the compiler. I&#x27;m going to do the loop unrolling myself.&#x27; Now very, very few people write any assembly.\"He expects PCB design to follow a similar arc: \"I hope the same thing happens with PCB design. Sure, a few people will hold out, but these tools are going to get so good that everyone else will move on.\"Fadell and Nesterenko spent months solving a delicate problem: how to automate design without stripping engineers of controlAutomating a task that skilled professionals have performed manually for decades raises an obvious question: how do engineers maintain control over designs that will ultimately ship in products where reliability matters?Fadell said he spent significant time with Nesterenko working through this tension. The solution, he said, lies in allowing users to choose their level of involvement at each stage of the process.\"If you&#x27;re a control freak, you can be a control freak. If you want to say &#x27;just do it for me,&#x27; you can do that too—and everything in between,\" Fadell said. \"You can walk through each phase of the design and get involved wherever you want, or let the AI handle it.\"The workflow breaks into three phases: setup, where engineers define constraints and requirements; execution, where the AI generates candidate layouts; and cleanup, where humans review and refine the output. Engineers can intervene at any point, adjusting constraints and regenerating designs until they&#x27;re satisfied.\"This is something Tony and I talk about a lot,\" Nesterenko said. \"How do we give users control while still automating most of the work?\"Quilter&#x27;s technology has clear boundaries: 10,000 pins and 10 gigahertz mark the current limitsThe technology has clear limitations. Quilter currently handles boards with up to roughly 10,000 pins — sufficient for a wide range of applications but well short of the most complex designs, which can exceed 100,000 connections.Physics complexity also creates boundaries. The system handles high-speed communications up to approximately 10 gigahertz, covering typical consumer electronics and many industrial applications. But advanced systems like sophisticated radar, which can operate at 100 gigahertz, exceed current capabilities.\"There are boards where Quilter won&#x27;t make enough progress to make the cleanup time worthwhile,\" Nesterenko acknowledged. \"We&#x27;re just not that helpful yet with the most advanced, sophisticated designs.\"The company has focused initially on categories where speed matters more than extreme complexity: test fixtures, evaluation boards, design validation boards, and environmental test hardware. These boards often sit in long queues behind higher-priority production designs, delaying engineering programs.The company bets that engineers will pay the same price for a 10x speed improvementQuilter prices its service by pin count, matching the billing conventions that already exist when companies hire outside layout specialists. The pitch to customers is cost neutrality with a ten-fold improvement in speed.\"We&#x27;re going to charge you roughly the same that you would pay for the pins that you would with a person,\" Nesterenko said. \"But the reason you choose us is that we do this 10 times faster.\"For a company waiting three months for a board layout, receiving it in a week fundamentally changes what&#x27;s possible. Engineering teams can run multiple design experiments in parallel. Firmware developers get hardware faster. Products reach the market sooner.The company offers free access for hobbyists, students, and small businesses with less than $50,000 in revenue — a strategy to build familiarity while targeting enterprise customers for commercial revenue.The iPod creator waited years to attach his name to Quilter — until he could prove the technology actually worksFadell said he chose this moment to publicly acknowledge his investment because the Project Speedrun demonstration provides concrete evidence that the technology works.\"It&#x27;s not about being comfortable—I was always comfortable with the team,\" he said. \"This was about waiting until we had something you could hang your hat on. Now I can say, &#x27;I&#x27;ve used the tool. I&#x27;ve seen it.&#x27;\"He contrasted his approach with typical investor announcements: \"Every investor goes, I invested in this, it&#x27;s gonna change the world. It&#x27;s like, no, I know better. I&#x27;ve used the tool. I know people who use it. I asked my startups to use the tool.\"Fadell&#x27;s involvement goes beyond capital. He described email exchanges running to \"a dozen pages of details\" covering product design, user experience, enterprise sales, and technical architecture.\"Of all the investors I work with, Tony by far goes deepest with me on the product side,\" Nesterenko said.If Quilter succeeds, it could unlock a new generation of hardware startups that were never economically viable beforeThe stakes extend far beyond one company&#x27;s product roadmap. If Quilter&#x27;s technology scales, it could fundamentally alter the economics of building physical products.Fadell argued that hardware development has historically moved slowly because each step in the process — schematic design, PCB layout, manufacturing, assembly — created friction. Other innovations have already smoothed schematic tools and manufacturing. Layout remained the stubborn holdout.\"Once you shrink that from weeks to hours, you can iterate so much faster because all the other friction in the chain has been reduced,\" Fadell said.He predicted the technology would eventually extend upstream into schematic design itself, with AI that understands both logical connections and physical constraints helping engineers avoid problems earlier in the process.At MIT, where Fadell now spends time, he encounters would-be founders who have abandoned hardware ambitions because the process seemed insurmountable.\"I talk to professors and startup founders, and they say, &#x27;I&#x27;m never doing hardware. It&#x27;s too hard,&#x27;\" he said. \"I hope we can make it easier for more people to jump in and try things.\"Industry veterans remain skeptical. Auto-routing tools — previous attempts at automation — became notorious for producing unusable results, spawning T-shirts proclaiming engineers would \"never trust the auto-router.\"Nesterenko has seen the skepticism dissolve in real time. He described a recent meeting with executives from a major customer who came to discuss Quilter&#x27;s capabilities. As the conversation unfolded, one executive picked up the Project Speedrun boards and began photographing them from every angle, turning them over in his hands.\"He was just fascinated by the fact that this is possible now,\" Nesterenko said.The question is no longer whether AI can design circuit boards. A working Linux computer, assembled from 843 components and booted on the first attempt, answers that definitively. The question now is what engineers will build when layout stops being the bottleneck — when hardware, as Fadell put it, finally \"moves at the speed of thought.\"On that point, Nesterenko offered a prediction. \"If you ask the average electrical engineer today whether automation or AI could at all help with the board of this complexity, they would say no,\" he said. For decades, they would have been right. As of last week, they&#x27;re not.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3ibU0O0ON6nC4NSVY5KYkP/e13a276f2bece890100148b10cbcf165/nuneybits_Vector_art_of_self-building_computer_isometric_ca3b7721-5759-4033-9885-e096e5d68ddc.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/how-huds-runtime-sensor-cut-triage-time-from-3-hours-to-10-minutes",
          "published_at": "Wed, 10 Dec 2025 14:00:00 GMT",
          "title": "How Hud's runtime sensor cut triage time from 3 hours to 10 minutes",
          "standfirst": "Engineering teams are generating more code with AI agents than ever before. But they&#x27;re hitting a wall when that code reaches production.The problem isn&#x27;t necessarily the AI-generated code itself. It&#x27;s that traditional monitoring tools generally struggle to provide the granular, function-level data AI agents need to understand how code actually behaves in complex production environments. Without that context, agents can&#x27;t detect issues or generate fixes that account for production reality.It&#x27;s a challenge that startup Hud is looking to help solve with the launch of its runtime code sensor on Wednesday. The company&#x27;s eponymous sensor runs alongside production code, automatically tracking how every function behaves, giving developers a heads-up on what&#x27;s actually occurring in deployment.\"Every software team building at scale faces the same fundamental challenge: building high-quality products that work well in the real world,\" Roee Adler, CEO and founder of Hud, told VentureBeat in an exclusive interview. \"In the new era of AI-accelerated development, not knowing how code behaves in production becomes an even bigger part of that challenge.\"What software developers are struggling with The pain points that developers are facing are fairly consistent across engineering organizations. Moshik Eilon, group tech lead at Monday.com, oversees 130 engineer and describes a familiar frustration with traditional monitoring tools.\"When you get an alert, you usually end up checking an endpoint that has an error rate or high latency, and you want to drill down to see the downstream dependencies,\" Eilon told VentureBeat. \"A lot of times it&#x27;s the actual application, and then it&#x27;s a black box. You just get 80% downstream latency on the application.\"The next step typically involves manual detective work across multiple tools. Check the logs. Correlate timestamps. Try to reconstruct what the application was doing. For novel issues deep in a large codebase, teams often lack the exact data they need.Daniel Marashlian, CTO and co-founder at Drata, saw his engineers spending hours on what he referred to as an \"investigation tax.\" \"They were mapping a generic alert to a specific code owner, then digging through logs to reconstruct the state of the application,\" Marashlian told VentureBeat. \"We wanted to eliminate that so our team could focus entirely on the fix rather than the discovery.\"Drata&#x27;s architecture compounds the challenge. The company integrates with numerous external services to deliver automated compliance, which creates sophisticated investigations when issues arise. Engineers trace behavior across a very large codebase spanning risk, compliance, integrations, and reporting modules.Marashlian identified three specific problems that drove Drata toward investing in runtime sensors. The first issue was the cost of context switching. \"Our data was scattered, so our engineers had to act as human bridges between disconnected tools,\" he said.The second issue, he noted, is alert fatigue. \"When you have a complex distributed system, general alert channels become a constant stream of background noise, what our team describes as a &#x27;ding, ding, ding&#x27; effect that eventually gets ignored,\" Marashlian said.The third key driver was a need to integrate with the company&#x27;s AI strategy.\"An AI agent can write code, but it cannot fix a production bug if it can&#x27;t see the runtime variables or the root cause,\" Marashlian said.Why traditional APMs can&#x27;t solve the problem easilyEnterprises have long relied on a class of tools and services known as Application Performance Monitoring (APM). With the current pace of agentic AI development and modern development workflows, both Monday.com and Drata simply were not able to get the required visibility from existing APM tools.\"If I would want to get this information from Datadog or from CoreLogix, I would just have to ingest tons of logs or tons of spans, and I would pay a lot of money,\" Eilon said. Eilon noted that Monday.com used very low sampling rates because of cost constraints. That meant they often missed the exact data needed to debug issues.Traditional application performance monitoring tools also require prediction, which is a problem because sometimes a developer just doesn&#x27;t know what they don&#x27;t know.\"Traditional observability requires you to anticipate what you&#x27;ll need to debug,\" Marashlian said. \"But when a novel issue surfaces, especially deep within a large, complex codebase, you&#x27;re often missing the exact data you need.\"Drata evaluated several solutions in the AI site reliability engineering and automated incident response categories and didn&#x27;t find what was needed. \"Most tools we evaluated were excellent at managing the incident process, routing tickets, summarizing Slack threads, or correlating graphs,\" he said. \"But they often stopped short of the code itself. They could tell us &#x27;Service A is down,&#x27; but they couldn&#x27;t tell us why specifically.\"Another common capability in some tools including error monitors like Sentry is the ability to capture exceptions. The challenge, according to Adler, is that being made aware of exceptions is nice, but that doesn&#x27;t connect them to business impact or provide the execution context AI agents need to propose fixes.How runtime sensors work differentlyRuntime sensors push intelligence to the edge where code executes. Hud&#x27;s sensor runs as an SDK that integrates with a single line of code. It sees every function execution but only sends lightweight aggregate data unless something goes wrong.When errors or slowdowns occur, the sensor automatically gathers deep forensic data including HTTP parameters, database queries and responses, and full execution context. The system establishes performance baselines within a day and can alert on both dramatic slowdowns and outliers that percentile-based monitoring misses.\"Now we just get all of this information for all of the functions regardless of what level they are, even for underlying packages,\" Eilon said. \"Sometimes you might have an issue that is very deep, and we still see it pretty fast.\"The platform delivers data through four channels:Web application for centralized monitoring and analysisIDE extensions for VS Code, JetBrains and Cursor that surface production metrics directly where code is writtenMCP server that feeds structured data to AI coding agentsAlerting system that identifies issues without manual configurationThe MCP server integration is critical for AI-assisted development. Monday.com engineers now query production behavior directly within Cursor. \"I can just ask Cursor a question: Hey, why is this endpoint slow?\" Eilon said. \"When it uses the Hud MCP, I get all of the granular metrics, and this function is 30% slower since this deployment. Then I can also find the root cause.\"This changes the incident response workflow. Instead of starting in Datadog and drilling down through layers, engineers start by asking an AI agent to diagnose the issue. The agent has immediate access to function-level production data.From voodoo incidents to minutes-long fixesThe shift from theoretical capability to practical impact becomes clear in how engineering teams actually use runtime sensors. What used to take hours or days of detective work now resolves in minutes.\"I&#x27;m used to having these voodoo incidents where there is a CPU spike and you don&#x27;t know where it came from,\" Eilon said. \"A few years ago, I had such an incident and I had to build my own tool that takes the CPU profile and the memory dump. Now I just have all of the function data and I&#x27;ve seen engineers just solve it so fast.\"At Drata, the quantified impact is dramatic. The company built an internal /triage command that support engineers run within their AI assistants to instantly identify root causes. Manual triage work dropped from approximately 3 hours per day to under 10 minutes. Mean time to resolution improved by approximately 70%.The team also generates a daily \"Heads Up\" report of quick-win errors. Because the root cause is already captured, developers can fix these issues in minutes. Support engineers now perform forensic diagnosis that previously required a senior developer. Ticket throughput increased without expanding the L2 team.Where this technology fitsRuntime sensors occupy a distinct space from traditional APMs, which excel at service-level monitoring but struggle with granular, cost-effective function-level data. They differ from error monitors that capture exceptions without business context.The technical requirements for supporting AI coding agents differ from human-facing observability. Agents need structured, function-level data they can reason over. They can&#x27;t parse and correlate raw logs the way humans do. Traditional observability also assumes you can predict what you&#x27;ll need to debug and instrument accordingly. That approach breaks down with AI-generated code where engineers may not deeply understand every function.\"I think we&#x27;re entering a new age of AI-generated code and this puzzle, this jigsaw puzzle of a new stack emerging,\" Adler said. \"I just don&#x27;t think that the cloud computing observability stack is going to fit neatly into how the future looks like.\"What this means for enterprisesFor organizations already using AI coding assistants like GitHub Copilot or Cursor, runtime intelligence provides a safety layer for production deployments. The technology enables what Monday.com calls \"agentic investigation\" rather than manual tool-hopping.The broader implication relates to trust. \"With AI-generated code, we are getting much more AI-generated code, and engineers start not knowing all of the code,\" Eilon said. Runtime sensors bridge that knowledge gap by providing production context directly in the IDE where code is written.For enterprises looking to scale AI code generation beyond pilots, runtime intelligence addresses a fundamental problem. AI agents generate code based on assumptions about system behavior. Production environments are complex and surprising. Function-level behavioral data captured automatically from production gives agents the context they need to generate reliable code at scale.Organizations should evaluate whether their existing observability stack can cost-effectively provide the granularity AI agents require. If achieving function-level visibility requires dramatically increasing ingestion costs or manual instrumentation, runtime sensors may offer a more sustainable architecture for AI-accelerated development workflows already emerging across the industry.",
          "content": "Engineering teams are generating more code with AI agents than ever before. But they&#x27;re hitting a wall when that code reaches production.The problem isn&#x27;t necessarily the AI-generated code itself. It&#x27;s that traditional monitoring tools generally struggle to provide the granular, function-level data AI agents need to understand how code actually behaves in complex production environments. Without that context, agents can&#x27;t detect issues or generate fixes that account for production reality.It&#x27;s a challenge that startup Hud is looking to help solve with the launch of its runtime code sensor on Wednesday. The company&#x27;s eponymous sensor runs alongside production code, automatically tracking how every function behaves, giving developers a heads-up on what&#x27;s actually occurring in deployment.\"Every software team building at scale faces the same fundamental challenge: building high-quality products that work well in the real world,\" Roee Adler, CEO and founder of Hud, told VentureBeat in an exclusive interview. \"In the new era of AI-accelerated development, not knowing how code behaves in production becomes an even bigger part of that challenge.\"What software developers are struggling with The pain points that developers are facing are fairly consistent across engineering organizations. Moshik Eilon, group tech lead at Monday.com, oversees 130 engineer and describes a familiar frustration with traditional monitoring tools.\"When you get an alert, you usually end up checking an endpoint that has an error rate or high latency, and you want to drill down to see the downstream dependencies,\" Eilon told VentureBeat. \"A lot of times it&#x27;s the actual application, and then it&#x27;s a black box. You just get 80% downstream latency on the application.\"The next step typically involves manual detective work across multiple tools. Check the logs. Correlate timestamps. Try to reconstruct what the application was doing. For novel issues deep in a large codebase, teams often lack the exact data they need.Daniel Marashlian, CTO and co-founder at Drata, saw his engineers spending hours on what he referred to as an \"investigation tax.\" \"They were mapping a generic alert to a specific code owner, then digging through logs to reconstruct the state of the application,\" Marashlian told VentureBeat. \"We wanted to eliminate that so our team could focus entirely on the fix rather than the discovery.\"Drata&#x27;s architecture compounds the challenge. The company integrates with numerous external services to deliver automated compliance, which creates sophisticated investigations when issues arise. Engineers trace behavior across a very large codebase spanning risk, compliance, integrations, and reporting modules.Marashlian identified three specific problems that drove Drata toward investing in runtime sensors. The first issue was the cost of context switching. \"Our data was scattered, so our engineers had to act as human bridges between disconnected tools,\" he said.The second issue, he noted, is alert fatigue. \"When you have a complex distributed system, general alert channels become a constant stream of background noise, what our team describes as a &#x27;ding, ding, ding&#x27; effect that eventually gets ignored,\" Marashlian said.The third key driver was a need to integrate with the company&#x27;s AI strategy.\"An AI agent can write code, but it cannot fix a production bug if it can&#x27;t see the runtime variables or the root cause,\" Marashlian said.Why traditional APMs can&#x27;t solve the problem easilyEnterprises have long relied on a class of tools and services known as Application Performance Monitoring (APM). With the current pace of agentic AI development and modern development workflows, both Monday.com and Drata simply were not able to get the required visibility from existing APM tools.\"If I would want to get this information from Datadog or from CoreLogix, I would just have to ingest tons of logs or tons of spans, and I would pay a lot of money,\" Eilon said. Eilon noted that Monday.com used very low sampling rates because of cost constraints. That meant they often missed the exact data needed to debug issues.Traditional application performance monitoring tools also require prediction, which is a problem because sometimes a developer just doesn&#x27;t know what they don&#x27;t know.\"Traditional observability requires you to anticipate what you&#x27;ll need to debug,\" Marashlian said. \"But when a novel issue surfaces, especially deep within a large, complex codebase, you&#x27;re often missing the exact data you need.\"Drata evaluated several solutions in the AI site reliability engineering and automated incident response categories and didn&#x27;t find what was needed. \"Most tools we evaluated were excellent at managing the incident process, routing tickets, summarizing Slack threads, or correlating graphs,\" he said. \"But they often stopped short of the code itself. They could tell us &#x27;Service A is down,&#x27; but they couldn&#x27;t tell us why specifically.\"Another common capability in some tools including error monitors like Sentry is the ability to capture exceptions. The challenge, according to Adler, is that being made aware of exceptions is nice, but that doesn&#x27;t connect them to business impact or provide the execution context AI agents need to propose fixes.How runtime sensors work differentlyRuntime sensors push intelligence to the edge where code executes. Hud&#x27;s sensor runs as an SDK that integrates with a single line of code. It sees every function execution but only sends lightweight aggregate data unless something goes wrong.When errors or slowdowns occur, the sensor automatically gathers deep forensic data including HTTP parameters, database queries and responses, and full execution context. The system establishes performance baselines within a day and can alert on both dramatic slowdowns and outliers that percentile-based monitoring misses.\"Now we just get all of this information for all of the functions regardless of what level they are, even for underlying packages,\" Eilon said. \"Sometimes you might have an issue that is very deep, and we still see it pretty fast.\"The platform delivers data through four channels:Web application for centralized monitoring and analysisIDE extensions for VS Code, JetBrains and Cursor that surface production metrics directly where code is writtenMCP server that feeds structured data to AI coding agentsAlerting system that identifies issues without manual configurationThe MCP server integration is critical for AI-assisted development. Monday.com engineers now query production behavior directly within Cursor. \"I can just ask Cursor a question: Hey, why is this endpoint slow?\" Eilon said. \"When it uses the Hud MCP, I get all of the granular metrics, and this function is 30% slower since this deployment. Then I can also find the root cause.\"This changes the incident response workflow. Instead of starting in Datadog and drilling down through layers, engineers start by asking an AI agent to diagnose the issue. The agent has immediate access to function-level production data.From voodoo incidents to minutes-long fixesThe shift from theoretical capability to practical impact becomes clear in how engineering teams actually use runtime sensors. What used to take hours or days of detective work now resolves in minutes.\"I&#x27;m used to having these voodoo incidents where there is a CPU spike and you don&#x27;t know where it came from,\" Eilon said. \"A few years ago, I had such an incident and I had to build my own tool that takes the CPU profile and the memory dump. Now I just have all of the function data and I&#x27;ve seen engineers just solve it so fast.\"At Drata, the quantified impact is dramatic. The company built an internal /triage command that support engineers run within their AI assistants to instantly identify root causes. Manual triage work dropped from approximately 3 hours per day to under 10 minutes. Mean time to resolution improved by approximately 70%.The team also generates a daily \"Heads Up\" report of quick-win errors. Because the root cause is already captured, developers can fix these issues in minutes. Support engineers now perform forensic diagnosis that previously required a senior developer. Ticket throughput increased without expanding the L2 team.Where this technology fitsRuntime sensors occupy a distinct space from traditional APMs, which excel at service-level monitoring but struggle with granular, cost-effective function-level data. They differ from error monitors that capture exceptions without business context.The technical requirements for supporting AI coding agents differ from human-facing observability. Agents need structured, function-level data they can reason over. They can&#x27;t parse and correlate raw logs the way humans do. Traditional observability also assumes you can predict what you&#x27;ll need to debug and instrument accordingly. That approach breaks down with AI-generated code where engineers may not deeply understand every function.\"I think we&#x27;re entering a new age of AI-generated code and this puzzle, this jigsaw puzzle of a new stack emerging,\" Adler said. \"I just don&#x27;t think that the cloud computing observability stack is going to fit neatly into how the future looks like.\"What this means for enterprisesFor organizations already using AI coding assistants like GitHub Copilot or Cursor, runtime intelligence provides a safety layer for production deployments. The technology enables what Monday.com calls \"agentic investigation\" rather than manual tool-hopping.The broader implication relates to trust. \"With AI-generated code, we are getting much more AI-generated code, and engineers start not knowing all of the code,\" Eilon said. Runtime sensors bridge that knowledge gap by providing production context directly in the IDE where code is written.For enterprises looking to scale AI code generation beyond pilots, runtime intelligence addresses a fundamental problem. AI agents generate code based on assumptions about system behavior. Production environments are complex and surprising. Function-level behavioral data captured automatically from production gives agents the context they need to generate reliable code at scale.Organizations should evaluate whether their existing observability stack can cost-effectively provide the granularity AI agents require. If achieving function-level visibility requires dramatically increasing ingestion costs or manual instrumentation, runtime sensors may offer a more sustainable architecture for AI-accelerated development workflows already emerging across the industry.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5OFBMkrEKqvqYY0hbPYaoF/e31f8e8b39af32f6197a402b42f96136/hud-code-dev-smk.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/instagram-will-let-you-control-which-topics-its-algorithm-recommends-133002612.html",
          "published_at": "Wed, 10 Dec 2025 13:30:02 +0000",
          "title": "Instagram will let you control which topics its algorithm recommends",
          "standfirst": "For the first time, Instagram will start letting you control the topics its algorithm recommends, much as you now can on TikTok. The new feature is starting with the Reels tab but will eventually come to Explore and other areas of the app. Like much of what Meta is doing right now (for better or worse), the \"Your Algorithm\" feature will be powered by AI. \"As your interests evolve over time, we want to give you more meaningful ways to control what you see,\" Instagram wrote on its blog post. \"Using AI, you can now more easily view and personalize the topics that shape your Reels, making recommendations feel even more tailored to you.\" To see and control the Reels algorithm, tap the icon in the upper right corner (two lines with hearts) to open Your Algorithm. It will show what topics Instagram thinks you're interested in, then you can specify which ones you want to see more or less of and your recommendations will adapt. You can fine tune topics as well: See your top interests: View a summary of the topics Instagram thinks you care about most, right at the top. Tune your preferences: Type in the topics you want to see more or less of, and your Reels will reflect your choices. Share your algorithm: If you’d like, you can share your interests to your Story, so friends and followers can see what you’re into. Another AI \"feature\" that surfaced yesterday on the platform didn't go over well with some users. It was discovered that Instagram was generating sensational and often inaccurate headlines that were likely created by an LLM. And you can expect AI to infiltrate its apps even more down the road, judging by the company's recent acquisitions and priority shifts. In any case, the new Your Algorithm feature for the Reels tab is debuting today in the US only and expanding to other territories in the future.This article originally appeared on Engadget at https://www.engadget.com/social-media/instagram-will-let-you-control-which-topics-its-algorithm-recommends-133002612.html?src=rss",
          "content": "For the first time, Instagram will start letting you control the topics its algorithm recommends, much as you now can on TikTok. The new feature is starting with the Reels tab but will eventually come to Explore and other areas of the app. Like much of what Meta is doing right now (for better or worse), the \"Your Algorithm\" feature will be powered by AI. \"As your interests evolve over time, we want to give you more meaningful ways to control what you see,\" Instagram wrote on its blog post. \"Using AI, you can now more easily view and personalize the topics that shape your Reels, making recommendations feel even more tailored to you.\" To see and control the Reels algorithm, tap the icon in the upper right corner (two lines with hearts) to open Your Algorithm. It will show what topics Instagram thinks you're interested in, then you can specify which ones you want to see more or less of and your recommendations will adapt. You can fine tune topics as well: See your top interests: View a summary of the topics Instagram thinks you care about most, right at the top. Tune your preferences: Type in the topics you want to see more or less of, and your Reels will reflect your choices. Share your algorithm: If you’d like, you can share your interests to your Story, so friends and followers can see what you’re into. Another AI \"feature\" that surfaced yesterday on the platform didn't go over well with some users. It was discovered that Instagram was generating sensational and often inaccurate headlines that were likely created by an LLM. And you can expect AI to infiltrate its apps even more down the road, judging by the company's recent acquisitions and priority shifts. In any case, the new Your Algorithm feature for the Reels tab is debuting today in the US only and expanding to other territories in the future.This article originally appeared on Engadget at https://www.engadget.com/social-media/instagram-will-let-you-control-which-topics-its-algorithm-recommends-133002612.html?src=rss",
          "feed_position": 27
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/adobe-brings-photoshop-acrobat-and-adobe-express-to-chatgpt-130000389.html",
          "published_at": "Wed, 10 Dec 2025 13:00:00 +0000",
          "title": "Adobe brings Photoshop, Acrobat and Adobe Express to ChatGPT",
          "standfirst": "Back in October, OpenAI announced apps like Spotify and Canva would be accessible in ChatGPT. At the time, the company said more software was on the way, and now one of the most popular professional applications is available through the chatbot. Starting today, you can access Photoshop, Acrobat and Adobe Express inside of ChatGPT. All the apps are free to use through OpenAI’s website, though before you can begin generating PDFs and illustrations using Acrobat and Adobe Express, you'll need to sign into your Adobe account. To use any of the apps in ChatGPT, either name them in your prompt or select them from the plus menu. Of the three apps, the way OpenAI's chatbot connects to Photoshop is probably the most interesting. Depending on the prompt, the interface will change to display the sliders most relevant to your request. For example, if you want to brighten an image, you'll see one slider allowing you to adjust the exposure, alongside other ones for the shadows and highlights. By comparison, if you want to add an effect to an image, ChatGPT might display options related to dithering and tri-tone, among others. What's interesting about all this is the way ChatGPT is interacting with Adobe's tools, through an MCP server, to offer a slice of the company's apps. I don't know about you, but I’ve always found Adobe software to be far too complicated, with often one too many ways to accomplish the same task. Granted, what I saw was a hands-off demo, but the routing Adobe created worked well. A ChatGPT user asks the chatbot to create a dance party invitation. Adobe\"We build the Lego blocks, which are the MCP tools, and we create detailed instructions, and then ChatGPT figures out what it wants to do,\" Aubrey Cattell, vice-president of developer platform and partner ecosystem at Adobe, explains. \"Sometimes it does what we want it, and sometimes it doesn't. That's the nature of it being non-deterministic, and we're continuing to hone as much as we can from users' intent and natural language to give them the result that they're looking for.\"Of course, if you ever want more control, the web versions of Photoshop, Acrobat and Adobe Express are a click away. For OpenAI, this is easily the biggest coup to date of its push to reshape ChatGPT into an operating system for all the apps its more than 800 million users depend on daily. For Adobe, it feels like the company is partnering with an entity out to eat its lunch. After all, OpenAI offers its own image generation. However, Cattell said Adobe doesn't see it that way. \"A couple weeks back, OpenAI dropped Apps SDK as a new paradigm for accessing ChatGPT, we saw there was a natural fit in the work we were doing with our applications,\" he said. \"Essentially, they gave us an operating system we were able to leverage to bring our applications to their surface. There's a lot of natural affinity there between the workflows OpenAI is trying to enable and Adobe's best in class capabilities.\" Cattell promised Adobe would continue to explore what it could offer inside of ChatGPT, but added the company's apps will continue to be the place users can go if they want more power, precision and control.This article originally appeared on Engadget at https://www.engadget.com/ai/adobe-brings-photoshop-acrobat-and-adobe-express-to-chatgpt-130000389.html?src=rss",
          "content": "Back in October, OpenAI announced apps like Spotify and Canva would be accessible in ChatGPT. At the time, the company said more software was on the way, and now one of the most popular professional applications is available through the chatbot. Starting today, you can access Photoshop, Acrobat and Adobe Express inside of ChatGPT. All the apps are free to use through OpenAI’s website, though before you can begin generating PDFs and illustrations using Acrobat and Adobe Express, you'll need to sign into your Adobe account. To use any of the apps in ChatGPT, either name them in your prompt or select them from the plus menu. Of the three apps, the way OpenAI's chatbot connects to Photoshop is probably the most interesting. Depending on the prompt, the interface will change to display the sliders most relevant to your request. For example, if you want to brighten an image, you'll see one slider allowing you to adjust the exposure, alongside other ones for the shadows and highlights. By comparison, if you want to add an effect to an image, ChatGPT might display options related to dithering and tri-tone, among others. What's interesting about all this is the way ChatGPT is interacting with Adobe's tools, through an MCP server, to offer a slice of the company's apps. I don't know about you, but I’ve always found Adobe software to be far too complicated, with often one too many ways to accomplish the same task. Granted, what I saw was a hands-off demo, but the routing Adobe created worked well. A ChatGPT user asks the chatbot to create a dance party invitation. Adobe\"We build the Lego blocks, which are the MCP tools, and we create detailed instructions, and then ChatGPT figures out what it wants to do,\" Aubrey Cattell, vice-president of developer platform and partner ecosystem at Adobe, explains. \"Sometimes it does what we want it, and sometimes it doesn't. That's the nature of it being non-deterministic, and we're continuing to hone as much as we can from users' intent and natural language to give them the result that they're looking for.\"Of course, if you ever want more control, the web versions of Photoshop, Acrobat and Adobe Express are a click away. For OpenAI, this is easily the biggest coup to date of its push to reshape ChatGPT into an operating system for all the apps its more than 800 million users depend on daily. For Adobe, it feels like the company is partnering with an entity out to eat its lunch. After all, OpenAI offers its own image generation. However, Cattell said Adobe doesn't see it that way. \"A couple weeks back, OpenAI dropped Apps SDK as a new paradigm for accessing ChatGPT, we saw there was a natural fit in the work we were doing with our applications,\" he said. \"Essentially, they gave us an operating system we were able to leverage to bring our applications to their surface. There's a lot of natural affinity there between the workflows OpenAI is trying to enable and Adobe's best in class capabilities.\" Cattell promised Adobe would continue to explore what it could offer inside of ChatGPT, but added the company's apps will continue to be the place users can go if they want more power, precision and control.This article originally appeared on Engadget at https://www.engadget.com/ai/adobe-brings-photoshop-acrobat-and-adobe-express-to-chatgpt-130000389.html?src=rss",
          "feed_position": 31,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/AX_Search_"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/smart-home/best-mesh-wifi-system-130028701.html",
          "published_at": "Wed, 10 Dec 2025 10:01:26 +0000",
          "title": "The best mesh Wi-Fi systems of 2025",
          "standfirst": "Spotty Wi-Fi can make even simple tasks feel harder than they should. If you’ve ever had a video call freeze in one room or watched a stream buffer in another, a mesh Wi-Fi system can fix those frustrations. Instead of relying on a single router tucked in a corner, a mesh setup uses multiple units that work together to spread a strong, consistent signal throughout your home.Modern mesh systems are built for busy households. They keep dozens of devices connected at once, manage traffic intelligently and often include helpful app features that make troubleshooting or adjusting settings much easier. Many support the latest Wi-Fi standards and faster internet plans too, so you can upgrade your network without replacing everything else.We’ve tested a range of mesh Wi-Fi systems to find the ones that deliver the best mix of speed, coverage and reliability. Whether you live in a small apartment or a multi-floor home, these picks can help you stay connected wherever you are. Table of contents Best mesh Wi-Fi systems for 2025 What to look for in a mesh Wi-Fi system Other mesh Wi-Fi router systems we tested How we test Wi-Fi routers Mesh Wi-Fi system FAQs Best mesh Wi-Fi systems for 2025 What to look for in a mesh Wi-Fi system Linksys’ CEO Jonathan Bettino told Engadget why mesh systems are an “advancement in Wi-Fi technology” over buying a single point router. With one transmitter, the signal can degrade the further away from the router you go, or the local environment isn’t ideal. “You can have a small [home], but there’s thick walls [...] or things in the way that just interfere with your wireless signal,” he said. Historically, the solution to a home’s Wi-Fi dead zone was to buy a Wi-Fi extender but Bettino said the hardware has both a “terrible user experience” and one of the highest return rates of any consumer electronics product. Mesh Wi-Fi, by comparison, offers “multiple nodes that can be placed anywhere in your home,” says Bettino, resulting in “ubiquitous Wi-Fi” that feels as if you have a “router in every room.” Rather than having one main router in your home, having a “router in every room” is the biggest selling point for mesh Wi-Fi given how reliant we all are on the internet. Each node is in constant contact with each other, broadcasting a single, seamless network to all of your connected devices. There’s no separate network for the 2.4GHz and 5GHz bands, just a single name that you connect to. It’s a good time to buy a mesh Wi-Fi system since the latest standard, Wi-Fi 6E, represents a big leap in the technology. Matt MacPherson, Cisco's Chief Technology Officer for Wireless, said Wi-Fi 6E is a big “inflection point,” using much more of the wireless spectrum than its predecessors. “If you’re using that spectrum with a Wi-Fi 6 [device],” he said, “you’re going to get significant gains [in speed.]” MacPherson added Wi-Fi 6E will likely “carry you for a long time” thanks to the fact its “top throughputs now typically exceed what people can actually connect their home to.” In short, with a top theoretical per-stream speed of 1.2 Gbps, Wi-Fi 6E is fast enough to outrun all but the fastest internet service. What do all these Wi-Fi numbers and letters mean? I’m sorry folks, we need to get boringly technical for one paragraph, but I promise you it’s worth it. Wi-Fi is governed by International Standard IEEE 802.11, and every few years a letter gets added onto that name when the technology evolves and improves. Until 2019, routers were sold under their IEEE name, leaving users to pick through the word soup of a product labeled 802.11 b/g/a/n/ac and so on. Mercifully, wiser heads opted to rebrand the letters as numbers, so rather than 802.11 b/g/a/n/ac, we have Wi-Fi 1, 2, 3 4 and 5. Right now, we’re in the middle of one of those Wi-Fi generations, with most of the gear on sale right now supporting either Wi-Fi 6 or Wi-Fi 6E. What’s the difference between Wi-Fi 6 and Wi-Fi 6E? Wi-Fi uses chunks of the radio frequency spectrum, with Wi-Fi 6 using the 2.4GHz and 5GHz bands to pump data around. In fact, back in the old days, it was likely your home router would offer you the choice of the 2.4GHz or the 5GHz network, as separate bands to access. These days, all of the spectrums are tied together as one thing, and Wi-Fi 6E has the added ability to use the 6GHz band as well. That’s a big chunk of extra wireless real estate that isn’t as cluttered up as the 2.4 and 5GHz bands. You’re going to talk about wireless frequencies now, aren’t you. Each Wi-Fi band had tradeoffs, because the slower radio frequencies have greater range but less speed. 2.4GHz signals will travel a long way in your home but aren’t quick, while 6GHz is blisteringly fast but can be defeated by a sturdy brick wall. A lot of Wi-Fi-enabled gear you own, like smart home products, only use the 2.4GHz band because the range is better and it’s a lot cheaper. But it means that the band is also overcrowded and slow, making it great for your doorbell and robovac, but lackluster for Twitch streaming. So, what am I looking for? Right now, the market is full of mature Wi-Fi 6 and 6E devices, and most new systems available to buy are capable of taking advantage of the faster speeds they offer. This guide focuses on Wi-Fi 6E gear since it’s what we think it’s more than enough to satisfy almost everyone’s at-home Wi-Fi needs. What about Wi-Fi 7? We’re now seeing the first generation of Wi-Fi 7 devices available to buy, but we don’t recommend you do so immediately. The Wi-Fi 7 standard is still so new that there’s little to no reason for you to rush out and buy one for your home. The hardware is tremendously expensive and while Wi-Fi 7 will, eventually, offer some great benefits over 6E, it’s not as transformative an upgrade as 6E. Not to mention, Wi-Fi 7 is so new that almost none of your home’s devices will be able to take advantage of its big-ticket features. I’d estimate you won’t need to worry about upgrading to Wi-Fi 7 for at least five years, if not longer. Range and speed All Wi-Fi routers boast a theoretical broadcast range and a theoretical top speed, and in some cases external antennas to boost signal directionality — but these figures don’t mean much. After all, manufacturers can’t control your ISP’s real speed, the materials and layout of your home or where you put your Wi-Fi gear. Raw speed isn’t everything, either, and you likely need a lot less than the internet speeds your provider is advertising. What matters more is how consistent your connection is between rooms and across devices.. After all, Netflix needs just 15 Mbps to push a single 4K video stream to your home. As cool as it is to say you’ve got all these hundreds of Mbps, factors like latency and reliability are far more crucial to a happy internet life. And unless you have Gigabit internet that can reach speeds of up to 1 Gbps, you won’t need a mesh router that offers that spec. Backhaul Mesh Wi-Fi systems work by connecting every hardware node to a single wireless network, letting them all communicate with each other. Imagine four people in a busy, noisy restaurant all trying to order their dinner from a weary staff member, all at once. Now imagine, while this is going on, that four more people at that same table are also trying to tell a funny anecdote. It’s no surprise that it might take a long time for the right information to reach its intended destination. To combat this, higher-end mesh routers offer dedicated wireless backhaul; a slice of the spectrum for node-to-node communication. So rather than everyone talking at once in the same space, the conversations are essentially separated, reducing the invisible clutter in the air. Because there’s less confusing cross-chatter, everything moves faster, offering a significant performance boost to those systems. Connectivity These days, even your washing machine can have a wireless connection, but that doesn’t mean you should ignore the joys of wired internet. No matter how fast Wi-Fi is, a hard line will always be faster, and some gear, like Philips’ Hue bridge, still needs an ethernet connection. Plenty of routers can also use these hard connections as backhaul, eliminating further wireless clutter. It’s convenient for spread-out systems and power users, but it will mean running more wires through your home. The most common standard is Cat 5e, or gigabit ethernet which, unsurprisingly, has a top speed of 1 Gigabit per second (Gbps). Since Ethernet cables are backward compatible, you should be able to easily find one that works with your system. However, to get the most out of your mesh routers, it’s worth investing in an Ethernet cable that meets the standard your router uses — if it’s Cat 5e, use a Cat 5e cable. You can check your router’s specs via the manufacturer’s website to be sure. Flexibility and scalability Mesh routers enable you to add (or subtract) modules from your home network to suit your needs. D-Link’s Alan Jones said users should “check how scalable the prospective product is” before you buy. This sense of scale doesn’t just apply to the number of nodes on the network, but how many simultaneous connections it can handle. It’s also worth looking at ASUS’ AiMesh products, which can combine mesh Wi-Fi gear and its standard “spider” Wi-Fi routers. If you’ve got a tricky part of your home, you can bolt on an ultra-power standalone Wi-Fi router to a compatible mesh. Placement Mesh networks replace one big piece of hardware with a series of identical nodes that you scatter around your home. You connect one to your modem (usually over ethernet), and then scatter the rest around the place for the best coverage. A good rule of thumb is to place each node no more than two rooms away from the last one, rather than sticking them at the far ends of your home. Bear in mind, every physical obstacle between a Wi-Fi node, its siblings and your devices will hurt your overall performance. You should aim to place them, at the very least, at waist height on furniture in open air, without too many obstructions. The reason many mesh Wi-Fi products are designed to look like an inoffensive white doodad is so you don’t feel compelled to hide them behind your TV. Other mesh Wi-Fi router systems we tested Amazon Eero Pro 7 Eero built its reputation on easy to use yet powerful mesh systems that offer a lot of good in a relatively small and affordable package. Setup is effortless, the app running things is clean and simple, and you get the added benefit of backwards compatibility with older hardware. Sadly, the issue with every Eero system is that so many basic management features, like parental controls, are paywalled behind the company’s Eero Plus subscription for $100 a year. Amazon Eero 6E Eero Pro 6E is an “easy” device, the sort a total novice can set up on their own and thrive with for years on end. There’s little brainwork required to get things set up, and the app has a clean UI with plenty of hand-holding. But, as with the Eero Pro 7, the fact that so many basic management tools are paywalled irks me, especially since you can get plenty of them for free with Google’s rival offering. Netgear Orbi 960 The Orbi 96T0 (RBKE963) is Netgear’s flagship mesh Wi-Fi product, which the company calls the “world’s most powerful Wi-Fi 6E system.” It’s also one of the most expensive consumer-level kits on the market, setting you back $1,499.99 for a three pack. It's a fantastic piece of gear, but it's worth saying that the subset of people who could, would or should buy it remains far smaller than you might expect. Ultimately, I feel that if you’re paying luxury prices, you should expect a luxury product. There were plenty of times during testing that I went looking for a feature that was either only available via the web client, or behind a paywall. While, yes, much of your cash is going to the superlative hardware, but for this sort of money, the fact you have to pay extra for some table-stakes features is insulting. If you’re looking for a new Wi-Fi system and aren’t prepared to spend almost $1,500, it’s worth considering our other top picks for the best Wi-Fi routers and mesh systems. How we test Wi-Fi routers My home covers around 2,200 square feet across three stories with the office on the third floor. It’s relatively long and thin, with the living room at the front of the house, the kitchen at the back and the three bedrooms on the first floor. Its age means there are a lot of solid brick walls, old-school lathe and plaster as well as aluminum foil-backed insulation boards to help with energy efficiency. There are two major Wi-Fi dead zones in the house: The bathroom and the third bedroom behind it, since there’s lots of old and new pipework in the walls and floors. For mesh routers with two nodes, I place the first in my living room, connected via ethernet to my cable modem with the second on the first floor landing in the (ostensible) center of the house. For three-node sets, the third goes in my kitchen, which I’ve found is the optimal layout to get the bulk of my house covered in Wi-Fi. Fundamentally, my home poses enough challenges that if it succeeds here, it stands a very good chance of succeeding in your place. Each mesh is judged on ease of setup, Wi-Fi coverage, reliability, speed and any additional features that it advertises. I look at how user-friendly each companion app is from the perspective of a novice rather than an expert given you shouldn’t need to be a network engineer to do this sort of thing. Tests I do include checking for dead zones, moving from room to room to measure consistency of connectivity and streaming multiple videos at once to replicate common usage patterns. Mesh Wi-Fi system FAQs This is the section of our mesh Wi-Fi buyer’s guide where we talk about the stuff that most people just glide past. If you’re not familiar with technology, it can be intimidating if people talk about these things as if you’re expected to already know. So here’s a very simple, very basic rundown of some of the stuff you might have missed in very basic terms. What’s the difference between a Wi-Fi router and a mesh router? A Wi-Fi router is a box that usually sits close to wherever the internet comes into your home and pumps out information over radio waves. A mesh router, meanwhile, is a set of smaller devices, one of which sits next to your internet connection while the rest are scattered around your home. A single Wi-Fi router is great if your home is small, your needs aren’t too demanding, or if your home doesn’t have many radio-blocking obstructions that mean those signals can’t reach every corner of your home. But, much like standing next to a radio transmitter and then walking away from it in a straight line, after a while, the signal will degrade. That’s the problem a mesh system is designed to solve, since it will take the signal from your modem and pump to the other mesh devices, known as nodes, in your home. That way, instead of having one big router in one part of your home, you have several small ones that ensure you have good Wi-Fi connectivity all over. It also helps ensure that there’s no risk of dropping your connection as you move around — a mesh router system makes it easy to, for instance, walk from room to room watching Netflix and know you won’t miss a single frame. What's the difference between a Wi-Fi extender and a mesh system? Oh boy. Wi-Fi extenders, or repeaters, are small devices designed to push Wi-Fi a little further than your Wi-Fi router can stretch. They’re cheap, compact and often come in the form of little boxes that sit on your plug sockets with the hope of pushing Wi-Fi to a signal-sparse corner of your home. They are, and I can’t put this delicately enough, often a big pile of rubbish and are often not worth your time. Especially since the price of mesh routers has fallen to within most people’s budgets. What is a wireless backhaul? As we explained above, mesh Wi-Fi systems work by connecting every hardware node to a single wireless network, letting them all communicate with each other. Imagine four people in a busy, noisy restaurant all trying to order their dinner from a weary staff member, all at once. Now imagine, while this is going on, that four more people at that same table are also trying to tell a funny anecdote. It’s no surprise that it might take a long time for the right information to reach its intended destination. To combat this, higher-end mesh routers offer dedicated wireless backhaul; a slice of the spectrum for node-to-node communication. So rather than everyone talking at once in the same space, the conversations are essentially separated, reducing the invisible clutter in the air. Because there’s less confusing cross-chatter, everything moves faster, offering a significant performance boost to those systems. Is it better to hard wire instead of using a mesh Wi-Fi system? This is a great question that doesn’t have a simple answer. It is (almost) always preferable to connect devices with a wire, in this case Ethernet, than to use Wi-Fi. The speeds are faster, it’s more reliable and your data is less vulnerable to the slings and arrows of the laws of physics. Hell, I spent about a year trying to work out how to build an iPhone to Ethernet connector back in the bad old days of Wi-Fi. But your ability to do so depends on your level of DIY skills and / or how much money you want to spend on contractors. Wiring your home for Ethernet if you don’t have the infrastructure already can be a costly and time-consuming process. Particularly if you don’t want ugly wires running along your baseboards and under your carpets or across your hardwood floors. If you’re building your own home or can do some serious DIY, then hard wiring is a fantastic thing to have. It goes wonderfully hand-in-glove with mesh networks too, since you’ll be able to hook up your nodes to the network for even better speeds. But if I’m honest, advances in Wi-Fi technology mean I’d only go for hard wiring if I really believed I needed the sort of speed it offers. Unless you’re a Twitch streamer running your own 24/7 content studio, it’s probably overkill. When we started renovating our 140-year-old home, I had Ethernet installed in the living room, the master and second bedroom and in my office, all at the front of the house. I can’t use it for my mesh since I’d need to put the wiring through the middle of the house. If I ever had the wiring done again, I would do so as I know I’ll instantly see a meaningful improvement in both my connection speed and reliability. But I wouldn’t spend several thousand pounds to have it done just for the sake of it.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-mesh-wifi-system-130028701.html?src=rss",
          "content": "Spotty Wi-Fi can make even simple tasks feel harder than they should. If you’ve ever had a video call freeze in one room or watched a stream buffer in another, a mesh Wi-Fi system can fix those frustrations. Instead of relying on a single router tucked in a corner, a mesh setup uses multiple units that work together to spread a strong, consistent signal throughout your home.Modern mesh systems are built for busy households. They keep dozens of devices connected at once, manage traffic intelligently and often include helpful app features that make troubleshooting or adjusting settings much easier. Many support the latest Wi-Fi standards and faster internet plans too, so you can upgrade your network without replacing everything else.We’ve tested a range of mesh Wi-Fi systems to find the ones that deliver the best mix of speed, coverage and reliability. Whether you live in a small apartment or a multi-floor home, these picks can help you stay connected wherever you are. Table of contents Best mesh Wi-Fi systems for 2025 What to look for in a mesh Wi-Fi system Other mesh Wi-Fi router systems we tested How we test Wi-Fi routers Mesh Wi-Fi system FAQs Best mesh Wi-Fi systems for 2025 What to look for in a mesh Wi-Fi system Linksys’ CEO Jonathan Bettino told Engadget why mesh systems are an “advancement in Wi-Fi technology” over buying a single point router. With one transmitter, the signal can degrade the further away from the router you go, or the local environment isn’t ideal. “You can have a small [home], but there’s thick walls [...] or things in the way that just interfere with your wireless signal,” he said. Historically, the solution to a home’s Wi-Fi dead zone was to buy a Wi-Fi extender but Bettino said the hardware has both a “terrible user experience” and one of the highest return rates of any consumer electronics product. Mesh Wi-Fi, by comparison, offers “multiple nodes that can be placed anywhere in your home,” says Bettino, resulting in “ubiquitous Wi-Fi” that feels as if you have a “router in every room.” Rather than having one main router in your home, having a “router in every room” is the biggest selling point for mesh Wi-Fi given how reliant we all are on the internet. Each node is in constant contact with each other, broadcasting a single, seamless network to all of your connected devices. There’s no separate network for the 2.4GHz and 5GHz bands, just a single name that you connect to. It’s a good time to buy a mesh Wi-Fi system since the latest standard, Wi-Fi 6E, represents a big leap in the technology. Matt MacPherson, Cisco's Chief Technology Officer for Wireless, said Wi-Fi 6E is a big “inflection point,” using much more of the wireless spectrum than its predecessors. “If you’re using that spectrum with a Wi-Fi 6 [device],” he said, “you’re going to get significant gains [in speed.]” MacPherson added Wi-Fi 6E will likely “carry you for a long time” thanks to the fact its “top throughputs now typically exceed what people can actually connect their home to.” In short, with a top theoretical per-stream speed of 1.2 Gbps, Wi-Fi 6E is fast enough to outrun all but the fastest internet service. What do all these Wi-Fi numbers and letters mean? I’m sorry folks, we need to get boringly technical for one paragraph, but I promise you it’s worth it. Wi-Fi is governed by International Standard IEEE 802.11, and every few years a letter gets added onto that name when the technology evolves and improves. Until 2019, routers were sold under their IEEE name, leaving users to pick through the word soup of a product labeled 802.11 b/g/a/n/ac and so on. Mercifully, wiser heads opted to rebrand the letters as numbers, so rather than 802.11 b/g/a/n/ac, we have Wi-Fi 1, 2, 3 4 and 5. Right now, we’re in the middle of one of those Wi-Fi generations, with most of the gear on sale right now supporting either Wi-Fi 6 or Wi-Fi 6E. What’s the difference between Wi-Fi 6 and Wi-Fi 6E? Wi-Fi uses chunks of the radio frequency spectrum, with Wi-Fi 6 using the 2.4GHz and 5GHz bands to pump data around. In fact, back in the old days, it was likely your home router would offer you the choice of the 2.4GHz or the 5GHz network, as separate bands to access. These days, all of the spectrums are tied together as one thing, and Wi-Fi 6E has the added ability to use the 6GHz band as well. That’s a big chunk of extra wireless real estate that isn’t as cluttered up as the 2.4 and 5GHz bands. You’re going to talk about wireless frequencies now, aren’t you. Each Wi-Fi band had tradeoffs, because the slower radio frequencies have greater range but less speed. 2.4GHz signals will travel a long way in your home but aren’t quick, while 6GHz is blisteringly fast but can be defeated by a sturdy brick wall. A lot of Wi-Fi-enabled gear you own, like smart home products, only use the 2.4GHz band because the range is better and it’s a lot cheaper. But it means that the band is also overcrowded and slow, making it great for your doorbell and robovac, but lackluster for Twitch streaming. So, what am I looking for? Right now, the market is full of mature Wi-Fi 6 and 6E devices, and most new systems available to buy are capable of taking advantage of the faster speeds they offer. This guide focuses on Wi-Fi 6E gear since it’s what we think it’s more than enough to satisfy almost everyone’s at-home Wi-Fi needs. What about Wi-Fi 7? We’re now seeing the first generation of Wi-Fi 7 devices available to buy, but we don’t recommend you do so immediately. The Wi-Fi 7 standard is still so new that there’s little to no reason for you to rush out and buy one for your home. The hardware is tremendously expensive and while Wi-Fi 7 will, eventually, offer some great benefits over 6E, it’s not as transformative an upgrade as 6E. Not to mention, Wi-Fi 7 is so new that almost none of your home’s devices will be able to take advantage of its big-ticket features. I’d estimate you won’t need to worry about upgrading to Wi-Fi 7 for at least five years, if not longer. Range and speed All Wi-Fi routers boast a theoretical broadcast range and a theoretical top speed, and in some cases external antennas to boost signal directionality — but these figures don’t mean much. After all, manufacturers can’t control your ISP’s real speed, the materials and layout of your home or where you put your Wi-Fi gear. Raw speed isn’t everything, either, and you likely need a lot less than the internet speeds your provider is advertising. What matters more is how consistent your connection is between rooms and across devices.. After all, Netflix needs just 15 Mbps to push a single 4K video stream to your home. As cool as it is to say you’ve got all these hundreds of Mbps, factors like latency and reliability are far more crucial to a happy internet life. And unless you have Gigabit internet that can reach speeds of up to 1 Gbps, you won’t need a mesh router that offers that spec. Backhaul Mesh Wi-Fi systems work by connecting every hardware node to a single wireless network, letting them all communicate with each other. Imagine four people in a busy, noisy restaurant all trying to order their dinner from a weary staff member, all at once. Now imagine, while this is going on, that four more people at that same table are also trying to tell a funny anecdote. It’s no surprise that it might take a long time for the right information to reach its intended destination. To combat this, higher-end mesh routers offer dedicated wireless backhaul; a slice of the spectrum for node-to-node communication. So rather than everyone talking at once in the same space, the conversations are essentially separated, reducing the invisible clutter in the air. Because there’s less confusing cross-chatter, everything moves faster, offering a significant performance boost to those systems. Connectivity These days, even your washing machine can have a wireless connection, but that doesn’t mean you should ignore the joys of wired internet. No matter how fast Wi-Fi is, a hard line will always be faster, and some gear, like Philips’ Hue bridge, still needs an ethernet connection. Plenty of routers can also use these hard connections as backhaul, eliminating further wireless clutter. It’s convenient for spread-out systems and power users, but it will mean running more wires through your home. The most common standard is Cat 5e, or gigabit ethernet which, unsurprisingly, has a top speed of 1 Gigabit per second (Gbps). Since Ethernet cables are backward compatible, you should be able to easily find one that works with your system. However, to get the most out of your mesh routers, it’s worth investing in an Ethernet cable that meets the standard your router uses — if it’s Cat 5e, use a Cat 5e cable. You can check your router’s specs via the manufacturer’s website to be sure. Flexibility and scalability Mesh routers enable you to add (or subtract) modules from your home network to suit your needs. D-Link’s Alan Jones said users should “check how scalable the prospective product is” before you buy. This sense of scale doesn’t just apply to the number of nodes on the network, but how many simultaneous connections it can handle. It’s also worth looking at ASUS’ AiMesh products, which can combine mesh Wi-Fi gear and its standard “spider” Wi-Fi routers. If you’ve got a tricky part of your home, you can bolt on an ultra-power standalone Wi-Fi router to a compatible mesh. Placement Mesh networks replace one big piece of hardware with a series of identical nodes that you scatter around your home. You connect one to your modem (usually over ethernet), and then scatter the rest around the place for the best coverage. A good rule of thumb is to place each node no more than two rooms away from the last one, rather than sticking them at the far ends of your home. Bear in mind, every physical obstacle between a Wi-Fi node, its siblings and your devices will hurt your overall performance. You should aim to place them, at the very least, at waist height on furniture in open air, without too many obstructions. The reason many mesh Wi-Fi products are designed to look like an inoffensive white doodad is so you don’t feel compelled to hide them behind your TV. Other mesh Wi-Fi router systems we tested Amazon Eero Pro 7 Eero built its reputation on easy to use yet powerful mesh systems that offer a lot of good in a relatively small and affordable package. Setup is effortless, the app running things is clean and simple, and you get the added benefit of backwards compatibility with older hardware. Sadly, the issue with every Eero system is that so many basic management features, like parental controls, are paywalled behind the company’s Eero Plus subscription for $100 a year. Amazon Eero 6E Eero Pro 6E is an “easy” device, the sort a total novice can set up on their own and thrive with for years on end. There’s little brainwork required to get things set up, and the app has a clean UI with plenty of hand-holding. But, as with the Eero Pro 7, the fact that so many basic management tools are paywalled irks me, especially since you can get plenty of them for free with Google’s rival offering. Netgear Orbi 960 The Orbi 96T0 (RBKE963) is Netgear’s flagship mesh Wi-Fi product, which the company calls the “world’s most powerful Wi-Fi 6E system.” It’s also one of the most expensive consumer-level kits on the market, setting you back $1,499.99 for a three pack. It's a fantastic piece of gear, but it's worth saying that the subset of people who could, would or should buy it remains far smaller than you might expect. Ultimately, I feel that if you’re paying luxury prices, you should expect a luxury product. There were plenty of times during testing that I went looking for a feature that was either only available via the web client, or behind a paywall. While, yes, much of your cash is going to the superlative hardware, but for this sort of money, the fact you have to pay extra for some table-stakes features is insulting. If you’re looking for a new Wi-Fi system and aren’t prepared to spend almost $1,500, it’s worth considering our other top picks for the best Wi-Fi routers and mesh systems. How we test Wi-Fi routers My home covers around 2,200 square feet across three stories with the office on the third floor. It’s relatively long and thin, with the living room at the front of the house, the kitchen at the back and the three bedrooms on the first floor. Its age means there are a lot of solid brick walls, old-school lathe and plaster as well as aluminum foil-backed insulation boards to help with energy efficiency. There are two major Wi-Fi dead zones in the house: The bathroom and the third bedroom behind it, since there’s lots of old and new pipework in the walls and floors. For mesh routers with two nodes, I place the first in my living room, connected via ethernet to my cable modem with the second on the first floor landing in the (ostensible) center of the house. For three-node sets, the third goes in my kitchen, which I’ve found is the optimal layout to get the bulk of my house covered in Wi-Fi. Fundamentally, my home poses enough challenges that if it succeeds here, it stands a very good chance of succeeding in your place. Each mesh is judged on ease of setup, Wi-Fi coverage, reliability, speed and any additional features that it advertises. I look at how user-friendly each companion app is from the perspective of a novice rather than an expert given you shouldn’t need to be a network engineer to do this sort of thing. Tests I do include checking for dead zones, moving from room to room to measure consistency of connectivity and streaming multiple videos at once to replicate common usage patterns. Mesh Wi-Fi system FAQs This is the section of our mesh Wi-Fi buyer’s guide where we talk about the stuff that most people just glide past. If you’re not familiar with technology, it can be intimidating if people talk about these things as if you’re expected to already know. So here’s a very simple, very basic rundown of some of the stuff you might have missed in very basic terms. What’s the difference between a Wi-Fi router and a mesh router? A Wi-Fi router is a box that usually sits close to wherever the internet comes into your home and pumps out information over radio waves. A mesh router, meanwhile, is a set of smaller devices, one of which sits next to your internet connection while the rest are scattered around your home. A single Wi-Fi router is great if your home is small, your needs aren’t too demanding, or if your home doesn’t have many radio-blocking obstructions that mean those signals can’t reach every corner of your home. But, much like standing next to a radio transmitter and then walking away from it in a straight line, after a while, the signal will degrade. That’s the problem a mesh system is designed to solve, since it will take the signal from your modem and pump to the other mesh devices, known as nodes, in your home. That way, instead of having one big router in one part of your home, you have several small ones that ensure you have good Wi-Fi connectivity all over. It also helps ensure that there’s no risk of dropping your connection as you move around — a mesh router system makes it easy to, for instance, walk from room to room watching Netflix and know you won’t miss a single frame. What's the difference between a Wi-Fi extender and a mesh system? Oh boy. Wi-Fi extenders, or repeaters, are small devices designed to push Wi-Fi a little further than your Wi-Fi router can stretch. They’re cheap, compact and often come in the form of little boxes that sit on your plug sockets with the hope of pushing Wi-Fi to a signal-sparse corner of your home. They are, and I can’t put this delicately enough, often a big pile of rubbish and are often not worth your time. Especially since the price of mesh routers has fallen to within most people’s budgets. What is a wireless backhaul? As we explained above, mesh Wi-Fi systems work by connecting every hardware node to a single wireless network, letting them all communicate with each other. Imagine four people in a busy, noisy restaurant all trying to order their dinner from a weary staff member, all at once. Now imagine, while this is going on, that four more people at that same table are also trying to tell a funny anecdote. It’s no surprise that it might take a long time for the right information to reach its intended destination. To combat this, higher-end mesh routers offer dedicated wireless backhaul; a slice of the spectrum for node-to-node communication. So rather than everyone talking at once in the same space, the conversations are essentially separated, reducing the invisible clutter in the air. Because there’s less confusing cross-chatter, everything moves faster, offering a significant performance boost to those systems. Is it better to hard wire instead of using a mesh Wi-Fi system? This is a great question that doesn’t have a simple answer. It is (almost) always preferable to connect devices with a wire, in this case Ethernet, than to use Wi-Fi. The speeds are faster, it’s more reliable and your data is less vulnerable to the slings and arrows of the laws of physics. Hell, I spent about a year trying to work out how to build an iPhone to Ethernet connector back in the bad old days of Wi-Fi. But your ability to do so depends on your level of DIY skills and / or how much money you want to spend on contractors. Wiring your home for Ethernet if you don’t have the infrastructure already can be a costly and time-consuming process. Particularly if you don’t want ugly wires running along your baseboards and under your carpets or across your hardwood floors. If you’re building your own home or can do some serious DIY, then hard wiring is a fantastic thing to have. It goes wonderfully hand-in-glove with mesh networks too, since you’ll be able to hook up your nodes to the network for even better speeds. But if I’m honest, advances in Wi-Fi technology mean I’d only go for hard wiring if I really believed I needed the sort of speed it offers. Unless you’re a Twitch streamer running your own 24/7 content studio, it’s probably overkill. When we started renovating our 140-year-old home, I had Ethernet installed in the living room, the master and second bedroom and in my office, all at the front of the house. I can’t use it for my mesh since I’d need to put the wiring through the middle of the house. If I ever had the wiring done again, I would do so as I know I’ll instantly see a meaningful improvement in both my connection speed and reliability. But I wouldn’t spend several thousand pounds to have it done just for the sake of it.This article originally appeared on Engadget at https://www.engadget.com/home/smart-home/best-mesh-wifi-system-130028701.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/how-googles-tpus-are-reshaping-the-economics-of-large-scale-ai",
          "published_at": "Wed, 10 Dec 2025 08:00:00 GMT",
          "title": "How Google’s TPUs are reshaping the economics of large-scale AI",
          "standfirst": "For more than a decade, Nvidia’s GPUs have underpinned nearly every major advance in modern AI. That position is now being challenged. Frontier models such as Google’s Gemini 3 and Anthropic’s Claude 4.5 Opus were trained not on Nvidia hardware, but on Google’s latest Tensor Processing Units, the Ironwood-based TPUv7. This signals that a viable alternative to the GPU-centric AI stack has already arrived — one with real implications for the economics and architecture of frontier-scale training.Nvidia&#x27;s CUDA (Compute Unified Device Architecture), the platform that provides access to the GPU&#x27;s massive parallel architecture, and its surrounding tools have created what many have dubbed the \"CUDA moat\"; once a team has built pipelines on CUDA, switching to another platform is prohibitively expensive because of the dependencies on Nvidia’s software stack. This, combined with Nvidia&#x27;s first-mover advantage, helped the company achieve a staggering 75% gross margin.Unlike GPUs, TPUs were designed from day one as purpose-built silicon for machine learning. With each generation, Google has pushed further into large-scale AI acceleration, but now, as the hardware behind two of the most capable AI models ever trained, TPUv7 signals a broader strategy to challenge Nvidia’s dominance.GPUs and TPUs both accelerate machine learning, but they reflect different design philosophies: GPUs are general-purpose parallel processors, while TPUs are purpose-built systems optimized almost exclusively for large-scale matrix multiplication. With TPUv7, Google has pushed that specialization further by tightly integrating high-speed interconnects directly into the chip, allowing TPU pods to scale like a single supercomputer and reducing the cost and latency penalties that typically come with GPU-based clusters.TPUs are \"designed as a complete &#x27;system&#x27; rather than just a chip,\" Val Bercovici, Chief AI Officer at WEKA, told VentureBeat.Google&#x27;s commercial pivot from internal to industry-wideHistorically, Google restricted access to TPUs solely through cloud rentals on the Google Cloud Platform. In recent months, Google has started offering the hardware directly to external customers, effectively unbundling the chip from the cloud service. Customers can choose between treating compute as an operating expense by renting via cloud, or a capital expenditure (purchasing hardware outright), removing a major friction point for large AI labs that prefer to own their own hardware and effectively bypassing the \"cloud rent\" premium for the base hardware.The centerpiece of Google&#x27;s shift in strategy is a landmark deal with Anthropic, where the Claude 4.5 Opus creator will receive access to up to 1 million TPUv7 chips — more than a gigawatt of compute capacity. Through Broadcom, Google&#x27;s longtime physical design partner, approximately 400,000 chips are being sold directly to Anthropic. The remaining 600,000 chips are leased through traditional Google Cloud contracts. Anthropic&#x27;s commitment adds billions of dollars to Google&#x27;s bottom line and locks one of OpenAI&#x27;s key competitors into Google&#x27;s ecosystem. Eroding the \"CUDA moat\"For years, Nvidia’s GPUs have been the clear market leader in AI infrastructure. In addition to its powerful hardware, Nvidia&#x27;s CUDA ecosystem features a vast library of optimized kernels and frameworks. Combined with broad developer familiarity and a huge installed base, enterprises gradually became locked into the \"CUDA moat,\" a structural barrier that made it impractically expensive to abandon a GPU-based infrastructure.One of the key blockers preventing wider TPU adoption has been ecosystem friction. In the past, TPUs worked best with JAX, Google&#x27;s own numerical computing library designed for AI/ML research. However, mainstream AI development relies primarily on PyTorch, an open-source ML framework that can be tuned for CUDA. Google is now directly addressing the gap. TPUv7 supports native PyTorch integration, including eager execution, full support for distributed APIs, torch.compile, and custom TPU kernel support under PyTorch’s toolchain. The goal is for PyTorch to run as easily on TPUs as it does on Nvidia GPUs.Google is also contributing heavily to vLLM and SGLang, two popular open-source inference frameworks. By optimizing these widely-used tools for TPU, Google ensures that developers are able to switch hardware without rewriting their entire codebase.Advantages and disadvantages of TPUs versus GPUsFor enterprises comparing TPUs and GPUs for large-scale ML workloads, the benefits center primarily on cost, performance, and scalability. SemiAnalysis recently published a deep dive weighing the advantages and disadvantages of the two technologies, measuring cost efficiency, as well as technical performance.Thanks to its specialized architecture and greater energy efficiency, TPUv7 offers significantly better throughput-per-dollar for large-scale training and high-volume inference. This allows enterprises to reduce operational costs related to power, cooling, and data center resources. SemiAnalysis estimates that, for Google&#x27;s internal systems, the total cost of ownership (TCO) for an Ironwood-based server is approximately 44% lower than the TCO for an equivalent Nvidia GB200 Blackwell server. Even after factoring in the profit margins for both Google and Broadcom, external customers like Anthropic are seeing a ~30% reduction in costs compared to Nvidia. \"When cost is paramount, TPUs make sense for AI projects at massive scale. With TPUs, hyperscalers and AI labs can achieve 30-50% TCO reductions, which could translate to billions in savings,\" Bercovici said.This economic leverage is already reshaping the market. Just the existence of a viable alternative allowed OpenAI to negotiate a ~30% discount on its own Nvidia hardware. OpenAI is one of the largest purchasers for Nvidia GPUs, however, earlier this year, the company added Google TPUs via Google Cloud to support its growing compute requirements. Meta is also reportedly in advanced discussions to acquire Google TPUs for its data centers.At this stage, it might seem like Ironwood is the ideal solution for enterprise architecture, but there are a number of trade-offs. While TPUs excel at specific deep learning workloads, they are far less flexible than GPUs, which can run a wide variety of algorithms, including non-AI tasks. If a new AI technique is invented tomorrow, a GPU will run it immediately. This makes GPUs more suitable for organizations that run a wide range of computational workloads beyond standard deep learning. Migration from a GPU-centric environment can also be expensive and time-consuming, especially for teams with existing CUDA-based pipelines, custom GPU kernels, or that leverage frameworks not yet optimized for TPUs. Bercovici recommends that companies \"opt for GPUs when they need to move fast and time to market matters. GPUs leverage standard infrastructure and the largest developer ecosystem, handle dynamic and complex workloads that TPUs aren&#x27;t optimized for, and deploy into existing on-premises standards-based data centers without requiring custom power and networking rebuilds.\" Additionally, the ubiquity of GPUs means that there is more engineering talent available. TPUs demand a rare skillset. \"Leveraging the power of TPUs requires an organization to have engineering depth, which means being able to recruit and retain the rare engineering talent that can write custom kernels and optimize compilers,\" Bercovici said. In practice, Ironwood’s advantages can be realized mostly for enterprises with large, tensor-heavy workloads. Organizations requiring broader hardware flexibility, hybrid-cloud strategies, or HPC-style versatility may find GPUs the better fit. In many cases, a hybrid approach combining the two may offer the best balance of specialization and flexibility.The future of AI architectureThe competition for AI hardware dominance is heating up, but it&#x27;s far too early to predict a winner — or if there will even be a winner at all. With Nvidia and Google innovating at such a rapid pace and companies like Amazon joining the fray, the highest-performing AI systems of the future could be hybrid, integrating both TPUs and GPUs.\"Google Cloud is experiencing accelerating demand for both our custom TPUs and Nvidia GPUs,” a Google spokesperson told VentureBeat. “As a result, we are significantly expanding our Nvidia GPU offerings to meet substantial customer demand. The reality is that the majority of our Google Cloud customers use both GPUs and TPUs. With our wide selection of the latest Nvidia GPUs and seven generations of custom TPUs, we offer customers the flexibility of choice to optimize for their specific needs.\"",
          "content": "For more than a decade, Nvidia’s GPUs have underpinned nearly every major advance in modern AI. That position is now being challenged. Frontier models such as Google’s Gemini 3 and Anthropic’s Claude 4.5 Opus were trained not on Nvidia hardware, but on Google’s latest Tensor Processing Units, the Ironwood-based TPUv7. This signals that a viable alternative to the GPU-centric AI stack has already arrived — one with real implications for the economics and architecture of frontier-scale training.Nvidia&#x27;s CUDA (Compute Unified Device Architecture), the platform that provides access to the GPU&#x27;s massive parallel architecture, and its surrounding tools have created what many have dubbed the \"CUDA moat\"; once a team has built pipelines on CUDA, switching to another platform is prohibitively expensive because of the dependencies on Nvidia’s software stack. This, combined with Nvidia&#x27;s first-mover advantage, helped the company achieve a staggering 75% gross margin.Unlike GPUs, TPUs were designed from day one as purpose-built silicon for machine learning. With each generation, Google has pushed further into large-scale AI acceleration, but now, as the hardware behind two of the most capable AI models ever trained, TPUv7 signals a broader strategy to challenge Nvidia’s dominance.GPUs and TPUs both accelerate machine learning, but they reflect different design philosophies: GPUs are general-purpose parallel processors, while TPUs are purpose-built systems optimized almost exclusively for large-scale matrix multiplication. With TPUv7, Google has pushed that specialization further by tightly integrating high-speed interconnects directly into the chip, allowing TPU pods to scale like a single supercomputer and reducing the cost and latency penalties that typically come with GPU-based clusters.TPUs are \"designed as a complete &#x27;system&#x27; rather than just a chip,\" Val Bercovici, Chief AI Officer at WEKA, told VentureBeat.Google&#x27;s commercial pivot from internal to industry-wideHistorically, Google restricted access to TPUs solely through cloud rentals on the Google Cloud Platform. In recent months, Google has started offering the hardware directly to external customers, effectively unbundling the chip from the cloud service. Customers can choose between treating compute as an operating expense by renting via cloud, or a capital expenditure (purchasing hardware outright), removing a major friction point for large AI labs that prefer to own their own hardware and effectively bypassing the \"cloud rent\" premium for the base hardware.The centerpiece of Google&#x27;s shift in strategy is a landmark deal with Anthropic, where the Claude 4.5 Opus creator will receive access to up to 1 million TPUv7 chips — more than a gigawatt of compute capacity. Through Broadcom, Google&#x27;s longtime physical design partner, approximately 400,000 chips are being sold directly to Anthropic. The remaining 600,000 chips are leased through traditional Google Cloud contracts. Anthropic&#x27;s commitment adds billions of dollars to Google&#x27;s bottom line and locks one of OpenAI&#x27;s key competitors into Google&#x27;s ecosystem. Eroding the \"CUDA moat\"For years, Nvidia’s GPUs have been the clear market leader in AI infrastructure. In addition to its powerful hardware, Nvidia&#x27;s CUDA ecosystem features a vast library of optimized kernels and frameworks. Combined with broad developer familiarity and a huge installed base, enterprises gradually became locked into the \"CUDA moat,\" a structural barrier that made it impractically expensive to abandon a GPU-based infrastructure.One of the key blockers preventing wider TPU adoption has been ecosystem friction. In the past, TPUs worked best with JAX, Google&#x27;s own numerical computing library designed for AI/ML research. However, mainstream AI development relies primarily on PyTorch, an open-source ML framework that can be tuned for CUDA. Google is now directly addressing the gap. TPUv7 supports native PyTorch integration, including eager execution, full support for distributed APIs, torch.compile, and custom TPU kernel support under PyTorch’s toolchain. The goal is for PyTorch to run as easily on TPUs as it does on Nvidia GPUs.Google is also contributing heavily to vLLM and SGLang, two popular open-source inference frameworks. By optimizing these widely-used tools for TPU, Google ensures that developers are able to switch hardware without rewriting their entire codebase.Advantages and disadvantages of TPUs versus GPUsFor enterprises comparing TPUs and GPUs for large-scale ML workloads, the benefits center primarily on cost, performance, and scalability. SemiAnalysis recently published a deep dive weighing the advantages and disadvantages of the two technologies, measuring cost efficiency, as well as technical performance.Thanks to its specialized architecture and greater energy efficiency, TPUv7 offers significantly better throughput-per-dollar for large-scale training and high-volume inference. This allows enterprises to reduce operational costs related to power, cooling, and data center resources. SemiAnalysis estimates that, for Google&#x27;s internal systems, the total cost of ownership (TCO) for an Ironwood-based server is approximately 44% lower than the TCO for an equivalent Nvidia GB200 Blackwell server. Even after factoring in the profit margins for both Google and Broadcom, external customers like Anthropic are seeing a ~30% reduction in costs compared to Nvidia. \"When cost is paramount, TPUs make sense for AI projects at massive scale. With TPUs, hyperscalers and AI labs can achieve 30-50% TCO reductions, which could translate to billions in savings,\" Bercovici said.This economic leverage is already reshaping the market. Just the existence of a viable alternative allowed OpenAI to negotiate a ~30% discount on its own Nvidia hardware. OpenAI is one of the largest purchasers for Nvidia GPUs, however, earlier this year, the company added Google TPUs via Google Cloud to support its growing compute requirements. Meta is also reportedly in advanced discussions to acquire Google TPUs for its data centers.At this stage, it might seem like Ironwood is the ideal solution for enterprise architecture, but there are a number of trade-offs. While TPUs excel at specific deep learning workloads, they are far less flexible than GPUs, which can run a wide variety of algorithms, including non-AI tasks. If a new AI technique is invented tomorrow, a GPU will run it immediately. This makes GPUs more suitable for organizations that run a wide range of computational workloads beyond standard deep learning. Migration from a GPU-centric environment can also be expensive and time-consuming, especially for teams with existing CUDA-based pipelines, custom GPU kernels, or that leverage frameworks not yet optimized for TPUs. Bercovici recommends that companies \"opt for GPUs when they need to move fast and time to market matters. GPUs leverage standard infrastructure and the largest developer ecosystem, handle dynamic and complex workloads that TPUs aren&#x27;t optimized for, and deploy into existing on-premises standards-based data centers without requiring custom power and networking rebuilds.\" Additionally, the ubiquity of GPUs means that there is more engineering talent available. TPUs demand a rare skillset. \"Leveraging the power of TPUs requires an organization to have engineering depth, which means being able to recruit and retain the rare engineering talent that can write custom kernels and optimize compilers,\" Bercovici said. In practice, Ironwood’s advantages can be realized mostly for enterprises with large, tensor-heavy workloads. Organizations requiring broader hardware flexibility, hybrid-cloud strategies, or HPC-style versatility may find GPUs the better fit. In many cases, a hybrid approach combining the two may offer the best balance of specialization and flexibility.The future of AI architectureThe competition for AI hardware dominance is heating up, but it&#x27;s far too early to predict a winner — or if there will even be a winner at all. With Nvidia and Google innovating at such a rapid pace and companies like Amazon joining the fray, the highest-performing AI systems of the future could be hybrid, integrating both TPUs and GPUs.\"Google Cloud is experiencing accelerating demand for both our custom TPUs and Nvidia GPUs,” a Google spokesperson told VentureBeat. “As a result, we are significantly expanding our Nvidia GPU offerings to meet substantial customer demand. The reality is that the majority of our Google Cloud customers use both GPUs and TPUs. With our wide selection of the latest Nvidia GPUs and seven generations of custom TPUs, we offer customers the flexibility of choice to optimize for their specific needs.\"",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5fpm1kFZ4PDgn6vjzrMoQu/39d54faf92de31f8d62a81ec9ab4df63/cruey3_photo_realistic_colorful_blocks_going_up_from_the_ground_3055ca54-93bb-4e1b-a45d-d53a8a0d193e.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/watch-the-day-of-the-devs-game-awards-2025-edition-right-here-at-1pm-et-060000319.html",
          "published_at": "Wed, 10 Dec 2025 06:00:00 +0000",
          "title": "Watch the Day of the Devs: Game Awards 2025 edition right here at 1PM ET",
          "standfirst": "The Game Awards 2025 edition of the Day of the Devs digital showcase goes live on Wednesday, December 10 at 1PM ET on Twitch and YouTube. That’s more than 30 hours before The Game Awards itself kicks off, which makes perfect sense. It is called Day of the Devs, after all, and if we’re judging by past appearances, the event absolutely deserves its own full 24 hours in the spotlight.This year, the Day of the Devs: The Game Awards Digital Showcase will feature 22 indie titles, including three release date announcements and six world premieres. That’s a packed show, even by Day of the Devs standards. Expect to see projects from developers including 17-BIT, BONE Assembly, Capybara Games, Deconstructeam and Panic Stations, and publishers Annapurna Interactive, Devolver and Blumhouse Games, among others.Each Day of the Devs showcase lasts about an hour and highlights a batch of extremely rad-looking independent games across a wide range of genres, complete with commentary from creators. The featured games are curated by industry veterans at Day of the Devs, and past shows have offered early looks at future hits like Animal Well, Blue Prince, Cocoon, Despelote, Crow Country, Phoenix Springs, Skate Story, UFO 50, Eternights, Sorry We’re Closed and many others.Day of the Devs is a non-profit operation that provides a platform for select independent creators to showcase their games to large audiences for free, founded by folks at Double Fine Productions and iam8bit. On top of accepting donations, it receives support from various industry players, including Xbox, PlayStation and Summer Game Fest.The Game Awards 2025 begins on Thursday, December 11 at 7:30PM ET, with a half-hour pre-show up first. The whole thing will certainly last longer than one hour, but we’ll find out together whether it’ll have more game reveals than Day of the Devs.This article originally appeared on Engadget at https://www.engadget.com/gaming/watch-the-day-of-the-devs-game-awards-2025-edition-right-here-at-1pm-et-060000319.html?src=rss",
          "content": "The Game Awards 2025 edition of the Day of the Devs digital showcase goes live on Wednesday, December 10 at 1PM ET on Twitch and YouTube. That’s more than 30 hours before The Game Awards itself kicks off, which makes perfect sense. It is called Day of the Devs, after all, and if we’re judging by past appearances, the event absolutely deserves its own full 24 hours in the spotlight.This year, the Day of the Devs: The Game Awards Digital Showcase will feature 22 indie titles, including three release date announcements and six world premieres. That’s a packed show, even by Day of the Devs standards. Expect to see projects from developers including 17-BIT, BONE Assembly, Capybara Games, Deconstructeam and Panic Stations, and publishers Annapurna Interactive, Devolver and Blumhouse Games, among others.Each Day of the Devs showcase lasts about an hour and highlights a batch of extremely rad-looking independent games across a wide range of genres, complete with commentary from creators. The featured games are curated by industry veterans at Day of the Devs, and past shows have offered early looks at future hits like Animal Well, Blue Prince, Cocoon, Despelote, Crow Country, Phoenix Springs, Skate Story, UFO 50, Eternights, Sorry We’re Closed and many others.Day of the Devs is a non-profit operation that provides a platform for select independent creators to showcase their games to large audiences for free, founded by folks at Double Fine Productions and iam8bit. On top of accepting donations, it receives support from various industry players, including Xbox, PlayStation and Summer Game Fest.The Game Awards 2025 begins on Thursday, December 11 at 7:30PM ET, with a half-hour pre-show up first. The whole thing will certainly last longer than one hour, but we’ll find out together whether it’ll have more game reveals than Day of the Devs.This article originally appeared on Engadget at https://www.engadget.com/gaming/watch-the-day-of-the-devs-game-awards-2025-edition-right-here-at-1pm-et-060000319.html?src=rss",
          "feed_position": 34
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/how-to-watch-the-game-awards-2025-on-december-11-205500124.html",
          "published_at": "Tue, 09 Dec 2025 20:55:00 +0000",
          "title": "How to watch The Game Awards 2025 on December 11",
          "standfirst": "The Game Awards are this week, with the grand showcase for 2025 coming up on Thursday, December 11 at 8PM ET. There's also a pre-show (in case the multi-hour affair just isn't enough TGA for you) and that kicks off at 7:30PM ET. The ceremony will be a mix of honoring games from the past year and debuting trailers for future releases, so expect a couple interesting announcements to emerge from Thursday night. Engadget will be reporting on any big stories as they happen at The Game Awards, but if you want to watch along with us, the whole shebang is available to watch for free on just about every streaming platform you could want. The primo spot to watch is probably YouTube, since it will be broadcasting the show in 4K and you'll want to see all those trailers in their full glory. The video is embedded above. The other official co-streaming partners are Twitch and TikTok Live, but you can also watch everything on Steam and Amazon Prime Video. The Game Awards will also be on social media via Facebook Live, Instagram and X. It's been a good year for gaming and lots of top-notch projects are up for nominations at the show this year. The Game Awards will also shine a light on important subjects such as Innovation in Accessibility and Games For Impact as well as recognizing recent releases for excellence in artistry and design. And don't sleep on the Day of the Devs showcase happening tomorrow, Wednesday, December 10; that will almost certainly have some hype stuff emerging from the indie scene.In terms of reveals, host Geoff Keighley has shared a few looks at what's to come. There will definitely be an appearance by Lara Croft and whatever is happening at Wildflower Interactive, the new studio helmed by The Last of Us co-director Bruce Straley, is due to be announced. PlayStation will also have more to say about Saros, which is Housemarque's follow-up to Returnal. And of course, hope springs eternal (as do the memes) for Half-Life 3. This article originally appeared on Engadget at https://www.engadget.com/gaming/how-to-watch-the-game-awards-2025-on-december-11-205500124.html?src=rss",
          "content": "The Game Awards are this week, with the grand showcase for 2025 coming up on Thursday, December 11 at 8PM ET. There's also a pre-show (in case the multi-hour affair just isn't enough TGA for you) and that kicks off at 7:30PM ET. The ceremony will be a mix of honoring games from the past year and debuting trailers for future releases, so expect a couple interesting announcements to emerge from Thursday night. Engadget will be reporting on any big stories as they happen at The Game Awards, but if you want to watch along with us, the whole shebang is available to watch for free on just about every streaming platform you could want. The primo spot to watch is probably YouTube, since it will be broadcasting the show in 4K and you'll want to see all those trailers in their full glory. The video is embedded above. The other official co-streaming partners are Twitch and TikTok Live, but you can also watch everything on Steam and Amazon Prime Video. The Game Awards will also be on social media via Facebook Live, Instagram and X. It's been a good year for gaming and lots of top-notch projects are up for nominations at the show this year. The Game Awards will also shine a light on important subjects such as Innovation in Accessibility and Games For Impact as well as recognizing recent releases for excellence in artistry and design. And don't sleep on the Day of the Devs showcase happening tomorrow, Wednesday, December 10; that will almost certainly have some hype stuff emerging from the indie scene.In terms of reveals, host Geoff Keighley has shared a few looks at what's to come. There will definitely be an appearance by Lara Croft and whatever is happening at Wildflower Interactive, the new studio helmed by The Last of Us co-director Bruce Straley, is due to be announced. PlayStation will also have more to say about Saros, which is Housemarque's follow-up to Returnal. And of course, hope springs eternal (as do the memes) for Half-Life 3. This article originally appeared on Engadget at https://www.engadget.com/gaming/how-to-watch-the-game-awards-2025-on-december-11-205500124.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/mistral-launches-powerful-devstral-2-coding-model-including-open-source",
          "published_at": "Tue, 09 Dec 2025 19:44:00 GMT",
          "title": "Mistral launches powerful Devstral 2 coding model including open source, laptop-friendly version",
          "standfirst": "French AI startup Mistral has weathered a rocky period of public questioning over the last year to emerge, now here in December 2025, with new, crowd-pleasing models for enterprise and indie developers.Just days after releasing its powerful open source, general purpose Mistral 3 LLM family for edge devices and local hardware, the company returned today to debut Devstral 2.The release includes a new pair of models optimized for software engineering tasks — again, with one small enough to run on a single laptop, offline and privately — alongside Mistral Vibe, a command-line interface (CLI) agent designed to allow developers to call the models up directly within their terminal environments. The models are fast, lean, and open—at least in theory. But the real story lies not just in the benchmarks, but in how Mistral is packaging this capability: one model fully free, another conditionally so, and a terminal interface built to scale with either.It’s an attempt not just to match proprietary systems like Claude and GPT-4 in performance, but to compete with them on developer experience—and to do so while holding onto the flag of open-source.Both models are available now for free for a limited time via Mistral’s API and Hugging Face. The full Devstral 2 model is supported out-of-the-box in the community inference provider vLLM and on the open source agentic coding platform Kilo Code. A Coding Model Meant to DriveAt the top of the announcement is Devstral 2, a 123-billion parameter dense transformer with a 256K-token context window, engineered specifically for agentic software development. Mistral says the model achieves 72.2% on SWE-bench Verified, a benchmark designed to evaluate long-context software engineering tasks in real-world repositories.The smaller sibling, Devstral Small 2, weighs in at 24B parameters, with the same long context window and a performance of 68.0% on SWE-bench. On paper, that makes it the strongest open-weight model of its size, even outscoring many 70B-class competitors.But the performance story isn’t just about raw percentages. Mistral is betting that efficient intelligence beats scale, and has made much of the fact that Devstral 2 is:5× smaller than DeepSeek V3.28× smaller than Kimi K2Yet still matches or surpasses them on key software reasoning benchmarks.Human evaluations back this up. In side-by-side comparisons:Devstral 2 beat DeepSeek V3.2 in 42.8% of tasks, losing only 28.6%.Against Claude Sonnet 4.5, it lost more often (53.1%)—a reminder that while the gap is narrowing, closed models still lead in overall preference.Still, for an open-weight model, these results place Devstral 2 at the frontier of what’s currently available to run and modify independently.Vibe CLI: A Terminal-Native AgentAlongside the models, Mistral released Vibe CLI, a command-line assistant that integrates directly with Devstral models. It’s not an IDE plugin or a ChatGPT-style code explainer. It’s a native interface designed for project-wide code understanding and orchestration, built to live inside the developer’s actual workflow.Vibe brings a surprising degree of intelligence to the terminal:It reads your file tree and Git status to understand project scope.It lets you reference files with @, run shell commands with !, and toggle behavior with slash commands.It orchestrates changes across multiple files, tracks dependencies, retries failed executions, and can even refactor at architectural scale.Unlike most developer agents, which simulate a REPL from within a chat UI, Vibe starts with the shell and pulls intelligence in from there. It’s programmable, scriptable, and themeable. And it’s released under the Apache 2.0 license, meaning it’s truly free to use—in commercial settings, internal tools, or open-source extensions.Licensing Structure: Open-ish — With Revenue LimitationsAt first glance, Mistral’s licensing approach appears straightforward: the models are open-weight and publicly available. But a closer look reveals a line drawn through the middle of the release, with different rules for different users.Devstral Small 2, the 24-billion parameter variant, is covered under a standard, enterprise- and developer-friendly Apache 2.0 license. That’s a gold standard in open-source: no revenue restrictions, no fine print, no need to check with legal. Enterprises can use it in production, embed it into products, and redistribute fine-tuned versions without asking for permission.Devstral 2, the flagship 123B model, is released under what Mistral calls a “modified MIT license.” That phrase sounds innocuous, but the modification introduces a critical limitation: any company making more than $20 million in monthly revenue cannot use the model at all—not even internally—without securing a separate commercial license from Mistral.“You are not authorized to exercise any rights under this license if the global consolidated monthly revenue of your company […] exceeds $20 million,” the license reads.The clause applies not only to the base model, but to derivatives, fine-tuned versions, and redistributed variants, regardless of who hosts them. In effect, it means that while the weights are “open,” their use is gated for large enterprises—unless they’re willing to engage with Mistral’s sales team or use the hosted API at metered pricing.To draw an analogy: Apache 2.0 is like a public library—you walk in, borrow the book, and use it however you need. Mistral’s modified MIT license is more like a corporate co-working space that’s free for freelancers but charges rent once your company hits a certain size.Weighing Devstral Small 2 for Enterprise UseThis division raises an obvious question for larger companies: can Devstral Small 2 with its more permissive and unrestricted Apache 2.0 licensing serve as a viable alternative for medium-to-large enterprises?The answer depends on context. Devstral Small 2 scores 68.0% on SWE-bench, significantly ahead of many larger open models, and remains deployable on single-GPU or CPU-only setups. For teams focused on:internal tooling,on-prem deployment,low-latency edge inference,…it offers a rare combination of legality, performance, and convenience.But the performance gap from Devstral 2 is real. For multi-agent setups, deep monorepo refactoring, or long-context code analysis, that 4-point benchmark delta may understate the actual experience difference.For most enterprises, Devstral Small 2 will serve either as a low-friction way to prototype—or as a pragmatic bridge until licensing for Devstral 2 becomes feasible. It is not a drop-in replacement for the flagship, but it may be “good enough” in specific production slices, particularly when paired with Vibe CLI.But because Devstral Small 2 can be run entirely offline — including on a single GPU machine or a sufficiently specced laptop — it unlocks a critical use case for developers and teams operating in tightly controlled environments. Whether you’re a solo indie building tools on the go, or part of a company with strict data governance or compliance mandates, the ability to run a performant, long-context coding model without ever hitting the internet is a powerful differentiator. No cloud calls, no third-party telemetry, no risk of data leakage — just local inference with full visibility and control.This matters in industries like finance, healthcare, defense, and advanced manufacturing, where data often cannot leave the network perimeter. But it’s just as useful for developers who prefer autonomy over vendor lock-in — or who want their tools to work the same on a plane, in the field, or inside an air-gapped lab. In a market where most top-tier code models are delivered as API-only SaaS products, Devstral Small 2 offers a rare level of portability, privacy, and ownership.In that sense, Mistral isn’t just offering open models—they’re offering multiple paths to adoption, depending on your scale, compliance posture, and willingness to engage.Integration, Infrastructure, and AccessFrom a technical standpoint, Mistral’s models are built for deployment. Devstral 2 requires a minimum of 4× H100-class GPUs, and is already available on build.nvidia.com. Devstral Small 2 can run on a single GPU or CPU such as those in a standard laptop, making it accessible to solo developers and embedded teams alike.Both models support quantized FP4 and FP8 weights, and are compatible with vLLM for scalable inference. Fine-tuning is supported out of the box.API pricing—after the free introductory window—follows a token-based structure:Devstral 2: $0.40 per million input tokens / $2.00 for outputDevstral Small 2: $0.10 input / $0.30 outputThat pricing sits just below OpenAI’s GPT-4 Turbo, and well below Anthropic’s Claude Sonnet at comparable performance levels.Developer Reception: Ground-Level BuzzOn X (formerly Twitter), developers reacted quickly with a wave of positive reception, with Hugging Face&#x27;s Head of Product Victor Mustar asking if the small, Apache 2.0 licensed variant was the \"new local coding king,\" i.e., the one developers could use to run on their laptops directly and privately, without an internet connection:Another popular AI news and rumors account, TestingCatalogNews, posted that it was \"SOTTA in coding,\" or \"State Of The Tiny Art\"Another user, @xlr8harder, took issue with the custom licensing terms for Devstral 2, writing \"calling the Devstral 2 license &#x27;modified MIT&#x27; is misleading at best. It’s a proprietary license with MIT-like attribution requirements.\"While the tone was critical, it reflected some attention Mistral’s license structuring was receiving, particularly among developers familiar with open-use norms.Strategic Context: From Codestral to Devstral and Mistral 3Mistral’s steady push into software development tools didn’t start with Devstral 2—it began in May 2024 with Codestral, the company’s first code-focused large language model. A 22-billion parameter system trained on more than 80 programming languages, Codestral was designed for use in developer environments ranging from basic autocompletions to full function generation. The model launched under a non-commercial license but still outperformed heavyweight competitors like CodeLlama 70B and Deepseek Coder 33B in early benchmarks such as HumanEval and RepoBench.Codestral’s release marked Mistral’s first move into the competitive coding-model space, but it also established a now-familiar pattern: technically lean models with surprisingly strong results, a wide context window, and licensing choices that invited developer experimentation. Industry partners including JetBrains, LlamaIndex, and LangChain quickly began integrating the model into their workflows, citing its speed and tool compatibility as key differentiators.One year later, the company followed up with Devstral, a 24B model purpose-built for “agentic” behavior—handling long-range reasoning, file navigation, and autonomous code modification. Released in partnership with All Hands AI and licensed under Apache 2.0, Devstral was notable not just for its portability (it could run on a MacBook or RTX 4090), but for its performance: it beat out several closed models on SWE-Bench Verified, a benchmark of 500 real-world GitHub issues.Then came Mistral 3, announced in December 2025 as a portfolio of 10 open-weight models targeting everything from drones and smartphones to cloud infrastructure. This suite included both high-end models like Mistral Large 3 (a MoE system with 41 active parameters and 256K context) and lightweight “Ministral” variants that could run on 4GB of VRAM. All were licensed under Apache 2.0, reinforcing Mistral’s commitment to flexible, edge-friendly deployment.Mistral 3 positioned the company not as a direct competitor to frontier models like GPT-5 or Gemini 3, but as a developer-first platform for customized, localized AI systems. Co-founder Guillaume Lample described the vision as “distributed intelligence”—many smaller systems tuned for specific tasks and running outside centralized infrastructure. “In more than 90% of cases, a small model can do the job,” he told VentureBeat. “It doesn’t have to be a model with hundreds of billions of parameters.”That broader strategy helps explain the significance of Devstral 2. It’s not a one-off release but a continuation of Mistral’s long-running commitment to code agents, local-first deployment, and open-weight availability—an ecosystem that began with Codestral, matured through Devstral, and scaled up with Mistral 3. Devstral 2, in this framing, is not just a model. It’s the next version of a playbook that’s been unfolding in public for over a year.Final Thoughts (For Now): A Fork in the RoadWith Devstral 2, Devstral Small 2, and Vibe CLI, Mistral AI has drawn a clear map for developers and companies alike. The tools are fast, capable, and thoughtfully integrated. But they also present a choice—not just in architecture, but in how and where you’re allowed to use them.If you’re an individual developer, small startup, or open-source maintainer, this is one of the most powerful AI systems you can freely run today. If you’re a Fortune 500 engineering lead, you’ll need to either talk to Mistral—or settle for the smaller model and make it work.In a market increasingly dominated by black-box models and SaaS lock-ins, Mistral’s offer is still a breath of fresh air. Just read the fine print before you start building.",
          "content": "French AI startup Mistral has weathered a rocky period of public questioning over the last year to emerge, now here in December 2025, with new, crowd-pleasing models for enterprise and indie developers.Just days after releasing its powerful open source, general purpose Mistral 3 LLM family for edge devices and local hardware, the company returned today to debut Devstral 2.The release includes a new pair of models optimized for software engineering tasks — again, with one small enough to run on a single laptop, offline and privately — alongside Mistral Vibe, a command-line interface (CLI) agent designed to allow developers to call the models up directly within their terminal environments. The models are fast, lean, and open—at least in theory. But the real story lies not just in the benchmarks, but in how Mistral is packaging this capability: one model fully free, another conditionally so, and a terminal interface built to scale with either.It’s an attempt not just to match proprietary systems like Claude and GPT-4 in performance, but to compete with them on developer experience—and to do so while holding onto the flag of open-source.Both models are available now for free for a limited time via Mistral’s API and Hugging Face. The full Devstral 2 model is supported out-of-the-box in the community inference provider vLLM and on the open source agentic coding platform Kilo Code. A Coding Model Meant to DriveAt the top of the announcement is Devstral 2, a 123-billion parameter dense transformer with a 256K-token context window, engineered specifically for agentic software development. Mistral says the model achieves 72.2% on SWE-bench Verified, a benchmark designed to evaluate long-context software engineering tasks in real-world repositories.The smaller sibling, Devstral Small 2, weighs in at 24B parameters, with the same long context window and a performance of 68.0% on SWE-bench. On paper, that makes it the strongest open-weight model of its size, even outscoring many 70B-class competitors.But the performance story isn’t just about raw percentages. Mistral is betting that efficient intelligence beats scale, and has made much of the fact that Devstral 2 is:5× smaller than DeepSeek V3.28× smaller than Kimi K2Yet still matches or surpasses them on key software reasoning benchmarks.Human evaluations back this up. In side-by-side comparisons:Devstral 2 beat DeepSeek V3.2 in 42.8% of tasks, losing only 28.6%.Against Claude Sonnet 4.5, it lost more often (53.1%)—a reminder that while the gap is narrowing, closed models still lead in overall preference.Still, for an open-weight model, these results place Devstral 2 at the frontier of what’s currently available to run and modify independently.Vibe CLI: A Terminal-Native AgentAlongside the models, Mistral released Vibe CLI, a command-line assistant that integrates directly with Devstral models. It’s not an IDE plugin or a ChatGPT-style code explainer. It’s a native interface designed for project-wide code understanding and orchestration, built to live inside the developer’s actual workflow.Vibe brings a surprising degree of intelligence to the terminal:It reads your file tree and Git status to understand project scope.It lets you reference files with @, run shell commands with !, and toggle behavior with slash commands.It orchestrates changes across multiple files, tracks dependencies, retries failed executions, and can even refactor at architectural scale.Unlike most developer agents, which simulate a REPL from within a chat UI, Vibe starts with the shell and pulls intelligence in from there. It’s programmable, scriptable, and themeable. And it’s released under the Apache 2.0 license, meaning it’s truly free to use—in commercial settings, internal tools, or open-source extensions.Licensing Structure: Open-ish — With Revenue LimitationsAt first glance, Mistral’s licensing approach appears straightforward: the models are open-weight and publicly available. But a closer look reveals a line drawn through the middle of the release, with different rules for different users.Devstral Small 2, the 24-billion parameter variant, is covered under a standard, enterprise- and developer-friendly Apache 2.0 license. That’s a gold standard in open-source: no revenue restrictions, no fine print, no need to check with legal. Enterprises can use it in production, embed it into products, and redistribute fine-tuned versions without asking for permission.Devstral 2, the flagship 123B model, is released under what Mistral calls a “modified MIT license.” That phrase sounds innocuous, but the modification introduces a critical limitation: any company making more than $20 million in monthly revenue cannot use the model at all—not even internally—without securing a separate commercial license from Mistral.“You are not authorized to exercise any rights under this license if the global consolidated monthly revenue of your company […] exceeds $20 million,” the license reads.The clause applies not only to the base model, but to derivatives, fine-tuned versions, and redistributed variants, regardless of who hosts them. In effect, it means that while the weights are “open,” their use is gated for large enterprises—unless they’re willing to engage with Mistral’s sales team or use the hosted API at metered pricing.To draw an analogy: Apache 2.0 is like a public library—you walk in, borrow the book, and use it however you need. Mistral’s modified MIT license is more like a corporate co-working space that’s free for freelancers but charges rent once your company hits a certain size.Weighing Devstral Small 2 for Enterprise UseThis division raises an obvious question for larger companies: can Devstral Small 2 with its more permissive and unrestricted Apache 2.0 licensing serve as a viable alternative for medium-to-large enterprises?The answer depends on context. Devstral Small 2 scores 68.0% on SWE-bench, significantly ahead of many larger open models, and remains deployable on single-GPU or CPU-only setups. For teams focused on:internal tooling,on-prem deployment,low-latency edge inference,…it offers a rare combination of legality, performance, and convenience.But the performance gap from Devstral 2 is real. For multi-agent setups, deep monorepo refactoring, or long-context code analysis, that 4-point benchmark delta may understate the actual experience difference.For most enterprises, Devstral Small 2 will serve either as a low-friction way to prototype—or as a pragmatic bridge until licensing for Devstral 2 becomes feasible. It is not a drop-in replacement for the flagship, but it may be “good enough” in specific production slices, particularly when paired with Vibe CLI.But because Devstral Small 2 can be run entirely offline — including on a single GPU machine or a sufficiently specced laptop — it unlocks a critical use case for developers and teams operating in tightly controlled environments. Whether you’re a solo indie building tools on the go, or part of a company with strict data governance or compliance mandates, the ability to run a performant, long-context coding model without ever hitting the internet is a powerful differentiator. No cloud calls, no third-party telemetry, no risk of data leakage — just local inference with full visibility and control.This matters in industries like finance, healthcare, defense, and advanced manufacturing, where data often cannot leave the network perimeter. But it’s just as useful for developers who prefer autonomy over vendor lock-in — or who want their tools to work the same on a plane, in the field, or inside an air-gapped lab. In a market where most top-tier code models are delivered as API-only SaaS products, Devstral Small 2 offers a rare level of portability, privacy, and ownership.In that sense, Mistral isn’t just offering open models—they’re offering multiple paths to adoption, depending on your scale, compliance posture, and willingness to engage.Integration, Infrastructure, and AccessFrom a technical standpoint, Mistral’s models are built for deployment. Devstral 2 requires a minimum of 4× H100-class GPUs, and is already available on build.nvidia.com. Devstral Small 2 can run on a single GPU or CPU such as those in a standard laptop, making it accessible to solo developers and embedded teams alike.Both models support quantized FP4 and FP8 weights, and are compatible with vLLM for scalable inference. Fine-tuning is supported out of the box.API pricing—after the free introductory window—follows a token-based structure:Devstral 2: $0.40 per million input tokens / $2.00 for outputDevstral Small 2: $0.10 input / $0.30 outputThat pricing sits just below OpenAI’s GPT-4 Turbo, and well below Anthropic’s Claude Sonnet at comparable performance levels.Developer Reception: Ground-Level BuzzOn X (formerly Twitter), developers reacted quickly with a wave of positive reception, with Hugging Face&#x27;s Head of Product Victor Mustar asking if the small, Apache 2.0 licensed variant was the \"new local coding king,\" i.e., the one developers could use to run on their laptops directly and privately, without an internet connection:Another popular AI news and rumors account, TestingCatalogNews, posted that it was \"SOTTA in coding,\" or \"State Of The Tiny Art\"Another user, @xlr8harder, took issue with the custom licensing terms for Devstral 2, writing \"calling the Devstral 2 license &#x27;modified MIT&#x27; is misleading at best. It’s a proprietary license with MIT-like attribution requirements.\"While the tone was critical, it reflected some attention Mistral’s license structuring was receiving, particularly among developers familiar with open-use norms.Strategic Context: From Codestral to Devstral and Mistral 3Mistral’s steady push into software development tools didn’t start with Devstral 2—it began in May 2024 with Codestral, the company’s first code-focused large language model. A 22-billion parameter system trained on more than 80 programming languages, Codestral was designed for use in developer environments ranging from basic autocompletions to full function generation. The model launched under a non-commercial license but still outperformed heavyweight competitors like CodeLlama 70B and Deepseek Coder 33B in early benchmarks such as HumanEval and RepoBench.Codestral’s release marked Mistral’s first move into the competitive coding-model space, but it also established a now-familiar pattern: technically lean models with surprisingly strong results, a wide context window, and licensing choices that invited developer experimentation. Industry partners including JetBrains, LlamaIndex, and LangChain quickly began integrating the model into their workflows, citing its speed and tool compatibility as key differentiators.One year later, the company followed up with Devstral, a 24B model purpose-built for “agentic” behavior—handling long-range reasoning, file navigation, and autonomous code modification. Released in partnership with All Hands AI and licensed under Apache 2.0, Devstral was notable not just for its portability (it could run on a MacBook or RTX 4090), but for its performance: it beat out several closed models on SWE-Bench Verified, a benchmark of 500 real-world GitHub issues.Then came Mistral 3, announced in December 2025 as a portfolio of 10 open-weight models targeting everything from drones and smartphones to cloud infrastructure. This suite included both high-end models like Mistral Large 3 (a MoE system with 41 active parameters and 256K context) and lightweight “Ministral” variants that could run on 4GB of VRAM. All were licensed under Apache 2.0, reinforcing Mistral’s commitment to flexible, edge-friendly deployment.Mistral 3 positioned the company not as a direct competitor to frontier models like GPT-5 or Gemini 3, but as a developer-first platform for customized, localized AI systems. Co-founder Guillaume Lample described the vision as “distributed intelligence”—many smaller systems tuned for specific tasks and running outside centralized infrastructure. “In more than 90% of cases, a small model can do the job,” he told VentureBeat. “It doesn’t have to be a model with hundreds of billions of parameters.”That broader strategy helps explain the significance of Devstral 2. It’s not a one-off release but a continuation of Mistral’s long-running commitment to code agents, local-first deployment, and open-weight availability—an ecosystem that began with Codestral, matured through Devstral, and scaled up with Mistral 3. Devstral 2, in this framing, is not just a model. It’s the next version of a playbook that’s been unfolding in public for over a year.Final Thoughts (For Now): A Fork in the RoadWith Devstral 2, Devstral Small 2, and Vibe CLI, Mistral AI has drawn a clear map for developers and companies alike. The tools are fast, capable, and thoughtfully integrated. But they also present a choice—not just in architecture, but in how and where you’re allowed to use them.If you’re an individual developer, small startup, or open-source maintainer, this is one of the most powerful AI systems you can freely run today. If you’re a Fortune 500 engineering lead, you’ll need to either talk to Mistral—or settle for the smaller model and make it work.In a market increasingly dominated by black-box models and SaaS lock-ins, Mistral’s offer is still a breath of fresh air. Just read the fine print before you start building.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5h08IT02qEnf15d2nC66XM/808f775396da3b120a6c20c72b759776/G-V5j_tz9IkXATIrqK6cF.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/playstation/playstations-2025-wrap-up-is-here-so-you-can-see-how-many-hours-youve-sunk-into-death-stranding-2-191508693.html",
          "published_at": "Tue, 09 Dec 2025 19:15:08 +0000",
          "title": "PlayStation's 2025 Wrap-Up is here, so you can see how many hours you've sunk into Death Stranding 2",
          "standfirst": "Sony's 2025 PlayStation Wrap-Up is now available. The recap, which is similar to those from music streaming services, sums up gaming habits from throughout the year. It shows players how many hours they used their PS4 or PS5, what games they played the most, preferred genres, trophy counts and more. These digital cards are shareable on social media, which is kind of the whole point. Nothing says \"bragging rights\" more than offering definitive proof of how long you spent on a couch grinding in Clair Obscur: Expedition 33 or wandering the wasteland in Death Stranding 2. Sony This year, the recap provides insight into how much players interacted with accessories like the PlayStation Portal and PS VR2. It also details the \"most used DualSense wireless controller design.\" The 2025 Wrap-Up will be available until January 8. Once completed, players also get a \"unique glass-themed avatar.\" It's only available for adults. My PlayStation wrap up 2025 pic.twitter.com/9Em96T4Xce— priceless (@Real__Priceless) December 9, 2025 The PlayStation Wrap-Up has been around since 2017, though it ran into some issues with accessibility in 2024. Spotify introduced the basic idea with Wrapped back in 2015. Since then, the concept of a shareable year-end streaming list has spread like a virus. Just about everyone does it now, from Apple Music to Nintendo and even YouTube. We love to reflect on things we recently experienced, don't we folks?This article originally appeared on Engadget at https://www.engadget.com/gaming/playstation/playstations-2025-wrap-up-is-here-so-you-can-see-how-many-hours-youve-sunk-into-death-stranding-2-191508693.html?src=rss",
          "content": "Sony's 2025 PlayStation Wrap-Up is now available. The recap, which is similar to those from music streaming services, sums up gaming habits from throughout the year. It shows players how many hours they used their PS4 or PS5, what games they played the most, preferred genres, trophy counts and more. These digital cards are shareable on social media, which is kind of the whole point. Nothing says \"bragging rights\" more than offering definitive proof of how long you spent on a couch grinding in Clair Obscur: Expedition 33 or wandering the wasteland in Death Stranding 2. Sony This year, the recap provides insight into how much players interacted with accessories like the PlayStation Portal and PS VR2. It also details the \"most used DualSense wireless controller design.\" The 2025 Wrap-Up will be available until January 8. Once completed, players also get a \"unique glass-themed avatar.\" It's only available for adults. My PlayStation wrap up 2025 pic.twitter.com/9Em96T4Xce— priceless (@Real__Priceless) December 9, 2025 The PlayStation Wrap-Up has been around since 2017, though it ran into some issues with accessibility in 2024. Spotify introduced the basic idea with Wrapped back in 2015. Since then, the concept of a shareable year-end streaming list has spread like a virus. Just about everyone does it now, from Apple Music to Nintendo and even YouTube. We love to reflect on things we recently experienced, don't we folks?This article originally appeared on Engadget at https://www.engadget.com/gaming/playstation/playstations-2025-wrap-up-is-here-so-you-can-see-how-many-hours-youve-sunk-into-death-stranding-2-191508693.html?src=rss",
          "feed_position": 44,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-12/8a07e330-d52e-11f0-b5f7-ffa2fe53a26a"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/meta-is-trying-to-make-facebook-suck-less-by-simplifying-things-a-bit-171910771.html",
          "published_at": "Tue, 09 Dec 2025 17:19:10 +0000",
          "title": "Meta is trying to make Facebook suck less by simplifying things a bit",
          "standfirst": "Somewhere along its never-ending quest to increase engagement, Meta realized that giving Facebook users more of what they want would make it more likely that they'll stick around. The company has announced a bunch of updates designed to help improve the feed and the broader Facebook experience by making it easier to find, create and share interesting things. (Because primarily showing updates from your friends with the occasional ad or meme post is maybe just too complicated.)Simplification is a big focus of this overhaul. First, the Facebook feed will be a bit more streamlined. Whenever you post multiple photos, Facebook will arrange them into a standardized grid. When you click into anything on the feed, you'll be able to see it in a full screen view. And there's a very welcome change in that you'll be able to like a photo by double-tapping it. Just be careful with that when you're swiping through an ex's or a crush's photos.Simplified Facebook feed.MetaSearch results are now said to \"show more content in a more immersive grid layout that supports all content types,\" according to Meta. The company is trying out a new full-screen viewer for Facebook that \"lets you explore different photo and video results without losing your place in search,\" which it plans to expand to \"more content and post types in the coming months.\"In addition, the company says you’ll be able to provide feedback on a Facebook post or Reel to help make future recommendations more relevant. More ways for you to \"shape your feed\" and offer feedback on what the algorithm serves up are coming soon.The Facebook feed sucks, and it's good that Meta knows it sucks. There have been numerous occasions over the last couple of years where I've had to scroll through a couple dozen uninteresting posts from pages and creators I've never heard of before seeing something from a friend. The glut of spam and AI slop isn't helping (things are pretty grim for creators who have been dealing with content thieves too). There was a spell of several months last year when, every single time I opened Facebook, I would see an utterly garbage AI-generated image of a \"tiny house,\" a supposedly cozy domicile where not much actually made sense (three TVs in a living room, stairs and railings that had the telltale signs of AI warping). I'd always provide feedback that I didn't want to see any posts from that page again. But the next day there'd be another rotten \"tiny house\" image from a different page in my feed.Here's hoping Meta will actually take feedback related to recommendations on board and act on it. If the company does, it might actually make the feed more interesting to scroll through again.Elsewhere, Facebook will place the most-used tab bar features — such as Reels, Friends, Marketplace and Profile — front and center on the tab bar for easier and faster access. Meta is also promising a refreshed look for the menu and \"cleaner\" tab notifications.Facebook Story creation screenMetaFacebook is making it easier to access more popular Story and Feed post creation tools like music and friend tagging by giving them more prominent placement. Advanced options like text background colors will be an extra tap or two away. The post and Story composer feature audience and cross-post settings prominently, so that you have ease of control over who can see what you're sharing. Meta has updated how comments work across the feed, Groups and Reels as well to make things more streamlined and easier to follow. On top of all of that, when you make changes to your profile, you might start seeing suggestions for friends with shared interests. Meta suggested that, \"if you update your profile to show you're into sourdough bread baking or planning a trip to Nashville, Facebook will show you friends who can give you sourdough starter tips or offer suggestions on the best local spots.\" As always, though, you can decide who sees what on your profile or simply opt to share none of this personal info with Facebook at all, especially if you feel that Meta already knows too much about you.This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-is-trying-to-make-facebook-suck-less-by-simplifying-things-a-bit-171910771.html?src=rss",
          "content": "Somewhere along its never-ending quest to increase engagement, Meta realized that giving Facebook users more of what they want would make it more likely that they'll stick around. The company has announced a bunch of updates designed to help improve the feed and the broader Facebook experience by making it easier to find, create and share interesting things. (Because primarily showing updates from your friends with the occasional ad or meme post is maybe just too complicated.)Simplification is a big focus of this overhaul. First, the Facebook feed will be a bit more streamlined. Whenever you post multiple photos, Facebook will arrange them into a standardized grid. When you click into anything on the feed, you'll be able to see it in a full screen view. And there's a very welcome change in that you'll be able to like a photo by double-tapping it. Just be careful with that when you're swiping through an ex's or a crush's photos.Simplified Facebook feed.MetaSearch results are now said to \"show more content in a more immersive grid layout that supports all content types,\" according to Meta. The company is trying out a new full-screen viewer for Facebook that \"lets you explore different photo and video results without losing your place in search,\" which it plans to expand to \"more content and post types in the coming months.\"In addition, the company says you’ll be able to provide feedback on a Facebook post or Reel to help make future recommendations more relevant. More ways for you to \"shape your feed\" and offer feedback on what the algorithm serves up are coming soon.The Facebook feed sucks, and it's good that Meta knows it sucks. There have been numerous occasions over the last couple of years where I've had to scroll through a couple dozen uninteresting posts from pages and creators I've never heard of before seeing something from a friend. The glut of spam and AI slop isn't helping (things are pretty grim for creators who have been dealing with content thieves too). There was a spell of several months last year when, every single time I opened Facebook, I would see an utterly garbage AI-generated image of a \"tiny house,\" a supposedly cozy domicile where not much actually made sense (three TVs in a living room, stairs and railings that had the telltale signs of AI warping). I'd always provide feedback that I didn't want to see any posts from that page again. But the next day there'd be another rotten \"tiny house\" image from a different page in my feed.Here's hoping Meta will actually take feedback related to recommendations on board and act on it. If the company does, it might actually make the feed more interesting to scroll through again.Elsewhere, Facebook will place the most-used tab bar features — such as Reels, Friends, Marketplace and Profile — front and center on the tab bar for easier and faster access. Meta is also promising a refreshed look for the menu and \"cleaner\" tab notifications.Facebook Story creation screenMetaFacebook is making it easier to access more popular Story and Feed post creation tools like music and friend tagging by giving them more prominent placement. Advanced options like text background colors will be an extra tap or two away. The post and Story composer feature audience and cross-post settings prominently, so that you have ease of control over who can see what you're sharing. Meta has updated how comments work across the feed, Groups and Reels as well to make things more streamlined and easier to follow. On top of all of that, when you make changes to your profile, you might start seeing suggestions for friends with shared interests. Meta suggested that, \"if you update your profile to show you're into sourdough bread baking or planning a trip to Nashville, Facebook will show you friends who can give you sourdough starter tips or offer suggestions on the best local spots.\" As always, though, you can decide who sees what on your profile or simply opt to share none of this personal info with Facebook at all, especially if you feel that Meta already knows too much about you.This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-is-trying-to-make-facebook-suck-less-by-simplifying-things-a-bit-171910771.html?src=rss",
          "feed_position": 47,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/facebook_feed.jpg"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/1P96HBSOE22cfl5djgDueT/df9398cb8f464a8f6519d964da86026c/mRfmh7TAQtPYv7mwcN551.png?w=300&q=30",
      "popularity_score": 2011.5922880555556
    },
    {
      "id": "cluster_30",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 17:50:01 -0500",
      "title": "Amazon now offers same-day perishable grocery delivery in 2,300+ US markets and has expanded the service's grocery offerings by 30%+ since its August launch (Peyton Bigora/Grocery Dive)",
      "neutral_headline": "Amazon now offers same-day delivery of perishable groceries in 2,300 US cities",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251210/p59#a251210p59",
          "published_at": "Wed, 10 Dec 2025 17:50:01 -0500",
          "title": "Amazon now offers same-day perishable grocery delivery in 2,300+ US markets and has expanded the service's grocery offerings by 30%+ since its August launch (Peyton Bigora/Grocery Dive)",
          "standfirst": "Peyton Bigora / Grocery Dive: Amazon now offers same-day perishable grocery delivery in 2,300+ US markets and has expanded the service's grocery offerings by 30%+ since its August launch &mdash; The company has expanded the service to 2,300 markets and said customers who buy perishables through the offering shop twice as often as those who don't.",
          "content": "Peyton Bigora / Grocery Dive: Amazon now offers same-day perishable grocery delivery in 2,300+ US markets and has expanded the service's grocery offerings by 30%+ since its August launch &mdash; The company has expanded the service to 2,300 markets and said customers who buy perishables through the offering shop twice as often as those who don't.",
          "feed_position": 14,
          "image_url": "http://www.techmeme.com/251210/i59.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/10/amazon-now-offers-same-day-delivery-of-perishable-groceries-in-2300-us-cities/",
          "published_at": "Wed, 10 Dec 2025 15:14:28 +0000",
          "title": "Amazon now offers same-day delivery of perishable groceries in 2,300 US cities",
          "standfirst": "The e-commerce giant says it will expand the service to additional cities in 2026.",
          "content": "The e-commerce giant says it will expand the service to additional cities in 2026.",
          "feed_position": 15
        }
      ],
      "featured_image": "http://www.techmeme.com/251210/i59.jpg",
      "popularity_score": 2011.4258991666666
    },
    {
      "id": "cluster_65",
      "coverage": 2,
      "updated_at": "Wed, 10 Dec 2025 18:40:58 +0000",
      "title": "Kindle Scribe Colorsoft brings color e-ink to Amazon’s 11-inch e-reader",
      "neutral_headline": "Kindle Scribe Colorsoft brings color e-ink to Amazon’s 11-inch e-reader",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/kindle-scribe-colorsoft-brings-color-e-ink-to-amazons-11-inch-e-reader/",
          "published_at": "Wed, 10 Dec 2025 18:40:58 +0000",
          "title": "Kindle Scribe Colorsoft brings color e-ink to Amazon’s 11-inch e-reader",
          "standfirst": "Amazon has added color e-ink to its devices more slowly than its competitors.",
          "content": "Amazon has been updating the large-screened Kindle Scribe tablet more frequently and regularly than it updates its standard e-readers, and today the company is announcing the tablet’s third hardware update in four years. The regular Scribe is also being joined by a lower-end Scribe with less storage and no front light and an upgraded Kindle Scribe Colorsoft model with a color e-ink screen. This makes it only the second Kindle to include a color screen, after last year’s Kindle Colorsoft. Both the regular Kindle Scribe and the Kindle Scribe Colorsoft are available to order starting today for $500 and $630, respectively. Both of those devices include a Premium Pen accessory and 32GB of internal storage; 64GB of storage is available for an extra $50 for both devices. The cheaper front light-less Scribe is coming sometime next year and will run $430 for a model with a more modest 16GB of storage. (These are all much more expensive than the original Scribe’s $340 launch price, but inflation, tariffs, and shortages are wreaking havoc with all kinds of tech prices for the past few years.) The Scribe and Scribe Colorsoft both come with an updated front light “with miniaturized LEDs that fit tightly against the display,” narrowing the bezel and improving the uniformity of the lighting. Amazon has also tweaked the friction level of the paper-like texture on the glass display, shrunk the gap between the glass and the actual display panel to make writing on the tablet feel more like writing on paper, and added a quad-core processor and more RAM to speed the tablet up.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/download-1152x648.jpeg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/review/kindle-scribe-colorsoft-2025/",
          "published_at": "Wed, 10 Dec 2025 14:01:00 +0000",
          "title": "Kindle Scribe Colorsoft and Kindle Scribe (3rd Gen) Review (2025)",
          "standfirst": "Amazon’s latest e-reader and digital notebook combos bring new features, but they may not be enough in a crowded market.",
          "content": "Amazon’s latest e-reader and digital notebook combos bring new features, but they may not be enough in a crowded market.",
          "feed_position": 12,
          "image_url": "https://media.wired.com/photos/6938b15e6714700b8598873d/master/pass/Kindle%20Scribe%20Colorsoft_Kindle%20Scribe%20(3rd%20Gen)%20comparison%20top%20art%20122025%20updated%20SOURCE%20Amazon.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/download-1152x648.jpeg",
      "popularity_score": 2007.2750658333334
    },
    {
      "id": "cluster_18",
      "coverage": 1,
      "updated_at": "Thu, 11 Dec 2025 00:29:54 +0000",
      "title": "NASA just lost contact with a Mars orbiter, and will soon lose another one",
      "neutral_headline": "NASA just lost contact with a Mars orbiter, and will soon lose another one",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/nasa-just-lost-contact-with-a-mars-orbiter-and-will-soon-lose-another-one/",
          "published_at": "Thu, 11 Dec 2025 00:29:54 +0000",
          "title": "NASA just lost contact with a Mars orbiter, and will soon lose another one",
          "standfirst": "If NASA is serious about exploring Mars, it's past time to send new missions.",
          "content": "NASA has lost contact with one its three spacecraft orbiting Mars, the agency announced Tuesday. Meanwhile, a second Mars orbiter is perilously close to running out of fuel, and the third mission is running well past its warranty. Ground teams last heard from the Mars Atmosphere and Volatile Evolution, or MAVEN, spacecraft on Saturday, December 6. “Telemetry from MAVEN had showed all subsystems working normally before it orbited behind the red planet,” NASA said in a short statement. “After the spacecraft emerged from behind Mars, NASA’s Deep Space Network did not observe a signal.” NASA said mission controllers are “investigating the anomaly to address the situation. More information will be shared once it becomes available.”Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GSFC_20171208_Archive_e000206orig-1041x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GSFC_20171208_Archive_e000206orig-1041x648.jpg",
      "popularity_score": 354.0906211111111
    },
    {
      "id": "cluster_28",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 23:16:52 +0000",
      "title": "After years of resisting it, SpaceX now plans to go public. Why?",
      "neutral_headline": "After years of resisting it, SpaceX now plans to go public. Why",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/after-years-of-resisting-it-spacex-now-plans-to-go-public-why/",
          "published_at": "Wed, 10 Dec 2025 23:16:52 +0000",
          "title": "After years of resisting it, SpaceX now plans to go public. Why?",
          "standfirst": "\"Much of the AI race comes down to amassing and deploying assets.\"",
          "content": "SpaceX is planning to raise tens of billions of dollars through an initial public offering next year, multiple outlets have reported, and Ars can confirm. This represents a major change in thinking from the world’s leading space company and its founder, Elon Musk. The Wall Street Journal and The Information first reported about a possible IPO last Friday, and Bloomberg followed that up on Tuesday evening with a report suggesting the company would target a $1.5 trillion valuation. This would allow SpaceX to raise in excess of $30 billion. This is an enormous amount of funding. The largest IPO in history occurred in 2019, when the state-owned Saudi Arabian oil company began public trading as Aramco and raised $29 billion. In terms of revenue, Aramco is a top-five company in the world.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/02/GettyImages-1238367289-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/02/GettyImages-1238367289-1152x648.jpg",
      "popularity_score": 342.8733988888889
    },
    {
      "id": "cluster_44",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 20:38:58 +0000",
      "title": "A new open-weights AI coding model is closing in on proprietary options",
      "neutral_headline": "A new open-weights AI coding model is closing in on proprietary options",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/12/mistral-bets-big-on-vibe-coding-with-new-autonomous-software-engineering-agent/",
          "published_at": "Wed, 10 Dec 2025 20:38:58 +0000",
          "title": "A new open-weights AI coding model is closing in on proprietary options",
          "standfirst": "Devstral 2 model scores 72% on industry benchmark, nearing proprietary rivals.",
          "content": "On Tuesday, French AI startup Mistral AI released Devstral 2, a 123 billion parameter open-weights coding model designed to work as part of an autonomous software engineering agent. The model achieves a 72.2 percent score on SWE-bench Verified, a benchmark that attempts to test whether AI systems can solve real GitHub issues, putting it among the top-performing open-weights models. Perhaps more notably, Mistral didn’t just release an AI model, it released a new development app called Mistral Vibe. It’s a command line interface (CLI) similar to Claude Code, OpenAI Codex, and Gemini CLI that lets developers interact with the Devstral models directly in their terminal. The tool can scan file structures and Git status to maintain context across an entire project, make changes across multiple files, and execute shell commands autonomously. Mistral released the CLI under the Apache 2.0 license. It’s always wise to take AI benchmarks with a large grain of salt, but we’ve heard from employees of the big AI companies that they pay very close attention to how well models do on SWE-bench Verified, which presents AI models with 500 real software engineering problems pulled from GitHub issues in popular Python repositories. The AI must read the issue description, navigate the codebase, and generate a working patch that passes unit tests. While some AI researchers have noted that around 90 percent of the tasks in the benchmark test relatively simple bug fixes that experienced engineers could complete in under an hour, it’s one of the few standardized ways to compare coding models.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/mistral_header_2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/mistral_header_2-1152x648.jpg",
      "popularity_score": 327.2417322222222
    },
    {
      "id": "cluster_41",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 21:05:44 +0000",
      "title": "After NPR and PBS defunding, FCC receives call to take away station licenses",
      "neutral_headline": "After NPR and PBS defunding, FCC receives call to take away station licenses",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/conservative-attacks-on-npr-and-pbs-continue-with-call-to-take-fcc-licenses/",
          "published_at": "Wed, 10 Dec 2025 21:05:44 +0000",
          "title": "After NPR and PBS defunding, FCC receives call to take away station licenses",
          "standfirst": "NPR and PBS stations targeted by group involved in Carr's news-distortion probes.",
          "content": "A conservative group yesterday urged the Federal Communications Commission to take licenses away from NPR and PBS stations and let other entities use the spectrum. The request came from the Center for American Rights (CAR), a nonprofit law firm that has played a prominent role in the news-distortion investigations spearheaded by FCC Chairman Brendan Carr. “In the wake of the wind-down of the Corporation for Public Broadcasting and the end of federal funding for NPR and PBS, the Center respectfully suggests that the Commission open an inquiry that looks at the future of ‘public’ broadcasting in that new environment,” a Center for American Rights filing said. The CPB is set to shut down after Congress approved President Trump’s request to rescind its funding. The Center for American Rights said the CPB shutdown should be used as an opportunity to reassign spectrum used by NPR and PBS stations to other entities.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/Sesame-Street-1152x648-1752686465.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/Sesame-Street-1152x648-1752686465.jpg",
      "popularity_score": 322.6878433333333
    },
    {
      "id": "cluster_49",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 20:07:47 +0000",
      "title": "Cable channel subscribers grew for the first time in 8 years last quarter",
      "neutral_headline": "Cable channel subscribers grew for the first time in 8 years last quarter",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/cable-channel-subscribers-grew-for-the-first-time-in-years-last-quarter/",
          "published_at": "Wed, 10 Dec 2025 20:07:47 +0000",
          "title": "Cable channel subscribers grew for the first time in 8 years last quarter",
          "standfirst": "Sports and YouTube TV played big roles, MoffettNathanson report says.",
          "content": "In a surprising, and likely temporary, turn of events, the number of people paying to watch cable channels has grown. On Monday, research analyst MoffettNathanson released its “Cord-Cutting Monitor Q3 2025: Signs of Life?” report. It found that the pay TV operators, including cable companies, satellite companies, and virtual multichannel video programming distributors (vMVPDs) like YouTube TV and Fubo, added 303,000 net subscribers in Q3 2025. According to the report, “There are more linear video subscribers now than there were three months ago. That’s the first time we’ve been able to say that since 2017.”Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2222725846-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2222725846-1152x648.jpg",
      "popularity_score": 301.72201
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 18:00:19 +0000",
      "title": "Ugly infotainment mars the 2025 Subaru Forester Hybrid experience",
      "neutral_headline": "Ugly infotainment mars the 2025 Subaru Forester Hybrid experience",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/12/ugly-infotainment-mars-the-2025-subaru-forester-hybrid-experience/",
          "published_at": "Wed, 10 Dec 2025 18:00:19 +0000",
          "title": "Ugly infotainment mars the 2025 Subaru Forester Hybrid experience",
          "standfirst": "It drives fine, but the first hybrid Forester is not without its flaws.",
          "content": "Although many of us associate it with rally-derived machinery from the late 1990s and early 2000s, these days, Subaru has mostly abandoned its performance cars to concentrate on its true calling—rugged, all-wheel-drive vehicles that are high on practicality, powered by horizontally opposed “boxer” engines. One area where the brand has never particularly excelled has been fuel efficiency, which is where today’s test car, the Subaru Forester Hybrid, comes in. The last time Ars reviewed a Subaru Forester, it left us impressed. How about one with 40 percent better economy, in that case? Now, the 2.5 L flat-four engine operates on the Atkinson/Miller cycle, which generates 162 hp (121 kW) and 154 lb-ft (208 Nm). There’s an electric motor-generator starter and an electric traction motor with 118 hp (88 kW) and 199 lb-ft (270 Nm) that work together to send a combined 194 hp (145 kW) to all four wheels via a symmetrical all-wheel drive system and a planetary continuously variable transmission. The Forester Hybrid is 183.3 inches (4,656 mm) long, 70.2 inches (1,783 mm) wide, and 68.1 inches (1,729 mm) tall, with a 105.1-inch (2,670 mm) wheelbase. Credit: Jonathan Gitlin Spot the two EyeSight cameras at the top of the windscreen. Credit: Jonathan Gitlin Hatching plots. Credit: Jonathan Gitlin If that sounds vaguely familiar, that’s because it’s the same powertrain that Subaru has also fitted to the smaller Crosstrek Hybrid that we drove in September.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/2025-Subaru-Forester-Hybrid-1-of-14-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/2025-Subaru-Forester-Hybrid-1-of-14-1152x648.jpg",
      "popularity_score": 282.59756555555555
    },
    {
      "id": "cluster_66",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 18:30:45 +0000",
      "title": "US taking 25% cut of Nvidia chip sales “makes no sense,” experts say",
      "neutral_headline": "US taking 25% cut of Nvidia chip sales “makes no sense,” experts say",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/us-taking-25-cut-of-nvidia-chip-sales-makes-no-sense-experts-say/",
          "published_at": "Wed, 10 Dec 2025 18:30:45 +0000",
          "title": "US taking 25% cut of Nvidia chip sales “makes no sense,” experts say",
          "standfirst": "Trump’s odd Nvidia reversal may open the door for China to demand Blackwell access.",
          "content": "Donald Trump’s decision to allow Nvidia to export an advanced artificial intelligence chip, the H200, to China may give China exactly what it needs to win the AI race, experts and lawmakers have warned. The H200 is about 10 times less powerful than Nvidia’s Blackwell chip, which is the tech giant’s currently most advanced chip that cannot be exported to China. But the H200 is six times more powerful than the H20, the most advanced chip available in China today. Meanwhile China’s leading AI chip maker, Huawei, is estimated to be about two years behind Nvidia’s technology. By approving the sales, Trump may unwittingly be helping Chinese chip makers “catch up” to Nvidia, Jake Sullivan told The New York Times. Sullivan, a former Biden-era national security advisor who helped design AI chip export curbs on China, told the NYT that Trump’s move was “nuts” because “China’s main problem” in the AI race “is they don’t have enough advanced computing capability.”Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2212801610-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2212801610-1024x648.jpg",
      "popularity_score": 280.1047877777778
    },
    {
      "id": "cluster_69",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 18:13:52 +0000",
      "title": "After key Russian launch site is damaged, NASA accelerates Dragon supply missions",
      "neutral_headline": "After key Russian launch site is damaged, NASA accelerates Dragon supply missions",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/after-key-russian-launch-site-is-damaged-nasa-accelerates-dragon-supply-missions/",
          "published_at": "Wed, 10 Dec 2025 18:13:52 +0000",
          "title": "After key Russian launch site is damaged, NASA accelerates Dragon supply missions",
          "standfirst": "It is by no means certain that Russia will be able to fix Site 31 soon.",
          "content": "With a key Russian launch pad out of service, NASA is accelerating the launch of two Cargo Dragon spaceships in order to ensure that astronauts on board the International Space Station have all the supplies they need next year. According to the space agency’s internal schedule, the next Dragon supply mission, CRS-34, is moving forward one month from June 2026 to May. And the next Dragon supply mission after this, CRS-35, has been advanced three months from November to August. A source indicated that the changing schedules are a “direct result” of a launch pad incident on Thanksgiving Day at the Russian spaceport in Baikonur, Kazakhstan.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/06/51842830239_a0768f7dc5_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/06/51842830239_a0768f7dc5_k-1152x648.jpg",
      "popularity_score": 269.8233988888889
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 17:14:08 +0000",
      "title": "This is the oldest evidence of people starting fires",
      "neutral_headline": "This is the oldest evidence of people starting fires",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/this-is-the-oldest-evidence-of-people-starting-fires/",
          "published_at": "Wed, 10 Dec 2025 17:14:08 +0000",
          "title": "This is the oldest evidence of people starting fires",
          "standfirst": "We didn't start the fire. (Neanderthals did, at least 400,000 years ago.)",
          "content": "Heat-reddened clay, fire-cracked stone, and fragments of pyrite mark where Neanderthals gathered around a campfire 400,000 years ago in what’s now Suffolk, England. Based on chemical analysis of the sediment at the site, along with the telltale presence of pyrite, a mineral not naturally found nearby but very handy for striking sparks with flint, British Museum archaeologist Rob Davis and his colleagues say the Neanderthals probably started the fire themselves. That makes the abandoned English clay pit at Barnham the oldest evidence in the world that people (Neanderthal people, in this case) had learned to not only use fire, but also create it and control it. A cozy Neanderthal campfire Today, the Barnham site is part of an abandoned clay pit where workers first discovered stone tools in the early 1900s. But 400,000 years ago, it would have been a picturesque little spot at the edge of a stream-fed pond, surrounded by a mix of forest and grassland. There are no hominin fossils here, but archaeologists unearthed a Neanderthal skull about 100 kilometers to the south, so the hominins at Barnham were probably also Neanderthals. The place would have have offered a group of Neanderthals a relatively quiet, sheltered place to set up camp, according to Davis and his colleagues.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/artist-e1765349023584-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/artist-e1765349023584-1152x648.jpg",
      "popularity_score": 254.82784333333333
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 15:11:10 +0000",
      "title": "Impeachment articles filed against RFK Jr., claiming abuse of power",
      "neutral_headline": "Impeachment articles filed against RFK Jr., claiming abuse of power",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/impeachment-articles-filed-against-rfk-jr-claiming-abuse-of-power/",
          "published_at": "Wed, 10 Dec 2025 15:11:10 +0000",
          "title": "Impeachment articles filed against RFK Jr., claiming abuse of power",
          "standfirst": "He's the \"biggest self-created threat to our health and safety,\" Stevens said.",
          "content": "Rep. Haley Stevens (D-Mich.) filed articles of impeachment against Health Secretary Robert F. Kennedy Jr. Wednesday, accusing him of abusing the powers of his office and undermining public health, putting Americans’ lives at risk. He “has got to go,” Stevens said in a video announcing the impeachment articles. In an accompanying press statement, she said Kennedy, who rose to prominence as an ardent anti-vaccine activist, “has turned his back on science, on public health, and on the American people—spreading conspiracies and lies, driving up costs, and putting lives at risk.” She called him the “biggest self-created threat to our health and safety.” It is very unlikely that an impeachment push will gain traction in the Republican-controlled Congress. No other Democratic lawmakers are backing the articles.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2233690134-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2233690134-1152x648.jpg",
      "popularity_score": 151.7783988888889
    },
    {
      "id": "cluster_101",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 14:00:43 +0000",
      "title": "AMD’s next-gen “FSR Redstone” brings big gains, as long as you’re using a new GPU",
      "neutral_headline": "AMD’s next-gen “FSR Redstone” brings big gains, as long as you’re using a new GPU",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/amds-fsr-redstone-upscaling-claims-to-close-the-gap-with-nvidias-dlss/",
          "published_at": "Wed, 10 Dec 2025 14:00:43 +0000",
          "title": "AMD’s next-gen “FSR Redstone” brings big gains, as long as you’re using a new GPU",
          "standfirst": "\"Redstone\" is a promising mix of old and new ideas, but Nvidia is years ahead.",
          "content": "Nvidia, AMD, and Intel have all made high-quality image upscaling a cornerstone feature of their new GPUs this decade. Upscaling technologies like Nvidia’s Deep Learning Super Sampling (DLSS), AMD’s FidelityFX Super Resolution (FSR), and Intel’s Xe Super Sampling (XeSS) are all ways to transform a lower-resolution source image into a higher-resolution image, delivering better-looking games without requiring as much graphics hardware as you’d need to render the higher-resolution image natively. Later additions have focused on improving ray-tracing performance and “frame generation” technologies that boost frame rates by creating new AI-generated frames to insert between natively rendered frames. Generally speaking, Nvidia’s DLSS technologies have provided better image quality than AMD’s FSR, but they have only been available on newer Nvidia hardware—the GeForce RTX 20-series or newer for most features, with frame-generation features locked to the RTX 40- and 50-series. FSR’s results don’t look as good, but they have benefited from running on just about anything, including older GPUs, Nvidia GPUs, and even integrated Intel and AMD GPUs. Today, AMD is trying to shift that dynamic with something called “FSR Redstone,” a collection of ray-tracing and frame-generation features all intended to boost AMD’s image quality while being relatively easy to implement for game developers who are already using FSR 3.1 or FSR 4.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Screenshot-2025-12-09-at-3.43.56-PM-1152x648-1765313186.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Screenshot-2025-12-09-at-3.43.56-PM-1152x648-1765313186.jpeg",
      "popularity_score": 150.6042322222222
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 21:08:11 +0000",
      "title": "Big Tech joins forces with Linux Foundation to standardize AI agents",
      "neutral_headline": "Big Tech joins forces with Linux Foundation to standardize AI agents",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/12/big-tech-joins-forces-with-linux-foundation-to-standardize-ai-agents/",
          "published_at": "Tue, 09 Dec 2025 21:08:11 +0000",
          "title": "Big Tech joins forces with Linux Foundation to standardize AI agents",
          "standfirst": "The Agentic AI Foundation launches to support MCP, AGENTS.md, and goose.",
          "content": "Big Tech has spent the past year telling us we’re living in the era of AI agents, but most of what we’ve been promised is still theoretical. As companies race to turn fantasy into reality, they’ve developed a collection of tools to guide the development of generative AI. A cadre of major players in the AI race, including Anthropic, Block, and OpenAI, has come together to promote interoperability with the newly formed Agentic AI Foundation (AAIF). This move elevates a handful of popular technologies and could make them a de facto standard for AI development going forward. The development path for agentic AI models is cloudy to say the least, but companies have invested so heavily in creating these systems that some tools have percolated to the surface. The AAIF, which is part of the nonprofit Linux Foundation, has been launched to govern the development of three key AI technologies: Model Context Protocol (MCP), goose, and AGENTS.md. MCP is probably the most well-known of the trio, having been open-sourced by Anthropic a year ago. The goal of MCP is to link AI agents to data sources in a standardized way—Anthropic (and now the AAIF) is fond of calling MCP a “USB-C port for AI.” Rather than creating custom integrations for every different database or cloud storage platform, MCP allows developers to quickly and easily connect to any MCP-compliant server.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1327016094-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-1327016094-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_81",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 16:59:15 +0000",
      "title": "Sperm donor with rare cancer mutation fathered nearly 200 children in Europe",
      "neutral_headline": "Sperm donor with rare cancer mutation fathered nearly 200 children in Europe",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/sperm-donor-with-rare-cancer-mutation-fathered-nearly-200-children-in-europe/",
          "published_at": "Wed, 10 Dec 2025 16:59:15 +0000",
          "title": "Sperm donor with rare cancer mutation fathered nearly 200 children in Europe",
          "standfirst": "Children with the mutation have up to a 90% chance of developing cancer by age 60.",
          "content": "A single sperm donor who carries a rare cancer-causing genetic mutation has fathered at least 197 children across 14 countries in Europe, according to a collaborative investigation by 14 European news groups. According to their investigative report, some of the children have already died, and many others are expected to develop deadly cancers. The man—Donor 7069, alias “Kjeld”—carries a rare mutation in the TP53 gene, which codes for a critical tumor suppressor called protein 53 or p53. This protein (which is a transcription factor) keeps cells from dividing uncontrollably, can activate DNA repair processes amid damage, and can trigger cell death when a cell is beyond repair. Many cancers are linked to mutations in p53.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2018/09/GettyImages-460716005-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2018/09/GettyImages-460716005-1152x648.jpg",
      "popularity_score": 138.57978777777777
    },
    {
      "id": "cluster_99",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 14:45:06 +0000",
      "title": "Dr. Oz tells his federal employees to eat less during the holidays",
      "neutral_headline": "Dr. Oz tells his federal employees to eat less during the holidays",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/dr-oz-tells-his-federal-employees-to-eat-less-during-the-holidays/",
          "published_at": "Wed, 10 Dec 2025 14:45:06 +0000",
          "title": "Dr. Oz tells his federal employees to eat less during the holidays",
          "standfirst": "“You don’t have to try every cookie on the holiday table,” wrote Mehmet Oz in an email to staff.",
          "content": "Dr. Mehmet Oz, the administrator for the Centers for Medicare and Medicaid Services (CMS) and former daytime talk show star, has recently been emailing all federal workers in his agency weekly tips on “Crushing Cubicle Cravings” and how to avoid snacking in the office. “We all love a fun cookie swap and potluck this time of year. With several teams across CMS hosting holiday gatherings this month, I am sharing some strategies to help you make healthier choices—while still indulging in festive treats,” Oz wrote in his latest missive, which appears as a recurring section in his weekly bulletin titled “From the Administrator’s Desk,” according to emails viewed by WIRED. “Set your intentions,” writes Oz. “Decide in advance how many treats you’ll allow yourself to enjoy and try to stick to that number. You don’t have to try every cookie on the cookie table.”Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2188660602-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2188660602-1-1152x648.jpg",
      "popularity_score": 136.34395444444445
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 12:32:21 +0000",
      "title": "Operation Bluebird wants to relaunch “Twitter,” says Musk abandoned the name and logo",
      "neutral_headline": "Operation Bluebird wants to relaunch “Twitter,” says Musk abandoned the name and logo",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2025/12/can-twitter-fly-again-startup-wants-to-pry-iconic-trademark-from-musks-x/",
          "published_at": "Wed, 10 Dec 2025 12:32:21 +0000",
          "title": "Operation Bluebird wants to relaunch “Twitter,” says Musk abandoned the name and logo",
          "standfirst": "“Abandonment” offers rare chance to reclaim one of tech’s most recognized brands.",
          "content": "A Virginia startup calling itself “Operation Bluebird” announced this week that it has filed a formal petition with the US Patent and Trademark Office, asking the federal agency to cancel X Corporation’s trademarks of the words “Twitter” and “tweet” since X has allegedly abandoned them. “The TWITTER and TWEET brands have been eradicated from X Corp.’s products, services, and marketing, effectively abandoning the storied brand, with no intention to resume use of the mark,” the petition states. “The TWITTER bird was grounded.” If successful, two leaders of the group tell Ars, Operation Bluebird would launch a social network under the name Twitter.new, possibly as early as late next year. (Twitter.new has created a working prototype and is already inviting users to reserve handles.)Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/03/getty-twitter-logo-1152x648-1765369763.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/03/getty-twitter-logo-1152x648-1765369763.jpg",
      "popularity_score": 134.13145444444444
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Wed, 10 Dec 2025 12:30:29 +0000",
      "title": "Win hardware, collectibles, and more in the 2025 Ars Technica Charity Drive",
      "neutral_headline": "Win hardware, collectibles, and more in the 2025 Ars Technica Charity Drive",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/12/win-hardware-collectibles-and-more-in-the-2025-ars-technica-charity-drive/",
          "published_at": "Wed, 10 Dec 2025 12:30:29 +0000",
          "title": "Win hardware, collectibles, and more in the 2025 Ars Technica Charity Drive",
          "standfirst": "Help yourself to prizes by helping us raise money for good causes.",
          "content": "It’s once again that special time of year when we give you a chance to do well by doing good. That’s right—it’s the 2025 edition of our annual Charity Drive! Every year since 2007, we’ve encouraged readers to give to Penny Arcade’s Child’s Play charity, which provides toys and games to kids being treated in hospitals around the world. In recent years, we’ve added the Electronic Frontier Foundation to our charity push, aiding in their efforts to defend Internet freedom. This year, as always, we’re providing some extra incentive for those donations by offering donors a chance to win pieces of our big pile of vendor-provided swag. We can’t keep it, and we don’t want it clogging up our offices, so it’s now yours to win. This year’s swag pile is full of high-value geek goodies. We have over a dozen prizes valued at nearly $5,000 total, including gaming hardware and collectibles, apparel, and more. In 2023, Ars readers raised nearly $40,000 for charity, contributing to a total haul of more than $542,000 since 2007. We want to raise even more this year, and we can do it if readers dig deep.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/charitydrive2025-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/charitydrive2025-1152x648.jpg",
      "popularity_score": 134.10034333333334
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 22:34:39 +0000",
      "title": "Over 250 people quarantined in South Carolina as measles outbreak rages",
      "neutral_headline": "Over 250 people quarantined in South Carolina as measles outbreak rages",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/over-250-people-quarantined-in-south-carolina-as-measles-outbreak-rages/",
          "published_at": "Tue, 09 Dec 2025 22:34:39 +0000",
          "title": "Over 250 people quarantined in South Carolina as measles outbreak rages",
          "standfirst": "16 cases are linked to a church, which followed exposures at four schools last week.",
          "content": "A measles outbreak that began in South Carolina at the start of October is showing no signs of slowing as officials on Tuesday reported 27 new cases since Friday. Those cases bring the outbreak total to 111. The southern state’s outbreak now rivals outbreaks ongoing in Utah and Arizona, which have tallied 115 and 176 cases, respectively. The outbreaks are threatening to cost the country its measles elimination status, which was earned in 2000 after vaccination efforts stopped the virus from spreading continuously. If the current transmission of the virus isn’t halted by January, the virus will have circulated for 12 consecutive months, marking it once again as an endemic disease in the US. In an update on Tuesday, South Carolina’s health department suggested the spread is far from over. Of the state’s 27 new cases, 16 were linked to exposure at a church, the Way of Truth Church in Inman. And amid the new cases, new exposures were identified at Inman Intermediate School. That’s on top of exposures announced Friday at four other schools in the region, which led to well over 100 students being quarantined.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2152300024-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2152300024-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 18:53:21 +0000",
      "title": "Supreme Court appears likely to approve Trump’s firing of FTC Democrat",
      "neutral_headline": "Supreme Court appears likely to approve Trump’s firing of FTC Democrat",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/supreme-court-appears-likely-to-approve-trumps-firing-of-ftc-democrat/",
          "published_at": "Tue, 09 Dec 2025 18:53:21 +0000",
          "title": "Supreme Court appears likely to approve Trump’s firing of FTC Democrat",
          "standfirst": "Conservative justices seem ready to back Trump control of independent agencies.",
          "content": "The Supreme Court’s conservative justices appear ready to overturn a 90-year-old precedent that said the president cannot fire a Federal Trade Commission member without cause. A ruling for Trump would give him more power over the FTC and potentially other independent agencies such as the Federal Communications Commission. Former FTC Commissioner Rebecca Kelly Slaughter, a Democrat, sued Trump after he fired both Democrats from the commission in March. Slaughter’s case rests largely on the 1935 ruling in Humphrey’s Executor v. United States, in which the Supreme Court unanimously held that the president can only remove FTC commissioners for inefficiency, neglect of duty, or malfeasance in office. Chief Justice John Roberts said during yesterday’s oral arguments that Humphrey’s Executor is a “dried husk” despite being the “primary authority” that Slaughter’s legal team is relying on. Roberts said the court’s 2020 ruling in Seila Law made it “pretty clear… that Humphrey’s Executor is just a dried husk of whatever people used to think it was because, in the opinion itself, it described the powers of the agency it was talking about, and they’re vanishingly insignificant, have nothing to do with what the FTC looks like today.”Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/09/getty-supreme-court-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/09/getty-supreme-court-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_138",
      "coverage": 1,
      "updated_at": "Tue, 09 Dec 2025 18:09:05 +0000",
      "title": "NASA astronauts will have their own droid when they go back to the Moon",
      "neutral_headline": "NASA astronauts will have their own droid when they go back to the Moon",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/lunar-outpost-rover-to-study-lunar-dust-alongside-artemis-astronauts-on-moon/",
          "published_at": "Tue, 09 Dec 2025 18:09:05 +0000",
          "title": "NASA astronauts will have their own droid when they go back to the Moon",
          "standfirst": "NASA crew will be the first astronauts to work with a robot on a celestial body other than Earth.",
          "content": "B-9 had Will Robinson. Twiki had Buck Rogers. And, of course, C-3PO and R2-D2 had Luke Skywalker. Now, in a scenario straight out of science fiction, MAPP will have whoever NASA names to the crew of the second Artemis mission to land on the moon. The space agency has selected Lunar Outpost’s Mobile Autonomous Prospecting Platform, or MAPP, to become the first robotic rover to operate on the moon alongside astronauts. Although its tasks will be far simpler than those of the robots seen on TV and in the movies, the autonomous four-wheeled MAPP will help scientists learn more about the crew’s surroundings. Science instruments on the rover will characterize the surface plasma and behavior of the dust in the lunar environment. “The Apollo era taught us that the further humanity is from Earth, the more dependent we are on science to protect and sustain human life on other planets,” said Nicky Fox, NASA’s associate administrator for science, in a statement. “By deploying these… science instruments on the lunar surface, our proving ground, NASA is leading the world in the creation of humanity’s interplanetary survival guide to ensure the health and safety of our spacecraft and human explorers as we begin our epic journey back to the Moon.”Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/news-120825a-lg-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/news-120825a-lg-1152x648.jpg",
      "popularity_score": 133
    }
  ]
}