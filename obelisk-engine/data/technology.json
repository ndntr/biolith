{
  "updated_at": "2026-01-23T07:25:59.610Z",
  "clusters": [
    {
      "id": "cluster_80",
      "coverage": 3,
      "updated_at": "Thu, 22 Jan 2026 18:40:01 +0000",
      "title": "Meta seeks to limit evidence in child safety case",
      "neutral_headline": "Meta seeks to limit evidence in child safety case",
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/01/22/meta-seeks-to-limit-evidence-in-child-safety-case/",
          "published_at": "Thu, 22 Jan 2026 18:40:01 +0000",
          "title": "Meta seeks to limit evidence in child safety case",
          "standfirst": "Meta is set to go on trial in New Mexico for allegedly failing to protect minors. The company is requesting a broad swath of information not be allowed to be presented in court.",
          "content": "Meta is set to go on trial in New Mexico for allegedly failing to protect minors. The company is requesting a broad swath of information not be allowed to be presented in court.",
          "feed_position": 15
        },
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/meta-wants-to-block-data-about-social-media-use-mental-health-in-child-safety-trial/",
          "published_at": "Thu, 22 Jan 2026 14:25:35 +0000",
          "title": "Meta wants to block data about social media use, mental health in child safety trial",
          "standfirst": "Company is pulling out all the stops to protect itself in advance of New Mexico trial.",
          "content": "As Meta heads to trial in the state of New Mexico for allegedly failing to protect minors from sexual exploitation, the company is making an aggressive push to have certain information excluded from the court proceedings. The company has petitioned the judge to exclude certain research studies and articles around social media and youth mental health; any mention of a recent high-profile case involving teen suicide and social media content; and any references to Meta’s financial resources, the personal activities of employees, and Mark Zuckerberg’s time as a student at Harvard University. Meta’s requests to exclude information, known as motions in limine, are a standard part of pretrial proceedings, in which a party can ask a judge to determine in advance which evidence or arguments are permissible in court. This is to ensure the jury is presented with facts and not irrelevant or prejudicial information and that the defendant is granted a fair trial.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/11/meta-1152x648.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/meta-child-safety-trial-ask-judge-bar-mental-health-harvard/",
          "published_at": "Wed, 21 Jan 2026 10:30:00 +0000",
          "title": "Meta Seeks to Bar Mentions of Mental Health—and Zuckerberg’s Harvard Past—From Child Safety Trial",
          "standfirst": "The trial starts soon in New Mexico’s case against Meta—and the company is pulling out all the stops to protect its reputation.",
          "content": "The trial starts soon in New Mexico’s case against Meta—and the company is pulling out all the stops to protect its reputation.",
          "feed_position": 44,
          "image_url": "https://media.wired.com/photos/69604db8dee1527d641e3c08/master/pass/Ahead-of-Child-Safety-Trial-Meta-Asks-Judge-to-Ban-Words-Images-and-Zuckerberg-Harvard-Pedigree-Business.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/11/meta-1152x648.jpg",
      "popularity_score": 3007.2337194444444
    },
    {
      "id": "cluster_12",
      "coverage": 2,
      "updated_at": "Fri, 23 Jan 2026 02:33:00 GMT",
      "title": "Everything in voice AI just changed: how enterprise AI builders can benefit",
      "neutral_headline": "Everything in voice AI just changed: how enterprise AI builders can benefit",
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/everything-in-voice-ai-just-changed-how-enterprise-ai-builders-can-benefit",
          "published_at": "Fri, 23 Jan 2026 02:33:00 GMT",
          "title": "Everything in voice AI just changed: how enterprise AI builders can benefit",
          "standfirst": "Despite lots of hype, \"voice AI\" has so far largely been a euphemism for a request-response loop. You speak, a cloud server transcribes your words, a language model thinks, and a robotic voice reads the text back. Functional, but not really conversational. That all changed in the past week with a rapid succession of powerful, fast, and more capable voice AI model releases from Nvidia, Inworld, FlashLabs, and Alibaba&#x27;s Qwen team, combined with a massive talent acquisition and tech licensing deal by Google DeepMind and Hume AI.Now, the industry has effectively solved the four \"impossible\" problems of voice computing: latency, fluidity, efficiency, and emotion.For enterprise builders, the implications are immediate. We have moved from the era of \"chatbots that speak\" to the era of \"empathetic interfaces.\" Here is how the landscape has shifted, the specific licensing models for each new tool, and what it means for the next generation of applications.1. The death of latency – no more awkward pausesThe \"magic number\" in human conversation is roughly 200 milliseconds. That is the typical gap between one person finishing a sentence and another beginning theirs. Anything longer than 500ms feels like a satellite delay; anything over a second breaks the illusion of intelligence entirely.Until now, chaining together ASR (speech recognition), LLMs (intelligence), and TTS (text-to-speech) resulted in latencies of 2–5 seconds.Inworld AI’s release of TTS 1.5 directly attacks this bottleneck. By achieving a P90 latency of under 120ms, Inworld has effectively pushed the technology faster than human perception. For developers building customer service agents or interactive training avatars, this means the \"thinking pause\" is dead. Crucially, Inworld claims this model achieves \"viseme-level synchronization,\" meaning the lip movements of a digital avatar will match the audio frame-by-frame—a requirement for high-fidelity gaming and VR training.It&#x27;s vailable via commercial API (pricing tiers based on usage) with a free tier for testing.Simultaneously, FlashLabs released Chroma 1.0, an end-to-end model that integrates the listening and speaking phases. By processing audio tokens directly via an interleaved text-audio token schedule (1:2 ratio), the model bypasses the need to convert speech to text and back again. This \"streaming architecture\" allows the model to generate acoustic codes while it is still generating text, effectively \"thinking out loud\" in data form before the audio is even synthesized. This one is open source on Hugging Face under the enterprise-friendly, commercially viable Apache 2.0 license. Together, they signal that speed is no longer a differentiator; it is a commodity. If your voice application has a 3-second delay, it is now obsolete. The standard for 2026 is immediate, interruptible response.2. Solving \"the robot problem\" via full duplexSpeed is useless if the AI is rude. Traditional voice bots are \"half-duplex\"—like a walkie-talkie, they cannot listen while they are speaking. If you try to interrupt a banking bot to correct a mistake, it keeps talking over you.Nvidia&#x27;s PersonaPlex, released last week, introduces a 7-billion parameter \"full-duplex\" model. Built on the Moshi architecture (originally from Kyutai), it uses a dual-stream design: one stream for listening (via the Mimi neural audio codec) and one for speaking (via the Helium language model). This allows the model to update its internal state while the user is speaking, enabling it to handle interruptions gracefully.Crucially, it understands \"backchanneling\"—the non-verbal \"uh-huhs,\" \"rights,\" and \"okays\" that humans use to signal active listening without taking the floor. This is a subtle but profound shift for UI design. An AI that can be interrupted allows for efficiency. A customer can cut off a long legal disclaimer by saying, \"I got it, move on,\" and the AI will instantly pivot. This mimics the dynamics of a high-competence human operator.The model weights are released under the Nvidia Open Model License (permissive for commercial use but with attribution/distribution terms), while the code is MIT Licensed.3. High-fidelity compression leads to smaller data footprintsWhile Inworld and Nvidia focused on speed and behavior, open source AI powerhouse Qwen (parent company Alibaba Cloud) quietly solved the bandwidth problem.Earlier today, the team released Qwen3-TTS, featuring a breakthrough 12Hz tokenizer. In plain English, this means the model can represent high-fidelity speech using an incredibly small amount of data—just 12 tokens per second.For comparison, previous state-of-the-art models required significantly higher token rates to maintain audio quality. Qwen’s benchmarks show it outperforming competitors like FireredTTS 2 on key reconstruction metrics (MCD, CER, WER) while using fewer tokens.Why does this matter for the enterprise? Cost and scale. A model that requires less data to generate speech is cheaper to run and faster to stream, especially on edge devices or in low-bandwidth environments (like a field technician using a voice assistant on a 4G connection). It turns high-quality voice AI from a server-hogging luxury into a lightweight utility.It&#x27;s available on Hugging Face now under a permissive Apache 2.0 license, perfect for research and commercial application.4. The missing &#x27;it&#x27; factor: emotional intelligencePerhaps the most significant news of the week—and the most complex—is Google DeepMind’s move to license Hume AI’s technology and hire its CEO, Alan Cowen, along with key research staff.While Google integrates this tech into Gemini to power the next generation of consumer assistants, Hume AI itself is pivoting to become the infrastructure backbone for the enterprise. Under new CEO Andrew Ettinger, Hume is doubling down on the thesis that \"emotion\" is not a UI feature, but a data problem.In an exclusive interview with VentureBeat regarding the transition, Ettinger explained that as voice becomes the primary interface, the current stack is insufficient because it treats all inputs as flat text.\"I saw firsthand how the frontier labs are using data to drive model accuracy,\" Ettinger says. \"Voice is very clearly emerging as the de facto interface for AI. If you see that happening, you would also conclude that emotional intelligence around that voice is going to be critical—dialects, understanding, reasoning, modulation.\"The challenge for enterprise builders has been that LLMs are sociopaths by design—they predict the next word, not the emotional state of the user. A healthcare bot that sounds cheerful when a patient reports chronic pain is a liability. A financial bot that sounds bored when a client reports fraud is a churn risk.Ettinger emphasizes that this isn&#x27;t just about making bots sound nice; it&#x27;s about competitive advantage. When asked about the increasingly competitive landscape and the role of open source versus proprietary models, Ettinger remained pragmatic. He noted that while open-source models like PersonaPlex are raising the baseline for interaction, the proprietary advantage lies in the data—specifically, the high-quality, emotionally annotated speech data that Hume has spent years collecting.\"The team at Hume ran headfirst into a problem shared by nearly every team building voice models today: the lack of high-quality, emotionally annotated speech data for post-training,\" he wrote on LinkedIn. \"Solving this required rethinking how audio data is sourced, labeled, and evaluated... This is our advantage. Emotion isn&#x27;t a feature; it&#x27;s a foundation.\"Hume’s models and data infrastructure are available via proprietary enterprise licensing.5. The new enterprise voice AI playbookWith these pieces in place, the \"Voice Stack\" for 2026 looks radically different.The Brain: An LLM (like Gemini or GPT-4o) provides the reasoning.The Body: Efficient, open-weight models like PersonaPlex (Nvidia), Chroma (FlashLabs), or Qwen3-TTS handle the turn-taking, synthesis, and compression, allowing developers to host their own highly responsive agents.The Soul: Platforms like Hume provide the annotated data and emotional weighting to ensure the AI \"reads the room,\" preventing the reputational damage of a tone-deaf bot.Ettinger claims the market demand for this specific \"emotional layer\" is exploding beyond just tech assistants.\"We are seeing that very deeply with the frontier labs, but also in healthcare, education, finance, and manufacturing,\" Ettinger told me. \"As people try to get applications into the hands of thousands of workers across the globe who have complex SKUs... we’re seeing dozens and dozens of use cases by the day.\"This aligns with his comments on LinkedIn, where he revealed that Hume signed \"multiple 8-figure contracts in January alone,\" validating the thesis that enterprises are willing to pay a premium for AI that doesn&#x27;t just understand what a customer said, but how they felt.From good enough to actually goodFor years, enterprise voice AI was graded on a curve. If it understood the user’s intent 80% of the time, it was a success.The technologies released this week have removed the technical excuses for bad experiences. Latency is solved. Interruption is solved. Bandwidth is solved. Emotional nuance is solvable.\"Just like GPUs became foundational for training models,\" Ettinger wrote on his LinkedIn, \"emotional intelligence will be the foundational layer for AI systems that actually serve human well-being.\"For the CIO or CTO, the message is clear: The friction has been removed from the interface. The only remaining friction is in how quickly organizations can adopt the new stack.",
          "content": "Despite lots of hype, \"voice AI\" has so far largely been a euphemism for a request-response loop. You speak, a cloud server transcribes your words, a language model thinks, and a robotic voice reads the text back. Functional, but not really conversational. That all changed in the past week with a rapid succession of powerful, fast, and more capable voice AI model releases from Nvidia, Inworld, FlashLabs, and Alibaba&#x27;s Qwen team, combined with a massive talent acquisition and tech licensing deal by Google DeepMind and Hume AI.Now, the industry has effectively solved the four \"impossible\" problems of voice computing: latency, fluidity, efficiency, and emotion.For enterprise builders, the implications are immediate. We have moved from the era of \"chatbots that speak\" to the era of \"empathetic interfaces.\" Here is how the landscape has shifted, the specific licensing models for each new tool, and what it means for the next generation of applications.1. The death of latency – no more awkward pausesThe \"magic number\" in human conversation is roughly 200 milliseconds. That is the typical gap between one person finishing a sentence and another beginning theirs. Anything longer than 500ms feels like a satellite delay; anything over a second breaks the illusion of intelligence entirely.Until now, chaining together ASR (speech recognition), LLMs (intelligence), and TTS (text-to-speech) resulted in latencies of 2–5 seconds.Inworld AI’s release of TTS 1.5 directly attacks this bottleneck. By achieving a P90 latency of under 120ms, Inworld has effectively pushed the technology faster than human perception. For developers building customer service agents or interactive training avatars, this means the \"thinking pause\" is dead. Crucially, Inworld claims this model achieves \"viseme-level synchronization,\" meaning the lip movements of a digital avatar will match the audio frame-by-frame—a requirement for high-fidelity gaming and VR training.It&#x27;s vailable via commercial API (pricing tiers based on usage) with a free tier for testing.Simultaneously, FlashLabs released Chroma 1.0, an end-to-end model that integrates the listening and speaking phases. By processing audio tokens directly via an interleaved text-audio token schedule (1:2 ratio), the model bypasses the need to convert speech to text and back again. This \"streaming architecture\" allows the model to generate acoustic codes while it is still generating text, effectively \"thinking out loud\" in data form before the audio is even synthesized. This one is open source on Hugging Face under the enterprise-friendly, commercially viable Apache 2.0 license. Together, they signal that speed is no longer a differentiator; it is a commodity. If your voice application has a 3-second delay, it is now obsolete. The standard for 2026 is immediate, interruptible response.2. Solving \"the robot problem\" via full duplexSpeed is useless if the AI is rude. Traditional voice bots are \"half-duplex\"—like a walkie-talkie, they cannot listen while they are speaking. If you try to interrupt a banking bot to correct a mistake, it keeps talking over you.Nvidia&#x27;s PersonaPlex, released last week, introduces a 7-billion parameter \"full-duplex\" model. Built on the Moshi architecture (originally from Kyutai), it uses a dual-stream design: one stream for listening (via the Mimi neural audio codec) and one for speaking (via the Helium language model). This allows the model to update its internal state while the user is speaking, enabling it to handle interruptions gracefully.Crucially, it understands \"backchanneling\"—the non-verbal \"uh-huhs,\" \"rights,\" and \"okays\" that humans use to signal active listening without taking the floor. This is a subtle but profound shift for UI design. An AI that can be interrupted allows for efficiency. A customer can cut off a long legal disclaimer by saying, \"I got it, move on,\" and the AI will instantly pivot. This mimics the dynamics of a high-competence human operator.The model weights are released under the Nvidia Open Model License (permissive for commercial use but with attribution/distribution terms), while the code is MIT Licensed.3. High-fidelity compression leads to smaller data footprintsWhile Inworld and Nvidia focused on speed and behavior, open source AI powerhouse Qwen (parent company Alibaba Cloud) quietly solved the bandwidth problem.Earlier today, the team released Qwen3-TTS, featuring a breakthrough 12Hz tokenizer. In plain English, this means the model can represent high-fidelity speech using an incredibly small amount of data—just 12 tokens per second.For comparison, previous state-of-the-art models required significantly higher token rates to maintain audio quality. Qwen’s benchmarks show it outperforming competitors like FireredTTS 2 on key reconstruction metrics (MCD, CER, WER) while using fewer tokens.Why does this matter for the enterprise? Cost and scale. A model that requires less data to generate speech is cheaper to run and faster to stream, especially on edge devices or in low-bandwidth environments (like a field technician using a voice assistant on a 4G connection). It turns high-quality voice AI from a server-hogging luxury into a lightweight utility.It&#x27;s available on Hugging Face now under a permissive Apache 2.0 license, perfect for research and commercial application.4. The missing &#x27;it&#x27; factor: emotional intelligencePerhaps the most significant news of the week—and the most complex—is Google DeepMind’s move to license Hume AI’s technology and hire its CEO, Alan Cowen, along with key research staff.While Google integrates this tech into Gemini to power the next generation of consumer assistants, Hume AI itself is pivoting to become the infrastructure backbone for the enterprise. Under new CEO Andrew Ettinger, Hume is doubling down on the thesis that \"emotion\" is not a UI feature, but a data problem.In an exclusive interview with VentureBeat regarding the transition, Ettinger explained that as voice becomes the primary interface, the current stack is insufficient because it treats all inputs as flat text.\"I saw firsthand how the frontier labs are using data to drive model accuracy,\" Ettinger says. \"Voice is very clearly emerging as the de facto interface for AI. If you see that happening, you would also conclude that emotional intelligence around that voice is going to be critical—dialects, understanding, reasoning, modulation.\"The challenge for enterprise builders has been that LLMs are sociopaths by design—they predict the next word, not the emotional state of the user. A healthcare bot that sounds cheerful when a patient reports chronic pain is a liability. A financial bot that sounds bored when a client reports fraud is a churn risk.Ettinger emphasizes that this isn&#x27;t just about making bots sound nice; it&#x27;s about competitive advantage. When asked about the increasingly competitive landscape and the role of open source versus proprietary models, Ettinger remained pragmatic. He noted that while open-source models like PersonaPlex are raising the baseline for interaction, the proprietary advantage lies in the data—specifically, the high-quality, emotionally annotated speech data that Hume has spent years collecting.\"The team at Hume ran headfirst into a problem shared by nearly every team building voice models today: the lack of high-quality, emotionally annotated speech data for post-training,\" he wrote on LinkedIn. \"Solving this required rethinking how audio data is sourced, labeled, and evaluated... This is our advantage. Emotion isn&#x27;t a feature; it&#x27;s a foundation.\"Hume’s models and data infrastructure are available via proprietary enterprise licensing.5. The new enterprise voice AI playbookWith these pieces in place, the \"Voice Stack\" for 2026 looks radically different.The Brain: An LLM (like Gemini or GPT-4o) provides the reasoning.The Body: Efficient, open-weight models like PersonaPlex (Nvidia), Chroma (FlashLabs), or Qwen3-TTS handle the turn-taking, synthesis, and compression, allowing developers to host their own highly responsive agents.The Soul: Platforms like Hume provide the annotated data and emotional weighting to ensure the AI \"reads the room,\" preventing the reputational damage of a tone-deaf bot.Ettinger claims the market demand for this specific \"emotional layer\" is exploding beyond just tech assistants.\"We are seeing that very deeply with the frontier labs, but also in healthcare, education, finance, and manufacturing,\" Ettinger told me. \"As people try to get applications into the hands of thousands of workers across the globe who have complex SKUs... we’re seeing dozens and dozens of use cases by the day.\"This aligns with his comments on LinkedIn, where he revealed that Hume signed \"multiple 8-figure contracts in January alone,\" validating the thesis that enterprises are willing to pay a premium for AI that doesn&#x27;t just understand what a customer said, but how they felt.From good enough to actually goodFor years, enterprise voice AI was graded on a curve. If it understood the user’s intent 80% of the time, it was a success.The technologies released this week have removed the technical excuses for bad experiences. Latency is solved. Interruption is solved. Bandwidth is solved. Emotional nuance is solvable.\"Just like GPUs became foundational for training models,\" Ettinger wrote on his LinkedIn, \"emotional intelligence will be the foundational layer for AI systems that actually serve human well-being.\"For the CIO or CTO, the message is clear: The friction has been removed from the interface. The only remaining friction is in how quickly organizations can adopt the new stack.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1MFFbtmycEjI7XIGStOyEk/b1ac57bcd9e094ed185588182a366f78/dZzvxHXOGs335kAJL9VOe.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/fable-will-let-you-be-a-heartless-landlord-this-fall-200409310.html",
          "published_at": "Thu, 22 Jan 2026 20:04:09 +0000",
          "title": "Fable will let you be a heartless landlord this fall",
          "standfirst": "After half a decade of waiting, Microsoft finally offered an extended preview of its long-awaited reboot of the beloved Fable RPG franchise on Thursday. During the company’s recent Developer Direct showcase, Playground Games, best known for its works on the Forza Horizon series, shared nearly 11 minutes of gameplay footage and commentary related to the upcoming title. The new game will feature a fully open world for players to explore, with locations from previous Fable games like Bowerstone making a return. Playground didn’t say exactly where the new game takes place in the Fable timeline. If you played 2010’s Fable 3, you may recall there was a time gap between each of the original games, with the final Lionhead entry giving players the chance to explore a version of Albion that’s been thrown into the tumult of an industrial revolution. This new game appears to offer a more traditional Medieval fantasy setting. From what little Playground shared of the story, the player character is the first hero born in Albion in a generation. Like previous Fable games, their story will begin when they’re a child. They’ll leave their home of Briar Hill after a “mysterious stranger” turns all the inhabitants into stone. Before you set off on your adventure, you’ll be able to decide what your hero looks like, with customization including options for different skin tones, head shapes, tattoos and scars. All pretty standard stuff, and combat doesn’t look groundbreaking. Your character can use a combination of melee and ranged weapons, alongside magic, to defeat their foes. In addition to a health bar, enemies appear to have a posture meter players can break through both light and heavy attacks, before carrying out “stylish” finishers. Judging from the footage Playground shared, combat doesn’t quite have the kinetic feel of say a FromSoftware title. Thankfully, there’s more to the game than just fighting monsters. Like past Fable games, players can ask villagers out on dates, before eventually marrying them and having children, and you’re not limited to a monogamous relationship. It looks like Playground built a modern polycule simulator. Beyond that, you can also purchase every house and business in Albion. The game’s NPCs will develop an opinion of your hero and their actions. Say you evict an artist that lived in one of the houses you bought, you can later meet them on the street and they’ll tell you to your face that you’re awful. Wonderful stuff. From a technical perspective, the footage Playground showed off looked on the rough side. The game’s frame rate and frame pacing wasn’t smooth, and I’m pretty sure I saw ghosting in some of the animations. Hopefully the studio has enough time between now and when the game is finally released sometime this autumn to polish the presentation. When the game does arrive, it will be available on Xbox Series X/S, PC via Xbox and Steam, PlayStation 5 and Game Pass Ultimate. Microsoft first announced a new Fable game was in development back in 2020. It then went three years before sharing a preview of the title, which was originally slated to arrive in 2025 before it was delayed to this year last February. This article originally appeared on Engadget at https://www.engadget.com/gaming/fable-will-let-you-be-a-heartless-landlord-this-fall-200409310.html?src=rss",
          "content": "After half a decade of waiting, Microsoft finally offered an extended preview of its long-awaited reboot of the beloved Fable RPG franchise on Thursday. During the company’s recent Developer Direct showcase, Playground Games, best known for its works on the Forza Horizon series, shared nearly 11 minutes of gameplay footage and commentary related to the upcoming title. The new game will feature a fully open world for players to explore, with locations from previous Fable games like Bowerstone making a return. Playground didn’t say exactly where the new game takes place in the Fable timeline. If you played 2010’s Fable 3, you may recall there was a time gap between each of the original games, with the final Lionhead entry giving players the chance to explore a version of Albion that’s been thrown into the tumult of an industrial revolution. This new game appears to offer a more traditional Medieval fantasy setting. From what little Playground shared of the story, the player character is the first hero born in Albion in a generation. Like previous Fable games, their story will begin when they’re a child. They’ll leave their home of Briar Hill after a “mysterious stranger” turns all the inhabitants into stone. Before you set off on your adventure, you’ll be able to decide what your hero looks like, with customization including options for different skin tones, head shapes, tattoos and scars. All pretty standard stuff, and combat doesn’t look groundbreaking. Your character can use a combination of melee and ranged weapons, alongside magic, to defeat their foes. In addition to a health bar, enemies appear to have a posture meter players can break through both light and heavy attacks, before carrying out “stylish” finishers. Judging from the footage Playground shared, combat doesn’t quite have the kinetic feel of say a FromSoftware title. Thankfully, there’s more to the game than just fighting monsters. Like past Fable games, players can ask villagers out on dates, before eventually marrying them and having children, and you’re not limited to a monogamous relationship. It looks like Playground built a modern polycule simulator. Beyond that, you can also purchase every house and business in Albion. The game’s NPCs will develop an opinion of your hero and their actions. Say you evict an artist that lived in one of the houses you bought, you can later meet them on the street and they’ll tell you to your face that you’re awful. Wonderful stuff. From a technical perspective, the footage Playground showed off looked on the rough side. The game’s frame rate and frame pacing wasn’t smooth, and I’m pretty sure I saw ghosting in some of the animations. Hopefully the studio has enough time between now and when the game is finally released sometime this autumn to polish the presentation. When the game does arrive, it will be available on Xbox Series X/S, PC via Xbox and Steam, PlayStation 5 and Game Pass Ultimate. Microsoft first announced a new Fable game was in development back in 2020. It then went three years before sharing a preview of the title, which was originally slated to arrive in 2025 before it was delayed to this year last February. This article originally appeared on Engadget at https://www.engadget.com/gaming/fable-will-let-you-be-a-heartless-landlord-this-fall-200409310.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/double-fine-announces-delightful-looking-multiplayer-pottery-game-kiln-195837155.html",
          "published_at": "Thu, 22 Jan 2026 19:58:37 +0000",
          "title": "Double Fine announces delightful-looking multiplayer pottery game Kiln",
          "standfirst": "Double Fine has been on a tear with its smaller projects lately. The popular indie game developer is following up last year's atmospheric adventure game Keeper with a new title in a totally different direction. As its Double Fine founder Tim Schaefer attempted to say five times fast during today's Xbox Developer Direct, Kiln is an \"online multiplayer pottery party brawler\" that boasts exactly the sort of colorful, clever fun that fans have come to expect from the studio. Kiln is a game with two facets: creation and destruction. On the creation side, players get to design a ceramic vessel of their choosing, anything from a dainty saucer to a massive vat. From the clips showed, this riff on character creation imitates many of the real processes of throwing on the wheel. There are options to decorate your vessel with glazes and stickers for additional personalization.Once you've made your pottery creation, it's time to destroy it. The game mode that Double Fine showed off during the Developer Direct is called Quench. In these capture-the-flag style matches, your teammates are trying to carry water in the vessels they've designed to the enemy's kiln, where the goal is to douse its flames before opponents can do the same to yours. Different vessel types have different attacks for smashing enemy ceramics to shards, so there can be a strategic angle to building up a smart team composition with a mix of defensive and offensive capabilities.Kiln looks like a really fun time, and it is due out in spring 2026. The game will be available on Xbox Series X/S, PlayStation 5 and Steam, as well as through Xbox programs such as Game Pass Ultimate and Xbox Cloud Gaming. This article originally appeared on Engadget at https://www.engadget.com/gaming/double-fine-announces-delightful-looking-multiplayer-pottery-game-kiln-195837155.html?src=rss",
          "content": "Double Fine has been on a tear with its smaller projects lately. The popular indie game developer is following up last year's atmospheric adventure game Keeper with a new title in a totally different direction. As its Double Fine founder Tim Schaefer attempted to say five times fast during today's Xbox Developer Direct, Kiln is an \"online multiplayer pottery party brawler\" that boasts exactly the sort of colorful, clever fun that fans have come to expect from the studio. Kiln is a game with two facets: creation and destruction. On the creation side, players get to design a ceramic vessel of their choosing, anything from a dainty saucer to a massive vat. From the clips showed, this riff on character creation imitates many of the real processes of throwing on the wheel. There are options to decorate your vessel with glazes and stickers for additional personalization.Once you've made your pottery creation, it's time to destroy it. The game mode that Double Fine showed off during the Developer Direct is called Quench. In these capture-the-flag style matches, your teammates are trying to carry water in the vessels they've designed to the enemy's kiln, where the goal is to douse its flames before opponents can do the same to yours. Different vessel types have different attacks for smashing enemy ceramics to shards, so there can be a strategic angle to building up a smart team composition with a mix of defensive and offensive capabilities.Kiln looks like a really fun time, and it is due out in spring 2026. The game will be available on Xbox Series X/S, PlayStation 5 and Steam, as well as through Xbox programs such as Game Pass Ultimate and Xbox Cloud Gaming. This article originally appeared on Engadget at https://www.engadget.com/gaming/double-fine-announces-delightful-looking-multiplayer-pottery-game-kiln-195837155.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/xbox/forza-horizon-6-will-hit-xbox-series-xs-and-pc-on-may-19-183242726.html",
          "published_at": "Thu, 22 Jan 2026 18:32:42 +0000",
          "title": "Forza Horizon 6 will hit Xbox Series X/S and PC on May 19",
          "standfirst": "Forza Horizon 6 is taking the racing series to Japan for the first time, and now we know exactly when you’ll be able to hit the virtual streets of Tokyo. The game will arrive on Xbox Series X/S, PC and Xbox Cloud on May 19, with an early access period commencing on May 15. That lines up with earlier reports about the release date(s) after an in-game ad supposedly appeared in Forza Horizon 5. The upcoming title will hit PS5 later this year.The standard edition of Forza Horizon 6 is expected to cost $70, though it will be on Xbox Game Pass Ultimate and PC Game Pass. To jump in a few days early, you’ll need the premium edition (a deluxe edition will be available too).Playground Games and co-developer Turn 10 Studios offered a first look at gameplay during Thursday’s Xbox Developer Direct showcase. You’ll start out by working through Horizon qualifiers in order to join the Horizon Festival racing circuit, then you’ll unlock faster cars and other goodies as you rise up through the ranks. In a few feature called Horizon Rush, you’ll take on obstacle courses. Playground says this is the largest Forza Horizon game to date. This version of Tokyo, for instance, is said to be five times larger than any urban area the studio has built before and it has multiple districts. There are lots of rural areas in the game as well, and the environments are affected by seasonal changes. As has been the case in previous games, you’ll be able to explore the world as you wish, either solo or with your friends.There will be more than 550 cars available at the jump, and you’ll be able to apply liveries to their windows. Each player house has a customizable garage. You can build up a part of the world called The Estate as you see fit and your friends can visit to see what you’ve made (building will be available in multiplayer for the first time in the series too). There are also new open-world car meets where you can show off your whips, buy copies of other players’ rides and download more songs.Playground is including all of the accessibility features from previous games. It’s adding new ones as well, such as a customizable high-contrast mode and an autodrive option.This article originally appeared on Engadget at https://www.engadget.com/gaming/xbox/forza-horizon-6-will-hit-xbox-series-xs-and-pc-on-may-19-183242726.html?src=rss",
          "content": "Forza Horizon 6 is taking the racing series to Japan for the first time, and now we know exactly when you’ll be able to hit the virtual streets of Tokyo. The game will arrive on Xbox Series X/S, PC and Xbox Cloud on May 19, with an early access period commencing on May 15. That lines up with earlier reports about the release date(s) after an in-game ad supposedly appeared in Forza Horizon 5. The upcoming title will hit PS5 later this year.The standard edition of Forza Horizon 6 is expected to cost $70, though it will be on Xbox Game Pass Ultimate and PC Game Pass. To jump in a few days early, you’ll need the premium edition (a deluxe edition will be available too).Playground Games and co-developer Turn 10 Studios offered a first look at gameplay during Thursday’s Xbox Developer Direct showcase. You’ll start out by working through Horizon qualifiers in order to join the Horizon Festival racing circuit, then you’ll unlock faster cars and other goodies as you rise up through the ranks. In a few feature called Horizon Rush, you’ll take on obstacle courses. Playground says this is the largest Forza Horizon game to date. This version of Tokyo, for instance, is said to be five times larger than any urban area the studio has built before and it has multiple districts. There are lots of rural areas in the game as well, and the environments are affected by seasonal changes. As has been the case in previous games, you’ll be able to explore the world as you wish, either solo or with your friends.There will be more than 550 cars available at the jump, and you’ll be able to apply liveries to their windows. Each player house has a customizable garage. You can build up a part of the world called The Estate as you see fit and your friends can visit to see what you’ve made (building will be available in multiplayer for the first time in the series too). There are also new open-world car meets where you can show off your whips, buy copies of other players’ rides and download more songs.Playground is including all of the accessibility features from previous games. It’s adding new ones as well, such as a customizable high-contrast mode and an autodrive option.This article originally appeared on Engadget at https://www.engadget.com/gaming/xbox/forza-horizon-6-will-hit-xbox-series-xs-and-pc-on-may-19-183242726.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/an-ai-pin-is-beneath-apple-182744647.html",
          "published_at": "Thu, 22 Jan 2026 18:27:44 +0000",
          "title": "An AI pin is beneath Apple",
          "standfirst": "So it's come to this: Apple is reportedly working on a wearable AI pin. According to The Information, it is going to be a small device with \"multiple cameras, a speaker, microphones and wireless charging.\" It sounds like the perfect gadget to pair with the long-awaited AI-powered Siri update, which will also reportedly work as a chatbot. But while many Apple rumors conjure up an air of excitement, the notion of an Apple AI pin sounds downright baffling. Worse, it just seems desperate. Apple, the company known for taking its time to jump into new categories with more thoughtful solutions than its competitors, is reportedly chasing the specter of OpenAI's unreleased AI pin. Never mind that OpenAI has never actually produced any hardware, and that it arguably stumbled into its position as a leading AI player. And never mind that Humane's AI pin was a notorious failure that barely worked, and seemed pointless from the start. Sure, Apple doesn't want more AI eggs on its face, after the delay of its Siri revamp and the underwhelming (and error-prone) debut of Apple Intelligence. Beyond OpenAI, there's also competition from Meta's Ray-Ban smart glasses, which lean heavily on the company’s AI. There’s also the looming threat of whatever AI hardware Meta is cooking up next, following the layoffs from its virtual reality division. And while Google doesn’t have much to show from its Android XR platform, which aims to bring its Gemini AI to your face, Samsung’s Galaxy XR is a start. We’ve also recently seen compelling demos of Google’s AR glasses prototypes and Xreal’s Project Aura glasses.If Apple's AI pin serves as a conduit to Siri, is it really that much more convenient than using an iPhone, AirPods or even an Apple Watch to do the same? The company has reportedly nixed plans to put cameras in the Apple Watch, and Bloomberg suggests it’s opting instead to focus on delivering its own smart glasses this year. But it’s not hard to imagine that faster hardware could let the Apple Watch handle more Siri and AI-related tasks on its own. It’s already a fairly self-sufficient device, allowing you to ask basic Siri queries, run apps and listen to music without an iPhone — the cellular models are even more capable since they can take calls and send messages.Rumors also point to infrared cameras coming to the next AirPods and AirPod Pros. Instead of taking photos, they could enable hand gestures and environmental awareness, which might be useful for Apple Intelligence down the line. The addition of heart rate tracking in the AirPods Pro 3 shows that there are still new features Apple can bring to its buds, beyond listening to music.At best, an Apple AI pin could just be a simple way for someone to access Siri if they don’t want to wear an Apple Watch, plug in AirPods or have their iPhone within shouting distance. But at least those devices do other things beyond talking to Siri. The same is true for Meta’s Ray-Bans and future smart glasses. Even without accessing AI, they’ll still let you listen to music, take calls and, well, be glasses for those who need prescription frames.Given the vocal pushback against Meta's Ray-Ban smart glasses, which are also being banned on cruises, clubs and other venues, I'm also not convinced many people would be eager to prominently display a surveillance device throughout the day. Wired’s Julian Chokkattu was questioned about wearing a camera while he was testing the Humane AI Pin, and I’ve also had to explain to curious people why I was wearing Xreal’s smart glasses, which feature a prominent camera accessory.Sure, we're already living in a panopticon of smartphone cameras, but it's also obvious when someone is using their phone to capture photos and video. An AI pin just dangling off of your clothes is a constant threat, an unblinking eye. Even if Apple implements some sort of capture notification, someone will always try to circumvent it.While The Information notes Apple's AI pin may never actually see the light of day, I wouldn't be surprised if it does. This is the company that partnered with OpenAI just to make Siri appear slightly smarter with the debut of Apple Intelligence. And instead of building its own home-brewed AI models, it's banking on Google's Gemini to power Siri's big AI upgrade, as well as its future foundation models. When it comes to AI, Apple will do almost anything to avoid being seen as a straggler (and to avoid even more stock declines). It’s genuinely strange that Apple, the company that let Samsung and Google get a multi-year head start on foldable smartphones and hasn't yet jumped into the world of smart rings, could fast-track an AI pin for 2027. It’s yet another example of how the AI hype cycle has warped priorities throughout the tech industry. But at least Apple’s fortunes don’t depend on standalone AI hardware as much as OpenAI. This article originally appeared on Engadget at https://www.engadget.com/ai/an-ai-pin-is-beneath-apple-182744647.html?src=rss",
          "content": "So it's come to this: Apple is reportedly working on a wearable AI pin. According to The Information, it is going to be a small device with \"multiple cameras, a speaker, microphones and wireless charging.\" It sounds like the perfect gadget to pair with the long-awaited AI-powered Siri update, which will also reportedly work as a chatbot. But while many Apple rumors conjure up an air of excitement, the notion of an Apple AI pin sounds downright baffling. Worse, it just seems desperate. Apple, the company known for taking its time to jump into new categories with more thoughtful solutions than its competitors, is reportedly chasing the specter of OpenAI's unreleased AI pin. Never mind that OpenAI has never actually produced any hardware, and that it arguably stumbled into its position as a leading AI player. And never mind that Humane's AI pin was a notorious failure that barely worked, and seemed pointless from the start. Sure, Apple doesn't want more AI eggs on its face, after the delay of its Siri revamp and the underwhelming (and error-prone) debut of Apple Intelligence. Beyond OpenAI, there's also competition from Meta's Ray-Ban smart glasses, which lean heavily on the company’s AI. There’s also the looming threat of whatever AI hardware Meta is cooking up next, following the layoffs from its virtual reality division. And while Google doesn’t have much to show from its Android XR platform, which aims to bring its Gemini AI to your face, Samsung’s Galaxy XR is a start. We’ve also recently seen compelling demos of Google’s AR glasses prototypes and Xreal’s Project Aura glasses.If Apple's AI pin serves as a conduit to Siri, is it really that much more convenient than using an iPhone, AirPods or even an Apple Watch to do the same? The company has reportedly nixed plans to put cameras in the Apple Watch, and Bloomberg suggests it’s opting instead to focus on delivering its own smart glasses this year. But it’s not hard to imagine that faster hardware could let the Apple Watch handle more Siri and AI-related tasks on its own. It’s already a fairly self-sufficient device, allowing you to ask basic Siri queries, run apps and listen to music without an iPhone — the cellular models are even more capable since they can take calls and send messages.Rumors also point to infrared cameras coming to the next AirPods and AirPod Pros. Instead of taking photos, they could enable hand gestures and environmental awareness, which might be useful for Apple Intelligence down the line. The addition of heart rate tracking in the AirPods Pro 3 shows that there are still new features Apple can bring to its buds, beyond listening to music.At best, an Apple AI pin could just be a simple way for someone to access Siri if they don’t want to wear an Apple Watch, plug in AirPods or have their iPhone within shouting distance. But at least those devices do other things beyond talking to Siri. The same is true for Meta’s Ray-Bans and future smart glasses. Even without accessing AI, they’ll still let you listen to music, take calls and, well, be glasses for those who need prescription frames.Given the vocal pushback against Meta's Ray-Ban smart glasses, which are also being banned on cruises, clubs and other venues, I'm also not convinced many people would be eager to prominently display a surveillance device throughout the day. Wired’s Julian Chokkattu was questioned about wearing a camera while he was testing the Humane AI Pin, and I’ve also had to explain to curious people why I was wearing Xreal’s smart glasses, which feature a prominent camera accessory.Sure, we're already living in a panopticon of smartphone cameras, but it's also obvious when someone is using their phone to capture photos and video. An AI pin just dangling off of your clothes is a constant threat, an unblinking eye. Even if Apple implements some sort of capture notification, someone will always try to circumvent it.While The Information notes Apple's AI pin may never actually see the light of day, I wouldn't be surprised if it does. This is the company that partnered with OpenAI just to make Siri appear slightly smarter with the debut of Apple Intelligence. And instead of building its own home-brewed AI models, it's banking on Google's Gemini to power Siri's big AI upgrade, as well as its future foundation models. When it comes to AI, Apple will do almost anything to avoid being seen as a straggler (and to avoid even more stock declines). It’s genuinely strange that Apple, the company that let Samsung and Google get a multi-year head start on foldable smartphones and hasn't yet jumped into the world of smart rings, could fast-track an AI pin for 2027. It’s yet another example of how the AI hype cycle has warped priorities throughout the tech industry. But at least Apple’s fortunes don’t depend on standalone AI hardware as much as OpenAI. This article originally appeared on Engadget at https://www.engadget.com/ai/an-ai-pin-is-beneath-apple-182744647.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html",
          "published_at": "Thu, 22 Jan 2026 17:00:14 +0000",
          "title": "The best VPN deals: Up to 87 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "In a chaotic world, one thing you can count on is your own common-sense steps toward better cybersecurity. Most of the holiday deals are over by now, but plenty of services are still offering excellent prices. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. We strongly recommend using a VPN, but you might get stuck with a substandard app if you jump on the very first deal you see. You might also mistakenly end up paying more than you want to, as even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Many of the best VPNs — including our top pick, Proton VPN — are still running deals that save you anywhere from 70 to 87 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $78.18 for a two-year subscription with four months free (78 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 78 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $100.58 for a two-year subscription with four months free (74 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan. NordVPN Plus — $93.36 for a two-year subscription (74 percent off): NordVPN has also taken 70 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with four months free (84 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 28 months of CyberGhost for 79 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. You can also get a shorter one-year subscription for $40 ($3.33 per month). Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "content": "In a chaotic world, one thing you can count on is your own common-sense steps toward better cybersecurity. Most of the holiday deals are over by now, but plenty of services are still offering excellent prices. With access to a virtual private network (VPN), you can stream TV shows and events from all over the world, protect your information from hackers and thwart online trackers. We strongly recommend using a VPN, but you might get stuck with a substandard app if you jump on the very first deal you see. You might also mistakenly end up paying more than you want to, as even otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even so, there are some great bargains on the table. Many of the best VPNs — including our top pick, Proton VPN — are still running deals that save you anywhere from 70 to 87 percent on annual subscriptions. Most of these discounts only apply if you sign up for a year or more, but if you divide the cost by the months of subscription, it's much cheaper over time. Best VPN deals ExpressVPN Basic — $78.18 for a two-year subscription with four months free (78 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 78 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $100.58 for a two-year subscription with four months free (74 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan. NordVPN Plus — $93.36 for a two-year subscription (74 percent off): NordVPN has also taken 70 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $67.23 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with four months free (84 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 28 months of CyberGhost for 79 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.95 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. You can also get a shorter one-year subscription for $40 ($3.33 per month). Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-88-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056445.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/xbox/xbox-developer-direct-2026-how-to-watch-and-what-we-expect-to-see-from-fable-forza-horizon-6-and-beast-of-reincarnation-161000242.html",
          "published_at": "Thu, 22 Jan 2026 16:10:00 +0000",
          "title": "Xbox Developer Direct 2026: How to watch and what we expect to see from Fable, Forza Horizon 6 and Beast of Reincarnation",
          "standfirst": "Xbox is set to hold the fourth installment of its now-annual Developer Direct showcase on January 22. You’ll be able to watch the 2026 edition at 1PM ET on YouTube (including versions with audio descriptions and ASL), Twitch, Facebook and Steam. Xbox will stream the Developer Direct on its regional channels simultaneously, and it’ll be available on Bilibili on Friday. The YouTube stream might be the way to go, since that one will be available in 4K and 60 fps. Because we’re so nice, we’ve embedded that stream above, so all you have to do is click the play button when the time is right.Microsoft has confirmed that it will feature three titles at the Developer Showcase: Fable and Forza Horizon 6 from Playground Games, and Beast of Reincarnation from Game Freak, which is best known for its work on Pokémon games. We should get developer interviews, gameplay footage and (for at least one of those) a release date. There is a chance that there will be some surprises, of course. The three previous editions of Developer Direct all featured five games — the first one showcased Hi-Fi Rush, which was released on the same day.This article originally appeared on Engadget at https://www.engadget.com/gaming/xbox/xbox-developer-direct-2026-how-to-watch-and-what-we-expect-to-see-from-fable-forza-horizon-6-and-beast-of-reincarnation-161000242.html?src=rss",
          "content": "Xbox is set to hold the fourth installment of its now-annual Developer Direct showcase on January 22. You’ll be able to watch the 2026 edition at 1PM ET on YouTube (including versions with audio descriptions and ASL), Twitch, Facebook and Steam. Xbox will stream the Developer Direct on its regional channels simultaneously, and it’ll be available on Bilibili on Friday. The YouTube stream might be the way to go, since that one will be available in 4K and 60 fps. Because we’re so nice, we’ve embedded that stream above, so all you have to do is click the play button when the time is right.Microsoft has confirmed that it will feature three titles at the Developer Showcase: Fable and Forza Horizon 6 from Playground Games, and Beast of Reincarnation from Game Freak, which is best known for its work on Pokémon games. We should get developer interviews, gameplay footage and (for at least one of those) a release date. There is a chance that there will be some surprises, of course. The three previous editions of Developer Direct all featured five games — the first one showcased Hi-Fi Rush, which was released on the same day.This article originally appeared on Engadget at https://www.engadget.com/gaming/xbox/xbox-developer-direct-2026-how-to-watch-and-what-we-expect-to-see-from-fable-forza-horizon-6-and-beast-of-reincarnation-161000242.html?src=rss",
          "feed_position": 21
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/ai-mode-in-google-search-can-now-pull-context-from-your-other-apps-160000103.html",
          "published_at": "Thu, 22 Jan 2026 16:00:00 +0000",
          "title": "AI Mode in Google search can now pull context from your other apps",
          "standfirst": "After adding Personal Intelligence to Gemini as an opt-in experience, Google has announced that it’s also integrating the feature into AI Mode in Search. What Personal Intelligence does is pull information from your Google apps to tailor its responses based on your history and interests. For Search, in particular, you can allow Personal Intelligence to look for information in your Gmail accounts and Google Photos libraries.If you use AI Mode to shop for clothes with the new feature enabled, for instance, Google could recommend items or models from a brand you previously purchased from. If it sees plane tickets or other reservations in Gmail, Google could also recommend specific items based on your destination and the season if you’re clothes shopping for that trip.Personal Intelligence is powered by Google’s Gemini 3 AI model. The company says it doesn’t train its models using information from your Gmail inbox or Google Photos library, but it does use your prompts and AI Mode’s responses. Google also warned that sometimes, the feature’s recommendations could feel inaccurate because it could not fully comprehend the context or could make incorrect connections between separate topics. At the moment, Personal Intelligence is an experimental feature that’s rolling out in Labs starting today. Google AI Pro and Ultra subscribers in the US, who use the service in English, will automatically have access to it and be able to connect AI Mode to Gmail and Google Photos. It will only be available to personal Google accounts, however, and not for Workspace accounts just yet. This article originally appeared on Engadget at https://www.engadget.com/ai/ai-mode-in-google-search-can-now-pull-context-from-your-other-apps-160000103.html?src=rss",
          "content": "After adding Personal Intelligence to Gemini as an opt-in experience, Google has announced that it’s also integrating the feature into AI Mode in Search. What Personal Intelligence does is pull information from your Google apps to tailor its responses based on your history and interests. For Search, in particular, you can allow Personal Intelligence to look for information in your Gmail accounts and Google Photos libraries.If you use AI Mode to shop for clothes with the new feature enabled, for instance, Google could recommend items or models from a brand you previously purchased from. If it sees plane tickets or other reservations in Gmail, Google could also recommend specific items based on your destination and the season if you’re clothes shopping for that trip.Personal Intelligence is powered by Google’s Gemini 3 AI model. The company says it doesn’t train its models using information from your Gmail inbox or Google Photos library, but it does use your prompts and AI Mode’s responses. Google also warned that sometimes, the feature’s recommendations could feel inaccurate because it could not fully comprehend the context or could make incorrect connections between separate topics. At the moment, Personal Intelligence is an experimental feature that’s rolling out in Labs starting today. Google AI Pro and Ultra subscribers in the US, who use the service in English, will automatically have access to it and be able to connect AI Mode to Gmail and Google Photos. It will only be available to personal Google accounts, however, and not for Workspace accounts just yet. This article originally appeared on Engadget at https://www.engadget.com/ai/ai-mode-in-google-search-can-now-pull-context-from-your-other-apps-160000103.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/expressvpn-two-year-plans-are-up-to-78-percent-off-right-now-180602025.html",
          "published_at": "Thu, 22 Jan 2026 15:45:35 +0000",
          "title": "ExpressVPN two-year plans are up to 78 percent off right now",
          "standfirst": "ExpressVPN is back on sale again, and its two-year plans are up to 78 percent off right now. You can get the Advanced tier for $101 for 28 months. This is marked down from the $392 that this time frame normally costs. On a per-month basis, it works out to roughly $3.59 for the promo period. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices. The Basic plan is $78 right now for 28 months, down from $363, and the Pro plan is $168, down from $560. That's 78 percent and 70 percent off, respectively. All plans carry a 30-day money-back guarantee for new users, so you can try it without committing long term if you’re on the fence.This article originally appeared on Engadget at https://www.engadget.com/deals/expressvpn-two-year-plans-are-up-to-78-percent-off-right-now-180602025.html?src=rss",
          "content": "ExpressVPN is back on sale again, and its two-year plans are up to 78 percent off right now. You can get the Advanced tier for $101 for 28 months. This is marked down from the $392 that this time frame normally costs. On a per-month basis, it works out to roughly $3.59 for the promo period. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices. The Basic plan is $78 right now for 28 months, down from $363, and the Pro plan is $168, down from $560. That's 78 percent and 70 percent off, respectively. All plans carry a 30-day money-back guarantee for new users, so you can try it without committing long term if you’re on the fence.This article originally appeared on Engadget at https://www.engadget.com/deals/expressvpn-two-year-plans-are-up-to-78-percent-off-right-now-180602025.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/canon-eos-r6-iii-review-a-video-powerhouse-thats-also-great-for-photography-153000494.html",
          "published_at": "Thu, 22 Jan 2026 15:30:00 +0000",
          "title": "Canon EOS R6 III review: A video powerhouse that's also great for photography",
          "standfirst": "With video features like RAW now the norm on midrange mirrorless cameras, Canon decided not to mess around with its latest model, the 33-megapixel EOS R6 III. It’s a veritable cinematic beast, allowing up to 7K RAW video capture internally with fast and reliable autofocus and rock solid stabilization. At the same time, it's a solid photo camera with high burst speeds and warm, accurate image quality. The R6 III has stiff competition with Sony’s 33MP A7 V, though, as the latter delivers higher dynamic range. The price could also be an issue for buyers, as the R6 III costs $300 more than its predecessor. Whether it’s worth that extra money depends on what you’re planning to do with it. Handling and design Canon EOS R6 III Steve Dent for Engadget The EOS R6 III is quintessentially Canon in terms of design. It strongly resembles the R6 II and EOS R5 II, with the same button and dial layout at the rear. In terms of functionality, this is a good thing as everything falls perfectly to hand, letting you control it by feel once you’re used to it. However, the R6 III’s design is a bit bland, so if you’re looking for a stylish camera a la Fujifilm, this is not the one. Holding the R6 III is also a pleasure thanks to the grippy, soft rubber exterior, though at 1.5 pounds it’s a bit heavier than the A7 V. It’s comfortable to hold and use all day, unlike Sony’s A7 V which felt uncomfortable after prolonged usage because of the harder material and sharp crease around the fingertip area. The R6 III’s 3.69-million dot, 120 fps electronic viewfinder (EVF) worked fine for me to check color and focus, but falls short of the one on the much cheaper Nikon Z6 III. The flip-out 3-inch 1.65-million-dot rear touch display is on par for this category and does the job well. For storage, the R6 III supports CFexpress Type B cards for capturing RAW video, along with SD UHS II for MP4 video and photos. Other key features include headphone and microphone ports, a full-sized HDMI input (instead of microHDMI as before, thankfully) and a USB-C port for charging and transfers. Battery life is decent for this category with a maximum 510 shots per charge or 620 shots if you engage the power saving mode or about 90 minutes of continuous 4K capture. However, you can roughly double those figures with Canon's optional $150 BG-R20 battery grip. Performance Canon's EOS R6 III offers fast burst speeds and skin-tone friendly colors Steve Dent for Engadget The R6 III offers a boost in shooting speeds over its predecessor thanks to an all-new 33MP sensor. It has a faster readout speed than the R6 II as well, allowing for faster bursts and lower rolling shutter skew. In comparison, Sony’s A7 V also has a 33MP sensor but it’s partially stacked, so it delivers less distortion when shooting fast-moving subjects. With that new sensor and a 34 percent faster Digic X processor, the R6 III can shoot bursts at up to 40 fps in electronic and 12 fps in mechanical shutter modes (with continuous AF and AE enabled). That’s second only to the Panasonic S1 II (70 fps) in this price range. You can fill the buffer in about 3.7 seconds at that speed (150 RAW frames), which is a decent amount for a midrange camera. You usually want to avoid the electronic shutter with fast-moving action due to rolling shutter distortion, but the R6 III’s faster sensor can handle objects that are moving reasonably quickly. I also caught a few photos of babies, bikes and dogs I might have otherwise missed by using the new pre-capture mode that records up to 15 photos before fully declencing the shutter. The new sensor and processor also make the R6 III’s autofocus system faster and more accurate than before. When shooting bursts for fast moving action like dogs running or biking, less than five percent of my shots were out of focus. And the EOS R6 III can now track animals, birds and vehicles, on top of the faces, eyes and bodies of people. This camera also has a couple of new autofocus tricks, including one called Register People Priority. That lets you save up to 10 individuals on camera that it can identify and automatically switch to. I found it handy in a large gathering, helping me focus on my niece enjoying her second Christmas. However, the R6 III lacks a few autofocus features found on the R5 II like “action priority” for sports, eye control AF and AI upscaling. In-body stabilization is also excellent, keeping the sensor rock-steady for handheld shooting with 8.5 stops of shake reduction. With that enabled, I was able to nicely blur action on the streets while keeping the background sharply in focus at shutter speeds down to a full second. Image quality With a 33MP sensor instead of a 24MP sensor, the R6 III offers quite a bit more sharpness and a touch more dynamic range than its predecessor. When shooting RAW, I was able to coax a lot of detail out of high contrast shots on sunny days with dark shadows. However, Sony’s A7 V soundly beats the R6 III in terms of dynamic range, thanks to its innovative new sensor. The R6 III’s high ISO performance isn’t too bad for a higher-resolution camera either, with noise staying under control up to ISO 12,800. As is typical with Canon models, skin tones are warmer and more flattering than on Sony and Nikon cameras, due to the slightly more yellow-biased pink tones. Those pleasing colors were consistent, even at high ISOs, when I shot kids and adults at a couple of indoor gatherings. If you don’t want the hassle of RAW, JPEG rendering is excellent straight out of the camera, with well balanced sharpening and noise reduction. Note that switching to electronic shutter mode drops the sensor to a 12-bit readout, which helps burst speeds but hurts image quality. This is a pretty big downside compared to the A7 V, which maintains 14-bit quality even when shooting at the camera’s maximum rate at 30 fps. So while on paper the R6 III wins the speed race, the 10 extra fps won’t be worth the drop in quality for many photographers. Video Canon’s EOS R6 III Steve Dent for Engadget Canon has improved video on the R6 III in every way, putting it nearly on par with the more expensive R5 II. Though it can’t shoot 8K, it can handle 7K RAW video at up to 60 fps (on CFexpress only) and 4K at 120p, with less rolling shutter than the R6 II. It also supports 3:2 “open gate” video that uses the full sensor area so you can output high-res vertical video and other formats. The R6 III supports 4K 10-bit MP4 shooting at high data rates too if you’d rather save storage space or shoot on SD cards. You also get CLog 2 on top of CLog 3 capability for improved dynamic range. Oddly though, Canon made it a bit of a pain to switch to log modes compared to past models, forcing you to slog through a bunch of menus to do so. Video autofocus is excellent across all resolutions, with rapid subject acquisition and reliable tracking. Face and eye detection work very well, and I only occasionally noticed slight autofocus lag with fast-moving subjects, particularly when they were moving toward the camera. As for stabilization, I could smoothly shoot handheld with no crop, provided I didn’t move the camera too aggressively. Digital stabilization allowed even more movement and the enhanced setting let me shoot smoothly while walking (7K doesn’t work in the digital stabilization modes, though). Panasonic’s S5 II is still the best in this regard with slightly smoother stabilization, but the R6 III isn’t far behind. Video on the EOS R6 III is extremely sharp in RAW and the HQ modes, particularly with supersampled 4K HQ. Other 4K modes are subsampled, but nearly as sharp. Rolling shutter is better managed than before, but you’ll still want to avoid things like whip pans, sudden jolts or rapid subjects like propellers or golf swings. In a variety of shooting scenarios in bright and dark conditions, Canon’s excellent color science delivered warm skin tones and accurate colors. Shooting RAW video allowed me to widely adjust shots in post, while the CLog 2 mode drastically improved dynamic range while I was shooting in contrasty conditions. For instance, I shot the famous Paris department store windows and was able to extract detail from the very bright and dark parts of the video. Overheating has been an issue in the past on Canon’s R6 models, but the R6 III never shut down for me, even during a few tests of over 15 minutes. Overall, it reliably delivered outstanding video quality and I actually preferred it to the R5 II due to the smaller RAW file sizes. Wrap-up Canon EOS R6 III mirrorless camera Steve Dent for Engadget Canon’s EOS R6 III is now the best midrange camera for creators thanks to the RAW video, rapid and accurate autofocus and excellent handling. At the same time, it’s a solid camera for photography with high burst speeds, extra resolution and, again, reliable AF. If it’s mainly photography you’re interested in, though, Sony’s $2,900 A7 V is a better choice. It matches the R6 III’s resolution, price and autofocus but offers superior dynamic range and lower rolling shutter distortion. Other video-centric options may be more attractive for other reasons — including budget. Nikon’s 24MP Z6 III offers similar capabilities, has a partially stacked sensor and retails for $2,400, but can often be found on sale for less. Panasonic’s S1 II is also a good pick due to its RAW video and creator-centric features, though it costs more at $3,200. Which one to buy, then, depends on your budget, usage (video or photography) and whether you already have lenses in one system or another. With that said, if it’s a Canon camera you’re after and you lean toward content creation, the EOS R6 III is your best choice. This article originally appeared on Engadget at https://www.engadget.com/cameras/canon-eos-r6-iii-review-a-video-powerhouse-thats-also-great-for-photography-153000494.html?src=rss",
          "content": "With video features like RAW now the norm on midrange mirrorless cameras, Canon decided not to mess around with its latest model, the 33-megapixel EOS R6 III. It’s a veritable cinematic beast, allowing up to 7K RAW video capture internally with fast and reliable autofocus and rock solid stabilization. At the same time, it's a solid photo camera with high burst speeds and warm, accurate image quality. The R6 III has stiff competition with Sony’s 33MP A7 V, though, as the latter delivers higher dynamic range. The price could also be an issue for buyers, as the R6 III costs $300 more than its predecessor. Whether it’s worth that extra money depends on what you’re planning to do with it. Handling and design Canon EOS R6 III Steve Dent for Engadget The EOS R6 III is quintessentially Canon in terms of design. It strongly resembles the R6 II and EOS R5 II, with the same button and dial layout at the rear. In terms of functionality, this is a good thing as everything falls perfectly to hand, letting you control it by feel once you’re used to it. However, the R6 III’s design is a bit bland, so if you’re looking for a stylish camera a la Fujifilm, this is not the one. Holding the R6 III is also a pleasure thanks to the grippy, soft rubber exterior, though at 1.5 pounds it’s a bit heavier than the A7 V. It’s comfortable to hold and use all day, unlike Sony’s A7 V which felt uncomfortable after prolonged usage because of the harder material and sharp crease around the fingertip area. The R6 III’s 3.69-million dot, 120 fps electronic viewfinder (EVF) worked fine for me to check color and focus, but falls short of the one on the much cheaper Nikon Z6 III. The flip-out 3-inch 1.65-million-dot rear touch display is on par for this category and does the job well. For storage, the R6 III supports CFexpress Type B cards for capturing RAW video, along with SD UHS II for MP4 video and photos. Other key features include headphone and microphone ports, a full-sized HDMI input (instead of microHDMI as before, thankfully) and a USB-C port for charging and transfers. Battery life is decent for this category with a maximum 510 shots per charge or 620 shots if you engage the power saving mode or about 90 minutes of continuous 4K capture. However, you can roughly double those figures with Canon's optional $150 BG-R20 battery grip. Performance Canon's EOS R6 III offers fast burst speeds and skin-tone friendly colors Steve Dent for Engadget The R6 III offers a boost in shooting speeds over its predecessor thanks to an all-new 33MP sensor. It has a faster readout speed than the R6 II as well, allowing for faster bursts and lower rolling shutter skew. In comparison, Sony’s A7 V also has a 33MP sensor but it’s partially stacked, so it delivers less distortion when shooting fast-moving subjects. With that new sensor and a 34 percent faster Digic X processor, the R6 III can shoot bursts at up to 40 fps in electronic and 12 fps in mechanical shutter modes (with continuous AF and AE enabled). That’s second only to the Panasonic S1 II (70 fps) in this price range. You can fill the buffer in about 3.7 seconds at that speed (150 RAW frames), which is a decent amount for a midrange camera. You usually want to avoid the electronic shutter with fast-moving action due to rolling shutter distortion, but the R6 III’s faster sensor can handle objects that are moving reasonably quickly. I also caught a few photos of babies, bikes and dogs I might have otherwise missed by using the new pre-capture mode that records up to 15 photos before fully declencing the shutter. The new sensor and processor also make the R6 III’s autofocus system faster and more accurate than before. When shooting bursts for fast moving action like dogs running or biking, less than five percent of my shots were out of focus. And the EOS R6 III can now track animals, birds and vehicles, on top of the faces, eyes and bodies of people. This camera also has a couple of new autofocus tricks, including one called Register People Priority. That lets you save up to 10 individuals on camera that it can identify and automatically switch to. I found it handy in a large gathering, helping me focus on my niece enjoying her second Christmas. However, the R6 III lacks a few autofocus features found on the R5 II like “action priority” for sports, eye control AF and AI upscaling. In-body stabilization is also excellent, keeping the sensor rock-steady for handheld shooting with 8.5 stops of shake reduction. With that enabled, I was able to nicely blur action on the streets while keeping the background sharply in focus at shutter speeds down to a full second. Image quality With a 33MP sensor instead of a 24MP sensor, the R6 III offers quite a bit more sharpness and a touch more dynamic range than its predecessor. When shooting RAW, I was able to coax a lot of detail out of high contrast shots on sunny days with dark shadows. However, Sony’s A7 V soundly beats the R6 III in terms of dynamic range, thanks to its innovative new sensor. The R6 III’s high ISO performance isn’t too bad for a higher-resolution camera either, with noise staying under control up to ISO 12,800. As is typical with Canon models, skin tones are warmer and more flattering than on Sony and Nikon cameras, due to the slightly more yellow-biased pink tones. Those pleasing colors were consistent, even at high ISOs, when I shot kids and adults at a couple of indoor gatherings. If you don’t want the hassle of RAW, JPEG rendering is excellent straight out of the camera, with well balanced sharpening and noise reduction. Note that switching to electronic shutter mode drops the sensor to a 12-bit readout, which helps burst speeds but hurts image quality. This is a pretty big downside compared to the A7 V, which maintains 14-bit quality even when shooting at the camera’s maximum rate at 30 fps. So while on paper the R6 III wins the speed race, the 10 extra fps won’t be worth the drop in quality for many photographers. Video Canon’s EOS R6 III Steve Dent for Engadget Canon has improved video on the R6 III in every way, putting it nearly on par with the more expensive R5 II. Though it can’t shoot 8K, it can handle 7K RAW video at up to 60 fps (on CFexpress only) and 4K at 120p, with less rolling shutter than the R6 II. It also supports 3:2 “open gate” video that uses the full sensor area so you can output high-res vertical video and other formats. The R6 III supports 4K 10-bit MP4 shooting at high data rates too if you’d rather save storage space or shoot on SD cards. You also get CLog 2 on top of CLog 3 capability for improved dynamic range. Oddly though, Canon made it a bit of a pain to switch to log modes compared to past models, forcing you to slog through a bunch of menus to do so. Video autofocus is excellent across all resolutions, with rapid subject acquisition and reliable tracking. Face and eye detection work very well, and I only occasionally noticed slight autofocus lag with fast-moving subjects, particularly when they were moving toward the camera. As for stabilization, I could smoothly shoot handheld with no crop, provided I didn’t move the camera too aggressively. Digital stabilization allowed even more movement and the enhanced setting let me shoot smoothly while walking (7K doesn’t work in the digital stabilization modes, though). Panasonic’s S5 II is still the best in this regard with slightly smoother stabilization, but the R6 III isn’t far behind. Video on the EOS R6 III is extremely sharp in RAW and the HQ modes, particularly with supersampled 4K HQ. Other 4K modes are subsampled, but nearly as sharp. Rolling shutter is better managed than before, but you’ll still want to avoid things like whip pans, sudden jolts or rapid subjects like propellers or golf swings. In a variety of shooting scenarios in bright and dark conditions, Canon’s excellent color science delivered warm skin tones and accurate colors. Shooting RAW video allowed me to widely adjust shots in post, while the CLog 2 mode drastically improved dynamic range while I was shooting in contrasty conditions. For instance, I shot the famous Paris department store windows and was able to extract detail from the very bright and dark parts of the video. Overheating has been an issue in the past on Canon’s R6 models, but the R6 III never shut down for me, even during a few tests of over 15 minutes. Overall, it reliably delivered outstanding video quality and I actually preferred it to the R5 II due to the smaller RAW file sizes. Wrap-up Canon EOS R6 III mirrorless camera Steve Dent for Engadget Canon’s EOS R6 III is now the best midrange camera for creators thanks to the RAW video, rapid and accurate autofocus and excellent handling. At the same time, it’s a solid camera for photography with high burst speeds, extra resolution and, again, reliable AF. If it’s mainly photography you’re interested in, though, Sony’s $2,900 A7 V is a better choice. It matches the R6 III’s resolution, price and autofocus but offers superior dynamic range and lower rolling shutter distortion. Other video-centric options may be more attractive for other reasons — including budget. Nikon’s 24MP Z6 III offers similar capabilities, has a partially stacked sensor and retails for $2,400, but can often be found on sale for less. Panasonic’s S1 II is also a good pick due to its RAW video and creator-centric features, though it costs more at $3,200. Which one to buy, then, depends on your budget, usage (video or photography) and whether you already have lenses in one system or another. With that said, if it’s a Canon camera you’re after and you lean toward content creation, the EOS R6 III is your best choice. This article originally appeared on Engadget at https://www.engadget.com/cameras/canon-eos-r6-iii-review-a-video-powerhouse-thats-also-great-for-photography-153000494.html?src=rss",
          "feed_position": 24,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Canon%20EOS%20R6%20Mark%20III_6077"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/nintendo/the-switch-2-version-of-super-mario-bros-wonder-arrives-on-march-26-150916983.html",
          "published_at": "Thu, 22 Jan 2026 15:09:16 +0000",
          "title": "The Switch 2 version of Super Mario Bros. Wonder arrives on March 26",
          "standfirst": "While many of us wait (im)patiently for a brand new Mario platformer for the Switch 2, Nintendo is filling the gap with an upgraded version of the tremendous Super Mario Bros. Wonder for the console. Super Mario Bros. Wonder – Nintendo Switch 2 Edition + Meetup in Bellabel Park (to give the new edition's full name) will arrive on March 26. Those who own the original Switch version of the game will be able to buy an upgrade pack, which costs $20. There's a lot of new stuff in the Switch 2 version, including co-op and multiplayer features. Bellabel Park, a fresh area of the Flower Kingdom, will open up. You can jump into some multiplayer modes here, such as one where you compete to collect as many coins as possible. A section that's all about local multiplayer has 17 co-op and versus modes. You can either play those on the same console or use GameShare so that up to three other people in the same physical place as you can join in on their own Switch or Switch 2. The Game Room Plaza, meanwhile, supports local and online play for six minigames — each player will need their own system for those. Up to eight people can play using the local wireless feature, and up to 12 via online multiplayer.Along with those multiplayer minigame areas, Bellabel Park is home to Toad Brigade Training Camp. Here, you can take on challenges based on levels from the main game. You can tackle these on your own or recruit up to three friends to help (you'll only need one Switch 2 for this). There are new things to check out in the main game as well. You can take on boss courses that feature all seven Koopalings and (finally!) play as Rosalina.Nintendo is adding an option in which a second player can control a Luma. They can help out the main player by defeating enemies and collecting coins. You can play as the Luma by using the Switch 2 mouse control feature. That's a great idea, as it could allow, say, a parent or guardian who is not too familiar with a game controller to assist a kid who needs some extra help to get through Super Mario Bros. Wonder. In addition, there's an assist mode. When this is enabled, you can quickly recover from falling into a pit (with a propeller flower bringing you back into the action) and avoid taking any damage. That's not all, folks. Also on March 26, you can snag three new amiibo from the game: Elephant Mario (which I'm going to have to buy), Poplin & Prince Florian and Captain Toad & Talking Flower. A couple of weeks earlier, on March 12, Nintendo will start selling a physical version of the Talking Flower from Super Mario Bros. Wonder. The battery-powered device will talk to you a couple of times per hour, mentioning things like the room temperature and time. It can play music as well. There's a button you can press to hear it talk (or hold to make it shut up). There's support for 11 languages and it can chatter at set times, making it a bit similar to Nintendo's Alarmo. You'll be able to buy Talking Flower from Nintendo's New York and San Francisco stores, its online store and some other retailers, with pre-orders opening today.This article originally appeared on Engadget at https://www.engadget.com/gaming/nintendo/the-switch-2-version-of-super-mario-bros-wonder-arrives-on-march-26-150916983.html?src=rss",
          "content": "While many of us wait (im)patiently for a brand new Mario platformer for the Switch 2, Nintendo is filling the gap with an upgraded version of the tremendous Super Mario Bros. Wonder for the console. Super Mario Bros. Wonder – Nintendo Switch 2 Edition + Meetup in Bellabel Park (to give the new edition's full name) will arrive on March 26. Those who own the original Switch version of the game will be able to buy an upgrade pack, which costs $20. There's a lot of new stuff in the Switch 2 version, including co-op and multiplayer features. Bellabel Park, a fresh area of the Flower Kingdom, will open up. You can jump into some multiplayer modes here, such as one where you compete to collect as many coins as possible. A section that's all about local multiplayer has 17 co-op and versus modes. You can either play those on the same console or use GameShare so that up to three other people in the same physical place as you can join in on their own Switch or Switch 2. The Game Room Plaza, meanwhile, supports local and online play for six minigames — each player will need their own system for those. Up to eight people can play using the local wireless feature, and up to 12 via online multiplayer.Along with those multiplayer minigame areas, Bellabel Park is home to Toad Brigade Training Camp. Here, you can take on challenges based on levels from the main game. You can tackle these on your own or recruit up to three friends to help (you'll only need one Switch 2 for this). There are new things to check out in the main game as well. You can take on boss courses that feature all seven Koopalings and (finally!) play as Rosalina.Nintendo is adding an option in which a second player can control a Luma. They can help out the main player by defeating enemies and collecting coins. You can play as the Luma by using the Switch 2 mouse control feature. That's a great idea, as it could allow, say, a parent or guardian who is not too familiar with a game controller to assist a kid who needs some extra help to get through Super Mario Bros. Wonder. In addition, there's an assist mode. When this is enabled, you can quickly recover from falling into a pit (with a propeller flower bringing you back into the action) and avoid taking any damage. That's not all, folks. Also on March 26, you can snag three new amiibo from the game: Elephant Mario (which I'm going to have to buy), Poplin & Prince Florian and Captain Toad & Talking Flower. A couple of weeks earlier, on March 12, Nintendo will start selling a physical version of the Talking Flower from Super Mario Bros. Wonder. The battery-powered device will talk to you a couple of times per hour, mentioning things like the room temperature and time. It can play music as well. There's a button you can press to hear it talk (or hold to make it shut up). There's support for 11 languages and it can chatter at set times, making it a bit similar to Nintendo's Alarmo. You'll be able to buy Talking Flower from Nintendo's New York and San Francisco stores, its online store and some other retailers, with pre-orders opening today.This article originally appeared on Engadget at https://www.engadget.com/gaming/nintendo/the-switch-2-version-of-super-mario-bros-wonder-arrives-on-march-26-150916983.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
          "published_at": "Thu, 22 Jan 2026 14:00:00 GMT",
          "title": "Railway secures $100 million to challenge AWS with AI-native cloud infrastructure",
          "standfirst": "Railway, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.TQ Ventures led the round, with participation from FPV Ventures, Redpoint, and Unusual Ventures. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like Amazon Web Services and Google Cloud.\"As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?\" said Jake Cooper, Railway&#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. \"The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&#x27;t keep up.\"The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a $20 million Series A from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.Why three-minute deploy times have become unacceptable in the age of AI coding assistantsRailway&#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using Terraform, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like Claude, ChatGPT, and Cursor can generate working code in seconds.\"When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,\" Cooper told VentureBeat. \"What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.\"The company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.\"The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,\" Lobaton said. \"If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.\"Inside the controversial decision to abandon Google Cloud and build data centers from scratchWhat distinguishes Railway from competitors like Render and Fly.io is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: \"People who are really serious about software should make their own hardware.\"\"We wanted to design hardware in a way where we could build a differentiated experience,\" Cooper said. \"Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &#x27;agentic speed&#x27; while staying 100 percent the smoothest ride in town.\"The approach paid dividends during recent widespread outages that affected major cloud providers — Railway remained online throughout.This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.\"The conventional wisdom is that the big guys have economies of scale to offer better pricing,\" Cooper noted. \"But when they&#x27;re charging for VMs that usually sit idle in the cloud, and we&#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.\"How 30 employees built a platform generating tens of millions in annual revenueRailway has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.Cooper emphasized that the fundraise was strategic rather than necessary. \"We&#x27;re default alive; there&#x27;s no reason for us to raise money,\" he said. \"We raised because we see a massive opportunity to accelerate, not because we needed to survive.\"The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&#x27;s two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.\"We basically did the standard engineering thing: if you build it, they will come,\" Cooper recalled. \"And to some degree, they came.\"From side projects to Fortune 500 deployments: Railway&#x27;s unlikely corporate expansionDespite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.Notable customers include Bilt, the loyalty program company; Intuit&#x27;s GoCo subsidiary; TripAdvisor&#x27;s Cruise Critic; and MGM Resorts. Kernel, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.\"At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,\" said Rafael Garcia, Kernel&#x27;s chief technology officer. \"Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.\"For enterprise customers, Railway offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&#x27;s existing cloud environment through a \"bring your own cloud\" configuration.Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).The startup&#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivalsRailway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.Cooper argues that Railway&#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.\"The hyperscalers have two competing systems, and they haven&#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,\" he observed. \"They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&#x27;t really need to?\"Against startup competitors, Railway differentiates by covering the full infrastructure stack. \"We&#x27;re not just containers; we&#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,\" Cooper said. \"And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.\"The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.Why investors are betting that AI will create a thousand times more software than exists todayRailway&#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like GitHub Copilot, Cursor, and Claude become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.\"The amount of software that&#x27;s going to come online over the next five years is unfathomable compared to what existed before — we&#x27;re talking a thousand times more software,\" Cooper predicted. \"All of that has to run somewhere.\"The company has already integrated directly with AI systems, building what Cooper calls \"loops where Claude can hook in, call deployments, and analyze infrastructure automatically.\" Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.\"The notion of a developer is melting before our eyes,\" Cooper said. \"You don&#x27;t have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity.\"What Railway plans to do with $100 million and zero marketing experienceRailway plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&#x27;s five-year history.\"One of my mentors said you raise money when you can change the trajectory of the business,\" Cooper explained. \"We&#x27;ve built all the required substrate to scale indefinitely; what&#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.\"The company&#x27;s investor roster reads like a who&#x27;s who of developer infrastructure. Angel investors include Tom Preston-Werner, co-founder of GitHub; Guillermo Rauch, chief executive of Vercel; Spencer Kimball, chief executive of Cockroach Labs; Olivier Pomel, chief executive of Datadog; and Jori Lallo, co-founder of Linear.The timing of Railway&#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.Whether Railway can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at Wolfram Alpha, Bloomberg, and Uber before founding Railway in 2020, seems unfazed by the scale of his ambition.\"In five years, Railway [will be] the place where software gets created and evolved, period,\" he said. \"Deploy instantly, scale infinitely, with zero friction. That&#x27;s the prize worth playing for, and there&#x27;s no bigger one on offer.\"For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.",
          "content": "Railway, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.TQ Ventures led the round, with participation from FPV Ventures, Redpoint, and Unusual Ventures. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like Amazon Web Services and Google Cloud.\"As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?\" said Jake Cooper, Railway&#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. \"The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&#x27;t keep up.\"The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a $20 million Series A from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network — metrics that rival far larger and better-funded competitors.Why three-minute deploy times have become unacceptable in the age of AI coding assistantsRailway&#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using Terraform, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like Claude, ChatGPT, and Cursor can generate working code in seconds.\"When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,\" Cooper told VentureBeat. \"What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.\"The company claims its platform delivers deployments in under one second — fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.\"The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,\" Lobaton said. \"If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.\"Inside the controversial decision to abandon Google Cloud and build data centers from scratchWhat distinguishes Railway from competitors like Render and Fly.io is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: \"People who are really serious about software should make their own hardware.\"\"We wanted to design hardware in a way where we could build a differentiated experience,\" Cooper said. \"Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &#x27;agentic speed&#x27; while staying 100 percent the smoothest ride in town.\"The approach paid dividends during recent widespread outages that affected major cloud providers — Railway remained online throughout.This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines — a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.\"The conventional wisdom is that the big guys have economies of scale to offer better pricing,\" Cooper noted. \"But when they&#x27;re charging for VMs that usually sit idle in the cloud, and we&#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.\"How 30 employees built a platform generating tens of millions in annual revenueRailway has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue — a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.Cooper emphasized that the fundraise was strategic rather than necessary. \"We&#x27;re default alive; there&#x27;s no reason for us to raise money,\" he said. \"We raised because we see a massive opportunity to accelerate, not because we needed to survive.\"The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&#x27;s two million users discovered the platform through word of mouth — developers telling other developers about a tool that actually works.\"We basically did the standard engineering thing: if you build it, they will come,\" Cooper recalled. \"And to some degree, they came.\"From side projects to Fortune 500 deployments: Railway&#x27;s unlikely corporate expansionDespite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.Notable customers include Bilt, the loyalty program company; Intuit&#x27;s GoCo subsidiary; TripAdvisor&#x27;s Cruise Critic; and MGM Resorts. Kernel, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.\"At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,\" said Rafael Garcia, Kernel&#x27;s chief technology officer. \"Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.\"For enterprise customers, Railway offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&#x27;s existing cloud environment through a \"bring your own cloud\" configuration.Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).The startup&#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivalsRailway enters a crowded market that includes not only the hyperscale cloud providers—Amazon Web Services, Microsoft Azure, and Google Cloud Platform—but also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.Cooper argues that Railway&#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.\"The hyperscalers have two competing systems, and they haven&#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,\" he observed. \"They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&#x27;t really need to?\"Against startup competitors, Railway differentiates by covering the full infrastructure stack. \"We&#x27;re not just containers; we&#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,\" Cooper said. \"And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.\"The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.Why investors are betting that AI will create a thousand times more software than exists todayRailway&#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like GitHub Copilot, Cursor, and Claude become standard fixtures in developer workflows, the volume of code being written — and the infrastructure needed to run it — is expanding dramatically.\"The amount of software that&#x27;s going to come online over the next five years is unfathomable compared to what existed before — we&#x27;re talking a thousand times more software,\" Cooper predicted. \"All of that has to run somewhere.\"The company has already integrated directly with AI systems, building what Cooper calls \"loops where Claude can hook in, call deployments, and analyze infrastructure automatically.\" Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.\"The notion of a developer is melting before our eyes,\" Cooper said. \"You don&#x27;t have to be an engineer to engineer things anymore — you just need critical thinking and the ability to analyze things in a systems capacity.\"What Railway plans to do with $100 million and zero marketing experienceRailway plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&#x27;s five-year history.\"One of my mentors said you raise money when you can change the trajectory of the business,\" Cooper explained. \"We&#x27;ve built all the required substrate to scale indefinitely; what&#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.\"The company&#x27;s investor roster reads like a who&#x27;s who of developer infrastructure. Angel investors include Tom Preston-Werner, co-founder of GitHub; Guillermo Rauch, chief executive of Vercel; Spencer Kimball, chief executive of Cockroach Labs; Olivier Pomel, chief executive of Datadog; and Jori Lallo, co-founder of Linear.The timing of Railway&#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities — they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.Whether Railway can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at Wolfram Alpha, Bloomberg, and Uber before founding Railway in 2020, seems unfazed by the scale of his ambition.\"In five years, Railway [will be] the place where software gets created and evolved, period,\" he said. \"Deploy instantly, scale infinitely, with zero friction. That&#x27;s the prize worth playing for, and there&#x27;s no bigger one on offer.\"For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates — no marketing, no sales team, no venture hype—the real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5RLyQIpBeVXxv0RpcXZxWQ/fd9680c6d82acd8208ac341fc575f5fb/nuneybits_Vector_art_of_a_sleek_bullet_train_bursting_from_a_cl_32a805aa-272c-4b34-ac16-cf20508b7ff4.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/spotifys-prompted-playlist-lets-you-describe-exactly-what-you-want-to-hear-140000153.html",
          "published_at": "Thu, 22 Jan 2026 14:00:00 +0000",
          "title": "Spotify's Prompted Playlist lets you describe exactly what you want to hear",
          "standfirst": "Ahead of its upcoming price hike, Spotify is rolling out a more advanced AI playlist feature in the US and Canada. Prompted Playlist, which the company trialed in New Zealand late last year, lets subscribers \"control the Spotify algorithm,\" as the company describes it. \"You're not just asking for music, you're shaping how Spotify goes about discovering it for you.\"For example, you can guide it to make a playlist of songs you've saved to your Library but haven't listened to yet. (It can tap into your entire Spotify history.) Or, you can tell it to round up songs from a specific television show or movie. (It uses real-time information about pop culture, charts, and history.)The feature includes options to refresh the playlist over time (daily or weekly). You can edit each playlist's prompt at any time. Each track will include a short note to explain why it was chosen.The standard AI Playlist creator will remain alongside the new Prompted Playlist.SpotifySpotify says beta testers have used Prompted Playlist to revisit songs tied to specific moments and filter out tracks they've overplayed lately. \"Others are asking for long, lyric-free electronic playlists to power through a workday, or mixing in artists connected to current pop culture moments and viral trends,\" the company wrote.There's room for some confusion here because Spotify already has an \"AI Playlist\" feature. That simpler type will stick around alongside the new \"Prompted\" variety, which allows for finer tuning and can sift through more data.Prompted Playlist will be available to Spotify Premium subscribers in the US and Canada \"by the end of the month.\" Once you have access, you can try it by tapping Create, then selecting Prompted Playlist.This article originally appeared on Engadget at https://www.engadget.com/audio/spotifys-prompted-playlist-lets-you-describe-exactly-what-you-want-to-hear-140000153.html?src=rss",
          "content": "Ahead of its upcoming price hike, Spotify is rolling out a more advanced AI playlist feature in the US and Canada. Prompted Playlist, which the company trialed in New Zealand late last year, lets subscribers \"control the Spotify algorithm,\" as the company describes it. \"You're not just asking for music, you're shaping how Spotify goes about discovering it for you.\"For example, you can guide it to make a playlist of songs you've saved to your Library but haven't listened to yet. (It can tap into your entire Spotify history.) Or, you can tell it to round up songs from a specific television show or movie. (It uses real-time information about pop culture, charts, and history.)The feature includes options to refresh the playlist over time (daily or weekly). You can edit each playlist's prompt at any time. Each track will include a short note to explain why it was chosen.The standard AI Playlist creator will remain alongside the new Prompted Playlist.SpotifySpotify says beta testers have used Prompted Playlist to revisit songs tied to specific moments and filter out tracks they've overplayed lately. \"Others are asking for long, lyric-free electronic playlists to power through a workday, or mixing in artists connected to current pop culture moments and viral trends,\" the company wrote.There's room for some confusion here because Spotify already has an \"AI Playlist\" feature. That simpler type will stick around alongside the new \"Prompted\" variety, which allows for finer tuning and can sift through more data.Prompted Playlist will be available to Spotify Premium subscribers in the US and Canada \"by the end of the month.\" Once you have access, you can try it by tapping Create, then selecting Prompted Playlist.This article originally appeared on Engadget at https://www.engadget.com/audio/spotifys-prompted-playlist-lets-you-describe-exactly-what-you-want-to-hear-140000153.html?src=rss",
          "feed_position": 28,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Sampled_Favorites.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/get-one-year-of-access-to-one-of-our-favorite-budgeting-apps-for-only-50-204507787.html",
          "published_at": "Thu, 22 Jan 2026 13:45:35 +0000",
          "title": "Get one year of access to one of our favorite budgeting apps for only $50",
          "standfirst": "A new year is the perfect time to get your spending in order, and if you're not trying to build your own spreadsheet, budgeting apps are one of the best ways to do it. To save yourself some money in the process, you can pick up a year-long subscription to Monarch Money, one of Engadget's favorite budgeting apps, for just $50 if you use code NEWYEAR2026 at checkout and you're a new subscriber. That's a 50 percent discount on the service's normal $100 price. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/apps/get-one-year-of-access-to-one-of-our-favorite-budgeting-apps-for-only-50-204507787.html?src=rss",
          "content": "A new year is the perfect time to get your spending in order, and if you're not trying to build your own spreadsheet, budgeting apps are one of the best ways to do it. To save yourself some money in the process, you can pick up a year-long subscription to Monarch Money, one of Engadget's favorite budgeting apps, for just $50 if you use code NEWYEAR2026 at checkout and you're a new subscriber. That's a 50 percent discount on the service's normal $100 price. Monarch Money makes for a capable and detailed budgeting companion. You can use the service via apps for iOS, Android, iPadOS or the web, and Monarch also offers a Chrome extension that can sync your Amazon and Target transactions and automatically categorize them. Like other budgeting apps, Monarch Money lets you connect multiple financial accounts and track your money based on where you spend it over time. Monarch offers two different approaches to tracking budgeting (flexible and category budgeting) depending on what fits your life best, and the ability to add a budget widget on your phone so you can know how you're tracking that month. How budgeting apps turn your raw transactions into visuals you can understand at a glance is one of the big things that differentiates one app from another, and Monarch Money offers multiple graphs and charts to look at for things like spending, investments or categories of your choice based on how you've labelled your expenses. The app can also monitor the spending of you and your partner all in one place, to make it easier to plan together. The main drawbacks Engadget found in testing Monarch Money were the app's learning curve, and the differences in features (and bugginess) between Monarch's web and mobile versions. Still, for 50 percent off, the Monarch Money is well worth experimenting with if you're trying to save money in 2026, especially if you want to do it collaboratively with a partner. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/apps/get-one-year-of-access-to-one-of-our-favorite-budgeting-apps-for-only-50-204507787.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/save-on-the-disney-hulu-bundle-get-one-month-for-only-10-192814972.html",
          "published_at": "Thu, 22 Jan 2026 13:22:08 +0000",
          "title": "Save on the Disney+ Hulu bundle: Get one month for only $10",
          "standfirst": "The peak time for deals on streaming services — the holiday shopping season — has come and gone, but Disney is back with a fresh offer for the new year. New and eligible returning subscribers can get one month of the ad-supported Disney+ Hulu bundle for just $10. That's $3 off the usual monthly rate for the bundle, and more than 58 percent off if you consider the prices for each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/save-on-the-disney-hulu-bundle-get-one-month-for-only-10-192814972.html?src=rss",
          "content": "The peak time for deals on streaming services — the holiday shopping season — has come and gone, but Disney is back with a fresh offer for the new year. New and eligible returning subscribers can get one month of the ad-supported Disney+ Hulu bundle for just $10. That's $3 off the usual monthly rate for the bundle, and more than 58 percent off if you consider the prices for each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/save-on-the-disney-hulu-bundle-get-one-month-for-only-10-192814972.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/pc/how-to-find-an-affordable-gpu-during-the-great-ramageddon-of-2026-130000654.html",
          "published_at": "Thu, 22 Jan 2026 13:00:00 +0000",
          "title": "How to find an affordable GPU during the great RAMageddon of 2026",
          "standfirst": "If you're thinking about upgrading to a new graphics card this year, your window for doing so at MSRP has closed. When I first reported on this at the start of December, things were looking bleak but you could still find GPUs from both AMD and NVIDIA at close to their recommended prices. That changed last week when YouTube channel Hardware Unboxed reported that ASUS had stopped producing the RTX 5070 Ti and 5060 Ti 16GB due to ongoing memory shortages. After Engadget published the news, NVIDIA disputed the report. “Demand for GeForce RTX GPUs is strong, and memory supply is constrained. We continue to ship all GeForce SKUs and are working closely with our suppliers to maximize memory availability,” a company spokesperson told us. The next day, ASUS walked back its previous statements. After “explicitly” telling Hardware Unboxed it had placed the 5060 Ti 16GB and 5070 Ti into \"end-of-life status,\" the company said \"certain media may have received incomplete information from an ASUS PR representative regarding these products,\" adding it had \"no plans to stop selling these models.\" Whether or not the 5060 Ti 16GB and 5070 Ti remain in production, one thing is certain: the AI boom has created a great deal of uncertainty in the GPU market. After the news, panic buying sent the price of the 5070 Ti through the roof. Right now, it's impossible to find that model priced at its MSRP of $749. As of the writing of this article, the most affordable version of the 5070 Ti I could find on Newegg was $1,199. The bigger problem is that the 5070 Ti isn't the only GPU selling for far more than MSRP. Tom's Hardware has been tracking GPU prices for months, and there's not a single model you can buy at either AMD or NVIDIA's recommended price. That puts PC builders in a tough spot. What do you do if you want to upgrade to a new graphics card this year? If you're sitting on an older GPU, the best advice I can give is to stick with your current hardware. If you're fine with the performance of your video card right now, it's best to wait a year or two for the market to settle down. On the other hand, if your current GPU is not up to the task of running the games you want to play, try to buy a card with at least 12GB of VRAM — preferably 16GB if your budget allows for it. Unless you plan to play mostly older games on a 1080p monitor, it's not worth considering a model with 8GB of VRAM — it won't last you long enough to warrant the purchase price. For the most part, the recommendations in Engadget's recent GPU guide are still as relevant today as they were a few months ago. The recommendations I provide here are pulled from that guide and are grouped from most affordable to most expensive. Where possible, I've tried to find options from both Newegg and Amazon. As you go about looking for a new GPU, your best friend is a website like PCPartPicker where you can track pricing across multiple retailers. RecommendationsAMD Radeon RX 9060 XT 16GBThe Radeon RX 9060 XT 16GB is the best mainstream option right now. Devindra Hardawar for EngadgetUnfortunately if you're on a tight budget, there aren't many great options under $400. For that reason, I would steer you to the Radeon RX 9060 XT as the best \"entry-level\" option. AMD offers two different versions of this GPU: one with 8GB of VRAM and the other with 16GB. Of the two, the latter is the better purchase, but if it's outside your budget, the more affordable model is probably the best 8GB GPU on the market right now.While I couldn't find the 16GB variant at its recommended price of $350, I did find a few models that weren't far off. Newegg has options from ASRock and Sapphire priced at $400 and $450. At Amazon, meanwhile, you can find models from PowerColor for $400 and $430. NVIDIA GeForce RTX 5070 A Founders Edition NVIDIA RTX 5080 sits on a wood desk.Devindra Hardawar for EngadgetI'm somewhat hesitant to recommend the RTX 5070. Don't get me wrong, it's a decent enough card, but with only 12GB of VRAM, you may end up replacing it sooner than you think. That said, it's one of the few NVIDIA GPUs that hasn't shot up massively in price, and I suspect that's because people have been passing it over in favor of other 50-series models. If you value NVIDIA's feature set over raw frames, then the 5070 is about the only GPU that makes sense to buy from the company right now. On Newegg, I found a 5070 model from Gigabyte for $650. The retailer also has a handful of different MSI variants priced at $630. Amazon has fewer options, but it does have one 5070 from Gigabyte for $585, which is the closest to the card's $549 MSRP. AMD Radeon RX 9070 If you're a fan of Team Red, the Radeon RX 9070 and 9070 XT are among the best cards of this generation. Devindra Hardawar for EngadgetFor a card that offers better price-to-performance than the 5070, the Radeon RX 9070 is your best bet. AMD's take on NVIDIA features like DLSS aren't as polished, but the RX 9070 offers more VRAM and excellent performance across the latest AAA games. It's unlikely you'll find one at its MSRP of $550, which was always more of an aspirational price, but I found a few models priced between $590 and $640. Both Newegg and Amazon have a PowerColor model for $590. The two also have a Gigabyte model priced at $600 after $40 rebate with coupon. AMD Radeon RX 9070XTFor those with more to spend, the RX 9070 XT is probably where I would cap things. Beyond that, you're looking at GPUs like the 5080 that cost far more than MSRP. On Newegg, I found a model from ASRock selling for $730. Amazon, meanwhile, has options from Gigabyte and ASUS for $720. None of those are great deals, but that's to be expected with a card that's at the top of the stack. This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/how-to-find-an-affordable-gpu-during-the-great-ramageddon-of-2026-130000654.html?src=rss",
          "content": "If you're thinking about upgrading to a new graphics card this year, your window for doing so at MSRP has closed. When I first reported on this at the start of December, things were looking bleak but you could still find GPUs from both AMD and NVIDIA at close to their recommended prices. That changed last week when YouTube channel Hardware Unboxed reported that ASUS had stopped producing the RTX 5070 Ti and 5060 Ti 16GB due to ongoing memory shortages. After Engadget published the news, NVIDIA disputed the report. “Demand for GeForce RTX GPUs is strong, and memory supply is constrained. We continue to ship all GeForce SKUs and are working closely with our suppliers to maximize memory availability,” a company spokesperson told us. The next day, ASUS walked back its previous statements. After “explicitly” telling Hardware Unboxed it had placed the 5060 Ti 16GB and 5070 Ti into \"end-of-life status,\" the company said \"certain media may have received incomplete information from an ASUS PR representative regarding these products,\" adding it had \"no plans to stop selling these models.\" Whether or not the 5060 Ti 16GB and 5070 Ti remain in production, one thing is certain: the AI boom has created a great deal of uncertainty in the GPU market. After the news, panic buying sent the price of the 5070 Ti through the roof. Right now, it's impossible to find that model priced at its MSRP of $749. As of the writing of this article, the most affordable version of the 5070 Ti I could find on Newegg was $1,199. The bigger problem is that the 5070 Ti isn't the only GPU selling for far more than MSRP. Tom's Hardware has been tracking GPU prices for months, and there's not a single model you can buy at either AMD or NVIDIA's recommended price. That puts PC builders in a tough spot. What do you do if you want to upgrade to a new graphics card this year? If you're sitting on an older GPU, the best advice I can give is to stick with your current hardware. If you're fine with the performance of your video card right now, it's best to wait a year or two for the market to settle down. On the other hand, if your current GPU is not up to the task of running the games you want to play, try to buy a card with at least 12GB of VRAM — preferably 16GB if your budget allows for it. Unless you plan to play mostly older games on a 1080p monitor, it's not worth considering a model with 8GB of VRAM — it won't last you long enough to warrant the purchase price. For the most part, the recommendations in Engadget's recent GPU guide are still as relevant today as they were a few months ago. The recommendations I provide here are pulled from that guide and are grouped from most affordable to most expensive. Where possible, I've tried to find options from both Newegg and Amazon. As you go about looking for a new GPU, your best friend is a website like PCPartPicker where you can track pricing across multiple retailers. RecommendationsAMD Radeon RX 9060 XT 16GBThe Radeon RX 9060 XT 16GB is the best mainstream option right now. Devindra Hardawar for EngadgetUnfortunately if you're on a tight budget, there aren't many great options under $400. For that reason, I would steer you to the Radeon RX 9060 XT as the best \"entry-level\" option. AMD offers two different versions of this GPU: one with 8GB of VRAM and the other with 16GB. Of the two, the latter is the better purchase, but if it's outside your budget, the more affordable model is probably the best 8GB GPU on the market right now.While I couldn't find the 16GB variant at its recommended price of $350, I did find a few models that weren't far off. Newegg has options from ASRock and Sapphire priced at $400 and $450. At Amazon, meanwhile, you can find models from PowerColor for $400 and $430. NVIDIA GeForce RTX 5070 A Founders Edition NVIDIA RTX 5080 sits on a wood desk.Devindra Hardawar for EngadgetI'm somewhat hesitant to recommend the RTX 5070. Don't get me wrong, it's a decent enough card, but with only 12GB of VRAM, you may end up replacing it sooner than you think. That said, it's one of the few NVIDIA GPUs that hasn't shot up massively in price, and I suspect that's because people have been passing it over in favor of other 50-series models. If you value NVIDIA's feature set over raw frames, then the 5070 is about the only GPU that makes sense to buy from the company right now. On Newegg, I found a 5070 model from Gigabyte for $650. The retailer also has a handful of different MSI variants priced at $630. Amazon has fewer options, but it does have one 5070 from Gigabyte for $585, which is the closest to the card's $549 MSRP. AMD Radeon RX 9070 If you're a fan of Team Red, the Radeon RX 9070 and 9070 XT are among the best cards of this generation. Devindra Hardawar for EngadgetFor a card that offers better price-to-performance than the 5070, the Radeon RX 9070 is your best bet. AMD's take on NVIDIA features like DLSS aren't as polished, but the RX 9070 offers more VRAM and excellent performance across the latest AAA games. It's unlikely you'll find one at its MSRP of $550, which was always more of an aspirational price, but I found a few models priced between $590 and $640. Both Newegg and Amazon have a PowerColor model for $590. The two also have a Gigabyte model priced at $600 after $40 rebate with coupon. AMD Radeon RX 9070XTFor those with more to spend, the RX 9070 XT is probably where I would cap things. Beyond that, you're looking at GPUs like the 5080 that cost far more than MSRP. On Newegg, I found a model from ASRock selling for $730. Amazon, meanwhile, has options from Gigabyte and ASUS for $720. None of those are great deals, but that's to be expected with a card that's at the top of the stack. This article originally appeared on Engadget at https://www.engadget.com/gaming/pc/how-to-find-an-affordable-gpu-during-the-great-ramageddon-of-2026-130000654.html?src=rss",
          "feed_position": 31,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/rx-9060.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/memrl-outperforms-rag-on-complex-agent-benchmarks-without-fine-tuning",
          "published_at": "Thu, 22 Jan 2026 10:15:00 GMT",
          "title": "MemRL outperforms RAG on complex agent benchmarks without fine-tuning",
          "standfirst": "A new technique developed by researchers at Shanghai Jiao Tong University and other institutions enables large language model agents to learn new skills without the need for expensive fine-tuning.The researchers propose MemRL, a framework that gives agents the ability to develop episodic memory, the capacity to retrieve past experiences to create solutions for unseen tasks. MemRL allows agents to use environmental feedback to refine their problem-solving strategies continuously.MemRL is part of a broader push in the research community to develop continual learning capabilities for AI applications. In experiments on key industry benchmarks, the framework outperformed other baselines such as RAG and other memory organization techniques, particularly in complex environments that require exploration and experiments. This suggests MemRL could become a critical component for building AI applications that must operate in dynamic real-world settings where requirements and tasks constantly shift.The stability-plasticity dilemmaOne of the central challenges in deploying agentic applications is adapting the underlying model to new knowledge and tasks after the initial training phase. Current approaches generally fall into two categories: parametric approaches, such as fine-tuning, and non-parametric approaches, such as RAG. But both come with significant trade-offs.Fine-tuning, while effective for baking in new information, is computationally expensive and slow. More critically, it often leads to catastrophic forgetting, a phenomenon where newly acquired knowledge overwrites previously learned data, degrading the model&#x27;s general performance.Conversely, non-parametric methods like RAG are fundamentally passive; they retrieve information based solely on semantic similarity, such as vector embeddings, without evaluating the actual utility of the information to the input query. This approach assumes that \"similar implies useful,\" which is often flawed in complex reasoning tasks. The researchers argue that human intelligence solves this problem by maintaining “the delicate balance between the stability of cognitive reasoning and the plasticity of episodic memory.” In the human brain, stable reasoning (associated with the cortex) is decoupled from dynamic episodic memory. This allows humans to adapt to new tasks without \"rewiring neural circuitry\" (the rough equivalent of model fine-tuning).Inside the MemRL frameworkInspired by humans’ use of episodic memory and cognitive reasoning, MemRL is designed to enable an agent to continuously improve its performance after deployment without compromising the stability of its backbone LLM. Instead of changing the model’s parameters, the framework shifts the adaptation mechanism to an external, self-evolving memory structure.In this architecture, the LLM&#x27;s parameters remain completely frozen. The model acts effectively as the \"cortex,\" responsible for general reasoning, logic, and code generation, but it is not responsible for storing specific successes or failures encountered after deployment. This structure ensures stable cognitive reasoning and prevents catastrophic forgetting.To handle adaptation, MemRL maintains a dynamic episodic memory component. Instead of storing plain text documents and static embedding values, as is common in RAG, MemRL organizes memory into \"intent-experience-utility\" triplets. These contain the user&#x27;s query (the intent), the specific solution trajectory or action taken (the experience), and a score, known as the Q-value, that represents how successful this specific experience was in the past (the utility).Crucially for enterprise architects, this new data structure doesn&#x27;t require ripping out existing infrastructure. \"MemRL is designed to be a &#x27;drop-in&#x27; replacement for the retrieval layer in existing technology stacks and is compatible with various vector databases,\" Muning Wen, a co-author of the paper and PhD candidate at Shanghai Jiao Tong University, told VentureBeat. \"The existence and updating of &#x27;Q-Value&#x27; is solely for better evaluation and management of dynamic data... and is independent of the storage format.\"This utility score is the key differentiator from classic RAG systems. At inference time, MemRL agents employ a \"two-phase retrieval\" mechanism. First, the system identifies memories that are semantically close to the query to ensure relevance. It then re-ranks these candidates based on their Q-value, effectively prioritizing proven strategies.The framework incorporates reinforcement learning directly into the memory retrieval process. When an agent attempts a solution and receives environmental feedback (i.e., success or failure) it updates the Q-value of the retrieved memory. This creates a closed feedback loop: over time, the agent learns to ignore distractor memories and prioritize high-value strategies without ever needing to retrain the underlying LLM.While adding a reinforcement learning step might sound like it adds significant latency, Wen noted that the computational overhead is minimal. \"Our Q-value calculation is performed entirely on the CPU,\" he said.MemRL also possesses runtime continual learning capabilities. When the agent encounters a new scenario, the system uses the frozen LLM to summarize the new trajectory and adds it to the memory bank as a new triplet. This allows the agent to expand its knowledge base dynamically as it interacts with the world.It is worth noting that the automation of the value assignment comes with a risk: If the system mistakenly validates a bad interaction, the agent could learn the wrong lesson. Wen acknowledges this \"poisoned memory\" risk but notes that unlike black-box neural networks, MemRL remains transparent and auditable. \"If a bad interaction is mistakenly classified as a positive example... it may spread more widely,\" Wen said. \"However … we can easily fix it by removing the contaminated data from the memory bank or resetting their Q-values.\"MemRL in actionThe researchers evaluated MemRL against several baselines on four diverse industry benchmarks: BigCodeBench (code generation), ALFWorld (embodied navigation), Lifelong Agent Bench (OS and database interaction), and Humanity&#x27;s Last Exam (complex multidisciplinary reasoning). The results showed that MemRL consistently outperformed baselines in both runtime learning (improving during the session) and transfer learning (generalizing to unseen tasks).The advantages of this value-aware retrieval mechanism were most pronounced in exploration-heavy environments like ALFWorld. In this benchmark, which requires agents to navigate and interact with a simulated household environment, MemRL achieved a relative improvement of approximately 56% over MemP, another agentic memory framework. The researchers found that the reinforcement learning component effectively encouraged the agent to explore and discover solutions for complex tasks that similarity-based retrieval methods often failed to solve.When the memory bank was frozen and tested on held-out sets to measure generalization, MemRL achieved the highest accuracy across benchmarks. For example, on the Lifelong Agent Bench, it improved significantly upon the standard RAG baseline on OS tasks. This indicates that the system does not merely memorize training data but effectively filters out low-value memories to retain high-utility experiences that generalize to new situations.The broader picture for self-evolving agentsMemRL fits within a growing body of research focused on Memory-Based Markov Decision Processes (M-MDP), a formulation that frames memory retrieval as an active decision-making step rather than a passive search function. By treating retrieval as an action that can be optimized via reinforcement learning, frameworks like MemRL and similar approaches such as Memento are paving the way for more autonomous systems. For enterprise AI, this shift is significant. It suggests a future where agents can be deployed with a general-purpose LLM and then rapidly adapt to specific company workflows, proprietary databases, and unique problem sets through interaction alone. The key shift we’re seeing is frameworks that are treating applications as dynamic environments that they can learn from.These emerging capabilities will allow organizations to maintain consistent, high-performance agents that evolve alongside their business needs, solving the problem of stale models without incurring the prohibitive costs of constant retraining.It marks a transition in how we value data. \"In a future where static data is about to be exhausted, the interaction experience generated by each intelligent agent during its lifespan will become the new fuel,\" Wen said.",
          "content": "A new technique developed by researchers at Shanghai Jiao Tong University and other institutions enables large language model agents to learn new skills without the need for expensive fine-tuning.The researchers propose MemRL, a framework that gives agents the ability to develop episodic memory, the capacity to retrieve past experiences to create solutions for unseen tasks. MemRL allows agents to use environmental feedback to refine their problem-solving strategies continuously.MemRL is part of a broader push in the research community to develop continual learning capabilities for AI applications. In experiments on key industry benchmarks, the framework outperformed other baselines such as RAG and other memory organization techniques, particularly in complex environments that require exploration and experiments. This suggests MemRL could become a critical component for building AI applications that must operate in dynamic real-world settings where requirements and tasks constantly shift.The stability-plasticity dilemmaOne of the central challenges in deploying agentic applications is adapting the underlying model to new knowledge and tasks after the initial training phase. Current approaches generally fall into two categories: parametric approaches, such as fine-tuning, and non-parametric approaches, such as RAG. But both come with significant trade-offs.Fine-tuning, while effective for baking in new information, is computationally expensive and slow. More critically, it often leads to catastrophic forgetting, a phenomenon where newly acquired knowledge overwrites previously learned data, degrading the model&#x27;s general performance.Conversely, non-parametric methods like RAG are fundamentally passive; they retrieve information based solely on semantic similarity, such as vector embeddings, without evaluating the actual utility of the information to the input query. This approach assumes that \"similar implies useful,\" which is often flawed in complex reasoning tasks. The researchers argue that human intelligence solves this problem by maintaining “the delicate balance between the stability of cognitive reasoning and the plasticity of episodic memory.” In the human brain, stable reasoning (associated with the cortex) is decoupled from dynamic episodic memory. This allows humans to adapt to new tasks without \"rewiring neural circuitry\" (the rough equivalent of model fine-tuning).Inside the MemRL frameworkInspired by humans’ use of episodic memory and cognitive reasoning, MemRL is designed to enable an agent to continuously improve its performance after deployment without compromising the stability of its backbone LLM. Instead of changing the model’s parameters, the framework shifts the adaptation mechanism to an external, self-evolving memory structure.In this architecture, the LLM&#x27;s parameters remain completely frozen. The model acts effectively as the \"cortex,\" responsible for general reasoning, logic, and code generation, but it is not responsible for storing specific successes or failures encountered after deployment. This structure ensures stable cognitive reasoning and prevents catastrophic forgetting.To handle adaptation, MemRL maintains a dynamic episodic memory component. Instead of storing plain text documents and static embedding values, as is common in RAG, MemRL organizes memory into \"intent-experience-utility\" triplets. These contain the user&#x27;s query (the intent), the specific solution trajectory or action taken (the experience), and a score, known as the Q-value, that represents how successful this specific experience was in the past (the utility).Crucially for enterprise architects, this new data structure doesn&#x27;t require ripping out existing infrastructure. \"MemRL is designed to be a &#x27;drop-in&#x27; replacement for the retrieval layer in existing technology stacks and is compatible with various vector databases,\" Muning Wen, a co-author of the paper and PhD candidate at Shanghai Jiao Tong University, told VentureBeat. \"The existence and updating of &#x27;Q-Value&#x27; is solely for better evaluation and management of dynamic data... and is independent of the storage format.\"This utility score is the key differentiator from classic RAG systems. At inference time, MemRL agents employ a \"two-phase retrieval\" mechanism. First, the system identifies memories that are semantically close to the query to ensure relevance. It then re-ranks these candidates based on their Q-value, effectively prioritizing proven strategies.The framework incorporates reinforcement learning directly into the memory retrieval process. When an agent attempts a solution and receives environmental feedback (i.e., success or failure) it updates the Q-value of the retrieved memory. This creates a closed feedback loop: over time, the agent learns to ignore distractor memories and prioritize high-value strategies without ever needing to retrain the underlying LLM.While adding a reinforcement learning step might sound like it adds significant latency, Wen noted that the computational overhead is minimal. \"Our Q-value calculation is performed entirely on the CPU,\" he said.MemRL also possesses runtime continual learning capabilities. When the agent encounters a new scenario, the system uses the frozen LLM to summarize the new trajectory and adds it to the memory bank as a new triplet. This allows the agent to expand its knowledge base dynamically as it interacts with the world.It is worth noting that the automation of the value assignment comes with a risk: If the system mistakenly validates a bad interaction, the agent could learn the wrong lesson. Wen acknowledges this \"poisoned memory\" risk but notes that unlike black-box neural networks, MemRL remains transparent and auditable. \"If a bad interaction is mistakenly classified as a positive example... it may spread more widely,\" Wen said. \"However … we can easily fix it by removing the contaminated data from the memory bank or resetting their Q-values.\"MemRL in actionThe researchers evaluated MemRL against several baselines on four diverse industry benchmarks: BigCodeBench (code generation), ALFWorld (embodied navigation), Lifelong Agent Bench (OS and database interaction), and Humanity&#x27;s Last Exam (complex multidisciplinary reasoning). The results showed that MemRL consistently outperformed baselines in both runtime learning (improving during the session) and transfer learning (generalizing to unseen tasks).The advantages of this value-aware retrieval mechanism were most pronounced in exploration-heavy environments like ALFWorld. In this benchmark, which requires agents to navigate and interact with a simulated household environment, MemRL achieved a relative improvement of approximately 56% over MemP, another agentic memory framework. The researchers found that the reinforcement learning component effectively encouraged the agent to explore and discover solutions for complex tasks that similarity-based retrieval methods often failed to solve.When the memory bank was frozen and tested on held-out sets to measure generalization, MemRL achieved the highest accuracy across benchmarks. For example, on the Lifelong Agent Bench, it improved significantly upon the standard RAG baseline on OS tasks. This indicates that the system does not merely memorize training data but effectively filters out low-value memories to retain high-utility experiences that generalize to new situations.The broader picture for self-evolving agentsMemRL fits within a growing body of research focused on Memory-Based Markov Decision Processes (M-MDP), a formulation that frames memory retrieval as an active decision-making step rather than a passive search function. By treating retrieval as an action that can be optimized via reinforcement learning, frameworks like MemRL and similar approaches such as Memento are paving the way for more autonomous systems. For enterprise AI, this shift is significant. It suggests a future where agents can be deployed with a general-purpose LLM and then rapidly adapt to specific company workflows, proprietary databases, and unique problem sets through interaction alone. The key shift we’re seeing is frameworks that are treating applications as dynamic environments that they can learn from.These emerging capabilities will allow organizations to maintain consistent, high-performance agents that evolve alongside their business needs, solving the problem of stale models without incurring the prohibitive costs of constant retraining.It marks a transition in how we value data. \"In a future where static data is about to be exhausted, the interaction experience generated by each intelligent agent during its lifespan will become the new fuel,\" Wen said.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/40SgVNw3VJp5vnnAeHNxFi/d5086bdc81a54e45d780d47f5cd2090d/self-evolving_agent.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/best-fitness-trackers-133053484.html",
          "published_at": "Thu, 22 Jan 2026 10:00:35 +0000",
          "title": "The best fitness trackers for 2026",
          "standfirst": "If you're looking to get fit, sleep better or just keep a closer eye on your health, a fitness wearable is a great place to start. Whether you're into intense workouts or just want to hit your step goal each day, the best fitness trackers available today can offer loads of helpful features, from sleep tracking and resting heart rate monitoring to built-in GPS and stress tracking. Some are even subtle enough to wear 24/7, like smart rings, while others double as stylish smartwatches.There are great options out there for beginners as well as more advanced users, and the variety of features means there’s something for every lifestyle and budget. In this guide, we’ll walk you through the best fitness trackers you can buy right now, and explain who each one is best suited for. Best fitness trackers for 2026 What do fitness trackers do best? The answer seems simple: Fitness wearables are best at monitoring exercise, be it a 10-minute walk around the block or that half marathon you’ve been diligently training for. Obviously, smartwatches can help you reach your fitness goals too, but there are some areas where fitness bands and smart rings have proven to be the best buy: focus, design, better battery life, durability and price. When I say “focus,” I’m alluding to the fact that fitness trackers are made to track activity well; anything else is extra. They often don’t have the bells and whistles that smartwatches do, which could distract from their advanced health tracking abilities — things like all-day resting heart rate monitoring, stress tracking, and even detailed sleep tracker insights. They also tend to have fewer sensors and internal components, which keeps them smaller and lighter. Fitness trackers are also a better option for those who just want a less conspicuous gadget on their wrists all day. Battery life tends to be better on fitness trackers, too. While most smartwatches last one to two days on a single charge, fitness bands offer between five and seven days of battery life — and that’s with all-day and all-night use even with sleep tracking features enabled. Many fitness trackers also slot nicely into your existing ecosystem, syncing seamlessly with your smartphone, other fitness apps and cloud storage to keep all your data in one place. When it comes to price point, there’s no competition. Most worthwhile smartwatches start at $175 to $200, but you can get a solid smart band starting at $70. That makes them a great entry point for beginners who want to track their progress without committing to a full smartwatch. Yes, more expensive bands and smart rings exist (and we recommend a few here), but you’ll find more options under $150 in the fitness tracker space than in the smartwatch space. When to get a smartwatch instead If you need a bit more from your wearable and don’t want to be limited to a fitness or activity tracker, a smartwatch may be the best buy for you. There are things like on-watch apps, alerts and even more robust fitness features that smartwatches have and the best fitness trackers don’t. You can use one to control smart home appliances, set timers and reminders, check weather reports and more. Some smartwatches let you choose which apps you want to receive alerts from, and the options go beyond just call and text notifications. Just make sure your smartwatch is compatible with your Android or iPhone, however, before purchasing, as not all of them work with both operating systems. But the extra fitness features are arguably the most important thing to think about when deciding between a fitness tracker and a smartwatch. The latter devices tend to be larger, giving them more space for things like GPS, barometers, onboard music storage and more. While you can find built-in GPS on select fitness trackers, it’s not common. If you’re someone who’s seriously training — say for a race or an endurance challenge — a dedicated running watch may be worth considering. These often provide more in-depth cardio analytics, recovery insights, and real-time pace data that go beyond what standard trackers can deliver. Other fitness trackers we've tested Fitbit Inspire 3 The Fitbit Inspire 3 strips out all the luxury features from the Charge 6 and keeps only the essential tracking features. You won’t get built-in GPS tracking or Fitbit Pay or Spotify control but you do get solid activity tracking, automatic workout detection, smartphone alerts and plenty more. The updated version has a sleeker design and includes a color touch display and connected GPS, the latter of which lets you track pace and distance while you run or bike outside while you have your phone with you. When compared to the Charge 6, the Inspire 3 is more fashionable, too. Its interchangeable bands let you switch up the look and feel of your tracker whenever you want, and it’s slim enough to blend in with other jewelry you might be wearing. We were also impressed by its multi-day battery life: Fitbit promises up to 10 days on a single charge, and that checked out for us. After four days of round-the-clock use, the Inspire 3 still had 66 percent battery left to go. Fitness tracker FAQs How long do fitness tracker batteries last? The battery life of fitness trackers can vary depending on the model and its features. On average, most fitness trackers last between five to seven days on a single charge. Basic models with limited features could stretch up to 10 days or more. However, more advanced trackers with features like continuous heart rate monitoring, GPS, or always-on displays may need recharging after one to three days. If you're using GPS or streaming music through your fitness tracker, you'll find that this drains the battery faster. By using these features less, or turning them off, you'll extend battery life. This article originally appeared on Engadget at https://www.engadget.com/wearables/best-fitness-trackers-133053484.html?src=rss",
          "content": "If you're looking to get fit, sleep better or just keep a closer eye on your health, a fitness wearable is a great place to start. Whether you're into intense workouts or just want to hit your step goal each day, the best fitness trackers available today can offer loads of helpful features, from sleep tracking and resting heart rate monitoring to built-in GPS and stress tracking. Some are even subtle enough to wear 24/7, like smart rings, while others double as stylish smartwatches.There are great options out there for beginners as well as more advanced users, and the variety of features means there’s something for every lifestyle and budget. In this guide, we’ll walk you through the best fitness trackers you can buy right now, and explain who each one is best suited for. Best fitness trackers for 2026 What do fitness trackers do best? The answer seems simple: Fitness wearables are best at monitoring exercise, be it a 10-minute walk around the block or that half marathon you’ve been diligently training for. Obviously, smartwatches can help you reach your fitness goals too, but there are some areas where fitness bands and smart rings have proven to be the best buy: focus, design, better battery life, durability and price. When I say “focus,” I’m alluding to the fact that fitness trackers are made to track activity well; anything else is extra. They often don’t have the bells and whistles that smartwatches do, which could distract from their advanced health tracking abilities — things like all-day resting heart rate monitoring, stress tracking, and even detailed sleep tracker insights. They also tend to have fewer sensors and internal components, which keeps them smaller and lighter. Fitness trackers are also a better option for those who just want a less conspicuous gadget on their wrists all day. Battery life tends to be better on fitness trackers, too. While most smartwatches last one to two days on a single charge, fitness bands offer between five and seven days of battery life — and that’s with all-day and all-night use even with sleep tracking features enabled. Many fitness trackers also slot nicely into your existing ecosystem, syncing seamlessly with your smartphone, other fitness apps and cloud storage to keep all your data in one place. When it comes to price point, there’s no competition. Most worthwhile smartwatches start at $175 to $200, but you can get a solid smart band starting at $70. That makes them a great entry point for beginners who want to track their progress without committing to a full smartwatch. Yes, more expensive bands and smart rings exist (and we recommend a few here), but you’ll find more options under $150 in the fitness tracker space than in the smartwatch space. When to get a smartwatch instead If you need a bit more from your wearable and don’t want to be limited to a fitness or activity tracker, a smartwatch may be the best buy for you. There are things like on-watch apps, alerts and even more robust fitness features that smartwatches have and the best fitness trackers don’t. You can use one to control smart home appliances, set timers and reminders, check weather reports and more. Some smartwatches let you choose which apps you want to receive alerts from, and the options go beyond just call and text notifications. Just make sure your smartwatch is compatible with your Android or iPhone, however, before purchasing, as not all of them work with both operating systems. But the extra fitness features are arguably the most important thing to think about when deciding between a fitness tracker and a smartwatch. The latter devices tend to be larger, giving them more space for things like GPS, barometers, onboard music storage and more. While you can find built-in GPS on select fitness trackers, it’s not common. If you’re someone who’s seriously training — say for a race or an endurance challenge — a dedicated running watch may be worth considering. These often provide more in-depth cardio analytics, recovery insights, and real-time pace data that go beyond what standard trackers can deliver. Other fitness trackers we've tested Fitbit Inspire 3 The Fitbit Inspire 3 strips out all the luxury features from the Charge 6 and keeps only the essential tracking features. You won’t get built-in GPS tracking or Fitbit Pay or Spotify control but you do get solid activity tracking, automatic workout detection, smartphone alerts and plenty more. The updated version has a sleeker design and includes a color touch display and connected GPS, the latter of which lets you track pace and distance while you run or bike outside while you have your phone with you. When compared to the Charge 6, the Inspire 3 is more fashionable, too. Its interchangeable bands let you switch up the look and feel of your tracker whenever you want, and it’s slim enough to blend in with other jewelry you might be wearing. We were also impressed by its multi-day battery life: Fitbit promises up to 10 days on a single charge, and that checked out for us. After four days of round-the-clock use, the Inspire 3 still had 66 percent battery left to go. Fitness tracker FAQs How long do fitness tracker batteries last? The battery life of fitness trackers can vary depending on the model and its features. On average, most fitness trackers last between five to seven days on a single charge. Basic models with limited features could stretch up to 10 days or more. However, more advanced trackers with features like continuous heart rate monitoring, GPS, or always-on displays may need recharging after one to three days. If you're using GPS or streaming music through your fitness tracker, you'll find that this drains the battery faster. By using these features less, or turning them off, you'll extend battery life. This article originally appeared on Engadget at https://www.engadget.com/wearables/best-fitness-trackers-133053484.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/best-live-tv-streaming-service-133000410.html",
          "published_at": "Thu, 22 Jan 2026 08:00:37 +0000",
          "title": "The best live TV streaming services to cut cable in 2026",
          "standfirst": "Sports fans who want to catch every last game and news junkies who want to watch network news as it unfolds have two main options: cable or a live TV streaming service. Cable or satellite service often requires extra equipment and convoluted contracts. Live TV streaming services only require an internet connection and a smart TV. These plans used to be cheaper and more user-friendly, too, but price hikes, media consolidation and contract disputes are starting to change the value a bit. We tested out all the major players to compare what you get and help you make sense of the options out there. Here are the best live TV streaming services, according to our testing.Editor’s note: YouTube TV announced in December it will start offering genre-specific plans in early 2026. We still don’t have word on the pricing or specifics, but will update this guide when we do. The blackout of NBC channels on Fubo’s service continues as negotiations drag on. That means fans hoping to catch the Super Bowl on Fubo will need to look elsewhere. Best live TV streaming services for 2026 How to watch the 2026 Super Bowl with a streaming service This year, the Super Bowl will take place on Sunday, February 8, 2026 at Levi's Stadium in Santa Clara, California. NBC has the rights to air the broadcast, which means you can watch it with a live TV streaming subscription to YouTube TV, Hulu + Live TV or DirecTV. Sling Blue plans include NBC in certain markets only. NBC channels are dark on Fubo as the company and NBC are still in negotiations. The traditional streaming service Peacock, which is owned by NBC, will also air the game. Those plans start at just $8 per month, which is nearly the cheapest way to watch. However, if you have a digital antenna, you can pick up the game’s broadcast signal from your local NBC affiliate for free. How can I stream NFL games for free? If you have a digital antenna hooked up to your TV, you can grab games that are broadcast over the airways for your region by tuning into your local CBS, Fox, NBC and ABC stations. You can buy a digital antenna for between $20 and $60. Alternatively, you can check out your local sports bar and watch the game for the price of a soda and maybe some nachos. As it turns out, bars and restaurants that provide those games to customers have to pay a ton of cash to do so, so you may as well take advantage of the opportunity. Will Peacock stream the Super Bowl? Yes. Peacock is owned by NBC Universal, which holds the rights to stream the big game this year. The Super Bowl will stream on both Peacock (all tiers) and local NBC stations (Premium Plus tier). The cheapest tier of Peacock's service starts at $8 per month. Can you stream live football on YouTube? September 5, 2025 marked the first time YouTube was an official live NFL broadcaster when it aired the Friday night, week-one game of the 2025 NFL season from São Paulo, Brazil. It pit the Los Angeles Chargers against the Kansas City Chiefs (LA won 21-27) and aired worldwide on YouTube for free as well as for subscribers to YouTube TV. There are no other plans for YouTube to air live NFL games for the 2025-6 season for free. Best free live TV streaming services for 2026 There are loads of ways to get free TV these days. To start, many standard streaming apps have added live components to their lineups — even Netflix. Peacock Premium Plus subscriptions include regional NBC stations. Paramount+ Premium subscribers can watch on-air CBS programming. The new Fox One service includes multiple live Fox stations. True, if you’re already paying for a service it’s not technically “free” but at least the live content isn’t extra. The smart TV operating system (OS) you use likely provides free live content too: Amazon’s Fire TV, Google/Android TV, Roku’s built-in Roku Channel and Samsung’s TV Plus all have hundreds of live channels and original programming. Some of the paid services we recommend above have a free version — namely Sling Freestream, Fubo Free (available after you cancel) and DirecTV’s MyFree. But if you’re looking for more, here are the best free ad-supported TV (FAST) apps with live TV that we tried: What to look for in a live TV streaming service How to stream live TV Streaming live TV is a lot like using Netflix. You get access through apps on your phone, tablet, smart TV or streaming device and the signal arrives over the internet. A faster and more stable connection tends to give you a better experience. Most live TV apps require you to sign up and pay via a web browser. After that, you can activate the app on all of your devices. Monthly Price When I started testing these cord-cutting alternatives, I was struck by the price difference between live TV and a standard video streaming app. Where the latter cost between $5 and $20 per month, most live TV services hit the $80 mark and can go higher than $200 with additional perks, channel packages and premium extras. The higher starting price is mostly due to the cost of providing multiple networks — particularly sports and local stations. And, in the past year or so, every service has raised base plan prices. Local channels Only two of the services I tried don’t include full local channel coverage for subscribers and one of those makes no effort to carry sports at all. That would be Philo and, as you might guess, it’s the cheapest. The next most affordable option, Sling, only carries three local stations — and only in larger markets — but it still manages to include some of the top sports channels. When you sign up with any provider that handles local TV, you’ll enter your zip code, ensuring you get your area’s broadcast affiliates for ABC, CBS, FOX and NBC. Of course, you can also get those stations for free. Nearly all modern television sets support a radio frequency (RF) connection, also known as the coaxial port, which means if you buy an HD antenna, you’ll receive locally broadcast stations like ABC, CBS, PBS, FOX and NBC. And since the signal is digital, reception is much improved over the staticky rabbit-ears era. But local channel access is another area where traditional streaming services, like Netflix, are bleeding into broadcast territory. For example, you can watch your local NBC station with a Peacock subscription and you can tune into your area’s CBS station through your Paramount+ subscription. Netflix is even getting into the mix with a recently announced deal with one of France’s broadcast companies, TF1. The streaming service will now air TF1's live TV channels and on-demand content inside the Netflix app. No word if the concept will expand to other regions, but it’s an interesting move to anyone interested in the future of streaming. Live sports coverage One reality that spun my head was the sheer number and iterations of sports networks in existence. Trying to figure out which network will carry the match-up you want to see can be tricky. I found that Google makes it a little easier for sports fans by listing out upcoming games (just swap in NBA, NFL, MLB, NHL and so on in the search bar). When you click an event, the “TV & streaming” button will tell you which network is covering it. That just leaves figuring out if your chosen service carries the RSNs (regional sports networks) you want. Unfortunately, even with add-ons and extra packages, some providers simply don’t have certain channels in their lineups. It would take a lawyer to understand the ins and outs of streaming rights negotiations, and networks leave and return to live TV carriers all the time. That said, most major sporting events in the US are covered by ESPN, Fox Sports, TNT, USA and local affiliates. I should also point out that traditional streaming services have started adding live sports to their lineups. Peacock carries live Premier League matches, Sunday Night Football games and aired the 2024 Olympic Games from Paris. Thursday Night Football as well as NBA and WNBA games are on Amazon Prime and Christmas Day Football airs on Netflix. HBO Max (formerly, er, HBO Max) now airs select, regular season games from the NHL, MLB, NCAA and NBA with a $10-per-month add-on. You can watch MLS games with an add-on through the Apple TV app, and Apple TV+ (now just called Apple TV) includes some MLB games. Roku users can watch the just-added free sports channel and those who subscribe to Paramount Plus can see many of the matches aired on CBS Sports, including live NFL games. In 2025, January's Super Bowl was live-streamed for free on Tubi. While all of these alternatives may not cover as much ground as live TV streamers, they could end up being cheaper avenues to the sports you want. And if sports is all you’re after, there are sports-only plans that are a touch cheaper, too. The promised sports streaming service from ESPN, Fox and Warner Bros. called Venu was cancelled early this year. But on August 21, ESPN launched its own streaming service that includes all ESPN channels and costs $30 per month. Fubo Sports is $56 monthly and includes local broadcast stations from ABC, CBS and FOX plus a slew of sports networks (CBS Sport and FS1 among them) as well as all networks included with ESPN Unlimited. Fox launched its own standalone service in August as well and it includes Fox Sports and all other Fox properties (News, Business, Weather) for $20 monthly. DirecTV also has a $70-per-month, sports-only streaming package called MySports and Comcast has a sports and news bundle for that same price (as long as you're an Xfinity customer with auto-pay, otherwise it's more expensive). Traditional cable networks Dozens of linear programming networks were once only available with cable TV, like Bravo, BET, Food Network, HGTV, CNN, Lifetime, SYFY and MTV. If you only subscribe to, say, Netflix or Apple TV+, you won’t have access to those. But as with sports, standard streamers are starting to incorporate this content into their offerings. After the Warner Bros. merger, Max incorporated some content from HGTV, Discovery and TLC. Peacock has Bravo and Hallmark shows, and Paramount+ has material from Nickelodeon, MTV and Comedy Central. Other entertainment channels like AMC+ have stand-alone apps. The Discovery+ app gives you 15 channels ad-free for $10 per month (or with ads for $6 monthly). And a service called Frndly TV starts at a mere $7 per month and streams A&E, Lifetime, Game Show Network, Outdoor Channel and about 35 others. Of course, most live TV streaming options will deliver more sizable lists of cable networks, but just note that you may already be paying for some of them — and if all you need is a certain channel, you could get it cheaper by subscribing directly. On-demand streaming Most live TV subscriptions include access to a selection of video-on-demand (VOD) content, like you would get with a traditional streaming service. Much of this content is made up of the movies and TV series that have recently aired on your subscribed networks. This typically doesn’t cover live events and news programming, but I was able to watch specific episodes of ongoing shows like Top Chef or BET’s Diarra from Detroit. Just search the on-demand library for the program, pick an episode and hit play. Partnerships, like Hulu’s relationship with Disney, and add-ons, such as bundling Max with your YouTube TV subscription or Starz with your Sling plan, will let you watch even larger libraries of on-demand content. But again, if VOD is all you’re after, paying for those networks directly instead of through a live TV plan will be far cheaper. Digital video recordings (DVR) limits Every option I tried offers some cloud DVR storage without needing a separate physical device. You’ll either get unlimited storage for recordings that expires after nine months or a year, or you’ll get a set number of hours (between 50 and 1,000) that you can keep indefinitely. Typically, all you need to do is designate what ongoing TV series you want to record and the DVR component will do all the hard work of saving subsequent episodes for you to watch later. You can do the same thing with sports events. Aside from being able to watch whenever it’s most convenient, you can also fast-forward through commercials in recorded content. In contrast, you can’t skip them on live TV or VOD. Simultaneous streams and profiles per account Each plan gives you a certain number of simultaneous streams, aka how many screens can play content at the same time. And while most providers will let you travel with your subscription, there are usually location restrictions that require you to sign in from your home IP address periodically. Stream allowances range from one at a time to unlimited screens (or as many as your ISP’s bandwidth can handle). Some plans require add-ons to get more screens. Most services also let you set up a few profiles so I was able to give different people in my family the ability to build their own watch histories and libraries, set their favorite channels and get individual recommendations. Picture-in-picture mode and multiview Picture-in-picture (PiP) usually refers to shrinking a video window on a mobile device or computer browser so you can watch it while using other apps. Sling, YouTube TV, FuboTV, Philo, DirecTV Stream and Hulu + Live TV all have PiP modes on computers and mobile devices. Another feature, multiview, lets you view multiple (usually four) sports matches or other live content at once on your TV screen. YouTube TV, FuboTV and now DirecTV all let you do this. With YouTube TV, you can select up to four views from a few preset selection of streams. FuboTV offers the same feature, but only if you're using an Apple TV or Roku streaming device. DirecTV lets you do so through “mixes” which include sports, news, business and kids variants with a set four channels in each mix. 4K live streams Right now, just FuboTV, YouTube TV and DirecTV Stream offer 4K live streams — but with caveats. YouTube TV requires a $20-per-month add-on, after which you’ll only be able to watch certain live content in 4K. DirecTV Stream has three channels that show live 4K content — one with shows and original series, and two with occasional sporting events. You don’t have to pay extra for these but you do need to have either DirecTV’s Gemini receiver, or a device from Fire TV, Apple TV or Roku. You’ll need those same streaming devices to watch the select 4K programming on Sling as well. FuboTV shows certain live events in 4K but access is limited to the Elite and Premier packages, not the base-level Pro plan. Of course, watching any 4K content also requires equipment that can handle it: a 4K smart TV or 4K streaming device paired with a cord and screen that can handle 4K resolution. Tiers, packages and add-ons Comparing price-to-offering ratios is a task for a spreadsheet. I… made three. The base plans range from $28 to $85 per month. From there, you can add packages, which are usually groups of live TV channels bundled by themes like news, sports, entertainment or international content. Premium VOD extras like Max, AMC+ and Starz are also available. Add-ons cost an extra $5 to $20 each per month and simply show up in the guide where you find the rest of your live TV. This is where streaming can quickly get expensive, pushing an $80 subscription to $200 monthly, depending on what you choose. How to stream live TV for free I also downloaded and tried out a few apps that offer free ad-supported TV (FAST) including Freevee, Tubi, PlutoTV and Sling Freestream. These let you drop in and watch a more limited selection of live networks at zero cost. Most don’t even require an email address, let alone a credit card. And if you have a Roku device, an Amazon Fire TV or Stick, a Samsung TV, a Chromecast device or a Google TV, you already have access to hundreds of live channels via the Roku Channel, the live tab in Fire TV, through the Samsung TV Plus app or through Google TV. How we tested live TV streaming services When I begin testing for a guide, I research the most popular and well-reviewed players in the category and narrow down which are worth trying. For the paid plans, just six services dominate so I tried them all. There are considerably more free live TV contenders so I tested the four most popular. After getting accounts set up using my laptop, I downloaded the apps on a Samsung smart TV running the latest version of Tizen OS. I counted the local stations and regional sports coverage, and noted how many of the top cable networks were available. I then weighed the prices, base packages and available add-ons. I then looked at how the programming was organized in each app’s UI and judged how easy everything was to navigate, from the top navigation to the settings. To test the search function, I searched for the same few TV shows on BET, Food Network, HGTV and Comedy Central, since all six providers carry those channels. I noted how helpful the searches were and how quickly they got me to season 6, episode 13 of Home Town. I used DVR to record entire series and single movies and watched VOD shows, making sure to test the pause and scan functions. On each service with sports, I searched for the same four upcoming NHL, NBA, MLS and NCAA basketball matches and used the record option to save the games and play them back a day or two later. Finally, I noted any extra perks or irritating quirks. All live TV streaming services we’ve tested: Philo Sling YouTube TV Hulu + Live TV DirecTV Stream FuboTV Freevee Tubi PlutoTV Sling Freestream Plex Live TV Streaming FAQs What is live streaming? Streaming simply refers to video content that is delivered to your screen over the internet. Live streaming can be split into two categories: linear programming and simultaneous transmission. That first one is similar to what you get with cable or broadcast TV, with channels that play a constant flow of movies and shows (sort of what TV looked like before Netflix). Simultaneous streaming lets you watch live events (like a basketball game) or a program (like the evening news) as they happen. What is the difference between streaming and live streaming? Standard streaming, the most popular example being Netflix, lets you pick what you want to watch from a menu of choices. It’s also referred to as “video on demand.” Live streaming refers to sports and news events that you can stream as they happen in real time. It also refers to channels that show a continuous, linear flow of programming. What streaming service is best for live TV? FuboTV does the best job of letting you organize live channels to help you find just what you want to watch. The interface is uncluttered and when you search for something, the UI clearly tells you whether something is live now or on-demand. YouTube TV also does a good job making that info clear. Both have just over 100 live channels on offer. What is the most cost effective TV streaming service? Free TV streaming services like PlutoTV, Plex, Tubi and FreeVee show plenty of ad-supported TV shows and movies without charging you anything. Of course, they won’t have the same channels or content that more premium subscriptions have. Ultimately it depends on what you want to watch and finding the service that can supply that to you in the most streamlined form so you’re not paying for stuff you don’t need. Is it cheaper to have cable or streaming? A basic cable package used to be more expensive than the base-level live TV streaming service. But now that nearly all major providers have raised their prices to over $75 per month, that’s no longer the case. And with add-ons and other premiums, you can easily pay over $200 a month for either cable or a live TV streaming service. But those who want to cut the cord will appreciate that streaming services don't have contracts. What streaming service has all the TV channels? No service that we tested had every available channel. Hulu + Live TV and DirecTV Stream carry the the highest number of the top rated channels, according to Neilsen. Hulu’s service also gets you Disney+ fare, which you can’t get elsewhere. FuboTV has the most sports channels and YouTube TV gives you the widest selection of add-ons. What is the most popular live TV streaming platform? YouTube TV has the most paying customers. According to 2024's letter from the CEO, the service has over eight million subscribers. Disney’s 2024 third quarter earnings put the Hulu + Live TV viewer count at 4.6 million. Sling’s customer count dipped from two million to about 1.9 million in 2024 and FuboTV grew its subscriber list to 1.6 million. How safe are free streaming services and websites? You may have heard certain sites that provide free content can be dangerous, leading to stolen info and/or exposing you to malware. That’s likely in reference to certain peer-to-peer (P2P) networks and file-sharing sites that let people download free movies and series — which can come bundled with malicious code. But if you’re talking about the free ad-supported streaming television (FAST) services listed here, from providers like PlutoTV, Tubi and Plex, they are just as safe as any other streaming service. Since you sometimes don’t even have to provide your email address or credit card info, they can even be more anonymous for cord cutters than apps that require login credentials. Recent updates December 2025: Included Fubo's channel and price adjustments. Confirmed pricing for all servicesThis article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/best-live-tv-streaming-service-133000410.html?src=rss",
          "content": "Sports fans who want to catch every last game and news junkies who want to watch network news as it unfolds have two main options: cable or a live TV streaming service. Cable or satellite service often requires extra equipment and convoluted contracts. Live TV streaming services only require an internet connection and a smart TV. These plans used to be cheaper and more user-friendly, too, but price hikes, media consolidation and contract disputes are starting to change the value a bit. We tested out all the major players to compare what you get and help you make sense of the options out there. Here are the best live TV streaming services, according to our testing.Editor’s note: YouTube TV announced in December it will start offering genre-specific plans in early 2026. We still don’t have word on the pricing or specifics, but will update this guide when we do. The blackout of NBC channels on Fubo’s service continues as negotiations drag on. That means fans hoping to catch the Super Bowl on Fubo will need to look elsewhere. Best live TV streaming services for 2026 How to watch the 2026 Super Bowl with a streaming service This year, the Super Bowl will take place on Sunday, February 8, 2026 at Levi's Stadium in Santa Clara, California. NBC has the rights to air the broadcast, which means you can watch it with a live TV streaming subscription to YouTube TV, Hulu + Live TV or DirecTV. Sling Blue plans include NBC in certain markets only. NBC channels are dark on Fubo as the company and NBC are still in negotiations. The traditional streaming service Peacock, which is owned by NBC, will also air the game. Those plans start at just $8 per month, which is nearly the cheapest way to watch. However, if you have a digital antenna, you can pick up the game’s broadcast signal from your local NBC affiliate for free. How can I stream NFL games for free? If you have a digital antenna hooked up to your TV, you can grab games that are broadcast over the airways for your region by tuning into your local CBS, Fox, NBC and ABC stations. You can buy a digital antenna for between $20 and $60. Alternatively, you can check out your local sports bar and watch the game for the price of a soda and maybe some nachos. As it turns out, bars and restaurants that provide those games to customers have to pay a ton of cash to do so, so you may as well take advantage of the opportunity. Will Peacock stream the Super Bowl? Yes. Peacock is owned by NBC Universal, which holds the rights to stream the big game this year. The Super Bowl will stream on both Peacock (all tiers) and local NBC stations (Premium Plus tier). The cheapest tier of Peacock's service starts at $8 per month. Can you stream live football on YouTube? September 5, 2025 marked the first time YouTube was an official live NFL broadcaster when it aired the Friday night, week-one game of the 2025 NFL season from São Paulo, Brazil. It pit the Los Angeles Chargers against the Kansas City Chiefs (LA won 21-27) and aired worldwide on YouTube for free as well as for subscribers to YouTube TV. There are no other plans for YouTube to air live NFL games for the 2025-6 season for free. Best free live TV streaming services for 2026 There are loads of ways to get free TV these days. To start, many standard streaming apps have added live components to their lineups — even Netflix. Peacock Premium Plus subscriptions include regional NBC stations. Paramount+ Premium subscribers can watch on-air CBS programming. The new Fox One service includes multiple live Fox stations. True, if you’re already paying for a service it’s not technically “free” but at least the live content isn’t extra. The smart TV operating system (OS) you use likely provides free live content too: Amazon’s Fire TV, Google/Android TV, Roku’s built-in Roku Channel and Samsung’s TV Plus all have hundreds of live channels and original programming. Some of the paid services we recommend above have a free version — namely Sling Freestream, Fubo Free (available after you cancel) and DirecTV’s MyFree. But if you’re looking for more, here are the best free ad-supported TV (FAST) apps with live TV that we tried: What to look for in a live TV streaming service How to stream live TV Streaming live TV is a lot like using Netflix. You get access through apps on your phone, tablet, smart TV or streaming device and the signal arrives over the internet. A faster and more stable connection tends to give you a better experience. Most live TV apps require you to sign up and pay via a web browser. After that, you can activate the app on all of your devices. Monthly Price When I started testing these cord-cutting alternatives, I was struck by the price difference between live TV and a standard video streaming app. Where the latter cost between $5 and $20 per month, most live TV services hit the $80 mark and can go higher than $200 with additional perks, channel packages and premium extras. The higher starting price is mostly due to the cost of providing multiple networks — particularly sports and local stations. And, in the past year or so, every service has raised base plan prices. Local channels Only two of the services I tried don’t include full local channel coverage for subscribers and one of those makes no effort to carry sports at all. That would be Philo and, as you might guess, it’s the cheapest. The next most affordable option, Sling, only carries three local stations — and only in larger markets — but it still manages to include some of the top sports channels. When you sign up with any provider that handles local TV, you’ll enter your zip code, ensuring you get your area’s broadcast affiliates for ABC, CBS, FOX and NBC. Of course, you can also get those stations for free. Nearly all modern television sets support a radio frequency (RF) connection, also known as the coaxial port, which means if you buy an HD antenna, you’ll receive locally broadcast stations like ABC, CBS, PBS, FOX and NBC. And since the signal is digital, reception is much improved over the staticky rabbit-ears era. But local channel access is another area where traditional streaming services, like Netflix, are bleeding into broadcast territory. For example, you can watch your local NBC station with a Peacock subscription and you can tune into your area’s CBS station through your Paramount+ subscription. Netflix is even getting into the mix with a recently announced deal with one of France’s broadcast companies, TF1. The streaming service will now air TF1's live TV channels and on-demand content inside the Netflix app. No word if the concept will expand to other regions, but it’s an interesting move to anyone interested in the future of streaming. Live sports coverage One reality that spun my head was the sheer number and iterations of sports networks in existence. Trying to figure out which network will carry the match-up you want to see can be tricky. I found that Google makes it a little easier for sports fans by listing out upcoming games (just swap in NBA, NFL, MLB, NHL and so on in the search bar). When you click an event, the “TV & streaming” button will tell you which network is covering it. That just leaves figuring out if your chosen service carries the RSNs (regional sports networks) you want. Unfortunately, even with add-ons and extra packages, some providers simply don’t have certain channels in their lineups. It would take a lawyer to understand the ins and outs of streaming rights negotiations, and networks leave and return to live TV carriers all the time. That said, most major sporting events in the US are covered by ESPN, Fox Sports, TNT, USA and local affiliates. I should also point out that traditional streaming services have started adding live sports to their lineups. Peacock carries live Premier League matches, Sunday Night Football games and aired the 2024 Olympic Games from Paris. Thursday Night Football as well as NBA and WNBA games are on Amazon Prime and Christmas Day Football airs on Netflix. HBO Max (formerly, er, HBO Max) now airs select, regular season games from the NHL, MLB, NCAA and NBA with a $10-per-month add-on. You can watch MLS games with an add-on through the Apple TV app, and Apple TV+ (now just called Apple TV) includes some MLB games. Roku users can watch the just-added free sports channel and those who subscribe to Paramount Plus can see many of the matches aired on CBS Sports, including live NFL games. In 2025, January's Super Bowl was live-streamed for free on Tubi. While all of these alternatives may not cover as much ground as live TV streamers, they could end up being cheaper avenues to the sports you want. And if sports is all you’re after, there are sports-only plans that are a touch cheaper, too. The promised sports streaming service from ESPN, Fox and Warner Bros. called Venu was cancelled early this year. But on August 21, ESPN launched its own streaming service that includes all ESPN channels and costs $30 per month. Fubo Sports is $56 monthly and includes local broadcast stations from ABC, CBS and FOX plus a slew of sports networks (CBS Sport and FS1 among them) as well as all networks included with ESPN Unlimited. Fox launched its own standalone service in August as well and it includes Fox Sports and all other Fox properties (News, Business, Weather) for $20 monthly. DirecTV also has a $70-per-month, sports-only streaming package called MySports and Comcast has a sports and news bundle for that same price (as long as you're an Xfinity customer with auto-pay, otherwise it's more expensive). Traditional cable networks Dozens of linear programming networks were once only available with cable TV, like Bravo, BET, Food Network, HGTV, CNN, Lifetime, SYFY and MTV. If you only subscribe to, say, Netflix or Apple TV+, you won’t have access to those. But as with sports, standard streamers are starting to incorporate this content into their offerings. After the Warner Bros. merger, Max incorporated some content from HGTV, Discovery and TLC. Peacock has Bravo and Hallmark shows, and Paramount+ has material from Nickelodeon, MTV and Comedy Central. Other entertainment channels like AMC+ have stand-alone apps. The Discovery+ app gives you 15 channels ad-free for $10 per month (or with ads for $6 monthly). And a service called Frndly TV starts at a mere $7 per month and streams A&E, Lifetime, Game Show Network, Outdoor Channel and about 35 others. Of course, most live TV streaming options will deliver more sizable lists of cable networks, but just note that you may already be paying for some of them — and if all you need is a certain channel, you could get it cheaper by subscribing directly. On-demand streaming Most live TV subscriptions include access to a selection of video-on-demand (VOD) content, like you would get with a traditional streaming service. Much of this content is made up of the movies and TV series that have recently aired on your subscribed networks. This typically doesn’t cover live events and news programming, but I was able to watch specific episodes of ongoing shows like Top Chef or BET’s Diarra from Detroit. Just search the on-demand library for the program, pick an episode and hit play. Partnerships, like Hulu’s relationship with Disney, and add-ons, such as bundling Max with your YouTube TV subscription or Starz with your Sling plan, will let you watch even larger libraries of on-demand content. But again, if VOD is all you’re after, paying for those networks directly instead of through a live TV plan will be far cheaper. Digital video recordings (DVR) limits Every option I tried offers some cloud DVR storage without needing a separate physical device. You’ll either get unlimited storage for recordings that expires after nine months or a year, or you’ll get a set number of hours (between 50 and 1,000) that you can keep indefinitely. Typically, all you need to do is designate what ongoing TV series you want to record and the DVR component will do all the hard work of saving subsequent episodes for you to watch later. You can do the same thing with sports events. Aside from being able to watch whenever it’s most convenient, you can also fast-forward through commercials in recorded content. In contrast, you can’t skip them on live TV or VOD. Simultaneous streams and profiles per account Each plan gives you a certain number of simultaneous streams, aka how many screens can play content at the same time. And while most providers will let you travel with your subscription, there are usually location restrictions that require you to sign in from your home IP address periodically. Stream allowances range from one at a time to unlimited screens (or as many as your ISP’s bandwidth can handle). Some plans require add-ons to get more screens. Most services also let you set up a few profiles so I was able to give different people in my family the ability to build their own watch histories and libraries, set their favorite channels and get individual recommendations. Picture-in-picture mode and multiview Picture-in-picture (PiP) usually refers to shrinking a video window on a mobile device or computer browser so you can watch it while using other apps. Sling, YouTube TV, FuboTV, Philo, DirecTV Stream and Hulu + Live TV all have PiP modes on computers and mobile devices. Another feature, multiview, lets you view multiple (usually four) sports matches or other live content at once on your TV screen. YouTube TV, FuboTV and now DirecTV all let you do this. With YouTube TV, you can select up to four views from a few preset selection of streams. FuboTV offers the same feature, but only if you're using an Apple TV or Roku streaming device. DirecTV lets you do so through “mixes” which include sports, news, business and kids variants with a set four channels in each mix. 4K live streams Right now, just FuboTV, YouTube TV and DirecTV Stream offer 4K live streams — but with caveats. YouTube TV requires a $20-per-month add-on, after which you’ll only be able to watch certain live content in 4K. DirecTV Stream has three channels that show live 4K content — one with shows and original series, and two with occasional sporting events. You don’t have to pay extra for these but you do need to have either DirecTV’s Gemini receiver, or a device from Fire TV, Apple TV or Roku. You’ll need those same streaming devices to watch the select 4K programming on Sling as well. FuboTV shows certain live events in 4K but access is limited to the Elite and Premier packages, not the base-level Pro plan. Of course, watching any 4K content also requires equipment that can handle it: a 4K smart TV or 4K streaming device paired with a cord and screen that can handle 4K resolution. Tiers, packages and add-ons Comparing price-to-offering ratios is a task for a spreadsheet. I… made three. The base plans range from $28 to $85 per month. From there, you can add packages, which are usually groups of live TV channels bundled by themes like news, sports, entertainment or international content. Premium VOD extras like Max, AMC+ and Starz are also available. Add-ons cost an extra $5 to $20 each per month and simply show up in the guide where you find the rest of your live TV. This is where streaming can quickly get expensive, pushing an $80 subscription to $200 monthly, depending on what you choose. How to stream live TV for free I also downloaded and tried out a few apps that offer free ad-supported TV (FAST) including Freevee, Tubi, PlutoTV and Sling Freestream. These let you drop in and watch a more limited selection of live networks at zero cost. Most don’t even require an email address, let alone a credit card. And if you have a Roku device, an Amazon Fire TV or Stick, a Samsung TV, a Chromecast device or a Google TV, you already have access to hundreds of live channels via the Roku Channel, the live tab in Fire TV, through the Samsung TV Plus app or through Google TV. How we tested live TV streaming services When I begin testing for a guide, I research the most popular and well-reviewed players in the category and narrow down which are worth trying. For the paid plans, just six services dominate so I tried them all. There are considerably more free live TV contenders so I tested the four most popular. After getting accounts set up using my laptop, I downloaded the apps on a Samsung smart TV running the latest version of Tizen OS. I counted the local stations and regional sports coverage, and noted how many of the top cable networks were available. I then weighed the prices, base packages and available add-ons. I then looked at how the programming was organized in each app’s UI and judged how easy everything was to navigate, from the top navigation to the settings. To test the search function, I searched for the same few TV shows on BET, Food Network, HGTV and Comedy Central, since all six providers carry those channels. I noted how helpful the searches were and how quickly they got me to season 6, episode 13 of Home Town. I used DVR to record entire series and single movies and watched VOD shows, making sure to test the pause and scan functions. On each service with sports, I searched for the same four upcoming NHL, NBA, MLS and NCAA basketball matches and used the record option to save the games and play them back a day or two later. Finally, I noted any extra perks or irritating quirks. All live TV streaming services we’ve tested: Philo Sling YouTube TV Hulu + Live TV DirecTV Stream FuboTV Freevee Tubi PlutoTV Sling Freestream Plex Live TV Streaming FAQs What is live streaming? Streaming simply refers to video content that is delivered to your screen over the internet. Live streaming can be split into two categories: linear programming and simultaneous transmission. That first one is similar to what you get with cable or broadcast TV, with channels that play a constant flow of movies and shows (sort of what TV looked like before Netflix). Simultaneous streaming lets you watch live events (like a basketball game) or a program (like the evening news) as they happen. What is the difference between streaming and live streaming? Standard streaming, the most popular example being Netflix, lets you pick what you want to watch from a menu of choices. It’s also referred to as “video on demand.” Live streaming refers to sports and news events that you can stream as they happen in real time. It also refers to channels that show a continuous, linear flow of programming. What streaming service is best for live TV? FuboTV does the best job of letting you organize live channels to help you find just what you want to watch. The interface is uncluttered and when you search for something, the UI clearly tells you whether something is live now or on-demand. YouTube TV also does a good job making that info clear. Both have just over 100 live channels on offer. What is the most cost effective TV streaming service? Free TV streaming services like PlutoTV, Plex, Tubi and FreeVee show plenty of ad-supported TV shows and movies without charging you anything. Of course, they won’t have the same channels or content that more premium subscriptions have. Ultimately it depends on what you want to watch and finding the service that can supply that to you in the most streamlined form so you’re not paying for stuff you don’t need. Is it cheaper to have cable or streaming? A basic cable package used to be more expensive than the base-level live TV streaming service. But now that nearly all major providers have raised their prices to over $75 per month, that’s no longer the case. And with add-ons and other premiums, you can easily pay over $200 a month for either cable or a live TV streaming service. But those who want to cut the cord will appreciate that streaming services don't have contracts. What streaming service has all the TV channels? No service that we tested had every available channel. Hulu + Live TV and DirecTV Stream carry the the highest number of the top rated channels, according to Neilsen. Hulu’s service also gets you Disney+ fare, which you can’t get elsewhere. FuboTV has the most sports channels and YouTube TV gives you the widest selection of add-ons. What is the most popular live TV streaming platform? YouTube TV has the most paying customers. According to 2024's letter from the CEO, the service has over eight million subscribers. Disney’s 2024 third quarter earnings put the Hulu + Live TV viewer count at 4.6 million. Sling’s customer count dipped from two million to about 1.9 million in 2024 and FuboTV grew its subscriber list to 1.6 million. How safe are free streaming services and websites? You may have heard certain sites that provide free content can be dangerous, leading to stolen info and/or exposing you to malware. That’s likely in reference to certain peer-to-peer (P2P) networks and file-sharing sites that let people download free movies and series — which can come bundled with malicious code. But if you’re talking about the free ad-supported streaming television (FAST) services listed here, from providers like PlutoTV, Tubi and Plex, they are just as safe as any other streaming service. Since you sometimes don’t even have to provide your email address or credit card info, they can even be more anonymous for cord cutters than apps that require login credentials. Recent updates December 2025: Included Fubo's channel and price adjustments. Confirmed pricing for all servicesThis article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/best-live-tv-streaming-service-133000410.html?src=rss",
          "feed_position": 34
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/why-linkedin-says-prompting-was-a-non-starter-and-small-models-was-the",
          "published_at": "Wed, 21 Jan 2026 23:30:00 GMT",
          "title": "Why LinkedIn says prompting was a non-starter — and small models was the breakthrough",
          "standfirst": "LinkedIn is a leader in AI recommender systems, having developed them over the last 15-plus years. But getting to a next-gen recommendation stack for the job-seekers of tomorrow required a whole new technique. The company had to look beyond off-the-shelf models to achieve next-level accuracy, latency, and efficiency.“There was just no way we were gonna be able to do that through prompting,” Erran Berger, VP of product engineering at LinkedIn, says in a new Beyond the Pilot podcast. “We didn&#x27;t even try that for next-gen recommender systems because we realized it was a non-starter.”Instead, his team set to develop a highly detailed product policy document to fine-tune an initially massive 7-billion-parameter model; that was then further distilled into additional teacher and student models optimized to hundreds of millions of parameters. The technique has created a repeatable cookbook now reused across LinkedIn’s AI products. “Adopting this eval process end to end will drive substantial quality improvement of the likes we probably haven&#x27;t seen in years here at LinkedIn,” Berger says. Why multi-teacher distillation was a ‘breakthrough’ for LinkedIn Berger and his team set out to build an LLM that could interpret individual job queries, candidate profiles and job descriptions in real time, and in a way that mirrored LinkedIn’s product policy as accurately as possible. Working with the company&#x27;s product management team, engineers eventually built out a 20-to-30-page document scoring job description and profile pairs “across many dimensions.” “We did many, many iterations on this,” Berger says. That product policy document was then paired with a “golden dataset” comprising thousands of pairs of queries and profiles; the team fed this into ChatGPT during data generation and experimentation, prompting the model over time to learn scoring pairs and eventually generate a much larger synthetic data set to train a 7-billion-parameter teacher model.However, Berger says, it&#x27;s not enough to have an LLM running in production just on product policy. “At the end of the day, it&#x27;s a recommender system, and we need to do some amount of click prediction and personalization.” So, his team used that initial product policy-focused teacher model to develop a second teacher model oriented toward click prediction. Using the two, they further distilled a 1.7 billion parameter model for training purposes. That eventual student model was run through “many, many training runs,” and was optimized “at every point” to minimize quality loss, Berger says. This multi-teacher distillation technique allowed the team to “achieve a lot of affinity” to the original product policy and “land” click prediction, he says. They were also able to “modularize and componentize” the training process for the student.Consider it in the context of a chat agent with two different teacher models: One is training the agent on accuracy in responses, the other on tone and how it should communicate. Those two things are very different, yet critical, objectives, Berger notes. “By now mixing them, you get better outcomes, but also iterate on them independently,” he says. “That was a breakthrough for us.” Changing how teams work togetherBerger says he can’t understate the importance of anchoring on a product policy and an iterative eval process. Getting a “really, really good product policy” requires translating product manager domain expertise into a unified document. Historically, Berger notes, the product management team was laser focused on strategy and user experience, leaving modeling iteration approaches to ML engineers. Now, though, the two teams work together to “dial in” and create an aligned teacher model. “How product managers work with machine learning engineers now is very different from anything we&#x27;ve done previously,” he says. “It’s now a blueprint for basically any AI products we do at LinkedIn.”Watch the full podcast to hear more about: How LinkedIn optimized every step of the R&D process to support velocity, leading to real results with days or hours rather than weeks; Why teams should develop pipelines for plugability and experimentation and try out different models to support flexibility; The continued importance of traditional engineering debugging.You can also listen and subscribe to Beyond the Pilot on Spotify, Apple or wherever you get your podcasts.",
          "content": "LinkedIn is a leader in AI recommender systems, having developed them over the last 15-plus years. But getting to a next-gen recommendation stack for the job-seekers of tomorrow required a whole new technique. The company had to look beyond off-the-shelf models to achieve next-level accuracy, latency, and efficiency.“There was just no way we were gonna be able to do that through prompting,” Erran Berger, VP of product engineering at LinkedIn, says in a new Beyond the Pilot podcast. “We didn&#x27;t even try that for next-gen recommender systems because we realized it was a non-starter.”Instead, his team set to develop a highly detailed product policy document to fine-tune an initially massive 7-billion-parameter model; that was then further distilled into additional teacher and student models optimized to hundreds of millions of parameters. The technique has created a repeatable cookbook now reused across LinkedIn’s AI products. “Adopting this eval process end to end will drive substantial quality improvement of the likes we probably haven&#x27;t seen in years here at LinkedIn,” Berger says. Why multi-teacher distillation was a ‘breakthrough’ for LinkedIn Berger and his team set out to build an LLM that could interpret individual job queries, candidate profiles and job descriptions in real time, and in a way that mirrored LinkedIn’s product policy as accurately as possible. Working with the company&#x27;s product management team, engineers eventually built out a 20-to-30-page document scoring job description and profile pairs “across many dimensions.” “We did many, many iterations on this,” Berger says. That product policy document was then paired with a “golden dataset” comprising thousands of pairs of queries and profiles; the team fed this into ChatGPT during data generation and experimentation, prompting the model over time to learn scoring pairs and eventually generate a much larger synthetic data set to train a 7-billion-parameter teacher model.However, Berger says, it&#x27;s not enough to have an LLM running in production just on product policy. “At the end of the day, it&#x27;s a recommender system, and we need to do some amount of click prediction and personalization.” So, his team used that initial product policy-focused teacher model to develop a second teacher model oriented toward click prediction. Using the two, they further distilled a 1.7 billion parameter model for training purposes. That eventual student model was run through “many, many training runs,” and was optimized “at every point” to minimize quality loss, Berger says. This multi-teacher distillation technique allowed the team to “achieve a lot of affinity” to the original product policy and “land” click prediction, he says. They were also able to “modularize and componentize” the training process for the student.Consider it in the context of a chat agent with two different teacher models: One is training the agent on accuracy in responses, the other on tone and how it should communicate. Those two things are very different, yet critical, objectives, Berger notes. “By now mixing them, you get better outcomes, but also iterate on them independently,” he says. “That was a breakthrough for us.” Changing how teams work togetherBerger says he can’t understate the importance of anchoring on a product policy and an iterative eval process. Getting a “really, really good product policy” requires translating product manager domain expertise into a unified document. Historically, Berger notes, the product management team was laser focused on strategy and user experience, leaving modeling iteration approaches to ML engineers. Now, though, the two teams work together to “dial in” and create an aligned teacher model. “How product managers work with machine learning engineers now is very different from anything we&#x27;ve done previously,” he says. “It’s now a blueprint for basically any AI products we do at LinkedIn.”Watch the full podcast to hear more about: How LinkedIn optimized every step of the R&D process to support velocity, leading to real results with days or hours rather than weeks; Why teams should develop pipelines for plugability and experimentation and try out different models to support flexibility; The continued importance of traditional engineering debugging.You can also listen and subscribe to Beyond the Pilot on Spotify, Apple or wherever you get your podcasts.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4XBHNMOZc0HSRXb863QC65/7d721c02ce3113eec61a47188e030fdf/LinkedIn.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/apple-is-reportedly-overhauling-siri-to-be-an-ai-chatbot-205303818.html",
          "published_at": "Wed, 21 Jan 2026 20:53:03 +0000",
          "title": "Apple is reportedly overhauling Siri to be an AI chatbot",
          "standfirst": "Apple has been spinning its wheels for many months over its approach to artificial intelligence, but a strategy finally appears to be emerging for the company. Bloomberg's Mark Gurman reported today that Apple's long-awaited Siri overhaul will allegedly involve transforming the voice assistant into an AI chatbot, internally called Campos. Sources have reportedly told Gurman that Apple chatbot will completely replace the current Siri interface in favor of a more interactive model similar to those used by OpenAI's ChatGPT and Google's Gemini. He also cited sources who claimed that while Apple has been testing a standalone Campos app, the company doesn't plan to release it for customers. Instead, the new chatbot will emphasize deep software integrations when it rolls out, reportedly as part of the iOS 27, iPadOS 27 and macOS 27 wave late next year. However, there will reportedly be a new features for the current iteration Siri coming in the iOS 26.4. Those additions will include the much-delayed updates Apple first promised for the platform back in 2024.Pivoting to a chatbot gives some additional context to Apple's recent move to collaborate with frequent rival Google; the companies announced earlier in January that Gemini models will be used to power the upcoming versions of Siri. Gemini has become ubiquitous in the Google ecosystem, and it makes sense for Apple to leverage outside help in this segment where it has already been trailing its competitors. Although Apple may not have a standalone app for its Siri chatbot, the company does appear to be considering new places to host its AI resource. Additional reports today claimed that 2027 could also see the release of a wearable AI pin.This article originally appeared on Engadget at https://www.engadget.com/ai/apple-is-reportedly-overhauling-siri-to-be-an-ai-chatbot-205303818.html?src=rss",
          "content": "Apple has been spinning its wheels for many months over its approach to artificial intelligence, but a strategy finally appears to be emerging for the company. Bloomberg's Mark Gurman reported today that Apple's long-awaited Siri overhaul will allegedly involve transforming the voice assistant into an AI chatbot, internally called Campos. Sources have reportedly told Gurman that Apple chatbot will completely replace the current Siri interface in favor of a more interactive model similar to those used by OpenAI's ChatGPT and Google's Gemini. He also cited sources who claimed that while Apple has been testing a standalone Campos app, the company doesn't plan to release it for customers. Instead, the new chatbot will emphasize deep software integrations when it rolls out, reportedly as part of the iOS 27, iPadOS 27 and macOS 27 wave late next year. However, there will reportedly be a new features for the current iteration Siri coming in the iOS 26.4. Those additions will include the much-delayed updates Apple first promised for the platform back in 2024.Pivoting to a chatbot gives some additional context to Apple's recent move to collaborate with frequent rival Google; the companies announced earlier in January that Gemini models will be used to power the upcoming versions of Siri. Gemini has become ubiquitous in the Google ecosystem, and it makes sense for Apple to leverage outside help in this segment where it has already been trailing its competitors. Although Apple may not have a standalone app for its Siri chatbot, the company does appear to be considering new places to host its AI resource. Additional reports today claimed that 2027 could also see the release of a wearable AI pin.This article originally appeared on Engadget at https://www.engadget.com/ai/apple-is-reportedly-overhauling-siri-to-be-an-ai-chatbot-205303818.html?src=rss",
          "feed_position": 37
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/apple-is-reportedly-developing-a-wearable-ai-pin-204705065.html",
          "published_at": "Wed, 21 Jan 2026 20:47:05 +0000",
          "title": "Apple is reportedly developing a wearable AI pin",
          "standfirst": "Apple will reportedly try to succeed where Humane failed (miserably). On Wednesday, The Information reported that the iPhone maker is working on an AI pin. The wearable is said to resemble a slightly thicker AirTag and include multiple cameras, a speaker, microphones, and wireless charging.The report coincides with another from Bloomberg that claims that Apple will revamp Siri as a ChatGPT-style chatbot. When combined with the recent announcement that Google's Gemini will power Siri AI, it looks like the company is finally making a more defined play for a piece of the generative AI pie. On the other hand, the wearable pin is reportedly only in the very early stages and could still be canceled.The pin is described as a thin, flat, circular disc with an aluminum and glass exterior. It includes two cameras (standard and wide-angle) for taking photos and videos of the user's surroundings. It also has three microphones. It includes a speaker and a physical button along one edge. It has a magnetic inductive charging interface, similar to the Apple Watch's charging mechanism.Given the way Apple markets itself as a privacy-focused company, it will be interesting to see how the company pitches the public on what sounds like an incognito recording device. Although on that note, the App Store still hosts the Grok app, which egregiously violates privacy by generating nearly-nude deepfakes of real people — despite Apple's rules explicitly prohibiting such apps.The Information says Apple could release its AI pin as early as 2027. The company sounds confident in the device's appeal, as it reportedly plans to produce around 20 million units at launch.This article originally appeared on Engadget at https://www.engadget.com/wearables/apple-is-reportedly-developing-a-wearable-ai-pin-204705065.html?src=rss",
          "content": "Apple will reportedly try to succeed where Humane failed (miserably). On Wednesday, The Information reported that the iPhone maker is working on an AI pin. The wearable is said to resemble a slightly thicker AirTag and include multiple cameras, a speaker, microphones, and wireless charging.The report coincides with another from Bloomberg that claims that Apple will revamp Siri as a ChatGPT-style chatbot. When combined with the recent announcement that Google's Gemini will power Siri AI, it looks like the company is finally making a more defined play for a piece of the generative AI pie. On the other hand, the wearable pin is reportedly only in the very early stages and could still be canceled.The pin is described as a thin, flat, circular disc with an aluminum and glass exterior. It includes two cameras (standard and wide-angle) for taking photos and videos of the user's surroundings. It also has three microphones. It includes a speaker and a physical button along one edge. It has a magnetic inductive charging interface, similar to the Apple Watch's charging mechanism.Given the way Apple markets itself as a privacy-focused company, it will be interesting to see how the company pitches the public on what sounds like an incognito recording device. Although on that note, the App Store still hosts the Grok app, which egregiously violates privacy by generating nearly-nude deepfakes of real people — despite Apple's rules explicitly prohibiting such apps.The Information says Apple could release its AI pin as early as 2027. The company sounds confident in the device's appeal, as it reportedly plans to produce around 20 million units at launch.This article originally appeared on Engadget at https://www.engadget.com/wearables/apple-is-reportedly-developing-a-wearable-ai-pin-204705065.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/cfos-are-now-getting-their-own-vibe-coding-moment-thanks-to-datarails",
          "published_at": "Wed, 21 Jan 2026 18:09:00 GMT",
          "title": "CFOs are now getting their own 'vibe coding' moment thanks to Datarails",
          "standfirst": "For the modern CFO, the hardest part of the job often isn&#x27;t the math—it&#x27;s the storytelling. After the books are closed and the variances calculated, finance teams spend days, sometimes weeks, manually copy-pasting charts into PowerPoint slides to explain why the numbers moved.Today, 11-year-old Israeli fintech company Datarails announced a set of new generative AI tools designed to automate that \"last mile\" of financial reporting, effectively allowing finance leaders to \"vibe code\" their way to a board deck.Launching today to accompany the firm&#x27;s newly announced $70 million Series C funding round, the company’s new Strategy, Planning, and Reporting AI Finance Agents promise to answer complex financial questions with fully formatted assets, not just text. A finance professional can now ask, \"What’s driving our profitability changes this year?\" or \"Why did Marketing go over budget last month?\" and the system will instantly generate board-ready PowerPoint slides, PDF reports, or Excel files containing the answer.The deployment of these agents marks a fundamental shift in how the \"Office of the CFO\" interacts with data.Beyond the chatbotThe promise of the new agents is to solve the fragmentation problem that plagues finance departments. Unlike a sales leader who lives in Salesforce, or a CIO who relies on ServiceNow, the CFO has no single \"system of truth\". Data is scattered across ERPs, HRIS, CRMs, and bank portals.A major barrier to AI adoption in finance has been security. CFOs are rightfully hesitant to plug P&L data into public models.Datarails has addressed this by leveraging Microsoft’s Azure OpenAI Service. \"We use the OpenAI in Azure to ensure the privacy and the security for our customers, they don&#x27;t like to share the data in [an] open LLM,\" Gurfinkel noted. This allows the platform to utilize state-of-the-art models while keeping data within a secure enterprise perimeter.Datarails’ new agents sit on top of a unified data layer that connects these disparate systems. Because the AI is grounded in the company’s own unified internal data, it avoids the hallucinations common in generic LLMs while offering a level of privacy required for sensitive financial data.\"If the CFO wants to leverage AI on the CFO level or the organization data, they need to consolidate the data,\" explained Datarails CEO and co-founder Didi Gurfinkel in an interview with VentureBeat.By solving that consolidation problem first, Datarails can now offer agents that understand the context of the business. \"Now the CFO can use our agents to run analysis, get insights, create reports... because now the data is ready,\" Gurfinkel said.&#x27;Vibe coding&#x27; for financeThe launch taps into a broader trend in software development where natural language prompts replace complex coding or manual configuration—a concept tech circles refer to as \"vibe coding.\" Gurfinkel believes this is the future of financial engineering.\"Very soon, the CFO and the financial team themselves will be able to develop applications,\" Gurfinkel predicted. \"The LLMs become so strong that in one prompt, they can replace full product runs.\"He described a workflow where a user could simply prompt: \"That was my budget and my actual of the past year. Now build me the budget for the next year.\"The new agents are designed to handle exactly these types of complex, multi-variable scenarios. For example, a user could ask, \"What happens if revenue grows slower next quarter?\" and receive a scenario analysis in return.Because the output can be delivered as an Excel file, finance teams can verify the formulas and assumptions, maintaining the audit trail that generic AI tools often lack.Ease of adoption: The &#x27;anti-implementation&#x27;For most engineering teams, the arrival of a new enterprise financial platform signals a looming headache: months of data migration, schema redesigns, and the inevitable friction of forcing non-technical users to abandon their preferred workflows. Datarails has engineered its way around this friction by building what might be best described as an \"anti-implementation.\"Instead of demanding a \"rip and replace\" of legacy systems, the platform accepts the messy reality of the modern finance stack. The architecture is designed to decouple the data storage from the presentation layer, effectively treating the organization&#x27;s existing Excel files as a frontend interface while Datarails acts as the backend database.\"We are not replacing anything,\" Gurfinkel explained. \"The implementation can be very fast, from a few hours to maybe a few days\".From a technical perspective, this means the \"engineering\" requirement is almost entirely stripped away. There are no ETL pipelines to build or Python scripts to maintain. The system comes pre-wired with over 200 native connectors—linking directly to ERPs like NetSuite and Sage, CRMs like Salesforce, and various HRIS and bank portals.The heavy lifting is replaced by a \"no-code\" mapping process. A finance analyst, not a developer, maps the fields from their General Ledger to their Excel models in a self-service workflow. For modules like Month-End Close, the company explicitly promises that \"no IT support is needed,\" a phrase that likely comes as a relief to stretched CTOs. Even complex setups, such as the new Cash Management module which requires banking integrations, are typically fully operational within two to three weeks.The result is a system where the \"technical debt\" usually associated with financial transformation is rendered obsolete. The finance team gets their \"single source of truth\" without ever asking engineering to provision a database.From version Control to vision control: a pivot that paid offDatarails wasn&#x27;t always the \"FinanceOS\" for the AI era. Founded in 2015 by Gurfinkel alongside co-founders Eyal Cohen (COO) and Oded Har-Tal (CTO), the Tel Aviv-based startup spent its early years tackling a dryer problem: version control for Excel. The initial premise was to synchronize and manage spreadsheets across enterprises, but adoption was sluggish as the team struggled to find the right product-market fit.The breakthrough came in 2020 with a strategic pivot. The team realized that finance professionals didn&#x27;t want to replace Excel with a new dashboard; they wanted to fix Excel&#x27;s limitations—specifically manual consolidation and data fragmentation. By shifting focus to SMB finance teams and embracing an \"Excel-native\" automation philosophy, the company found its stride.This alignment led to rapid scaling, fueled by a $55 million Series A in June 2021 led by Zeev Ventures, followed quickly by a $50 million Series B in March 2022 led by Qumra Capital. While the company faced headwinds during the tech downturn—resulting in an 18% workforce reduction in late 2022—it has since rebounded aggressively. By 2025, Datarails had nearly doubled its workforce to over 400 employees globally, driven by a multi-product expansion strategy that now includes Month-End Close and Cash Management solutions.Fueling the expansionThe new AI capabilities are supported by the $70 million Series C injection from One Peak, along with existing investors Vertex Growth, Vintage Investment Partners, and others. The funding arrives after a year of 70% revenue growth for Datarails, driven largely by the expansion of its product suite.More than 50% of the company&#x27;s growth in 2025 came from solutions launched in the last 12 months, including Datarails Month-End Close (a tool for automating reconciliations and workflow management) and Datarails Cash Management (for real-time liquidity monitoring).These products serve as the \"plumbing\" that makes the new AI agents effective. By automating the month-end close and unifying cash data, Datarails ensures that when a CFO asks the AI a question, the underlying numbers are accurate and up-to-date.For Gurfinkel, the goal is to make the finance office \"AI-native\" without forcing users to abandon their favorite tool: Excel.\"We are not replacing anything,\" Gurfinkel said. \"We connect the Excel so Excel now becomes the calculation and the presentation.\"With the launch of these new agents, Datarails is betting that the future of finance isn&#x27;t about learning new software, but about having a conversation with the data you already have.",
          "content": "For the modern CFO, the hardest part of the job often isn&#x27;t the math—it&#x27;s the storytelling. After the books are closed and the variances calculated, finance teams spend days, sometimes weeks, manually copy-pasting charts into PowerPoint slides to explain why the numbers moved.Today, 11-year-old Israeli fintech company Datarails announced a set of new generative AI tools designed to automate that \"last mile\" of financial reporting, effectively allowing finance leaders to \"vibe code\" their way to a board deck.Launching today to accompany the firm&#x27;s newly announced $70 million Series C funding round, the company’s new Strategy, Planning, and Reporting AI Finance Agents promise to answer complex financial questions with fully formatted assets, not just text. A finance professional can now ask, \"What’s driving our profitability changes this year?\" or \"Why did Marketing go over budget last month?\" and the system will instantly generate board-ready PowerPoint slides, PDF reports, or Excel files containing the answer.The deployment of these agents marks a fundamental shift in how the \"Office of the CFO\" interacts with data.Beyond the chatbotThe promise of the new agents is to solve the fragmentation problem that plagues finance departments. Unlike a sales leader who lives in Salesforce, or a CIO who relies on ServiceNow, the CFO has no single \"system of truth\". Data is scattered across ERPs, HRIS, CRMs, and bank portals.A major barrier to AI adoption in finance has been security. CFOs are rightfully hesitant to plug P&L data into public models.Datarails has addressed this by leveraging Microsoft’s Azure OpenAI Service. \"We use the OpenAI in Azure to ensure the privacy and the security for our customers, they don&#x27;t like to share the data in [an] open LLM,\" Gurfinkel noted. This allows the platform to utilize state-of-the-art models while keeping data within a secure enterprise perimeter.Datarails’ new agents sit on top of a unified data layer that connects these disparate systems. Because the AI is grounded in the company’s own unified internal data, it avoids the hallucinations common in generic LLMs while offering a level of privacy required for sensitive financial data.\"If the CFO wants to leverage AI on the CFO level or the organization data, they need to consolidate the data,\" explained Datarails CEO and co-founder Didi Gurfinkel in an interview with VentureBeat.By solving that consolidation problem first, Datarails can now offer agents that understand the context of the business. \"Now the CFO can use our agents to run analysis, get insights, create reports... because now the data is ready,\" Gurfinkel said.&#x27;Vibe coding&#x27; for financeThe launch taps into a broader trend in software development where natural language prompts replace complex coding or manual configuration—a concept tech circles refer to as \"vibe coding.\" Gurfinkel believes this is the future of financial engineering.\"Very soon, the CFO and the financial team themselves will be able to develop applications,\" Gurfinkel predicted. \"The LLMs become so strong that in one prompt, they can replace full product runs.\"He described a workflow where a user could simply prompt: \"That was my budget and my actual of the past year. Now build me the budget for the next year.\"The new agents are designed to handle exactly these types of complex, multi-variable scenarios. For example, a user could ask, \"What happens if revenue grows slower next quarter?\" and receive a scenario analysis in return.Because the output can be delivered as an Excel file, finance teams can verify the formulas and assumptions, maintaining the audit trail that generic AI tools often lack.Ease of adoption: The &#x27;anti-implementation&#x27;For most engineering teams, the arrival of a new enterprise financial platform signals a looming headache: months of data migration, schema redesigns, and the inevitable friction of forcing non-technical users to abandon their preferred workflows. Datarails has engineered its way around this friction by building what might be best described as an \"anti-implementation.\"Instead of demanding a \"rip and replace\" of legacy systems, the platform accepts the messy reality of the modern finance stack. The architecture is designed to decouple the data storage from the presentation layer, effectively treating the organization&#x27;s existing Excel files as a frontend interface while Datarails acts as the backend database.\"We are not replacing anything,\" Gurfinkel explained. \"The implementation can be very fast, from a few hours to maybe a few days\".From a technical perspective, this means the \"engineering\" requirement is almost entirely stripped away. There are no ETL pipelines to build or Python scripts to maintain. The system comes pre-wired with over 200 native connectors—linking directly to ERPs like NetSuite and Sage, CRMs like Salesforce, and various HRIS and bank portals.The heavy lifting is replaced by a \"no-code\" mapping process. A finance analyst, not a developer, maps the fields from their General Ledger to their Excel models in a self-service workflow. For modules like Month-End Close, the company explicitly promises that \"no IT support is needed,\" a phrase that likely comes as a relief to stretched CTOs. Even complex setups, such as the new Cash Management module which requires banking integrations, are typically fully operational within two to three weeks.The result is a system where the \"technical debt\" usually associated with financial transformation is rendered obsolete. The finance team gets their \"single source of truth\" without ever asking engineering to provision a database.From version Control to vision control: a pivot that paid offDatarails wasn&#x27;t always the \"FinanceOS\" for the AI era. Founded in 2015 by Gurfinkel alongside co-founders Eyal Cohen (COO) and Oded Har-Tal (CTO), the Tel Aviv-based startup spent its early years tackling a dryer problem: version control for Excel. The initial premise was to synchronize and manage spreadsheets across enterprises, but adoption was sluggish as the team struggled to find the right product-market fit.The breakthrough came in 2020 with a strategic pivot. The team realized that finance professionals didn&#x27;t want to replace Excel with a new dashboard; they wanted to fix Excel&#x27;s limitations—specifically manual consolidation and data fragmentation. By shifting focus to SMB finance teams and embracing an \"Excel-native\" automation philosophy, the company found its stride.This alignment led to rapid scaling, fueled by a $55 million Series A in June 2021 led by Zeev Ventures, followed quickly by a $50 million Series B in March 2022 led by Qumra Capital. While the company faced headwinds during the tech downturn—resulting in an 18% workforce reduction in late 2022—it has since rebounded aggressively. By 2025, Datarails had nearly doubled its workforce to over 400 employees globally, driven by a multi-product expansion strategy that now includes Month-End Close and Cash Management solutions.Fueling the expansionThe new AI capabilities are supported by the $70 million Series C injection from One Peak, along with existing investors Vertex Growth, Vintage Investment Partners, and others. The funding arrives after a year of 70% revenue growth for Datarails, driven largely by the expansion of its product suite.More than 50% of the company&#x27;s growth in 2025 came from solutions launched in the last 12 months, including Datarails Month-End Close (a tool for automating reconciliations and workflow management) and Datarails Cash Management (for real-time liquidity monitoring).These products serve as the \"plumbing\" that makes the new AI agents effective. By automating the month-end close and unifying cash data, Datarails ensures that when a CFO asks the AI a question, the underlying numbers are accurate and up-to-date.For Gurfinkel, the goal is to make the finance office \"AI-native\" without forcing users to abandon their favorite tool: Excel.\"We are not replacing anything,\" Gurfinkel said. \"We connect the Excel so Excel now becomes the calculation and the presentation.\"With the launch of these new agents, Datarails is betting that the future of finance isn&#x27;t about learning new software, but about having a conversation with the data you already have.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2JKMdzG9HS26opXgs2P44p/b3ca78544561a561c34b4c3a849fedbe/Left_to_right__Oded_Har-Tal_Co-Founder___CTO__Datarails-_mascot__Bob_Sheetner___Didi_Gurfinkel__Co-Founder___CEO_and_Eyal_Co.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/what-servicenow-and-openai-signal-for-enterprises-as-ai-moves-from-advice-to",
          "published_at": "Wed, 21 Jan 2026 17:30:00 GMT",
          "title": "ServiceNow positions itself as the control layer for enterprise AI execution",
          "standfirst": "ServiceNow announced a multi-year partnership with OpenAI to bring GPT-5.2 into its AI Control Tower and Xanadu platform, reinforcing ServiceNow’s strategy to focus on enterprise workflows, guardrails, and orchestration rather than building frontier models itself.For enterprise buyers, the deal underscores a broader shift: general-purpose models are becoming interchangeable, while the platforms that control how they’re deployed and governed are where differentiation now lives.ServiceNow lets enterprises develop agents and applications, plug them into existing workflows, and manage orchestration and monitoring through its unified AI Control Tower. The partnership does not mean ServiceNow will no longer use other models to power its services, said John Aisien, senior vice president of product management at ServiceNow.\"We will remain an open platform. There are things we will partner on with each of the model providers, depending on their expertise. Still, ServiceNow will continue to support a hybrid, multi-model AI strategy where customers can bring any model to our AI platform,” Aisien said in an email to VentureBeat. “Instead of exclusivity, we give enterprise customers maximum flexibility by combining powerful general-purpose models with our own LLMs built for ServiceNow workflows.”What the OpenAI partnership unlocks for ServiceNow customersServiceNow customers get:Voice-first agents: Speech-to-speech and voice-to-text supportEnterprise knowledge access: Q&A grounded in enterprise data, with improved search and discoveryOperational automation: Incident summarization and resolution supportServiceNow said it plans to work directly with OpenAI to build “real-time speech-to-speech AI agents that can listen, reason and respond naturally without text intermediation.” The company is also interested in tapping OpenAI’s computer use models to automate actions across enterprise tools such as email and chat.The enterprise playbookThe partnership reinforces ServiceNow’s positioning as a control layer for enterprise AI, separating general-purpose models from the services that govern how they’re deployed, monitored, and secured. Rather than owning the models, ServiceNow is emphasizing orchestration and guardrails — the layers enterprises increasingly need to scale AI safely.Some companies that work with enterprises see the partnership as a positive. Tom Bachant, co-founder and CEO of AI workflow and support platform Unthread, said this could further reduce integration friction. “Deeply integrated systems often lower the barrier to entry and simplify initial deployment,\" he told VentureBeat in an email. \"However, as organizations scale AI across core business systems, flexibility becomes more important than standardization. Enterprises ultimately need the ability to adapt performance benchmarks, pricing models, and internal risk postures; none of which remain static over time.”As enterprise AI adoption accelerates, partnerships like this suggest the real battleground is shifting away from the models themselves and toward the platforms that control how those models are used in production.",
          "content": "ServiceNow announced a multi-year partnership with OpenAI to bring GPT-5.2 into its AI Control Tower and Xanadu platform, reinforcing ServiceNow’s strategy to focus on enterprise workflows, guardrails, and orchestration rather than building frontier models itself.For enterprise buyers, the deal underscores a broader shift: general-purpose models are becoming interchangeable, while the platforms that control how they’re deployed and governed are where differentiation now lives.ServiceNow lets enterprises develop agents and applications, plug them into existing workflows, and manage orchestration and monitoring through its unified AI Control Tower. The partnership does not mean ServiceNow will no longer use other models to power its services, said John Aisien, senior vice president of product management at ServiceNow.\"We will remain an open platform. There are things we will partner on with each of the model providers, depending on their expertise. Still, ServiceNow will continue to support a hybrid, multi-model AI strategy where customers can bring any model to our AI platform,” Aisien said in an email to VentureBeat. “Instead of exclusivity, we give enterprise customers maximum flexibility by combining powerful general-purpose models with our own LLMs built for ServiceNow workflows.”What the OpenAI partnership unlocks for ServiceNow customersServiceNow customers get:Voice-first agents: Speech-to-speech and voice-to-text supportEnterprise knowledge access: Q&A grounded in enterprise data, with improved search and discoveryOperational automation: Incident summarization and resolution supportServiceNow said it plans to work directly with OpenAI to build “real-time speech-to-speech AI agents that can listen, reason and respond naturally without text intermediation.” The company is also interested in tapping OpenAI’s computer use models to automate actions across enterprise tools such as email and chat.The enterprise playbookThe partnership reinforces ServiceNow’s positioning as a control layer for enterprise AI, separating general-purpose models from the services that govern how they’re deployed, monitored, and secured. Rather than owning the models, ServiceNow is emphasizing orchestration and guardrails — the layers enterprises increasingly need to scale AI safely.Some companies that work with enterprises see the partnership as a positive. Tom Bachant, co-founder and CEO of AI workflow and support platform Unthread, said this could further reduce integration friction. “Deeply integrated systems often lower the barrier to entry and simplify initial deployment,\" he told VentureBeat in an email. \"However, as organizations scale AI across core business systems, flexibility becomes more important than standardization. Enterprises ultimately need the ability to adapt performance benchmarks, pricing models, and internal risk postures; none of which remain static over time.”As enterprise AI adoption accelerates, partnerships like this suggest the real battleground is shifting away from the models themselves and toward the platforms that control how those models are used in production.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/55ywB5pweRdcKS0AR7NkuG/cfb973781feb2a8313a171ab19f06703/crimedy7_illustration_of_a_partnership_between_robots_abstrac_ee1e138f-dc4a-4f66-9dd7-94c1d5216de3_3.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/evs/volvo-ex60-suv-preview-400-mile-range-670-hp-and-google-gemini-onboard-173000033.html",
          "published_at": "Wed, 21 Jan 2026 17:30:00 +0000",
          "title": "Volvo EX60 SUV preview: 400-mile range, 670 hp and Google Gemini onboard",
          "standfirst": "Volvo hasn't exactly had a great run of EVs lately. The rollout of its flagship EX90 was stymied out of the gate by a bevy of software glitches. The EX30, meanwhile, was too expensive when it launched — the promised $35,000 model was incompatible with the currently chaotic global tariff situation.Now, it's time for a new generation of EV from Volvo, one that's radically different at its core with a gigacast frame, a much higher-density battery and enough digital and literal horsepower to impress the most jaded of automotive enthusiasts. Mix in high-performance chipsets from both NVIDIA and Qualcomm, plus Google's Gemini AI onboard, and on paper, it has a lot to offer. After getting an early look at the thing at its unveiling in Sweden, I feel like this EV is ready and able to face off against BMW's new iX3 and Mercedes-Benz's upcoming GLC.Let's start with the basics: The EX60 slots in the Volvo product lineup right alongside the existing XC60, Volvo's most popular model in the U.S. It's a two-row, mid-size SUV that seats five, the sort of thing perfect for those with small families or big dogs. It'll be available in three different basic configurations, starting with the single-motor, rear-drive, 369-horsepower, 310-mile EX60 P6. Next up is the AWD dual-motor, 503-hp, 320-mile P10, and finally the top-shelf, 670-hp, 400-mile P12.670 horsepower in an SUV of this size seems frankly excessive to me, but then it does have a lot of weight to move around — 5,137 pounds to be exact. That’s thanks in large part to the P12's 112-kilowatt-hour net battery pack which is about 50 percent bigger than the one inside a Tesla Model Y. The P6 is a relatively svelte 4,663 pounds thanks to its smaller 80-kWh net battery pack, while the P10 has 91 kWh.Volvo EX60VolvoBeyond the powertrain divisions, the Volvo EX60 will also be available in a variety of different trims with varying amounts of equipment, including the Volvo Cross Country edition with air suspension and a 20mm boost of ride height. Prices are said to start \"around $60k\" for an EX60 P10 Plus with a 21-speaker Bose system, but a 28-speaker Bowers & Wilkins system with Dolby Atmos will be available for those who really need all the channels.Of course, Atmos support is no good without a good source, and to that end, the EX60 will be the first Volvo with Apple Music built in. That'll be part of the company's Android Automotive-based infotainment system, running on a curved 15-inch OLED screen and powered by a Qualcomm 8255 chipset. It’s paired with a low, wide gauge cluster set far back on the dashboard behind the steering wheel.This will also be Volvo's first car with integrated Gemini, and indeed one of the first cars on the road with Google's smart agent. You can, of course, do typical Gemini things like ask about the weather or the nuances of René Descartes's concepts on dualism. Beyond that, Volvo CTO Anders Bell said that it will eventually gain access to the car's outward-looking cameras, meaning you'll be able to ask for more details on whatever it is you can see looming on the horizon.Volvo EX60VolvoVolvo calls the car's software-defined architecture and the hardware that powers it HuginCore, named for Huginn, the raven of Norse mythology and represents Odin's mind and senses. Qualcomm powers the infotainment side of the avian experience, but when it comes to active safety, the EX60 relies on an NVIDIA Drive AGX Orin chipset. Unlike the EX90, the EX60 will not use a LiDAR sensor.Volvo CTO Bell downplayed the absence of the sensor. \"We realized we can now achieve many more meaningful and safe automated functions without LiDAR than we could have years ago,\" he said. Per Bell, LiDAR was never really in the plan for the EX60 anyway, a decision looking all the brighter given the recent bankruptcy of Volvo's former LiDAR partner Luminar.The car's cameras and radar sensors all tuck nicely into the new exterior of the EX60, which certainly doesn't look miles off from the EX90 or indeed the current, gas-powered XC60. But the pronounced flares on the front fenders are a nice touch of personality on an otherwise understated SUV.At the core of the EX60 is a new platform Volvo calls SPA3, with a chassis made using gigacasting. This refers to the force required to inject molten aluminum into massive castings, allowing more of the car to be made from fewer components. Volvo says the carbon footprint of the EX60 is lower even than that of the much smaller EX30.The battery packs use the on-trend cell-to-pack construction method, which means all the cells are lumped together into a single unit. Typically, this boosts density at the cost of repairability, a tradeoff most manufacturers seem willing to make in pursuit of higher range and lower costs. However, Bell said that the company has actually made pack maintenance easier by optimizing the layout of the ancillary equipment.Volvo EX60Volvo\"The absolute vast majority, 90 percent of anything that ever needs to be repaired on a battery pack is electronics,\" he said. In the EX60, Volvo positioned the battery electronics beneath the rear seat to make them even easier to access. \"We save a lot of weight, save a lot of cost.\"The EX60 will be Volvo's first car to use the Tesla-style NACS charging standard, and the largest two packs will support charging speeds up to 370 kW. That drops to 320 kW on the 80-kWh net P6.In practical terms, though, they're all roughly the same. Each model charges from 10 to 80 percent in less than 20 minutes, adding between 160 and 173 miles of range in 10 minutes. That's not quite the 200 miles BMW's iX3 can manage in the same time, but it is close.The iX3 will probably be the EX60's fiercest competition when Volvo opens up orders later this spring. The EX60's $60,000 price for a midrange P10 Plus puts it right in line with the $60,000 that BMW says to expect for its iX3. Mercedes hasn't set American pricing for its GLC yet, but that, too, will be on a lot of shoppers' lists to compare.I've already been impressed by how both the iX3 and the GLC drive. Sadly, Volvo wouldn't let me behind the wheel of its EX60 just yet, but hopefully I can report back with impressions soon to start to see how all these stack up on the road. This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/volvo-ex60-suv-preview-400-mile-range-670-hp-and-google-gemini-onboard-173000033.html?src=rss",
          "content": "Volvo hasn't exactly had a great run of EVs lately. The rollout of its flagship EX90 was stymied out of the gate by a bevy of software glitches. The EX30, meanwhile, was too expensive when it launched — the promised $35,000 model was incompatible with the currently chaotic global tariff situation.Now, it's time for a new generation of EV from Volvo, one that's radically different at its core with a gigacast frame, a much higher-density battery and enough digital and literal horsepower to impress the most jaded of automotive enthusiasts. Mix in high-performance chipsets from both NVIDIA and Qualcomm, plus Google's Gemini AI onboard, and on paper, it has a lot to offer. After getting an early look at the thing at its unveiling in Sweden, I feel like this EV is ready and able to face off against BMW's new iX3 and Mercedes-Benz's upcoming GLC.Let's start with the basics: The EX60 slots in the Volvo product lineup right alongside the existing XC60, Volvo's most popular model in the U.S. It's a two-row, mid-size SUV that seats five, the sort of thing perfect for those with small families or big dogs. It'll be available in three different basic configurations, starting with the single-motor, rear-drive, 369-horsepower, 310-mile EX60 P6. Next up is the AWD dual-motor, 503-hp, 320-mile P10, and finally the top-shelf, 670-hp, 400-mile P12.670 horsepower in an SUV of this size seems frankly excessive to me, but then it does have a lot of weight to move around — 5,137 pounds to be exact. That’s thanks in large part to the P12's 112-kilowatt-hour net battery pack which is about 50 percent bigger than the one inside a Tesla Model Y. The P6 is a relatively svelte 4,663 pounds thanks to its smaller 80-kWh net battery pack, while the P10 has 91 kWh.Volvo EX60VolvoBeyond the powertrain divisions, the Volvo EX60 will also be available in a variety of different trims with varying amounts of equipment, including the Volvo Cross Country edition with air suspension and a 20mm boost of ride height. Prices are said to start \"around $60k\" for an EX60 P10 Plus with a 21-speaker Bose system, but a 28-speaker Bowers & Wilkins system with Dolby Atmos will be available for those who really need all the channels.Of course, Atmos support is no good without a good source, and to that end, the EX60 will be the first Volvo with Apple Music built in. That'll be part of the company's Android Automotive-based infotainment system, running on a curved 15-inch OLED screen and powered by a Qualcomm 8255 chipset. It’s paired with a low, wide gauge cluster set far back on the dashboard behind the steering wheel.This will also be Volvo's first car with integrated Gemini, and indeed one of the first cars on the road with Google's smart agent. You can, of course, do typical Gemini things like ask about the weather or the nuances of René Descartes's concepts on dualism. Beyond that, Volvo CTO Anders Bell said that it will eventually gain access to the car's outward-looking cameras, meaning you'll be able to ask for more details on whatever it is you can see looming on the horizon.Volvo EX60VolvoVolvo calls the car's software-defined architecture and the hardware that powers it HuginCore, named for Huginn, the raven of Norse mythology and represents Odin's mind and senses. Qualcomm powers the infotainment side of the avian experience, but when it comes to active safety, the EX60 relies on an NVIDIA Drive AGX Orin chipset. Unlike the EX90, the EX60 will not use a LiDAR sensor.Volvo CTO Bell downplayed the absence of the sensor. \"We realized we can now achieve many more meaningful and safe automated functions without LiDAR than we could have years ago,\" he said. Per Bell, LiDAR was never really in the plan for the EX60 anyway, a decision looking all the brighter given the recent bankruptcy of Volvo's former LiDAR partner Luminar.The car's cameras and radar sensors all tuck nicely into the new exterior of the EX60, which certainly doesn't look miles off from the EX90 or indeed the current, gas-powered XC60. But the pronounced flares on the front fenders are a nice touch of personality on an otherwise understated SUV.At the core of the EX60 is a new platform Volvo calls SPA3, with a chassis made using gigacasting. This refers to the force required to inject molten aluminum into massive castings, allowing more of the car to be made from fewer components. Volvo says the carbon footprint of the EX60 is lower even than that of the much smaller EX30.The battery packs use the on-trend cell-to-pack construction method, which means all the cells are lumped together into a single unit. Typically, this boosts density at the cost of repairability, a tradeoff most manufacturers seem willing to make in pursuit of higher range and lower costs. However, Bell said that the company has actually made pack maintenance easier by optimizing the layout of the ancillary equipment.Volvo EX60Volvo\"The absolute vast majority, 90 percent of anything that ever needs to be repaired on a battery pack is electronics,\" he said. In the EX60, Volvo positioned the battery electronics beneath the rear seat to make them even easier to access. \"We save a lot of weight, save a lot of cost.\"The EX60 will be Volvo's first car to use the Tesla-style NACS charging standard, and the largest two packs will support charging speeds up to 370 kW. That drops to 320 kW on the 80-kWh net P6.In practical terms, though, they're all roughly the same. Each model charges from 10 to 80 percent in less than 20 minutes, adding between 160 and 173 miles of range in 10 minutes. That's not quite the 200 miles BMW's iX3 can manage in the same time, but it is close.The iX3 will probably be the EX60's fiercest competition when Volvo opens up orders later this spring. The EX60's $60,000 price for a midrange P10 Plus puts it right in line with the $60,000 that BMW says to expect for its iX3. Mercedes hasn't set American pricing for its GLC yet, but that, too, will be on a lot of shoppers' lists to compare.I've already been impressed by how both the iX3 and the GLC drive. Sadly, Volvo wouldn't let me behind the wheel of its EX60 just yet, but hopefully I can report back with impressions soon to start to see how all these stack up on the road. This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/volvo-ex60-suv-preview-400-mile-range-670-hp-and-google-gemini-onboard-173000033.html?src=rss",
          "feed_position": 44,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/JPG_Full-vin0490_34FrontAlt_746_EX60_ROW.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/sony-linkbuds-clip-review-open-fit-benefits-arent-enough-to-stand-out-160000140.html",
          "published_at": "Wed, 21 Jan 2026 16:00:00 +0000",
          "title": "Sony LinkBuds Clip review: Open-fit benefits aren't enough to stand out",
          "standfirst": "I vividly remember when Bose announced the Ultra Open Earbuds. While I applauded the company for trying something different, I wasn’t sure if the clip-on design would take hold. Well, here we are almost two years later and most earbud makers now have something akin to Bose’s fashion experiment. You can now count Sony among those as the company revealed its LinkBuds Clip ($230) open-fit earbuds today. These aren’t the first open-wear earbuds in Sony’s LinkBuds lineup. The company has two generations of the LinkBuds Open (originally called just LinkBuds) under its belt, giving users a more traditional earbud fit with donut-shaped drivers that let ambient sounds in. Now Sony is taking a cue from Bose and others with a clip-on design that attaches securely and comfortably to the ear while leaving the ear canal unobstructed. It’s clear companies believe customers like this type of earbuds, but Sony’s challenge is to make the LinkBuds Clip unique among the growing list of alternatives. Design and fit Sony isn’t offering anything distinctive in terms of design here, but that’s okay. To be fair, I haven’t seen too much innovation in terms of aesthetics in these clip-on-style earbuds. For the most part, they all have similar shapes: two cylindrical cases connected by short, flexible cable. True to its predecessors, Sony put the drivers in a squatty housing while the bulk of the components are in a larger one that sits behind your ear lobe. Sony kept the weight of the LinkBuds Clip low, and it avoided the bulk of the Ultra Open Earbuds. Both of these factors contribute to a very comfortable fit, so the IPX4-rated earbuds can be easily worn all day without becoming a burden. And while I didn’t need them, Sony includes a pair of flexible silicone “fitting cushions” in the box. These clip on to the short, flat cable of the newest LinkBuds for a more secure fit. During my tests, the LinkBuds Clip stayed in place just fine without them, but there also wasn’t any decreased comfort when I did install them. The last design-related item I’ll mention is the touch controls. On the LinkBuds Clip, the flat connector between the two housings accepts taps for playback controls, volume changes, cycling through sound modes and more. You can tap along this area to make an adjustment, and you don’t have to do so right in the center. The LinkBuds Clip were pleasantly responsive during this review, quickly completing the task without delay or repeated taps. That is, except for volume, because you have to keep tapping for that change to happen. LinkBuds Clip features Controls are situated along the connector between the two cylindrical housings Billy Steele for Engadget Sony typically throws a whole host of features at its earbuds. Even though they’re technically the company’s midrange line, the LinkBuds family has a robust set of conveniences that make them well suited for both productivity and leisure. Unfortunately, the LinkBuds Clip doesn’t have as much to offer here. The company gives you the basics, like the ability to fine-tune the tap controls or customize the EQ, and there’s even the Adaptive Audio tool that lets you customize settings based on activity or location (Sony calls them “scenes”). But there are some handy features I’ve come to expect from Sony that are notably absent. The LinkBuds Clip doesn’t support speak-to-chat, Sony’s voice recognition feature that pauses audio and activates ambient sound when you start talking. Quick attention mode, the tool that lowers the volume and lets in ambient sound for brief chats, isn’t here either. These earbuds don’t even have wear detection, and you have to settle for regular ol’ DSEE audio upscaling instead of an enhanced version of that tech. Sony did equip the LinkBuds Clip with unique listening modes meant to enhance the audio performance in two scenarios. First, Voice Boost increases the volume of voices when you’re on a call or listening to podcasts or audiobooks. The company says this is designed for noisy environments where the ambient sound is overly raucous. During my testing, I found the setting to be an extreme treble boost and volume increase — something that’s definitely not well-suited for music. Next, Sound Leakage Reduction dials back high-pitched tones to avoid annoying your neighbors in the office or coffee shop. To me, this is the opposite of Voice Boost, removing the highs for a more mid- and bass-heavy tuning, but it doesn’t sound very good compared to the default setting. Plus, my family wasn’t really able to hear any leakage on the LinkBuds Clip anyway, unless I had the volume cranked uncomfortably high. I’ll also note that any EQ customization/presets and DSEE upscaling are only available in Standard (default) listening mode. Sound and call quality The LinkBuds Clip have both noise reduction and bone conduction tech for calls Billy Steele for Engadget Open-fit earbuds typically struggle to muster adequate low-end tone, and the LinkBuds Clip meets the same fate. However, it’s not all bad in the audio department as these earbuds have great clarity and provide a solid soundstage so overall quality doesn’t suffer to the point of being unpleasant. The lack of bass is most apparent in booming genres, like hip-hop and synth-heavy electronic tunes. The LinkBuds Clip doesn’t fare much better with more chaotic music styles like rock and metal. Spiritbox’s “Holy Roller” doesn’t have the depth that it does on closed-fit earbuds like the AirPods Pro 3 or over-ear headphones like Sony’s WH-1000XM6. As such, the band’s songs aren’t nearly as immersive or impactful without adequate amounts of bass. So if pristine, enveloping sound quality is your primary aim, you’ll want to look elsewhere, and you’ll want to tread carefully with any other open-type earbuds. The open nature of the LinkBuds Clip makes them well-suited for calls. Since your ears aren’t plugged, you can clearly hear your own voice so you never feel like you need to shout. Sony says these earbuds have AI noise reduction and a bone conduction sensor for voice pickup, both of which are supposed to keep you sounding good. During the course of this review, I found the background noise reduction worked well without making me sound overly processed. However, the overall voice quality is average at best, which means you can get by with using these for calls, but there are better options if you really value clarity here. Battery life on the LinkBuds Clip When it comes to battery life, Sony says you can expect up to nine hours of use on a charge with up to 37 hours when you factor in the case. That means the LinkBuds Clip alone is enough to get you through a full workday, especially if you’re pausing for the occasional office chat or in-person meeting. And you’ll get more if you’re docking the earbuds in their case once or twice a day. If you do find yourself with a depleted battery though, a three-minute charge will give you an hour of play time. In multiple attempts at a full, nine-hour run down, I wasn’t able to hit Sony’s stated figure. In Standard mode with DSEE upscaling set to automatic and volume at about 60-70 percent, the LinkBuds Clip lasted just over six hours. This timeframe included a mix of music, podcasts and calls — typical work day activities. The competition The including \"fitting cushion\" (left) can help with a secure fit Billy Steele for Engadget Based on my testing, the Bose Ultra Open Earbuds are still the best in this emerging clip-on category. However, they’re the bulkiest and the most expensive at $299. While they offer all the perks of open wear, sound quality can vary based on how they fit your ears and the lack of multipoint Bluetooth could be a deal breaker for some. If you’re hoping to pay less than either Bose or Sony, Anker’s Soundcore line offers the AeroClip for $170. Or if you’re truly ballin’ on a budget, JLab has the Flex Open Earbuds that are now just $40. JBL just announced a new $150 set during CES too, but those won’t be available until March. I’ve only given these two a casual listen without any in-depth testing, so I won’t make a definitive call on which one stacks up best against the LinkBuds Clip. But they’re also just three of currently available options, and there are many more if none of these seem compelling. Wrap-up The LinkBuds Clip expands Sony’s midrange lineup with a completely different design that comes with inherent perks. They’re plenty comfortable and exploit the benefits of open-type designs while doing basic earbud functionality well. Subpar bass performance and the omission of some of Sony’s more attractive features (and even some basic ones) mean the company hasn’t done enough to distinguish the Clip from the competition in an obvious way. Sure, these earbuds work as intended without being flashy or overly complicated, but there are plenty of other options that do that too. Update, January 21 2026, 4:45PM ET: After conducting additional battery testing, I still wasn’t able to meet the nine hour figure Sony promises. Due to this, I’ve adjusted the score from a 72 to a 70 to reflect the performance in this area. I’ve also updated the battery life section with more detailed impressions. This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sony-linkbuds-clip-review-open-fit-benefits-arent-enough-to-stand-out-160000140.html?src=rss",
          "content": "I vividly remember when Bose announced the Ultra Open Earbuds. While I applauded the company for trying something different, I wasn’t sure if the clip-on design would take hold. Well, here we are almost two years later and most earbud makers now have something akin to Bose’s fashion experiment. You can now count Sony among those as the company revealed its LinkBuds Clip ($230) open-fit earbuds today. These aren’t the first open-wear earbuds in Sony’s LinkBuds lineup. The company has two generations of the LinkBuds Open (originally called just LinkBuds) under its belt, giving users a more traditional earbud fit with donut-shaped drivers that let ambient sounds in. Now Sony is taking a cue from Bose and others with a clip-on design that attaches securely and comfortably to the ear while leaving the ear canal unobstructed. It’s clear companies believe customers like this type of earbuds, but Sony’s challenge is to make the LinkBuds Clip unique among the growing list of alternatives. Design and fit Sony isn’t offering anything distinctive in terms of design here, but that’s okay. To be fair, I haven’t seen too much innovation in terms of aesthetics in these clip-on-style earbuds. For the most part, they all have similar shapes: two cylindrical cases connected by short, flexible cable. True to its predecessors, Sony put the drivers in a squatty housing while the bulk of the components are in a larger one that sits behind your ear lobe. Sony kept the weight of the LinkBuds Clip low, and it avoided the bulk of the Ultra Open Earbuds. Both of these factors contribute to a very comfortable fit, so the IPX4-rated earbuds can be easily worn all day without becoming a burden. And while I didn’t need them, Sony includes a pair of flexible silicone “fitting cushions” in the box. These clip on to the short, flat cable of the newest LinkBuds for a more secure fit. During my tests, the LinkBuds Clip stayed in place just fine without them, but there also wasn’t any decreased comfort when I did install them. The last design-related item I’ll mention is the touch controls. On the LinkBuds Clip, the flat connector between the two housings accepts taps for playback controls, volume changes, cycling through sound modes and more. You can tap along this area to make an adjustment, and you don’t have to do so right in the center. The LinkBuds Clip were pleasantly responsive during this review, quickly completing the task without delay or repeated taps. That is, except for volume, because you have to keep tapping for that change to happen. LinkBuds Clip features Controls are situated along the connector between the two cylindrical housings Billy Steele for Engadget Sony typically throws a whole host of features at its earbuds. Even though they’re technically the company’s midrange line, the LinkBuds family has a robust set of conveniences that make them well suited for both productivity and leisure. Unfortunately, the LinkBuds Clip doesn’t have as much to offer here. The company gives you the basics, like the ability to fine-tune the tap controls or customize the EQ, and there’s even the Adaptive Audio tool that lets you customize settings based on activity or location (Sony calls them “scenes”). But there are some handy features I’ve come to expect from Sony that are notably absent. The LinkBuds Clip doesn’t support speak-to-chat, Sony’s voice recognition feature that pauses audio and activates ambient sound when you start talking. Quick attention mode, the tool that lowers the volume and lets in ambient sound for brief chats, isn’t here either. These earbuds don’t even have wear detection, and you have to settle for regular ol’ DSEE audio upscaling instead of an enhanced version of that tech. Sony did equip the LinkBuds Clip with unique listening modes meant to enhance the audio performance in two scenarios. First, Voice Boost increases the volume of voices when you’re on a call or listening to podcasts or audiobooks. The company says this is designed for noisy environments where the ambient sound is overly raucous. During my testing, I found the setting to be an extreme treble boost and volume increase — something that’s definitely not well-suited for music. Next, Sound Leakage Reduction dials back high-pitched tones to avoid annoying your neighbors in the office or coffee shop. To me, this is the opposite of Voice Boost, removing the highs for a more mid- and bass-heavy tuning, but it doesn’t sound very good compared to the default setting. Plus, my family wasn’t really able to hear any leakage on the LinkBuds Clip anyway, unless I had the volume cranked uncomfortably high. I’ll also note that any EQ customization/presets and DSEE upscaling are only available in Standard (default) listening mode. Sound and call quality The LinkBuds Clip have both noise reduction and bone conduction tech for calls Billy Steele for Engadget Open-fit earbuds typically struggle to muster adequate low-end tone, and the LinkBuds Clip meets the same fate. However, it’s not all bad in the audio department as these earbuds have great clarity and provide a solid soundstage so overall quality doesn’t suffer to the point of being unpleasant. The lack of bass is most apparent in booming genres, like hip-hop and synth-heavy electronic tunes. The LinkBuds Clip doesn’t fare much better with more chaotic music styles like rock and metal. Spiritbox’s “Holy Roller” doesn’t have the depth that it does on closed-fit earbuds like the AirPods Pro 3 or over-ear headphones like Sony’s WH-1000XM6. As such, the band’s songs aren’t nearly as immersive or impactful without adequate amounts of bass. So if pristine, enveloping sound quality is your primary aim, you’ll want to look elsewhere, and you’ll want to tread carefully with any other open-type earbuds. The open nature of the LinkBuds Clip makes them well-suited for calls. Since your ears aren’t plugged, you can clearly hear your own voice so you never feel like you need to shout. Sony says these earbuds have AI noise reduction and a bone conduction sensor for voice pickup, both of which are supposed to keep you sounding good. During the course of this review, I found the background noise reduction worked well without making me sound overly processed. However, the overall voice quality is average at best, which means you can get by with using these for calls, but there are better options if you really value clarity here. Battery life on the LinkBuds Clip When it comes to battery life, Sony says you can expect up to nine hours of use on a charge with up to 37 hours when you factor in the case. That means the LinkBuds Clip alone is enough to get you through a full workday, especially if you’re pausing for the occasional office chat or in-person meeting. And you’ll get more if you’re docking the earbuds in their case once or twice a day. If you do find yourself with a depleted battery though, a three-minute charge will give you an hour of play time. In multiple attempts at a full, nine-hour run down, I wasn’t able to hit Sony’s stated figure. In Standard mode with DSEE upscaling set to automatic and volume at about 60-70 percent, the LinkBuds Clip lasted just over six hours. This timeframe included a mix of music, podcasts and calls — typical work day activities. The competition The including \"fitting cushion\" (left) can help with a secure fit Billy Steele for Engadget Based on my testing, the Bose Ultra Open Earbuds are still the best in this emerging clip-on category. However, they’re the bulkiest and the most expensive at $299. While they offer all the perks of open wear, sound quality can vary based on how they fit your ears and the lack of multipoint Bluetooth could be a deal breaker for some. If you’re hoping to pay less than either Bose or Sony, Anker’s Soundcore line offers the AeroClip for $170. Or if you’re truly ballin’ on a budget, JLab has the Flex Open Earbuds that are now just $40. JBL just announced a new $150 set during CES too, but those won’t be available until March. I’ve only given these two a casual listen without any in-depth testing, so I won’t make a definitive call on which one stacks up best against the LinkBuds Clip. But they’re also just three of currently available options, and there are many more if none of these seem compelling. Wrap-up The LinkBuds Clip expands Sony’s midrange lineup with a completely different design that comes with inherent perks. They’re plenty comfortable and exploit the benefits of open-type designs while doing basic earbud functionality well. Subpar bass performance and the omission of some of Sony’s more attractive features (and even some basic ones) mean the company hasn’t done enough to distinguish the Clip from the competition in an obvious way. Sure, these earbuds work as intended without being flashy or overly complicated, but there are plenty of other options that do that too. Update, January 21 2026, 4:45PM ET: After conducting additional battery testing, I still wasn’t able to meet the nine hour figure Sony promises. Due to this, I’ve adjusted the score from a 72 to a 70 to reflect the performance in this area. I’ve also updated the battery life section with more detailed impressions. This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sony-linkbuds-clip-review-open-fit-benefits-arent-enough-to-stand-out-160000140.html?src=rss",
          "feed_position": 48,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/DSC_5728.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/kitchen-tech/webers-2026-smart-grill-lineup-includes-the-companys-first-wi-fi-equipped-charcoal-grill-150000097.html",
          "published_at": "Wed, 21 Jan 2026 15:00:00 +0000",
          "title": "Weber's 2026 smart grill lineup includes the company's first Wi-Fi-equipped charcoal grill",
          "standfirst": "Weber has been in the smart grilling game since 2020, dabbling in Wi-Fi connectivity for gas and pellet grills. It has also offered grillers a standalone option for its Weber Connect platform. For 2026, the company is expanding its smart grilling lineup to its original fuel source: charcoal. Today, Weber announced the Performer Smart Charcoal Grill and Kettle Smart Ring, both of which bring Weber Connect control and cooking guidance to charcoal grilling in a more integrated way. The 22-inch Performer Smart Charcoal Grill has a Wi-Fi-enabled LCD controller that regulates grill temperature by adjusting the airflow to lit charcoal. Weber says this grill is well-suited for overnight smoking and longer cooks thanks to this bit of automation. The new Performer also has a so-called Rapidfire Assist mode to get those coals lit faster. The grill can be controlled remotely with the Weber Connect app, which can also keep tabs on any connected food probes. The new Performer is essentially an upgraded version of the Performer Premium, Deluxe and base options that currently exist. You still get the porcelain-enamel finish, adjustable dampers for manual temperature controls and the One-Touch cleaning system for ash removal. The other upgrade is a Weber Works side table and side rail that accommodate the company’s line of accessories. A premium version comes with a cart with storage shelves for $799 while an option with a more basic cart will be $599. Weber also plans to sell non-smart versions for $649 and $449, respectively. The company says the base models will arrive this spring while the premium trims will be available this summer. Weber Kettle Smart RingWeber BlackstoneIf you already have a Weber Kettle and are looking to add a bit of automation to your setup, the Kettle Smart Ring brings temperature control and smart connectivity for $280 this spring. This accessory fits the company’s 22-inch grills and is equipped with an LCD display and knob-based controls. Of course, it also syncs with the Weber Connect app and offers two slots for wired food probes. Another key smart grilling area Weber lags behind its competition is wireless temperature probes, but that changes this spring. The company will debut a $70 Smart Wireless Probe and a $115 version with range booster and charger. These new probes sync with any Weber smart grill, the Weber Connect app or the new Smart Hub Display and Booster ($90) that works on any grill. Weber also built a retractable wired Smart Probe ($40) that can be used to monitor the temperature at the grates. And if you’re loyal to propane, Weber has new options for you too. Updated Genesis Smart Gas Grills have a Sear Zone that can hit temperatures of up to 750 degrees Fahrenheit and a side table that now accommodates Weber Works accessories. It will be available in both propane and natural gas versions — in both three- and four-burner configurations — this spring starting at $999. More affordable Spirit Smart Gas Grills will start at $599 and will also come in three- and four-burner options. Both the Genesis and Spirit smart models work with the Weber Connect app like the rest of the company’s Wi-Fi grills and accessories. This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/webers-2026-smart-grill-lineup-includes-the-companys-first-wi-fi-equipped-charcoal-grill-150000097.html?src=rss",
          "content": "Weber has been in the smart grilling game since 2020, dabbling in Wi-Fi connectivity for gas and pellet grills. It has also offered grillers a standalone option for its Weber Connect platform. For 2026, the company is expanding its smart grilling lineup to its original fuel source: charcoal. Today, Weber announced the Performer Smart Charcoal Grill and Kettle Smart Ring, both of which bring Weber Connect control and cooking guidance to charcoal grilling in a more integrated way. The 22-inch Performer Smart Charcoal Grill has a Wi-Fi-enabled LCD controller that regulates grill temperature by adjusting the airflow to lit charcoal. Weber says this grill is well-suited for overnight smoking and longer cooks thanks to this bit of automation. The new Performer also has a so-called Rapidfire Assist mode to get those coals lit faster. The grill can be controlled remotely with the Weber Connect app, which can also keep tabs on any connected food probes. The new Performer is essentially an upgraded version of the Performer Premium, Deluxe and base options that currently exist. You still get the porcelain-enamel finish, adjustable dampers for manual temperature controls and the One-Touch cleaning system for ash removal. The other upgrade is a Weber Works side table and side rail that accommodate the company’s line of accessories. A premium version comes with a cart with storage shelves for $799 while an option with a more basic cart will be $599. Weber also plans to sell non-smart versions for $649 and $449, respectively. The company says the base models will arrive this spring while the premium trims will be available this summer. Weber Kettle Smart RingWeber BlackstoneIf you already have a Weber Kettle and are looking to add a bit of automation to your setup, the Kettle Smart Ring brings temperature control and smart connectivity for $280 this spring. This accessory fits the company’s 22-inch grills and is equipped with an LCD display and knob-based controls. Of course, it also syncs with the Weber Connect app and offers two slots for wired food probes. Another key smart grilling area Weber lags behind its competition is wireless temperature probes, but that changes this spring. The company will debut a $70 Smart Wireless Probe and a $115 version with range booster and charger. These new probes sync with any Weber smart grill, the Weber Connect app or the new Smart Hub Display and Booster ($90) that works on any grill. Weber also built a retractable wired Smart Probe ($40) that can be used to monitor the temperature at the grates. And if you’re loyal to propane, Weber has new options for you too. Updated Genesis Smart Gas Grills have a Sear Zone that can hit temperatures of up to 750 degrees Fahrenheit and a side table that now accommodates Weber Works accessories. It will be available in both propane and natural gas versions — in both three- and four-burner configurations — this spring starting at $999. More affordable Spirit Smart Gas Grills will start at $599 and will also come in three- and four-burner options. Both the Genesis and Spirit smart models work with the Weber Connect app like the rest of the company’s Wi-Fi grills and accessories. This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/webers-2026-smart-grill-lineup-includes-the-companys-first-wi-fi-equipped-charcoal-grill-150000097.html?src=rss",
          "feed_position": 49,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/weber-2.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/truefoundry-launches-truefailover-to-automatically-reroute-enterprise-ai",
          "published_at": "Wed, 21 Jan 2026 14:00:00 GMT",
          "title": "TrueFoundry launches TrueFailover to automatically reroute enterprise AI traffic during model outages",
          "standfirst": "When OpenAI went down in December, one of TrueFoundry’s customers faced a crisis that had nothing to do with chatbots or content generation. The company uses large language models to help refill prescriptions. Every second of downtime meant thousands of dollars in lost revenue — and patients who could not access their medications on time.TrueFoundry, an enterprise AI infrastructure company, announced Wednesday a new product called TrueFailover designed to prevent exactly that scenario. The system automatically detects when AI providers experience outages, slowdowns, or quality degradation, then seamlessly reroutes traffic to backup models and regions before users notice anything went wrong.\"The challenge is that in the AI world, failover is no longer that simple,\" said Nikunj Bajaj, co-founder and chief executive of TrueFoundry, in an exclusive interview with VentureBeat. \"When you move from one model to another, you also have to consider things like output quality, latency, and whether the prompt even works the same way. In many cases, the prompt needs to be adjusted in real-time to prevent results from degrading. That is not something most teams are set up to manage manually.\"The announcement arrives at a pivotal moment for enterprise AI adoption. Companies have moved far beyond experimentation. AI now powers prescription refills at pharmacies, generates sales proposals, assists software developers, and handles customer support inquiries. When these systems fail, the consequences ripple through entire organizations.Why enterprise AI systems remain dangerously dependent on single providersLarge language models from OpenAI, Anthropic, Google, and other providers have become essential infrastructure for thousands of businesses. But unlike traditional cloud services from Amazon Web Services or Microsoft Azure — which offer robust uptime guarantees backed by decades of operational experience — AI providers operate complex, resource-intensive systems that remain prone to unexpected failures.\"Major LLM providers experience outages, slowdowns, or latency spikes every few weeks or months, and we regularly see the downstream impact on businesses that rely on a single provider,\" Bajaj told VentureBeat.The December OpenAI outage that affected TrueFoundry&#x27;s pharmacy customer illustrates the stakes. \"At their scale, even seconds of downtime can translate into thousands of dollars in lost revenue,\" Bajaj explained. \"Beyond the economic impact, there is also a human consequence when patients cannot access prescriptions on time. Because this customer had our failover solution in place, they were able to reroute requests to another model provider within minutes of detecting the outage. Without that setup, recovery would likely have taken hours.\"The problem extends beyond complete outages. Partial failures — where a model slows down or produces lower-quality responses without going fully offline — can quietly destroy user experience and violate service-level agreements. These \"slow but technically up\" scenarios often prove more damaging than dramatic crashes because they evade traditional monitoring systems while steadily eroding performance.Inside the technology that keeps AI applications online when providers failTrueFailover operates as a resilience layer on top of TrueFoundry&#x27;s AI Gateway, which already processes more than 10 billion requests per month for Fortune 1000 companies. The system weaves together several interconnected capabilities into a unified safety net for enterprise AI.At its core, the product enables multi-model failover by allowing enterprises to define primary and backup models across providers. If OpenAI becomes unavailable, traffic automatically shifts to Anthropic, Google&#x27;s Gemini, Mistral, or self-hosted alternatives. The routing happens transparently, without requiring application teams to rewrite code or manually intervene.The system extends this protection across geographic boundaries through multi-region and multi-cloud resilience. By distributing AI endpoints across zones and cloud providers, health-based routing can detect problems in specific regions and divert traffic to healthy alternatives. What would otherwise become a global incident transforms into an invisible infrastructure adjustment that users never perceive.Perhaps most critically, TrueFailover employs degradation-aware routing that continuously monitors latency, error rates, and quality signals. \"We look at a combination of signals that together indicate when a model&#x27;s performance is starting to degrade,\" Bajaj explained. \"Large language models are shared resources. Providers run the same model instance across many customers, so when demand spikes for one user or workload, it can affect everyone else using that model.\"The system watches for rising response times, increasing error rates, and patterns suggesting instability. \"Individually, none of these signals tell the full story,\" Bajaj said. \"But taken together, they allow us to detect early signs that a model is slowing down or becoming unreliable. Those signals feed into an AI-driven system that can decide when and how to reroute traffic before users experience a noticeable drop in quality.\"Strategic caching rounds out the protection by shielding providers from sudden traffic spikes and preventing rate-limit cascades during high-demand periods. This allows systems to absorb demand surges and provider limits without brownouts or throttling surprises.The approach represents a fundamental shift in how enterprises should think about AI reliability. \"TrueFailover is designed to handle that complexity automatically,\" Bajaj said. \"It continuously monitors how models behave across many customers and use cases, looks for early warning signs like rising latency, and takes action before things break. Most individual enterprises do not have that kind of visibility because they are only able to see their own systems.\"The engineering challenge of switching models without sacrificing output qualityOne of the thorniest challenges in AI failover involves maintaining consistent output quality when switching between models. A prompt optimized for GPT-5 may produce different results on Claude or Gemini. TrueFoundry addresses this through several mechanisms that balance speed against precision.\"Some teams rely on the fact that large models have become good enough that small differences in prompts do not materially affect the output,\" Bajaj explained. \"In those cases, switching from one provider to another can happen with some visible impact — that&#x27;s not ideal, but some teams choose to do it.\"More sophisticated implementations maintain provider-specific prompts for the same application. \"When traffic shifts from one model to another, the prompt shifts with it,\" Bajaj said. \"In that case, failover is not just switching models. It is switching to a configuration that has already been tested.\"TrueFailover automates this process. The system dynamically routes requests and adjusts prompts based on which model handles the query, keeping quality within acceptable ranges without manual intervention. The key, Bajaj emphasized, is that \"failover is planned, not reactive. The logic, prompts, and guardrails are defined ahead of time, which is why end users typically do not notice when a switch happens.\"Importantly, many failover scenarios do not require changing providers at all. \"It can be routing traffic from the same model in one region to another region, such as from the East Coast to the West Coast, where no prompt changes are required,\" Bajaj noted. This geographic flexibility provides a first line of defense before more complex cross-provider switches become necessary.How regulated industries can use AI failover without compromising complianceFor enterprises in healthcare, financial services, and other regulated sectors, the prospect of AI traffic automatically routing to different providers raises immediate compliance concerns. Patient data cannot simply flow to whichever model happens to be available. Financial records require strict controls over where they travel. TrueFoundry built explicit guardrails to address these constraints.\"TrueFailover will never route data to a model or provider that an enterprise has not explicitly approved,\" Bajaj said. \"Everything is controlled through an admin configuration layer where teams set clear guardrails upfront.\"Enterprises define exactly which models qualify for failover, which providers can receive traffic, and even which regions or model categories — such as closed-source versus open-source — are acceptable. Once those rules take effect, TrueFailover operates only within them.\"If a model is not on the approved list, it is simply not an option for routing,\" Bajaj emphasized. \"There is no scenario where traffic is automatically sent somewhere unexpected. The idea is to give teams full control over compliance and data boundaries, while still allowing the system to respond quickly when something goes wrong. That way, reliability improves without compromising security or regulatory requirements.\"This design reflects lessons learned from TrueFoundry&#x27;s existing enterprise deployments. A Fortune 50 healthcare company already uses the platform to handle more than 500 million IVR calls annually through an agentic AI system. That customer required the ability to run workloads across both cloud and on-premise infrastructure while maintaining strict data residency controls — exactly the kind of hybrid environment where failover policies must be precisely defined.Where automatic failover cannot help and what enterprises must plan forTrueFoundry acknowledges that TrueFailover cannot solve every reliability problem. The system operates within the guardrails enterprises configure, and those configurations determine what protection is possible.\"If a team allows failover from a large, high-capacity model to a much smaller model without adjusting prompts or expectations, TrueFailover cannot guarantee the same output quality,\" Bajaj explained. \"The system can route traffic, but it cannot make a smaller model behave like a larger one without appropriate configuration.\"Infrastructure constraints also limit protection. If an enterprise hosts its own models and all of them run on the same GPU cluster, TrueFailover cannot help when that infrastructure fails. \"When there is no alternate infrastructure available, there is nothing to fail over to,\" Bajaj said.The question of simultaneous multi-provider failures occasionally surfaces in enterprise risk discussions. Bajaj argues this scenario, while theoretically possible, rarely matches reality. \"In practice, &#x27;going down&#x27; usually does not mean an entire provider is offline across all models and regions,\" he explained. \"What happens far more often is a slowdown or disruption in a specific model or region because of traffic spikes or capacity issues.\"When that occurs, failover can happen at multiple levels — from on-premise to cloud, cloud to on-premise, one region to another, one model to another, or even within the same provider before switching providers entirely. \"That alone makes it very unlikely that everything fails at once,\" Bajaj said. \"The key point is that reliability is built on layers of redundancy. The more providers, regions, and models that are included in the guardrails, the smaller the chance that users experience a complete outage.\"A startup that built its platform inside Fortune 500 AI deploymentsTrueFoundry has established itself as infrastructure for some of the world&#x27;s largest AI deployments, providing crucial context for its failover ambitions. The company raised $19 million in Series A funding in February 2025, led by Intel Capital with participation from Eniac Ventures, Peak XV Partners, and Jump Capital. Angel investors including Gokul Rajaram and Mohit Aron also joined the round, bringing total funding to $21 million.The San Francisco-based company was founded in 2021 by Bajaj and co-founders Abhishek Choudhary and Anuraag Gutgutia, all former Meta engineers who met as classmates at IIT Kharagpur. Initially focused on accelerating machine learning deployments, TrueFoundry pivoted to support generative AI capabilities as the technology went mainstream in 2023.The company&#x27;s customer roster demonstrates enterprise-scale adoption that few AI infrastructure startups can match. Nvidia employs TrueFoundry to build multi-agent systems that optimize GPU cluster utilization across data centers worldwide — a use case where even small improvements in utilization translate into substantial business impact given the insatiable demand for GPU capacity. Adopt AI routes more than 15 million requests and 40 billion input tokens through TrueFoundry&#x27;s AI Gateway to power its enterprise agentic workflows.Gaming company Games 24x7 serves machine learning models to more than 100 million users through the platform at scales exceeding 200 requests per second. Digital adoption platform Whatfix migrated to a microservices architecture on TrueFoundry, reducing its release cycle sixfold and cutting testing time by 40 percent.TrueFoundry currently reports more than 30 paid customers worldwide and has indicated it exceeded $1.5 million in annual recurring revenue last year while quadrupling its customer base. The company manages more than 1,000 clusters for machine learning workloads across its client base.TrueFailover will be offered as an add-on module on top of the existing TrueFoundry AI Gateway and platform, with pricing following a usage-based model tied to traffic volume along with the number of users, models, providers, and regions involved. An early access program for design partners opens in the coming weeks.Why traditional cloud uptime guarantees may never apply to AI providersEnterprise technology buyers have long demanded uptime commitments from infrastructure providers. Amazon Web Services, Microsoft Azure, and Google Cloud all offer service-level agreements with financial penalties for failures. Will AI providers eventually face similar expectations?Bajaj sees fundamental constraints that make traditional SLAs difficult to achieve in the current generation of AI infrastructure. \"Most foundational LLMs today operate as shared resources, which is what enables the standard pricing you see publicly advertised,\" he explained. \"Providers do offer higher uptime commitments, but that usually means dedicated capacity or reserved infrastructure, and the cost increases significantly.\"Even with substantial budgets, enterprises face usage quotas that create unexpected exposure. \"If traffic spikes beyond those limits, requests can still spill back into shared infrastructure,\" Bajaj said. \"That makes it hard to achieve the kind of hard guarantees enterprises are used to with cloud providers.\"The economics of running large language models create additional barriers that may persist for years. \"LLMs are still extremely complex and expensive to run. They require massive infrastructure and energy, and we do not expect a near-term future where most companies run multiple, fully dedicated model instances just to guarantee uptime.\"This reality drives demand for solutions like TrueFailover that provide resilience regardless of what individual providers can promise. \"Enterprises are realizing that reliability cannot come from the model provider alone,\" Bajaj said. \"It requires additional layers of protection to handle the realities of how these systems operate today.\"The new calculus for companies that built AI into critical business processesThe timing of TrueFoundry&#x27;s announcement reflects a fundamental shift in how enterprises use AI — and what they stand to lose when it fails. What began as internal experimentation has evolved into customer-facing applications where disruptions directly affect revenue and reputation.\"Many enterprises experimented with Gen AI and agentic systems in the past, and production use cases were largely internal-facing,\" Bajaj observed. \"There was no immediate impact on their top line or the public perception of the enterprise.\"That era has ended. \"Now that these enterprises have launched public-facing applications, where both the top line and public perception can be impacted if an outage occurs, the stakes are much higher than they were even six months ago. That&#x27;s why we are seeing more and more attention on this now.\"For companies that have woven AI into critical business processes — from prescription refills to customer support to sales operations — the calculus has changed entirely. The question is no longer which model performs best on benchmarks or which provider offers the most compelling features. The question that now keeps technology leaders awake is far simpler and far more urgent: what happens when the AI disappears at the worst possible moment?Somewhere, a pharmacist is filling a prescription. A customer support agent is resolving a complaint. A sales team is generating a proposal for a deal that closes tomorrow. All of them depend on AI systems that depend on providers that, despite their scale and sophistication, still go dark without warning.TrueFoundry is betting that enterprises will pay handsomely to ensure those moments of darkness never reach the people who matter most — their customers.",
          "content": "When OpenAI went down in December, one of TrueFoundry’s customers faced a crisis that had nothing to do with chatbots or content generation. The company uses large language models to help refill prescriptions. Every second of downtime meant thousands of dollars in lost revenue — and patients who could not access their medications on time.TrueFoundry, an enterprise AI infrastructure company, announced Wednesday a new product called TrueFailover designed to prevent exactly that scenario. The system automatically detects when AI providers experience outages, slowdowns, or quality degradation, then seamlessly reroutes traffic to backup models and regions before users notice anything went wrong.\"The challenge is that in the AI world, failover is no longer that simple,\" said Nikunj Bajaj, co-founder and chief executive of TrueFoundry, in an exclusive interview with VentureBeat. \"When you move from one model to another, you also have to consider things like output quality, latency, and whether the prompt even works the same way. In many cases, the prompt needs to be adjusted in real-time to prevent results from degrading. That is not something most teams are set up to manage manually.\"The announcement arrives at a pivotal moment for enterprise AI adoption. Companies have moved far beyond experimentation. AI now powers prescription refills at pharmacies, generates sales proposals, assists software developers, and handles customer support inquiries. When these systems fail, the consequences ripple through entire organizations.Why enterprise AI systems remain dangerously dependent on single providersLarge language models from OpenAI, Anthropic, Google, and other providers have become essential infrastructure for thousands of businesses. But unlike traditional cloud services from Amazon Web Services or Microsoft Azure — which offer robust uptime guarantees backed by decades of operational experience — AI providers operate complex, resource-intensive systems that remain prone to unexpected failures.\"Major LLM providers experience outages, slowdowns, or latency spikes every few weeks or months, and we regularly see the downstream impact on businesses that rely on a single provider,\" Bajaj told VentureBeat.The December OpenAI outage that affected TrueFoundry&#x27;s pharmacy customer illustrates the stakes. \"At their scale, even seconds of downtime can translate into thousands of dollars in lost revenue,\" Bajaj explained. \"Beyond the economic impact, there is also a human consequence when patients cannot access prescriptions on time. Because this customer had our failover solution in place, they were able to reroute requests to another model provider within minutes of detecting the outage. Without that setup, recovery would likely have taken hours.\"The problem extends beyond complete outages. Partial failures — where a model slows down or produces lower-quality responses without going fully offline — can quietly destroy user experience and violate service-level agreements. These \"slow but technically up\" scenarios often prove more damaging than dramatic crashes because they evade traditional monitoring systems while steadily eroding performance.Inside the technology that keeps AI applications online when providers failTrueFailover operates as a resilience layer on top of TrueFoundry&#x27;s AI Gateway, which already processes more than 10 billion requests per month for Fortune 1000 companies. The system weaves together several interconnected capabilities into a unified safety net for enterprise AI.At its core, the product enables multi-model failover by allowing enterprises to define primary and backup models across providers. If OpenAI becomes unavailable, traffic automatically shifts to Anthropic, Google&#x27;s Gemini, Mistral, or self-hosted alternatives. The routing happens transparently, without requiring application teams to rewrite code or manually intervene.The system extends this protection across geographic boundaries through multi-region and multi-cloud resilience. By distributing AI endpoints across zones and cloud providers, health-based routing can detect problems in specific regions and divert traffic to healthy alternatives. What would otherwise become a global incident transforms into an invisible infrastructure adjustment that users never perceive.Perhaps most critically, TrueFailover employs degradation-aware routing that continuously monitors latency, error rates, and quality signals. \"We look at a combination of signals that together indicate when a model&#x27;s performance is starting to degrade,\" Bajaj explained. \"Large language models are shared resources. Providers run the same model instance across many customers, so when demand spikes for one user or workload, it can affect everyone else using that model.\"The system watches for rising response times, increasing error rates, and patterns suggesting instability. \"Individually, none of these signals tell the full story,\" Bajaj said. \"But taken together, they allow us to detect early signs that a model is slowing down or becoming unreliable. Those signals feed into an AI-driven system that can decide when and how to reroute traffic before users experience a noticeable drop in quality.\"Strategic caching rounds out the protection by shielding providers from sudden traffic spikes and preventing rate-limit cascades during high-demand periods. This allows systems to absorb demand surges and provider limits without brownouts or throttling surprises.The approach represents a fundamental shift in how enterprises should think about AI reliability. \"TrueFailover is designed to handle that complexity automatically,\" Bajaj said. \"It continuously monitors how models behave across many customers and use cases, looks for early warning signs like rising latency, and takes action before things break. Most individual enterprises do not have that kind of visibility because they are only able to see their own systems.\"The engineering challenge of switching models without sacrificing output qualityOne of the thorniest challenges in AI failover involves maintaining consistent output quality when switching between models. A prompt optimized for GPT-5 may produce different results on Claude or Gemini. TrueFoundry addresses this through several mechanisms that balance speed against precision.\"Some teams rely on the fact that large models have become good enough that small differences in prompts do not materially affect the output,\" Bajaj explained. \"In those cases, switching from one provider to another can happen with some visible impact — that&#x27;s not ideal, but some teams choose to do it.\"More sophisticated implementations maintain provider-specific prompts for the same application. \"When traffic shifts from one model to another, the prompt shifts with it,\" Bajaj said. \"In that case, failover is not just switching models. It is switching to a configuration that has already been tested.\"TrueFailover automates this process. The system dynamically routes requests and adjusts prompts based on which model handles the query, keeping quality within acceptable ranges without manual intervention. The key, Bajaj emphasized, is that \"failover is planned, not reactive. The logic, prompts, and guardrails are defined ahead of time, which is why end users typically do not notice when a switch happens.\"Importantly, many failover scenarios do not require changing providers at all. \"It can be routing traffic from the same model in one region to another region, such as from the East Coast to the West Coast, where no prompt changes are required,\" Bajaj noted. This geographic flexibility provides a first line of defense before more complex cross-provider switches become necessary.How regulated industries can use AI failover without compromising complianceFor enterprises in healthcare, financial services, and other regulated sectors, the prospect of AI traffic automatically routing to different providers raises immediate compliance concerns. Patient data cannot simply flow to whichever model happens to be available. Financial records require strict controls over where they travel. TrueFoundry built explicit guardrails to address these constraints.\"TrueFailover will never route data to a model or provider that an enterprise has not explicitly approved,\" Bajaj said. \"Everything is controlled through an admin configuration layer where teams set clear guardrails upfront.\"Enterprises define exactly which models qualify for failover, which providers can receive traffic, and even which regions or model categories — such as closed-source versus open-source — are acceptable. Once those rules take effect, TrueFailover operates only within them.\"If a model is not on the approved list, it is simply not an option for routing,\" Bajaj emphasized. \"There is no scenario where traffic is automatically sent somewhere unexpected. The idea is to give teams full control over compliance and data boundaries, while still allowing the system to respond quickly when something goes wrong. That way, reliability improves without compromising security or regulatory requirements.\"This design reflects lessons learned from TrueFoundry&#x27;s existing enterprise deployments. A Fortune 50 healthcare company already uses the platform to handle more than 500 million IVR calls annually through an agentic AI system. That customer required the ability to run workloads across both cloud and on-premise infrastructure while maintaining strict data residency controls — exactly the kind of hybrid environment where failover policies must be precisely defined.Where automatic failover cannot help and what enterprises must plan forTrueFoundry acknowledges that TrueFailover cannot solve every reliability problem. The system operates within the guardrails enterprises configure, and those configurations determine what protection is possible.\"If a team allows failover from a large, high-capacity model to a much smaller model without adjusting prompts or expectations, TrueFailover cannot guarantee the same output quality,\" Bajaj explained. \"The system can route traffic, but it cannot make a smaller model behave like a larger one without appropriate configuration.\"Infrastructure constraints also limit protection. If an enterprise hosts its own models and all of them run on the same GPU cluster, TrueFailover cannot help when that infrastructure fails. \"When there is no alternate infrastructure available, there is nothing to fail over to,\" Bajaj said.The question of simultaneous multi-provider failures occasionally surfaces in enterprise risk discussions. Bajaj argues this scenario, while theoretically possible, rarely matches reality. \"In practice, &#x27;going down&#x27; usually does not mean an entire provider is offline across all models and regions,\" he explained. \"What happens far more often is a slowdown or disruption in a specific model or region because of traffic spikes or capacity issues.\"When that occurs, failover can happen at multiple levels — from on-premise to cloud, cloud to on-premise, one region to another, one model to another, or even within the same provider before switching providers entirely. \"That alone makes it very unlikely that everything fails at once,\" Bajaj said. \"The key point is that reliability is built on layers of redundancy. The more providers, regions, and models that are included in the guardrails, the smaller the chance that users experience a complete outage.\"A startup that built its platform inside Fortune 500 AI deploymentsTrueFoundry has established itself as infrastructure for some of the world&#x27;s largest AI deployments, providing crucial context for its failover ambitions. The company raised $19 million in Series A funding in February 2025, led by Intel Capital with participation from Eniac Ventures, Peak XV Partners, and Jump Capital. Angel investors including Gokul Rajaram and Mohit Aron also joined the round, bringing total funding to $21 million.The San Francisco-based company was founded in 2021 by Bajaj and co-founders Abhishek Choudhary and Anuraag Gutgutia, all former Meta engineers who met as classmates at IIT Kharagpur. Initially focused on accelerating machine learning deployments, TrueFoundry pivoted to support generative AI capabilities as the technology went mainstream in 2023.The company&#x27;s customer roster demonstrates enterprise-scale adoption that few AI infrastructure startups can match. Nvidia employs TrueFoundry to build multi-agent systems that optimize GPU cluster utilization across data centers worldwide — a use case where even small improvements in utilization translate into substantial business impact given the insatiable demand for GPU capacity. Adopt AI routes more than 15 million requests and 40 billion input tokens through TrueFoundry&#x27;s AI Gateway to power its enterprise agentic workflows.Gaming company Games 24x7 serves machine learning models to more than 100 million users through the platform at scales exceeding 200 requests per second. Digital adoption platform Whatfix migrated to a microservices architecture on TrueFoundry, reducing its release cycle sixfold and cutting testing time by 40 percent.TrueFoundry currently reports more than 30 paid customers worldwide and has indicated it exceeded $1.5 million in annual recurring revenue last year while quadrupling its customer base. The company manages more than 1,000 clusters for machine learning workloads across its client base.TrueFailover will be offered as an add-on module on top of the existing TrueFoundry AI Gateway and platform, with pricing following a usage-based model tied to traffic volume along with the number of users, models, providers, and regions involved. An early access program for design partners opens in the coming weeks.Why traditional cloud uptime guarantees may never apply to AI providersEnterprise technology buyers have long demanded uptime commitments from infrastructure providers. Amazon Web Services, Microsoft Azure, and Google Cloud all offer service-level agreements with financial penalties for failures. Will AI providers eventually face similar expectations?Bajaj sees fundamental constraints that make traditional SLAs difficult to achieve in the current generation of AI infrastructure. \"Most foundational LLMs today operate as shared resources, which is what enables the standard pricing you see publicly advertised,\" he explained. \"Providers do offer higher uptime commitments, but that usually means dedicated capacity or reserved infrastructure, and the cost increases significantly.\"Even with substantial budgets, enterprises face usage quotas that create unexpected exposure. \"If traffic spikes beyond those limits, requests can still spill back into shared infrastructure,\" Bajaj said. \"That makes it hard to achieve the kind of hard guarantees enterprises are used to with cloud providers.\"The economics of running large language models create additional barriers that may persist for years. \"LLMs are still extremely complex and expensive to run. They require massive infrastructure and energy, and we do not expect a near-term future where most companies run multiple, fully dedicated model instances just to guarantee uptime.\"This reality drives demand for solutions like TrueFailover that provide resilience regardless of what individual providers can promise. \"Enterprises are realizing that reliability cannot come from the model provider alone,\" Bajaj said. \"It requires additional layers of protection to handle the realities of how these systems operate today.\"The new calculus for companies that built AI into critical business processesThe timing of TrueFoundry&#x27;s announcement reflects a fundamental shift in how enterprises use AI — and what they stand to lose when it fails. What began as internal experimentation has evolved into customer-facing applications where disruptions directly affect revenue and reputation.\"Many enterprises experimented with Gen AI and agentic systems in the past, and production use cases were largely internal-facing,\" Bajaj observed. \"There was no immediate impact on their top line or the public perception of the enterprise.\"That era has ended. \"Now that these enterprises have launched public-facing applications, where both the top line and public perception can be impacted if an outage occurs, the stakes are much higher than they were even six months ago. That&#x27;s why we are seeing more and more attention on this now.\"For companies that have woven AI into critical business processes — from prescription refills to customer support to sales operations — the calculus has changed entirely. The question is no longer which model performs best on benchmarks or which provider offers the most compelling features. The question that now keeps technology leaders awake is far simpler and far more urgent: what happens when the AI disappears at the worst possible moment?Somewhere, a pharmacist is filling a prescription. A customer support agent is resolving a complaint. A sales team is generating a proposal for a deal that closes tomorrow. All of them depend on AI systems that depend on providers that, despite their scale and sophistication, still go dark without warning.TrueFoundry is betting that enterprises will pay handsomely to ensure those moments of darkness never reach the people who matter most — their customers.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6RXfga7DhprWJByZbNoNyJ/54c08868d8100860ecfb2ea2d9ddd918/nuneybits_Vector_art_of_highway_interchange_at_night_one_road_c_0553d47b-482b-4521-9f16-54b3a908db80.webp?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/1MFFbtmycEjI7XIGStOyEk/b1ac57bcd9e094ed185588182a366f78/dZzvxHXOGs335kAJL9VOe.jpg?w=300&q=30",
      "popularity_score": 2015.116775
    },
    {
      "id": "cluster_34",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 23:07:45 +0000",
      "title": "US officially out of WHO, leaving hundreds of millions of dollars unpaid",
      "neutral_headline": "US officially out of WHO, leaving hundreds of millions of dollars unpaid",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/us-stiffs-who-hundreds-of-millions-as-it-officially-withdrawals/",
          "published_at": "Thu, 22 Jan 2026 23:07:45 +0000",
          "title": "US officially out of WHO, leaving hundreds of millions of dollars unpaid",
          "standfirst": "US did not pay $278 million in 2024–2025 dues and millions more in promised funds.",
          "content": "As of today, the US is no longer a member of the World Health Organization—and it leaves the United Nations health agency with hundreds of millions of dollars in unpaid bills, according to reporting by Stat News. A year ago today, the US informed the WHO of its intent to exit, setting the clock for a one-year withdrawal period mandated in a 1948 joint resolution of Congress. But, in practice, the withdrawal was immediate, with the Trump administration cutting all ties with WHO upon the announcement. In explaining his reasoning for leaving the WHO, Trump referenced his long-standing complaints about the agency’s handling of the COVID-19 pandemic, dues payments, and alleged protection of China. Trump had attempted extract the US from WHO during his first term, but the Biden administration rescinded the withdrawal on the first day in office, well before the one-year notice period was reached. The joint resolution also stipulated that the US would have to pay its financial obligations in full before departing. But, that too has not been honored by the Trump administration. According to Stat, the US owed the WHO $278 million in dues, which are a percentage of each member state’s gross domestic product. That dues payment covered the country's 2024–2025 membership, as WHO runs on a two-year budget cycle.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/05/GettyImages-1250822831-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/05/GettyImages-1250822831-1152x648.jpeg",
      "popularity_score": 359.69594166666667
    },
    {
      "id": "cluster_35",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 22:46:30 +0000",
      "title": "Overrun with AI slop, cURL scraps bug bounties to ensure \"intact mental health\"",
      "neutral_headline": "Overrun with AI slop, cURL scraps bug bounties to ensure \"intact mental health\"",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/overrun-with-ai-slop-curl-scraps-bug-bounties-to-ensure-intact-mental-health/",
          "published_at": "Thu, 22 Jan 2026 22:46:30 +0000",
          "title": "Overrun with AI slop, cURL scraps bug bounties to ensure \"intact mental health\"",
          "standfirst": "The onslaught includes LLMs finding bogus vulnerabilities and code that won't compile.",
          "content": "The project developer for one of the Internet’s most popular networking tools is scrapping its vulnerability reward program after being overrun by a spike in the submission of low-quality reports, much of it AI-generated slop. “We are just a small single open source project with a small number of active maintainers,” Daniel Stenberg, the founder and lead developer of the open source app cURL, said Thursday. “It is not in our power to change how all these people and their slop machines work. We need to make moves to ensure our survival and intact mental health.” Manufacturing bogus bugs His comments came as cURL users complained that the move was treating the symptoms caused by AI slop without addressing the cause. The users said they were concerned the move would eliminate a key means for ensuring and maintaining the security of the tool. Stenberg largely agreed, but indicated his team had little choice.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-1152x648.jpg",
      "popularity_score": 349.341775
    },
    {
      "id": "cluster_52",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 21:32:28 +0000",
      "title": "Report: Apple plans to launch AI-powered wearable pin device as soon as 2027",
      "neutral_headline": "Report: Apple plans to launch AI-powered wearable pin device as soon as 2027",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/apple/2026/01/report-apple-plans-to-launch-ai-powered-wearable-pin-device-as-soon-as-2027/",
          "published_at": "Thu, 22 Jan 2026 21:32:28 +0000",
          "title": "Report: Apple plans to launch AI-powered wearable pin device as soon as 2027",
          "standfirst": "Apple, OpenAI, Meta, and more are all racing toward AI hardware products.",
          "content": "Apple is working on a wearable device that will allow the user to take advantage of AI models, according to sources familiar with the product who spoke with tech publication The Information. The product is said to be \"the same size as an AirTag, only slightly thicker,\" and will be worn as a pin, inviting comparisons to the failed Humane AI pin that launched to bad reviews and lackluster sales in 2024. The Humane product was criticized for sluggish performance and low battery life, but those shortcomings could potentially be addressed by Apple's solution, should Apple offload the processing to a synced external device like an iPhone. The Information's sources don't specify whether that's the plan, or if it will be a standalone device.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-1152x648.png",
      "popularity_score": 346.1078861111111
    },
    {
      "id": "cluster_41",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 22:23:15 +0000",
      "title": "Hacker who stole 120,000 bitcoins wants a second chance—and a security job",
      "neutral_headline": "Hacker who stole 120,000 bitcoins wants a second chance—and a security job",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/hacker-who-stole-120000-bitcoins-wants-a-second-chance-and-a-security-job/",
          "published_at": "Thu, 22 Jan 2026 22:23:15 +0000",
          "title": "Hacker who stole 120,000 bitcoins wants a second chance—and a security job",
          "standfirst": "Crypto theft was \"the worst thing I had ever done.\"",
          "content": "On Thursday, Ilya Lichtenstein, who was at the center of a massive 2016 crypto heist worth billions at the time, wrote online that he is now out of prison and has changed his ways. “Ten years ago, I decided that I would hack the largest cryptocurrency exchange in the world,” Lichtenstein wrote on LinkedIn, detailing a time when his startup was barely making money and he decided to steal some instead. “This was a terrible idea. It was the worst thing I had ever done,” he added. “It upended my life, the lives of people close to me, and affected thousands of users of the exchange. I know I disappointed a lot of people who believed in me and grossly misused my talents.”Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/04/getty-hacker-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/04/getty-hacker-1152x648.jpg",
      "popularity_score": 341.954275
    },
    {
      "id": "cluster_59",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 20:46:10 +0000",
      "title": "Google begins offering free SAT practice tests powered by Gemini",
      "neutral_headline": "Google begins offering free SAT practice tests powered by Gemini",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/01/google-begins-offering-free-sat-practice-tests-powered-by-gemini/",
          "published_at": "Thu, 22 Jan 2026 20:46:10 +0000",
          "title": "Google begins offering free SAT practice tests powered by Gemini",
          "standfirst": "Google says more kinds of standardized tests will be added in the future.",
          "content": "It's no secret that students worldwide use AI chatbots to do their homework and avoid learning things. On the flip side, students can also use AI as a tool to beef up their knowledge and plan for the future with flashcards or study guides. Google hopes its latest Gemini feature will help with the latter. The company has announced that Gemini can now create free SAT practice tests and coach students to help them get higher scores. As a standardized test, the content of the SAT follows a predictable pattern. So there's no need to use a lengthy, personalized prompt to get Gemini going. Just say something like, \"I want to take a practice SAT test,\" and the chatbot will generate one complete with clickable buttons, graphs, and score analysis. Of course, generative AI can go off the rails and provide incorrect information, which is a problem when you're trying to learn things. However, Google says it has worked with education firms like The Princeton Review to ensure the AI-generated tests resemble what students will see in the real deal.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-1152x648.jpg",
      "popularity_score": 309.33621944444445
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 21:16:42 +0000",
      "title": "Asking Grok to delete fake nudes may force victims to sue in Musk's chosen court",
      "neutral_headline": "Asking Grok to delete fake nudes may force victims to sue in Musk's chosen court",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/asking-grok-to-delete-fake-nudes-may-force-victims-to-sue-in-musks-chosen-court/",
          "published_at": "Thu, 22 Jan 2026 21:16:42 +0000",
          "title": "Asking Grok to delete fake nudes may force victims to sue in Musk's chosen court",
          "standfirst": "Millions likely harmed by Grok-edited sex images as X advertisers shrugged.",
          "content": "Journalists and advocates have been trying to grasp how many victims in total were harmed by Grok's nudifying scandal after xAI delayed restricting outputs and app stores refused to cut off access for days. The latest estimates show that perhaps millions were harmed in the days immediately after Elon Musk promoted Grok's undressing feature on his own X feed by posting a pic of himself in a bikini. Over just 11 days after Musk's post, Grok sexualized more than 3 million images, of which 23,000 were of children, the Center for Countering Digital Hate (CCDH) estimated in research published Thursday.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-1024x648.jpg",
      "popularity_score": 302.8451083333333
    },
    {
      "id": "cluster_70",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 19:18:34 +0000",
      "title": "Check out the first trailer for Masters of the Universe",
      "neutral_headline": "Check out the first trailer for Masters of the Universe",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/01/check-out-the-first-trailer-for-masters-of-the-universe/",
          "published_at": "Thu, 22 Jan 2026 19:18:34 +0000",
          "title": "Check out the first trailer for Masters of the Universe",
          "standfirst": "\"Talking tigers, spaceships, and magic swords that can make a man as mighty as a god.\"",
          "content": "Ars readers of a certain age no doubt remember the 1980s He-Man and the Masters of the Universe series (and its spinoff, She-Ra: Princess of Powers) and the many, many offshoots of this hugely popular Mattel franchise, including an extensive line of action figures. Amazon MGM Studios no doubt hopes to cash in on any lingering nostalgia with its forthcoming film, Masters of the Universe. Judging by the extended teaser trailer, we're getting an origin story for He-Man. It's not the first time someone has turned He-Man into a feature film: Dolph Lundgren starred in 1987's Masters of the Universe, a critical and box office bomb that also featured Frank Langella as arch-villain Skeletor. Its poor reception might have stemmed from the 1987 film deviating significantly from the original cartoon, angering fans. But frankly, it was just a bad, cheesy movie, though it still has its share of cult fans today. This latest big-screen live-action adaptation has been languishing in development hell for nearly two decades. There were rumors in 2007 that John Woo would direct a He-Man feature for Warner Bros., but the project never got the green light. Sony Pictures gained the rights in 2009, and there were multiple script rewrites and much shuffling of possible directors (with John Chu, McG, and David S. Goyer among the candidates).Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/heman4-1152x648-1769098758.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/heman4-1152x648-1769098758.jpg",
      "popularity_score": 295.8762194444445
    },
    {
      "id": "cluster_98",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 16:35:41 +0000",
      "title": "Google adds your Gmail and Photos to AI Mode to enable \"Personal Intelligence\"",
      "neutral_headline": "Google adds your Gmail and Photos to AI Mode to enable \"Personal Intelligence\"",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/01/google-ai-mode-can-now-customize-responses-with-your-email-and-photos/",
          "published_at": "Thu, 22 Jan 2026 16:35:41 +0000",
          "title": "Google adds your Gmail and Photos to AI Mode to enable \"Personal Intelligence\"",
          "standfirst": "Personal Intelligence is optional and rolling out first to AI Pro and AI Ultra subscribers.",
          "content": "Google believes AI is the future of search, and it's not shy about saying it. After adding account-level personalization to Gemini earlier this month, it's now updating AI Mode with so-called \"Personal Intelligence.\" According to Google, this makes the bot's answers more useful because they are tailored to your personal context. Starting today, the feature is rolling out to all users who subscribe to Google AI Pro or AI Ultra. However, it will be a Labs feature that needs to be explicitly enabled (subscribers will be prompted to do this). Google tends to expand access to new AI features to free accounts later on, so free users will most likely get access to Personal Intelligence in the future. Whenever this option does land on your account, it's entirely optional and can be disabled at any time. If you decide to integrate your data with AI Mode, the search bot will be able to scan your Gmail and Google Photos. That's less extensive than the Gemini app version, which supports Gmail, Photos, Search, and YouTube history. Gmail will probably be the biggest contributor to AI Mode—a great many life events involve confirmation emails. Traditional search results when you are logged in are adjusted based on your usage history, but this goes a step further.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/AI-Mode-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/AI-Mode-1152x648.png",
      "popularity_score": 285.16149722222224
    },
    {
      "id": "cluster_87",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 17:49:24 +0000",
      "title": "Blue Origin makes impressive strides with reuse—next launch will refly booster",
      "neutral_headline": "Blue Origin makes impressive strides with reuse—next launch will refly booster",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/blue-origin-makes-impressive-strides-with-reuse-next-launch-will-refly-booster/",
          "published_at": "Thu, 22 Jan 2026 17:49:24 +0000",
          "title": "Blue Origin makes impressive strides with reuse—next launch will refly booster",
          "standfirst": "With this quick turnaround, Blue Origin takes a step toward a faster cadence.",
          "content": "Blue Origin confirmed Thursday that the next launch of its New Glenn rocket will carry a large communications satellite into low-Earth orbit for AST SpaceMobile. The rocket will launch the next-generation Block 2 BlueBird satellite \"no earlier than late February\" from Launch Complex 36 at Cape Canaveral Space Force Station. However, the update from Blue Origin appears to have buried the real news toward the end: \"The mission follows the successful NG-2 mission, which included the landing of the 'Never Tell Me The Odds' booster. The same booster is being refurbished to power NG-3,\" the company said.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/blue-bird-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/blue-bird-1152x648.jpg",
      "popularity_score": 269.39010833333333
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 16:15:08 +0000",
      "title": "Finally, a new controller that solves the Switch 2's \"flat Joy-Con\" problem",
      "neutral_headline": "Finally, a new controller that solves the Switch 2's \"flat Joy-Con\" problem",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/finally-a-new-controller-that-solves-the-switch-2s-flat-joy-con-problem/",
          "published_at": "Thu, 22 Jan 2026 16:15:08 +0000",
          "title": "Finally, a new controller that solves the Switch 2's \"flat Joy-Con\" problem",
          "standfirst": "But Nyxi's Hyperion 3 upgrade comes with a pretty high asking price.",
          "content": "When I reviewed the Switch 2 back in June, I noted that the lack of any sort of extended grip on the extremely thin Joy-Con 2 controllers made them relatively awkward to hold, both when connected to the system and when cradled in separate hands. At the time, I said that \"my Switch 2 will probably need something like the Nyxi Hyperion Pro, which I’ve come to rely on to make portable play on the original Switch much more comfortable.\" Over half a year later, Nyxi is once again addressing my Switch controller-related comfort concerns with the Hyperion 3, which was made available for preorder earlier this week ahead of planned March 1 shipments. Unfortunately, it looks like players will have to pay a relatively high price for a potentially more ergonomic Switch 2 experience. While there are plenty of third-party controllers for the Switch 2, none of the current options mimic the official Joy-Cons' ability to connect magnetically to the console tablet itself (controllers designed to slide into the grooves on the original Switch tablet also can't hook to the successor console). The Hyperion 3 is the first Switch 2 controller to offer this magnetic connection, making it uniquely suited for handheld play on the system.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/hyperion3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/hyperion3-1152x648.jpg",
      "popularity_score": 247.8189972222222
    },
    {
      "id": "cluster_103",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 15:56:33 +0000",
      "title": "eBay bans illicit automated shopping amid rapid rise of AI agents",
      "neutral_headline": "EBay bans illicit automated shopping amid rapid rise of AI agents",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2026/01/ebay-bans-illicit-automated-shopping-amid-rapid-rise-of-ai-agents/",
          "published_at": "Thu, 22 Jan 2026 15:56:33 +0000",
          "title": "eBay bans illicit automated shopping amid rapid rise of AI agents",
          "standfirst": "New policy requires \"buy for me\" AI tools and chatbots to obtain permission before accessing the platform.",
          "content": "On Tuesday, eBay updated its User Agreement to explicitly ban third-party \"buy for me\" agents and AI chatbots from interacting with its platform without permission, first spotted by Value Added Resource. On its face, a one-line terms of service update doesn't seem like major news, but what it implies is more significant: The change reflects the rapid emergence of what some are calling \"agentic commerce,\" a new category of AI tools designed to browse, compare, and purchase products on behalf of users. eBay's updated terms, which go into effect on February 20, 2026, specifically prohibit users from employing \"buy-for-me agents, LLM-driven bots, or any end-to-end flow that attempts to place orders without human review\" to access eBay's services without the site's permission. The previous version of the agreement contained a general prohibition on robots, spiders, scrapers, and automated data gathering tools but did not mention AI agents or LLMs by name. At first glance, the phrase \"agentic commerce\" may sound like aspirational marketing jargon, but the tools are already here, and people are apparently using them. While fitting loosely under one label, these tools come in many forms.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/robot_shopper_1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/04/robot_shopper_1-1152x648.jpg",
      "popularity_score": 152.509275
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 21:03:02 +0000",
      "title": "Why adding modern controls to 1996's Tomb Raider simply doesn't work",
      "neutral_headline": "Why adding modern controls to 1996's Tomb Raider simply doesn't work",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/01/the-problem-with-revisiting-tomb-raider-reacclimating-to-tank-controls/",
          "published_at": "Wed, 21 Jan 2026 21:03:02 +0000",
          "title": "Why adding modern controls to 1996's Tomb Raider simply doesn't work",
          "standfirst": "For our C:\\ArsGames series, we look at the controls conundrum of early 3D.",
          "content": "For a lot of the games I've written about in the C:\\ArsGames series, I've come to the conclusion that the games hold up pretty well, despite their age—Master of Orion II, Jill of the Jungle, and Wing Commander Privateer, for example. Each of those have flaws that show now more than ever, but I still had a blast revisiting each of them. This time I'd like to write about one that I think doesn't hold up quite as well for me: For the first time in almost 30 years, I revisited the original Tomb Raider via 2024's Tomb Raider I-III Remastered collection. You might be thinking this is going to be a dunk on the work done on the remaster, but that's not the case, because the core issue with playing 1996's Tomb Raider in 2026 is actually unsolvable, no matter how much care is put into a remaster.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Tomb-Raider-hero-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Tomb-Raider-hero-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_128",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 23:33:43 +0000",
      "title": "Judge orders stop to FBI search of devices seized from Washington Post reporter",
      "neutral_headline": "Judge orders stop to FBI search of devices seized from Washington Post reporter",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/judge-orders-stop-to-fbi-search-of-devices-seized-from-washington-post-reporter/",
          "published_at": "Wed, 21 Jan 2026 23:33:43 +0000",
          "title": "Judge orders stop to FBI search of devices seized from Washington Post reporter",
          "standfirst": "Order says gov't must stop search while court reviews Washington Post motions.",
          "content": "A federal judge today ordered the US government to stop searching devices seized from the house of a Washington Post reporter. It may be only a temporary reprieve for the Post and reporter Hannah Natanson, however. Further proceedings will be held on whether the search can resume or whether the government must return the devices. Natanson herself isn't the subject of investigation, but the FBI executed a search warrant at her home and seized her work and personal devices last week as part of an investigation into alleged leaks by a Pentagon contractor. The Post filed a motion to force the return of the reporter's property, and a separate motion for a standstill order that would prevent review of the seized devices until the court rules on whether they must be returned. \"Almost none of the seized data is even potentially responsive to the warrant, which seeks only records received from or relating to a single government contractor,\" a Post court filing today said. \"The seized data is core First Amendment-protected material, and some is protected by the attorney-client privilege.\"Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/judges-gavel-1152x648-1747771043.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/judges-gavel-1152x648-1747771043.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_105",
      "coverage": 1,
      "updated_at": "Thu, 22 Jan 2026 14:41:38 +0000",
      "title": "All sorts of interesting flags and artifacts will fly to the Moon on Artemis II",
      "neutral_headline": "All sorts of interesting flags and artifacts will fly to the Moon on Artemis II",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/01/nasa-to-fly-apollo-aviation-artifacts-on-artemis-ii/",
          "published_at": "Thu, 22 Jan 2026 14:41:38 +0000",
          "title": "All sorts of interesting flags and artifacts will fly to the Moon on Artemis II",
          "standfirst": "More than 2,300 commemorative items fill the duffel bag-size pouch.",
          "content": "NASA's first astronauts to fly to the Moon in more than 50 years will pay tribute to the lunar and space exploration missions that preceded them, as well as aviation and American history, by taking with them artifacts and mementos representing those past accomplishments. NASA, on Wednesday, January 21, revealed the contents of the Artemis II mission's Official Flight Kit (OFK), continuing a tradition dating back to the Apollo program of packing a duffel bag-sized pouch of symbolic and celebratory items to commemorate the flight and recognize the people behind it. The kit includes more than 2,300 items, including a handful of relics. \"This mission will bring together pieces of our earliest achievements in aviation, defining moments from human spaceflight and symbols of where we're headed next,\" Jared Isaacman, NASA's administrator, said in a statement. \"Historical artifacts flying aboard Artemis II reflect the long arc of American exploration and the generations of innovators who made this moment possible.\"Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/news-012226a-lg-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/news-012226a-lg-1-1152x648.jpg",
      "popularity_score": 136.2606638888889
    },
    {
      "id": "cluster_129",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 23:22:14 +0000",
      "title": "Millions of people imperiled through sign-in links sent by SMS",
      "neutral_headline": "Millions of people imperiled through sign-in links sent by SMS",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/01/millions-of-people-imperiled-through-sign-in-links-sent-by-sms/",
          "published_at": "Wed, 21 Jan 2026 23:22:14 +0000",
          "title": "Millions of people imperiled through sign-in links sent by SMS",
          "standfirst": "Even well-known services with millions of users are exposing sensitive data.",
          "content": "Websites that authenticate users through links and codes sent in text messages are imperiling the privacy of millions of people, leaving them vulnerable to scams, identity theft, and other crimes, recently published research has found. The links are sent to people seeking a range of services, including those offering insurance quotes, job listings, and referrals for pet sitters and tutors. To eliminate the hassle of collecting usernames and passwords—and for users to create and enter them—many such services instead require users to provide a cell phone number when signing up for an account. The services then send authentication links or passcodes by SMS when the users want to log in. Easy to execute at scale A paper published last week has found more than 700 endpoints delivering such texts on behalf of more than 175 services that put user security and privacy at risk. One practice that jeopardizes users is the use of links that are easily enumerated, meaning scammers can guess them by simply modifying the security token, which usually appears at the right of a URL. By incrementing or randomly guessing the token—for instance, by first changing 123 to 124 or ABC to ABD and so on—the researchers were able to access accounts belonging to other users. From there, the researchers could view personal details, such as partially completed insurance applications.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/sms-phone-risk-trap-privacy-security-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/sms-phone-risk-trap-privacy-security-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 22:51:26 +0000",
      "title": "mRNA cancer vaccine shows protection at 5-year follow-up, Moderna and Merck say",
      "neutral_headline": "MRNA cancer vaccine shows protection at 5-year follow-up, Moderna and Merck say",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/01/mrna-cancer-vaccine-shows-protection-at-5-year-follow-up-moderna-and-merck-say/",
          "published_at": "Wed, 21 Jan 2026 22:51:26 +0000",
          "title": "mRNA cancer vaccine shows protection at 5-year follow-up, Moderna and Merck say",
          "standfirst": "The vaccines are tailor-made to target each patient's unique cancer.",
          "content": "In a small clinical trial, customized mRNA vaccines against high-risk skin cancers appeared to reduce the risk of cancer recurrence and death by nearly 50 percent over five years when compared with standard treatment alone. That's according to Moderna and Merck, the two pharmaceutical companies that have collaborated on the experimental cancer vaccine, called intismeran autogene (mRNA-4157 or V940). So far, the companies have only reported the top-line results in a press release this week. However, the results align closely with previous, more detailed analyses from the trial, which examined rates of recurrence and death at earlier time points, specifically at two years and three years after the treatment. More data from the trial—a Phase 2 trial—will soon be presented at a medical conference, the companies said. A Phase 3 trial is also underway, with enrollment complete. The ongoing Phase 2 trial included 157 patients who were diagnosed with stage 3 or stage 4 melanoma and were at high risk of having it recur after surgical removal. A standard treatment to prevent recurrence after such surgery is immunotherapy, including Merck's Keytruda (pembrolizumab). This drug essentially enables immune cells, specifically T cells, to attack and kill cancer cells—something they normally do. But, in many types of cancers, including melanoma, cancer cells have the ability to bind to receptors on T cells (called PD-1 receptors), which basically shuts the T cells down. Keytruda works by physically blocking the PD-1 receptors, preventing cancer cells from binding and keeping the T cells activated so they can kill the cancer.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/12/GettyImages-1290558683.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2020/12/GettyImages-1290558683.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_133",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 21:50:21 +0000",
      "title": "Trump FCC threatens to enforce equal-time rule on late-night talk shows",
      "neutral_headline": "Trump FCC threatens to enforce equal-time rule on late-night talk shows",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/01/trump-fcc-tries-to-get-more-republicans-on-late-night-and-daytime-talk-shows/",
          "published_at": "Wed, 21 Jan 2026 21:50:21 +0000",
          "title": "Trump FCC threatens to enforce equal-time rule on late-night talk shows",
          "standfirst": "FCC disputes long-standing view that the shows are exempt from equal-time rule.",
          "content": "The Federal Communications Commission today issued a warning to late-night and daytime talk shows, saying these shows may no longer qualify for an exemption to the FCC's equal-time rule. Because the FCC is chaired by vocal Trump supporter Brendan Carr, changing how the rule is enforced could pressure shows into seeking out more interviews with Republican candidates. The public notice providing what the FCC calls \"guidance on political equal opportunities requirement for broadcast television stations\" appears to be part of the Trump administration's campaign against alleged liberal bias on broadcast TV. Carr, who has eroded the FCC's historical independence from the White House, previously pressured ABC to suspend Jimmy Kimmel and threatened ABC’s The View with the equal-time rule. The Carr FCC's public notice today said that federal rules \"prevent broadcast television stations, which have been given access to a valuable public resource (namely, spectrum), from unfairly putting their thumbs on the scale for one political candidate or set of candidates over another.\" These rules come from \"the decision by Congress that broadcast television stations have an obligation to operate in the public interest—not in any narrow partisan, political interest,\" the Carr FCC said.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/jimmy-kimmel-return-1152x648-1758739114.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/jimmy-kimmel-return-1152x648-1758739114.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 20:37:00 +0000",
      "title": "Kioxia's memory is \"sold out\" for 2026, prolonging a \"high-end and expensive phase\"",
      "neutral_headline": "Kioxia's memory is \"sold out\" for 2026, prolonging a \"high-end and expensive phase\"",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/01/kioxias-memory-is-sold-out-for-2026-prolonging-a-high-end-and-expensive-phase/",
          "published_at": "Wed, 21 Jan 2026 20:37:00 +0000",
          "title": "Kioxia's memory is \"sold out\" for 2026, prolonging a \"high-end and expensive phase\"",
          "standfirst": "Kioxia is spinning up more manufacturing capacity, but relief will come slowly.",
          "content": "The companies that make RAM and flash memory chips are enjoying record profits because of the AI-induced memory crunch—and they’re also indicating that they don’t expect conditions to improve much if at all in 2026. And while RAM kits have been hit the fastest and hardest by shortages and price increases, we shouldn't expect SSD pricing to improve any time soon, either. That's the message from Shunsuke Nakato (via PC Gamer), managing director of the memory division of Kioxia, the Japanese memory company that was spun off from Toshiba at the end of the 2010s. Nakato says that Kioxia’s manufacturing capacity is sold out through the rest of 2026, driving the market for both enterprise and consumer SSDs to a “high-end and expensive phase.” “There is a sense of crisis that companies will be eliminated the moment they stop investing in AI, so they have no choice but to continue investing,” said Nakato, as reported by the Korean-language publication Digital Daily. Absent a big change in the demand for generative AI data centers, that cycle of investments will keep prices high for the foreseeable future.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/kioxia-ssds-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/kioxia-ssds-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_138",
      "coverage": 1,
      "updated_at": "Wed, 21 Jan 2026 19:47:27 +0000",
      "title": "Watch a robot swarm \"bloom\" like a garden",
      "neutral_headline": "Watch a robot swarm \"bloom\" like a garden",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/01/watch-a-robot-swarm-bloom-like-a-garden/",
          "published_at": "Wed, 21 Jan 2026 19:47:27 +0000",
          "title": "Watch a robot swarm \"bloom\" like a garden",
          "standfirst": "The Swarm Garden: An array of modular robot agents that adapt to changing conditions for living architecture.",
          "content": "Researchers at Princeton University have built a swarm of interconnected mini-robots that \"bloom\" like flowers in response to changing light levels in an office. According to their new paper published in the journal Science Robotics, such robotic swarms could one day be used as dynamic facades in architectural designs, enabling buildings to adapt to changing climate conditions as well as interact with humans in creative ways. The authors drew inspiration from so-called \"living architectures,\" such as beehives. Fire ants provide a textbook example of this kind of collective behavior. A few ants spaced well apart behave like individual ants. But pack enough of them closely together, and they behave more like a single unit, exhibiting both solid and liquid properties. You can pour them from a teapot like ants, as Goldman’s lab demonstrated several years ago, or they can link together to build towers or floating rafts—a handy survival skill when, say, a hurricane floods Houston. They also excel at regulating their own traffic flow. You almost never see an ant traffic jam. Naturally scientists are keen to mimic such systems. For instance, in 2018, Georgia Tech researchers built ant-like robots and programmed them to dig through 3D-printed magnetic plastic balls designed to simulate moist soil. Robot swarms capable of efficiently digging underground without jamming would be super beneficial for mining or disaster recovery efforts, where using human beings might not be feasible.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/swarm1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/swarm1-1152x648.jpg",
      "popularity_score": 130
    }
  ]
}