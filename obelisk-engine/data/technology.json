{
  "updated_at": "2025-11-06T07:19:19.435Z",
  "clusters": [
    {
      "id": "cluster_25",
      "coverage": 2,
      "updated_at": "Wed, 05 Nov 2025 21:30:01 -0500",
      "title": "Sandbar introduces Stream Ring, an AI-powered smart ring for transcribing audio notes into text via an app, preorder now from $249 and shipping in summer 2026 (Julian Chokkattu/Wired)",
      "neutral_headline": "Sandbar introduces Stream Ring, an AI-powered smart ring for transcribing audio notes into text via an app, preorder now from $249 and shipping in summer 2026 (Julian Chokkattu/Wired)",
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251105/p60#a251105p60",
          "published_at": "Wed, 05 Nov 2025 21:30:01 -0500",
          "title": "Sandbar introduces Stream Ring, an AI-powered smart ring for transcribing audio notes into text via an app, preorder now from $249 and shipping in summer 2026 (Julian Chokkattu/Wired)",
          "standfirst": "Julian Chokkattu / Wired: Sandbar introduces Stream Ring, an AI-powered smart ring for transcribing audio notes into text via an app, preorder now from $249 and shipping in summer 2026 &mdash; A new company called Sandbar has unveiled a smart wearable called Stream Ring, which uses a microphone to record your softly spoken thoughts.",
          "content": "Julian Chokkattu / Wired: Sandbar introduces Stream Ring, an AI-powered smart ring for transcribing audio notes into text via an app, preorder now from $249 and shipping in summer 2026 &mdash; A new company called Sandbar has unveiled a smart wearable called Stream Ring, which uses a microphone to record your softly spoken thoughts.",
          "feed_position": 12,
          "image_url": "http://www.techmeme.com/251105/i60.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/sandbar-stream-smart-ring/",
          "published_at": "Wed, 05 Nov 2025 11:00:00 +0000",
          "title": "Whisper Into This AI-Powered Smart Ring to Organize Your Thoughts",
          "standfirst": "A new company called Sandbar has unveiled a smart wearable called Stream Ring, which uses a microphone to record your softly spoken thoughts. And it’s powered by—you guessed it—an AI chatbot.",
          "content": "A new company called Sandbar has unveiled a smart wearable called Stream Ring, which uses a microphone to record your softly spoken thoughts. And it’s powered by—you guessed it—an AI chatbot.",
          "feed_position": 19,
          "image_url": "https://media.wired.com/photos/690ac75e0688aae134b0cb56/master/pass/Sandbar%20Stream%20Smart%20Ring%20SOURCE%20Julian%20Chokkattu(2).jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/251105/i60.jpg",
      "popularity_score": 2015.1782125,
      "ai_summary": [
        "Sandbar unveiled the Stream Ring, a smart wearable device.",
        "The Stream Ring uses a microphone to record spoken thoughts.",
        "It utilizes an AI chatbot for transcribing audio notes into text.",
        "Preorders for the Stream Ring are available now for $249.",
        "Shipping of the Stream Ring is planned for the summer of 2026."
      ]
    },
    {
      "id": "cluster_67",
      "coverage": 2,
      "updated_at": "Wed, 05 Nov 2025 18:57:04 +0000",
      "title": "Fitbit Black Friday deals are here early and one of our favorite fitness trackers is on sale for $100",
      "neutral_headline": "Fitbit Black Friday deals are here early and one of our favorite fitness trackers is on sale for $100",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/fitbit-black-friday-deals-are-here-early-and-one-of-our-favorite-fitness-trackers-is-on-sale-for-100-185704387.html",
          "published_at": "Wed, 05 Nov 2025 18:57:04 +0000",
          "title": "Fitbit Black Friday deals are here early and one of our favorite fitness trackers is on sale for $100",
          "standfirst": "Fitbit is holding an early Black Friday and there are plenty of noteworthy deals. The Charge 6 fitness tracker is on sale for $100, which is a nice discount of $60 and 38 percent off. The deal applies to multiple colorways. The Charge 6 topped our list of the best fitness trackers, and for good reason. It features built-in GPS, which means it doesn't have to be tethered to a phone when doing some cardio. The heart rate monitor is much more accurate when compared to the Charge 5 and the battery lasts a full week before requiring a trip to the outlet. All told, it tracks 20 exercise types, in addition to sleep. The Charge 6 features a full-color AMOLED display that's easy on the eyes and a relatively thin design. This makes it feel fairly premium, especially when compared to rival devices. On the downside, there's no real integration with Apple Health. This could be a dealbreaker for some. Also, some health data is hidden behind a Fitbit Premium paywall. That service costs $10 each month. This isn't the only Fitbit product on sale right now. The Inspire 3 fitness tracker is available for $70, which is a discount of 30 percent.This article originally appeared on Engadget at https://www.engadget.com/deals/fitbit-black-friday-deals-are-here-early-and-one-of-our-favorite-fitness-trackers-is-on-sale-for-100-185704387.html?src=rss",
          "content": "Fitbit is holding an early Black Friday and there are plenty of noteworthy deals. The Charge 6 fitness tracker is on sale for $100, which is a nice discount of $60 and 38 percent off. The deal applies to multiple colorways. The Charge 6 topped our list of the best fitness trackers, and for good reason. It features built-in GPS, which means it doesn't have to be tethered to a phone when doing some cardio. The heart rate monitor is much more accurate when compared to the Charge 5 and the battery lasts a full week before requiring a trip to the outlet. All told, it tracks 20 exercise types, in addition to sleep. The Charge 6 features a full-color AMOLED display that's easy on the eyes and a relatively thin design. This makes it feel fairly premium, especially when compared to rival devices. On the downside, there's no real integration with Apple Health. This could be a dealbreaker for some. Also, some health data is hidden behind a Fitbit Premium paywall. That service costs $10 each month. This isn't the only Fitbit product on sale right now. The Inspire 3 fitness tracker is available for $70, which is a discount of 30 percent.This article originally appeared on Engadget at https://www.engadget.com/deals/fitbit-black-friday-deals-are-here-early-and-one-of-our-favorite-fitness-trackers-is-on-sale-for-100-185704387.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-expressvpn-surfshark-and-more-120056432.html",
          "published_at": "Wed, 05 Nov 2025 18:23:27 +0000",
          "title": "The best VPN deals: 88 percent discounts on ProtonVPN, ExpressVPN, Surfshark and more",
          "standfirst": "A virtual private network (VPN) is useful in several ways — a good one can stream foreign TV shows and events, save you from giving up information to hackers and keep you anonymous to protect against online tracking. Although we strongly recommend using a VPN, a bit of comparison shopping goes a long way in this market. VPN pricing can be opaque, and providers don't always portray their best deals accurately. Even so, there are genuinely great bargains on the table. VPN providers give out deep discounts to customers who sign up for a year or more at a time. This lets them boost their subscriber numbers, but it's a win for you as well — while you pay out more upfront, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $59.95 for a two-year subscription with five months free (79 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like Black Friday/Cyber Monday. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-expressvpn-surfshark-and-more-120056432.html?src=rss",
          "content": "A virtual private network (VPN) is useful in several ways — a good one can stream foreign TV shows and events, save you from giving up information to hackers and keep you anonymous to protect against online tracking. Although we strongly recommend using a VPN, a bit of comparison shopping goes a long way in this market. VPN pricing can be opaque, and providers don't always portray their best deals accurately. Even so, there are genuinely great bargains on the table. VPN providers give out deep discounts to customers who sign up for a year or more at a time. This lets them boost their subscriber numbers, but it's a win for you as well — while you pay out more upfront, if you divide the cost by the months of service, it's significantly cheaper over time. Most of the deals we highlight below follow that pattern, so make sure you're comfortable with a longer commitment before you take the plunge. If you've been thinking about subscribing to a VPN service, read on for the best VPN deals we could find right now. Best VPN deals ExpressVPN Basic — $97.72 for a two-year subscription with four months free (73 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This deal, which gets you 28 months of ExpressVPN service, represents a 73 percent savings. ExpressVPN Advanced — $125.72 for a two-year subscription with four months free (67 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. NordVPN Basic — $80.73 for a two-year subscription with three months free (74 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. Although I'm sad to see it shutting down Meshnet, NordVPN still includes a lot of cool features, like servers that instantly connect you to Tor. This early Black Friday deal gives you 74 percent off the two-year plan, which also comes with three extra months. NordVPN Plus — $105.03 for a two-year subscription with three months free (74 percent off): In another early Black Friday discount, NordVPN has also taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $59.13 for a two-year subscription with three months free (88 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with two months free (83 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 26 months of CyberGhost for 83 percent off the usual price. hide.me — $59.95 for a two-year subscription with five months free (79 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. Private Internet Access — $79 for a three-year subscription with three months free (83 percent off): It's a bit hard to find (the link at the start of this paragraph includes the coupon), but Private Internet Access (PIA) is giving out the best available price right now on a VPN I'd recommend using. With this deal, you can get 39 months of PIA for a little bit over $2 per month — an 83 percent discount on its monthly price. Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like Black Friday/Cyber Monday. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-88-percent-discounts-on-protonvpn-expressvpn-surfshark-and-more-120056432.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/the-agent-builder-arms-race-continues-as-google-cloud-pushes-deeper-into",
          "published_at": "Wed, 05 Nov 2025 17:44:00 GMT",
          "title": "Google Cloud updates its AI Agent Builder with new observability dashboard and faster build-and-deploy tools",
          "standfirst": "Google Cloud has introduced a big update in a bid to keep AI developers on its Vertex AI platform for concepting, designing, building, testing, deploying and modifying AI agents in enterprise use cases.The new features, announced today, include additional governance tools for enterprises and expanding the capabilities for creating agents with just a few lines of code, moving faster with state-of-the-art context management layers and one-click deployment, as well as managed services for scaling production and evaluation, and support for identifying agents.Agent Builder, released last year during its annual Cloud Next event, provides a no-code platform for enterprises to create agents and connect these to orchestration frameworks like LangChain.Google’s Agent Development Kit (ADK), which lets developers build agents “in under 100 lines of code,” can also be accessed through Agent Builder. “These new capabilities underscore our commitment to Agent Builder, and simplify the agent development process to meet developers where they are, no matter which tech stack they choose,” said Mike Clark, director of Product Management, Vertex AI Agent Builder. Build agents fasterPart of Google’s pitch for Agent Builder’s new features is that enterprises can bake in-orchestration even as they construct their agents. “Building an agent from a concept to a working product involves complex orchestration,” said Clark. The new capabilities, which are shipped with the ADK, include:SOTA context management layers including Static, Turn, User and Cache layers so enterprises have more control over the agents’ contextPrebuilt plugins with customizable logic. One of the new plugins allows agents to recognize failed tool calls and “self-heal” by retrying the task with a different approachAdditional language support in ADK, including Go, alongside Python and Java, that launched with ADKOne-click deployment through the ADK command line interface to move agents from a local environment to live testing with a single commandGovernance layerEnterprises require high accuracy; security; observability and auditability (what a program did and why); and steerability (control) in their production-grade AI agents.While Google had observability features in the local development environment at launch, developers can now access these tools through the Agent Engine managed runtime dashboard. The company said this brings cloud-based production monitoring to track token consumption, error rates and latency. Within this observability dashboard, enterprises can visualize the actions agents take and reproduce any issues. Agent Engine will also have a new Evaluation Layer to help “simulate agent performance across a vast array of user interactions and situations.”This governance layer will also include:Agent Identities that Google said give “agents their own unique, native identities within Google Cloud Model Armor, which would block prompt injections, screen tool calls and agent responsesSecurity Command Center, so admins can build an inventory of their agents to detect threats like unauthorized access“These native identities provide a deep, built-in layer of control and a clear audit trail for all agent actions. These certificate-backed identities further strengthen your security as they cannot be impersonated and are tied directly to the agent&#x27;s lifecycle, eliminating the risk of dormant accounts,” Clark said. The battle of agent builders It’s no surprise that model providers create platforms to build agents and bring them to production. The competition lies in how fast new tools and features are added.Google’s Agent Builder competes with OpenAI’s open-source Agent Development Kit, which enables developers to create AI agents using non-OpenAI models. Additionally, there is the recently announced AgentKit, which features an Agent Builder that enables companies to integrate agents into their applications easily. Microsoft has its Azure AI Foundry, launched last year around this time for AI agent creation, and AWS also offers agent builders on its Bedrock platform, but Google is hoping is suite of new features will help give it a competitive edge. However, it isn’t just companies with their own models that court developers to build their AI agents within their platforms. Any enterprise service provider with an agent library also wants clients to make agents on their systems. Capturing developer interest and keeping them within the ecosystem is the big battle between tech companies now, with features to make building and governing agents easier.",
          "content": "Google Cloud has introduced a big update in a bid to keep AI developers on its Vertex AI platform for concepting, designing, building, testing, deploying and modifying AI agents in enterprise use cases.The new features, announced today, include additional governance tools for enterprises and expanding the capabilities for creating agents with just a few lines of code, moving faster with state-of-the-art context management layers and one-click deployment, as well as managed services for scaling production and evaluation, and support for identifying agents.Agent Builder, released last year during its annual Cloud Next event, provides a no-code platform for enterprises to create agents and connect these to orchestration frameworks like LangChain.Google’s Agent Development Kit (ADK), which lets developers build agents “in under 100 lines of code,” can also be accessed through Agent Builder. “These new capabilities underscore our commitment to Agent Builder, and simplify the agent development process to meet developers where they are, no matter which tech stack they choose,” said Mike Clark, director of Product Management, Vertex AI Agent Builder. Build agents fasterPart of Google’s pitch for Agent Builder’s new features is that enterprises can bake in-orchestration even as they construct their agents. “Building an agent from a concept to a working product involves complex orchestration,” said Clark. The new capabilities, which are shipped with the ADK, include:SOTA context management layers including Static, Turn, User and Cache layers so enterprises have more control over the agents’ contextPrebuilt plugins with customizable logic. One of the new plugins allows agents to recognize failed tool calls and “self-heal” by retrying the task with a different approachAdditional language support in ADK, including Go, alongside Python and Java, that launched with ADKOne-click deployment through the ADK command line interface to move agents from a local environment to live testing with a single commandGovernance layerEnterprises require high accuracy; security; observability and auditability (what a program did and why); and steerability (control) in their production-grade AI agents.While Google had observability features in the local development environment at launch, developers can now access these tools through the Agent Engine managed runtime dashboard. The company said this brings cloud-based production monitoring to track token consumption, error rates and latency. Within this observability dashboard, enterprises can visualize the actions agents take and reproduce any issues. Agent Engine will also have a new Evaluation Layer to help “simulate agent performance across a vast array of user interactions and situations.”This governance layer will also include:Agent Identities that Google said give “agents their own unique, native identities within Google Cloud Model Armor, which would block prompt injections, screen tool calls and agent responsesSecurity Command Center, so admins can build an inventory of their agents to detect threats like unauthorized access“These native identities provide a deep, built-in layer of control and a clear audit trail for all agent actions. These certificate-backed identities further strengthen your security as they cannot be impersonated and are tied directly to the agent&#x27;s lifecycle, eliminating the risk of dormant accounts,” Clark said. The battle of agent builders It’s no surprise that model providers create platforms to build agents and bring them to production. The competition lies in how fast new tools and features are added.Google’s Agent Builder competes with OpenAI’s open-source Agent Development Kit, which enables developers to create AI agents using non-OpenAI models. Additionally, there is the recently announced AgentKit, which features an Agent Builder that enables companies to integrate agents into their applications easily. Microsoft has its Azure AI Foundry, launched last year around this time for AI agent creation, and AWS also offers agent builders on its Bedrock platform, but Google is hoping is suite of new features will help give it a competitive edge. However, it isn’t just companies with their own models that court developers to build their AI agents within their platforms. Any enterprise service provider with an agent library also wants clients to make agents on their systems. Capturing developer interest and keeping them within the ecosystem is the big battle between tech companies now, with features to make building and governing agents easier.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/T84hNL2FLkCHG8Qpdt8AR/8ad71c54daf9b7e5a06242ac44108a23/crimedy7_illustration_of_robots_constructing_a_building_vivid_40fa4859-c9cc-453b-ad1e-3f01969c44fe_2.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/youtube-tv-blackout-with-disney-will-impact-nba-games-tonight-how-to-watch-espn-abc-and-more-173330987.html",
          "published_at": "Wed, 05 Nov 2025 17:32:30 +0000",
          "title": "YouTube TV blackout with Disney will impact NBA games tonight: How to watch ESPN, ABC and more",
          "standfirst": "SOPA Images via Getty Images It doesn't look like Disney-owned channels including ABC and ESPN will be returning to YouTube TV anytime soon. The Walt Disney Co. pulled its channels from YouTube TV as of midnight on Oct. 30 after the two companies failed to reach new terms on their latest carriage agreement and the spat is showing no signs of a resolution yet. While big sporting events are often where the rubber meets the road on these channel blackouts, YouTube TV subscribers were unable to see any college football games on ABC or ESPN all weekend, and a number of tonight's NBA games are going to be affected, too. YouTube TV management officially rebuffed Disney's request for a 24-hour restoration of its channels in a blog post on Monday — ostensibly to offer coverage of Tuesday's elections — proposing instead that Disney reactivate the feeds for ABC and ESPN while negotiations continue. YouTube TV had previously stated that if Disney’s channels remain off the platform for an extended period, customers will receive a $20 monthly credit. (Some users have reportedly noticed an option for $10 off in their accounts.) This discount provides little consolation though if you want to watch tonight's NBA games or your favorite shows like Abbott Elementary, Grey's Anatomy and Dancing with the Stars. If you don't want to miss out on tonight's Minnesota Timberwolves vs. New York Knicks or San Antonio Spurs vs. Los Angeles Lakers games — both on ESPN — you'll need to seek out alternative viewing methods. And unfortunately for YouTube TV's negotiating position, there are plenty of options. One of the cheapest ways to watch ESPN is with a Sling Day Pass — for just $5/day, you can tune into any and all ESPN programming, including tonight's NBA games, with no other commitments. If you want a full switch from YouTube TV, there's Hulu + Live TV, DirecTV, or Fubo, where you can watch all the Disney-owned channels. (Remember, unlike a lot of cable plans, you can easily pause or cancel YouTube TV or any of these alternatives, so long as you have month-to-month subscriptions.) If you're looking for a workaround to watch ESPN, the Disney Channel, ABC and more, here's are the best options so you won't miss a moment of sports, news, or entertainment, all pulled from our list of best live TV streaming services to cut cable. Grab an ESPN bundle so you won't miss the NFL, NBA or any other games Get Hulu + Live TV at a great price Try Fubo free for a week and get $30 your first month Try DirecTV free for 5 days, and get $30 off your first month What about Sling \"day passes\"? You may have heard that Sling offers day, weekend and week passes to its streaming programming for as little as $5 per day. That is an option if you're looking for just some of the ESPN channels (the Sling Orange tier), but ABC isn't included. (If you're just looking to catch one of this week's big games, like Monday Night Football on ESPN, it's a great short-term solution.) If you want a longer-term solution, you can get both ESPN and ABC with Sling's Orange and Blue package ($30 a month to start, $61 thereafter), but you'll need to add on the Sports Extra package for ESPNU, which requires an additional charge. Get your local Disney/ABC programming for free Need your local ABC programming? Your station may have its own free local streaming news channel (many do), you can see if The Roku Channel carries your local station's news, or download your local news station app if it's a Nexstar channel. The other alternative — if you're within the broadcast radius of a local ABC affiliate — is to get an over-the-air antenna. You can plug in your ZIP code at antennaweb.org to see what channels are in your area. This off-brand unit has worked very well in our initial testing — it's under $30, and the channels are truly free. What games are on ESPN/ABC this week? If you're wondering what games you might miss as a result of the YouTubeTV/Disney blackout, here's a list of some upcoming sports you may not want to miss: NBA Wednesday, Nov. 5 7:30 p.m. | Minnesota Timberwolves vs. New York Knicks | ESPN10 p.m. | San Antonio Spurs vs. Los Angeles Lakers | ESPN College Football Wednesday, Nov. 5 7 p.m. | Kent State at Ball State | ESPNU7 p.m. | Northern Illinois at Toledo | ESPN2 Thursday, Nov. 6 7:30 p.m. | Georgia Southern at Appalachian State | ESPN27:30 p.m. | UTSA at South Florida | ESPN Friday, Nov. 79 p.m. | Tulane at Memphis | ESPN Saturday, Nov. 812 p.m. | No. 5 Georgia at Mississippi State | ESPN12 p.m. | No. 7 BYU at No. 8 Texas Tech | ABC12 p.m. | SMU at Boston College | ACC Network12 p.m. | James Madison at Marshall | ESPN212 p.m. | Southern Miss at Arkansas State | ESPNU3:30 p.m. | No. 3 Texas A&M at No. 22 Missouri | ABC3:30 p.m. | Syracuse at No. 18 Miami (Fla.) | ESPN3:30 p.m. | Kansas at Arizona | ESPN24 p.m. | Auburn at No. 16 Vanderbilt | SEC Network4 p.m. | Kennesaw State at New Mexico State | ESPN+4 p.m. | Georgia State at Coastal Carolina | ESPN+5 p.m. | Texas State at Louisiana | ESPN+7 p.m. | Wake Forest at No. 14 Virginia | ESPN7 p.m. | Cal at No. 15 Louisville | ESPN27 p.m. | Florida State at Clemson | ACCN7:30 p.m. | LSU at No. 4 Alabama | ABC7:30 p.m. | Florida at Kentucky | SEC NetworkUpdate Nov. 5 2025, 12:32PM ET: This story has been updated to include detailed info on tonight's ESPN NBA games, as well as the college football games on deck for this weekend. Update Nov. 3 2025, 6:36PM ET: This story has been updated to include YouTube TV's latest response to Disney's request to restore its channels for just 24 hours.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/youtube-tv-blackout-with-disney-will-impact-nba-games-tonight-how-to-watch-espn-abc-and-more-173330987.html?src=rss",
          "content": "SOPA Images via Getty Images It doesn't look like Disney-owned channels including ABC and ESPN will be returning to YouTube TV anytime soon. The Walt Disney Co. pulled its channels from YouTube TV as of midnight on Oct. 30 after the two companies failed to reach new terms on their latest carriage agreement and the spat is showing no signs of a resolution yet. While big sporting events are often where the rubber meets the road on these channel blackouts, YouTube TV subscribers were unable to see any college football games on ABC or ESPN all weekend, and a number of tonight's NBA games are going to be affected, too. YouTube TV management officially rebuffed Disney's request for a 24-hour restoration of its channels in a blog post on Monday — ostensibly to offer coverage of Tuesday's elections — proposing instead that Disney reactivate the feeds for ABC and ESPN while negotiations continue. YouTube TV had previously stated that if Disney’s channels remain off the platform for an extended period, customers will receive a $20 monthly credit. (Some users have reportedly noticed an option for $10 off in their accounts.) This discount provides little consolation though if you want to watch tonight's NBA games or your favorite shows like Abbott Elementary, Grey's Anatomy and Dancing with the Stars. If you don't want to miss out on tonight's Minnesota Timberwolves vs. New York Knicks or San Antonio Spurs vs. Los Angeles Lakers games — both on ESPN — you'll need to seek out alternative viewing methods. And unfortunately for YouTube TV's negotiating position, there are plenty of options. One of the cheapest ways to watch ESPN is with a Sling Day Pass — for just $5/day, you can tune into any and all ESPN programming, including tonight's NBA games, with no other commitments. If you want a full switch from YouTube TV, there's Hulu + Live TV, DirecTV, or Fubo, where you can watch all the Disney-owned channels. (Remember, unlike a lot of cable plans, you can easily pause or cancel YouTube TV or any of these alternatives, so long as you have month-to-month subscriptions.) If you're looking for a workaround to watch ESPN, the Disney Channel, ABC and more, here's are the best options so you won't miss a moment of sports, news, or entertainment, all pulled from our list of best live TV streaming services to cut cable. Grab an ESPN bundle so you won't miss the NFL, NBA or any other games Get Hulu + Live TV at a great price Try Fubo free for a week and get $30 your first month Try DirecTV free for 5 days, and get $30 off your first month What about Sling \"day passes\"? You may have heard that Sling offers day, weekend and week passes to its streaming programming for as little as $5 per day. That is an option if you're looking for just some of the ESPN channels (the Sling Orange tier), but ABC isn't included. (If you're just looking to catch one of this week's big games, like Monday Night Football on ESPN, it's a great short-term solution.) If you want a longer-term solution, you can get both ESPN and ABC with Sling's Orange and Blue package ($30 a month to start, $61 thereafter), but you'll need to add on the Sports Extra package for ESPNU, which requires an additional charge. Get your local Disney/ABC programming for free Need your local ABC programming? Your station may have its own free local streaming news channel (many do), you can see if The Roku Channel carries your local station's news, or download your local news station app if it's a Nexstar channel. The other alternative — if you're within the broadcast radius of a local ABC affiliate — is to get an over-the-air antenna. You can plug in your ZIP code at antennaweb.org to see what channels are in your area. This off-brand unit has worked very well in our initial testing — it's under $30, and the channels are truly free. What games are on ESPN/ABC this week? If you're wondering what games you might miss as a result of the YouTubeTV/Disney blackout, here's a list of some upcoming sports you may not want to miss: NBA Wednesday, Nov. 5 7:30 p.m. | Minnesota Timberwolves vs. New York Knicks | ESPN10 p.m. | San Antonio Spurs vs. Los Angeles Lakers | ESPN College Football Wednesday, Nov. 5 7 p.m. | Kent State at Ball State | ESPNU7 p.m. | Northern Illinois at Toledo | ESPN2 Thursday, Nov. 6 7:30 p.m. | Georgia Southern at Appalachian State | ESPN27:30 p.m. | UTSA at South Florida | ESPN Friday, Nov. 79 p.m. | Tulane at Memphis | ESPN Saturday, Nov. 812 p.m. | No. 5 Georgia at Mississippi State | ESPN12 p.m. | No. 7 BYU at No. 8 Texas Tech | ABC12 p.m. | SMU at Boston College | ACC Network12 p.m. | James Madison at Marshall | ESPN212 p.m. | Southern Miss at Arkansas State | ESPNU3:30 p.m. | No. 3 Texas A&M at No. 22 Missouri | ABC3:30 p.m. | Syracuse at No. 18 Miami (Fla.) | ESPN3:30 p.m. | Kansas at Arizona | ESPN24 p.m. | Auburn at No. 16 Vanderbilt | SEC Network4 p.m. | Kennesaw State at New Mexico State | ESPN+4 p.m. | Georgia State at Coastal Carolina | ESPN+5 p.m. | Texas State at Louisiana | ESPN+7 p.m. | Wake Forest at No. 14 Virginia | ESPN7 p.m. | Cal at No. 15 Louisville | ESPN27 p.m. | Florida State at Clemson | ACCN7:30 p.m. | LSU at No. 4 Alabama | ABC7:30 p.m. | Florida at Kentucky | SEC NetworkUpdate Nov. 5 2025, 12:32PM ET: This story has been updated to include detailed info on tonight's ESPN NBA games, as well as the college football games on deck for this weekend. Update Nov. 3 2025, 6:36PM ET: This story has been updated to include YouTube TV's latest response to Disney's request to restore its channels for just 24 hours.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/youtube-tv-blackout-with-disney-will-impact-nba-games-tonight-how-to-watch-espn-abc-and-more-173330987.html?src=rss",
          "feed_position": 20,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-02/f18a9a20-ea15-11ef-b5d3-3ae5ab47679d"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/playstation/the-playstation-portal-is-still-flawed-but-ive-learned-to-love-it-as-a-new-dad-120000850.html",
          "published_at": "Wed, 05 Nov 2025 16:30:00 +0000",
          "title": "The PlayStation Portal is still flawed, but I’ve learned to love it as a new dad",
          "standfirst": "When it was first announced, the PlayStation Portal was sort of a joke. The Nintendo Switch was a megahit, and many PlayStation fans had long hoped Sony would respond with a new handheld of its own. It did… in the form of a $200 peripheral that can only stream games over the internet and required you to already own a PlayStation 5. Instead of a successor to the beloved yet famously neglected PlayStation Vita, we got the PlayStation version of the Wii U GamePad. My colleague Devindra Hardawar called it “baffling” in our PlayStation Portal review, and many of his criticisms still stand two years later. I was happy to ignore the Portal as a result. Besides, I already owned a bunch of devices that covered every way I wanted to play. The PS5 and PC were for the “pretty” games I want to sit and revel in on my monitor, while the Switch and Steam Deck were for playing away from my desk. This combination worked for me. Then, a few months ago, my wife and I had our first child. She is wonderful, and we are happy. But life pre-kids is often incongruous with life post-kids. My old routines and any pretense of personal time are gone. And while this might be the single least important aspect of my life that’s changed since becoming a father, the whiplash of going from “mid-30s man who spends too much time thinking about video games” to “mid-30s man who wants to enjoy his hobby but is now responsible for raising a kid” has completely turned me around on the Portal, which my wife gifted to me a few months prior to our baby’s birth. To be clear, I’m not here jonesing to play games all day instead of bonding with my daughter. But every parent needs a break sometimes, and whatever “free” time I get these days is inherently staggered. It’s not just the usual changing, feeding, tummy-time monitoring and diaper pail maintenance; it’s the 20-30 minutes of prep and clean-up that often comes with each of those. Topping up the formula dispenser here, running out for more wipes and baby laundry detergent there. Spending 10 minutes pedaling her legs so she can get a fart out. Photo by Devindra Hardawar/Engadget All of this has been much more fun than it sounds, but for gaming purposes, it means I’ve almost exclusively switched to things I can play in short bursts. It’s been a lot of Balatro, a lot of clearly timed multiplayer games like Rocket League, plus some slower, single-player games that let you save and quit at any time. These kinds of games have always been best suited to handhelds, and are thus the ones the Portal has helped me enjoy again when we get the baby to bed. Yes, I could just use the Switch or Steam Deck. But I dropped $500 on this damn PS5 back in 2020. I have more games in my PlayStation library than any other platform. I want to (slowly) make my way through exclusives like Ghost of Yotei. I don’t want my fancy console to collect dust, and as silly as it sounds, finding the energy to sit at my desk and give my full attention to a game is difficult after a day of work and parenting. Most nights I’d prefer to unspool on the couch with my wife, and I need to be nearby to lend a hand or change a diaper. The Portal has allowed me to do this, and it’s kept my PlayStation from turning into a funky-looking paperweight in the process. The Portal fills this niche mostly by just being a handheld device, but it has its own benefits. The controls are fantastic, essentially splitting a normal PS5 controller in half. They give everything an “official” feel that you just can’t replicate with a smartphone controller like a Backbone. I wish the 8-inch display had a more color-rich OLED panel, but it’s still good for an LCD, roomier than my phone’s screen and sharp enough at 1080p. I’m a wired headphone guy, so I can live with its lack of Bluetooth audio, as asinine as that is. And while I’m no longer paying $160 per year for PlayStation Plus Premium, those that do can now stream certain games directly from the cloud without having to boot up their console. That worked fine in the short time I tried it. The back of the PlayStation Portal. Photo by Devindra Hardawar/Engadget My experience with the Portal is entirely predicated on the fact that I live in a modest apartment with decent Wi-Fi. It’s still a streaming device, so there’ve been some hiccups here and there. Using it for shooters or fighting games is just asking for frustration, and things start to destabilize if we have several streams going in the house at once. But under normal conditions, I’ve been able to play competitive multiplayer games like Rematch without ruinous lag, and I just haven’t had the crushing connection issues some folks have suffered through with single-player fare. As long as I keep the PS5 in rest mode, everything turns on and eventually works as it should. It’s a weird one: I still wouldn’t recommend the Portal to most PS5 owners, nor would I change all that much about our initial review. Of course, receiving it as a gift skews my perspective. Yet it’s made it easier to fit some games into my new life all the same. Looking after an infant has been one of my greatest joys, but it’s undeniably exhausting. With the Portal, I can still enjoy a platform I’ve heavily invested in — provided I don’t pass out first.This article originally appeared on Engadget at https://www.engadget.com/gaming/playstation/the-playstation-portal-is-still-flawed-but-ive-learned-to-love-it-as-a-new-dad-120000850.html?src=rss",
          "content": "When it was first announced, the PlayStation Portal was sort of a joke. The Nintendo Switch was a megahit, and many PlayStation fans had long hoped Sony would respond with a new handheld of its own. It did… in the form of a $200 peripheral that can only stream games over the internet and required you to already own a PlayStation 5. Instead of a successor to the beloved yet famously neglected PlayStation Vita, we got the PlayStation version of the Wii U GamePad. My colleague Devindra Hardawar called it “baffling” in our PlayStation Portal review, and many of his criticisms still stand two years later. I was happy to ignore the Portal as a result. Besides, I already owned a bunch of devices that covered every way I wanted to play. The PS5 and PC were for the “pretty” games I want to sit and revel in on my monitor, while the Switch and Steam Deck were for playing away from my desk. This combination worked for me. Then, a few months ago, my wife and I had our first child. She is wonderful, and we are happy. But life pre-kids is often incongruous with life post-kids. My old routines and any pretense of personal time are gone. And while this might be the single least important aspect of my life that’s changed since becoming a father, the whiplash of going from “mid-30s man who spends too much time thinking about video games” to “mid-30s man who wants to enjoy his hobby but is now responsible for raising a kid” has completely turned me around on the Portal, which my wife gifted to me a few months prior to our baby’s birth. To be clear, I’m not here jonesing to play games all day instead of bonding with my daughter. But every parent needs a break sometimes, and whatever “free” time I get these days is inherently staggered. It’s not just the usual changing, feeding, tummy-time monitoring and diaper pail maintenance; it’s the 20-30 minutes of prep and clean-up that often comes with each of those. Topping up the formula dispenser here, running out for more wipes and baby laundry detergent there. Spending 10 minutes pedaling her legs so she can get a fart out. Photo by Devindra Hardawar/Engadget All of this has been much more fun than it sounds, but for gaming purposes, it means I’ve almost exclusively switched to things I can play in short bursts. It’s been a lot of Balatro, a lot of clearly timed multiplayer games like Rocket League, plus some slower, single-player games that let you save and quit at any time. These kinds of games have always been best suited to handhelds, and are thus the ones the Portal has helped me enjoy again when we get the baby to bed. Yes, I could just use the Switch or Steam Deck. But I dropped $500 on this damn PS5 back in 2020. I have more games in my PlayStation library than any other platform. I want to (slowly) make my way through exclusives like Ghost of Yotei. I don’t want my fancy console to collect dust, and as silly as it sounds, finding the energy to sit at my desk and give my full attention to a game is difficult after a day of work and parenting. Most nights I’d prefer to unspool on the couch with my wife, and I need to be nearby to lend a hand or change a diaper. The Portal has allowed me to do this, and it’s kept my PlayStation from turning into a funky-looking paperweight in the process. The Portal fills this niche mostly by just being a handheld device, but it has its own benefits. The controls are fantastic, essentially splitting a normal PS5 controller in half. They give everything an “official” feel that you just can’t replicate with a smartphone controller like a Backbone. I wish the 8-inch display had a more color-rich OLED panel, but it’s still good for an LCD, roomier than my phone’s screen and sharp enough at 1080p. I’m a wired headphone guy, so I can live with its lack of Bluetooth audio, as asinine as that is. And while I’m no longer paying $160 per year for PlayStation Plus Premium, those that do can now stream certain games directly from the cloud without having to boot up their console. That worked fine in the short time I tried it. The back of the PlayStation Portal. Photo by Devindra Hardawar/Engadget My experience with the Portal is entirely predicated on the fact that I live in a modest apartment with decent Wi-Fi. It’s still a streaming device, so there’ve been some hiccups here and there. Using it for shooters or fighting games is just asking for frustration, and things start to destabilize if we have several streams going in the house at once. But under normal conditions, I’ve been able to play competitive multiplayer games like Rematch without ruinous lag, and I just haven’t had the crushing connection issues some folks have suffered through with single-player fare. As long as I keep the PS5 in rest mode, everything turns on and eventually works as it should. It’s a weird one: I still wouldn’t recommend the Portal to most PS5 owners, nor would I change all that much about our initial review. Of course, receiving it as a gift skews my perspective. Yet it’s made it easier to fit some games into my new life all the same. Looking after an infant has been one of my greatest joys, but it’s undeniably exhausting. With the Portal, I can still enjoy a platform I’ve heavily invested in — provided I don’t pass out first.This article originally appeared on Engadget at https://www.engadget.com/gaming/playstation/the-playstation-portal-is-still-flawed-but-ive-learned-to-love-it-as-a-new-dad-120000850.html?src=rss",
          "feed_position": 25,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-11/8114d040-8255-11ee-bff7-c2a788437010"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/black-friday-2025-the-best-early-tech-deals-on-apple-shark-lego-and-other-gear-ahead-of-the-biggest-sale-of-the-year-100052620.html",
          "published_at": "Wed, 05 Nov 2025 15:30:35 +0000",
          "title": "Black Friday 2025: The best early tech deals on Apple, Shark, Lego and other gear ahead of the biggest sale of the year",
          "standfirst": "Black Friday has become the time to buy the hottest tech of the year. Whether you're shopping for yourself or stocking up on gifts for the holidays, Black Friday deals are sure to bring the best prices of the year to things like headphones, game consoles, robot vacuums, phone accessories and everything in between. You don't even have to wait until Black Friday proper to save a ton of money. Over the past few years, we've seen Black Friday tech deals start earlier and earlier — to the point where the entire month of November is packed with discounts.If you're on the hunt for solid tech deals, Engadget has you covered. We've collected the best Black Friday deals on tech you can get right now, and we'll continue to update this post as we get closer to the big day at the end of November. Note that you probably have the best chance of snagging record-low prices when we get to about one week before Thanksgiving, but these deals available now are worth considering. Black Friday deals to shop now Apple iPad mini for $399 ($100 off): Apple's smallest tablet, the iPad mini is the best option for those who prefer their tablet be roughly the size of a paperback book. The latest model runs on the A17 Pro chipset and has an upgraded 128GB of storage in the base configuration. It also supports the Apple Pencil Pro. Apple Mac Mini M4 for $499 ($100 off): Desktop users looking for an upgrade should consider the latest Mac Mini, which runs on the M4 chip and 16GB of RAM as standard in the base configuration. This version has a smaller design that takes up less space, front-facing USB-C ports and a headphone jack, plus Thunderbolt 5 support. Bose QuietComfort headphones for $199 (43 percent off): These noise-cancelling headphones have a comfortable (albeit a bit boring) design, an \"Aware\" mode that lets you hear more of your surroundings when you need to and up to 24 hours of battery life. Also available at Best Buy. EcoFlow Black Friday deals — get up to 80 percent off: Portable power stations are an investment, but they can be crucial pieces of tech during emergencies. The top pick from our friends at Yahoo Tech has been heavily discounted in this early Black Friday sale. You can pick up the EcoFlow Delta Pro 3 for $1,400 off, down to $2,299, or the power station with an extra battery bundled in for $2,699 off, down to $3,599. Apple Watch SE 3 for $200 ($50 off): The SE has been our top pick for the best Apple Watch for those on a budget, and the latest model only solidifies that further. It has the same chipset found in the latest flagship Apple Watches, fast-charging capabilities, an always-on display and most of the same activity-tracking features you'll find in more expensive model. Jisulife Life 7 handheld fan for $25 (14 percent off): This handy little fan is a must-have if you life in a warm climate or have a tropical vacation planned anytime soon. It can be used as a table or handheld fan and even be worn around the neck so you don't have to hold it at all. Its 5,000 mAh battery allows it to last hours on a single charge, and the small display in the middle of the fan's blades show its remaining battery level. Lego Disney advent calendar 2025 43253 for $39 (14 percent off): I probably don't need to tell you 'tis the season for advent calendars. Lego has a bunch, and this one in particular is on a good deal right now. Like most Lego advent calendars, this one includes a number of bricks and minifigs that, when put together, make a coherent, themed scene. Leebin 2025 electric spin scrubber for $40 (43 percent off, Prime exclusive): This weird little scrubber makes cleaning my bathroom and shower much less of a pain. Just choose the brush head you need for your job and the rotating head takes care of most of the hard work. I love the adjustable handle, which extends from 12 to 50 inches so you can get into hard-to-reach places without breaking a sweat. SanDisk microSD Express card (256GB) for $60 (12 percent off): If you have a Switch 2, no regular microSD card will do if you want to expand the console's storage. You need a newer microSD Express card, and currently there are only a handful on the market. We did some testing to find the best microSD Express card for the Switch 2 and found that performance was, in general, very similar amongst all the readily available cards. We recommend getting whichever fits within your budget at the capacity you want. Google TV Streamer 4K for $75 ($25 off): Our top pick for the best streaming device right now, the latest version of Google's streamer supports 4K video and an excellent, easy-to-use interface that will feel familiar to anyone who's seen a set with the Google TV technology built in. It provides access to all of the major streaming services including Netflix, Disney+, HBO Max, YouTube and more, plus it has a handy on-screen pop up that lets you control all compatible smart home devices right from your TV. Also available at Walmart. Cosori 9-in-1 air fryer for $90 (25 percent off): I personally have this air fryer, one of our top picks, in my house and I've used it for over a year with no issues. I love that it makes good use of vertical space so it doesn't take up too much space on my counter, and its rounded-square shape allows me to cook more food than you'd think in one go in the basket. It crisps all kinds of foods up well and generally takes a lot of the guess work (and time) out of making a good meal. Shark AI Ultra robot vacuum with 60-day self-emptying base for $300 (50 percent off): This is a version of one of our top picks for the best robot vacuums. We generally like Shark machines because they do a good job cleaning all types of flooring, produce accurate home maps and the companion app is pretty easy to use. This one in particularly comes with a self-emptying base that can hold up to 60 days worth of debris. Black Friday FAQs When is Black Friday 2025? Black Friday 2025 lands on November 28. Which stores have Black Friday deals? Many physical retail stores have Black Friday deals including Walmart, Target, Best Buy and others. Even more retailers have online Black Friday deals, including Amazon, GameStop, Costco and others. When do Black Friday sales start? Gone are the times when Black Friday sales were one-day-only affairs. Now, Black Friday deals are often available starting on Thanksgiving, or even earlier. Last year, we saw Black Friday deals online begin the week before Black Friday proper. When do Black Friday sales end? Black Friday and Cyber Monday have blended a lot over the past few years. Now, you can expect to see a good portion of Black Friday deals extend through the weekend and into Cyber Monday. It's not uncommon for Black Friday deals to expire at the end of Cyber Monday. Which retailers have the best Black Friday tech deals? The best Black Friday tech deals are typically available online at retailers like Amazon, Walmart, Best Buy and Target. It's also a good idea to check the store websites of the companies that make the products you want — for example, if you're looking for a Sonos speaker, check the Sonos website on Black Friday. Most of the time, you'll find the best Black Friday tech deals are matched at multiple retailers. Does Apple have Black Friday sales? No, you will usually not find Black Friday sales at Apple stores or on Apple's website. However, you can find Black Friday deals on Apple devices elsewhere; we recommend checking Amazon, Best Buy and other big retailers for discounts on iPads, Apple Watches and more on Black Friday. Does Amazon have Black Friday sales? Yes, Amazon has Black Friday sales. The online retailer's site will look similar to Prime Day on Black Friday, with discounts on all sorts of items from household essentials to fashion to tech.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-2025-the-best-early-tech-deals-on-apple-shark-lego-and-other-gear-ahead-of-the-biggest-sale-of-the-year-100052620.html?src=rss",
          "content": "Black Friday has become the time to buy the hottest tech of the year. Whether you're shopping for yourself or stocking up on gifts for the holidays, Black Friday deals are sure to bring the best prices of the year to things like headphones, game consoles, robot vacuums, phone accessories and everything in between. You don't even have to wait until Black Friday proper to save a ton of money. Over the past few years, we've seen Black Friday tech deals start earlier and earlier — to the point where the entire month of November is packed with discounts.If you're on the hunt for solid tech deals, Engadget has you covered. We've collected the best Black Friday deals on tech you can get right now, and we'll continue to update this post as we get closer to the big day at the end of November. Note that you probably have the best chance of snagging record-low prices when we get to about one week before Thanksgiving, but these deals available now are worth considering. Black Friday deals to shop now Apple iPad mini for $399 ($100 off): Apple's smallest tablet, the iPad mini is the best option for those who prefer their tablet be roughly the size of a paperback book. The latest model runs on the A17 Pro chipset and has an upgraded 128GB of storage in the base configuration. It also supports the Apple Pencil Pro. Apple Mac Mini M4 for $499 ($100 off): Desktop users looking for an upgrade should consider the latest Mac Mini, which runs on the M4 chip and 16GB of RAM as standard in the base configuration. This version has a smaller design that takes up less space, front-facing USB-C ports and a headphone jack, plus Thunderbolt 5 support. Bose QuietComfort headphones for $199 (43 percent off): These noise-cancelling headphones have a comfortable (albeit a bit boring) design, an \"Aware\" mode that lets you hear more of your surroundings when you need to and up to 24 hours of battery life. Also available at Best Buy. EcoFlow Black Friday deals — get up to 80 percent off: Portable power stations are an investment, but they can be crucial pieces of tech during emergencies. The top pick from our friends at Yahoo Tech has been heavily discounted in this early Black Friday sale. You can pick up the EcoFlow Delta Pro 3 for $1,400 off, down to $2,299, or the power station with an extra battery bundled in for $2,699 off, down to $3,599. Apple Watch SE 3 for $200 ($50 off): The SE has been our top pick for the best Apple Watch for those on a budget, and the latest model only solidifies that further. It has the same chipset found in the latest flagship Apple Watches, fast-charging capabilities, an always-on display and most of the same activity-tracking features you'll find in more expensive model. Jisulife Life 7 handheld fan for $25 (14 percent off): This handy little fan is a must-have if you life in a warm climate or have a tropical vacation planned anytime soon. It can be used as a table or handheld fan and even be worn around the neck so you don't have to hold it at all. Its 5,000 mAh battery allows it to last hours on a single charge, and the small display in the middle of the fan's blades show its remaining battery level. Lego Disney advent calendar 2025 43253 for $39 (14 percent off): I probably don't need to tell you 'tis the season for advent calendars. Lego has a bunch, and this one in particular is on a good deal right now. Like most Lego advent calendars, this one includes a number of bricks and minifigs that, when put together, make a coherent, themed scene. Leebin 2025 electric spin scrubber for $40 (43 percent off, Prime exclusive): This weird little scrubber makes cleaning my bathroom and shower much less of a pain. Just choose the brush head you need for your job and the rotating head takes care of most of the hard work. I love the adjustable handle, which extends from 12 to 50 inches so you can get into hard-to-reach places without breaking a sweat. SanDisk microSD Express card (256GB) for $60 (12 percent off): If you have a Switch 2, no regular microSD card will do if you want to expand the console's storage. You need a newer microSD Express card, and currently there are only a handful on the market. We did some testing to find the best microSD Express card for the Switch 2 and found that performance was, in general, very similar amongst all the readily available cards. We recommend getting whichever fits within your budget at the capacity you want. Google TV Streamer 4K for $75 ($25 off): Our top pick for the best streaming device right now, the latest version of Google's streamer supports 4K video and an excellent, easy-to-use interface that will feel familiar to anyone who's seen a set with the Google TV technology built in. It provides access to all of the major streaming services including Netflix, Disney+, HBO Max, YouTube and more, plus it has a handy on-screen pop up that lets you control all compatible smart home devices right from your TV. Also available at Walmart. Cosori 9-in-1 air fryer for $90 (25 percent off): I personally have this air fryer, one of our top picks, in my house and I've used it for over a year with no issues. I love that it makes good use of vertical space so it doesn't take up too much space on my counter, and its rounded-square shape allows me to cook more food than you'd think in one go in the basket. It crisps all kinds of foods up well and generally takes a lot of the guess work (and time) out of making a good meal. Shark AI Ultra robot vacuum with 60-day self-emptying base for $300 (50 percent off): This is a version of one of our top picks for the best robot vacuums. We generally like Shark machines because they do a good job cleaning all types of flooring, produce accurate home maps and the companion app is pretty easy to use. This one in particularly comes with a self-emptying base that can hold up to 60 days worth of debris. Black Friday FAQs When is Black Friday 2025? Black Friday 2025 lands on November 28. Which stores have Black Friday deals? Many physical retail stores have Black Friday deals including Walmart, Target, Best Buy and others. Even more retailers have online Black Friday deals, including Amazon, GameStop, Costco and others. When do Black Friday sales start? Gone are the times when Black Friday sales were one-day-only affairs. Now, Black Friday deals are often available starting on Thanksgiving, or even earlier. Last year, we saw Black Friday deals online begin the week before Black Friday proper. When do Black Friday sales end? Black Friday and Cyber Monday have blended a lot over the past few years. Now, you can expect to see a good portion of Black Friday deals extend through the weekend and into Cyber Monday. It's not uncommon for Black Friday deals to expire at the end of Cyber Monday. Which retailers have the best Black Friday tech deals? The best Black Friday tech deals are typically available online at retailers like Amazon, Walmart, Best Buy and Target. It's also a good idea to check the store websites of the companies that make the products you want — for example, if you're looking for a Sonos speaker, check the Sonos website on Black Friday. Most of the time, you'll find the best Black Friday tech deals are matched at multiple retailers. Does Apple have Black Friday sales? No, you will usually not find Black Friday sales at Apple stores or on Apple's website. However, you can find Black Friday deals on Apple devices elsewhere; we recommend checking Amazon, Best Buy and other big retailers for discounts on iPads, Apple Watches and more on Black Friday. Does Amazon have Black Friday sales? Yes, Amazon has Black Friday sales. The online retailer's site will look similar to Prime Day on Black Friday, with discounts on all sorts of items from household essentials to fashion to tech.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-2025-the-best-early-tech-deals-on-apple-shark-lego-and-other-gear-ahead-of-the-biggest-sale-of-the-year-100052620.html?src=rss",
          "feed_position": 27
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/proton-vpn-black-friday-deal-two-year-plans-are-75-percent-off-right-now-153737976.html",
          "published_at": "Wed, 05 Nov 2025 15:00:36 +0000",
          "title": "Proton VPN Black Friday deal: Two-year plans are 75 percent off right now",
          "standfirst": "Now is arguably the best time of year to sign up for a VPN, or gift a subscription to someone. Black Friday VPN deals are already available, with one of the best being on our favorite VPN overall. Proton VPN is offering two years of access to its VPN Plus tier for $59.76, which works out to $2.49 per month. That's a discount of 75 percent compared with the regular price of $10 per month. Overall, you'd save $180. Proton VPN is our pick for the best VPN overall because it checks all of the boxes it needs to. There is a free plan with unlimited data, but with that you can only connect to servers in a few countries and the connection might not be fast enough for you to watch anything from your preferred streaming service's library in that locale. The VPN Plus tier unlocks a lot more options, such as the ability to connect to 15,000 servers across more than 120 countries and simultaneous protection for up to 15 devices. The apps are well-designed — Proton has clients for Windows, Mac, iOS and Android — and it's easy to find a feature or setting you're looking for. In our testing, Proton VPN Plus had a relatively small impact on browsing speeds. Our download speeds dropped by 12 percent and uploads by 4 percent, while the global average ping remained below 300 ms (which is especially impressive if you're connecting to a server on the other side of the planet). Perhaps, most importantly, though, it's Proton's commitment to privacy that helps make its VPN an easy recommendation. There's a no-logs policy, meaning it does not log user activity or any identifiable characteristics of devices that connect to the VPN. Proton's servers use full-disk encryption to bolster privacy as well.This article originally appeared on Engadget at https://www.engadget.com/deals/proton-vpn-black-friday-deal-two-year-plans-are-75-percent-off-right-now-153737976.html?src=rss",
          "content": "Now is arguably the best time of year to sign up for a VPN, or gift a subscription to someone. Black Friday VPN deals are already available, with one of the best being on our favorite VPN overall. Proton VPN is offering two years of access to its VPN Plus tier for $59.76, which works out to $2.49 per month. That's a discount of 75 percent compared with the regular price of $10 per month. Overall, you'd save $180. Proton VPN is our pick for the best VPN overall because it checks all of the boxes it needs to. There is a free plan with unlimited data, but with that you can only connect to servers in a few countries and the connection might not be fast enough for you to watch anything from your preferred streaming service's library in that locale. The VPN Plus tier unlocks a lot more options, such as the ability to connect to 15,000 servers across more than 120 countries and simultaneous protection for up to 15 devices. The apps are well-designed — Proton has clients for Windows, Mac, iOS and Android — and it's easy to find a feature or setting you're looking for. In our testing, Proton VPN Plus had a relatively small impact on browsing speeds. Our download speeds dropped by 12 percent and uploads by 4 percent, while the global average ping remained below 300 ms (which is especially impressive if you're connecting to a server on the other side of the planet). Perhaps, most importantly, though, it's Proton's commitment to privacy that helps make its VPN an easy recommendation. There's a no-logs policy, meaning it does not log user activity or any identifiable characteristics of devices that connect to the VPN. Proton's servers use full-disk encryption to bolster privacy as well.This article originally appeared on Engadget at https://www.engadget.com/deals/proton-vpn-black-friday-deal-two-year-plans-are-75-percent-off-right-now-153737976.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/driving-hondas-lighter-faster-and-more-fun-next-gen-hybrid-prototype-150000472.html",
          "published_at": "Wed, 05 Nov 2025 15:00:00 +0000",
          "title": "Driving Honda's lighter, faster and more fun next-gen hybrid prototype",
          "standfirst": "With the American market still struggling to get its head around the whole electric car thing, plenty of manufacturers are scaling back their EV ambitions to refocus on hybrid power. Whether that's right for the market and, indeed, the globe remains to be seen, but we can for sure expect to see a lot more cars with internal combustion over the next few years.Honda has made its plans clear on that front, which might be cause for concern among many for one simple reason: Outside of the NSX, the company's hybrids thus far haven't exactly been the most engaging of machines. That, though, could change with a new set of hybrid platforms launching soon that'll be lighter, quicker and even more fun to drive.At the company's extensive proving grounds outside of Tochigi, Japan, I was given a go in a pair of cars that gave me reason to be optimistic about this next generation of electrically assisted but still combustion-dependent machines. They rely on a series of advancements that come together to form three different platforms: Small, Medium and Large.Collectively, they're known as the Next Generation Hybrid System, and each one is designed to be modular, able to be scaled up or down to fit different models while still keeping their fundamental sections the same. Platform sharing like this makes it much easier (and cheaper) for manufacturers to roll out new machines and to do it quickly. With Honda looking to ramp up its hybrid offerings, that's key.The the engine for Honda's \"Large\" next-gen hybrid system Tim Stevens for EngadgetThese platforms encompass things like chassis, engines, electric motors and electronics, plus the wonderful web of software required to tie it all together. Reducing weight is a huge focus here, with Honda's engineers coming up with a way to maintain crash safety while dramatically reducing the size of the front and rear subframes. This alone equates to a weight savings of some 90 kilograms (about 200 pounds) in a vehicle the size of a Honda Civic. Lighter weight means more efficiency and better fuel economy. There's also a commensurate reduction in cost of 10 percent for manufacturing versus the company's current platforms, plus promises of increased grip and reduced road noise. The smallest of Honda's new platforms is destined for Honda's smallest cars, including ultra-minis that swarm Japanese streets but have rarely found much success in the United States. For now, at least, we won't be getting any cars based on that platform.The Medium and Large platforms, though, will be tucked in neatly throughout many next-generation cars from the brand. Medium will be suitable for four-cylinder machines like the Civic and crossover SUVs like the HR-V. The Large platform, meanwhile, will be used for bigger V6 machines, like the Ridgeline and Passport.Each system ties that engine to a pair of electric motors, plus an optional third electric motor at the back for all-wheel drive. A revised, more compact battery provides the high-voltage current to power the system. It's tucked in beneath the rear seat.A next-gen prototype on track at Honda's facility near Tochigi, JapanTim Stevens for EngadgetNone of that is radically different from what can be found in Honda's current hybrids. And, like those, these new hybrids will be able to run in an effective series hybrid mode, where the engine just charges the battery and the car drives exclusively using the electric motors. Or, step on that throttle harder at higher speeds and the car can directly engage the engine to power the car forward.That's all familiar, but a few changes could have some significant impacts. On the Large platform, a new transmission enables the car to have both a \"hi\" and \"lo\" gear range, which could be a boon for anyone towing their trusty trailer up into the mountains for a weekend getaway. The Medium-sized platform can do some shifting, too, but it's only pretend shifting here using a system called S+ Shift. At the press of a button (conveniently labeled S+), this new technology creates the experience of driving a virtual eight-speed transmission that you can run up or down through by pulling on the shift paddles on the back of the steering wheel.Since, again, these hybrids are driven by their electric motors, shifting isn't really doing much of anything but making the engine rev more or less. But, by varying the electric motor's output and regeneration, you get a surge of extra resistance on deceleration and a kick of acceleration on upshifts, all to simulate the feeling of a proper transmission.I confess that I was very skeptical about how this system would really help when I went to Japan, but I was wrong. It's great. Honda prepared a prototype sedan for me to drive, and it looked all the world like a current-gen Civic up top, except with a rather large nose stuck on the front and some decidedly pronounced flared fenders. Underneath the skin was a completely different machine, built around a front-drive version of the next-gen platform. It sounded great to start, helped by what looked like a sport exhaust at the back, plus no shortage of digital augmentation coming through the speakers.The S+ button on Honda's upcoming Prelude hybridTim Stevens for EngadgetBut the S+ Shift mode really made a compelling difference, too. Even though you're really just needlessly revving that hybrid engine more or less, and actually making the system less efficient, the result is a car that feels responsive and in control, rather than something just droning on as deftly as possible.The way the car responds, aggressively downshifting as you brake for corners and giving you a little kick with every upshift on the way out, it made me smile.The rest of the car did, too. Honda's test track was far too smooth for me to sample the improved ride quality or reduction in road noise, but the car's handling felt good and its steering sharp, not quite as remarkable as the current Civic Type R but, again, way more fun than today's humble Civic Hybrid. Honda hasn't announced where this new platform will first appear, but if you want to get an early taste of S+ Shift, it'll be debuting in the upcoming Honda Prelude hybrid. That reborn coupe lacks all the other advancements to be found in Honda's next-gen platform, but it does offer the S+ virtual shifting. It's remarkably effective here, too, and with lots of parts sharing with the Civic Type R, the Prelude was a surprisingly good time.While the Prelude is hitting dealers soon, to sample cars featuring the next-gen hybrid platform, you'll have to wait a little longer. Honda representatives said it'll start showing up beneath the flesh of its machines starting as soon as next year. Based on the shape of that prototype I drove, I'd say a next-generation Civic will be among the first to sport it.This article originally appeared on Engadget at https://www.engadget.com/transportation/driving-hondas-lighter-faster-and-more-fun-next-gen-hybrid-prototype-150000472.html?src=rss",
          "content": "With the American market still struggling to get its head around the whole electric car thing, plenty of manufacturers are scaling back their EV ambitions to refocus on hybrid power. Whether that's right for the market and, indeed, the globe remains to be seen, but we can for sure expect to see a lot more cars with internal combustion over the next few years.Honda has made its plans clear on that front, which might be cause for concern among many for one simple reason: Outside of the NSX, the company's hybrids thus far haven't exactly been the most engaging of machines. That, though, could change with a new set of hybrid platforms launching soon that'll be lighter, quicker and even more fun to drive.At the company's extensive proving grounds outside of Tochigi, Japan, I was given a go in a pair of cars that gave me reason to be optimistic about this next generation of electrically assisted but still combustion-dependent machines. They rely on a series of advancements that come together to form three different platforms: Small, Medium and Large.Collectively, they're known as the Next Generation Hybrid System, and each one is designed to be modular, able to be scaled up or down to fit different models while still keeping their fundamental sections the same. Platform sharing like this makes it much easier (and cheaper) for manufacturers to roll out new machines and to do it quickly. With Honda looking to ramp up its hybrid offerings, that's key.The the engine for Honda's \"Large\" next-gen hybrid system Tim Stevens for EngadgetThese platforms encompass things like chassis, engines, electric motors and electronics, plus the wonderful web of software required to tie it all together. Reducing weight is a huge focus here, with Honda's engineers coming up with a way to maintain crash safety while dramatically reducing the size of the front and rear subframes. This alone equates to a weight savings of some 90 kilograms (about 200 pounds) in a vehicle the size of a Honda Civic. Lighter weight means more efficiency and better fuel economy. There's also a commensurate reduction in cost of 10 percent for manufacturing versus the company's current platforms, plus promises of increased grip and reduced road noise. The smallest of Honda's new platforms is destined for Honda's smallest cars, including ultra-minis that swarm Japanese streets but have rarely found much success in the United States. For now, at least, we won't be getting any cars based on that platform.The Medium and Large platforms, though, will be tucked in neatly throughout many next-generation cars from the brand. Medium will be suitable for four-cylinder machines like the Civic and crossover SUVs like the HR-V. The Large platform, meanwhile, will be used for bigger V6 machines, like the Ridgeline and Passport.Each system ties that engine to a pair of electric motors, plus an optional third electric motor at the back for all-wheel drive. A revised, more compact battery provides the high-voltage current to power the system. It's tucked in beneath the rear seat.A next-gen prototype on track at Honda's facility near Tochigi, JapanTim Stevens for EngadgetNone of that is radically different from what can be found in Honda's current hybrids. And, like those, these new hybrids will be able to run in an effective series hybrid mode, where the engine just charges the battery and the car drives exclusively using the electric motors. Or, step on that throttle harder at higher speeds and the car can directly engage the engine to power the car forward.That's all familiar, but a few changes could have some significant impacts. On the Large platform, a new transmission enables the car to have both a \"hi\" and \"lo\" gear range, which could be a boon for anyone towing their trusty trailer up into the mountains for a weekend getaway. The Medium-sized platform can do some shifting, too, but it's only pretend shifting here using a system called S+ Shift. At the press of a button (conveniently labeled S+), this new technology creates the experience of driving a virtual eight-speed transmission that you can run up or down through by pulling on the shift paddles on the back of the steering wheel.Since, again, these hybrids are driven by their electric motors, shifting isn't really doing much of anything but making the engine rev more or less. But, by varying the electric motor's output and regeneration, you get a surge of extra resistance on deceleration and a kick of acceleration on upshifts, all to simulate the feeling of a proper transmission.I confess that I was very skeptical about how this system would really help when I went to Japan, but I was wrong. It's great. Honda prepared a prototype sedan for me to drive, and it looked all the world like a current-gen Civic up top, except with a rather large nose stuck on the front and some decidedly pronounced flared fenders. Underneath the skin was a completely different machine, built around a front-drive version of the next-gen platform. It sounded great to start, helped by what looked like a sport exhaust at the back, plus no shortage of digital augmentation coming through the speakers.The S+ button on Honda's upcoming Prelude hybridTim Stevens for EngadgetBut the S+ Shift mode really made a compelling difference, too. Even though you're really just needlessly revving that hybrid engine more or less, and actually making the system less efficient, the result is a car that feels responsive and in control, rather than something just droning on as deftly as possible.The way the car responds, aggressively downshifting as you brake for corners and giving you a little kick with every upshift on the way out, it made me smile.The rest of the car did, too. Honda's test track was far too smooth for me to sample the improved ride quality or reduction in road noise, but the car's handling felt good and its steering sharp, not quite as remarkable as the current Civic Type R but, again, way more fun than today's humble Civic Hybrid. Honda hasn't announced where this new platform will first appear, but if you want to get an early taste of S+ Shift, it'll be debuting in the upcoming Honda Prelude hybrid. That reborn coupe lacks all the other advancements to be found in Honda's next-gen platform, but it does offer the S+ virtual shifting. It's remarkably effective here, too, and with lots of parts sharing with the Civic Type R, the Prelude was a surprisingly good time.While the Prelude is hitting dealers soon, to sample cars featuring the next-gen hybrid platform, you'll have to wait a little longer. Honda representatives said it'll start showing up beneath the flesh of its machines starting as soon as next year. Based on the shape of that prototype I drove, I'd say a next-generation Civic will be among the first to sport it.This article originally appeared on Engadget at https://www.engadget.com/transportation/driving-hondas-lighter-faster-and-more-fun-next-gen-hybrid-prototype-150000472.html?src=rss",
          "feed_position": 30,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/2025_Honda_Next-Gen_Hybrid_first_drive_%285%29.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/transportation/evs/honda-shows-off-three-new-evs-in-tokyo-but-its-us-plans-are-getting-more-tepid-150000775.html",
          "published_at": "Wed, 05 Nov 2025 15:00:00 +0000",
          "title": "Honda shows off three new EVs in Tokyo, but its US plans are getting more tepid",
          "standfirst": "Every two years, the Japan Mobility Show gives us a preview of the future of motoring as envisioned by the major Japanese manufacturers. Sadly, for Honda, the resounding message coming from this year's show was that the future is getting a little farther away. That's the case for American drivers, at least, thanks largely to the effects of the Trump administration according to Honda CEO Toshihiro Mibe. In Tokyo this year, the company unveiled a trio of cool, next-gen electric vehicles at the show, each more compelling than the next. First up is the new 0 Series α, a new addition to the 0 Series of EVs that Honda has been teasing us with for a few years now.Back in January at CES, the company showed off the evocatively styled 0 Saloon and 0 SUV. Both made quite a stir, particularly the former, which was impossible to admire without picking up strong Lamborghini vibes. Mibe confirmed that those cars are still on track, coming towards the end of 2026 or 2027. However, expected sales have been reduced. Mibe didn't give specifics there, only saying: \"The volume initially will probably be less than we had envisioned earlier.\"Honda 0 Series α EV looks similar to the SUV prototype from CES 2025HondaThe newly unveiled 0 Series α is a new, third member of Honda's nascent next-gen EV family. It looks nigh identical to the SUV concept, but in reality, it's significantly smaller. It will be cheaper, too, enabling it to target the Indian market. It has a hope of going elsewhere in the world, including Japan and Europe, but Honda representatives said repeatedly that it's not for the American market. Mibe said it's \"probably too small\" for the US market.So, too, the Super-One Prototype. This tiny hatchback made a run up the hill at the Goodwood Festival of Speed earlier this year, wrapped in camouflage to hide its decidedly angular profile. In Tokyo, Honda stripped off the graphics, revealing a cheeky mini-sized machine with big box fenders and endless personality. While Honda didn't quote a power output, it surely won’t be a rocket ship, but with the instant torque of an EV, plus a variety of selectable synthesized engine notes, it should still be a mighty good time.Indeed, it was. I got a brief go behind the wheel of a prototype machine at Honda's proving grounds in Tochigi, Japan. Though it wasn't much for outright speed, the brisk acceleration combined with petite dimensions made me grin ear-to-ear. Sadly, though, that's probably the only chance I'll ever get to drive one. The Super-One is intended for drivers in Japan and the United Kingdom, with potential expansion elsewhere in Europe based on demand.Driving the Honda Super-One on a test track near Tochigi, JapanTim Stevens for EngadgetAmerica has never been a great market for machines of that size, so it shouldn't be a surprise that these two aren't US-bound, but it is part of a more troubling trend. Honda has largely paused its efforts to develop low-cost EVs for the American market, waiting for political headwinds to come around.\"With the Trump administration in place, we have a sense that maybe the EV growth has been moved back out by maybe five years or so into the future. So, the timing for doing anything will be difficult,\" he said. \"2030, at that point in time, maybe we need to provide a wide, broad product range, including EVs. So, we will have to think about future strategy for the US market.\"Tellingly, Mibe said that they're actively watching American mid-term elections, to see whether there's any hope of the political climate changing in the future. Just like in discount furniture stores, volume is the real factor here, particularly when it comes to battery production. The company's partnership with General Motors was an attempt to do just that.Honda's Super-One prototype isn't much for speed, but that's okayTim Stevens for Engadget\"Our first objective in collaborating with GM was to expand the volume to reduce the cost,\" he said. \"I believe the aim there, from on the side of GM, was the same.\"That partnership, however, was aborted after just the Honda Prologue and Acura ZDX reached the market, leaving Honda to go its own way for now, at least, bereft of a partner to boost its battery volume. This could complicate Honda's plans to be totally carbon neutral by 2050, a pledge that Mibe said is still very much in the cards. To start in that direction, the company will push more towards advanced hybrids of the sort we'll get our first taste of starting next year. (I also got to sample that while I was out there, which you can read about here.)However, while these new hybrids will decrease consumption and further reduce the carbon footprint of a given car, they will not completely eliminate it. So, Honda is working on other means of decreasing the company's effective carbon footprint, including direct air capture (DAC), devices which can suck carbon dioxide straight out of the air — a long-time environmental dream that's always seemed just a few years away.So small, cheap EVs aren't in the plans for the immediate future, but Honda isn't totally giving up on its US EV aspirations. Again, the 0 Series SUV and Saloon are due next year. Mibe said there's another, even larger EV due for the American market sometime after 2030, but that too could depend on which way the American government swings between now and then. Honda's EV Outlier is an electric motorcycle concept with sci-fi looksHondaIf all's looking well, we might eventually get a taste of another electric concept that Honda rolled out at the show. Called the EV Outlier, it's an electric motorcycle with a lean, sharp style and a laid-back riding position that is hard not to read as at least partially inspired by that most iconic sci-fi motorcycle of all time: Kaneda's bike in Akira.This one isn't red and it lacks the distinctive stickers, but like Kaneda's bike, both wheels are driven by electricity. It relies on a pair of integrated hub motors to provide the thrust, and if the width of the rear tire is any indication, there'll be plenty of that.A sweeping, free-standing digital display serves as the dashboard, and controls are minimalist in a way that only a concept bike can be. Honda said this might be ready for production by 2030, but the svelte packaging here may necessitate next-generation, solid-state batteries to make that a reality. Those batteries, Mibe said, are still progressing. Honda has a prototype production line in process, so they're actually building the things and trying to turn them into viable products.But that's only if Honda can overcome some significant engineering challenges between now and then, and if the US government dials back on the EV hate by the end of the decade. Those are two pretty big ifs, and I confess I'm not sure which poses the biggest challenge.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/honda-shows-off-three-new-evs-in-tokyo-but-its-us-plans-are-getting-more-tepid-150000775.html?src=rss",
          "content": "Every two years, the Japan Mobility Show gives us a preview of the future of motoring as envisioned by the major Japanese manufacturers. Sadly, for Honda, the resounding message coming from this year's show was that the future is getting a little farther away. That's the case for American drivers, at least, thanks largely to the effects of the Trump administration according to Honda CEO Toshihiro Mibe. In Tokyo this year, the company unveiled a trio of cool, next-gen electric vehicles at the show, each more compelling than the next. First up is the new 0 Series α, a new addition to the 0 Series of EVs that Honda has been teasing us with for a few years now.Back in January at CES, the company showed off the evocatively styled 0 Saloon and 0 SUV. Both made quite a stir, particularly the former, which was impossible to admire without picking up strong Lamborghini vibes. Mibe confirmed that those cars are still on track, coming towards the end of 2026 or 2027. However, expected sales have been reduced. Mibe didn't give specifics there, only saying: \"The volume initially will probably be less than we had envisioned earlier.\"Honda 0 Series α EV looks similar to the SUV prototype from CES 2025HondaThe newly unveiled 0 Series α is a new, third member of Honda's nascent next-gen EV family. It looks nigh identical to the SUV concept, but in reality, it's significantly smaller. It will be cheaper, too, enabling it to target the Indian market. It has a hope of going elsewhere in the world, including Japan and Europe, but Honda representatives said repeatedly that it's not for the American market. Mibe said it's \"probably too small\" for the US market.So, too, the Super-One Prototype. This tiny hatchback made a run up the hill at the Goodwood Festival of Speed earlier this year, wrapped in camouflage to hide its decidedly angular profile. In Tokyo, Honda stripped off the graphics, revealing a cheeky mini-sized machine with big box fenders and endless personality. While Honda didn't quote a power output, it surely won’t be a rocket ship, but with the instant torque of an EV, plus a variety of selectable synthesized engine notes, it should still be a mighty good time.Indeed, it was. I got a brief go behind the wheel of a prototype machine at Honda's proving grounds in Tochigi, Japan. Though it wasn't much for outright speed, the brisk acceleration combined with petite dimensions made me grin ear-to-ear. Sadly, though, that's probably the only chance I'll ever get to drive one. The Super-One is intended for drivers in Japan and the United Kingdom, with potential expansion elsewhere in Europe based on demand.Driving the Honda Super-One on a test track near Tochigi, JapanTim Stevens for EngadgetAmerica has never been a great market for machines of that size, so it shouldn't be a surprise that these two aren't US-bound, but it is part of a more troubling trend. Honda has largely paused its efforts to develop low-cost EVs for the American market, waiting for political headwinds to come around.\"With the Trump administration in place, we have a sense that maybe the EV growth has been moved back out by maybe five years or so into the future. So, the timing for doing anything will be difficult,\" he said. \"2030, at that point in time, maybe we need to provide a wide, broad product range, including EVs. So, we will have to think about future strategy for the US market.\"Tellingly, Mibe said that they're actively watching American mid-term elections, to see whether there's any hope of the political climate changing in the future. Just like in discount furniture stores, volume is the real factor here, particularly when it comes to battery production. The company's partnership with General Motors was an attempt to do just that.Honda's Super-One prototype isn't much for speed, but that's okayTim Stevens for Engadget\"Our first objective in collaborating with GM was to expand the volume to reduce the cost,\" he said. \"I believe the aim there, from on the side of GM, was the same.\"That partnership, however, was aborted after just the Honda Prologue and Acura ZDX reached the market, leaving Honda to go its own way for now, at least, bereft of a partner to boost its battery volume. This could complicate Honda's plans to be totally carbon neutral by 2050, a pledge that Mibe said is still very much in the cards. To start in that direction, the company will push more towards advanced hybrids of the sort we'll get our first taste of starting next year. (I also got to sample that while I was out there, which you can read about here.)However, while these new hybrids will decrease consumption and further reduce the carbon footprint of a given car, they will not completely eliminate it. So, Honda is working on other means of decreasing the company's effective carbon footprint, including direct air capture (DAC), devices which can suck carbon dioxide straight out of the air — a long-time environmental dream that's always seemed just a few years away.So small, cheap EVs aren't in the plans for the immediate future, but Honda isn't totally giving up on its US EV aspirations. Again, the 0 Series SUV and Saloon are due next year. Mibe said there's another, even larger EV due for the American market sometime after 2030, but that too could depend on which way the American government swings between now and then. Honda's EV Outlier is an electric motorcycle concept with sci-fi looksHondaIf all's looking well, we might eventually get a taste of another electric concept that Honda rolled out at the show. Called the EV Outlier, it's an electric motorcycle with a lean, sharp style and a laid-back riding position that is hard not to read as at least partially inspired by that most iconic sci-fi motorcycle of all time: Kaneda's bike in Akira.This one isn't red and it lacks the distinctive stickers, but like Kaneda's bike, both wheels are driven by electricity. It relies on a pair of integrated hub motors to provide the thrust, and if the width of the rear tire is any indication, there'll be plenty of that.A sweeping, free-standing digital display serves as the dashboard, and controls are minimalist in a way that only a concept bike can be. Honda said this might be ready for production by 2030, but the svelte packaging here may necessitate next-generation, solid-state batteries to make that a reality. Those batteries, Mibe said, are still progressing. Honda has a prototype production line in process, so they're actually building the things and trying to turn them into viable products.But that's only if Honda can overcome some significant engineering challenges between now and then, and if the US government dials back on the EV hate by the end of the decade. Those are two pretty big ifs, and I confess I'm not sure which poses the biggest challenge.This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/honda-shows-off-three-new-evs-in-tokyo-but-its-us-plans-are-getting-more-tepid-150000775.html?src=rss",
          "feed_position": 31,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/2026_Honda_0_series_alpha_%282%29.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/you-can-now-stream-ps5-games-you-own-over-the-cloud-on-the-playstation-portal-135025829.html",
          "published_at": "Wed, 05 Nov 2025 14:25:07 +0000",
          "title": "You can now stream PS5 games you own over the cloud on the PlayStation Portal",
          "standfirst": "Slowly but surely, Sony has been transforming the initially limited PlayStation Portal into a viable handheld for PS5 gamers, albeit only those with a solid internet connection. What launched as a strictly remote play device eventually got unlocked for cloud streaming, with PS Plus Premium members able to play select Game Catalog games without needing to connect to a PS5. And from 6am PT today, you can also stream select digital PS5 games that you own on the Portal. Again, you’ll need to have a PS Plus Premium membership to take advantage of the new features, but once signed up to the most expensive tier of Sony’s subscription service you’ll be able to stream the likes of Astro Bot, Borderlands 4, Final Fantasy VII Rebirth and Ghost of Yotei, which are among the the thousands of games supported at launch. Naturally some of the games in your library will probably be on PS Plus as cloud-streamable games already, but newer first-party games like several of those mentioned above aren't. You could, of course, already also play all of these games on the Portal over remote play from your PS5. But now that the device has been untethered from the main console, it gets a little bit closer to the dedicated go-anywhere PlayStation handheld everyone wants. That's provided you have a decent enough Wi-Fi connection to get a good quality stream. Alongside the new cloud streaming functionality, the Portal has a new home screen that adds a search tab for quickly finding games that are available to stream. The latest update also adds 3D audio support for supported games on both remote play and cloud streams when using wired headphones or one of Sony’s proprietary PlayStation Link headsets. You can also now add a passcode lock to the device, while a new network status screen is available in the Quick menu. Sony now allows you to make in-game purchases while streaming games over the cloud without leaving a session, and if you have a friend playing the same game you’re streaming, you can receive invites and join their game from the Quick menu. Sony seems intent on the PlayStation Portal plugging the gap between now and the PS6, which could reportedly arrive in the next two years alongside a powerful complementary handheld device that might beat out the ROG Xbox Ally X in the specs department. A next-generation native PlayStation handheld remains the dream, but in the meantime, the Portal is a lot more appealing than it was a few years ago. This article originally appeared on Engadget at https://www.engadget.com/gaming/you-can-now-stream-ps5-games-you-own-over-the-cloud-on-the-playstation-portal-135025829.html?src=rss",
          "content": "Slowly but surely, Sony has been transforming the initially limited PlayStation Portal into a viable handheld for PS5 gamers, albeit only those with a solid internet connection. What launched as a strictly remote play device eventually got unlocked for cloud streaming, with PS Plus Premium members able to play select Game Catalog games without needing to connect to a PS5. And from 6am PT today, you can also stream select digital PS5 games that you own on the Portal. Again, you’ll need to have a PS Plus Premium membership to take advantage of the new features, but once signed up to the most expensive tier of Sony’s subscription service you’ll be able to stream the likes of Astro Bot, Borderlands 4, Final Fantasy VII Rebirth and Ghost of Yotei, which are among the the thousands of games supported at launch. Naturally some of the games in your library will probably be on PS Plus as cloud-streamable games already, but newer first-party games like several of those mentioned above aren't. You could, of course, already also play all of these games on the Portal over remote play from your PS5. But now that the device has been untethered from the main console, it gets a little bit closer to the dedicated go-anywhere PlayStation handheld everyone wants. That's provided you have a decent enough Wi-Fi connection to get a good quality stream. Alongside the new cloud streaming functionality, the Portal has a new home screen that adds a search tab for quickly finding games that are available to stream. The latest update also adds 3D audio support for supported games on both remote play and cloud streams when using wired headphones or one of Sony’s proprietary PlayStation Link headsets. You can also now add a passcode lock to the device, while a new network status screen is available in the Quick menu. Sony now allows you to make in-game purchases while streaming games over the cloud without leaving a session, and if you have a friend playing the same game you’re streaming, you can receive invites and join their game from the Quick menu. Sony seems intent on the PlayStation Portal plugging the gap between now and the PS6, which could reportedly arrive in the next two years alongside a powerful complementary handheld device that might beat out the ROG Xbox Ally X in the specs department. A next-generation native PlayStation handheld remains the dream, but in the meantime, the Portal is a lot more appealing than it was a few years ago. This article originally appeared on Engadget at https://www.engadget.com/gaming/you-can-now-stream-ps5-games-you-own-over-the-cloud-on-the-playstation-portal-135025829.html?src=rss",
          "feed_position": 32
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/dyson-black-friday-deals-get-up-to-330-off-cordless-vacuums-right-now-173533592.html",
          "published_at": "Wed, 05 Nov 2025 13:20:37 +0000",
          "title": "Dyson Black Friday deals: Get up to $330 off cordless vacuums right now",
          "standfirst": "Early Black Friday deals are starting to pop up across the web, and a great one to check out is at Dyson. While we still think you have the best shot to get the steepest discounts the closer to Black Friday we get, some of the discounts on Dyson's site right now are some of the best we've seen. One of those is $330 off the Dyson V9 Motorbar cordless vacuum, bringing it down to $270. Dyson devices are all over our list of the best cordless vacuums, and for good reason. The company makes effective products. The V9 Motorbar has been designed to clean all floor types, in addition to upholstery. It's also been engineered to squeeze into tight spots, which is great for hitting those oft-neglected parts of the home. The suction power is on point and the battery lasts for 40 minutes before requiring a charge. That's just enough time to vacuum a standard-sized home if you don't stop for too many breaks. The V9 is getting a bit long-in-the-tooth. If you want a newer model, the V11 Extra is on sale for $400, which is a discount of $260. This one boosts the suction power and increases the battery life to 60 minutes. The early Black Friday sale isn't just for cordless vacuums. The 360 Vis Nav robot vacuum is on sale right now for $500, which is a massive discount of $500. This is one of our favorite robot vacuums, primarily because of its incredible suction power. This article originally appeared on Engadget at https://www.engadget.com/deals/dyson-black-friday-deals-get-up-to-330-off-cordless-vacuums-right-now-173533592.html?src=rss",
          "content": "Early Black Friday deals are starting to pop up across the web, and a great one to check out is at Dyson. While we still think you have the best shot to get the steepest discounts the closer to Black Friday we get, some of the discounts on Dyson's site right now are some of the best we've seen. One of those is $330 off the Dyson V9 Motorbar cordless vacuum, bringing it down to $270. Dyson devices are all over our list of the best cordless vacuums, and for good reason. The company makes effective products. The V9 Motorbar has been designed to clean all floor types, in addition to upholstery. It's also been engineered to squeeze into tight spots, which is great for hitting those oft-neglected parts of the home. The suction power is on point and the battery lasts for 40 minutes before requiring a charge. That's just enough time to vacuum a standard-sized home if you don't stop for too many breaks. The V9 is getting a bit long-in-the-tooth. If you want a newer model, the V11 Extra is on sale for $400, which is a discount of $260. This one boosts the suction power and increases the battery life to 60 minutes. The early Black Friday sale isn't just for cordless vacuums. The 360 Vis Nav robot vacuum is on sale right now for $500, which is a massive discount of $500. This is one of our favorite robot vacuums, primarily because of its incredible suction power. This article originally appeared on Engadget at https://www.engadget.com/deals/dyson-black-friday-deals-get-up-to-330-off-cordless-vacuums-right-now-173533592.html?src=rss",
          "feed_position": 37
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/ecoflows-early-black-friday-deals-include-42-percent-off-portable-power-stations-130041544.html",
          "published_at": "Wed, 05 Nov 2025 13:00:41 +0000",
          "title": "EcoFlow's early Black Friday deals include 42 percent off portable power stations",
          "standfirst": "EcoFlow is hosting an early Black Friday sale on portable power stations. This drops prices by up to 42 percent on many of its well-regarded products. For instance, the Delta Pro 3 is on sale for $2,299. This is a discount of 37 percent, as the typical cost is $3,699. That's a significant drop in price. The Delta Pro 3 topped Yahoo's list of the best portable power stations, and for very good reason. This thing is a beast. It boasts a 4,096Wh capacity, so it can power an average 500-watt refrigerator for over 24 hours. That's with continuous use. It can be stretched out to two or three days by only running the appliance during daylight hours. There's even a discounted bundle that includes an extra battery for $3,599. It includes four standard 120V AC outlets and a single 240V outlet. It could potentially be a temporary hub of a whole-home battery backup. There are numerous charging options here, including a standard AC outlet, solar panels and, interestingly, a cigarette lighter. The only potential downside here is the Delta Pro 3 really pushes the boundaries of what can be considered portable. It weighs 113 pounds, though it does have wheels and a telescoping handle. The Delta Pro 3 is just one of the products on sale right now. The Delta Pro Ultra, which is intended as a whole-home backup, is down to $3,999. This represents a savings of more than $2,000.This article originally appeared on Engadget at https://www.engadget.com/deals/ecoflows-early-black-friday-deals-include-42-percent-off-portable-power-stations-130041544.html?src=rss",
          "content": "EcoFlow is hosting an early Black Friday sale on portable power stations. This drops prices by up to 42 percent on many of its well-regarded products. For instance, the Delta Pro 3 is on sale for $2,299. This is a discount of 37 percent, as the typical cost is $3,699. That's a significant drop in price. The Delta Pro 3 topped Yahoo's list of the best portable power stations, and for very good reason. This thing is a beast. It boasts a 4,096Wh capacity, so it can power an average 500-watt refrigerator for over 24 hours. That's with continuous use. It can be stretched out to two or three days by only running the appliance during daylight hours. There's even a discounted bundle that includes an extra battery for $3,599. It includes four standard 120V AC outlets and a single 240V outlet. It could potentially be a temporary hub of a whole-home battery backup. There are numerous charging options here, including a standard AC outlet, solar panels and, interestingly, a cigarette lighter. The only potential downside here is the Delta Pro 3 really pushes the boundaries of what can be considered portable. It weighs 113 pounds, though it does have wheels and a telescoping handle. The Delta Pro 3 is just one of the products on sale right now. The Delta Pro Ultra, which is intended as a whole-home backup, is down to $3,999. This represents a savings of more than $2,000.This article originally appeared on Engadget at https://www.engadget.com/deals/ecoflows-early-black-friday-deals-include-42-percent-off-portable-power-stations-130041544.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/best-cheap-android-phone-160029703.html",
          "published_at": "Wed, 05 Nov 2025 10:01:28 +0000",
          "title": "The best cheap Android phones to buy in 2025",
          "standfirst": "Getting a solid Android phone doesn’t necessitate spending a small fortune. The best budget models strike a great balance between price and performance, giving you smooth everyday use without cutting too many corners. Whether you’re scrolling social media, streaming your favorite shows or snapping photos of a night out, there’s an affordable Android phone that can handle it all.Cheaper phones have come a long way in recent years. Many now feature bright, fast displays, reliable cameras and battery life that lasts well into the next day. You might miss out on top-tier extras like the latest processor or ultra-high-resolution zoom, but what you get instead is value that makes sense. Some models even surprise with cameras that rival far pricier flagships, making them ideal for casual photographers or anyone who just wants to capture a great shot on the go.We’ve tested budget Android phones from brands like Google, Samsung and OnePlus to find the ones that deliver the most for less. These are the models that prove you don’t need a flagship price tag to get a dependable Android phone. Table of contents Best budget Android phones for 2025 How cheap should you go for an Android phone? What to look for in a cheap phone Android phone FAQs Best budget Android phones for 2025 How cheap should you go for an Android phone? We tend to define a budget smartphone as costing between $150 and $350. Any lower and the device runs the risk of suffering from too many compromises in function, and above that, you cross over to pricier midrange handsets (if you're open to spending more, we shouted out a couple of our favorite flagship phones at the very end of this guide). But for those with a little wiggle room, there are some things to consider. For example, a child may be better off with a cheaper device, especially if it’s intended mainly for emergencies, WiFi browsing or texting parents (and not social media). On the higher end of this price spectrum, sub-$350 Samsung phones and other Android devices have come a long way thanks to improved performance, better phone cameras with low-light capabilities, fast charging, and nicer displays like AMOLED panels. This makes them a viable alternative to, say, a flagship handset with a premium design, even if you have the flexibility to spend more. What to look for in a cheap Android phone When it comes to cheap phones, you get what you pay for. Most smartphones in this price range are made out of plastic, though the fit and finish of a specific model can vary a lot based on price. A bright screen is also important. Typically you’ll get LCD panels with a 60Hz or 90Hz refresh rate, but some phones may have OLED or AMOLED screens with increased color saturation. Long battery life is critical as well, so we tend to favor devices with larger power cells of around 5,000 mAh. In this price range, performance can vary a lot, so look for devices with at least 8GB of RAM and processors that can deliver stutter-free visuals. It’s also important to consider support length: as periodic security updates and lengthy software support can extend the longevity of your device, which will save you money in the long run. Android phone FAQs What's the price difference for a cheap Android vs a cheap iPhone? iPhones tend to be more expensive compared to Android phones — even the cheapest iPhone, the iPhone SE, which starts from $429, is a harder pill to swallow compared to a cheap Android phone. In contrast, you can get your hands on a cheap Android device for as low as $100.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-cheap-android-phone-160029703.html?src=rss",
          "content": "Getting a solid Android phone doesn’t necessitate spending a small fortune. The best budget models strike a great balance between price and performance, giving you smooth everyday use without cutting too many corners. Whether you’re scrolling social media, streaming your favorite shows or snapping photos of a night out, there’s an affordable Android phone that can handle it all.Cheaper phones have come a long way in recent years. Many now feature bright, fast displays, reliable cameras and battery life that lasts well into the next day. You might miss out on top-tier extras like the latest processor or ultra-high-resolution zoom, but what you get instead is value that makes sense. Some models even surprise with cameras that rival far pricier flagships, making them ideal for casual photographers or anyone who just wants to capture a great shot on the go.We’ve tested budget Android phones from brands like Google, Samsung and OnePlus to find the ones that deliver the most for less. These are the models that prove you don’t need a flagship price tag to get a dependable Android phone. Table of contents Best budget Android phones for 2025 How cheap should you go for an Android phone? What to look for in a cheap phone Android phone FAQs Best budget Android phones for 2025 How cheap should you go for an Android phone? We tend to define a budget smartphone as costing between $150 and $350. Any lower and the device runs the risk of suffering from too many compromises in function, and above that, you cross over to pricier midrange handsets (if you're open to spending more, we shouted out a couple of our favorite flagship phones at the very end of this guide). But for those with a little wiggle room, there are some things to consider. For example, a child may be better off with a cheaper device, especially if it’s intended mainly for emergencies, WiFi browsing or texting parents (and not social media). On the higher end of this price spectrum, sub-$350 Samsung phones and other Android devices have come a long way thanks to improved performance, better phone cameras with low-light capabilities, fast charging, and nicer displays like AMOLED panels. This makes them a viable alternative to, say, a flagship handset with a premium design, even if you have the flexibility to spend more. What to look for in a cheap Android phone When it comes to cheap phones, you get what you pay for. Most smartphones in this price range are made out of plastic, though the fit and finish of a specific model can vary a lot based on price. A bright screen is also important. Typically you’ll get LCD panels with a 60Hz or 90Hz refresh rate, but some phones may have OLED or AMOLED screens with increased color saturation. Long battery life is critical as well, so we tend to favor devices with larger power cells of around 5,000 mAh. In this price range, performance can vary a lot, so look for devices with at least 8GB of RAM and processors that can deliver stutter-free visuals. It’s also important to consider support length: as periodic security updates and lengthy software support can extend the longevity of your device, which will save you money in the long run. Android phone FAQs What's the price difference for a cheap Android vs a cheap iPhone? iPhones tend to be more expensive compared to Android phones — even the cheapest iPhone, the iPhone SE, which starts from $429, is a harder pill to swallow compared to a cheap Android phone. In contrast, you can get your hands on a cheap Android device for as low as $100.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-cheap-android-phone-160029703.html?src=rss",
          "feed_position": 43
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-magsafe-power-banks-120015338.html",
          "published_at": "Wed, 05 Nov 2025 08:00:35 +0000",
          "title": "The best MagSafe power banks for your iPhone",
          "standfirst": "When you search for a MagSafe power bank on Amazon, among the top recommendations are outdated banks that max out at 7.5-watt wireless charging. Now that Qi2 and Qi2 25W technology have arrived, iPhones can refill much faster. In our tests, older-gen batteries got a phone to 50 percent in just under two hours on average. Our pick for the best Qi2 25W power bank did that in about a half hour. You may also be tempted by Apple’s iPhone Air MagSafe Battery, but we found a better (read: cheaper) choice. We used more than a dozen batteries for this guide and continue to try out new models so you can buy the best MagSafe power bank — that someone actually tested first. The best MagSafe power banks for 2025 What to consider before buying a MagSafe power bank Choose the right capacity. Most portable MagSafe chargers have either a 5,000 milliamp hour (mAh) or 10,000mAh capacity. Obviously, the larger capacity batteries are physically bigger, but thanks to an iPhone’s magnetic attachment points, you can still use the phone comfortably as it charges. If you’re worried about overall bulk, you may prefer the slimness of a 5,000mAh battery. Just note that a 5K battery pack won’t deliver its entire capacity to your phone due to energy loss from voltage conversion and heat dissipation. Over the years, I’ve measured around a 60-percent delivery rate for wireless banks. For example, that means an iPhone 16 with its 3,561mAh battery will get about 85 to 90 percentage points from a 5K battery. A 10K bank will charge that same phone fully once, with enough for a 50- to 60-percent boost next time. Understand MagSafe versus Qi2. All iPhones model 12 and later have MagSafe technology, which rely on embedded magnets to align the phone with a wireless charger and can support charging speeds of up to 15 watts. The MagSafe name is owned by Apple — third-party chargers can’t freely use the term and instead call their accessories “magnetic,” or apply a branded name like Anker’s MagGo or UGreen’s MagFlow. Be sure to check the product details before buying: anything that works with Apple’s technology will be listed as MagSafe-compatible. Qi2 is a standard from the Wireless Power Consortium (of which Apple is a member) and has the same stipulations as MagSafe (15W charging and magnetic alignment). Any company can submit their tech for this certification. iPhones 13 and later are Qi2 compatible. The newest standard, Qi2 25W (also called Qi2.2), bumps wireless charging speeds up to 25W. The WPC says a certified smartphone using a certified charger can wirelessly go from dead to half full in about 30 minutes (keep in mind that both the charger and phone need to be certified to get those speeds) and that aligns with our testing. Accessories, like power banks that support the new standard are starting to hit shelves now. As for phones, Google’s Pixel 10 Pro XL, Apple’s iPhone 17, iPhone 17 Pro and Pro Max all support the standard as well. iPhone 16 models (except the 16e) support the standard after an update to iOS 26. Remember travel restrictions. You may have seen news reports of flights being grounded because a power bank caught fire in the cabin. Currently, the TSA allows them in your carry-on luggage as long as they’re rated at 100 watt-hours or lower (about 27,000mAh for lithium ion batteries). But some airlines have enacted further restrictions. Southwest, for example, requires you to keep power banks out of the bag and visible while charging. Even if your airline doesn’t make such demands, keeping a power brick out in the open while it’s in use is a good idea — it’ll keep it cooler and you’ll be more likely to notice if it starts to overheat. Most, if not all, MagSafe battery packs come in at under the 100-watt-hour limit, so traveling should be easy with one. Consider the extra features. You may not need them, but the little extra perks of a MagSafe power bank can come in handy. Some have stands so you can watch your phone while it refills. Some have LED displays that tell you how much charge is left, which can be a little more precise than the lighted pips other banks use. Some also have straps to make the bank easier to carry around or fish out of your bag. What about the iPhone Air MagSafe Battery? When Apple introduced the iPhone Air, it announced the new $99 iPhone Air MagSafe Battery in the same breath. It’s now the sole Apple-branded MagSafe power bank — but it only works with the iPhone Air. It’s a pretty divisive battery. In his review of the new phone, Engadget’s Sam Rutherford appreciated that the accessory keeps with the sleekness of the iPhone Air design and liked that it can also charge the new AirPods 3 wirelessly. But Valentina Palladino called out its dismal price-to-capacity ratio. Anker’s Nano MagGo Slim is probably a better bet for all but the most devoted iPhone user. It has the same minimalist look and pocketable thinness as Apple’s proprietary battery, but it’ll attach to other phones in addition to the Air. Plus it’s $35 cheaper. Other MagSafe batteries we tested Mophie Powerstation Slim 5K The Mophie Powerstation Slim 5K, too, has a super slim design that nearly disappears into the back of the phone as it charges. It makes excellent use of its 5K capacity, delivering a 90 percent refill to an iPhone 15. But it’s a little more expensive than the our top slim pick, Anker’s Nano MagGo Slim, and the squared off design makes it feel bulkier than it actually is. Neither of those make it a bad choice; the MagSafe battery playing field is just terribly competitive right now. Belkin BoostCharge Pro 10K Belkin’s BoostCharge Pro is Qi2-certified and was only a touch slower than other models in terms of charging speeds, boosting an iPhone 15 from 5 percent to full in about two and a half hours. The feel is premium and the stand is sturdy, but it got quite hot during charging, took overly long to refill itself and is pricer and a bit bulkier than similar models. Baseus Picogo 5K The Picogo 5K from Baseus is teensy but still packs a stand and a 5,000mAh capacity. It’s Qi2-certified and delivered a 43 percent bump to our tester iPhone 15 in 42 minutes, ultimately charging it to 91 percent. The slim slab of the Anker Nano battery is sleeker. But that one doesn’t have a stand — so if you want to prop up your phone while it charges, go for this one. MagSafe power banks FAQs What does MagSafe do? MagSafe is Apple’s own technology that supports up to 25W wireless charging speeds and incorporates embedded magnets to align the phone with chargers and other accessories. Which iPhones support MagSafe? iPhones 12 and later support 15W MagSafe technology, though only iPhones 13 and later can reach the 15W charging speed with third-party Qi2 accessories. The iPhone 12 maxes out at 7.5W with non-Apple accessories. The new iPhone 17, 17 Pro and 17 Pro Max support up to 25W charging speeds with Qi2 25W-certified chargers. iPhone 16, 16 Pro and 16 Pro Max should also support those speeds after an update to iOS 26. The iPhone Air supports MagSafe charging at a max speed of 20W. Can you use MagSafe batteries with a case? In most cases (heh), yes. The wireless charge can travel across a distance of a few millimeters. If the case is more than 5mm thick or contains metal components, the wireless charge can be blocked. Many iPhone cases are marketed as MagSafe-compatible, which means the case itself has complimentary magnets inside and should not interfere with charging accessories. We tested a MagSafe power bank on an iPhone 15 with and without a MagSafe case and got the same charging speeds and amounts in both tests. How much power do MagSafe batteries provide? That depends on the power bank. If it is Qi2-certified, it can provide up to 15 watts of wireless power. Qi2 25W-enabled chargers can deliver up to 25 watts to a compatible handset. Non-Qi2 batteries typically deliver around 7.5 watts. The amount of charge delivered depends on the capacity. Most MagSafe portable chargers are rated at 5,000mAh or 10,000mAh. The former can get a standard iPhone 15 from five percent to around 90 percent. The latter can fill the phone completely with enough left over for another half charge.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-magsafe-power-banks-120015338.html?src=rss",
          "content": "When you search for a MagSafe power bank on Amazon, among the top recommendations are outdated banks that max out at 7.5-watt wireless charging. Now that Qi2 and Qi2 25W technology have arrived, iPhones can refill much faster. In our tests, older-gen batteries got a phone to 50 percent in just under two hours on average. Our pick for the best Qi2 25W power bank did that in about a half hour. You may also be tempted by Apple’s iPhone Air MagSafe Battery, but we found a better (read: cheaper) choice. We used more than a dozen batteries for this guide and continue to try out new models so you can buy the best MagSafe power bank — that someone actually tested first. The best MagSafe power banks for 2025 What to consider before buying a MagSafe power bank Choose the right capacity. Most portable MagSafe chargers have either a 5,000 milliamp hour (mAh) or 10,000mAh capacity. Obviously, the larger capacity batteries are physically bigger, but thanks to an iPhone’s magnetic attachment points, you can still use the phone comfortably as it charges. If you’re worried about overall bulk, you may prefer the slimness of a 5,000mAh battery. Just note that a 5K battery pack won’t deliver its entire capacity to your phone due to energy loss from voltage conversion and heat dissipation. Over the years, I’ve measured around a 60-percent delivery rate for wireless banks. For example, that means an iPhone 16 with its 3,561mAh battery will get about 85 to 90 percentage points from a 5K battery. A 10K bank will charge that same phone fully once, with enough for a 50- to 60-percent boost next time. Understand MagSafe versus Qi2. All iPhones model 12 and later have MagSafe technology, which rely on embedded magnets to align the phone with a wireless charger and can support charging speeds of up to 15 watts. The MagSafe name is owned by Apple — third-party chargers can’t freely use the term and instead call their accessories “magnetic,” or apply a branded name like Anker’s MagGo or UGreen’s MagFlow. Be sure to check the product details before buying: anything that works with Apple’s technology will be listed as MagSafe-compatible. Qi2 is a standard from the Wireless Power Consortium (of which Apple is a member) and has the same stipulations as MagSafe (15W charging and magnetic alignment). Any company can submit their tech for this certification. iPhones 13 and later are Qi2 compatible. The newest standard, Qi2 25W (also called Qi2.2), bumps wireless charging speeds up to 25W. The WPC says a certified smartphone using a certified charger can wirelessly go from dead to half full in about 30 minutes (keep in mind that both the charger and phone need to be certified to get those speeds) and that aligns with our testing. Accessories, like power banks that support the new standard are starting to hit shelves now. As for phones, Google’s Pixel 10 Pro XL, Apple’s iPhone 17, iPhone 17 Pro and Pro Max all support the standard as well. iPhone 16 models (except the 16e) support the standard after an update to iOS 26. Remember travel restrictions. You may have seen news reports of flights being grounded because a power bank caught fire in the cabin. Currently, the TSA allows them in your carry-on luggage as long as they’re rated at 100 watt-hours or lower (about 27,000mAh for lithium ion batteries). But some airlines have enacted further restrictions. Southwest, for example, requires you to keep power banks out of the bag and visible while charging. Even if your airline doesn’t make such demands, keeping a power brick out in the open while it’s in use is a good idea — it’ll keep it cooler and you’ll be more likely to notice if it starts to overheat. Most, if not all, MagSafe battery packs come in at under the 100-watt-hour limit, so traveling should be easy with one. Consider the extra features. You may not need them, but the little extra perks of a MagSafe power bank can come in handy. Some have stands so you can watch your phone while it refills. Some have LED displays that tell you how much charge is left, which can be a little more precise than the lighted pips other banks use. Some also have straps to make the bank easier to carry around or fish out of your bag. What about the iPhone Air MagSafe Battery? When Apple introduced the iPhone Air, it announced the new $99 iPhone Air MagSafe Battery in the same breath. It’s now the sole Apple-branded MagSafe power bank — but it only works with the iPhone Air. It’s a pretty divisive battery. In his review of the new phone, Engadget’s Sam Rutherford appreciated that the accessory keeps with the sleekness of the iPhone Air design and liked that it can also charge the new AirPods 3 wirelessly. But Valentina Palladino called out its dismal price-to-capacity ratio. Anker’s Nano MagGo Slim is probably a better bet for all but the most devoted iPhone user. It has the same minimalist look and pocketable thinness as Apple’s proprietary battery, but it’ll attach to other phones in addition to the Air. Plus it’s $35 cheaper. Other MagSafe batteries we tested Mophie Powerstation Slim 5K The Mophie Powerstation Slim 5K, too, has a super slim design that nearly disappears into the back of the phone as it charges. It makes excellent use of its 5K capacity, delivering a 90 percent refill to an iPhone 15. But it’s a little more expensive than the our top slim pick, Anker’s Nano MagGo Slim, and the squared off design makes it feel bulkier than it actually is. Neither of those make it a bad choice; the MagSafe battery playing field is just terribly competitive right now. Belkin BoostCharge Pro 10K Belkin’s BoostCharge Pro is Qi2-certified and was only a touch slower than other models in terms of charging speeds, boosting an iPhone 15 from 5 percent to full in about two and a half hours. The feel is premium and the stand is sturdy, but it got quite hot during charging, took overly long to refill itself and is pricer and a bit bulkier than similar models. Baseus Picogo 5K The Picogo 5K from Baseus is teensy but still packs a stand and a 5,000mAh capacity. It’s Qi2-certified and delivered a 43 percent bump to our tester iPhone 15 in 42 minutes, ultimately charging it to 91 percent. The slim slab of the Anker Nano battery is sleeker. But that one doesn’t have a stand — so if you want to prop up your phone while it charges, go for this one. MagSafe power banks FAQs What does MagSafe do? MagSafe is Apple’s own technology that supports up to 25W wireless charging speeds and incorporates embedded magnets to align the phone with chargers and other accessories. Which iPhones support MagSafe? iPhones 12 and later support 15W MagSafe technology, though only iPhones 13 and later can reach the 15W charging speed with third-party Qi2 accessories. The iPhone 12 maxes out at 7.5W with non-Apple accessories. The new iPhone 17, 17 Pro and 17 Pro Max support up to 25W charging speeds with Qi2 25W-certified chargers. iPhone 16, 16 Pro and 16 Pro Max should also support those speeds after an update to iOS 26. The iPhone Air supports MagSafe charging at a max speed of 20W. Can you use MagSafe batteries with a case? In most cases (heh), yes. The wireless charge can travel across a distance of a few millimeters. If the case is more than 5mm thick or contains metal components, the wireless charge can be blocked. Many iPhone cases are marketed as MagSafe-compatible, which means the case itself has complimentary magnets inside and should not interfere with charging accessories. We tested a MagSafe power bank on an iPhone 15 with and without a MagSafe case and got the same charging speeds and amounts in both tests. How much power do MagSafe batteries provide? That depends on the power bank. If it is Qi2-certified, it can provide up to 15 watts of wireless power. Qi2 25W-enabled chargers can deliver up to 25 watts to a compatible handset. Non-Qi2 batteries typically deliver around 7.5 watts. The amount of charge delivered depends on the capacity. Most MagSafe portable chargers are rated at 5,000mAh or 10,000mAh. The former can get a standard iPhone 15 from five percent to around 90 percent. The latter can fill the phone completely with enough left over for another half charge.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-magsafe-power-banks-120015338.html?src=rss",
          "feed_position": 44
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/the-motorola-edge-70-is-another-ridiculously-thin-smartphone-080009244.html",
          "published_at": "Wed, 05 Nov 2025 08:00:09 +0000",
          "title": "The Motorola Edge 70 is another ridiculously thin smartphone",
          "standfirst": "Motorola just announced the Edge 70 smartphone, which is an ultra-thin handset that could rival the recently-launched Apple iPhone Air. It's a bit thicker than the Air, at 5.9mm compared to 5.6mm, but the camera bump is less noticeable. As for that camera bump, the Edge 70 features a trio of 50MP camera sensors. The main camera can capture 4K video and there's also a front camera, an ultrawide with a macro lens and a dedicated light sensor. Like most modern smartphones, there are AI tools available for photo editing. The frame is made from \"aircraft-grade aluminum,\" which is a good thing because my uncoordinated fingers will absolutely be dropping this thing within three days of owning one. Other durability features include Corning Gorilla Glass 7i and IP69 water protection. Motorola The phone will also have access to the company's proprietary moto ai2 chatbot. This can do all of the usual stuff like create images and answer queries. However, Motorola also boasts that the AI can understand what's on the screen and can point users to the correct course of action. We'll have to wait and see how that works in real life. This skinny handset somehow includes a massive 4800mAh battery that allows up to 50 hours of continuous use. That's over two full days of doomscrolling without ever heading to the power outlet. As a comparison, the iPhone Air lasts anywhere from 22 to 27 hours The Edge 70 ships with a magnetic case that can handle wireless charging and includes a Snapdragon 7 Gen 4 Mobile chipset. Motorola promises active software support and security upgrades all the way until 2031. Given the form factor and specs, the price is actually fairly reasonable. The Edge 70 starts at £700, which breaks down to around $910 USD. It's available for purchase right now, but there's a spot of bad news. It's launching in the UK and there's no current information as to when it'll cross the pond.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/the-motorola-edge-70-is-another-ridiculously-thin-smartphone-080009244.html?src=rss",
          "content": "Motorola just announced the Edge 70 smartphone, which is an ultra-thin handset that could rival the recently-launched Apple iPhone Air. It's a bit thicker than the Air, at 5.9mm compared to 5.6mm, but the camera bump is less noticeable. As for that camera bump, the Edge 70 features a trio of 50MP camera sensors. The main camera can capture 4K video and there's also a front camera, an ultrawide with a macro lens and a dedicated light sensor. Like most modern smartphones, there are AI tools available for photo editing. The frame is made from \"aircraft-grade aluminum,\" which is a good thing because my uncoordinated fingers will absolutely be dropping this thing within three days of owning one. Other durability features include Corning Gorilla Glass 7i and IP69 water protection. Motorola The phone will also have access to the company's proprietary moto ai2 chatbot. This can do all of the usual stuff like create images and answer queries. However, Motorola also boasts that the AI can understand what's on the screen and can point users to the correct course of action. We'll have to wait and see how that works in real life. This skinny handset somehow includes a massive 4800mAh battery that allows up to 50 hours of continuous use. That's over two full days of doomscrolling without ever heading to the power outlet. As a comparison, the iPhone Air lasts anywhere from 22 to 27 hours The Edge 70 ships with a magnetic case that can handle wireless charging and includes a Snapdragon 7 Gen 4 Mobile chipset. Motorola promises active software support and security upgrades all the way until 2031. Given the form factor and specs, the price is actually fairly reasonable. The Edge 70 starts at £700, which breaks down to around $910 USD. It's available for purchase right now, but there's a spot of bad news. It's launching in the UK and there's no current information as to when it'll cross the pond.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/the-motorola-edge-70-is-another-ridiculously-thin-smartphone-080009244.html?src=rss",
          "feed_position": 45,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-11/4e2de1d0-b999-11f0-a5cf-ddd16f7bb90f"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ais-capacity-crunch-latency-risk-escalating-costs-and-the-coming-surge",
          "published_at": "Wed, 05 Nov 2025 05:00:00 GMT",
          "title": "AI’s capacity crunch: Latency risk, escalating costs, and the coming surge-pricing breakpoint",
          "standfirst": "The latest big headline in AI isn’t model size or multimodality — it’s the capacity crunch. At VentureBeat’s latest AI Impact stop in NYC, Val Bercovici, chief AI officer at WEKA, joined Matt Marshall, VentureBeat CEO, to discuss what it really takes to scale AI amid rising latency, cloud lock-in, and runaway costs.Those forces, Bercovici argued, are pushing AI toward its own version of surge pricing. Uber famously introduced surge pricing, bringing real-time market rates to ridesharing for the first time. Now, Bercovici argued, AI is headed toward the same economic reckoning — especially for inference — when the focus turns to profitability.\"We don&#x27;t have real market rates today. We have subsidized rates. That’s been necessary to enable a lot of the innovation that’s been happening, but sooner or later — considering the trillions of dollars of capex we’re talking about right now, and the finite energy opex — real market rates are going to appear; perhaps next year, certainly by 2027,\" he said. \"When they do, it will fundamentally change this industry and drive an even deeper, keener focus on efficiency.\"The economics of the token explosion\"The first rule is that this is an industry where more is more. More tokens equal exponentially more business value,\" Bercovici said. But so far, no one&#x27;s figured out how to make that sustainable. The classic business triad — cost, quality, and speed — translates in AI to latency, cost, and accuracy (especially in output tokens). And accuracy is non-negotiable. That holds not only for consumer interactions with agents like ChatGPT, but for high-stakes use cases such as drug discovery and business workflows in heavily regulated industries like financial services and healthcare.\"That’s non-negotiable,\" Bercovici said. \"You have to have a high amount of tokens for high inference accuracy, especially when you add security into the mix, guardrail models, and quality models. Then you’re trading off latency and cost. That’s where you have some flexibility. If you can tolerate high latency, and sometimes you can for consumer use cases, then you can have lower cost, with free tiers and low cost-plus tiers.\" However, latency is a critical bottleneck for AI agents. “These agents now don&#x27;t operate in any singular sense. You either have an agent swarm or no agentic activity at all,” Bercovici noted.In a swarm, groups of agents work in parallel to complete a larger objective. An orchestrator agent — the smartest model — sits at the center, determining subtasks and key requirements: architecture choices, cloud vs. on-prem execution, performance constraints, and security considerations. The swarm then executes all subtasks, effectively spinning up numerous concurrent inference users in parallel sessions. Finally, evaluator models judge whether the overall task was successfully completed.“These swarms go through what&#x27;s called multiple turns, hundreds if not thousands of prompts and responses until the swarm convenes on an answer,” Bercovici said. “And if you have a compound delay in those thousand turns, it becomes untenable. So latency is really, really important. And that means typically having to pay a high price today that&#x27;s subsidized, and that&#x27;s what&#x27;s going to have to come down over time.”Reinforcement learning as the new paradigmUntil around May of this year, agents weren&#x27;t that performant, Bercovici explained. And then context windows became large enough, and GPUs available enough, to support agents that could complete advanced tasks, like writing reliable software. It&#x27;s now estimated that in some cases, 90% of software is generated by coding agents. Now that agents have essentially come of age, Bercovici noted, reinforcement learning is the new conversation among data scientists at some of the leading labs, like OpenAI, Anthropic, and Gemini, who view it as a critical path forward in AI innovation..\"The current AI season is reinforcement learning. It blends many of the elements of training and inference into one unified workflow,” Bercovici said. “It’s the latest and greatest scaling law to this mythical milestone we’re all trying to reach called AGI — artificial general intelligence,” he added. \"What’s fascinating to me is that you have to apply all the best practices of how you train models, plus all the best practices of how you infer models, to be able to iterate these thousands of reinforcement learning loops and advance the whole field.\"The path to AI profitability There’s no one answer when it comes to building an infrastructure foundation to make AI profitable, Bercovici said, since it&#x27;s still an emerging field. There’s no cookie-cutter approach. Going all on-prem may be the right choice for some — especially frontier model builders — while being cloud-native or running in a hybrid environment may be a better path for organizations looking to innovate agilely and responsively. Regardless of which path they choose initially, organizations will need to adapt their AI infrastructure strategy as their business needs evolve.\"Unit economics are what fundamentally matter here,\" said Bercovici. \"We are definitely in a boom, or even in a bubble, you could say, in some cases, since the underlying AI economics are being subsidized. But that doesn’t mean that if tokens get more expensive, you’ll stop using them. You’ll just get very fine-grained in terms of how you use them.\" Leaders should focus less on individual token pricing and more on transaction-level economics, where efficiency and impact become visible, Bercovici concludes. The pivotal question enterprises and AI companies should be asking, Bercovici said, is “What is the real cost for my unit economics?”Viewed through that lens, the path forward isn’t about doing less with AI — it’s about doing it smarter and more efficiently at scale.",
          "content": "The latest big headline in AI isn’t model size or multimodality — it’s the capacity crunch. At VentureBeat’s latest AI Impact stop in NYC, Val Bercovici, chief AI officer at WEKA, joined Matt Marshall, VentureBeat CEO, to discuss what it really takes to scale AI amid rising latency, cloud lock-in, and runaway costs.Those forces, Bercovici argued, are pushing AI toward its own version of surge pricing. Uber famously introduced surge pricing, bringing real-time market rates to ridesharing for the first time. Now, Bercovici argued, AI is headed toward the same economic reckoning — especially for inference — when the focus turns to profitability.\"We don&#x27;t have real market rates today. We have subsidized rates. That’s been necessary to enable a lot of the innovation that’s been happening, but sooner or later — considering the trillions of dollars of capex we’re talking about right now, and the finite energy opex — real market rates are going to appear; perhaps next year, certainly by 2027,\" he said. \"When they do, it will fundamentally change this industry and drive an even deeper, keener focus on efficiency.\"The economics of the token explosion\"The first rule is that this is an industry where more is more. More tokens equal exponentially more business value,\" Bercovici said. But so far, no one&#x27;s figured out how to make that sustainable. The classic business triad — cost, quality, and speed — translates in AI to latency, cost, and accuracy (especially in output tokens). And accuracy is non-negotiable. That holds not only for consumer interactions with agents like ChatGPT, but for high-stakes use cases such as drug discovery and business workflows in heavily regulated industries like financial services and healthcare.\"That’s non-negotiable,\" Bercovici said. \"You have to have a high amount of tokens for high inference accuracy, especially when you add security into the mix, guardrail models, and quality models. Then you’re trading off latency and cost. That’s where you have some flexibility. If you can tolerate high latency, and sometimes you can for consumer use cases, then you can have lower cost, with free tiers and low cost-plus tiers.\" However, latency is a critical bottleneck for AI agents. “These agents now don&#x27;t operate in any singular sense. You either have an agent swarm or no agentic activity at all,” Bercovici noted.In a swarm, groups of agents work in parallel to complete a larger objective. An orchestrator agent — the smartest model — sits at the center, determining subtasks and key requirements: architecture choices, cloud vs. on-prem execution, performance constraints, and security considerations. The swarm then executes all subtasks, effectively spinning up numerous concurrent inference users in parallel sessions. Finally, evaluator models judge whether the overall task was successfully completed.“These swarms go through what&#x27;s called multiple turns, hundreds if not thousands of prompts and responses until the swarm convenes on an answer,” Bercovici said. “And if you have a compound delay in those thousand turns, it becomes untenable. So latency is really, really important. And that means typically having to pay a high price today that&#x27;s subsidized, and that&#x27;s what&#x27;s going to have to come down over time.”Reinforcement learning as the new paradigmUntil around May of this year, agents weren&#x27;t that performant, Bercovici explained. And then context windows became large enough, and GPUs available enough, to support agents that could complete advanced tasks, like writing reliable software. It&#x27;s now estimated that in some cases, 90% of software is generated by coding agents. Now that agents have essentially come of age, Bercovici noted, reinforcement learning is the new conversation among data scientists at some of the leading labs, like OpenAI, Anthropic, and Gemini, who view it as a critical path forward in AI innovation..\"The current AI season is reinforcement learning. It blends many of the elements of training and inference into one unified workflow,” Bercovici said. “It’s the latest and greatest scaling law to this mythical milestone we’re all trying to reach called AGI — artificial general intelligence,” he added. \"What’s fascinating to me is that you have to apply all the best practices of how you train models, plus all the best practices of how you infer models, to be able to iterate these thousands of reinforcement learning loops and advance the whole field.\"The path to AI profitability There’s no one answer when it comes to building an infrastructure foundation to make AI profitable, Bercovici said, since it&#x27;s still an emerging field. There’s no cookie-cutter approach. Going all on-prem may be the right choice for some — especially frontier model builders — while being cloud-native or running in a hybrid environment may be a better path for organizations looking to innovate agilely and responsively. Regardless of which path they choose initially, organizations will need to adapt their AI infrastructure strategy as their business needs evolve.\"Unit economics are what fundamentally matter here,\" said Bercovici. \"We are definitely in a boom, or even in a bubble, you could say, in some cases, since the underlying AI economics are being subsidized. But that doesn’t mean that if tokens get more expensive, you’ll stop using them. You’ll just get very fine-grained in terms of how you use them.\" Leaders should focus less on individual token pricing and more on transaction-level economics, where efficiency and impact become visible, Bercovici concludes. The pivotal question enterprises and AI companies should be asking, Bercovici said, is “What is the real cost for my unit economics?”Viewed through that lens, the path forward isn’t about doing less with AI — it’s about doing it smarter and more efficiently at scale.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4htZ4RXS4bpdlPbXEaKYhp/1dd9f6065c85eae3d9e3e44acda4c7fa/IMG_8825.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/from-logs-to-insights-the-ai-breakthrough-redefining-observability",
          "published_at": "Wed, 05 Nov 2025 05:00:00 GMT",
          "title": "From logs to insights: The AI breakthrough redefining observability",
          "standfirst": "Presented by Elastic Logs set to become the primary tool for finding the “why” in diagnosing network incidents Modern IT environments have a data problem: there’s too much of it. Organizations that need to manage a company’s environment are increasingly challenged to detect and diagnose issues in real-time, optimize performance, improve reliability, and ensure security and compliance — all within constrained budgets. The modern observability landscape has many tools that offer a solution. Most revolve around DevOps teams or Site Reliability Engineers (SREs) analyzing logs, metrics, and traces to uncover patterns and figure out what’s happening across the network, and diagnose why an issue or incident occurred. The problem is that the process creates information overload: A Kubernetes cluster alone can emit 30 to 50 gigabytes of logs a day, and suspicious behavior patterns can sneak past human eyes. \"It’s so anachronistic now, in the world of AI, to think about humans alone observing infrastructure,\" says Ken Exner, chief product officer at Elastic. \"I hate to break it to you, but machines are better than human beings at pattern matching.“An industry-wide focus on visualizing symptoms forces engineers to manually hunt for answers. The crucial \"why\" is buried in logs, but because they contain massive volumes of unstructured data, the industry tends to use them as a tool of last resort. This has forced teams into costly tradeoffs: either spend countless hours building complex data pipelines, drop valuable log data and risk critical visibility gaps, or log and forget.Elastic, the Search AI Company, recently released a new feature for observability called Streams, which aims to become the primary signal for investigations by taking noisy logs and turning them into patterns, context and meaning. Streams uses AI to automatically partition and parse raw logs to extract relevant fields, and greatly reduce the effort required of SREs to make logs usable. Streams also automatically surfaces significant events such as critical errors and anomalies from context-rich logs, giving SREs early warnings and a clear understanding of their workloads, enabling them to investigate and resolve issues faster. The ultimate goal is to show remediation steps.\"From raw, voluminous, messy data, Streams automatically creates structure, putting it into a form that is usable, automatically alerts you to issues and helps you remediate them,\" Exner says. \"That is the magic of Streams.\"A broken workflowStreams upends an observability process that some say is broken. Typically, SREs set up metrics, logs and traces. Then they set up alerts, and service level objectives (SLOs) — often hard-coded rules to show where a service or process has gone beyond a threshold, or a specific pattern has been detected. When an alert is triggered, it points to the metric that&#x27;s showing an anomaly. From there, SREs look at a metrics dashboard, where they can visualize the issue and compare the alert to other metrics, or CPU to memory to I/O, and start looking for patterns. They may then need to look at a trace, and examine upstream and downstream dependencies across the application to dig into the root cause of the issue. Once they figure out what&#x27;s causing the trouble, they jump into the logs for that database or service to try and debug the issue. Some companies simply seek to add more tools when current ones prove ineffective. That means SREs are hopping from tool to tool to keep on top of monitoring and troubleshooting across their infrastructure and applications.\"You’re hopping across different tools. You’re relying on a human to interpret these things, visually look at the relationship between systems in a service map, visually look at graphs on a metrics dashboard, to figure out what and where the issue is, \" Exner says. \"But AI automates that workflow away.\" With AI-powered Streams, logs are not just used reactively to resolve issues, but also to proactively process potential issues and create information-rich alerts that help teams jump straight to problem-solving, offering a solution for remediation or even fixing the issue entirely, before automatically notifying the team that it&#x27;s been taken care of.\"I believe that logs, the richest set of information, the original signal type, will start driving a lot of the automation that a service reliability engineer typically does today, and does very manually,\" he adds. \"A human should not be in that process, where they are doing this by digging into themselves, trying to figure out what is going on, where and what the issue is, and then once they find the root cause, they’re trying to figure out how to debug it.\"Observability’s future Large language models (LLMs) could be a key player in the future of observability. LLMs excel at recognizing patterns in vast quantities of repetitive data, which closely resembles log and telemetry data in complex, dynamic systems. And today’s LLMs can be trained for specific IT processes. With automation tooling, the LLM has the information and tools it needs to resolve database errors or Java heap issues, and more. Incorporating those into platforms that bring context and relevance will be essential. Automated remediation will still take some time, Exner says, but automated runbooks and playbooks generated by LLMs will become standard practice within the next couple of years. In other words, remediation steps will be driven by LLMs. The LLM will offer up fixes, and the human will verify and implement them, rather than calling in an expert.Addressing skill shortagesGoing all in on AI for observability would help address a major shortage in the talent needed to manage IT infrastructure. Hiring is slow because organizations need teams with a great deal of experience and understanding of potential issues, and how to resolve them fast. That experience can come from an LLM that is contextually grounded, Exner says.\"We can help deal with the skill shortage by augmenting people with LLMs that make them all instantly experts,\" he explains. \"I think this is going to make it much easier for us to take novice practitioners and make them expert practitioners in both security and observability, and it’s going to make it possible for a more novice practitioner to act like an expert.” Streams in Elastic Observability is available now. Get started by reading more on the Streams. Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Elastic Logs set to become the primary tool for finding the “why” in diagnosing network incidents Modern IT environments have a data problem: there’s too much of it. Organizations that need to manage a company’s environment are increasingly challenged to detect and diagnose issues in real-time, optimize performance, improve reliability, and ensure security and compliance — all within constrained budgets. The modern observability landscape has many tools that offer a solution. Most revolve around DevOps teams or Site Reliability Engineers (SREs) analyzing logs, metrics, and traces to uncover patterns and figure out what’s happening across the network, and diagnose why an issue or incident occurred. The problem is that the process creates information overload: A Kubernetes cluster alone can emit 30 to 50 gigabytes of logs a day, and suspicious behavior patterns can sneak past human eyes. \"It’s so anachronistic now, in the world of AI, to think about humans alone observing infrastructure,\" says Ken Exner, chief product officer at Elastic. \"I hate to break it to you, but machines are better than human beings at pattern matching.“An industry-wide focus on visualizing symptoms forces engineers to manually hunt for answers. The crucial \"why\" is buried in logs, but because they contain massive volumes of unstructured data, the industry tends to use them as a tool of last resort. This has forced teams into costly tradeoffs: either spend countless hours building complex data pipelines, drop valuable log data and risk critical visibility gaps, or log and forget.Elastic, the Search AI Company, recently released a new feature for observability called Streams, which aims to become the primary signal for investigations by taking noisy logs and turning them into patterns, context and meaning. Streams uses AI to automatically partition and parse raw logs to extract relevant fields, and greatly reduce the effort required of SREs to make logs usable. Streams also automatically surfaces significant events such as critical errors and anomalies from context-rich logs, giving SREs early warnings and a clear understanding of their workloads, enabling them to investigate and resolve issues faster. The ultimate goal is to show remediation steps.\"From raw, voluminous, messy data, Streams automatically creates structure, putting it into a form that is usable, automatically alerts you to issues and helps you remediate them,\" Exner says. \"That is the magic of Streams.\"A broken workflowStreams upends an observability process that some say is broken. Typically, SREs set up metrics, logs and traces. Then they set up alerts, and service level objectives (SLOs) — often hard-coded rules to show where a service or process has gone beyond a threshold, or a specific pattern has been detected. When an alert is triggered, it points to the metric that&#x27;s showing an anomaly. From there, SREs look at a metrics dashboard, where they can visualize the issue and compare the alert to other metrics, or CPU to memory to I/O, and start looking for patterns. They may then need to look at a trace, and examine upstream and downstream dependencies across the application to dig into the root cause of the issue. Once they figure out what&#x27;s causing the trouble, they jump into the logs for that database or service to try and debug the issue. Some companies simply seek to add more tools when current ones prove ineffective. That means SREs are hopping from tool to tool to keep on top of monitoring and troubleshooting across their infrastructure and applications.\"You’re hopping across different tools. You’re relying on a human to interpret these things, visually look at the relationship between systems in a service map, visually look at graphs on a metrics dashboard, to figure out what and where the issue is, \" Exner says. \"But AI automates that workflow away.\" With AI-powered Streams, logs are not just used reactively to resolve issues, but also to proactively process potential issues and create information-rich alerts that help teams jump straight to problem-solving, offering a solution for remediation or even fixing the issue entirely, before automatically notifying the team that it&#x27;s been taken care of.\"I believe that logs, the richest set of information, the original signal type, will start driving a lot of the automation that a service reliability engineer typically does today, and does very manually,\" he adds. \"A human should not be in that process, where they are doing this by digging into themselves, trying to figure out what is going on, where and what the issue is, and then once they find the root cause, they’re trying to figure out how to debug it.\"Observability’s future Large language models (LLMs) could be a key player in the future of observability. LLMs excel at recognizing patterns in vast quantities of repetitive data, which closely resembles log and telemetry data in complex, dynamic systems. And today’s LLMs can be trained for specific IT processes. With automation tooling, the LLM has the information and tools it needs to resolve database errors or Java heap issues, and more. Incorporating those into platforms that bring context and relevance will be essential. Automated remediation will still take some time, Exner says, but automated runbooks and playbooks generated by LLMs will become standard practice within the next couple of years. In other words, remediation steps will be driven by LLMs. The LLM will offer up fixes, and the human will verify and implement them, rather than calling in an expert.Addressing skill shortagesGoing all in on AI for observability would help address a major shortage in the talent needed to manage IT infrastructure. Hiring is slow because organizations need teams with a great deal of experience and understanding of potential issues, and how to resolve them fast. That experience can come from an LLM that is contextually grounded, Exner says.\"We can help deal with the skill shortage by augmenting people with LLMs that make them all instantly experts,\" he explains. \"I think this is going to make it much easier for us to take novice practitioners and make them expert practitioners in both security and observability, and it’s going to make it possible for a more novice practitioner to act like an expert.” Streams in Elastic Observability is available now. Get started by reading more on the Streams. Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/27gJHUFa8zIMnql7WcOsgp/ac5e9d96209e2fea9f36db14be5dd724/AdobeStock_1211315173.jpeg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/databricks-research-reveals-that-building-better-ai-judges-isnt-just-a",
          "published_at": "Tue, 04 Nov 2025 20:00:00 GMT",
          "title": "Databricks research reveals that building better AI judges isn't just a technical concern, it's a people problem",
          "standfirst": "The intelligence of AI models isn&#x27;t what&#x27;s blocking enterprise deployments. It&#x27;s the inability to define and measure quality in the first place.That&#x27;s where AI judges are now playing an increasingly important role. In AI evaluation, a \"judge\" is an AI system that scores outputs from another AI system. Judge Builder is Databricks&#x27; framework for creating judges and was first deployed as part of the company&#x27;s Agent Bricks technology earlier this year. The framework has evolved significantly since its initial launch in response to direct user feedback and deployments.Early versions focused on technical implementation but customer feedback revealed the real bottleneck was organizational alignment. Databricks now offers a structured workshop process that guides teams through three core challenges: getting stakeholders to agree on quality criteria, capturing domain expertise from limited subject matter experts and deploying evaluation systems at scale.\"The intelligence of the model is typically not the bottleneck, the models are really smart,\" Jonathan Frankle, Databricks&#x27; chief AI scientist, told VentureBeat in an exclusive briefing. \"Instead, it&#x27;s really about asking, how do we get the models to do what we want, and how do we know if they did what we wanted?\"The &#x27;Ouroboros problem&#x27; of AI evaluationJudge Builder addresses what Pallavi Koppol, a Databricks research scientist who led the development, calls the \"Ouroboros problem.\" An Ouroboros is an ancient symbol that depicts a snake eating its own tail. Using AI systems to evaluate AI systems creates a circular validation challenge.\"You want a judge to see if your system is good, if your AI system is good, but then your judge is also an AI system,\" Koppol explained. \"And now you&#x27;re saying like, well, how do I know this judge is good?\"The solution is measuring \"distance to human expert ground truth\" as the primary scoring function. By minimizing the gap between how an AI judge scores outputs versus how domain experts would score them, organizations can trust these judges as scalable proxies for human evaluation.This approach differs fundamentally from traditional guardrail systems or single-metric evaluations. Rather than asking whether an AI output passed or failed on a generic quality check, Judge Builder creates highly specific evaluation criteria tailored to each organization&#x27;s domain expertise and business requirements.The technical implementation also sets it apart. Judge Builder integrates with Databricks&#x27; MLflow and prompt optimization tools and can work with any underlying model. Teams can version control their judges, track performance over time and deploy multiple judges simultaneously across different quality dimensions.Lessons learned: Building judges that actually workDatabricks&#x27; work with enterprise customers revealed three critical lessons that apply to anyone building AI judges.Lesson one: Your experts don&#x27;t agree as much as you think. When quality is subjective, organizations discover that even their own subject matter experts disagree on what constitutes acceptable output. A customer service response might be factually correct but use an inappropriate tone. A financial summary might be comprehensive but too technical for the intended audience.\"One of the biggest lessons of this whole process is that all problems become people problems,\" Frankle said. \"The hardest part is getting an idea out of a person&#x27;s brain and into something explicit. And the harder part is that companies are not one brain, but many brains.\"The fix is batched annotation with inter-rater reliability checks. Teams annotate examples in small groups, then measure agreement scores before proceeding. This catches misalignment early. In one case, three experts gave ratings of 1, 5 and neutral for the same output before discussion revealed they were interpreting the evaluation criteria differently.Companies using this approach achieve inter-rater reliability scores as high as 0.6 compared to typical scores of 0.3 from external annotation services. Higher agreement translates directly to better judge performance because the training data contains less noise.Lesson two: Break down vague criteria into specific judges. Instead of one judge evaluating whether a response is \"relevant, factual and concise,\" create three separate judges. Each targets a specific quality aspect. This granularity matters because a failing \"overall quality\" score reveals something is wrong but not what to fix.The best results come from combining top-down requirements such as regulatory constraints, stakeholder priorities, with bottom-up discovery of observed failure patterns. One customer built a top-down judge for correctness but discovered through data analysis that correct responses almost always cited the top two retrieval results. This insight became a new production-friendly judge that could proxy for correctness without requiring ground-truth labels.Lesson three: You need fewer examples than you think. Teams can create robust judges from just 20-30 well-chosen examples. The key is selecting edge cases that expose disagreement rather than obvious examples where everyone agrees.\"We&#x27;re able to run this process with some teams in as little as three hours, so it doesn&#x27;t really take that long to start getting a good judge,\" Koppol said.Production results: From pilots to seven-figure deploymentsFrankle shared three metrics Databricks uses to measure Judge Builder&#x27;s success: whether customers want to use it again, whether they increase AI spending and whether they progress further in their AI journey.On the first metric, one customer created more than a dozen judges after their initial workshop. \"This customer made more than a dozen judges after we walked them through doing this in a rigorous way for the first time with this framework,\" Frankle said. \"They really went to town on judges and are now measuring everything.\"For the second metric, the business impact is clear. \"There are multiple customers who have gone through this workshop and have become seven-figure spenders on GenAI at Databricks in a way that they weren&#x27;t before,\" Frankle said.The third metric reveals Judge Builder&#x27;s strategic value. Customers who previously hesitated to use advanced techniques like reinforcement learning now feel confident deploying them because they can measure whether improvements actually occurred.\"There are customers who have gone and done very advanced things after having had these judges where they were reluctant to do so before,\" Frankle said. \"They&#x27;ve moved from doing a little bit of prompt engineering to doing reinforcement learning with us. Why spend the money on reinforcement learning, and why spend the energy on reinforcement learning if you don&#x27;t know whether it actually made a difference?\"What enterprises should do nowThe teams successfully moving AI from pilot to production treat judges not as one-time artifacts but as evolving assets that grow with their systems.Databricks recommends three practical steps. First, focus on high-impact judges by identifying one critical regulatory requirement plus one observed failure mode. These become your initial judge portfolio.Second, create lightweight workflows with subject matter experts. A few hours reviewing 20-30 edge cases provides sufficient calibration for most judges. Use batched annotation and inter-rater reliability checks to denoise your data.Third, schedule regular judge reviews using production data. New failure modes will emerge as your system evolves. Your judge portfolio should evolve with them.\"A judge is a way to evaluate a model, it&#x27;s also a way to create guardrails, it&#x27;s also a way to have a metric against which you can do prompt optimization and it&#x27;s also a way to have a metric against which you can do reinforcement learning,\" Frankle said. \"Once you have a judge that you know represents your human taste in an empirical form that you can query as much as you want, you can use it in 10,000 different ways to measure or improve your agents.\"",
          "content": "The intelligence of AI models isn&#x27;t what&#x27;s blocking enterprise deployments. It&#x27;s the inability to define and measure quality in the first place.That&#x27;s where AI judges are now playing an increasingly important role. In AI evaluation, a \"judge\" is an AI system that scores outputs from another AI system. Judge Builder is Databricks&#x27; framework for creating judges and was first deployed as part of the company&#x27;s Agent Bricks technology earlier this year. The framework has evolved significantly since its initial launch in response to direct user feedback and deployments.Early versions focused on technical implementation but customer feedback revealed the real bottleneck was organizational alignment. Databricks now offers a structured workshop process that guides teams through three core challenges: getting stakeholders to agree on quality criteria, capturing domain expertise from limited subject matter experts and deploying evaluation systems at scale.\"The intelligence of the model is typically not the bottleneck, the models are really smart,\" Jonathan Frankle, Databricks&#x27; chief AI scientist, told VentureBeat in an exclusive briefing. \"Instead, it&#x27;s really about asking, how do we get the models to do what we want, and how do we know if they did what we wanted?\"The &#x27;Ouroboros problem&#x27; of AI evaluationJudge Builder addresses what Pallavi Koppol, a Databricks research scientist who led the development, calls the \"Ouroboros problem.\" An Ouroboros is an ancient symbol that depicts a snake eating its own tail. Using AI systems to evaluate AI systems creates a circular validation challenge.\"You want a judge to see if your system is good, if your AI system is good, but then your judge is also an AI system,\" Koppol explained. \"And now you&#x27;re saying like, well, how do I know this judge is good?\"The solution is measuring \"distance to human expert ground truth\" as the primary scoring function. By minimizing the gap between how an AI judge scores outputs versus how domain experts would score them, organizations can trust these judges as scalable proxies for human evaluation.This approach differs fundamentally from traditional guardrail systems or single-metric evaluations. Rather than asking whether an AI output passed or failed on a generic quality check, Judge Builder creates highly specific evaluation criteria tailored to each organization&#x27;s domain expertise and business requirements.The technical implementation also sets it apart. Judge Builder integrates with Databricks&#x27; MLflow and prompt optimization tools and can work with any underlying model. Teams can version control their judges, track performance over time and deploy multiple judges simultaneously across different quality dimensions.Lessons learned: Building judges that actually workDatabricks&#x27; work with enterprise customers revealed three critical lessons that apply to anyone building AI judges.Lesson one: Your experts don&#x27;t agree as much as you think. When quality is subjective, organizations discover that even their own subject matter experts disagree on what constitutes acceptable output. A customer service response might be factually correct but use an inappropriate tone. A financial summary might be comprehensive but too technical for the intended audience.\"One of the biggest lessons of this whole process is that all problems become people problems,\" Frankle said. \"The hardest part is getting an idea out of a person&#x27;s brain and into something explicit. And the harder part is that companies are not one brain, but many brains.\"The fix is batched annotation with inter-rater reliability checks. Teams annotate examples in small groups, then measure agreement scores before proceeding. This catches misalignment early. In one case, three experts gave ratings of 1, 5 and neutral for the same output before discussion revealed they were interpreting the evaluation criteria differently.Companies using this approach achieve inter-rater reliability scores as high as 0.6 compared to typical scores of 0.3 from external annotation services. Higher agreement translates directly to better judge performance because the training data contains less noise.Lesson two: Break down vague criteria into specific judges. Instead of one judge evaluating whether a response is \"relevant, factual and concise,\" create three separate judges. Each targets a specific quality aspect. This granularity matters because a failing \"overall quality\" score reveals something is wrong but not what to fix.The best results come from combining top-down requirements such as regulatory constraints, stakeholder priorities, with bottom-up discovery of observed failure patterns. One customer built a top-down judge for correctness but discovered through data analysis that correct responses almost always cited the top two retrieval results. This insight became a new production-friendly judge that could proxy for correctness without requiring ground-truth labels.Lesson three: You need fewer examples than you think. Teams can create robust judges from just 20-30 well-chosen examples. The key is selecting edge cases that expose disagreement rather than obvious examples where everyone agrees.\"We&#x27;re able to run this process with some teams in as little as three hours, so it doesn&#x27;t really take that long to start getting a good judge,\" Koppol said.Production results: From pilots to seven-figure deploymentsFrankle shared three metrics Databricks uses to measure Judge Builder&#x27;s success: whether customers want to use it again, whether they increase AI spending and whether they progress further in their AI journey.On the first metric, one customer created more than a dozen judges after their initial workshop. \"This customer made more than a dozen judges after we walked them through doing this in a rigorous way for the first time with this framework,\" Frankle said. \"They really went to town on judges and are now measuring everything.\"For the second metric, the business impact is clear. \"There are multiple customers who have gone through this workshop and have become seven-figure spenders on GenAI at Databricks in a way that they weren&#x27;t before,\" Frankle said.The third metric reveals Judge Builder&#x27;s strategic value. Customers who previously hesitated to use advanced techniques like reinforcement learning now feel confident deploying them because they can measure whether improvements actually occurred.\"There are customers who have gone and done very advanced things after having had these judges where they were reluctant to do so before,\" Frankle said. \"They&#x27;ve moved from doing a little bit of prompt engineering to doing reinforcement learning with us. Why spend the money on reinforcement learning, and why spend the energy on reinforcement learning if you don&#x27;t know whether it actually made a difference?\"What enterprises should do nowThe teams successfully moving AI from pilot to production treat judges not as one-time artifacts but as evolving assets that grow with their systems.Databricks recommends three practical steps. First, focus on high-impact judges by identifying one critical regulatory requirement plus one observed failure mode. These become your initial judge portfolio.Second, create lightweight workflows with subject matter experts. A few hours reviewing 20-30 edge cases provides sufficient calibration for most judges. Use batched annotation and inter-rater reliability checks to denoise your data.Third, schedule regular judge reviews using production data. New failure modes will emerge as your system evolves. Your judge portfolio should evolve with them.\"A judge is a way to evaluate a model, it&#x27;s also a way to create guardrails, it&#x27;s also a way to have a metric against which you can do prompt optimization and it&#x27;s also a way to have a metric against which you can do reinforcement learning,\" Frankle said. \"Once you have a judge that you know represents your human taste in an empirical form that you can query as much as you want, you can use it in 10,000 different ways to measure or improve your agents.\"",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/75UWyAdt4L6TmmJjkbVDJu/96a54479b06fb94b7d13366ad4f046af/ouroboros-ai-smk.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/attention-isnt-all-you-need-new-qwen3-variant-brumby-14b-base-leverages",
          "published_at": "Tue, 04 Nov 2025 19:37:00 GMT",
          "title": "Attention ISN'T all you need?! New Qwen3 variant Brumby-14B-Base leverages Power Retention technique",
          "standfirst": "When the transformer architecture was introduced in 2017 in the now seminal Google paper \"Attention Is All You Need,\" it became an instant cornerstone of modern artificial intelligence. Every major large language model (LLM) — from OpenAI&#x27;s GPT series to Anthropic&#x27;s Claude, Google&#x27;s Gemini, and Meta&#x27;s Llama — has been built on some variation of its central mechanism: attention, the mathematical operation that allows a model to look back across its entire input and decide what information matters most.Eight years later, the same mechanism that defined AI’s golden age is now showing its limits. Attention is powerful, but it is also expensive — its computational and memory costs scale quadratically with context length, creating an increasingly unsustainable bottleneck for both research and industry. As models aim to reason across documents, codebases, or video streams lasting hours or days, attention becomes the architecture’s Achilles’ heel.On October 28, 2025, the little-known AI startup Manifest AI introduced a radical alternative. Their new model, Brumby-14B-Base, is a retrained variant of Qwen3-14B-Base, one of the leading open-source transformer models.But while many variants of Qwen have been trained already, Brumby-14B-Base is novel in that it abandons attention altogether. Instead, Brumby replaces those layers with a novel mechanism called Power Retention—a recurrent, hardware-efficient architecture that stores and updates information over arbitrarily long contexts without the exponential memory growth of attention.Trained at a stated cost of just $4,000, the 14-billion-parameter Brumby model performs on par with established transformer models like Qwen3-14B and GLM-4.5-Air, achieving near-state-of-the-art accuracy on a range of reasoning and comprehension benchmarks.From Attention to Retention: The Architectural ShiftThe core of Manifest AI’s innovation lies in what they call the Power Retention layer. In a traditional transformer, every token computes a set of queries (Q), keys (K), and values (V), then performs a matrix operation that measures the similarity between every token and every other token—essentially a full pairwise comparison across the sequence. This is what gives attention its flexibility, but also what makes it so costly: processing a sequence twice as long takes roughly four times the compute and memory.Power Retention keeps the same inputs (Q, K, V), but replaces the global similarity operation with a recurrent state update. Each layer maintains a memory matrix S, which is updated at each time step according to the incoming key, value, and a learned gating signal. The process looks more like an RNN (Recurrent Neural Network) than a transformer: instead of recomputing attention over the entire context, the model continuously compresses past information into a fixed-size latent state.This means the computational cost of Power Retention does not grow with context length. Whether the model is processing 1,000 or 1,000,000 tokens, the per-token cost remains constant. That property alone—constant-time per-token computation—marks a profound departure from transformer behavior.At the same time, Power Retention preserves the expressive power that made attention successful. Because the recurrence involves tensor powers of the input (hence the name “power retention”), it can represent higher-order dependencies between past and present tokens. The result is an architecture that can theoretically retain long-term dependencies indefinitely, while remaining as efficient as an RNN and as expressive as a transformer.Retraining, Not RebuildingPerhaps the most striking aspect of Brumby-14B’s training process is its efficiency. Manifest AI trained the model for only 60 hours on 32 Nvidia H100 GPUs, at a cost of roughly $4,000 — less than 2% of what a conventional model of this scale would cost to train from scratch.However, since it relied on a transformer-based model, it&#x27;s safe to say that this advance alone will not end the transformer AI-era.As Jacob Buckman, founder of Manifest AI, clarified in an email to VentureBeat: “The ability to train for $4,000 is indeed only possible when leveraging an existing transformer model,” he said. “Brumby could not be trained from scratch for that price.”Still, Buckman emphasized the significance of that result: “The reason this is important is that the ability to build on the weights of the previous generation of model architectures is a critical accelerant for the adoption of a new modeling paradigm.” He argues this demonstrates how attention-free systems can catch up to transformer performance “for orders-of-magnitude less” investment.In the loss curves released by Manifest AI, Brumby’s training loss quickly converges to that of the Qwen3 baseline within 3,000 training steps, even as the architecture diverges significantly from its transformer origins. Although Brumby-14B-Base began life as Qwen3-14B-Base, it did not remain identical for long. Manifest AI fundamentally altered Qwen3’s architecture by removing its attention layers—the mathematical engine that defines how a transformer model processes information—and replacing them with their new “power retention” mechanism. This change restructured the model’s internal wiring, effectively giving it a new brain while preserving much of its prior knowledge.Because of that architectural swap, the existing Qwen3 weights no longer fit perfectly. They were trained to operate within a transformer’s attention dynamics, not the new retention-based system. As a result, the Brumby model initially “forgot” how to apply some of its learned knowledge effectively. The retraining process—about 3,000 steps of additional learning—served to recalibrate those weights, aligning them with the power retention framework without having to start from zero.A helpful way to think about this is to imagine taking a world-class pianist and handing them a guitar. They already understand rhythm, harmony, and melody, but their hands must learn entirely new patterns to produce the same music. Similarly, Brumby had to relearn how to use its existing knowledge through a new computational instrument. Those 3,000 training steps were, in effect, its crash course in guitar lessons.By the end of this short retraining phase, Brumby had regained its full performance, reaching the same accuracy as the original Qwen3 model. That quick recovery is what makes the result so significant: it shows that an attention-free system can inherit and adapt the capabilities of a transformer model with only a fraction of the training time and cost.The benchmark progression plots show a similar trend: the model rapidly approaches its target accuracy on core evaluations like GSM8K, HellaSwag, and MMLU after only a few thousand steps, matching or even slightly surpassing Qwen3 on several tasks.Benchmarking the BrumbyAcross standard evaluation tasks, Brumby-14B-Base consistently performs at or near parity with transformer baselines of comparable scale.TaskBrumby-14BQwen3-14BGLM-4.5-AirNemotron Nano (12B)ARC0.890.940.920.93GSM8K0.880.840.830.84GSM8K (Platinum)0.870.880.850.87HellaSwag0.770.810.850.82MATH0.620.540.470.26MBPP0.570.750.730.71MMLU0.710.780.770.78MMLU (Pro)0.360.550.510.53While it lags slightly behind transformers on knowledge-heavy evaluations like MMLU-Pro, it matches or outperforms them on mathematical reasoning and long-context reasoning tasks—precisely where attention architectures tend to falter. This pattern reinforces the idea that recurrent or retention-based systems may hold a structural advantage for reasoning over extended temporal or logical dependencies.Hardware Efficiency and Inference PerformanceBrumby’s power retention design offers another major advantage: hardware efficiency.Because the state update involves only local matrix operations, inference can be implemented with linear complexity in sequence length. Manifest AI reports that their fastest kernels, developed through their in-house CUDA framework Vidrial, can deliver hundreds-fold speedups over attention on very long contexts.Buckman said the alpha-stage Power Retention kernels “achieve typical hardware utilization of 80–85%, which is higher than FlashAttention2’s 70–75% or Mamba’s 50–60%.” (Mamba is another emerging “post-transformer” architecture developed by Carnegie Mellon scientists back in 2023 that, like Power Retention, seeks to eliminate the computational bottleneck of attention. It replaces attention with a state-space mechanism that processes sequences linearly — updating an internal state over time rather than comparing every token to every other one. This makes it far more efficient for long inputs, though it typically achieves lower hardware utilization than Power Retention in early tests.)Both Power Retention and Mamba, he added, “expend meaningfully fewer total FLOPs than FlashAttention2 on long contexts, as well as far less memory.” According to Buckman, the reported 100× speedup comes from this combined improvement in utilization and computational efficiency, though he noted that “we have not yet stress-tested it on production-scale workloads.”Training and Scaling EconomicsPerhaps no statistic in the Brumby release generated more attention than the training cost.A 14-billion-parameter model, trained for $4,000, represents a two-order-of-magnitude reduction in the cost of foundation model development.Buckman confirmed that the low cost reflects a broader scaling pattern. “Far from diminishing returns, we have found that ease of retraining improves with scale,” he said. “The number of steps required to successfully retrain a model decreases with its parameter count.” Manifest has not yet validated the cost of retraining models at 700B parameters, but Buckman projected a range of $10,000–$20,000 for models of that magnitude—still far below transformer training budgets.He also reiterated that this approach could democratize large-scale experimentation by allowing smaller research groups or companies to retrain or repurpose existing transformer checkpoints without prohibitive compute costs.Integration and DeploymentAccording to Buckman, converting an existing transformer into a Power Retention model is designed to be simple. “It is straightforward for any company that is already retraining, post-training, or fine-tuning open-source models,” he said. “Simply pip install retention, change one line of your architecture code, and resume training where you left off.”He added that after only a small number of GPU-hours, the model typically recovers its original performance—at which point it gains the efficiency benefits of the attention-free design. “The resulting architecture will permit far faster long-context training and inference than previously,” Buckman noted.On infrastructure, Buckman said the main Brumby kernels are written in Triton, compatible with both NVIDIA and AMD accelerators. Specialized CUDA kernels are also available through the team’s in-house Vidrial framework. Integration with vLLM and other inference engines remains a work in progress: “We have not yet integrated Power Retention into inference engines, but doing so is a major ongoing initiative at Manifest.”As for distributed inference, Buckman dismissed concerns about instability: “We have not found this difficulty to be exacerbated in any way by our recurrent-state architecture. In fact, context-parallel training and GPU partitioning for multi-user inference both become significantly cleaner technically when using our approach.”Mission and Long-Term VisionBeyond the engineering details, Buckman also described Manifest’s broader mission. “Our mission is to train a neural network to model all human output,” he said. The team’s goal, he explained, is to move beyond modeling “artifacts of intelligence” toward modeling “the intelligent processes that generated them.” This shift, he argued, requires “fundamentally rethinking” how models are designed and trained—work that Power Retention represents only the beginning of.The Brumby-14B release, he said, is “one step forward in a long march” toward architectures that can model thought processes continuously and efficiently.Public Debate and Industry ReceptionThe launch of Brumby-14B sparked immediate discussion on X (formerly Twitter), where researchers debated the framing of Manifest AI’s announcement. Some, including Meta researcher Ariel (@redtachyon), argued that the “$4,000 foundation model” tagline was misleading, since the training involved reusing pretrained transformer weights rather than training from scratch.“They shuffled around the weights of Qwen, fine-tuned it a bit, and called it ‘training a foundation model for $4k,’” Ariel wrote.Buckman responded publicly, clarifying that the initial tweet had been part of a longer thread explaining the retraining approach. “It’s not like I was being deceptive about it,” he wrote. “I broke it up into separate tweets, and now everyone is mad about the first one.”In a follow-up email, Buckman took a measured view of the controversy. “The end of the transformer era is not yet here,” he reiterated, “but the march has begun.” He also acknowledged that the $4,000 claim, though technically accurate in context, had drawn attention precisely because it challenged expectations about what it costs to experiment at frontier scale.Conclusion: A Crack in the Transformer’s Wall?The release of Brumby-14B-Base is more than an engineering milestone; it is a proof of concept that the transformer’s dominance may finally face credible competition. By replacing attention with power retention, Manifest AI has demonstrated that performance parity with state-of-the-art transformers is possible at a fraction of the computational cost—and that the long-context bottleneck can be broken without exotic hardware.The broader implications are twofold. First, the economics of training and serving large models could shift dramatically, lowering the barrier to entry for open research and smaller organizations. Second, the architectural diversity of AI models may expand again, reigniting theoretical and empirical exploration after half a decade of transformer monoculture.As Buckman put it: “The end of the transformer era is not yet here. Our release is just one step forward in a long march toward the future.”",
          "content": "When the transformer architecture was introduced in 2017 in the now seminal Google paper \"Attention Is All You Need,\" it became an instant cornerstone of modern artificial intelligence. Every major large language model (LLM) — from OpenAI&#x27;s GPT series to Anthropic&#x27;s Claude, Google&#x27;s Gemini, and Meta&#x27;s Llama — has been built on some variation of its central mechanism: attention, the mathematical operation that allows a model to look back across its entire input and decide what information matters most.Eight years later, the same mechanism that defined AI’s golden age is now showing its limits. Attention is powerful, but it is also expensive — its computational and memory costs scale quadratically with context length, creating an increasingly unsustainable bottleneck for both research and industry. As models aim to reason across documents, codebases, or video streams lasting hours or days, attention becomes the architecture’s Achilles’ heel.On October 28, 2025, the little-known AI startup Manifest AI introduced a radical alternative. Their new model, Brumby-14B-Base, is a retrained variant of Qwen3-14B-Base, one of the leading open-source transformer models.But while many variants of Qwen have been trained already, Brumby-14B-Base is novel in that it abandons attention altogether. Instead, Brumby replaces those layers with a novel mechanism called Power Retention—a recurrent, hardware-efficient architecture that stores and updates information over arbitrarily long contexts without the exponential memory growth of attention.Trained at a stated cost of just $4,000, the 14-billion-parameter Brumby model performs on par with established transformer models like Qwen3-14B and GLM-4.5-Air, achieving near-state-of-the-art accuracy on a range of reasoning and comprehension benchmarks.From Attention to Retention: The Architectural ShiftThe core of Manifest AI’s innovation lies in what they call the Power Retention layer. In a traditional transformer, every token computes a set of queries (Q), keys (K), and values (V), then performs a matrix operation that measures the similarity between every token and every other token—essentially a full pairwise comparison across the sequence. This is what gives attention its flexibility, but also what makes it so costly: processing a sequence twice as long takes roughly four times the compute and memory.Power Retention keeps the same inputs (Q, K, V), but replaces the global similarity operation with a recurrent state update. Each layer maintains a memory matrix S, which is updated at each time step according to the incoming key, value, and a learned gating signal. The process looks more like an RNN (Recurrent Neural Network) than a transformer: instead of recomputing attention over the entire context, the model continuously compresses past information into a fixed-size latent state.This means the computational cost of Power Retention does not grow with context length. Whether the model is processing 1,000 or 1,000,000 tokens, the per-token cost remains constant. That property alone—constant-time per-token computation—marks a profound departure from transformer behavior.At the same time, Power Retention preserves the expressive power that made attention successful. Because the recurrence involves tensor powers of the input (hence the name “power retention”), it can represent higher-order dependencies between past and present tokens. The result is an architecture that can theoretically retain long-term dependencies indefinitely, while remaining as efficient as an RNN and as expressive as a transformer.Retraining, Not RebuildingPerhaps the most striking aspect of Brumby-14B’s training process is its efficiency. Manifest AI trained the model for only 60 hours on 32 Nvidia H100 GPUs, at a cost of roughly $4,000 — less than 2% of what a conventional model of this scale would cost to train from scratch.However, since it relied on a transformer-based model, it&#x27;s safe to say that this advance alone will not end the transformer AI-era.As Jacob Buckman, founder of Manifest AI, clarified in an email to VentureBeat: “The ability to train for $4,000 is indeed only possible when leveraging an existing transformer model,” he said. “Brumby could not be trained from scratch for that price.”Still, Buckman emphasized the significance of that result: “The reason this is important is that the ability to build on the weights of the previous generation of model architectures is a critical accelerant for the adoption of a new modeling paradigm.” He argues this demonstrates how attention-free systems can catch up to transformer performance “for orders-of-magnitude less” investment.In the loss curves released by Manifest AI, Brumby’s training loss quickly converges to that of the Qwen3 baseline within 3,000 training steps, even as the architecture diverges significantly from its transformer origins. Although Brumby-14B-Base began life as Qwen3-14B-Base, it did not remain identical for long. Manifest AI fundamentally altered Qwen3’s architecture by removing its attention layers—the mathematical engine that defines how a transformer model processes information—and replacing them with their new “power retention” mechanism. This change restructured the model’s internal wiring, effectively giving it a new brain while preserving much of its prior knowledge.Because of that architectural swap, the existing Qwen3 weights no longer fit perfectly. They were trained to operate within a transformer’s attention dynamics, not the new retention-based system. As a result, the Brumby model initially “forgot” how to apply some of its learned knowledge effectively. The retraining process—about 3,000 steps of additional learning—served to recalibrate those weights, aligning them with the power retention framework without having to start from zero.A helpful way to think about this is to imagine taking a world-class pianist and handing them a guitar. They already understand rhythm, harmony, and melody, but their hands must learn entirely new patterns to produce the same music. Similarly, Brumby had to relearn how to use its existing knowledge through a new computational instrument. Those 3,000 training steps were, in effect, its crash course in guitar lessons.By the end of this short retraining phase, Brumby had regained its full performance, reaching the same accuracy as the original Qwen3 model. That quick recovery is what makes the result so significant: it shows that an attention-free system can inherit and adapt the capabilities of a transformer model with only a fraction of the training time and cost.The benchmark progression plots show a similar trend: the model rapidly approaches its target accuracy on core evaluations like GSM8K, HellaSwag, and MMLU after only a few thousand steps, matching or even slightly surpassing Qwen3 on several tasks.Benchmarking the BrumbyAcross standard evaluation tasks, Brumby-14B-Base consistently performs at or near parity with transformer baselines of comparable scale.TaskBrumby-14BQwen3-14BGLM-4.5-AirNemotron Nano (12B)ARC0.890.940.920.93GSM8K0.880.840.830.84GSM8K (Platinum)0.870.880.850.87HellaSwag0.770.810.850.82MATH0.620.540.470.26MBPP0.570.750.730.71MMLU0.710.780.770.78MMLU (Pro)0.360.550.510.53While it lags slightly behind transformers on knowledge-heavy evaluations like MMLU-Pro, it matches or outperforms them on mathematical reasoning and long-context reasoning tasks—precisely where attention architectures tend to falter. This pattern reinforces the idea that recurrent or retention-based systems may hold a structural advantage for reasoning over extended temporal or logical dependencies.Hardware Efficiency and Inference PerformanceBrumby’s power retention design offers another major advantage: hardware efficiency.Because the state update involves only local matrix operations, inference can be implemented with linear complexity in sequence length. Manifest AI reports that their fastest kernels, developed through their in-house CUDA framework Vidrial, can deliver hundreds-fold speedups over attention on very long contexts.Buckman said the alpha-stage Power Retention kernels “achieve typical hardware utilization of 80–85%, which is higher than FlashAttention2’s 70–75% or Mamba’s 50–60%.” (Mamba is another emerging “post-transformer” architecture developed by Carnegie Mellon scientists back in 2023 that, like Power Retention, seeks to eliminate the computational bottleneck of attention. It replaces attention with a state-space mechanism that processes sequences linearly — updating an internal state over time rather than comparing every token to every other one. This makes it far more efficient for long inputs, though it typically achieves lower hardware utilization than Power Retention in early tests.)Both Power Retention and Mamba, he added, “expend meaningfully fewer total FLOPs than FlashAttention2 on long contexts, as well as far less memory.” According to Buckman, the reported 100× speedup comes from this combined improvement in utilization and computational efficiency, though he noted that “we have not yet stress-tested it on production-scale workloads.”Training and Scaling EconomicsPerhaps no statistic in the Brumby release generated more attention than the training cost.A 14-billion-parameter model, trained for $4,000, represents a two-order-of-magnitude reduction in the cost of foundation model development.Buckman confirmed that the low cost reflects a broader scaling pattern. “Far from diminishing returns, we have found that ease of retraining improves with scale,” he said. “The number of steps required to successfully retrain a model decreases with its parameter count.” Manifest has not yet validated the cost of retraining models at 700B parameters, but Buckman projected a range of $10,000–$20,000 for models of that magnitude—still far below transformer training budgets.He also reiterated that this approach could democratize large-scale experimentation by allowing smaller research groups or companies to retrain or repurpose existing transformer checkpoints without prohibitive compute costs.Integration and DeploymentAccording to Buckman, converting an existing transformer into a Power Retention model is designed to be simple. “It is straightforward for any company that is already retraining, post-training, or fine-tuning open-source models,” he said. “Simply pip install retention, change one line of your architecture code, and resume training where you left off.”He added that after only a small number of GPU-hours, the model typically recovers its original performance—at which point it gains the efficiency benefits of the attention-free design. “The resulting architecture will permit far faster long-context training and inference than previously,” Buckman noted.On infrastructure, Buckman said the main Brumby kernels are written in Triton, compatible with both NVIDIA and AMD accelerators. Specialized CUDA kernels are also available through the team’s in-house Vidrial framework. Integration with vLLM and other inference engines remains a work in progress: “We have not yet integrated Power Retention into inference engines, but doing so is a major ongoing initiative at Manifest.”As for distributed inference, Buckman dismissed concerns about instability: “We have not found this difficulty to be exacerbated in any way by our recurrent-state architecture. In fact, context-parallel training and GPU partitioning for multi-user inference both become significantly cleaner technically when using our approach.”Mission and Long-Term VisionBeyond the engineering details, Buckman also described Manifest’s broader mission. “Our mission is to train a neural network to model all human output,” he said. The team’s goal, he explained, is to move beyond modeling “artifacts of intelligence” toward modeling “the intelligent processes that generated them.” This shift, he argued, requires “fundamentally rethinking” how models are designed and trained—work that Power Retention represents only the beginning of.The Brumby-14B release, he said, is “one step forward in a long march” toward architectures that can model thought processes continuously and efficiently.Public Debate and Industry ReceptionThe launch of Brumby-14B sparked immediate discussion on X (formerly Twitter), where researchers debated the framing of Manifest AI’s announcement. Some, including Meta researcher Ariel (@redtachyon), argued that the “$4,000 foundation model” tagline was misleading, since the training involved reusing pretrained transformer weights rather than training from scratch.“They shuffled around the weights of Qwen, fine-tuned it a bit, and called it ‘training a foundation model for $4k,’” Ariel wrote.Buckman responded publicly, clarifying that the initial tweet had been part of a longer thread explaining the retraining approach. “It’s not like I was being deceptive about it,” he wrote. “I broke it up into separate tweets, and now everyone is mad about the first one.”In a follow-up email, Buckman took a measured view of the controversy. “The end of the transformer era is not yet here,” he reiterated, “but the march has begun.” He also acknowledged that the $4,000 claim, though technically accurate in context, had drawn attention precisely because it challenged expectations about what it costs to experiment at frontier scale.Conclusion: A Crack in the Transformer’s Wall?The release of Brumby-14B-Base is more than an engineering milestone; it is a proof of concept that the transformer’s dominance may finally face credible competition. By replacing attention with power retention, Manifest AI has demonstrated that performance parity with state-of-the-art transformers is possible at a fraction of the computational cost—and that the long-context bottleneck can be broken without exotic hardware.The broader implications are twofold. First, the economics of training and serving large models could shift dramatically, lowering the barrier to entry for open research and smaller organizations. Second, the architectural diversity of AI models may expand again, reigniting theoretical and empirical exploration after half a decade of transformer monoculture.As Buckman put it: “The end of the transformer era is not yet here. Our release is just one step forward in a long march toward the future.”",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4w8pJoJCpKW8g1eJxxgy3f/c8d0f3a8431956228510e551a2b474f1/aRNZNKxpXqqt3S_iXlQfh_71e40940f61b4bf89d6b5f5cbeafd63e.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data-infrastructure/snowflake-builds-new-intelligence-that-goes-beyond-rag-to-query-and",
          "published_at": "Tue, 04 Nov 2025 16:00:00 GMT",
          "title": "Snowflake builds new intelligence that goes beyond RAG to query and aggregate thousands of documents at once",
          "standfirst": "Enterprise AI has a data problem. Despite billions in investment and increasingly capable language models, most organizations still can&#x27;t answer basic analytical questions about their document repositories. The culprit isn&#x27;t model quality but architecture: Traditional retrieval augmented generation (RAG) systems were designed to retrieve and summarize, not analyze and aggregate across large document sets.Snowflake is tackling this limitation head-on with a comprehensive platform strategy announced at its BUILD 2025 conference. The company unveiled Snowflake Intelligence, an enterprise intelligence agent platform designed to unify structured and unstructured data analysis, along with infrastructure improvements spanning data integration with Openflow, database consolidation with Snowflake Postgres and real-time analytics with interactive tables. The goal: Eliminate the data silos and architectural bottlenecks that prevent enterprises from operationalizing AI at scale.A key innovation is Agentic Document Analytics, a new capability within Snowflake Intelligence that can analyze thousands of documents simultaneously. This moves enterprises from basic lookups like \"What is our password reset policy?\" to complex analytical queries like \"Show me a count of weekly mentions by product area in my customer support tickets for the last six months.\"The RAG bottleneck: Why sampling fails for analyticsTraditional RAG systems work by embedding documents into vector representations, storing them in a vector database and retrieving the most semantically similar documents when a user asks a question.\"For RAG to work, it requires that all of the answers that you are searching for already exist in some published way today,\" Jeff Hollan, head of Cortex AI Agents at Snowflake explained to VentureBeat during a press briefing. \"The pattern I think about with RAG is it&#x27;s like a librarian, you get a question and it tells you, &#x27;This book has the answer on this specific page.&#x27;\"However, this architecture fundamentally breaks when organizations need to perform aggregate analysis. If, for example, an enterprise has 100,000 reports and wants to identify all of the reports that talk about a specific business entity and sum up all the revenue discussed in those reports, that&#x27;s a non-trivial task.\"That&#x27;s a much more complex thing than just traditional RAG,\" Hollan said.This limitation has typically forced enterprises to maintain separate analytics pipelines for structured data in data warehouses and unstructured data in vector databases or document stores. The result is data silos and governance challenges for enterprises.How Agentic Document Analytics works differentlySnowflake&#x27;s approach unifies structured and unstructured data analysis within its platform by treating documents as queryable data sources rather than retrieval targets. The system uses AI to extract, structure and index document content in ways that enable SQL-like analytical operations across thousands of documents.The capability leverages Snowflake&#x27;s existing architecture. Cortex AISQL handles document parsing and extraction. Interactive Tables and Warehouses deliver sub-second query performance on large datasets. By processing documents within the same governed data platform that houses structured data, enterprises can join document insights with transactional data, customer records and other business information.\"The value of AI, the power of AI, the productivity and disruptive potential of AI, is created and enabled by connecting with enterprise data,\" said Christian Kleinerman, EVP of product at Snowflake. The company&#x27;s architecture keeps all data processing within its security boundary, addressing governance concerns that have slowed enterprise AI adoption. The system works with documents across multiple sources. These include PDFs in SharePoint, Slack conversations, Microsoft Teams data and Salesforce records through Snowflake&#x27;s zero-copy integration capabilities. This eliminates the need to extract and move data into separate AI processing systems.Comparison with current market approachesThe announcement positions Snowflake differently from both traditional data warehouse vendors and AI-native startups. Companies like Databricks have focused on bringing AI capabilities to lakehouses, but typically still rely on vector databases and traditional RAG patterns for unstructured data. OpenAI&#x27;s Assistants API and Anthropic&#x27;s Claude both offer document analysis, but are limited by context window sizes.Vector database providers like Pinecone and Weaviate have built businesses around RAG use cases but sometimes face challenges when customers need analytical queries rather than retrieval-based ones. These systems excel at finding relevant documents but cannot easily aggregate information across large document sets.Among the key high-value use cases that were previously difficult with RAG-only architectures that Snowflow highlights for its approach is customer support analysis. Instead of manually reviewing support tickets, organizations can query patterns across thousands of interactions. Questions like \"What are the top 10 product issues mentioned in support tickets this quarter, broken down by customer segment?\" become answerable in seconds.What this means for enterprise AI strategyFor enterprises building AI strategies, Agentic Document Analytics represents a shift from the \"search and retrieve\" paradigm of RAG to a \"query and analyze\" paradigm more familiar from business intelligence tools. Rather than deploying separate vector databases and RAG systems for each use case, enterprises can consolidate document analytics into their existing data platform. This reduces infrastructure complexity while extending business intelligence practices to unstructured data.The capability also democratizes access. Making document analysis queryable through natural language means insights that previously required data science teams become available to business users.For enterprises looking to lead in AI, the competitive advantage comes not from having better language models, but from analyzing proprietary unstructured data at scale alongside structured business data. Organizations that can query their entire document corpus as easily as they query their data warehouse will gain insights competitors cannot easily replicate.\"AI is a reality today,\" Kleinerman said. \"We have lots of organizations already getting value out of AI, and if anyone is still waiting it out or sitting on the sidelines, our call to action is to start building now.\"",
          "content": "Enterprise AI has a data problem. Despite billions in investment and increasingly capable language models, most organizations still can&#x27;t answer basic analytical questions about their document repositories. The culprit isn&#x27;t model quality but architecture: Traditional retrieval augmented generation (RAG) systems were designed to retrieve and summarize, not analyze and aggregate across large document sets.Snowflake is tackling this limitation head-on with a comprehensive platform strategy announced at its BUILD 2025 conference. The company unveiled Snowflake Intelligence, an enterprise intelligence agent platform designed to unify structured and unstructured data analysis, along with infrastructure improvements spanning data integration with Openflow, database consolidation with Snowflake Postgres and real-time analytics with interactive tables. The goal: Eliminate the data silos and architectural bottlenecks that prevent enterprises from operationalizing AI at scale.A key innovation is Agentic Document Analytics, a new capability within Snowflake Intelligence that can analyze thousands of documents simultaneously. This moves enterprises from basic lookups like \"What is our password reset policy?\" to complex analytical queries like \"Show me a count of weekly mentions by product area in my customer support tickets for the last six months.\"The RAG bottleneck: Why sampling fails for analyticsTraditional RAG systems work by embedding documents into vector representations, storing them in a vector database and retrieving the most semantically similar documents when a user asks a question.\"For RAG to work, it requires that all of the answers that you are searching for already exist in some published way today,\" Jeff Hollan, head of Cortex AI Agents at Snowflake explained to VentureBeat during a press briefing. \"The pattern I think about with RAG is it&#x27;s like a librarian, you get a question and it tells you, &#x27;This book has the answer on this specific page.&#x27;\"However, this architecture fundamentally breaks when organizations need to perform aggregate analysis. If, for example, an enterprise has 100,000 reports and wants to identify all of the reports that talk about a specific business entity and sum up all the revenue discussed in those reports, that&#x27;s a non-trivial task.\"That&#x27;s a much more complex thing than just traditional RAG,\" Hollan said.This limitation has typically forced enterprises to maintain separate analytics pipelines for structured data in data warehouses and unstructured data in vector databases or document stores. The result is data silos and governance challenges for enterprises.How Agentic Document Analytics works differentlySnowflake&#x27;s approach unifies structured and unstructured data analysis within its platform by treating documents as queryable data sources rather than retrieval targets. The system uses AI to extract, structure and index document content in ways that enable SQL-like analytical operations across thousands of documents.The capability leverages Snowflake&#x27;s existing architecture. Cortex AISQL handles document parsing and extraction. Interactive Tables and Warehouses deliver sub-second query performance on large datasets. By processing documents within the same governed data platform that houses structured data, enterprises can join document insights with transactional data, customer records and other business information.\"The value of AI, the power of AI, the productivity and disruptive potential of AI, is created and enabled by connecting with enterprise data,\" said Christian Kleinerman, EVP of product at Snowflake. The company&#x27;s architecture keeps all data processing within its security boundary, addressing governance concerns that have slowed enterprise AI adoption. The system works with documents across multiple sources. These include PDFs in SharePoint, Slack conversations, Microsoft Teams data and Salesforce records through Snowflake&#x27;s zero-copy integration capabilities. This eliminates the need to extract and move data into separate AI processing systems.Comparison with current market approachesThe announcement positions Snowflake differently from both traditional data warehouse vendors and AI-native startups. Companies like Databricks have focused on bringing AI capabilities to lakehouses, but typically still rely on vector databases and traditional RAG patterns for unstructured data. OpenAI&#x27;s Assistants API and Anthropic&#x27;s Claude both offer document analysis, but are limited by context window sizes.Vector database providers like Pinecone and Weaviate have built businesses around RAG use cases but sometimes face challenges when customers need analytical queries rather than retrieval-based ones. These systems excel at finding relevant documents but cannot easily aggregate information across large document sets.Among the key high-value use cases that were previously difficult with RAG-only architectures that Snowflow highlights for its approach is customer support analysis. Instead of manually reviewing support tickets, organizations can query patterns across thousands of interactions. Questions like \"What are the top 10 product issues mentioned in support tickets this quarter, broken down by customer segment?\" become answerable in seconds.What this means for enterprise AI strategyFor enterprises building AI strategies, Agentic Document Analytics represents a shift from the \"search and retrieve\" paradigm of RAG to a \"query and analyze\" paradigm more familiar from business intelligence tools. Rather than deploying separate vector databases and RAG systems for each use case, enterprises can consolidate document analytics into their existing data platform. This reduces infrastructure complexity while extending business intelligence practices to unstructured data.The capability also democratizes access. Making document analysis queryable through natural language means insights that previously required data science teams become available to business users.For enterprises looking to lead in AI, the competitive advantage comes not from having better language models, but from analyzing proprietary unstructured data at scale alongside structured business data. Organizations that can query their entire document corpus as easily as they query their data warehouse will gain insights competitors cannot easily replicate.\"AI is a reality today,\" Kleinerman said. \"We have lots of organizations already getting value out of AI, and if anyone is still waiting it out or sitting on the sidelines, our call to action is to start building now.\"",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/aNb5OOWRBwXwTcNyiXZd6/eea66c4d9359d596ed1345fc0e5ee004/snowflake-circuuits-code-e1687808581398.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/98-of-market-researchers-use-ai-daily-but-4-in-10-say-it-makes-errors",
          "published_at": "Tue, 04 Nov 2025 08:00:00 GMT",
          "title": "98% of market researchers use AI daily, but 4 in 10 say it makes errors — revealing a major trust problem",
          "standfirst": "Market researchers have embraced artificial intelligence at a staggering pace, with 98% of professionals now incorporating AI tools into their work and 72% using them daily or more frequently, according to a new industry survey that reveals both the technology&#x27;s transformative promise and its persistent reliability problems.The findings, based on responses from 219 U.S. market research and insights professionals surveyed in August 2025 by QuestDIY, a research platform owned by The Harris Poll, paint a picture of an industry caught between competing pressures: the demand to deliver faster business insights and the burden of validating everything AI produces to ensure accuracy.While more than half of researchers — 56% — report saving at least five hours per week using AI tools, nearly four in ten say they&#x27;ve experienced \"increased reliance on technology that sometimes produces errors.\" An additional 37% report that AI has \"introduced new risks around data quality or accuracy,\" and 31% say the technology has \"led to more work re-checking or validating AI outputs.\"The disconnect between productivity gains and trustworthiness has created what amounts to a grand bargain in the research industry: professionals accept time savings and enhanced capabilities in exchange for constant vigilance over AI&#x27;s mistakes, a dynamic that may fundamentally reshape how insights work gets done.How market researchers went from AI skeptics to daily users in less than a yearThe numbers suggest AI has moved from experiment to infrastructure in record time. Among those using AI daily, 39% deploy it once per day, while 33% use it \"several times per day or more,\" according to the survey conducted between August 15-19, 2025. Adoption is accelerating: 80% of researchers say they&#x27;re using AI more than they were six months ago, and 71% expect to increase usage over the next six months. Only 8% anticipate their usage will decline.“While AI provides excellent assistance and opportunities, human judgment will remain vital,” Erica Parker, Managing Director Research Products at The Harris Poll, told VentureBeat. “The future is a teamwork dynamic where AI will accelerate tasks and quickly unearth findings, while researchers will ensure quality and provide high level consultative insights.”The top use cases reflect AI&#x27;s strength in handling data at scale: 58% of researchers use it for analyzing multiple data sources, 54% for analyzing structured data, 50% for automating insight reports, 49% for analyzing open-ended survey responses, and 48% for summarizing findings. These tasks—traditionally labor-intensive and time-consuming — now happen in minutes rather than hours.Beyond time savings, researchers report tangible quality improvements. Some 44% say AI improves accuracy, 43% report it helps surface insights they might otherwise have missed, 43% cite increased speed of insights delivery, and 39% say it sparks creativity. The overwhelming majority — 89% — say AI has made their work lives better, with 25% describing the improvement as \"significant.\"The productivity paradox: saving time while creating new validation workYet the same survey reveals deep unease about the technology&#x27;s reliability. The list of concerns is extensive: 39% of researchers report increased reliance on error-prone technology, 37% cite new risks around data quality or accuracy, 31% describe additional validation work, 29% report uncertainty about job security, and 28% say AI has raised concerns about data privacy and ethics.The report notes that \"accuracy is the biggest frustration with AI experienced by researchers when asked on an open-ended basis.\" One researcher captured the tension succinctly: \"The faster we move with AI, the more we need to check if we&#x27;re moving in the right direction.\"This paradox — saving time while simultaneously creating new work — reflects a fundamental characteristic of current AI systems, which can produce outputs that appear authoritative but contain what researchers call \"hallucinations,\" or fabricated information presented as fact. The challenge is particularly acute in a profession where credibility depends on methodological rigor and where incorrect data can lead clients to make costly business decisions.\"Researchers view AI as a junior analyst, capable of speed and breadth, but needing oversight and judgment,\" said Gary Topiol, Managing Director at QuestDIY, in the report.That metaphor — AI as junior analyst — captures the industry&#x27;s current operating model. Researchers treat AI outputs as drafts requiring senior review rather than finished products, a workflow that provides guardrails but also underscores the technology&#x27;s limitations.Why data privacy fears are the biggest obstacle to AI adoption in researchWhen asked what would limit AI use at work, researchers identified data privacy and security concerns as the greatest barrier, cited by 33% of respondents. This concern isn&#x27;t abstract: researchers handle sensitive customer data, proprietary business information, and personally identifiable information subject to regulations like GDPR and CCPA. Sharing that data with AI systems — particularly cloud-based large language models — raises legitimate questions about who controls the information and whether it might be used to train models accessible to competitors.Other significant barriers include time to experiment and learn new tools (32%), training (32%), integration challenges (28%), internal policy restrictions (25%), and cost (24%). An additional 31% cited lack of transparency in AI use as a concern, which could complicate explaining results to clients and stakeholders.The transparency issue is particularly thorny. When an AI system produces an analysis or insight, researchers often cannot trace how the system arrived at its conclusion — a problem that conflicts with the scientific method&#x27;s emphasis on replicability and clear methodology. Some clients have responded by including no-AI clauses in their contracts, forcing researchers to either avoid the technology entirely or use it in ways that don&#x27;t technically violate contractual terms but may blur ethical lines.\"Onboarding beats feature bloat,\" Parker said in the report. \"The biggest brakes are time to learn and train. Packaged workflows, templates, and guided setup all unlock usage faster than piling on capabilities.\"Inside the new workflow: treating AI like a junior analyst who needs constant supervisionDespite these challenges, researchers aren&#x27;t abandoning AI — they&#x27;re developing frameworks to use it responsibly. The consensus model, according to the survey, is \"human-led research supported by AI,\" where AI handles repetitive tasks like coding, data cleaning, and report generation while humans focus on interpretation, strategy, and business impact.About one-third of researchers (29%) describe their current workflow as \"human-led with significant AI support,\" while 31% characterize it as \"mostly human with some AI help.\" Looking ahead to 2030, 61% envision AI as a \"decision-support partner\" with expanded capabilities including generative features for drafting surveys and reports (56%), AI-driven synthetic data generation (53%), automation of core processes like project setup and coding (48%), predictive analytics (44%), and deeper cognitive insights (43%).The report describes an emerging division of labor where researchers become \"Insight Advocates\" — professionals who validate AI outputs, connect findings to stakeholder challenges, and translate machine-generated analysis into strategic narratives that drive business decisions. In this model, technical execution becomes less central to the researcher&#x27;s value proposition than judgment, context, and storytelling.\"AI can surface missed insights — but it still needs a human to judge what really matters,\" Topiol said in the report.What other knowledge workers can learn from the research industry&#x27;s AI experimentThe market research industry&#x27;s AI adoption may presage similar patterns in other knowledge work professions where the technology promises to accelerate analysis and synthesis. The experience of researchers — early AI adopters who have integrated the technology into daily workflows — offers lessons about both opportunities and pitfalls.First, speed genuinely matters. One boutique agency research lead quoted in the report described watching survey results accumulate in real-time after fielding: \"After submitting it for fielding, I literally watched the survey count climb and finish the same afternoon. It was a remarkable turnaround.\" That velocity enables researchers to respond to business questions within hours rather than weeks, making insights actionable while decisions are still being made rather than after the fact.Second, the productivity gains are real but uneven. Saving five hours per week represents meaningful efficiency for individual contributors, but those savings can disappear if spent validating AI outputs or correcting errors. The net benefit depends on the specific task, the quality of the AI tool, and the user&#x27;s skill in prompting and reviewing the technology&#x27;s work.Third, the skills required for research are changing. The report identifies future competencies including cultural fluency, strategic storytelling, ethical stewardship, and what it calls \"inquisitive insight advocacy\" — the ability to ask the right questions, validate AI outputs, and frame insights for maximum business impact. Technical execution, while still important, becomes less differentiating as AI handles more of the mechanical work.The strange phenomenon of using technology intensively while questioning its reliabilityThe survey&#x27;s most striking finding may be the persistence of trust issues despite widespread adoption. In most technology adoption curves, trust builds as users gain experience and tools mature. But with AI, researchers appear to be using tools intensively while simultaneously questioning their reliability — a dynamic driven by the technology&#x27;s pattern of performing well most of the time but failing unpredictably.This creates a verification burden that has no obvious endpoint. Unlike traditional software bugs that can be identified and fixed, AI systems&#x27; probabilistic nature means they may produce different outputs for the same inputs, making it difficult to develop reliable quality assurance processes.The data privacy concerns — cited by 33% as the biggest barrier to adoption — reflect a different dimension of trust. Researchers worry not just about whether AI produces accurate outputs but also about what happens to the sensitive data they feed into these systems. QuestDIY&#x27;s approach, according to the report, is to build AI directly into a research platform with ISO/IEC 27001 certification rather than requiring researchers to use general-purpose tools like ChatGPT that may store and learn from user inputs.\"The center of gravity is analysis at scale — fusing multiple sources, handling both structured and unstructured data, and automating reporting,\" Topiol said in the report, describing where AI delivers the most value.The future of research work: elevation or endless verification?The report positions 2026 as an inflection point when AI moves from being a tool researchers use to something more like a team member — what the authors call a \"co-analyst\" that participates in the research process rather than merely accelerating specific tasks.This vision assumes continued improvement in AI capabilities, particularly in areas where researchers currently see the technology as underdeveloped. While 41% currently use AI for survey design, 37% for programming, and 30% for proposal creation, most researchers consider these appropriate use cases, suggesting significant room for growth once the tools become more reliable or the workflows more structured.The human-led model appears likely to persist. \"The future is human-led, with AI as a trusted co-analyst,\" Parker said in the report. But what \"human-led\" means in practice may shift. If AI handles most analytical tasks and researchers focus on validation and strategic interpretation, the profession may come to resemble editorial work more than scientific analysis — curating and contextualizing machine-generated insights rather than producing them from scratch.\"AI gives researchers the space to move up the value chain – from data gatherers to Insight Advocates, focused on maximising business impact,\" Topiol said in the report.Whether this transformation marks an elevation of the profession or a deskilling depends partly on how the technology evolves. If AI systems become more transparent and reliable, the verification burden may decrease and researchers can focus on higher-order thinking. If they remain opaque and error-prone, researchers may find themselves trapped in an endless cycle of checking work produced by tools they cannot fully trust or explain.The survey data suggests researchers are navigating this uncertainty by developing a form of professional muscle memory — learning which tasks AI handles well, where it tends to fail, and how much oversight each type of output requires. This tacit knowledge, accumulated through daily use and occasional failures, may become as important to the profession as statistical literacy or survey design principles.Yet the fundamental tension remains unresolved. Researchers are moving faster than ever, delivering insights in hours instead of weeks, and handling analytical tasks that would have been impossible without AI. But they&#x27;re doing so while shouldering a new responsibility that previous generations never faced: serving as the quality control layer between powerful but unpredictable machines and business leaders making million-dollar decisions.The industry has made its bet. Now comes the harder part: proving that human judgment can keep pace with machine speed — and that the insights produced by this uneasy partnership are worth the trust clients place in them.",
          "content": "Market researchers have embraced artificial intelligence at a staggering pace, with 98% of professionals now incorporating AI tools into their work and 72% using them daily or more frequently, according to a new industry survey that reveals both the technology&#x27;s transformative promise and its persistent reliability problems.The findings, based on responses from 219 U.S. market research and insights professionals surveyed in August 2025 by QuestDIY, a research platform owned by The Harris Poll, paint a picture of an industry caught between competing pressures: the demand to deliver faster business insights and the burden of validating everything AI produces to ensure accuracy.While more than half of researchers — 56% — report saving at least five hours per week using AI tools, nearly four in ten say they&#x27;ve experienced \"increased reliance on technology that sometimes produces errors.\" An additional 37% report that AI has \"introduced new risks around data quality or accuracy,\" and 31% say the technology has \"led to more work re-checking or validating AI outputs.\"The disconnect between productivity gains and trustworthiness has created what amounts to a grand bargain in the research industry: professionals accept time savings and enhanced capabilities in exchange for constant vigilance over AI&#x27;s mistakes, a dynamic that may fundamentally reshape how insights work gets done.How market researchers went from AI skeptics to daily users in less than a yearThe numbers suggest AI has moved from experiment to infrastructure in record time. Among those using AI daily, 39% deploy it once per day, while 33% use it \"several times per day or more,\" according to the survey conducted between August 15-19, 2025. Adoption is accelerating: 80% of researchers say they&#x27;re using AI more than they were six months ago, and 71% expect to increase usage over the next six months. Only 8% anticipate their usage will decline.“While AI provides excellent assistance and opportunities, human judgment will remain vital,” Erica Parker, Managing Director Research Products at The Harris Poll, told VentureBeat. “The future is a teamwork dynamic where AI will accelerate tasks and quickly unearth findings, while researchers will ensure quality and provide high level consultative insights.”The top use cases reflect AI&#x27;s strength in handling data at scale: 58% of researchers use it for analyzing multiple data sources, 54% for analyzing structured data, 50% for automating insight reports, 49% for analyzing open-ended survey responses, and 48% for summarizing findings. These tasks—traditionally labor-intensive and time-consuming — now happen in minutes rather than hours.Beyond time savings, researchers report tangible quality improvements. Some 44% say AI improves accuracy, 43% report it helps surface insights they might otherwise have missed, 43% cite increased speed of insights delivery, and 39% say it sparks creativity. The overwhelming majority — 89% — say AI has made their work lives better, with 25% describing the improvement as \"significant.\"The productivity paradox: saving time while creating new validation workYet the same survey reveals deep unease about the technology&#x27;s reliability. The list of concerns is extensive: 39% of researchers report increased reliance on error-prone technology, 37% cite new risks around data quality or accuracy, 31% describe additional validation work, 29% report uncertainty about job security, and 28% say AI has raised concerns about data privacy and ethics.The report notes that \"accuracy is the biggest frustration with AI experienced by researchers when asked on an open-ended basis.\" One researcher captured the tension succinctly: \"The faster we move with AI, the more we need to check if we&#x27;re moving in the right direction.\"This paradox — saving time while simultaneously creating new work — reflects a fundamental characteristic of current AI systems, which can produce outputs that appear authoritative but contain what researchers call \"hallucinations,\" or fabricated information presented as fact. The challenge is particularly acute in a profession where credibility depends on methodological rigor and where incorrect data can lead clients to make costly business decisions.\"Researchers view AI as a junior analyst, capable of speed and breadth, but needing oversight and judgment,\" said Gary Topiol, Managing Director at QuestDIY, in the report.That metaphor — AI as junior analyst — captures the industry&#x27;s current operating model. Researchers treat AI outputs as drafts requiring senior review rather than finished products, a workflow that provides guardrails but also underscores the technology&#x27;s limitations.Why data privacy fears are the biggest obstacle to AI adoption in researchWhen asked what would limit AI use at work, researchers identified data privacy and security concerns as the greatest barrier, cited by 33% of respondents. This concern isn&#x27;t abstract: researchers handle sensitive customer data, proprietary business information, and personally identifiable information subject to regulations like GDPR and CCPA. Sharing that data with AI systems — particularly cloud-based large language models — raises legitimate questions about who controls the information and whether it might be used to train models accessible to competitors.Other significant barriers include time to experiment and learn new tools (32%), training (32%), integration challenges (28%), internal policy restrictions (25%), and cost (24%). An additional 31% cited lack of transparency in AI use as a concern, which could complicate explaining results to clients and stakeholders.The transparency issue is particularly thorny. When an AI system produces an analysis or insight, researchers often cannot trace how the system arrived at its conclusion — a problem that conflicts with the scientific method&#x27;s emphasis on replicability and clear methodology. Some clients have responded by including no-AI clauses in their contracts, forcing researchers to either avoid the technology entirely or use it in ways that don&#x27;t technically violate contractual terms but may blur ethical lines.\"Onboarding beats feature bloat,\" Parker said in the report. \"The biggest brakes are time to learn and train. Packaged workflows, templates, and guided setup all unlock usage faster than piling on capabilities.\"Inside the new workflow: treating AI like a junior analyst who needs constant supervisionDespite these challenges, researchers aren&#x27;t abandoning AI — they&#x27;re developing frameworks to use it responsibly. The consensus model, according to the survey, is \"human-led research supported by AI,\" where AI handles repetitive tasks like coding, data cleaning, and report generation while humans focus on interpretation, strategy, and business impact.About one-third of researchers (29%) describe their current workflow as \"human-led with significant AI support,\" while 31% characterize it as \"mostly human with some AI help.\" Looking ahead to 2030, 61% envision AI as a \"decision-support partner\" with expanded capabilities including generative features for drafting surveys and reports (56%), AI-driven synthetic data generation (53%), automation of core processes like project setup and coding (48%), predictive analytics (44%), and deeper cognitive insights (43%).The report describes an emerging division of labor where researchers become \"Insight Advocates\" — professionals who validate AI outputs, connect findings to stakeholder challenges, and translate machine-generated analysis into strategic narratives that drive business decisions. In this model, technical execution becomes less central to the researcher&#x27;s value proposition than judgment, context, and storytelling.\"AI can surface missed insights — but it still needs a human to judge what really matters,\" Topiol said in the report.What other knowledge workers can learn from the research industry&#x27;s AI experimentThe market research industry&#x27;s AI adoption may presage similar patterns in other knowledge work professions where the technology promises to accelerate analysis and synthesis. The experience of researchers — early AI adopters who have integrated the technology into daily workflows — offers lessons about both opportunities and pitfalls.First, speed genuinely matters. One boutique agency research lead quoted in the report described watching survey results accumulate in real-time after fielding: \"After submitting it for fielding, I literally watched the survey count climb and finish the same afternoon. It was a remarkable turnaround.\" That velocity enables researchers to respond to business questions within hours rather than weeks, making insights actionable while decisions are still being made rather than after the fact.Second, the productivity gains are real but uneven. Saving five hours per week represents meaningful efficiency for individual contributors, but those savings can disappear if spent validating AI outputs or correcting errors. The net benefit depends on the specific task, the quality of the AI tool, and the user&#x27;s skill in prompting and reviewing the technology&#x27;s work.Third, the skills required for research are changing. The report identifies future competencies including cultural fluency, strategic storytelling, ethical stewardship, and what it calls \"inquisitive insight advocacy\" — the ability to ask the right questions, validate AI outputs, and frame insights for maximum business impact. Technical execution, while still important, becomes less differentiating as AI handles more of the mechanical work.The strange phenomenon of using technology intensively while questioning its reliabilityThe survey&#x27;s most striking finding may be the persistence of trust issues despite widespread adoption. In most technology adoption curves, trust builds as users gain experience and tools mature. But with AI, researchers appear to be using tools intensively while simultaneously questioning their reliability — a dynamic driven by the technology&#x27;s pattern of performing well most of the time but failing unpredictably.This creates a verification burden that has no obvious endpoint. Unlike traditional software bugs that can be identified and fixed, AI systems&#x27; probabilistic nature means they may produce different outputs for the same inputs, making it difficult to develop reliable quality assurance processes.The data privacy concerns — cited by 33% as the biggest barrier to adoption — reflect a different dimension of trust. Researchers worry not just about whether AI produces accurate outputs but also about what happens to the sensitive data they feed into these systems. QuestDIY&#x27;s approach, according to the report, is to build AI directly into a research platform with ISO/IEC 27001 certification rather than requiring researchers to use general-purpose tools like ChatGPT that may store and learn from user inputs.\"The center of gravity is analysis at scale — fusing multiple sources, handling both structured and unstructured data, and automating reporting,\" Topiol said in the report, describing where AI delivers the most value.The future of research work: elevation or endless verification?The report positions 2026 as an inflection point when AI moves from being a tool researchers use to something more like a team member — what the authors call a \"co-analyst\" that participates in the research process rather than merely accelerating specific tasks.This vision assumes continued improvement in AI capabilities, particularly in areas where researchers currently see the technology as underdeveloped. While 41% currently use AI for survey design, 37% for programming, and 30% for proposal creation, most researchers consider these appropriate use cases, suggesting significant room for growth once the tools become more reliable or the workflows more structured.The human-led model appears likely to persist. \"The future is human-led, with AI as a trusted co-analyst,\" Parker said in the report. But what \"human-led\" means in practice may shift. If AI handles most analytical tasks and researchers focus on validation and strategic interpretation, the profession may come to resemble editorial work more than scientific analysis — curating and contextualizing machine-generated insights rather than producing them from scratch.\"AI gives researchers the space to move up the value chain – from data gatherers to Insight Advocates, focused on maximising business impact,\" Topiol said in the report.Whether this transformation marks an elevation of the profession or a deskilling depends partly on how the technology evolves. If AI systems become more transparent and reliable, the verification burden may decrease and researchers can focus on higher-order thinking. If they remain opaque and error-prone, researchers may find themselves trapped in an endless cycle of checking work produced by tools they cannot fully trust or explain.The survey data suggests researchers are navigating this uncertainty by developing a form of professional muscle memory — learning which tasks AI handles well, where it tends to fail, and how much oversight each type of output requires. This tacit knowledge, accumulated through daily use and occasional failures, may become as important to the profession as statistical literacy or survey design principles.Yet the fundamental tension remains unresolved. Researchers are moving faster than ever, delivering insights in hours instead of weeks, and handling analytical tasks that would have been impossible without AI. But they&#x27;re doing so while shouldering a new responsibility that previous generations never faced: serving as the quality control layer between powerful but unpredictable machines and business leaders making million-dollar decisions.The industry has made its bet. Now comes the harder part: proving that human judgment can keep pace with machine speed — and that the insights produced by this uneasy partnership are worth the trust clients place in them.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/69hFvbU4ambt5HRDl1GrZa/1a33a47f699ce8af5cf3783ee71cb52c/nuneybits_Vector_art_of_magnifying_glass_revealing_AI_errors_fed1833a-d173-4100-bd60-4e3416c7e83b.webp?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/T84hNL2FLkCHG8Qpdt8AR/8ad71c54daf9b7e5a06242ac44108a23/crimedy7_illustration_of_robots_constructing_a_building_vivid_40fa4859-c9cc-453b-ad1e-3f01969c44fe_2.png?w=300&q=30",
      "popularity_score": 2007.6290458333333,
      "ai_summary": [
        "Fitbit is offering early Black Friday deals on its products.",
        "The Charge 6 fitness tracker is on sale for $100, a $60 discount.",
        "The Charge 6 features built-in GPS and a more accurate heart rate monitor.",
        "The device tracks 20 exercise types and offers a week-long battery life.",
        "The Inspire 3 fitness tracker is also on sale, with a 30 percent discount."
      ]
    },
    {
      "id": "cluster_38",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 23:00:46 +0000",
      "title": "5 AI-developed malware families analyzed by Google fail to work and are easily detected",
      "neutral_headline": "AI-Developed Malware Fails to Work and Is Easily Detected",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/11/ai-generated-malware-poses-little-real-world-threat-contrary-to-hype/",
          "published_at": "Wed, 05 Nov 2025 23:00:46 +0000",
          "title": "5 AI-developed malware families analyzed by Google fail to work and are easily detected",
          "standfirst": "You wouldn't know it from the hype, but the results fail to impress.",
          "content": "Google on Wednesday revealed five recent malware samples that were built using generative AI. The end results of each one were far below par with professional malware development, a finding that shows that vibe coding of malicious wares lags behind more traditional forms of development, which means it still has a long way to go before it poses a real-world threat. One of the samples, for instance, tracked under the name PromptLock, was part of an academic study analyzing how effective the use of large language models can be “to autonomously plan, adapt, and execute the ransomware attack lifecycle.” The researchers, however, reported the malware had “clear limitations: it omits persistence, lateral movement, and advanced evasion tactics” and served as little more than a demonstration of the feasibility of AI for such purposes. Prior to the paper’s release, security firm ESET said it had discovered the sample and hailed it as “the first AI-powered ransomware.” Don’t believe the hype Like the other four samples Google analyzed—FruitShell, PromptFlux, PromptSteal, and QuietVault—PromptLock was easy to detect, even by less-sophisticated endpoint protections that rely on static signatures. All samples also employed previously seen methods in malware samples, making them easy to counteract. They also had no operational impact, meaning they didn’t require defenders to adopt new defenses.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/malware-threat-1000x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/malware-threat-1000x648.jpg",
      "popularity_score": 357.6907125,
      "ai_summary": [
        "Google analyzed five AI-developed malware families.",
        "The results of the analysis failed to impress.",
        "The malware families were easily detected.",
        "The hype surrounding AI-developed malware is not justified.",
        "The study suggests current AI malware is ineffective."
      ]
    },
    {
      "id": "cluster_33",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 23:50:26 +0000",
      "title": "Musk and Trump both went to Penn—now hacked by someone sympathetic to their cause",
      "neutral_headline": "Musk and Trump Both Went to Penn—now hacked by someone sympathetic to their cause",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2025/11/musk-and-trump-both-went-to-penn-now-hacked-by-someone-sympathetic-to-their-cause/",
          "published_at": "Wed, 05 Nov 2025 23:50:26 +0000",
          "title": "Musk and Trump both went to Penn—now hacked by someone sympathetic to their cause",
          "standfirst": "Social engineering strikes again.",
          "content": "The University of Pennsylvania has a somewhat unusual distinction: It is the alma mater of two of the planet’s most polarizing figures, Elon Musk and Donald Trump. As the political power of both men rose over the last year, the US government began to pressure Penn, first by pulling its research funding and then by targeting the school for past actions related to a transgender swimmer. After the “sticks” were deployed, a “carrot” was offered. Penn became one of just nine schools nationally to be offered a special “compact” with the federal government, which would give the feds broad control over the school and its speech in return for preferential access to federal funds. Penn declined to sign the deal. (Making the whole surreal situation stranger was the fact that one of Penn’s own wealthy boosters apparently helped the Trump administration write the compact.) In other words, Penn has become an obvious target of the Trump administration; now it has been targeted by a hacker claiming to share Trump and Musk’s grievances over affirmative action and “wokeness.”Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1405238501-1152x648-1762385719.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-1405238501-1152x648-1762385719.jpg",
      "popularity_score": 355.5184902777778,
      "ai_summary": [
        "The University of Pennsylvania was hacked.",
        "The hack was carried out by someone sympathetic to a cause.",
        "Both Elon Musk and Donald Trump attended the university.",
        "The incident is an example of social engineering.",
        "The hack highlights vulnerabilities in cybersecurity."
      ]
    },
    {
      "id": "cluster_35",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 23:29:42 +0000",
      "title": "83-year-old man married 50 years nearly stumps doctors with surprise STI",
      "neutral_headline": "83-year-old man married 50 years nearly stumps doctors with surprise STI",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/11/rare-form-of-syphilis-in-married-elderly-man-nearly-stumps-doctors/",
          "published_at": "Wed, 05 Nov 2025 23:29:42 +0000",
          "title": "83-year-old man married 50 years nearly stumps doctors with surprise STI",
          "standfirst": "Man said he was in a monogamous 50-year marriage, but doctors aren't so sure now.",
          "content": "Syphilis can be a tricky disease to diagnose—especially when a patient may not be sharing the whole story. Doctors in Belgium met with a real head-scratcher when an 83-year-old married man came in with a rare form of secondary syphilis—the second of four stages of the sexually transmitted bacterial infection that has been called a “master of disguise.” The man told doctors up front that he was in a monogamous 50-year-long marriage and had been sexually inactive in recent years following treatment for cancer. In a Clinical Problem-Solving report published today in the New England Journal of Medicine, doctors laid out the step-by-step tests and reasoning they used to get to the right diagnosis, which still didn’t answer all their questions.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2157231571-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2157231571-1152x648.jpg",
      "popularity_score": 335.17293472222224,
      "ai_summary": [
        "An 83-year-old man was diagnosed with a sexually transmitted infection.",
        "The man claimed to be in a monogamous marriage for 50 years.",
        "Doctors are questioning the man's claim of monogamy.",
        "The case presents a medical mystery for doctors.",
        "The STI diagnosis is unexpected given the man's history."
      ]
    },
    {
      "id": "cluster_48",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 21:03:03 +0000",
      "title": "DHS offers “disturbing new excuses” to seize kids’ biometric data, expert says",
      "neutral_headline": "DHS offers “disturbing new excuses” to seize kids’ biometric data, expert says",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/11/dhs-wants-to-use-biometrics-to-track-immigrant-kids-throughout-their-lives/",
          "published_at": "Wed, 05 Nov 2025 21:03:03 +0000",
          "title": "DHS offers “disturbing new excuses” to seize kids’ biometric data, expert says",
          "standfirst": "Sweeping DHS power grab would collect face, iris, voice scans of all immigrants.",
          "content": "Civil and digital rights experts are horrified by a proposed rule change that would allow the Department of Homeland Security to collect a wide range of sensitive biometric data on all immigrants, without age restrictions, and store that data throughout each person’s “lifecycle” in the immigration system. If adopted, the rule change would allow DHS agencies, including Immigration and Customs Enforcement (ICE), to broadly collect facial imagery, finger and palm prints, iris scans, and voice prints. They may also request DNA, which DHS claimed “would only be collected in limited circumstances,” like to verify family relations. These updates would cost taxpayers $288.7 million annually, DHS estimated, including $57.1 million for DNA collection alone. Annual individual charges to immigrants submitting data will likely be similarly high, estimated at around $231.5 million. Costs could be higher, DHS admitted, especially if DNA testing is conducted more widely than projected.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-511484858-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-511484858-1152x648.jpg",
      "popularity_score": 312.7287680555556,
      "ai_summary": [
        "The Department of Homeland Security is seeking to collect biometric data.",
        "The data collection includes face, iris, and voice scans.",
        "The data collection would apply to all immigrants.",
        "An expert called the DHS's actions \"disturbing\".",
        "The DHS is expanding its power to collect biometric information."
      ]
    },
    {
      "id": "cluster_89",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 16:36:12 +0000",
      "title": "If you want to satiate AI’s hunger for power, Google suggests going to space",
      "neutral_headline": "If you want to satiate AI’s hunger for power, Google suggests going to space",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/if-you-want-to-satiate-ais-hunger-for-power-google-suggests-going-to-space/",
          "published_at": "Wed, 05 Nov 2025 16:36:12 +0000",
          "title": "If you want to satiate AI’s hunger for power, Google suggests going to space",
          "standfirst": "Google engineers think they already have all the pieces needed to build a data center in orbit.",
          "content": "It was probably always when, not if, Google would add its name to the list of companies intrigued by the potential of orbiting data centers. Google announced Tuesday a new initiative, named Project Suncatcher, to examine the feasibility of bringing artificial intelligence to space. The idea is to deploy swarms of satellites in low-Earth orbit, each carrying Google’s AI accelerator chips designed for training, content generation, synthetic speech and vision, and predictive modeling. Google calls these chips Tensor Processing Units, or TPUs. “Project Suncatcher is a moonshot exploring a new frontier: equipping solar-powered satellite constellations with TPUs and free-space optical links to one day scale machine learning compute in space,” Google wrote in a blog post.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/googletpu-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/googletpu-1152x648.jpg",
      "popularity_score": 303.28126805555553,
      "ai_summary": [
        "Google engineers are considering building a data center in orbit.",
        "They believe they have the necessary components for an orbital data center.",
        "The project aims to meet the growing power demands of AI.",
        "The data center would be located in space.",
        "The plan addresses the energy needs of AI development."
      ]
    },
    {
      "id": "cluster_58",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 20:00:26 +0000",
      "title": "New quantum hardware puts the mechanics in quantum mechanics",
      "neutral_headline": "New quantum hardware puts the mechanics in quantum mechanics",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/11/new-quantum-computing-hardware-sorts-ions-for-computation/",
          "published_at": "Wed, 05 Nov 2025 20:00:26 +0000",
          "title": "New quantum hardware puts the mechanics in quantum mechanics",
          "standfirst": "As a test case, the machine was used to test a model of superconductivity.",
          "content": "Quantum computers based on ions or atoms have one major advantage: The hardware itself isn’t manufactured, so there’s no device-to-device variability. Every atom is the same and should perform similarly every time. And since the qubits themselves can be moved around, it’s theoretically possible to entangle any atom or ion with any other in the system, allowing for a lot of flexibility in how algorithms and error correction are performed. This combination of consistent, high-fidelity performance with all-to-all connectivity has led many key demonstrations of quantum computing to be done on trapped-ion hardware. Unfortunately, the hardware has been held back a bit by relatively low qubit counts—a few dozen compared to the hundred or more seen in other technologies. But on Wednesday, a company called Quantinuum announced a new version of its trapped-ion hardware that significantly boosts the qubit count and uses some interesting technology to manage their operation. Trapped-ion computing Both neutral atom and trapped-ion computers store their qubits in the spin of the nucleus. That spin is somewhat shielded from the environment by the cloud of electrons around the nucleus, giving these qubits a relatively long coherence time. While neutral atoms are held in place by a network of lasers, trapped ions are manipulated via electromagnetic control based on the ion’s charge. This means that key components of the hardware can be built using standard electronic manufacturing, although lasers are still needed for manipulations and readout.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/helios-chip_top-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/helios-chip_top-1152x648.jpg",
      "popularity_score": 301.68515694444443,
      "ai_summary": [
        "New quantum hardware has been developed.",
        "The hardware was used to test a model of superconductivity.",
        "The machine was used as a test case.",
        "The hardware advances quantum mechanics research.",
        "The research focuses on quantum mechanics."
      ]
    },
    {
      "id": "cluster_62",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 19:10:45 +0000",
      "title": "YouTube TV’s Disney blackout reminds users that they don’t own what they stream",
      "neutral_headline": "YouTube TV’s Disney blackout reminds users that they don’t own what they stream",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/youtube-tvs-disney-blackout-reminds-users-that-they-dont-own-what-they-stream/",
          "published_at": "Wed, 05 Nov 2025 19:10:45 +0000",
          "title": "YouTube TV’s Disney blackout reminds users that they don’t own what they stream",
          "standfirst": "“This is a hard lesson for us all.”",
          "content": "Google and Disney have been in a contract dispute since October 30 that has resulted in YouTube TV subscribers losing access to 21 Disney-owned TV channels, including ABC, ESPN, and The Disney Channel. In addition to reducing access to popular live content, the corporate conflict is highlighting another frustration in the streaming era. As Google and Disney continue duking it out, their customers have lost some access to content they thought was permanent: DVR files and digital movie purchases. A perk of subscribing to YouTube TV, per Google’s marketing, is the ability to “record it all with unlimited DVR space.” A footnote on the YouTube TV homepage notes that unlimited DVR is subject to “device, regional, and Internet restrictions” but overlooks an additional restriction in the form of multi-conglomerate spats.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/12/getty-youtube-tv-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/12/getty-youtube-tv-1152x648.jpg",
      "popularity_score": 290.8571013888889,
      "ai_summary": [
        "YouTube TV users experienced a Disney blackout.",
        "The blackout highlights the limitations of streaming services.",
        "Users do not own the content they stream.",
        "The incident serves as a lesson for streaming users.",
        "The blackout underscores the lack of ownership in streaming."
      ]
    },
    {
      "id": "cluster_87",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 16:45:22 +0000",
      "title": "Flock haters cross political divides to remove error-prone cameras",
      "neutral_headline": "Flock haters cross political divides to remove error-prone cameras",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/11/flock-haters-cross-political-divides-to-remove-error-prone-cameras/",
          "published_at": "Wed, 05 Nov 2025 16:45:22 +0000",
          "title": "Flock haters cross political divides to remove error-prone cameras",
          "standfirst": "Lawmakers' calls for Flock probe may help kill local contracts, expert says.",
          "content": "Flock Safety—the surveillance company behind the country’s largest network of automated license plate readers (ALPRs)—currently faces attacks on multiple fronts seeking to tear down the invasive and error-prone cameras across the US. This week, two lawmakers, Sen. Ron Wyden (D-Ore.) and Rep. Raja Krishnamoorthi (D-Ill.), called for a federal investigation, alleging that Flock has been “negligently handling Americans’ personal data” by failing to use cybersecurity best practices. The month prior, Wyden wrote a letter to Flock CEO Garrett Langley, alleging that Flock’s security failures mean that “abuse of Flock cameras is inevitable” and that they threaten to expose billions of people’s harvested data should a catastrophic breach occur. “In my view, local elected officials can best protect their constituents from the inevitable abuses of Flock cameras by removing Flock from their communities,” Wyden wrote.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2205485838-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2205485838-1024x648.jpg",
      "popularity_score": 278.43404583333336,
      "ai_summary": [
        "Opposition to Flock cameras is uniting across political lines.",
        "Lawmakers are calling for probes into Flock cameras.",
        "The calls for probes may lead to contract cancellations.",
        "The cameras are prone to errors.",
        "The issue involves local contracts."
      ]
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 16:26:02 +0000",
      "title": "Google settlement with Epic caps Play Store fees, boosts other Android app stores",
      "neutral_headline": "Google Settles with Epic, Modifies Android App Store Policies",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/google-settlement-with-epic-caps-play-store-fees-boosts-other-android-app-stores/",
          "published_at": "Wed, 05 Nov 2025 16:26:02 +0000",
          "title": "Google settlement with Epic caps Play Store fees, boosts other Android app stores",
          "standfirst": "Google will make several changes to Android app support globally, supported through at least 2032.",
          "content": "Google has spent the last few years waging a losing battle against Epic Games, which accused the Android maker of illegally stifling competition in mobile apps. Losses in court left Google to make sweeping changes to the Play Store, but Google appeared poised to take the case all the way to the Supreme Court. That is unlikely now that Epic and Google have reached a settlement in the case. It still needs to be approved by the judge, but the agreement provides a framework for long-term changes to Android app distribution that would apply globally. Late last month, Google was forced to make the first round of mandated changes to the Play Store to comply with the court’s ruling. It grudgingly began allowing developers to direct users to alternative payment options and app downloads outside of Google’s ecosystem. By next summer, Google was supposed to open up Android to third-party app stores in a big way. These changes were only mandated for three years and in the United States. The new agreement includes a different vision for third-party stores on Android—one that Google finds more palatable and that still gives Epic what it wants. If approved, the settlement will lower Google’s standard fee for developers. There will also be new support in Android for third-party app stores that will reduce the friction of leaving the Google bubble. Under the terms of the settlement, Google will support these changes through at least June 2032.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/google-logo-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/08/google-logo-1152x648.jpg",
      "popularity_score": 270.1118236111111,
      "ai_summary": [
        "Google will modify Android app support globally, extending through at least the year 2032.",
        "The settlement addresses Play Store fees and impacts other Android app stores.",
        "Details of the settlement include changes to app distribution and developer agreements.",
        "This agreement resolves legal disputes related to app store practices.",
        "The changes aim to address concerns about competition and developer practices."
      ]
    },
    {
      "id": "cluster_98",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 15:42:57 +0000",
      "title": "How to declutter, quiet down, and take the AI out of Windows 11 25H2",
      "neutral_headline": "Guide to Decluttering and Optimizing Windows 11 25H2",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/what-i-do-to-clean-up-a-clean-install-of-windows-11-23h2-and-edge/",
          "published_at": "Wed, 05 Nov 2025 15:42:57 +0000",
          "title": "How to declutter, quiet down, and take the AI out of Windows 11 25H2",
          "standfirst": "A new major Windows 11 release means a new guide for cleaning up the OS.",
          "content": "It’s that time of year again—temperatures are dropping, leaves are changing color, and Microsoft is gradually rolling out another major yearly update to Windows 11. The Windows 11 25H2 update is relatively minor compared to last year’s 24H2 update (the “25” here is a reference to the year the update was released, while the “H2” denotes that it was released in the second half of the year, a vestigial suffix from when Microsoft would release two major Windows updates per year). The 24H2 update came with some major under-the-hood overhauls of core Windows components and significant performance improvements for the Arm version; 25H2 is largely 24H2, but with a rolled-over version number to keep it in line with Microsoft’s timeline for security updates and tech support. But Microsoft’s continuous update cadence for Windows 11 means that even the 24H2 version as it currently exists isn’t the same one Microsoft released a year ago.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/02/windows-11-cleanup-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/02/windows-11-cleanup-1152x648.jpg",
      "popularity_score": 262.39376805555554,
      "ai_summary": [
        "A new major Windows 11 release necessitates a guide for cleaning up the operating system.",
        "The guide focuses on decluttering, reducing noise, and removing AI features.",
        "It provides steps to optimize the system for performance and user experience.",
        "The guide helps users customize the new Windows 11 release.",
        "It offers tips for a cleaner and more efficient Windows 11 experience."
      ]
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 14:00:26 +0000",
      "title": "So long, Assistant—Gemini is taking over Google Maps",
      "neutral_headline": "Gemini Replacing Assistant in Google Maps on Android and iOS",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/11/so-long-assistant-gemini-is-taking-over-google-maps/",
          "published_at": "Wed, 05 Nov 2025 14:00:26 +0000",
          "title": "So long, Assistant—Gemini is taking over Google Maps",
          "standfirst": "Gemini is rolling out to Maps on Android and iOS, with Android Auto coming soon.",
          "content": "Google is in the process of purging Assistant across its products, and the next target is Google Maps. Starting today, Gemini will begin rolling out in Maps, powering new experiences for navigation, location info, and more. This update will eventually completely usurp Google Assistant’s hands-free role in Maps, but the rollout will take time. So for now, the smart assistant in Google Maps will still depend on how you’re running the app. Across all Gemini’s incarnations, Google stresses its conversational abilities. Whereas Assistant was hard-pressed to keep one or two balls in the air, you can theoretically give Gemini much more complex instructions. Google’s demo includes someone asking for nearby restaurants with cheap vegan food, but instead of just providing a list, it suggests something based on the user’s input. Gemini can also offer more information about the location. Maps will also get its own Gemini-infused version of Lens for after you park. You will be able to point the camera at a landmark, restaurant, or other business to get instant answers to your questions. This experience will be distinct from the version of Lens available in the Google app, focused on giving you location-based information. Maybe you want to know about the menu at a restaurant or what it’s like inside. Sure, you could open the door… but AI!Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-in-navigation-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Gemini-in-navigation-1152x648.jpg",
      "popularity_score": 147.68515694444443,
      "ai_summary": [
        "Gemini is rolling out to Google Maps on both Android and iOS platforms.",
        "Android Auto integration is planned for the near future.",
        "The transition involves replacing the existing Google Assistant functionality.",
        "Users will experience Gemini's features within the Maps application.",
        "This change aims to enhance the user experience with AI integration."
      ]
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Tue, 04 Nov 2025 22:50:29 +0000",
      "title": "Google’s new hurricane model was breathtakingly good this season",
      "neutral_headline": "Google's Hurricane Model Performed Well, US System Lagged",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/11/googles-new-weather-model-impressed-during-its-first-hurricane-season/",
          "published_at": "Tue, 04 Nov 2025 22:50:29 +0000",
          "title": "Google’s new hurricane model was breathtakingly good this season",
          "standfirst": "Meanwhile, the US Global Forecasting System continues to get worse.",
          "content": "The Atlantic hurricane season is drawing to a close, and with the tropics quieting down for a winter slumber, the focus of forecasters turns to evaluating what worked and what did not during the preceding season. This year, the answers are clear. Although Google DeepMind’s Weather Lab only started releasing cyclone track forecasts in June, the company’s AI forecasting service performed exceptionally well. By contrast, the Global Forecast System model, which is operated by the US National Weather Service, is based on traditional physics, and runs on powerful supercomputers, performed abysmally. The official data comparing forecast model performance will not be published by the National Hurricane Center for a few months. However, Brian McNoldy, a senior researcher at the University of Miami, has already done some preliminary number crunching.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/1000x1000-1000x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/1000x1000-1000x648.jpg",
      "popularity_score": 145,
      "ai_summary": [
        "Google's new hurricane model demonstrated impressive accuracy this season.",
        "The US Global Forecasting System, however, continues to decline in performance.",
        "The comparison highlights differences in forecasting capabilities.",
        "The Google model provided more accurate predictions during the season.",
        "The US system's performance has been a source of concern."
      ]
    },
    {
      "id": "cluster_99",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 15:40:58 +0000",
      "title": "Tesla’s European and Chinese customers are staying away in droves",
      "neutral_headline": "Tesla Sales Decline in Europe and China, Investors Watch",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/11/after-a-great-q3-tesla-sees-double-digit-declines-all-over-europe/",
          "published_at": "Wed, 05 Nov 2025 15:40:58 +0000",
          "title": "Tesla’s European and Chinese customers are staying away in droves",
          "standfirst": "Sales tank as investors get ready to decide whether to make Musk a trillionaire.",
          "content": "Tesla’s shareholders are ready to vote tomorrow on whether to give Elon Musk an even more vast slice of the company in an effort to keep him focused on selling electric vehicles. Currently, the trolling tycoon appears a little obsessed with the UK, a place he appears to conflate with Middle Earth, which investors may or may not take into account when making their decision. What they ought to take into account is how many cars Tesla sold last month. Although Tesla only publishes quarterly sales figures and does not divide those up by region, slightly more granular data is available from some countries via monthly new car registrations. And the numbers for October, when compared year on year to the same month in 2024, should be alarming. Sales fell by double-digit margins in Sweden (89 percent), Denmark (86 percent), Belgium (69 percent), Finland (68 percent), Austria (65 percent), Switzerland (60 percent), Portugal (59 percent), Germany (54 percent), Norway (50 percent), the Netherlands (48 percent), the UK (47 percent), Italy (47 percent), and Spain (31 percent).Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2211638677-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2211638677-1152x648.jpg",
      "popularity_score": 143.3607125,
      "ai_summary": [
        "Tesla's sales have decreased significantly in both European and Chinese markets.",
        "Investors are preparing to decide on Elon Musk's potential valuation.",
        "The sales decline raises questions about Tesla's market position.",
        "Investor decisions will influence the company's future trajectory.",
        "The situation reflects challenges in key international markets."
      ]
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 09:15:41 +0000",
      "title": "Space junk may have struck a Chinese crew ship in low-Earth orbit",
      "neutral_headline": "Space Junk May Have Damaged a Chinese Crew Ship in Orbit",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/landing-postponed-for-chinese-astronauts-after-suspected-space-debris-strike/",
          "published_at": "Wed, 05 Nov 2025 09:15:41 +0000",
          "title": "Space junk may have struck a Chinese crew ship in low-Earth orbit",
          "standfirst": "The three-man crew was supposed to return to Earth on Wednesday to wrap up six months in space.",
          "content": "Three Chinese astronauts were due to depart the Tiangong space station, reenter the atmosphere, and land in the remote desert of Inner Mongolia on Wednesday. Instead, officials ordered the crew to remain at the station while engineers investigate a potential problem with their landing craft. The China Manned Space Agency, run by the country’s military, announced the change late Tuesday in a brief statement posted to Weibo, the Chinese social media platform. “The Shenzhou 20 manned spacecraft is suspected of being impacted by small space debris,” the statement said. “Impact analysis and risk assessment are underway. To ensure the safety and health of the astronauts and the complete success of the mission, it has been decided that the Shenzhou 20 return mission, originally scheduled for November 5, will be postponed.”Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2211173685-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2211173685-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "Space debris may have struck a Chinese crew ship in low-Earth orbit.",
        "The three-man crew was scheduled to return to Earth on Wednesday.",
        "The crew had been in space for a six-month mission.",
        "The incident raises concerns about space debris hazards.",
        "The impact could potentially affect the crew's return."
      ]
    },
    {
      "id": "cluster_134",
      "coverage": 1,
      "updated_at": "Tue, 04 Nov 2025 23:24:50 +0000",
      "title": "FDA described as “clown show” amid latest scandal; top drug regulator is out",
      "neutral_headline": "FDA Criticized Amid Scandal, Top Drug Regulator Departs",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/11/fda-described-as-clown-show-amid-latest-scandal-top-drug-regulator-is-out/",
          "published_at": "Tue, 04 Nov 2025 23:24:50 +0000",
          "title": "FDA described as “clown show” amid latest scandal; top drug regulator is out",
          "standfirst": "FDA regulator accused of using position to exact revenge on old business associate.",
          "content": "An alleged extortion attempt, a petty yearslong grudge, shocking social media posts, and ominous text messages make up the latest scandal at the Food and Drug Administration, an agency that industry outsiders are calling a “clown show” and “soap opera” amid the Trump administration’s leadership, according to reporting by Stat News. Federal health agencies, in general, have taken heavy blows in Trump’s second term. The Centers for Disease Control and Prevention, in particular, has seen the abrupt dismantling of whole programs and divisions—teams that provide critical health services to Americans. CDC staff regularly describe being demoralized over the last year. Their Senate-confirmed director didn’t make it a full month before being dramatically ousted after allegedly refusing to rubber-stamp vaccine recommendations from a panel filled with vaccine skeptics by anti-vaccine Health Secretary Robert. F. Kennedy Jr. While the CDC is in shambles, the FDA has turned into something of a sideshow, with concern mounting that it remains a serious enough regulator to keep America’s medicines and treatments modern and safe. Many of the scandals are tied to Vinay Prasad, the Trump administration’s top vaccine regulator, who also has the titles of chief medical officer and chief scientific officer. Prasad made a name for himself on social media during the pandemic as a COVID-19 response skeptic and, since joining the FDA, has been known for overruling agency scientists and sowing distrust, unrest, and paranoia among staff. He was pushed out of the agency in July only to be reinstated about two weeks later.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2019/05/GettyImages-496532228-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2019/05/GettyImages-496532228-1152x648.jpg",
      "popularity_score": 138,
      "ai_summary": [
        "The FDA is facing criticism, described as a \"clown show\" due to a scandal.",
        "A top drug regulator has left their position.",
        "The regulator is accused of using their position for revenge.",
        "The accusations involve a former business associate.",
        "The scandal raises questions about the FDA's integrity."
      ]
    },
    {
      "id": "cluster_108",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 14:42:10 +0000",
      "title": "Why being too attractive can hurt fitness influencers",
      "neutral_headline": "Attractiveness Can Negatively Impact Fitness Influencers",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/11/why-being-too-attractive-can-hurt-fitness-influencers/",
          "published_at": "Wed, 05 Nov 2025 14:42:10 +0000",
          "title": "Why being too attractive can hurt fitness influencers",
          "standfirst": "The \"beauty backfire effect\" is especially strong in the fitness space.",
          "content": "“Sex sells” has been a mantra in marketing for decades. As researchers who study consumer behavior, we’ve seen plenty of evidence to support it: Attractive models and spokespeople have been shown to reliably grab attention, boost clicks, and make products seem more desirable. But our new research suggests that in a digital world full of influencers—trusted tastemakers with large online followings—being too attractive can actually backfire, particularly in the fitness space. We call this the “beauty backfire effect,” and we put it to the test in a series of laboratory experiments.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/influencer-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/influencer-1152x648.jpg",
      "popularity_score": 136.38071250000002,
      "ai_summary": [
        "Being too attractive can negatively affect fitness influencers.",
        "The \"beauty backfire effect\" is particularly strong in the fitness space.",
        "This effect can impact how audiences perceive influencers.",
        "It can influence the credibility and relatability of influencers.",
        "The effect highlights the complexities of social media influence."
      ]
    },
    {
      "id": "cluster_117",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 13:00:50 +0000",
      "title": "“So much more menacing”: Formula E’s new Gen4 car breaks cover",
      "neutral_headline": "Formula E's New Gen4 Car Unveiled with Advanced Features",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/11/formula-e-gets-2x-the-power-and-awd-with-new-gen4-car/",
          "published_at": "Wed, 05 Nov 2025 13:00:50 +0000",
          "title": "“So much more menacing”: Formula E’s new Gen4 car breaks cover",
          "standfirst": "Up to 700 kW regen braking, new Bridgestone tires, and it's even fully recyclable.",
          "content": "Formula E officially revealed its next electric racing car today. At first glance, the Gen4 machine looks similar to machinery of seasons past, but looks are deceiving—it’s “so much more menacing,” according to Formula E CEO Jeff Dodds. The new car is not only longer and wider, it’s far more powerful. The wings and bodywork now generate meaningful aerodynamic downforce. There will be a new tire supplier as Bridgestone returns to single-seat racing. The car is even completely recyclable. I’m not sure that everyone who attended a Formula E race in its first season would have bet on the sport’s continued existence more than a decade down the line. When the cars took their green flag for the first time in Beijing in 2014, as many people derided it for being too slow or for the mid-race car swaps as praised it for trying something new in the world of motorsport. Despite that, the racing was mostly entertaining, and it got better with the introduction of the Gen2 car, which made car swapping a thing of the past. Gen3 added more power, then temporary all-wheel drive with the advent of the Gen3 Evo days. That car will continue to race in season 12, which kicks off in Brazil on December 6 and ends in mid-August in London. When season 13 picks up in late 2026, we might see a pretty different kind of Formula E racing.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/FORMULAE_15-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/FORMULAE_15-1152x648.jpeg",
      "popularity_score": 134.69182361111112,
      "ai_summary": [
        "Formula E's new Gen4 car has been revealed, showcasing new features.",
        "The car features up to 700 kW regenerative braking capabilities.",
        "It includes new Bridgestone tires for improved performance.",
        "The car is designed to be fully recyclable.",
        "The advancements aim to enhance racing and sustainability."
      ]
    },
    {
      "id": "cluster_132",
      "coverage": 1,
      "updated_at": "Wed, 05 Nov 2025 00:50:43 +0000",
      "title": "In a stunning comeback, Jared Isaacman is renominated to lead NASA",
      "neutral_headline": "Jared Isaacman Renominated to Lead NASA Mission",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/in-a-stunning-comeback-jared-isaacman-is-renominated-to-lead-nasa/",
          "published_at": "Wed, 05 Nov 2025 00:50:43 +0000",
          "title": "In a stunning comeback, Jared Isaacman is renominated to lead NASA",
          "standfirst": "\"I will do everything I can to live up to those expectations.\"",
          "content": "President Trump announced Tuesday evening that he is renominating private astronaut Jared Isaacman to lead NASA. “Jared’s passion for space, astronaut experience, and dedication to pushing the boundaries of exploration, unlocking the mysteries of the universe, and advancing the new space economy make him ideally suited to lead NASA into a bold new era,” Trump wrote on his social media network, Truth Social. In his statement, Trump did not offer an explanation for why he found Isaacman acceptable now after pulling his original nomination in late May.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/02/Jared_Isaacman_at_SpaceX_2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/02/Jared_Isaacman_at_SpaceX_2-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Jared Isaacman has been renominated to lead a NASA mission.",
        "Isaacman expressed his commitment to meeting expectations.",
        "He previously led the Inspiration4 mission.",
        "The nomination reflects his experience in space exploration.",
        "He will play a key role in future space endeavors."
      ]
    },
    {
      "id": "cluster_137",
      "coverage": 1,
      "updated_at": "Tue, 04 Nov 2025 22:14:24 +0000",
      "title": "New HDR10+ Advanced standard will try to fix the soap opera effect",
      "neutral_headline": "New HDR10+ Standard Aims to Improve Motion Smoothing",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/11/hdr10-advanced-joins-dolby-vision-2-in-trying-to-make-you-like-motion-smoothing/",
          "published_at": "Tue, 04 Nov 2025 22:14:24 +0000",
          "title": "New HDR10+ Advanced standard will try to fix the soap opera effect",
          "standfirst": "Can more creator control fix motion smoothing?",
          "content": "Motion smoothing has a bad reputation among most cinephiles, as well as many home theater enthusiasts and content creators. Also known as motion or video interpolation, motion smoothing is available in virtually every modern TV today. It’s supposed to remove judder from films and TV shows that are shot with 24p (24 frames per second) or 25p film and displayed on 60Hz or 120Hz TVs. But motion smoothing often results in the dreaded soap opera effect and unwanted visual artifacts. Two upcoming HDR standards, HDR10+ Advanced and Dolby Vision 2, are looking to change how we perceive motion smoothing and more closely align motion interpolation with a creator’s vision. However, it’s unclear if these standards can pull that off. HDR10+ Advanced’s Intelligent FRC Today, Samsung provided details about the next version of the HDR10 format, which introduces six new features. Among HDR10+ Advanced’s most interesting features is HDR10+ Intelligent FRC (frame rate conversion), which is supposed to improve motion smoothing.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/mission-impossible-fallout-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/mission-impossible-fallout-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "A new HDR10+ Advanced standard will attempt to fix the soap opera effect.",
        "The standard aims to give creators more control over motion smoothing.",
        "The goal is to improve the viewing experience.",
        "The changes could reduce unwanted motion artifacts.",
        "The standard seeks to enhance visual quality."
      ]
    },
    {
      "id": "cluster_140",
      "coverage": 1,
      "updated_at": "Tue, 04 Nov 2025 21:26:03 +0000",
      "title": "US gives local police a face-scanning app similar to one used by ICE agents",
      "neutral_headline": "US Police Use Face-Scanning App Similar to ICE's",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/11/us-gives-local-police-a-face-scanning-app-similar-to-one-used-by-ice-agents/",
          "published_at": "Tue, 04 Nov 2025 21:26:03 +0000",
          "title": "US gives local police a face-scanning app similar to one used by ICE agents",
          "standfirst": "Mobile Identify app on Google Play helps police perform tasks delegated by ICE.",
          "content": "US Customs and Border Protection (CBP) launched a face-scanning app for local law enforcement agencies that assist the federal government with immigration-enforcement operations. The Mobile Identify app was released on the Google Play store on October 30. “This app facilitates functions authorized by Section 287(g) of the Immigration and Nationality Act (INA),” a US law that lets Immigration and Customs Enforcement (ICE) delegate immigration-officer duties to state and local law enforcement, according to the Mobile Identify app’s description on the Google Play store. “Through a formal agreement, or Memorandum of Agreement (MOA), with DHS [Department of Homeland Security], participating agencies like your Sheriff’s Department can have designated officers who are trained, certified, and authorized to perform certain immigration enforcement functions, helping to identify and process individuals who may be in the country unlawfully. This tool is built to streamline those responsibilities securely and efficiently, directly in the field.” A screenshot of the app on the Google Play listing shows it requires camera access “to take photos of subjects.” More information on how it works was reported today by 404 Media. “A source with knowledge of the app told 404 Media the app doesn’t return names after a face search. Instead it tells users to contact ICE and provides a reference number, or to not detain the person depending on the result,” the news report said.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/ice-badge-1152x648-1762290384.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/ice-badge-1152x648-1762290384.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "US police are using a face-scanning app similar to ICE's.",
        "The app, Mobile Identify, is available on Google Play.",
        "It helps police perform tasks delegated by ICE agents.",
        "The app raises concerns about privacy and surveillance.",
        "The technology allows for facial recognition by law enforcement."
      ]
    }
  ]
}