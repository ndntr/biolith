{
  "updated_at": "2025-11-11T11:17:45.943Z",
  "clusters": [
    {
      "id": "cluster_9",
      "coverage": 2,
      "updated_at": "Tue, 11 Nov 2025 10:00:36 +0000",
      "title": "The best E Ink tablets for 2025",
      "neutral_headline": "The best E Ink tablets for 2025",
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/tablets/best-e-ink-tablet-130037939.html",
          "published_at": "Tue, 11 Nov 2025 10:00:36 +0000",
          "title": "The best E Ink tablets for 2025",
          "standfirst": "E Ink tablets have always been intriguing to me because I’m a longtime lover of pen and paper. I’ve had probably hundreds of notebooks over the years, serving as repositories for my story ideas, to-do lists, meeting notes and everything in between. However, I turned away from physical notebooks at a certain point because it was just easier to store everything digitally so I always had my most important information at my fingertips.E Ink tablets seem to provide the best of both worlds: the tactile satisfaction of regular notebooks with many of the conveniences found in digital tools, plus easy-on-the-eyes E Ink screens. These devices have come a long way in the past few years, and we’re just starting to see more color E Ink tablets become more widely available. I tested out a number of different E Ink tablets to see how well they work, how convenient they really are and which are the best tablets using E Ink screens available today.Editor's note: Amazon announced a revamped family of Kindle Scribe E Ink tablets in September 2025. The Kindle Scribe 3 is thinner and lighter than its predecessor with faster page-turning and writing experiences. The Kindle Scribe Colorsoft is the first full-color addition to the lineup, with a pen that will support writing in 10 colors and highlighting in five different shades. Both new Scribe tablets will be available in the US \"later this year.\" You can read our Kindle Scribe Colorsoft hands on to get a first look, but we'll update this guide once we've had the chance to test out both new E Ink tablets. Table of contents Best E Ink tablets for 2025 Are E Ink tablets worth it? What to look for in an E Ink tablet Other E Ink tablets we've tested Best E Ink tablets for 2025 Are E Ink tablets worth it? An E Ink tablet will be a worthwhile purchase to a very select group of people. If you prefer the look and feel of an e paper display to LCD panels found on traditional tablets, it makes a lot of sense. They’re also good options for those who want a more paper-like writing experience (although you can get that kind of functionality on a regular tablet with the right screen protector) or a more distraction-free device overall. The final note is key here. Many E Ink tablets don’t run on the same operating systems as regular tablets, so you’re automatically going to be limited in what you can do. And even with those that do allow you to download traditional apps like Chrome, Instagram and Facebook, E Ink tablets are not designed to give you the best casual-browsing experience. This is mostly due to the nature of E Ink displays, which have noticeable refreshes, a lack of vibrant colors and lower picture quality than the panels you’ll find on even the cheapest iPad. Arguably the biggest reason why you wouldn’t want to go with an iPad (all models of which support stylus input, a plethora of reading apps, etc) is because it’s much easier to get distracted by email, social media and other Internet-related temptations. What to look for in an E Ink tablet Writing and latency Arguably the most important thing to consider when looking for an E Ink tablet is the writing experience. How good it is will depend a lot on the display’s refresh rate (does it refresh after every time you put pen to “paper,” or at a different regular interval) and the stylus’ latency. Most of the tablets I’ve tested have little to no latency, but some are certainly better than others. Finally, you should double check before buying that your preferred E Ink tablet comes with a stylus, or if you need to purchase one separately. Reading How much will you be reading books, documents and other things on this tablet? E Ink tablets come in many sizes, but most of them tend to be larger than your standard e-reader because it makes writing much easier. Having a larger display isn’t a bad thing, but it might make holding it for long periods slightly more uncomfortable. (Most e-readers are roughly the size of a paperback book, giving you a similar feeling to analog reading). The supported file types for e-books can also make a big difference. It’s hard to make a blanket statement here because this varies so much among E Ink tablets. The TL;DR is that you’ll have a much better reading experience if you go with one made by a company that already has a history in e-book sales (i.e. Amazon or Kobo). All of the titles you bought via the Kindle or Kobo store should automatically be available to you on your Kindle or Kobo E Ink tablet. Also with Kindle titles, specifically, since they are protected by DRM, it’s not necessarily the best idea to try to bring those titles over to a third-party device. Unless the tablet runs an operating system like Android that supports downloads for apps like Kindle and Kobo, you’ll be limited to supported file types, like ePUB, PDF, MOBI, JPEG, PNG and others. Search functionality Most E Ink tablets have some on-device search features, but they can vary widely between models. You’ll want to consider how important it is to you to be able to search through all your handwritten notes and markups. I noticed in my testing that Amazon’s and Kobo’s E Ink tablets made it easy to refer back to notes made in books and files because they automatically save to the specific pages on which you took notes, made highlights and more. Searching is less standardized on E Ink tablets that have different supported file types, but their features can be quite powerful in their own right. For example, a few devices I tested supported text search in handwritten notes along with handwriting recognition, the latter of which allows you to translate your scribbles into typed text. Sharing and connectivity While we established that E Ink tablets can be great distraction-free devices, most manufacturers understand that your notes and doodles aren’t created in a vacuum. You may want to access them elsewhere, and that requires some form of connectivity. All of the E Ink tablets I tried have Wi-Fi support, and some support cloud syncing, companion mobile apps and the ability to export notes via email so you can access them elsewhere. None of them, however, integrate directly with a digital note taking system like Evernote or OneNote, so these devices will always be somewhat supplementary if you use apps like that, too. I’d argue that, if you already lean heavily on apps like OneNote, a standard tablet with a stylus and screen protector might be the best way to go. Ultimately, you should think about what you will want to do with the documents you’ll interact with on your E Ink tablet after the tablet portion is done. Price E Ink tablets aren’t known for being cheap. They generally fall into the $300-$800 price range, which is what you can expect to pay for a solid regular tablet, too. A key factor in price is size: cheaper devices with E Ink displays are likely to have smaller screens, and stylus support isn’t as much of a given. Also, those types of devices are generally considered e-readers because of their size and may not be the best for note-taking, doodling and the like. E Ink tablets have gone up in price recently. Supernote and Onyx Boox increased prices, as did reMarkable. The former said it was due to \"increased costs,” and a reMarkable representative confirmed this to Engadget and provided the following statement: \"We regularly review our pricing based on market conditions and operational costs. We've communicated an upcoming adjustment for the US market effective in May to provide transparency to our customers. Multiple factors influence our pricing decisions, including supply chain dynamics and overall operational costs in specific markets.” As a result, the reMarkable Paper Pro jumped from $579 to $629 (that's for the bundle with the standard Marker and no Folio). This isn't great, considering the Paper Pro was already on the expensive side of the spectrum for E Ink tablets. It's also worth noting that Supernote and Onyx Boox have raised prices in the past few months as well. Other E Ink tablets we've tested Onyx Boox Tab X C The Boox Tab X C is a color-screened version of the Tab X, the company’s all-purpose e-paper Android tablet. The Tab X C has a lovely 13.3-inch Kaleido 3 E Ink color display, an octa-core processor, 6GB of RAM and it runs on Android 13, making it one of the most powerful tablets in Boox’s lineup. I’ve used the Tab X in the past and this color version runs similarly, if not better, and at 5.3mm thick, it’s impressively svelte even when you pair it with its folio keyboard case. As someone who loves legal-pad sized things to write on, I also like how the Tab X C is most akin to A4-size paper. But at $820 for the bundle with the standard case (or a whopping $970 for the tablet and its keyboard case), it’s really only best for those who are ready to go all-in on a premium E Ink tablet. Lenovo Smart Paper Lenovo made a solid E Ink tablet in the Smart Paper, but it's too pricey and too married to the company's companion cloud service to warrant a spot on our top picks list. The hardware is great, but the software isn't as flexible as those of competitors like the reMarkable 2. It has good Google Drive integration, but you must pair it with Lenovo's cloud service to really get the most use out of it — and in the UK, the service costs £9 per month for three months, which is quite expensive. Onyx Boox Tab Ultra The Boox Tab Ultra has a lot of the same features we like in the Note Air 2 Plus, but it’s designed to be a true, all-purpose tablet with an E Ink screen. Running Android 11 and compatible with a magnetic keyboard case, you can use it like a standard 2-in-1 laptop, albeit a low-powered one. You can browse the web, check email and even watch YouTube videos on this thing — but that doesn’t mean you should. A standard 2-in-1 laptop with a more responsive screen and better overall performance would be a better fit for most people who even have the slightest desire to have an all-in-one device. Like the rest of Onyx’s devices, the Tab Ultra is specifically for those who put reading and eye comfort above all else.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-e-ink-tablet-130037939.html?src=rss",
          "content": "E Ink tablets have always been intriguing to me because I’m a longtime lover of pen and paper. I’ve had probably hundreds of notebooks over the years, serving as repositories for my story ideas, to-do lists, meeting notes and everything in between. However, I turned away from physical notebooks at a certain point because it was just easier to store everything digitally so I always had my most important information at my fingertips.E Ink tablets seem to provide the best of both worlds: the tactile satisfaction of regular notebooks with many of the conveniences found in digital tools, plus easy-on-the-eyes E Ink screens. These devices have come a long way in the past few years, and we’re just starting to see more color E Ink tablets become more widely available. I tested out a number of different E Ink tablets to see how well they work, how convenient they really are and which are the best tablets using E Ink screens available today.Editor's note: Amazon announced a revamped family of Kindle Scribe E Ink tablets in September 2025. The Kindle Scribe 3 is thinner and lighter than its predecessor with faster page-turning and writing experiences. The Kindle Scribe Colorsoft is the first full-color addition to the lineup, with a pen that will support writing in 10 colors and highlighting in five different shades. Both new Scribe tablets will be available in the US \"later this year.\" You can read our Kindle Scribe Colorsoft hands on to get a first look, but we'll update this guide once we've had the chance to test out both new E Ink tablets. Table of contents Best E Ink tablets for 2025 Are E Ink tablets worth it? What to look for in an E Ink tablet Other E Ink tablets we've tested Best E Ink tablets for 2025 Are E Ink tablets worth it? An E Ink tablet will be a worthwhile purchase to a very select group of people. If you prefer the look and feel of an e paper display to LCD panels found on traditional tablets, it makes a lot of sense. They’re also good options for those who want a more paper-like writing experience (although you can get that kind of functionality on a regular tablet with the right screen protector) or a more distraction-free device overall. The final note is key here. Many E Ink tablets don’t run on the same operating systems as regular tablets, so you’re automatically going to be limited in what you can do. And even with those that do allow you to download traditional apps like Chrome, Instagram and Facebook, E Ink tablets are not designed to give you the best casual-browsing experience. This is mostly due to the nature of E Ink displays, which have noticeable refreshes, a lack of vibrant colors and lower picture quality than the panels you’ll find on even the cheapest iPad. Arguably the biggest reason why you wouldn’t want to go with an iPad (all models of which support stylus input, a plethora of reading apps, etc) is because it’s much easier to get distracted by email, social media and other Internet-related temptations. What to look for in an E Ink tablet Writing and latency Arguably the most important thing to consider when looking for an E Ink tablet is the writing experience. How good it is will depend a lot on the display’s refresh rate (does it refresh after every time you put pen to “paper,” or at a different regular interval) and the stylus’ latency. Most of the tablets I’ve tested have little to no latency, but some are certainly better than others. Finally, you should double check before buying that your preferred E Ink tablet comes with a stylus, or if you need to purchase one separately. Reading How much will you be reading books, documents and other things on this tablet? E Ink tablets come in many sizes, but most of them tend to be larger than your standard e-reader because it makes writing much easier. Having a larger display isn’t a bad thing, but it might make holding it for long periods slightly more uncomfortable. (Most e-readers are roughly the size of a paperback book, giving you a similar feeling to analog reading). The supported file types for e-books can also make a big difference. It’s hard to make a blanket statement here because this varies so much among E Ink tablets. The TL;DR is that you’ll have a much better reading experience if you go with one made by a company that already has a history in e-book sales (i.e. Amazon or Kobo). All of the titles you bought via the Kindle or Kobo store should automatically be available to you on your Kindle or Kobo E Ink tablet. Also with Kindle titles, specifically, since they are protected by DRM, it’s not necessarily the best idea to try to bring those titles over to a third-party device. Unless the tablet runs an operating system like Android that supports downloads for apps like Kindle and Kobo, you’ll be limited to supported file types, like ePUB, PDF, MOBI, JPEG, PNG and others. Search functionality Most E Ink tablets have some on-device search features, but they can vary widely between models. You’ll want to consider how important it is to you to be able to search through all your handwritten notes and markups. I noticed in my testing that Amazon’s and Kobo’s E Ink tablets made it easy to refer back to notes made in books and files because they automatically save to the specific pages on which you took notes, made highlights and more. Searching is less standardized on E Ink tablets that have different supported file types, but their features can be quite powerful in their own right. For example, a few devices I tested supported text search in handwritten notes along with handwriting recognition, the latter of which allows you to translate your scribbles into typed text. Sharing and connectivity While we established that E Ink tablets can be great distraction-free devices, most manufacturers understand that your notes and doodles aren’t created in a vacuum. You may want to access them elsewhere, and that requires some form of connectivity. All of the E Ink tablets I tried have Wi-Fi support, and some support cloud syncing, companion mobile apps and the ability to export notes via email so you can access them elsewhere. None of them, however, integrate directly with a digital note taking system like Evernote or OneNote, so these devices will always be somewhat supplementary if you use apps like that, too. I’d argue that, if you already lean heavily on apps like OneNote, a standard tablet with a stylus and screen protector might be the best way to go. Ultimately, you should think about what you will want to do with the documents you’ll interact with on your E Ink tablet after the tablet portion is done. Price E Ink tablets aren’t known for being cheap. They generally fall into the $300-$800 price range, which is what you can expect to pay for a solid regular tablet, too. A key factor in price is size: cheaper devices with E Ink displays are likely to have smaller screens, and stylus support isn’t as much of a given. Also, those types of devices are generally considered e-readers because of their size and may not be the best for note-taking, doodling and the like. E Ink tablets have gone up in price recently. Supernote and Onyx Boox increased prices, as did reMarkable. The former said it was due to \"increased costs,” and a reMarkable representative confirmed this to Engadget and provided the following statement: \"We regularly review our pricing based on market conditions and operational costs. We've communicated an upcoming adjustment for the US market effective in May to provide transparency to our customers. Multiple factors influence our pricing decisions, including supply chain dynamics and overall operational costs in specific markets.” As a result, the reMarkable Paper Pro jumped from $579 to $629 (that's for the bundle with the standard Marker and no Folio). This isn't great, considering the Paper Pro was already on the expensive side of the spectrum for E Ink tablets. It's also worth noting that Supernote and Onyx Boox have raised prices in the past few months as well. Other E Ink tablets we've tested Onyx Boox Tab X C The Boox Tab X C is a color-screened version of the Tab X, the company’s all-purpose e-paper Android tablet. The Tab X C has a lovely 13.3-inch Kaleido 3 E Ink color display, an octa-core processor, 6GB of RAM and it runs on Android 13, making it one of the most powerful tablets in Boox’s lineup. I’ve used the Tab X in the past and this color version runs similarly, if not better, and at 5.3mm thick, it’s impressively svelte even when you pair it with its folio keyboard case. As someone who loves legal-pad sized things to write on, I also like how the Tab X C is most akin to A4-size paper. But at $820 for the bundle with the standard case (or a whopping $970 for the tablet and its keyboard case), it’s really only best for those who are ready to go all-in on a premium E Ink tablet. Lenovo Smart Paper Lenovo made a solid E Ink tablet in the Smart Paper, but it's too pricey and too married to the company's companion cloud service to warrant a spot on our top picks list. The hardware is great, but the software isn't as flexible as those of competitors like the reMarkable 2. It has good Google Drive integration, but you must pair it with Lenovo's cloud service to really get the most use out of it — and in the UK, the service costs £9 per month for three months, which is quite expensive. Onyx Boox Tab Ultra The Boox Tab Ultra has a lot of the same features we like in the Note Air 2 Plus, but it’s designed to be a true, all-purpose tablet with an E Ink screen. Running Android 11 and compatible with a magnetic keyboard case, you can use it like a standard 2-in-1 laptop, albeit a low-powered one. You can browse the web, check email and even watch YouTube videos on this thing — but that doesn’t mean you should. A standard 2-in-1 laptop with a more responsive screen and better overall performance would be a better fit for most people who even have the slightest desire to have an all-in-one device. Like the rest of Onyx’s devices, the Tab Ultra is specifically for those who put reading and eye comfort above all else.This article originally appeared on Engadget at https://www.engadget.com/mobile/tablets/best-e-ink-tablet-130037939.html?src=rss",
          "feed_position": 2
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/rodecaster-video-s-review-compact-and-comprehensive-video-production-230000221.html",
          "published_at": "Mon, 10 Nov 2025 23:41:42 +0000",
          "title": "Rodecaster Video S review: Compact and comprehensive video production",
          "standfirst": "The Rodecaster series of podcast mixers have become a mainstay among audio creatives. Last year, the company expanded the line with its first multimedia model — the Rodecaster Video. It was a more niche proposition, aimed at streamers, video podcasters and live producers, and, at $1,200, people with deeper pockets. Today, Rode returns with the Rodecaster Video S (RCV-S), a streamlined version that offers much of the same functionality for less than half the cost of the original ($499). If you currently use Ecamm Live, OBS, a Stream Deck, a Rodecaster Pro/Duo, a video capture card or Blackmagic Atem type switcher, then there’s a good chance the RCV-S does something, or many things, useful to you. Maybe it can replace all those products, some of them or enhance your workflow. It’s a little complicated, but within that complication is a lot of versatility. With three HDMI inputs, one USB webcam/mic input and up to four NDI/wireless camera inputs, video is clearly the focus here. But there are also two XLR/Combo ports for studio microphones and instruments and the option to connect up to two of Rode’s wireless lav mics (such as the Wireless Go) directly without the need for a receiver. The RCV-S, like Blackmagic’s popular Atem Mini, outputs over HDMI at 1080p/60 (no 4K) or can be used over USB as a virtual camera just like you’d find in Zoom or Teams. Unlike the Rodecaster Pro or Duo, there are no faders; instead, there are two rows of pads for switching between video sources and scenes. There’s 20GB of onboard storage for media — such as overlays, graphics and audio/video clips — and you can record shows directly onto USB hard-drives or stream natively to Twitch, YouTube and other platforms via RTMP/S. There’s a lot going on, and how you want to use it all is largely up to you. While the RCV-S leans more toward “live” productions such as streaming or podcasts, you can use it for conventional YouTube-style video production, depending on your workflow or video preferences. Rodecaster Video versus Rodecaster Video S The huge price difference between the original Rodecaster Video and the new S model might lead you to expect some serious feature trimming this time around, but Rode’s garden shears have been fairly kind. Most notably, the number of sources you can connect has been reduced from six to four. Meanwhile, the number of “scenes” you can create is now five, down from seven. As mentioned above, there are three HDMI inputs, not four, and only one USB webcam/mic input, down from two on the original. There are still nine channels of audio with two headphone outputs, but the line outputs on the original are no longer here. The SD card slot for media has also been removed in favor of internal storage. In short, there’s a little bit less connectivity, but not enough for it to feel hobbled, especially for the more casual users this is clearly aimed at. In-use At its most basic, the RCV-S is an all-in-one video switcher. You don’t need to connect it to a PC, just plug in your video and audio sources and you can jump between them in real time with a choice of transitions. For a more polished production you can create “scenes” via the menu with a selection of layouts for multiple cameras, picture-in-picture and so on. That could be two talking heads for a podcast, overlaying your web camera on top of your gameplay or a top-down camera mixed with a different perspective for cooking tutorials or presentations. You can create scenes directly on the device in advance or live via templates, but things get a lot easier and more creative when you use Rode’s companion Rodecaster app. Here, you’ll find a “scene creator” tool that’s both visual and intuitive, plus it has the option to make custom layouts where you can freely resize and place all your different media wherever you want, add borders or rounded corners and so on. While the main pads are primarily for switching between sources and scenes, they can also trigger media — pre-made video clips, overlays and graphics, for example. You can assign media to them without reducing the number of sources/scenes that are available to switch between, just tap the Media/Overlay button to temporarily change the functionality of the pads. You can also set up chromakey/green screening directly on the device or via the Rodecaster App, too. Once you have everything set up, you can directly record output onto a USB SSD, again, without the need for a PC. There’s even the option to record only the main output (“program”) or a multi-track version which will export a recording of every input as a separate file that you can edit as you see fit. This is helpful if you’re using apps like Adobe Premier or Davinci Resolve. If you shoot multi-camera dance tutorials, for example, you can jump between your main and wide camera and then to a close up without having to hunt-down the right part from each file you recorded on different memory cards. Rode recently updated the Rodecaster Video firmware to add support for up to four “NDI” wireless cameras as additional sources. Typically these are remote or security-style cameras, but Rode’s Capture mobile app also supports NDI streaming, meaning you can use your phone wirelessly as another camera that you can switch to, which is particularly useful. Though do note, the Rodecaster Video will need to be hard-wired to your router on the same network as your phone for this to work. Audio The Rodecaster Video S handles audio and video with ease. James Trew for Engadget While the RCV-S offers nine audio tracks, it’s fair to say it isn’t really designed for live audio mixing in the pure sense since there are no faders. Instead, you have to access different channels via the menu on a small display and a dial — It’s a lot of hunting and pecking. If you’re connected to a PC, the Rodecaster app does offer a software mixer with faders though, which makes adjusting levels on the fly much easier. The good news is that some voice enhancement tools, such as Depth, Sparkle and Punch have been carried over from the Rodecaster Pro/Duo, giving you a little more fine-grained control over how you or your guests sound. There’s a slight drawback when using the RCV-S as a standalone unit, in that you need to physically push the buttons to change the scene, which might not be ideal if you’re trying to make a polished recording or can’t always be near the console. Thankfully, Rode has a solution in “auto switching.” I’m mentioning it here, in the audio section, as the RCV-S can switch cameras based on which one has the strongest audio or based on user-defined priority. Typically, that would be whoever is talking in a podcast, but it could also be in-game sound or when you switch to playing a musical instrument. Auto switching works well, but it’s not quite dependable enough to rely on for full autonomy in a professional environment — say while recording a panel at a conference — but it solves a problem if you’re on your own, and it could at least save some time in a casual podcast situation. Things to consider The Rodecaster Video S (top) vs. The Rodecaster Video (bottom) James Trew for Engadget It’s clear that the RCV-S, despite having fewer inputs than the original Rodecaster Video, is still quite a complex, open-ended tool. If you already have a streaming setup you like and the software and interfaces you need, then the appeal of the RCV-S will be down to whether it can do what you need more efficiently. For live video production, it’s an easier sell, as there aren’t many all-in-one devices to compete with it that can be used standalone. For example, Blackmagic’s Atem series is incredibly popular, and until now, had the advantage on price with the Mini Pro costing just $330. Even the Mini Pro ISO ($550) that exports multi-track video was half the price of the original Rodecaster Video. The RCV-S now offers comparable connectivity, onboard recording, more expansive audio features and multi-track export for $50 less. For general content creators it’s a little trickier. As someone that makes YouTube videos, the appeal to me is the chance to consolidate a few devices into one and remove some friction in my recordings. Right now, I have a Rodecaster Duo handling my audio, a capture card for my main camera and I swap out that camera for a smaller one if I am shooting top-down footage or need a second angle. That means I have several different devices on my desk, and I’m constantly doing a dance of unplugging things and juggling media or different recordings before I get everything ready to edit. The Rodecaster Video S has a tiny display for menus and settings. James Trew for Engadget With the RCV-S I can ditch my standalone capture card and permanently leave multiple cameras connected to the Rodecaster so that they are ready to go at any time. I can even remove the Rodecaster Duo and bring it back out again on the occasions I need more immediate control over multiple sources of audio (which is sometimes, but not often). The appeal in my case is fewer devices on my desk, and the ability to record multi-camera video without having to set up every shot, every single time, which saves significant time that I can then use to actually get more work done. There are, of course, some limitations. Not least of all is the lack of 4K. I’m still inclined to record on camera for my primary shot to ensure I still have a 4K copy for YouTube and then use the Rodecaster Video S for everything else, but as a small creator, convenience and flexibility is very appealing. For streamers and live video production, the Rodecaster Video S is a very capable tool that offers a wide range of functionality for an accessible price that will no doubt become the central hub for many creators. The real kicker here is the price. Let’s be clear, $500 is still significant money. But at less than half the price of the original Rodecaster with decent connectivity and basically the same functionality, it's an easy recommendation to those who were holding off based on price alone. Likewise, if you’re just starting out with content creation and need something with solid video credentials and audio chops, Rode makes a good case for itself with the Rodecaster Video S.This article originally appeared on Engadget at https://www.engadget.com/general/rodecaster-video-s-review-compact-and-comprehensive-video-production-230000221.html?src=rss",
          "content": "The Rodecaster series of podcast mixers have become a mainstay among audio creatives. Last year, the company expanded the line with its first multimedia model — the Rodecaster Video. It was a more niche proposition, aimed at streamers, video podcasters and live producers, and, at $1,200, people with deeper pockets. Today, Rode returns with the Rodecaster Video S (RCV-S), a streamlined version that offers much of the same functionality for less than half the cost of the original ($499). If you currently use Ecamm Live, OBS, a Stream Deck, a Rodecaster Pro/Duo, a video capture card or Blackmagic Atem type switcher, then there’s a good chance the RCV-S does something, or many things, useful to you. Maybe it can replace all those products, some of them or enhance your workflow. It’s a little complicated, but within that complication is a lot of versatility. With three HDMI inputs, one USB webcam/mic input and up to four NDI/wireless camera inputs, video is clearly the focus here. But there are also two XLR/Combo ports for studio microphones and instruments and the option to connect up to two of Rode’s wireless lav mics (such as the Wireless Go) directly without the need for a receiver. The RCV-S, like Blackmagic’s popular Atem Mini, outputs over HDMI at 1080p/60 (no 4K) or can be used over USB as a virtual camera just like you’d find in Zoom or Teams. Unlike the Rodecaster Pro or Duo, there are no faders; instead, there are two rows of pads for switching between video sources and scenes. There’s 20GB of onboard storage for media — such as overlays, graphics and audio/video clips — and you can record shows directly onto USB hard-drives or stream natively to Twitch, YouTube and other platforms via RTMP/S. There’s a lot going on, and how you want to use it all is largely up to you. While the RCV-S leans more toward “live” productions such as streaming or podcasts, you can use it for conventional YouTube-style video production, depending on your workflow or video preferences. Rodecaster Video versus Rodecaster Video S The huge price difference between the original Rodecaster Video and the new S model might lead you to expect some serious feature trimming this time around, but Rode’s garden shears have been fairly kind. Most notably, the number of sources you can connect has been reduced from six to four. Meanwhile, the number of “scenes” you can create is now five, down from seven. As mentioned above, there are three HDMI inputs, not four, and only one USB webcam/mic input, down from two on the original. There are still nine channels of audio with two headphone outputs, but the line outputs on the original are no longer here. The SD card slot for media has also been removed in favor of internal storage. In short, there’s a little bit less connectivity, but not enough for it to feel hobbled, especially for the more casual users this is clearly aimed at. In-use At its most basic, the RCV-S is an all-in-one video switcher. You don’t need to connect it to a PC, just plug in your video and audio sources and you can jump between them in real time with a choice of transitions. For a more polished production you can create “scenes” via the menu with a selection of layouts for multiple cameras, picture-in-picture and so on. That could be two talking heads for a podcast, overlaying your web camera on top of your gameplay or a top-down camera mixed with a different perspective for cooking tutorials or presentations. You can create scenes directly on the device in advance or live via templates, but things get a lot easier and more creative when you use Rode’s companion Rodecaster app. Here, you’ll find a “scene creator” tool that’s both visual and intuitive, plus it has the option to make custom layouts where you can freely resize and place all your different media wherever you want, add borders or rounded corners and so on. While the main pads are primarily for switching between sources and scenes, they can also trigger media — pre-made video clips, overlays and graphics, for example. You can assign media to them without reducing the number of sources/scenes that are available to switch between, just tap the Media/Overlay button to temporarily change the functionality of the pads. You can also set up chromakey/green screening directly on the device or via the Rodecaster App, too. Once you have everything set up, you can directly record output onto a USB SSD, again, without the need for a PC. There’s even the option to record only the main output (“program”) or a multi-track version which will export a recording of every input as a separate file that you can edit as you see fit. This is helpful if you’re using apps like Adobe Premier or Davinci Resolve. If you shoot multi-camera dance tutorials, for example, you can jump between your main and wide camera and then to a close up without having to hunt-down the right part from each file you recorded on different memory cards. Rode recently updated the Rodecaster Video firmware to add support for up to four “NDI” wireless cameras as additional sources. Typically these are remote or security-style cameras, but Rode’s Capture mobile app also supports NDI streaming, meaning you can use your phone wirelessly as another camera that you can switch to, which is particularly useful. Though do note, the Rodecaster Video will need to be hard-wired to your router on the same network as your phone for this to work. Audio The Rodecaster Video S handles audio and video with ease. James Trew for Engadget While the RCV-S offers nine audio tracks, it’s fair to say it isn’t really designed for live audio mixing in the pure sense since there are no faders. Instead, you have to access different channels via the menu on a small display and a dial — It’s a lot of hunting and pecking. If you’re connected to a PC, the Rodecaster app does offer a software mixer with faders though, which makes adjusting levels on the fly much easier. The good news is that some voice enhancement tools, such as Depth, Sparkle and Punch have been carried over from the Rodecaster Pro/Duo, giving you a little more fine-grained control over how you or your guests sound. There’s a slight drawback when using the RCV-S as a standalone unit, in that you need to physically push the buttons to change the scene, which might not be ideal if you’re trying to make a polished recording or can’t always be near the console. Thankfully, Rode has a solution in “auto switching.” I’m mentioning it here, in the audio section, as the RCV-S can switch cameras based on which one has the strongest audio or based on user-defined priority. Typically, that would be whoever is talking in a podcast, but it could also be in-game sound or when you switch to playing a musical instrument. Auto switching works well, but it’s not quite dependable enough to rely on for full autonomy in a professional environment — say while recording a panel at a conference — but it solves a problem if you’re on your own, and it could at least save some time in a casual podcast situation. Things to consider The Rodecaster Video S (top) vs. The Rodecaster Video (bottom) James Trew for Engadget It’s clear that the RCV-S, despite having fewer inputs than the original Rodecaster Video, is still quite a complex, open-ended tool. If you already have a streaming setup you like and the software and interfaces you need, then the appeal of the RCV-S will be down to whether it can do what you need more efficiently. For live video production, it’s an easier sell, as there aren’t many all-in-one devices to compete with it that can be used standalone. For example, Blackmagic’s Atem series is incredibly popular, and until now, had the advantage on price with the Mini Pro costing just $330. Even the Mini Pro ISO ($550) that exports multi-track video was half the price of the original Rodecaster Video. The RCV-S now offers comparable connectivity, onboard recording, more expansive audio features and multi-track export for $50 less. For general content creators it’s a little trickier. As someone that makes YouTube videos, the appeal to me is the chance to consolidate a few devices into one and remove some friction in my recordings. Right now, I have a Rodecaster Duo handling my audio, a capture card for my main camera and I swap out that camera for a smaller one if I am shooting top-down footage or need a second angle. That means I have several different devices on my desk, and I’m constantly doing a dance of unplugging things and juggling media or different recordings before I get everything ready to edit. The Rodecaster Video S has a tiny display for menus and settings. James Trew for Engadget With the RCV-S I can ditch my standalone capture card and permanently leave multiple cameras connected to the Rodecaster so that they are ready to go at any time. I can even remove the Rodecaster Duo and bring it back out again on the occasions I need more immediate control over multiple sources of audio (which is sometimes, but not often). The appeal in my case is fewer devices on my desk, and the ability to record multi-camera video without having to set up every shot, every single time, which saves significant time that I can then use to actually get more work done. There are, of course, some limitations. Not least of all is the lack of 4K. I’m still inclined to record on camera for my primary shot to ensure I still have a 4K copy for YouTube and then use the Rodecaster Video S for everything else, but as a small creator, convenience and flexibility is very appealing. For streamers and live video production, the Rodecaster Video S is a very capable tool that offers a wide range of functionality for an accessible price that will no doubt become the central hub for many creators. The real kicker here is the price. Let’s be clear, $500 is still significant money. But at less than half the price of the original Rodecaster with decent connectivity and basically the same functionality, it's an easy recommendation to those who were holding off based on price alone. Likewise, if you’re just starting out with content creation and need something with solid video credentials and audio chops, Rode makes a good case for itself with the Rodecaster Video S.This article originally appeared on Engadget at https://www.engadget.com/general/rodecaster-video-s-review-compact-and-comprehensive-video-production-230000221.html?src=rss",
          "feed_position": 4,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/DSCF1856.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/meta-returns-to-open-source-ai-with-omnilingual-asr-models-that-can",
          "published_at": "Mon, 10 Nov 2025 20:27:00 GMT",
          "title": "Meta returns to open source AI with Omnilingual ASR models that can transcribe 1,600+ languages natively",
          "standfirst": "Meta has just released a new multilingual automatic speech recognition (ASR) system supporting 1,600+ languages — dwarfing OpenAI’s open source Whisper model, which supports just 99. Is architecture also allows developers to extend that support to thousands more. Through a feature called zero-shot in-context learning, users can provide a few paired examples of audio and text in a new language at inference time, enabling the model to transcribe additional utterances in that language without any retraining.In practice, this expands potential coverage to more than 5,400 languages — roughly every spoken language with a known script.It’s a shift from static model capabilities to a flexible framework that communities can adapt themselves. So while the 1,600 languages reflect official training coverage, the broader figure represents Omnilingual ASR’s capacity to generalize on demand, making it the most extensible speech recognition system released to date.Best of all: it&#x27;s been open sourced under a plain Apache 2.0 license — not a restrictive, quasi open-source Llama license like the company&#x27;s prior releases, which limited use by larger enterprises unless they paid licensing fees — meaning researchers and developers are free to take and implement it right away, for free, without restrictions, even in commercial and enterprise-grade projects!Released on November 10 on Meta&#x27;s website, Github, along with a demo space on Hugging Face and technical paper, Meta’s Omnilingual ASR suite includes a family of speech recognition models, a 7-billion parameter multilingual audio representation model, and a massive speech corpus spanning over 350 previously underserved languages. All resources are freely available under open licenses, and the models support speech-to-text transcription out of the box.“By open sourcing these models and dataset, we aim to break down language barriers, expand digital access, and empower communities worldwide,” Meta posted on its @AIatMeta account on XDesigned for Speech-to-Text TranscriptionAt its core, Omnilingual ASR is a speech-to-text system. The models are trained to convert spoken language into written text, supporting applications like voice assistants, transcription tools, subtitles, oral archive digitization, and accessibility features for low-resource languages.Unlike earlier ASR models that required extensive labeled training data, Omnilingual ASR includes a zero-shot variant. This version can transcribe languages it has never seen before—using just a few paired examples of audio and corresponding text. This lowers the barrier for adding new or endangered languages dramatically, removing the need for large corpora or retraining.Model Family and Technical DesignThe Omnilingual ASR suite includes multiple model families trained on more than 4.3 million hours of audio from 1,600+ languages:wav2vec 2.0 models for self-supervised speech representation learning (300M–7B parameters)CTC-based ASR models for efficient supervised transcriptionLLM-ASR models combining a speech encoder with a Transformer-based text decoder for state-of-the-art transcriptionLLM-ZeroShot ASR model, enabling inference-time adaptation to unseen languagesAll models follow an encoder–decoder design: raw audio is converted into a language-agnostic representation, then decoded into written text.Why the Scale MattersWhile Whisper and similar models have advanced ASR capabilities for global languages, they fall short on the long tail of human linguistic diversity. Whisper supports 99 languages. Meta’s system:Directly supports 1,600+ languagesCan generalize to 5,400+ languages using in-context learningAchieves character error rates (CER) under 10% in 78% of supported languagesAmong those supported are more than 500 languages never previously covered by any ASR model, according to Meta’s research paper.This expansion opens new possibilities for communities whose languages are often excluded from digital toolsHere’s the revised and expanded background section, integrating the broader context of Meta’s 2025 AI strategy, leadership changes, and Llama 4’s reception, complete with in-text citations and links:Background: Meta’s AI Overhaul and a Rebound from Llama 4The release of Omnilingual ASR arrives at a pivotal moment in Meta’s AI strategy, following a year marked by organizational turbulence, leadership changes, and uneven product execution. Omnilingual ASR is the first major open-source model release since the rollout of Llama 4, Meta’s latest large language model, which debuted in April 2025 to mixed and ultimately poor reviews, with scant enterprise adoption compared to Chinese open source model competitors.The failure led Meta founder and CEO Mark Zuckerberg to appoint Alexandr Wang, co-founder and prior CEO of AI data supplier Scale AI, as Chief AI Officer, and embark on an extensive and costly hiring spree that shocked the AI and business communities with eye-watering pay packages for top AI researchers.In contrast, Omnilingual ASR represents a strategic and reputational reset. It returns Meta to a domain where the company has historically led — multilingual AI — and offers a truly extensible, community-oriented stack with minimal barriers to entry. The system’s support for 1,600+ languages and its extensibility to over 5,000 more via zero-shot in-context learning reassert Meta’s engineering credibility in language technology. Importantly, it does so through a free and permissively licensed release, under Apache 2.0, with transparent dataset sourcing and reproducible training protocols.This shift aligns with broader themes in Meta’s 2025 strategy. The company has refocused its narrative around a “personal superintelligence” vision, investing heavily in infrastructure (including a September release of custom AI accelerators and Arm-based inference stacks) source while downplaying the metaverse in favor of foundational AI capabilities. The return to public training data in Europe after a regulatory pause also underscores its intention to compete globally, despite privacy scrutiny source.Omnilingual ASR, then, is more than a model release — it’s a calculated move to reassert control of the narrative: from the fragmented rollout of Llama 4 to a high-utility, research-grounded contribution that aligns with Meta’s long-term AI platform strategy.Community-Centered Dataset CollectionTo achieve this scale, Meta partnered with researchers and community organizations in Africa, Asia, and elsewhere to create the Omnilingual ASR Corpus, a 3,350-hour dataset across 348 low-resource languages. Contributors were compensated local speakers, and recordings were gathered in collaboration with groups like:African Next Voices: A Gates Foundation–supported consortium including Maseno University (Kenya), University of Pretoria, and Data Science NigeriaMozilla Foundation’s Common Voice, supported through the Open Multilingual Speech FundLanfrica / NaijaVoices, which created data for 11 African languages including Igala, Serer, and UrhoboThe data collection focused on natural, unscripted speech. Prompts were designed to be culturally relevant and open-ended, such as “Is it better to have a few close friends or many casual acquaintances? Why?” Transcriptions used established writing systems, with quality assurance built into every step.Performance and Hardware ConsiderationsThe largest model in the suite, the omniASR_LLM_7B, requires ~17GB of GPU memory for inference, making it suitable for deployment on high-end hardware. Smaller models (300M–1B) can run on lower-power devices and deliver real-time transcription speeds.Performance benchmarks show strong results even in low-resource scenarios:CER <10% in 95% of high-resource and mid-resource languagesCER <10% in 36% of low-resource languagesRobustness in noisy conditions and unseen domains, especially with fine-tuningThe zero-shot system, omniASR_LLM_7B_ZS, can transcribe new languages with minimal setup. Users provide a few sample audio–text pairs, and the model generates transcriptions for new utterances in the same language.Open Access and Developer ToolingAll models and the dataset are licensed under permissive terms:Apache 2.0 for models and codeCC-BY 4.0 for the Omnilingual ASR Corpus on HuggingFaceInstallation is supported via PyPI and uv:pip install omnilingual-asrMeta also provides:A HuggingFace dataset integrationPre-built inference pipelinesLanguage-code conditioning for improved accuracyDevelopers can view the full list of supported languages using the API:from omnilingual_asr.models.wav2vec2_llama.lang_ids import supported_langsprint(len(supported_langs)) print(supported_langs)Broader ImplicationsOmnilingual ASR reframes language coverage in ASR from a fixed list to an extensible framework. It enables:Community-driven inclusion of underrepresented languagesDigital access for oral and endangered languagesResearch on speech tech in linguistically diverse contextsCrucially, Meta emphasizes ethical considerations throughout—advocating for open-source participation and collaboration with native-speaking communities.“No model can ever anticipate and include all of the world’s languages in advance,” the Omnilingual ASR paper states, “but Omnilingual ASR makes it possible for communities to extend recognition with their own data.”Access the ToolsAll resources are now available at:Code + Models: github.com/facebookresearch/omnilingual-asrDataset: huggingface.co/datasets/facebook/omnilingual-asr-corpusBlogpost: ai.meta.com/blog/omnilingual-asrWhat This Means for EnterprisesFor enterprise developers, especially those operating in multilingual or international markets, Omnilingual ASR significantly lowers the barrier to deploying speech-to-text systems across a broader range of customers and geographies. Instead of relying on commercial ASR APIs that support only a narrow set of high-resource languages, teams can now integrate an open-source pipeline that covers over 1,600 languages out of the box—with the option to extend it to thousands more via zero-shot learning.This flexibility is especially valuable for enterprises working in sectors like voice-based customer support, transcription services, accessibility, education, or civic technology, where local language coverage can be a competitive or regulatory necessity. Because the models are released under the permissive Apache 2.0 license, businesses can fine-tune, deploy, or integrate them into proprietary systems without restrictive terms.It also represents a shift in the ASR landscape—from centralized, cloud-gated offerings to community-extendable infrastructure. By making multilingual speech recognition more accessible, customizable, and cost-effective, Omnilingual ASR opens the door to a new generation of enterprise speech applications built around linguistic inclusion rather than linguistic limitation.",
          "content": "Meta has just released a new multilingual automatic speech recognition (ASR) system supporting 1,600+ languages — dwarfing OpenAI’s open source Whisper model, which supports just 99. Is architecture also allows developers to extend that support to thousands more. Through a feature called zero-shot in-context learning, users can provide a few paired examples of audio and text in a new language at inference time, enabling the model to transcribe additional utterances in that language without any retraining.In practice, this expands potential coverage to more than 5,400 languages — roughly every spoken language with a known script.It’s a shift from static model capabilities to a flexible framework that communities can adapt themselves. So while the 1,600 languages reflect official training coverage, the broader figure represents Omnilingual ASR’s capacity to generalize on demand, making it the most extensible speech recognition system released to date.Best of all: it&#x27;s been open sourced under a plain Apache 2.0 license — not a restrictive, quasi open-source Llama license like the company&#x27;s prior releases, which limited use by larger enterprises unless they paid licensing fees — meaning researchers and developers are free to take and implement it right away, for free, without restrictions, even in commercial and enterprise-grade projects!Released on November 10 on Meta&#x27;s website, Github, along with a demo space on Hugging Face and technical paper, Meta’s Omnilingual ASR suite includes a family of speech recognition models, a 7-billion parameter multilingual audio representation model, and a massive speech corpus spanning over 350 previously underserved languages. All resources are freely available under open licenses, and the models support speech-to-text transcription out of the box.“By open sourcing these models and dataset, we aim to break down language barriers, expand digital access, and empower communities worldwide,” Meta posted on its @AIatMeta account on XDesigned for Speech-to-Text TranscriptionAt its core, Omnilingual ASR is a speech-to-text system. The models are trained to convert spoken language into written text, supporting applications like voice assistants, transcription tools, subtitles, oral archive digitization, and accessibility features for low-resource languages.Unlike earlier ASR models that required extensive labeled training data, Omnilingual ASR includes a zero-shot variant. This version can transcribe languages it has never seen before—using just a few paired examples of audio and corresponding text. This lowers the barrier for adding new or endangered languages dramatically, removing the need for large corpora or retraining.Model Family and Technical DesignThe Omnilingual ASR suite includes multiple model families trained on more than 4.3 million hours of audio from 1,600+ languages:wav2vec 2.0 models for self-supervised speech representation learning (300M–7B parameters)CTC-based ASR models for efficient supervised transcriptionLLM-ASR models combining a speech encoder with a Transformer-based text decoder for state-of-the-art transcriptionLLM-ZeroShot ASR model, enabling inference-time adaptation to unseen languagesAll models follow an encoder–decoder design: raw audio is converted into a language-agnostic representation, then decoded into written text.Why the Scale MattersWhile Whisper and similar models have advanced ASR capabilities for global languages, they fall short on the long tail of human linguistic diversity. Whisper supports 99 languages. Meta’s system:Directly supports 1,600+ languagesCan generalize to 5,400+ languages using in-context learningAchieves character error rates (CER) under 10% in 78% of supported languagesAmong those supported are more than 500 languages never previously covered by any ASR model, according to Meta’s research paper.This expansion opens new possibilities for communities whose languages are often excluded from digital toolsHere’s the revised and expanded background section, integrating the broader context of Meta’s 2025 AI strategy, leadership changes, and Llama 4’s reception, complete with in-text citations and links:Background: Meta’s AI Overhaul and a Rebound from Llama 4The release of Omnilingual ASR arrives at a pivotal moment in Meta’s AI strategy, following a year marked by organizational turbulence, leadership changes, and uneven product execution. Omnilingual ASR is the first major open-source model release since the rollout of Llama 4, Meta’s latest large language model, which debuted in April 2025 to mixed and ultimately poor reviews, with scant enterprise adoption compared to Chinese open source model competitors.The failure led Meta founder and CEO Mark Zuckerberg to appoint Alexandr Wang, co-founder and prior CEO of AI data supplier Scale AI, as Chief AI Officer, and embark on an extensive and costly hiring spree that shocked the AI and business communities with eye-watering pay packages for top AI researchers.In contrast, Omnilingual ASR represents a strategic and reputational reset. It returns Meta to a domain where the company has historically led — multilingual AI — and offers a truly extensible, community-oriented stack with minimal barriers to entry. The system’s support for 1,600+ languages and its extensibility to over 5,000 more via zero-shot in-context learning reassert Meta’s engineering credibility in language technology. Importantly, it does so through a free and permissively licensed release, under Apache 2.0, with transparent dataset sourcing and reproducible training protocols.This shift aligns with broader themes in Meta’s 2025 strategy. The company has refocused its narrative around a “personal superintelligence” vision, investing heavily in infrastructure (including a September release of custom AI accelerators and Arm-based inference stacks) source while downplaying the metaverse in favor of foundational AI capabilities. The return to public training data in Europe after a regulatory pause also underscores its intention to compete globally, despite privacy scrutiny source.Omnilingual ASR, then, is more than a model release — it’s a calculated move to reassert control of the narrative: from the fragmented rollout of Llama 4 to a high-utility, research-grounded contribution that aligns with Meta’s long-term AI platform strategy.Community-Centered Dataset CollectionTo achieve this scale, Meta partnered with researchers and community organizations in Africa, Asia, and elsewhere to create the Omnilingual ASR Corpus, a 3,350-hour dataset across 348 low-resource languages. Contributors were compensated local speakers, and recordings were gathered in collaboration with groups like:African Next Voices: A Gates Foundation–supported consortium including Maseno University (Kenya), University of Pretoria, and Data Science NigeriaMozilla Foundation’s Common Voice, supported through the Open Multilingual Speech FundLanfrica / NaijaVoices, which created data for 11 African languages including Igala, Serer, and UrhoboThe data collection focused on natural, unscripted speech. Prompts were designed to be culturally relevant and open-ended, such as “Is it better to have a few close friends or many casual acquaintances? Why?” Transcriptions used established writing systems, with quality assurance built into every step.Performance and Hardware ConsiderationsThe largest model in the suite, the omniASR_LLM_7B, requires ~17GB of GPU memory for inference, making it suitable for deployment on high-end hardware. Smaller models (300M–1B) can run on lower-power devices and deliver real-time transcription speeds.Performance benchmarks show strong results even in low-resource scenarios:CER <10% in 95% of high-resource and mid-resource languagesCER <10% in 36% of low-resource languagesRobustness in noisy conditions and unseen domains, especially with fine-tuningThe zero-shot system, omniASR_LLM_7B_ZS, can transcribe new languages with minimal setup. Users provide a few sample audio–text pairs, and the model generates transcriptions for new utterances in the same language.Open Access and Developer ToolingAll models and the dataset are licensed under permissive terms:Apache 2.0 for models and codeCC-BY 4.0 for the Omnilingual ASR Corpus on HuggingFaceInstallation is supported via PyPI and uv:pip install omnilingual-asrMeta also provides:A HuggingFace dataset integrationPre-built inference pipelinesLanguage-code conditioning for improved accuracyDevelopers can view the full list of supported languages using the API:from omnilingual_asr.models.wav2vec2_llama.lang_ids import supported_langsprint(len(supported_langs)) print(supported_langs)Broader ImplicationsOmnilingual ASR reframes language coverage in ASR from a fixed list to an extensible framework. It enables:Community-driven inclusion of underrepresented languagesDigital access for oral and endangered languagesResearch on speech tech in linguistically diverse contextsCrucially, Meta emphasizes ethical considerations throughout—advocating for open-source participation and collaboration with native-speaking communities.“No model can ever anticipate and include all of the world’s languages in advance,” the Omnilingual ASR paper states, “but Omnilingual ASR makes it possible for communities to extend recognition with their own data.”Access the ToolsAll resources are now available at:Code + Models: github.com/facebookresearch/omnilingual-asrDataset: huggingface.co/datasets/facebook/omnilingual-asr-corpusBlogpost: ai.meta.com/blog/omnilingual-asrWhat This Means for EnterprisesFor enterprise developers, especially those operating in multilingual or international markets, Omnilingual ASR significantly lowers the barrier to deploying speech-to-text systems across a broader range of customers and geographies. Instead of relying on commercial ASR APIs that support only a narrow set of high-resource languages, teams can now integrate an open-source pipeline that covers over 1,600 languages out of the box—with the option to extend it to thousands more via zero-shot learning.This flexibility is especially valuable for enterprises working in sectors like voice-based customer support, transcription services, accessibility, education, or civic technology, where local language coverage can be a competitive or regulatory necessity. Because the models are released under the permissive Apache 2.0 license, businesses can fine-tune, deploy, or integrate them into proprietary systems without restrictive terms.It also represents a shift in the ASR landscape—from centralized, cloud-gated offerings to community-extendable infrastructure. By making multilingual speech recognition more accessible, customizable, and cost-effective, Omnilingual ASR opens the door to a new generation of enterprise speech applications built around linguistic inclusion rather than linguistic limitation.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5WF8w75sB7wnAYEK5pYnPD/16059c6ac3f6b853b3b301bc66f950d3/cfr0z3n_graphic_novel_abstract_expressionist_outline_style_show_390da294-e50e-424d-ab36-20b02133d3d9.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/chronosphere-takes-on-datadog-with-ai-that-explains-itself-not-just-outages",
          "published_at": "Mon, 10 Nov 2025 19:00:00 GMT",
          "title": "Chronosphere takes on Datadog with AI that explains itself, not just outages",
          "standfirst": "Chronosphere, a New York-based observability startup valued at $1.6 billion, announced Monday it will launch AI-Guided Troubleshooting capabilities designed to help engineers diagnose and fix production software failures — a problem that has intensified as artificial intelligence tools accelerate code creation while making systems harder to debug.The new features combine AI-driven analysis with what Chronosphere calls a Temporal Knowledge Graph, a continuously updated map of an organization&#x27;s services, infrastructure dependencies, and system changes over time. The technology aims to address a mounting challenge in enterprise software: developers are writing code faster than ever with AI assistance, but troubleshooting remains largely manual, creating bottlenecks when applications fail.\"For AI to be effective in observability, it needs more than pattern recognition and summarization,\" said Martin Mao, Chronosphere&#x27;s CEO and co-founder, in an exclusive interview with VentureBeat. \"Chronosphere has spent years building the data foundation and analytical depth needed for AI to actually help engineers. With our Temporal Knowledge Graph and advanced analytics capabilities, we&#x27;re giving AI the understanding it needs to make observability truly intelligent — and giving engineers the confidence to trust its guidance.\"The announcement comes as the observability market — software that monitors complex cloud applications— faces mounting pressure to justify escalating costs. Enterprise log data volumes have grown 250% year-over-year, according to Chronosphere&#x27;s own research, while a study from MIT and the University of Pennsylvania found that generative AI has spurred a 13.5% increase in weekly code commits, signifying faster development velocity but also greater system complexity.AI writes code 13% faster, but debugging stays stubbornly manualDespite advances in automated code generation, debugging production failures remains stubbornly manual. When a major e-commerce site slows during checkout or a banking app fails to process transactions, engineers must sift through millions of data points — server logs, application traces, infrastructure metrics, recent code deployments — to identify root causes.Chronosphere&#x27;s answer is what it calls AI-Guided Troubleshooting, built on four core capabilities: automated \"Suggestions\" that propose investigation paths backed by data; the Temporal Knowledge Graph that maps system relationships and changes; Investigation Notebooks that document each troubleshooting step for future reference; and natural language query building.Mao explained the Temporal Knowledge Graph in practical terms: \"It&#x27;s a living, time-aware model of your system. It stitches together telemetry—metrics, traces, logs—infrastructure context, change events like deploys and feature flags, and even human input like notes and runbooks into a single, queryable map that updates as your system evolves.\"This differs fundamentally from the service dependency maps offered by competitors like Datadog, Dynatrace, and Splunk, Mao argued. \"It adds time, not just topology,\" he said. \"It tracks how services and dependencies change over time and connects those changes to incidents—what changed and why. Many tools rely on standardized integrations; our graph goes a step further to normalize custom, non-standard telemetry so application-specific signals aren&#x27;t a blind spot.\"Why Chronosphere shows its work instead of making automatic decisionsUnlike purely automated systems, Chronosphere designed its AI features to keep engineers in the driver&#x27;s seat—a deliberate choice meant to address what Mao calls the \"confident-but-wrong guidance\" problem plaguing early AI observability tools.\"&#x27;Keeping engineers in control&#x27; means the AI shows its work, proposes next steps, and lets engineers verify or override — never auto-deciding behind the scenes,\" Mao explained. \"Every Suggestion includes the evidence—timing, dependencies, error patterns — and a &#x27;Why was this suggested?&#x27; view, so they can inspect what was checked and ruled out before acting.\"He walked through a concrete example: \"An SLO [service level objective] alert fires on Checkout. Chronosphere immediately surfaces a ranked Suggestion: errors appear to have started in the dependent Payment service. An engineer can click Investigate to see the charts and reasoning and, if it holds up, choose to dig deeper. As they steer into Payment, the system adapts with new Suggestions scoped to that service—all from one view, no tab-hopping.\"In this scenario, the engineer asks \"what changed?\" and the system pulls in change events. \"Our Notebook capability makes the causal chain plain: a feature-flag update preceded pod memory exhaustion in Payment; Checkout&#x27;s spike is a downstream symptom,\" Mao said. \"They can decide to roll back the flag. That whole path — suggestions followed, evidence viewed, conclusions—is captured automatically in an Investigation Notebook, and the outcome feeds the Temporal Knowledge Graph so similar future incidents are faster to resolve.\"How a $1.6 billion startup takes on Datadog, Dynatrace, and SplunkChronosphere enters an increasingly crowded field. Datadog, the publicly traded observability leader valued at over $40 billion, has introduced its own AI-powered troubleshooting features. So have Dynatrace and Splunk. All three offer comprehensive \"all-in-one\" platforms that promise single-pane-of-glass visibility.Mao distinguished Chronosphere&#x27;s approach on technical grounds. \"Early &#x27;AI for observability&#x27; leaned heavily on pattern-spotting and summarization, which tends to break down during real incidents,\" he said. \"These approaches often stop at correlating anomalies or producing fluent explanations without the deeper analysis and causal reasoning observability leaders need. They can feel impressive in demos but disappoint in production—they summarize signals rather than explain cause and effect.\"A specific technical gap, he argued, involves custom application telemetry. \"Most platforms reason over standardized integrations—Kubernetes, common cloud services, popular databases—ignoring the most telling clues that live in custom app telemetry,\" Mao said. \"With an incomplete picture, large language models will &#x27;fill in the gaps,&#x27; producing confident-but-wrong guidance that sends teams down dead ends.\"Chronosphere&#x27;s competitive positioning received validation in July when Gartner named it a Leader in the 2025 Magic Quadrant for Observability Platforms for the second consecutive year. The firm was recognized based on both \"Completeness of Vision\" and \"Ability to Execute.\" In December 2024, Chronosphere also tied for the highest overall rating among recognized vendors in Gartner Peer Insights&#x27; \"Voice of the Customer\" report, scoring 4.7 out of 5 based on 70 reviews.Yet the company faces intensifying competition for high-profile customers. UBS analysts noted in July that OpenAI now runs both Datadog and Chronosphere side-by-side to monitor GPU workloads, suggesting the AI leader is evaluating alternatives. While UBS maintained its buy rating on Datadog, the analysts warned that growing Chronosphere usage could pressure Datadog&#x27;s pricing power.Inside the 84% cost reduction claims—and what CIOs should actually measureBeyond technical capabilities, Chronosphere has built its market position on cost control — a critical factor as observability spending spirals. The company claims its platform reduces data volumes and associated costs by 84% on average while cutting critical incidents by up to 75%.When pressed for specific customer examples with real numbers, Mao pointed to several case studies. \"Robinhood has seen a 5x improvement in reliability and a 4x improvement in Mean Time to Detection,\" he said. \"DoorDash used Chronosphere to improve governance and standardize monitoring practices. Astronomer achieved over 85% cost reduction by shaping data on ingest, and Affirm scaled their load 10x during a Black Friday event with no issues, highlighting the platform&#x27;s reliability under extreme conditions.\"The cost argument matters because, as Paul Nashawaty, principal analyst at CUBE Research, noted when Chronosphere launched its Logs 2.0 product in June: \"Organizations are drowning in telemetry data, with over 70% of observability spend going toward storing logs that are never queried.\"For CIOs fatigued by \"AI-powered\" announcements, Mao acknowledged skepticism is warranted. \"The way to cut through it is to test whether the AI shortens incidents, reduces toil, and builds reusable knowledge in your own environment, not in a demo,\" he advised. He recommended CIOs evaluate three factors: transparency and control (does the system show its reasoning?), coverage of custom telemetry (can it handle non-standardized data?), and manual toil avoided (how many ad-hoc queries and tool-switches are eliminated?).Why Chronosphere partners with five vendors instead of building everything itselfAlongside the AI troubleshooting announcement, Chronosphere revealed a new Partner Program integrating five specialized vendors to fill gaps in its platform: Arize for large language model monitoring, Embrace for real user monitoring, Polar Signals for continuous profiling, Checkly for synthetic monitoring, and Rootly for incident management.The strategy represents a deliberate bet against the all-in-one platforms dominating the market. \"While an all-in-one platform may be sufficient for smaller organizations, global enterprises demand best-in-class depth across each domain,\" Mao said. \"This is what drove us to build our Partner Program and invest in seamless integrations with leading providers—so our customers can operate with confidence and clarity at every layer of observability.\"Noah Smolen, head of partnerships at Arize, said the collaboration addresses a specific enterprise need. \"With a wide array of Fortune 500 customers, we understand the high bar needed to ensure AI agent systems are ready to deploy and stay incident-free, especially given the pace of AI adoption in the enterprise,\" Smolen said. \"Our partnership with Chronosphere comes at a time when an integrated purpose-built cloud-native and AI-observability suite solves a huge pain point for forward-thinking C-suite leaders who demand the very best across their entire observability stack.\"Similarly, JJ Tang, CEO and founder of Rootly, emphasized the incident resolution benefits. \"Incidents hinder innovation and revenue, and the challenge lies in sifting through vast amounts of observability data, mobilizing teams, and resolving issues quickly,\" Tang said. \"Integrating Chronosphere with Rootly allows engineers to collaborate with context and resolve issues faster within their existing communication channels, drastically reducing time to resolution and ultimately improving reliability—78% plus decreases in repeat Sev0 and Sev1 incidents.\"When asked how total costs compare when customers use multiple partner contracts versus a single platform, Mao acknowledged the current complexity. \"At present, mutual customers typically maintain separate contracts unless they engage through a services partner or system integrator,\" he said. However, he argued the economics still favor the composable approach: \"Our combined technologies deliver exceptional value—in most circumstances at just a fraction of the price of a single-platform solution. Beyond the savings, customers gain a richer, more unified observability experience that unlocks deeper insights and greater efficiency, especially for large-scale environments.\"The company plans to streamline this over time. \"As the ISV program matures, we&#x27;re focused on delivering a more streamlined experience by transitioning to a single, unified contract that simplifies procurement and accelerates time to value,\" Mao said.How two Uber engineers turned Halloween outages into a billion-dollar startupChronosphere&#x27;s origins trace to 2019, when Mao and co-founder Rob Skillington left Uber after building the ride-hailing giant&#x27;s internal observability platform. At Uber, Mao&#x27;s team had faced a crisis: the company&#x27;s in-house tools would fail on its two busiest nights — Halloween and New Year&#x27;s Eve — cutting off visibility into whether customers could request rides or drivers could locate passengers.The solution they built at Uber used open-source software and ultimately allowed the company to operate without outages, even during high-volume events. But the broader market insight came at an industry conference in December 2018, when major cloud providers threw their weight behind Kubernetes, Google&#x27;s container orchestration technology.\"This meant that most technology architectures were eventually going to look like Uber&#x27;s,\" Mao recalled in an August 2024 profile by Greylock Partners, Chronosphere&#x27;s lead investor. \"And that meant every company, not just a few big tech companies and the Walmarts of the world, would have the exact same problem we had solved at Uber.\"Chronosphere has since raised more than $343 million in funding across multiple rounds led by Greylock, Lux Capital, General Atlantic, Addition, and Founders Fund. The company operates as a remote-first organization with offices in New York, Austin, Boston, San Francisco, and Seattle, employing approximately 299 people according to LinkedIn data.The company&#x27;s customer base includes DoorDash, Zillow, Snap, Robinhood, and Affirm — predominantly high-growth technology companies operating cloud-native, Kubernetes-based infrastructures at massive scale.What&#x27;s available now—and what enterprises can expect in 2026Chronosphere&#x27;s AI-Guided Troubleshooting capabilities, including Suggestions and Investigation Notebooks, entered limited availability Monday with select customers. The company plans full general availability in 2026. The Model Context Protocol (MCP) Server, which enables engineers to integrate Chronosphere directly into internal AI workflows and query observability data through AI-enabled development environments, is available immediately for all Chronosphere customers.The phased rollout reflects the company&#x27;s cautious approach to deploying AI in production environments where mistakes carry real costs. By gathering feedback from early adopters before broad release, Chronosphere aims to refine its guidance algorithms and validate that its suggestions genuinely accelerate troubleshooting rather than simply generating impressive demonstrations.The longer game, however, extends beyond individual product features. Chronosphere&#x27;s dual bet — on transparent AI that shows its reasoning and on a partner ecosystem rather than all-in-one integration — amounts to a fundamental thesis about how enterprise observability will evolve as systems grow more complex.If that thesis proves correct, the company that solves observability for the AI age won&#x27;t be the one with the most automated black box. It will be the one that earns engineers&#x27; trust by explaining what it knows, admitting what it doesn&#x27;t, and letting humans make the final call. In an industry drowning in data and promised silver bullets, Chronosphere is wagering that showing your work still matters — even when AI is doing the math.",
          "content": "Chronosphere, a New York-based observability startup valued at $1.6 billion, announced Monday it will launch AI-Guided Troubleshooting capabilities designed to help engineers diagnose and fix production software failures — a problem that has intensified as artificial intelligence tools accelerate code creation while making systems harder to debug.The new features combine AI-driven analysis with what Chronosphere calls a Temporal Knowledge Graph, a continuously updated map of an organization&#x27;s services, infrastructure dependencies, and system changes over time. The technology aims to address a mounting challenge in enterprise software: developers are writing code faster than ever with AI assistance, but troubleshooting remains largely manual, creating bottlenecks when applications fail.\"For AI to be effective in observability, it needs more than pattern recognition and summarization,\" said Martin Mao, Chronosphere&#x27;s CEO and co-founder, in an exclusive interview with VentureBeat. \"Chronosphere has spent years building the data foundation and analytical depth needed for AI to actually help engineers. With our Temporal Knowledge Graph and advanced analytics capabilities, we&#x27;re giving AI the understanding it needs to make observability truly intelligent — and giving engineers the confidence to trust its guidance.\"The announcement comes as the observability market — software that monitors complex cloud applications— faces mounting pressure to justify escalating costs. Enterprise log data volumes have grown 250% year-over-year, according to Chronosphere&#x27;s own research, while a study from MIT and the University of Pennsylvania found that generative AI has spurred a 13.5% increase in weekly code commits, signifying faster development velocity but also greater system complexity.AI writes code 13% faster, but debugging stays stubbornly manualDespite advances in automated code generation, debugging production failures remains stubbornly manual. When a major e-commerce site slows during checkout or a banking app fails to process transactions, engineers must sift through millions of data points — server logs, application traces, infrastructure metrics, recent code deployments — to identify root causes.Chronosphere&#x27;s answer is what it calls AI-Guided Troubleshooting, built on four core capabilities: automated \"Suggestions\" that propose investigation paths backed by data; the Temporal Knowledge Graph that maps system relationships and changes; Investigation Notebooks that document each troubleshooting step for future reference; and natural language query building.Mao explained the Temporal Knowledge Graph in practical terms: \"It&#x27;s a living, time-aware model of your system. It stitches together telemetry—metrics, traces, logs—infrastructure context, change events like deploys and feature flags, and even human input like notes and runbooks into a single, queryable map that updates as your system evolves.\"This differs fundamentally from the service dependency maps offered by competitors like Datadog, Dynatrace, and Splunk, Mao argued. \"It adds time, not just topology,\" he said. \"It tracks how services and dependencies change over time and connects those changes to incidents—what changed and why. Many tools rely on standardized integrations; our graph goes a step further to normalize custom, non-standard telemetry so application-specific signals aren&#x27;t a blind spot.\"Why Chronosphere shows its work instead of making automatic decisionsUnlike purely automated systems, Chronosphere designed its AI features to keep engineers in the driver&#x27;s seat—a deliberate choice meant to address what Mao calls the \"confident-but-wrong guidance\" problem plaguing early AI observability tools.\"&#x27;Keeping engineers in control&#x27; means the AI shows its work, proposes next steps, and lets engineers verify or override — never auto-deciding behind the scenes,\" Mao explained. \"Every Suggestion includes the evidence—timing, dependencies, error patterns — and a &#x27;Why was this suggested?&#x27; view, so they can inspect what was checked and ruled out before acting.\"He walked through a concrete example: \"An SLO [service level objective] alert fires on Checkout. Chronosphere immediately surfaces a ranked Suggestion: errors appear to have started in the dependent Payment service. An engineer can click Investigate to see the charts and reasoning and, if it holds up, choose to dig deeper. As they steer into Payment, the system adapts with new Suggestions scoped to that service—all from one view, no tab-hopping.\"In this scenario, the engineer asks \"what changed?\" and the system pulls in change events. \"Our Notebook capability makes the causal chain plain: a feature-flag update preceded pod memory exhaustion in Payment; Checkout&#x27;s spike is a downstream symptom,\" Mao said. \"They can decide to roll back the flag. That whole path — suggestions followed, evidence viewed, conclusions—is captured automatically in an Investigation Notebook, and the outcome feeds the Temporal Knowledge Graph so similar future incidents are faster to resolve.\"How a $1.6 billion startup takes on Datadog, Dynatrace, and SplunkChronosphere enters an increasingly crowded field. Datadog, the publicly traded observability leader valued at over $40 billion, has introduced its own AI-powered troubleshooting features. So have Dynatrace and Splunk. All three offer comprehensive \"all-in-one\" platforms that promise single-pane-of-glass visibility.Mao distinguished Chronosphere&#x27;s approach on technical grounds. \"Early &#x27;AI for observability&#x27; leaned heavily on pattern-spotting and summarization, which tends to break down during real incidents,\" he said. \"These approaches often stop at correlating anomalies or producing fluent explanations without the deeper analysis and causal reasoning observability leaders need. They can feel impressive in demos but disappoint in production—they summarize signals rather than explain cause and effect.\"A specific technical gap, he argued, involves custom application telemetry. \"Most platforms reason over standardized integrations—Kubernetes, common cloud services, popular databases—ignoring the most telling clues that live in custom app telemetry,\" Mao said. \"With an incomplete picture, large language models will &#x27;fill in the gaps,&#x27; producing confident-but-wrong guidance that sends teams down dead ends.\"Chronosphere&#x27;s competitive positioning received validation in July when Gartner named it a Leader in the 2025 Magic Quadrant for Observability Platforms for the second consecutive year. The firm was recognized based on both \"Completeness of Vision\" and \"Ability to Execute.\" In December 2024, Chronosphere also tied for the highest overall rating among recognized vendors in Gartner Peer Insights&#x27; \"Voice of the Customer\" report, scoring 4.7 out of 5 based on 70 reviews.Yet the company faces intensifying competition for high-profile customers. UBS analysts noted in July that OpenAI now runs both Datadog and Chronosphere side-by-side to monitor GPU workloads, suggesting the AI leader is evaluating alternatives. While UBS maintained its buy rating on Datadog, the analysts warned that growing Chronosphere usage could pressure Datadog&#x27;s pricing power.Inside the 84% cost reduction claims—and what CIOs should actually measureBeyond technical capabilities, Chronosphere has built its market position on cost control — a critical factor as observability spending spirals. The company claims its platform reduces data volumes and associated costs by 84% on average while cutting critical incidents by up to 75%.When pressed for specific customer examples with real numbers, Mao pointed to several case studies. \"Robinhood has seen a 5x improvement in reliability and a 4x improvement in Mean Time to Detection,\" he said. \"DoorDash used Chronosphere to improve governance and standardize monitoring practices. Astronomer achieved over 85% cost reduction by shaping data on ingest, and Affirm scaled their load 10x during a Black Friday event with no issues, highlighting the platform&#x27;s reliability under extreme conditions.\"The cost argument matters because, as Paul Nashawaty, principal analyst at CUBE Research, noted when Chronosphere launched its Logs 2.0 product in June: \"Organizations are drowning in telemetry data, with over 70% of observability spend going toward storing logs that are never queried.\"For CIOs fatigued by \"AI-powered\" announcements, Mao acknowledged skepticism is warranted. \"The way to cut through it is to test whether the AI shortens incidents, reduces toil, and builds reusable knowledge in your own environment, not in a demo,\" he advised. He recommended CIOs evaluate three factors: transparency and control (does the system show its reasoning?), coverage of custom telemetry (can it handle non-standardized data?), and manual toil avoided (how many ad-hoc queries and tool-switches are eliminated?).Why Chronosphere partners with five vendors instead of building everything itselfAlongside the AI troubleshooting announcement, Chronosphere revealed a new Partner Program integrating five specialized vendors to fill gaps in its platform: Arize for large language model monitoring, Embrace for real user monitoring, Polar Signals for continuous profiling, Checkly for synthetic monitoring, and Rootly for incident management.The strategy represents a deliberate bet against the all-in-one platforms dominating the market. \"While an all-in-one platform may be sufficient for smaller organizations, global enterprises demand best-in-class depth across each domain,\" Mao said. \"This is what drove us to build our Partner Program and invest in seamless integrations with leading providers—so our customers can operate with confidence and clarity at every layer of observability.\"Noah Smolen, head of partnerships at Arize, said the collaboration addresses a specific enterprise need. \"With a wide array of Fortune 500 customers, we understand the high bar needed to ensure AI agent systems are ready to deploy and stay incident-free, especially given the pace of AI adoption in the enterprise,\" Smolen said. \"Our partnership with Chronosphere comes at a time when an integrated purpose-built cloud-native and AI-observability suite solves a huge pain point for forward-thinking C-suite leaders who demand the very best across their entire observability stack.\"Similarly, JJ Tang, CEO and founder of Rootly, emphasized the incident resolution benefits. \"Incidents hinder innovation and revenue, and the challenge lies in sifting through vast amounts of observability data, mobilizing teams, and resolving issues quickly,\" Tang said. \"Integrating Chronosphere with Rootly allows engineers to collaborate with context and resolve issues faster within their existing communication channels, drastically reducing time to resolution and ultimately improving reliability—78% plus decreases in repeat Sev0 and Sev1 incidents.\"When asked how total costs compare when customers use multiple partner contracts versus a single platform, Mao acknowledged the current complexity. \"At present, mutual customers typically maintain separate contracts unless they engage through a services partner or system integrator,\" he said. However, he argued the economics still favor the composable approach: \"Our combined technologies deliver exceptional value—in most circumstances at just a fraction of the price of a single-platform solution. Beyond the savings, customers gain a richer, more unified observability experience that unlocks deeper insights and greater efficiency, especially for large-scale environments.\"The company plans to streamline this over time. \"As the ISV program matures, we&#x27;re focused on delivering a more streamlined experience by transitioning to a single, unified contract that simplifies procurement and accelerates time to value,\" Mao said.How two Uber engineers turned Halloween outages into a billion-dollar startupChronosphere&#x27;s origins trace to 2019, when Mao and co-founder Rob Skillington left Uber after building the ride-hailing giant&#x27;s internal observability platform. At Uber, Mao&#x27;s team had faced a crisis: the company&#x27;s in-house tools would fail on its two busiest nights — Halloween and New Year&#x27;s Eve — cutting off visibility into whether customers could request rides or drivers could locate passengers.The solution they built at Uber used open-source software and ultimately allowed the company to operate without outages, even during high-volume events. But the broader market insight came at an industry conference in December 2018, when major cloud providers threw their weight behind Kubernetes, Google&#x27;s container orchestration technology.\"This meant that most technology architectures were eventually going to look like Uber&#x27;s,\" Mao recalled in an August 2024 profile by Greylock Partners, Chronosphere&#x27;s lead investor. \"And that meant every company, not just a few big tech companies and the Walmarts of the world, would have the exact same problem we had solved at Uber.\"Chronosphere has since raised more than $343 million in funding across multiple rounds led by Greylock, Lux Capital, General Atlantic, Addition, and Founders Fund. The company operates as a remote-first organization with offices in New York, Austin, Boston, San Francisco, and Seattle, employing approximately 299 people according to LinkedIn data.The company&#x27;s customer base includes DoorDash, Zillow, Snap, Robinhood, and Affirm — predominantly high-growth technology companies operating cloud-native, Kubernetes-based infrastructures at massive scale.What&#x27;s available now—and what enterprises can expect in 2026Chronosphere&#x27;s AI-Guided Troubleshooting capabilities, including Suggestions and Investigation Notebooks, entered limited availability Monday with select customers. The company plans full general availability in 2026. The Model Context Protocol (MCP) Server, which enables engineers to integrate Chronosphere directly into internal AI workflows and query observability data through AI-enabled development environments, is available immediately for all Chronosphere customers.The phased rollout reflects the company&#x27;s cautious approach to deploying AI in production environments where mistakes carry real costs. By gathering feedback from early adopters before broad release, Chronosphere aims to refine its guidance algorithms and validate that its suggestions genuinely accelerate troubleshooting rather than simply generating impressive demonstrations.The longer game, however, extends beyond individual product features. Chronosphere&#x27;s dual bet — on transparent AI that shows its reasoning and on a partner ecosystem rather than all-in-one integration — amounts to a fundamental thesis about how enterprise observability will evolve as systems grow more complex.If that thesis proves correct, the company that solves observability for the AI age won&#x27;t be the one with the most automated black box. It will be the one that earns engineers&#x27; trust by explaining what it knows, admitting what it doesn&#x27;t, and letting humans make the final call. In an industry drowning in data and promised silver bullets, Chronosphere is wagering that showing your work still matters — even when AI is doing the math.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6Jp2LKG6zzFEnDhB9m893X/06467084db114c990d9e72be3896bf51/nuneybits_Vector_art_of_AI_debugging_maze_2b3bfc89-ab17-4839-a03e-6331a42f5030.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/nintendo-announces-its-black-friday-and-cyber-monday-2025-sale-switch-2-bundles-switch-game-deals-and-more-155223898.html",
          "published_at": "Mon, 10 Nov 2025 15:52:23 +0000",
          "title": "Nintendo announces its Black Friday and Cyber Monday 2025 sale: Switch 2 bundles, Switch game deals and more",
          "standfirst": "Nintendo gear is always sought after during the holiday shopping season, but this year likely more so than others. The Nintendo Switch 2 is the console launch of 2025 and it will undoubtedly be at the top of many wish lists for both kids and adults alike. If you were hoping to save a bit on the console during the Black Friday shopping season, you may be disappointed. The Nintendo Black Friday sale was just announced, and unsurprisingly, there aren't a lot of true \"deals\" to be had. This is typical of Nintendo — legit Nintendo Black Friday deals are hard to come by — but there are ways to at least get the best value for your money if you're going to pick up a Switch 2 before the year is out. As has been the case for many years, the marquee Nintendo deals for the holidays come in the form of console bundles. When the Switch 2 launched earlier this year, it was available as just the console only for $449 or bundled with Mario Kart World for $499. Both options are still available now, but there's a new bundle to consider as well — the console with the new Pokémon Legends: Z-A game, which also costs $499. Considering the games by themselves cost $70 each, you do save a bit by picking up a console bundle. you can pick up the console and its bundles at most retailers including Amazon, Walmart, Best Buy and others. When it comes to deals on Nintendo Switch 2 games, the Nintendo eShop will have Cyber Deals starting on November 20, running through December 3. The shop will feature \"holiday offers on select games,\" so it appears we'll all just have to go to the online store on November 20 to see the games on offer. Starting on November 23, select retailers will have discounts on some physical Switch games including Princess Peach: Showtime!, The Legend of Zelda: Echoes of Wisdom, Luigi’s Mansion 3 and Kirby’s Return to Dream Land Deluxe. Those will each be $40, while other games like Super Mario Odyssey, Nintendo Switch Sports, Paper Mario: The Thousand-Year Door and Splatoon 3 will be $30. Even if you can't get huge discounts on Nintendo consoles or new games this year, that doesn't mean you can't find decent deals on other Nintendo gear. There are plenty of great ideas for gifts for the Nintendo fan in your life, and Engadget's Sam Rutherford got to see a bunch of them in person when he attended Nintendo's holiday showcase. From collectibles to clothing to plushies and holiday decor, there's really a ton to choose from — but you may want to pace yourself if you're also a Nintendo fan finding things that you want to pick up for yourself in the process of looking for good gifts. Here are just some of the best Nintendo gift ideas that you can look out for during Black Friday and Cyber Monday. This article originally appeared on Engadget at https://www.engadget.com/deals/nintendo-announces-its-black-friday-and-cyber-monday-2025-sale-switch-2-bundles-switch-game-deals-and-more-155223898.html?src=rss",
          "content": "Nintendo gear is always sought after during the holiday shopping season, but this year likely more so than others. The Nintendo Switch 2 is the console launch of 2025 and it will undoubtedly be at the top of many wish lists for both kids and adults alike. If you were hoping to save a bit on the console during the Black Friday shopping season, you may be disappointed. The Nintendo Black Friday sale was just announced, and unsurprisingly, there aren't a lot of true \"deals\" to be had. This is typical of Nintendo — legit Nintendo Black Friday deals are hard to come by — but there are ways to at least get the best value for your money if you're going to pick up a Switch 2 before the year is out. As has been the case for many years, the marquee Nintendo deals for the holidays come in the form of console bundles. When the Switch 2 launched earlier this year, it was available as just the console only for $449 or bundled with Mario Kart World for $499. Both options are still available now, but there's a new bundle to consider as well — the console with the new Pokémon Legends: Z-A game, which also costs $499. Considering the games by themselves cost $70 each, you do save a bit by picking up a console bundle. you can pick up the console and its bundles at most retailers including Amazon, Walmart, Best Buy and others. When it comes to deals on Nintendo Switch 2 games, the Nintendo eShop will have Cyber Deals starting on November 20, running through December 3. The shop will feature \"holiday offers on select games,\" so it appears we'll all just have to go to the online store on November 20 to see the games on offer. Starting on November 23, select retailers will have discounts on some physical Switch games including Princess Peach: Showtime!, The Legend of Zelda: Echoes of Wisdom, Luigi’s Mansion 3 and Kirby’s Return to Dream Land Deluxe. Those will each be $40, while other games like Super Mario Odyssey, Nintendo Switch Sports, Paper Mario: The Thousand-Year Door and Splatoon 3 will be $30. Even if you can't get huge discounts on Nintendo consoles or new games this year, that doesn't mean you can't find decent deals on other Nintendo gear. There are plenty of great ideas for gifts for the Nintendo fan in your life, and Engadget's Sam Rutherford got to see a bunch of them in person when he attended Nintendo's holiday showcase. From collectibles to clothing to plushies and holiday decor, there's really a ton to choose from — but you may want to pace yourself if you're also a Nintendo fan finding things that you want to pick up for yourself in the process of looking for good gifts. Here are just some of the best Nintendo gift ideas that you can look out for during Black Friday and Cyber Monday. This article originally appeared on Engadget at https://www.engadget.com/deals/nintendo-announces-its-black-friday-and-cyber-monday-2025-sale-switch-2-bundles-switch-game-deals-and-more-155223898.html?src=rss",
          "feed_position": 18
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/black-friday-deals-for-2025-are-here-early-we-found-the-best-sales-from-apple-amazon-lego-dyson-and-more-100052430.html",
          "published_at": "Mon, 10 Nov 2025 15:00:35 +0000",
          "title": "Black Friday deals for 2025 are here early: We found the best sales from Apple, Amazon, Lego, Dyson and more",
          "standfirst": "November has turned into Black Friday and vice versa. What was once a one-day shopping sprint has turned into a month-long marathon, with retailers rolling out discounts week after week. Thanks to this, it can be easy to get deal fatigue after a while — but no one wants to miss out on a good discount, regardless of if you’re buying for yourself or someone else. We’re tracking all of the best Black Friday deals you can get right now so you don’t have to go searching for them.Engadget can help if you have tech on your shopping list this year. Here, we’ve curated the best Black Friday tech deals you can get right now, and we'll continue to update this post as we get closer to the big day at the end of November. Note that you probably have the best chance of snagging record-low prices when we get to about one week before Thanksgiving, but these deals available now are worth considering. Black Friday deals to shop now Apple AirPods 4 for $85 (34 percent off): These are the most affordable AirPods you can get, and the latest model has been substantially improved over the previous. They have a better fit and noticeably better sound quality than their predecessor, plus some advanced features previously only found on pricer models. Apple Watch SE 3 for $200 ($50 off): The SE has been our top pick for the best Apple Watch for those on a budget, and the latest model only solidifies that further. It has the same chipset found in the latest flagship Apple Watches, fast-charging capabilities, an always-on display and most of the same activity-tracking features you'll find in more expensive model. Apple AirTags (four pack) for $65 (34 percent off): iPhone users who frequently misplace things should invest in a few AirTags. Slip them into your wallet, bag, jacket and other belongings to keep track of their locations in the Find My app. Just make sure that, if you're going to attach one to your keys, you also pick up an AirTag holder to go along with it. LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable 75375 for $68 (20 percent off): This is a set that any Star Wars fan will love to build and then love to display once it's complete. The 921-piece set features a fully-detailed Millennium Falcone, buildable stand and nameplate. It's one of many Lego Black Friday deals you can get right now. Apple Mac Mini M4 for $499 ($100 off): Desktop users looking for an upgrade should consider the latest Mac Mini, which runs on the M4 chip and 16GB of RAM as standard in the base configuration. This version has a smaller design that takes up less space, front-facing USB-C ports and a headphone jack, plus Thunderbolt 5 support. Jisulife Life 7 handheld fan for $25 (14 percent off): This handy little fan is a must-have if you life in a warm climate or have a tropical vacation planned anytime soon. It can be used as a table or handheld fan and even be worn around the neck so you don't have to hold it at all. Its 5,000 mAh battery allows it to last hours on a single charge, and the small display in the middle of the fan's blades show its remaining battery level. Leebin 2025 electric spin scrubber for $40 (43 percent off, Prime exclusive): This weird little scrubber makes cleaning my bathroom and shower much less of a pain. Just choose the brush head you need for your job and the rotating head takes care of most of the hard work. I love the adjustable handle, which extends from 12 to 50 inches so you can get into hard-to-reach places without breaking a sweat. Monarch Money budgeting app (one year) for $50 (50 percent off with code MONARCHVIP): One of our favorite budgeting apps, Monarch Money gives you a lot of control over the organization of your funds. There's a helpful goals feature for when you're planning out big purchases or financial milestones you want to hit, and we found the month-in-review recap it provides to be more thorough than other budgeting apps we tried. There's even Zillow integration for folks looking to buy a home. SanDisk microSD Express card (256GB) for $60 (12 percent off): If you have a Switch 2, no regular microSD card will do if you want to expand the console's storage. You need a newer microSD Express card, and currently there are only a handful on the market. We did some testing to find the best microSD Express card for the Switch 2 and found that performance was, in general, very similar amongst all the readily available cards. We recommend getting whichever fits within your budget at the capacity you want. Google TV Streamer 4K for $75 ($25 off): Our top pick for the best streaming device right now, the latest version of Google's streamer supports 4K video and an excellent, easy-to-use interface that will feel familiar to anyone who's seen a set with the Google TV technology built in. It provides access to all of the major streaming services including Netflix, Disney+, HBO Max, YouTube and more, plus it has a handy on-screen pop up that lets you control all compatible smart home devices right from your TV. Also available at Walmart. Cosori 9-in-1 air fryer for $90 (25 percent off): I personally have this air fryer, one of our top picks, in my house and I've used it for over a year with no issues. I love that it makes good use of vertical space so it doesn't take up too much space on my counter, and its rounded-square shape allows me to cook more food than you'd think in one go in the basket. It crisps all kinds of foods up well and generally takes a lot of the guess work (and time) out of making a good meal. Dyson 360 Vis Nav robot vacuum for $500 (50 percent off): This is one of the best robot vacuums you can get, period. It doesn't have a self-emptying base, but its superior suction power almost makes up for that. It's one of the strongest robot vacuums I've ever tested, and it has excellent obstacle avoidance. The latter means you will rarely, if ever, have to attend to it getting caught on the edge of a carpet or getting stuck under a piece of furniture. If a cordless stick vacuum is what you're looking for, don't forget to check out all of the other Dyson Black Friday deals. EcoFlow Black Friday deals — get up to 80 percent off: Portable power stations are an investment, but they can be crucial pieces of tech during emergencies. The top pick from our friends at Yahoo Tech has been heavily discounted in this early Black Friday sale. You can pick up the EcoFlow Delta Pro 3 for $1,400 off, down to $2,299, or the power station with an extra battery bundled in for $2,699 off, down to $3,599. Black Friday FAQs When is Black Friday 2025? Black Friday 2025 lands on November 28. Which stores have Black Friday deals? Many physical retail stores have Black Friday deals including Walmart, Target, Best Buy and others. Even more retailers have online Black Friday deals, including Amazon, GameStop, Costco and others. When do Black Friday sales start? Gone are the times when Black Friday sales were one-day-only affairs. Now, Black Friday deals are often available starting on Thanksgiving, or even earlier. Last year, we saw Black Friday deals online begin the week before Black Friday proper. When do Black Friday sales end? Black Friday and Cyber Monday have blended a lot over the past few years. Now, you can expect to see a good portion of Black Friday deals extend through the weekend and into Cyber Monday. It's not uncommon for Black Friday deals to expire at the end of Cyber Monday. Which retailers have the best Black Friday tech deals? The best Black Friday tech deals are typically available online at retailers like Amazon, Walmart, Best Buy and Target. It's also a good idea to check the store websites of the companies that make the products you want — for example, if you're looking for a Sonos speaker, check the Sonos website on Black Friday. Most of the time, you'll find the best Black Friday tech deals are matched at multiple retailers. Does Apple have Black Friday sales? No, you will usually not find Black Friday sales at Apple stores or on Apple's website. However, you can find Black Friday deals on Apple devices elsewhere; we recommend checking Amazon, Best Buy and other big retailers for discounts on iPads, Apple Watches and more on Black Friday. Does Amazon have Black Friday sales? Yes, Amazon has Black Friday sales. The online retailer's site will look similar to Prime Day on Black Friday, with discounts on all sorts of items from household essentials to fashion to tech.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-deals-for-2025-are-here-early-we-found-the-best-sales-from-apple-amazon-lego-dyson-and-more-100052430.html?src=rss",
          "content": "November has turned into Black Friday and vice versa. What was once a one-day shopping sprint has turned into a month-long marathon, with retailers rolling out discounts week after week. Thanks to this, it can be easy to get deal fatigue after a while — but no one wants to miss out on a good discount, regardless of if you’re buying for yourself or someone else. We’re tracking all of the best Black Friday deals you can get right now so you don’t have to go searching for them.Engadget can help if you have tech on your shopping list this year. Here, we’ve curated the best Black Friday tech deals you can get right now, and we'll continue to update this post as we get closer to the big day at the end of November. Note that you probably have the best chance of snagging record-low prices when we get to about one week before Thanksgiving, but these deals available now are worth considering. Black Friday deals to shop now Apple AirPods 4 for $85 (34 percent off): These are the most affordable AirPods you can get, and the latest model has been substantially improved over the previous. They have a better fit and noticeably better sound quality than their predecessor, plus some advanced features previously only found on pricer models. Apple Watch SE 3 for $200 ($50 off): The SE has been our top pick for the best Apple Watch for those on a budget, and the latest model only solidifies that further. It has the same chipset found in the latest flagship Apple Watches, fast-charging capabilities, an always-on display and most of the same activity-tracking features you'll find in more expensive model. Apple AirTags (four pack) for $65 (34 percent off): iPhone users who frequently misplace things should invest in a few AirTags. Slip them into your wallet, bag, jacket and other belongings to keep track of their locations in the Find My app. Just make sure that, if you're going to attach one to your keys, you also pick up an AirTag holder to go along with it. LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable 75375 for $68 (20 percent off): This is a set that any Star Wars fan will love to build and then love to display once it's complete. The 921-piece set features a fully-detailed Millennium Falcone, buildable stand and nameplate. It's one of many Lego Black Friday deals you can get right now. Apple Mac Mini M4 for $499 ($100 off): Desktop users looking for an upgrade should consider the latest Mac Mini, which runs on the M4 chip and 16GB of RAM as standard in the base configuration. This version has a smaller design that takes up less space, front-facing USB-C ports and a headphone jack, plus Thunderbolt 5 support. Jisulife Life 7 handheld fan for $25 (14 percent off): This handy little fan is a must-have if you life in a warm climate or have a tropical vacation planned anytime soon. It can be used as a table or handheld fan and even be worn around the neck so you don't have to hold it at all. Its 5,000 mAh battery allows it to last hours on a single charge, and the small display in the middle of the fan's blades show its remaining battery level. Leebin 2025 electric spin scrubber for $40 (43 percent off, Prime exclusive): This weird little scrubber makes cleaning my bathroom and shower much less of a pain. Just choose the brush head you need for your job and the rotating head takes care of most of the hard work. I love the adjustable handle, which extends from 12 to 50 inches so you can get into hard-to-reach places without breaking a sweat. Monarch Money budgeting app (one year) for $50 (50 percent off with code MONARCHVIP): One of our favorite budgeting apps, Monarch Money gives you a lot of control over the organization of your funds. There's a helpful goals feature for when you're planning out big purchases or financial milestones you want to hit, and we found the month-in-review recap it provides to be more thorough than other budgeting apps we tried. There's even Zillow integration for folks looking to buy a home. SanDisk microSD Express card (256GB) for $60 (12 percent off): If you have a Switch 2, no regular microSD card will do if you want to expand the console's storage. You need a newer microSD Express card, and currently there are only a handful on the market. We did some testing to find the best microSD Express card for the Switch 2 and found that performance was, in general, very similar amongst all the readily available cards. We recommend getting whichever fits within your budget at the capacity you want. Google TV Streamer 4K for $75 ($25 off): Our top pick for the best streaming device right now, the latest version of Google's streamer supports 4K video and an excellent, easy-to-use interface that will feel familiar to anyone who's seen a set with the Google TV technology built in. It provides access to all of the major streaming services including Netflix, Disney+, HBO Max, YouTube and more, plus it has a handy on-screen pop up that lets you control all compatible smart home devices right from your TV. Also available at Walmart. Cosori 9-in-1 air fryer for $90 (25 percent off): I personally have this air fryer, one of our top picks, in my house and I've used it for over a year with no issues. I love that it makes good use of vertical space so it doesn't take up too much space on my counter, and its rounded-square shape allows me to cook more food than you'd think in one go in the basket. It crisps all kinds of foods up well and generally takes a lot of the guess work (and time) out of making a good meal. Dyson 360 Vis Nav robot vacuum for $500 (50 percent off): This is one of the best robot vacuums you can get, period. It doesn't have a self-emptying base, but its superior suction power almost makes up for that. It's one of the strongest robot vacuums I've ever tested, and it has excellent obstacle avoidance. The latter means you will rarely, if ever, have to attend to it getting caught on the edge of a carpet or getting stuck under a piece of furniture. If a cordless stick vacuum is what you're looking for, don't forget to check out all of the other Dyson Black Friday deals. EcoFlow Black Friday deals — get up to 80 percent off: Portable power stations are an investment, but they can be crucial pieces of tech during emergencies. The top pick from our friends at Yahoo Tech has been heavily discounted in this early Black Friday sale. You can pick up the EcoFlow Delta Pro 3 for $1,400 off, down to $2,299, or the power station with an extra battery bundled in for $2,699 off, down to $3,599. Black Friday FAQs When is Black Friday 2025? Black Friday 2025 lands on November 28. Which stores have Black Friday deals? Many physical retail stores have Black Friday deals including Walmart, Target, Best Buy and others. Even more retailers have online Black Friday deals, including Amazon, GameStop, Costco and others. When do Black Friday sales start? Gone are the times when Black Friday sales were one-day-only affairs. Now, Black Friday deals are often available starting on Thanksgiving, or even earlier. Last year, we saw Black Friday deals online begin the week before Black Friday proper. When do Black Friday sales end? Black Friday and Cyber Monday have blended a lot over the past few years. Now, you can expect to see a good portion of Black Friday deals extend through the weekend and into Cyber Monday. It's not uncommon for Black Friday deals to expire at the end of Cyber Monday. Which retailers have the best Black Friday tech deals? The best Black Friday tech deals are typically available online at retailers like Amazon, Walmart, Best Buy and Target. It's also a good idea to check the store websites of the companies that make the products you want — for example, if you're looking for a Sonos speaker, check the Sonos website on Black Friday. Most of the time, you'll find the best Black Friday tech deals are matched at multiple retailers. Does Apple have Black Friday sales? No, you will usually not find Black Friday sales at Apple stores or on Apple's website. However, you can find Black Friday deals on Apple devices elsewhere; we recommend checking Amazon, Best Buy and other big retailers for discounts on iPads, Apple Watches and more on Black Friday. Does Amazon have Black Friday sales? Yes, Amazon has Black Friday sales. The online retailer's site will look similar to Prime Day on Black Friday, with discounts on all sorts of items from household essentials to fashion to tech.This article originally appeared on Engadget at https://www.engadget.com/deals/black-friday-deals-for-2025-are-here-early-we-found-the-best-sales-from-apple-amazon-lego-dyson-and-more-100052430.html?src=rss",
          "feed_position": 20
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/how-context-engineering-can-save-your-company-from-ai-vibe-code-overload",
          "published_at": "Mon, 10 Nov 2025 15:00:00 GMT",
          "title": "How context engineering can save your company from AI vibe code overload: lessons from Qodo and Monday.com",
          "standfirst": "As cloud project tracking software monday.com’s engineering organization scaled past 500 developers, the team began to feel the strain of its own success. Product lines were multiplying, microservices proliferating, and code was flowing faster than human reviewers could keep up. The company needed a way to review thousands of pull requests each month without drowning developers in tedium — or letting quality slip.That’s when Guy Regev, VP of R&D and head of the Growth and monday Dev teams, started experimenting with a new AI tool from Qodo, an Israeli startup focused on developer agents. What began as a lightweight test soon became a critical part of monday.com’s software delivery infrastructure, as a new case study released by both Qodo and monday.com today reveals. “Qodo doesn’t feel like just another tool—it’s like adding a new developer to the team who actually learns how we work,\" Regev told VentureBeat in a recent video call interview, adding that it has \"prevented over 800 issues per month from reaching production—some of them could have caused serious security vulnerabilities.\"Unlike code generation tools like GitHub Copilot or Cursor, Qodo isn’t trying to write new code. Instead, it specializes in reviewing it — using what it calls context engineering to understand not just what changed in a pull request, but why, how it aligns with business logic, and whether it follows internal best practices. \"You can call Claude Code or Cursor and in five minutes get 1,000 lines of code,\" said Itamar Friedman, co-founder and CEO of Qodo, in the same video call interview as with Regev. \"You have 40 minutes, and you can&#x27;t review that. So you need Qodo to actually review it.”For monday.com, this capability wasn’t just helpful — it was transformative.Code Review, at ScaleAt any given time, monday.com’s developers are shipping updates across hundreds of repositories and services. The engineering org works in tightly coordinated teams, each aligned with specific parts of the product: marketing, CRM, dev tools, internal platforms, and more.That’s where Qodo came in. The company’s platform uses AI not just to check for obvious bugs or style violations, but to evaluate whether a pull request follows team-specific conventions, architectural guidelines, and historical patterns. It does this by learning from your own codebase — training on previous PRs, comments, merges, and even Slack threads to understand how your team works.\"The comments Qodo gives aren’t generic—they reflect our values, our libraries, even our standards for things like feature flags and privacy,\" Regev said. \"It’s context-aware in a way traditional tools aren’t.\"What “Context Engineering” Actually MeansQodo calls its secret sauce context engineering — a system-level approach to managing everything the model sees when making a decision. This includes the PR code diff, of course, but also prior discussions, documentation, relevant files from the repo, even test results and configuration data.The idea is that language models don’t really “think” — they predict the next token based on the inputs they’re given. So the quality of their output depends almost entirely on the quality and structure of their inputs.As Dana Fine, Qodo’s community manager, put it in a blog post: “You’re not just writing prompts; you’re designing structured input under a fixed token limit. Every token is a design decision.”This isn’t just theory. In monday.com’s case, it meant Qodo could catch not only the obvious bugs, but the subtle ones that typically slip past human reviewers — hardcoded variables, missing fallbacks, or violations of cross-team architecture conventions.One example stood out. In a recent PR, Qodo flagged a line that inadvertently exposed a staging environment variable — something no human reviewer caught. Had it been merged, it might have caused problems in production. \"The hours we would spend on fixing this security leak and the legal issue that it would bring would be much more than the hours that we reduce from a pull-request,\" said Regev.Integration into the PipelineToday, Qodo is deeply integrated into monday.com’s development workflow, analyzing pull requests and surfacing context-aware recommendations based on prior team code reviews. “It doesn’t feel like just another tool... It feels like another teammate that joined the system — one who learns how we work,\" Regev noted. Developers receive suggestions during the review process and remain in control of final decisions — a human-in-the-loop model that was critical for adoption.Because Qodo integrated directly into GitHub via pull request actions and comments, Monday.com’s infrastructure team didn’t face a steep learning curve.“It’s just a GitHub action,” said Regev. “It creates a PR with the tests. It’s not like a separate tool we had to learn.”“The purpose is to actually help the developer learn the code, take ownership, give feedback to each other, and learn from that and establish the standards,\" added Friedman.The Results: Time Saved, Bugs PreventedSince rolling out Qodo more broadly, monday.com has seen measurable improvements across multiple teams.Internal analysis shows that developers save roughly an hour per pull request on average. Multiply that across thousands of PRs per month, and the savings quickly reach thousands of developer hours annually.These aren’t just cosmetic issues — many relate to business logic, security, or runtime stability. And because Qodo’s suggestions reflect monday.com’s actual conventions, developers are more likely to act on them.The system’s accuracy is rooted in its data-first design. Qodo trains on each company’s private codebase and historical data, adapting to different team styles and practices. It doesn’t rely on one-size-fits-all rules or external datasets. Everything is tailored.From Internal Tool to Product VisionRegev’s team was so impressed with Qodo’s impact that they’ve started planning deeper integrations between Qodo and Monday Dev, the developer-focused product line monday.com is building.The vision is to create a workflow where business context — tasks, tickets, customer feedback — flows directly into the code review layer. That way, reviewers can assess not just whether the code “works,” but whether it solves the right problem.“Before, we had linters, danger rules, static analysis... rule-based... you need to configure all the rules,\" Regev said. \"But it doesn’t know what you don’t know... Qodo... feels like it’s learning from our engineers.”This aligns closely with Qodo’s own roadmap. The company doesn’t just review code. It’s building a full platform of developer agents — including Qodo Gen for context-aware code generation, Qodo Merge for automated PR analysis, and Qodo Cover, a regression-testing agent that uses runtime validation to ensure test coverage.All of this is powered by Qodo’s own infrastructure, including its new open-source embedding model, Qodo-Embed-1-1.5B, which outperformed offerings from OpenAI and Salesforce on code retrieval benchmarks.What’s Next?Qodo is now offering its platform under a freemium model — free for individuals, discounted for startups through Google Cloud’s Perks program, and enterprise-grade for companies that need SSO, air-gapped deployment, or advanced controls.The company is already working with teams at NVIDIA, Intuit, and other Fortune 500 companies. And thanks to a recent partnership with Google Cloud, Qodo’s models are available directly inside Vertex AI’s Model Garden, making it easier to integrate into enterprise pipelines.\"Context engines will be the big story of 2026,\" Friedman said. \"Every enterprise will need to build their own second brain if they want AI that actually understands and helps them.\"As AI systems become more embedded in software development, tools like Qodo are showing how the right context — delivered at the right moment — can transform how teams build, ship, and scale code across the enterprise.",
          "content": "As cloud project tracking software monday.com’s engineering organization scaled past 500 developers, the team began to feel the strain of its own success. Product lines were multiplying, microservices proliferating, and code was flowing faster than human reviewers could keep up. The company needed a way to review thousands of pull requests each month without drowning developers in tedium — or letting quality slip.That’s when Guy Regev, VP of R&D and head of the Growth and monday Dev teams, started experimenting with a new AI tool from Qodo, an Israeli startup focused on developer agents. What began as a lightweight test soon became a critical part of monday.com’s software delivery infrastructure, as a new case study released by both Qodo and monday.com today reveals. “Qodo doesn’t feel like just another tool—it’s like adding a new developer to the team who actually learns how we work,\" Regev told VentureBeat in a recent video call interview, adding that it has \"prevented over 800 issues per month from reaching production—some of them could have caused serious security vulnerabilities.\"Unlike code generation tools like GitHub Copilot or Cursor, Qodo isn’t trying to write new code. Instead, it specializes in reviewing it — using what it calls context engineering to understand not just what changed in a pull request, but why, how it aligns with business logic, and whether it follows internal best practices. \"You can call Claude Code or Cursor and in five minutes get 1,000 lines of code,\" said Itamar Friedman, co-founder and CEO of Qodo, in the same video call interview as with Regev. \"You have 40 minutes, and you can&#x27;t review that. So you need Qodo to actually review it.”For monday.com, this capability wasn’t just helpful — it was transformative.Code Review, at ScaleAt any given time, monday.com’s developers are shipping updates across hundreds of repositories and services. The engineering org works in tightly coordinated teams, each aligned with specific parts of the product: marketing, CRM, dev tools, internal platforms, and more.That’s where Qodo came in. The company’s platform uses AI not just to check for obvious bugs or style violations, but to evaluate whether a pull request follows team-specific conventions, architectural guidelines, and historical patterns. It does this by learning from your own codebase — training on previous PRs, comments, merges, and even Slack threads to understand how your team works.\"The comments Qodo gives aren’t generic—they reflect our values, our libraries, even our standards for things like feature flags and privacy,\" Regev said. \"It’s context-aware in a way traditional tools aren’t.\"What “Context Engineering” Actually MeansQodo calls its secret sauce context engineering — a system-level approach to managing everything the model sees when making a decision. This includes the PR code diff, of course, but also prior discussions, documentation, relevant files from the repo, even test results and configuration data.The idea is that language models don’t really “think” — they predict the next token based on the inputs they’re given. So the quality of their output depends almost entirely on the quality and structure of their inputs.As Dana Fine, Qodo’s community manager, put it in a blog post: “You’re not just writing prompts; you’re designing structured input under a fixed token limit. Every token is a design decision.”This isn’t just theory. In monday.com’s case, it meant Qodo could catch not only the obvious bugs, but the subtle ones that typically slip past human reviewers — hardcoded variables, missing fallbacks, or violations of cross-team architecture conventions.One example stood out. In a recent PR, Qodo flagged a line that inadvertently exposed a staging environment variable — something no human reviewer caught. Had it been merged, it might have caused problems in production. \"The hours we would spend on fixing this security leak and the legal issue that it would bring would be much more than the hours that we reduce from a pull-request,\" said Regev.Integration into the PipelineToday, Qodo is deeply integrated into monday.com’s development workflow, analyzing pull requests and surfacing context-aware recommendations based on prior team code reviews. “It doesn’t feel like just another tool... It feels like another teammate that joined the system — one who learns how we work,\" Regev noted. Developers receive suggestions during the review process and remain in control of final decisions — a human-in-the-loop model that was critical for adoption.Because Qodo integrated directly into GitHub via pull request actions and comments, Monday.com’s infrastructure team didn’t face a steep learning curve.“It’s just a GitHub action,” said Regev. “It creates a PR with the tests. It’s not like a separate tool we had to learn.”“The purpose is to actually help the developer learn the code, take ownership, give feedback to each other, and learn from that and establish the standards,\" added Friedman.The Results: Time Saved, Bugs PreventedSince rolling out Qodo more broadly, monday.com has seen measurable improvements across multiple teams.Internal analysis shows that developers save roughly an hour per pull request on average. Multiply that across thousands of PRs per month, and the savings quickly reach thousands of developer hours annually.These aren’t just cosmetic issues — many relate to business logic, security, or runtime stability. And because Qodo’s suggestions reflect monday.com’s actual conventions, developers are more likely to act on them.The system’s accuracy is rooted in its data-first design. Qodo trains on each company’s private codebase and historical data, adapting to different team styles and practices. It doesn’t rely on one-size-fits-all rules or external datasets. Everything is tailored.From Internal Tool to Product VisionRegev’s team was so impressed with Qodo’s impact that they’ve started planning deeper integrations between Qodo and Monday Dev, the developer-focused product line monday.com is building.The vision is to create a workflow where business context — tasks, tickets, customer feedback — flows directly into the code review layer. That way, reviewers can assess not just whether the code “works,” but whether it solves the right problem.“Before, we had linters, danger rules, static analysis... rule-based... you need to configure all the rules,\" Regev said. \"But it doesn’t know what you don’t know... Qodo... feels like it’s learning from our engineers.”This aligns closely with Qodo’s own roadmap. The company doesn’t just review code. It’s building a full platform of developer agents — including Qodo Gen for context-aware code generation, Qodo Merge for automated PR analysis, and Qodo Cover, a regression-testing agent that uses runtime validation to ensure test coverage.All of this is powered by Qodo’s own infrastructure, including its new open-source embedding model, Qodo-Embed-1-1.5B, which outperformed offerings from OpenAI and Salesforce on code retrieval benchmarks.What’s Next?Qodo is now offering its platform under a freemium model — free for individuals, discounted for startups through Google Cloud’s Perks program, and enterprise-grade for companies that need SSO, air-gapped deployment, or advanced controls.The company is already working with teams at NVIDIA, Intuit, and other Fortune 500 companies. And thanks to a recent partnership with Google Cloud, Qodo’s models are available directly inside Vertex AI’s Model Garden, making it easier to integrate into enterprise pipelines.\"Context engines will be the big story of 2026,\" Friedman said. \"Every enterprise will need to build their own second brain if they want AI that actually understands and helps them.\"As AI systems become more embedded in software development, tools like Qodo are showing how the right context — delivered at the right moment — can transform how teams build, ship, and scale code across the enterprise.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6ITdq6fWHUqQToLpa2LMjE/9071464cc3dabd3e163518c89f5eb3b2/cfr0z3n_aerial_view_extended_view_of_hundreds_of_software_devel_dac48c75-82c8-48b8-9ca4-ff785e9ba5f3.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/the-logitech-mx-master-4-comes-with-haptic-feedback-less-rubber-and-the-same-general-shape-070129482.html",
          "published_at": "Mon, 10 Nov 2025 14:00:38 +0000",
          "title": "The Logitech MX Master 4 comes with haptic feedback, less rubber and the same general shape",
          "standfirst": "Editor’s note (11/10/25): After spending another month with the MX Master 4, our impressions remain largely unchanged. The new textured plastic finish and silicone thumb rest have shown no signs of wear, and we’ve continued to see no erratic behavior with the electromagnetic scroll wheel. Battery life still lines up with Logitech’s rating, while the haptic feedback and Actions Ring functionality remain useful if inessential. We’ve added an official review score to this post as a result. Our original hands-on is below. Original post (9/30/25): If you’ve shopped around for a wireless mouse at any point in the past decade, you’ve probably seen lots of people recommending a Logitech MX Master. There’s good reason for that: They aren’t cheap, but they’re usually comfortable, versatile and loaded with features designed to make working in front of a monitor all day a little less annoying. The current MX Master 3S has sat at the top of our own wireless mouse buying guide for some time now. Now, three years after releasing the 3S, Logitech is rolling out the new MX Master 4, which costs $120 and will ship in October. I’ve been able to test it out for the past few weeks. For the most part, this is an iterative update, with the same general shape, battery life, 8K DPI sensor and ultra-quiet clicks as the MX Master 3S before it. It is a touch heavier (150 grams vs. 141g), wider (3.48 inches vs 3.32 in.) and taller (5.05 inches vs. 4.92 in.) than the last model, and the main click buttons are slightly larger. But if you found the 3S or older MX Master 3 comfortable, you should have few issues here. That said, this is still a hefty mouse designed for palm grippers and right-handed users: Its gentle contours, generous hump, ample thumb rest and large buttons will fit like a glove if that describes you, but lefties and those with especially petite hands won’t agree. The flashiest change here is the addition of haptic feedback, which is built into a small panel within the mouse’s thumb rest. You can customize the intensity of this effect through Logitech’s Options+ software — or turn it off entirely — but it essentially brings a modicum of smartphone-style feedback to your desktop. When you first pair the mouse, for one, you’ll feel a little bump. The same goes if you move between devices using Logitech’s “Flow” feature. When battery is low, it’ll vibrate. If you’re trying to precisely line up a graphic in an app like Photoshop, you’ll get a little buzz when you’ve moved it to the exact right spot. Jeff Dunn for Engadget You’ll also feel it when you hover over options in the Actions Ring, a customizable overlay that presents different shortcuts depending on the app you’re using. This pops up when you click the side panel; you could use it quickly access the screenshot tool while in Chrome, for instance, or the brightness and contrast sliders in Photoshop. If all of this sounds like a gimmick, well, yeah it kind of is. It’s not the kind of thing anyone needs. But the effect is surprisingly subtle on the default “medium” setting, and there’s a level of reassurance that comes with feeling a confirmed action instead of just seeing it. I found it more pleasant than distracting. The catch is that only a few apps will natively support the MX Master 4’s haptics at launch: Photoshop, Lightroom and Zoom, with Adobe Premiere Pro to follow soon after. You’ll still be able to utilize the haptic feedback on a system level on Windows and macOS, and Logitech is releasing an SDK for more developers to integrate the functionality, but we’ll have to see how many do so. Another change is with the mouse’s coating, which trades the 3S’ rubbery finish for a lightly textured plastic around the top. (The thumb rest area and right side still use a denser rubber.) Some users have complained about older MX Master mice peeling and wearing down after extended use; time will tell how well the new model holds up, but it should avoid the same sort of sweat-induced degradation. Either way, I’ve found it smooth to the touch without being slippery. I also haven’t been able to replicate the accuracy issues some 3S buyers have had with that mouse’s electromagnetic scroll wheel, which is still made of a high-quality metal and lets you conveniently swap between a notched and free-spin scroll on the fly. Customizing the Actions Ring in Logitech's Options+ app. Logitech/Jeff Dunn for Engadget There are other minor tweaks and improvements. The receiver included with the Windows model is now USB-C instead of USB-A. The horizontal scroll wheel on the side — which remains a blessing for navigating spreadsheets — is now more exposed and extends a little farther with each spin. The PTFE feet on the bottom are a bit larger for a smoother glide. The dedicated gesture button is no longer awkwardly integrated into the thumb rest; instead, it’s been pulled out ahead of the two programmable side buttons. Logitech says there’s a more powerful chip inside the mouse to improve connection quality. The edges around the main click buttons are now translucent: nothing major, but a bit more stylish. The screws on the bottom are now exposed, too, which Logitech says should be helpful for recycling purposes down the road. The rest is largely the same as before, which isn’t a bad thing. The best feature here is still the virtually silent main buttons, which keep a pleasing level of travel but will never bother anyone around you. Battery life is still rated at a solid 70 days, which seems about right — I haven’t charged the mouse in about a month and the Options+ app says I still have about 50 percent juice left. The design still feels super sturdy, with no flexing or creaking. The side buttons feel firm and tactile. Options+ is resource-heavy but still intuitive enough for reprogramming buttons and customizing app-specific settings. It can still track on a variety of surfaces, including glass or the fabric of my couch. You can still connect to three devices simultaneously and switch between them with a button on the bottom, too. Logitech On the downside, there’s no USB-C cable included in the box anymore, and the polling rate is still set at a basic 125Hz, which means tracking isn’t quite as buttery smooth as it could be. (Though you'd never want to use something this heavy for gaming.) The Mac version doesn’t come with a USB receiver, and there’s still no built-in storage compartment for the dongle with either model. You also need to keep Options+ open to feel the haptic feedback, which is annoying, especially if your work limits use of third-party software. Some of those complaints have been issues for a while, so it’s frustrating to see them three years later. Still, they’re probably not dealbreakers. The MX Master 4 may not be a essential upgrade if you’re happy with an older MX Master mouse, and if those didn’t work for you before, this one probably won’t work for you now. But if you’re a power user in the market for a new productivity mouse, we’d expect this newest iteration to be as popular as its predecessors.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/the-logitech-mx-master-4-comes-with-haptic-feedback-less-rubber-and-the-same-general-shape-070129482.html?src=rss",
          "content": "Editor’s note (11/10/25): After spending another month with the MX Master 4, our impressions remain largely unchanged. The new textured plastic finish and silicone thumb rest have shown no signs of wear, and we’ve continued to see no erratic behavior with the electromagnetic scroll wheel. Battery life still lines up with Logitech’s rating, while the haptic feedback and Actions Ring functionality remain useful if inessential. We’ve added an official review score to this post as a result. Our original hands-on is below. Original post (9/30/25): If you’ve shopped around for a wireless mouse at any point in the past decade, you’ve probably seen lots of people recommending a Logitech MX Master. There’s good reason for that: They aren’t cheap, but they’re usually comfortable, versatile and loaded with features designed to make working in front of a monitor all day a little less annoying. The current MX Master 3S has sat at the top of our own wireless mouse buying guide for some time now. Now, three years after releasing the 3S, Logitech is rolling out the new MX Master 4, which costs $120 and will ship in October. I’ve been able to test it out for the past few weeks. For the most part, this is an iterative update, with the same general shape, battery life, 8K DPI sensor and ultra-quiet clicks as the MX Master 3S before it. It is a touch heavier (150 grams vs. 141g), wider (3.48 inches vs 3.32 in.) and taller (5.05 inches vs. 4.92 in.) than the last model, and the main click buttons are slightly larger. But if you found the 3S or older MX Master 3 comfortable, you should have few issues here. That said, this is still a hefty mouse designed for palm grippers and right-handed users: Its gentle contours, generous hump, ample thumb rest and large buttons will fit like a glove if that describes you, but lefties and those with especially petite hands won’t agree. The flashiest change here is the addition of haptic feedback, which is built into a small panel within the mouse’s thumb rest. You can customize the intensity of this effect through Logitech’s Options+ software — or turn it off entirely — but it essentially brings a modicum of smartphone-style feedback to your desktop. When you first pair the mouse, for one, you’ll feel a little bump. The same goes if you move between devices using Logitech’s “Flow” feature. When battery is low, it’ll vibrate. If you’re trying to precisely line up a graphic in an app like Photoshop, you’ll get a little buzz when you’ve moved it to the exact right spot. Jeff Dunn for Engadget You’ll also feel it when you hover over options in the Actions Ring, a customizable overlay that presents different shortcuts depending on the app you’re using. This pops up when you click the side panel; you could use it quickly access the screenshot tool while in Chrome, for instance, or the brightness and contrast sliders in Photoshop. If all of this sounds like a gimmick, well, yeah it kind of is. It’s not the kind of thing anyone needs. But the effect is surprisingly subtle on the default “medium” setting, and there’s a level of reassurance that comes with feeling a confirmed action instead of just seeing it. I found it more pleasant than distracting. The catch is that only a few apps will natively support the MX Master 4’s haptics at launch: Photoshop, Lightroom and Zoom, with Adobe Premiere Pro to follow soon after. You’ll still be able to utilize the haptic feedback on a system level on Windows and macOS, and Logitech is releasing an SDK for more developers to integrate the functionality, but we’ll have to see how many do so. Another change is with the mouse’s coating, which trades the 3S’ rubbery finish for a lightly textured plastic around the top. (The thumb rest area and right side still use a denser rubber.) Some users have complained about older MX Master mice peeling and wearing down after extended use; time will tell how well the new model holds up, but it should avoid the same sort of sweat-induced degradation. Either way, I’ve found it smooth to the touch without being slippery. I also haven’t been able to replicate the accuracy issues some 3S buyers have had with that mouse’s electromagnetic scroll wheel, which is still made of a high-quality metal and lets you conveniently swap between a notched and free-spin scroll on the fly. Customizing the Actions Ring in Logitech's Options+ app. Logitech/Jeff Dunn for Engadget There are other minor tweaks and improvements. The receiver included with the Windows model is now USB-C instead of USB-A. The horizontal scroll wheel on the side — which remains a blessing for navigating spreadsheets — is now more exposed and extends a little farther with each spin. The PTFE feet on the bottom are a bit larger for a smoother glide. The dedicated gesture button is no longer awkwardly integrated into the thumb rest; instead, it’s been pulled out ahead of the two programmable side buttons. Logitech says there’s a more powerful chip inside the mouse to improve connection quality. The edges around the main click buttons are now translucent: nothing major, but a bit more stylish. The screws on the bottom are now exposed, too, which Logitech says should be helpful for recycling purposes down the road. The rest is largely the same as before, which isn’t a bad thing. The best feature here is still the virtually silent main buttons, which keep a pleasing level of travel but will never bother anyone around you. Battery life is still rated at a solid 70 days, which seems about right — I haven’t charged the mouse in about a month and the Options+ app says I still have about 50 percent juice left. The design still feels super sturdy, with no flexing or creaking. The side buttons feel firm and tactile. Options+ is resource-heavy but still intuitive enough for reprogramming buttons and customizing app-specific settings. It can still track on a variety of surfaces, including glass or the fabric of my couch. You can still connect to three devices simultaneously and switch between them with a button on the bottom, too. Logitech On the downside, there’s no USB-C cable included in the box anymore, and the polling rate is still set at a basic 125Hz, which means tracking isn’t quite as buttery smooth as it could be. (Though you'd never want to use something this heavy for gaming.) The Mac version doesn’t come with a USB receiver, and there’s still no built-in storage compartment for the dongle with either model. You also need to keep Options+ open to feel the haptic feedback, which is annoying, especially if your work limits use of third-party software. Some of those complaints have been issues for a while, so it’s frustrating to see them three years later. Still, they’re probably not dealbreakers. The MX Master 4 may not be a essential upgrade if you’re happy with an older MX Master mouse, and if those didn’t work for you before, this one probably won’t work for you now. But if you’re a power user in the market for a new productivity mouse, we’d expect this newest iteration to be as popular as its predecessors.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/the-logitech-mx-master-4-comes-with-haptic-feedback-less-rubber-and-the-same-general-shape-070129482.html?src=rss",
          "feed_position": 23,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2025-09/057abd00-9d5b-11f0-bffe-e1d42d429546"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/baseten-takes-on-hyperscalers-with-new-ai-training-platform-that-lets-you",
          "published_at": "Mon, 10 Nov 2025 14:00:00 GMT",
          "title": "Baseten takes on hyperscalers with new AI training platform that lets you own your model weights",
          "standfirst": "Baseten, the AI infrastructure company recently valued at $2.15 billion, is making its most significant product pivot yet: a full-scale push into model training that could reshape how enterprises wean themselves off dependence on OpenAI and other closed-source AI providers.The San Francisco-based company announced Thursday the general availability of Baseten Training, an infrastructure platform designed to help companies fine-tune open-source AI models without the operational headaches of managing GPU clusters, multi-node orchestration, or cloud capacity planning. The move is a calculated expansion beyond Baseten&#x27;s core inference business, driven by what CTO Amir Haghighat describes as relentless customer demand and a strategic imperative to capture the full lifecycle of AI deployment.\"We had a captive audience of customers who kept coming to us saying, &#x27;Hey, I hate this problem,&#x27;\" Haghighat said in an interview. \"One of them told me, &#x27;Look, I bought a bunch of H100s from a cloud provider. I have to SSH in on Friday, run my fine-tuning job, then check on Monday to see if it worked. Sometimes I realize it just hasn&#x27;t been working all along.&#x27;\"The launch comes at a critical inflection point in enterprise AI adoption. As open-source models from Meta, Alibaba, and others increasingly rival proprietary systems in performance, companies face mounting pressure to reduce their reliance on expensive API calls to services like OpenAI&#x27;s GPT-5 or Anthropic&#x27;s Claude. But the path from off-the-shelf open-source model to production-ready custom AI remains treacherous, requiring specialized expertise in machine learning operations, infrastructure management, and performance optimization.Baseten&#x27;s answer: provide the infrastructure rails while letting companies retain full control over their training code, data, and model weights. It&#x27;s a deliberately low-level approach born from hard-won lessons.How a failed product taught Baseten what AI training infrastructure really needsThis isn&#x27;t Baseten&#x27;s first foray into training. The company&#x27;s previous attempt, a product called Blueprints launched roughly two and a half years ago, failed spectacularly — a failure Haghighat now embraces as instructive.\"We had created the abstraction layer a little too high,\" he explained. \"We were trying to create a magical experience, where as a user, you come in and programmatically choose a base model, choose your data and some hyperparameters, and magically out comes a model.\"The problem? Users didn&#x27;t have the intuition to make the right choices about base models, data quality, or hyperparameters. When their models underperformed, they blamed the product. Baseten found itself in the consulting business rather than the infrastructure business, helping customers debug everything from dataset deduplication to model selection.\"We became consultants,\" Haghighat said. \"And that&#x27;s not what we had set out to do.\"Baseten killed Blueprints and refocused entirely on inference, vowing to \"earn the right\" to expand again. That moment arrived earlier this year, driven by two market realities: the vast majority of Baseten&#x27;s inference revenue comes from custom models that customers train elsewhere, and competing training platforms were using restrictive terms of service to lock customers into their inference products.\"Multiple companies who were building fine-tuning products had in their terms of service that you as a customer cannot take the weights of the fine-tuned model with you somewhere else,\" Haghighat said. \"I understand why from their perspective — I still don&#x27;t think there is a big company to be made purely on just training or fine-tuning. The sticky part is in inference, the valuable part where value is unlocked is in inference, and ultimately the revenue is in inference.\"Baseten took the opposite approach: customers own their weights and can download them at will. The bet is that superior inference performance will keep them on the platform anyway.Multi-cloud GPU orchestration and sub-minute scheduling set Baseten apart from hyperscalersThe new Baseten Training product operates at what Haghighat calls \"the infrastructure layer\" — lower-level than the failed Blueprints experiment, but with opinionated tooling around reliability, observability, and integration with Baseten&#x27;s inference stack.Key technical capabilities include multi-node training support across clusters of NVIDIA H100 or B200 GPUs, automated checkpointing to protect against node failures, sub-minute job scheduling, and integration with Baseten&#x27;s proprietary Multi-Cloud Management (MCM) system. That last piece is critical: MCM allows Baseten to dynamically provision GPU capacity across multiple cloud providers and regions, passing cost savings to customers while avoiding the capacity constraints and multi-year contracts typical of hyperscaler deals.\"With hyperscalers, you don&#x27;t get to say, &#x27;Hey, give me three or four B200 nodes while my job is running, and then take it back from me and don&#x27;t charge me for it,&#x27;\" Haghighat said. \"They say, &#x27;No, you need to sign a three-year contract.&#x27; We don&#x27;t do that.\"Baseten&#x27;s approach mirrors broader trends in cloud infrastructure, where abstraction layers increasingly allow workloads to move fluidly across providers. When AWS experienced a major outage several weeks ago, Baseten&#x27;s inference services remained operational by automatically routing traffic to other cloud providers — a capability now extended to training workloads.The technical differentiation extends to Baseten&#x27;s observability tooling, which provides per-GPU metrics for multi-node jobs, granular checkpoint tracking, and a refreshed UI that surfaces infrastructure-level events. The company also introduced an \"ML Cookbook\" of open-source training recipes for popular models like Gemma, GPT OSS, and Qwen, designed to help users reach \"training success\" faster.Early adopters report 84% cost savings and 50% latency improvements with custom modelsTwo early customers illustrate the market Baseten is targeting: AI-native companies building specialized vertical solutions that require custom models.Oxen AI, a platform focused on dataset management and model fine-tuning, exemplifies the partnership model Baseten envisions. CEO Greg Schoeninger articulated a common strategic calculus, telling VentureBeat: \"Whenever I&#x27;ve seen a platform try to do both hardware and software, they usually fail at one of them. That&#x27;s why partnering with Baseten to handle infrastructure was the obvious choice.\"Oxen built its customer experience entirely on top of Baseten&#x27;s infrastructure, using the Baseten CLI to programmatically orchestrate training jobs. The system automatically provisions and deprovisions GPUs, fully concealing Baseten&#x27;s interface behind Oxen&#x27;s own. For one Oxen customer, AlliumAI — a startup bringing structure to messy retail data — the integration delivered 84% cost savings compared to previous approaches, reducing total inference costs from $46,800 to $7,530.\"Training custom LoRAs has always been one of the most effective ways to leverage open-source models, but it often came with infrastructure headaches,\" said Daniel Demillard, CEO of AlliumAI. \"With Oxen and Baseten, that complexity disappears. We can train and deploy models at massive scale without ever worrying about CUDA, which GPU to choose, or shutting down servers after training.\"Parsed, another early customer, tackles a different pain point: helping enterprises reduce dependence on OpenAI by creating specialized models that outperform generalist LLMs on domain-specific tasks. The company works in mission-critical sectors like healthcare, finance, and legal services, where model performance and reliability aren&#x27;t negotiable.\"Prior to switching to Baseten, we were seeing repetitive and degraded performance on our fine-tuned models due to bugs with our previous training provider,\" said Charles O&#x27;Neill, Parsed&#x27;s co-founder and chief science officer. \"On top of that, we were struggling to easily download and checkpoint weights after training runs.\"With Baseten, Parsed achieved 50% lower end-to-end latency for transcription use cases, spun up HIPAA-compliant EU deployments for testing within 48 hours, and kicked off more than 500 training jobs. The company also leveraged Baseten&#x27;s modified vLLM inference framework and speculative decoding — a technique that generates draft tokens to accelerate language model output — to cut latency in half for custom models.\"Fast models matter,\" O&#x27;Neill said. \"But fast models that get better over time matter more. A model that&#x27;s 2x faster but static loses to one that&#x27;s slightly slower but improving 10% monthly. Baseten gives us both — the performance edge today and the infrastructure for continuous improvement.\"Why training and inference are more interconnected than the industry realizesThe Parsed example illuminates a deeper strategic rationale for Baseten&#x27;s training expansion: the boundary between training and inference is blurrier than conventional wisdom suggests.Baseten&#x27;s model performance team uses the training platform extensively to create \"draft models\" for speculative decoding, a cutting-edge technique that can dramatically accelerate inference. The company recently announced it achieved 650+ tokens per second on OpenAI&#x27;s GPT OSS 120B model — a 60% improvement over its launch performance — using EAGLE-3 speculative decoding, which requires training specialized small models to work alongside larger target models.\"Ultimately, inference and training plug in more ways than one might think,\" Haghighat said. \"When you do speculative decoding in inference, you need to train the draft model. Our model performance team is a big customer of the training product to train these EAGLE heads on a continuous basis.\"This technical interdependence reinforces Baseten&#x27;s thesis that owning both training and inference creates defensible value. The company can optimize the entire lifecycle: a model trained on Baseten can be deployed with a single click to inference endpoints pre-optimized for that architecture, with deployment-from-checkpoint support for chat completion and audio transcription workloads.The approach contrasts sharply with vertically integrated competitors like Replicate or Modal, which also offer training and inference but with different architectural tradeoffs. Baseten&#x27;s bet is on lower-level infrastructure flexibility and performance optimization, particularly for companies running custom models at scale.As open-source AI models improve, enterprises see fine-tuning as the path away from OpenAI dependencyUnderpinning Baseten&#x27;s entire strategy is a conviction about the trajectory of open-source AI models — namely, that they&#x27;re getting good enough, fast enough, to unlock massive enterprise adoption through fine-tuning.\"Both closed and open-source models are getting better and better in terms of quality,\" Haghighat said. \"We don&#x27;t even need open source to surpass closed models, because as both of them are getting better, they unlock all these invisible lines of usefulness for different use cases.\"He pointed to the proliferation of reinforcement learning and supervised fine-tuning techniques that allow companies to take an open-source model and make it \"as good as the closed model, not at everything, but at this narrow band of capability that they want.\"That trend is already visible in Baseten&#x27;s Model APIs business, launched alongside Training earlier this year to provide production-grade access to open-source models. The company was the first provider to offer access to DeepSeek V3 and R1, and has since added models like Llama 4 and Qwen 3, optimized for performance and reliability. Model APIs serves as a top-of-funnel product: companies start with off-the-shelf open-source models, realize they need customization, move to Training for fine-tuning, and ultimately deploy on Baseten&#x27;s Dedicated Deployments infrastructure.Yet Haghighat acknowledged the market remains \"fuzzy\" around which training techniques will dominate. Baseten is hedging by staying close to the bleeding edge through its Forward Deployed Engineering team, which works hands-on with select customers on reinforcement learning, supervised fine-tuning, and other advanced techniques.\"As we do that, we will see patterns emerge about what a productized training product can look like that really addresses the user&#x27;s needs without them having to learn too much about how RL works,\" he said. \"Are we there as an industry? I would say not quite. I see some attempts at that, but they all seem like almost falling to the same trap that Blueprints fell into—a bit of a walled garden that ties the hands of AI folks behind their back.\"The roadmap ahead includes potential abstractions for common training patterns, expansion into image, audio, and video fine-tuning, and deeper integration of advanced techniques like prefill-decode disaggregation, which separates the initial processing of prompts from token generation to improve efficiency.Baseten faces crowded field but bets developer experience and performance will win enterprise customersBaseten enters an increasingly crowded market for AI infrastructure. Hyperscalers like AWS, Google Cloud, and Microsoft Azure offer GPU compute for training, while specialized providers like Lambda Labs, CoreWeave, and Together AI compete on price, performance, or ease of use. Then there are vertically integrated platforms like Hugging Face, Replicate, and Modal that bundle training, inference, and model hosting.Baseten&#x27;s differentiation rests on three pillars: its MCM system for multi-cloud capacity management, deep performance optimization expertise built from its inference business, and a developer experience tailored for production deployments rather than experimentation.The company&#x27;s recent $150 million Series D and $2.15 billion valuation provide runway to invest in both products simultaneously. Major customers include Descript, which uses Baseten for transcription workloads; Decagon, which runs customer service AI; and Sourcegraph, which powers coding assistants. All three operate in domains where model customization and performance are competitive advantages.Timing may be Baseten&#x27;s biggest asset. The confluence of improving open-source models, enterprise discomfort with dependence on proprietary AI providers, and growing sophistication around fine-tuning techniques creates what Haghighat sees as a sustainable market shift.\"There is a lot of use cases for which closed models have gotten there and open ones have not,\" he said. \"Where I&#x27;m seeing in the market is people using different training techniques — more recently, a lot of reinforcement learning and SFT — to be able to get this open model to be as good as the closed model, not at everything, but at this narrow band of capability that they want. That&#x27;s very palpable in the market.\"For enterprises navigating the complex transition from closed to open AI models, Baseten&#x27;s positioning offers a clear value proposition: infrastructure that handles the messy middle of fine-tuning while optimizing for the ultimate goal of performant, reliable, cost-effective inference at scale. The company&#x27;s insistence that customers own their model weights — a stark contrast to competitors using training as a lock-in mechanism — reflects confidence that technical excellence, not contractual restrictions, will drive retention.Whether Baseten can execute on this vision depends on navigating tensions inherent in its strategy: staying at the infrastructure layer without becoming consultants, providing power and flexibility without overwhelming users with complexity, and building abstractions at exactly the right level as the market matures. The company&#x27;s willingness to kill Blueprints when it failed suggests a pragmatism that could prove decisive in a market where many infrastructure providers over-promise and under-deliver.\"Through and through, we&#x27;re an inference company,\" Haghighat emphasized. \"The reason that we did training is at the service of inference.\"That clarity of purpose — treating training as a means to an end rather than an end in itself—may be Baseten&#x27;s most important strategic asset. As AI deployment matures from experimentation to production, the companies that solve the full stack stand to capture outsized value. But only if they avoid the trap of technology in search of a problem.At least Baseten&#x27;s customers no longer have to SSH into boxes on Friday and pray their training jobs complete by Monday. In the infrastructure business, sometimes the best innovation is simply making the painful parts disappear.",
          "content": "Baseten, the AI infrastructure company recently valued at $2.15 billion, is making its most significant product pivot yet: a full-scale push into model training that could reshape how enterprises wean themselves off dependence on OpenAI and other closed-source AI providers.The San Francisco-based company announced Thursday the general availability of Baseten Training, an infrastructure platform designed to help companies fine-tune open-source AI models without the operational headaches of managing GPU clusters, multi-node orchestration, or cloud capacity planning. The move is a calculated expansion beyond Baseten&#x27;s core inference business, driven by what CTO Amir Haghighat describes as relentless customer demand and a strategic imperative to capture the full lifecycle of AI deployment.\"We had a captive audience of customers who kept coming to us saying, &#x27;Hey, I hate this problem,&#x27;\" Haghighat said in an interview. \"One of them told me, &#x27;Look, I bought a bunch of H100s from a cloud provider. I have to SSH in on Friday, run my fine-tuning job, then check on Monday to see if it worked. Sometimes I realize it just hasn&#x27;t been working all along.&#x27;\"The launch comes at a critical inflection point in enterprise AI adoption. As open-source models from Meta, Alibaba, and others increasingly rival proprietary systems in performance, companies face mounting pressure to reduce their reliance on expensive API calls to services like OpenAI&#x27;s GPT-5 or Anthropic&#x27;s Claude. But the path from off-the-shelf open-source model to production-ready custom AI remains treacherous, requiring specialized expertise in machine learning operations, infrastructure management, and performance optimization.Baseten&#x27;s answer: provide the infrastructure rails while letting companies retain full control over their training code, data, and model weights. It&#x27;s a deliberately low-level approach born from hard-won lessons.How a failed product taught Baseten what AI training infrastructure really needsThis isn&#x27;t Baseten&#x27;s first foray into training. The company&#x27;s previous attempt, a product called Blueprints launched roughly two and a half years ago, failed spectacularly — a failure Haghighat now embraces as instructive.\"We had created the abstraction layer a little too high,\" he explained. \"We were trying to create a magical experience, where as a user, you come in and programmatically choose a base model, choose your data and some hyperparameters, and magically out comes a model.\"The problem? Users didn&#x27;t have the intuition to make the right choices about base models, data quality, or hyperparameters. When their models underperformed, they blamed the product. Baseten found itself in the consulting business rather than the infrastructure business, helping customers debug everything from dataset deduplication to model selection.\"We became consultants,\" Haghighat said. \"And that&#x27;s not what we had set out to do.\"Baseten killed Blueprints and refocused entirely on inference, vowing to \"earn the right\" to expand again. That moment arrived earlier this year, driven by two market realities: the vast majority of Baseten&#x27;s inference revenue comes from custom models that customers train elsewhere, and competing training platforms were using restrictive terms of service to lock customers into their inference products.\"Multiple companies who were building fine-tuning products had in their terms of service that you as a customer cannot take the weights of the fine-tuned model with you somewhere else,\" Haghighat said. \"I understand why from their perspective — I still don&#x27;t think there is a big company to be made purely on just training or fine-tuning. The sticky part is in inference, the valuable part where value is unlocked is in inference, and ultimately the revenue is in inference.\"Baseten took the opposite approach: customers own their weights and can download them at will. The bet is that superior inference performance will keep them on the platform anyway.Multi-cloud GPU orchestration and sub-minute scheduling set Baseten apart from hyperscalersThe new Baseten Training product operates at what Haghighat calls \"the infrastructure layer\" — lower-level than the failed Blueprints experiment, but with opinionated tooling around reliability, observability, and integration with Baseten&#x27;s inference stack.Key technical capabilities include multi-node training support across clusters of NVIDIA H100 or B200 GPUs, automated checkpointing to protect against node failures, sub-minute job scheduling, and integration with Baseten&#x27;s proprietary Multi-Cloud Management (MCM) system. That last piece is critical: MCM allows Baseten to dynamically provision GPU capacity across multiple cloud providers and regions, passing cost savings to customers while avoiding the capacity constraints and multi-year contracts typical of hyperscaler deals.\"With hyperscalers, you don&#x27;t get to say, &#x27;Hey, give me three or four B200 nodes while my job is running, and then take it back from me and don&#x27;t charge me for it,&#x27;\" Haghighat said. \"They say, &#x27;No, you need to sign a three-year contract.&#x27; We don&#x27;t do that.\"Baseten&#x27;s approach mirrors broader trends in cloud infrastructure, where abstraction layers increasingly allow workloads to move fluidly across providers. When AWS experienced a major outage several weeks ago, Baseten&#x27;s inference services remained operational by automatically routing traffic to other cloud providers — a capability now extended to training workloads.The technical differentiation extends to Baseten&#x27;s observability tooling, which provides per-GPU metrics for multi-node jobs, granular checkpoint tracking, and a refreshed UI that surfaces infrastructure-level events. The company also introduced an \"ML Cookbook\" of open-source training recipes for popular models like Gemma, GPT OSS, and Qwen, designed to help users reach \"training success\" faster.Early adopters report 84% cost savings and 50% latency improvements with custom modelsTwo early customers illustrate the market Baseten is targeting: AI-native companies building specialized vertical solutions that require custom models.Oxen AI, a platform focused on dataset management and model fine-tuning, exemplifies the partnership model Baseten envisions. CEO Greg Schoeninger articulated a common strategic calculus, telling VentureBeat: \"Whenever I&#x27;ve seen a platform try to do both hardware and software, they usually fail at one of them. That&#x27;s why partnering with Baseten to handle infrastructure was the obvious choice.\"Oxen built its customer experience entirely on top of Baseten&#x27;s infrastructure, using the Baseten CLI to programmatically orchestrate training jobs. The system automatically provisions and deprovisions GPUs, fully concealing Baseten&#x27;s interface behind Oxen&#x27;s own. For one Oxen customer, AlliumAI — a startup bringing structure to messy retail data — the integration delivered 84% cost savings compared to previous approaches, reducing total inference costs from $46,800 to $7,530.\"Training custom LoRAs has always been one of the most effective ways to leverage open-source models, but it often came with infrastructure headaches,\" said Daniel Demillard, CEO of AlliumAI. \"With Oxen and Baseten, that complexity disappears. We can train and deploy models at massive scale without ever worrying about CUDA, which GPU to choose, or shutting down servers after training.\"Parsed, another early customer, tackles a different pain point: helping enterprises reduce dependence on OpenAI by creating specialized models that outperform generalist LLMs on domain-specific tasks. The company works in mission-critical sectors like healthcare, finance, and legal services, where model performance and reliability aren&#x27;t negotiable.\"Prior to switching to Baseten, we were seeing repetitive and degraded performance on our fine-tuned models due to bugs with our previous training provider,\" said Charles O&#x27;Neill, Parsed&#x27;s co-founder and chief science officer. \"On top of that, we were struggling to easily download and checkpoint weights after training runs.\"With Baseten, Parsed achieved 50% lower end-to-end latency for transcription use cases, spun up HIPAA-compliant EU deployments for testing within 48 hours, and kicked off more than 500 training jobs. The company also leveraged Baseten&#x27;s modified vLLM inference framework and speculative decoding — a technique that generates draft tokens to accelerate language model output — to cut latency in half for custom models.\"Fast models matter,\" O&#x27;Neill said. \"But fast models that get better over time matter more. A model that&#x27;s 2x faster but static loses to one that&#x27;s slightly slower but improving 10% monthly. Baseten gives us both — the performance edge today and the infrastructure for continuous improvement.\"Why training and inference are more interconnected than the industry realizesThe Parsed example illuminates a deeper strategic rationale for Baseten&#x27;s training expansion: the boundary between training and inference is blurrier than conventional wisdom suggests.Baseten&#x27;s model performance team uses the training platform extensively to create \"draft models\" for speculative decoding, a cutting-edge technique that can dramatically accelerate inference. The company recently announced it achieved 650+ tokens per second on OpenAI&#x27;s GPT OSS 120B model — a 60% improvement over its launch performance — using EAGLE-3 speculative decoding, which requires training specialized small models to work alongside larger target models.\"Ultimately, inference and training plug in more ways than one might think,\" Haghighat said. \"When you do speculative decoding in inference, you need to train the draft model. Our model performance team is a big customer of the training product to train these EAGLE heads on a continuous basis.\"This technical interdependence reinforces Baseten&#x27;s thesis that owning both training and inference creates defensible value. The company can optimize the entire lifecycle: a model trained on Baseten can be deployed with a single click to inference endpoints pre-optimized for that architecture, with deployment-from-checkpoint support for chat completion and audio transcription workloads.The approach contrasts sharply with vertically integrated competitors like Replicate or Modal, which also offer training and inference but with different architectural tradeoffs. Baseten&#x27;s bet is on lower-level infrastructure flexibility and performance optimization, particularly for companies running custom models at scale.As open-source AI models improve, enterprises see fine-tuning as the path away from OpenAI dependencyUnderpinning Baseten&#x27;s entire strategy is a conviction about the trajectory of open-source AI models — namely, that they&#x27;re getting good enough, fast enough, to unlock massive enterprise adoption through fine-tuning.\"Both closed and open-source models are getting better and better in terms of quality,\" Haghighat said. \"We don&#x27;t even need open source to surpass closed models, because as both of them are getting better, they unlock all these invisible lines of usefulness for different use cases.\"He pointed to the proliferation of reinforcement learning and supervised fine-tuning techniques that allow companies to take an open-source model and make it \"as good as the closed model, not at everything, but at this narrow band of capability that they want.\"That trend is already visible in Baseten&#x27;s Model APIs business, launched alongside Training earlier this year to provide production-grade access to open-source models. The company was the first provider to offer access to DeepSeek V3 and R1, and has since added models like Llama 4 and Qwen 3, optimized for performance and reliability. Model APIs serves as a top-of-funnel product: companies start with off-the-shelf open-source models, realize they need customization, move to Training for fine-tuning, and ultimately deploy on Baseten&#x27;s Dedicated Deployments infrastructure.Yet Haghighat acknowledged the market remains \"fuzzy\" around which training techniques will dominate. Baseten is hedging by staying close to the bleeding edge through its Forward Deployed Engineering team, which works hands-on with select customers on reinforcement learning, supervised fine-tuning, and other advanced techniques.\"As we do that, we will see patterns emerge about what a productized training product can look like that really addresses the user&#x27;s needs without them having to learn too much about how RL works,\" he said. \"Are we there as an industry? I would say not quite. I see some attempts at that, but they all seem like almost falling to the same trap that Blueprints fell into—a bit of a walled garden that ties the hands of AI folks behind their back.\"The roadmap ahead includes potential abstractions for common training patterns, expansion into image, audio, and video fine-tuning, and deeper integration of advanced techniques like prefill-decode disaggregation, which separates the initial processing of prompts from token generation to improve efficiency.Baseten faces crowded field but bets developer experience and performance will win enterprise customersBaseten enters an increasingly crowded market for AI infrastructure. Hyperscalers like AWS, Google Cloud, and Microsoft Azure offer GPU compute for training, while specialized providers like Lambda Labs, CoreWeave, and Together AI compete on price, performance, or ease of use. Then there are vertically integrated platforms like Hugging Face, Replicate, and Modal that bundle training, inference, and model hosting.Baseten&#x27;s differentiation rests on three pillars: its MCM system for multi-cloud capacity management, deep performance optimization expertise built from its inference business, and a developer experience tailored for production deployments rather than experimentation.The company&#x27;s recent $150 million Series D and $2.15 billion valuation provide runway to invest in both products simultaneously. Major customers include Descript, which uses Baseten for transcription workloads; Decagon, which runs customer service AI; and Sourcegraph, which powers coding assistants. All three operate in domains where model customization and performance are competitive advantages.Timing may be Baseten&#x27;s biggest asset. The confluence of improving open-source models, enterprise discomfort with dependence on proprietary AI providers, and growing sophistication around fine-tuning techniques creates what Haghighat sees as a sustainable market shift.\"There is a lot of use cases for which closed models have gotten there and open ones have not,\" he said. \"Where I&#x27;m seeing in the market is people using different training techniques — more recently, a lot of reinforcement learning and SFT — to be able to get this open model to be as good as the closed model, not at everything, but at this narrow band of capability that they want. That&#x27;s very palpable in the market.\"For enterprises navigating the complex transition from closed to open AI models, Baseten&#x27;s positioning offers a clear value proposition: infrastructure that handles the messy middle of fine-tuning while optimizing for the ultimate goal of performant, reliable, cost-effective inference at scale. The company&#x27;s insistence that customers own their model weights — a stark contrast to competitors using training as a lock-in mechanism — reflects confidence that technical excellence, not contractual restrictions, will drive retention.Whether Baseten can execute on this vision depends on navigating tensions inherent in its strategy: staying at the infrastructure layer without becoming consultants, providing power and flexibility without overwhelming users with complexity, and building abstractions at exactly the right level as the market matures. The company&#x27;s willingness to kill Blueprints when it failed suggests a pragmatism that could prove decisive in a market where many infrastructure providers over-promise and under-deliver.\"Through and through, we&#x27;re an inference company,\" Haghighat emphasized. \"The reason that we did training is at the service of inference.\"That clarity of purpose — treating training as a means to an end rather than an end in itself—may be Baseten&#x27;s most important strategic asset. As AI deployment matures from experimentation to production, the companies that solve the full stack stand to capture outsized value. But only if they avoid the trap of technology in search of a problem.At least Baseten&#x27;s customers no longer have to SSH into boxes on Friday and pray their training jobs complete by Monday. In the infrastructure business, sometimes the best innovation is simply making the painful parts disappear.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/789u1ePM0udlJqqwgxRkPd/6fd3661185f8285972d95d68249faa03/nuneybits_Vector_art_of_multi-cloud_nodes_interconnected_global_df5a72fb-1f71-4b95-8b12-94c1e8def7d6.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/wearables/apple-watch-se-3-review-good-enough-for-most-people-133000008.html",
          "published_at": "Mon, 10 Nov 2025 13:30:00 +0000",
          "title": "Apple Watch SE 3 review: Good enough for most people",
          "standfirst": "I started my review of the Apple Watch Series 11 talking about how everyone uses smartwatches differently. And based on your needs, the right Apple Watch might not be the one with the most features. The Apple Watch SE series has long been the option for parents to buy for their kids or other dependents, or people who are dipping their toe into the world of smartwatches. But with the introduction of an always-on-display (AOD), on-device Siri and faster charging, the Apple Watch SE 3 has shed most of its limitations and may well be good enough for most people. Throw in an onboard temperature sensor, support for 5G, media playback and gestures like double tap and wrist flick, and the latest Watch SE is not only a serious upgrade over its predecessor but also a compelling option for pretty much anyone. I used the SE 3 for a few weeks to see if it’s good enough to replace the Apple Watch Series 11 I regularly wear, and, setting aside some small caveats, the short answer is yes. What’s new in the Apple Watch SE 3? The most important upgrades in this generation of the entry-level smartwatch are the arrival of the always-on-display, faster charging speeds and on-device Siri. That latter addition allowed me to ask the assistant to start workouts, reply to messages or check the weather without having to deal with the tiny buttons on the cramped screen. You’ll also be able to dismiss notifications and alarms with a flick of your wrist, or use the double tap gesture to navigate the smart stack and select or confirm items onscreen. Older models of the Watch SE would not only require a connection to your iPhone to work with Siri, but those requests would also be a lot slower since the system would need to wait for the phone to deliver the answer. I also loathed how long it took for earlier Apple Watches to charge, and in my testing the Watch SE 3’s speed comes closer to more recent models like the Series 7 and newer. It still took noticeably more time to recharge than the Series 11, but it’s not slow enough to be a dealbreaker. You’ll just need to establish some sort of charging routine that allows at least a few hours for the Watch SE 3 to get back to 100 percent. An always-on-display is something I missed when I tested the Watch SE 2, because I’m the sort of gym fiend that likes to be able to quickly glance at my wrist while pumping some pushups and see exactly what my heart rate is. Without AOD, you’d need to raise your wrist or wake the screen somehow to see your stats, which is annoying if you’re in the middle of a workout or are lugging heavy weights around. The Watch SE 3 delivered basically the same experience as the Series 11 when I wore both to my resistance and HIIT (high intensity interval training) sessions, though the latter’s larger display did make it easier to read my stats. Speaking of the screen, the Watch SE 3 hasn’t gotten any brighter, with its peak of 1,000 nits being the same as the SE 2’s. But the latest SE can get as dim as 2 nits, which is very close to the Series 11’s 1 nit. You may wonder why this is worth noting, but trust me — your retinas will be grateful when you accidentally raise your wrist or get a notification in the middle of the night or are in a darkened theater. Older smartwatches were pretty disruptive in cinemas since their screens were bright enough to scorch any eyeballs that were accustomed to low-light environments. The Apple Watch Series 11 and Apple Watch SE 3 side by side on the same forearm. Cherlynn Low for Engadget Another screen-related update that isn’t immediately obvious is the Ion-X glass on the SE 3, which Apple says is four times more crack-resistant than the SE 2. I haven’t put this claim to the test, but the hardier material should help keep your smartwatch safe from more mishaps. I should also point out that the Watch SE 3 uses the same S10 processor as the Series 11, which has a four-core neural engine that should help speed up Siri and Apple Intelligence tasks. In general, I found the SE 3 snappy and responsive, and mostly as fast as the Series 11. Previous Watch SE models tended to be a bit sluggish, so it’s nice to see the SE 3 get this particular bump. The impact of most of the other improvements to the SE 3 depend on how you use a smartwatch. The new 5G support, for example, would be helpful if you get a cellular model and want to leave your phone behind while you run errands or go on walks. The wrist temperature sensor is mostly there to help with predicting cycles, so if you don’t ovulate it is unlikely to be useful to you right now. Sleep apnea notifications don’t affect non-sufferers, though they’re a nice feature to have. And finally, though I appreciate the ability to play songs of media through the watch’s onboard speaker, I rarely find myself wanting to do so. It might be worth noting that the SE 3 comes in one fewer color option than the SE 2. You can only choose between starlight (a warm light gray) or midnight (black), as the silver version is not available in the latest generation. Apple Watch Series 11 vs the Watch SE 3 The main thing I wanted to determine when reviewing the Watch SE 3 was whether it’s good enough to replace the Series 11. Like I said earlier, the short answer is yes, but it depends on how you use these devices. I don’t wear smartwatches to bed, and as a result my Watch SE 3 still has plenty of power left in the morning when I need it, so I’m a lot less affected by its relatively slower charging speeds. If you use your Apple Watch all the time, you might find something that recharges faster a lot more suitable — the Series 10 or 11 are both better on that front. The Apple Watch Series 11 and Apple Watch SE 3 side by side on the same forearm, with the same photo watch face on their screens. Cherlynn Low for Engadget The Series 11’s larger screen and smaller bezels makes it a lot nicer to look at, though since the SE 3 also runs watchOS 26, I was able to use the same watch faces for both. Aesthetically, I didn’t find the two to be very far apart in terms of appearances, and if you’re not familiar with the latest Apple Watches like I am, you might not find the bezels as unsightly as I did. And though the SE 3 uses a flat OLED compared to the Series 11’s wide-angle OLED, I never really had an issue reading it, regardless of the position. Thanks to their electrical heart rate sensors, the Series 11 and Series 10 support Apple’s newer health-centric features like hypertension alerts, as well as apps for ECG and blood oxygen readings. The SE 3’s optical sensor is older and doesn’t have those capabilities, but you’ll still get notifications for irregular rhythms, low cardio fitness, as well as high and low heart rate notifications. Those were more than enough for me, and though I occasionally run an ECG reading on my Series 11, it’s not something I’d miss (especially if a $150 difference in price were in the balance). I’m also not a big swimmer or underwater enthusiast, so the SE 3’s lack of a depth gauge and water temperature sensor don’t bother me. All three watches I’ve mentioned in this section are water resistant to 50 meters, and that’s more than enough for my needs. If you want your watch to help with your underwater activities, it’s probably worth splurging on the Series 10 or 11. The pricier watches are also certified IP6x for dust resistance, meaning they should offer a bit more peace of mind for those who work on beaches or on job sites, for example. I’ve not yet encountered a smartwatch that stopped working due to dust ingress, regardless of whether it was rated, so the SE 3 not having this certification doesn’t bother me either. One thing that the most discerning tech fans might call out is the fact that the SE 3 doesn’t have the same ultra wideband (UWB) chip that the Series 10 and 11 do. This enables the greater precision in Find My that allows you to locate your iPhone or wearable down to the number of feet. But you’ll still get basic Find My support on the Watch SE 3, and honestly all I really did with this was to use my watch to ring my phone so I could confirm it was with me without having to dig through all the pockets in my gigantic purse. Still, if you use this Find My interface a lot, it’s worth considering when getting your next Apple Watch. Finally, if you’re a fan of the titanium finish or multiple color options in Apple’s more-premium lineup, only the Series 10 and 11 come in the silver and rose gold colors for the aluminum case. The Series 11 is also available in Space Gray in aluminum, as well as Slate, Gold and Natural hues for the titanium finish. Again, the SE 3 is only available in two colors. Using the Apple Watch SE 3 as a Series 11 wearer I’m the sort of person who straps on my smartwatch when I head out and removes it when I get home. When I’m outside, I expect my Apple Watch to track my steps and activity, automatically detect and log extended walks, tell me when someone’s calling or texting and keep tabs on my workouts. For all those situations, the SE 3 was more than adequate. Occasionally I noticed it was a bit slower than the Series 11 at recognizing when I was done working out and suggesting I end the session, but not at a frequency that was concerning. The SE 3 was also as capable as the Series 11 when it came to acting as a remote viewfinder for my iPhone’s camera, and Siri was satisfyingly responsive at launching my workouts or telling me about the weather. I also enjoyed having the double tap and wrist flick gestures at my disposal, and honestly kind of liked the watch’s smaller size. But I did miss the Series 11’s brighter screen and smaller bezels. I also prefer the Series 11 for its ability to recharge more quickly, as well as its slightly longer-lasting battery. Both still were able to make it through an entire day before needing a charge, but the Series 11 generally did more in the background in that amount of time. In the end, it wasn’t the features like blood oxygen readings or hypertension notifications that I wanted back. It boiled down to physical components like a brighter display or bigger battery and more durable case that I wanted around for peace of mind. Wrap-up Is peace of mind worth a $150 premium? In this economy, it’s hard to say. On one hand, it’s possible a $399 Apple Watch will outlast the $249 SE 3, mostly due to its harder materials, making it a more astute investment in the long run. But for those who currently have tight budgets and need to replace aging or broken smartwatches, the SE 3 is the way to go. This article originally appeared on Engadget at https://www.engadget.com/wearables/apple-watch-se-3-review-good-enough-for-most-people-133000008.html?src=rss",
          "content": "I started my review of the Apple Watch Series 11 talking about how everyone uses smartwatches differently. And based on your needs, the right Apple Watch might not be the one with the most features. The Apple Watch SE series has long been the option for parents to buy for their kids or other dependents, or people who are dipping their toe into the world of smartwatches. But with the introduction of an always-on-display (AOD), on-device Siri and faster charging, the Apple Watch SE 3 has shed most of its limitations and may well be good enough for most people. Throw in an onboard temperature sensor, support for 5G, media playback and gestures like double tap and wrist flick, and the latest Watch SE is not only a serious upgrade over its predecessor but also a compelling option for pretty much anyone. I used the SE 3 for a few weeks to see if it’s good enough to replace the Apple Watch Series 11 I regularly wear, and, setting aside some small caveats, the short answer is yes. What’s new in the Apple Watch SE 3? The most important upgrades in this generation of the entry-level smartwatch are the arrival of the always-on-display, faster charging speeds and on-device Siri. That latter addition allowed me to ask the assistant to start workouts, reply to messages or check the weather without having to deal with the tiny buttons on the cramped screen. You’ll also be able to dismiss notifications and alarms with a flick of your wrist, or use the double tap gesture to navigate the smart stack and select or confirm items onscreen. Older models of the Watch SE would not only require a connection to your iPhone to work with Siri, but those requests would also be a lot slower since the system would need to wait for the phone to deliver the answer. I also loathed how long it took for earlier Apple Watches to charge, and in my testing the Watch SE 3’s speed comes closer to more recent models like the Series 7 and newer. It still took noticeably more time to recharge than the Series 11, but it’s not slow enough to be a dealbreaker. You’ll just need to establish some sort of charging routine that allows at least a few hours for the Watch SE 3 to get back to 100 percent. An always-on-display is something I missed when I tested the Watch SE 2, because I’m the sort of gym fiend that likes to be able to quickly glance at my wrist while pumping some pushups and see exactly what my heart rate is. Without AOD, you’d need to raise your wrist or wake the screen somehow to see your stats, which is annoying if you’re in the middle of a workout or are lugging heavy weights around. The Watch SE 3 delivered basically the same experience as the Series 11 when I wore both to my resistance and HIIT (high intensity interval training) sessions, though the latter’s larger display did make it easier to read my stats. Speaking of the screen, the Watch SE 3 hasn’t gotten any brighter, with its peak of 1,000 nits being the same as the SE 2’s. But the latest SE can get as dim as 2 nits, which is very close to the Series 11’s 1 nit. You may wonder why this is worth noting, but trust me — your retinas will be grateful when you accidentally raise your wrist or get a notification in the middle of the night or are in a darkened theater. Older smartwatches were pretty disruptive in cinemas since their screens were bright enough to scorch any eyeballs that were accustomed to low-light environments. The Apple Watch Series 11 and Apple Watch SE 3 side by side on the same forearm. Cherlynn Low for Engadget Another screen-related update that isn’t immediately obvious is the Ion-X glass on the SE 3, which Apple says is four times more crack-resistant than the SE 2. I haven’t put this claim to the test, but the hardier material should help keep your smartwatch safe from more mishaps. I should also point out that the Watch SE 3 uses the same S10 processor as the Series 11, which has a four-core neural engine that should help speed up Siri and Apple Intelligence tasks. In general, I found the SE 3 snappy and responsive, and mostly as fast as the Series 11. Previous Watch SE models tended to be a bit sluggish, so it’s nice to see the SE 3 get this particular bump. The impact of most of the other improvements to the SE 3 depend on how you use a smartwatch. The new 5G support, for example, would be helpful if you get a cellular model and want to leave your phone behind while you run errands or go on walks. The wrist temperature sensor is mostly there to help with predicting cycles, so if you don’t ovulate it is unlikely to be useful to you right now. Sleep apnea notifications don’t affect non-sufferers, though they’re a nice feature to have. And finally, though I appreciate the ability to play songs of media through the watch’s onboard speaker, I rarely find myself wanting to do so. It might be worth noting that the SE 3 comes in one fewer color option than the SE 2. You can only choose between starlight (a warm light gray) or midnight (black), as the silver version is not available in the latest generation. Apple Watch Series 11 vs the Watch SE 3 The main thing I wanted to determine when reviewing the Watch SE 3 was whether it’s good enough to replace the Series 11. Like I said earlier, the short answer is yes, but it depends on how you use these devices. I don’t wear smartwatches to bed, and as a result my Watch SE 3 still has plenty of power left in the morning when I need it, so I’m a lot less affected by its relatively slower charging speeds. If you use your Apple Watch all the time, you might find something that recharges faster a lot more suitable — the Series 10 or 11 are both better on that front. The Apple Watch Series 11 and Apple Watch SE 3 side by side on the same forearm, with the same photo watch face on their screens. Cherlynn Low for Engadget The Series 11’s larger screen and smaller bezels makes it a lot nicer to look at, though since the SE 3 also runs watchOS 26, I was able to use the same watch faces for both. Aesthetically, I didn’t find the two to be very far apart in terms of appearances, and if you’re not familiar with the latest Apple Watches like I am, you might not find the bezels as unsightly as I did. And though the SE 3 uses a flat OLED compared to the Series 11’s wide-angle OLED, I never really had an issue reading it, regardless of the position. Thanks to their electrical heart rate sensors, the Series 11 and Series 10 support Apple’s newer health-centric features like hypertension alerts, as well as apps for ECG and blood oxygen readings. The SE 3’s optical sensor is older and doesn’t have those capabilities, but you’ll still get notifications for irregular rhythms, low cardio fitness, as well as high and low heart rate notifications. Those were more than enough for me, and though I occasionally run an ECG reading on my Series 11, it’s not something I’d miss (especially if a $150 difference in price were in the balance). I’m also not a big swimmer or underwater enthusiast, so the SE 3’s lack of a depth gauge and water temperature sensor don’t bother me. All three watches I’ve mentioned in this section are water resistant to 50 meters, and that’s more than enough for my needs. If you want your watch to help with your underwater activities, it’s probably worth splurging on the Series 10 or 11. The pricier watches are also certified IP6x for dust resistance, meaning they should offer a bit more peace of mind for those who work on beaches or on job sites, for example. I’ve not yet encountered a smartwatch that stopped working due to dust ingress, regardless of whether it was rated, so the SE 3 not having this certification doesn’t bother me either. One thing that the most discerning tech fans might call out is the fact that the SE 3 doesn’t have the same ultra wideband (UWB) chip that the Series 10 and 11 do. This enables the greater precision in Find My that allows you to locate your iPhone or wearable down to the number of feet. But you’ll still get basic Find My support on the Watch SE 3, and honestly all I really did with this was to use my watch to ring my phone so I could confirm it was with me without having to dig through all the pockets in my gigantic purse. Still, if you use this Find My interface a lot, it’s worth considering when getting your next Apple Watch. Finally, if you’re a fan of the titanium finish or multiple color options in Apple’s more-premium lineup, only the Series 10 and 11 come in the silver and rose gold colors for the aluminum case. The Series 11 is also available in Space Gray in aluminum, as well as Slate, Gold and Natural hues for the titanium finish. Again, the SE 3 is only available in two colors. Using the Apple Watch SE 3 as a Series 11 wearer I’m the sort of person who straps on my smartwatch when I head out and removes it when I get home. When I’m outside, I expect my Apple Watch to track my steps and activity, automatically detect and log extended walks, tell me when someone’s calling or texting and keep tabs on my workouts. For all those situations, the SE 3 was more than adequate. Occasionally I noticed it was a bit slower than the Series 11 at recognizing when I was done working out and suggesting I end the session, but not at a frequency that was concerning. The SE 3 was also as capable as the Series 11 when it came to acting as a remote viewfinder for my iPhone’s camera, and Siri was satisfyingly responsive at launching my workouts or telling me about the weather. I also enjoyed having the double tap and wrist flick gestures at my disposal, and honestly kind of liked the watch’s smaller size. But I did miss the Series 11’s brighter screen and smaller bezels. I also prefer the Series 11 for its ability to recharge more quickly, as well as its slightly longer-lasting battery. Both still were able to make it through an entire day before needing a charge, but the Series 11 generally did more in the background in that amount of time. In the end, it wasn’t the features like blood oxygen readings or hypertension notifications that I wanted back. It boiled down to physical components like a brighter display or bigger battery and more durable case that I wanted around for peace of mind. Wrap-up Is peace of mind worth a $150 premium? In this economy, it’s hard to say. On one hand, it’s possible a $399 Apple Watch will outlast the $249 SE 3, mostly due to its harder materials, making it a more astute investment in the long run. But for those who currently have tight budgets and need to replace aging or broken smartwatches, the SE 3 is the way to go. This article originally appeared on Engadget at https://www.engadget.com/wearables/apple-watch-se-3-review-good-enough-for-most-people-133000008.html?src=rss",
          "feed_position": 27,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/apple-watch-series-11-vs-se-3.JPG"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/the-best-christmas-gifts-to-give-everyone-on-your-2025-holiday-shopping-list-170018456.html",
          "published_at": "Mon, 10 Nov 2025 13:00:37 +0000",
          "title": "The best Christmas gifts to give everyone on your 2025 holiday shopping list",
          "standfirst": "This time of year has a lot of merry and bright things to be excited about, but it can be stressful if you’re stumped on what to get your mom, dad, best friend, coworker or kids’ teacher as a holiday gift. Whether you enjoy or dread buying gifts for people, it’s safe to say we all want to give our loved ones things they will enjoy and appreciate. But there’s a lot of noise, junk and bad deals disguised as good deals to sift through as we get closer and closer to the holidays.Allow us at Engadget to help you through it. Here, you’ll find all of our holiday gift guides collected in one place, so you can more easily find the best Christmas gifts you need this year. Are you looking for white elephant gift ideas? Are you struggling to come up with a good gift for the father figure in your life? Are you just looking for a good board game to pick up for your own family? We’ve got you covered with gift ideas for all of those scenarios and more. Check back here throughout the season as we add more of our gift guides to the list. Best tech gifts and gadgets Trying to find the right gift for an unabashed gadget lover during the holidays can be difficult, especially if you don’t keep up with tech industry news yourself. Fortunately, you’re reading Engadget.com, a site entirely staffed by people who spend all day figuring out what new stuff is and isn’t actually good. So allow us to help. We’ve rounded up some of our favorite gadgets and gear that just might satisfy the avid geek in your life. Read more: The best tech gifts and gadgets Best board game gifts We could all use more time away from screens of all types and sizes, and board games are a fun way to do that and bond with friends and family. You can find plenty of unique sets out there now, from word puzzles to whodunnits to calming playthroughs that showcase the beauty of the little things in life. From games with giant monsters to those with haunted mansions, we’re sure at least one of our suggestions will be a hit with you and your loved ones. Read more: The best board games to gift this season Best gifts under $50 We wouldn’t blame you if you try to do all of your tech shopping around the holidays. That’s when you can typically get the best sales, both on relatively affordable gear and (more importantly) on big-ticket items. But it would be wrong to think that only the most expensive tech is worth gifting. Since we at Engadget test a plethora of gadgets every year, we know that there are some hidden (and not so hidden) tech gems at lower price ranges — you just have to know where to find them. Read more: The best gifts under $50 that make great stocking stuffers Best gifts for remote workers There's a pretty good chance you know at least one person who works remotely in some fashion. While the WFH life has its perks — nobody likes a long commute — it comes with its own set of challenges, from lacking pro-level equipment to dealing with household disturbances. If you’re looking to give a gift to someone who spends much of their time in their home office, we’ve rounded up a few techy gift ideas that should make their days a little more delightful, or at least easier to manage. Read more: The best gift ideas for the remote worker in your life Best white elephant gift ideas According to legend, the King of Siam would give a white elephant to courtiers who had upset them. The recipient had no choice but to simply thank the king for such an opulent gift, knowing that they likely could not afford the upkeep for such an animal. It would inevitably lead them to financial ruin. This story is almost certainly untrue, but it has led to a modern holiday staple: the white elephant gift exchange. These gift ideas will not only get you a few chuckles, but will also make your recipient feel (slightly) burdened. Read more: The best white elephant gift ideas Check out the rest of our gift ideas here.This article originally appeared on Engadget at https://www.engadget.com/the-best-christmas-gifts-to-give-everyone-on-your-2025-holiday-shopping-list-170018456.html?src=rss",
          "content": "This time of year has a lot of merry and bright things to be excited about, but it can be stressful if you’re stumped on what to get your mom, dad, best friend, coworker or kids’ teacher as a holiday gift. Whether you enjoy or dread buying gifts for people, it’s safe to say we all want to give our loved ones things they will enjoy and appreciate. But there’s a lot of noise, junk and bad deals disguised as good deals to sift through as we get closer and closer to the holidays.Allow us at Engadget to help you through it. Here, you’ll find all of our holiday gift guides collected in one place, so you can more easily find the best Christmas gifts you need this year. Are you looking for white elephant gift ideas? Are you struggling to come up with a good gift for the father figure in your life? Are you just looking for a good board game to pick up for your own family? We’ve got you covered with gift ideas for all of those scenarios and more. Check back here throughout the season as we add more of our gift guides to the list. Best tech gifts and gadgets Trying to find the right gift for an unabashed gadget lover during the holidays can be difficult, especially if you don’t keep up with tech industry news yourself. Fortunately, you’re reading Engadget.com, a site entirely staffed by people who spend all day figuring out what new stuff is and isn’t actually good. So allow us to help. We’ve rounded up some of our favorite gadgets and gear that just might satisfy the avid geek in your life. Read more: The best tech gifts and gadgets Best board game gifts We could all use more time away from screens of all types and sizes, and board games are a fun way to do that and bond with friends and family. You can find plenty of unique sets out there now, from word puzzles to whodunnits to calming playthroughs that showcase the beauty of the little things in life. From games with giant monsters to those with haunted mansions, we’re sure at least one of our suggestions will be a hit with you and your loved ones. Read more: The best board games to gift this season Best gifts under $50 We wouldn’t blame you if you try to do all of your tech shopping around the holidays. That’s when you can typically get the best sales, both on relatively affordable gear and (more importantly) on big-ticket items. But it would be wrong to think that only the most expensive tech is worth gifting. Since we at Engadget test a plethora of gadgets every year, we know that there are some hidden (and not so hidden) tech gems at lower price ranges — you just have to know where to find them. Read more: The best gifts under $50 that make great stocking stuffers Best gifts for remote workers There's a pretty good chance you know at least one person who works remotely in some fashion. While the WFH life has its perks — nobody likes a long commute — it comes with its own set of challenges, from lacking pro-level equipment to dealing with household disturbances. If you’re looking to give a gift to someone who spends much of their time in their home office, we’ve rounded up a few techy gift ideas that should make their days a little more delightful, or at least easier to manage. Read more: The best gift ideas for the remote worker in your life Best white elephant gift ideas According to legend, the King of Siam would give a white elephant to courtiers who had upset them. The recipient had no choice but to simply thank the king for such an opulent gift, knowing that they likely could not afford the upkeep for such an animal. It would inevitably lead them to financial ruin. This story is almost certainly untrue, but it has led to a modern holiday staple: the white elephant gift exchange. These gift ideas will not only get you a few chuckles, but will also make your recipient feel (slightly) burdened. Read more: The best white elephant gift ideas Check out the rest of our gift ideas here.This article originally appeared on Engadget at https://www.engadget.com/the-best-christmas-gifts-to-give-everyone-on-your-2025-holiday-shopping-list-170018456.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/best-record-player-120000239.html",
          "published_at": "Mon, 10 Nov 2025 12:00:00 +0000",
          "title": "The best record players for 2025",
          "standfirst": "Everyone knows by now that vinyl is back. The classic format has seen a resurgence for years at this point, and new albums these days almost always include a vinyl preorder. If you’ve finally decided to embark on the hobby, or if you’re looking to upgrade your current setup, we’ve compiled a list of the best turntables you can buy for under $600. Obviously, there are some very good, very popular options out there for around $1,000, but we had to start somewhere, and we had to narrow down the options a bit. Plus, there’s no reason for novices or even experienced spinners to spend that much to get a decent deck. Best record players for 2025 Other record players we tested Audio-Technica AT-LP60XBT This is about as basic as it gets, unless you opt for the AT-LP60X which ditches the Bluetooth connectivity. This is a perfectly decent option for someone just getting into vinyl, but if you spend a little more for the AT-LP70X, you won’t be in quite as big of a hurry to upgrade once you surrender to the obsession. Cambridge Audio Alva ST The Alva ST has a refined design that made me want to keep it out in my living room longer than many of the models on this list. The controls are limited on the top to power and individual options for 33 and 45 RPM speeds. Everything else is on the back panel, including Bluetooth pairing and preamp buttons. To complete the look, Cambridge Audio opted for a 1mm aluminium top plate, which sits on an MDF plinth with a layer of EVA to absorb vibrations in between. While the overall audio performance on the Alva ST is warm and inviting, there is a lack of detail across genres. I’ve noticed albums don’t have a particularly wide soundstage, and songs lack their normal punch at times, so some sound compressed compared to when they’re played on other turntables. Additionally, the free swinging tone arm needs more resistance so it’s not so prone to dropping on a record immediately if it slips out of your fingers when you have the cueing lever down. Since this turntable is fully manual operation, I felt a bit of peril every time I went to lower the needle. (The price increased during testing for this guide.) Denon DP-300F Denon’s DP-300F is a mixed bag. On one hand, you get the convenience of fully automatic operation, dedicated speed and record size buttons and somewhat refined design. There are also some confounding decisions though, like the permanently affixed cables, the preamp switch being under the platter and the overall midrange build quality for a $500 turntable. The sound from the preamp and Denon’s cartridge has a clear lack of depth and detail that almost any model at this price should offer. How to shop for a turntable The first question you’ll need to ask yourself when looking for a turntable is how you plan to use it. Are you into vinyl for the ritual? If you simply like the concept of physical media, having to flip a record to finish it or the need to intentionally swap out an album when it’s done, that’s just fine. You probably can make do with a more affordable turntable since overall sound quality may not be a main concern. If you crave the warmth of analog sound, and you want the collection you’ve invested in to sound its best, you’ll need to consider something with better specs. You’ll also need to account for where and how you’re going to listen to vinyl. Are you planning to connect this turntable to headphones or Bluetooth speakers? Do you have shelf or tower speakers you’re going to use? Are you willing to invest in a dedicated preamp or would you rather a new turntable come with one built in? All of these questions will impact your buying decision — even the Bluetooth codecs, if you’re going the wireless route. Best record players Billy Steele for Engadget Automatic, semi-auto and manual operation If you’re just getting into vinyl, an automatic turntable will save you a lot of stress. These are the models that place the stylus for you — all you have to do is push a button. When you get to the end of the record, the turntable will also return the tonearm to its resting spot automatically. Or, if you need to stop your session mid-side, there’s a button for that too. Some turntables have semi-automatic operation. Maybe they can’t place the needle for you, but they do have an automatic stop when a side of a record is complete. This auto stop, which sometimes comes with an on/off switch, can prevent unnecessary wear on your stylus and vinyl. Plus, many turntables with automatic operation allow you to take control if you need to drop the stylus in a certain place (that’s not the beginning of the record) or if you have a die-cut vinyl (like the It's the Great Pumpkin, Charlie Brown soundtrack). Then there’s the fully manual option. Here, you’re solely responsible for placing the tonearm and taking it off when the music stops. A lot of turntables have a cue lever to assist with the process, and a lot of tonearms have a mechanism that lowers them slowly rather than violently dropping them on a record. This adds one more step to the ritual, and it’s one many purists prefer. Preamp The biggest decision you’ll need to make in terms of a preamp is to decide if you want one built into your turntable or if you’d rather use a separate one. It can be very convenient, especially for beginners, to use a built-in component to amplify the signal from the turntable before it hits any speakers or headphones. The downside is that you’re left with what the company provides from the factory, so if you’re looking to upgrade, you’ll have to disable the preamp inside. On most turntables, there’s a switch that allows you to do this, so it’s no trouble. But, opting to skip the preamp on some models could save you money that could be invested elsewhere. A dedicated preamp typically uses higher-quality components and reduces noise by keeping internal parts properly separated. More robust models may even provide controls for things like tone or multiple inputs, while the basic options will simply allow you to plug in, play and forget it. If you’re after the best possible clarity and realism from your record collection, we’d recommend a dedicated preamp right from the start. Best record players Billy Steele for Engadget Removable cartridge/headshell The next item you’ll want to consider is if the turntable you’re eyeing can be upgraded in the future. The best way to do this is by swapping out the cartridge. Most turntables allow you to do this but there are some that don’t, so you’ll need to pay attention to this detail. Upgrading the cartridge down the road is a great way to improve overall sound quality without having to buy a new turntable, new speakers or a new amp. Belt drive vs. direct drive There are two main types of turntables: belt drive and direct drive. All of the models we tested for this guide are belt drive, which means there’s a thin belt that connects the platter to the motor to make the thing spin. Direct drive turntables are widely used by DJs and Technics was the first to make them. Here, the motor is directly under the platter and connected to it directly so the setup is less prone to wearing out. This is especially key when you’re doing things like scratching. Direct-drive turntables tend to be more expensive than their belt-driven counterparts. Counterweight and anti-skate control Most turntables will include a counterweight on the tonearm and some form of anti-skate control. Both of these help keep the stylus in place with the correct amount of pressure, all to ensure proper operation with minimal wear on your records. Sometimes the anti-skate elements are built into the tonearm while other models offer a dedicated dial on the surface of the plinth. The ability to adjust both of these can help you fine-tune the performance of your turntable over time, which may be necessary after upgrading the cartridge or other components. Other components to consider Some final items you’ll want to evaluate on a prospective turntable purchase include the materials used for the base (plinth), platter and even the feet. Cheaper turntables may be mostly plastic affairs while more expensive models can use solid MDF (medium-density fibreboard) for the plinth. A lot of turntables have aluminum platters with a felt pad while others may feature a thick acrylic version. And while entry-level turntables may have small, plastic feet, premium models come with larger, adjustable, rubberized feet for better vibration isolation. While some of these come down to personal preference — a frosted acrylic platter looks really nice — there are some performance boosts to be gained depending on how the company uses the components. How we test turntables Since most turntables under $600 meet the criteria for entry-level through midrange, we tested every model with a set of Audio-Technica AT-SP3X powered speakers. These offer balanced sound for turntables with a 1.1-inch tweeter and 3-inch woofer in each unit. And at $269, they won’t break the bank if you need speakers for your new turntable and they’ll provide ample sound performance even if you spend more than our budget on a new deck. For all of our test units that didn’t have a built-in preamp, we used the Fluance PA-10. At $100, it’s an affordable upgrade if you’re looking to bypass a turntable’s included components or if you’re looking to go more analog with your turntable purchase. There are no buttons or controls, just connect your turntable, speakers and ground wire (if you’re using one) and you’re ready to go. It’s simple, straightforward and inexpensive, so it’s a great option for beginners and more experienced vinyl collectors alike. In terms of performance testing, we play a variety of genres on each turntable to evaluate sound quality. We also carefully examine the overall experience of putting a record on, setting the speed, placing the tonearm and more, which allows us to judge how well each turntable will work for users at different experience levels. Lastly, we take notes on design and components, comparing those elements from each turntable with our other test subjects to make our recommendations. This article originally appeared on Engadget at https://www.engadget.com/audio/best-record-player-120000239.html?src=rss",
          "content": "Everyone knows by now that vinyl is back. The classic format has seen a resurgence for years at this point, and new albums these days almost always include a vinyl preorder. If you’ve finally decided to embark on the hobby, or if you’re looking to upgrade your current setup, we’ve compiled a list of the best turntables you can buy for under $600. Obviously, there are some very good, very popular options out there for around $1,000, but we had to start somewhere, and we had to narrow down the options a bit. Plus, there’s no reason for novices or even experienced spinners to spend that much to get a decent deck. Best record players for 2025 Other record players we tested Audio-Technica AT-LP60XBT This is about as basic as it gets, unless you opt for the AT-LP60X which ditches the Bluetooth connectivity. This is a perfectly decent option for someone just getting into vinyl, but if you spend a little more for the AT-LP70X, you won’t be in quite as big of a hurry to upgrade once you surrender to the obsession. Cambridge Audio Alva ST The Alva ST has a refined design that made me want to keep it out in my living room longer than many of the models on this list. The controls are limited on the top to power and individual options for 33 and 45 RPM speeds. Everything else is on the back panel, including Bluetooth pairing and preamp buttons. To complete the look, Cambridge Audio opted for a 1mm aluminium top plate, which sits on an MDF plinth with a layer of EVA to absorb vibrations in between. While the overall audio performance on the Alva ST is warm and inviting, there is a lack of detail across genres. I’ve noticed albums don’t have a particularly wide soundstage, and songs lack their normal punch at times, so some sound compressed compared to when they’re played on other turntables. Additionally, the free swinging tone arm needs more resistance so it’s not so prone to dropping on a record immediately if it slips out of your fingers when you have the cueing lever down. Since this turntable is fully manual operation, I felt a bit of peril every time I went to lower the needle. (The price increased during testing for this guide.) Denon DP-300F Denon’s DP-300F is a mixed bag. On one hand, you get the convenience of fully automatic operation, dedicated speed and record size buttons and somewhat refined design. There are also some confounding decisions though, like the permanently affixed cables, the preamp switch being under the platter and the overall midrange build quality for a $500 turntable. The sound from the preamp and Denon’s cartridge has a clear lack of depth and detail that almost any model at this price should offer. How to shop for a turntable The first question you’ll need to ask yourself when looking for a turntable is how you plan to use it. Are you into vinyl for the ritual? If you simply like the concept of physical media, having to flip a record to finish it or the need to intentionally swap out an album when it’s done, that’s just fine. You probably can make do with a more affordable turntable since overall sound quality may not be a main concern. If you crave the warmth of analog sound, and you want the collection you’ve invested in to sound its best, you’ll need to consider something with better specs. You’ll also need to account for where and how you’re going to listen to vinyl. Are you planning to connect this turntable to headphones or Bluetooth speakers? Do you have shelf or tower speakers you’re going to use? Are you willing to invest in a dedicated preamp or would you rather a new turntable come with one built in? All of these questions will impact your buying decision — even the Bluetooth codecs, if you’re going the wireless route. Best record players Billy Steele for Engadget Automatic, semi-auto and manual operation If you’re just getting into vinyl, an automatic turntable will save you a lot of stress. These are the models that place the stylus for you — all you have to do is push a button. When you get to the end of the record, the turntable will also return the tonearm to its resting spot automatically. Or, if you need to stop your session mid-side, there’s a button for that too. Some turntables have semi-automatic operation. Maybe they can’t place the needle for you, but they do have an automatic stop when a side of a record is complete. This auto stop, which sometimes comes with an on/off switch, can prevent unnecessary wear on your stylus and vinyl. Plus, many turntables with automatic operation allow you to take control if you need to drop the stylus in a certain place (that’s not the beginning of the record) or if you have a die-cut vinyl (like the It's the Great Pumpkin, Charlie Brown soundtrack). Then there’s the fully manual option. Here, you’re solely responsible for placing the tonearm and taking it off when the music stops. A lot of turntables have a cue lever to assist with the process, and a lot of tonearms have a mechanism that lowers them slowly rather than violently dropping them on a record. This adds one more step to the ritual, and it’s one many purists prefer. Preamp The biggest decision you’ll need to make in terms of a preamp is to decide if you want one built into your turntable or if you’d rather use a separate one. It can be very convenient, especially for beginners, to use a built-in component to amplify the signal from the turntable before it hits any speakers or headphones. The downside is that you’re left with what the company provides from the factory, so if you’re looking to upgrade, you’ll have to disable the preamp inside. On most turntables, there’s a switch that allows you to do this, so it’s no trouble. But, opting to skip the preamp on some models could save you money that could be invested elsewhere. A dedicated preamp typically uses higher-quality components and reduces noise by keeping internal parts properly separated. More robust models may even provide controls for things like tone or multiple inputs, while the basic options will simply allow you to plug in, play and forget it. If you’re after the best possible clarity and realism from your record collection, we’d recommend a dedicated preamp right from the start. Best record players Billy Steele for Engadget Removable cartridge/headshell The next item you’ll want to consider is if the turntable you’re eyeing can be upgraded in the future. The best way to do this is by swapping out the cartridge. Most turntables allow you to do this but there are some that don’t, so you’ll need to pay attention to this detail. Upgrading the cartridge down the road is a great way to improve overall sound quality without having to buy a new turntable, new speakers or a new amp. Belt drive vs. direct drive There are two main types of turntables: belt drive and direct drive. All of the models we tested for this guide are belt drive, which means there’s a thin belt that connects the platter to the motor to make the thing spin. Direct drive turntables are widely used by DJs and Technics was the first to make them. Here, the motor is directly under the platter and connected to it directly so the setup is less prone to wearing out. This is especially key when you’re doing things like scratching. Direct-drive turntables tend to be more expensive than their belt-driven counterparts. Counterweight and anti-skate control Most turntables will include a counterweight on the tonearm and some form of anti-skate control. Both of these help keep the stylus in place with the correct amount of pressure, all to ensure proper operation with minimal wear on your records. Sometimes the anti-skate elements are built into the tonearm while other models offer a dedicated dial on the surface of the plinth. The ability to adjust both of these can help you fine-tune the performance of your turntable over time, which may be necessary after upgrading the cartridge or other components. Other components to consider Some final items you’ll want to evaluate on a prospective turntable purchase include the materials used for the base (plinth), platter and even the feet. Cheaper turntables may be mostly plastic affairs while more expensive models can use solid MDF (medium-density fibreboard) for the plinth. A lot of turntables have aluminum platters with a felt pad while others may feature a thick acrylic version. And while entry-level turntables may have small, plastic feet, premium models come with larger, adjustable, rubberized feet for better vibration isolation. While some of these come down to personal preference — a frosted acrylic platter looks really nice — there are some performance boosts to be gained depending on how the company uses the components. How we test turntables Since most turntables under $600 meet the criteria for entry-level through midrange, we tested every model with a set of Audio-Technica AT-SP3X powered speakers. These offer balanced sound for turntables with a 1.1-inch tweeter and 3-inch woofer in each unit. And at $269, they won’t break the bank if you need speakers for your new turntable and they’ll provide ample sound performance even if you spend more than our budget on a new deck. For all of our test units that didn’t have a built-in preamp, we used the Fluance PA-10. At $100, it’s an affordable upgrade if you’re looking to bypass a turntable’s included components or if you’re looking to go more analog with your turntable purchase. There are no buttons or controls, just connect your turntable, speakers and ground wire (if you’re using one) and you’re ready to go. It’s simple, straightforward and inexpensive, so it’s a great option for beginners and more experienced vinyl collectors alike. In terms of performance testing, we play a variety of genres on each turntable to evaluate sound quality. We also carefully examine the overall experience of putting a record on, setting the speed, placing the tonearm and more, which allows us to judge how well each turntable will work for users at different experience levels. Lastly, we take notes on design and components, comparing those elements from each turntable with our other test subjects to make our recommendations. This article originally appeared on Engadget at https://www.engadget.com/audio/best-record-player-120000239.html?src=rss",
          "feed_position": 32,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/turntables-group-lead.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-keyboard-120000018.html",
          "published_at": "Mon, 10 Nov 2025 10:00:38 +0000",
          "title": "The best keyboards for 2025",
          "standfirst": "Typing, gaming, coding or just browsing — how your fingers connect with your keyboard can change the whole feel of your setup. Whether you’re looking for something whisper-quiet and compact or a thunderous mechanical board that sings with every stroke, the best keyboards make a real difference in comfort and performance.Some people want a minimalist board that lives neatly next to their laptop or slips into a travel bag. Others need a full-size model with a numpad, dedicated macros and a build that stands up to long sessions. Today’s keyboard market is more diverse than ever. You’ll find boards designed for elegant workspace minimalism, gaming keyboards with aggressive RGB-lit setups and ergonomic keyboards built to reduce strain when you spend hours typing. Wireless models offer flexibility and tidy desks, while wired options still lead when speed and reliability matter most.Whether you’re upgrading your first desktop, building a pro-level gaming rig or simply looking for a board that works better day after day, we’ve found the keyboards worth your time and money. Table of contents Best keyboards for 2025 What to look for in a keyboard Best keyboards for 2025 What to look for in a keyboard Design Size The first thing you’ll want to consider when it comes to your next computer keyboard’s design is size. There are a number of different keyboard layouts to choose from, but the most common are full-sized, tenkeyless and those smaller than tenkeyless. Full-sized keyboards, or 100 percent, include a function row at the top and a complete numpad with arrow keys on the right side, along with all of the rest of the alphanumeric keys you’d expect on a standard QWERTY layout. Tenkeyless, or 80 percent, removes the number pad but keeps the arrow keys and the function row, reducing the overall width measurement of the board by a decent amount. Compact keyboards keep things ultra simple by including only the alphanumeric keys and modifiers like Alt, Shift, Ctrl and others and they come in different sizes like 60 percent, 65 percent and more. These are the most popular sizes out there, but you can find plenty of other designs that include different mixes of keys along with the standard letters and numbers all should have. Aside from size, there are two other big categories that you could use to define a keyboard: ergonomic and mechanical. Ergonomic keyboards are designed with, you guessed it, better ergonomics in mind, taking into account where you should position your fingers, hands and forearms to maintain proper posture. Separately, mechanical keyboards use mechanical switches (of which there are many types) that differ greatly from the membrane or scissor-switch keyboards you’ll find dominating most wired and wireless options widely available today. We have guides to the best ergonomic keyboards and best mechanical keyboards, but we’ll summarize what you need to know about both here. Ergonomic keyboards If you deal with discomfort from working at a computer all day, ergonomic keyboards can help. These specially designed boards re-orient the keys, allowing you to hold your elbows farther apart and maintain a straighter line from your forearms to hands. Some people find this subtle change more comfortable. Ergonomic keyboards typically fall into two categories: Alice and split keyboards. The former is a single unit with an A-shaped gap in the center of the keys. Split models come in two separate pieces which you can arrange as you like on your desk. Additional ergonomic features like tenting and negative tilt can make typing feel even more comfortable, and are often available on both Alice and split boards. Tenting raises the middle of the keys up so your hands take on more of a “handshake” position. Negative tilting lowers the top of the keyboard to keep your wrists angled downward instead of back towards your forearms. The way the keys are arranged on the keyboard may make typing easier as well. Traditionally, keyboards are staggered, with one row of letters slightly offset from the row beneath it. Columnar keyboards arrange the keys in a grid of rows and columns. This style takes a little getting used to, but some people find it allows them to type faster. You can also make the keys of some keyboards do more than just produce letters. Programmable boards let you map shortcuts and other functions, including macros, which may keep you from reaching for the mouse quite so often, saving you time and possibly strain as well. Mechanical keyboards Mechanical keyboards have blown up in popularity as more people have been thrust into creating their own workspaces at home. It’s easy to see why: Compared to a traditional membrane keyboard, a good mechanical board is more durable, more satisfying to press and, most importantly, infinitely more customizable. The best of them usually come with a price premium, but even some cheaper models let you “hot-swap” between keycaps, switches and other materials, letting you tinker with different typing sensations and sound profiles until you find a combination that best expresses your preferences. Do you want each press to feel deep and full or fast and light? Do you need them to sound loud and clacky or almost totally muffled? Do you prefer your keycaps to look subdued and professional, stuffed with RGB lights or written in an Elvish language from The Lord of the Rings for some reason? With the right new keyboard, it’s all up to you — the only things really holding you back are your imagination and your wallet. We have a dedicated buying guide that digs deeper into the key aspects to consider when buying a mechanical gaming keyboard, so we encourage you to look at that for a full rundown. To keep things high-level, the most influential part of your purchase is your keyboard’s switch type. These little mechanisms slot underneath the keycaps and generally have the biggest effect on how your keyboard feels and sounds as you type away. You can broadly separate mechanical switches into three buckets: linear, tactile and clicky. Linear switches feel smooth all the way down; they’re often popular with gamers since they tend to be light and fast to actuate. Tactile switches create a tangible “bump” sensation partway through a press; many people who spend all day typing prefer them because they clearly confirm each press without (always) being all that loud. Clicky switches are functionally similar to tactiles but make an audible “click” sound to match the bump; your coworkers may hate them, but others love the full-throated sense of feedback they provide. To be clear, just because two switches fall within the same bucket doesn’t mean they feel or sound exactly the same. The only way to figure out which switch works best for you is to do your research and, preferably, try some out for yourself. Other keyboards have a mechanical-style feel but are built on different mechanisms entirely. The hot new trend in gaming-focused keyboards, for example, is Hall effect switches, which use tiny magnets to register keystrokes and let you customize the sensitivity of each press. Optical switches, meanwhile, offer similar functionality by replacing the physical contact point of a typical mechanical switch with a beam of infrared light. More recently, we’ve seen a couple keyboards launch with inductive switches, which can work like magnetic switches but use inductive coils in the keyboard’s printed circuit board (PCB) to cater to all switches collectively and don’t require a sensor for each individual switch. We touch on a couple of magnetic-switch keyboards in our picks below, but for a fuller breakdown of this sort of tech, we recommend you check out our dedicated buying guide to the best gaming keyboards. Connectivity You’ve got two options here: wired or wireless. Wired keyboards typically have an attached cable that plugs into a USB-A or USB-C port on your computer (or docking station), although some come with cables that can be removed. Wireless mechanical keyboards connect to your machine either via Bluetooth or a wireless receiver dongle. There’s always the chance of some latency with wireless keyboards, so keep that in mind if you’re picking one up to use primarily with a gaming PC. Of course, you’ll only have to worry about battery life with Bluetooth keyboards.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-keyboard-120000018.html?src=rss",
          "content": "Typing, gaming, coding or just browsing — how your fingers connect with your keyboard can change the whole feel of your setup. Whether you’re looking for something whisper-quiet and compact or a thunderous mechanical board that sings with every stroke, the best keyboards make a real difference in comfort and performance.Some people want a minimalist board that lives neatly next to their laptop or slips into a travel bag. Others need a full-size model with a numpad, dedicated macros and a build that stands up to long sessions. Today’s keyboard market is more diverse than ever. You’ll find boards designed for elegant workspace minimalism, gaming keyboards with aggressive RGB-lit setups and ergonomic keyboards built to reduce strain when you spend hours typing. Wireless models offer flexibility and tidy desks, while wired options still lead when speed and reliability matter most.Whether you’re upgrading your first desktop, building a pro-level gaming rig or simply looking for a board that works better day after day, we’ve found the keyboards worth your time and money. Table of contents Best keyboards for 2025 What to look for in a keyboard Best keyboards for 2025 What to look for in a keyboard Design Size The first thing you’ll want to consider when it comes to your next computer keyboard’s design is size. There are a number of different keyboard layouts to choose from, but the most common are full-sized, tenkeyless and those smaller than tenkeyless. Full-sized keyboards, or 100 percent, include a function row at the top and a complete numpad with arrow keys on the right side, along with all of the rest of the alphanumeric keys you’d expect on a standard QWERTY layout. Tenkeyless, or 80 percent, removes the number pad but keeps the arrow keys and the function row, reducing the overall width measurement of the board by a decent amount. Compact keyboards keep things ultra simple by including only the alphanumeric keys and modifiers like Alt, Shift, Ctrl and others and they come in different sizes like 60 percent, 65 percent and more. These are the most popular sizes out there, but you can find plenty of other designs that include different mixes of keys along with the standard letters and numbers all should have. Aside from size, there are two other big categories that you could use to define a keyboard: ergonomic and mechanical. Ergonomic keyboards are designed with, you guessed it, better ergonomics in mind, taking into account where you should position your fingers, hands and forearms to maintain proper posture. Separately, mechanical keyboards use mechanical switches (of which there are many types) that differ greatly from the membrane or scissor-switch keyboards you’ll find dominating most wired and wireless options widely available today. We have guides to the best ergonomic keyboards and best mechanical keyboards, but we’ll summarize what you need to know about both here. Ergonomic keyboards If you deal with discomfort from working at a computer all day, ergonomic keyboards can help. These specially designed boards re-orient the keys, allowing you to hold your elbows farther apart and maintain a straighter line from your forearms to hands. Some people find this subtle change more comfortable. Ergonomic keyboards typically fall into two categories: Alice and split keyboards. The former is a single unit with an A-shaped gap in the center of the keys. Split models come in two separate pieces which you can arrange as you like on your desk. Additional ergonomic features like tenting and negative tilt can make typing feel even more comfortable, and are often available on both Alice and split boards. Tenting raises the middle of the keys up so your hands take on more of a “handshake” position. Negative tilting lowers the top of the keyboard to keep your wrists angled downward instead of back towards your forearms. The way the keys are arranged on the keyboard may make typing easier as well. Traditionally, keyboards are staggered, with one row of letters slightly offset from the row beneath it. Columnar keyboards arrange the keys in a grid of rows and columns. This style takes a little getting used to, but some people find it allows them to type faster. You can also make the keys of some keyboards do more than just produce letters. Programmable boards let you map shortcuts and other functions, including macros, which may keep you from reaching for the mouse quite so often, saving you time and possibly strain as well. Mechanical keyboards Mechanical keyboards have blown up in popularity as more people have been thrust into creating their own workspaces at home. It’s easy to see why: Compared to a traditional membrane keyboard, a good mechanical board is more durable, more satisfying to press and, most importantly, infinitely more customizable. The best of them usually come with a price premium, but even some cheaper models let you “hot-swap” between keycaps, switches and other materials, letting you tinker with different typing sensations and sound profiles until you find a combination that best expresses your preferences. Do you want each press to feel deep and full or fast and light? Do you need them to sound loud and clacky or almost totally muffled? Do you prefer your keycaps to look subdued and professional, stuffed with RGB lights or written in an Elvish language from The Lord of the Rings for some reason? With the right new keyboard, it’s all up to you — the only things really holding you back are your imagination and your wallet. We have a dedicated buying guide that digs deeper into the key aspects to consider when buying a mechanical gaming keyboard, so we encourage you to look at that for a full rundown. To keep things high-level, the most influential part of your purchase is your keyboard’s switch type. These little mechanisms slot underneath the keycaps and generally have the biggest effect on how your keyboard feels and sounds as you type away. You can broadly separate mechanical switches into three buckets: linear, tactile and clicky. Linear switches feel smooth all the way down; they’re often popular with gamers since they tend to be light and fast to actuate. Tactile switches create a tangible “bump” sensation partway through a press; many people who spend all day typing prefer them because they clearly confirm each press without (always) being all that loud. Clicky switches are functionally similar to tactiles but make an audible “click” sound to match the bump; your coworkers may hate them, but others love the full-throated sense of feedback they provide. To be clear, just because two switches fall within the same bucket doesn’t mean they feel or sound exactly the same. The only way to figure out which switch works best for you is to do your research and, preferably, try some out for yourself. Other keyboards have a mechanical-style feel but are built on different mechanisms entirely. The hot new trend in gaming-focused keyboards, for example, is Hall effect switches, which use tiny magnets to register keystrokes and let you customize the sensitivity of each press. Optical switches, meanwhile, offer similar functionality by replacing the physical contact point of a typical mechanical switch with a beam of infrared light. More recently, we’ve seen a couple keyboards launch with inductive switches, which can work like magnetic switches but use inductive coils in the keyboard’s printed circuit board (PCB) to cater to all switches collectively and don’t require a sensor for each individual switch. We touch on a couple of magnetic-switch keyboards in our picks below, but for a fuller breakdown of this sort of tech, we recommend you check out our dedicated buying guide to the best gaming keyboards. Connectivity You’ve got two options here: wired or wireless. Wired keyboards typically have an attached cable that plugs into a USB-A or USB-C port on your computer (or docking station), although some come with cables that can be removed. Wireless mechanical keyboards connect to your machine either via Bluetooth or a wireless receiver dongle. There’s always the chance of some latency with wireless keyboards, so keep that in mind if you’re picking one up to use primarily with a gaming PC. Of course, you’ll only have to worry about battery life with Bluetooth keyboards.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-keyboard-120000018.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/celosphere-2025-where-enterprise-ai-moved-from-experiment-to-execution",
          "published_at": "Mon, 10 Nov 2025 05:00:00 GMT",
          "title": "Celosphere 2025: Where enterprise AI moved from experiment to execution",
          "standfirst": "Presented by CelonisAfter a year of boardroom declarations about “AI transformation,” this was the week where enterprise leaders came together to talk about what actually works. Speaking from the stage at Celosphere in Munich, Celonis co-founder and co-CEO Alexander Rinke set the tone early in his keynote:“Only 11 % of companies are seeing measurable benefits from AI projects today,” he said. “That’s not an adoption problem. That’s a context problem.”It’s a sentiment familiar to anyone who’s tried to deploy AI inside a large enterprise. You can’t automate what you don’t understand — and most organizations still lack a unified picture of how work in their companies really gets done.Celonis’ answer, showcased across three days at the company’s annual event, was less about new tech acronyms and more about connective tissue: how to make AI fit within the messy, living processes that drive business. The company framed it as achieving a real “Return on AI (ROAI)” — measurable impact that comes only when intelligence is grounded in process context.A living model of how the enterprise worksAt the heart of the keynote was what Rinke called a “living digital twin of your operations.” Celonis has been building toward this moment for years — but this was the first time the company made clear how far that concept has evolved.“We start by freeing the process,” said Rinke. “Freeing it from the restrictions of your current legacy systems.” Data Core, Celonis’ data infrastructure, extracts raw data from source systems. It’s capable of querying billions of records in near real time with sub-minute refresh — extending visibility beyond traditional systems of record.Built on this foundation, the Process Intelligence Graph sits at the center of the Celonis Platform. It’s a system-agnostic, graph-based model that unifies data across systems, apps, and even devices, including task-mining data that captures clicks, spreadsheets, and browser activity. It combines this data with business context—business rules, KPIs, benchmarks, and exceptions. Every transaction, rule, and process interaction becomes part of a continuously updated replica that reflects how the organization actually operates.On top of the Graph, the company’s new Build Experience allows organizations to analyze, design, and operate AI-driven, composable processes — integrating AI where it delivers business impact, not just technical demos:Analyze where processes stall or repeatDesign the future state, setting outcomes, guardrails, and AI touchpointsOperate with humans, systems, and AI agents working in sync — now orchestrated through a generally available Orchestration Engine that can trigger and monitor every step in one flowIt’s a deliberate shift from discovery-driven AI pilots to outcome-driven AI operations — and a blueprint for orchestrating agentic AI, where human teams, systems, and autonomous agents work together through shared process context rather than in silos.Real-world proof: Mercedes-Benz, Vinmar, and UniperThe Celosphere stage offered real proof of theCelonisPlatform in action, through live stories from customers already building on it.Mercedes-Benz shared how process intelligence became their “connective tissue” during the semiconductor crisis. “We had data everywhere — plants, suppliers, logistics,” recalled Dr. Jörg Burzer, Member of the Board of Management of Mercedes-Benz Group AG. “What we didn’t have was a way to see it together. Celonis helped us connect those dots fast enough to act.”The partnership has since expanded across eight of the company’s ten most critical processes, from supply chain to quality to after-sales. But what impressed the audience wasn’t just the scale — it was the cultural shift.“If you show data in context, and let teams visualize processes, you also change the culture,” Burzer said. “It’s not just process transformation — it’s people transformation.”At Vinmar, CEO Vishal Baid described Celonis as “the foundation of our automation and AI strategy.” His global plastics distribution business has already automated its entire order-to-cash process for a $3 B unit, achieving a 40 % productivity lift. But Baid wasn’t there to just celebrate finished work — he was looking ahead. “Now we’re tackling the non-algorithmic stuff,” he said. “Matching purchase and sales orders sounds simple until you have thousands of edge cases. We’re building an AI agent that can do that allocation intelligently. That’s the next frontier.”And in the energy sector, Uniper, with partner Microsoft, demonstrated how process-aware AI copilots are already reshaping operations. Using Celonis and Microsoft’s AI stack, Uniper can predict when hydropower plants will need maintenance — and cluster those jobs to reduce downtime and emissions.“Each technician, each part, each system plays a role in a living process,” said Hans Berg, Uniper’s CIO. “The human can’t see all of it. But process intelligence can — and it can nudge the system toward the best outcome.”Agnes Heftberger, CVP & CEO, Microsoft Germany & Austria, who joined Berg on stage, summed it up crisply:“The hard part isn’t building AI features — it’s scaling them responsibly,” she explained. “You need to marry intelligence with the beating heart of the company: its processes.”Across the global community, Celonis reports more than $8 billion in realized business valueand over 120 certified value champions — proof that process intelligence is driving measurable impact far beyond pilots. Rinke called it “the early proof points of a true return on AI.” From closed systems to composable intelligenceCelosphere 2025 marked a shift from architecture to interoperability — from defining enterprise AI to making it work across boundaries.Rinke’s vision for the future is unapologetically open: “Good things grow from open ecosystems,” he said. That philosophy is taking shape through deeper platform integrations — including Microsoft Fabric, Databricks, and Bloomfilter — with zero-copy, bidirectional lakehouse access that lets customers query process data in place with minimal latency. The company also announced MCP Server support for embedding the Process Intelligence Graph directly into agentic AI platforms like Amazon Bedrock and Microsoft Copilot Studio.These updates make “composable enterprise AI” tangible — organizations can now assemble and govern AI solutions across ecosystems rather than being locked into any single vendor.Rather than competing on who has the “best agent,” the message was that enterprise AI will thrive when agents work together through shared context and models that mirror how businesses actually run.“Every vendor is bringing out their own agent,” Rinke said. “But each one is limited to that vendor’s world. If they can’t work together, they can’t work for you. That’s what process intelligence fixes.”The idea drew sustained applause. For companies juggling multiple cloud platforms, ERPs, and data tools, composability isn’t just elegant; it’s survival.Beyond operations: data, democracy, and directionThe closing moments of the keynote took an unexpected turn — from enterprise architecture to human courage. Venezuelan opposition leader and Nobel Peace Prize winner María Corina Machado joined live via satellite to share how her movement used data, encrypted apps, and civic coordination to expose election fraud and mobilize millions.It was a powerful contrast: the same principles — transparency, accountability, context — at work in both business and democracy.“Technology can be a weapon or a liberator,” Machado said. “It depends on who holds the context.”Her words landed with weight in a room full of people used to talking about data, systems, and governance — a reminder that context isn’t just technical, it’s human.Why this year matteredCelosphere 2025 marked a shift in how enterprises approach AI — from experimentation to results grounded in process intelligence. The shift was evident in both tone and technology, with a more powerful Data Core, enhanced Process Intelligence Graph, and new Build Experience. But the deeper takeaway was philosophical: AI only scales when it’s grounded in how people and systems actually work together.Celonis president Carsten Thoma was candid in acknowledging that early process-mining projects often “stormed in with discovery” before understanding organizational value — a lesson that now defines the company’s measured, pragmatic approach to enterprise AI.Rinke put it best near the end of his keynote:“We’re not just automating steps,” he said. “We’re building enterprises that can adapt instantly, innovate freely, and improve continuously.”Missed it? Catch up with all the highlights from Celosphere 2025 here. Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by CelonisAfter a year of boardroom declarations about “AI transformation,” this was the week where enterprise leaders came together to talk about what actually works. Speaking from the stage at Celosphere in Munich, Celonis co-founder and co-CEO Alexander Rinke set the tone early in his keynote:“Only 11 % of companies are seeing measurable benefits from AI projects today,” he said. “That’s not an adoption problem. That’s a context problem.”It’s a sentiment familiar to anyone who’s tried to deploy AI inside a large enterprise. You can’t automate what you don’t understand — and most organizations still lack a unified picture of how work in their companies really gets done.Celonis’ answer, showcased across three days at the company’s annual event, was less about new tech acronyms and more about connective tissue: how to make AI fit within the messy, living processes that drive business. The company framed it as achieving a real “Return on AI (ROAI)” — measurable impact that comes only when intelligence is grounded in process context.A living model of how the enterprise worksAt the heart of the keynote was what Rinke called a “living digital twin of your operations.” Celonis has been building toward this moment for years — but this was the first time the company made clear how far that concept has evolved.“We start by freeing the process,” said Rinke. “Freeing it from the restrictions of your current legacy systems.” Data Core, Celonis’ data infrastructure, extracts raw data from source systems. It’s capable of querying billions of records in near real time with sub-minute refresh — extending visibility beyond traditional systems of record.Built on this foundation, the Process Intelligence Graph sits at the center of the Celonis Platform. It’s a system-agnostic, graph-based model that unifies data across systems, apps, and even devices, including task-mining data that captures clicks, spreadsheets, and browser activity. It combines this data with business context—business rules, KPIs, benchmarks, and exceptions. Every transaction, rule, and process interaction becomes part of a continuously updated replica that reflects how the organization actually operates.On top of the Graph, the company’s new Build Experience allows organizations to analyze, design, and operate AI-driven, composable processes — integrating AI where it delivers business impact, not just technical demos:Analyze where processes stall or repeatDesign the future state, setting outcomes, guardrails, and AI touchpointsOperate with humans, systems, and AI agents working in sync — now orchestrated through a generally available Orchestration Engine that can trigger and monitor every step in one flowIt’s a deliberate shift from discovery-driven AI pilots to outcome-driven AI operations — and a blueprint for orchestrating agentic AI, where human teams, systems, and autonomous agents work together through shared process context rather than in silos.Real-world proof: Mercedes-Benz, Vinmar, and UniperThe Celosphere stage offered real proof of theCelonisPlatform in action, through live stories from customers already building on it.Mercedes-Benz shared how process intelligence became their “connective tissue” during the semiconductor crisis. “We had data everywhere — plants, suppliers, logistics,” recalled Dr. Jörg Burzer, Member of the Board of Management of Mercedes-Benz Group AG. “What we didn’t have was a way to see it together. Celonis helped us connect those dots fast enough to act.”The partnership has since expanded across eight of the company’s ten most critical processes, from supply chain to quality to after-sales. But what impressed the audience wasn’t just the scale — it was the cultural shift.“If you show data in context, and let teams visualize processes, you also change the culture,” Burzer said. “It’s not just process transformation — it’s people transformation.”At Vinmar, CEO Vishal Baid described Celonis as “the foundation of our automation and AI strategy.” His global plastics distribution business has already automated its entire order-to-cash process for a $3 B unit, achieving a 40 % productivity lift. But Baid wasn’t there to just celebrate finished work — he was looking ahead. “Now we’re tackling the non-algorithmic stuff,” he said. “Matching purchase and sales orders sounds simple until you have thousands of edge cases. We’re building an AI agent that can do that allocation intelligently. That’s the next frontier.”And in the energy sector, Uniper, with partner Microsoft, demonstrated how process-aware AI copilots are already reshaping operations. Using Celonis and Microsoft’s AI stack, Uniper can predict when hydropower plants will need maintenance — and cluster those jobs to reduce downtime and emissions.“Each technician, each part, each system plays a role in a living process,” said Hans Berg, Uniper’s CIO. “The human can’t see all of it. But process intelligence can — and it can nudge the system toward the best outcome.”Agnes Heftberger, CVP & CEO, Microsoft Germany & Austria, who joined Berg on stage, summed it up crisply:“The hard part isn’t building AI features — it’s scaling them responsibly,” she explained. “You need to marry intelligence with the beating heart of the company: its processes.”Across the global community, Celonis reports more than $8 billion in realized business valueand over 120 certified value champions — proof that process intelligence is driving measurable impact far beyond pilots. Rinke called it “the early proof points of a true return on AI.” From closed systems to composable intelligenceCelosphere 2025 marked a shift from architecture to interoperability — from defining enterprise AI to making it work across boundaries.Rinke’s vision for the future is unapologetically open: “Good things grow from open ecosystems,” he said. That philosophy is taking shape through deeper platform integrations — including Microsoft Fabric, Databricks, and Bloomfilter — with zero-copy, bidirectional lakehouse access that lets customers query process data in place with minimal latency. The company also announced MCP Server support for embedding the Process Intelligence Graph directly into agentic AI platforms like Amazon Bedrock and Microsoft Copilot Studio.These updates make “composable enterprise AI” tangible — organizations can now assemble and govern AI solutions across ecosystems rather than being locked into any single vendor.Rather than competing on who has the “best agent,” the message was that enterprise AI will thrive when agents work together through shared context and models that mirror how businesses actually run.“Every vendor is bringing out their own agent,” Rinke said. “But each one is limited to that vendor’s world. If they can’t work together, they can’t work for you. That’s what process intelligence fixes.”The idea drew sustained applause. For companies juggling multiple cloud platforms, ERPs, and data tools, composability isn’t just elegant; it’s survival.Beyond operations: data, democracy, and directionThe closing moments of the keynote took an unexpected turn — from enterprise architecture to human courage. Venezuelan opposition leader and Nobel Peace Prize winner María Corina Machado joined live via satellite to share how her movement used data, encrypted apps, and civic coordination to expose election fraud and mobilize millions.It was a powerful contrast: the same principles — transparency, accountability, context — at work in both business and democracy.“Technology can be a weapon or a liberator,” Machado said. “It depends on who holds the context.”Her words landed with weight in a room full of people used to talking about data, systems, and governance — a reminder that context isn’t just technical, it’s human.Why this year matteredCelosphere 2025 marked a shift in how enterprises approach AI — from experimentation to results grounded in process intelligence. The shift was evident in both tone and technology, with a more powerful Data Core, enhanced Process Intelligence Graph, and new Build Experience. But the deeper takeaway was philosophical: AI only scales when it’s grounded in how people and systems actually work together.Celonis president Carsten Thoma was candid in acknowledging that early process-mining projects often “stormed in with discovery” before understanding organizational value — a lesson that now defines the company’s measured, pragmatic approach to enterprise AI.Rinke put it best near the end of his keynote:“We’re not just automating steps,” he said. “We’re building enterprises that can adapt instantly, innovate freely, and improve continuously.”Missed it? Catch up with all the highlights from Celosphere 2025 here. Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/uV4vD3ySkvCA0p9ZGxJhR/2ad630e0970a0d2668b8a78dd5c9e013/2025_10_04_Celosphere_3O7A5496__1_.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/how-to-adjust-the-liquid-glass-effect-in-ios-261-203634681.html",
          "published_at": "Sun, 09 Nov 2025 20:36:34 +0000",
          "title": "How to adjust the Liquid Glass effect in iOS 26.1",
          "standfirst": "Apple's latest iterative update for iPhones brings a welcome change for those who aren't a fan of its Liquid Glass design overhaul. After user complaints that the Liquid Glass' translucent design was hard to read, Apple introduced a compromise in iOS 26's fourth beta that allowed for a more frosted look as well as a Reduce Transparency option buried in the Accessibility settings. Now, Apple is making this Liquid Glass toggle available for all iPhone users with iOS 26.1. What is Liquid Glass? Apple debuted Liquid Glass at WWDC 2025 as its major visual redesign, which prompted a lot of comparisons to Windows Vista. Everything from switches and sliders to sidebars and panels would imitate glass, so that users can see the underlying colors and content. While some iPhone users liked the fluidity and freshness, others said the transparent look often created legibility issues, caused lag from the animations and led to eye strain over extended periods of time. How to reduce the Liquid Glass effect To access the new Liquid Glass toggle, make sure your iPhone is updated to iOS 26.1. You can check which version you're by navigating to Settings, then General, then Software Update. After you confirmed that you're on the most recent iOS, you can go back into Settings, then Display & Brightness. From there, you'll find a new setting for Liquid Glass that lets you choose between \"Clear\" or \"Tinted.\" The Clear option is Apple's original vision for Liquid Glass with see-through controls, while the Tinted option \"increases opacity and adds more contrast.\" You can preview the differences between the two choices in the Liquid Glass setting before you commit to one. When in use, the Tinted option switches to the same frosted look first seen by iOS beta testers, which adds a more solid background to panels that have been Liquid Glass-ified. It's important to note that there are only two options and Apple didn't instead opt for a slider to adjust opacity. However, Apple is leaning more into customizability with its operating systems, as indicated by its recently introduced Spatial Scenes feature. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/how-to-adjust-the-liquid-glass-effect-in-ios-261-203634681.html?src=rss",
          "content": "Apple's latest iterative update for iPhones brings a welcome change for those who aren't a fan of its Liquid Glass design overhaul. After user complaints that the Liquid Glass' translucent design was hard to read, Apple introduced a compromise in iOS 26's fourth beta that allowed for a more frosted look as well as a Reduce Transparency option buried in the Accessibility settings. Now, Apple is making this Liquid Glass toggle available for all iPhone users with iOS 26.1. What is Liquid Glass? Apple debuted Liquid Glass at WWDC 2025 as its major visual redesign, which prompted a lot of comparisons to Windows Vista. Everything from switches and sliders to sidebars and panels would imitate glass, so that users can see the underlying colors and content. While some iPhone users liked the fluidity and freshness, others said the transparent look often created legibility issues, caused lag from the animations and led to eye strain over extended periods of time. How to reduce the Liquid Glass effect To access the new Liquid Glass toggle, make sure your iPhone is updated to iOS 26.1. You can check which version you're by navigating to Settings, then General, then Software Update. After you confirmed that you're on the most recent iOS, you can go back into Settings, then Display & Brightness. From there, you'll find a new setting for Liquid Glass that lets you choose between \"Clear\" or \"Tinted.\" The Clear option is Apple's original vision for Liquid Glass with see-through controls, while the Tinted option \"increases opacity and adds more contrast.\" You can preview the differences between the two choices in the Liquid Glass setting before you commit to one. When in use, the Tinted option switches to the same frosted look first seen by iOS beta testers, which adds a more solid background to panels that have been Liquid Glass-ified. It's important to note that there are only two options and Apple didn't instead opt for a slider to adjust opacity. However, Apple is leaning more into customizability with its operating systems, as indicated by its recently introduced Spatial Scenes feature. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/how-to-adjust-the-liquid-glass-effect-in-ios-261-203634681.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/apple-is-reportedly-working-on-more-satellite-features-for-iphone-172151203.html",
          "published_at": "Sun, 09 Nov 2025 17:21:52 +0000",
          "title": "Apple is reportedly working on more satellite features for iPhone",
          "standfirst": "Your iPhone may soon be able to do more than call for emergency help and send messages via satellite, according to the latest Power On newsletter. Bloomberg's Mark Gurman reported that Apple is planning to expand on satellite features available on iPhones. Apple introduced the ability to send and receive texts with the Messages via Satellite feature last year, but is reportedly looking to enhance this with the option to send photos too. Beyond texting, Apple wants to enable 5G NTN support on its iPhones, which allows cell towers to get a coverage boost by tapping into satellites, according to Gurman. For anyone who needs directions in a remote area without a cellular or Wi-Fi connection, Apple reportedly has plans to introduce satellite connectivity to Apple Maps. Along with these upgrades, Gurman reported that Apple is looking into \"natural usage\" improvements where users won't have to point their iPhones towards the sky to connect to a satellite network. Instead, an iPhone could stay connected even when there's no clear view of the sky, like in indoor environments. On the developer side of things, Gurman said that Apple is also working on an API that allows app makers to add satellite connections. There's no timeline for when these rumored satellite features will go live, but Apple previously waited a couple of years between introducing Emergency SOS via Satellite in 2022 and Messages via Satellite with the release of iOS 18.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/apple-is-reportedly-working-on-more-satellite-features-for-iphone-172151203.html?src=rss",
          "content": "Your iPhone may soon be able to do more than call for emergency help and send messages via satellite, according to the latest Power On newsletter. Bloomberg's Mark Gurman reported that Apple is planning to expand on satellite features available on iPhones. Apple introduced the ability to send and receive texts with the Messages via Satellite feature last year, but is reportedly looking to enhance this with the option to send photos too. Beyond texting, Apple wants to enable 5G NTN support on its iPhones, which allows cell towers to get a coverage boost by tapping into satellites, according to Gurman. For anyone who needs directions in a remote area without a cellular or Wi-Fi connection, Apple reportedly has plans to introduce satellite connectivity to Apple Maps. Along with these upgrades, Gurman reported that Apple is looking into \"natural usage\" improvements where users won't have to point their iPhones towards the sky to connect to a satellite network. Instead, an iPhone could stay connected even when there's no clear view of the sky, like in indoor environments. On the developer side of things, Gurman said that Apple is also working on an API that allows app makers to add satellite connections. There's no timeline for when these rumored satellite features will go live, but Apple previously waited a couple of years between introducing Emergency SOS via Satellite in 2022 and Messages via Satellite with the release of iOS 18.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/apple-is-reportedly-working-on-more-satellite-features-for-iphone-172151203.html?src=rss",
          "feed_position": 40
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/these-are-the-black-friday-tech-deals-i-want-to-see-in-2025-100014651.html",
          "published_at": "Sun, 09 Nov 2025 15:00:35 +0000",
          "title": "These are the Black Friday tech deals I want to see in 2025",
          "standfirst": "Black Friday is a time for all kinds of shopping, not just gifts. And since it’s become more of a month-long affair than a one-day event, it’s a good time to pick up things for yourself and for other people while you can save some money in the process. But to say money is tight is an understatement this year. If Amazon’s Prime Big Deal Days was any indicator, folks are spending more on essentials than anything else right now. That, combined with the rising trend of holding on to big tech purchases for longer means that gadgets may be showing up lower on your shopping list this year.Even if that’s the case, I’d recommend not overlooking tech entirely this Black Friday. Besides, all of us have essential tech that we use every day; more often than not, you can avoid paying full price for most of those devices (and all of the rest of the best tech of the year) if you're looking to add to your repertoire or need a replacement. Personally, I'm not eyeing a new smartphone or laptop this holiday shopping season, but there are a few tech purchases I’d like to make if the prices are right. This is the tech I’m hoping to save on this year during Black Friday. This article originally appeared on Engadget at https://www.engadget.com/deals/these-are-the-black-friday-tech-deals-i-want-to-see-in-2025-100014651.html?src=rss",
          "content": "Black Friday is a time for all kinds of shopping, not just gifts. And since it’s become more of a month-long affair than a one-day event, it’s a good time to pick up things for yourself and for other people while you can save some money in the process. But to say money is tight is an understatement this year. If Amazon’s Prime Big Deal Days was any indicator, folks are spending more on essentials than anything else right now. That, combined with the rising trend of holding on to big tech purchases for longer means that gadgets may be showing up lower on your shopping list this year.Even if that’s the case, I’d recommend not overlooking tech entirely this Black Friday. Besides, all of us have essential tech that we use every day; more often than not, you can avoid paying full price for most of those devices (and all of the rest of the best tech of the year) if you're looking to add to your repertoire or need a replacement. Personally, I'm not eyeing a new smartphone or laptop this holiday shopping season, but there are a few tech purchases I’d like to make if the prices are right. This is the tech I’m hoping to save on this year during Black Friday. This article originally appeared on Engadget at https://www.engadget.com/deals/these-are-the-black-friday-tech-deals-i-want-to-see-in-2025-100014651.html?src=rss",
          "feed_position": 43
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/lego-black-friday-deals-get-up-to-40-percent-off-star-wars-and-disney-sets-with-these-early-sales-155007211.html",
          "published_at": "Sun, 09 Nov 2025 13:46:27 +0000",
          "title": "Lego Black Friday deals: Get up to 40 percent off Star Wars and Disney sets with these early sales",
          "standfirst": "Lego sets make popular gifts all year round, but now is the time when they're some of the most in-demand items you can get. They make great gifts for anyone who you know loves these little building bricks, kids and adults like. Black Friday Lego deals can make it easier for you to get all the sets you want for the holidays because you can typically save at least 20 percent on most sets you'll find. Yes, that often includes the most popular ones from the Star Wars, Super Mario, Harry Potter and other collections. If you're shopping online, don't forget to use a price tracker to make sure you're actually getting a good Lego deal before you buy. Below, we've collected the best Lego Black Friday deals we could find right now. You'll find Lego deals across the board this holiday season at retailers like Amazon and Walmart, but don't overlook Lego's own site. If you join the free Lego Insiders program, you'll build up points with each purchase that you can redeem in the future, get special discounts and sometimes get exclusive gifts when you buy. While not a deal, arguably the hottest Lego for Black Friday will be the brand new Star Trek USS Enterprise set, which was announced recently. It has a whopping 3,600 pieces and will be a must-have for any Star Trek fans. The set will be available starting November 28 for $400. Best Lego Black Friday deals LEGO Star Wars Advent Calendar 2025 75418 for $27 (40 percent off) LEGO Disney Frozen Advent Calendar 2025 43273 for $31 (32 percent off) Lego Harry Potter Advent Calendar 2025 76456 for $39 (13 percent off) LEGO Star Wars Brick-Built Star Wars Logo 75407 for $48 (20 percent off) LEGO Star Wars Grogu with Hover Pram Building Toy Set 75403 for $65 (36 percent off) LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable Model 75375 for $68 (20 percent off) LEGO Star Wars R2-D2 Building Toy Set 75379 for $80 (20 percent off) LEGO Harry Potter Hogwarts Castle and Grounds 76419 for $136 (20 percent off) LEGO Creator 3 in 1 Magical Unicorn Toy 31140 for $7 (32 percent off) LEGO City Donut Truck Toy 60452 for $16 (20 percent off) LEGO Speed Champions 2 Fast 2 Furious Nissan Skyline GT-R (R34) Race Car 76917 for $18 (28 percent off) LEGO Botanicals Happy Plants Building Toys 10349 for $20 (13 percent off) LEGO Botanicals Mini Orchid Building Set 10343 for $24 (20 percent off) LEGO Ideas Tuxedo Cat 21349 for $81 (19 percent off) LEGO Art Hokusai The Great Wave Framed Japanese Wall Art Building Set 31208 for $85 (15 percent off) This article originally appeared on Engadget at https://www.engadget.com/deals/lego-black-friday-deals-get-up-to-40-percent-off-star-wars-and-disney-sets-with-these-early-sales-155007211.html?src=rss",
          "content": "Lego sets make popular gifts all year round, but now is the time when they're some of the most in-demand items you can get. They make great gifts for anyone who you know loves these little building bricks, kids and adults like. Black Friday Lego deals can make it easier for you to get all the sets you want for the holidays because you can typically save at least 20 percent on most sets you'll find. Yes, that often includes the most popular ones from the Star Wars, Super Mario, Harry Potter and other collections. If you're shopping online, don't forget to use a price tracker to make sure you're actually getting a good Lego deal before you buy. Below, we've collected the best Lego Black Friday deals we could find right now. You'll find Lego deals across the board this holiday season at retailers like Amazon and Walmart, but don't overlook Lego's own site. If you join the free Lego Insiders program, you'll build up points with each purchase that you can redeem in the future, get special discounts and sometimes get exclusive gifts when you buy. While not a deal, arguably the hottest Lego for Black Friday will be the brand new Star Trek USS Enterprise set, which was announced recently. It has a whopping 3,600 pieces and will be a must-have for any Star Trek fans. The set will be available starting November 28 for $400. Best Lego Black Friday deals LEGO Star Wars Advent Calendar 2025 75418 for $27 (40 percent off) LEGO Disney Frozen Advent Calendar 2025 43273 for $31 (32 percent off) Lego Harry Potter Advent Calendar 2025 76456 for $39 (13 percent off) LEGO Star Wars Brick-Built Star Wars Logo 75407 for $48 (20 percent off) LEGO Star Wars Grogu with Hover Pram Building Toy Set 75403 for $65 (36 percent off) LEGO Star Wars Millennium Falcon A New Hope 25th Anniversary Collectable Model 75375 for $68 (20 percent off) LEGO Star Wars R2-D2 Building Toy Set 75379 for $80 (20 percent off) LEGO Harry Potter Hogwarts Castle and Grounds 76419 for $136 (20 percent off) LEGO Creator 3 in 1 Magical Unicorn Toy 31140 for $7 (32 percent off) LEGO City Donut Truck Toy 60452 for $16 (20 percent off) LEGO Speed Champions 2 Fast 2 Furious Nissan Skyline GT-R (R34) Race Car 76917 for $18 (28 percent off) LEGO Botanicals Happy Plants Building Toys 10349 for $20 (13 percent off) LEGO Botanicals Mini Orchid Building Set 10343 for $24 (20 percent off) LEGO Ideas Tuxedo Cat 21349 for $81 (19 percent off) LEGO Art Hokusai The Great Wave Framed Japanese Wall Art Building Set 31208 for $85 (15 percent off) This article originally appeared on Engadget at https://www.engadget.com/deals/lego-black-friday-deals-get-up-to-40-percent-off-star-wars-and-disney-sets-with-these-early-sales-155007211.html?src=rss",
          "feed_position": 47
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/DSCF1856.jpg",
      "popularity_score": 2018.7139047222222,
      "ai_summary": [
        "E Ink tablets offer the tactile feel of notebooks with digital convenience.",
        "The devices provide easy-on-the-eyes E Ink screens.",
        "Amazon announced revamped Kindle Scribe E Ink tablets in September 2025.",
        "The new Kindle Scribe 3 is thinner and lighter with faster page-turning.",
        "The Kindle Scribe Colorsoft is the first full-color addition to the lineup."
      ]
    },
    {
      "id": "cluster_24",
      "coverage": 1,
      "updated_at": "Tue, 11 Nov 2025 00:39:13 +0000",
      "title": "Neutron rocket’s debut slips into mid-2026 as company seeks success from the start",
      "neutral_headline": "Neutron rocket’s debut slips into mid-2026 as company seeks success from the start",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/neutron-rockets-debut-slips-into-mid-2026-as-company-seeks-success-from-the-start/",
          "published_at": "Tue, 11 Nov 2025 00:39:13 +0000",
          "title": "Neutron rocket’s debut slips into mid-2026 as company seeks success from the start",
          "standfirst": "\"Those who have failed to deliver are numerous.\"",
          "content": "During an earnings call on Monday, Rocket Lab chief executive Pete Beck announced that the company’s medium-lift launch vehicle, Neutron, would not launch this year. For anyone with the slightest understanding of the challenges involved in bringing a new rocket to the launch pad, as well as a calendar, the delay does not come as a surprise. Although Rocket Lab had been holding on to the possibility of launching Neutron this year publicly, it has been clear for months that a slip into 2026 was inevitable. According to Beck, speaking during a third-quarter 2025 earnings call, the new timeline has the company bringing Neutron to Launch Complex 2 at Wallops Flight Facility in Virginia during the first quarter of next year. The first launch is scheduled to occur “thereafter,” according to the company’s plans.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Neutron-Stack-Deploy-Artwork_med__ScaleHeightWzg1MF0-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Neutron-Stack-Deploy-Artwork_med__ScaleHeightWzg1MF0-1152x648.jpg",
      "popularity_score": 342.3575158333333,
      "ai_summary": [
        "Neutron rocket's debut has been delayed to mid-2026.",
        "The company aims for success from the very beginning of operations.",
        "The company is focused on ensuring a successful initial launch.",
        "The delay allows for further refinement of the rocket's design.",
        "The company is taking a cautious approach to its first flight."
      ]
    },
    {
      "id": "cluster_34",
      "coverage": 1,
      "updated_at": "Mon, 10 Nov 2025 23:06:42 +0000",
      "title": "Researchers isolate memorization from reasoning in AI neural networks",
      "neutral_headline": "Researchers isolate memorization from reasoning in AI neural networks",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/11/study-finds-ai-models-store-memories-and-logic-in-different-neural-regions/",
          "published_at": "Mon, 10 Nov 2025 23:06:42 +0000",
          "title": "Researchers isolate memorization from reasoning in AI neural networks",
          "standfirst": "Basic arithmetic ability lives in the memorization pathways, not logic circuits.",
          "content": "When engineers build AI language models like GPT-5 from training data, at least two major processing features emerge: memorization (reciting exact text they’ve seen before, like famous quotes or passages from books) and reasoning (solving new problems using general principles). New research from AI startup Goodfire.ai provides the first potentially clear evidence that these different functions actually work through completely separate neural pathways in the model’s architecture. The researchers discovered that this separation proves remarkably clean. In a preprint paper released in late October, they described that when they removed the memorization pathways, models lost 97 percent of their ability to recite training data verbatim but kept nearly all their “logical reasoning” ability intact. For example, at layer 22 in Allen Institute for AI’s OLMo-7B language model, the bottom 50 percent of weight components showed 23 percent higher activation on memorized data, while the top 10 percent showed 26 percent higher activation on general, non-memorized text. This mechanistic split enabled the researchers to surgically remove memorization while preserving other capabilities.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprised_robot_2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprised_robot_2-1152x648.jpg",
      "popularity_score": 335.8155713888889,
      "ai_summary": [
        "Researchers have separated memorization from reasoning in AI.",
        "Basic arithmetic ability resides in memorization pathways.",
        "Logic circuits are not responsible for basic arithmetic.",
        "The study provides insight into AI neural network functions.",
        "This research could improve AI development and understanding."
      ]
    },
    {
      "id": "cluster_28",
      "coverage": 1,
      "updated_at": "Mon, 10 Nov 2025 23:34:09 +0000",
      "title": "Intuitive Machines—known for its Moon landers—will become a military contractor",
      "neutral_headline": "Intuitive Machines—known for its Moon landers—will become a military contractor",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/intuitive-machines-known-for-its-moon-landers-will-become-a-military-contractor/",
          "published_at": "Mon, 10 Nov 2025 23:34:09 +0000",
          "title": "Intuitive Machines—known for its Moon landers—will become a military contractor",
          "standfirst": "\"They've been Ford Aerospace, Space Systems/Loral, Maxar, Lanteris, and now it'll be Intuitive Machines.\"",
          "content": "Intuitive Machines announced last week an $800 million acquisition that will catapult the one-time startup into the space industry establishment. The company’s planned purchase of Lanteris Space Systems, a satellite manufacturer you may have never heard of, is rather significant. Lanteris is the latest addition to a line of corporate brands that dates back to 1957. Until last month, the company was known as Maxar Space Systems. Its acquisition by Intuitive Machines would be perhaps the industry’s most evident example of a “New Space” firm buying up an “Old Space” company. The deal would help Intuitive Machines expand beyond its core competency of Moon missions to the broader sector of satellite manufacturing and space services. Lanteris has been owned since 2023 by Advent International, a private equity firm. The transaction is expected to close early next year, subject to “customary regulatory approvals and closing conditions,” according to Intuitive Machines.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/lanterisppe-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/lanterisppe-1152x648.jpg",
      "popularity_score": 331.27307138888887,
      "ai_summary": [
        "Intuitive Machines will become a military contractor.",
        "The company is known for its Moon lander projects.",
        "The company has a history of name changes.",
        "The company's previous names include Ford Aerospace and Maxar.",
        "This shift marks a new direction for the company."
      ]
    },
    {
      "id": "cluster_41",
      "coverage": 1,
      "updated_at": "Mon, 10 Nov 2025 22:10:04 +0000",
      "title": "Canada fought measles and measles won; virus now endemic after 1998 elimination",
      "neutral_headline": "Canada fought measles and measles won; virus now endemic after 1998 elimination",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/11/canada-fought-measles-and-measles-won-virus-now-endemic-after-1998-elimination/",
          "published_at": "Mon, 10 Nov 2025 22:10:04 +0000",
          "title": "Canada fought measles and measles won; virus now endemic after 1998 elimination",
          "standfirst": "Canada's loss also represents a loss of regional elimination for the Americas.",
          "content": "Canada has lost its measles elimination status, meaning the highly infectious virus is considered endemic once again in the country, The Pan American Health Organization (PAHO) announced Monday. The determination was made by a committee of PAHO experts, who spent last week poring over disease data to assess the measles status of countries across the entire region. The fact that Canada has lost its elimination status means that the region of the Americas overall has also lost the status, which it achieved in 2016. Of the 35 countries and territories in the region—a health region designated by the World Health Organization—Canada is currently the only country where measles is considered to be spreading endemically, though other countries, namely the US and Mexico, are headed in the same direction. Measles is considered eliminated when a country can go 12 months without continuous local spread. Sporadic cases brought in from international travel can continue to occur, potentially causing limited outbreaks. But elimination is lost and endemicity is declared only when transmission is sustained over the course of a year.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2224876606-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2224876606-1152x648.jpg",
      "popularity_score": 309.8716825,
      "ai_summary": [
        "Canada's measles elimination status has been lost.",
        "Measles is now considered endemic in Canada.",
        "The Americas also lost regional elimination status.",
        "Canada had eliminated measles in 1998.",
        "The virus's resurgence is a public health concern."
      ]
    },
    {
      "id": "cluster_68",
      "coverage": 1,
      "updated_at": "Mon, 10 Nov 2025 18:41:42 +0000",
      "title": "Apple TV execs dismiss introducing an ad tier, buying Warner Bros. Discovery",
      "neutral_headline": "Apple TV execs dismiss introducing an ad tier, buying Warner Bros. Discovery",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/apple/2025/11/apple-has-no-plans-to-bring-ads-to-apple-tv/",
          "published_at": "Mon, 10 Nov 2025 18:41:42 +0000",
          "title": "Apple TV execs dismiss introducing an ad tier, buying Warner Bros. Discovery",
          "standfirst": "Apple execs say Apple TV shows and movies are about \"emotional\" experiences.",
          "content": "The heads of Apple TV have “no plans” to bring ads to the streaming service, balking, at least for now, at a strategy that has driven success for Apple’s streaming rivals. In its November 2025 issue, British movie magazine Screen International asked Eddy Cue, senior vice president of Apple Services, if there are plans to launch an ad-based subscription tier for Apple TV. Cue responded: Nothing at this time. … I don’t want to say no forever, but there are no plans. If we can stay aggressive with our pricing, it’s better for consumers not to get interrupted with ads. The comments follow reports over the years suggesting that Apple has been seeking knowledge on how to build a streaming ads business. Most recently, The Telegraph reported that Apple TV executives met with the United Kingdom’s ratings body, Barb, to discuss what tracking ads on Apple TV would look like. In 2023, Apple hired advertising exec Lauren Fry as head of video and Apple News ad sales.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Severance_Photo_0201-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/Severance_Photo_0201-1152x648.jpg",
      "popularity_score": 308.3989047222222,
      "ai_summary": [
        "Apple TV executives are not planning an ad-supported tier.",
        "Apple executives are not interested in acquiring Warner Bros. Discovery.",
        "Apple executives emphasize \"emotional\" experiences in content.",
        "The company is focused on its current content strategy.",
        "This decision reflects Apple's approach to streaming services."
      ]
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Mon, 10 Nov 2025 18:09:28 +0000",
      "title": "New project brings strong Linux compatibility to more classic Windows games",
      "neutral_headline": "New project brings strong Linux compatibility to more classic Windows games",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/11/new-project-brings-strong-linux-compatibility-to-more-classic-windows-games/",
          "published_at": "Mon, 10 Nov 2025 18:09:28 +0000",
          "title": "New project brings strong Linux compatibility to more classic Windows games",
          "standfirst": "But author warns that Direct3D 7 \"is a land of highly cursed API inter-operability.\"",
          "content": "For years now, Valve has been slowly improving the capabilities of the Proton compatibility layer that lets thousands of Windows games work seamlessly on the Linux-based SteamOS. But Valve’s Windows-to-Linux compatibility layer generally only extends back to games written for Direct3D 8, the proprietary Windows graphics API Microsoft released in late 2000. Now, a new open source project is seeking to extend Linux interoperability further back into PC gaming history. The d7vk project describes itself as “a Vulkan-based translation layer for Direct3D 7 [D3D7], which allows running 3D applications on Linux using Wine.” More options are always welcome The new project isn’t the first attempt to get Direct3D 7 games running on Linux. Wine‘s own built-in WineD3D compatibility layer has supported D3D7 in some form or another for at least two decades now. But the new d7vk project instead branches off the existing dxvk compatibility layer, which is already used by Valve’s Proton for SteamOS and which reportedly offers better performance than WineD3D on many games.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/arxfatalis.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/arxfatalis.png",
      "popularity_score": 285.86168250000003,
      "ai_summary": [
        "A new project enhances Linux compatibility for Windows games.",
        "The project aims to improve the gaming experience on Linux.",
        "The author warns of challenges with Direct3D 7.",
        "Direct3D 7 presents interoperability issues.",
        "The project seeks to overcome these compatibility hurdles."
      ]
    },
    {
      "id": "cluster_81",
      "coverage": 1,
      "updated_at": "Mon, 10 Nov 2025 16:29:34 +0000",
      "title": "The Running Man’s final trailer amps up the high-octane action",
      "neutral_headline": "The Running Man’s final trailer amps up the high-octane action",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2025/11/the-running-mans-final-trailer-amps-up-the-high-octane-action/",
          "published_at": "Mon, 10 Nov 2025 16:29:34 +0000",
          "title": "The Running Man’s final trailer amps up the high-octane action",
          "standfirst": "Get ready for what could be the \"biggest underdog win in game show history.\"",
          "content": "It’s shaping up to be an excellent season for Stephen King adaptations. In September, we got The Long Walk, an excellent (though harrowing) adaptation of King’s 1979 Richard Bachman novel. Last month, HBO debuted its new series IT: Welcome to Derry, which explores the mythology and origins of Pennywise the killer clown. And this Friday is the premiere of The Running Man, director Edgar Wright’s (Shaun of the Dead, Baby Driver, Last Night in Soho) take on King’s novel of the same name. So naturally Paramount has released a final trailer to lure us to the theater. As previously reported, the 1987 action film starring Schwarzenegger was only loosely based on King’s novel, preserving the basic concept and very little else in favor of more sci-fi gadgetry and high-octane action. It was a noisy, entertaining romp—and very late ’80s—but it lacked King’s subtler satirical tone. Wright expressed interest in adapting his own version of The Running Man in 2017, and Paramount greenlit the project four years later. Wright and co-screenwriter Michael Bacall envisioned their film as less of a remake and more of a faithful adaptation of King’s original novel. (We’ll see if that faithfulness extends to the novel’s bleak ending.) Per the official premise:Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/running1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/running1-1152x648.jpg",
      "popularity_score": 279.1966825,
      "ai_summary": [
        "The final trailer for \"The Running Man\" has been released.",
        "The trailer highlights the film's action sequences.",
        "The film is expected to have high-octane action.",
        "The film could feature a major underdog victory.",
        "The trailer builds anticipation for the film's release."
      ]
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Mon, 10 Nov 2025 17:37:14 +0000",
      "title": "Runaway black hole mergers may have built supermassive black holes",
      "neutral_headline": "Runaway black hole mergers may have built supermassive black holes",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/11/runaway-black-hole-mergers-may-have-built-supermassive-black-holes/",
          "published_at": "Mon, 10 Nov 2025 17:37:14 +0000",
          "title": "Runaway black hole mergers may have built supermassive black holes",
          "standfirst": "Early superdense star clusters may have planted seeds for monster black holes.",
          "content": "A new simulation could help solve one of astronomy’s longstanding mysteries—how supermassive black holes formed so rapidly—along with a new one: What are the James Webb Space Telescope’s (JWST) “little red dots?” Invisible leviathans lurk at the cores of nearly all of the 2 trillion or so galaxies strewn throughout space-time. Monster black holes entered the cosmic scene soon after the Universe’s birth and grew rapidly, reaching millions or even billions of times the Sun’s mass in less than a billion years. Astronomers have long wondered how these supermassive black holes could have grown so hefty in such little time. The monster black hole mystery became even more perplexing in 2022 when “little red dots” were spotted at the far edges of space. When these tiny scarlet orbs began unexpectedly popping up in JWST images of the distant Universe, their nature was hotly debated. Now that scientists have amassed a sample of hundreds of them, many think the dots are growing supermassive black holes.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/image-1-1152x648-1762702202.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/image-1-1152x648-1762702202.png",
      "popularity_score": 275.3244602777778,
      "ai_summary": [
        "Runaway black hole mergers may have created supermassive black holes.",
        "Early star clusters could have seeded monster black holes.",
        "The mergers may have contributed to black hole growth.",
        "The research explores the origins of supermassive black holes.",
        "This research provides insight into black hole formation."
      ]
    },
    {
      "id": "cluster_84",
      "coverage": 1,
      "updated_at": "Mon, 10 Nov 2025 16:10:06 +0000",
      "title": "F1 in Brazil: That’s what generational talent looks like",
      "neutral_headline": "F1 in Brazil: That’s what generational talent looks like",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/11/f1-in-brazil-thats-what-generational-talent-looks-like/",
          "published_at": "Mon, 10 Nov 2025 16:10:06 +0000",
          "title": "F1 in Brazil: That’s what generational talent looks like",
          "standfirst": "Filled with passionate fans, the racetrack between the lakes is a favorite.",
          "content": "After a weekend off, perhaps spent trick or treating, Formula 1’s drivers, engineers, and mechanics made their yearly trip to the Interlagos track for the Brazilian Grand Prix. More formally called the Autodromo Jose Carlos Pace, it’s definitely one of the more old-school circuits that F1 visits—and invariably one of the more dramatic. For one thing, it’s anything but billiard-smooth. Better yet, there’s elevation—lots of it—and cambers, too. Unlike most F1 tracks, it runs counterclockwise, and it combines some very fast sections with several rather technical corners that can catch out even the best drivers in the world. Nestled between a couple of lakes in São Paulo, weather is also a regular factor in races here. And indeed, a severe weather warning was issued in the lead-up to this weekend’s race. You have to hit the ground running This was another sprint weekend, which means that instead of two practice sessions on Friday and another on Saturday morning, the teams get one on Friday, then go into qualifying for the Saturday sprint race. The shortened testing time tends to shake things up a bit, and we definitely saw that this weekend.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2245155272-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2245155272-1152x648.jpg",
      "popularity_score": 253.87223805555556,
      "ai_summary": [
        "The article discusses Formula 1 racing in Brazil.",
        "The race is held at a favorite racetrack.",
        "The racetrack is located between lakes.",
        "The race is filled with passionate fans.",
        "The article highlights the talent of drivers."
      ]
    },
    {
      "id": "cluster_108",
      "coverage": 1,
      "updated_at": "Mon, 10 Nov 2025 12:00:24 +0000",
      "title": "NASA is kind of a mess: Here are the top priorities for a new administrator",
      "neutral_headline": "NASA Administrator Faces Tough Decisions Regarding Priorities",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/nasa-is-kind-of-a-mess-here-are-the-top-priorities-for-a-new-administrator/",
          "published_at": "Mon, 10 Nov 2025 12:00:24 +0000",
          "title": "NASA is kind of a mess: Here are the top priorities for a new administrator",
          "standfirst": "\"He inevitably will have to make tough calls.\"",
          "content": "After a long summer and fall of uncertainty, private astronaut Jared Isaacman has been renominated to lead NASA, and there appears to be momentum behind getting him confirmed quickly as the space agency’s 15th administrator. It is possible, although far from a lock, the Senate could finalize his nomination before the end of this year. It cannot happen soon enough. The National Aeronautics and Space Administration is, to put it bluntly, kind of a mess. This is not meant to disparage the many fine people who work at NASA. But years of neglect, changing priorities, mismanagement, creeping bureaucracy, meeting bloat, and other factors have taken their toll. NASA is still capable of doing great things. It still inspires. But it needs a fresh start.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/polaris-dawn-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/polaris-dawn-1152x648.jpg",
      "popularity_score": 243,
      "ai_summary": [
        "NASA's new administrator will need to make difficult choices regarding agency priorities.",
        "The article discusses the challenges and priorities facing the new NASA administrator.",
        "The administrator will need to manage budget constraints and competing projects.",
        "The article highlights the importance of balancing scientific goals with practical considerations.",
        "The new administrator will need to navigate political pressures and public expectations."
      ]
    },
    {
      "id": "cluster_122",
      "coverage": 1,
      "updated_at": "Sun, 09 Nov 2025 15:34:52 +0000",
      "title": "Here’s how orbital dynamics wizardry helped save NASA’s next Mars mission",
      "neutral_headline": "Orbital Dynamics Aids NASA's Mars Mission Success",
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/11/heres-how-orbital-dynamics-wizardry-helped-save-nasas-next-mars-mission/",
          "published_at": "Sun, 09 Nov 2025 15:34:52 +0000",
          "title": "Here’s how orbital dynamics wizardry helped save NASA’s next Mars mission",
          "standfirst": "Blue Origin is getting ready to launch its second New Glenn rocket.",
          "content": "Blue Origin scrubbed Sunday’s launch attempt due to poor weather, a cruise ship in restricted waters near the launch site, and ground system issues. The company says the next available launch opportunity is Wednesday, November 12, with a window opening at 2:50 pm EST (19:50 UTC). CAPE CANAVERAL, Florida—The field of astrodynamics isn’t a magical discipline, but sometimes it seems like trajectory analysts can pull a solution out of a hat. That’s what it took to save NASA’s ESCAPADE mission from a lengthy delay, and possible cancellation, after its rocket wasn’t ready to send it toward Mars during its appointed launch window last year. ESCAPADE, short for Escape and Plasma Acceleration and Dynamics Explorers, consists of two identical spacecraft setting off for the red planet as soon as Sunday with a launch aboard Blue Origin’s massive New Glenn rocket.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/NG2-Launch-Rollout-3-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/NG2-Launch-Rollout-3-1152x648.jpg",
      "popularity_score": 141,
      "ai_summary": [
        "Orbital dynamics expertise helped save NASA's next Mars mission.",
        "Blue Origin is preparing to launch its second New Glenn rocket.",
        "The article discusses the technical aspects of the mission's trajectory.",
        "The mission's success depends on precise calculations and maneuvers.",
        "The article highlights the role of orbital mechanics in space exploration."
      ]
    }
  ]
}